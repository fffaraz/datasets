No offense to the author of the blog, but it came up in the comments that he had never heard of Boost. If you've never heard of Boost then your appreciation of a C++ book doesn't mean that much to me.
Not a major release, but if you're interested in 3D rendering and haven't looked at Ogre before you should check it out.
It's funny that first post on c++ subreddit is about Lisp ;)
People are actually voting this down, yet it's clearly a real issue. Reddit can be a crazy place.
The logo is still white is many area's of the website. The first place I spotted a white logo was in the prefernces section. I would give them until the end of the week to fix this.
I never understood the pointless down voting.
http://www.airs.com/blog/archives/154
Did you even read the posted article? It is a completely different use of volatile than the blog your comment links to. The ddj article espouses a potential use as a function modifier in an attempt to force users of a class to lock the class before using it. The author (Andrei Alexandrescu) claims to have used it in a project and that it has pretty much eliminated race conditions (but not deadlocks.) The blog you link to talks about using it as a variable modifier. The irony is that a comment, in the blog you link to, links to this same article. The author replies: &gt;Thanks for the pointer to the article. I admit that I had not considered that way of using volatile in C++ to prevent inadvertent unlocked accesses. That seems like a good idea. 
Interesting read, indeed. C++ always baffles me as an inspiring "discovery by accident", with beautiful stuff.
volatile is very useful in omitting compiler optimization when relying on atomic operations (such as interlocked modifications on machine word variables). However volatile won't fix complex race conditions where non-atomic operations need to take place. For that you have to use mutex/semaphore/etc to lockdown a section of the code. Interesting read nevertheless since multi-threading is often an afterthought than a design criterion. 
The article title is a little misleading, the blog is called "Core Dump", not the book. Having said that, to be fair, the book to which he's actually referring is ["Programming in C++"](http://www.amazon.com/gp/product/0131827189/ref=cm_cr_pr_product_top) which according to Amazon is aimed at beginners and C developers interested in C++. I wouldn't necessarily expect them to cover Boost, nor would I necessarily expect the typical reader of this book to be aware of Boost.
I can't wait.
There are some really exciting new features their that fix a lot of C++'s warts. The new for loop syntax, initializer loops, initializer lists, variable argument templates, lamda functions are all features I expect to get a lot of use in my code. Lately Microsoft has been surprisingly cooperative with C++ standards so we can probably expect them to ship an update to Visual C++ with OK compliance pretty soon after the standard is finalized.
Lots of good stuff here, some of which I hadn't heard of before. The new user defined literals seems like yet another step to allow user defined types to be first class types.
This is an old article, which IIRC, has since been criticized fairly extensively. Apparently there are some pretty major negative consequences to using volatile in this manner.
Related: [Threads Cannot be Implemented as a Library](http://lambda-the-ultimate.org/node/950)
I'd wait for C++0x with lambda support instead of using some hacked up library.
awesome, thanks
Wow, I'm excited and all that but... Don't you think 0x feels a bit, um, heavy? I mean, some of these are extremely eclectic. I'm sure that's what they said about templates back in the day, but... Assigning delete to a member function? Doesn't make much sense IMHO.
Good article. I really need to read up on 0x. I always thought the weirdest feature (already existing) was the conversion-operator. Come on, operator int() const? The [seed](http://reddit.com/r/cpp/info/6lc3b/comments/c046h58) for this article is so obvious too. ;-)
Ha, I got a real kick out of this post. The first paragraph is spot-on. Still, I can't wait to get my hands on the C++0x goodies.
&gt; I always thought the weirdest feature (already existing) was the conversion-operator. Come on, operator int() const? Well, I think there is a lot of contenders for "weirdest feature". Are you sure "operator int() const" wins out over say "T&amp; operator++(int)"? &gt; The seed for this article is so obvious too. ;-) Well, only obvious if you are a cpp.reddit.com subscriber. ;-)
Did the Ogre license ever change? I thought I remembered something in it that used to require you putting the ogre logo on the product.
Oh no, there has never been any requirement that is anything like that. Ogre is LGPL, no more, no less. If you improve Ogre, you have to share the improvement. But you can use Ogre in your projects and your code remains yours, private and unaffected by Ogre's license.
I understand the LGPL; for some reason I thought they had a different license with that restriction. A quick search of their commercial license didn't bring it up either. It must have been some other open source graphics/game engine I looked at around the same time. 
Just to clarify, the "commercial" license is actually a way for people who need to link statically, like console developers, to use Ogre. Ogre is free for any use, commercial or otherwise, that doesn't involve static linking or other violations of the LGPL.
You need perl, so if you're on unix or if you're running cygwin, you're pretty much good to go.
The existence of this tool is probably the best reason to get going with the implementation of concepts!
Modded down simply because I thought everyone know about this thing.
5 people disagree, but thanks for helping.
Yeah, it's clear fewer people agree than disagree with me, which is kind of shocking. I just didn't want to mod down and have people think it was because the tool wasn't worth using. It really, really is worth using.
Let the haters keep hatin' Let the playas keep playin' Fuck yo bitch language cuz C++ keeps payin' 1994! MC Stroustrup in da hooouuuuuse! 
hmm, the so-called programmers that roam on reddit might not like this one :)
Because C++ &gt; Python ?
Well C++ is clearly a good language, and it is now 14 years after that paper was published and it is the first language I learned in Computer Science at my college (in 2006), even before Visual Basic. C++ is a powerful language, then you get the Microsoft people who think that C++ .NET is the greatest thing since sliced bread. C++ without the .NET portion is a wonderful language in my book, and anyone who disagrees is just wrooooong.
most people don't realize that STL can give you most of the valuable stuff from interpreted languages without all the crap ...
Spend 30 minutes looking for a sample data file... like everything else Sun does, the important stuff is very hard to find but useless information is on every page. I actually wanted to try and write a parser in C/assembly... oh well another time.
Try clicking on the arrow for "The #define Guard". Do you see 3 different things in IE, FF and Opera?
Wot no C++ exceptions? Seriously?!
If your code isn't exception safe, you probably already have resource leaks anyway. Fix them, make your code exception safe, and then use exceptions, because propogating errors and forgetting to handle them (and getting terminate()d) is much better IMO than accidentally ignoring errors and then behaving in mysterious and broken ways somewhere down the line. RAII: It exists for a reason.
I think the using namespace directive is ok in a function scope. I definetly think it should be forbidden at the top of a *.cc file.
Useful guide but I don't agree with their view of exceptions and RTTI. While they do admit that if they had to start all over they may consider exceptions, but RTTI is a lightweight way of maintaining generic base objects and using dynamic_cast to safely upcast. However not knowing all the details behind their design it's not really a criticism but more of a curiosity. 
This is a huge problem in the project I'm working on. The code has evolved over time to expect multiple includes in the right order! I think I'm actually going to take a crack at running his script to detect all of the problematic headers.
Mentioned in TFA's comments, but not answered: why should I use this over CppUnit or Boost.Test? Reading the docs doesn't tell me if they're easier to use in a real situation. Anybody have an expert's point of view?
wow, JSON for STL maps!!
I noticed that too -- Google Test's site says how great it is that this library is based *Unit and how you'll feel right at home if you ever used JUnit or PyUnit, but *nowhere in the entire wiki does it menation CppUnit*, not once. It almost looks like they're in denial about its existence...
...or CxxUnit for that matter... or a variety of others.
Years ago when I first saw the phrase "GPU graphics pipeline" I thought Pfft! How can a 3D scene be coerced to a 1D pipeline? I had been building my own naive geometry rendering engine as a teen and my approach was dependant on a global world data structure. I thought there was no other way. You can't put a graph into a pipeline, right? It was pretty humbling to see how a real rendering engine worked and it's a perfect example of parallelism with pipelines. As usual, I was wrong. Incidentally, Unix has had the right idea for decades. 
&gt; “Oh, and we will be adding a new step to our build system. Every header file header.h will be tested to ensure it is a compilable standalone by attempting to build a file like this.” She wrote on the whiteboard: &gt; &gt;&gt; #include "header.h" &gt;&gt; int main() { } I like this idea
trip report confused me thoroughly. Thought I was on erowid or something.
Prefer [mingw](http://www.mingw.org/) use that with automake/libtool et al, to port from linux to osx to windows without missing a step. don't need a dependency lib like cygwin either.
the problem is that you may still need windows.h 
This is true, and unfortunate, but I wrote a foundation library with automake conditionals to take care of most of that. Took some work, but it's nice to be able to go from embedded linux to X11 to OSX Quartz to WinGDI/DX, and ActiveX and NsPlugin, and opengl in there too, without having to change the front-end code. Fire one make and you're off. The only problem I had with cyg was that you need to send a dependency dll along with the app, which isn't always feasible, while mingw gave you nice clean windows apps that look like they came from vc++(which I hate and is unportable). edit: would like to figure out how to integrate icc into this mix someday, because mingw's performance is kinda lame compared to vc++ unless you hand-tune the whole thing.
i think that cygwin performance are worst than those of mingw...having windows things inside your apps isn't that bad anyway. Thats like if you want to use sockets/thread/dynamic shared object or anything that is mostly dependent of the OS you're using. you have to find a lib or roll your own. The problem would only be corrected if programming in C/C++ was exactly the same whatever OS you're using. Unfortunately. This isn't actually the case. it would make things so much more easier if every OS had the same function signature / object name etc. 
So far it actually seems to do a bit less than Boost.Test. Just read a post about how EXPECT versus ASSERT is this grand glorious new idea when virtually every other unit testing framework has them. Hrm.
Well, you have to recognize that while Google doesn't think everything they do is brilliant and innovative, there are lots of other people who do.
C++ and Java patterns: Making simple things Really Fucking Complex.
I stumbled on this when finally going through the cpp subbreddit, and the article is really insightful. However, some of the comments here look like as if the commenters would have just rushed through the article (or not even that). For those considering the same, here is what the article really says: * It is possible to have a generic, reliable and simple mechanism (LockingPtr template class in the article) for introducing mutex-protected critical sections in the code. * With the LockingPtr class, it is possible to utilize volatile qualifier with user-defined classes to make compiler catch accidental race conditions. * The article also points out that even simple assignments of primitive C++ types are not atomic, and that volatile qualifier on them has also a bit different semantics than on user-defined classes, and shared primitive variables should reside inside volatile objects to benefit from the LockingPtr mechanism. ...And a lot of things in between. It's really worth a good, thoughtful read. 
I'm just glad that BCB 2008 will FINALLY support unicode.
As geeked out as I am about Phoenix, the need for a "private" PDB (w/stack variable types etc.) is a major deal-breaker for any real reverse engineering task. In the wild you will often encounter binaries linked against PDBs, though pretty much only in the case of official Microsoft OS binaries will you be able to acquire them (from the symbol server), and when you do it's the "public" symbols, not the aforementioned private ones. Negative outlook aside, I wonder what differences in testing speed and results would arise from using something like [BinHunt](http://flyer.sis.smu.edu.sg/tech08.pdf) instead of the lattice framework. Oh, and I wish those m6/m7 links went somewhere :)
"it is the developer responsibility to check that the reading/writing std::list&lt;T&gt;::iterator is atomic" That's a pretty bad call. The C++ standard says nothing about the atomicity of iterators. The author even mentions one common implementation (MSVC) where the iterators are NOT atomic. This is a cool trick, but stay away if you value reliability.
Upmod for manbearpig.
Upmodded for insanity.
ahhh the macros my eyes my eyes!!!
Seriously, the compile-time factorial is getting so old it's becoming the "Hello World" of template meta programming. Do these people know no other example?
sorry, the author has no clue ...
I completely agree. I only clicked through in the hopes that "algorithms" in the title meant that it would show something other than the factorial function.
&gt; Is garbage collection a failed concept? No.
As others have pointed out, there are far more useful uses for C++ templates. I wouldn't even introduce people to C++ templates with factorial&lt;&gt;
good post!
Start of 4th paragraph: "Boost Date Time have nice documentation." What's the point in this blog post then? It's not even written well.
Basically advertising for Cilk++.
The last comment about how this enables objects to be allocated in stack-based char arrays is interesting. What would that be primarily used for? Stack-based memory pools?
This blog entry about a poor article containing falsehoods about C++ is itself a poor article full of falsehoods about C++. Not sure if he'll let my comment through moderation, so here goes. "Using templates doesn’t cause massive bloat." -- False in general. Suppose we have a std::list&lt;A *&gt; and a std::list&lt;B *&gt;. The compiler is most likely going to generate two sets of std::list-related functions that are identical on the binary level. Some implementations will cast to a void *, but don't count on it. "Empty constructors are optimized out during link." -- Only for compilers with link-time code generation, and even then it's not guaranteed. "[ill-informed crap about relocations]" -- You don't know what "relocations" means -- it has nothing to do with position-independent code. In fact, each entry in a C++ VTable will require relocations, if the module is relocatable (e.g. in a DLL). This will in fact slow down the load time of an application.
I have to agree with you. I was terribly disappointed when I read this one. Modern compilers have closed a lot of the issues that those articles were talking about, but some of the other stuff... the blog writer doesn't even seem to understand what the problem is. Oh, and I thought OCR stood for optical character recognition, but I apparently know more about C++ than the guy who wrote said article.
Ditto about OCR.
&gt; Some implementations will cast to a void *, but don't count on it. Poor implementations cause massive bloat. I've had to work with Java lately and I would much rather have the potential for bloat than type erasure. &gt; You don't know what "relocations" means -- it has nothing to do with position-independent code. Well... Technically it has something to do with the absence of PIC... That's almost something. &gt; if the module is relocatable If the module is relocat*ed*. DLLs are given a preferred link address and if they can be loaded at that address then they won't be relocated. &gt; This will in fact slow down the load time of an application. More importantly it means the instance can't be shared with other processes and can't be backed by the file it was loaded from. So it'll take more physical memory and pagefile space.
Fair enough on the distinction in point #3, and good point for #4.
&gt;"Using templates doesn’t cause massive bloat." -- False in general. Suppose we have a std::list&lt;A *&gt; and a std::list&lt;B *&gt;. The compiler is most likely going to generate two sets of std::list-related functions that are identical on the binary level. Some implementations will cast to a void *, but don't count on it. I don't think your list example is a good representation of what he was trying to say with that. Even still I'll try to go with it. I think he was saying that the alternative of writing your own AList and BList functions would create similar code bloat only it would be less maintainable. Obviously, that's not very realistic though, since a typical C implementation would be closer to using list&lt;void*&gt;. It's kind of disingenuous when you consider the later point of: &gt;C++'s tighter type-checking makes it difficult to write the space-conscious code reuse common to C applications (think: void *). Not sure how to get it to break up these quotes without intervening text... &gt;"Empty constructors are optimized out during link." -- Only for compilers with link-time code generation, and even then it's not guaranteed. GCC has been able to do this at least as far back as 3.4.0. It's not exactly automatic though. You just need a few options: "-ffunction-sections -fdata-sections -Wl,--gc-sections". I haven't read the rest of the article yet, but the fact that people are pouncing on the author doesn't give me faith.
Wouldn't erasing the type make the compiler miss out on some optimizations? eg: function calls through an iterator. &gt;You don't know what "relocations" means -- it has nothing to do with position-independent code. In fact, each entry in a C++ VTable will require relocations, if the module is relocatable (e.g. in a DLL). This will in fact slow down the load time of an application. Doesn't rebasing the DLL get rid of the relocation problem? Here's a quote from an old Matt Pietrek article: &gt;When the linker creates an executable, it assumes that the file will be memory-mapped to a specific location in memory. That address is stored in this field, assuming a load address allows linker optimizations to take place. If the file really is memory-mapped to that address by the loader, the code doesn't need any patching before it can be run. In executables produced for Windows NT, the default image base is 0x10000. For DLLs, the default is 0x400000. In Windows 95, the address 0x10000 can't be used to load 32-bit EXEs because it lies within a linear address region shared by all processes. Because of this, Microsoft has changed the default base address for Win32 executables to 0x400000. Older programs that were linked assuming a base address of 0x10000 will take longer to load under Windows 95 because the loader needs to apply the base relocations. 
Regarding the first point, I should be more clear. When I said the compiler will cast the A* and B* to a void *, what I mean to say is that it does this on the _binary level_ -- everything still continues to function as usual inside of the compiler, but in the generated assembly language, the list functions will be shared between the two. Regarding rebasing the DLLs, yes, choosing an imagebase that doesn't overlap with other DLLs in the project / operating system is a good idea that speeds up the process of loading, but it isn't fool-proof: what happens if, for example, an extra DLL gets mapped into the process' address space (say via the AppInit DLLs registry key) which clashes with the imagebase of one of the loaded modules? One of them is going to have to be rebased anyway.
This would be cool if it didn't kick out pages and pages of error messages under gcc 4.3 and actually compiled.
Had this same problem a while ago. Thinking back I would've tried to use basic C, but I have always been addicted to C++ for some stupid reason. 1. MUST get rid of exceptions. They are not always supported on ucontrollers, and generally end up being more trouble than they're worth. Also need to be careful about stack-allocating objects, especially in deep call-stacks. 2. Templates will kill you, but if you keep them simple (lists, etc) the size is mitigated, especially if you don't actually call functions on the templated objects (storage/pointers only). Honestly though, for simple stuff go back to C if you can. I recently rewrote a networking server I wrote in C++ originally. Took me 1/3 the time because I could just write functions to handle what I wrote toolkit sub-classes to handle in the first app. Made coding fun again...
I feel bad, but this isn't news in any way. Destructors with stack variables are used this way all the time
I don't have a multi-core processor, but between the bit I've read and the upgrades listed here, TBB sounds pretty good. Anyone have any personal experience with the library?
I would recommend plain C for an embedded environment. This is one of the few locations where it is worth it. If you do want to go down the C++ route - I would suggest keeping it as C-with-classes: disable RTTI and disable exceptions. Be careful with templates and the standard libraries. For example most implementations of std::vector do not shrink.
In the C++ case, the solution is to use an initializer list with an owning pointer, such as [std::auto_ptr](http://www.cppreference.com/cppmisc/auto_ptr.html) or [boost::scoped\_ptr](http://www.boost.org/doc/libs/1_35_0/libs/smart_ptr/scoped_ptr.htm). i.e.: class Gadget { scoped_ptr&lt;Widget&gt; w; public: Gadget() : w(new Widget()) { throw new exception(); // … or some API call might throw } }; Added bonus: it's [RAII](http://www.hackcraft.net/raii/) so no need to clean up (the smart pointer does cleanup for you).
Checks for null like the following from TFA are also unnecessary, the delete operator is null pointer safe. if( w != nullptr ) delete w; I can see why they did it, for comparison to C# and Java, but this sort of minor thing spreads misinformation.
stupid, because they don't use whats in your processor to compute vectors. and matrix.
&gt;(Furthermore, C++ developers will know that the test is unnecessary for a second reason: Delete is a no-op if the pointer passed to it is null, so there’s never a need to check for that special case.)
doing matrices as pointers to rows isn't exactly the best. I find it's better to use class with a double* with high/wide parameters and implement begin()/end() and operator[]. Might not have a lot of impact on how this code runs but constructing the type of matrices he's using is very expensive.
I know many of these, but this could be a nice reference to help pass them on, thanks!
Discussed here: http://codeblog.bsdninjas.co.uk/index.php?/archives/69-Loops-considered-harmful.html
[Counterpoint](http://www.acm.org/ubiquity/views/v7i24_fallacy.html)
lol, not the best comparison predicate there.
There are two problems here: 1. He's using the STL anyway, so there's no reason to not use the builtin function "random_shuffle" which does exactly what he wants. 2. A better idea for writing your own version of shuffle is to not just swap random items over and over again, but instead, choose an item at random between element zero and element *n* (initially the length of the vector), swap the selected item with element *n*, then decrement *n* and repeat.
So, I'm hoping they're in the middle of editing it or something, but at the moment 4-12 have nothing in them, they're just headers. and #6 is the same header as #3
If you're giving sample code to show how to use a library _never_ bring all the names into the global namespace with something like `using boost::progress_timer` -- it makes the code far too hard to skim read. EDIT to add: &gt;Given a C++ string, if you want to pass it's contents as a char* to a function that takes a (non-const) char* rather than a const char* (like legacy_api above), you have to make a copy of the string's underlying character array into a new array, and pass the base address of the array instead. What utter twaddle. Sigh. This is what `const_cast` is for _unless_ the C API is going to write to the string (which the example doesn't) -- and C APIs aren't done like that because it doesn't even work in C.
What happens if the C API writes to the const-casted string? I assume most STL implementations return the non-const internal pointer in data/c_str.
Very cool. This seems to be somewhat of a response to another article recently published in DDJ on lock free queues, that REALLY seemed too good to be true! Seems it was... I had planned on revisiting that same article for a perfect producer/consumer scenario I'm working on, and this rebuttal might have just saved my hash!
"Writing lock free software in c++ is nearly impossible " in C++. But with proper application of state diagrams or a specially designed toolkit like in Erlang or Ada life gets easier somewhat.
The return from c_str() and data() are both `const x *` -- the character type `x` depends on which string type we're talking about. If the buffer is written to then as I recall the results are undefined (for example, it can be a buffer shared between many strings). If you want a character buffer to write to then by all means use `boost::scoped_array`, or even just `std::auto_ptr`. I have an example of it's use a couple of weeks ago here on Reddit. http://www.reddit.com/comments/6sjz0/why_java_will_always_be_slower_than_c/c04r8od
&gt; that REALLY seemed too good to be true! Seems it was... Yeah, I was waiting for this article. Rule of thumb: If it's concurrent, and it doesn't involve locks and/or memory barriers, it doesn't work.
Announcement here: http://www.ultimatepp.org/forum/index.php?t=msg&amp;th=3658&amp;start=0&amp;
Yeah, except! there *is* that lovely exception described in the original article. You can make a lock free, producer/consumer queue, but you can't use some random (stl) container implementation! You would want to use a pure fixed array for the storage and then use atomic read/writes to index variables for the read and write head on the queue. I think the original author probably learned this technique and somehow made a leap of logic thinking that the stl container operations were atomic! Doh, and published in DDJ no less. Incidentally, if you are interested in implementing this technique, before they print the repaired version in DDJ, check out the apache portable runtime. They have cross platform routines for doing atomic reads and writes to index variables, and on platforms that don't allow atomic read/writes in hardware, they are emulated with mutexes, so your code can stay generic.
No; that is no exception. If you want your code to be lock-free, it *must* use memory barriers. You need atomic *and* ordered writes and reads.
Wouldn't an atomic test-and-set instruction cover that? -edit- Mulling it over more, I see your point. I'm curious how the next installment in the article will address this. 
If we're talking about assembly programming on specific hardware that has certain auto-memory-barrier guarentees (x86 does not reorder writes, for example), then I could imagine a concurrent program which could use test-and-set, sure. But not this one. Take a look at page 3 and 4 of the article.
Wow. Yeah CPUs have become much hairier beasts since the olden days. Thanks for the headsup, I think I will stick with critical sections for now.
One may want to read the overview page at http://www.ultimatepp.org/www$uppweb$overview$en-us.html since it mentions several points of which one might want to be aware. 
The author seems to make some observations and then makes few some specific criticisms: * The author has doubts about fundamental C++ abstractions and their associated constructs (Constructors, destructors, virtual dispatch, 'copying' etc.) harming performance. * C++ compilers generate code to do things behind the programmers back (like default shallow copying constructors). To be honest all I glean from this blog post is "Highly experienced C programmer has difficultly coming to terms with C++." This is ultimately the biggest problem with C++, people with C experience try it, but they treat it as an extension of C, failing to approach it as a completely new language like they would learning C#, Python, Perl or D. At the end, the author tells what triggered his rant, and he reads as pissed off. To him I would offer this advice: * Always add a default constructor, a copy constructor, and an assignment operator to all classes. Do this as soon as you start writing a class. * Make the copy constructor and assignment operator protected until they need to be public. This will help catch unwanted copying. * Make all of your constructors explicit until you need them to be implicit. * Make your destructor's virtual. * Consider isolating POD (data) parts of your objects into simple member struct's that way you can benefit from compiler provided copying and assignment without writing too much tedious code. * Use Boost to supplement the C++ SL and STL. * Learn to love the STL, it really is thoughtfully put together even if you hate it now. For example, std::for _each, std::ostream _iterator and std::istream _iterator are little gems that are easy to add support for in your own classes. * Checkout [KDE's Binary Compatibility Issues with C++](http://techbase.kde.org/Policies/Binary_Compatibility_Issues_With_C%2B%2B), they are a good summary of what you can get away with in C++ with regards to ABI. * If you are using GCC, for new C++ programs use -fvisibility=hidden and the visibility attribute effectively. This helps with ABI maintenance. * C++ is not C, where you don't need mutable references use C++ references at the very least, not raw pointers. * Since you're a C programmer, consider avoiding exceptions, for example when dynamic_cast'ing, do so on pointers and check for 0 (NULL) if this makes you feel more comfortable.
The author admits to being inexperienced but claims that people with more experience than him agree with him. If someone has more experience than you it's often hard to know it. On what grounds would you judge the experience level of someone with more experience than you? Surely not on the grounds of experience!?
How can the most popular language be "elitist"? I don't get it. I don't even get how any mainstream computer language could be considered elitist. Anyone is allowed to program with it. Maybe some obscure language that somebody considers to be "cool and bohemian" might be somewhat elitist, but even then I don't think elitist is the right word. Maybe bohemian is more the way I'd think of it. To me an elitist computer language would be one that was proprietary and you charge $250,000 for a license for the compiler or something.
I'm so used to hearing false questions: Is X a Y? When they really mean to say the statement: X is Y. I was pleasantly surprised to find this article is about how C++ is NOT elitist.
Well Obama does love OO programming. I'd say yes, it's elitist.
very good article
Fucking hell, some guy leaves a comment on a blog and it spawns a post and more comments. I need to get my face out of this paper bag. The original commenter no doubt being a Java programmer, rightly had an inferiority complex.
I didn't actually go to the Javalobby article to see what they said, but I suspect they're saying C++ is elitist because people that write in C++ tend to look down on managed languages like Java. Maybe you don't, and good for you, but overwhelmingly I hear C++ people say that GC languages can't be as fast and therefore can't be as good. Whether or not that's true is irrelevant, it's an elitist position
He's apparently also not a fan of the bubble sort.
&gt; This is more personal opinion than anything, but I never found pointers to be that difficult of a thing to deal with. Once you get an understanding of them it’s really a trivial matter. I know that some people make a fuss because you have to always be thinking ‘is this a pointer to an object, or the object’, but that consideration has never slowed me down. **This** makes you elite. Some people *are* confused with pointers, and they're the ones usually bitching about C++ being elitist
&gt; How can the most popular language be "elitist"? I don't get it. I'm not sure what your metric for this is. Most of the metrics I've seen don't show C++ as "the most popular language""? More importantly though, popularity is largely orthogonal to the attitude/thinking behind a language.
&gt; except in the most special of situations. Uh, that's the point?
&gt; Each iteration of the outermost loop causes 1000 allocations and deallocations. 5000 such iterations result in 10 million switches between user and kernel code. Err, what? I think you'll find no malloc anyone actually uses does this, for pretty obvious reasons. e.g. FreeBSD: -% time ./complex Real: 0:00.37 CPU: 100.0% (0.000/0.375) Page: 0 Swap: 0 I/O: (0/0) Mem: 666 VCSW: 1 IVCSW: 4 A whole 1 voluntary context switch. And indeed a look at ktrace shows that once all the libraries have been mmapped in and malloc has started up and allocated its own scratch space, the app's memory use is handled by a single call to break().
I read through this article all the while thinking "Why...why would you do this?". The chances of writing something that still works in every circumstance, without leaving your code littered with unreproducable and undiagnosable bugs, and still giving you a performance boost, are vanishingly small. If you genuinely have a performance problem in your memory allocation, there are better ways of getting around it than re-defining operators new and delete. 
&gt; "Why...why would you do this?" The same reason why he would use scribd.com
A very good point, and well made. I used a PDF print driver to convert it to a more readable format. 
I gave up reading this about five pages in after I spotted the second serious error.
Intel's free Threading Building Blocks uses task stealing as well. 
The lesson here is don't make c++ into another language. There are things c++ does very very well and typing a couple extra lines won't necessarily kill you. The other thing that gets me in general is that too many programmers thing threading is something you do at the instruction level...well to properly nail threading you have to engineer it into your product from the get go...note the importance of the "engineer" part.
&gt; This project aims to come up with a comprehensive cross-platform library of networking routines for inclusion in the Boost C++ Library. But hasn't boost already accepted asio?
Yes, as of 1.35.0 (released in March). I guess that wasn't true when he posted his previous blog entry 9 months ago, or when he started.
And when will I have [stdint.h](http://en.wikipedia.org/wiki/Stdint.h) and [inttypes.h](http://en.wikipedia.org/wiki/Inttypes.h) by default in Visual Studio? Woops, never...
If command line processing is a significant bottleneck you have already failed. However, gperf is a useful tool.
Nothing wrong with these choices. They made decisions based on a generally consisistent policy backed up by a philosophy. It may not always be convenient but at least its predictable and it makes sense. And c++ isn't married to stl, it's a bolt on library.
tr1 is has regex as part of the C++ runtime library and majority of compilers already support it without using 3rd party library (Visual Studio 2008 SP1, g++ (latest version)). Just saying is all. My only gripe with boost is the 20MBs worth of code that you have to redistribute if you work on open source project, otherwise it does have some nice extensions. 
One of my greater frustrations is the my big corp. employer doesn't allow the use of Boost in projects. This is what happens when lawyers call the shots in an organization, and another reason startups have the advantage even when they're ostensibly out-gunned.
That's strange. Boost has one of the most liberal licenses out there.
Yep, and I've argued that with the lawyers, believe me. It's standard game theory: they're the gate-keepers, and they win nothing if we, the programmers are more productive due to our use of these tools. On the other hand, in the exceedingly unlikely case that a lawsuit comes up, they have to deal with it, and probably get a black mark in the eyes of the execs. This is why you need competent executives who are the independent voice in these sorts of disagreements, who can take the big picture view based on their expectation of how it will affect the stock price. In that world, greater productivity can easily outweigh this (imaginary) risk.
Half way through your post, I was thinking exactly what you said. The execs should be the ones realizing how much value is in increased productivity. So, can you tell me where I might find some of these "competent" executives? :)
Good article. As a long-time C++ programmer, but now doing most of my stuff in C#, I'd forgotten what a total and utter **** C++ can be at times :-) This is just one more example of why you should never, ever, ever roll-your-own Stack class, or String class, or...
-1 Doxygen does it already, better.
"what a total and utter ** C++ can be" Pointer pun? :)
Hehehe, yeah, possibly :-)
I don't understand all the complaints about how top() &amp; pop() work differenty from other languages. It's an api decision and a minor one at that. About exceptions: c++ wasn't designed with exceptions in mind in the first place. Compiling with exceptions hits performance across the board and blasts the stack while its at it. The biggest deal I see with the next iteration of c++ is to make templates clearer and add real closures for more functional programming. I certainly wish they could eliminate some of the bad decisions made originally with c++ but it's too late for that.
pygments too
Excellent post. Most of the C++ haters I see have don't have experience with projects where C++ is the most sensible language.
More insane stuff to be asked at interviews... Nice to see they decided on -&gt; rather than =&gt; for lambdas, just to be different. 
Nice. But when will we be able to use this with GCC / Visual C++ / CodeWarrior / [insert compiler name here] ? I mean, if we get it only for one compiler and the other don't adopt it soon enough we'll still end up having to support many different API... but sure it's a step in the right direction.
For lambdas i'd be just as happy if they let me define a named function inside another function and pass that function into an stl adapter. Not exactly the same as a lambda but it has the same effect: allowing locality of definition of an adapter function. Nice they have a spec for defining a multi threading library. It may be that this api is implementable today with normal c++. Not that condition_varialbles have any hope of working with XP...
Solves a few problems. However the main problems, such as atrocious packaging (can we have a standard ABI please?) and lack of a GC *option*, are still not solved. 
I found it surprising to see him mention that the C syntax is horrendous; I am so used to it that I don't even think about it any more. Interesting. This is also one of the few times (- first?) I've seen him express an unambiguous negative opinion of C. Edit: missed a page. The last two questions are definitely something to think about. An interesting interview all in all. 
I'd imagine they did so because -&gt; is already a token in the language.
Lack of an *official* GC option. There are [options](http://www.hpl.hp.com/personal/Hans_Boehm/gc/) if you don't mind using a third party library.
&gt; My only gripe with boost is the 20MBs worth of code that you have to redistribute No you don't?
That and the definition of a standard memory model in C++0x makes developing garbage collection much easier, AFAIK.
Am I the only one who finds it disconcerting that thread_local is a *keyword* (qualifier)?
There are three things C++ needs: * a standard ABI * a bigger and more consistent standard library * standard GC option None of these are included in C++0x. The first is the most important - if I can just use libraries in peace I am happy to patch over the other problems.
I tend to agree on the ABI ... but (until now) the lack of ABI was very much on purpose ...
it's so complicated, we really needed a tutorial for this... maybe somebody can release some lecture notes?
Er. OK, maybe I'm just missing it, is there something more to this than "override the copy constructor and assignment operator to prevent copying"? This is trivial
Can you elaborate? I tried using boost in my code few years ago and made it open source with alink to boost.org and last year had to include the version I used because something in boost changed enough to have me look up API changes. I would be more than happy to use boost if I didn't have to deal with the dreaded versioning issue. I don't want to keep downloading every incremental release to make sure my code still works, I would rather be doing something else.
Is this a computer program generated article? It's total nonsense.
This should be more like "stl adapters". Anyways his example sucks since he can replace it with: std::accumulate(foo.begin(), foo.end(), 0) accumulate will take other Binary Operators as adapters. A better example might be an adapter that strips off a single attribute of a collection of objects. That's the cool stuff about stl adapters.
The "more" is that you're making the copy constructor and assignment operator private. They can therefore only be called by member functions of the noncopyable class, and as there are no other member functions (except for a default constructor which does nothing), they can never be called, hence the object can never be copied.
My example was a simple one meant to illustrate the concept. A more complicated example would hide the point in the details. Even though this example can be achieved more easily in other ways, it's simple enough for most people to understand, and doesn't add unnecessary confusion.
This is really C++ 101, but I suppose it's good to rehash stuff like this periodically for people new to the language. Personally, since I tend to shy away from inheritance when I can, I use a macro instead of a base class: #define NONCOPYABLE( _className ) \ _className ( const _className &amp; ); \ _className &amp;operator= ( const _className &amp; ); Put NONCOPYABLE( ClassName ); in the private section of a class's header and you're good to go.
That's a terrible design, and incomplete as well. If someone uses that macro in a class, then they're forced to write a default constructor for the class as well, which the compiler can do more cleanly and efficiently especially if it's a POD. Secondly, class member functions can still create copies since they have access to the private copy-constructor and op= method.
&gt; If someone uses that macro in a class, then they're forced to write a default constructor for the class as well, which the compiler can do more cleanly and efficiently especially if it's a POD. Hmm, interesting point. None of my use cases so far have a default constructor so I haven't run into this issue. &gt; Secondly, class member functions can still create copies since they have access to the private copy-constructor and op= method. Nope. The constructors are declared but not implemented, so attempts to use them even within the class will generate a link error.
Pretty crummy examples; as a commenter to his blog points out he really should be using *shared_array* rather than *shared_ptr*
great review, i have always wanted to buy this book, now i see it's a great book and really worth reading!
Buy a cheap fucking window unit. You can get one for roughly $115 and it takes 10 minutes to set up.
Can't do that. Most of the new housing communities up here have HOA (Home Owner Associations), and the CCR says no to window mounted units. My neighbor has one and had a lien put on his house because of it along with a monthly fine.
As the author of this, I'm not really sure why this got posted to reddit :) I don't talk about writing c++ at all. It was simply a mild rant on my part about not wanting to lose a skill set I have. And if you read between the lines, my coming to terms with skill sets that just aren't as applicable to my career anymore. So if you read this article expecting some deep insight into writing C++ code, I apologize.
Fair enough. You can get indoor ones though and get a vent put on the outside of your house. One of the server farms I host my backup servers at does this (they are in the middle of a big multi story building. 
 ~ $ du -sh /usr/lib64/*boost*mt.so 68K /usr/lib64/libboost_date_time-mt.so 64K /usr/lib64/libboost_filesystem-mt.so 432K /usr/lib64/libboost_graph-mt.so 48K /usr/lib64/libboost_iostreams-mt.so 68K /usr/lib64/libboost_prg_exec_monitor-mt.so 228K /usr/lib64/libboost_program_options-mt.so 328K /usr/lib64/libboost_python-mt.so 16K /usr/lib64/libboost_random-mt.so 580K /usr/lib64/libboost_regex-mt.so 516K /usr/lib64/libboost_serialization-mt.so 80K /usr/lib64/libboost_signals-mt.so 16K /usr/lib64/libboost_system-mt.so 76K /usr/lib64/libboost_thread-mt.so 332K /usr/lib64/libboost_unit_test_framework-mt.so 1.1M /usr/lib64/libboost_wave-mt.so 452K /usr/lib64/libboost_wserialization-mt.so Hardly seems like 20MB of code to me, not to mention, boost is nice and modular.
Since I ship it as a product with an API, I have to include more than just the binaries: boost_1_35_0$ du -sh boost 47M boost Note: 'boost' directory where headers are is 47MB unzipped and 20MB zipped... 
I remember having to program with Sockets back in the day and I hope I never have to do it again unless I'm doing something that really requires that level of control. It wasn't the sockets that were the problem though, it was always getting [a] to work with [b] with custom code on both sides by different parties, I once spent 2 weeks because I had a decimal when I shouldn't have, a typo from their documentation. If we could have just communicated over http, it would have made much more sense, and been much more reliable.
This is really exciting, not having to write thead wrappers for each OS for multi-OS code. I wish sockets get the same treatment, why can't a socket be yet another std::stream based class?! On a side note the article introduces this code: void bar() { static my_class z(42+foo()); // initialization is thread-safe z.do_stuff(); } This is not thread safe on all compilers, actually on gcc and visualc it is not thread safe because init is done during function call and if called by multiple threads the first threads gets the roght value while others have the uninitialize value. Atomic inits for primitive types may be able to get away with it most of the time, but a class will not. Global statics are guaranteed to be thread safe since init happens by the single startup thread.
Good succinct article with a decent solution to a common problem.
Here's a [C version](http://voi.aagh.net/thrqueue.c) I wrote a few years ago. Constructive mocking welcome, I don't use C much.
Btw this is NOT safe under XP. True race fee condition variables flat don't exist. Vista has a specific api for condition variables that so far has been reliable under my testing. There's an article about this somewhere on MSDN and usenet threads about exactly this. Just heads up.
Are you referring to the win32 condition variable API (InitializeConditionVariable, WakeConditionVariable and so on)? Or are you referring to "condition variables" in general, such as the Boost implementation? Reason I ask is that Boost (as far as I know) does not rely on win32 condition variable API. Boost contains a "custom" condition variable implementation which relies on semaphores, event objects and other stuff. Assuming you're referring to Microsoft's condition variable API, and Boost does not use that, I'm not sure why this code would not be safe (from this specific point of view, that is).
the vista win32 condition variable API actually accesses a kernel API that implements a true condition variable. Under xp there is no way to guarantee an atomic unlock &amp; wait unless the kernel is hacked (I know someone who did just that for their embedded system a customer required to have run on windows).
http://lists.boost.org/Archives/boost/2001/03/9605.php Posts like these are legion. Boost *can't* implement it's own threads. It *must* rely on the operating system to provide these services.
Note to self: start a blog and excerpt Scott Meyers or Andrei Alexendrescu as though the ideas were mine.
Cool I can vent about std::string. It's COW implementation is stupid since c++ supports std::string const &amp; somestring(origstring). That explicitly says you don't want a copy, share what's there. std::string otherstring(origstring) implies "otherstring" will be edited. std::string const conststring(origstring) implies "origistring" will continue to be edited. c++ compilers of the past 5+ years or so are able to construct in place in the following instance: std::string somefunc() { std::string somestring; return somestring } std::string const funcstring(somefunc()); So basically std::string implementing copy on write has a bunch of extra complexity tossed into its implementation that's utterly redundant, utterly unnecessary and makes implementing std::string that much harder. Not to mention that you cannot present std::string as a fixed length char * buffer since you don't know what will get corrupted (been there done that).
The authors suffers from the NIH syndrome.
I'm amazed at the performance of libPCRE. I wonder why Boost can't or hasn't matched it.
Agreed. You'd think the meta programming opportunities in regex would allow for a huge speed up.
Is there any reason behind your company not using boost ??? I mean if you are whining about something THAT should be the reason :)
A very intelligible explanation.
Learn C++ before you code, it's that easy.
BS int b = 0; int a = ++b + b++; //a = 2, b = 2 ++b: Preincrement operator. First increment, then evaluate. So, before computing the addition, b turns to 1 The addition is performed with b = 1, yielding a = 2 b++: Postincrement operator. First evaluate, then increment. So, after the sum is computed, b is incremented again. Anyway, if you can't understand a = b++ + ++b, don't use it. You can do it in another ways. And, on the other hand, you shouldn't do pointer arithmetics unless you know what you're doing. Furthermore, the issue mentioned here has nothing to do with pointers, but with integer overflows. Consider the following: uint32_t a = (pow(2, 32) - 1 ) - 10; a += 11; a -= 2; // a == (pow(2, 32) - 1) - 1 ? Left as an exercise to the reader ;)
C++ is dead - long live (not) C++
I think you are missing some of the subtlety here. What tfa is saying is that the behaviour in the b++ + ++b scenario is Not Guaranteed, by the language spec. The line of code you presented could give different results on different architectures, and that compiler still be considered as conforming to the C/C++ spec. The problem arises from modifying the same variable twice in an expression. The compiler is free to fuck that expression up in any number of ways, although in practice, it seems unlikely that many compilers would. The fact that C/C++ is so close to the hardware means that there are a LOT of little caveats like this, to using the language. If you go in completely blind, you can expect to get mugged eventually. (disclaimer: I am a C/C++ fanboy.)
IMO, the examples he provides in order to build a case against C++ are less damning of C++ and more of C. Any article whose purpose is to inform the unwashed about C++ and its complex syntax (cry me a river, btw) should consider providing examples using overly-complex but commonly used/suggested language idioms that are unique to C++. It might then follow up with counter-examples in C that accomplish the same task with less hassle. But instead, this article provides examples of code that a) would never be used in production, as they're useless, trivial, and would never be used in real production code, and b) are also valid problems with C. Terrible article, shame on the author.
Allow me to emphasize that this problem is not overblown. We've actually been bitten by an undefined double-update expression when we switched compilers. The code in question was something like this: b = b++; The Microtec compiler compiled it one way, while GCC compiled it another. When we switched to GCC, it no longer incremented. The danger is equivalent to the original expression because neither '=' or '+' are sequence points. Let me add that this particular area of our codebase was rife with confused code.
Consider: int f(int *p) { return ++(*p); } int g(int *p) { return (*p)++; } int main() { int b = 0; int a = f(&amp;b) + g(&amp;b); printf("a = %d, b = %d\n", a, b); } 
"messy, too ugly and complex" if you don't understand the syntax and if you think it is then you should stay in the happy world of ruby with your rainbows and unicorns and care bears and stay away from C++, you are bound to get hurt. C++ may be complex, but there is a lot of beauty in it that many novices miss. C++ is the Firefly of the programming languages... brilliant and ignored by the masses.
yes, keep in mind most people who have the free time to post and write in blogs all day: 1) don't have jobs 2) don't have anything interesting to say. Yet, the more free time, the more 'gems' they seem to pass on.
how the how else are people going to write native code? lisp...? Or is this author beating a dead horse 15 years too late? why do people write these retarded articles? Somone fucking shoot me in the face plzkthx. and why are people comparing ruby to c++... that's not even fucking apples to oranges. (ps, ruby sucks shit btw).
What's with all the kickback amazon links in the small post. That is obviously the main point of this link.
The comments are classic fanboyism after the first commenter tried to give him a clue.
It's not an article against c++ : &gt;I had intended to jump directly into discussing those (hence the post title), but tradition almost dictates that any discussion about C++ must be preceded by a mention of all its bad points, and who am I to argue? &gt; &gt;So coming up next, some of C++'s saving graces, some of the features and tricks that make it usable, and in some areas, actually an extremely powerful language. * [C++ - It’s not all bad (pt. II) - Advanced C++ for beginners](http://jalf.dk/blog/?p=66) * [C++ - It’s not all bad (pt. III) - The STL](http://jalf.dk/blog/?p=83)
I docked it a point because it correctly points out that const modifies whatever is to its immediate left unless nothing is to immediate left. Then procedes to do all the examples with a mixture of using the rule and exception. Meaning he intentionally obfuscates his own code to his own ends. If you're going to do a paper about correctness then your syntax should be as correct as possible, even though most programmers have been taught how to do const incorrectly.
Actually, in fairness that first example IS a bad example, but not because there is any guarantee of order of execution present. Witness the two scenarios b = 0 t1 = ++b (1) t2 = b++ (1) a = t1 + t2 (2) and b = 0 t2 = b++ (0) t1 = ++b (2) a = t1 + t2 (2) While the intermediate values aren't guaranteed to be calculated in the same order, the end result is the same in both cases. If the author had introduced a 3rd pre or post modification of b in the equation, it would have become a lot more obvious how the lack of OOE guarantee affects the output value.
&gt; Boost can't implement it's own threads. It must rely on the operating system to provide these services. You don't say... 
I'm really looking forward to this, it's one feature I've always liked in other languages that has been missing from C/C++. Of course, we still have at least a few more years to wait until this is standardized AND available widely in compilers :/
AND then about another thousand before you'd be allowed to use it at work. ;)
I'm curious who's voting this down. I've been looking for a gdb macro to translate UTF16 unicode strings to wchar for a while, it never occured to me to just write an external c(++) function and call it from the debugger. So, are you voting it down because it's too trivial? For anyone who cares, here is a related issue: http://bugs.kde.org/show_bug.cgi?id=109921
Well, I don't 'work', I only code for myself these days. But even when I was employed, whenever I've used a language, I've never been told I couldn't use a specific language feature, anything went as far as code, as long as it worked with the company's chosen toolchain, and fitted with the company's stance on code-style. When I programmed in C/C++ on embedded-like systems, I was actually free to choose my own compiler, for some projects I used gcc (hand-built with some changes for specific targets) on others I used VC++. When I programmed in Java, I was free to use any Java features supported by the JVM on the target, which was 1.5/1.6. The only time I've really been limited as to what language features I could use, was when I've dealt with browser-based javascript. I suspect these working conditions make up the majority of how people work - they've certainly been similar for me across several companies. So I imagine once VS 201x and gcc 4.x/5.x supports C++0x then most developers will be free to use lambda syntax C++.
 Really? So you could use scala? Nobody would have said a word? Or Clojure? Good on you. I work at a particularly 'results-oriented' place where we are given wide latitude, but people still frown on using many of the techniques and libraries found in boost. 
Scala maybe, Clojure would probably have been pushing it too far.
That dude is SO Bruce Willis' Canadian alias in The Jackal.
so, could I pass a couple closures into a pthread target, and then pick one of them to execute based on some conditions later in the thread? That would be *so* useful for me right now. Hopefully I won't still be using pthreads when C++0x comes out, but I digress... 
Try [Boost.Function](http://www.boost.org/doc/libs/1_36_0/doc/html/function.html). And while you're at it, consider [Boost.Thread](http://www.boost.org/doc/libs/1_36_0/doc/html/thread.html).
Yeah, the state of the art has definitely moved a bit since the stl string was designed. I like [the standard ruby string class, myself](http://corelib.rubyonrails.org/classes/String.html), and have an extensions which uses some of its naming conventions (e.g. upcase, downcase, strip, includes). As a sidenote, why does anyone do this?: &gt; (std::string::npos!=original.find(other))?true:false; (x != y) already evaluates to bool, yet I see this ?true:false stuff all the time.. :-P
Wondering a few things 1) How well would these toupper/tolower methods work with UTF8? Not very well, I imagine. 2) Why do none of them take (const when possible) references to the strings? You cannot assume that your STL uses copy-on-write for the char buffer. If it doesn't, this guy's string operations are extremely expensive and force a return value where one isn't needed. 3) The rpad method is totally useless. What's the difference between that and std::basic_string::append? Someone needs to RTFM before reinventing the wheel 4) In this day and age who still uses the single byte string and not UTF-16/32? You're setting yourself up for i18n problems in the future. And yeah, the Ruby string is great. But I've never seen anything compare to NSString from Cocoa. It can handle pretty much anything thrown at it.
Or you could just use the Boost string algorithms library and call it a day.
OK, so I can kind of understand liking the power of C++, but it's not really a language one loves. Maybe C++ is like a porn star; on TV, she seems lithe and flexible, and when you first meet her you're starstruck. But after a couple of years, all you see are the big pores and the personality quirks. I wonder what effect the [FQA](http://yosefk.com/c++fqa/) would have on his enthusiasm.
I've never understood why people quote the FQA as some sort of awesome critique of C++ that will put you off the language. I read it after having learnt C++ and don't think it really changed anything for me. And for the record, I still love C++.
Best indentation style evar.
I kind of like it too, but I'm still aware of its warts. Functors make a good portion of functional programming possible, but the syntax and background you need to make basic use of them is daunting. I actually learned quite a bit from the FQA; almost as much as I learned from Effective STL. Knowing lisp makes using advanced C++ features a bit painful for all the hoops you have to jump through. All I'm saying is that it's hard to love, and I think the trade-offs you make to use C++ are (in most cases) not worth it, unless you're unwilling (edit: or unable) to use something else.
via: http://www.richardbishop.net/wpress/?p=23 Compiling STLdb4 on Debian Linux 
I'd like to see someone go into even more depth comparing these build systems, but this was a good start. I'm big on the separate build tree thing too, so I'm glad to see that was the approach he took. On that note, has anyone had any success with integrating scons with KDevelop? I'm not a big fan of the way the wiki describes because *Compile File* doesn't seem to work as expected. I had to hack together a script for KDevelop to call, which then calls scons. It worked, but it's ugly.
I still prefer cppUnit tbh, gTest looks nice, but I never felt that Boost's unit testing offered what I wanted.
Took me a few minutes to understand *why* I would want a "vector" that doesn't store its elements in contiguous memory... but I get it now. Pretty cool.
via: http://en.wikipedia.org/wiki/OpenFrameworks
For supersimple web applications, developing your own C++ embedded web server is OK but if you need to do something "real", which needs scalability, ease of development (no need to write HTML, CSS or Javascript), multithread, etc, use Wt ( http://webtoolkit.eu ). There are packages available for Debian and Ubuntu under the name "witty".
Or, if you just need a multithreaded responsive server (not only http) you should take a look at [asio](http://tenermerx.com/Asio/) directly, which Wt uses
&gt; Have each thread do a completely separate task. If your program can’t be split up into tasks that can be run mostly independent of one another, don’t even attempt it. Hehe, so you can use threads... just don't use them in a way where they have an advantage over straight processes. ;-)
... from a year ago.
Funny that they mention CUDA as a possible "alternative" to GPU. Maybe what they really mean is twilight of OpenGL and DirectX.
Uh... yeah, that's const alright. So what's the point? I should hope most of us already know how to use const properly.
const is much more than just a signifier of a constant. proper const assurance can be hard for a lot of people to come to grips with. i remember when i was at uni it wasnt taught properly. this reference does a good job of making it clear. nice link :D
&gt; if you follow a straightforward set of rules, it’s easily possible to write good — and safe — multithreaded programs. &gt; I can’t offer a complete list of these rules. Great... 
Asio is pretty nice. I started to use Winsock/IOCP a while back and it was a pain to get it right. With Asio, it's so simple. :) 
see also: http://www.stlport.org/resources/StepanovUSA.html An Interview with A. Stepanov
Nice. Would love to be able to call stuff such as *num_hydrogens* which *Returns the number of total hydrogens attached to an atom.*. Too bad I'm writing an email server where this isn't exactly needed.
What he describes as "templated namespaces" are more likely just type traits. Whether assigning them as template parameter or using them inside a class isn't really making any difference IMO. For instance it could be either template&lt;typename T&gt; struct iterator { typedef typename std::iterator_traits&lt;T&gt;::x y; }; or template&lt;typename T&gt; struct iterator { typedef typename T::x y; }; iterator&lt;std::iterator_traits&lt;X&gt; &gt;
Yes and no. Same mechanism, however the use is different. Type traits are used primarily for ad-hoc introspection and template specialization, while what I'm proposing would be for a using class to completely remove all dependencies to other classes and have them injected, a la dependency injection, at use, rather than at design.
Reading about that led me to learn about the [Forwarding Function Problem](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2002/n1385.htm). Ugh. They can fix it once C++0x shows up, but until then, I think it means that you can't call lambda functions with literals as arguments.
via: http://wthwdik.wordpress.com/2007/07/06/boost-c-builder/ and: http://wthwdik.wordpress.com/2008/09/22/c-builder-2009-boost-bcbboost/ 
Umm...this code doesn't work: # for (i = 0; i &lt; M; ++i) { # std::vector&lt;int&gt; array; # array.reserve(N); # for (j = 0; j &lt; N; ++j) array[j] = j; # } Use "reserve" still requires a push_back(). What you have here won't work for iteration.
This is old. Spirit 2 was release about a month ago.
there is a better explanation on deitel &amp; deitel how to program in C++...
Cute. But remind me again why we still need C++
This is quite clever and interesting (at least in an academic way), but I'm amazed that Meyers doesn't provide a simple downloadable header file so readers can play with his stuff. He gives all the crucial code in various listings, so it's a strange omission. Anyway, in case I wasn't the only one who felt like messing with it, I've consolidated the core code into a usable header file, [here](http://pastebin.com/f297b6d5).
Sure. I am aware of this. I just want to get the fastest implementation with C++ vector. It is still quite surprising that even with [] C++ is slower than C. [] is simply: reference operator [] (size_type __n) { return *(begin() + __n); }
Is the same "Proust" as in "Marcel Proust"? What does he have to do with C++?
http://en.wikipedia.org/wiki/Proust_questionnaire : The Proust Questionnaire is a questionnaire about one's personality, first popularized by the responses given by the French writer Marcel Proust. It seems to basically be a list of wide-ranging "personality probing questions" with a scope somewhere on the narrow line between shallow and profound.
... or not.
Dear ESR, I suggest you start with this quotation from Bjarne Stroustrup: &gt; There are only two kinds of languages: the ones people complain about and the ones nobody uses. Please consider deeply the implications of that statement, observe that a very substantial proportion of the most useful software in the world is written in C++, and reevaluate whether you or Stroustrup has the right idea about what the "right problems to solve" might be. And then you should probably abandon this paper before you invest any more time in it. If you think you know how to design a better language that combines good performance and control with high safety and expressiveness, go ahead and show us all what it looks like. I'm sure many of the three million or so C++ developers in the world would be happy to take a look, along with plenty who use other languages today as well. But I think you'll find it's hotter under the stage lights than when you're looking down from the cheap seats. Writing yet another article slagging off a phenomenally successful practical tool for not being theoretically pure is not constructive.
Haha: &gt;I’m particularly looking for empirical studies on the importance of manual memory management as a defect attractor (I have the Prechelt paper from the year 2000). std::tr1::shared_ptr&lt;&gt; exists. ESR should get an update on what C++ provides resp. what is available for it before trying to write a C++-hate article.
It seems to me that every feature added C++ is designed to FIX a previously added feature. I don't miss C++ at all.
That's funny, C++ has only had good things to say about you.
That's surprising, since the STL that comes with VC++ 2008 is the same old HP implementation that came with VC++ 5.0. What I think is more likely, is that you're confusing "iostream.h" and "iostream" (and the cout/cin/cerr dependance there-on), one of them requires the old VC++ runtime since it wasn't using the STL implementation but a linked-in version. Sometime between 2003 and 2005 would sound about right for MS finally transitioning away from the old iostream.h approach.
See Achilleas' suggestion in the comments. Similar to one I've worked on. There are lots of other advantages to working in this manner because the structure supports reflection/introspection.
Erm ever considered that C++0x's atomic&lt;&gt; may use locks internally? But kudos on actually using a technique which (should) work. Verdict: FAIL
This is the kind of article that I think should be posted in programming. I imagine that most people subscribed to the cpp reddit are already familiar with the language. I guess a little confirmation bias doesn't hurt though. heh
Liked Socrates comment: "One can actually get a job programming Haskell? I thought the only practical way of using Haskell was talking on reddit about it…" ;) 
Well this is reddit. Mostly script monkeys here I'd wager.
Because once you've learned C++, you will truly appreciate how beautiful just about every other popular language is. . . 
This quote says it all: "I think it’s fair to say that if you were designing a better C from scratch these days, you probably wouldn’t end up with C++." 
scriptz, lulz.
That seems to be the popular sentiment. But as a long-time C++ user, learning some new languages such as Java, Python, and Javascript, I REALLY miss C++'s destructors. Why do I even need garbage collection, when I have smart pointers, that can clean up ALL my resources, and not just memory?
You would probably end up with yet another almost unused programming language (like D). Anders Hejlsberg: &gt;"C++ was an incredibly appropriate evolution of C. Once you have huge language use, it is much easier to evolve and bring an existing base with you than it is to go create something brand new. If you look at the mechanics of new languages, when you design a new language you can either decide to evolve an existing language or start from scratch. &gt;Evolving an existing language means you have an instantaneous big user base, and everything you add to the language is just gravy… there’s really no draw back as all of the old code still works. Start with a brand new language and you essentially start with minus 1,000 points. And now, you’ve got to win back your 1,000 points before we’re even talking. Lots of languages never get to more than minus 500. Yeah, they add value but they didn’t add enough value over what was there before."
Another example of why I hit reddit more than digg. I'm not a c++ fan but I can't argue this article. Truth hurts. /me brushes up on the c++, I'm tired of b projects. 
Ook ook eeeek.
Well, I don't think everything about C++ is awful and I do wish that garbage collected languages like Java, Python etc. optionally allowed you to delete whatever you've allocated. My big problem with C++ is that it's such a monumentally complex language. Its syntax is fairly ugly too. Really, the big thing it has going for it, is that it's higher level than C i.e. it makes object oriented programming easy (which you can do in C, just not very easily) and it compiles to native code fairly efficiently and is therefore quite fast. Actually, take away the speed and I can't see any good reason to C++ at all. 
Just because D is (relatively) unused doesn't mean it isn't better. Also, just because it's unused now doesn't mean it will stay that way. C++ has been around since the 80's but wasn't really heavily adopted until the 90's. Really, C++ isn't the problem. The problem is that once there's enough code written in any language, it's hard to switch to an alternative. Also, the industry is ripe with lots of shiny trendy crap technologies which makes it hard to determine what actually has substance and what's vaporware.
see also: http://evolution.genetics.washington.edu/phylip/newicktree.html The Newick tree format
No, all (mainstream, at least) chips have memory barriers and hardware instructions for atomic-ish operations. The committee is in tune with that. If you want to learn this stuff, go hang out in comp.programming.threads, and / or get "The Art of Multiprocessor Programming". 
If you're going to start doing this everywhere (and I strongly suggest you do), the first thing to do is to follow the rule: "const applies to whatever is at the immediately left of the const keyword" Be consistent and stop following old habit. I really wish compilers would start to bitch and moan about putting const on the left....it doesn't belong there.
I don't mean to be snarky by asking "why should I care?" There just really isn't any information there for anyone who has never heard of Xerces-C++ before. Perhaps a link to a FAQ is in order.
I am not sure whether I am making a wrong claim again. As I read the uset.h, ustl::set is just a common vector, not a search tree. Maybe the author wants to continue the development on the hard part in future?
Looks good...I really like that it doesn't include thread locks internally like the stl that ships with c++ does (locks on locale crap). I'm not a fan of how map/set are implemented. RB trees are well defined and should be used here. The performance hit on using vector to implement these is just way too much. He should take his current set/map code and name it something else as low memory alternatives to the "more correct" algorithms. Or else just allow a user to keep a sorted vector around and use a sorted insert with it, removing the "old" implementation entirely.
Honestly, if you don't know what Xerces is, you probably don't want to use it.
Someone was kind enough to respond with http://xerces.apache.org/xerces-c/ which is a useful description of the project! I don't see why you think it is such exclusively knowledge, an XML parser is no fluid-dynamics-simulator-library, or something like that.
Xerces-C++ is sort of the canonical XML Parser. If one doesn't even know what it is, chances are one isn't doing XML Parsing in C++ and/or already have a perfectly fine XML Parser. As for the link to the Apache project, one could have found that either through Google or by simply following the link in the posted article. If one needed help to find it...
tell me more about these "maximum powers"
I'd challenge his assertion that the member variables be private. This results in extra code "just for fun" in the form of accessors. All the member data is orthogonal, therefore directly changing the values does just that...changes the values and has no affect on the operations.
I used Xerces some 2 years ago. I'll wager the latest version sucks just as bad. I mean good grief, that was a crappy API...
I just wasted one minute of my life. "Compiler writers in efficiently implementing trivial language elements shock".
Better explanation of NRVO for VC++: [MSDN](http://msdn.microsoft.com/en-us/library/ms364057.aspx)
As multiple cores become more frequent, I expect to slowly see our familiar existing commands rewritten to take advantage of them.
Most important part: "You should always use a profiler both before and after optimization to see if your change actually made an improvement"
About #2. My experience on implementing sorting algorithms told me that using pointer instead of array is more efficient. Maybe in other cases (vectorisation?) using array notation is more efficient. But anyway, this is a general tip.
#3. Completely unroll loops that have a small fixed loop count and a small loop body Are they drunk? Seriously?
Yeah I think some of that is filler. I know I checked GCC, it unrolls 'small, fixed loops' at -O2 in 4.4, and at -O3 in 4.2. And you can be sure that VC++ and Intel compilers, at least, do it too. 
"(Besides I only started programming C++ 8 months ago... Gimme a break)" ...not the kind of thing to leave in an article about C++. Anyhow, this is quite intrustive and you have to instrument a lot of code and probably wrap it in #ifdef/#endif. There are cases where console is not available (like in games, services, etc), it would have been more prudent to log to the debug console which can be attached remotely. Might make life easier by adding a scoped object that will do the logging for you on construction and finalize on destruction, thus you would only have to insert 1 line of code at the head of the function instead of 2 wrapping it. This can also include the conditional define inside the scoped object and not litter the code with #ifdef/#endif 
&gt; 1. Declare as static functions that are not used outside the file where they are defined Use anonymous namespace instead of "static" keyword.
blogspam
via: http://blog.programmerslog.com/?p=214 Programming Language Trench Warfare 
see also: http://msinilo.pl/blog/?p=189 RDESTL - changes
I don't understand why his member function returns a const non-reference type. What's the point? :-)
know those `boost` headers that repeat definitions for one, two.. up to 50 parameters? That would be sooo gone.
Yea this is a fantastic new feature, it has been very useful in D. 
what's TBB? Even the article doesn't define TBB.
Warning: article written by someone coming from c# who seems to have never done 'c' or 'c++' That would be "using c strings" in c++
[Probably this: Intel threading building blocks](http://en.wikipedia.org/wiki/TBB)
this is more about platforms and environments rather than actual c++...
This is something I've recently needed to know how to accomplish. I would also recommend looking at MySQL++.
A good description of Brent's Method can be found [here](http://www.network-theory.co.uk/docs/gslref/MinimizationAlgorithms.html)
Is it really smart to check for validity on every dereference? Aside from that, what is this: bool operator==(const int i) {return (i == (int)ptr);} // ?
It's overloading the == operator when a smart_ptr is being compared to an integer.
It lets you compare a standard pointer with a smart pointer.
The lack of a reference counter makes for the possibility of bugs, as he points out.
Just smart enough to be dangerous. Not smart enough to do the right thing when copied, which includes being returned from a function. What exactly is wrong with std::auto_ptr&lt;&gt; anyway? I mean, it came with your compiler, so the #include is only one line of code, not 9. Is it just not "double-deletey" enough for ya? It reminds me of that story of the US letting the Soviets steal some sabotaged gas pipeline control software. Expect this to show up in all the wrong places, i.e. everywhere it is used.
well duhhhh... But it's stupid. This is never useful. Perhaps if the argument were Type const * const and remove the operator==(Type const &amp;) function. Use derefernce for that. Even worse....equality operator indicates trouble since this smart pointer will delete on destruct.
And what if sizeof(int) &lt; sizeof(T*)? One use for this smart pointer might be in a job interview question or in an exam, perhaps.
That's very cool about the array associativity. These are all equivalent: int x[5]; *(x+4) = 1; *(4+x) = 1; x[4] = 1; 4[x] = 1;
I agree. "grep" is the next obvious command to parallelize using the wc-cilk model. Other commands that process multiple files are also candidates; compilers (gcc, etc.) come to mind. You could create a process or a convention thread to process each file (I've done both), but I found the Cilk++ model to be much easier to implement, and it also keeps the thread (or process) management overhead low.
Useful article, the code behind it (the concurrent container library) is alpha and 11MB with no source code and not usable in any production software. If they want people to embrace multi-core they should advocate it, provide source examples and usable libraries for developers to move their code towards multi-core development. I am still writing my own multi-threaded containers because STL (as the article mentions gets too slow when synchronized) and I haven't found boost libraries that are much better at it than STL. This is definitely a good start, but Intel needs to open source this type of stuff so that it can be ported to other platforms. They are a hardware company first and should be releasing software to support their hardware. Just my 2 cents.
I write high performance multi threaded apps for a living. I tend to split parallel things into two domains. Instruction level (exploit vector units) Application level (exploit multiple cores). Instruction level should be exploited by the compiler with programmers following a smart programming convention. Application level should be exploited at the engineering level with software design. The problem is that there's a hard to define middle ground that's totally dependent on the popular hardware of the month where parallelizing data structure operations may help you on some platforms and will kill you on other platforms. So my personal experience and advice is to avoid diddling with this level of multi core stuff.
&gt; Intel needs to open source this type of stuff [They have](http://en.wikipedia.org/wiki/Intel_Threading_Building_Blocks#History) 
Thanks, I thought I clicked everything on the Intel site, guess should have checked Wikipedia :)
The API made me cry once
The **here** link given for the downloads is broken (it consists of two urls pasted together), here's the [correct link](http:/www.wintellect.com/CS/files/folders/7145/download.aspx). 
Building it with Visual Studio 2008 and running it caused VS to crash and send the report to Microsoft, not the kind of a crash I was expecting. The actual executable is in ../Debug (unlike all intermediate files that are in ./Debug), not quite where I expected it to go, changed the project props to make everything go into ./Debug and ./Release. I think I need a newer version of dbghelp (there should be a README included really to tell you this). Using 6.6.3.5 I have in another output directory worked in at least finding the ordinal it was looking for. Now mfc90ud.dll is missing, found it in VC redist directory and copied them to the Debug directory. (This is probably because I built it in debug mode). Same thing for msvcr90d.dll, found in the same redist directory. "The application failed to initialize property (0x80000003). Click on OK to terminate the application. This is getting annoying... That error means "One or more arguments are invalid", I have seen this type of an error before when a call into one of the many stack functions in dbghelp is incorrect (sad part of dbghelp, it's extremely useful but so poorly maintained that APIs between DLLs do not work the same and you spend as much time making this DLL work as you do actually using it). As I have done so far. Rebuilt CrashFinder in release mode, crashed VC with SymLoadModuleExW not found... this thing crashed my Visual Studio again! Ok repeat the above step for mfc and crt dlls for release mode. Same thing, crashed with 0x80000003 error. I give up... 
Here is the output from running it in debug mode after all the DLLs were copied into the output directory (now VC doesn't crash): {{{ 'CrashFinder.EXE': Loaded 'C:\Code\CrashFinder_2.8\Debug\CrashFinder.EXE', Symbols loaded. 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\ntdll.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\kernel32.dll' 'CrashFinder.EXE': Loaded 'C:\Code\CrashFinder_2.8\Debug\dbghelp.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\msvcrt.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\advapi32.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\rpcrt4.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\secur32.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\imagehlp.dll' 'CrashFinder.EXE': Loaded 'C:\Code\CrashFinder_2.8\Debug\mfc90ud.dll', Symbols loaded. 'CrashFinder.EXE': Loaded 'C:\Code\CrashFinder_2.8\Debug\msvcr90d.dll', Symbols loaded. 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\user32.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\gdi32.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\shlwapi.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\comctl32.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\msimg32.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\shell32.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\oleaut32.dll' 'CrashFinder.EXE': Loaded 'C:\WINDOWS\system32\ole32.dll' First-chance exception at 0x7c90e450 in CrashFinder.EXE: 0xC0000005: Access violation reading location 0x00000130. R6034 An application has made an attempt to load the C runtime library without using a manifest. This is an unsupported way to load Visual C++ DLLs. You need to modify your application to build with a manifest. For more information, see the "Visual C++ Libraries as Shared Side-by-Side Assemblies" topic in the product documentation. CrashFinder.EXE has triggered a breakpoint }}} Anyone get this thing to work?
Does not import into Visual Studio 2008, seems like the provided solution files are from a very old version with .vcproj xml that is not compatible and not upgradeable to VC9 (which is Visual Studio 2008). After a bit of digging I found that Intel compiler is used as an override and if you don't have it then the flag confuses visual studio during upgrade and it aborts. The way to fix it is to remove IntelOptions tags inside the VCPROJ and then compact &lt; Tool ...&gt;&lt; /Tool&gt; to &lt; Tool ... /&gt; since text element is not allowed with Tool tag by the XSD. This means you have to hand edit about 10 VCPROJ files to get it to build... 
I've just tested this with Visual Studio Express 2008, and it works fine, but on g++4.2.3 it still has the resolution error: template &lt;typename T&gt; struct outer { struct inner; }; template &lt;typename T&gt; struct outer&lt;T&gt;::inner { inner(const T &amp; a) : a_(a) {} const T a_; }; template&lt;typename T&gt; bool operator==(const typename outer&lt;T&gt;::inner&amp; l, const typename outer&lt;T&gt;::inner&amp; r) { return l.a_ == r.a_; } What does work however is to explicitly call operator== with both parameters. outer&lt;int&gt;::inner a(0); operator==&lt;int&gt;(a, a);
Makes a good case for a surprisingly controversial issue. 
Good news, boost 1.37 is right around the corner(a couple of weeks away). Time to try again!
Exceptions should be exceptional. Blasting the stack can get confusing and make for a mess -- it can get very difficult and confusing trying to figure out where the hell some exception got thrown. One way to get around this is to have objects smartly maintain their state and make them robust enough to handle issues. And no, there's no perfect way to deal with any of this.
Nice improvements. I'm really thinking about choosing Boost.Threads as my favorite threading library. Do you know any other threading library as thin and clean as this one?
Man, C++ is such an *ugly* language. I mean, I *like* various things about C++ but the ugliness is so drastic I hate using it (and so mostly don't).
Good. Let real men program operating systems, physics simulators and real-time financial derivatives trading systems in C++. Noobs who're too intimidated and/or lazy to take the time to really learn how to navigate the harrowing corridors involved in a high performance "ugly" language like C++ can stick to whatever scripting language they find most pretty to gaze at with batting eyelids.
i'm a c++ lover as most people, but oh dear god, spirit scares me. wtf would write a parser in code like that? ugh. i also wonder about the performance of spirit code over other competitors 
Not sure about *clean*. Requires very specific compiler support to get some of these features.
I have worked on a real C++ codebase (a clean compile took over half an hour) with all the patterns, factories, templates, custom COM system, etc... Is C++ powerful? Yes. Is it so goddamned ugly that D looks awesome in comparison? Hell yes.
Or you could just friggin buy Visual Studio. It's not that expensive... $250 VS 2008 Std: http://www.newegg.com/Product/Product.aspx?Item=N82E16832116418 $650 VS 2008 Pro: http://www.newegg.com/Product/Product.aspx?Item=N82E16832116411 Product Comparison: http://msdn.microsoft.com/en-us/vs2008/products/bb980920.aspx 
Yeah, but if you don't have to spend 250/650 bucks, why bother? If you can get the same (or near same) experience with the free product (legally) why bother paying?
Debugging? It's worth it alone if you want your shit to work. Hopefully you make money off this software or what's the point.
To be fair, Boost is sort of taking C++ beyond its natural envisioned use, and jamming new powerful things into the same old syntax. It's Spirit you're objecting to, as much as C++. 
Fascinating stuff.
Those are all going to be nice, especially lambdas. It's a shame concepts won't make it.
Wilson is great; I can't wait for his inevitable book on C++0x 2 years from now. Come to think of it, how much of everyone's hard-earned expertise will just vanish into Just Clean Code with the new version? 
1000 points for you
TBB uses some awesome concepts.. but ive yet to use it in production for anything www.threadingbuildingblocks.org
&gt; Exceptions should be exceptional. [Boost / Error and Exception Handling](http://www.boost.org/community/error_handling.html) says: An oft-cited guideline is to ask yourself the question ``is this an exceptional (or unexpected) situation?'' This guideline has an attractive ring to it, but is usually a mistake. The problem is that one person's ``exceptional'' is another's ``expected'': when you really look at the terms carefully, the distinction evaporates and you're left with no guideline. After all, if you check for an error condition, then in some sense you expect it to happen, or the check is wasted code. 
My friend and I wrote a compiler using Spirit for a class (the language was based on Python but far simpler) and the parsers written by others using Flex and Bison were far faster. As a bonus, Im sure they didn't end up with a multi-megabyte binary and their program probably didn't take 10 minutes to compile.
.. not make it, into VCXX you mean; I understand they're a big part of C++0x proper. 
Real link: http://www.boost.org/users/news/version_1_37_0
Right. They are supposedly the "biggest part". Personally I'm more excited about lambdas and auto so this is nice. Concepts fixing the horror that is template error messages is something I wish we could have gotten early though.
Oohh, direct link. 
Wow, direct link!
a library so powerful, it has its own make system that is built in itself, and may, in fact, require you to build it, in itself. 
very few components of boost require you to "build" it separately. most can just be #include'd
openMP is awesome!
In the end this doesn't create any less code. If I want to override the default of one or more of these virtual methods, I still have to create a new function for it and now on top of that a factory method to generate the Opt and correctly set the boost::functions to my custom behavior. And eliminating the hierarchy eliminates the possibility to call the parent class' implementation in less trivial virtual methods, because Opt no longer has an inheritance chain. While I often use boost::function for similar problems, in this case I prefer to write a class template to customize the behavior. Using the example in the link: class Opt { public: virtual bool barrier(double S) = 0; virtual double pay(double S) = 0; }; template &lt;class T, bool B&gt; class DefaultBarrier : public T { public: virtual bool barrier(double S) { return B; } }; template &lt;class T&gt; class DefaultPay : public T { double K; public: virtual double pay(double S) { return (S-K) &gt; 0 ? S-K : 0; } }; typedef DefaultPay&lt;DefaultBarrier&lt;Opt,false&gt; &gt; Vanilla; Now I can still use Vanilla as a class, derive from it, etc. Additionally, if I wanted to, say, change the barrier to always return true by default, it is no longer a matter of writing a new function and creating a new factory, but rather creating a new typedef, like so: typedef DefaultPay&lt;DefaultBarrier&lt;Opt,true&gt; &gt; VanillaWithBarrier; And to prove this works: std::auto_ptr&lt;Opt&gt; test( new Vanilla ); assert( !test-&gt;barrier(0.0f) ); test = std::auto_ptr&lt;Opt&gt;( new VanillaWithBarrier ); assert( test-&gt;barrier(0.0f) ); 
Once you start using it you will rather soon have a few libraries to link. System, filesystem, thread, serialization, etc. Maybe there are some parts which can be used "header only", but so far I had to link some libs for nearly every example I did run. I'm not complaining about that, just my experience with it after using it for about 2 months now. Thanks to the nice make system that has not been a big deal anyway. 
Nice design. I needed a class like [QCache](http://doc.trolltech.com/4.4/qcache.html). I guess it can be implemented beautifully using Boost.MultiIndex. If you know an implementation please let me know. Edit: [Here](http://www.boost.org/doc/libs/1_37_0/libs/multi_index/doc/examples.html#example9) is MRU which may help
Very big news.
The changes are nice, but it's still a language for experts. I don't feel C programmers will now flock to C++, nor do I think coders who use other languages will think "oh man C++ is such a great language now" and convert back. These changes are simply some fixes to make the headaches of people who must deal with the language a little bit easier to bear. 
Looking forward to lambda forms in C++... I would use the VS2010 preview, but it means running everything in a VirtualPC session. 
It's still the best language for cross-platform programming that needs optimal performance. Python, Haskell, Java and all the rest are great, but they just don't match c++ in terms of performance. Pure C works fine, but it's nice to have the abstractions of c++ when you need them. Granted, C++ is still a very hard language to master, but that doesn't mean it's useless.
No, but there are some nice treats in there for us die-hard C++ guys.
passing in memory like that now makes the function non-reentrant. Allocating memory in a function opens you up to defect of type a, but passing in the address opens you up to defect of type b. Choose your poison.
This looks like it might be cool, but really I think the gun was jumped posting it at this point..
Isn't this just a deque? 
Why do does passing the working space make the function non-reentrant? I can only see this happening if the calling function itself is non-reentrant....
Anyone have a list of c++ compilers for embedded systems? Are there any that work with MPLAB?
I see what you are saying. I did not explain the advantage of the approach I wrote about clearly enough. Imagine there are five different payoff types and five different barrier types. To represent all combination you would need 25 derived classes. Although the template approach could be useful, it requires you to have to know the combination of payoff and barrier at compiler time. 
I worked for a company where I had to make a case for C instead of ASM. The boss didn't believe that C would be fast enough, or the compilers good enough to be able to do the project in C because he couldn't accomplish it fast enough in ASM. It was a bad case of choosing a microcontroller before understanding all the processing it would have to do as quickly as it needed to do it. I completely restructured the system to accomplish it in C and found out it was able to run at 75% of the full speed. Yes, the approach in theory could have been done in ASM, but the amount of code needing to be rewritten during development means it wouldn't have been done on time. This is very similar to the case for C++. If you are know what you are doing and can avoid C++ pitfalls, it may actually save you time. The trick is to avoid C++'s weaknesses and use as many of it's strengths.
The pointer has no guarantee of not being shared with other functions using the same memory, I'd suppose.
&gt; This is very similar to the case for C++. The major dissimilarity is that while C does genuinely have a performance cost over and above raw assembly (given programmers competent in each), C++ does not have a performance cost over and above raw C. You don't pay for features you don't use, and when used properly, you can actually get significantly *better* performance out of C++ than C (cf. `qsort` vs. `std::sort`).
-1 not informative enough. 
To me, inventing a new term for something isn't really news worthy.
I've updated the article slightly to make it clearer 
I think if the calling function is reentrant than this guarantee does exist... I should have made this a bit clearer...
I believe reentrancy should exist atomically, i.e., a function should not have to rely on it's caller to be reentrant for it to be reentrant.
Try Anjuta or Eclipse. While you may not have the 'visual' aspect, they are both very useful and free (as in beer) software. I personally prefer a notepad-style editor, but all I need is syntax highlighting and line-numbers.
gVim (MacVim) using some plugins and ctypes is fine for development. Combine that with a build system (I use bam, like SCons but fast). Only thing missing is good debugger integration, using mostly gdb for that now but XCode when doing something with graphics. You can use this setup (except XCode that is =) with MS Platform SDK too if you don't want to use the gnu toolchain.
Apart from a slightly broken version of vcbuild, VC++ Express works just fine as a compiler, even offering TR1 features*. You can use it as just a command line compiler together with makefiles or you can work around vcbuild's problems. So the question is really, what is it about VC++ Express that you want to transition away from? \* Yes, I'm aware gcc 4.x has TR1 too, but gcc 4.x still isn't mainline in mingw, and there are still a lot of things that break with the 'beta' gcc 4.x versions for mingw. So if you're programming on/for windows, mingw may not be an option.
There is no replacement for Visual Studio. 
Code::Blocks, Eclipse, NetBeans. They all have strong and weak points, it really depends on your preferences. 
You kind of have to tell us what platform (still Windows?) and what features you need.
The title isn't totally clear for reasons of limited space, but the issue is that in VC, std::exception has a constructor that takes a const char *, but GCC doesn't. Is Microsoft screwing around with the STL or are implementers allowed to do whatever they want there?
To some people standards are like the *register* keyword -- they are a hint to the compiler.
It's probably a difference in the HP and SGI implementations of the STL. MS use HP, gcc use SGI, iirc.
Once [again](http://en.wikipedia.org/wiki/Stdint.h#Downloads), [Microsoft](http://msdn.microsoft.com/en-us/library/ft39hh4x.aspx) is [fucking up](http://tinyurl.com/6h29oy) the [C++](http://msdn.microsoft.com/en-us/library/8xsbhyzw.aspx) [language](http://msdn.microsoft.com/en-us/library/skce93f2.aspx) [specifications](http://msdn.microsoft.com/en-us/library/ms177255.aspx). But that's OK, well, according to the engineers at Microsoft... (sorry for the rant, I write cross-platform C++ for a living and I'm fed up with all those #ifdef WIN32)
Where are your standards now Stallman? HAHAHAHA! *//ballmer flings chairs in background//* This is standard practice for MS though. Why follow a language standard when you can invent a new one and keep it to yourself?
What is says on the tin. I'm looking at developing an application that needs to run on OS X, Linux and Windows. It requires multithreading. I'm aware there are portable threading libraries (Boost and SDL both have threading) but I'm unsure about the thread safety of the standard libraries and issues with instruction reordering in the compiler. My project will use GCC on all three platforms but unfortunately different versions (MinGW uses 3.*, OS X is 4.0 I think and I will probably use the latest stable version on Linux). Is there a reliable way to ensure GCC doesn't reorder the vital instructions across all these platforms?
Assuming that you write thread safe code to begin with, GCC isn't going to do anything that breaks it. Newer versions of STL are thread safe in the sense that you can use them across threads, but you have to provide locks for anything that accesses shared data. In other words, STL containers don't have locks internally. For portable threads I've used Boost, pthreads (yes, there is a Windows port), and apr. Personally, I prefer Boost if for no other reason than I'm probably already using it on any non-trivial C++ program.
It'd be easier to comment if you could tell us what you don't like about VC++ Express. edit: I realize we could be here for years, so maybe just your top 3 annoyances or something.
Take it to stackoverflow.com. Having said that, compilers are more standard than that you need to use GCC on all 3. If you're using lock-free / other flag-fiddling methods, you should use processor-specific memory barriers; I don't think you want to rely on a specific compiler's behavior's effect wrt any specific architecture. What if you change compiler versions later? What if you add another architecture (you've already got 3)? For lock-free stuff a good place to start is the book "The Art of Multiprocesor Programming"; if you're just using threads, the threading API is all you need. 
I've heard good stuff about [OpenMP](http://openmp.org/wp/) but have not used it myself.
Get a copy of STLport and link with it instead. My experience with MS standard C++ libraries is profoundly negative, especially on WinCE.
It's pretty common for compilers to implement their own extensions to the standard language to "help" users out. It's like being able to declare main() as returning void. Technically not allowed by the language, but almost any compiler will let you do it anyway. I personally think it sucks, because you can inadvertently write non-portable code without ever knowing it. But they probably do it on purpose to help with vendor lock (this code only compiles on VC, therefore, you'll have to either heavily modify it or buy VC). Ugh x2.
I'm pretty sure MS uses Dinkumware.
The STL library support on CE (at least older versions) is pathetic, but VC++ 2005/8 should be shipping with the latest and greates from Dinkumware.
Well, like has been said here before, it depends on what you're looking for feature-wise. You've already got VC++ Express. Why not pay the $200 upgrade fee and get Visual Studio Standard? Better debugging, multiple languages, and support for plugins.
As long as you use thread-safe programming for everything, any threading library should do. All other libraries you use (STL etc.) will specify in the docs which parts are thread-safe and which are not. You probably won't need to use gcc on all platforms: MS compiler on window, gcc on linux and apple's gcc on OS X should be fine. Instruction reordering shouldn't be a big concern if you use fine-grained synchronization. I am assuming you are using locks et al, and not lock-free methods.. Go down to inline assembly (mfence, monitor/mwait, cmpxchg) if you really need precise control on the thread synchronization. Otherwise I recommend either Boost's threading library, or the [Juce](http://www.rawmaterialsoftware.com/juce) library. The latter is an entire app framework, so it might have other tidbits useful to you.
1. As far as I know, the STL and CRT don't have multithreading requirements mandated by the standard, so each vendor has freedom to implement as they see fit. A basic assumption to make is that you are going to have to use synchronization. You must check the documentation for each implementation. 2. Using barriers should avoid unwanted compiler reorders. I would go with Boost. Another option might be Intel's TBB, but check the license, I'm not sure the OSS version can be used for commercial development. I think the license is GPL with runtime exception.
Boost treading
Also look into poco. http://pocoproject.org/ It's a bit lighter weight &amp; less coupled than boost, and definitely more cross compiler safe.
MS used to use HP's implementation, but switched to Dinkumware sometime around VC7 IIRC.
Yeah, the only problem with that is that I'd have to recompile all the dependencies (and there are many) that I can otherwise pick up as binaries. I'm hoping that by continuing to code in Linux I'll come to know what is MS specific and learn to avoid it in cross platform code.
A wrapper library like Boost, APR, or NSPR. As a side-effect, you'll get a suite of additional cross-platform utilities.
It's not a general purpose multithreading solution, but rather a system where you put hints into the code using #pragma's like "you can parallelize this loop here" and "this variable is thread-local", and the compiler and the runtime will take care of most things.
Visual Studio Team.
im a unix dev but i started oyut on windows with a borland toolchain, is it still an option?
Intel TBB. If you can't use that, then Boost threads isn't a bad way to go.
&gt; But they probably do it on purpose to help with vendor lock That may be part of it, but given the number of extensions that gcc provides (where there is far less incentive for vendor lock in), I find it less convincing. Also, anything you need to *buy* VC for (rather than using the EE) probably has you locked in anyway. 
* Microsoft didn't write the VC++ STL implementation; they're licensing it from [Dinkumware](http://www.dinkumware.com/). If you don't want to hate on *them*, you can use another one: either SGI's, or even gcc's libstdc++... * ...except that it won't work, because a) it's bundled with gcc, and b) it actually is gcc-specific—we're talking [syntax stuff like this](http://www.ibm.com/developerworks/linux/library/l-gcc-hacks/index.html). If this isn't lock-in, I don't know what to call it.
Did you try to google: C++ IDE ?
I love VS 2008.
wait a few years till the c++0x standard is implemented widely enough then you'll get it by default :D
They should license something that follows the standard. Hell they could probably import the Gnu equivalent. The Gnu stuff adds AFAIK without breaking the standard.
Take a look at this MS [std::exception defect report](https://connect.microsoft.com/VisualStudio/feedback/ViewFeedback.aspx?FeedbackID=200471). It seems they "fixed" it by changing the documentation. &gt; Thanks for taking the time to provide feedback on the Visual C++ documentation. I have added a comment to the exception topic noting that two of the constructors are Microsoft extensions to the Standard C++ Library. This change will appear in an upcoming release of Visual Studio Someone added this comment: &gt; Please correct me if I'm wrong, but from what I get from the text, it seems that you only want to update the documentation, leaving the class as it is. The problem with this specific constructor is that it's not marked explicit, which means that valid C++ code might not compile under Visual Studio 2005... see this thread for more info: [http://forums.microsoft.com/MSDN/ShowPost.aspx?PostID=1204436&amp;SiteID=1](http://forums.microsoft.com/MSDN/ShowPost.aspx?PostID=1204436&amp;SiteID=1) 
Geany, Code::Blocks, Eclipse, KDevelop. ;)
Pointing the gun under your chin, facing upwards.
I'm using Code::Blocks on windows and Linux and I like it. I heard Eclipe is good for C++ too.
OpenMP is really cool for some applications.
It's an option, but Borland sold their dev tools division to Embarcadero. The C++ Builder software packages are very expensive and IMHO not worth it at this point. The VC++ team has been working hard towards standards compliance in the latest versions, and VC++ Professional has an acceptable price. I think this is the best choice for commercial development on Windows right now.
&gt; If you know me, you know I HATE the private keyword ... and then i stopped reading
Most important thing to know on modern processors (for micro optimizations): optimize for cache misses, not instruction count.
.. or stackoverflow.com
[Did not (need to) RTFA.] No, the most important thing to know about optimizing is: Don't do it unless you really need it. See famous Knuth quote. If, when you know your code really does suck, THEN you look at fixing it. At that time, run Google's Perftools, Valgrind, Memprof, etc. Find out what part of your code is screwing you the most and fix it (and only it). Repeat until happy. Otherwise, don't sweat it as you will only be wasting your time and making your code more crappy.
There are a lot of false assumptions and inaccuracies in the post. However, for beginners, some of the tips can be useful.
I found there is far more on the [author's site](http://www.agner.org/optimize/): * Optimizing software in C++: An optimization guide for Windows, Linux and Mac platforms * Optimizing subroutines in assembly language: An optimization guide for x86 platforms * The microarchitecture of Intel and AMD CPU’s: An optimization guide for assembly programmers and compiler makers * Instruction tables: Lists of instruction latencies, throughputs and micro-operation breakdowns for Intel and AMD CPU's * Calling conventions for different C++ compilers and operating systems It seems well worth a look.
Indeed - Crap! Is that guy an Opera dev? WTF? It's on opera.com and if you click on his 'Opera' tab it goes to an 'About opera' type page. If he isn't, they should protect themselves from looking like he is. 
Well opera offer a lot of cool free blogging and community services. Not sure why to be honest but they are pretty good.
And Bill Gates and Ballmer love you!
no need for other language beyond C++ thanks. What i really need is something that would let me make Windows/Linux 32/64b code in C++ and has a nice debugger. thanks for all the replys, but im still stuck...
- optimizer compiler; - Inline ASM or good intrinsics (MS ones create a lot of bloat); - Integrated debugger (and possibility of integrating a profiler); - free as in "i wont pay a $ for it" and can do whatever i like with it;
I believe DTanner was assuming that you've already found a need to optimize, and in that case, optimize for cache misses, not instruction count.
"it's just evidence that we should really start paying attention to the parallel computing space if we want to remain relevant" If you aren't already, you may have been left at the station.. 
I wonder why a healthy minded programmer would want to use such a thing when many great, stable, cross-platform, open source regex libraries, such as Boost.Xpressive, Boost.Regex and PCRE already exist for C++!
Looks nice, at least for basic threaded operation, not sure if it offers all of the control functionality of things like pthread though. And of course, I have to wait for C++0x support... 
&gt; And of course, I have to wait for C++0x support... That's what I was thinking. How long until these features are in my compiler?
Isn't the new extension basically boost::thread?
gcc recently started supporting the C++0x premlininary spec, so if you're using linux, as soon as your distro takes the latest 4.3 version you can use -std=c++0x or -std=gnu++0x. For VC++ there is a VS 2010 virtual machine image you can get from MS, but I don't like using virtual machine images to work, so it'll be whenever VC++ 2010 comes out - which is likely to be early 2009 I believe. If you're using mingw it's probably easier to give up hope on waiting :/ Any other compilers *shrug*
Thanks. You hit the two I use, VC++ and gcc.
Very cool project. I wonder what took so long?
Yes. A lot of boost became tr1 which is moving into std in C++0x. Wonderful process IMO.
In the meantime this spec is implemented in boost::thread which works on pretty much everything (even slugs like VC6). So go play and when C++0x rolls into your town it should just be a namespace swap. 
From the comments: &gt; I really don't understand why people are so angry with Linus when he has an opinion. Who really cares? Well, it's because people assume that because he is responsible for some of linux, and some of git, that he must somehow be an authority, and that his word carries more weight than others.
&gt;Linus can implement Git in whatever language he wants to. He can do it in brainfuck for all I care, I’m just a user. But he’s lying to himself if he believes he chose C and Perl because they were the best tools for the job, and not just because they’re the tools he’s most used to. You mean - Linus isn't being objective, and that he's just a self important douche with an army of fanatical idiots who parrot everything he says?
&gt;It all boils down to git was never designed to take user’s needs into mind. It was designed to download Linux source as fast as possible, and I’m sure it does that well. The problem is if git fanboys and Linus want to go around advertising their system as the superior one, they might have to actually start listening to these ‘users’. If he wants to build something for himself, as his own personal tool, then why not use the language he’s most familiar with? But if he wants to build something that the programming community as a whole should use and enjoy, then he needs to stop pretending he magically shits bricks and every design decision he makes is the best one. Choosing C for a project he expects others to adopt, maintain and extend was a bad one - it was one he made for himself, and which he’s continuing to justify by holding on to shreds of an early 90’s fear of a new language. That's arguably the basic problem with linux in general. Written by nerds purely for their self satisfaction, and not for users. Here's a classic quote on a KDE development blog, that really sums up what linux is all about: ["KDE, like many other open-source projects, doesn't really need users at all."](http://www.kdedevelopers.org/node/3535) 
&gt; That's arguably the basic problem with linux in general. Written by nerds purely for their self satisfaction, and not for users. How is that a problem? That's like saying the problem with my model train set is that I made it for my own entertainment in my basement. That's not a problem. It may be a problem for *someone else* who has decided they want to rely on my train set for their morning commute, but it's not a problem with me or the train set.
People who trash C++ come in three flavors: 1) older, hard-core C guys 2) jerkoffs from the GC world like Java, C#, etc. who were never able or never cared to really *truly* learn C++ - seriously guys, it's not that hard to remember to delete a pointer 3) VB and web programmers who, while certainly working in a complicated field, have no appreciation of what C++ is really for or how it differs from what they do. Of the three types, #1 is by far the most palatable to me. If you're looking down on C++ from an even more hardcore language, fair enough. I'll admit that you can do the same things conceptually in C that you can in C++. The system is just expressed with different code and maybe C++ isn't always worth it. * I actually like C# and don't mind Java. C# certainly has its place together with .NET for any sort of smallish GUI program.
It's a problem if your model of developing that train set is to get as many competent people involved as possible, and encourage them to contribute new elements through a quality controlled process. I think that it is to the advantage of any open source project have as many reasonable users as possible. And has become identified very strongly as a fight against Microsoft. That's a role that needs to be filled, and to have that role filled by free software is a great thing. Now is a great time for Linux adoption. With Vista having such a bad reputation I'm sure that untold masses of users are giving Linux a try. I've certainly been hearing a lot more about Ubuntu lately. And if Windows 7 sucks as hard as Vista... 
I am certainly not an older, hard-core C guy, but I love C for the system level projects I work on. However, for other projects, where languages like C++ / Java / C# are more suitable, I tend to side with Java not because I don't understand C++ but because I don't want to waste time ensuring that all of my pointers are deleted or that my types are correct or that I am linking correctly or that my templates are in order. I am much happier with Java or C# taking care of that for me. If C++ works for you, then that's great. Personally, I don't want to deal with it because it leaves a bad taste in my mouth. I rarely have a project that can not be done in C, Java, or any of the many other popular languages.
There are pointer constructs that make such tasks in C++ a *lot* easier. The first that comes to mind is boost::shared_ptr. One of the major powers of C++ is that it, as a language, supports the creation and use of facilities like this to manage the not-so-nice things about working with raw pointers.
How did it NOT have template support already?! Christ, I can't think of a program I've written in the last 5 years that hasn't used templates/generics.
&gt; I tend to side with Java not because I don't understand C++ but because I don't want to waste time ensuring that all of my pointers are deleted If you're writing modern C++ (e.g., using shared_ptr as the previous poster noted) this isn't a serious concern. &gt; or that my types are correct I'm not sure what you mean. If your types are incorrect in Java or C#, your program is just as incorrect as it would be in C++. &gt; I rarely have a project that can not be done in C To paraphrase Stroustrup, the only reason I would ever write in plain C would be lack of a C++ compiler. Even if only for templates and the stricter type checking, I'll pick C++ over C. I see no real technical reason ever to go with raw C over C++.
People that trash people that trash C++ come in two flavors. Those that generalize and those that don't.
Read the blog instead of just the title before ranting, troll
Ugh, I did read it you idiot. I can't believe KDevelop didn't have templates in it, I can't imagine using an environment without support for templates. There, do you prefer my re-wording of what I said?
it's probably a better bet to use the tr1/soon-to-be-std tr1::shared_ptr now, it's identical (afaik) to boost's, but is supported as standard in recent versions of VC++, g++ and probably others. It's easier than relying on boost to be present.
Definitely use a 'c++' compiler over a 'c' compiler. In my experiece the c++ compiler is pickier with types and error chekcing which helps write higher quality code. In more advanced cases the ability to replace #define macros with debuggable inline template functions is another big win. Another big win is the &lt;algorithm&gt; interface which is capable of improving SIMD performance over 'c' without having to hand code routines.
If you have read it, why don't you know that a) It has tons of templates in it, and that's not even what the whole blog is about. b) It has had template-support since forever, which means it helps you writing templates. The blog just says that it can now additionally compute meta-programs, which no other IDE I know of can do. Learn reading, and stop calling people idiots who can.
There are only two kinds of programming languages: those people always bitch about and those nobody uses. (Bjarne Stroustrup) From here: http://www.sysprog.net/quotlang.html 
Shh
&gt; This means one day (in the not so distant future) hardware vendors that support OpenCL on their devices will be able to run applications that depend on the OpenCL spec -- imagine your 4-core-8-thread-capable application will be able to seamlessly scale to 32-core-128-thread machines. I call bullshit. No programming language or hardware standard can increase the scalability of your algorithms, it can exploit existing potential for concurrency, yes, but it won't automagically convert your inherently serial (or low number of threads parallel) code into highly parallel versions.
super oldie, but mega goldie
If premature optimisation is the root of all evil, surely premature optimisation using meta programming is the devil himself.
&lt;luddite name="linus"&gt; But... but... C++ is so much slower than C! &lt;/luddite&gt;
How wanktastic. If you used a plain old inline function or macro, the cranky old C compiler could just unroll the loop for you.
runtime efficiency isn't the only concern. what about code bloat caused by templates? (tbh, i'm a C++ guy, so i know the answer to that particular Q, but i'm sure other readers necesarily wouldn't)
 Relevant discussion: https://twiki.cern.ch/twiki/bin/view/Atlas/CalculatingIntegerPowers
 struct Vector3 { float x, y, z; Vector3(float x, float y, float z) { this-&gt;x = x, this-&gt;y = y, this-&gt;z = z; } } std::vector&lt;Vector3&gt; myVector;
this post has been on the c++ subreddit front page for a couple of weeks. are we just not submitting enough material?
The STL doesn't support struct types? What sort of crack is this author smoking?
 template&lt;class T&gt; class Vector3 { public: Vector3() : x(T()), y(T()), z(T()) {} Vector3(T x, T y, T z) : x(x), y(y), z(z) {} T x, y, z; }; 
unfortunately the guy does not seem to quite understand STL ... and is probably reinventing it ...
I am currently writing a little C++ logging class and have been programming C++ (mostly Qt) for a while. I decided to allow users of the class to use the stream operators so they won't have to write code to convert stuff to strings all the time. Now I am wondering if it is possible to define a template (I am new to templates) that would allow me to define code to stream e.g. std::list or std::map once and have it work instantly with any type where the element type has a stream operator defined. Basically I want e.g. all lists to look the same, a list of int should be: &gt; [1,2,3] a list of string &gt; ["a","b","c"] and so on. Is this possible or do I need to define a macro that is instantiated for each element type to get container streaming support for that type (i.e. have effectively one copy of the container streaming implementation for each element type)?
Not all metaprogramming is as ugly as C++ metaprogramming, in fact in most languages the metaprogramming version probably looks cleaner than doing it another way.
You can probably find implementations of this, and I would have thought Qt would provide one, but here is what I would do: Write a "template&lt;typename TYPE&gt; ostream&amp; operator&lt;&lt;(ostream&amp; os, const TYPE&amp; collection)" that streams out the "[", iterates on the collection calling operator&lt;&lt; on each iterator's value, streams a "," after each and then the final "]". The sequence collections (list, vector) and the associative (set, map) collections have different iterator dereferencing. I would make the generic operator assume sequence iterators and then write specialized ones for the most common associative collections (using the ".first" and ".second" type dereferencing). Probably just specializing for "map" would cover most usage. 
Well, yes, I should probably clarify that point, I don't mind writing one implementation per collection, I just don't want one for each element type. I tried template&lt;typename T&gt; ...operator&lt;&lt;(..., std::list&lt;T&gt; l) but that didn't work. Qt doesn't provide any support for any of the std types, they have a strong case of NIH syndrome and implement all the collections themselves. Edit: Basically what I would like to do is convert this LogStreamHelper operator&lt;&lt;(LogStreamHelper streamHelper, std::list&lt;int&gt; l) { streamHelper.append("["); std::list&lt;int&gt;::iterator it; for(it = l.begin(); it != l.end(); it++) { if(it != l.begin()) streamHelper &lt;&lt; ","; streamHelper &lt;&lt; *it; } streamHelper.append("]"); return streamHelper; } to work with any type where a definition like this exists: LogStreamHelper operator&lt;&lt;(LogStreamHelper streamHelper, int number) { std::stringstream ss; ss &lt;&lt; number; streamHelper.append(ss.str()); return streamHelper; }
&gt; I don't mind writing one implementation per collection, I just don't want one for each element type. If you follow what I describe you should only need to write two implementations: the generic one that assumes a sequence type collection (ie, assume TYPE is "vector", "list", etc) and a specialized one that explicitly specifies TYPE as "map". For every other, non-map associative collection (eg, "set") you would need an additional specialized implementation. But it is rare to see anything but "map" used so unless you want to be very thorough you can ignore them.
 template&lt;typename T&gt; LogStreamHelper operator&lt;&lt;(LogStreamHelper streamHelper, const T &amp;l) { streamHelper.append("["); T::iterator it; for(it = l.begin(); it != l.end(); it++) { if(it != l.begin()) streamHelper &lt;&lt; ","; streamHelper &lt;&lt; *it; } streamHelper.append("]"); return streamHelper; } gives me a compiler error on the T::iterator line: error: expected `;' before 'it' and of course the followup error about undeclared use of the variable "it". Is there a special syntax I have to use to prevent those? I hope I am not getting too annoying, just trying to figure this out and (unlike most other features so far) my google searches turned up nothing, just plenty of tutorials how to implement generic containers, not how to use the existing ones in generic ways.
Your code looks correct to me, however you will eventually need to use "const_iterator" instead of "iterator". But, I don't think that is what causes your current compile error. I assume you get this error where you are instantiating the template. Are you #includ'ing the header that defines the type you are using in that same file where you use this template? Older compilers let you get away with doing this outside file scope but newer ones require it (I'm talking about GCC here, I don't know about others). 
I figured it out by temporarily moving the code into the (test) cpp file where it is used, then the compiler error contains the additional hint: error: dependent-name 'T::const_iterator' is parsed as a non-type, but instantiation yields a type note: say 'typename T::const_iterator' if a type is meant Once I fixed this I could move the working code back to the header: template&lt;typename T&gt; LogStreamHelper operator&lt;&lt;(LogStreamHelper streamHelper, const T &amp;l) { streamHelper.append("["); typename T::const_iterator it; for(it = l.begin(); it != l.end(); it++) { if(it != l.begin()) streamHelper &lt;&lt; ","; streamHelper &lt;&lt; *it; } streamHelper.append("]"); return streamHelper; } Thanks a lot for your help :-) It is always annoying to figure out stuff where you aren't even sure if the language can do it at all.
I'm glad you got it working. 
I'd like to use this with VS2008 - I guess I'll have to wait for a long time for this, or use boost:thread as before. I guess boost one is virtually the same, no?
That can be a problem if you don't enable the optimiser or if you're not 'modularising' your templates properly. Generally templates should be designed such that they same code as what you would have written by hand, but make the code more readable and less error prone. GCC is rather good at flatening deep template hierarchies though and i've seen it do some amazing things with templates.
"...other guys who’s sole knowledge...". The apostrophe police grasp the back of your under-shorts and tug upwards sharply, causing a wedge of fabric to become lodged between your buttocks.
Not so surprised :) 
So basically, c++ is ten times faster than c# for high-performance applications, while python is ten times more productive than c# for performance-indifferent applications. What exactly is c# useful for?
It's more productive than C++ for building Windows GUI apps and other Microsoft-only programs. Not that I have ever used it or plan on ever using it - I hate proprietary languages like C#. Python's my favorite language by a long shot.
C# is not proprietary. http://www.ecma-international.org/publications/standards/Ecma-334.htm http://msdn.microsoft.com/en-us/netframework/aa569283.aspx Why do you hate things you've never used or plan on ever using? 
I call bullshit. This guy is not exactly doing a proper test. He does not state the environment specifics he is running the test in, the link to his C# code is broken so you can't even analyse it, and what's more, C# uses JIT compilation of intermediate code, where as C++ is fully compiled. I really wonder which one you expect to be quicker?! Also, he is not exactly doing an in-depth analysis to understand the performance issues, he clearly is not an expert on C# anyway, I mean: &gt; the generic version of Sort&lt;T&gt; is faster than the non-generic one, probably because the CLR can remove dynamic casts or something. Or something? Just reflect the bloody assembly and analyse what's happened in the MSIL! 
It's proprietary because the spec is controlled by microsoft and changes quite often. Are you aware of any implementations that *aren't* sponsored by microsoft?
If by changes you mean progresses you are right it progresses quite often. Didn't Python just come out with a backwards incompatible new version? And python is controlled by one guy (hi Guido!). How is that not proprietary? Mono originally was a rogue project not sponsored by anybody. Just because they see value in sponsoring them now doesn't change Mono's history or what any other project could do. How many alternative java implementations are there, or free competitors to g++ for that matter? C# is a good language and I've yet to hear an argument against it that didn't involve MS bashing at one point. Yes, it's x10 slower than c++. That's good. That's a constructive criticism. I hate microsoft as much as the next redditor but calling out a technology as bad just because it has some microsoft taint to it is akin to invoking Godwin's law and you lose your argument in my book. 
Good points. I agree, my main reason for not liking c# is that it's made by microsoft. I don't like seeing it gaining traction in the linux world, and I'm afraid one day microsoft could use its patents to wreak havoc in the open source community. But I can't prove that, and that isn't really criticism against the language.
Agree to a point. I did post in the comments on the blog asking what versions he used of everything. Source code would have been nice too. Personally, I hate virtual machines (Java, .NET) unless you're doing something that needs the security or to be cross platform. But well written C/C++ can be cross platform with a simple recompile.
How you program to the exact latest spec on ANY product?
[dotGNU](http://www.gnu.org/software/dotgnu/)
Godwin's law is not an indication of an invalid argument but merely a statement of inevitability
Well, this really wasn't meant to be a complete test of C#'s performance by any means. Nor was it meant to be an example of how to best sort in C# - which is why I didn't bother to investigate why one method is better than another. Anyways, the link to the C# code is fixed, and if you're interested I suggest you just run each test for yourself.
I know there is a high chance of me getting down modded for this, but I'm glad MS is interested in Mono. In fact, I hope lots of companies start showing more interest in Linux projects. Especially GPL'd ones like Mono. But I'm ok with proprietary projects too. Adobe Photoshop on Linux would be great in my opinion. So would MS Office. 
The problem with MS using patents to wreak havoc in the open source community is that the open source community could do the same thing back to Microsoft. Sun, Novell, Redhat, and many more have patents that MS infringes on, just like Linux infringes in many of MS patents. Neither side will sue because it becomes mutually assured destruction for both sides.
The way C++ and C# handle generics at runtime is completely different. C# generics are a stuct with a (void*) to the instantiated object while C++ generics ARE the object. Dynamic cast or not, the C# version will always have the extra level of indirection. They did this for a reason. Not sure what that is but Java, [Vala](http://live.gnome.org/Vala/Tutorial), and pretty much any other language newer than C++ does generics this way. Maybe someone more studied in this can state the reason.
Breaking: Blog author's preferred programming language surprisingly beats out other language in irrelevant benchmark.
This is the data type he's using in C#: unsafe struct Data { public int key; public fixed char data[128]; } which is, needless to say, not a typical C# one. I did a comparison using a regular class for Data and [the results](http://journal.stuffwithstuff.com/2009/01/03/debunking-c-vs-c-performance/) were not surprisingly much more in C#'s favor.
Microsoft has a lot more money to pay for legal expenses. Also, the open nature of open source makes it far easier to prove there is actual patent infringement.
&gt; I suggest you just run each test for yourself. [I did](http://journal.stuffwithstuff.com/2009/01/03/debunking-c-vs-c-performance/). What made you decide to use a struct with a fixed array for Data?
http://www.linuxfoundation.org/en/Members That's the list of people who will fund the counter-suit. http://www.patent-commons.org/commons/patentsearch.php?searchSubmit=Find&amp;formType=results That's a list of patents they can use to go after Microsoft. I think Linux will do ok.
Good update.
If you read the originating article on cache pressure it would be obvious why I didn't put the data array on the heap.
I don't know why munificent's comment got modded down and it upsets me. You use different tools for different situations. C++ for cross-platform systems programming, C# for Windows programming. One is not better than the other except for situational reasons. Why is this so hard to understand?
The problem I have with your retest is this line at the end: "Um, slightly different? In his original post, he states that the indirect sorting is twice as fast in C++ than in C#. I can’t do a direct comparison since I didn’t run the C++ code, but since my change to the C# made it run 2.885 times faster than his C# code, it stands to reason that the C# and C++ performance are neck and neck, if not a bit faster in C#." What he actually said was that the slow C++ direct sort was twice as fast as the fast C# indirect sort. Therefore, your statement should really claim that C# is neck and neck in performance with the slow C++ sort.
Don't get all smarmy with me. I worked for years at Windows shops. I have plenty of experience with Microsoft tools: Visual Source Safe, Visual Studio (VB/C++), SQL Server, ASP etc. etc. C# is Microsoft's rip off of Java - everyone knows that. BTW, I haven't used it professionally but I've played around with it a bit and yeah, I don't like that it's tied to the M$ monopoly, so I don't plan on using it again. But I ain't stoppin' you from drinking the Kool-Aid. 
...so you opted for a solution that performed worse?
&gt; I don't know why munificent's comment got modded down and it upsets me. Probably because it's snarky instead of informative.
&gt; What he actually said was that the slow C++ direct sort was twice as fast as the fast C# indirect sort. Good point. I didn't notice that in the original article.
yes, good update ...
&gt; However, it’s fairly easy to create objects with 128-bytes or more of data. That’s 32 4-bytes variables, which isn’t a huge amount of variables to have in a class, especially one with a few parent classes each with a few member variables. True, but even so those objects will rarely be moved around in memory since C# is a pass-by-ref language. Object size in C# is generally only relevant at creation/deletion time as far as performance goes. Once it's in memory, a reference to it is 32 bits no matter how big the object is.
A class wasn't the best example, a better example is a vertex. Each vertex will be a struct and part of a larger block of memory (VertexBuffer). It's common to have very large vertices in particles systems, and common need to sort these vertices.
Within games, that's a common use case. Within C# programming at large, not so much. In that scenario the built-in sort function is unlikely to be used anyway. I'm not a graphics guy, but I'd expect a more optimal algorithm taking into account the previous sorted state would be more useful: something like a heap or ordering-preserving collection. Or even just a sort function that handles nearly-sorted arrays better (the built-in sort is likely quicksort).
When boost::spirit works, it's great. When you get a compile error, it literally goes on for friggin' pages. 
You could try [Cilk++](http://www.cilk.com/multicore-blog/bid/7775/Cilk-for-Linux-a-great-stocking-stuffer). To be honest, I didn't try it myself yet but it seems rather neat. The Windows version is due this January. And no, it probably isn't a good idea if by multiplatform you also mean Mac, PowerPC and SPARC.
I'm still fairly new at C#, but wouldn't using an unsafe data object trigger a ton of marshaling overhead?
Have they fixed the ABI yet? Nothing like being unable to link to a library because a different compiler (or same compiler, different settings) was used... (hard-core C programmer, switching to C++/Boost for a larger project, uses C# at work and... and... goddammit, I'm staring to *like* it...)
For values of ok bordering 1% market share. 
I don't think it has to be marshalled (which implies serializing it some way), but I think it may need to be pinned to prevent the garbage collector from relocating it while it's in use. But I'm not a low-level .NET guy, so I'm not sure.
Local Variable Colorization - is not good enough. The problem - different colors every time look what [visual assist](http://www.wholetomato.com/tour.asp) can do and at least try do all its features...
It's weird, because while a computer can read text really fast but has troubles with images, the human brain can scan images really quickly but has a harder time deciphering text. That's why we use syntax highlighting: it makes your text look more like an image and reduces load on your poor brain.
Yep, I found it painful to develop with MSVC without it. Although I haven't tried the newer versions. I found the better syntax highlighting, and the better intellisense/suggest were really helpful.
just do not forget we scan images - thats why the l I 1 looks similar to us. So actually colors creates substantial differences...
switching to linux without VA was a disaster to me. I used to compile code 3 times less in VS/VA - because VA highlighted "bad" code. I really like templates: ie ife -&gt; if ([CURSOR_HERE]) { } else { } 
tried. I use xemacs. Flymake was very hard to configure with our makefiles. But it is still not as responsive as visual assist. VA gives you choices/highlighting momentary. Templates - less important but i will check them. VA also has a very strong syntax highlighting...
Well what do you expect? Starting from simple cells, animals always had to find a way to navigate in a more or less unknown world which quickly led to the development of eyes. Evolution had millions of years for eyes to develop and for the brain to adapt to it. I contrast, we've been reading stuff for a few thousand years only. And only since recently you can say that "most people are able to read". Give it a few ten thousand years and we might just get better at it :D
I'm going to bet on nanobots enhancing your brain capacity. :O
&gt; It's weird, because while a computer can read text really fast but has troubles with images, the human brain can scan images really quickly but has a harder time deciphering text. You're comparing different media. Our eyes don't process text, they process *images* of text. Computers are much worse than us at that too. But if you give them *OCRed* text, then sure, it's easy.
This will get voted down 'cause it mentions an MS tech, but the syntax highlighting in VS for C# is fucking brilliant. One particularly nice feature is that it won't syntax color class names that aren't actually defined classes. If your class is named "Foo" and you type "Fooo", it shows up black. Compile errors from typoes are a thing of the past. Stangely, their syntax highlighting actually helped me really grok generics (templates for you C++ folks). If you have a generic class Bar&lt;T&gt;, it doesn't color it *until the generic parameter is provided*, so "Bar" shows up black but "Bar&lt;int&gt;" is colored. That helped it click in my head that Bar is *not* a class, it's a construct you can use to create one. Bar&lt;int&gt;, on the other hand, *is* a class.
It looks like - *gasp* - Visual Studio 2003.
Agreed. 
*"Don't wait for a full C++0x compiler: **Buy** your copy of just::thread now and start using the C++0x thread library in minutes."* Don't get me wrong I'm all for people selling libraries for profit. I just thought I'd point out the commercial nature of the library.
via: http://gafferongames.wordpress.com/2009/01/12/unit-test-bloody-idiot/
yeah, so?
Misleading title is misleading. This isn't partial template specialisation at all and the article ignores the fact that inheritance drops operator= and constructors from the derived class.
I prefer CppUnit personally, but that's just me.
I prefer Googletest and Googlemock which seem very polished unlike all the other C++ unit test frameworks I tried.
I think he overstates how hunky dory things are in the Java world with volatile. Until they fixed the memory model, volatile was largely useless, and even now it is pretty much useless.
I wrote the original CppUnit and I prefer UnitTest++.
Isn't Boost there, or almost there, anyway? edit: looks like not. 
How about boost.Test?
Boost.Test is pretty nice. A cool feature I discovered by accident is that if your test leaks memory, Boost.Test will let you know. Also, the fact that it can output test results in XML made it easier to integrate into our build system.
I always have to say this... All you need is a simple class which contains a vector of function pointers and evaluates them. If anything unit tests should meet the KISS principle and be readable, in fact portiosn of the unit tests should be the code sucked directly into the documentation.
Nice to see Apple so high on the list of companies contributing to advances in multicore. 
Has anyone tried it yet?
useful
It comes in a self-contained .exe file. Doesn't do us Mac users much good.
As someone currently rewriting a hardware driver from BSD written in C for OS X (embedded C++), I wholeheartedly agree with the article's main idea. Although the author has not really developed it further. The advantage of C++ comes in abstraction. It makes a ton of boilerplate OR hardware-specific constructs seem less tedious to code, and be very reusable. Also, the idea of 'superclass' for device families providing basic services and derived classes for hardware specific stuff makes it pretty slick compared to plain old C. Anyone interested in seeing C++ in action, for low-level hardware programming should read [IOKit documentation](http://developer.apple.com/documentation/DeviceDrivers/Conceptual/IOKitFundamentals/Introduction/chapter_1_section_1.html).
I thought this article was too basic/obvious to vote up, but I agree with the sentiment. C++ makes abstraction penalties as minimal as possible, while allowing you to use the type system in particular to catch boneheaded moves (and in the case of templates, generate very efficient code in a declarative fashion).
I really had hoped for something more than just "you can abstract and it has some sugar!". Of coarse you can write good embedded code in c++, if you turn off some features.
I have done some very low-level driver code in C++ -- not using MI, or templates, or whatever, but relying on small classes to wrap certain hardware objects (registers, FIFOs, etc.) That actually proved a big win: for one thing, ctors and dtors can hide a lot of init/deinit code, which makes the places where you express your main algorithms simpler. It was for the win in that case, but I didn't see a real benefit to the C++ example in the article.
Upvoted for some interesting modes, even though I always find CEDET messes my emacs config up more than I can bear.
That's pretty cool. I don't really see how it makes sense that a static const member can reference instance variables across multiple instances, but it appears to work. 
Crazy - agree. BUT(!!!) there is no such thing as operator precedence in real life. Do not rely on this. Never. Except obvious cases with "=": a = b + c; use f..g parenthesis. Even if you write: a = b + c * 4; use parenthesis. a = b + (c * 4); any person that look on second code will never ask what was intention of programmer. p.s. fixed typo wright -&gt;&gt; write.... 
wright on.
you are wright!! Oxford Marglexx Dictionary **wright** : to write something rightly! 
Who me?
&gt; Incidentally, it’s more and more clear that C++ is not a superset of C. First, this is a pretty well known fact. About the only people I hear that make that claim are people with nothing more than a passing knowledge of one or both of the languages. C++ has it's roots in C and some work has gone into making different constructs compatible, but the two languages have evolved on their own and occasionally borrow from each other. Second, even if C++ was a proper superset of C, this particular statement doesn't disprove that. If C++ is a superset then that means all valid C would have to be valid C++. Since that statement isn't valid C syntax then it places no restriction on C++'s behavior. It would be the same as saying a class isn't valid C but it is valid C++, therefore C++ isn't a superset of C. 
Exactly, be explicit in all your code. Ambiguity is bad.
&gt; any person that look on second code will never ask what was intention of programmer. Any *intelligent* person can look at the first example and never ask what the intention of the programmer was.
&gt; any person that look on second code will never ask what was intention of programmer. While I agree with that, in "real life" the standards really do define operator precedence, so while it is often a poor indicator of intent, you can rely on how the compiler will interpret it (at least these days). I've seen people argue that the precedent is literally undefined, which is just bogus.
I came here to write just that - chances are the person maintaining your code isn't going to want to keep looking up operator orders just because you didn't feel like adding parentheses.
ANSI C has 14 or 15 different precedence levels. Do you remember them all? Is intelligence just ability to remember a list?
I agree in principle, but arithmetic operator precedence should be obvious.
say
The example given only uses * and +, whose precedence in C is the same as the precedence everyone's known since elementary school. It's one thing to argue against assuming programmers know the precedence of the ternary operator and the assignment operator; it's an entirely different thing to argue against assuming programmers know the precedence of addition and multiplication. The OP's point reaches too far. Programmers may need to parenthesize logical operators or ternary operators or assignment operators; they absolutely *do not* need to parenthesize addition and multiplication operators when they're the only operators used in an expression. Such parentheses are just syntactical noise that reduce the readability of the code.
&gt;And if you care about languages other than Seventh Edition New Jersey ASCII, you're probably writing something that should be in Java rather than C++ This is a sad world we live in.
Sure it should... until you write an expression like `a+b+c` in floating point arithmetic, and discover that in floating point maths, lots of associative operators aren't.
That's a good point. But if you have a good reason to need potentially suspicious looking parentheses, you should document it somehow. And it might be better to split up the expression instead. Otherwise someone might think they're unnecessary and remove them.
Oh, I completely agree with everything you just wrote. I'm just pointing out that arithmetic operators in software aren't necessarily as "obvious" as we might expect at first glance, even for basic operations.
yes. but assume you are hunting bug in my code and see a + b * 4. Is it possible that I actually wanted to write (a + b) * 4 and just forgot the parenthesis? yes. and if a + (b * 4) it is clear.
No, it's not clear. If I see `a + (b * 4)`, I'll wonder why you thought parentheses were necessary and suspect that you might have put them in the wrong place or used the wrong operator.
Explicit is better than implicit. You entire argument is utterly fatuous. You suspect that they didn't have a firm grasp of operator precedence because they used brackets. So you therefore suspect that they might have put them in the wrong place or even used the wrong operator. What the hell? So instead you'd rather they just guess and likely get it totally wrong? Why stop there? How do you know they even meant to write 4? or b?! How do you know they weren't actually trying to write an essay about October Revolution but somehow ended up writing some basic arithmetic operations instead? I'm not saying you should *always* put the brackets in, but yeah, sometimes it's pretty handy and makes it easier to read, even when it's something simple like that. Certainly being more explicit isn't a bad code smell at all and I'd much rather there too many brackets than a confused person used too few. There are much much much worse and more common signs of idiocy than being a bit bracket happy. 
ICU is your friend.
 str.find("PREFIX") == 0 // oh noes
Cool.
Biggest problem I have with locales is that with gcc/glibc at least there's hidden mutexes inside their relationship with streams. I got massively burned by this trying to adapt mmap to streams. Also locales only deal with one side of the coin (hehe i made a funny). The other part is translation and most especially grammar differences which affect sentence and thus argument ordering. The grammar problem really shows the utter weakness of streams which can really only be properly solved with a "compose" type interface which goes back to using printf style output.
Remember: we're presupposing that *something* is wrong. Maybe not in this expression, but somewhere nearby. And given that this is very vague code without context, it's hard to say exactly what I would think. &gt; Explicit is better than implicit. Understanding is better than parroting hard rules. &gt; You suspect that they didn't have a firm grasp of operator precedence because they used brackets. On the contrary, I assume that if I'm reading someone's code they have the basic skills to know how arithmetic operators work. If they think parentheses are necessary, there's probably a reason. Yeah, if enough people start putting in superfluous parentheses, I can no longer look at things this way. But right now, they usually don't. &gt; How do you know they even meant to write 4? or b?! I don't, those could be wrong. Remember again that we're presupposing there is a bug. But right now I don't have the context to say anything about them. &gt; How do you know they weren't actually trying to write an essay about October Revolution but somehow ended up writing some basic arithmetic operations instead? I suppose that's possible as well, but I've only once encountered a giant essay in the middle of code and it'd be hard to make such a large mistake. &gt; There are much much much worse and more common signs of idiocy than being a bit bracket happy. Yes, but it's still a sign that something is amiss.
those are IDEs. not compilers.
No.
There's a problem....Qt and modern c++. They clash and overlap. I'd like to see large parts of Qt ripped out and replaced with stdc++ for future maintenance purposes, and other portions of Qt to be considered for replacement by other possible better technologies. Qt's commercial basis means there's a lot of stuff implemented purely for the sake of developer lock in and not because of technology choices.
Um... C# vs C++? The answer was obvious before the charts and tests. C++ is *compiled*. To even do this tells me you have no idea what C# even is.
I highly recommend Netbeans as a C++ IDE, on Linux. After playing with every goddamn IDE there is, I found Netbeans' code-completion to be the most accurate and quite fast. It's the closest thing to VisualStudio on the Linux platform. Eclipse takes ages to index the code and the completion is a hit or miss. The other IDE features are right on as well. The trouble with Netbeans however is that it uses Java5 (or something.. I don't know java terminology) GUI toolkit instead of the newer one, so in addition to looking non-native, the font rendering is absolutely horrendous. On the plus side, like Eclipse, you can install Vim-like editing mode in Netbeans too. (IMHO the way to go is to adapt/embed Vim-based code editor into the IDE rather than trying to turn Vim itself into an IDE). Before the fanbois start posting: Anjuta and KDevelop are garbage unless you are writing Gnome or KDE centered apps. You can't write a helloworld.cpp in either of these IDEs without creating a directory structure, makefile, autoconf nonsense, README, Changelog, package description and other crap. Plus the code completion is subpar. Code::Blocks is kinda OK but its code completion is not good either.
I revisited Netbeans recently and was pleasantly surprised. 
I have managed to convert many to Netbeans for C++ in our team. But as he says we majorly work for non UI stuff so we do not have an option to switch to C::B. I can't understand people having problems with Makefiles. I mean, come on, I've been doing it for years, it's soooo darn easy! Read the docs dude!
The only reason we use C::B is because of it's close integration with a UI builder for WX for UI stuff. Other than that Netbeans rules.
I also tried every IDE under the sun in both Windows and Linux, and have found NetBeans to be at the very top in both environments for C++. I like the versioning system of NetBeans allowing you to connect to SVN and commit/update easily with two clicks. I did my senior programming project last semester using NB and it went smoother than if I had tried it with Visual Studio. The code completion and everything it does to keep track of your work is just great.
What about its RAM use/consumption? Less than, say, Eclipse?
Does anyone know of an offline listing of C++ standard library classes, templates and functions in a similar vein to the Sun Java class library listings? I have many books on C++ but trawling through a guide when I really want a technical listing of members is painful.
Upvoted, I like that guys writing style! He's so enthusiastic about everything!
looks to be windows only... that's a shame since I miss stuff like this when coding in c++ instead of java. even something like the basic blockingqueue in java has so many uses in a multithreaded app. hopefully with the upcoming standardized threading support, we'll see more cross platform concurrent libs for c++.
I'm not *exactly* sure what you're looking for but [SGI's documentation can be downloaded for offline viewing.](http://www.sgi.com/tech/stl/download.html) You'll need to scroll down to the documentation links.
I have a class that contains some settings stored in fixed-known-at-compile-time non-dynamically-allocated arrays and I just want to serialize the darned thing. It appears to save just fine, but loading fails with an "array too short" exception. Is this possible without having to resort to a vector or conversions to/from a binary_object?
Code for object: class heightmap_settings_t { public: int width_in_blocks; int height_in_blocks; double reflectivity [ Layer_Count ]; // 0 = absorb all, 1 = reflect all double specific_heat [ Layer_Count ]; // ? double heat_transfer_rate[ Layer_Count ]; // 0 = fully insulated, 1 = fully balanced double water_evaporation_rate; // Amount of water to evaporate in height units double water_viscosity; // &lt; 1 = thick, 1 = regular, &gt; 1 = sloshy double water_rock_dissolve_rate; // 0 = no dissolve, 1 = full capacity dissolve double water_soil_dissolve_rate; // 0 = no dissolve, 1 = full capacity dissolve double water_soil_capacity; // 1 = 1:1 water/soil ratio at saturation double air_viscosity; // &lt; 1 = thick, 1 = regular, &gt; 1 = swooshy double air_water_capacity; // 1 = 1:1 air/water ratio at saturation heightmap_settings_t() { memset(this, 0, sizeof(heightmap_settings_t)); } // --------------------------------------------------------------- // Serialization template&lt;class Archive&gt; void serialize(Archive &amp; ar, const unsigned int version) { ar &amp; width_in_blocks; ar &amp; height_in_blocks; ar &amp; reflectivity; ar &amp; specific_heat; ar &amp; heat_transfer_rate; ar &amp; water_evaporation_rate; ar &amp; water_viscosity; ar &amp; water_rock_dissolve_rate; ar &amp; water_soil_dissolve_rate; ar &amp; water_soil_capacity; ar &amp; air_viscosity; ar &amp; air_water_capacity; } }; The trouble is coming from the three arrays. The single-var settings serialize/unserialize with no problems. Layer_Count is a constant defined in an enum.
Why not subscribe to the boost user's mailing list, and ask your question there?
I thought I would look here first before subscribing to yet another list.
That looks like someone regurgitated a text book onto a blog.
Please link directly to actual content.
Damn. Ugly code and it *still* doesn't answer my serialization question.
No comments yet? I'm a newbie Vim user, and was hoping to learn about good Vim plugins for C and C++ (no, not for C/C++... :) in this thread. Is this a commonly used plugin? Are there better ones available? Any piece of wisdom would be appreciated... Thanks in advance. 
Well, I don't think I've seen this plugin in use that often. CppOmniComplete and your regular small extensions is usually enough. To be honest, how often do you actually write new code? =) Most of my time is spent editing code, where shortcuts to creating new functions is not that useful. You also has to setup the style of things to match each project you work on. I usually use :make to build stuff.
[changelog](http://gcc.gnu.org/gcc-4.3/changes.html)
Umm...this was released Jan27 I believe. And this is news now ???
Good link. I wrote C++ for ten years, and this reminds me why I would never go back to it. Yuck!
What about this? `!str.find("PREFIX")`
I think that works too :)
:D I know it works. Just a bit weird! It looks like "If couldn't find `PREFIX` in `str`". :|
I've recently tried [codelite](http://www.codelite.org/) which seems to be heading in the right direction. My biggest problem is always integrating an external build system. KDevelop is the most disappointing there because it's close, but not quite there. Perhaps I should blame myself though, because I have an idea about what is needed but haven't contributed.
that article barely has any content, just a link to [boost::serialization](http://www.boost.org/doc/libs/1_38_0/libs/serialization/doc/index.html) and a zip file. Look my post has 50% usefulness of your post.
I wish they'd do a POSIX (and specifically Linux) version of the library.
This vapid blog post is written by someone who hates c++ from the start and admits only dabbles in it between Java, D and god knows what other fad. He does a great service to any future readers by declaring "templates are horrible" and discounting any of his future opinions from consideration. But this is the internet and noise is to be expected. One piece of unwarranted useless advice: first step to achieve faster c++ compilation is good software engineering practices, see [Large Scale C++ Design](http://www.amazon.com/Large-Scale-Software-Addison-Wesley-Professional-Computing/dp/0201633620) for example. Try DLLs, try more abstractions, and only then go for hardware solutions. 
via: http://www.ddj.com/cpp/213401579?cid=RSSfeed_DDJ_Cpp Dr. Dobb's | Concurrency in C++ | Februar 9, 2009
Heres a sick trick I found recently. Take ALL your .cpp files in your huge project... Create ONE .cpp file that includes ALL of them. like: Mega.cpp: #include "source1.cpp" #include "source2.cpp" #include "source3.cpp" Resolve any conflicts... (This is actually a good excercise in itself because you will be left with a cleaner and more modular codebase) and then make a build configuration that only builds Mega.cpp. My compile times on a medium sized project in MSVC (about 50 .cpp files around 5-20k each) went down 10x. The tradeoff is that any source change requires a full (fast) rebuild. The architecture can confuse some debuggers. On the plus side I also think it helps the compiler produce better code since more code gets packed into each compilation unit, allowing better reuse.. and stuff (but I'm just making that up.). I now use this technique exclusively now for my release builds, and its a pleasure to be able to just whip out a release build at will and fast. Give it a try and let me know your results! (p.s.-I've only tested this with msvc on win32 so ymmv visavis gcc, et al, kthx!)
Sorry, have to ask: How would better design speed up the compilation of a hello world? For some things, throwing hardware at a problem is the cheapest way to solve it. Teaching your team good practices that speed up builds may cost more time and money than just getting them a fast dedicated build server. Your argument stands for 99% of other design issues, though.
I will second that I implemented a script to generate an 'uber build' here at work and one particularly nasty build went from 20min to 5min on my machine. Of course incremental builds still beat the snot out of it, but for those full builds it is a great method. But we ended up not adopting it for our build server. Why not? Because this prevents distributed build tools like distributed make or Incredibuild from doing their magic, and in our case it introduced a new way to break the build (source file symbol collision) at a very marginal speed increase over a distributed full rebuild. Also the rebuild /still/ supports incremental builds, so we rarely hit the full clean/rebuild cycle. All in all this is a great technique for personal use, but there are other ways to that scale better for really monstrous codebases. (disclaimer: Our codebase is a bit messy and mustDeref's comment about proper engineering practices is spot on. If we took a week or two to sort out our physical dependencies I imagine we could reduce our builds significantly. But this is one of those "wouldn't it be nice" things that gets trampled by a tight schedule and the need for all programming time to go into features, features, features)
This blog post is load of crap: &gt; Disc access is slow, that's why. And since #include is nothing more than copy+paste, the compiles has to read from disc, preprocess and parse a lot. (Precompiled headers is a good first step to solve solves this problem). Hate to break the news to the author, but precompiled headers help with *interpretation* of the headers, not their loading. &gt; So, we conclude that compiling is mostly I/O bound. Actually, it's CPU-bound, as anybody who actually *uses* any C++ compiler knows. The I/O component is insignificant... &gt; Aha, of course! RAM-drives! ...and pretty well handled by any decent OS' by caching the data in I/O buffers.
I just, *just* spent a day waiting for Boost 1.37 to finish building. *sigh*
I'm disappointed by the new ScopeExit library. IMHO they should have either leveraged boost::bind, or waited for lambdas. Using preprocessor trickery is no good.
These dudes release far far too often and with far far too many libraries
Huh. It's funny you say that. I always wish they'd release more often and I keep thinking of more libraries I'd like to see them distributing. ;-)
This post isn't about C++. Operator++ may or may not be thread safe in C++, because you know...you can overload it. Secondly ++ on an int could be 'thread safe' depending on your architecture, the alignment of the int, etc etc
But where is thread?
The properties stuff is pretty cool, though it seems like a lot of work when you could use a macro to help write simple get/set methods. Sure there are probably other advantages that you wouldn't get using macros (I didn't study the article), but I bet you could get pretty close. In the first comment on the article page, some guy shows a simple example using the "property" keyword to do basically the same thing. Is that some MS specific extension or is that actually managed C++ rather than native?
If you mean the header file, it's part of the C++0x standard library.
std::thread, awesome.
 __declspec(property (get = getName )) std::wstring name; It's a Microsoft extension. Don't know whether it applies to Microsoft's native runtime. You wouldn't be able to compile this code with the GNU compiler.
Are you taking about the KDE plasmoids? I think you can Javascript to write them too.
Cool, thanks. Cross platform compatibility is important to me so such extensions aren't my cup of tea, but they are interesting.
Likewise. I prefer my code to be portable.
Rather than ask the compiler to guess what type of calculation you're performing and hope it is able to optimize it for you, programmers should just stop being lazy and do it properly: align your variables/structures to 16-byte boundaries, parallelize your algorithm (fine-tune it) by hand, and then use compiler intrinsics (supported by MS, Intel and GNU compilers). Better yet, use something like SSEPlus so that your app chooses the most appropriate instruction set to use for the CPU its running on. That way you can be sure you're getting the best performance for speed-sensitive calculations.
For core algorithms, I completely agree that is the best way to approach it. However, auto-vectorization is still a nice feature. The compiler technology to produce it (the SSA tree) is also very important for many other compiler optimizations. 
&gt;align your variables/structures to 16-byte boundaries Would you happen to have a link explaining how to do that?
It's usually a flag specified while declaring a variable. For GCC it's something like: struct mydata { float a[4]; } __attribute__((aligned(16))); Will align the beginning of `mydata` (containing 4 floats) to a 16-byte boundary. These 4 floating point values can then be used directly as 4 packed single-precision floating point numbers, in any SSE2/3 operation which references memory. Other compilers might have similar syntax, just google for "compilername variable memory alignment" or such terms.. edit: almost forgot, if you use compiler intrinsics (emmintrin.h, xmmintrin.h etc.) for sse operations, you can use conveniently defined data types `__m128` and similar instead of having to align manually. These should be compiler-agnostic also. [Here is an MSDN page](http://msdn.microsoft.com/en-us/library/01fth20w(VS.80\).aspx) with more info.
Thanks a lot! I think I just got what alignment is all about.
[Windows Data Alignment on IPF, x86, and x64](http://msdn.microsoft.com/en-us/library/aa290049.aspx)
external memory computation, generic c++, out of the core
Huh? Boost is mostly a collection of header files to be used directly, only a few parts of it need building. What kind of machine did you use that it took a day?
Any non - msdn page with a listing and short description of the available SSE calls using ?mmintrin.h ?
Check out Dyninst API: http://www.cs.wisc.edu/paradyn/ I've never used it but a prof at my school works on it and it lets you dynamically modify binaries.
It's an old dual-processor 1-GHz G4 PowerMac, and doing a full Boost build takes staggering amount of time, so the timing of this new release is kinda funny. (This all started when I dived into serialization and figured I might as well get a full build of the all the compiled libraries over and done with.) By this summer I should have enough saved up for a new 8-core Mac.
It's irritating, but GCC doesn't break the point release info out from that of the whole branch, ie, that changelog is for where 4.3 is now at, not what changed between 4.3.2 and 4.3.3. 
I'm a big fan of vim and eclipse CDT but I have recently discovered netbeans 6.5 for c++ + jvi plugin. http://www.netbeans.org/downloads/ http://jvi.sourceforge.net/ If you like vim + eclipse/cdt you should give netbeans + jvi a try. 
I tried Eclipse CDT; it sucked hard; and I happily went back to vi, Makefiles, and the shell. My coworker does the same thing except that he uses emacs. We're both damn productive and our respective editors support add-ins to do many of the nice things you get from and IDE.
huh? I was hoping this would be about an alternative implementation of "streams". This submittal is lame.
Or, in GCC you could compile unit tests with -fno-access-control.
It's really bad that C++0x does not contain the restrict keyword! Does anybody now why? But to achieve "Fortran" performance or even better: http://www.oonumerics.org/blitz/ 
How does it compare with [eigen](http://eigen.tuxfamily.org/index.php?title=Main_Page)?
If you have the money, I'd go for both fastest hardware and good design. But code bases can easily get slower at a faster rate than hardware improves its compilation times. Unless I'm mistaken as to what amounts to useful work, nobody is trying to speed up the compilation of hello world. Speeding up compilation is only an issue when compilation takes long enough to be a productivity loss. Its very true that it costs more money up front to employ disciplined engineering practices. The mistaken trade off favoring low initial cost vs. long term benefit has bit many large software projects. Few examples I can think of are the Windows Vista re-start, and several large commercial game engines I had to work with. 
Well, you could compress those three for loops into one, the main body of Compute() looks very compressable and you could always bitshift, remove unnecessary operations, SDIM the shit out of it and finally convert it to assembly for RAW POWER. I like C++. 
I've tested blitz, and it cannot do better than Fortran. Ten years ago, it did, but now, it can't (it behaves exactly like the simple C++ code I've given). The restrict keyword is used in Blitz, but the compilers I've tested (ICC, GCC and PGI mainly) cannot use this, as the restrict keyword is declared in the structure (like in Test, for instance).
It could be in this simple test. The actual test I have is far more complicated than what I've given. Here, the spatial order is fixed, but in real life, you have to use second order near the border, and you have also to add border conditions that will make the stencil far more complex.
I'd counter-argue that employee training is a zero-sum game. In other words, there's only so much you can fit in their heads. You can spend that head-space on compilation techniques and design techniques who's sole purpose is to speed up compilation, or you can fill it with other design techniques that reduce bug counts, complexity, etc. Ultimately, though, I'm sure any corporation is going to fill that head-space to capacity with TPS reports, so this is all a moot point.
Only way to "beat" fortran is probably using SIMD, which I guess you can from fortran too which brings it back to square 1 =)
In fact, vectorization stems from Fortran processors. But to make the compiler vectorize the loop, you have to tell it it can, so back to square one: how to tell him the arrays do not alias ?
Does telling the compiler that P (in compute) is const (in fact const float * const) help any? I would also be curious if there are any alignment pragmas/command flags you can use. While it is sad the __restrict keyword didn't make it into the spec, it's also in MSVC, for what it's worth, so I think its not unreasonable to use it. As to your algorithm, did you think about caching the sums of the four positive and four negative terms that vary in i, and only updating them? Or does weighting or some other complexity rule that out? I know that has nothing to do with comparing the languages, but would still be interesting. PS, I would also be curious if changing N to a `#define` would change anything. PPS I would also think 'whole program optimization' (can't remember flag) should discover that aliasing can't occur here....
This behavior is illegal. The C++ standard prohibits using #define for a name that is the same as that of a reserved word.
No, it doesn't help. There is the #pragma ivdep that can also be useful, but it's not something one can rely on. I can't add the complexity of caching the four positive and negative terms. In fact, it is a weighted sum, not a simple sum. PS: Changing the constant to a define will not change the global time difference PPS: ipo is not something that can be relied on either, as there are some bugs that still occur in this part of the compiler. And the compiler will not find out that the two array do not alias, as it is in this case only one file ;)
What Fortran compiler did you use? I'd like to compare its performance to Microsoft's C++ compiler.
I don't have much interest into belaboring this discussion, but its perplexing and telling that you assume speeding up compilation is somehow mutually exclusive to reducing bug counts and complexity. I'm perfectly fine with c++ getting a bad wrap by those that don't know how to use it, and large companies slowly leaking productivity with bloated unmanageable code bases.
Web Graph generation Eigen template library for linear algebra computation
#define is perfectly legal for the c pre processor which uses its own language as a pre compiler. The c++ compiler itself never has a clue. Perhaps you meant that this is an illegal pre processor directive??
Cross platform is best. Does icc, msvc, bcc have the same sort of options?
I doubt it; I just figured I'd share the gcc-specific tip.
It's such a shame that usenet has been dropped by eg Comcast and maybe some other large ISPs. On the other hand, comp.lang.c++.moderated wasn't what it was in the good old days when the giants battled the meaning of everything out amongst themselves as this author recalls. 
I'm not claiming its mutually exclusive, but I would claim that it's not too terribly correlated either. Linking to libraries, for example, is usually faster than recompiling code but with templates its far easier to simply recompile and put everything in .h's You can have it both ways, but if resources were limited and I could only ask developers to use one thing, either linking to libraries to speed up compilation or using generic code via templates, I'd advocate generic code.
so now we can directly inject c++ code. great
Except for the fact that it embeds the database methods directly into your classes and doesn't separate the persistence from the model better, this seems really cool. It's like Core Data for C++ almost.
It is illegal to do the following: \#define **name** Where **name** is a reserved word, ie. a keyword. Since public, private, protected are all reserved words, doing any of the following are illegal in C++. \#define public \#define private \#define protected
really cool, perhaps i'll give it a shot
Can I convert my inline php code directly to C++ for speed up??????????
Interesting timing for me. We've been profiling our app lately, and found in some cases that almost 10% of execution time is spent in malloc/free (on Linux). I'm going to have to give this a shot. :)
A couple of years ago I'd used nedmalloc for some work. Our software runs multi threaded on 8+ core machines, typically 8GB ram required. I believe when glibc updated to 2.4 I stopped seeing huge performance gains with the allocator. About hoard: On our workload the behaviour was strange. Yes it ran fast but the application would constantly "stall". In the end the hoard version ran the same if not slightly slower than glibc's 2.3 allocator. I contacted the hoard guy(s?) about this. Received one reply and no more followup, nothing else. I'm certainly interested in running more tests again. More performance is great, we always find ways to slow down our software.
The font looks fine to me (Chrome). Maybe your OS is missing the font and the browser has to substitute?
I'm trying to test the memory allocators. Unfortunately they don't have instructions for how to build for use with LD_PRELOAD for efficient testing. I tried to configure nedmalloc as shared, threaded library but it just core dumps. TLSF likely would need to be patched to run this way. I was able to get some malloc ported from bsd to work with LD_PRELOAD (just to prove I'm able to get *something* to work).
Web search ranking and GPU Nvidia CUDA many core computation
Comment by "Noway2" "Project Engineer" in article FTW
Nice tip using the try-catch block in main() to prevent hard failures of the entire program. I never thought of that with Java, so now I'll remember it with C++.
They even have a compiler that works with crappy screenshots of the source code, it's great!
CMP has always had trouble understanding the WWW. It's quite frustrating.
Unfortunately the article seems to biased (and too marketing oriented) to be that useful. It details the numerous features that OpenMP has, and then spins this as it being too complicated. While it can be complicated, it can also be stunningly simple (e.g. for a 'for' loop). It has a paragraph about performance that doesn't say anything other than that Cilk is better for unbalanced problems, but that they haven't benchmarked it against the more-than-year-old OpenMP 3.0 Sadly, this is marketing, not information.
Yeah, we wrestled with this post a bit. Tried to make the case that for simple balanced loop, OpenMP is a solid choice (very easy, good performance, free, supported in major compilers), yet point out some meaningful differences across what (I think) are relevant dimensions. We would like to benchmark Cilk++ and OpenMP 3.0 on an unbalanced problem. But if we write the OpenMP code, we can't very well claim that it is representative of best OpenMP practices since we aren't OpenMP experts. Does anyone know of an example of an unbalanced problem that’s been implemented in OpenMP, so that we can build a Cilk++ version for comparison? thanks in advance.
None springs to mind, unfortunately. However, I can think of two places worth checking out. First, the [language shootout](http://shootout.alioth.debian.org/) is now running on a quad-core system, and I think some of the sample programs are using OpenMP. The guy in charge (Isaac Guoy? igouy) shows up pretty frequently on programming reddit. Also, I know that some solutions to the programming challenge the Intel put on for Threading Building Blocks (might be a bit of a pain to find, as it ended last fall I believe) also used OpenMP, rather than TBB. Obviously, your problem is a common one for benchmarks -- I think the best way to resolve is to try and do a solid job, and allow public feedback for improvements. I'm not tied to OpenMP, and I will agree, as you diverge from simple vector operations, it gets much more complicated, and less useful. Still, it's fairly good for a lot of things, and now that it's in GCC, ICC, and MSVC, it's very widely available. Intel's TBB was also fairly useful, and is more task-based. I would be interested in learning more about Cilk, and hoped that the article might detail a bit more about the advantages and design differences. Admittedly, this is partly laziness on my side -- I could have browsed further on the site. However, the article was sold as a comparison, presumably a fair one, and that I found lacking. (BTW, if Cilk does an analysis of potential race conditions/loop dependencies, that's a pretty big plus.)
They need to hurry up to get the C++0X out, before it is 1X.
Hmm....can do this already by passing a pointer to an object to a static function. I don't recall if that pointer cast to a base class will obey the inheritance hierarchy but it should.
I'm getting the informations!
&gt; ACCLib is based on the 0858275 french patent since the 4th December 2008. It will become public knowledge the 4th june 2010 and until then I won't explain the inside mechanism of the library without a NDA. I need that competitive advantage, I'm sure you can understand my point of view. Haha. Lots of pretty graphs tho.
&gt;I never loved it. Since you have to specify the number of clusters a-priori. But it's useful, e.g. in computer graphics where you would like to partition your space into a known number of partitions to reduce the search time. For completely 'blind' clustering it's perhaps better to use perceptrons or other forms of neural nets.
much better to start with a preliminary step. If you have N points, you select sqrt(N) of them and compute the matrix of all distances among them in O(sqrt(N)^2) = O(N). If two points are closer than a threshold T, you discard one of them. The remaining set is S, such that |S| = k and 0 &lt; k &lt; sqrt(N). It's a simple heuristic but it works quite well in certain domains.
looks nice. is it a generic ide ?
I've hit that so many times I started using simple freelists for scenarios where I have the same-sized chunks of data constantly being allocated and freed.
Oh Joy!
Cool. But non-standard things can get annoying.
Nice, liking the fact it only uses standard libs.
Agreed, but the lack of floating point support at present makes this pretty much useless as-is.
Could anyone recommend another JSON parser that does support floating point?
I have used [JsonCpp](http://jsoncpp.sourceforge.net/). Works fine, no external dependencies, and you can't beat the license.
Thank you.
I'll stick to Boost.Spirit, thx.
Kick ass. Now I script in C++ while I write C++... hey, it's a yo dawg!
There's also [cint](http://root.cern.ch/drupal/content/cint) which has been around for some years already.
Thanks, I'll try out cint too
Modded down because valgrind is already a well known tool, wasn't mentioned in the subject line, and isn't a C++ specific tool.
you seem not to understand what this is for.
I used to use this a lot but the more our code base leveraged 64bit and multi threading the better valgrind started to work (and duma stopped working entirely). I haven't used duma in over a year now. This article reminds me that I should probably try yet again. Pretty cool this advertises running on windows. I never even tried in the past.
I've never understood the style of programming that goes: "instead of keeping a couple of variables in a loop all in one function, I can write 4 classes, each with constructors, operators, and somewhere in there a method that actually does something so that if anyone wants to understand what is going on they have to parse through 8 or more files instead of the one nice neat function!" Not a language problem anyway that I see it.
It's the same mentality that finds it hard to parse code that is doing several orthogonal things at once. Really, it is quite understandable, but of course it trades off between "easier to understand what is going on conceptually" and "easier to understand what the computer is doing at each step". That said, I don't see how your comment has anything to do with this article. There isn't a real separation of concerns going on (if anything it is the opposite).
This example is kind of lost on me since it's clear how to do this with normal c++ using: struct MinMaxMean { int min, max, sum, num; void operator() (int const &amp; val) const { // simple logic here.... } }; MinMaxMean const minMaxMean (std::for_each(nums.begin(), nums.end(), MinMaxMean()); Or to put it better...the author shouldn't have set up a straw man by starting with a stupid implementation. Compare a best c++98 solution to a best c++0x solution, it just makes more sense.
I'm not sure how this is better than currying other than to make it look more like a 'c' style array. I guess the automatic sizing is nice, the currying i've used takes the size of the curry "vector" as a template argument to "reserve" the vector being curried into.
I was expecting the C++0X code to use a for_each call with a closure.
Thanks! Adaboost is awesome!
If you are looking for reasons not to like C++ the #1 reason on my list is the retarded ABI which prevents proper compatibility with most other programming languages, in particular the non-standard name-mangling.
Here's my story: my strongest disappoinment of c++ came with Boost.Lambda. More I looked its documentation,more I was horrified: examples like it's easy to find for_each(a.begin(), a.end(), std::cout &lt;&lt; _1 &lt;&lt; ' '); in the beginning of documentation , but if you want to call member function(this is much more common operation than cout&lt;&lt;ing data) - you'll end up with something unreadable like (_1 -&gt;* &amp;B::foo)(b). c++ standard was harsh too: I always blamed hard-to-parse grammar of c++ for the absence of normal tools for c++. XRefactory and VisualAssistX afaik use edg and visc. Also I was disappointed that committee can not agree on naming convension in sense should names be shorted or no: compare setw name with static_cast keyword with decltype keyword. That's basically main reasons why my interest in c++ faded away. 
It's 2009 break backward compatibility with C already! Seriously D is a good language but C++ has the tools and support. Can we have D with C++'s tools?
What?
What's wrong with: \#ifdef __cplusplus extern "C" { \#endif IObject *CreateInstance(); \#ifdef __cplusplus } \#endif ? :) 
The fact that every other languages sees C++ stuff through a C-tainted filter, allowing no direct use of C++ features that language shares but C does not?
For me it's mainly that the complexity of the language is out of control. I think they were bolting on marginal features (are lambda really necessary when we have functors?) when the focus should have been on the standard library...for example making everything more unicode friendly and better thread primitives. I think D is the future (it's going to take a good while, but it'll get there).
You're only restricted to C language features in the exposed API. Although the exposed API is C, the above example returns a c++ object which itself can use whatever c++ language features you want. Just curious, but do you have an example where you would use a c++ language feature in the exposed API? 
I think my biggest gripe is template error messages. Templates where just not designed in a way that could allow compilers to give easy to understand error description. I'm not talking about the confusing wording VS's likes to use (where you have to substitute the types yourself). Stuff like that can be fixed with [STLFilt](http://www.bdsoft.com/tools/stlfilt.html). I'm talking about error messages that only point to some deep system header file (after you've changed several hundred lines of code all over a project and have no idea where the error is located). Having to write function objects to use parts of the STL needlessly complicates your code and the tools the STL provides to use the more functional style it promotes are often inadequate (bind1st) for pleasant coding. I love boost bind but anything more than a simple call can get confusing fast (nesting a couple levels deep for instance). Not including hashed containers in the standard was a big oversight. That all said, C++0x will fix all of those (Concepts, lambda expressions, unordered_*) so that's pretty exciting. I'm sad to hear that concepts won't make it into the next version of the compiler I have to work with the most (Visual C++). C++0x also fixes little nitpicks I've had with the languages for a long time (a lot of which were inherited from C). The only thing I think was missing from the update was a better, more uniform approach to unicode. ICU's API turned me off immediately and boost has yet to adopt something (though there are discussions every couple of years about tackling it).
After years of systems and applications programming with C++, I switched to Delphi in the 90s. Since then, there has never been a single moment where I've had to stop and think to myself "damn it, this would have been easier in C++" As far as I can tell, each new release of C++ is designed to fix what they broke in the previous release. It's just duct tape on top of more duct tape.
When I want to use pretty much any C++ library from any other language without the library writers planning ahead or writing a huge wrapper. Most commonly GUI frameworks like Qt or 3D engines like Ogre3D and other projects of similar size that are missing in other languages.
Couldn't agree more.
can't believe someone downvoted you. Very informed opinion. C++ suffers a lot from it's total impossibility to parse. The actually syntax of the language itself is sort of drunken and mad. (like the million different things static can mean, and how you can put a identifier before or after the brackets of a struct to either define a type or declare an instance, or how hard it can be to tell a function declaration from a call to a classes default initializer.)
Other than C, what other *popular*, *static* languages enforce a standard ABI which allow easy cross language bindings? C++ has the extern "arbitrary-string" form, which theoretically allows you to expose functions with any kind of linkage you like. It is just a matter of support at the compiler level, GCC already supports 'extern "Java"'
About 'D' ... doesn't it violate the "language out of control" issue? D already has more reserved keywords than almost any other language out there....and it seems that they're just bolting lots of unnecessary stuff on themselves. Yes I do agree with you about the standard libraries. Better thread primites are dealt with in c++0x. I'm not exactly sure what state unicode is in. I'd personally like to see iostreams refactored and std::string redone assuming utf8 (and including removing 75% of std::string's methods to be replaced by use of more generic algorithms)
It may mean that there's room for another language that's more like c++ but easier to write compilers for (easier to parse, faster compilation, etc). And one that's simpler, more elegant and orthogonal. What really bothers me about 'D' is that it has more reserved keywords (a metric for cruft) than c++ or java and the language isn't even mainstream yet!
I just don't see a place for it. For embedded or performance code, C makes a lot of sense, because it is easy to become familiar with the code produced by a compiler on a particular platform. This is not true of C++. If you want expressiveness, conciseness or execution safety, there are any number of languages better than C++.
I would like to ask the c++ subreddit the following: If you became disappointed with c++ and are currently still disappointed, what is your reasoning for feeling so?
Functors require more work to save all of the state variables that are in scope where it's created. You have to do twice as much work as you would with the proposed lambda syntax, because you're both passing them in and creating members for each and every one that you'll need. And it's weird that you'd complain about bolting on marginal features instead of focusing on tackling complexity, but don't bother to mention stuff like auto (which will reduce the amount of time spent deciding/remembering the correct type for variables), the new range style iteration for for-loops (which will reduce the amount of boilerplate loop code you have to write), rvalue references (which will prevent you from having to jump through hoops to avoid making unnecessary copies of expensive containers), struct-style initialization for arbitrary objects (which means you can declare a container, for example, in one line instead of 400 lines of .push_back, .push_back, .push_back..; it also means you finally can initialize a constant container, which is pretty cool), variadic template arguments (which means you can write mixins that take a base class list and support single or multiple inheritance for free instead of having to write multiple versions of the mixin for n number of base classes). The list goes on. I don't think you've even actually bothered to read the C++0x plans. Yeah it's still an ugly language, but what do you want from something so low-level?
&gt; Just curious, but do you have an example where you would use a c++ language feature in the exposed API? * Exceptions * Basic templates * Construction/destruction semantics (particularly where any sort of resources are concerned) Without these, you have to mess around with returning error codes for any operation that can fail, you wind up with `void*`-type parameters on generic algorithms, and you have to marshall things and jump through all sorts of hoops if you're talking to any sort of managed environment, just to keep the memory access straight.
If a library is in C++ then use C++. That's the point of C++. 
The point of C++ is to build it's own small walled garden that refuses to be compatible with anyone else for no practical reason at all? Just because of a few small oversights when writing the C++ standards a few decades ago? 
Most or all STL containers have member functions for particular algorithms in the cases where the container can provide faster implementations than the generic versions in &lt;algorithm&gt;. Just like list, map, set, and so on, basic_string is a container.
That might be okay if they at least aren't so overloaded, like static. But I wouldn't be astonished that D is no panacea. 
&gt; If you want expressiveness, conciseness or execution safety, there are any number of languages better than C++. Your list conveniently omits "performance". C++ is popular because it provides a more expressive and safer environment than C, while maintaining most of the performance characteristics. There are very few languages that can make this sort of claim, and even fewer that do it with a familiar syntax and programming model and good tool support.
The backward compatibility with C is what kills it for me. I love C, it's great for what it's great at, but when you want to go outside of that, just ditch it and start with something new. Don't hang onto a tool that was made for solving different types of problems and try to adapt it to fit different problems. Just make a new tool for solving these problems.
Well c++ was a (but not the) leader in OO concepts. They couldn't get everything right. It really was a testbed language that ended going mainstream, warts and all. I'd say it was wildly successful and for the most part not bad.
That's not true - I mention performance along with C. My argument is - if you need performance or you are programming close to the silicon, you are better off with C; if performance is not an issue, other factors will dominate and you are better off with a more modern language than C++. So I see no place for C++, except legacy support. I use both C and C++ a lot and I've used them both pretty much since their inception. I've seen bad code written by bad programmers in both languages, but I've only seen bad code written by good programmers in C++. 
C is not C++, and I don't find your argument to be at all compelling. *Why* am I better of with C if I need performance? Because you say so? What C++ gives me is the ability to write efficient code without having to write my own `struct node { void* data; node* next; }` every time I want to store more than one thing. It's safer than C in terms of its type system, supports ways of organizing your programs that C does not, and is just generally a different language than C with its own strengths and weaknesses. And, yes, it has weaknesses. So does every other language in existence. It's up to each individual person to decide how they feel about the tradeoffs that must be made when choosing any language. I'll repeat, C++ is not C. They force different tradeoffs on the programmer and provide different benefits. 
&gt; Because you say so? Yes, though I don't think it's a particularly controversial opinion. I'm very convinced of it, after examining reams of asm output over the years. For embedded systems or hardware drivers I think C is usually a better choice than C++. As an application development language, C++ provides many features that make it a better choice than C in most cases. My argument is that there are better application development languages than C++. So I think we'll continue to see C used for performance &amp; low level code, whilst C++ will gradually be replaced in the application development domain. 
Personally, I like to use C++ as "a better C". I do use classes, and templates, etc., enjoy the benefits of improved type safety and template-metaprogramming performance, but generally avoid the Object-Oriented aspects (i.e. avoid C++ polymorphism, I regard the C++ virtual function model as badly broken). I really can't see any reason to stick to C for that sort of work.
That sort of usage may make sense if you disable RTTI and exceptions, then make sure that you don't inadvertently use some template that drags in half of stdlib. I agree with you about template meta-programming - concise code that is type-safe and efficient. 
I think you're conflating two different things: low level hardware access and efficiency in "applications". For hardware and embedded systems, C is definitely a better choice. However, there are many applications that aren't constrained by the physical requirements of embedded systems, but are still extremely computational intensive. You seem to be saying that either you need the extra 0.5% of speed that C gives you over C++ and you're willing to pay whatever price to get it (performance matters) or else you don't even need the 200% performance that C++ gives you over everything else (performance doesn't matter). I reject that as a false dichotomy. Life isn't that black and white. I've made a conscious decision in my own work -- I can get almost as fast in C++ as I can in C, and the coding is much more pleasant. I could get even more pleasant code by switching to something like Lisp or Python, but my code would run 300% slower, and I'm not willing to make that tradeoff. To be fair, you did say "most cases", although the rest of your argument seems to discount that those other cases exist. I happen to work in one of those areas in which a month of computation time instead of a week is unacceptable, and I get a little tired of reading the usual anti-C++ rants, so forgive me if I seem a little picky.
I'm not conflating them. I clearly state that performance and hardware programming are areas where I think C offers advantages over C++. I'm not religious about this and I'm not anti C++; I use it as much as I use C. If C++ works for your application, great. But if performance is important to you, try it in C. I'd be surprised if you can't easily achieve 50% improvement and maybe quite a bit more. I also work in areas where performance is absolutely crucial. Most of my work involves making code run faster. I always get significant performance improvements moving C++ code to C. Granted, I could probably get similar (though still lesser) improvements in C++ by limiting myself to the C subset of the language, but that would largely defeat the purpose.
I'm relying on some C++-isms that don't have a C analogue for performance (template tomfoolery mostly), and my code has been profiled within an inch of its life, but there are no doubt some areas in which C would give me faster code. Of course, Fortran would kick both their asses. The reason I'm not using Fortran is the same reason I'm not using C -- even though the code would be faster, C++ hits a compromise between making my code fast and making my life easier that I prefer over the alternatives. I read your original comments as saying that there was never any reason why a rational person would choose C++, and I felt the need to disagree. I don't have any problem with your arguments now that I'm clearer on what they are.
Cool! I love using templates to write special case optimisations, amongst other things. What area are you working in? I'm mainly doing cryptography primitives &amp; processor emulation at the moment. 
People will go to massive lengths to avoid learning how to use unix properly. Just log into the remote box and use vim/emacs for fuck sake instead of wasting your time with crutches like netbeans.
Simulation and optimization.
I'm pretty familiar with 0x standard...yes there are nice things (especially auto). I don't buy though that lamdas are better than functors to the point of justifying all the new syntax.
I dont think reserved keywords are a very good metric. What I _do_ think is a good metric is that D has a context free grammar...this means fast compiles and easy parsing. D 2.0 which walter is working on has a much more 'templatey' standard library and better support for functional type programming...the point being it might be a (possibly unwelcome?) step up in complexity. D 1.0 is as simple as pascal or java. 
There's a bad error in this code. What threw me for a loop was that the constructor calls "reserve" on both the vectors. That only pre allocates space for "push_back". Indexing into these vectors that have only been "reserved" is an invalid operation. More correct would be to construct the vectors with the proper number of entries.
I wouldn't necessarily have coded it that way, but it's not a mistake. This data structure only needs the memory allocated, not initialized, when it's constructed.
I suspect a "fail" might happen when copying one SparseSet to another. I'm not sure if copying a vector that's only had "reserved" called on it results in the copies being sized as intended or even initialized at all. This definitely is not the first time I've seen posted code here using reserve incorrectly.
Ah, good catch. The default copy constructor and assignment operator are likely to lead to segfaults here.
That's correct: "This data structure only needs the memory allocated, not initialized, when it's constructed". Accoding to the standard 23.2.6.2 vector capacity: "After reserve(), capacity() is greater or equal to the argument of reserve if reallocation happens; and equal to the previous value of capacity() otherwise. Reallocation happens at this point if and only if the current capacity is less than the argument of reserve(). If an exception is thrown, there are no effects....It is guaranteed that no reallocation takes place during insertions that happen after a call to reserve() until the time when an insertion would make the size of the vector greater than the value of capacity()." My understanding is that the memory is allocated and the capacity() is changed. When the copy is invoked the right capacity() should be allocated. Please let me know if this is wrong, and you have other suggestions.
Yes, when you call a.reserve() the memory is allocated (if necessary) and a.capacity() is updated. But when you then do b = a, the standard does not require that b.capacity() == a.capacity(), only that b.size() == a.size() and the size() elements are copied. Most likely you actually get b.capacity() == b.size() if an allocation is done, but that's an implementation detail. Even if capacity() were maintained, copy and assignment would behave incorrectly for non-empty sparse sets because none of the data in the allocated memory would be copied, since size() is always 0. The quick fix is to just construct the vectors with size max_element as bnolsen suggested, in which case the compiler defaults will work correctly. But then copying a large, very sparse set will be expensive since you're copying a lot of junk data. The alternative is to write your own copy constructor and operator=, copying only the meaningful data. Usually when I'm writing a new class with any sort of tricky memory behavior I'll just inherit from boost::noncopyable to keep myself from getting into trouble, then sort out the details later when I actually need copying. Is this your blog? Aside from the C++ gotcha it's a nice little piece of code. Edit: I think what this shows is that using vector::reserve() is a back-handed way of managing the memory. Since you don't need resizing (the big selling point of vector), you might as well just malloc the arrays the old-fashioned way.
This data structure also appears in NIST DADS as [huge sparse array](http://www.itl.nist.gov/div897/sqg/dads/HTML/hugeSparseArray.html) and was posted to proggit a few months ago as [Ullman set](http://www.reddit.com/r/programming/comments/7qj88/a_favorite_data_structure_ullman_set/). (and then from the comments on that, [another interesting article about it a year ago](http://www.reddit.com/r/programming/comments/6c2ou/using_uninitialized_memory_for_fun_and_profit/) with pretty diagrams.) It's neat. 
I used this in my undergraduate thesis and even got a paper published on applying it to diffusion tensor image vectors. It worked like a charm. 
Added the copy constructor and assignment operator, which is always a good thing ;-)
Thats always funny. Instead of deriving just make the copy constructor/assignment operator private. Its two lines of code (statements) instead of one (include + derived class). Part of why the boost philosophy really bothers me. And yes, valgrind doesn't like the uninitialized memory use. But that's just valgrind. I wonder if there's some explicit way to tell valgrind to overlook this use.
"capacity()" is only a hint to help us to make more efficient code. "size()" is what is important for the validity of the program.
Man I like this dudes style. Short and sweet explanations/references of the algorithms and then an implementation in gods own C++. Respek! And thanks for posting! 
Sorry, stopped at first paragraph. &gt; implementation quality for it is sadly still generations ahead of other languages. Sadly? Huh?
If you want to use java then use java. If you want to use c++ use c++. One of the worst things you can do is try to cram one language into another. c++ definitely has advantages over java. Learn to understand it for what it is. Header files can provide a very concise way of seeing the api of a class by looking at code and not needing to use a separate tool to generate docs and view. Also lean header files cut down compilation time if done right.
I've recently tried out Mudflap and it seems to have very little documentation and geared mostly towards C rather than C++. A few options you can use tend to lower the number of false positives on C++, but it's still hundreds in a medium sized program - way more than it's worth. Has anyone else had any better luck with Valgrind(I've heard good things) or DUMA in checking for standard C++ memory errors? (Buffer overflows, leaked memory, null pointer usage, etc).
I like valgrind, but it will your programs down terribly if they do anything even remotely taxing. There is also purify.
Google's perftools comes with a memory profiler that has helped find problems. If you have a leak that doesn't show up in valgrind because the leaked memory is managed by a layer on top of the OS, then perftools can find it.
I've heard good things about purify but also that it's Linux port has been unmaintained and sucks since IBM took a hold of the company. Does it not slow things down as much as Valgrind?
Also, valgrind uses a 64-bit double representation even if the code uses 80-bit. Often the bug disappears when you run it with valgrind. This is true more with numerically intensive code of course.
&gt;C++ was meant to be efficient in the hands of good programmers, capable of expressing elegant solutions to hard systems programming problems This is for all of the C++ bashers.
Gotta disagree with you on noncopyable. Inheriting from noncopyable clearly and succinctly expresses the intent, and it's clear from just scanning the class declaration rather than looking for a couple lines of mildly obscure C++-isms buried in a private/protected section. It's also impossible to screw up, whereas you might accidentally leave the ampersand out of the copy constructor or something. IIRC Google has some sort of aversion to mixin-style inheritance, so they have some NONCOPYABLE(classname) macro instead. That's OK too, though I think it's clearer in documentation to see the inheritance from boost::noncopyable. What do you mean by the "boost philosophy" and why does it bother you?
I kind of expected somebody covered by a **beard**.
Pretty much valgrind for me. duma didn't do very well in a 64 bit optimized program last time I tried about a year ago.
Also: &gt;People are still stuck arguing language choice (e.g., C vs. functional vs. Java vs. domain specific vs. C++ vs. Python) rather than techniques and principles. I fear we have a lot of work still to do in this area - it is not easy to express and apply principles across languages. What people have to do is to articulate principles for their languages of choice and try to see languages - any language - as an incomplete approximation to the ideals.
That's good to know. We are tracing a bug now that we suspect is due to this memory/register precision difference.
I used a Rational's purify, quantify(profiler) - they are not bad at all. Valgrind also helped me to find a lot of problems. ( nature of my apps - is tht I do not care about memory leaks - only about corruptions. Duma almost crashed my computer (took me 10 minutes to ssh and skill) and was slower than valgrind at least in order of magnitude... 
Yes It is slow - and now - it does not sux, I would say it is as good as it was on HP_UX. However the quantify (profiler) is much better. I found very easy the performance bugs with it. Usually I do not think that checker/profiler runtime is a problem. Just create a reasonable and representatvie test case that run for an 15-min--hour - run it on evening. Next morning enjoy the results :) 
Eigen ( http://eigen.tuxfamily.org/index.php?title=Main_Page ) seems to be very cool. No fortran, great API, great performance. A little young maybe, though.
blas, lapack are pretty standard suitesparse is good for sparse systems My personal favorite is numpy, because I don't care so much about efficiency as I do an easy to use library with excellent documentation. 
blas &amp; lapack are nightmares to compile under windows. The fortran style indexing is also irritating. At work we cooked our own. Very simple, easy to test and maintain. Funny enough the core2 architecture itself almost totally eliminates any performance penalties for iterating a matrix in the "slow" direction.
&gt; blas &amp; lapack are nightmares to compile under windows I've never had this problem. The code they use is pretty standard. You gotta remember to not compile dlamch optimized. But yeah, agree about the fortran indexing.
numpy uses blas and lapack...
&gt;Funny enough the core2 architecture itself almost totally eliminates any performance penalties for iterating a matrix in the "slow" direction. What do you call the slow direction? How do you allocate your matrices?
You asked the wrong guy. I guess he means inner [outer] loop over rows [columns] in C and the opposite in fortran (is the slow direction).
I've used and/or every now and then... Sometimes it's Python syntax spilling into C++, but frankly, they *can* sometimes look much nicer than the alternative: Compare: if (&amp;x &amp;&amp; &amp;y &amp;&amp; &amp;z) { ... } if (&amp;x and &amp;y and &amp;z) { ... } 
True, but writing a solver in C++ using lapack, and using numpy are totally different things. Also, numpy may be wrappers to fortran and C libraries, but that doesn't mean it's as fast as C or fortran
I want "Composite Operators" ! :-)
"What was needed wasn't just the ability to overload explicit use of whitespace, but also implicit application. This is easily achieved by modifying the lexical analyzer to recognize xy as the two tokens x y." ... And when you have the variables "foo", "bar", "fo", and "obar" what does the lexer do for "foobar"? And it gets better: "Multi-character names are a relic of languages that relied heavily on global name and encouraged overly-large scopes." Bye bye descriptive variable names! I love his example: ☎-&gt;✆(); // take my phone (☎) off hook (✆) Edit: Tomorrow is April 1st. Grrr. 
You're a few hours early on this side of the pond.
Take a guess....you got a 50/50 chance...its a 2d data structure. Hint...typically acessing memory by reading adjacent bytes is fastest.
It was just midnight in Europe when I submit it :-) 
&gt; Tomorrow is April 1st. Grrr. Indeed. I was just about to submit how Warner Bros will acquire TPB to the WTF subreddit. I figured it's 1st of April just before clicking submit.
I agree with you completely, I was just pointing out a fact. I love numpy btw :)
Link to fuzzy clustering code disappeared. Anyone get it before it went? Ooof fixed link: http://www.di.unipi.it/%7Egulli/coding/FuzzyClustering.tgz
I fixed the link, sorry for it.
The author claimed that he didn't find a splay tree implementation, so he wrote one. But the first place to check should be: http://www.boost.org/doc/libs/1_38_0/doc/html/intrusive/splay_set_multiset.html
Thanks for point this out. I was not aware of it. Boost.Intrusive, I add a pointer to my blog as well.
how well do these work in place of a traditional LRU cache? How much bigger would the cache need to be compared to a traditional LRU to make it work comparably? This class here maintains the "size" metric but modified to add a "longest path" metric might make it better for caching purposes. Also adding a very lightweight class which just maintains the current root pointer might be wise.
That's the newest API. Start going through it and trying out different stuff. :) http://www.boost.org/doc/libs/1_38_0
I'm looking for an overview of the most important features, even though I know that eventually I will need to look at the API documentation, of course.
Well... maybe I'm missing something but Boost is a library... so the most important features will depend entirely upon what you are using it for right? Or are you wondering about the underlying code and algorithms? Edit: Hey on the Boost webpage there is their own tutorial called "Boost Getting Started" at: http://www.boost.org/doc/libs/1_38_0/more/getting_started/index.html
Amazon.com: http://www.amazon.com/Beyond-Standard-Library-Introduction-Boost/dp/0321133544
Have you read it?
Each library should come w/ its own documentation w/ a tutorial and examples. Just pick and choose what you need and it'll come to you. If you're feeling overwhelmed because no part of the library resembles the C++ you learned in school, you should consider picking up a copy of [Modern C++ Design](http://books.google.com/books?id=aJ1av7UFBPwC). It talks about a different library, Loki, but if you understand the underlying concepts, then you'll grok Boost. edit: By "each library" I meant each boost sub-library.
I have some experience with C++, I'm not just out of school. I've just never used boost and wonder if I should start using it, because there seems to be lots of interesting things in it. I'm looking for someone with experience with boost to tell me where to start.
Careful what you learn. Many of the best things about Boost are either semi-standard or becoming standard soon, so it might be a waste of time to learn the boost way and then re-learn the real way. Luckily, the two ways are usually pretty similar. I'm speaking in this case of things like generic bind, lambdas, smart pointers and threads.
Sorry, didn't mean to imply you were a C++ noob. I learned C++ in 1997 and used it to write ISAPI DLLs waaaaay before learning about perl &amp; php. When I first saw boost in 2005, it knocked me for a loop. If you've ever in your life screwed up looping over an array or container (off by 1 error, etc), consider using [BOOST_FOREACH](http://www.boost.org/doc/libs/1_38_0/doc/html/foreach.html). If you're writing a command line program that takes lots of options, consider using [Boost Program Options](http://www.boost.org/doc/libs/1_38_0/doc/html/program_options.html). If you do any sort of string parsing, check out [Boost Regex](http://www.boost.org/doc/libs/1_38_0/libs/regex/doc/html/index.html). After endless attempts to get clapack (and other linear algebra packages) to work cross-platform in g++ &amp; VC++ 8, I just gave up and went w/ [uBLAS](http://www.boost.org/doc/libs/1_38_0/libs/numeric/ublas/doc/index.htm). (I am a moron, YMMV) If you've ever tried a functional programming language and wished that you could do that sort of stuff at work, check out [Boost Lambda](http://www.boost.org/doc/libs/1_38_0/doc/html/lambda.html). To see that what took 5 minutes in matlab only took 3 seconds in C++, I used [Boost Timer](http://www.boost.org/doc/libs/1_38_0/libs/timer/index.html). I made extensive use of [Boost Test](http://www.boost.org/doc/libs/1_38_0/libs/test/index.html) to confirm my output and matlab's output weren't *that* different. If you're stuck using C++ @ work, Boost will make it fun again. Good luck. edit: Oops, totally forgot boost lambda was folded into the C++ standard.
Thanks a lot for the detailed answer.
I find that the library I use the most is the smart pointers (shared_ptr specifically). It makes memory management much more pleasant. I love the signals library. If you do any MVC work its incredibly useful. It can help you make your programs much more modular be breaking explicit binding between objects. Mulit-index is very useful (though it takes a bit to understand how it works). I've replaced all sorts of containers with it. Boost bind, of course. I use it far more than lambda just because it's much easier to figure out what is wrong if—no, *when* you get a compile time error and the "magic" of Boost lambda kind of turns me off (I'm excited for C++0x lambdas though). lexical_cast, Format, and the string algorithms are just nice to have when you need them. Personally I stay away from most of the template metaprogramming stuff. Most of it seems like it was made through dares between C++ titans and using them will only make your life more difficult. That's just me though.
thanks for the answer.
I have. While not every library is covered, the motivating examples are interesting and the explanations are clear without being overly chummy or idiotic.
Thanks a lot, that's useful.
You're quite welcome.
replying so I can reference this later
I prefer the first method.
multi-index really seems like overkill for most use cases, where an std::multimap would've worked just as well, along with some custom code for your use case of course. And if multi-index compilation fails, those miles and miles of template error messages ain't pretty to look at.
The first method is better. If I read '\*' as 'pointer' and '&amp;' as 'reference', then my internal vocalization of what I'm reading sounds correct, e.g.: "int\* foo" in my head sounds like "int pointer foo", whereas "int \*foo" in my head sounds like "int, pointer foo". The space gives an awkward pause between 'pointer' and the variable name 'foo'. 
A little nitpick - the lambdas in the coming C++ standard aren't really like boost lambda.
Good point. It's close enough that maybe compiler support means fewer parentheses and casts will be needed. (I can dream, can't I?)
I switched to the second method years back, and for good reason: multiple variables declared on the same line. int* p1,p2; The type of p2 is 'int'. Grouping the '*' with the 'int' makes this confusing. References are declared the same way as pointers, so the same goes for them. I even do it in other areas such as function declarations where I may not name the arguments. For example: int (*length)(const std::string &amp;); 
hehe...i do neither spaces on both sides (or const) int &amp; ii NEVER use single letter variables...they're a bitch to search for. int * ptr; int const * ptr; int * const ptr; int const * const ptr;
The original question presented two ambiguous styles, and you came up with one that was more ambiguous. Well done.
I use the second style just while declaring more than one variable at a time. I find the first style separates the type and name more clearly so I use that everywhere else.
The difference between the two was one of the first major syntactical turnoffs for me with C++. When declaring a variable, I prefer the first as it implies that is is a variable of type "reference to an integer". At least for me it does. Let me just be honest, I am not a C++ fan. Today I was just thinking that if for no other reason, I prefer Java (Python/Ruby/Perl etc.) over C++ because it does not require header files. 
I do int* i; To solve the problem of multiple declarations on one line: I don't declare multiple pointers on one line. Makes the code clearer anyways, imo.
&gt;NEVER use single letter variables...they're a bitch to search for. I don't, but I did for the question so that it would make the question shorter. I hate questions and post titles that take up several lines.
You've taught me a new thing today. I've always thought of "int*" as the data type, and I've always just assumed that multiple variables on the same line would use that type. ++(*this-&gt;getCommenter()-&gt;getAnnoyedWithC())
&gt; NEVER use single letter variables...they're a bitch to search for. /\&lt;i\&gt; 
I also do them on separate lines, but I put a space on either side of the splat. (int * ptr;)
&gt; I prefer Java (Python/Ruby/Perl etc.) over C++ because it does not require header files. Stay away from JBoss, then.
My way: int &amp;i but if function returns pointer or ref i do void* ReturnVoid();
Try reading variables right to left. Makes sense for most simple declarations. int *foo = foo is a pointer to an integer int &amp;bar = bar is a reference to an integer 
Oh god, header files D: Was that really the most sensible way of doing things, when compared to *just not having header files*? They drives me crazy!
I just use `int &amp;i` because `int&amp; i` is ugly. \*: Sure, downvote me. But I'm calling it what it is: a matter of taste. You like `int&amp; i` better because of the semantic meaning? Well, guess what, you're going to see both, so get over it. Holding on to that little whitespace hint will just set you up for confusion. You like `int &amp;i` because of multiple definition syntax? That syntax quirk was a mistake and confuses people. It's best to just not start multiple definitions with a pointer or reference.
The first, because the type of the variable is a reference to an int.
I'm not a huge fan myself of header files...BUT.. they sure help seeing the interface easily when you don't need to actually look at the content of the methods and stuff. Actually most of the time, you don't NEED nor don't WANT to see the code, only the interface.
Same here, hence the up vote, and a reply, just in case. A pointer to something is a type, thus it just makes sense to group the * or &amp; to the type it refers to.
That's what javadoc is for. I hate having to type everything twice. Header files are so pathetic. There are better, non-programatic ways to summarize an interface. //Still use C/C++/Objective-C daily.
I came to c++ having learned programming in java, and header files were one of the biggest reliefs (apart from feeling like a god of computing instead of a baby in a sandbox). Hiding implementation behind interface is always useful as your project scales up, and header files allow the programmer using a class or struct to look at the interface without worrying about the implementation! I'm not saying the problem hasn't been solved in java: [block folding](http://en.wikipedia.org/wiki/Folding_editor) and javadoc amount to a similar solution, but those are IDE-specific features and extra documentation, not integrated into the source itself as is the case with c++'s headers. Frankly, header files seem the best solution to me.
i prefer the first method, considering int&amp; as a (temporal) data type - an extension, if you will, of int.
Wow. I was under the impression I was the only one that prefers "int&amp; i", but apparently most people go for that
Came in here to say exactly what you said - upvoted! :)
&gt;most likely just due to how I was "raised" when I first started learning to program (C++ was my first language). If C++ was your first language you were not "raised" you were "instantiated". 
No downvote from me, but &amp;i makes me think the address of i not a reference to i. 
Borland aka CodeGear aka Embarcadero's products automatically use the "int &amp;i" form for the methods/event handlers for the objects in the IDE. This quirk lead to my question that I proposed to the CPP subreddit.
Why the hell do people downvote an opinion on a self post in the cpp subreddit?
No opinion, just syntax.
The former, and the same with pointers, too. It's a part of the type. I never declare multiple variables using commas. It has to change for some complex decls, but not for most.
The former. Always! Same as *.
Boost is such a weird and wonderful assortment of libraries that its really hard to find recent and relevant information on it, that doesn't consist of the boost documentation. I've been using boost for over a year and still have only scratched the surface!
Actually neither, I write int &amp; i I put a space on both sides. And I NEVER allow a * in a formal parameter list. I interpret it the same way as I would interpret var i : integer in Pascal and I don't think about the variable in terms of whether it is a pointer or a reference (or not) to anything --- that's just too low-level thinking.
This makes sense (the reading part). As mentioned above I just put spaces between it all and declare variables on one line each and on demand. i tend to do int const &amp; bar(foo); my partner prefers int const &amp; bar = foo;
In the old C days, the idiom was supposed to be that declarations should look like their usage, so one thought in terms of "*i is an integer" as opposed to "i is a pointer to an integer". Sadly, that low-level thinking persists today and so the idiom was applied to the &amp; as well. My view of the &amp; in C++ is that it removes the onus from every caller to have to worry about how to call a function (or method) in terms of how to pass parameters. You can just write foo(a,b,c) and the callee worries about how the parameters should be passed.
not "aka"... CodeGear was split off from Borland to do the IDE/compiler business as an own company, and was then sold by Borland to Embarcadero. Borland still exists, even though it sells no more IDE products.
&gt; I just use int &amp;i because int&amp; i is ugly. &gt; But I'm calling it what it is: a matter of taste. please stay away from my codes
"Thrown", surely? :-)
&gt; That syntax quirk was a mistake and confuses people. I certainly agree that the syntax is confusing, but this use isn't a quirk, it's a consequence of the more general inside-out rules for type declarations. See also functions, arrays, functions accepting or returning pointers to arrays, arrays of function pointers...
&gt; You can just write foo(a,b,c) and the callee worries about how the parameters should be passed. The problem with that is that the semantics of a function can silently change: a call to a function that had no side effects when the calling code was first written can wind up modifying the variables passed to it with no change (and therefore no warning) at the site of the call. I've always found it odd that the language designers introduced rules to deal with a much more specialised version of this problem, where a derived class implementation of `f(int)` hides a base class implementation of `f(char)` by default for example, and the rationale given is that it shouldn't be possible for a change in the base class to silently change the behaviour of code that is looking only at the derived class's interface. That rule is a frequent cause of unexpected behaviour for novice C++ programmers. And yet, they were quite happy to let a function be in charge of whether or not the variables passed to it could be modified, with no indication or check either way at the calling site.
The best tutorial is the online documentation, that's how I've learned to use it. For the graph library there's a dedicated book (which is also included in the online documentation). A part of Boost is becoming standard C++ through TR1 and a good TR1 book was written by Pete Becker. If you'll read a book about Boost, this should be it, the rest you can learn from the online docs. *Later edit* I would start with the part of Boost that was included in TR1: smart pointers, the functional header (function, bind, mem_fn), regex and unordered maps/sets. Other interesting libraries: asio (networking), thread, pointer container, tokenizer, integer (cstdint impl), conversion (string &lt;-&gt; number conversions), format (typesafe printf replacement), static assert.
Am I the only one who puts a space on both sides? "`int &amp; i`" and "`int * i`".
I use the first method. I like to think that stuff like &amp;, *, const, volatile, are like operators/functions being applied to the type. Given a data type X, you can construct a new data type Y by applying any of the above mentioned operators, or by applying a template operator to it (vector&lt;X&gt;, shared_ptr&lt;X&gt;). By keeping the operator associated more with the type, as opposed to associating it with the name, it makes this notion more clear. It's unfortunate that int* p1, p2 results in p2 being only an int rather than an int pointer, but that to me seems more like a design problem with C/C++ and thus should be avoided (by not using one declaration to declare multiple variables).
Almost all my pointers are typedefs... so it does not matter: XObjPtr pObj, pObj2... 
people use it as upvote=agree downvote=disagree
I have to admit it's been a long while since I've done C++. In practice I actually would use the second method. I learned C first so the second method was natural. With C++ and the invention of references, I started to appreciate the first method. The top post however points out the error with the first method: int\* p1,p2; // p1 = int\*, p2 = int int \*p1,p2; // p1 = int\*, p2 = int Both lines are correct, but IMO the second line is more apparent that p2 is not a pointer.
Good luck with readability. You may think that is what you're achieving now, but come back in a few years and casing all of those typedefs is going to be a major source of pain.
int &amp;i, *foo, etc 
I'm not sure I understand why that would be a major source of pain. Sounds to me like marglexx is being pretty smart here. If he ever wants to migrate one module to another he'll have a really easy time, a few find/replaces later and everything will be ready to go, readability will be enforced, and the way the pointers are used will be very predictable. If anything I would say this standard increases useability later down the line, not decreases. You can get away with not typedefing the pointers with smaller projects, but a project spanning multiple frameworks with millions of lines of code, 10 architects, 30 devs, or larger, and you're going to want things to be enforced and predictable.
Even more apparent, however, is: WrapperIntPtr pNumber1; WrapperInt number2;
Likewise, if you'd make a stink about such trivial things.
Actually you are on right track here - because actually my "pointers" are "persistent object handlers" in some cases and in some cases are real pointers - so everything is configured in one header file and thus people are just using the DevPtr and ObjPtr like pointers on Dev and Obj (while inside DevPtr is real pointer and ObjPtr is some kind of handler that have pointer semantics) And the reason I did typedefs for this is exactly the one you said - I wanted to have the ability to change implementation of persistency layer (to some totaly different platform i.e. sql instead of some internal library) without changing a lot of unrelated code... My application is around 100K lines C++ and 100K lines TCL + ~10K autogenerated C++ code... there are 2-3 people who working on it.
I still stick with the int &amp;i; int *foo; convention myself for the same reason. It's that damned internal dialog I always have going on while I code. I can't type int &amp;i with out saying "'address of' i" 
&gt; javadoc &gt; I hate having to type everything twice. You contradict yourself there...
Yeah, anything with a well defined persistent object structure is going to benefit loads with this type of standardization.
Typedefs don't enforce anything. They exist to hide details, and sometimes as a bonus, reduce typing. I'm all for using the occasional typedef to reduce typing. But This typedef actually manages to increase typing. So all it accomplishes is to hide stuff. What is it hiding? It hides the real nature of the types I am dealing with. That is bad, IMHO. If it's a pointer, I may need to know that. If it's a smart pointer, I may need to know that. What if I want to keep hold of an XObjPtr you passed me, after I return? With a smart pointer, I can just do that. With plain pointers, there is a question of ownership. Some details should be abstracted and hidden. The semantics of referencing, dereferencing, copying, etc, should not be hidden. If XObjPtr starts out as a typedef for a smart pointer, and I stash away the one you gave me, everything would be fine. Then you switch it to a plain pointer, and there's a subtle ownership bug. I'm likely to dereference a freed pointer, which is likely to succeed under light or periodic load patterns, but in the wild, the code will crash. This sort of thing could almost be excused away as something along the lines of a DSL. But it isn't quite that--it is never extensive enough to really get into that territory. You are writing C++ code. So embrace that fact, and write in C++, not some idealized language of your dreams where C++ has automatic memory management or some such nonsense. This is like the advice of "live in the moment". But here, it's "write in the language". C++ has pointers. Use them or don't use them. Don't pretend not to use them.
I will take your philosophical code suggestions under advisement.
Poorly titled. This entry should be called "More reasons for avoiding C++"
The posting is new but the content is a few months old; Herb Sutter no longer is head of the committee, eg. 
Oh, that's news to me. Who is it now?
P.J. Plauger. Here's [his announcement](http://herbsutter.wordpress.com/2008/10/28/september-2008-iso-c-standards-meeting-the-draft-has-landed-and-a-new-convener)
&gt; Simply put a the function input iterator implementation wraps a nullary function object and allows for bounded iterators using an embedded state variable. That's not what I'd call simply put. Although if I understand what he's saying... he's basically implementing something like generators in Python. Why must C++ make things that would otherwise be simple, seem so obscure?
yuk thats some pretty unreadable code. Not your fault but it does highlight some of the philosophies of many of these types of toolkits.
Not that I'm disagreeing with you about the unnecessary complexity, but "wrapping of a nullary function object allowing for bounded iterators using an embedded state variable" does give you a pretty accurate idea of the construct's ability, once you get your head around the terminology, that is. "Generator" is much more simple to say, but it doesn't quite explain what a generator is. There was a discussion about just this sort of easy-name/accurate-name dilemma in the Haskell community not too long ago.
Same here. Besides, when declaring class members, I can document them better with one member per line.
What in the gnu does vim OR emacs have to do with development? They are editors. That's it. Software development also uses compilers and debuggers, makefiles, and a whole slew of gnu. I can use dbx/gdb as well as the next guy or gal, and have personally gone to *extreme* lengths (over the years) to get Vi-like functionality in eclipse and/or netbeans -- and, now that Vim has been ported to Netbeans (jVi), why shouldn't I use Netbeans to set breakpoints in my code when developing on AIX or HP-UX ... where there's perhaps only "vi" (no vim &amp; not *allowed* to install it) and simple tools like grep &amp; diff are stripped-down versions of their gnu brethren? Btw, I'm remote developing w/ Netbeans, too -- but from my Linux laptop to 5 different flavors of Unix / Linux (and many versions thereof) -- including a windows (vm) running on my linux host -- all remotely, *concurrently*, from a single samba share (I need to be sure my changes work on all platforms before checking-in). You're jumping to conclusions.
In real life I have worked on a production system framework that was written in C++. It relied on a plug-in architecture (of C++ dynamic libraries) for functionality. The plug-ins inherited and subclassed classes and objects from the framework. That would not work through a C exposed API.
I wrote a bottom up implementation thats actually readable. Additionally it seems the bottom up implementation may be faster. That may be because of the following during splay (top down): extra complexity behind maintaining two separate trees on splay (probably not a big deal) not implementing zag-zig and zig-zag (doubles number of rotations for those operations) iterating back down the two subtrees to update sizes (removes node visitation advantage) I had to implement the bottom up to augment the node data structure. I may do some more formal testing to see if this is really the case.
const int &amp; foo; const int * bar;
int const &amp;foo; int const *bar;
I enjoyed his java basing far more than his code sample. The bashing is very concise.
no
I'm not following GCC development very closely, but aren't the dates there supposed to be 2009?
A few decades ago, C++ was a high-level language, and people weren't sure computers were fast enough to compile it on human timescales. I heard somewhere that when you make something 10x faster, you haven't just made it faster, you've made a new thing. It's not surprising that a 10,000x improvement in CPU speeds changes the rules. The best way we know of now to get inter-language interop is to run everything inside a virtual machine (e.g. .NET or the JVM). Try selling **that** solution to the guys buying the PDP-11.
Gawd, I want the new syntax, it takes away a lot of the cognitive friction when deciding to use one. Right now, it's less code to write a C-style for loop to iterate through an STL container than it is to write against for_each, and there's less syntactic noise. Plus, all the code is in the same place.
Well, non-standard name mangling, the main C++ ABI issue, isn't really a performance issue though. They could have picked any of the implementations and made them the standard and it would have improved interoperability without any performance losses.
I wonder if you could use this somehow to auto-generate accessors and member declarations.
i hope this allows for efficient n-dimensional grid space declarations and operations allowing indexing using (for example) el[0][0][0][0][0] to arbitrary dimension.
Well, aren't they?
They weren't when I wrote the comment. I wouldn't bother otherwise ;)
We rolled our own libraries in part because of readability issues, and also because we can better control the noise in the precision.
You mean doing linear algebra in C and compiling it with a C++ compiler is no fun. Doing linear algebra in C++ with modern C++ techniques shouldn't be so difficult: even the author of the linked article notes that Blitz++ makes this easier, but says he was unwilling/unable to learn it.
I use Eigen, and love it... http://eigen.tuxfamily.org/index.php?title=Main_Page
Redundant title is redundant.
I've been working with Qt signals/slots lately and I really like the flexibility. It's quite easy to create a thread-safe asynchronous message passing mechanism for example. Has anyone tried doing this with Boost? Maybe by combining Asio and signals2?
they removed their configure/make layer. That sucks.
This looks like a maintenance release. Not a lot of interesting stuff here unless you've been dealing with the bugs.
Actually, C++ compilation is *not* CPU bound on processes in the megaloc range. It's IO bound. You can fix some of that by rigorously following Lakos' advice, but it still hurts. OK - correction - the *real* IO bottleneck is linking. Technically separate from compilation, but practically a necessary step (No, Edit&amp;Continue doesn't fix it - it's a major stability hazard) PCHs are a benefit in terms of IO because they reduce the number of files you open (and hence the number of seeks). As for the decent OS' caching.. I guess we agree. Unfortunately, a lot of C++ work happens under Windows. Hence, RAM drive is a must. 
Maybe that's because the newly added CMake can create Makefiles already configured.
nope never
std::lock() alone is the shiznit, yet what an easy solution - just lock them in address (or perhaps some id) order! Shucks man, shared-memory multi-threaded programming just got too easy; time to move on to lock-free, or functional programming or something. 
I've seen people do this with signals1 + their own version of ASIO. Works pretty well.
Sadly, locking in address order doesn't work in general. std::lock() is a template, and can take any sequence of lockable objects, including std::unique\_lock&lt;&gt; instances and user-defined lockable objects. The address of the std::unique\_lock is entirely unrelated to the address of the mutex being locked. Also, it has to work in the case that another thread locks the mutexes in a fixed order, which may be different to your chosen order (e.g. reverse address order). Typically, implementations will use some form of try-and-back-off algorithm for std::lock() --- lock as many mutexes as you can, if one cannot be locked, unlock the others and start again, maybe in the same order, maybe in a different order.
well, I would assume in the order of the underlying OS lock identifier, whatever that is. But, you say it has to work with other, arbitrary orders of the same locks? That sounds complicated and expensive. But it would eliminate deadlock as long as there was no more than one non-std::lock() use of locks at the same time. Hum, very interesting. 
2000 is a VERY long time ago.
True, but this stuff was ground-breaking then. These techniques still form the basis of modern high-performance C++ libraries.