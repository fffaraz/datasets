Exceptions or mutable object state (i.e. valid/invalid) comes to mind. 
Seems like tree construction is pretty simple: &gt; Although Fenwick trees are trees in concept, in practice they are implemented as an implicit data structure using a flat array analogous to implementations of a binary heap. PS: Wiki's sample implementation also has this comment: &gt; A simple C implementation follows. The setup phase takes about 20% times longer than for a simple flat array, but the subsequent queries are (because of the large array used [N=4\*1024\*1024]) about 1600 times faster.
This comment would probably be more interesting if you had a few specific examples.
I wrote this! Originally it was so I could make sense of C++ TMP personally, but I love writing and felt it might be helpful to others. I would love suggestions to spruce it up. Even since I wrote it I have learned a lot about C++, so there is definitely room for improvement.
sounds like you have seen some insane naming schemes.
Capitulating to these people is why we have to support things that are shitty and old. 
I use BOOST_STRONG_TYPEDEF and I am not ashamed
there's a cmake setting to make it behave like older versions
Unfortunately, to use an object with range-v3, it seems that its begin() needs to return an iterator that supports both pre- and post-increment (see http://en.cppreference.com/w/cpp/experimental/ranges/iterator/WeaklyIncrementable). That also requires the iterators to be copyable, which makes it awkward to wrap things like lazy generators. I'd be interested if anyone knows a way around that.
What is ADL? 
[Argument dependent lookup](http://en.cppreference.com/w/cpp/language/adl), see also [Stack Overflow](http://stackoverflow.com/questions/8111677/what-is-argument-dependent-lookup-aka-adl-or-koenig-lookup). Also known among friends as argument dependent fuckup, because it works exactly the way you expect it about 50% of the time.
Although not contradicting you, I think I should point out that on Windows mutexes provide a richer interface compared to CSes, specifically, they can be abandoned when thread exits with mutexes held and they can be WaitForMultiple() on. It of course comes at a cost.
What if I want to call a function which takes two functions as parameters? Wouldn't that brake it?
IMAO you should not use is_integral, but is_same&lt;... , int&gt;
That is not the reason they are problematic -- big inputs happen, and that is when big O becomes important. If you want to complain about them, complain that they encourage programming quickly, hacking together hardcoded solutions and so on.
Cool! Seems indeed like it would be faster.
That's called the passkey idiom, aka client-attorney idiom.
[++](https://2ch.hk/mov/arch/2017-01-10/src/1265662/14813689533810.gif)
`Test(_constructor_tag) = default;` is illegal, use `{}` to give it a trivial implementation. 
It's not possible because one doesn't know what function is calling new, so it's not possible to pick a friend in a portable way. For example, make_unique might call something like _Construct_unique to actually construct the object. 
Sad face
Not really saying much tbh. Cmake's language is a mess.
only special member functions may be defaulted (literally the compiler error when I copy-pasted it). Lesson: never blog without checking your examples 
So you need to annotate each part of the code that I want to profile with a `EASY_BLOCK` macro, is that correct? No annotation, no profiling? (No judgement, just asking, since it's not too obvious from the GitHub readme :-) )
You kidding me... This is exactly what I was looking for yesterday. Now I already wrote my own shitty profiler... edit: Can this capture GPU times?
Looks like a great start. If you could work on the readme a bit and add some screenshots with sample output and I could see this project taking off (similar to the catch test library https://github.com/philsquared/Catch)
[removed]
We're lucky: upgrading one of the libraries fixed that particular issue for us on MSVC2017, so I won't even bother with that one anymore. It works, it passes tests, oh well. Going back to MSVC2015 *or* going back one library version brings the issue back. As long as MSVC2017 production release doesn't break it again :/ It's also possible that we need to bite the bullet and get the tedium of this minimization job out and develop some tools to make us more productive. I worry that we're only kicking the can down the road.
Teaching is the ultimate form of learning, I guess... Thank you
&gt; External users cannot construct the tag type and hence cannot invoke the constructors. External users cannot _name_ the tag type, but [they can still construct it](http://coliru.stacked-crooked.com/a/0756c0b7953e35f1). `_constructor_tag` needs an explicit default constructor so that construction necessitates naming the type.
&gt; add a parameter with a private »cookie« to the constructor which proves that the class is being constructed »from within« [No it doesn't](http://coliru.stacked-crooked.com/a/8d2002f6feb6094f). Anyway, kind of strange to submit two different blog posts about the exact same thing back to back...
Yes, that's right, you have to put EASY_BLOCK and EASY_FUNCTION manually (maybe we will create a script which could put EASY_FUNCTION automatically). You can put disabled blocks everywhere (use profiler::OFF or profiler::OFF_RECURSIVE; see Wiki for more details) and enable these blocks later at runtime from profiler_gui. Disabled blocks are not affecting performance in any way. I would recommend to use both profiler types together: automatic profiler (like Intel VTune) and manual profiler (like this one).
Yes, the documentation is one of opened issues at the moment :) Thanks for a feedback.
Wrong year. You want the Q1 2017 post.
You can use Apache licence instead GPL :-)
That's not actually sufficient, since it's possible to have an omniconvertible X with an implicit conversion to Y, returning Y{}. One way to really lock this down is to give Z a templated ctor, enabled only when the tag is Y. However, such paranoia is rarely justified. The only place I've used it is tuple, which has a trillion greedy constructors, so I don't want my internal tags to disrupt them.
Other existing libs for those curious: * [Remotery](https://github.com/Celtoys/Remotery) * [microprofile](https://github.com/jonasmr/microprofile)
I might be overlooking a lot, but couldn't this just be solved by making the pointer specialization a friend class? 
&gt; Anyway, kind of strange to submit two different blog posts about the exact same thing back to back... Why? 
So if I already use a really good profiler like VTune (or even VS2015/2017's integrated one is great), what does easy_profiler give me in addition to that?
I could implement something but it would be rendering API specific. If your intrested in it I could make a pull request for DX12 and OpenGL/ES gpu measurements.
&gt;global Sounds like bad practice to me.
Sure, added.
VTune tells you what is taking time. It does not *show* you *when* things take time at a function or block level granularity.
Totally correct. That's what I get for using example code I haven't tested directly. :) I'll try to update it soon, but I've only got my phone on me for the rest of the week (at GDC). (Ok, updated - easier to do on my phone than I expected!)
Brofiler as well. The gold standard fur this kind of lib (proprietary) is RAD Telemetry.
That's exactly what I want to say :)
Exactly :) We have been inspired by Brofiler, but we needed the same solution for Linux. Also we've implemented some things more handy for us.
I would love to see this support modern / core OpenGL.
As for me I don't know yet how to profile GPU code. I need some example =) If you will make pull request it will be good enough. Tnanks.
Thanks!
I moderately agree with dynamic dispatch insofar as that's a very vague term. Function pointers are dynamic dispatch, and I'm not really sure what there is to say about their implementation as it maps almost exactly to assembly. Assuming they mean virtual functions, I do think it's important to understand virtual function dispatch to a degree. I also think CRTP and SFINAE are quite important. The point is not that you can't be a good C++ programmer without it. The point is that if you are say, claiming to be a good C++ dev with 3+ years of experience, not knowing these things I would consider a hole in your knowledge. This doesn't mean you have to be an expert in these things, but you need to know what they are, why you'd use it, and be able to hammer out a simple working example with a short refresher. For virtual inheritance, I may be biased, but I more so agree with you. I think you should know that it stops the grandfather duplication in the diamond inheritance pattern, and that's about it. If you need to use it you can look it up. I think complex inheritance hierarchies aren't favored as much in C++ these days so usually most people would just prefer to avoid diamonds of non-interface classes.
Just `struct _constructor_tag { explicit _constructor_tag(){} };` is sufficient to prevent passing `{}` as the argument. As /u/STL noted, this won't stop devious users, but preventing naked-`{}` seems worthwhile to me.
Hmm. I think I understand. Thanks!
int err = func(args...); should probably be changed to int err = func(std::forward&lt;Args&gt;(args)...);
https://www.reddit.com/r/cpp/comments/5wna6o/enabling_make_unique_with_private_constructors/debfyv4/
:-) It was an "amazing" company. A very "special" place.
thanks for this video series, I'm watching it now and enjoying it. I'm curious, what IDE are you using in these videos? It looks interesting, I want to try it out.
Hierarchy view filled by blocks inside selection. To make selection press *right mouse button* and move mouse *left* (this will select only those blocks which are *fully* inside selection boundaries and their parents) or *right* (in addition to previous mode this will also select blocks intersecting with selection boundaries) then release mouse button. Also hierarchy view has 2 modes: plain (plain blocks set without hierarchy) and hierarchy (displaying full call-stack of blocks). Be careful when making very wide selection - hierarhcy view is now built using QTreeWidget which takes a lot of memory per block. What do you mean by "no threading support"? Do we missing necessary linking with pthread?
https://www.qt.io/
Here's my take on the same type of project: https://gitlab.com/groups/cxxprof. Some differences (just read your readme): * different type of makros, not only for blocks but also to measure values over time or to set markers * usage of chrome profiling tool, no need for qt (though that has advantages too) * removing the whole integration via define * measuring over network and process borders * integration with Conan package manager Perhaps you can find inspiration for further features, I currently find no time to maintain my project :/
+1
On mobile so I can't really dig into it, but serious question: what is a profiler?
thanks for this, this is a good article. while i *do* appreciate auto, i'm not sold on it for quite a lot of things that this article is using it for, specifically explicitly typing variables. his ”reasons” for this boil down to ”i like using auto, because i'm using auto elsewhere”. auto definitely has its place and purpose, especially separating abstractions and detyping *where appropriate*. unfortunately, i still see a lot of use being ”zomfg new thing let's use it everywhere” mentality. i also tend to write code for systems that require very explicit data types and memory organization, so i'm kinda biased. if i want an int16_t, i want and int16_t, and having an auto x = (int16_t) 0 doesn't actually add anything to performance, readability, or really anything at all. i also think auto is too broad. it should possibly be split into ”var” and ”func”, although i'm still thinking about this. either way, i find the name 'auto' to be poorly chosen for everything it's trying to do. lastly, sometimes you need a hammer to put a nail in, and making a whole infrastructure and blueprints for a generic fastener applicator is far, far out of scope for the solution requirements. sometimes an int *should* just be an int. 
Added that to the example. I'll need to review the text and explain the addition a bit I think, but that's probably best left to when I am behind a real keyboard. :)
+1
Looks good! You just made a game, most don't finish. Keep up the good work!
Yes it is and I have made plans to fix that along with a couple of other things. Thanks.
&gt; A common idiom is to have a privately constructable class with a (static) factory that returns a shared (or unique) pointer. It is? Not to be overly argumentative, but the base example looks like something that wouldn't pass code review where I work. Specifically, one-line factory methods aren't any more convenient than using `make_shared` or `make_unique` in practice. If there's potentially expensive work, it should be properly encapsulated and not hidden behind a constructor alternative. I just can't quite imagine a scenario where I wouldn't trust the caller to determine the location of memory allocation by hiding the constructor like this.
Please don't use URL shorteners as they trigger Reddit's spam filter.
preceding underscores are only reserved when they are followed by a capital letter or a second underscore.
Or are in the global namespace &amp;ndash; [the very next bullet](http://eel.is/c++draft/lex.name#3) ;-]
Two things I can think of for your computer guess dependency. Instead of having it be in reference to the given number, you could have the computer randomly guess between 0-100. Then say it chose 20, but was low. Then have it generate a random number 20-100. And so on. It will eventually achieve the correct answer. The quickest way to solve the Problem is to always split the problem set in half. So first guess should be 50. Then either 25 or 75. Then either 12/13, 37/38, 62/63, or 87/88. And so on. Until the final number is discovered. It will generally be quickest unless by luck, the random # generator gets the right pick. 
Thank you for actually reading the README! Very useful advice, and I think I am going to go the "split the problem in half" route. If you'd like credit, I could definitely mention your github on the readme next update. Just PM me.
I'm trying to figure out how timestamps are recorded. It looks like whatever architecture-specific high performance counter is used. The problem I've had doing something like this in the past for my own very simple profiler is that on multi-core CPUs each core frequently has its own high performance counter. This causes problems when the CPU changes what core is executing the thread between the beginning and ending of a timed block. Sometimes you get large numbers and sometimes you get negative (or if unsigned -- *huge*) numbers. I've had to pin threads to certain cores to profile correctly. Does easy_profiler suffer from the same problem?
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5wtjvq/need_help_with_minor_thing/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
No worries giving me credit! I couldn't think of the term before, but it's a Binary Search Algorithm. Quick way of finding an element in a sorted array. Since 0-100 is sorted, the binary search is an excellent choice for finding the result. Hope this helps you for sure! wikipedia.org/wiki/Binary_search_algorithm
Thanks for the link. This will definitely be useful to follow for proper implementation. I really appreciate all the help. :)
`_constructor_tag` has to be a complete type only if you need everything to be in the header file (that is if the factory function is inline or if you are writing a template). OTOH, if the factory is defined in the implementation file, just leaving the type incomplete in the header file should be sufficient to prevent misuse. 
Support for [Chrome tracing format](https://docs.google.com/document/d/1CvAClvFfyA5R-PhYUmn5OOQtYMH4h6I0nSsKchNAySU/edit) would be nice. Then you can use any Chromium based browser to view the results with *about:tracing*.
Nah, but FP opened my eyes to certain patterns that appear in my ranges code. For a good example, take a look at my blog post about [range comprehensions](http://ericniebler.com/2014/04/27/range-comprehensions).
 #define private public
&gt; It's like requiring a c++17 compiler for code that compiles fine in 03. I honestly think that it's a good thing, if only to force people to update their toolchain. Even if it's an inconvenience for the developer, it makes the world a better place overall. Besides just compiling something in C++17 can magically improve performance without changing the code due to forced RVO, small string optimization, etc.
well, yes, but it leads to people reinventing it anyways. Like everything, it's a tool that has its uses and drawbacks; and would be much safer than other features of the language. And C++ in my opinion is a toolbox before everything else, and should aim to encompass most use cases.
Why macros? I mean, a RAII-based approach without macros is feasible with no added cost in the "release" case.
Do I need to set a colour for each function/block name or is there some way to automate this to avoid having to assign and manage colours to parts of my project? The README.md seems to suggest that if I don’t do this, every block will have the same colour?
First reason - declaration of blocks requires static block-descriptions. Also blocks are scoped, there is no need to call EASY_END_BLOCK for each block. Second reason - to be able to exclude all profiler code from profiled application fast (via empty macros). Third reason - macros makes it possible to replace one profiler by another very easily - good example is CryEngine, they are using several profilers.
Yes, if you don't set color for a block explicitly it will have default color. You can create your own palette or use unsigned int ARGB values directly. Also you can create your own macro wrappers (e.g. EASY_CORE_FUNCTION with white color, EASY_IO_FUNCTION with orange color and so on).
If you want to capture thread *context-switch* event under linux you can run special [systemtap](https://sourceware.org/systemtap/) script. I've added some information to readme about it: https://github.com/yse/easy_profiler#note-about-context-switch
That would be great as we do not have much experience with GPU :) Feel free to contact us directly if you need any help or if you will have questions about easy_profiler_core.
My bad about mentioning scope :) But would be non-macro way be as compact and easy-to-read (I mean *this particular case*)? Can you suggest a RAII-based implementation for some of our macros? Maybe this would be better and we would include it into next release, who knows. (Private message would be better, I think, if there are a lot of details/code)
Ah, ok, thank you! I’ll have a look at it soon, it looks really nice and Intel VTune is always a bit heavy.
I think few employers are looking for just a C++ developer. It is always C++ in some specific application, such as embedded, or financial, or medical devices. So you should describe the settings where you have used C++ and match that with the job ads. It is also useful to know the tools that are used in the company you are interested in, for example Qt if that is what they use for a GUI, a cross-compiler if they are doing embedded development etc. Knowing a couple of languages is good - some problems might be better solved using Python or a quick little Bash script, than in C++.
indeed goto FAIL; as made famous by Apple!
I have been a broker on equity derivatives mainly and for 4 years I develop trading strategies and do quant research in C++ and python as a hobby so ideally I would like to find a junior position in such a role but they ask for professional programming experience and I do not know how to get it
You should look into making this class based instead, as this is very C style C++.
 void f(char const volatile * s) Just jigger the cv-qualification. Remove the `volatile` inside the function, on the sound assumption that nothing is ever actually `volatile` in the first place.
I'm looking into modularizing more of the code in the next update* Thank you. Edit: Hit enter too soon.
Try installing this KB: https://support.microsoft.com/en-us/help/3207317/visual-c-optimizer-fixes-for-visual-studio-2015-update-3 Your issue sounds similar to this issue that is fixed in the KB: https://connect.microsoft.com/visualstudio/feedback/details/2920681/vc-code-generation-bug-when-converting-from-uint32-to-int64-on-x64-o2 
What code will fit better then GOTO here? Could, you, please, share example? 
How does this compare to tcmalloc? Its built in profiler is already my goto tool for low overhead memory profiling. Looks like this might have a nicer gui for exploring the collected results, but so far that's all that has jumped out at me. 
Looks like that fixed it. Don't get the bug anymore after installing that hotfix and triggered a full rebuild ...
That problem also appears [here](https://randomascii.wordpress.com/2017/01/08/add-a-const-here-delete-a-const-there/). Simply put, the compiler generates a "deleted default constructor". There is a report related to this problem [here](https://connect.microsoft.com/VisualStudio/feedback/details/3117602). Now, whether this is standard compliant, I'm not sure. Can someone enlighten us?
Very true. `make_unique` in this case is the easy example; my actual projects trend to use a graceful of smart pointer types optimized for different use cases (common in any modern-ish game engine), much closer in spirit to `make_shared`. I'd use it for the example, but the last thing I want to do is encourage people to use `shared_ptr`. :)
You need to use the `in_place_index` constructor for `variant`. Otherwise, the `variant` construction fails due to ambiguity if you have repeat types in your `tuple`. That said, does this buy you anything over just writing a function that takes a `tuple` and a callback and just calls you for each element?
For normal users, the biggest difference really is the GUI and the ease of use in general. I.e. no manual LD_PRELOAD'ing. I know that this could be scripted with tcmalloc, but if you compare the "how to use" over at http://goog-perftools.sourceforge.net/doc/heap_profiler.html to how you use heaptrack, I think the latter is more in line with other profilers like perf etc. Also note that the official tcmalloc documentation says that the LD_PRELOAD way of using it isn't recommended. Personally, I didn't ever manage to get good results with it either, e.g. when I try to use tcmalloc via LD_PRELOAD on kwrite the results are wrong and I'm missing most of the interesting hotspots, where heaptrack works fine. For advanced users, another difference is that heaptrack supports custom pool allocators via a special API, similar to what you may know from valgrind's massif. See e.g. https://codereview.qt-project.org/#/c/163017/ Finally, do note that three years ago, when I started heaptrack, I wasn't even aware of this feature in tcmalloc. See http://milianw.de/blog/heaptrack-a-heap-memory-profiler-for-linux and search for "reinventing the wheel". Because I personally don't use tcmalloc, and thought this project was super interesting, I decided to pursue this project and see it evolve. Now, I would love to see a converter for tcmalloc's output into the heaptrack format, such that we can display it in heaptrack's GUI. Patches welcome :)
I think [Hana](https://github.com/boostorg/hana)'s map would solve most of your problem, except for the `.member` syntax (but it's unclear to me how much of it is just nice syntactic sugar, and how much of it is actually useful). Also, I guess you can't optimize away storage for empty types in your implementation?
Thanks for the info, very helpful!
The compiler is standard compliant. The relevant wording is [class.ctor] para 4.4.
You are right, Hana's map is similar to iod::metamap, but serves different usecases. The biggest difference is that only its keys and value type are known at compile time, not the values themselves. In Hana both key and values are compile time (as I understood). The .member syntax is inherited form the [iod::symbol](https://github.com/iodcpp/metajson) features and this is what makes this implementation pretty interesting : - checking for the existence of a map key is straightforward, and compile in O(1) time. This is done with the has_member routine generated with each symbol definition : https://github.com/iodcpp/symbol/blob/master/symbol/symbol.hh#L37 - The map behave exactly like a plain C++ object, whose members are a bit simpler to access. - The a string representation of each key is available in case you need it to serialize the map. To answer your last question, I just did a small test: auto m = iod::make_metamap(_test1 = 12, _test2 = 13); std::cout &lt;&lt; sizeof(m) &lt;&lt; std::endl; And it prints 8, so the map keys do not seem to have any memory footprint at runtime. For a nice usecase, you should have a look to iod::metajson: https://github.com/iodcpp/metajson It relies on symbols and metamaps to implement JSON de/serializer. 
thank you very much
Always add your version(s) (in this case the compiler version) to your bug reports.
I'd start with functions. Nothing in your game looks like it would benefit from using classes. One of the things you will learn as you use C++ more and more is when to use (or not use) various features.
Note: on stackoverflow we've dubbed the pattern [Pass Key](http://stackoverflow.com/questions/3217390/clean-c-granular-friend-equivalent-answer-attorney-client-idiom/3218920#3218920). You must choose whether the parameter must be passed by value or reference; reference making it possible to control the lifetime... somewhat.
Hmm. Pity it's a thick GUI, I've not developed locally in years
So you know, it seems to use ~~both RTTI and~~ exceptions.
I use emacs for that. But then again I use it for everything.
You and me both :(
&gt; const correctness way of declaring my variables Typically we don't define things inside the class or struct as `const` because it seriously messes up `operator=`. So I would say that your definitions here: struct parameter { const int x = 1; }; struct result { const parameter p; }; are themselves atypical. Now, when you have something like struct result { parameter p; }; and you try to create a variable `const result my_result;` when you go ahead and access the `p` member via `my_result.p` this itself evaluates to a `const parameter&amp;`. That is, the `const` applied to the variable is applied to each member so that a `const result` really does have a `const parameter` inside it. The only thing to keep in mind when you play this game is that `const` applied to a pointer like `int*` means `int* const` -- *not* `const int*`. That is, you can use the pointer to change the underlying `int` but you can't make the pointer point elsewhere. With `const int*` you can make the pointer point somewhere else but you can't use it to change the underlying `int`. With `const int* const` you effectively have a nullable `const int&amp;` since you can't make it point elsewhere (rebind it) and you can't use it to change the `int` value. --- The one exception for things that should be `const` inside a class are things that are also `static`. It's possible you can end up with a situation where you naturally would want a `const T&amp;` as a member, and you can definitely do that, but again you run into issues with `operator=`. In that case a non-owning `const T*` is better since you can "rebind" it so that `operator=` is implementable. --- One place where you should use `const` liberally, though, is in your functions. If your function doesn't modify the object you should absolutely mark the function as `const`. In many ways, when people talk about writing "const correct" code they are referring to a combination of marking non-mutating functions `const`, using `const T&amp;` parameter types, and marking variables which won't change as `const`. It's better to handle that at the variable level rather than at the member level. (The keyword `mutable` can break parts of this and though it's rarely useful, when it is useful it's probably very useful.)
Why is `auto get()` bad?
Tested with the following compilers all in 64-bit mode (amd64) and 32-bit mode (x86) with and without optimizer flags: - Visual Studio 2015 Update 3 - Visual Studio 2015 - Visual Studio 2013 - Visual Studio 2010 - Visual Studio 2008 All failed the test in 64-bit mode when an optimizer flag was used (/O2 and /O1). The [released fix](https://support.microsoft.com/en-us/help/3207317/visual-c-optimizer-fixes-for-visual-studio-2015-update-3) only "applies to" VS2015 Update 3.
Just tried installing this via ARCH. Holy crap this thing has a crapton of dependencies....like substantial portions of kde. Would be nice if it were factored into 2 parts, data collector and some sort of exploitation gui(s).
I get the expected behaviour too, and never manually installed any hotfixes. 
The heaptrack data files are completely stand-alone. Collect data on an embedded/remote machine, copy it over to your local machine and launch the GUI there to analyze the data. Or use heaptrack_print and try to grasp tons of data by staring at ASCII output. 
I think I've fixed all the issues mentioned. Thanks so much for the feedback.
Note that `const` can be a pessimization in C++, because move operations are mutating. In other words, you can't move a `const` object. This is logically opposite of what most people want or expect, but is a necessary facet of how move semantics use revalue references. For example, consider a `const unique_ptr&lt;T&gt;`. Moving out from it _must_ set its internal pointer to `nullptr` so its destructor won't free the resource. If it's a constant, though, you clearly can't modify its internal state; you'll get a compiler error if you try to move it. For other types, like a `vector`, you'll implicitly get an extensive copy instead of a move with no diagnostic or warning. I really like the idea of `const` everywhere in most languages, but it just doesn't work well in C++. It works better for references in most cases I've personally run into though (I almost never want to move out of a reference unless its explicitly an rvalue or forwarding reference).
I'm searching through an array which has 200k string names. I'm suppose to find the most popular name and return it. There are 1000 unique names. My current program takes around 30 min to run on Xcode. I don't know why I was informed there was 1000 unique names thou, I didn't implement it into my code. 
I can't repro using yesterday's daily Nuget build (compiler v19.10.25027); output for both x86 and x64 release builds is: &gt; 4224838037 32bit 4224838037 64bit 4154708778 32bit 4154708778 64bit
done
Can confirm. My VS 2015 was at Update 3 and not showing any update notifications. The bug was reproducible as presented. After installing the above hotfix, the output of OP's code is correct.
&gt; skill level varying from learning - intelligent I find this rather insulting. &gt; c_and_cpp Will this madness ever stop? C and C++ are quite different languages.
I mean you can link to the code, just not with the URL shortener.
If only it was made open source. I've extended and reimplemented almost all of mfc at this point. There are rarely new features and bugs go unfixed. The MFC Feature Pack popup menu still will eat and ignore random window messages posted to your thread causing all sorts of incredibly hard to reproduce bugs :( I don't rarely mess with it anymore but there is so much legacy code that could benefit from simple things. 
While I like having frequent updates to VC it is getting confusing asking *which* Update 3 people have. 
Nowadays is there any new project using MFC?
How can you say that SFINAE isn't important? Using things like `enable_if` and Concepts are almost the exact opposite of something that isn't really important.
that KB works for me, thanks!
Because concepts aren't in a currently published standard and enable_if is C++11, which blocks it from being used at many companies that haven't yet updated from C++11. You don't need either of those to be an effective C++ programmer.
Looks good over all, but there are a few things you could think about in the future. This function bool isCollision(Ball &amp;b, Brick &amp;br) could instead have this signature bool isCollision(Ball const&amp; b, Brick const&amp; br) since you're not modifying any of the objects. You could also have more descriptive function names. For example, it's hard to know exactly what this function does void Mouse(int ax, int ay) The global variables in 'vars.h' could probably live inside some object. Labels are usually frowned upon also, and it seems the label in Timer() is not needed. I.e. the execution flow will naturally end up at Draw() even if you don't have the goto-statement. Speaking of Timer(), it takes an unnamed int-argument which, of course, is not needed. Other than that, nice work.
&gt; Wrap it into a class where you acquire the socket in constructor, and close it in the destructor. At risk of flogging a dead horse, a new C++ programmer might not realise how powerful this is. It provides a guarantee that as long as the destructor is called, the resources get tidied. Ports closed, memory released, files that are open closed, whatever might need to happen. If the object is on the stack, the destructor will be called when the object goes out of scope. Doesn't matter how or where or when that happens. A return from anywhere, an exception thrown from anywhere, doesn't matter. It removes the bug-prone, maintenance-nightmare of manually creating and destroying resources. Even if the object isn't on the stack, and you've to delete it yourself, it's still the right thing to do; now you just need to remember to delete that one object and you can forget all about the resources, trusting that they're closed properly.
what about Windows Version ? Can I port this program to Windows ?
Yeah, this problem doesn't exist if you can use lower-resolution timers that are safe across multiple cores, however they usually* only have a resolution on the order of microseconds or on some systems as low as a millisecond. For Windows, chrono::high_resolution_clock is a typedef for chrono::steady_clock which relies on QueryPerformanceCounter() which usually has resolutions in the ~microsecond~ hundreds of nanoseconds to microseconds range and can be susceptible to BIOS bugs. If the code you want to profile is large enough that microsecond (or maybe even hundreds of microseconds) resolution is fine, then you don't need to worry about pinning threads. If however you need resolution in the 10s of microseconds (for intel-based chips), microsecond resolution for non-intel chips, or CPU cycle-count resolutions, you need to use a different API and also have threads pinned to certain cores. This may be a way to expand your project. Have 2 sets of macros: one for very high resolution measurements and one for lower resolution cross-core measurements along that come with thread-pinning support macros. I know this complicates things *a lot*, but it is something to think about. Anyway, [here's a great article about the challenges of measuring time on multicore processors](https://msdn.microsoft.com/en-us/library/ee417693(v=vs.85\).aspx)(MSDN. While functions are Windows-specific, the lessons are universal.) EDIT: [Here's another article worth reading](https://floodyberry.wordpress.com/2009/10/07/high-performance-cplusplus-profiling/). One lesson pointed out here is that the RDTSC instruction can be executed out-of-order and give you incorrect results. The profiler can use [the serializable RDTSCP instruction](http://stackoverflow.com/questions/12631856/difference-between-rdtscp-rdtsc-memory-and-cpuid-rdtsc) instead, but it is slower to execute (i.e. has more overhead). EDIT 2: [And here's an interesting whitepaper from Intel](http://www.intel.com/content/www/us/en/embedded/training/ia-32-ia-64-benchmark-code-execution-paper.html) about profiling on ia-32 and ia-64. EDIT 3: corrected timing information based on feedback from u/yse_ji &amp;nbsp; ^(*) Obviously I can really only talk about the systems I've dealt with, but they come from the x86, x64, and PowerPC families and all use some external timer for this timing. The very high-resolution timers are core-specific which lead to the problems I described.
Cannot understand why people downvote this kind of posts.
I'll give try to port it to Windows I guess My problems it'll face me in KDE GUI as you know but I'll do it with Qt , if it works as I expected I'll mail you as soon as i finish this
Wow, your registration page simply made me quit My city doesn't appear in your list of indian cities, I don't have a "Year of Study", I don't want to give you my contact info After putting lot of fake info, I still didn't get an email after 2 minutes (my patience is not what is used to be) Good luck in your endeavors (you can check I didn't bullshit you, I tried to register as fez@yopmail.com)
There's no such thing as 'KDE GUI'. Please inform yourself about which bits and pieces of KDE Frameworks Heaptrack uses before trying to reinvent the wheel. The KDE Frameworks libraries are cross-platform(!).
The 2nd attempt is template &lt;std::size_t I&gt; decltype(auto) operator[](std::size_t idx) { // what to do with parameter idx? return std::get&lt;I&gt;(*this); } But there is no connection between `I` and `size_t idx`. So, the compiler cannot deduce `I` from the function's parameter even if the function's parameter is a constant expression.
Because chances are you probably don't want to return a copy?
I'm not trying to reinvent the wheel ,I checked it out I thought KDE Frameworks are not cross-platform, anyway sorry I confused about 'KDE GUI'
Ah. Did not know templated conversion operators worked like that. http://stackoverflow.com/questions/25123709/why-is-a-templated-user-defined-conversion-operator-able-to-determine-its-return
I was curious to see what went wrong. With VS2013 Update 4, the code is compiled to something like this: int main(int, char**) { reg32_t tmp = 0xfbd1e995; reg32_t n = 2; reg32_t a = tmp; reg64_t b = tmp; reg64_t arg; loop: arg = a; std::cout &lt;&lt; arg &lt;&lt; " 32bit" &lt;&lt; std::endl; arg = b; // oops! no truncation std::cout &lt;&lt; arg &lt;&lt; " 64bit" &lt;&lt; std::endl; a += tmp; b += tmp; if (--n != 0) goto loop; }
Just a few thoughts, so far: * Why safe_literal and not std::integral_constant? * "trap_exception" feels a rather confusing name for an exception policy; "trap" in the context of integer types already has meaning ("trap representations", e.g.) Possibly something with "static" in the name would be better, e.g. "static_exception". * It might be useful to have an exception policy that explicitly invokes undefined behavior. "ignore_exception" has this effect for signed integers but not for unsigned integers, which wrap. This is __builtin_unreachable on gcc and clang, assume(0) on MSVC, etc. * Also some people might want explicit wrap, saturate etc. policies.
I'm not going to give you my home address and all that personal info just to check out a game.
I like how the main proposal fits in syntactically with the existing type_traits library. But then again, concepts will hopefully be hiding a lot of that away. So maybe a more modern approach could be good
&gt; I don't know why I was informed there was 1000 unique names Because knowing that, it's easy to check that you got the right answer, if you implement it the way the teacher envisioned (which, as /u/this_is_the_internet says, will cut the runtime down to fractions of a second).
Have a look at [theCore](https://github.com/forGGe/theCore). TheCore is a modern C++ framework for embedded systems which aims to do as much as possible at compile-time thus minimizing the size of resulting executables.
&gt; Not Included: attributes Is there any other way of specifying which members get serialized through reflection? I was hoping to be able to do something along these lines: struct MyStruct { int [[serialize]] field1; // or int [[no_serialize]] field2; };
That's a pretty fast* QueryPerformanceCounter frequency. Please note however that QueryPerformanceCounter frequency depends on your MOBO, not your processor. It's run by an external clock which is why the MSDN page talks about buggy BIOS causing problems. ^(*) Granted, again I haven't looked at typical frequencies for QPC in the last 4 years or so. My current project is working with 1+GHz multicore embedded PowerPC chips. On that system the portable counter increments once every 125 microseconds, making it completely useless for may timings.
Andrews and Herbs approach isn't completely new, but I doubt that all ideas from the current main proposal will be scrapped. The current main proposal is in revision 3, so there has been some substantial review by the committee already. The object based approach is still a good one, and could be there as a library building up on the current main proposal. I'm still not sure which approach I'd personally favor though. I find much more interesting Daveeds hint, that we're about to create a new monster in the type system. Also a complete reset would make this an unlikely C++20 feature. Lets see what happens in Kona or later in Toronto. 
I guess things like that would be added in later standards. For now, it might make sense to split the serialized and non serialized members into two different structs: struct foo { struct serialize{int a,b,c;}; //non serialized members int d; } Or any other workaround :o)
This is probably the reason why the MFC exceptions suck: In MFC land, exceptions are thrown as pointers :-)
`std::enable_if` is new to C++11, but nothing about it is inherently limited to C++11; the idea applies equally to C++98, Boost has had an implementation forever, and implementing it yourself is all of 2-5 lines of code (depending on formatting). You may not need to use it yourself, directly; but if one isn't using a single library that relies on SFINAE somewhere in its implementation, there's a _very strong chance_ one isn't an effective C++ programmer...
That's good user feedback, thanks. For the TS, we're sticking with `reflexpr`.
Hana's maps can have runtime values. In fact, it can also have runtime keys, as long as they can be hashed and compared at compile-time. As for the keys, if you use Hana compile-time strings, you can achieve the same as what you are achieving but you don't need to pre-declare stuff with macros. You lose the `.foo` syntax too, but I don't see that as a big problem. My .02.
A fun moment I had was speaking at a conference with live translation (from English to Russian) and pronouncing keywords like `constexpr`. the translators hated me. (Advice for others ever in that situation - talk to the translators beforehand, give them a heads up on weird nonstandard words you're likely to use a lot so they're ready for it.)
The fact that registration isn't just my email address and name means I won't be doing that. People care about their privacy. You have no reason to need my address or education or if I'm even in school.
&gt; Designing something knowing full well that workarounds are necessary for its shortcomings right out the door seems absolutely atrocious. It's also pragmatic. Better is the enemy of good: I'd rather have an embryo of reflection that is imperfect than wait longer for a potentially perfect one (we all know it'll never be...).
Your parse function is broken for values &gt; 99. Yes, tuples with 100+ elements are not very common, but still, that shouldn't be an excuse for such mistake :)
This is more like C++ish than $ syntax. I hope they change $ too.
I would agree but that's almost as much time as I've been programming so what would that make me ...
&gt; &gt; &gt; &gt; &gt; Better is the enemy of good: I'd rather have an embryo of reflection that is imperfect than wait longer for a potentially perfect one (we all know it'll never be...). if it was at least as much as what you can do in c# or python or with Qt, it would already be fantastic.
&gt; This type say clear it is some not owned pointer that is guaranteed not null. What's the difference between that and a reference? &gt; A optional pointer is a non owning pointer and that might be a nullptr. Why use that over `std::optional&lt;T&amp;&gt;`? If that isn't in your C++ you can easily find the code for it...
`std::optional&lt;T&amp;&gt;` is explicitly forbidden; `boost::optional&lt;T&amp;&gt;` is still fine.
[N3740](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3740.pdf) is somewhat related but does not explicitly enforce non-nullness.
Metal is also SFINAE friendly, which is nice if you need it.
Const works great for local variables, especially variables that are either simple (like int, bool, etc), or ones that have expressive enough constructors that you can construct them directly into the state you'll need them instead of mutating after construction. If you really want to make an effort you can even use immediately evaluated lambdas to get a const local in that case. I agree that `const` for member variables doesn't work out so well but I think that saying that `const` doesn't work well for values in general is overgeneralizing.
 int i = 1, j = 2; optional&lt;int&amp;&gt; o{i}; o = j; Is it the case that `i` == 2 or that `o` is now seated on `j` rather than `i`? This question, and the lack of an overwhelmingly-compelling victory for either argument, resulted in it just being forbidden instead (the lesser of two evils).
The committee plans to ship Module TS/Ranges TS/Concepts TS/Reflection TS/Network TS all in C++ 20? I think it's impossible.
This is not the right subreddit for this question.
Reffle-exper?
$ is just too ugly, and I think reflection is merely a minor feature
Umm... nice, but the version of Deflate that takes an `unsigned char*` buffer could *really, really* use a bounds check. Trusting data to not decompress to a size larger than expected is just asking for a security nightmare.
What does this bring over gdb TUI?
I just worked this out. WeaklyIncrementable and CopyConstructible (and therefore InputIterator) don't mean that the copy of the iterator has to be independent of the original iterator, so for a lazy sequence it's OK for any increment of an iterator to affect all other iterators on the same sequence. So, to work with range-v3 you just need to fulfil the requirements of the InputIterator concept, which means you need to have post-increment and copy construction and assignment but they don't need to do anything clever.
A more intuitive graphical debugging environment I guess. Not having to run all of the different display commands after every step but seeing all of it automatically.
To add to Louis' answer, Metal has indeed been designed to reduce compile times as much as possible. Because Metal is more specialized than Hana and only dwells in the pure type level, it is on the other hand able to compile much faster. You can browse some compile time benchmarks on http://metaben.ch
I wonder how hard it would be for compiler vendors to provide basic metaprogramming facilities as builtins, and what would be the performance gains at compile time...
I acknowledge that possibility, and am working on a resolution using the "pay only for what you use" principle. EDIT: I saw you, downvote orc. In any case, function versions with full range checking have been added now.
That is already our reality, newer versions of mainstream compilers, specially Clang, do provide a few core intrinsics to aid in metaprogramming and Metal takes advantage of them whenever available. See https://github.com/brunocodutra/metal/blob/master/include/metal/list/iota.hpp And https://github.com/brunocodutra/metal/blob/master/include/metal/detail/lookup.hpp
People use the term "literally" to mean "figuratively". What's commonly used for a term doesn't make it logically correct :P
It's in the roadmap and should soon be added. Anyway it won't affect the simplicity of the high level API which is what I think make this post interesting.
Indeed these are two good reasons to remove the use of exceptions. I'm adding this to my roadmap. It will be pretty easy to handle anyway since the decoder implementation is only ~100LOC. Thanks for your feedback and if you have any other suggestions I'm open, especially if it's to "lighten" the library. 
`observer_ptr` is part of ["Library Fundamentals TS V2"](https://wg21.link/n4617), so it's half-standard. I think very few things from Library Fundamentals V2 made it to C++17 (like `gcd` and `lcm`)
Deflate is the name of the compression method and format. This lib deals with that format. There is no inflate format.
...what are the arguments for the `i==2` answer ? 
utf8 is actually almost done.
&gt; I've worked with Qt [...] and I have to say that ncurses is easier, smaller and simpler to get started with. Perhaps, but the expenditure for a framework is one-time only. I would think, having a passing experience in Qt, that your game would be much smaller in Qt and the code should be more expressive/high level. You're also not really writing C++. Even if you just did that, it'd be much smaller and easier to read.
Sorting did make it faster thank you 
It should be very fast anyway and take just a few seconds at most on [this word list](https://raw.githubusercontent.com/dwyl/english-words/master/words.txt). It's not supposed to be a hard problem. If it takes minutes, you're doing something quite inefficient. The below is a *very* simple implementation and not optimized at all. The "magic" is done by `std::map`: it's a sorted container. It sorts in ascending order on the keys. Reading it backwards (`rbegin()`) gives elements in descending order. #include &lt;iostream&gt; #include &lt;map&gt; int main() { std::map&lt;std::string, int&gt; words; for (std::string word; std::cin &gt;&gt; word; ) words[std::move(word)]++; std::cout &lt;&lt; "Unique words count: " &lt;&lt; words.size() &lt;&lt; std::endl; if (words.empty()) return 1; std::map&lt;int, std::string&gt; frequency; for (auto pair : words) frequency[pair.second] = std::move(pair.first); std::cout &lt;&lt; "Most frequent word: " &lt;&lt; frequency.rbegin()-&gt;second &lt;&lt; std::endl; } Usage: `main &lt; words.txt`.
So what is the point of this? It is basically a raw pointer, so why not just use a raw pointer? There isn't a single motivating example in the blog post so I don't know why you would ever want this. The only things I saw was: 1. Only points to one element, so increment/decrement/add/subtract aren't needed. Well you can just not use them. Of course it eliminates accidental use but I have never encountered that, so it seems to me like a non-issue. 2. The null check also seems to me to be solving a non-issue: Null pointer dereferences really aren't scary, since on all modern operating systems they just crash your program (technically they SIGSEGV which then crashes your program), because there is never anything at address 0. Null dereferences tend to be because you are in an invalid state, and as a result there isn't really a way to recover from them anyway. If you really want to fix them use sanitizers which will at least give you detailed information about what and where things went wrong, rather than an unhelpful exception with no information for diagnosing the issue. It also does nothing to handle dangling pointers which are a much larger issue, which you can't just check for. Also which static analysis tool requires you to null check before you dereference? and can you not just turn that off?
RemindMe! 2017-03-14
According to MS what is the "correct" way to write a GUI in C++ for Windows these days? Do they try to force you to use some dot net thingy? I've just used Qt or Wx when it has come up.
I'm somewhat with you on "expressive". It is terribly subjective - however, such an exercise is a decent starting point for what others consider expressive, and what feels awkward for them. On pi: - you randomly generate N uniformly distributed points wihtin the square - you count how many of these points fall into the circle (by calculating whether their distance from the center point is &lt;=r). That's M - for large numbers of N, the ratio M/N will approach the ratio of the circle area to the square area - this ratio is pi/4 It's more or less the standard example for [Monte Carlo simulations](https://en.wikipedia.org/wiki/Monte_Carlo_method)
Opinions are still valuable, though much more so in bulk.
`reflexpr` is simply a different spelling of `$reflect`.
[removed]
Found the Kansan.
[removed]
I don't think the current Coroutine TS is the right direction. I prefer the call/cc approach which is more powerful.
Huh? [call/cc](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0534r0.pdf) is not an alternative to the Coroutines TS. They do different things. You'd use them both together.
Don't they both capture the context(environment) and resume it at some point?
Coroutines is a language feature which can be used to "split" your function up into pieces, allowing you to "suspend" and "resume" a function. The suspension and resumption happens through an `Awaitable` type. call/cc is a library feature which you could use to implement fibers, lightweight threading, etc. You could build `Awaitable` types with call/cc and then use the Coroutines TS to write continuation-passing-style asynchronous code with that type.
(And my first paper, though Jens did all the work :D https://mobile.twitter.com/AlisdairMered/status/837853072244129792 )
UWP, it works pretty well with C++/CX, and as soon as C++/WinRT works with UI stuff, we'll be golden with a standard C++ UI framework for Windows
Perhaps [this](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4628.pdf) or [this](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0057r5.pdf)?
I get that. 4628 isn't too far off, but I don't know what happened or if it will simply come into existence at a later point.
`#pragma currency GBP`
Yep. That library twisted so many beginner programmers. One of the worst designs ever. Can't wait for iostreams to die. Another ugly sob.
I believe this is correct.
Pretty cool! I love seeing innovation in the area of deflate/gzip, because that official zlib library is quite old and showing its age! I'd also like to add, that Beast has a port of zlib's deflate to modern, header-only C++11: https://github.com/vinniefalco/Beast/tree/master/include/beast/zlib
Yep, I saw 2 comments but ther is only yours. I think the other one was a removed or something like that. 
I feel your pain brother. But the reality is that a very small percentage of C++ programmers have a need for such a thing. It would be a boutique library. That doesn't mean its not needed. But I think the only way for this to happen is that someone needs to be the champion for the cause. In other words, someone needs to take this up as a hobby project and commit to maintaining it for the next decade. Perhaps you could be that person?
So are you more frustrated by the fact you need to build a c library on Windows for image support, or the fact that you have to build anything at all? Presumably the reason that libpng doesn't switch over is that it has 20+ years of development and bug fixes put into it by the development team, they know the internals extremely well, and it seems to work (i.e., to them, why fix it if it isn't broken? ). I also chuckle at your statement that it would be so easy to accomplish, particularly in getting it into an ISO C++ standard. - What platforms would you provide support for? Linux, Windows, Mac, Amiga (supported by libpng)? You are tied to the version of c++ available on that platform. - What is your public interface? Data structures? Memory handling? Multithreaded support? Exceptions vs error codes? Versioning and support for updated standards? - Putting something like this into the standard could be extremely challenging from a political standpoint. It may be ideally suited for ending up in the library section. You will have to get people on board with it and what the library is supposed to do. Then, the regular updates for all the image types to support. Png, jpeg, tiff, raw, geotiff, etc...where will it end? As much as I would love a library that can read images without needing to complie things on Windows, I dont believe going the ISO route is appropriate. At least go through boost first :)
&gt; CImg, is C No, CImg is C++. http://cimg.eu/ But, I think what you're looking for is ImageMagik https://www.imagemagick.org/Magick++/tutorial/Magick++_tutorial.pdf Ya, you're going to need to link to some stuff and set up includes, but that's C++. If you're using CMake, it's a lot easier these days. For something header only, there's boost.gil, but it's more about abstracting pixel formats so you won't be rendering text on those images, for example, using Gil. http://www.boost.org/doc/libs/1_63_0/libs/gil/doc/index.html 
AFAICT, don't use Asio for a thread-pool thing, its performace is really not good. I've done benchmark before (PPL/TBB/Asio/my work-stealing scheduler), on Windows, PPL performs best, and mine is on par with TBB, and asio::io_service is the worst, far worse than the others.
LOL well that was a mouthful. I agree about going through Boost. Or even just put up an independent library to start.
If you need to read / write images you generally use a gui library and they all have this feature built-in.
&gt; CImg, is C There's a comma - other libraries are C. But sorry for the ambiguous language. Still you don't want to pull in whole CImg just for writing a png. ImageMagick looks quite nice actually, haven't looked at their API so far, thanks! I wonder why they are basing ISO graphics proposal on ugly Cairo instead of ImageMagick. &gt; If you're using CMake, it's a lot easier these days. No it's not in the cases that I mentioned. Ever built an sdist for PyPi with external dependencies? Gil is probably dead, can't find any activity, and accordings to the docs, Gil hasnt been updated since 2007. &gt; you won't be rendering text on those images I wasn't writing the post about drawing text into images. Just about reading and writing images. Like loading a png into a vector&lt;uchar&gt; (or some basic image/data type). And writing the same to the disk.
I don't think you have to solve all of that at once. Many new things and boost libraries even require a C++14 compiler (e.g. Hana). No Amiga there. You have to support the common use case, modern platforms, where people use modern C++ on. The 0.0000000001% of people that want to program &gt;C++17 on Amigas, I'm happy to leave them by themselves. So we should get bogged down by all these details and never get to a consensus, or maybe in 20 years? For something as basic as image reading and writing? If the committee works that way, there's something wrong. But in my experience it doesn't. It has to be cautious yes, and can get bogged down in some details, that's necessary - to some degree. Of course the best route is to go through an independent (preferably header-only) library =&gt; Boost =&gt; ISO C++, but that doesn't mean that I shouldn't mention ISO route, particularly because there might be some interdependencies with the graphics proposal. &gt; Presumably the reason that libpng doesn't switch over is that it has 20+ years of development and bug fixes put into it by the development team, they know the internals extremely well, and it seems to work (i.e., to them, why fix it if it isn't broken? ). For sure they wouldn't and shouldn't switch. Yes, that's a big problem, it wouldn't be a trivial project.
The marginal cost of just accepting the warts inherent with a 20 year old image library with a C interface is MUCH lower than the cost of writing a new one (and debugging, testing, and seasoning it). That's why there are few new libraries.
Not C++, but [stb_image.h](https://github.com/nothings/stb/blob/master/stb_image.h) seems to be exactly what you are looking for. Its extremely lightweight, header only (in a C kinda way, you need to #include the header once in a translation unit with implementations activated) and very easy to write a RTTI wrapper for so it is easily usable in C++ projects. It supports most popular image formats. Only negative would be that it is not really general purpose but geared towards game development.
I've had positive experience with boost.GIL (had to visualize some fairly complex sensor readings), but it doesn't seem like anyone wants to propose it... basic reading/writing can be seen in their docs here: http://www.boost.org/doc/libs/1_63_0/libs/gil/test/image_io.cpp
&gt; I wasn't writing the post about drawing text into images. Just about reading and writing images. Like loading a png into a vector&lt;uchar&gt; (or some basic image/data type). And writing the same to the disk. Well, then I think gil will do exactly what you want. It's not actively maintained no, but because it's distributed with boost, it's at least not rotting. I've used it within the last year, on modern compilers, with no troubles.
It's shadowbanned garbage.
Yeah, /u/sumo952, it sounds like you need to learn how to use your build system. Adding a library dependency shouldn't be so difficult... handling this is exactly the problem that build systems should solve. The undercurrent to OP's post is that libraries are/should be distributed as header-only, and therefore any platform-specific (or whatever) code in a cpp file belongs in the standard library. But the header-only trend is in many cases driven by poor use/understanding of build systems. If you have difficulty linking to any "true" libraries (from cpp files) outside the stdlib, fix your project, mate. 
Yep I know about stb_image.h. The problem with it is that it writes out png's that are about 20-50% larger than ones written with libpng, at least that's what their docs say. And it's got C globals and macros :\
I've got a pretty good handle on CMake, I would call myself quite knowledgeable. I've even contributed to CMake. As I wrote in my OP, the issue isn't with your standard Linux, OS X and Windows build. One can handle that, with some minor pain points (yet some things are still annoying). The issue is if you want to maintain single source (and single build-system) and venture into the area of building sdist's for PyPi (ever tried that?), or emscripten or Android builds (though the situation with Android is manageable too - just takes effort).
So, at some point, the reason that there are more useful libraries written in C is that, a lot of people who make such libraries want them to be used not only by C++ programs, but by C programs, by python programs, by rust programs, etc. It's much more difficult to make C++ libraries that are called by python or rust than it is to make C libraries this way. C++ is just a lot more complex, and ABI, yadda yadda. I actually don't think it's a bad thing to have most of the low level libraries written in C, and then have simple C++ wrappers over them. I think such programs are often easier to reason about, and there's less that can go wrong. Also, I'm personally a lot more comfortable using `libpng` and knowing that I can swap out the version and distribute a dll or link a specific version statically into my project if my users report a problem with some version, than I would be using `#include&lt;png&gt;`. Because then, I'm hoping that ALL of the gcc, clang, msvc, etc. teams get it right, or I get to deal with the inconsistencies. This is similar to how, if I use `#include &lt;random&gt;` and my code uses `std::random_device` and I compile with mingw, I'm actually just going to get a broken random generator which always reports the same number. http://stackoverflow.com/questions/18880654/why-do-i-get-the-same-sequence-for-every-run-with-stdrandom-device-with-mingw I'm still not totally clear on why this doesn't work, but I *think* the reason is, to do this right on windows requires access to a proprietary microsoft crypto API, and it's very uncomfortable for libstdc++ to depend on this API without any assurance that it won't change in the future. Yet, if I use `&lt;boost/random.hpp&gt;`, my random device works on all platforms and does the right thing. And it's maintained by one guy who tries hard to make sure there's consistency and that no platforms fall through the cracks. He has no particular problem with MS changing it's crypto API, because releasing a new version of boost::random is not nearly such a big deal as releasing a new version of libstdc++. (At least, this is what I surmise. I don't think it's the case that libstdc++ devs just don't care about this or aren't aware of his code.) I think the truth is that the standard library should not contain graphics or gui at all or any of these other goodies that people want, and it probably shouldn't really get much bigger than it currently is. Rather it should be ultrastable and limited in scope, to avoid painful development cycles. For instance, this is one of the most horrible bugs I've ever heard about, first saw it here on this reddit: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=66145 The more complicated crap they add to stdlib, the more such bugs we are going to encounter, unfortunately and inevitably. And if the stdlib is has a big problem like this, you have very few workarounds. If the problem is only a bad version of libpng, that's easily worked around. If the problem is a mistake in stdlib, and it's like, &gt; Daniel Seither 2015-11-16 10:44:02 UTC &gt; Is there any simple workaround for this bug short of checking f.fail() after each operation? &gt; Jonathan Wakely 2015-11-16 12:16:20 UTC &gt; I would suggest not using exceptions with iostreams, they've always been an odd mix anyway. I mean that's like, sorry, this stuff may be standard, but if you used it in your program, it's not going to work with certain versions of libstdc++ and there's nothing you can do about it, so you should rewrite your program, or tell your users they just can't use gcc-5 or gcc-6 stdlib I guess (!). Please don't make stdlib larger or more complicated. Instead the extra stuff should go in boost. Moar boost please!
Refactor to &lt;algorithm&gt; ;)
Note that libpng is a special degree of horrible due to using setjmp or abort for error handling. Although it is written in C, the error handling is incompatible with every other language, even C++. (You can technically use setjmp in C++, but it's horribly unsafe and doesn't interact well with RAII or exceptions)
&gt; The problem with it is that it writes out png's that are about 20-50% larger than ones written with libpng, at least that's what their docs say. Docs say "it is 20-50% larger than the file written by a *decent optimizing implementation*", not libpng. From my tests, stb_image_write output only 5-10% larger than libpng with default compression setting.
Loading and saving images? That's like saying writing text to stdout shouldn't be in the standard library. The world and applications are build around images. Name me one application that doesn't have to load or save at least one image, and if it's only the window icon. (I'm sure you can name a few - which is besides the point). And even if it's not a GUI application, there's so many console/server applications that load, process or store some form of images.
So nice I have to post comment.
&gt; things that are truly universally useful That's to some degree opinionated and we can debate about that. I'm not talking about image manipulation, just loading and saving. For many applications you can't just use a framework because you don't want to pull in a whole framework and ten/hundred thousands of LOC just for saving an image. And as outlined in my OP, the libraries out there are not good enough. They're really not, from a modern C++ programmer's perspective.
Nice. Note include should use forward slashes. Regarding the comment by /u/def-pri-pub, as a next step converting to use the newer GL 3 or 4 core profile would definitely be a useful exercise. In particular, you could make use of a uniform to control the size and the opacity, and you can play with geometry or tessellation shaders to generate the circle vertices. You can also draw an anti-aliased line in the fragment shader. There's a fairly huge learning curve, but it opens up a lot of new and exciting possibilities!
Basically, it's giving concept misuse errors at template definition time instead of at instantiation time.
Thank you very much for this great post, it is very enlightening. And at the same time a bit disheartening. It looks like the situation will not change, even in the next decades. I disagree a little bit on your last part. It would definitely be great to have this as a separate library first. But I do think it could be part of the standard library. As many of these image formats require compression, maybe the way to start this would be to try to get zlib, deflate and this stuff into the STL. I do think that's something generic enough to be in the standard. A lot of algorithms and other libraries depend on it, and it's an important building block alongside of filesystem, networking, etc.
Is this used to generate the Beast reference docs (which look very like ASIO's)? If so, then if you've automated that then amazing job. But that format of docs, rather like those output by Standardese, don't suit a library like Outcome well. What I **really** need to reference document is a template alias, because these are option&lt;T&gt;, result&lt;T&gt; and outcome&lt;T&gt;: template&lt;class T&gt; using option = basic_monad&lt;policy::option_policy&lt;T&gt;&gt;; template&lt;class T&gt; using result = basic_monad&lt;policy::result_policy&lt;T&gt;&gt;; template&lt;class T&gt; using outcome = basic_monad&lt;policy::outcome_policy&lt;T&gt;&gt;; So what I *need* the docs tool to do is do the CRTP instantiation of basic_monad&lt;&gt; with the policy and write out a reference docs page for the composed class. I am unaware of **any** C++ reference docs generator which can do this for a CRTP policy instantiated template alias. The closest I know of is doxygen where when being parsed with doxygen, you fake option/result/outcome to be classes inheriting from the CRTP mix and thus get the reference docs you want. At least, doxygen would work except for the preprocessor metaprogramming used to generate the policy classes as they all get stamped out by the preprocessor. My Python C99 preprocessor is doing an amazing job so far at being a partial pre-preprocessor, and I hope to get a de-metaprogrammed edition of Outcome spat out next few days that will actually compile. Still though, if anyone knows of a C++ reference docs tool which can automate documenting template aliases, I am all ears. Standardese came closest, but the page it generates is nigh on unreadable and I'd have to write a custom Python script to strip large chunks out of it to make it usable. So the pcpp + doxygen route looks least work currently :(
How about [strong/opaque typedefs](https://isocpp.org/blog/2013/08/new-paper-n3741-toward-opaque-typedefs-for-c1y-v2-walter-brown)? Please? Pretty please?
Thanks for your feedback!
I think all four of those things are really important, but for new programmers I think ranges are the most important. For example, right now you can't just write "sort(vec)", you have to write "sort(vec.begin(), vec.end())" which means that people have to have some grasp on iterators before they can sort an array, which is terrible. Essentially the standard library is creating a partial ordering of what topics must be introduced before what other topics, and these topics don't match what is best pedagogically for people learning to program. Just like how range-based for loops eliminated the need for people to know iterators in order to iterate over a generic container, we need to allow all of the standard library functions to just accept a container instead of an iterator pair.
I like this list; all four are features that would make coding in C++ faster and more pleasant, and help many developers. I think Networking will be the trickiest to do in a properly robust way, but if we don't make it an emphasis, it certainly won't happen. The one item missing from your list that I am personally most hoping for is Reflection. I have so many hacks in my code at the moment to make tools as dynamic as possible, all of which should be simplified by real reflection. That said, depending on how concepts are implemented, it might seriously reduce that need.
There's also the fact that the image format's spec sometimes disagrees with Photoshop, so you just have to know by tribal knowledge to skip over some parts of the spec because they are right in theory but wrong in practice.
ovh.com is even cheaper. For like $3.50 USD you get 2GB ram, 10GB SSD and a 1 vcpu at 2.4Ghz. Plus they have hosting outside the US if wanted/needed.
Yeah, that's true, the setjmp for error handling is pretty ugly. But, that's more an argument to look at `lodepng` or something, rather than an argument to make it part of C++ stdlib, at least in my mind.
I do agree that you have a point sort of, but wow, you sure have low expectations. Just because you **can** do something and it works (more or less), doesn't mean it's a good or satisfying solution and that one shouldn't try to improve the situation - particularly when there is loads of room for improvements.
Also aren't these all things that have been repeatedly proposed since C++11?
&gt;Modules Concepts Ranges Networking Oh look, my wishlist for C++11. And then it became my wishlist for C++14. And then it became my wishlist for C++17. And then it became my wishlist for C++20. I'm starting to see a pattern here.
I didn't say that it should be part of the standard library. I just think libpng is bad.
Can we get some hash up in the standard library? I want to throw a pair of ints into an unordered_map without rolling my own each time!
I want concept. But not in the form of current Concept Lite. Unlike C++0x Concept which compare the comcepts with inheriting reletionship, Concept lite compare them with, by using the formal term, if one concept subsume another. I really don't like it.
`future::then`, please...
1 and You will also need a custom equal_to. You could also try using emplace which will construct in place if you are creating the Foo in the same scope.
As far as I understand modules will make c++ incomparable with c headers. The key issue here are macros. I find it hard to justify killings macros for the sake of a particular compiling optimization. Where per library pre compiler header would do a much better job then modules for instance. I find the lack of good support for macros in development environment like visual studio the real reason macros get such negative views. I also see most code bases using macros which means that are solving a problem than the rest of C++ can not. Unless modules also come with a C++ feature that fills completely the niche that macros are solving I personally don't want modules.
I understand why modules, concepts and ranges take time as they are language changes. Network is an interesting one in that it's a library. I reckon the reason C++ doesn't have a network API is because there are too many ways to do it. Should it be templated or OO, sync or async. Callbacks or co-routines? If TLS which TLS library? decisions decisions. I vote to simply absorb the standalone ASIO (i.e non-boost) into std:: and get on with it already! :)
I would like a superset not a subset.
I don't know any ready to use lib. but there is a lot of PNG optimizers like pngcrush, optipng and many others. And you can switch from zlib to zopfli for deflate. But all this come with huge performance penalties. You may want to try more modern formats if you need maximum lossless compression.
good point -- did not consider that.
If modules by the standard are force to keep macros, then should be no downside and everyone should be happy. Btw no one stops you neither to build you own module system. The "no one stops you" type of arguments are a waste of everyone's time. 
Axe networking and handle stuff thats incredible hard to do in the language first (aka coroutine).
No. Just no. See [N3980](https://isocpp.org/files/papers/n3980.html) instead.
Yeah, try not having them on your wish list for C++20.
But why do you use memset instead of manually initializing each member?
You can generalise this by using the flyweight pattern. Each Foo is really a handle (pointer) to a unique instance in some global data structure. This means that you can define the hash of Foo to be the hash of the handle, which is very cheap, because any Foo with a given value will always point to the same instance. Construction of Foo becomes more expensive, but hashing, equality comparisons and copies become extremely fast. I use boost::flyweight for this, but be warned that it comes with slow compilation and a hit to program startup time and binary size. Also, as you clearly care about performance, unless you have a *lot* of entries I would suggest trying to implement your "map" as a sorted std::vector of std::pair&lt;Foo, Bar&gt; and searching using std::find_if, with the predicate being the given key equals the .first of the pair. I haven't yet written code where this didn't turn out to be much faster than a map/hash map lookup, but obviously it depends on the container size, use pattern, etc. 
That's not in the standard library. 
Don't use memset or memcpy at all in C++. By following this rule you do not have to learn all the minutiae about PODs and whatnot, and you reduce the risk of your code containing bugs. edit: Hey, you guys want to spend more of your time debugging and paying for support tickets like the one in this question, instead of having your code work first time... fine by me 
My advice would be to never use non-static const class members. They are more trouble than they are worth. 
Don't use C or C++ at all. By following this rule you do not have to learn about all the minutiae about memory layouts and memory management and whatnot, and you reduce the risk of your code containing bugs. **No, for god's sake, don't take any of these comments seriously!**
Also that the type of an entity is different to the type of an expression consisting of just that entity. The type of an expression is never a reference.
Well, given the size of the class, the memset implementation, the frequency of usage of the class in question, and other factors, it can be a huge win thanks to SIMD and similar things. But it comes with its own set problems, of course. Definitely only worth it at the core level of the application, which is only touched by a select few more experienced people, who know about the issues with memset construction. EDIT: Well, apparently the most popular compilers can do it automagically, as it has been pointed out down below by a few people. I didn't know that, as I don't have the habit of checking generated assembly - but I definitely should start doing that! So it probably makes the manual optimization pretty much unimportant under normal conditions.
The Networking TS is based on ASIO
&gt; CTRL+F reflection &gt; 0 hits :'( I don't see why networking, which is essentially going to be the adoption of an already available library (asio) to the standard takes so much precedence over a feature that needs language support. To implement networking in a program today, you can use asio or other solutions and you can be fairly happy with that. To implement reflection, you need code generation or writing boilerplate by hand (i.e. there is no good solution without language support). Is it already lost for C++20? When is it coming then? C++27?
You would have a problem if two different Foo ended up with the same size_t
Concepts have been on my wishlist since I first heard them proposed and I've literally forgotten what they are it's been so long. They seemed logical and useful but there's too much information in the world to keep speculative language syntax floating around in the noggin. So I've never revisited them but I'm rooting for them nonetheless. When they finally appear I'm going to have a revelatory moment of "oh yes, right" and it'll be glorious. 
Annoyingly you can't memset if you have a destructor (according to the spec). So if you have a class that has a bunch of handles/opaque pointers that need freeing/deleting/destroying you can't just memset them all to nullptr in the constructor.
Msdn samples are full of memset on classes and structs.. Especially MFC/COM code
just value-initialize instances of the class instead, that will zero-initialize it in a superset of the cases that memset would be legal (except for members with non-zero default member initializers). or you can value-initialize each member instead if you want default-initialized instances to be zeroed as well.
Partial ordering handles this example just fine unless your range and comparator have the same type, which is probably exceedingly uncommon at best.
Also for setting an array to -1 or for string manipulations. But you are right, not useful for much else.
Consistent networking across all platforms. std::socket pls.
I think ranges are a library thing that doesn't depend on language changes ps. I think ranges are awesome
That's good to know, thank you! :)
Difficult things are difficult. More, academia for some reason seems mostly uninterested in this stuff, so it's generally people from industry working in their spare time.
yes, please, reflection, and custom attributes / decorators defined in code just like C#, Python, etc... It makes everything so much simpler.
&gt; It is basically a raw pointer, so why not just use a raw pointer? because some people apparently get eczema when they see `*` in their code.
Let's see if anyone of us will live long enough to experience concepts as actual part of the standard. They should have been in 14 and I really see no excuse for not having them in 17 but all those people who have been stopping it before probably won't stop whining no matter what you do. /rant
I think compilers should emit warnings when they meet code like ```memset(this, 0, sizeof(*this))``` which `decltype(*this)` is not POD.
I once told a supervisor this. It was around the time the C++98 standard was published, maybe a bit earlier, maybe a bit later - we were still using Borland C++ 5.02, the company was still making the transition from C to C++, and a lot of the code was basically C compiled using a C++ compiler). I wouldn't have used the term "undefined behavior" because I wasn't aware of that term back then - I said something about "there's a virtual pointer which is needed to call virtual methods and handle run-time type identification, it's initialized by the constructor, and then you're immediately wiping it". For anyone who may not know - virtual pointers (a hidden implicit field in the class which points to a "virtual table") are an implementation detail which isn't mandated by the standard, but which most if not all C++ (and C# and Java etc) compilers use. I explained repeatedly, but he was convinced I was describing a design decision I had made and kept saying something like "no, you can't do that, because this memset thing is a standard idiom that's used everywhere" and even told me that if I really insisted on having this virtual pointer thing I had to put it at a negative offset to the object. I told him it wasn't a decision I made, it was part of C++, but it didn't seem to register. He worked it out later, though he never acknowledged that particular mistake that I remember - actually, he was very smart in general (and I've certainly got the wrong idea stuck in my head many times) but that was a very frustrating conversation. 
I agree with the only good reason for macros being "conditionally compiling code depending on compiler settings", but isn't most of this now taken care of by constexpr if? Personally, I use my own version of assert throughout my code and love that it can be scoped in C++17. 
Yes, that whole section is a joke. 
 * Reflections * Modules * Concepts * Ranges * Reflections
I am skeptical about the possibility of having a good networking library without executors.
The whole "Braced initialization: a trap" part is really messy. &gt; Braced initialization is an initializers list with one element... Well, no, list-initialization rules are applied with multiple elements as well, they just have a bunch of special cases for the single element which are irrelevant here. &gt; ...thus, when writing: `std::vector&lt;int&gt; v{2, 1};` You are not writing: `std::vector&lt;int&gt; v(2, 1);` well, that's technically true :) &gt; ... but this: `std::vector&lt;int&gt; v = {2, 1};` ... and that is list-initialization again (copy-list-initialization as opposed to direct-list-initialization before), and still would call `vector(int, int)` constructor in absence of `std::initializer_list` one. Much more explanatory example would be `std::vector&lt;int&gt; v({2, 1});`. I'd advocate for reading the corresponding [standard clause](http://eel.is/c++draft/dcl.init.list) instead which is IMO surprisingly comprehensible. 
Not a string, but an int array for example. -1 is commonly used to denote an invalid or unknown value.
I mean, at least this time Microsoft (and specifically Gabriel Dos Reis) seem to really be pushing for modules, so I actually think they'll probably make it. For the rest... let's just hope.
Yes and many others must also agree specially if clang is indeed supporting macros in their implementation of modules. "Many people agree" is also another type of bad argument.
I don't know (FWIW: I'm using it a lot in my new projects). But the library itself is not important, the concepts in it are. Consider using those in your code instead of my concrete implementation of them.
This is a perfectly fine opinion if you only have a tiny number of dependencies and only have to build on one or two different systems.
If possible, almost certainly the best answer
Actually 18, the C++98 standard was published in September.
Let's not be too hasty there. I'm fully with not allowing this on classes that are polymorphic, and maybe classes with a destructor is a good idea, but even adding a simple constructor to a class makes it non-pod and there are valid use cases for zeroing those out. Bad enough that offsetof only works with pods when it could be defined much more broadly.
+1 for emplace and mention of custom equal_to Assuming rhomboid's answer is not feasible, this seems to be the next best solution. I might also suggest using unique_ptr to automated cleanup
If you at all can, please don't learn C++98, even though Accelerated C++ is a great book (or so I've heard). You'll save yourself a lot of time and trouble as modern C++ is just so much better. Unfortunately, I can't recommend you any books, because I haven't ever read one.
Networking TS *does* include executors. 
I added a more detailed discussion about SFINAE-friendliness to the docs, which compares Metal directly to Hana with this respect on a real world example http://brunocodutra.github.io/metal/#SFINAE
What do you mean? This just doesn't compile: reinterpret_cast&lt;float&gt;(uint_value) And this: *reinterpret_cast&lt;float*&gt;(&amp;uint_value) is breaking strict aliasing rules.
You may consider using [CPP Rest SDK](https://github.com/Microsoft/cpprestsdk) instead. It is a native C++ library, and looks like has everything you are looking for. 
Suppose I want to use Facebook API. How can I use OAuth2 authorization with CPP Rest SDK?
&gt; you start integrating it into all new code instead of making a big fuzz about applying it to your entire code base in one go. welcome to the [lava layer](http://mikehadlow.blogspot.fr/2014/12/the-lava-layer-anti-pattern.html) !
Thanks.
&gt; And this: &gt; &gt; *reinterpret_cast&lt;float*&gt;(&amp;uint_value) &gt; &gt; is breaking strict aliasing rules. And how does memcpy not break the same strict aliasing rule?
Quoting the answer: &gt; If an object of type `T` is located at an address `A`, a pointer of type *cv* `T*` whose value is the address `A` is said to point to that object, **regardless of how the value was obtained.** That got me curious, because remembering a [C survey](https://www.cl.cam.ac.uk/~pes20/cerberus/notes50-survey-discussion.html) with the following quote (Question 5/15). &gt; It is not, however, valid or safe to manufacture a pointer value out of thin air by, for example, generating random bytes and seeing if the representation happens to compare equal to that of a pointer. Looks like C and C++ disagree at this point.
If `sizeof(SomeClass) == Sum of sizeof(SomeClass's members)` is true, but `std::is_pod&lt;SomeClass&gt;::value` is false, is a memset safe? In this case, what would prevent a safe memset? There is no vtable pointer or otherwise to overwrite.
Casting pointers to `char*` and copying byte by byte doesn't break the strict aliasing rules, because the rules allow it. `memcpy` does this, and the compiler is aware of `memcpy` and `memset` enough to optimize them.
 std::string foo{"wot"};
Thanks for sharing! 1996 "Inside the C++ object model" - Lippman's book '2.3 Program Transformation Semantics' had this mentioned! 
What's the big problem with including it?
`std::vector` does actually have an initializer_list contructor so I'm not sure what point you are trying to make - it's moot to talk about what would happen if it didn't; that constructor is one of the key features of vector as of C++11. `vector&lt;int&gt; v{2, 1}`, and `vector&lt;int&gt; v = {2, 1}`and `auto v = vector&lt;int&gt;{2, 1}` all call the initializer_list constructor.
because there might be 30+ members which are all going to be initialized to zero and in some cases it's neater to use the memset instead of having {0} next to everything. In engineering simulation type projects, I see these types of PoDs all the time
1. Why should this sort of reflection be limited to enums? I much prefer the proper static reflection being worked on, that works much more uniformly across the entire language. 2. With Herb and Andrew's proposal, it would be as simple as `$MyEnum.count()`, though I can't be bothered to look up the actual enum interface they thought up. With a Hana-like library on top of the other proposal, `count(reflexpr_&lt;MyEnum&gt;{})` would still be pretty simple. 3. &gt; Yes, it fucking is. Months ago I wrote a Python script during an afternoon that would parse C++ headers in the search of enums and generate actual valid C++ usable code with this interface. Writing a Python script isn't the same level of effort as actually standardizing such a feature. What's proposed in the article would change enums rather significantly or create a number of special cases. It doesn't make sense from a C++ perspective to allow `Type::function()` syntax on something that isn't a class. This would need to be addressed and worded to remain consistent and not inadvertently break *anything* else in the language. The easy way out is special-casing, but I don't want a language where we add on by needlessly having special cases when the feature could be properly designed in the first place. And then what would you propose for the rest of the language? How are we to implement other aspects of reflection? Anything general can no longer cover enums unless we want two ways of doing it for enums, but nothing else. What if `MyEnum` already has a `count` enumerator? What do we do about existing `count` macros? Should enums behave differently when being used as flags? For `isValidValue`, what happens if the underlying type is larger than `int`? Should we take the underlying type? What about when the underlying type is `uint8_t` and we get a warning when passing an `int` because of the signed-&gt;unsigned conversion? How is generic code supposed to deal with this? It boggles my mind how the logic is "I wrote a simple script to preprocess C++, so why doesn't this exist?"
I have always felt the lava layer is a bigger problem with architectural changes. Having a portion of your code use generics, hard references and interfaces (well abstract base classes with only pure virtual methods but same thing) seemingly at random is painful. However portions of your code using niceties like braced initialization or lambdas isn't nearly as impactful as the alternatives are mostly syntactically different versus having huge functional changes everywhere. I would agree that even minor changes add up unless you eventually clean house though.
Actually, memset only requires TriviallyCopyable, so unless you add copy/move ctor/assignment or destructor you're good.
I think pybind11 is used only for generating python native extensions, i.e. to embed C++ in a python application, but not viceversa. Boost.python can do both native extensions and embedding. 
[P0223](http://wg21.link/P0223)
Can you really not tell?
The executors in the Networking TS are just a part of the overall executor framework that we are working on.
The primary design goal was to reduce latency. The hardware concurrency is reasonably easy to put into use by decoding multiple streams simultaneously, in other words, decode multiple files at the same time. This gives linear performance increase as long as there is bandwidth to supply each thread with enough data. So, throughput is the low hanging fruit; any existing code, as long as it is thread safe can be used for that. Having more efficient implementation will just save some power, mostly relevant on mobile devices but those have other means to assist in the task. So back to the latency; the task at hand is to reduce latency for processing individual stream. For that we need per stream concurrency but the Huffman was bottlenecking the whole process. Once that is taken care of the decoder itself has to be multi-threaded, which I am not sure the libjpeg-turbo is. My best understanding on the topic is that it isn't but that's not necessarily a bad thing as it would just made the code more complicated with very small returns in terms of performance improvement. How I got into this? Back in the 2009, when OpenCL was just coming out I was tasked to do R&amp;D on the topic how to leverage mobile GPU for the upcoming API. I wrote a prototype OpenCL accelerated JPEG decoder as test case for the hardware ecosystem that we were building at the time. At that time OpenCL still couldn't write into OpenGL textures from the compute kernel so the data did roundtrip from system ram to GPU's internal memory, the results were written back to system ram and then uploaded back to the GPU. Talk about roundtrip, huh? The mobile GPU in question used UMA so the ram was shared but conceptually the whole thing was just bad and the performance *decreased* instead of improved. This was fixed later when it was possible to write into the textures from the CL compute kernel. I just had written a simple JPEG decoder. Fast forward to 2012. I was fooling around with atomics and lock-free and wait-free algorithms and wrote a neat new toy, ThreadPool which used lock-free queue to send messages between threads. It was OK but eventually I found out moody camel's concurrentqueue and replaced my hack with it, which was a good move. But as you know when you have a hammer everything is a nail, so I re-visited the topic of JPEG and messed with it a lot. I shaved 2 ms off here, 1 ms off there and kept record of the decoding run times in a sheet. Then I hit the performance wall, the Huffman one and I don't know what coctail I enjoyed one too many or what happened but the idea just came to me out of nowhere; RST markers - wait.. don't they, like, RESTART the decoding interval? Yes they do.. I could kind of feel that I had hit a jackpot even before running the code. I had all of the infrastructure in place to make the surgical code change and I was blown away as the decoding test run ran in 50% of the time time it normally takes! That was a good fun moment right there. I am still doing a lot of dumb AoS format stuff there, each pixel is individual entity even though my decoding primitive is MCU which can be up to 256 pixels. I really should process something like 4 or 8 pixels at once to make the code faster and simpler. But I am not too excited about that, because if I comment out everything after the Huffman decoding the code doesn't get much faster anymore -- even if doing _nothing_ after it. Suitability for general use: 9 / 10, the Baseline Profile is fully supported. I was unable to find 12 bit color and non-lossy jpeg files so those are not supported. The code is resistant to malformed or incomplete files up to a point but this area isn't the strongest one in the code. :( 
There's no concrete design for how it should function nor any working implementation experience. Concepts were originally meant to be in C++0x (called "constraints" then) and the major reason that 0x was delayed was that getting definition checking hammered out was taking forever; eventually template constraints were cut entirely and C++11 came out. Gating concepts on definition checking is possibly just going to mean that C++ won't get concepts for many, many years, given that it's already been a decade since they were first proposed and there's still no progress on how to realistically add definition checking to C++. It's an example of the saying "the perfect is the enemy of the good."
Many of those are not C++, rather "C with `&lt;iostreams&gt;`".
As someone who's only ever known post C++11 I would whole-heartedly recommend **not** learning C++98 (at least at first). The language feels very different with the new language features and standard library improvements. e.g. I could not imagine for one moment programming without std::unique_ptr.
Hence they should be part of the STL, yes. =)
In the most common use case, it would just be a single parameter: sort(vec). This shouldn't cause any confusion for the overloads. And even if you did create an overload for it passing in a compare function: sort(vec,mysort), then the compiler can tell from the fact that the first parameter is a container and not an iterator which overload to use. If this is too complicated, then just the single parameter version should be implemented, IMO.
You don't need to use OpenGL4.0+ for that. I would go for something lower, trying to find a balance between the functionality that you need and the devices you want to target.
You're thinking of constexpr functions. Lambdas were always allowed multiple statements. As far as lambdas were concerned, it was generalized initializers and parameters that were introduced in C++14 int x = 4; [y = x](){}(); // generalized initialiser [](auto f){}(); // generalized parameter 
&gt; by making your native code a Python module Could you expand this please? What tools do you use?
I think he meant he has to pass reviews again for the code he already wrote and went through review many times. 
&gt; The project already has large codebase in C++ and Qt5. Since you already use Qt5, why not directly use the Qt Javascript engine and do your "scripting" from js ? (With [QJSEngine](http://doc.qt.io/qt-5/qjsengine.html)). You won't have to integrate anything new to your codebase, but you can access all your QObject almost automagically, as well as JS libs.
Seems this was my mistake. Really even `clang++ -std=c++11` can compile multiple-statement lambdas. But I sure, it was impossible about 4-5 years ago. I suspect, that was partial implementation of a working draft, not the full implementation of the final version of the Standard. Maybe changes was applied retrospectively.
You wrote: * the branch code "is done in 2 or 3 cycles, provided that the branch prediction was correct — a mispredict [...] typically adds 15–20 cycles." * the conditional move code "needs 5 cycles to execute" from that, you conclude that "the version with conditional moves takes twice the time to execute compared to the version using a branch". To be pedantic, you cannot reach this conclusion if don't discuss the probability of having a mispredicted branch. I mean, if we take the more optimistic estimates, the branch version takes, on average, 2+15p cycles, where p is the probability of a misprediction, so there is a trade-off when p=0.2. Your conclusion is therefore correct, since in this particular case p is extremely small (about 2.5e-18) **assuming that the compiler is able to correctly detect which branch occurs more frequently**. To help the compiler in such decision, there's a recently proposed paper [p0479](http://wg21.link/p0479). 
Can you imagine how much of a messy spaghetti nightmare you will face if every new developer redefines basic stuff like this however he prefers? If you do this, please list the companies you have worked for so that I make sure never to touch them with a ten foot pole.
A lot of it will be over your head at this point (and even as you get more experience), but I suggest watching talk videos from CppCon, C++Now, GoingNative, etc.; it might take several watches to internalize the ideas, or to pick out the bits that are useful and relevant to you, but a lot of them focus on or at least touch on common problems in resource management, error handling, abstraction, polymorphism, concurrency and parallelism, refactoring, and systems design. I'd specifically recommend looking up talks by Herb Sutter, Scott Meyers, and Sean Parent.
`QImage::load`. You don't need to bring the whole of Qt into your project. If you wish, you can factor out `QImage` and a few supporting bits it needs. BTDT, works OK. If you then include `QPainter` &amp; friends, it becomes easy to draw on the images. It's just a couple dozen source files to get this functionality, and you're using something with decent documentation that works on quite a few platforms.
I like this advice. I'm very careful about adding dependencies to an existing project. JS lib seems like a good middle ground, if you are still unsure about doing OAuth in C++. 
so, first of thanks for telling me about strict aliasing. Secondly, so that i make sure i understand it: char *ch = reinterpret_cast&lt;char*&gt;(&amp;int_value); float_value = *reinterpret_cast&lt;float*&gt;(ch); would not brake strict aliasing rule as i first cast it to a char* and than from one? Or is that still breaking the rule? BTW: why does the above code not produce an error, but if i write it in one statement i get an error from gcc with `-fstrict-aliasing -Werror=strict-aliasing` active?
The Python C API and distutils, for the most part. It's well-documented on Python.org.
&gt; I suspect the largest thing that might change coding style would be fold expressions I don't think I am going to see many of those. I believe structured bindings have a greater chance to change the coding style profoundly. I see them replacing the idiom of having by-ref out arguments to implement functions with more than one return value.
It runs the risk that you miss one. Of course memset runs the risk that someone adds a std::string later. Both cases are not nice to debug. 
The main ones I see are swig/sip and boost.python/pybind11. I wouldn't recommend building the module completely by hand using the c API as there is lots of boilerplate.
Embedding a Python interpreter to allow users to extend an application or for user macros is reasonable.
I am one of those people. We also work on C99. I do, in fact, hate every minute of work.
c++03, you're in the new age. I'm maintaining win32/MFC.
&gt; assuming that the compiler is able to correctly detect which branch occurs more frequently This assumption isn't necessary, modern CPUs have branch predictors that learn whether branches are likely to be taken based on past executions. The main benefit of things like `unlikely()` is to keep the likely code path in a smaller area for the cache benefits, not as a hint to the branch predictor.
&gt; non-use of available libraries What do you mean by this? Where is non-use of available libraries implied?
But it's modern!!!1one
Definition checking seems like something that could come out in a later standard from concepts without any negative impact. Is that the case? I feel like that would be the way to go. And having concepts already in the standard might provide additional motivation to get a working design for definition checking.
&gt; To be pedantic, you cannot reach this conclusion if don't discuss the probability of having a mispredicted branch. To be pedantic, when dealing with probabilities as small as 2.5e-18 it is perfectly reasonable to ignore them entirely. 
Except the branch might be mispredicted in majority of the cases if the branch is taken truly randomly.
C++17 is quite underwhelming in terms of scope. It's a candy release in my eyes. Don't get me wrong, I love candy, but there aren't many ground breaking changes. If Mr. Stroustrup gets his way, C++20 will be the one to look out for. Nothing you learn is ever obsolete. At worst, you'll have gained new abilities or new ways to think about problems.
C++17 doesn't really "change things", per se. There are a few changes (like the removal of `std::unary_function` and `std::auto_ptr`), but those have been deprecated for years, and were discouraged from being used in C++11/14 anyways. And the few other ways in which C++17 changes things are unlikely to affect a novice programmer. What C++17 is doing, mostly, is adding new features. `std::optional` (*might* contain a value), `std::variant` (type-safe `union` with library support for "visitors" which contain all the logic necessary to handle the possible types), and `std::any` (allows for heterogenous data structures) let us express some new behaviors that we didn't have standardized before (and had to rely on boost or hand-roll our own solution), and are the features I'm really looking forward to. `std::variant` in particular is really interesting to me, as I've already made use of it in an event-handling library I'm writing, where the ability to express a polymorphic relationship between different objects without expressly declaring them a sub/super-class of some other common type has been extremely valuable. I recommend you look at the other resources that have been put out, discussing the changes in the C++17.
and if the history length is longer than that of branch history table edit: for some implementations of branch predictors. latest research makes use of perceptrons, etc.
Your definition of "pedantic" is different from mine, apparently. 
&gt; structured bindings For the Core Language and most users, I agree. For library programmers, `if constexpr` will be life-changing. Fold expressions are nice to have.
That is still breaking the rule, and is just begging for alignment problems as well. The rule allows you to actually _read the data_ through a pointer to `[unsigned] char`; just casting to one of those types and then to some other type without any _read_ occurring does nothing.
Thanks, for the clarification. One last question: If i cast to a char* (and make sure that i only write at places &lt; sizeof(orig_type)), am i allowed to write to the char-array, or would that also be undefined behavior?
Not the worst idea. But - is Qt not using libpng &amp; stuff behind the scenes? Did they really write all they own loaders? If it's using libpng &amp; stuff as well, it doesn't help. And Qt is LGPL.
It helps because you don't have to deal with libpng &amp; stuff yourself, and that was your whole point - right? Qt is LGPL if you choose it to be. Or GPL if you choose otherwise. Or commercial.
&gt; For the Core Language and most users, I agree. For library programmers, if constexpr will be life-changing. Fold expressions are nice to have. The whole `constexpr` sub-universe got significantly improved with features that play well together: `constexpr` lambdas, `inline` variables (just put pre-computed global constants in header-only libs), an almost fully `constexpr array&lt;T, N&gt;`, and the first slew of `constexpr` algorithms (`min_element` and cousins). Now we need the rest of non-allocating parts of `&lt;algorithm&gt;` to follow suit! 
98... kill me Edit, we are planning on moving to 11 in the not too distant future. 
Structured Bindings struct { int x; string str; } Stuff; Stuff makeStuff(); auto [ i, s ] = makeStuff(); i++; cout &lt;&lt; s; if-init - note the `;` inside the if condition if (auto stf = makeStuff(); stf.x == 17) cout &lt;&lt; stf.str; combined: if (auto [i, s] = makeStuff(); i == 17) cout &lt;&lt; s; That probably covers most typical questions of the form "what is that syntax?". There are other syntax changes (template deduction, folds, etc) but they are fairly natural - you will probably understand them without thinking about it. There are lots of new library types, but just like any code you look at, there are always types to understand, so hopefully they are fairly clear when you see them. more at https://github.com/tvaneerd/cpp17_in_TTs/blob/master/ALL_IN_ONE.md 
Oh good lord. They say in ten years half the jobs in the world will be gone. I am not going to pretend to offer job advice, because I cannot think of a single profession that will be around in those ten years, much less be lucrative. I can only tell you how to become a good programmer. Unlike what some people say don't learn category theory. Half of mathematicians hate category theory, you think any programming discipline which depends on programmers who have more mathematical rigor then the pros would take off? Beyond that I would learn algorithms and general computer science to the point that you understand what O(N) means. Beyond that I would spend time learning design. Page Meiller-Jones is the person to read there. Debugging techniques, which I fear that you will have to just invent. Generic tools: profilers, memory inspectors ( like valgrind ), version control and the rest is just practice. Do learn set theory if you do not know it already. 
This is a very narrow use case, though.
Ha... damn auto correct :p
They also say in 10 years only 1/3 of programming jobs will be filled, so yeah
Look at the Stack Overflow list of C++ books. There are a couple of good options to learn C++ on it. http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list#388282
For the interesting jobs you will probably need a degree. You will find all the information on how to learn C++ programming in the sidebar.
The situation is dire. The new `enum class` is even worse than a regular `enum`, because there isn't a use case to use it cleanly. You bypass 'safety' anyway to get iteration and other things.
If you haven't done any coding at all then C++ may not be the best language to start with. A common easier starting language is Python. Obviously up to you but there is a (million) reason(s) C++ is almost never taught to new undergraduates as the first language.
You need to learn the basics of C++ before you can understand all these changes, so don't worry about it.
I mean if he really wants to do it he can try. C++ is one of the more difficult languages to master, but it certainly is possible to start with it. Personally I started with C, which lead to an easy transition to C++.
libstdc++ uses the identity hash, MSVC does not. I don't know about libc++. It's a trade-off, as the identity hash has its downsides. Imagine for example that you are dealing with operating system handles as the keys in hash table. In some cases, such as on Windows, kernel handles are always multiples of four, i.e. the two least significant bits are always zero. (Actually, it's more complicated than that; the OS is doing the user a favor here, in that it just ignores the two least significant bits, and they may be used by the user for any purpose. Most programs don't have a need for that, so in almost all cases the bits will be zero.) Anyway, that means that if you used an identity hash, the effectiveness of your hash table has just been reduced by a factor of four, i.e. three out of every four buckets can never be used. That could lead to a serious degrade in performance. And you can imagine other scenarios where user-provided data is used as keys. Using the identity hash requires that the lower 'n' bits of that data is distributed well, but that's often not the case. Using an actual hash will mix around the entropy of the upper bits and fold it all together, so that the resulting lower bits are higher quality. 
Thank you very much!
You mean COBOL? (The language itself *loves* Caps Lock) 
Exactly, that's why some folks are pushing for concepts now rather than waiting. :) There's also a lot of benefit _right now_ from concepts that we'd be missing out on if we waited, like concept overloading. The counter-argument is that definition checking will be potentially be much harder to add later than doing it up front, which is true for just about every feature IMO. For instance, without definition checking in now, there will be concepts-using code that compiles and works despite using under-constrained concepts and which would fail with checking enabled (e.g., a template that requires a `Forward_iterator` concept but uses them like random-access iterators, and just happens to work because the user only ever supplied random-access iterators to that particular template). Adding definition checking will thus likely either require breaking valid concept-using code or it will require adding some new syntax or markup to conditionally enable definition checking (which is annoying because it's yet another case of something that should be on-by-default once it's there but would have to be off-by-default for back compat). My personal take is that the concepts wording should allow for optional definition checking diagnostics in some form (e.g., by just saying that the use of under-constrained concepts results in unspecific behavior) and maybe a few incomplete examples of diagnostics in a compiler, but I'm not knowledgeable enough on the current paper to say for sure how reasonable that is.
Well I'm just saying you don't necessarily have to go all the way right away - there's a first step possible.
yup! not really!
Do you make much use of inheritance? Perhaps even multiple inheritance? Template code can solve some problems at compile time that could also be solved later at runtime using inheritance and virtual functions. 
I tried Python and Visual basic and I personally found both much more confusing than c++ so I think whether or not a language is "easier" really depends on the user. I would say however that everyone else I know who tried both found Python easier so maybe try some basic stuff with multiple languages and find what one works best for you.
That's a good point. I didn't consider the case where the user's domain would be a small(er) subset of the full `size_t` domain. In those cases, you would need to add entropy to make the hashes higher quality. Thanks for the reponse!
Why not find another job?
You're welcome. Feel free to PM me if you want. 
Optionals will be a big change for me at least, they seem like a pretty decent choice for functions that can return nullptrs and should help enforce better/strict guidelines for things that can be null, even just on an informational api documentation level (hey this might legit be null!) I guess its not huge. Still super useful though
That would be the mighty and modern us government
Hm, I didn't know C++ was rare as a first language. My school (University of Michigan) teaches C++ in its introductory programming class with a little bit of Python tacked on on the side.
I'll be happier when we get consensus about monadic interfaces. Optional ought to be able to short circuit, so you ought to be able to work with functions not expecting a std::optional, lifting them up so that out get the function value if it's there, and empty without the function being called if its not. And I wish we had a less scary word than 'monadic' for 'composes sensibly'. 
I don't think that's at all true. Definitely not the places I have worked.
we have different definitions of professional.
&gt;Modern functional/bind style callback instead of C-style function pointer. Example uses a function pointer.
Modern in what sense? If it's in the "modern C++" sense, a cursory read of the source code suggests it's *very far* from modern.
Thanks for your attention. "Modern C++" here means using C++11 features, e.g. lambda, functional/bind, shared_ptr and so on. Maybe I misunderstand something.
Literally, all the examples on the Readme page.
It really depends on what you're doing. Some of my work uses templates, and some of it doesn't. I can spend months without touching template code depending on what I'm doing. There are lots of situations where you don't even need to use templates. Are there relevant use cases for templates in your codebase? Try looking for places that might benefit from function templates. Then move on to class templates.
I agree with this. It doesn't even seem to use fixed-size integer types, so not exactly portable. Furthermore, it links libraries using the preprocessor. And for some reason they have their own `Duration` class instead of using `std::chrono`. Additionally, it doesn't use modern CMake. Also there are quite a few comments and commit messages written in mandarin. This a reason alone to not use it, as if I had to ever fix an issue I encounter, I might not be able to understand the source code and the comments wouldn't be of any help either.
I agree with you, I'd like to see some benchmarks that compare it to other available libraries.
Thanks very much. In the readme.md we expolained `Duration` problem. We do use CMake. The comments written in mandarin problem will be fixed in the future. `fixed-size` problem I don't get it, sorry.
As a c++ beginner (who just finished P:PP by stroustup with c++) what is the way to learn all these extra libraries? Just choose one and read the docs?
You need to do a benchmark before claiming "high performance" in the title. Multi-threading and non-blocking I/O do not make a library magically faster. I have seen dev using fancy technologies but getting fundamentals wrong, which leads to worse-than-usual performance instead.
Definitely. Of course, library programmers and "non-library" (for the lack of a better term) programmers are going to like different parts of C++17 most. However, even if library programmers may use little of structured bindings, they are still affected by them, since their mere presence is going to influence the design of library interfaces. 
stdout is line buffered if outputting to a tty, so you wouldn't need to flush to "see" output. If your stdout is a file or pipe then it actually does have a significant impact. using an entire namespace is not trivial. Idk everything in namespace std, and I've seen students actually get really confusing compiler errors when unknowingly causing a conflict.
Don't learn "all these" libraries. They are just too many. No one lives long enough to learn them all. Only choose one or two long-standing, high reputation libraries to learn from. Or learn it only when you need it.
&gt; There are lots of people still writing and maintaining C++98 code (although I'm sure a fair portion of them are hating life for being under those constraints.) Doing that for a living. Can confirm. Cannot wait for the project (a big combat system for Spanish Navy) to get up to date with the times. At least I can use boost. :|
He's referring to using "int", and "unsigned int" instead of the explicit sized version: "int8_t", "uint8_t", "int32_t", "uint32_t", "uint64_t" and so on.
&gt; In the readme.md we expolained Duration problem. There are units such as `std::chrono::milliseconds`, `std::chrono::nanoseconds`, etc. You would use `std::chrono::duration` and then convert to units you desire in your function. &gt; We do use CMake. I didn't argue against that. Except you use **old** CMake. Newer CMake versions use commands to set compiler options, flags, includes, etc in such a way that they work better across different compilers and don't influence other projects' options when building a library/executable lower in the current build tree. They also make the build files much more reasonable to both write and understand, in my opinion. &gt; The comments written in mandarin problem will be fixed in the future. Good to hear. &gt; fixed-size problem I don't get it, sorry. As mentioned in another comment, I mean fixed-size integer types such as `std::int32_t`, `std::uint32_t`, etc, that are found in the `cstdint` header. Since different type sizes can vary between compilers and platforms, this will ensure your types are the same size on all systems.
**Company:** [Sharp Reflections GmbH](http://sharpreflections.com) **Type:** Full time **Description:** Sharp Reflections is a fast-growing technology provider to the oil and gas industry. We are the first commercial provider of Big Data technology for seismic analytics. Our tools dramatically reduce the time required to process and analyze huge datasets, and improve the quality of the pre-drill reservoir predictions. We’re building a world class technology company to meet the needs of a growing global client base that includes several leading international energy companies. Pre-Stack Pro, our flagship software product, leverages HPC compute technologies to process and analyze huge 3D seismic datasets used to target oil and gas wells. The developer will work in the core team that develops both the front and back end software components. We offer competitive salary and a great work environment, where your contribution will have an immediate impact on business results. You will join a young and highly motivated team working in an agile development process. Flexible working conditions and a self-driven team await. Specific tasks include user interface design and implementation, scientific data visualization, integration of geophysical algorithms in close cooperation with domain experts and system administration. **Location:** Kaiserslautern, Germany **Remote:** No **Visa Sponsorship:** No **Technologies:** Required: C++98, move to C++11 or 14 soon, using the Intel compiler and building using CMake. Platform is Linux. Experience with at least one of the following: Linux/UNIX system programming, multithreaded programming, HPC technologies like MPI, GPI, etc., scientific visualization e.g. using OpenGL, last but not least Qt. Experience with UNIX system administration. **Contact:** Please send your application to matthias.decker@sharpreflections.com
How much do *you* want to write code for?
Don't dive into other libraries quite yet as a beginner. Try to use all the given tools at your disposal to the fullest extent. But honestly, the best way to learn new libraries is to read the docs. The most popular third party library for C++ would be Boost, but once you read those docs you'll see how easy it is to get overwhelmed. 
What kind of hacks you have which could be solved by reflection or concepts at the same time? 
I think you've got a point in your first part, I'll think about that. As to the second part, you know, these are all valid questions, but it kind of had me chuckle while reading it. Not because your text, but because in C++ all these problems exist and have to be solved perfectly, that don't even seem to be there in other languages, or they somehow managed to deal with it. I'm sure we have to discuss about these details but the fact is that in Java you can just use java.ImageIO and it works (tm). (and that doesn't have much to do with the VM I think). So why can't C++ just do it? In any case I agree with you it's probably best in a library, for example Python can't "natively" read images either, you need PIL, Image, or other library packages to do it. In C++ we do not even have that, we have to resort to C libraries and have to deal with all their cruft. Btw regarding who uses what funtionality, we can as well argue that many programs will never open a network socket, or an iostream, or never need to compute a cosine, yet this stuff is in the standard library. There's no clear line to draw.
I hope we would see more of fancy print/log functions, e.g. `void Log(T... t) { (log &lt;&lt; ... &lt;&lt; t); }` instead of `LOG() &lt;&lt; a &lt;&lt; b;`
OK, I got it. I really think this library is a modern C++ project. Maybe I misunderstood something. Please give some Modern C++ example projects. I go to learn how to write modern C++.
Thanks. Can you give me some modern C++ example projects?
can you do some like following with constexpr? class X { if constexpr (PLATFORM_A) { TypeA a; } else { TypeB b; } } 
One more good use case is where proper reflection would be used otherwise.
Thanks.
Very, very true. Increasingly an all synchronous design is becoming competitive for some workloads e.g file I/o on low latency storage you're far better off not using async. Also, libevent is not the fastest of its kind out there. Many alternatives are faster in absolute terms. Libevent at least has competitive scaling curves, unlike libuv for example.
How does it compare to boost::asio and beast http library?
The `log4cxx` memtioned here are using `SocketAppender` instead of `FileAppender`. Yes, we know there many network libraries, but we do have some old applications which are based on `libevent`. So use `libevent` to build our library is easier to integrate.
So, the thing that changed my opinion of optionals from 'eh' to 'ooh' was someone saying that they're actually probably more useful at an api boundary rather than a type you should actually *use* as such generally EG this function returns optional&lt;T&gt;. You don't then use the optional returned repeatedly in your code later anywhere, you just do if(!whatever_optional.has_value_whatever()) handle_error(); then just use the raw value after that In that sense, I think its actually beneficial that optionals *aren't* implicitly convert-able, because that's the whole point of an optional. You would never pass an optional into a function that expects a value, because it doesn't make any sense for you to have an optional in the first place. It should be checked, then ditched
Over a million per second every second of the day? Across how many computers and cores is that, and where are all those requests coming from?
Thank you so much, I'll look into those options!
https://github.com/isocpp/CppCoreGuidelines
&gt; How does it compare to boost::asio and beast http library we will give some benchmarks in the furture. Now we only have the benchmarks of `evnsq` and `evmc` against `log4cxx` and a internal async memcached library.
I hadn't considered this option, but you're absolutely right. And better tooling would be much appreciated! 
It looks like NO. Here's a good article talking about what ifdefs "if constexpr" can be used to replace: http://blog.tartanllama.xyz/c++/2016/12/12/if-constexpr/
When you start using them, you get addicted! In our codebase, components rarely expose function that takes pointers. Abstract classes, pointers, classes hierarchies are all considered as implementation detail of a component and should not be exposed in it's public interface. If there is a base class in the public interface, they are usually without virtual function. Of course, templates are needed to do that, but it's totally worth it!
Those aren't benchmarks, those are optimizations. Benchmarks are essentially **comparing your library's performance to other libraries**, by having them do the same task (usually averaged over lots of times) and comparing the time each one takes. You need to prove that it's faster or at least comparable to the alternatives, to claim that it's "high performance".
True but having a mindset of a C# programmer and trying to learn C++ is hard especially when you automatically assume how certain things will act like and it doesn't work the same way in different platforms.
Release Notes: https://www.visualstudio.com/en-gb/news/releasenotes/vs2017-relnotes
If evpp was inspired by another open source networking lib Muduo, why didn't you guys just fork then develop based upon that? You can contribute back by merging your features/functionalities.
First of all why do you care about the size of your integers?
What is the reason for implementing own Duration class instead of using std::chrono::duration?
For those curious about pricing: https://www.visualstudio.com/vs/pricing/ Edit: the Community version is indeed free; sometimes you may be tempted to upgrade because a paid version has an extra feature you need.
Does anyone know what version of Clang the "Clang / C2" option ships with? AFAIK Visual Studio 2015 shipped with Clang 3.8, did they update it to 3.9? Same question about the CMake version, the 2017 RC used a custom CMake 3.6, but no info on whether they updated it to 3.7. Thanks! Edit: got around to installing it myself. Clang / C2 is still 3.8.0, and CMake is still 3.6.
Does it work with gcc 4.9?
I care about the min and max values. I care about serialization. I care about memory usage. There are plenty of good reasons. The fact that C/C++ have a bunch of vaguely labeled data types is one of my least favorite aspects. (Databases aren't much better with their `SMALLINT`, `TINYINT`, etc.) I recognize the need for loosely defined types (`size_t`, `intptr_t`, etc.), but I have a much greater need for carefully controlled integers.
Using it for months now -- has been great so far. Only a few minor issues with the RC few weeks ago which were solved quite quickly (since the Repair functionality actually worked for us!). Recommended! Thanks STL et. al. at MSVC.
&gt; __int32 to specify a specific int range so it's compatible and predictable in all compilers. Anything that starts with a double underscore is not compatible or predictable on all compilers. The meaning of double underscore is actually "this is an extension to the standard" and should be avoided in portable code. If you need a 32 bit signed integer, use `std::int32_t`(this type will not be defined if it isn't natively supported on the platform) or `std::int_least32_t` from [`&lt;cstdint&gt;`](http://en.cppreference.com/w/cpp/types/integer).
I do the same, i never use short/long/long long, only int and fixed-width integer types.
TI's MSP430 compiler for its embedded microcontrollers has `short` and `int` as 16 bits and `long` as 32 bits and `long long` at 64 bits.
Bug! #include &lt;emmintin.h&gt; namespace xyz { static inline __m128i foo(__m128i a, __m128i b) { return _mm_and_si128(a, b); } } 1&gt;c:\code\xxx\test.cpp(71): error C2668: 'xyz::_mm_and_si128': ambiguous call to overloaded function (compiling source file ..\\source\test.cpp) If I call intrinsic function in a namespace, it gets decorated by that namespace! Workaround: ::_mm_and_si128(a, b); ... 
The article shows the case with the vector constructor (std::vector&lt;int&gt; v(2, 1); vs std::vector&lt;int&gt; v{2, 1};) , which can lead to nasty bugs. This is also one more thing to be aware when checking if someone has not inserted voluntarily malformed code to exploit it later.
I look at this as legacy issue. Today almos every machine is x86 and the rest are ARM. New languages like rust have fixed width integers, only c and c++ does this "write program where you dont really know how big the int is and if you mess up its UB" Important to understand, its not the compiler thats causing the change really, its the target arch.
Replying here for visibility: I'm French and so the link redirected me to https://www.visualstudio.com/fr/downloads/ which is fine, I guess. However, there are some very poorly translated bits. For exemple "Build should be translated by "compilation" and not "génération". Get someone on that if you can ! Thanks !
Fair reasons :-) Good luck to you and hope you can find some enjoyment in your job nonetheless from time to time!
If you got the RC Installer already installed (the new one), can you upgrade the installer and upgrade RC and everything from there? Or would you recommend uninstall &amp; reinstall everything?
And if anyone missed it, the STL's more detailed changelog: [Part 1](https://blogs.msdn.microsoft.com/vcblog/2016/08/24/c1417-features-and-stl-fixes-in-vs-15-preview-4/), [Part 2](https://blogs.msdn.microsoft.com/vcblog/2016/10/11/c1417-features-and-stl-fixes-in-vs-15-preview-5/), [Part 3](https://blogs.msdn.microsoft.com/vcblog/2017/02/06/stl-fixes-in-vs-2017-rtm/).
I'm sorry, currently only compilers with full C++14 support are supported which excludes GCC 4.9 (see an online compiler example here: http://melpon.org/wandbox/permlink/AZwFrnQUCip2ygaz). The library supports GCC &gt;= 5.0. However, I'm open for pullrequests which improve the compiler compatibility - GCC 4.9 support should be feasible.
You can read more about it here: https://blogs.msdn.microsoft.com/vcblog/2016/10/05/faster-c-solution-load-with-vs-15/
I wouldn't recommend a using directive for any large namespace, std is just the one that always show up in examples (obviously). `using namespace boost;` would be worse. Ideally yes all c++ programmers would know all of std, but there's just so much in it that it's not realistic. using declarations are fine within non-header files since they don't dump everything, and though I rarely use them I don't discourage their use. Verbosity is fine and good if it gives clarification, it's bad when it's redundant.
Why do that in runtime? A `static_assert` will work for that at compile time.
Even if certain implementations exploit this (see /u/Rhomboid's comment) you can't/shouldn't depend on it, so it's not really useful/meaningful knowledge. Also: Before you go implementing small optimizations, measure. If your hash algorithm is simple then the performance hit of implementing a check and branch is probably larger than the performance gain by not hashing the upper 64 bits.
Still don't understand specific use case. You usually use ints to count stuff in vectors, so it's just `size_t` and difference types that are defined by the containers. Other use case is serialization and binary protocols - you use `uint32_t`, `int32_t`, etc there.
Nope. From what I understand they are not doing ISOs anymore due to how third party software can also be installed which makes redistributing those installers difficult due to license agreements, etc. You can create your own offline installer using the --layout switch though. 
we did a LOT of work on acquisition so I hope you will find that things are better. a) many formerly required things are now optional so those won't end up elsewhere unless you choose them. b) many things should be in the new directory layout. That being said, in some cases we lay down things that are not VS and have to respect their install dirs. Let me know which are the worst offenders. 
I just recorded an episode of GoingNative on the history of the team. Believe it or not, the versioning stuff has been worse in the past :) 
this is really nice to hear. Thanks for sharing. We appreciate it. - Steve, VC Dev Mgr.
std::wstring is 2 bytes on windows/msvc libs, 4 bytes with other libs -- same underlying target platform, just different 'standard' libs. Count your lucky stars std::string is the same everywhere (I think...) But I get what you're saying... Generally though, after the 'school' phase, the main gripes about c++ usually amount to "I want a real base class library. Why can't I do anything useful in this damn thing. There's only so much that std::vector and std::string provide. What about networking, json and xml handling, zip file processing, security primitives for access control. Oh there's a random assortment of libs for that, each written in a random dialect/style of whatever 11/14/17 variation their authors preferred? Fine... how do I reference them in my nice project over here... oh my god you're kidding right?!"
Second this. We've been building/testing `build2` with RC's for several months now without any regressions compared to 14U3.
Thanks for all your (team's) hard work!
I just recorded an episode of GoingNative on the previous versions.
We are a small indie game dev team, which means we have very little time for developing our own infrastructure, libraries and many other details that are usually handled by dedicated people in big companies. With all the small improvements you are doing here and there, plus compiling C++14 as closely to the standard as possible, as well as supporting third-party software/platforms like Python, Git, GitHub, Boost, etc., you are basically enabling us to get the most out of our time developing and ultimately delivering the best game we can possibly make for players' enjoyment. We have worked in big products/companies in the past and we know it helps to hear from time to time how every bit of work is helping other people all across the globe. Therefore, thanks a lot to all the team :)
Sorry to bother, but has anything changed regarding the plugin architecture? Do/Should plugins/addons from vs2015 work for 2017?
&gt; due to how third party software can also be installed which makes redistributing those installers difficult due to license agreements Didn't get this part at all. A bit more detailed explanation? How is the present scenario of "download files and make your own ISO" different from "directly download an ISO"?
ETA of the episode?
Out of interest, what strikes you as being not modern about the code?
Please list the architectures where a 32-bit integer has a different min/max than that of typical desktop PCs.
i'm sure people will be updating plugins now that we are at RTM, but of course there have been many prereleases for plugin developers to test there stuff on. I can't give a catch all answer, but I suspect many will work.
So I just added Xamarin and all the Android crap was put on the C: drive, up to about 20GB on C:. Pretty lame.
For example Sun don't allow others to redistribute the JDK which Microsoft install as part of their Android support. Using the online installer allows MS to use the JDK directly from Sun and therefore not upset Sun's legal team. If they were to provide an ISO it wouldn't be a complete ISO. By doing a --layout they can download the JDK installer in exactly the same way as the online installer. This isn't just an JDK issue though as MS offer several different third party packages in recent VS installers. So if you *really* want an ISO then make your own from the contents of the --layout download :)
Why would you assume that `int` is 32 bits? 
Not yet. They're still working on it. This is a feature where nothing will appear to happen while the compiler's data structures are gradually improved, and then the feature will appear fully formed as if from Zeus's forehead. (And it will have to be controlled by a switch due to the source breakage impact.) The STL is two-phase clean (verified by Clang) and we're working on cleaning up other libraries (e.g. ATL) in advance of the compiler changes.
Good to know, thanks !
I have not understood how to list major new and unsolved bugs. This one was pretty bad in the RC, but I hope it's now fixed: https://developercommunity.visualstudio.com/content/problem/15710/c-amp-gives-seemingly-incorrect-uninitialized-valu.html?childToView=22839#comment-22839 
The sync_server I wrote is based upon this example: http://www.boost.org/doc/libs/1_49_0/doc/html/boost_asio/example/echo/blocking_tcp_echo_server.cpp Edit: The definition of sync and async I'm using is similar to the one mentioned in [this article](https://msdn.microsoft.com/en-us/library/windows/desktop/aa365683%28v=vs.85%29.aspx). But I suppose we do have different definitions of synchronous. 
That is a good example to learn about blocking nature of I/O with ASIO, however it is not the *best* example to differentiate latency numbers between an asynchronous model versus a synchronous model - hence the name of the example uses *"blocking"*. Perhaps you can rename your sync_server to blocking_server? *(or something similar)* and probably rethink the latency graph and what it is supposed to convey. 
No clue. It stressed the async server enough that the client started having issues connecting to the server after 7,000 concurrent clients (the sync server was the same way). So thats why I stopped at 7k. Also both servers used around 100% CPU load, to the point where the QPS started going down the more clients I added.
Visual Studio is a full IDE. Sublime Text is a very sophisticated programmers editor that can be extended a lot with plugins but doesn't give you the *whole* IDE experience. At least not in my opinion. 
I'm not. I'm specifically asking about a 32-bit integer. I'm not gonna bother with inquiring about `int` when I can just grab `int32_t` and get what I want.
Does it work with SDL2 now? (without being a pain in the ass). 
&gt; Idk, my understanding of the software industry is that embedded systems is a small niche compared to everything else yeah, a small [multi-billion dollar niche](https://www.gminsights.com/industry-analysis/embedded-software-market)
&gt; I don't know a single compiler where int is not 32 bit Compilers for PIC are generally 16 bit for int. avr-gcc is 16 bit for int, and has a flag to put it down to 8 bit.
I already thought about it but decided not to take the capability for setting a global executor in as of now. Although this seems like a profitable feature its drawbacks prevail: * We would have to store the default executor even in type-erased continuables which introduces unnecessary size overhead. * Storing the default executor in the un-erased state could be possible, however it should behave like the erased type. * The question persists how we could treat the default executors when connecting several continuables. For the future, it's planned to upgrade the underlying type-erasure wrapper [function2](https://github.com/Naios/function2) to also support multiple signatures (overloading erased types), for mainly supporting error handling. We could also use this to implement the feature mentioned above. 
By the way, Steve Carroll and Daniel Moth from the Visual C++ team are doing a presentation now on the top 7 reasons to be excited about VS 2017 as a C++ developer here: https://launch.visualstudio.com/
Release announcements regarding C++ development tools are always welcome on r/cpp, from GNU to Microsoft. Especially for a major development environment like Visual Studio. It saddens me a little to see this sort of response. Microsoft and the Visual Studio team have made huge contributions to the community in the past few years. I generally find their presentation of their products to be tasteful and not at all pushy.
I haven't used Visual Studio since the late 1990s, prior to *.Net*. Although I wasn't a fan of the MFC framework, I liked the IDE. The download page at the other end of this link indicates that there is a version of VS freely available to open-source and independent developers. Can anyone who is familiar with the free version of the VS product, its license, and Linux alternatives share their perspective on using it for web development (PHP) and projects for target environments other than Windows? **EDIT 1**: Minor grammatical errors
Non exhaustively and in no specific order: - Doesn't always use RAII when it could - `NULL` instead of `nullptr` - Raw `new` / `delete` - `goto` for error handling - initializing PODs with `memset` instead of `{}` - uses the old anonymous `enum` trick for compile-time constants Other criticism (unrelated to "modernism") is that the code base is generally not very consistent / good quality: - Accepts pointers in plenty of cases where a reference is wanted - Lambdas freely mixed with `std::bind`s (sometimes just lines away from each other) - Superfluous struct keywords (this isn't C!) - Returns false (or worse, void) and logs an error when something fails (instead of a saner error handling mechanism) - Mixing of concerns (e.g udp client and socket do IP address parsing) - Two phase init - No wrapping away platform-specific details in their own layer All in all, I'm not saying it's a catastrophe, simply that in its current state I *personally* do not consider it representative of a good quality, modern C++ codebase.
but I have had visual studio 2017 for about 2 months now
&gt; SDL2 do you mean this? http://libsdl.org/download-2.0.php 
not fixed, but being worked on actively. thanks! EDIT: please upvote the issue if this is affecting you. Upvotes help us understand which of our release trains to use to deploy the fix once we have it.
oh yes a bunch of words I do not understand :D fucks a RTW not going google it. But yes it does seem I am running a RC build, so time to upgrade, Thanks for the info though.
Great write-up, write more! How about a fork per connection, and a 1 thread per connection model?
Hi /u/spongo2, when Visual C++ Build Tools will be released? I have tried the new installer and didn't see the option to install the c++ build tools, only community, professional and enterprise. EDIT: Never mind, i found it ;)
[removed]
 You don't need to prefix any of the types in `&lt;cstdint&gt;` with `std::`, either. That's because the type is actually declared in the global namespace (and either also redeclared in `namespace std` or else brought in via `typedef` or `using`). You should contrast `int_least32_t` against `int_fast32_t` from the same header. Remember, C++ is a *toolboox*. You don't use *every* tool in the toolbox to accomplish your goals... because you need to use the _right tool for the right job_. If you neither need to be _exact_ on the bit specification (eg, you're not dealing with data going on-the-wire) and you don't need to worry about "wasting" bits (because sometimes a 64 bit implementation might be faster than a 32 bit implementation), then... just use `int32_t`. 
I'll let /u/spongo2 comment on the CMake issue, but we are no longer using MSDN for documentation. We actually have a brand new site: https://docs.microsoft.com/en-us/visualstudio/ which will contain all documentation from VS 2017 onwards, as well as past documentation (we are working on porting it over to the new site). 
I would like my health monitoring devices to not overflow, thank you) 
I like how people continue to forget about embedded development, even tho, most of our real critical infrastructure is all about embedded devices. The "webscale" era exists only because said embedded... 
glad you found it! 
hrm... we actually use Dolphin for compiler testing, iirc. Let me ping some people.
totally depends on the selected options. I am given to understand that the Xamarin and Android tools are quite large. If you just choose the Desktop workload, it should fit. 
I posted a fairly detailed summary of the context of this here: https://www.reddit.com/r/programming/comments/5y0zu5/visual_studio_2017_released/demymfe/ TL;DR ISOs are a legacy from the days when you'd burn your own CD image, and the concept doesn't really work when tools and runtimes are distributed over the internet and changing every week. We've tried to replicate the use cases in the new installer. Best wishes, Tim Sneath | Visual Studio Team
The core of Visual Studio (the IDE) installs to the drive you select; unfortunately we're not yet at the point where other dependencies also follow suit. It's complicated because `%ProgramFiles%` has meaning. When you say install Visual Studio 2017 to `D:\VS2017`, where should we install the Android SDK? `D:\VS2017\Android`? But then if you install Android Studio, is it OK that we've installed the SDK to a VS subdirectory? And there's complexity in asking "which directory" for every dependency. We don't have a perfect answer. We're considering adding a directory for third-party dependencies as an "advanced" setting, but we haven't got a great design yet that works for the full diversity of Visual Studio users. All ideas gratefully accepted :) Warm wishes, Tim Sneath | Visual Studio Team
modern? like c++03 modern?
I know and that's great! For some reason, we had intrin.h included within a namespace and VS2015 was fine with that. VS2017 doesn't like it a bit. When I moved it out, it built! What is weird is that according to this documentation, we don't need any include for _BitScanReverse64 : https://docs.microsoft.com/en-us/cpp/intrinsics/bitscanreverse-bitscanreverse64 Yet, I get an identifier not found without the include (or well, in my case if I change the re-root the header's namespace...). As for the documentation, it was very convenient to have a quick way to navigate between Visual Studio versions to see what was supported and when, the new website doesn't offer the possibility as I can see yet.
Other people have mentioned it, but I thought I'd highlight it in a top comment: `#include &lt;cstdint&gt;` gives you integers of specific sizes namely `std::intN_t` for signed N-bit integers, `std::uintN_t` for unsigned N-bit integers. It also has types that are at least a certain bit-width (`std::(u)int_leastN_t`) though I personally don't like using them, types that are at least a certain bit-width but hopefully faster (`std::(u)int_fastN_t`) though I personally haven't seen the point, and a good amount more (see http://en.cppreference.com/w/cpp/header/cstdint). There is also `std::size_t` from a bunch of headers (`#include &lt;cstddef&gt;` for example) which is guaranteed to be able to address any element in any contiguous set of data (basically any array including dynamically allocated ones). **tl;dr:** `#include &lt;cstdint&gt;`, `#include &lt;cstddef&gt;`, use `std::(u)intN_t` for integers when you know the size you want, use `std::size_t` for integers that address arrays (including `std::vector`s).
OK. So I decided to give up. I canceled the offline installer and tried deleting the folder. And... its continuing to download stuff even though I have closed it. What is the process I need to kill to get it to stop? \* Is it the "EmulatorSetup.exe" process? 
I can at least tell you a bit about the PHP (web) development inside VS. I make heavy use of Devsense's PHP Tools extension and have done so for a while. The extension is constantly improved and has satisfied my PHP needs wonderfully for the past few years. I know they also have a lot of effort they've put into framework support and you can even use xdebug inside VS to an extent with the system now. It ended up being worth the cost to allow me to (mostly) stay inside one IDE 90% of my days.
The author mentions the advice from uncle Bob almost at the end: just avoid *boolean* parameters! (I have never heard *toggle* parameter until now) On the other hand he almost found the right solution: package parameters into objects (might be a struct or class), but with **named ctor** as it is called in C++ land... other call it *fluent builder* or alike. Then the signature of the function becomes readable ``process_with(const configuration &amp;)`` and the construction of the configuration object too: configuration.new().withFlagA ().withFlagB().build() 
&gt; as someone who has no experience with rsync Hm, I haven't thought of such a possibility ;-). Seriously, though, thanks for the feedback. I am sure everyone is familiar with plain shell/glob patterns (`*.cpp`, `*.?pp`). `rsync` just extends it slightly with things like recursive matches (`**.cpp`). &amp;nbsp; &gt; Make's patterns are more straightforward although they also use custom-to-Make syntax. I am not sure which patterns you refer to here. If that's the `$(wildcard)` function (or in prerequisites list) then it is plain old shell/glob pattern. If you are talking about things like `$(patsubst)`, then yes, it is a custom, fairly limited pattern substitution syntax. The feature we are talking about here is equivalent to `$(wildcard)`. For the other one we will surely use regex, no questions about that. &amp;nbsp; &gt; Why not allow plain old regular expressions? Hm, I see two immediate problems: 1. For the common cases the shell pattern will be clearer and more familiar. Compare: `*.cpp` vs `.*\.cpp`, `*.?pp` vs `.*\..pp`. 2. We still need a mechanism to distinguish recursive/non-recursive search. 
Yeah, escaping dots would be horrible. I am probably a bad source of ideas here.
whoops you're right, I read the code too quickly
Sucks that live unit testing is only for enterprise!
OK, no problem. Probably Windows since it was showing up as Windows 10 Emulator in task manager (My box is Win 8.1). It looks like it hung after I canceled the download process, but was easy enough to kill in task manager.
Installed, switched my VS2015-based project to v141_xp and got a clean compile and run with no issues... so nice job, installer/compiler/library teams. To fix the build log being polluted with huge command lines: Text Editor &gt; C/C++ &gt; Experimental &gt; Enable Faster Project Load = False Still haven't found a way to completely get rid of the start page or the Add to Source Control button. 
And here I am, with my Community Edition 15
So outdated it is painful to go back to a codebase written in C++98 after using C++11. *However* Accelerated C++ and Effective C++ are still amazing books to learn from. You still learn a lot from those books, some areas might be outdated, and they may teach you workarounds for language limitations which are no longer needed with C++11, but the tricks and workarounds will still teach you the nuances of using the language. Most people here learned C++98 before learning C++11 and 14 and will soon update to 17. I'd say you'd gain maybe 10% or 15% efficiency if someone were to update Accelerated C++ to C++14 and you start learning from that, the rest of the 85% or 90% is still valid.
What's the problem of having small subsets like avr-gcc C++ does? It's still modern C++ for micro-controllers.
How do you enable them? Mine just doesn't recognize the import line.
Tip: if you have the SDKs already, then just set the path inside VS2017, I wouldnt redownload it.
I still recommend to use good-old syntax because of all of these traps. Especially when dealing with initializer_list's or POD data. Using brace initialization everywhere is a no go to me.
Got it. Thanks.
We explained in the readme.md. Based on libevent is preferable for our projects. Given your older applications were based on libevent, it was preferable to have your new framework also be based on it, so as to reduce the overall time/effort/cost to completion. Actually, we do have some older applications which were based on libevent. 
I don't see them disagreeing. The first quote there states that there is a word we use when a pointer's value is the address of A. The second quote states that it's not valid or safe to make pointer values out of thin air. The first quote is about words we can use. The second is about safety of pointer values. They're completely different things.
Yeah I am probably reading an outdated book.
How do you use the new CMake support with clang/c2? I cannot find how to do it.
I don't code to hypothetical platforms. I code to reality. Do any of the mainstream platforms abandon the standard 2's complement format for integers? Desktops? Laptops? Smartphones? Game consoles?
Yeah, those hypothetical IBM platforms. 
Especially not for C++ I feel. Have yet to find a plugin / syntax coloring scheme that takes into consideration custom types and completes nicely within scope etc.
Please look at the original conversation and the context - we talked about int type. int32_t is indeed fully standardized in its width and representation. As for int - people already provided below the archs where int is not 32 or even 64 bits. 
Why not [XPath](https://www.w3schools.com/xml/xpath_syntax.asp) ? It's quite standard and made exactly for these problems.
My brain legitimately thought for a few seconds that you just referred to yourself in the third person definitive. The Sean didn't judge. :p
We should also clarify that Live Unit Testing is only available for .NET, it's not a VS-wide feature. 
Been using SDL2 in the the RCs for months, no problems or (new) pains at all.
the cl.exe versions *are* the sane one. It is a monotonically increasing number :)
&gt;If you have access to C++11 I must be reading my calendar wrong it says 2017. Seriously people this is as fucked up as the Python 2 vs. 3 thing at this point.
&gt; You don't need to prefix any of the types in &lt;cstdint&gt; with std::, either. That's because the type is actually declared in the global namespace (and either also redeclared in namespace std or else brought in via typedef or using). Really? &gt;In the C++ standard library, however, the declarations (except for names which are defined as macros in C) are within namespace scope of the namespace `std`. It is unspecified whether these names (including any overloads added in Clauses 18 through 30 and Annex D) are first declared within the global namespace scope and are then injected into namespace `std` by explicit *using-declarations*. §17.6.1.2 [headers]
Any architecture that uses 1s complement signed representation.
I tried to use that, but unfortunately CMake doesn't seem to find out configure the toolset properly. I'll try with the release.
In that case, it makes total sense because you explicitly want that type to expand with system limits and definitions. Of course, I still wouldn't use a raw `int`. That's the kind of place I'd use `std::size_t`. However, imagine something like a cross-platform TIFF image library. Lots of indices and values are specified with a certain integer size, and a library is responsible for reading and storing that size regardless of the system's word size. I feel vastly safer writing code that refers directly to `uint64`, knowing that the compiler authors have defined that correctly, than a bunch of macros and typedefs that attempt to detect and abstract word size.
**THIS ^** Visual Studio has name changes and marketing people and superstitions (they skipped 13!) and crazy numbering. MSVC just counts. Up. One by one. Like sane people do.
Now that the committee meeting is over, we'll have a blog post coming out on the standard library modules. It won't be published this week but it should be soon. They should work on x86/x64, debug/release but note this is a *very* experimental bit of IDE integration. (They should work fine from the command line.) 
There's a section on the backend in this blog post: https://blogs.msdn.microsoft.com/vcblog/2017/03/07/msvc-the-best-choice-for-windows The optimizer team has been building on the new SSA framework. It's lots of little improvements that add up, but not easy to describe in a blog post as a cohesive whole. If you'd like to see another comprehensive roll-up I can try to get one underway. Note that we really can't talk about a lot of the most interesting researchy stuff we're doing in security. 
Than we are in agreement. Of course I would like any kind of serialization to be cross-platform, so I would pick the platform independent type representation. My main point is - it depends on what are you doing.
Is there any particular reason to use such an old compiler? Would like to see if there's a performance difference with newer compilers - for example with GCC7 and Clang 4.
&gt;My main use case for writing this is to assemble my header only Boost libraries into a single "drop in and go" file. This is one of the times and places where "*why do you want this?*" is a better "*answer*" than actually telling you how to do what you want.
In a corporation the size of MSFT, you can't simply expect everyone to agree on how to count. That's non-inclusive.
Thanks my man
some week I will actually keep count of the number of times I have to utter the phrase "STL... the person or the library?"
https://github.com/Microsoft/GSL/blob/master/include/gsl/span
&gt; then the feature will appear fully formed as if from Zeus's forehead. (And it will have to be controlled by a switch due to the source breakage impact.) /athena ?
I never really liked how much space VS asks for installation (about 10gb), is this fixed? I'm currently using eclipse for c++ developing and i will have to install VS in order to use C++ in Unreal Engine.
List the _specific_ architectures. I need to see if I remotely care.
What does it do with this? https://github.com/swansontec/map-macro My experience has been that despite what's written in the standard, `...` variadic macros are implemented one way in gcc and clang and one way in msvc. T_T Smaller, related example, described here: http://stackoverflow.com/questions/21869917/visual-studio-va-args-issue http://stackoverflow.com/questions/5134523/msvc-doesnt-expand-va-args-correctly If I were you I would hope that your preprocessor agrees with either gcc / clang, or with msvc, and doesn't create it's own third "camp" on this, or you may have a lot of problems with some boost headers, which are heavily doctored with preprocessor stuff. I mean some of them use boost::preprocessor, if I'm not mistaken, to try to guard against such problems.
Do others use GSL in their everyday work? I thought it was mostly meant to be a reference implementation. Or do people cherry pick parts of it?
I have no incentive to. Coding to the standard causes breakdowns down the line. Compilers aren't always standards-compliant. Sometimes the standard approach to something generates abysmal assembly. The standard is full of undefined behavior. And lastly, I really don't care about my code running on an obscure platform that doesn't use two's complement.
For even more fun, we could open up a satellite office in St. Louis.
&gt; The original proposal for array_view died because it became too complicated trying to work out how to handle multi-dimensional arrays while still providing a zero cost abstraction. Exactly correct. You can see a simple array_view implementation at https://github.com/mclow/snippets/blob/master/array_view.cpp
We use it where I work, but not extensively. We cherry pick pieces that we feel provide good semantics. I think the thing we use most often is the narrow_cast to be explicit, like when casting from an int to a uint8_t
I could repro it in a small test case, just invoking the x64 compiler over a test file and the header was required. Putting a namespace around it triggered the same issue. The issue isn't with CMake itself but due to you compiling our solution directly which uses a precompiled header, which includes a lot of things (cctype was missing somewhere and probably intrin.h was included indirectly). We don't have any on the CMake side as it didn't give any speedup as flags are changing all the time and I could sometimes trigger some annoying ICE. 
I would be interested in a comprehensive write-up of changes - especially about the changes since the last optimization post in May. And about SSA.
&gt; Will this (or other things from the GSL) ultimately end up in a proposal for the standard as well? Yes, see papers like [P0122](http://open-std.org/Jtc1/sc22/wg21/docs/papers/2017/p0122r4.pdf) (PDF of current `span` proposal targeting C++20).
You can alternatively set *PreferredToolArchitecture* as a **system environment variable** and the setting will apply to all MSBuild builds (from IDE or command line) on that particular machine. Specifying it in the project file has the advantage that the option travels with the code though.
"STL by STL in STL" Toss in the version number confusion and you might very well have a new perfect test case for natural language comprehension AIs.
Thanks for that great clarification. I've now even noticed that range-v3 contains an implementation of span! I can rest easy, knowing that everything is there for a reason!
good job! but still no structured bindings :(
Thanks, unfortunately it's got to go into the project file as our libraries fail to link (out of memory) with the 32-bit toolchain, so it's a requirement rather than a preference. Also, has the incremental linker maximum file size been increased in VS2017? We have to disable incremental linking in VS2015 which isn't ideal.
It says under "C++ Libraries" that &lt;any&gt; and &lt;string_view&gt; were added but I can't include them using Visual Studio 2017. Anyone know why?
"What 99 percent of programmers need to know is not how to build components but how to use them." -- Alexander Stepanov
You might try searching for Gor Nishanov's CppCon talks. The Coroutines TS documentation on cppreference might also be a good place to look.
I can understand. But libevent is preferable for our projects.
Perhaps you can use symlinks to get the files off your system drive.
Makes sense. Thanks.
I believe this is the link to that talk: https://channel9.msdn.com/Events/Visual-Studio/Visual-Studio-2017-Launch/220
That is great to hear. Looking forward to that blog post.
We use much of it
High performance- Show me the benchmarks! Any reason why I should use this library instead of Asio (Boost/ Standalone) ? 
Obligatory gripe about CUDA support. I'd love to use 2017, but can't.
Um, wait. We've been working with the folks at NVidia to make certain that this release works with CUDA. They've been verifying that every 2017 RC works with CUDA. If you have a failing repro, *please* send it my way! Edit: my mistake, please see below. Miscommunication with our friends at NVidia. 
Former; just the cout; and I can fiddle with the window a bit and adjust the font, but it's frustrating that there isn't away to just have a horizontal scrollbar (because that would be too sensible). It is printing to the screen of the console window if I'm using my terms right 
Right, so as I say, click on the output window's top left icon, properties, layout, and adjust "Window Size" width. You might need to set a breakpoint to keep the window open while you make the property changes.
Must admit didn't see this one coming. And still not sure if you are serious or just yanking my chain. In case you are serious: While I think you can make it work (by basically saying that half of the spec, like attribute selection, conditions, etc., does not applying), in the end, semantically you will end up with pretty much what we have. Just with a very odd syntax. In case this is a joke, I will see your XPath and raise you SQL ;-) SELECT file FROM dir/ WHERE file LIKE '%.txt' 
Why wouldn't one want conditions? Wouldn't that be half the point?
If you share before and after screenshots, I'm sure someone will be able to help.
Thanks! Many C++17 features are still in development. The standard isn't even published yet : )
Thanks ! I sure will have a look on the talk.
Can you show a realistic example where an XPath-like condition would be useful while looking for filesystem entries in this context?
That sounds quite good, thank you very much for this insight! I hope the multidimensional case will not be forgotten - it's always a risk if there are one or a couple of people championing it, and then it takes too long a time, the person stops working on it, and nothing happens anymore. Let's hope the best! :-)
A lot of Danish banks are running COBOL actually.
I use both concurrently. Also very few people using the GSL use Microsoft's GSL, they use one of the GSL clones. I personally prefer Martin Moene's https://github.com/martinmoene/gsl-lite as it's C++ 98 compatible and very tightly implemented, much less splosh than the Microsoft GSL. But there are additional GSL clones, each with strengths and weaknesses, Martin actually provides a big tick box comparison matrix at the bottom of his Github page so you can compare them all.
Man, clang is really knocking on gcc's door from a performance perspective
Most use of the Boost libraries by far is people using them for study when replicating Boost functionality into their locally spun implementations. And that's no bad thing.
tl;dr: Too many libraries, created yet another one! https://xkcd.com/927
Recently my CRT assert message boxes stopped showing up in VS2015 (the process just exits with `0xc0000417`). I think it started occurring when I installed VS2017. When I move the same debug application to my laptop, the assert message window pops up just fine. Is it maybe some Windows setting I changed inadvertently, or a result of a CRT update?
Never heard of imgui. Looks cool, could be a nice way to get just a little bit of GUI in my purely opengl/graphics applications, without it appropriating everything else in my code structure/build system/... As for the rest of the article, if the code is not available, why tell us about it?
I'd have thought you guys would call him Stephan internally.
How did I not know about this, looks great.
&gt; Finding the right tool ... &gt; Independent of any UI system, allowing to create desktop applications or small web-apps, sharing the majority of backend code Ok, so if I get this straight, you are looking for "the right tool for the job" but are listing 3 jobs: web backend, web frontend and desktop UI. There is nothing similar between the three, why on earth would you do them with the same tools? And frankly, if you develop your own, closed-source web+desktop framework, you're not selecting the right tool for the job, you're building your own "library of everything".
Can you go into a little more details about how you created the remote imgui displays? Do you basically send the gl commands to the client and execute them in webgl? 
How can you call something "best practice" if you won't allow peers to review the results? 
While I would prefer the whole source code, I enyojed the article and it's much bettter than no sharing at all.
The use case is "having a strongly-typed enumeration", and _enum class is better than enum because of it_. 
Imgui is ok, but lacks a lot of functionality, and some of what it does support is quite broken (columns) Its reasonably good for debug tools, but I wouldnt use it for much past that
The reactor pattern coupled with single threaded design makes it possible to avoid explicit thread programming with mutex/semaphore. Achieving concurrency through explicit multi-thread programming is not easy to master in my experience and error prone (I have been hit big time by race conditions and similar problems in the past). The composability of node.js streams is nice for some use cases. Then it's hard to create a good API from scratch, taking inspiration from projects that had good or great success was in my opinion a good starting point.
A few reasons: - Boost causes longer compile times. Lower compile times impact iteration time and productivity. - Boost and Boost.Asio make excessive use of templates and generic programming techniques for our taste. We advocate use of modern C++ but keeping it simple. - Use of exceptions (we don't use them) - Back in the days when we started we were not allowed to use C++ 11 and Asio without C++11 was bringing in entire Boost Simplicity was more important than performance: I am sure that boost is more performant than our library but network performance was not our ultimate goal and most of our use cases will not show any difference between a more and a less performant network library. Boost also has some more features that we don't (currently) have or need, like SSL for example as all of our simple/small web-apps are hosted on local LAN networks. Some concepts of the node api like streams were really nice, even if not super-efficient they're good enough. My opinion is that libraries relying too much on generic programming and dark template techniques will fly when concepts and modules will be accepted in the standard. Being able to define a template into some implementation file, that I hope will be possibile with the modules proposal, will be a game changer. 
Sorry, but the best practices you spoke of earlier begin to read like a compilation of all C++ (and programming in general) anti-patterns you could find.
Thanks for the suggestion, but it only works (integrates) with VS 2015 or older. I do hope the LLVM maintainers will update their MSBuild integration for VS 2017, now that it's released. I was using that before I moved to Clang / C2 (my only option with VS 2017). Fortunately, the compiler team for MSVC also made some improvements (better template metaprogramming support and C++14 constexpr support were the most important things for me), so it's not so bad. I just like having multiple compilers to test my code with.
That's good news! The reason I really want CMake 3.7 is because it has support for .natvis (VS debugger customization) files. Wouldn't it be possible to allow the user to manually install / upgrade the CMake version? I mean, assuming the new version's protocol is still compatible with the IDE.
It seems too blunt when the readers expectation is usually, "someone makes a blog post about some cool new thing they made, then they share it". I understand it is out of your control but your answer doesn't illustrate that. I would just say, "Unfortunately nowhere, while it would be great to share, current company policy does not support open-source."
Done! Updated post. English is not my native language and sometimes sentences are poorly written. Thanks for the input!
&gt;std::wstring is 2 bytes on windows/msvc libs, 4 bytes with other libs -- same underlying target platform Which libs? I'm using MingW-w64 and libstdc++ and wchar_t is 2 bytes.
Yes, the screenshot and gifs provided are from a sofware driving laser triangulation sensors used to drive industrial robots in finding seams for welding/glueing, mainly in the automotive field. Another software shown is a visual guidance system for robots in 6DOF currently in production. The entire remoting stuff is used in one of our latest products that you can see on our website (https://recognitionrobotics.com/raio/). I should admit that first releases in production have been a little bit painful but lately we're only getting minor bug reports. We're testing everything using AddressSanitizer and on multiple platforms as well. It's so strange that some huge bugs were only triggering on some platforms while potentially they could have been affecting every platform. This is to say that multiplatform testing is really great to improve overall stability of the software, and really forces you to properly divide the platform specific part from the generic one. 
known issue. fixed in a pending release :(
Templates are indeed Turing complete.
This isn't a C++ topic, you should probably ask /r/programming or something.
There's an episode of Batman Beyond where a villain is trying to drive old Batman mad, by projecting thoughts into his brain, commanding "Bruce" to do crazy things (the villain knows Batman's secret identity). At the end of the episode, after Terry has saved the day, Bruce reveals that he was never in danger of going mad, because he knew the thoughts were foreign. Why? Because Bruce Wayne refers to himself in his head as "Batman". That's like how STL is my True Name.
There are millions of projects online that you can look at, copy, improve, etc. The end product is not as important as the process of solving the problem. 
&gt; I agree it's daft to reinvent the wheel. But it's so much easier to make yourself look busy writing code than go through the hassle of getting approval to use something external, then defend it ad nauseum against the naysayers etc etc. So I've certainly ended up with Boost source code open on the left, and me writing an inferior hack clone of the same thing on the right so I can deliver JIRA ticket X within my allotted time and quota. Same as everyone. Yes, I've run into this plenty of times myself over the years. I try pretty hard to change that culture by telling people that we're not in the software business, we're in the product business. So if it's possible to get something done with something open source or off the shelf, then assume it will be approved. 
Don't have any experience with MingW but this is a simple example showing the same target x86-64 platform delivering awesome 'standard' behavior: https://godbolt.org/g/EYKlRW To be fair, there's generally never any ABI requirements for interoperability between libs so it's a fine difference, but the difference sucks.
No, they've been always there.
&gt; If you're not following the standard, your program is not C++. Might as well use another language. It's either that or undefined behavior, at which point you're on your own. I like how you included no incentive in response to my statement that I have no incentive. My program isn't C++? Hm, that's a new one. Is that supposed to scare me into compliance? I get why standards exist, but the C++ standard sits in a rocky place. &gt; Yes, they are sometimes wrong. Those are bugs, which is something that every software has, and eventually get fixed. And I am supposed to sit there and wait until it is fixed? I'm gonna change the code until it does what I want. If it means using a non-standard approach, so be it. &gt; The standard defines the language, and every program that follows the standard is allowed to go through any transformation that do not result in a program that is not standards-compliant. If you want optimizations that do something the standard does not allow, that's not C++. Why do you keep coming back to this argument? "It's not C++." Nobody cares. They need their code to work, and if the standard refuses to help here, they are going to do whatever it takes. &gt; Doesn't make much sense. Would you rather not have the standard explicitly determine the causes for UB and let everyone fend for themselves? C++ programmers **currently fend for themselves**. I don't know about you, but the C++ professionals I associate with don't sit there with the C++ standard open while they're programming. Heck, many don't even know there is a standard. All they know is "GCC vs Visual C++" or platform-specific shenanigans. At best, they turn on all compiler warnings, but those warnings often don't catch non-standard code. &gt; This one is reasonable (I don't care either), but it's selfish. You're not the only C++ user in the world. I'm not even sure how to respond to this one. What is my moral obligation to other C++ users?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. 
`std::wstring` is an alias. If you want a string that can hold UTF-16, use `std::u16string`. If you want to hold UTF-32, use `std::u32string`. `std::string` always aliases to `std::basic_string&lt;char&gt;` and is for UTF-8 (generally speaking). Nothing hard about it. C++11 has been out for 6 years now. If your platform doesn't support those types, it's time to move on.
It depends on you but i suggest that you use the other and if you can publish both, one with the other and one with your build system
That's what I thought but still wanted to get another opinion. Thanks!
This is very, very cool. It's rather rare I completely agree with any one architecture, but this one I could easily stand behind and not have any gripes with. And the products this supports are very nice too! Thank you so much for sharing this overview. This might be something I might end up pursuing at work as well.
If you use the system itself, how will you bootstrap it?
&gt; There is nothing similar between the three Au contraire, what they've demonstrated is that **everything** is similar between them. Just think about it: from a high enough vantage point, all that we care about is the ability to efficiently react to asynchronous events, and to structure the code in a way that doesn't suck. This applies whether you're doing backend or frontend code, and whether you're thin- or thick-client. Finally, what they've done is basically what X Windows should have been all along, but got itself mired in old raster-like mantra. Geometry (and optionally textures) are shipped to the display, whatever it might be, and events are shipped back. Other events arrive from network and other I/O devices. Since what's shipped back-and-forth is very simple, a basic yet fully functional implementation of a front-end simple as well - simple enough that you can have it running in a web browser with no performance penalty. If I ever considered switching jobs, I'd be probably applying with them :) [I've set this up for a joke on purpose. If you take advantage of it, you lose the argument by default.]
&gt; Just re-read your post and now I have no idea what you're actually asking Yep. This. I'm baffled.
Using another one / none.
I love the podcast but this episode was like one long commercial.
Exactly. Which way would you prefer though?
If it's just a learning exercise, I'd use a different build system (i.e. CMake) and learn that too. If you want this to be a serious build system, I'd ship a simple version (or just use a plain Makefile, which is probably what your system produces as output).
CMake wants to go for MS Visual Bullshit. Using Makefiles oer parameter though. Thank you!
On Linux, it generates Makefiles by default. On Windows, it does make sense to generate Visual Studio projects by default, since that is what most people would use to compile.
Yeah I know. Still disliking it.
I think bootstrapping your own build system with your own build system is a pretty cool thing to do :&gt; Other than that, (i.e. if not for educational purposes), use CMake :)
C++11, 14 and 17 makes it a lot easier to do metaprogramming. For example, before C++11 if you wanted to calculate the factorial of a number at compile time, you'd make use of some perks/tricks in the language. template &lt;int I&gt; struct factorial { enum { value = I * factorial&lt;I - 1&gt;::value }; }; template &lt;&gt; struct factorial&lt;0&gt; { enum { value = 1 }; }; static_assert(factorial&lt;4&gt;::value == 24, ""); You could just as well use `static const int` instead of `enum`s for the value, it's a matter of choice. Now, with C++11's `constexpr` and some extra metaprogramming improvements, you can come up with code like this: template &lt;int I&gt; constexpr int factorial() { return I * factorial&lt;I - 1&gt;(); } template &lt;&gt; constexpr int factorial&lt;0&gt;() { return 1; } static_assert(factorial&lt;4&gt;() == 24, ""); C++14 allows for variable templates, so it can be simplified even further, becoming just a constant: template &lt;int I&gt; constexpr int factorial = I * factorial&lt;I - 1&gt;; template &lt;&gt; constexpr int factorial&lt;0&gt; = 1; static_assert(factorial&lt;4&gt; == 24, ""); 
It makes sense to me. About 95% of developers only want a one dimensional array, 95% of the time. It's perfectly reasonable to have two separate classes.
I'll look into it.
From the other answer you gave: &gt; Boost and Boost.Asio make excessive use of templates and generic programming techniques for our taste. We advocate use of modern C++ but keeping it simple. &gt; &gt; Use of exceptions (we don't use them) &gt; &gt; Back in the days when we started we were not allowed to use C++ 11 and Asio without C++11 was bringing in entire Boost All I can say: ouch!!!
Awesome, thank you.
What you're seeing is expected and Andrew was mistaken (CUDA's development version was being verified). Here's our official statement: CUDA 8.0 (released Sep 2016) doesn't support VS 2017. We're working with NVIDIA and CUDA's next release in 2017 will support VS 2017.
I suspect much of that is because GCC and Clang's iostreams implementation is separately compiled.
You might find this interesting: [CppCon 2016: “Introduction to C++ python extensions and embedding Python in C++ Apps"](https://www.youtube.com/watch?v=bJq1n4gQFfw&amp;list=PLHTh1InhhwT7J5jl4vAhO1WvGHUUFgUQH&amp;index=70)
You can choose not to follow your standard. That's entirely up to you. Just don't blame anyone else for yourself when you have portability issues, or because you had some unexpected bug because you violated the standard. That's why you should follow the standard, so you can have an idea of what the heck are you doing. Anything else is shotgun programming. This is the final response, because you're either a troll or someone who is not worth talking to.
Ah, that's how you meant same underlying target platform. Yeah, wchar_t is usually 4 bytes, except for on Windows.
Any hope for MS to implement CUDA compilation, like Google did with GPGPU? I need templates to optimize kernels for GPU computing, but have little affection for NVIDIA. http://dl.acm.org/citation.cfm?id=2854041
Good explaination. I got it. Thanks.
I am unable to comment, not just due to policy but also my own ignorance about things far away from the STL. I know that AMP is a thing, and that's all I know.
&gt; Include system headers only in the master source file and never in the master / public header file But what about cases when we use that system stuff as parts of our classes, like `std::vector&lt;std::string&gt; m_options`? Do you imply that this is a reason to use PIMPL? Also great job on skinning Dear Imgui! On desktop do you use it in tie with SDL or some other window management library, or do you have a custom code for that too?
I think this is a baseless claim. Can you back this up with any actual evidence? I think lots of people do machine learning, which deals with matrices, which are 2D arrays. Most of the world operates on matrix multiplication. Hell, Linear Algebra is why modern computers where invented. It's honestly a bit sad that the C++ standard doesn't have support for Linear Algebra. 
&gt; My main use case for writing this is to assemble my header only Boost libraries into a single "drop in and go" file. To that end it has a (still buggy) --passthru mode which passes through #define and #undef plus any #if logic which uses an undefined macro. Ill be testing this soon on Catch, if it works you might have saved me from fixing our current ad-hoc stitching script :-)
Do you use std::string? If yes, you're using exceptions, do you understand that? IOW: it is **exceedingly** hard to not use exceptions in C++, because they are required for the **interface** of the **standard library** to work. If you want to not use exceptions, you practically **have** to do one of * drop the standard library * design a multiprocess system which you manage by restarting processes upon exceptions. Or have a "works by accident" system. To be honest, this is what I think you have.
Being single header drop-in is a significant factor for Catch's popularity. Developing in a single header would be positively insane though.
This went way too far down the rabbit hole for me. This can't be right.
Honestly, try learning it from Wikipedia first
&gt; I must be reading my calendar wrong it says 2017. We have support contracts that can last more than 10 years and customers stuck with legacy systems until they can no longer find replacement parts. 
You're Phil?
"Standard" classes like std::vector, std::string and few more exceptions are allowed to escape the PIMPL firewall ;) There are two techniques that I am using, depending on if I want the containing class of this members to behave as a reference or as a value type. In the first case (reference) I am declaring an opaque pointer to a struct that is defined only in the implementation. Constructors/destructors/assignment/move operators are acting to work as a shared_ptr for that class, allowing the hidden struct. In the second case (value) I am using some raw bytes (with large alignment to prevent issues on some architectures like ARM) that gets constructed inside the implementation file using placement new and manual use of destructor. Pseudo Code Examples: // In public-header.h class MyReferenceType { struct HiddenDetails; HiddenDetails* self; public: FANCY_MACRO_THAT_CREATES_SHARED_PTR_LIKE_BEHAVIOUR(MyReferenceType) void doSystemStuff(); }; // in public-implementation.cpp #include &lt;secretSystemHeader.h&gt; struct MyReferenceType::HiddenDetails { HANDLE systemHandle; SystemStruct systemStruct; char* pointersToRawMemoryAreBadButThatsLife; //etc. etc. }; void MyReferenceType::doSystemStuff() { systemFunc(&amp;self-&gt;systemHandle, 1); //.. etc } In the second case I am doing something like this: // In public-header.h class MyValueType { public: std::vector&lt;std::string&gt; allowedOptionsToBeAccessedPublicly; MyValueType(); ~MyValueType(); //define also all copy / move / assignment operators etc. private: struct HiddenStuff; int64_t hiddenStuffRawMemory[200]; }; struct MyValueType::HiddenStuff { HANDLE systemStuff; //etc. etc.. } MyValueType::MyValueType() { static_assert(sizeof(hiddenStuffRawMemory) &gt;= sizeof(HiddenStuff)); callPlacementNewOnRawMemory(hiddenStuffRawMemory); MyValueType::HiddenStuff* self = reinterpret_cast&lt;MyValueType::HiddenStuff*&gt;(hiddenStuffRawMemory); systemFunc(&amp;self-&gt;systemHandle, 1); //use system stuff } MyValueType::~MyValueType() { //when done let's destroy hidden stuff MyValueType::HiddenStuff* self = reinterpret_cast&lt;MyValueType::HiddenStuff*&gt;(hiddenStuffRawMemory); self-&gt;~HiddenStuff(); } On Dear Imgui I have been choosing the route of writing system specific window initialization stuff myself, because I need to interact with the window messaging system in order to coordinate with the event loop (that can only run on another thread) and dispatch callbacks on the main UI thread (that was really one of the most difficult tasks of the integration...).
You shouldn't be going around just telling folks your True Name. You never know when someone might use it against you.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/5ykr51/sources_for_learning_linked_listsxpost/deqx4bk/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; hrm... we actually use Dolphin for compiler testing, iirc. That's...kind of amazing. Thanks MSVC team!
fixed my VS 2017 problem - needed to install additional components: - Windows SDK version 8.1 - Visual C++ runtime for UWP - Windows Universal CRT SDK maybe cuz on windows 7... Windows SDK 10 was already installed 
I don't object! If the conclusion of all the researching and experimenting on this topic so far by committee members is like that, then that would be the best way to move forward. Sometimes you can generalize something, sometimes you can't. I just hope we'll get the second part of it as well :-)
Wait, `stdlib` had `qsort` since forever? Huh... TIL.
No, but Phil is not the only Catch's maintainer anymore.
If you ever load or save things from disk or network, you care.
The throughput benchmark of `evpp` is 40% higher than `boost.asio` and 17% higher than `libevent2`. The reason of `evpp` has a better throughput benchmark than `libevent` is that evpp implements its own IO buffer instead of libevent's evbuffer. The benchmark code is at https://github.com/Qihoo360/evpp/tree/master/benchmark/tcp Please visit https://github.com/Qihoo360/evpp for more detail. And the detail report is coming soon. Thanks for your attention. 
Also, `less&lt;&gt;`
Lambdas got us covered on this one! You can have a look at http://www.fluentcpp.com/2017/01/19/making-code-expressive-lambdas/
That would have to be changed in the language standard, and gradually implemented, as any code that currently uses fallthrough is perfectly valid and well-defined and should not break by simply upgrading the compiler. Some new languages have omitted fall-through from their switch statements, but it is a bit too late to try to do the same in C.
Write "overload". It takes 2 or more lambdas, and produces the overload set object. Write "projected_order". It takes a function object (the projection), and creates an ordering based off that projection. auto ref_projection = overload( [](int x){return x;}, [](Employee const&amp; e){return e.getReference();} ); auto ref_order = projected_order(ref_projection); now `ref_order` is your `CompareWithReference` but done without explicitly written functors. Writing those out of line functors is really annoying, and you only really need it if you want your set to have a transparent comparator. 
Opt-in exhaustiveness is at least feasible, but probably unlikely to become part of the standard any time soon IMO. &gt; or a standardized pragma Pragmas are by definition not standardized. They're completely implementation-defined. Even common ones like `#pragma once` are only *de facto* standards because enough compilers support them. &gt; For example, they could introduce a different keyword That seems very unlikely, new keywords are rarely if ever introduced in new C revisions.
Thanks for sharing this interesting feature of std::set!
lambda is just syntax candy for function object, so why you even think it's dead?
*twitches violently*
I really like their use of comments as poor man's attributes. This is actually a good idea, a compiler that reads your comments as well. (I'm not being very serious, although I do humble their creative workaround)
The concensus I think we reached is that no one should use the word functor because everyone gets confused 
From the github description and the overall project structure it looks like you put indeed a lot of work into it to keep it clean and well organized. Will definitely remember it if I have an application that could benefit from it ;)
&gt;You can use std::string operator [] that doesn't throw for example instead of .at(). Yes, but I can't construct a string without exceptions, so that game was over before it started. &gt; Are you wrapping all your string operations everywhere in your code with a try{}catch(out_of_memory){} ? No, and it is I think it is **unbelievably** naive to think anyone should. If oom is thrown, it will be caught and dealt with much, much later up the stack. &gt; assuming that you have implemented perfect exception safety everywhere so that your exception can safely travel up the stack without destroying your application state (very hard to do), what are you doing then? When my exception safety isn't right, I fix it. Modern C++ really has plenty of tools to get there easily. I like to think that my exceptions do safely travel up the stack. Now get this... while they do so, resources are freed, memory included. By the time exception reaches a matching catch, there's plenty of memory to report an error, and error reporting infrastructure is ready from before (failure to get it is dealt with a horrible death). You seem to believe that, if a memory allocation fails, there is no memory at all. This is, in practice, false. In practice, allocations fail for **big** items, e.g. an unexpected huge request, so they fail, but there can be plenty left for "normal" operation, error reporting included. I know of Google and JSF guidelines and can comment on them: google has historically exception-unsafe code base, that's reason 0 why they don't want exceptions. JSF allows for exceptions at startup, but JSF recommends preallocating all at startup, too. This is a common approach for embedded software and even old game engines, and does work, within constraints. My question to you, really is: did you think this through? My guess is, you did not. But I only say this from my experience, from what I have seen in the wild. I have seen people using vanilla std lib, but compiling their code without exceptions support. I have seen people "not using exceptions" and then, their code breaking in horrible ways when some 3rd party threw. I struggle to remember if i have seen a "we don't do exceptions" codebase that, as I arrogantly put it, didn't work by accident. But yes, it can be done. Sure you're doing it? ;-)
Install size depends on what you choose to install. Different workloads have different default sizes, though you can pick and choose specific things under each workload that you want as well, or switch to the Individual Components tab and pick stuff from the larger list. You might find that you don't need everything VS suggests by default for your specific requirements, and if you find out later that you missed something you can always open the installer again later and add anything that is missing. 
I think he is nitpicking that the examples are free-standing functions (and pointers) instead of lambdas or bound object instances. Lambda's work fine, so I don't see the issue.
That complexity with a simple kind of comment match for =2, wider one for =3 and different ones for 4 and 5 again, honestly at that point I was expecting the article to be a joke. What maintainer accepts that kind of sprawling construction into their project. I'd have picked a bit more focused approach.
`/* implicit */` as a fake attribute for conversion operators and constructors would also be nice to have
Maybe for some people, but given that [`FindCatch.cmake`](https://github.com/philsquared/Catch/blob/master/docs/build-systems.md#cmake) exists and takes care of it all with git, whether it's one file or a bunch that all happen to get pulled in when I `#include &lt;catch.hpp&gt;` I don't really care.
Rust was like that some time ago, and I couldn't even stand my code breaking every compiler upgrade. So yeah, I know Rust is somewhat new, but code breakage is still bad, e.g. now there are thousand of deprecated Rust codes out there, that don't compile anymore.
Why is #5 wrong? The construction of the temporary object will still initialize catalog because its static, right?
There were various discussion on the gcc mailing list, but neither side (-Wimplicit-fallthrough=1 (match any comment) vs. -Wimplicit-fallthrough=3 (the current default)) was willing to give way. But hey, this is free software so you may just change the defaults to your liking easily.
Well, if you set the default to -Wimplicit-fallthrough=1 you will never hit any of the that complexity in the parser. But I agree that the warning is over-engineered.
What does defining the type `is_transparent` do?
Update: I forwarded your coroutines question to Gor Nishanov on our team, his reply is below: --- Sure: We have a few blog posts https://blogs.msdn.microsoft.com/vcblog/2016/04/04/using-c-coroutines-to-simplify-async-uwp-code/ and several recent talks Introduction to coroutines: https://www.youtube.com/watch?v=ZTqHjjm86Bw Putting coroutines to use with Windows Runtime. https://www.youtube.com/watch?v=v0SjumbIips Unlike C# coroutines that come prepacked with a task library. C++ coroutines are open to be adapted to be used by arbitrary asynchronous libraries, such as PPL, IAsyncXXX, boost::future, etc. Thus, the focus during presentations on adaptability, as opposed to use, since, once you have proper adapters the use is pretty straightforward. Say, you are using ppl tasks as your async types, than, simply make task&lt;void&gt; or task&lt;whatever&gt; your return type and use co_await or co_return in the body of the function. Here is the tiniest example: #include &lt;pplawait.h&gt; #include &lt;stdio.h&gt; using concurrency::task; task&lt;int&gt; g() { puts("Hello from a coroutine"); co_return 42; } task&lt;void&gt; f() { auto v = co_await g(); printf("got value %d\n", v); } int main() { f().get(); }
As a German: While I do get pissed when Americans assume that the entire world consists of the US, I (and almost everyone I know) consider non-english code an abomination that should indeed be abolished. And comments are part of the code.
A syntax like `enum switch Foo { bar, baz, qux };` might be possible to get through the standards committee. It doesn't introduce any new keywords, and it's in a place that other stuff is being tacked on. Another possible syntactic move in this area would be along the lines of `switch break (Foo) { case 1: . . . ; case 2: . . . ; default: . . . }`, to explicitly disable fall-through for the particular switch statement in question. It's much more palatable because it doesn't change the meaning of any existing code, and it potentially makes new/revised code more concise (at the expense of locality of reading, though that's mitigated by an absence of `[[fallthrough]]` that coding standards may otherwise mandate). I may actually write up these ideas, just to see what people say.
As an exception (possibly one that proves the rule), trigraphs were not just deprecated, but completely removed from the standard, over IBM's very loud objections. Given that their compiler lead was also the head of the Canadian national delegation, they also had an official vote against the change when the issue came up for balloting. They lost.
Confusing: * ~~"reference"~~ id or identifier * ~~"functor"~~ function object Otherwise the article is good.
This is a very cool project. I like the ease with which you can bind and invoke functions. I looked over your docs and I curious about your plans to support versioning? The other more minor features you'll find in fully featured solutions are compression, authentication, encryption, tracing, and multi-language support.
I have changed the examples to lambda on the README page.
[removed]
Your post has been automatically removed because it appears to contain profanity or slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5y4b0k/cppcast_visual_studio_2017_for_c_developers_with/des3o0w/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
No, we don't change names every few years just because people feel like it. If you don't like all the silly names in C++, kill them when they're new. Don't come in 20 years later and kill them when they're established.
Thanks very very much. It means a lot for us. We learned a lot. Thank you. &gt; Doesn't always use RAII when it could Could you please point it out? How to do it, could you please explain more? &gt; NULL instead of nullptr Have refactored this. &gt; Raw new / delete Have refactored `InvokeTimer::timer_` using shared_ptr. &gt; goto for error handling We use `goto` to fast fail and never use it jump to above. Maybe we can improve it in the future. &gt; initializing PODs with memset instead of {} Could you please point it out? How to do it, could you please explain more? &gt; uses the old anonymous enum trick for compile-time constants How to improve it, could you please explain more? &gt; Accepts pointers in plenty of cases where a reference is wanted Have refactored `InvokeTimer::timer_` using shared_ptr. Others, we cannot find the problem. &gt; Lambdas freely mixed with std::binds (sometimes just lines away from each other) Have refactored most of these cases. &gt; Superfluous struct keywords (this isn't C!) We use struct keyword to remind this is a C struct. We don't think there is a problem here. e.g https://github.com/Qihoo360/evpp/blob/master/evpp/fd_channel.h#L93 &gt; Returns false (or worse, void) and logs an error when something fails (instead of a saner error handling mechanism) Could you please point it out? we can discuss it case by case. &gt; Mixing of concerns (e.g udp client and socket do IP address parsing) We confused this point. The sync udp client is a most for testing. We have add a comment to this. Others, `socket do IP address parsing` I cannot get it. Could you please explain more? &gt; Two phase init We do two phase init in EventLoop is because we hope the EventLoop can be embedded into the old applications based on libevent. &gt; No wrapping away platform-specific details in their own layer How to improve it, could you please explain more? 
In the server_session::do_read, do you really want to be calling "async_read_some"? I ask because presumably the message format could have some framing information such as 2/4 bytes at the head to denote expected frame size. If so then in exactly two reads one could obtain the message off the wire - as in first read the size then the remaining bytes based on the size. For connections where there might be multiple hops (ie: not on same machine, or connected to the same switch), do_read may end up being called multiple times due to nagles and other things etc. In short making more async requests than is needed can sometimes add more overhead and latency than what would normally be expected depending on the underlying reactor implementation (select, epoll etc..) 
+1!
It doesn't deal with other problems of `switch`. I'd rather see a more complete pattern matching system (and I believe that the committee is working on that).
Excellent job. I really like the interface. Hope it get more language support. Unsurprisingly, grpc is among the last of them. Its c++ api is really shitty and http2 gives lot overhead. Although it may looks like has a lot of language support, them seem to mostly focus on go api. Thrift also has some asio backends, you may want to have a look. I've used lots of rpc framework, but they are all pain in the ass: * force you use their own io model. * maintain idl * generate shit load of code(grpc/protobuf generates thousands line of source code for a simple message definition. You may use something like protozero to write them by hand, but that's kinda against the purpose of sdl) * too many heap allocation(grpc/protobuf again) * few language support, not widely used * keys cannot be effectively compressed in schemeless rpc 
I'd also like to report a bug: `warning C4996: '_strdup': The POSIX name for this item is deprecated. Instead, use the ISO C and C++ conformant name: _strdup. See online help for details.` I know this isn't really the right place for it, but I'd rather it get with the right people quickly than sit in a bug tracker for a few months.
AFAIK, it's just another C++ implementation for [msgpack-rpc](https://github.com/msgpack-rpc/msgpack-rpc), which already has many [language support](https://github.com/msgpack-rpc/msgpack-rpc#implementations).
&gt; the power of the language and in particular its compiler can leave you stunned. Compiler can also function as interpreter at the same time. News at 11! The power that comes with executing arbitrary code is not surprising. The nice thing, though, is that the compile-time interpreted code and the run-time compiled code can share the same definitions. That's really nice.
You're right, it's a slip-up. It happens, you know. Only those who don't write articles don't make mistakes in them. :) However, it's shit code anyway and one shouldn't write like that. Perhaps the programmer wanted to call the constructor but failed, and the code works only because of sheer luck.
[removed]
No, it is not. This feature already has found numerous bugs in different projects. And if you don't care the solution is simple: just disable the warning. 
&gt; void A::foo() { // virtual &gt; static_assert(sizeof(A) == sizeof(Derived)); &gt; new(this) Derived; &gt; } &gt; This is call of placement new operator - it doesn’t allocate new memory, it just creates a new object in the provided location. So, by constructing a `Derived` object in the place where an object of type `A` was living, we change the vptr to point to `Derived`’s vtable. Is this code even legal? C++ Standard says yes. I am surprised this is considered legal. I thought changing the dynamic type of an object during its lifetime was illegal (special case: trivial types see their lifetime ending when their storage is reused), and I thought that ending the lifetime of an object within its own method was illegal... Is this really legal? And if so, what clauses support this shenanigan?
I'm also surprised that this is legal. And if it is, wouldn't this also require an explicit destructor call before the placement new, or am I missing something?
I don't know anything about the standard specifications, but I would think this would be a straight forward operation, disregarding whether it is a good idea. I would think the new operator would just overwrite the memory at 'this' and not run the destructor.
[\[basic.life\]/5](http://eel.is/c++draft/basic.life#5) &gt; **A program may end the lifetime of any object by reusing the storage which the object occupies** or by explicitly calling the destructor for an object of a class type with a non-trivial destructor. **For an object of a class type with a non-trivial destructor, the program is not required to call the destructor explicitly before the storage which the object occupies is reused or released**; however, if there is no explicit call to the destructor or if a delete-expression is not used to release the storage, the destructor shall not be implicitly called and any program that depends on the side effects produced by the destructor has undefined behavior. :/
This has an issue that the destructor is called on a object whose lifetime has already ended. What A::foo does is legal, but it can be called only on objects whose lifetime is manually managed (i.e. not on automatic, global, thread local variables -- and I may miss some cases).
Even if C++ had excellent reflection capabilities, many RPC libraries would still choose to use an IDL for cross-language capabilities.
That was actually interesting so yeah shameless self-promotion was helpful.
Variants calls the destructor.
Why wait? Both Boost.Fiber and Boost.Coroutine work well with ASIO
I don't think that using an IDL/code generator by itself makes the experience bad. Rather, many libraries seem to require tedious setup even when no real options are given to the user (i.e. they leak implementation details), and often require extra work to process parameters and return values (despite the fact that they are generating code and could very well spare their users from that). The point with cross-language capabilities is valid, although an IDL wouldn't be the only way to reach that goal in my opinion.
[removed]
How big was the stack for the ~~blocking~~synchronous server threads? That could probably be made smaller, no? Otherwise... Node is web scale :-)
We had technical issues and had to rehost: http://youtu.be/xjKTV-UMZm0
We don't? I remember when "Koenig lookup" was the preferred term, and now most everyone says ADL. 
I think it's most likely Java SDK. I don't program Java regularly, I was not aware of this distinction. I did not know there are platforms where Java runs but there exists no SDK. In any case you've got the SDK readily available on a majority of platforms, and the ones where you don't have it, you're probably not going to read images.
If I am reading what you are asking correctly is why after the C99 standards were put into place why inactive members in unions are not just explicit standard-layout types across the board now? I would have to guess for backwards comparability to older compilers that are not compliant. I am confused on what your question is I guess. I thought they had to be both to cover the new standards and also retroactively handle older unions.
&gt; If I am reading what you are asking correctly is why after the C99 standards were put into place why inactive members in unions are not just explicit standard-layout types across the board now? Not exactly. While compatibility with the C99 standard is definitely a bonus, I'm rather wondering why, if the union is standard-layout, and the members are standard-layout, access to an inactive member is classified as undefined behavior, instead of being declared as resulting in (implementation-defined, due to alignment and endianness) type-punning/bitcasting. This could have been considered even before C99 standardized the behavior; of course the question is even more pressing after C99. &gt; I would have to guess for backwards comparability to older compilers that are not compliant. &gt; I am confused on what your question is I guess. I thought they had to be both to cover the new standards and also retroactively handle older unions. I don't think explicitly allowing type punning via inactive member access in the standard layout case in the C++11 would have broken backwards compatibility, though, since in older revisions of the standard it was classified as UB: (1) for C++98 sources compiled in C++98 mode nothing would have changed; (2) for C++98 sources compiled in C++11 mode (and therefore specifically by a C++11-compliant compiler) would have resulted in type punning, which would have been an admissible outcome for a C++98 source (since in C++98 it was UB); (3) for C++11 sources, backwards compatibility wouldn't have been an issue. In general, a new standard version changing something from UB to defined behavior would not break backwards compatibility. So I think the rationale must have been something deeper, but I can't see what, and that's exactly what I would like to know: the rationale for not defining it to result in type punning/bitcasting. 
Yeah I know the name sucks. But it's the most descriptive one I could come up with. And "jwdpmi" is nearly point-symmetric so it's got that going for it.
Note that you can achieve the same thing prior to C++11 by making a struct with a C-style array in it, and providing member functions for things like `size`, `data`, `begin`.
If that's the case, then you really should just start with writing your own vector and go from there. Template programming as it's used just for generic code is very easy. It only gets hard when you're doing the advanced static polymorphism stuff. Check my GitHub. That thread pool? I originally wrote it in my sophomore year of college. (Obviously not with C++17 and concepts, it's been through a few iterations.) I *was not* all that exceptional of a sophomore, just very persistent. 
Not quite. Did you read the article?
Pray tell: how is `boost::array&lt;&gt;`, which has been around since 2001, inferior to `std::array&lt;&gt;`?
What's the purpose of using concepts in this case? If you simply used templates and the requirements were not met (e.g. no string_t member), then the compiler would error out. I'm guessing it's for better error checking?
"It should be pretty clear" that the whole context of this subthread is "*prior to C++11*"... ;-] This was simply not an interesting C++11 addition; worthwhile, obviously, but not interesting since it was trivially implementable by _anyone_ since C++98. EDIT: &gt; but I wouldn't equate them to a struct with a few member functions. Throw in a few free functions as well and that's _exactly_ what they _both_ are. No magic here (unlike e.g. `initializer_list`)!
If your build machine only has 12 GBs of RAM you're going to have a bad time.
I use i:! And j:f for upside-down letter mappings. Close, though!
That makes sense. Wasn't `std::array` purely a library extension?
100%.
&gt; allowing const fields to be moved from and statically enforcing that a moved-from value cannot be reused. But that's ridiculous. It's not just the breaking changes to the language - it's that const would have zero meaning if any function you called could actually move out from your "const" reference. Overall, I really don't understand the initial problem at all. Why exactly do you end up wanting to move out of a `const` variable? How exactly do move semantics and `const` interact badly? Can you give us a code sample? (Yes, I read the two linked articles, and I didn't see it at all. The one issue that seemed somewhat substantive is that `std::move` might secretly not actually "move" its argument, if it's `const` - I can see perhaps a proposal for an alternative to `std::move` that fails on const items, or conceivably somehow on items that aren't `const` but also can't be moved from...)
We are just lacking the type of such a descriptive variable.
auto man. The compiler will deduce the type.
&gt; No, it also allows compiler-enforced unique ownership What does that mean? Is it not possible to create two unique_ptr-s pointing to the same object?
You have a point, and I don't expect a fix in the next decade. In a sense, the problem is that the definition/concept of const is poor or unhelpful. Perhaps you could define a new concept that better fits your needs. As for workarounds, I suppose you could make a container where the contents are const but movable to another container.
I'm not too knowledable about this topic, but I think it probably is because different types is potentially stored in a different way on different systems (for example, signed integers can be (and are in practice) stored in a variety of ways on different systems). Therefore is this kind of type punning more or less meaningless. Edit: This might be a C++-specific thing. C allows this IIRC.
I think he's not splitting hairs but your statement is plain wrong and therefore misleading for someone not familiar with the concept of move semantics. std::move does not really move anything. It could have been named differently though ...
Sometimes `std::array` is really annoying: 1. Before C++ 17, you have to write the count of elements explicitly because `make_array` has not been standardized. 2. Sometimes, you need extra braces even with C++ 14: #include &lt;array&gt; #include &lt;utility&gt; int main() { //compile error const auto arr1 = std::array&lt;std::pair&lt;int, int&gt;, 2&gt;{{2, 3}, {4, 5}}; //works const std::pair&lt;int, int&gt; arr2[] = {{2, 3}, {4, 5}}; } 3. more typing: `std::array&lt;T, X&gt;` V.S. `T[X]`.
Question... why not cmake instead of make?
Thanks, now we can point anybody that arguments with "but the compiler will devirtualize the call" to this article. Designing a program in such a way, that acceptable performance relies on devirtualization, is pretty bad design mistake.
I'm only targeting a single platform, so there's no need to use cross-platform build tools.
&gt; it's that const would have zero meaning if any function you called could actually move out from your "const" reference Not really. It is called destructive move. The move also destroys the object it moves out of. I remember a couple of proposals which called for adding destructive moves to C++, but they didn't go anywhere. In general, there is no reason why you cannot move out of const objects. You just need a different type system.
Right, but is it faster? I've only seen that it exists but not any details.
Fair enough. I still find it easier to use on a single platform but i get your idea.
I have no idea what that question means... I mean, yes I'm okay with it, because it makes perfect sense given that `array` is just an aggregate type wrapping a C-array &amp;ndash; I wouldn't expect anything _else_.
So, the semantics you want is that you can't change b, but you can transfer its ownership? Have you tried using a unique_ptr&lt;const BigMovableType&gt;? I haven't tried it but it's my understanding that should give you those semantics. Granted you'd have to make b private and have a method that returns a const reference for people to use so they don't mess with the pointer, but that seems like a reasonable thing. Alternatively you could make b private and non-const (or mutable) and add a method that returns a reference.
You don't. You can pass the object by reference or the unique pointer by reference, but you can't pass the unique pointer by value without a move.
I don't think "can" is the point so much as "want to".
I don't think you and I have the same understanding of the word "ownership".
What if the delete operator returned an r-value reference to the soon-to-be-deleted object, instead of returning void? Then the object could be move-assigned from or move-constructed from and the destructor would be called before the next sequence point. The delete operator should already have the power to do this because it can be called on const objects and can modify const members (I think). Edit: I just realized that this doesn't work for stack allocated const objects. But since deleting a stack allocated object is currently illegal we can make it legal and give it useful semantics: deleting a stack allocated object returns an r-value reference and forces the object out of scope immediately afterward.
I think gnu make is relatively easy and straightforward to use. Are you thinking of autotools?
&gt; I think it probably is because different types is potentially stored in a different way on different systems No, as you can legally get the platform specific byte pattern with memcpy() or reinterpret_cast&lt;char*&gt;, just like with union type punning.
Yes, but it is illegal to "view" a type as a different type due to the strict aliasing rules. You can create a new type from the byte pattern of the old one with memcpy(), which is how you do type punning in C++.
&gt; Long story short, type-based alias analysis. Architecturally, most compilers "forget" that the access is coming from an union quite soon on the pipeline, explicit support is required to prevent the alias analyzer from reporting a (wrong) "no-alias" when type-punning through an union. &gt; If I recall correctly, GCC shipped a version that broke all the code relying on type-punning through union, but the amount of broken code was so big that they were forced to put it back to the current status (documented [here](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html#Type-punning)). &gt; Common sequences of standard layout types are allowed pretty much for this reason, they have the same type, hence the type-based alias analysis cannot simply flags all the accesses as "no-alias". Thank you very much for your answer, very enlightening (particularly the GCC documentation about `-fstrict-aliasing` and union-based type-punning falling through with even just one layer of indirection), if surprising: I say surprising because I fail to see how anyone would _not_ consider unions as an intentional violation of type safety (in the sense of “well duh of course they alias, that's the whole point of unions!”). So essentially the rationale was to favor allowing more optimization opportunities, at the cost of the natural behavior of the class type. However, this comes at the cost of no “natural” way of doing type-punning/bitcasting in C++ core. Well, can't say I'm happy with the choice, but at least I can see a rationale in it, even if it's one I don't agree with ;-) Thanks a bunch. 
My understanding is that you can use the byte pattern for standard-layout types after a `memcpy`, but not going through a reinterpret cast (except to read the individual bytes).
Your third line is also a way to pass it to a foo without transfering ownership.
Yes, it would most likely be implementation-dependent instead.
Interesting, I've never considered that. I don't think I've ever made a const member variable that wasn't a pointer or a reference though.
&gt; Then you *could* retain correct behavior of your program if all pointers to `foo` were updated to point to `bar` Er, but this unequivocally _doesn't_ happen, so what is the point being made? o_O
The options struct would actually work fine if C++ allowed designated initializers.
You can also look at how destructors and move semantics interact in the language Rust. Like C++, it has automatically-inserted destructors for all stack values. Code like { let nums = vec![1, 2, 3]; use(nums[1]); // automatic: drop(nums); } has an automatic destructor. Unlike C++, it uses static and dynamic code-flow analysis to never run the destructor on moved-from values, and static analysis to disallow access to possibly-moved-from ones. So you get code like // automatic: let mut nums_was_moved = false; let nums = vec![1, 2, 3]; if condition { consume(nums); // automatic: nums_was_moved = true; } // nums is inaccessible here, whether or not the branch was taken // automatic: if !nums_was_moved { drop(nums); } In C++, though, moved-from values are still accessible. You can call member functions on them, and their destructors run. That means that moving from a value is an observable mutation, so you can't do it to a value that you're not allowed to mutate.
`unique_ptr` would be simply impossible without move semantics. The we could get was `auto_ptr`. 
Just one of the ways things can get wrong. Probably the only real-life problem is foo(a.get()) where foo can delete the pointer
You replied to a statement involving std::move; it was in scope. ;-]
Well, I don't like the new aggressiveness we have in /r/cpp. The second top level comment starts with "that's rediculous". That's not a good atmosphere for discussion. For what it's worth, I agree more and more with parts of what OP wanted to say. For example when returning a local const from a function, it is strange that moving is impossible. After all, the destructor is called afterwards, and that isn't really a const operation either. It is defined as an "expiring value", so why can't it be moved from?
I do not know enough about unique_ptr, but what about the following code: template &lt;typename T&gt; struct TakeOwnership { ... custom_unique_ptr&lt;T&gt;&amp; ptr; }; template &lt;typename T&gt; struct custom_unique_ptr { ... custom_unique_ptr(TakeOwnership&lt;T&gt;&amp; rhs) { ... } TakeOwnership&lt;T&gt; move() { ... } ... T* ptr; ... }; void foo(TakeOwnership&lt;int&gt;&amp; ptr) { ... } custom_unique_ptr&lt;int&gt; x(new int); foo(x.move());
That sounds like a good approach. Then the only thing the class writer has to avoid is accidentally reassigning the pointer at the wrong time, which is easier to avoid than accidentally calling a non-`const` member function on it.
Of course things will go wrong when you write meaningless code. And when you pass the unique_ptr's raw resource to some C/pre-unique_ptr function, you are already putting yourself at risk, and you only do this if you're sure (reading the documentation or code) that the function won't pretend that that resource has no owner.
You must understand one thing -- there is no move semantic in C++. There is "move-and-init". This is all result of sticking to the old idea of "object and memory it uses is the same entity". Endless source of problems and hacks (like in-place ctor/etc). This is what Alex Stepanov was complaining about decade ago -- C++ has no pure "values". These r-values, x-values and other 15 insane types of values are all results of dodging this fundamental feature/problem. 
I don't quite understand. What's the alternative to this? &gt; object and memory it uses is the same entity Could you refer me to Alex Stepanov's complaints?
Actually, I think this raises a totally separate issue from move semantics. c++ lets you destroy const objects. afaik its legal to explicitly call dtor on a const object and use placement new to put a new one there. you can put const types in many variant impls for instance. If you can't destroy const then it become too awkward to use in many cases, but this is sort of a loophole. const is not perfect or some philosophical ideal, its just a practical tool to avoid common accidents. "pure r-value" is much closer to such an ideal, but that's very different from const.
I jus filled bug against MSVC compiler which crashes (VS2015) or ICEs (VS2017), when using array with one initialization brace missing. https://connect.microsoft.com/VisualStudio/feedback/details/3128214/compiler-ice-when-working-with-std-array
My comment consisted of an answer to your question, a joke, and a smiley... I really can't fathom how that could be interpreted as aggressive.
&gt; Actually... I am afraid you are underestimating the amount of optimization that is solely based on type-based aliasing. It's not that I underestimate the optimization opportunities, it's that I don't think these should come at the cost of “sensibleness”, so to say. For example, I'm fine with the no-alias assumption for pointers to different types as function arguments. I'm not fine with not allowing bitcasting through unions (or `reinterpret_cast`, for the matter). Moreover, I feel that the performance argument for strict aliasing is flaky in itself: while on the one hand it allows a swath of optimizations that would not be possible otherwise, on the other it prevents _intrinsically_ fast code (that often depends on type-punning and other forms of bitcasting) from being written in the first place in other cases. A lot of I/O and memory manipulations, for example, _cannot_ be made _intrinsically_ fast in conforming C++ under strict aliasing rules: they have to _rely_ on the compiler being smart enough, and having to fight with both “too smart” and “not smart enough” compilers gets pretty old pretty fast. Concerning your «silly example», &gt; With your union rule? It depends whether `a` and `b` points to the same point in memory. I don't think so. Given `union { int a, float b} var;`, with the actual C++ standard, calling `doit(&amp;var.a, &amp;var.b)` would trigger _two_ UBs: one from passing aliasing pointers to different types to a function, and one (indirectly) from reading a member of the union after writing to the other. Even if the C++ standard adopted “my” union rule (which is rather the C99 union rule), a conforming compiler would still have the function return 1, even if subsequent access to `var.a` may return `0x40133333` instead (or 1, if the compiler decided to optimize by switching the assignment order), due to the “aliasing pointer arguments of different types” UB. The type-punning union rule doesn't mean that suddenly all other aliasing rules go flying out of the window. &gt; in the absence of explicit aliasing information in the type system, type-based aliasing is a useful crutch. I think the solution should be to provide keywords to define aliasing overrides beyond what the current standard(s) claim: I can't say I'm happy about C++ not having `restrict`, for example, or about neither C nor C++ having the equivalent of GCC's `may_alias` attribute. In the mean time, I would rather not have the type-based aliasing going from being a useful crutch to being an impediment. 
&gt; Maybe I have the C++ terming not quite correct. But if you consider the idea (what OP probably meant) that an "object" lives on completely unchanged, but at a different address, then it would make total sense, just that everyone who knows the object has to be updated. No, in C++ this is totally incorrect, and it's really not splitting hairs. There are dozens of questions on SO of people being confused about "why is the destructor called an extra time when I move" etc. because they expect it to work the way you are saying. This is like one of the most common misconceptions programmers have when they start C++11. In C++ we have a formal object model since like C++98. Objects are created at a specific address when their ctor is called, and their lifetime continues until the moment the dtor is called. Nothing really moves, move semantics is just the cleanest way we have to fake it. If the address did change during it's lifetime like you say, it would dramatically complicate code generation, and break many libraries, tools and large programs. That's one reason they specifically didn't standardize it that way. &gt; Well, I don't like the new aggressiveness we have in /r/cpp. The second top level comment starts with "that's rediculous". That's not a good atmosphere for discussion. I don't think this is `/r/cpp` being aggressive, I think you are simply wrong about something you really didn't expect to be and starting to get a little defensive about it. Sorry if that comes off as harsh.
Yeah, it doesn't rely on any core language features that C++03 didn't have. As noted elsewhere on this thread, it's nearly identical to `boost::array`.
This is not the place to ask that kind of questions and do your own homework.
I see. Thanks ill delete the post and thanks for the tip as well I kept trying to get it to format
If you recreate const objects, you probably need `std::launder` in there somewhere.
You can't make them orthogonal. At least not in any moderately complex program that involves more than one thread. If you limit yourself to one thread per program than sure, you could enforce compiler checks, otherwise I don't see how performance would not majorly suffer. What does it mean if thread 1 moves object A while thread 2 tries to read from it at the same time? Being const it is a promise that its value will not be mutated by anything. Maybe a COW type could be applicable? If someone moves the object and some other reference exists, it will instead of moving the object clone it. But that is highly non-deterministic and I kinda dislike that kind of behaviour in a language such as C++. 
You can use .data() for the same thing: http://www.cplusplus.com/reference/array/array/data/
.data() returns a T*. /u/danrav is proposing to return a reference to a T[N]. He covers the distinction in point 5 of his attached proposal.
The name is fine. In fact, it's pretty much self-explanatory. Don't listen to people who've obviously never worked with DOS... unless they're going to tell you something like "640K isn't enough". Though since you're using DPMI you obviously knew that already.
&gt;would trigger two UBs: one from passing aliasing pointers to different types to a function, and one (indirectly) from reading a member of the union after writing to the other. Passing different pointers is not UB. Only reading through such pointers is UB. 
Your code won't compile - you attempt to declare two variables called `a` in the same scope
&gt; afaik its legal to explicitly call dtor on a const object and use placement new to put a new one there. Actually it isn't; see C++14 [basic.life]/7.3. (Well, you can put a new object there but any attempt to access that new object causes undefined behaviour).
I see, thanks
&gt; A moved-from variable usually has little value and good code rarely had any reason to reuse those variables I recommend creating a demo-type that detects when it is moved from, and asserts if used in any way other than the destructor when in a moved-from state. Then create a `vector` of those types. Insert into it, erase from it, sort the vector. Report back here what you find. What I find: Not even `std::swap` (the generic overload) works when you prohibit reuse of a moved-from value. Destructive move would be a good tool to have in the toolbox. But it would in no way come close to eliminating the need for non-destructive move. I've been inviting someone to step up and add destructive move for 15 years: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2002/n1377.htm#Alternative%20move%20designs But that would be in addition to, not instead of non-destructive move semantics, the presence of which provides the lion's share of the benefits (if you value sequence-modifying algorithms). It's the algorithms in `&lt;algorithm&gt;`, and `vector::insert` and `vector::erase`, that really drive the move semantics requirements. And out of these algorithms, there is a need for destructive move semantics (under `vector::insert` and `vector::erase`), but it is not dominant. It's a nice-to-have.
Right, the idea with concepts in general is to improve the quality of the error messages. Without the Concept you get errors at much lower (and therefore uglier) levels. It also serves as documentation, I guess.
That only works because of special language added to the standard explicitly allowing it to work; the same language could be applied to `take_ownership` ^(theoretically) ^^\(doubtful).
Not really. You can verify that using dynamic cast. auto base = new Base(); auto derived = dynamic_cast&lt;Derived&gt;(base); 'derived' will be nullptr, always. C-cast or static_cast may return non-null value, but that will be UB assuming code even compile.
you did not understand what I was talking about. It is a common mistake amongst amateur coders.
&gt; I don't quite understand. C++ was designed with objects in mind. It operates objects and object is it's main building block. Object's identity is it's address in memory, state (as defined by it's bits living at that address) and type. It doesn't really have concept of pure value -- it is simulated with objects. Originally we had "copy" -- it's semantic implies that we create new object (or assign to existing one) from another object while leaving it's state unchanged. Note that all operations tightly tie together object state and it's memory -- you can't separate them without breaking smth. E.g. you can't create object on stack, destroy object and recreate it again without language hacks that don't work very well (aka in-place ctors/dtors). Now, const was invented so that language can give certain guarantee to certain objects -- immutability, so that they can be put into read only data section (which is designed to be shared between processes to reduce memory requirements, yada-yada). It works seamlessly with 'copy' semantics. "Move" semantics appeared -- it doesn't move objects, it moves it's state (which is rather nebulous concept in C++ language). Consequently, object has to stay constructed after "move". But it doesn't work with const -- const requires object to stay unchanged, "move" implies change to object state. &gt; Could you refer me to Alex Stepanov's complaints? Somewhere in "Four Algorithmic Journeys" (https://www.youtube.com/user/A9Videos/playlists) he goes on a tangent and laments lack of "values" in C++. I apologize, I don't remember exactly where. &gt; What's the alternative to this? Language where memory occupied by values is a first-class citizen. Where I have full control (and necessary facilities) to handle lifetime of values and memory they occupy separately.
Const is fine, the problem is the interaction with move. This happens everywhere - many features practically means surprising interaction thereof.
As long as an "empty" state is a reasonable state for a type (and it is for any container), what you're asking for is not possible. It is also illogical. What you're asking for is a destructive move, which I think is interesting for many types. I do not see how this can be achieved in C++ without going very much towards Rust :-). One thing i always disliked about the move semantics is that it makes it a requirement for types (and more importantly, me) to deal with an empty state. But empty state is *often* undesirable and it can be made to work only if move is destructive. Oh well...
&gt; A lot of I/O and memory manipulations, for example, cannot be made intrinsically fast in conforming C++ under strict aliasing rules: they have to rely on the compiler being smart enough Type-punning through memcpy is as fast as it can be on any modern compiler. If you use something too old, which can't optimize it then you'll have a lot more problems in other situations. And if you're proposing a change in standard, why not write a proposal to allow reinterpret_cast&lt;int&gt;(float_value) to perform type punning?
Your comments don't make much sense. C++ does have values. `2 + 2` is a value. "rvalues" and "xvalues" are expression categories, not values.
I don't decry RAII. I criticize (Bjarn's?) decision to package memory and value into one concept (aka object). He did it for convenience (it is much easier to declare an object, than declare memory and construct a value in it), but as result we end up with proliferation of additional artificial concepts designed to make things work. They don't make our life (as developers) easier, they clutter language and make it complex (to the extreme, as of 2011+). Their only reason for existence is to allow certain things. And we can;t get rid of them, because otherwise we can't have these nice shiny things ("move" semantic, etc) without breaking original postulate (object = memory + state + type), which in turn will break entire language. Examples: R-values are objects who's address is controlled by compiler (because compiler needs some freedom to be able to implement function calls), x-value is some other object in some other context. Just look at this: http://en.cppreference.com/w/cpp/language/value_category -- it is fucking insane. Most of it stems from the fact that language is built in such way that hides memory from you. And after gargantuan effort of tweaking language to allow move semantic we ended up with "move-and-init" instead (with dim hope that optimizer can get rid of "init" part) -- all this is fault of that fundamental axiom. In fact, afaik, in-place ctor was introduced into language as a hack to allow STL to happen (you know, containers like vector). Committee was discussing "destructive move" for considerable time and deemed it too hard to implement (without breaking the language, I assume). In language where value is not "tied" to memory it occupies such move is triviality. I am not saying such language exist or is more convenient than C++ (you know, syntax-wise, etc). I think Rust has implemented proper move semantic (according to my friend), but I never looked at it since my first experience with it ages ago (when it had GC and some crazy semantics associated with pointers). I have absolutely nothing against RAII, it is one of the main powers of C++. But I am saying that long ago something was sacrificed on altar of convenience and we are paying the price right now. Oh, here is another good one. How many devs actually understand what is going on during function call and why? Like, how value of type T gets passed into function? when and how it gets constructed/destroyed? All these vague and complicated copy-elisions-rules... Because we don't control memory taken by values, compiler freedom is limited by arcane rules than no one really understands. Even now MSVC is not standard-compliant (and tbh standard doesn't make any fucking sense wrt destruction of these r-values). God damn it, this is almost 4 decades old language, most of users don't understand it's most basic building block! 
I am sorry, I don't like helping people who open conversation with insults.
He opened with "*The C++ standard clearly distinguishes between storage and object using that storage*"; you opened with "*You must understand one thing*" and "*you did not understand what I was talking about*". One fact versus two personal accusations of ignorance and **he** is the insulting one..? What's with all the petulant drama around here?
You are right, it's a typo, the second should have been "b"
I understand your point, and I have seen such things as well and they scare me as much as you! :D Regarding your last question, we are trying to do our best, but no, we are not planning as of today to be able recovering from a failed memory allocation. That being said, if we will ever change our mind on the topic, retro-fitting (optional) exception support would not be huge task: everything is already very RAII-ized because of the asynchronous events everywhere and because even regular error handling with error objects needs proper RAII and invariants to be observed religiously to avoid leaking everywhere.
Or just don't make the member variable const, and always access it through a function. No need for the pointer. 
No, it is a completely different object - an object which has the same contents as the original. Indeed, if the original object cannot be moved from, then _both_ objects exist at the same time. This isn't "splitting hairs". It's important to understand that an object in C++ can _never_ change its address. You are just confusing people by claiming otherwise.
If you're willing to pay US rates for training, almost all of the well known US based trainers are willing to train in Europe. If however you want to pay European rates, you'll need to settle for European based trainers. You should start with those who provide training each year at the ACCU conferences in the UK, so https://conference.accu.org/site/stories/2017/fulldayworkshops.html is this year's, also inspect previous years. Regarding your specific topics, you luck out in that the guy who mostly designed the C++ 11 threading library is British and lives in Britain: Anthony Williams. He is an independent consultant and provides training for an appropriate level of fee. You can contact him at https://www.linkedin.com/in/anthonyajwilliams/.
&gt; Quick scan through the code says that it very much does not implement 90% of what Catch does, not even a headliner feature like expression decomposition. Also quick stitch job says its about 1600 LoC. Exactly what Phil said :) But as I argued in return, mine does 90% of what people actually use in CATCH. As much as expression decomposition is nice, it's hardly needed by most. Printing the expression on failure is sufficient. The stdout capturing in JUnit XML is much more useful, but even that one can live without as CIs capture stdout for you anyway. There are a lot of alternative "light weight" unit test frameworks out there, and most don't provide enough stuff to be actually useful e.g. JUnit XML capture so Jenkins can track testing. Mine does provide that stuff, and remains API compatible with Boost.Test so if one needs to upgrade, it's easy. &gt; However, if you feel that your own framework works better for you, use it. We are not out for world domination :-) Oh for sure. But my point to Phil, and I'll make the same point to you, is that it's always easy to bloat out any piece of software with new features and stuff. It's much harder to go back to the drawing board and reboot with a better and breaking design. I'm not saying CATCH should do this, but my original use of CATCH was to emulate Boost.Test which had become very bloated and full of stuff no one needs and thus with an ever increasing compile time. CATCH has increasingly become the same. I don't need most of that stuff, yet I pay for it per compiland. A reformed CATCH would not compile in most of those features at all in the first place unless asked to with a macro. Keeps everyone's compile times low.
Const member variables have issues, such as disabling assignment, and as you've discovered, moves. There are other workarounds to prevent the class from altering, like wrapping them in a constants struct. class MyClass { class constants { int const_int_; public: constants(int i) : const_int_(i) {} int const&amp; get_int() { return const_int_; } }; };
KDAB offers courses in C++ and Qt: https://www.kdab.com/software-services/scheduled-training/whats-new-cpp11-cpp14/ Rainer Grimm also offers courses: http://modernescpp.com/
Yeah sorry this remark is not about the wildcard pattern, for this I feel I do not have enough experience with (or no specific pattern seems intuitive or easy to me anyway). &gt; What would such a syntax look like? I would really like to help about this, by providing feedback and propositions. However I think I need first to work on a non-toy project with build2 to give actually useful feedback. I have one planned but couldn't start it yet, I need to finish another first. So I will send reports and suggestions then.
One of the justifications I gave for myself for being ok with it is thinking of it as if I was suppressing a warning from a static analysis tool which generally works by comments as well.
I dunno about the compiler itself, but the c++ preprocessor can do more-or-less the same thing, with some caveats. resource.txt R"DATA(Hello World!)DATA" or (will add newline characters, but surely your program is robust enough that that won't matter) R"DATA( Hello World! )DATA" main.cpp #include&lt;string&gt; #include&lt;iostream&gt; constexpr const char * hello_world_literal = "" #include "Resource.txt" ; int main() { std::cout &lt;&lt; hello_world_literal &lt;&lt; std::endl; std::string hello_world_string = "" #include "Resource.txt" ; std::cout &lt;&lt; hello_world_string &lt;&lt; std::endl; return 0; } This program will print out `Hello World!` on two lines, as expected. It's not the most elegant syntax in the world (and boy what I wouldn't give to have [Actual File Literals](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0373r0.pdf) added to the standard so that we can use binary files!) but so far I've encountered very few situations where this code doesn't suit my needs.
&gt; Destructive move would be a good tool to have in the toolbox. But it would in no way come close to eliminating the need for non-destructive move. I never said otherwise. :) I was merely pointing out that non-destructive move being the only option in local user code makes a lot of bugs easy to write. I also feel the same about copy operations on expensive types (the number of severe performance bugs we've had because someone wrote `auto v = get_some_vector()` instead of `auto&amp; v = get_some_vector()`) but I'm obviously not advocating that we remove copies from the language now or ever. :) We can't be rid of non-destructive moves now anyway purely for back-compat reasons anyway. That ship has sailed. I think we could have a long discussion about this next time we run into each other if you're game - I don't particularly like having these kinds of discussions on sites like Reddit rather than just over beer/coffee. :)
I'll buy. :-)
I use both of these features all the time. I think I am a bit behind the fashion curve with C++ though.
The title makes it seem as if there's an incompatibility between `make_shared` and the `shared_ptr` ctor, but it's actually just the fact that `make_shared` allocates the object and control block with one allocation, so you waste more memory if you keep `weak_ptr`s around. Don't get me wrong, this can be a gotcha and it's good content, but the title is misleading.
&gt; Moreover, I feel that the performance argument for strict aliasing is flaky in itself I fully agree. That's exactly why I'm calling this a crutch. Contrast with Rust which has aliasing built into the type-system: - `&amp;T` is a read-only pointer which guarantees no modification happens to the pointed memory, - `&amp;mut T` is a read-write pointer which guarantees no aliasing. In Rust, it's perfectly valid to type-cast/bit-cast, and yet Rust has *richer* aliasing information.
[removed]
The explanation is 1 sentence though, I don't see the need for a full post to create an example. 
This is one of the few "nevers" that's actually, "No, really, never at all."
Unique_ptr doesn't support allocators because it doesn't allocate anything. There's no control block like with shared_ptr, because unique_ptr does not need to store a refcount, and does not use type-erasure on the deleter. The deleter is part of the type and is not stored in memory anywhere. As far as allocation is concerned, unique_ptr is equivalent to a raw pointer (same size, alignment, etc.) 
Because it's no longer 'perfectly valid code'. Of course there is good reason, it's good code. Huge code improvements and safety/security bugs could be solved with the new versions of the compilers. Breaking the old ones should be fixable by selecting the appropriate flags. 
In no particular order: - Better for newbies and not-so-newbies - Better for those having troubles with English - Easier for the curious ones who would like to reproduce it - When OP failed to understand something and his/her sentence doesn't make sense for an expert, the example can be used to understand what OP was trying to say. - (Makes a better blog post on LinkedIn for potential recruiter)
Interesting! But that's an hour talk - can you summarize that one little bit? 
Fair points.
It was never implemented _anywhere_. It was, likely, unimplementable.
I was (and still am) using Malte Skarupke's implementation ([link](https://github.com/skarupke/std_function/blob/master/function.h)) which does support it. However I'm not entirely sure if I really need it, since it's hard to tell when and what a `std::function` would allocate.
This thing is a consequence of a more general principle of not reporting errors from cleanup code. In any language. Exceptions or not. Consider the following C pseudocode: int f(params) { FILE* f = fopen(...); if (f) return 0; if (!fwrite(f, params)) goto error; // etc. if (!fclose(f)) return 0; error: if (!fclose(f)) // NOW WHAT? return 0; } The deal is: if the cleanup fails in the error case (fwrite failed, fclose failed), **which error is/should be reported?** Write or the close error? Both? If both, how? Some C APIs provide a stack-like error info, but here, it's not a question of a stack - it is just two errors one after the other. Yes, one can provide some interface to report multiple errors - but how many of us actually do it? The simple, effective answer is: **do not report cleanup errors to callers**. Instead, move as much as possible of cleanup in "normal" operation (e.g. in the example above, call fflush and report its errors). And do one of the following: * report the cleanup error in some side-channel (log or some such) * terminate on the spot. Same logic goes for finally blocks in languages like Java/C#. Your code in them should better not throw, and the reasoning is 100% the same as above. It's turtles all the way down. 
There was an attempted implementation in MSVC's STL, but we're glad to see it go away.
But that doesn't really answer the question: why is there no `std::allocate_unique`? That seems like something that should belong in the standard library, especially since we already have `std::make_unique` which does allocate using `new`.
I've worked on a project that uses Boost.Python extensively, with a lot of complicated logic, and chains of calls like C++ -&gt; Python -&gt; C++ -&gt; Python were possible. Some memories (note that our use case was pretty unusual, and might not fully apply to you): - Boost.Python is nice enough - We didn't manage to make python debugger work reliably, but we didn't try too hard (we uses Stackless Python instead of the regular one, IIRC it was one of the reasons) - The main problem was memory management. It is very easy to create a cyclic dependency while having C++-&gt;Python and Python-&gt;C++ callbacks stored somewhere simultaneously, and python's GC often refused to work when Boost.Python objects were present in the ownership cycle. - Related to the previous bullet, our application life cycle was divided into "sessions", after which all allocated objects could (and must) be dropped. We tried to use `Py_Initialize()`/`Py_Finalize()` to create/shut down the interpreter, but `Py_Finalize()` is [broken](https://docs.python.org/3.7/c-api/init.html#c.Py_FinalizeEx). We ended up moving all session-related logic to a separate process and nuke everything when the session is over, which worked fine but might be complicated. So, you can make things work, but if you can't avoid Pyton-&gt;C++-&gt;Python or C++-&gt;Python-&gt;C++ calls, some caution is advised.
Oh, nice! I really hope this will make it in C++17. In the meantime, I just tried to write my own `allocate_unique()` and came up with this: template&lt;typename Alloc&gt; struct allocator_deleter { Alloc alloc; allocator_deleter(const Alloc&amp; a) : alloc(a) { } void operator()(auto* p) { using T = std::remove_reference_t&lt;decltype(*p)&gt;; p-&gt;~T(); alloc.deallocate(p, 1); } }; template&lt;typename T, typename Alloc, typename... Args&gt; auto allocate_unique(const Alloc&amp; alloc, Args&amp;&amp;... args) { using rebind = typename std::allocator_traits&lt;Alloc&gt;::template rebind_alloc&lt;T&gt;; using deleter = allocator_deleter&lt;rebind&gt;; auto d = deleter { rebind { alloc } }; auto* p = d.alloc.allocate(1); try { p = new(p) T { std::forward&lt;Args&gt;(args)... }; } catch (...) { d.alloc.deallocate(p, 1); throw; } return std::unique_ptr&lt;T, deleter&gt;(p, d); }
Similar reasons for making local variable const - it expresses intent (in this case that the variable is immutable after construction) and it makes modification (which perhaps would break invariants) either accidentally, or unwittingly by some later author, a compile-time error. All of which is good, except now your class is can't be moveable, which is bad. Hence the dilemma. And this despite the fact that moving from e.g. a scalar quantity doesn't actually do anything.
The SOCI has the following code: #if defined(SOCI_HAVE_CXX_C11) || (defined(_MSC_VER) &amp;&amp; _MSC_VER &gt;= 1900) #define SOCI_NOEXCEPT_FALSE noexcept(false) #else #define SOCI_NOEXCEPT_FALSE #endif That actually makes compiler to generate a proper code for exceptions. As for galera, the build script doesn't specify the standard so that means that they use C++03 that works normally with exception in destructor. The point of the post is actually to say that the code throwing exceptions in destructor just stops working if you switch to C++11 and does it in very ugly way.
this is quiet interesting. could you please clarify what "projected_order" is? is it a standard function or something the user would have to implement.
why do we need to log-in in to download the slides?
What is the status of clang on windows with this? Will lldb work? 
If an `std::function` captures some variables by value, and then you make a copy of that `std::function`, you have to copy those captured variables, and that requires an allocation of some type.
The shared_ptrs own the object, the shared_ptrs and weak_ptrs together own the control block. In the case of make_shared (and allocate_shared), the object lives in the control block. That's why object lifetime is separate from the underlying memory's lifetime. The *whole point* of make_shared is to permit a single memory allocation and the extra We Know Where You Live optimization that saves a pointer. That's something that users can't implement themselves.
It does store them as a tuple, but because `std::default_delete` doesn't contain any data members, it doesn't take up any space in the tuple. $ cat foo.cpp #include &lt;memory&gt; #include &lt;tuple&gt; #include &lt;iostream&gt; #include &lt;ios&gt; int main() { std::tuple&lt;char *, std::default_delete&lt;char *&gt;&gt; foo; std::cout &lt;&lt; std::boolalpha &lt;&lt; (sizeof(foo) == sizeof(char *)) &lt;&lt; '\n'; } $ g++ -std=c++11 foo.cpp -o foo $ ./foo true So in the case where you don't pass a custom deleter to the unique_ptr constructor, there's only a pointer to the data. 
std::function must allocate (on construction, copy construction, or copy assignment) when the stored callable object is large, or if it has a potentially throwing move constructor (because std::function must be nothrow swappable).
There should be a rule against referring to libraries as Boost.Meow before they've been accepted into Boost.
This is not the way C++ works, you write to the standard committee. More importantly, modules should take care of this issue.
This is actually not an effective way to influence the standard. A thoughtful, well championed proposal at a committee meeting is how you do it.
Because exceptions can be slow
How do you write to the standard committee? The petition would show if more people actually want the change, and would allow some proof when writing to the committee.
I unfortunately don't remember the details (maybe STL does?), but I think part of the discussion was that there was actually something in the specification that conflicts with allocators, making it impossible to completely implement it. But I may be wrong.
How can we support this proposal? I'm very new to this system. Thank you for posting the proposal! I missed it earlier when I got the notifications.
The proposal is not mine, I just posted a link. (And personally, I am pretty OK with include guards.) I don't have experience of proposing anything myself, so this is just what I read on the internet. You can try discussing the idea om the mailing list https://groups.google.com/a/isocpp.org/forum/?fromgroups#!forum/std-proposals Also you can communicate with committee members and try to persuade them (several of them are actually pretty frequent in this reddit so they might be reading us now). I guess you may want to get support of some influential people. Edit: And of course, try contact proposal author to join forces. 
&gt; How can we support this proposal? I'm very new to this system. - Contact the author and offer to help with any refinements, editing, or wording changes that came out of the last committee review. - Author support for the proposal on GCC or Clang as a proof-of-implementation. - Show up to a committee meeting and participate in the discussion. - _If_ you feel that you have something new and novel to add beyond just "I want this" (seriously, _we know_) you could post your persuasive and informative message to the [std-proposals](https://groups.google.com/a/isocpp.org/forum/?fromgroups#!forum/std-proposals) reflector. 
That will never be standardized. Implementers have good reason to vary the size (e.g. 32-bit versus 64-bit).
this is my favorite answer so far. thanks!
Plain old Boost.QuickBooks is quite nice if your code is too complicated for Doxygen to parse. I recommend picking some existing Boost lib which uses QuickBooks, and copying it. I wrote my documentation with QuickBooks last year and it really was pretty painless.
What you're showing really is "the worst of both worlds". The stated goal of this library are high-performance environments, but in the example above, not only it throws, but it forces the use of exception\_ptr, which requires usage of heap. This example contradicts library with itself. I understand this is done for completeness reasons, but still... I had a huge argument with u/ned14 about this earlier. My bias is: I **dread** the day when this will become the norm in C++ programming. I believe that people do not think their error handling through (or rather, I **see** this all the time on various codebases), and this will add more opportunity for a mess. I understand that performance is a reason to code in such ways, but I think that people will use performance as an excuse, not because they know what price they are really paying, let alone consciously deciding that the price is too high.
&gt; So it's basically a way of packaging the return value **and** a std::error_code? I think it's **or**, not **and**.
There is :/
Not really; [the policy](http://www.boost.org/community/policy.html#lib_names) is simply to make it clear that the library isn't official: &gt; Please take care to avoid confusion in discussions between libraries that have been accepted into Boost and those that have not. Acceptance as a Boost library indicates that the code and design have passed through our peer-review process; failing to make the distinction devalues the hard work of library authors who've gone through that process. Here are some suggested ways to describe potential Boost libraries: &gt; - the proposed Boost _Name_ library - the Boost._Name_ candidate - the _Name_ library (probably the best choice where applicable) &gt; Note that this policy only applies to discussions, not to the documentation, directory structure, or even identifiers in the code of potential Boost libraries.
Correct. I appreciate Stephan that you were probably expressing your personal opinion here as I vaguely you remember stating the same on boost-dev last time it was discussed. I argued in opposition that a Boost *aspiring* library gets to prefix Boost. before its name so long as it's otherwise obvious it's not in Boost yet. And a library entering the peer review queue is necessarily going to be review ready, which means using the boost namespace, calling itself Boost.Meow in its docs etc. Referring it not as Boost.Meow but as Meow in this situation would be confusing. And in the above case, it is very, very clear it's entering the review queue, and indeed the title asks for a review manager. I think all that very unambiguous.
There is a three part Tutorial gently taking you from first principles through the rationale to the refinements over the LEWG Expected (Outcome implements proposed expected&lt;T, E&gt; which is before WG21 for standardisation into C++). I'd suggest you read the first part of that Tutorial https://ned14.github.io/boost.outcome/md_doc_md_02-tutorial_a.html by the end of which you'll understand. The tutorial was developed in large thanks to the Reddit community here who were responsible for how it looks today. It looked very different originally. If you want videos to watch, Charley Bay is speaking on Expected and Outcome at C++ Now in May. And I'm speaking at ACCU next month on this topic in the "most popular" tracks, it'll be a very full room.
A full history is at https://ned14.github.io/boost.outcome/md_doc_md_09-acknowledgements.html but yes, it was a case of coevolution with the Expected proposal returning back to Expected thanks to Reddit feedback in January where people clearly wanted an expected&lt;T, E&gt; implementation not my refinements. The same TMP infrastructure could deliver both easily, so now Outcome is primarily a high quality Expected implementation. AFIO v2 and my other Boost-ish library KernelTest very heavily uses Outcome throughout - as in, every single API in those libraries is using Outcome. It's why Outcome produces ABI stable signatures because it's expected to form part of a DLL's official stable ABI.
It wasn't received well during the last meeting in Kona, here are the results of the poll vote: &gt; P0538R0 as a direction poll? 1 | 6 | 3 | 9 | 10 The numbers correspond to the votes "strongly for" the proposal, "for", "neutral", "against" and "strongly against". Considering that votes against tend to have more weight in the final decision than votes for, it's a clear sign that P0538 isn't going to make it into the standard. Also, here are the comments following the straw poll: &gt; "Take your pragma once proposals from off my door." &gt; &gt; We can take this back to the community now the next time they ask for it. Basically, #pragma once isn't going to make it into the standard anytime soon, and waiting for modules is the preferred solution.
SG14 has struggled to find any clear performance differential. There is widespread agreement that disabling C++ exceptions is good for lots of other stuff though. Outcome was designed from the beginning to be SG14 friendly and works great with C++ exceptions and RTTI disabled. It also lets one easily create islands of code where one dives into the STL which can throw exceptions whilst maintaining a non-throwing overall environment. Again, the tutorial goes into some detail on this. If you're any interested or involved with SG14's study, all this stuff will be very familiar to you.
A lot of time when people refer to "performance", they really mean *predictable* performance. Some people keenest on SG14, despite it being called "low latency/games/financial trading" are those compiling all their code with -O0 because they need **hard** guarantees about performance, even if that is slow performance. Monadic error handling is almost certainly more performance predictable than exception throws which are one of two areas in C++ without a guaranteed complexity specification. The reason for the lack of guarantee is the potential unbounded RTTI lookup during handling which will be at best O(log N) to the total number of RTTI chains currently loaded into the process via DLLs etc. SG14 has been doing some work to better specify this in the standard, so one approach they've been seriously considering are C++ exception throws with the RTTI lookup disabled. This would make their execution time predictable. But that's a while away yet, and in the meantime library only solutions such as Outcome save a lot of hassle writing performance predictable code.
I've always been of the opinion that you give the people what they want. I doubt using Outcome or Expected makes sense for 80% of the C++ written, but where it does, I think it's a face palm sensible choice. I can't tell you how much easier AFIO v2 is to write over AFIO v1 thanks to Outcome. The code is faster, clearer, much easier to read and audit for correct handling of failure. For low level systems programming in C++, in my opinion it's not even a debate that using anything else is worthwhile once you've tried it. This stuff is a genuine step forward over the previous state of the art. But again, I am not disagreeing with you in general. These are a bad fit to lots of other C++, and if misapplied there then yes it will add opportunity for a mess. Same as most of everything else in C++, and indeed added to C++ which is not a programming language intended to hold your hand.
&gt; I'm showing what's on the landing page of the library. Perhaps they should come up with a better example. Yeah that example has caused a fair bit of complaint. Some think it has no place there at all. Some are strenuously convinced it needs to be there. The example chosen went through multiple iterations, what is there now deliberately models the loading page example from Boost.Optional precisely because that example was determined through trial and error to least upset the most people. So it's definitely a non-ideal compromise chosen to create consensus, but then so is any Boost library, or indeed C++ standard. &gt; In contexts where exceptions can be used, you don't need outcome::exception(), but where they can't be used, you can't construct them either. You're forgetting that you can enable exceptions for some translation units, but not others. You're also forgetting that std::make_exception_ptr() works just fine in exceptions disabled code, and this can be very convenient for manufacturing exceptions in code with exceptions disabled to be thrown later once one returns to exceptions enabled space. &gt; I just don't really see a use case for this, especially not in boost. I really would read the tutorial before deciding this. If after reading it you still feel this way, you can of course vote for its rejection during its peer review.
&gt; Counterintuitively it is even faster to compile a unity file with one core than to use four cores to build the files individually. I don't think this is always true. The reasons why this may be true are: 1. In non-unity build each core has to compile common included files "for itself". 2. If only one/few cores are utilized then they can be turbo-boosted. So if the individual files have little common inclusion, then they will probably be slower to compile in the unity setup. Overall, this is a hack which (as the article mentions at the end) usually doesn't work without at least some effort. Modules will eventually make it unnecessary. And in the meantime remote compilation is probably a better answer. At least this will be our answer to this problem in `build2`.
As a Finn I'm firmly of the opinion that anyone commenting in other language than english should be executed on the spot.
Thank you for information, I did not know about fate of the proposal.
C++17 has shipped, but something like that should make it into C++20...
I personally like it, but you'd need to persuade boost-dev to change the official policy at http://www.boost.org/community/policy.html#lib_names
What does O0 bring over other optimization levels with regards to predictability? 
__UPDATE: I have updated this project. It now requires 70 % less memory than it did when this was posted. The memory usage was reduced from 2371 bytes into 568 bytes.__
&gt; The code is ... much easier to read and audit for correct handling of failure. This is a matter of opinion, I suppose? Mine is: the problem with error-return code is "can't see the forest from the trees". With exceptions, no handling is correct handling most of the time, that's why one wants exceptions in the first place. Granted, exceptions require a different kind of thinking ("everything throws"), but my mind is made up that this is easier than reading vast swaths of conditional logic.
Interesting. Let's say I have a set of string, will it work if I set is_transparent to string_view and overload the operator() accordingly?
&gt; terminate on the spot. If you do this then why not simply throw from the destructor? If this is not a cascading failure (most likely) then the user gets to handle the exception. If this is a cascading failure, then the runtime will terminate you. Sounds like a win-win.
I think you are referring to the range-based for loop: http://en.cppreference.com/w/cpp/language/range-for
Thank you!
I vote for module.
Am I the only one who finds that code less readable than naive C++ version?
Exactly, repetition of `_t` after the word `type` seems nonsensical.
&gt;Yeah that example has caused a fair bit of complaint. Some think it has no place there at all. Some are strenuously convinced it needs to be there. Do you find it odd that a "hello world"-style example, aiming to show a prototypical use case, would generate controversy? Do you think people have differing views of what the library should be accomplishing?
&gt; More importantly, modules should take care of this issue In 25 years, maybe.
Files in the standalone tarball(boost.outcome-v1.0-source-latest.tar.xz) should be in a folder preferably called "boost.outcome-v1.0-source-latest". Simply extracting the tarball produces a bunch of files and folders with 9 of them being hidden files(hard to notice and delete later on when i am done checking out the library). 
 "Operator" means something that operates on expression(s) to produce another expression. Of the things you listed, the conditional operator is the only one that is an operator (and the : cannot be mentioned without the associated ? )
Completely agree -- but those were values known at compile time. For known int distributions, absolutely.
**Company:** [Creative Assembly](http://www.creative-assembly.com/job/170307/campaign-gameplay-programmer?utm_source=Reddit&amp;utm_campaign=Reddit%202017&amp;utm_medium=Thread%20Post&amp;utm_content=Campaign%20Programmer) **Type:** Full Time Permanent **Description:** This is a fantastic opportunity to join the well established Total War Campaign team. This position will see you working alongside programmers, designers and artists to deliver new, innovative and compelling gameplay features for the campaign map area of Total War **Key Responsibilities** * Work with designers and artists to create high-quality gameplay features, including contributing to the design and iteration of those features * Take ownership of new and existing features, and see those features through production to release * Create high-quality, maintainable code using up-to-date C++ practices **Location:** Horsham, West Sussex, United Kingdom **Remote:** No **Visa Sponsorship:** Yes **Technologies:** **Essential** * Strong academic background with a 2:1 degree or higher (or equivalent) in a relevant technical field such as computer science, software engineering, mathematics or physics * Excellent C++ programming skillset * Strong analytical and mathematical ability * Good communication skills to enable effective collaboration with programmers, designers, artists and management staff * Experience as a programmer in the games industry – at least 2 shipped titles **Desirable** * Experience developing gameplay systems for strategy games or similar * Broad gaming experience and a sense of good game design * A keen player of strategy games and games in general, including Total War **Contact:** [Click here to apply](http://www.creative-assembly.com/job/170307/campaign-gameplay-programmer?utm_source=Reddit&amp;utm_campaign=Reddit%202017&amp;utm_medium=Thread%20Post&amp;utm_content=Campaign%20Programmer)
&gt; if (!fclose(f)) // NOW WHAT? Easy. error: if (!fclose(f)) goto error; Really, `f` can't return normally or by throwing exception until it closes the file. Looping forever or terminating are the only options.
&gt; Do you find it odd that a "hello world"-style example, aiming to show a prototypical use case, would generate controversy? It's Boost. Even the most uncontroversial things are controversial, even highly divisive. &gt; Do you think people have differing views of what the library should be accomplishing? Recent additions to Boost are getting more and more niche with time, so I think most don't have a view at all as it's outside their domain. It's getting ever harder to get any reviews at all, once ten or fifteen was the norm, now five reviews is great and two is more likely without the review manager manually prodding people by private email to write one. There is also debate in WG21 LEWG over Expected. I am told a minority doesn't see any point in it all. A very small number think it's totally a wrong design. A loose majority thinks it okay once a long list of small issues is fixed, with different people having different opinions on what those issues are and the best fix for them. So sure, people have differing views. But in the end, he who implements the thing gets to choose its design.
Seems, your RSS Code broke ;) pubdate is missing.
I'm embarrassed. Somehow I had an expectations of something in line with "exception safety" of `fcose`, yet never bother to actually RTFM. 
If performance is a concern, inlining the getRandom calls and cancelling out radius (as well as squaring both sides of the comparison) are both obvious optimizations that should be done first, with the added benefit of answering the question without running the program. :-)
 &gt; I thought the convention was that _t was a shorthand to extract a nested `_type` withouth have to type typename all over My understanding is that this is exactly the case; `ranges::value_type_t&lt;I&gt;` is equivalent to ``` typename std::iterator_traits&lt;I&gt;::value_type; ``` in the current standard library, and equivalently for `size_type_t&lt;I&gt;` and `difference_type_t&lt;I&gt;`.
&gt; inlining the getRandom calls They probably will not inline because of the static mt19937 and uniform_real_distribution members. &gt; cancelling out radius (as well as squaring both sides of the comparison) what are you talking about? It's only using `std::hypot`
You should inline manually, if performance is an issue. std::hypot == sqrt(x*x + y*y) square it so you avoid sqrt x * x + y * y &lt; radius * radius
Sure. But both versions use `std::hypot`. I've only indicated the range version is faster. That was as far as my point went.
&gt; Sounds like you didn't enable C++11 It's not necessary in VS2015, at least I never do it and I used c++11 features. &gt; Version 7 should automatically promote int to double It just emitted warning because 10 is promoted to double, pow(double, double) is called, and the result (double) is assigned to int (it caused warning, even though it should be ok for values we used). &gt; If you are interested, MS has a fork Thanks, but I am not an early adopter, there is no value in it for. I will wait untill it's properly supported.