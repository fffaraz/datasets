In my experience VS is was easier and faster to use. Better code completion that can get even better with external plugins, great debugger, pretty much a standard. I've always found the other 2 you mention very "sticky" to use, performance is really bad.. no idea if it's Java's fault and I don't care, but typing in CLion, Eclipse or even in VS with the Resharper stuff active feels like coding on a remote computer sitting somewhere in Australia. If you really want a more portable alternative to VS I'd look into QtCreator instead.
Great, the only problem is that it's only available in paperback. I really hate physical books! Oh well.
You can mess the checking of find_last_of:s return value. 
But you can mess up checking the return value of your own `lastIndex` and the return value is identical.
Over the years, John has presented pretty much all the ideas in the book at conferences; these talks can be found on YouTube: * https://www.youtube.com/watch?v=K_fTl_hIEGY * https://www.youtube.com/watch?v=QjFpKJ8Xx78 * https://www.youtube.com/watch?v=fzFOLsFASjU * https://www.youtube.com/watch?v=NrARQ7rHV-c
Hi, I'm a bot (in Beta). I combined your list of YouTube videos into one shareable highlight reel link: https://app.hivevideo.io/view/f796bc You can play through the whole highlight reel (with timestamps if they were in the links), or select each video. Reply with the word ignore and I won't reply to your comments.
Crazy thought - doesn’t `z` show up a lot in mangled C++ function names? Hence it’s quite likely that there is a `z` in your binary somewhere if there’s debug information compiled in? (I don’t properly understand ELF so this is a proper crazy thought)
I thought that too!
Came here to say this. I really enjoy using it.
Like some have already mentioned, QtCreator is a very good alternative: it's much snappier than the competition, has great clang tooling integration (e.g. highlight warnings and errors as you type, format code according to clang-format), really fast and accurate code indexing and navigation navigation, plus great CMake support. Oh, and it is free and works on Windows, macOS and Linux. Btw, I strongly suggest that you learn and use CMake (or something similar, like meson), rather than making your projects dependent on a specific IDE.
Thanks!!
That it is of no concern in your codebase does not mean it is of no concern for other code bases. Lots of functions in any code base accept pointers. You don't have to change existing code. Future code can benefit from this. You may have to call a function even if you don't know completely how it works inside, or some aspect of it is not documented properly. Better be safe than sorry. You don't need dual APIs. Existing code bases will work as is. Future codebase would benefit from it.
On x86 if you are storing SIMD types and use aligned load instructions eg MOVAPS your program will fault if you try to load from an unaligned address. 
[mp4 link](https://external-preview.redd.it/mp4/JK10SqgHvMQ_Oi11UeJG1GkuJWx9eaFogG-ZfeISRk8-source.mp4?s=b0677539f5637243bf62e9f71688909db0496870) --- This mp4 version is 87.94% smaller than the gif (488.44 KB vs 3.96 MB). --- *Beep, I'm a bot.* [FAQ](https://np.reddit.com/r/anti_gif_bot/wiki/index) | [author](https://np.reddit.com/message/compose?to=MrWasdennnoch) | [source](https://github.com/wasdennnoch/reddit-anti-gif-bot) | v1.1.2
Source code here: [GuiLite](https://github.com/idea4good/GuiLite)
I love this idea. But couldn't it be done even simpler? `typedecl Celsius = double;` would declare a new type Celsius that "inherited" from double, meaning a reference or pointer to Celsius would be valid as input to any function expecting a reference or pointer to double. It would have an implicit conversion to double (but not from) so anything taking a double by value would "just work". 
Would it be possible to finally fix our name mangling?
Sorry, I actually meant memberfunctions. Btw.: In your example, the compiker is absolutely within his rights to put all public members together at the start of the object c++ gives no guarantees on the layout of types with members of different visibility.
This kind of type system exists in Ada at least. It seems extremely useful.
I'm impressed. How long will a particular ABI be supported for? 
Well, modules might get rid of that requirement, but the Idea behind forward declaration of classes is specifically to only give the compiler the information it needs at that point (There is a class called `Foo`) and not force it to parse the whole definition and all the definitions of its members. 
I think they should at least now offer Intellisense for CMake in VS itself. Other than that, CMake in VS is rather nice. Maybe they are waiting till when they can implement the LSP 
You definitely need to respect the alignment. I deal with a couple of bugs a year where this goes wrong and the people involved decide it's a compiler bug (it hardly ever is). There must be more that don't get that far. The most common issue is that the big platforms (at least x86 &amp; ARM) have load and store instructions which crash when given a misaligned pointer, but are theoretically faster than the more forgiving equivalents. The compiler always assumes types are properly aligned and will use those instructions leading to a crash at runtime. Rarer, but still present, is that the compiler itself does some transformations based on assumed alignment. LLVM will transform `ptr + 1` into `ptr | 1`sometimes, as long as it believes the pointer is properly aligned. Obviously that goes wrong if `ptr` is odd.
Cool, thanks!
I've been hacking a bit at libc++.
 #define true (reinterpret_cast&lt;long&gt;(&amp;main) % 7 &gt; 3 ? 1 : 0)
The flashbacks... I ran into an actual undocumented cpu bug that made instruction address determine whether cpu sleep worked or not. That one was ”fun” to figure out.
With all this compatibility, shouldn't the default used toolset in a project be the most current one? Our main solution is set to v141 and I can't just update everything to 142 because my teammembers don't install VS2019 yet. &amp;#x200B; Also when installing only VS2019 on my pc with the v141 toolchain, compiling does not work: warning MSB8003: Could not find VCToolsInstallDir variable from the registry. TargetFrameworkVersion or PlatformToolset may be set to an invalid version number. &amp;#x200B;
JetBrains started to integrate clangd to clion so at some not too far point in the future your code completion concern may be resolved. I like clion but I'd recommend Vs for Windows too.
OSX user here. It seems CLion is a more reasonable option.
The demo has a Chinese name: 天女散花(means: fairy scatter blossoms)
I can't fault that logic, but I'm not searching the entire image of the process; I'm starting at my read-only string pointer, which may come before all the symbols. My program finds a *z* pretty close to the core dump (it ranks 6th-to-last and *Z* is 7th-to-last).
[https://drive.google.com/open?id=1L-oX-hIfBRz1pw5bpDwYxv0fA0ydNu\_y](https://drive.google.com/open?id=1L-oX-hIfBRz1pw5bpDwYxv0fA0ydNu_y) &amp;#x200B; Here it shows that size\_t is an unsigned int ( or UINT) and in your specific case, the function returns -1 through size\_t which is UINT and trying to assign an unsigned variable a negative value yields unknown results.
Uh, you probably want to be careful with that. The reference doesn't point at the function after all, it points at the other memory where you're storing the function pointer. If you let the function pointer go out of scope then your reference is invalidated.
&gt;That it is of no concern in your codebase does not mean it is of no concern for other code bases. And I did mot say that. But unless I see much more data about its usefulness in the wild, I don't believe it is valuable enough to put it into the standard and change the recommendations of how to write code. &gt;Lots of functions in any code base accept pointers. That may depend on the definition of "lots", but I definitely see far fewer of them nowerdays than let's say a decade ago (And don't forget that you can't change the API of l low level c interfaces anyway). Also, the important part was the second: How many of those raw pointers are used for deletion of an object? &gt;You don't have to change existing code. Future code can benefit from this. &gt;You don't need dual APIs. Existing code bases will work as is. Future codebase would benefit from it. The whole motivation of observer_ptr is that you don't know if **existing** code already follows the convention of marking owning pointers (smart_ptr or e.g. gsl::owning), so that any raw pointer can assumed to be non-owning. In newly written post c++23 code that should not be an issue. And if you don't rewrite existing APIs you are just going to end up in some intermediate mixed up state, where you still don't have any guarantees but have litter your code with explicit conversions. I'm not saying observer_ptr has zero usefulness. I'm saying it is neither useful enough, nor difficult enough, nor will its use be common enough to warrant inclusion into the standard. &gt;You may have to call a function even if you don't know completely how it works inside, or some aspect of it is not documented properly. Better be safe than sorry. You may not know, what it does exactly but destruction of an argument is a pretty significant part, not just some detail.
I used VS for Cuda-Development and in my opinion its a pain in the ass Now Im using CLion for C++ and I really like that IDE
I appreciate your contribution, but how is this compared to other embedded GL libraries like littlevGL? Nobody will use a minimal GUI library like this given sufficient resources, so it might be pointless to create a one-for-all GUI library.
What does your last paragraph have to do with alignment if the logic is always wrong?
FRequest! The name alone got to be worth something! 
I'd write this loop using the down-to operator: while (idx --&gt; 0) { ... }
While unaligned access is allowed on some architectures it may incur performance penalties from accessing multiple cache lines or pages. x86: unaligned access for ALU is always acceptable. For SIMD unaligned move instructions must be used, which have been same performance since Nehalem (2008) on Intel implementations. On AMD there is a performance hit as the aligned and unaligned move execute different microcode. ARM: a rule-of-thumb is that non-alignment is not encouraged. Most systems opt to configure the processor to work correctly with unaligned memory access but this varies and you cannot know that at compile time since the feature is configurable. To avoid headache it is recommended that you just align your data (-accesses). That said, there are reasonably simple ways to work around these things. For example, I have a serialization code which has stuff like: u16 foo = stream.read16(); float bar = stream.read32f(); I cannot know if the stream is aligned or not, or if the data is packed or whatever there might be.. I only read the file format specifications and it might say that "data is always DWORD aligned" or what ever. At any rate, the serializer has to deal with all kinds of formats so the read/write functions deal with unaligned data. This comes down to: u32 temp; std::memcpy(&amp;temp, ptr, 4); return temp; .. most compilers recognise the "short memcpy" idiom and for example on x86 generate "mov reg, [reg]" instruction, so it's OK. If you have configuration header where you detect platform, compiler and other details there can be a macro like PLATOFORM_SUPPORTS_UNALIGNED_STUFF and based on that you can do other optimizations if you find out that the memcpy degenerates into something that sucks on a specific target. Or you can go nuts with over-engineering like this code here does: template &lt;typename T&gt; class TypeCopy { protected: char data[sizeof(T)]; public: TypeCopy() = default; TypeCopy(const T &amp;value) { std::memcpy(data, &amp;value, sizeof(T)); } // copy-on-write const TypeCopy&amp; operator = (const T &amp;value) { std::memcpy(data, &amp;value, sizeof(T)); return *this; } // copy-on-read operator T () const { T temp; std::memcpy(&amp;temp, data, sizeof(T)); return temp; } }; template &lt;typename T&gt; class TypeSwap { protected: char data[sizeof(T)]; public: TypeSwap() = default; TypeSwap(const T &amp;value) { T temp = byteswap(value); std::memcpy(data, &amp;temp, sizeof(T)); } // swap-on-write const TypeSwap&amp; operator = (const T &amp;value) { T temp = byteswap(value); std::memcpy(data, &amp;temp, sizeof(T)); return *this; } // swap-on-read operator T () const { T temp; std::memcpy(&amp;temp, data, sizeof(T)); return byteswap(temp); } }; using int16le = detail::TypeCopy&lt;int16&gt;; using int32le = detail::TypeCopy&lt;int32&gt;; using int64le = detail::TypeCopy&lt;int64&gt;; using uint16le = detail::TypeCopy&lt;uint16&gt;; using uint32le = detail::TypeCopy&lt;uint32&gt;; using uint64le = detail::TypeCopy&lt;uint64&gt;; using float16le = detail::TypeCopy&lt;float16&gt;; using float32le = detail::TypeCopy&lt;float32&gt;; using float64le = detail::TypeCopy&lt;float64&gt;; using int16be = detail::TypeSwap&lt;int16&gt;; using int32be = detail::TypeSwap&lt;int32&gt;; using int64be = detail::TypeSwap&lt;int64&gt;; using uint16be = detail::TypeSwap&lt;uint16&gt;; using uint32be = detail::TypeSwap&lt;uint32&gt;; using uint64be = detail::TypeSwap&lt;uint64&gt;; using float16be = detail::TypeSwap&lt;float16&gt;; using float32be = detail::TypeSwap&lt;float32&gt;; using float64be = detail::TypeSwap&lt;float64&gt;; Above we had LITTLE_ENDIAN aliases.. for BIG_ENDIAN we would want to reverse the conditions. Now we can write: struct Foo { uint32be a; uint32be b; }; Now we can memory map a file, or read sizeof(Foo) into a buffer and just do this: Foo foo; int a = foo.a; int b = foo.b; The storage is char[] so the object will always consume correct amount of storage in the stream. Then alignment-neutral short-memcpy will used to construct the object w/o type punning caveats and the value is returned to the caller. In practise this compiles into one move instruction, or bswap instruction, depending on the endianness of the target machine and source data. The code is really fun to use and it generates good quality compiler output. The downside is that there is significant technical debt and complexity involved in such a trivial thing. :( RULES OF THUMB: 1. align your data! 2. if you cannot guarantee alignment, write code that is alignment neutral! 3. profit! 
Thanks for your question. Sincerely, I like littleGL very much. I believe you're the only person understand yourself, understand UI you want, no GL libraries. I want a UI library would be as simple as possible, even do not provide many default widgets(e,g. button, check box...) Because our UI maybe very special, no default widgets meet our needs. GuiLite has only 5,000 lines code(maybe 2,000 lines for core), it just show how UI work, and help people build special UI for themselves. I believe people will create wonderful UI if they understand how UI work. I never encourage any people use GuiLite, on the other hand, I want more people understand UI itself, and build unique UI for themselves.
There's actually a proposal to add a generic function pointer to C to solve exactly that problem: http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2230.htm
Ouch. I feel you. I once worked on a DSP chip (although in assembler) where you had to manually put NOPs so that both pipelines align perfectly. If you refactored code, you had to do it again. If you missed one single NOP, it just failed silently without any warnings and the code didn't work at all. 
Wouldn't that result in a combinatoric explosion of types? In the example with width and height, you'd sooner or later need the area. So you would define a new type Area based on width * height. Then you maybe need volume and so on... I think it is similar to the unit system for physical values like m, kg...Useful for consistency checks in formulas but if you use a calculator you do not want to specify the correct unit for each value all the time.
On a more serious note, C++/CX users would probably have a heart attack if this was added to Standard C++, and maybe Microsoft would as well
Thanks for the response, this answers my questions.
Yes, that was exactly my thought as well - I have no idea which order the symbols and variables come in.
That reminds me of TI C54xx I had to write a bit of asm for. That was decidedly unpleasant. What kind of idiot exposes the internal cpu pipeline to users? You had to consider address generation hazards and manually insert extra instructions in those cases or the dsp would just use old address register contents. Every sane cpu detects the hazard and inserts a stall. Except the C5xxx series...
For Windows 10 only work, check out C++WinRT
Wait! There's more! ;---) This code.. #include &lt;cstdint&gt; using u8 = uint8_t; using u16 = uint16_t; using u32 = uint32_t; using u64 = uint64_t; constexpr u32 make32(u8 s0, u8 s1, u8 s2, u8 s3) { return (s3 &lt;&lt; 24) | (s2 &lt;&lt; 16) | (s1 &lt;&lt; 8) | s0; } template &lt;typename T&gt; class LittleEndianStorage { protected: char data[sizeof(T)]; public: operator T () const { return make32(data[0], data[1], data[2], data[3]); //return (data[3] &lt;&lt; 24) | (data[2] &lt;&lt; 16) | (data[1] &lt;&lt; 8) | data[0]; } }; using u32le = LittleEndianStorage&lt;u32&gt;; u32 test(const u32le &amp;x) { return x; } Compiles differently (obviously) with different compilers. clang 7.0.0 mov eax, dword ptr [rdi] ret gcc 8.2 mov eax, DWORD PTR [rdi] ret icc 19.0.1 movzx eax, BYTE PTR [3+rdi] #20.50 movzx edx, BYTE PTR [2+rdi] #20.41 shl eax, 24 #10.19 shl edx, 16 #10.32 movzx ecx, BYTE PTR [1+rdi] #20.32 or eax, edx #10.32 shl ecx, 8 #10.45 or eax, ecx #10.45 movzx esi, BYTE PTR [rdi] #20.23 or eax, esi #10.50 ret #29.12 msvc 19.16 movzx edx, BYTE PTR [rcx+2] movzx eax, BYTE PTR [rcx+3] shl eax, 8 or eax, edx movzx edx, BYTE PTR [rcx+1] movzx ecx, BYTE PTR [rcx] shl eax, 8 or eax, edx shl eax, 8 or eax, ecx ret 0 Whoah... MSVC and ICC blow up the code, CLANG and GCC do the "right thing". If we DON'T use the make32() helper function but write the expression inline (commented out) EVERY compiler blows up the code! The build-with-shifts approach is THAT brittle. You never know what you'll end up getting out from the compiler. The memcpy is also volatile in this sense but it is more consistent in my experience. There was this article recently that claimed that you don't need to deal with endianness; just write neutral code like the make32 function is doing and you will be fine. That is true, if you don't care what happens as long as it works correctly (that is a highly valid and commendable attitude, and nothing wrong with it but I am a bit excessive detail-oriented, probably some kind of disorder, but anyway, this is how you do it if you like wasting time on details that probably won't matter anyway). ;-----) 
Seems to return the same void* value after the cast in every function you use this code. So does not seem to return a pointer/reference to the function pointer itself but to the actual function.
Not true. The original pointer is being cast directly. It gets cast from a function pointer to a void\*&amp; to a void\* without any dereferencing at all. [Here](https://godbolt.org/z/fdEgX6) you can see that it compiles to essentially a register move.
Visual Studio + some extension for refactoring (ReSharper C++ or Visual Assist X). That's what is using for every-day production development in many, many companies. 
Why not use Haskell's wording? newtype Celcius = double
`strlen` returns a `size_t`, which is required to be an unsigned integer type. Therefore, `idx` will be a `size_t`, and always be &gt;= 0. When it reaches 0, the next decrement will roll over to the maximum value for a `size_t`, so it'll never return--the `while` loop is infinite. A competently written compiler should warn you that the condition of the loop is always true.
You would also need to pay the dynamic runtime cost of initializing cout/cerr, for example, even if you don't need it.
For example if `ptr` is a plain `int *`, then that normally has 32-bit alignment requirements (ignoring weird platforms). That means any legitimate pointer will be == 0 (mod 4) and the transformation I mentioned is allowed.
If you are interested in something more experimental/academic, I wrote a C++14 ECS library for my CS thesis: [**`ecst`**](https://github.com/SuperV1234/ecst). It's a &gt; C++14 multithreaded compile-time Entity-Component-System header-only library where users define components and system in a compile-time DAG. The library then automatically parallelizes execution and separates data/system layout from the logic. 
Yeah, I've read a lot about it. Would be nice to try it out one day. At the present moment I'm working on two new applications, and maintaining third one, just three years old, that all need to work on Windows XP. Due to either business requirements (no resources to upgrade thousands of devices) or very specific market and userbase.
This is perfect, actually.
Thanks for sharing your blog, it's always good to have new material like this to read
You could just cast it to a void function pointer - C++ allows casts of functions to other types as long as you restore the correct type before calling. void (*fn)();
And I ask again: why can't the compiler figure that out? A hypothetical future compiler could easily scan your source code and derive a list of items that are declared and/or defined. Moreover, whenever it finds a definition it could also generate the associated declaration. It sticks all this knowledge in a database, together with a hash of each item that gets stored. Then it makes a second pass over each source file. It checks if any of the included items (from the database) has changed, and if so, it recompiles the source file. Of course, to know whether something it has changed, after compilation it writes out a list of symbols it used and their hashes. So all your symbols get extracted automatically, you don't need to forward declare anything because the compiler figures it all out on its own, and oh, by the way, we no longer even need modules because this solves all the same problems, without getting bogged down in dependency order problems. It all works nicely in parallel builds as well: while the two passes happen after one another, inside each pass you can operate on as many translation units as you want in parallel. We don't even need to change the language! It all works without any new keywords or new rules. All we need is a smarter build process that extracts symbols first, and then uses that as input for a second compiler pass.
Good Luck. My read of the Arduino Developer community tells me that Modern C++ or even templates is not something they admire/appreciate a lot. A lot of the places where Macros are used could be replaced with Templates &amp; constexpr with probably no issues at End User Level. Considering GCC is pretty good at optimisations, a lot of it would probably just get inlined anyways Arduino's would probably benefit substantially from addition of &lt;algorithm&gt; SFINAE et all would make substantial amounts of tasks simpler with no runtime cost. vector would be even more beneficial. Even optional would probably make Arduino development simpler But am not sure if there is even a push or a desire in that direction. I tried to make something similar to &lt;algorithm&gt; and it mostly involved copy-pasting the how-to of implementing from CppReference To better describe what I am saying think about how difficult would it be to implement Serial.println("The Speed is ", speed); Even today Serial.print("The Speed is "); Serial.print(speed); Serial.println(); doesn't really look like the most optimal solution &amp;#x200B; Implementing it would not be very difficult considering Varadic Templates are a thing. But even that's not something that has been implemented. While addition of STL is a wonderful idea to the Arduino Systems and something I personally support, I don't think the Adoption Rates are going to be high enough. And I personally believe, the Arduino Community is not very interested. 
In Haskell you spell it *Celcius*? ^joking^of^course
It does give some guarantees. C++11 gives even more guarantees, but it's true that compiler can group members with the same visibility together. But you can't rely on this anyway and it's not really done in practice, so the point still stands. For member functions: Hm, what's the big issue with exposing them? They are much harder to abuse than fields. Also, I haven't tried, but delegating all private functions to `class Aimpl`, and have just `friend class Aimpl` in `A` declaration would probably work to solve this "problem".
&gt; And I ask again: why can't the compiler figure that out? The problem isn't that the compiler can't figure it out. The problem is that it takes the compiler ages to figure it out. If my class has a std::string member then I currently need to include the string header which in turn includes all kinds of other headers. The compiler has to churn through all of that in every translation unit that uses my class even if that particular TU doesn't need to produce any code that actually involves std::string. That is what forward declaration would safe you. Sure, if you completely change the compilation model (I don't think this is possible without changes to the language because e.g. the overload set of a function calls explcitly only depends on symbols that you have seen so far in the current TU) that problem may or may not go away or be at least reduced but that isn't an answer for why doesn't that feature (forward declarations of memberfunctions) exist in a language that has had the current compilation model for several decades and probably will have to support that model for one or two decades more. 
I actually remembered seeing a blog post about implementing strong typedefs: https://foonathan.net/blog/2016/10/19/strong-typedefs.html
I grew up with Volume I; I might retire before Volume || happens :) Thanks John anyway :)
My questions are rethorical. We all know our decades-old compilation model has flaws, I'm trying to show a method that I believe will work much better. You state that including &lt;string&gt; is costly. I agree, and that's why I say we should stop doing that! This future compiler gets its symbols from its database, so it only needs to include &lt;string&gt; once, in a single translation unit. After that its symbols are in the database and can be used without parsing &lt;string&gt; ever again. Let's have a practical example. In source file a.cpp we have the following statements: int a = 1; int add (int x) { return x + b; } In source file b.cpp we have this: int b = 2; int main () { return add (a); } During the first compilation pass, we add the following symbols to our database: for a.cpp: int a; int add (int); for b.cpp: int b; We aren't actually compiling anything, or instantiating objects, or optimizing, we are just figuring out what symbols are available. This is cheap, and it can be done on any number of source files in parallel, so it scales well. Now, for the second compiler pass we'll pretend this information is implicitly forward declared in every source file, so we pretend the files look like this: a.cpp: // these symbols are implicitly declared. I show them here to show the effect: extern int a; extern int b; int add (int); // actual code the programmer writes: int a = 1; int add (int a) { return a + y; } b.cpp: // these symbols are implicitly declared. I show them here to show the effect: extern int a; extern int b; int add (int); // actual code the programmer writes: int b = 2; int main () { return add (a); } These two (imaginary) source files we can both compile, because they are perfectly normal C++. The second compiler pass has the same cost as today, except we have (almost) completely eliminated all of our include files - that information now comes from the database. There is also no limit on how many translation units we can compile in parallel. Now, notice that both a.cpp and b.cpp have the same implicit block of declarations at the top. No matter how many source files you are compiling, they use the same input - so we can load it once, and then keep it in memory until we are done. So not only is it stored in a much more efficient format, we do far less IO as well. Also, notice how there is a nasty cross-dependency between a.cpp and b.cpp. Modules cannot express this, but if we change our compilers like this, it isn't a problem. Note, finally, that neither a.cpp nor b.cpp has any #include statements. I didn't leave them out because I was lazy, but because they are not needed. I should mention that the database has a specific scope: it is equivalent to either a single static library or a single executable. So it doesn't include symbols from all over your harddisk, but just those symbols you are working with in your project. Is there a problem with overload sets? Possibly yes, but software that relies on that would be exceedingly brittle anyway (just one forward declaration hidden in a header somewhere could bring it to its knees). Is that enough reason to avoid what would certainly be a massive improvement for the entire C++ community? 
Here, have fun: https://gist.github.com/aras-p/6224951
Good point on the macros, didn't consider that. Precompiled headers is an interesting thought. They seem useful but how is it handled if you have a precompiled header and an include into that header is changed, does the compiler reliably detect there was a change and rebuild or is that something handled by the build tool? And do modules help with that situation?
I think the trick in the article might be useful for situations where you'd wanna pass a function pointer through some callback API that provides pointers to "user data" in the interface.
Here is where generic programming comes in. Templates/concepts would make it work.
&gt; A typedecl based on a std::string should bring its member functions, with all instances of std::string parameters replaced with the new type. I've wished for strong typedeffing too, but this is actually a really hard nut to crack. In some edge-cases, it might not make sense to replace ALL instances of std::string parameters with the new type... And how do you make room for these? Consider the following: ```cpp struct T { T clone() const; T convertToT() const; //provided to make T usable in generic code }; ``` Here only one of the T returning members should be replaced during a strong typedef. Also, if it was limited to functionality provided by members, it would be very painstaking to use this feature if you have a lot of functionality provided as free functions. A `void sortString(std::string&amp; s);` that is provided by some lib that you use suddenly not working if you create a strong typedef `Name` of `std::string` would be pretty annoying. 
If you consider "C++" your profession...
Rust is the biggest threat to C++ right now. There's no other language that covers that niches beyond C, and we all know how well that usually goes.
&gt; a data reference ... and thus it can be cast to `void*&amp;` Is that true? Can all data references be reinterpreted as `void*&amp;`? I've never come across this.
In my opinion i wouldn't focus too much on a language itself but on the skills that are transferable to any language. If you train yourself on general programming paradigms and develop your knowledge of concept, algorithms etc. the language itself is a merely a tool which is just another part of the solution. Why you choose a language may be out of your control but Bjarne Stroustrup even said you should know a few languages (cant find the exact quote but was in one of his many talks) 
I worked with other languages and technologies. However, I know that my strongest experience is in C++, and if I switch to another language, I can demand less pay. While engineers should be flexible, they should also have a specialty (which, admittedly, can change over time).
There will always be a need for a certain level of performance in a constrained systems that you can only get from zero cost abstraction languages. Right now it’s basically C++ that provides that, with Rust and maybe D being the only viable alternatives. The main issue is that the bar for a good language keeps getting higher and C++ is struggling to keep pace. As Rust matures C++ needs to fix its threading, module, editor tooling and packaging story. Those efforts are all under way, but it’s not clear we’ll be able to fully break free of legacy constraints. The other risk is that many performance critical systems are shifting to a machine learning core, where the real limiting factor is how powerful and fast the model is. And how good the training and evaluation infrastructure is for that system. In those cases C++ is only needed for a few core bits of the training system (ie TensorFlow), and a possibly very small wrapper on top of the inference system (ie data processing and GPU driver) at runtime. Other wise you can use a language with better tooling, and fewer corner cases. My advice is to become good at one popular service language like C# or Go, follow and play with Rust. Then if you have the aptitude and desire strongly consider working on machine learning it’s the new “software developer” a limited pool of people who can have a huge impact on a company and product. Your competition doesn’t really know software engineering, so you can bring a lot to the table with both.
I am not sure if I know what IS C++'s niche? If you add destructors and constructors to C (which seems to be kinda happening with gcc's extensions), I think it can replace C++ for many people. Others are just using C++ as a faster Java, and may decide that the rarity of C++ developers is more expensive than just throwing hardware at the problem.
Nope
As I said above: I worked with other languages and technologies. However, I know that my strongest experience is in C++, and if I switch to another language, I can demand less pay. While engineers should be flexible, they should also have a specialty (which, admittedly, can change over time). &amp;#x200B;
Python and Java are incredibly popular now, and you're almost always assured a job if you know either one of them (or both), mostly because they're not as concerned with the way things work under the hood (i.e. easier, faster to reach an audience etc as far as I've seen anyway). C++ will never really die out because of how much more powerful it is (job opportunities are still available, and the market is growing), it's just growing at a slower rate than the rest.
I'm been interested in the development of generators for Catch2, but I'm not certain of their function. For as long as I've been using catch, I've been using test-case driven tests, and not had any difficulties. Beyond syntactic sugar, it's not clear how they are better than simply using a loop inside of your tests. &amp;#x200B; [https://cx.rv8.io/g/a4jctU](https://cx.rv8.io/g/a4jctU)
Ya I understand but I dont believe the language is the limiting factor when it comes to pay but what the industry is demanding. I would tend to argue that demand is usually where the industry is trending (for example ML or AI) but I do not have enough market info to assess. You make a valid point regardless about the demand for certain skills but in the end an employer should value your experience over say your language you focused on.
Never understood such a narrow specialization. The company I work for just needs to know whether you are any good at C++ and then throws projects at you written in multiple different languages: C++, Java, Perl, Python, shell scripting etc. With help of search engines, once you know major important programming concepts, you can pick up new languages pretty quickly
I worked with other languages and technologies. However, I know that my strongest experience is in C++, and if I switch to another language, I can demand less pay. While engineers should be flexible, they should also have a specialty (which, admittedly, can change over time).
At least from my experience, I had much more leverage in jobs where it is very hard to find other programmers. Had this not only with C++, but also with other, more esoteric languages.
The problem I see is that c++ isn't truly zero overhead (C is the only one I know that truly deserves that lable) and there are fewer and fewer situations where the "near zero overhead" is worth the trouble compared to a different language that is easier to use and achieves almost the same or even identical/better performance or memory overhead. 
They can have sections without extra gymnastics.
GCC extensions make your code non portable; Java uses memory like a hog and in the days of big data that can be a problem (I've seen it be a problem); there are problems where you need C++ _because_ of the hardware.
You are right, the design prevent what I feared in the first place. Adding this compiler warning woul't hurt and may help detecting dumb misuses of Mutex&lt;T&gt; class. &amp;#x200B;
In many codebases, people don't care that much for portability. Also, I suspect that this extension will one day become a part of C, but admittedly that's just my guess.
It is far to be a threat honestly...
&gt; Blazing fast resolution using clever heuristics "clever heuristics". It appears only Conan handles binary distribution. I'm not sure why other "package managers" take it so lightly. There are some libraries at my work place that are 1+GB. It'll take hours to build their debug version on my personal machine. I simply cannot do a release build of these libraries on my machine.
I think the niche of C++ (fast, small footprint, close to the metal, yet very library rich and relatively safe if you follow certain paradigms) is not going away any time soon. Whether it is going to be defeated by other languages is another question, but I think we'll be able to adapt
Some side menu for easier navigation would be quite handy in my opinion.
My bad, I misread the assignment. However, this is no more portable than the other option was. If you enable the right warnings, clang will tell you as such: https://godbolt.org/Z7G19l
I work in the games industry, and C++ is going _nowhere_. Everything is in C++, no AAA games are made in _anything_ else. We are seeing a shortage of skilled C++ programmers as well, so my company are actively working with the local university to improve their C++ course and hiring and training graduates. My company isn't alone in this, there were a dozen different local C++-centric companies represented at the last industry feedback panel the university held. The shortage of developers seems to have been largely caused by industries insisting on only hiring "experienced developers" for the past decade, and that attitude has turned around to bite us due to there now only being a small number of highly experienced developers with nothing below.
Buckaroo has a package cache and the underlying build-system solves the problem of accelerating the build using \[caches\]([https://buckbuild.com/files-and-dirs/buckconfig.html#cache](https://buckbuild.com/files-and-dirs/buckconfig.html#cache)). This problem should be solved using a build cache not binary packages. However "clever heuristics" refers to the resolution process that determines the right set of versions and packages to install. Unlike Conan, Buckaroo works without a central registries and complex version constraints. As a result versions and packages need to be discovered. GoDep has this same \[challenge\]([https://github.com/golang/dep/blob/master/docs/FAQ.md#why-is-dep-slow](https://github.com/golang/dep/blob/master/docs/FAQ.md#why-is-dep-slow)) but does not use the heuristics. Without those heuristics resolution time increases from 7s to upto 20min for large projects. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
&gt; compiling does not work The issue and the workaround are described here: [https://developercommunity.visualstudio.com/content/problem/434385/vs2019-preview-2-targetframeworkversion-or-platfor.html](https://developercommunity.visualstudio.com/content/problem/434385/vs2019-preview-2-targetframeworkversion-or-platfor.html)
[https://unity3d.com/](https://unity3d.com/) [https://en.wikipedia.org/wiki/C\_Sharp\_(programming\_language)](https://en.wikipedia.org/wiki/C_Sharp_(programming_language))
I'm aware of Unity - it's not widely used in AAA development. Pretty much everything is UE4 or custom engines, all in C++.
&gt; there is no competitor to C++ in that field &amp;#x200B; how about there is but people use something else..
In what respects do you find that C++ has higher overhead than C? Basically everything, with the exception of exceptions, can be eliminated by the compiler in either language.
Something existing doesn't make it a _competitor_.
&gt; should be solved using a build cache And money should be free. I've tried using ccache just for my own object files, but it just leads to me having to clear the cache regularly because there's nowhere near that much disk space available. Imagine if I had to do that will all my dependencies.
I can't see the future. However I know some people who are currently working as specialists in Cobol and some in Smalltalk. And they have a lot of job security because they're very hard to replace. I suspect that may be close to worst-case-scenario for C++ in the coming decades.
https://en.cppreference.com/w/ is the best documentation around and it's free
See https://en.cppreference.com/
I wish the reference would look nice on the phone
Asking this question seems to be implying that you've came across... paid C++ standard library documentation?
Didnt both of them move to a Clang based implementation? Thought that would be fast to be honest
And you can use it offline with Zeal: https://zealdocs.org
The official C++ standard document is pay-walled, and Microsoft used to make you pay for their MSDN documentation IIRC - but you can get the _draft_ C++ standard for free (which is essentially the same as the standard one) and MSDN is online now. Everything else I've ever seen is free, so I suspect they just didn't look.
&gt; money should be free amen [CChache](https://ccache.samba.org/) has a garbage collection scheme. Is this hidden behind a config? &gt; level 3ShhTinyBanjoPurr2 points · 14 minutes I've tried using ccache just for my own object files, but it just leads to me having to clear the cache regularly because there's nowhere near that much disk space available. Imagine if I had to do that will all my dependencies. We usually use a cache on the network where diskspace is not an issue. Additionally this way the cache is shared between other team members.
I also have another question, I am following Programming Principles and Practice using C++ by Bjarne Stroustrup to learn C++. Should I go through chapter by chapter or what should I do? &amp;#x200B;
That is just wrong, that code is only muting a compiler warning, that is not the proper way to do anything. Either the target processor architecture has no issues with casting to ***void\**** and there is no warning, or one should take in mind the warning and give a proper solution, not just hide it using some cheap trick. 
In VS 2017, you can use CMake directly without the need to generate an IDE project They use Ninja by default for building the CMake Projects
Then what if you just get STL for free? It doesn't seem like too much of a leap to imagine that if the compiler sees `std::vector&lt;int&gt;` then it just pulls in what it needs to compile it. Now that we wont have to text-substitute the entire stl source at the top of the file, it seems somewhat plausible in this fantasy world I've invented.... Assuming people couldn't create their own std namespace with their own vector in it... which they probably can.... So, never mind. I retract my crazy thought experiment. &amp;#x200B;
How much disk space does it use? A cheap 256GB SSD can be bought for $25 USD.
 #define false !std::rand() or #define throw &amp;#x200B;
There might be another reason for that shortage: game companies have a towering reputation for being absolute shitholes to work for. Nice when you're below the age of 28, and don't care about spending 200+ hours in the office every week for a bonus you might not even get if your metacritic score is one point too low, but unsuitable if you care about anything else in your life. 
The problem is that the way it's suggested in the article, it actually misses much of the point of strong typedefs. For example, let's say I want to create a strong typedef to an integer, that represents a student ID. Adding two student IDs just does not make any case, neither does multiplying them, etc. It's not really clear to me what the distinction even is between "internal functionality" and "external functionality"; the article never really makes it clear. As a lot of people have posted about, this is fairly well doable in C++ as it stands with only a moderate amount of boilerplate. You basically just write a bunch of mixins that forward functionality, then you have a class template that encapsulates the existing type and creates a new type. You can with a very lightweight macro get the syntax down to: DEFINE_STRONG_TYPE(MyType, int, Hashable, Comparable) For example. And it works just fine. It takes like a day or two to implement and then you can create as many new types as you want with most of the functionality described, and better (except for the ability to "clone" whole namespaces at once).
Too true - but actually a lot of companies have changed that as their workforce has aged. There basically isn't anyone between the ages of ~23 and ~30 in the AAA companies _at all_ at the moment - as a result the majority of employees actually have families and won't work excessive overtime. The recent story with Rockstar is pretty unusual for an AAA.
It looks like that book has sections at the beginning about the structure of the book and its approach to teaching the language. Those would probably tell you how the book is intended to be used.
Chapter-by-chapter. It's not meant to be a quick reference.
Some hardware/OSes will generate unrecoverable faults on alignment violation. Some compilers will generate "bad" code when the programmer triggers UB by violating alignment rules. Sometimes it will seem to work just fine, but you can observe in a profiler fairly large perf gains by using the correct alignment. Folks also forget how alignment and cachelines interoperate. Namely, it's normally impossible for primitive scalar types to span cacheline boundaries, but ignoring alignment concerns makes it possible (which then has a further perf cost, even if you're just `memcpy`ing and not even violating the alignment rules!). Computers is hard.
So a couple of things: * I completely agree that the majority of arduino users won't rely on the STL if it were there, I'm more interested in targeting library developers, I've seen some pretty advanced stuff go on behind the scenes, from weird template metaprogramming and all the way to embedded ASM code, I doubt there's as big a profeicency gap there. * A big part of my motivation here was how surprised I was seeing that GCC-avr could target C++17. Embedded programming is like, one of the best use cases for compile time optimization, and it saddens me how much harder that is to do without some of the basic facilities you get from the standard lib. * There's alot of existing C++ code that would work wonders if it could be made to run on arduino. That problem you've got with println? How much better would it be if you could just use [fmt](https://github.com/fmtlib/fmt)?
I work in Jerusalem and in my company and field c++ is the dominant player. So although I too sometimes worry like you about the future of c++ developers (and native development in general), I think that soke markets will remain for a long time c++ oriented. BTW, you might consider coming to the c++ conference in Tel Aviv. https://corecpp.org/
&gt; We also removed 17k lines of Java code Yes!!! &gt; and replaced it with 8k of F#! Oh, no... :(
**Company:** [Maven Securities](https://www.mavensecurities.com/career-opportunities?gh_src=b9adf9d81) **Type:** Full time **Description:** Maven is a proprietary high-frequency trading (HFT) organisation formed in 2011. We employ the most talented traders, developers and engineers in the market, executing a diverse range of strategies across global equities and derivatives. We are the most active participant in many of the products we trade, contributing significant liquidity to markets around the world. Core to our success is a tight integration between trading, research, and technology, and everyone involved in making these pieces come together. Maven has a culture that is relaxed and informal but highly rewarding of strong performance; there's no dress code, plenty of free food and regular social events. We have offices in London, Hong Kong and New York and will be opening a new Chicago office in early 2020 as part of our plans to expand our coverage of derivatives markets. **Location:** London, Hong Kong **Remote:** No **Visa Sponsorship:** Yes **Technologies:** C++11, C++14, C++17. Low-latency networking, Linux kernel, FPGA, Julia, data analytics. **Contact:** Apply at [https://grnh.se/741a6cdb1](https://grnh.se/741a6cdb1) or visit [https://workatmaven.com/](https://workatmaven.com/)
Precisely. I am completely in agreement with you.But the reason STL is successful is because it's available by default. For example, MSVC/Dinkumware STL on Windows, Libstdc++ on Linux etc. Arduino would never support nor ship with anything as such by default. Rather than using something like fmt, it would be very simple to extend Serial.print functionality using variadic templates `template&lt;typename T, typename... Others&gt;` `void print(T t, Others.... others)` `{` `print(t);` `print(others);` `}` But something as simple as this hasn't still been implemented. GCC AVR can support C++17. Arduino probably can itself make substantial gains by using if constexpr. But would they is an important question? In fact Arduino can and should use Templates. Templates probably would grant them a substantial rise in speed. But they don't. Or for that matter Lambdas. Even those are not completely supported I believe. &amp;#x200B; I would disagree with using inline assembly a bit much. Inline assembly would render the STL, this community creates for an Arduino useless for other boards like Teensy which are substantially compatible with Arduino as far as code is concerned but utilise 32 bit ARM Processors. 
What about https://devdocs.io/cpp/? It looks like Zeal (with multiple doc sets), but in the browser instead of a separate app.
Unity is also written in C++, but its game logic uses C#. So its a weird trade off right.
Productivity and age. Compile times, a language and its STL designed when CPUs cache, modern network and multi-core CPUs didn't exist. If you use C++ for performance and memory control you have to use the "dark magic" of template metaprogramming which leads to even longer builds. Not saying "bytecode" languages like Java or C# have all of them but they're far more productive and have very decent performance for many uses. Having an owner (Oracke, Google, MSoft) has its pros. Not C++ fault, but in the long run some fast compiled language will replace it. Rust or another, who knows.
Offline???
A non-exhaustive list of official proposals to add "strong typedefs" to the language that should be perused and studied closely before making new proposals: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2141.html http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0109r0.pdf https://isocpp.org/files/papers/n3741.pdf None have gained traction because there's all kinds of tricky edge cases and usability problems for different potential uses. It's easy to make a proposal that solves _your_ use case but troublesome to also handle everyone else's with an acceptable interface. :)
If you don't need to support all the operation of the underlying type then you can implement your type the old way. Strong typedefs are useful only when it is meaningful to inherit features from the underlying type. 
We were looking forward to writing it in C++ but the lack of monads and tail-call recursive coroutines made it a quite scary task and hard to get it right. We invested quite a lot of time and even wrote \[conduit\]([https://github.com/LoopPerfect/conduit/](https://github.com/LoopPerfect/conduit/)) but concluded that the CorotineTS is not quite ready for such a task. We had to fight with many compiler bugs and ICE (Internal Compiler Exceptions). &amp;#x200B; We don't think this detracts from C++ in any way, you need to use the right tool for the job. 
What's "offline?" On a serious note, is anybody ever offline these days? PS: I'm downloading the Boost docset in Zeal right now. It's taking 10+ minutes. Instead, I could go online and look up what I need in seconds.
Try https://devdocs.io You can save it for offline use and it supports dozens of other languages. 
Do you think it will have interesting content for someone who has a very deep knowledge of C++? (I implemented features of C++ before they were there using compiler plugins and template libraries of my own)
They have a lot of job security, but few jobs. 
I am offline when working on a train.
I haven't been a full time dev for long but from what I've seen around companies seem to know that C++ developers have pretty strong knowledge of the basics and understanding of algorithms and the internals of software development since you usually fall into efficiency and memory handling by hand, through this if you're good at C/C++ one could say that working in a new language is just a matter of picking up a reference and getting used to it, so no I don't think C++ is going anywhere but as other have mentioned there will probably be less C++ developers in the future since the new "trendy" languages go to python and JavaScript and such. Albeit if you dear falling into a niche it would really be good if you get to know several languages, I don't think you should master them but get a good grasp at them, anywhere from c# to specialty ones like Matlab or something like that.
I understand that there are reasons for using Java or F# instead of C++ or Python or any another language. But if not C++ then Python or Ruby is more preferable because some kind of scripting language is used anyway in development, sometimes both. And both of them are more widespread in C++devs than F#.
So does it require the Mono runtime on Linux now? This is all too complicated. I prefer the simple `pip install --user conan` instead.
No, It is a self-containing native executable. It does not even need python.
Neither Python or Ruby have the features we required for building Buckaroo. If we had to choose between Python, Ruby or C++, C++ would be the preferred language due to templates, typesystem and performance
&gt; but the lack of monads and tail-call recursive coroutines I know, right? How did we live without monads and recursive coroutines before?
Ohmygod, is it 2000 again ? I heard this since forever. C++ is alive and well. It will never be a language for everyone, but is the safest bet for anyone looking for absolute raw performance and control. &gt; most companies would shift to other languages because of this shortage. No, most companies would shift if they can use something else. But are you going to write firmware in C# ? Drivers in scala ? Web browsers in javascript ? AAA games in erlang ? A compiler in phyton ? As long as there will be n advantage to be close to the metal, C++ will be alive. Or another close language. 
At first glance I thought `while (idx--)` would leave us off by one somewhere, but it doesn't. It's a nice, simple fix.
Unless you have some overarching objection to .Net, rewriting Java in a saner language should always be applauded. F# is strongly, statically typed – Python or Ruby are too different to be "preferable", and if you don't know enough about F# to know that then why are you being critical of it? "People" not knowing it is not an answer.
Writing highly complex applications were hard to get right and a maintenance nightmare. It might sound like a cheeky response but, it is similar to the jump from assembly to oop. We tried in Buckaroo V1 to manage concurrency using Reactive-Extensions but the lack of recursion made some algorithms very complicated. Furthermore not having syntactic sugar for monads required us to write a lot of boilerplate to deal with callback hell. This added a lot of cognitive overhead and made it hard to write concise and algorithms that are easy to understand. 
"preferable" mean not "preferable for authors of Buckaroo" but "preferable for users of Buckaroo". As a potential user of a package manager for C++ I don't understand why I should to install another tool with installer in 65 megabytes. Just for a package manager.
I hadn't looked into that. I should. &gt; where diskspace is not an issue. I don't have access to any such place. &gt; cache is shared between other team members. I can't even get the ccache binary shared between users on the same machine. Must be nice to have cooperative admins.
I would get in trouble if I tried to bring my own storage into work. But yeah - I agree it's a silly thing to limit people on.
I'm not sure if it is being developed actively. But I found Nonius (https://github.com/libnonius/nonius) to be a much better micro-benchmarking tool than Google Benchmark. Interactive HTML reports with interactive graphs, automatic timing bootstrapping, statistics calculations (sd,min,max etc.) and much more in a single self-contained header file is pretty cool + no other dependencies. + It's much more easier to intergrate than GBenchmark. 
&gt;money should be free &gt; &gt;amen Oy vey.
True. I'm not saying it's a good fate, but it does establish a floor it's unlikely C++ won't fall through in my working years.
1) We offer a self-contained executable. This means no other dependencies need to be installed and it should work on all platforms. We could make it leaner and depend on things preinstalled on your system, but in our experience this does not work as nice in practice. 2) 65mb are not a lot, especially considering in a world where most IDE's are electron apps and IDE's like visual studio are dozens of Gigabytes big. 
http://eel.is/c++draft/ if you need a latest draft of the ISO C++ Standard. 
One simple library is TinyExpr [https://github.com/codeplea/tinyexpr](https://github.com/codeplea/tinyexpr) (zlib license)
Damn those Admins! I really feel sorry for you. This is really detrimental for productivity. Wait do you guys use bintray? - Let me get this straight: So you cannot share a CCache on your local network but you can download arbitrary blobs off of the internet and bundle them into production applications?
That's fine, but I'm asking, how much does it actually use? You just said 'there's not enough disk space available', how about throwing out a number. 
Do you do a lot of coding on your phone? I know it's possible, I just don't know anyone who does it a lot.
Well, _my_ trees grow from the root up! :-D Did that and added a few more free functions to get a more uniform interface: https://github.com/rec/tfile/commit/bc2c668758a4e3be3f5baf58cade5f4363cf6773 
&gt; Adding this compiler warning wouldn't hurt and may help detecting dumb misuses of `Mutex&lt;T&gt;` class. Yep; that's why it's a nice warning: 0 false-positives. 
&gt; We offer a self-contained executable. What's about FreeBSD? &gt; 65mb are not a lot For example, we use several VMs and several Docker-images for building software in different conditions. There are no electron based apps nor IDEs. Only necessary minimum.
I have no idea what you mean here, or what you are referring to by "the old way". You also jump between your first and second sentence "all the operations of the underlying type", and then "to inherit features" (no "all"). A strong typedef for a T where you can opt in to which T-operations you want for your strong typedef is very useful indeed, I use it all the time.
&gt; Bench-marking shows that in the 2D case, plain linear search beats all for up to 50 elements. This particularly happens if you keep keys and values separate, and your keys are simple: searching a particular u32 in an array of u32 is so vectorizable! I think in this sense, you could even implement an "unrolled" Eytzinger layout where each "node" is actually a small array of 4/8/16 elements (keys and values stored in two arrays), with the usual two children: lesser to the left, greater to the right.
It's one of the little tricks you learn if you've written a bit of C89.
&gt; In most cases there is no run-time cost to enforce the rule in Rust, but in some cases enforcement has to be provided by a `Cell` wrapper, which does have a run-time cost, or a `RefCell` wrapper, which also introduces the possibility of a panic. Actually, `Cell` should have no run-time cost: it has no memory overhead nor extra state, it simply forces you to `Copy` in `get` and `set`, and `Copy` types are generally cheap enough (`i32`...). You may be mistaking it with `RefCell` which keeps a counter of readers and writers, and therefore involves a small memory and a small run-time overhead both for obtaining a read reference and a write reference.
There's lots of things idiomatic in C that are higher overhead compared to their idiomatic counterparts in C++. A (no doubt partial) list: - passing functions - data encapsulation - passing stack arrays - generic code Outside of exceptions and RTTI, in C++ you generally only pay overhead when you actually use something, and it's more expensive than the C version because it's doing something the C version doesn't, which doesn't violate zero overhead.
No. Artifact repository is in-house. 
I routinely pull up documentation on my phone when I am talking with coworkers. This can be in meetings, hallways, or at their desks. Anywhere that isn't my desk really.
I'm not the GP, but for me the point isn't about _coding_ on the phone – I only have a 2nd screen about half the time but I always have my phone.
Come on profession is much more syntax. Your experience will not vanish if you are thrown at a Rust or C# project. 
Is there any reason why compilers can't just make `#include &lt;header&gt;` effectively just import an implementation-defined module that exports the entities that &lt;header&gt; is supposed to provide? &amp;#x200B; For example, #include &lt;header&gt; would be translated to: `import __std_legacy_header.header;` or something similar? &amp;#x200B; That way users get most or all all of the benefits of standard library modules without even having to change any code, and any reorganization can be deferred until there is more experience with modules.
&gt; Strong typedefs are useful only when it is meaningful to inherit features from the underlying type. That is, almost never. 
You just want boost::units. 
Actually... infinite loops are Undefined Behavior in C++. It's been annoying Rust embedded developers for a while, because the assumption is simply baked in LLVM, and using `loop {}` is often in embedded development instead of `abort` as it "pauses" the program which gives the developer time to hook-up their debugger and see where the program paused :(
Another form of writing that is `while (idx --&gt; 0)`. That arrow is actually `--` (post-decrement) followed by a regular `&gt;` (strictly greater). *Strictly same semantics, just potentially more "telling" visually.*
I've still got a good 30 years to go before retirement, and I'm pretty sure I'll find C++ gigs aplenty until then if I wish to; there's so much existing C++ code, it won't disappear overnight.
&gt; it's often fine because `std::aligned_storage_t` defaults to `max_align_t` which is supposed to be the maximum alignment of any fundamental type on your architecture. Unfortunately, that's likely 8/16 bytes only, and it's pretty common to have 64/128 bytes aligned types (see `std::hardware_[constructive|destructive]_inference_size`). 
&gt; This problem should be solved using a build cache not binary packages. That's certainly not something everybody would agree with. The behavior of a build depending on the existence of a cache means that you can't expect the same behavior when trying to reproduce a build. It also means you can get different behavior on different CI servers that are intended to be interchangeable nodes in a cluster if you allow that cache to persist. Depending on cached results for things to work correctly instead of having binary artifacts basically eventually always results in some variation of being unable to do a clean build from scratch... Why did my build fail? Oh, it timed out. Why did it time out? Because server003 or 003 are the only ones with pre-populated cached dependencies, so you have been chasing your tail trying to understand what you broke -- Just keep resubmitting it until you hit the magic box with the pre-populated cache and ignore the CI build failures. ... Okay, I got a build to go through that hit the box with the cache. But now production is getting an error that I can't reproduce on my dev box. Oh, right, the cache on server003 was made in 2017, so it uses really old version of the libs. You should only actually deploy the builds from server004 because it has versions from 6 months ago. Can we clear the caches and start over? No, then we wouldn't be able to build at all because only certain accounts can put the cache somewhere globally visible, so all your builds would just fail by timing out and be unable to persist the cache until dave gets back from vacation to do manual builds.
As long as people decide to do badass projects in C++, there will be a market for C++ programmers. &amp;#x200B; Look at Vinnie Falco's Boost.Beast. It's an incredible project, fast and easy to use. He just laid a foundation for Django-style web frameworks in C++. I suspect an entire ecosystem will spring up around it. &amp;#x200B; And almost all new numerical mathematics codes are being written in C++. Tensorflow, CUDA, deal.II, Stan. These projects won't switch to a new language overnight. &amp;#x200B; I'm not the least bit worried about the future of C++, but if your "doomsday" prediction for C++ is correct, I don't really care. I like Python and Rust and modern Javascript as well.
It's Undefined Behavior. There are a number of answers which explain the difference between various architectures (ARM, x86, ...). They give good advice if you are writing assembly. Since you are writing C++, however, those answers are awfully incomplete. **Undefined Behavior is a contract between the developer and the compiler: YOU promise it'll never happens, and the compiler assumes you will hold your promise.** As a result, Undefined Behavior may "strike" at two stages: 1. During **compilation**: the compiler may emit "nonsensical" assembly. 2. During **execution**: the run-time behavior is unpredictable. For the particular case of unaligned access, I've seen really interesting compiler optimizations happening in the wild. For example, I remember a compiler optimizing a CRC routine which was something like: std::uint32_t crc(char const* begin, char const* end) { auto view = (std::uint32_t const*) begin; auto end_view = (std::uint32_t const*) end; std::uint32_t result = 0; for (; view &lt; end_view; ++view) { result += *view; } // Don't cite on this, my memory is shaky. This was supposed to take care of the potential remainder bytes (1 to 3). auto p = (char const*) (view - 1); if (p != end) { char buffer[4] = {}; std::memcpy(buffer, p, end - p); result += reinterpret_cast&lt;std::uint32_t*&gt;(&amp;buffer); } return result; } The compiler looked, assumed that `begin` and `end` were 4 bytes aligned^1 , and thus that `p != end` was therefore always false. It also somehow transformed the loop to do one more iteration than expected on unaligned data, leading to reading between 1 and 3 random bytes. Needless to say, the CRC result it got was... *interesting*. Even more deliciously, somehow the optimization wasn't triggered in the *unit-tests*, so that the tests were all correct, and only in actual field-testing was the CRC wrong. *Surprise* ^1 *Certainly, no true C++ developer would violate alignment requirements, right, RIGHT?*
The proper fix is to change the API to take a `union { void *data_pointer; void (*function_pointer)(void)}` so that whatever one is larger will fit.
I’m pretty sure the inter generational star ships of the future will run on top of old C and C++ code
Except that's just not allowed, strictly speaking. :) A `void*` is not guaranteed to even _be able_ to hold a function pointer (as in, `sizeof(&amp;funcion) &gt; sizeof(void*)` is allowed). See the answer at: https://stackoverflow.com/questions/3941793/what-is-guaranteed-about-the-size-of-a-function-pointer You're unlikely to run into problems on mainstream CPUs (x86/x64, ARM, etc.) but there's a reason that the standards haven't just "fixed" their language: there are still CPUs in active use that make use of these liberties. There are still non-8-bit-byte embedded CPUs manufactured this decade and in active use, for example.
I actually really like going to a coffee ship and _not_ getting on the wifi, so I can spend some time working on a project where my really bad habits checking my email/facebook/reddit/whatever every time I get distracted aren't applicable. Turning off the wifi is a really good mitigation strategy for having the attention span of a... brb, just got a Facebook chat message.
MS Visual Studio docs including C++ are available online, downloadable as pdf and are very human readable if I may put it so. Unlike the standard or even cppreference.
The compiler doesn't detect such things. That is the job of the build tools. Just like the compiler won't check if an object file is out of date compared to the reference source file. Modules are the same thing - you're 'precompiling' source file(s) into a module, which is effectively a trimmed-down precompiled header that also includes implementation with special syntax. I actually have an urge to write a parser to go over the entirety of WinAPI, and generate module interfaces for it. Be *much* nicer than `#include &lt;Windows.h&gt;`. Not sure if there is a 'standard' module file extension, yet... I know that MSVC uses *.ixx*, don't recall what Clang uses off-hand (I just use *.ixx* there, and am specific to the compiler about what I am doing). Modules (and precompiled headers) are greatly dependent on build tool support. CMake's support for PCH is... not really existent. I know that build2 supports modules, unsure about PCH. MSBuild supports PCH, but doesn't have any proper support for modules - it can build them, but it has no way to resolve dependencies.
That opening paragraph was so well-crafted I feel microtargeted.
&gt; microtargeted Is that when they lock onto your glowing red weak spot?
`57d::un0rd3r3d_m30w`
&gt; Actually... infinite loops are Undefined Behavior in C++. Correction, infinite loops without side effects are UB. I am aware of problems that may arise from that, but for these cases `volatile` is your friend. Accessing a `volatile` variable is a side effect, so `while(volatile int i = 1);` isn't UB.
I downvoted because I'm not a fan of jokes/satires like this, but &gt;One Definition Rule (0DR) violations is clever
Your background sounds a lot like mine -- deeply embedded, DSP, MCUs, assembly language, etc. &amp;#x200B; You mentioned exposing the pipeline -- have you ever worked with MIPS (or SuperH, or even the older SPARC processors). If so, you might be familiar with the term "[branch delay slot](https://en.wikipedia.org/wiki/Delay_slot#Branch_delay_slots)" -- this is the instruction (or two) /after/ a branch instruction, that is executed /even if the branch is taken/. Again, the pipeline... &amp;#x200B; As a consultant I used to port a lot of RTOSes to different CPU architectures for RTOS companies. The things I've seen... between the tools, the chip architectures, the errata (I'm looking at you, ARM), cache coherency and flusing, latent bugs in context switch routines, etc. &amp;#x200B; Good times.
Double-plus-ungood.
Thanks. I was probably thinking about the `Rc&lt;&gt;` case where often the target type isn't small so the copying could have some cost.
Your posts sound like a broken record where you worry about pay while at the same time claim that there is a demand for C++ programmers. The lack of logic here is surprising for a programmer. As for the future why worry. Seriously there could be a nuclear war tomorrow or Yelliowstone could blow dramatically altering life. As for C++ there are no good alternatives at the moment. Rust is a bit of a joke and Julia, Swift and others are too immature for serious use. It may take 5-10 years before something like Swift is accepted as a C++ replacement and frankly id be surprised if it ever does. There are a number of lesser languages that are extremely popular such as Python. The priblem here is the types of projects such languages are suitable for are limited. Further I’m not sure how to put this delicately but many programmers gravitate to Python and other easy platforms, because their gray matter can’t handle more demanding projects or languages. 
If we could inherit from primitives, it would also be easier.
I have a Starbucks near me that I go to that has *very* slow non-google WiFi that gets me to be more productive due to the incredibly slow access to things like image and "live" javascript pages. It also blocks connections through port 22 though(lots of public WiFis do this for some reason) but my servers have their ssh on non-standard ports. I can't use github's ssh though but a simple ssh alias will help with that: Host github.com Hostname ssh.github.com Port 443 [devdocs.io](https://devdocs.io) also supports saving the documentations locally for offline use so I can easily remind myself of printf format specifiers for the 5998350923th time.
I actually prefer Python for its scripting abilities but it is a terrible solution where C++ is often a better solution. In a way it balances the capabilities of C++. It is better to think of them as players on the same team than competitors. BEyond that python allows contribution from a wider array of project team members. while C++ is a powerful tool for more advanced team members. 
There are some standard ones [such as `_IOFBF`](http://eel.is/c++draft/cstdio.syn) inherited from C
I suspect you are misinterpreting the data. The advent of web technologies and the associated languages does not imply a contraction in industries where C++ is heavily used. The only thing these new industries offered if the ability for anybody to call themselves a programmer as long as they write code in Python or JavaScript. Too many “programmers” these says suffer from very thin knowledge of computer science. 
Is it April 1st already?
Would you have some links to the right cmake tutorials?
Kona meeting in February is the closest one to April, so... yes.
Thanks for the reply I am definitely trying to avoid undefined behavior.
I don't write code on my phone, but I do write a shit ton of notes about algorithms I'm developing.
Nice job. Have you thought about porting the demo(s) to the lower cost and more powerful [32F746GDISCOVERY](https://www.st.com/en/evaluation-tools/32f746gdiscovery.html) board? The '746 board is about 7x cheaper than your board, the M7 CPU is about 5x more powerful. &amp;#x200B;
Processed your comments. Thanks again!
I appreciate all the details, but it seems we've now come full circle as based on everything you've said I'm still unsure what problem modules solve that good organizational practices in standard code development don't handle. But I do thank you for the informed responses.
Modules are just fancier, standardized, more effective precompiled headers that also hide implementation details. You can accomplish the same other ways, though modules will likely be simpler and more effective.
If they actually get delivered. :D
I get that this is satire, but I don't quite understand if the author is satirizing aspects of C++ as well. Also, I'm on the verge of growing old and haven't programmed in any language other than C++ for over a decade, how do the modern languages measure up to C++ in performance?
That was too aggressive on my part, I apologize. Fair enough. I don't care to use Clang because of their treatment of some of the edge-cases and UB still not mimicking MSVC's behaviors, even with their extensive work at supporting the ABI. For some reason, I have less issues using GCC than Clang. For example, clang has decided that naked functions are essentially useless without raw assembly, which is not the case in either GCC or MSVC.
C++ may not be going away, but the jobs are just not as common as other languages. I doubt it will be "defeated" by other languages, at least not for the domains it still dominates, but one should be flexible when it comes to jobs.
&gt; If you add destructors and constructors to C (which seems to be kinda happening with gcc's extensions), I think it can replace C++ for many people. C has enough tooling and low-level compatibility to bypass C++ for native code, but it comes at a cost. If you're talking about enhancing C, then you're better off just using C++ anyway.
std::iota
After six years or so of experience, if your main selling point is language expertise you probably don't actually have a "career", you have a job. You should have both broad technical domain knowledge in an area, and also know a lot about business operations in a sector. Maybe you've not properly developed a career. I would worry about that, not C++ job postings or book sales.
Wow! Thanks for your vote of confidence. I'm really looking forward to presenting this paper at Kona. My hope is that it will unanimously pass, but if there's one or two "nay" votes, I'll live. This is the single most important paper of the meeting, and possibly the most important feature being introduced in C++20.
The date is actually a mistake. I submitted the paper on January 4th but mixed up the ordering of month and day. Sorry about that 
Congratulations!
r/programmerhumor
Sure, You can porting on any MCU with this [guidence](https://github.com/idea4good/GuiLiteSamples/blob/master/HelloWave/README.md#How-to-port-on-any-MCU-) Or, give me a Keil project which would enable LCD, I could port it on STM32F749 very soon.
N33t!
\*n337
I feel like this should mention somewhere it’s a package manager for the Buck build system. It’s a cool project but that limits its appeal.
Thank you for reminding me of the Zeal! BTW, its c++ docset is a cppreference copy, so I can finally stop using that site.
I like that username
I saw a paper related to this before in WG21 papers list. I think it is a very good idea to deal with aliasing this way, taking into account that a compiler can optimize based on contract precoditions.
Thank! I made it myself :)
Works offline too: https://devdocs.io/offline
Simple template to get started (yes the globbing is deliberate): cmake_minimum_required(VERSION 3.9) project(workspacename) set(CMAKE_CXX_STANDARD 17) file(GLOB SRCS src/*.cpp src/*.h) add_executable(projectname ${SRCS}) Then use the `target_link_libraries` and related functions to extend.
I tried multiple times with different projects but it's just not on par with the traditional generated projects.
Note though that `target_include_directories(target SYSTEM` does not work yet for VS: [https://gitlab.kitware.com/cmake/cmake/issues/17904](https://gitlab.kitware.com/cmake/cmake/issues/17904)
&gt;typedecl A bit of a bikeshed, but I don't want to teach `decltype` and `typedecl` and how they are different. I've considered the syntax `using Celsius = typedef double;`. It's a simple extension of existing syntax, but there are a lot of tokens. *shrug*
I clicked on the Las Vegas link but got: The page you're looking for doesn't exist. [Noch nicht bekannt](https://www.meetup.com/CppUserGroupHamburg/events/257854554/) means not yet known. &amp;#x200B;
Because it's not nearly as easy as you think it is. I suspect most people here haven't written production C++ with asan (one of the few tools that can catch this) -- it is \*very\* common in most codebases and in practice not really undefined behavior. Like type punning, all compilers will accept the code and not do stupid optimizations even though it's technically UB. &amp;#x200B; And to the point of it being easy, try writing a networking stack where you receive a packet in a buffer and need to grab a word that may or may not be word aligned. &amp;#x200B; I suspect most people riffing on the 'correctness' of this don't have a practical understanding of how common this is and how in reality it's accepted practice.
My biggest thing in Clang-Format is getting it to align a whole function the same way, like currently if there's any break whatsoever, maybe because there's a macro, or just an empty line to seperate sections, it wants to start the formatting over and have sections be aligned different and idk it's just annoying.
You don't need a PhD in mathematics to understand special functions- you just need a book on engineering mathematics. ^no ^slight ^against ^engineers. ^ok ^maybe ^a ^little, ^but ^I ^was ^once ^one. ^:p To implement them with stable algorithms _does_ essentially require a PhD in computer science.
Actually what you're saying is partially false. Compilers will not, in practice, generate bad code when you violate alignment rules. While the compiler technically can, like type punning, this is such a common pattern that compilers happily accept the code. This is a common pitfall in C++ -- people are so worried about correct code that they lack an understanding of what is so common that it's only undefined in standards; in practice, every modern compiler will produce the correct outcome for it and has well defined behavior for these types of UB. &amp;#x200B; Perf is definitely a reason to stick to proper alignment but that needs to be measured and done consciously. When you need to parse a buffer and the word you need to read may occur at any arbitrary byte boundary (common in networking stacks), a proper 'aligned' read is more verbose. There are many situations where you can't guarantee the alignment of a buffer or a read, and for those, it's stupid to write microoptimized code for a theoretical issue. &amp;#x200B; So yeah, I say don't bother worrying about it. If it's really an issue in the architecture you're targeting (which is almost certainly not the case -- as I mentioned, ARM uncached reads are the only modern platform that comes to mind), testing should find it very quickly. It's such a common pattern that you'll know if you need to care. For the other 99%, you really don't... :) &amp;#x200B; Btw, I should mention I write code for ARM -- one of the few platforms that has circumstances where aligned memory access actually matters -- and I suppress most of the asan warnings around it for the reasons I detailed above. Don't microoptimize your code in the name of misguided 'correctness'. Computers are hard indeed.
It's even easier when your proposal is very light on details :)
Quick question about GPU code structuring. I know that you should avoid branching as much as possible, but how do you otherwise structure the code? should you avoid fragmenting things by type, or should you judiciously use sub function calls, that hopefully get optimized? how should nested loops be treated, that sort of thing?
OpenMP 5 (and I think 4?) support "accelerators" aka GPUs among other things.
Why are the other C++ IDEs so far behind VS in terms of debugging?
You mean `priority_meow`? Or is it a `purring_queue`?
Rerename
There are better isosurface generators.
No no, clearly the language needs a new 1337sp33k operator that returns a type object which is used as such: ///compile error auto var_t = l1337sp33k(std::string); ///runs but crashes 0.4% of the time due to dangling reference rvalue template deduction forwarding move semantics decltype(auto) var_t = l1337sp33k(std::string); ///works using adl, though nobody is exactly sure why using namespace l1337sp33k; auto var_t = adl::helpers::reference_wrapper_use_this_one_for_real&lt;std::string&gt;({[](){}}); ///hypothetical correct conforming code autogenerated by scott meyers, not implemented in msvc 21 and gcc has a 5 year old bug that means it doesn't work on tuesdays unless you feed it a cat template&lt;typename T&gt; constexpr decltype(decltype(T)) var_t = l1337sp33k::vector&lt;bool&gt;(); ///what future c++ will look like very soon thus solving the problem forever (this time for real) import leetspeek.std;
Tepends. Most of them are a little slower. Rust is generally on far with C though. A few others are about on par with C++ but they are the minority.
What were the differences that you noticed? Did you configure the CMakeSettings.json file?
Compilers on a *regular basis* will generate code that simply fails if alignment isn't as expected. This isn't theoretical, it happens on the #1 platform (x86) which is usually used as an example of an "alignment doesn't matter" platform. The compiler can and does issue all sorts of instructions will simply crash if alignment isn't as expected (especially SSE instructions with alignment required).
There are virtually no mainstream platforms where "unaligned access is allowed" in terms of C++ code passed to a compiler. Even x86, which is the most forgiving at the assembly level, will fail on a regular basis if alignment is violated. In general, the answer should be that if alignment is violated, you should expect a failure, possible unpredictably in the future. The cost for doing it right is usually small, so either do it right in C++ or use assembly.
This is about as funny as Eddie Murphy in a Disney Movie.
Again, there are very specific circumstances where it matters (and with SSE, it’s very explicit in code and fairly difficult to mess up) but in the vast majority it doesn’t. And your assertions that compilers generate code that fails if alignment is off is false. Compilers don’t make optimizations that cause programs to fail for unaligned access. If you explicitly use SSE instructions, alignments matters. Most of the time it doesn’t. This kind of thing is all over the Linux kernel, for example. 
Sorry, you are straight up wrong. With plain C++ code compilers will generate code that relies on alignment. It's almost a meme at this point. By "SSE" I don't mean the user actually used SSE explicitly - they are just writing plain C++ code and the compiler generates SSE code that requires alignment. Since SSE2 is "baseline" for x86-64, compilers will generate this code freely without any particular arch flags.
If you're going to glob, at least use 3.12 and `CONFIGURE_DEPENDS`.
Are they advertising on places like LinkedIn? I look through there and don't see many game related jobs. So many of them seem to be "We are creating a cloud of clouds to support machine learning driven development of recursive artificial intelligence engines for cloud computing... with more clouds if we can figure out how." And an awful lot seem to be for really specialized stuff like embedded or designing media codecs, or for Linux/Unix only which would leave a lot of us out. * The problem with a LOT of job listings is that the software world is running a million different directions and so many of these listings are looking for someone really strong in like 10 different things, and only 10 people on the planet have probably actually delved deeply into all of them. I read these things and have to go look up half the acronyms sometimes (most of which I'll have forgotten by tomorrow when I have to look up ten more.) &amp;#x200B;
Obviously you never worked maintaining a legacy system. Code is a liability, is not an asset. 
You should probably look at the schedule and decide for yourself. I think that if you keep up to date with conference videos on YouTube and c++ publications (mainly blogs, but also iso posts, cppcast talks etc etc ) then it might seem like you've encountered most of the content in some way or another. But some of the speakers are Israeli so some of it is definitely new. And I found out that you'd be surprised at how many we are not aware until presented to us. 
Depends on the scale of your project and target platform. For small to medium windows only development VS is the best, especially for debugging. For small sized cross platform development CLion is quite good. There are many nice features there. But it scales quite poorly. For big cross platform projects Eclipse CDT is the best IMHO. There is only one quirk - default memory limit of 1Gb. If you allow Eclipse to use up to 6Gb of RAM (or more, depeding on the size of the project), it will be very fast and very responsive even on quite big codebase. Also there is Eclipse project target in CMake. &amp;#x200B; From my experience - QtCreator is more or less fine, but somewhat bugged. Sublime Text 3 with ECC plugin is very good for "quick hack" prototyping.
F# is a much better and concise language than Java. The only problem is the poor .NET (mono) support on Unix-like Oses, the core F# works fine, but the lacks suitable GUIs libraries and does not have any WPF - Windows Presentation Foundation. The killer feature of F# and other ML-based functional languages is the pattern matching that makes easier to handle complex logic. 
Yes, like the crazy struct/class thing.
I played with shaders 8 years ago; I know virtually nothing about GPUs.
https://blog.therocode.net/2018/08/simplest-entity-component-system
Java, .NET, Swift, Rust, Go ... good enough to avoid writing full stacks in C++. Their JIT and AOT compilers still need some work, as their designers weren't targeting the ultimate performance. Only now do Java/.NET have added SIMD support as an example. Java still lacks value types, their are on the roadmap, but we don't have any guarantee that they will actually happen. So most businesses prefer the productivity of those languages, eventually with a couple of native libraries, instead of 100% C++. Look for Android, iOS/macOS, UWP, ChromeOS for such architectures. 
The .net executable could be bundle with Mono runtime (.NET VM for Unix-like systems) with [AppImage](https://appimage.org/) system. Many Linux applications such as KDevlop IDE, QT Creator and so on are using this tool for distributing self-contained executable without any dependencies. 
Didn't know about that! Certainly a good idea for such a template. Has any one tested the impact though? Getting the file list every time you build has to be slow.
Oh alright. I l0ll3d.
oWo::whatsthis()
Nice work! The only drawback I see is the map intersect operation, which best case would be N, and worst case N^C, where N is the number of entities, and C the number of components (if I understand correctly). An approach that proves to be more performant is to create tables for every combination of components found on entities, and then matching these tables (once) against the set of systems. The matching is T (the number of tables) which only happens once. Every subsequent frame the matching is O(1). Anyway, I like the blog. I’ll reference it in the FAQ.
Native executable? .NET It seems to be a PE-32 Windows executable that requires the Mono runtime to run. So, it is not a native executable at all, but it could be turned into a truly native executable by packing the .NET app with Mono runtime using [https://appimage.org/](https://appimage.org/) On Windows it doesn't need any dependency because .NET is already installed on Windows by default.
Most games companies seem to prefer to hire directly - go ask Google for local games companies and go look at some websites!
I don't know how slow it is, unfortunately. I list my files manually because that's what the docs suggest. I'd love to see benchmarks, though.
.NET can also AOT compile to native code, even if few people are aware of their options.
C++ will never go away. There are lots of situations where it is unbeatable such as performance critical code, game engines, heavy numerical computations, system programming, IOT, embedded systems, robotics and real time systems. It doesn't make much sense using C++ for non-peformance critical applications such as CRUD business applications with lots of forms that could be easily built with Java, C# or anything else easier.
Eclipse rules in the enterprise space still. Not many ITs are welcoming to increase their budgets on InteliJ licenses for developer images, update internal trainings and such.
Windows only environments, I would use Visual Studio. For cross platform, Eclipse C++ or Qt Creator (it isn't only for Qt). 
Unity is actually a shell in C# that calls the engine which is written in C++.
I understand benefits F# has in comparison to Java or C++. But there are some points I want to mention: 1. In development of more or less complex C++ project some scripting language is already used usually. It doesn't matter for what. Maybe for testing, maybe for code generation, maybe for extending app logic with scripts. In many cases it is Python, sometimes Ruby (or Lua, or JavaScript). So average C++ developer already has C++ compiler (may be several versions of them) and Python (or Ruby). If you give that developer a tool written in C++ or in Python/Ruby there won't be any problem (mental or organisational) to integrate that tool to an existing toolset. But if you propose to use a tool dependent on JVM or .NET there will be some problems. It depends on the type of the tool, of course. For example if it is a complex static analyzer or powerful documentation-extraction and visualization tool then implementation technology doesn't matter because tool's benefits obviously overweight burden of dealing with JVM or .NET runtime. But not in case of such simple and very specific tool like dependency manager. 2. I can't understand why such tool as dependency manager requires such powerful language and such big run-time like F# and .NET. That tool should parse some config, should check the presence of dependencies and should get necessary dependencies from removes. And I suppose that downloading is implemented by using external tools like wget/curl in case of zip/tarballs and, especially, in case of Git/Hg/Svn dependencies. I suppose that locally installed git/hg/svn are used in that case. So the scripting language seems to be enough for implementation of dependency manager because a language will be used almost as a glue for binding calls of external tools. Python and Ruby are just perfect in that role. 3. I can't understand why tools for C++ (especially not very complex in the nature tools) are not developed in C++. If someone use Java and F# for solving problems of C++ developer then I have a question: "Does he/she really knows C++ or problems of C++ development?" And, if not, why I should use a solution from F# developer instead of solution from C++-oriented developers (like folks behind CMake-based Hunter, vcpkg, build2, or even Conan)? I also don't quite understand reasons described here. You can't write in C++ like in F#/OCaml/Haskell? What a problem? Just write in C++. I suppose that many C++ developers will not use tools like mentioned conduit. Take a look at example from README. I believe many C++ devs will say that it looks over engineered. Some say it looks like an attempt to reimplement Haskell in C++. But not as an attempt to solve a particular problem. PS. This IMHO of course. PPS. I implemented an in-house dependency management tool somewhat similar to Buckaroo three years ago. It doesn't require centralized package repository, it doesn't even require to provide some package recipe to foreign project (in contrast with vcpkg or Conan), it supports zip/7z/tarballs and Git/Hg/Svn repos. And it is 843 lines of Ruby with comments and blank lines. In Ruby because we already used Ruby extensively. It can be easily reimplemented in Python or in C++. So I have a little knowledge of the problem of dependency management for C++ projects.
I believe both of the problems mentioned in the "The Payoff" section can be addressed more easily: allow the usage of Python-like keyword arguments in functions and templates. So you would have: `draw_rect(width=width, height=height, stroked=stroked, filled=filled)` `std::variant`
Seems to be doable, but there are a lot of symbols that are generated by the compilation phase properly, like template symbols. It may get a bit complex. I wish Reddit had the feature of “watching” a post, so I can read its responses later.
Architectures obviously refers to the hardware. Did you contradict the rules of thumb in the end? Did I anywhere above show code that did not access objects correctly? Show the error and I will fix the code.
You can save the post
That's not an operator, it's just `while (idx-- &gt; 0) { ... }` written differently...
https://matrix.org for anyone else lacking context, as I was.
Once installed vcpkg provides functionality to help you consistently redistribute the binaries of whatever has been built as part of your internal build process.
Reddit Enhancement Suite has such a feature.
The first problem in the "The Payoff" section can be addressed more simply by allowing Python-like named arguments in functions. For example: `void draw_rect(int height, int width, bool stroked, bool filled);` `draw_rect(width=3, height=4, filled=true, stroked=false);` Something similar could be done for template parameters, though I don't have a syntax in mind. I'm not even sure if it's a common problem with templates. Having something like `std::variant&lt;Width, Height&gt;` would necessarily make assignments more verbose, since the right-hand side in `v = 3;` would be ambiguous. Regardless, concepts and constraints should alleviate similar issues, because they allow distinguishing between types based on the syntactic requirements they satisfy. 
&gt; Leading numeric characters in symbols &gt; &gt; As of C++17, symbols with leading numeric characters are invalid. This will be fixed in C++2a with the addition of modules. Thanks.
https://godbolt.org/z/-FBwRO use r/cpp_questions for basic C++ questions 
Event links aren't perfect with meetup all the time. Working link for Las Vegas https://www.meetup.com/The-Las-Vegas-C-C-Meetup-Group/events/258118165/ 
Put the forward declaration in the glm namespace.
 namespace glm { class mat4; } This is assuming there are no inline namespaces in the glm header. Inline namespaces should be considered implementation details and shouldn't be used to forward declare a third party type. If there are inline namespaces at play and there's an actual need for forward declarations, glm should provide a header like `glm_fwd.h`.
Humor++
Sorry. I couldn't find the subreddit rules.
As in replacing the manually written header by a manually written module file and a compiler- generated bmi? I guess I don't see why the module file should not contain sufficient information to be 'compiled' to a binary representation of the interface
I don't think so. First of all there's so much C++ code around, which isn't thrown out of the Window just because. Second of all you shouldn't see your skillset not as C++, but developer. Seriously, if you have understood most programming concepts, you can learn any other language pretty quickly. After university I was hired for my Java and C++ skills (pretty much non existent, if I view it from now), later I've done projects in C# and C. Today I mostly use C++ and started using Python. Granted, it takes a couple of years to be really proficient in a language, but it's not too much of a problem.
save
Ok, but to learn programming the standard probably isn't very useful anyway.
I was so confused :/
`glm::mat4` is a typedef though.
is it the server the one lives in?
&gt; I wish Reddit had the feature of “watching” a post, so I can read its responses later. Isn't that what browser tabs are for? :-)
I use the mobile app
Whatever the declaration of `glm::mat4` is, you just need to put that in the `namepsace glm {}`.
Be careful with your volatile trick; I have seen optimizers "elide" the `volatile` qualifier in a number of situations, such as forming a `volatile` pointer to a non-`volatile` variable. At some point, they may realize that in your case `i` cannot meaningfully be accessed by the hardware (random address) and just elide the write altogether.
Congratulations, you just invented precompiled headers.
It basically runs cmake in script mode to execute your file(GLOB) line and compares its output. Costs ~100ms with a hundred files in src and warm caches.
How do you access that feature?
Unfortunately, you didn't write a proposal, so your feedback will probably not be taken into consideration in next committee meeting in Kona, 2 weeks from now.
You are right, but that's a big endeavour, and I'd like to get some less formal feedback before attempting to such a thing. 
With a `volatile` pointer to non-`volatile` variable things get interesting. Changing the value of the pointed-to variable isn't volatile and the same goes for reading it. However, changing the value of the pointer ("redirecting") and reading the address of the pointed-to variable is volatile. The latter pair of read/write operations should not be treated as non-volatile for a conforming compiler. Thankfully, there's `-Wdiscarded-qualifiers` that warns when compiler discards `const` or `volatile`.
Precompiled headers still rely on headers to actually be there, and still suffers from every downside they bring. They are no help for headers that change regularly either. If precompiled headers solved our problems we wouldn't be looking for better solutions. 
Yeah, I was being fatuous. Sorry. I've been reading about the problems with modules from a tooling and build system standpoint and it just has me down.
AFAIK, to even build a proper AST during parsing, for each referenced symbol it needs to be known whether it is a type or not and whether it is a template or not. Now given: template &lt;typename T&gt; struct Foo { using Bar = int; } template &lt;&gt; struct Foo&lt;Quux&gt; { template &lt;typename T&gt; using Bar = std::vector&lt;T&gt;; } What would you store in the symbol database? Obviously, `Foo` is a template type, but what do you store about `Foo::Bar`? Note that Quux could be a type alias, we don't know during symbol scanning phase if it is defined in another TU. So I think, in general its not feasible to store information about the inner workings of templates. This means that the information in the symbol database that can be gathered during an initial token scanning phase alone cannot be enough to parse files. Thus "Any number of TUs can be processed in parallel in either compilation phase." seems not to be doable for the phases beyond symbol scanning.
I think modules will be nice, but the zapcc compiler exposed something interesting that may cause issues with modules. If you have a pp definition in a header, the cpp will process it before the compiler generates a module (zapcc stores it in a database or something). Because of this, if that macro is generated differently based on where it is included but the logic exists in the header you can get different behaviors just by changing the compilation order. For legacy code where that is common, how will modules work? Will modules also have to contain the pp step, which as far as I know is not part of the standard.
Sorry, I didn't mean `T* volatile` but `volatile T*` (which reads `volatile` pointer, no :x?). I'll edit to pointer to `volatile`.
&gt; I propose that we split compilation of a project into two phases: the symbol scanning phase, and the compilation phase. During the symbol scanning phase, each translation unit (TU) is scanned for symbols that are visible to other TUs. All discovered symbols are stored in a project-specific database. During the compilation phase, the contents of the database are used to provide all the information the compiler needs. How do you handle code generation? Not template-style code generation, more D mixin code generation (such as Sutter's meta classes). Those rely on running code (which is not yet compiled) to generate new symbols (such as `operator==`, `operator&lt;`, ... for value classes). *See below for a proposal.* &gt; This topic raises the problem of module ordering, a problem that is not adequately addressed by the design, and that has not been fixed in similar module systems in other languages despite decades of opportunity. Actually, any language in which the module hierarchy is equal to the filesystem hierarchy doesn't care about this problem; with a 1-to-1 mapping between file and module, it's unnecessary to know which symbols a module exports, all that matters is which other modules it depends on. The case of code generation can also be solved by simply making it so that the generated code can only depend on: 1. Dependencies of the code generation module invoked. 2. OR Dependencies already explicitly imported in the scope in which code generation occurs. Which means that without even running the code generation code, you can know the dependencies simply from the AST, which in turn enables a two-phases system: 1st pass to gather module names and build dependency tree (purely AST-based, w/o generated code), 2nd pass to actually perform code generation+compilation. &gt; Because we get rid of most of our headers, the actual compiled length of any source file drops dramatically. AFAIK there's no `#include` (apart for macros) in the module proposal so it already fixes that.
It's true that we cannot construct an AST for Foo&lt;Quux&gt; until we know what Quux actually is, but do we need to do that during the symbol scanning phase already? Or can we afford to wait until scanning is complete? I'm hopeful we can get enough detail to fill the database with all required information, without fully understanding what everything we encounter actually is, and figure out the rest after scanning is completed. But maybe my thinking is too simplistic, which is one reason why I'm asking for feedback here. 
1. Consider the dozens of `operator&lt;&lt;`'s in the standard library. Should they all be visible to all TUs, even when not requested? 2. How does this idea interact with order of declaration?
&gt; ... where each "node" is actually a small array of 4/8/16 elements ... That's a good idea [also for my kdtree]. It's a similar idea as [generally applied] in sorting, once the problem is small enough, revert to the "small case" option. 
That might attract Gundam fans.
`volatile`, like `const`, refers to the thing on the left, unless there's nothing on the left, in which case it refers to the thing on the right. With that in mind: - `T* volatile` is a volatile pointer to `T`. - `T volatile *` is a pointer to a `volatile T`. - `volatile T*` is a pointer to a `volatile T`. Now I'll re-read your post.
&gt;How do you handle code generation? Code generation works almost exactly the same as today: you have .cpp files, they get compiled into .o files, those get linked into a .lib or .exe (or .dll, .so, etc.). There are only two deviations: * There is an additional source of symbols: the database. * We will want to keep track of all symbols that were actually consumed by a TU during its compilation. We will need this information in order to avoid unnecessary recompilation during incremental builds. A mechanism could be based around hashing symbols, forcing recompilation if one or more hashes are different between the database and the TU. I don't know what to say about metaclasses, I'm only vaguely familiar with that proposal. &gt; Actually, any language in which the module hierarchy is equal to the filesystem hierarchy doesn't care about this problem ... That only solves the problem of figuring out which module goes with which TU; it does not solve the problem where TUs are cross-dependent. And that's not something that can simply be ignored. &amp;#x200B; &amp;#x200B;
GLM makes heavy use of templates so manual forward declarations will cause problems, but its header structure lets you include the forward declaration separately: #include &lt;GLM/detail/type_mat.hpp&gt; This header forward declares the mat4 type. I'm not sure if this header is part of the "public" API for GLM, so this could change with new versions.
I don't like the fact that symbols appear magically in TUs without any mention of them being declared. With headers the declaration are in the headers, and with modules in the module. I know exactly (or can easily look it up) what I'm getting, but not with your proposal. Would ``` int main() { return x; } ``` become a valid TU in your world? What's `x`? Where is it declared?
&gt;Consider the dozens of operator&lt;&lt;'s in the standard library. Should they all be visible to all TUs, even when not requested? That's correct, yes. &gt;Sometimes a declaration depends on declarations in another header file (e.g. int foo(Bar); where Bar is declared elsewhere). How does this idea deal with this dependency? During symbol scanning we just remember that there is something called \`int foo (Bar);\`. At that point it doesn't matter what Bar is; this only becomes relevant during the second stage. Let's have a practical example. In source file a.cpp we have this (and only this, i.e. this is the entire file): int a = 1; int add (int x) { return x + b; } In source file b.cpp we have this (and again, only this): int b = 2; int main () { return add (a); } During the first compilation pass, we add the following symbols to our database: for a.cpp: `int a; int add (int);` for b.cpp: `int b;` During the second compiler pass we'll pretend this information is implicitly forward declared in every source file, so we pretend the files look like this: a.cpp: // these symbols are implicitly declared. I show them here to show the effect: extern int a; extern int b; int add (int); // actual code the programmer writes: int a = 1; int add (int a) { return a + y; } b.cpp: // these symbols are implicitly declared. I show them here to show the effect: extern int a; extern int b; int add (int); // actual code the programmer writes: int b = 2; int main () { return add (a); } So after the first pass, both files are normal C++, and can be compiled normally.
&gt; I wish Reddit had the feature of “watching” a post, so I can read its responses later. !remindme 2 days
I will be messaging you on [**2019-02-04 14:06:57 UTC**](http://www.wolframalpha.com/input/?i=2019-02-04 14:06:57 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/amcti9/we_can_fix_modules/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/amcti9/we_can_fix_modules/]%0A%0ARemindMe! 2 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Let me ask you a counter-question: in current C++, would this be a valid TU? &gt;\#include "some\_header.h" &gt; &gt;int main () { return x; } The answer is that you don't know. It suffers from the exact same problem: you have no idea what x is, where it is declared, or even if it has been declared. It all depends on what is in that mystery header. So in this sense, nothing changes: the TU in your post is valid if it is in a project that has another TU that declares a global x that is convertible to int. Without knowing about that other TU, I cannot answer the question - same as you cannot answer my question without knowing what is in some\_header.h. 
Reddit predium will mark new posts since your last visit. There may be a browser extention that duplicates this.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The matrix has you, Neo.
&gt; How do you handle code generation? Sorry, there was a total misunderstanding here. I was not referring at generating *assembly*, but at generating *extra source code* programmatically. For example, in D, a mixin could be `implement_comparable!("MyClass")` and would generate: bool operator&lt;=&gt;(MyClass const&amp; left, MyClass const&amp; right) = default; which introduces a new symbol (`operator&lt;=&gt;`) in the current module. The crux of the matter being that `implement_comparable` could be defined in another module, not yet compiled, and thus at the time of parsing the "Symbol Parser" would not know how to expand it. &gt; That only solves the problem of figuring out which module goes with which TU; it does not solve the problem where TUs are cross-dependent. And that's not something that can simply be ignored. It does not *fully* solve the problem of dependencies, however it greatly simplifies the problem. Without restricting the module &lt;-&gt; file relationship, any of the 1000s files in a project can introduce a symbol in the module. Without restricting code generation, any "mixin generation" in any of the 1000s files in the project can create such an injection that is invisible on the first AST pass. Enforcing the strict 1 module = 1 file relationship, a mixin generation cannot arbitrarily inject code in another module. Add in a simple further restriction of which dependencies it can drag, as I explained above, and the issue of mixin generation can be ignored as far as the dependency graph is concerned.
Excuse me? Java and .Net? You must be joking full time. They don't measure up in performance to C++ at all. .Net is getting better and better and is good enough for most apps, especially ui based, but Java is miles away from performing anywhere near C/C++. 
&gt; 10 if you rate C ++ changes horny xD &gt; 9) How old are you? &gt; Mniej niż 8 ---&gt; less than 8 &gt; Ponad 50 -----&gt; Over 50 That seems kind of weird. Why and how would 8 year olds and younger fill out your questionnaire? &gt; 10) You're a woman? Why do you not just ask for the gender? You said "but I can not modify or create new ones questionnaires. " but what prevents you from creating a new google forms? Anyway good luck with your survey and the translations are quite funny :-) I wonder if some of the text is phrased in a similarly weird way in Polish.
We are now mortal enemies.
Couldn't really find out from matrix.org - does "Matrix" provide video and screen-sharing facilities? If not then it's pretty much useless as a messaging tool in 2019.
I think the #include version is much better. At least that gives me some idea of where the variable might be declared.
Tell that to our customers replacing C++ servers by managed languages. Or check the recent post from Kerry Kent about Windows UI team not adopting C++, in spite of C++/WinRT improvements and being used on UWP components. Apparently you missed the part I explicit mentioned that a large majority of business are quite happy with good enough performance with just a couple of native libs, and the OS which I provided as an example where C++ no longer has full stack rights.
Is there any way I could forward declare the matrices without including a header. My library isn't supposed to have any non-library headers (if possible).
Actually, they help a ton for frequently changing "root" headers. Any time the cost of compiling the pch + the cost of recompiling tus that depend on the pch but not the changed header is less than the saving by using the pch on tus that would need to be recompiled, you are winning. On linux, I think the cutoff is headers transitively included in ~80% of tus. On windows, the cutoff is much lower because pch helps a TON with linking there.
New comments, too? 
The type declaration requires you to reference an enum (precision), you have to include the header that defines it or you'll end up with type redefinition errors.
Side note, I was under the impression that like modern Intel CPU's un-aligned SSE instructions (movups et al) on modern AMD have no penalty for misaligned access? Eg: [https://developer.amd.com/wordpress/media/2012/10/SOG\_16h\_52128\_PUB\_Rev1\_1.pdf](https://developer.amd.com/wordpress/media/2012/10/SOG_16h_52128_PUB_Rev1_1.pdf) 2.5.2 [https://developer.amd.com/wordpress/media/2013/12/55723\_SOG\_Fam\_17h\_Processors\_3.00.pdf](https://developer.amd.com/wordpress/media/2013/12/55723_SOG_Fam_17h_Processors_3.00.pdf) 2.6.2 (Jaguar and Zen)
Our company uses Java as main language, and we have enormous performance issues, because it's just shit for UIs. We used to have C++ MFC based UIs, and no performance issues at all. What really caused the switch was the fact that good C++ skills are rather in decline, and you can just use mediocre Java/.Net devs to do similar thing. C++ is always going to be needed for high performance targets, but it's just too expensive to maintain.
Thought that was added to normal users a while ago? If not it's definitely in RES
I meant comments. I changed it.
The more I read about modules the more I get the impression that the current approach is an attempt to serve a tiny fringe-group that doesn't want to update their platform to something remotely resembling a modern system (which by the way makes me question whether they would even switch to a new enough compiler for it to ever matter for them in the first place) at a gigantic cost for the 99.99% of the community who use systems that are remotely sensible. Which is doubly ironic considering that this is the release that drops support for non-two-complement integers because virtually nobody uses them. And I am fairly confident that somebody out there still uses some ancient system that uses something else. We rightly don't care about them, so why should we care about people who have filesystems that don't allow file-endings? Pretty much every other language follows the simple approach of modulename ≈ filename and nobody complains to them. So why should C++ care?
There is a subscribe button on the bottom right of the post (near the sidebar) when clicked it says: &gt; You are now subscribed to this thread for 2 days. When new comments are posted you'll receive a notification. Note that not all of the RES features work on the new design
Damn they really made an effort to hide that button. That's a cool feature, thanks!
Citation needed. Show me the godbolt. 
what is the objective of this survey? - what are you trying to find out?
So basically the AST database model that died with Energize C++ and Visual Age for C++ v4, as they consumed too many resources for their hardware generation. 
Apparently this is a joke, but where is the fun part?
In fact, you are straight up wrong and asserting nonsense. Even gcc at O3 does not assume alignment for auto vectorization to SSE2: https://locklessinc.com/articles/vectorize/ Case in point: gcc does not assume alignment even if it’s technically ub. 
I'm conflicted about 2017 C++. I like it, but my contention that 2011 C++ was both late and immature when it did arrive is bolstered as I find things that are only fixed in 2017 C++. 2014 was a "bug fix" release; I'm afraid 2017 is to some extent also a bug fix release. I've asked/suggested this before, but back-porting string\_view and/or span to 2011 C++ would help me in terms of not having to require 2017 C++ of my users. If that's too much to ask for, back-porting span to 2017 would help.
I agree with /u/Tyg13. In your counter-example, I can look in the include file (and it's include files, ad nauseum) to find the declaration. As I understand your purposal, that information is hidden in a database, requiring another to inspect it. 
Maybe your Java devs could get hold of a couple of copies of [Filthy Rich Clients](https://www.amazon.com/Filthy-Rich-Clients-Developing-Applications/dp/0132413930), and in the process learn not to write C++ in Java.
I want const pointers to be fixed way more :P
&gt; an attempt to serve a tiny fringe-group But that fringe group happens to also be the group responsible for (paying for) writing the major compilers... so how fringe are they really?
I don't think so...
It look like a nice example of how modules can be implemented. This is why do much details are left implementation defined. Implementations should decide how it's implementable. Not the standard. If we overspecify how it should be implemented, many optimisations or new way of doing it would be impossible. For example, the standard don't even define the BMI. It's just the way many implementation choose to do it. Alternatively, an implementation could choose to use a database, or even use inter-process communication.
**Company:** SpikeGadgets **Type:** Full time remote, intermediate and senior levels **Description:** SpikeGadgets is trying something new. Our hybrid approach is to design and sell powerful hardware that interfaces with an open-source software platform supported by a large community of scientists and developers. Our goal is to support the efforts of the open-source community in a commercially sustainable way. We strive to make hardware and software with ease of use in mind, but with minimal compromises in performance or flexibility. We are looking for a Qt/C++ Software Engineer at the earliest possible date. The position is full-time remote. Requirements: \- experience in C/C++ and CMake \- experience developing Qt-based software \- comfortable working with git \- bachelor's degree or higher in computer science or a related engineering field &amp;#x200B; You should answer the following questions in your email(or cover letter): \- Have you ever contributed to any open source project? If so, what's your GitHub/GitLab/etc profile? \- What do we need to know about you? \- What qualifications do you have? \- What kind of salary do you expect? &amp;#x200B; **Location:** Remote **Technologies:** CMake, Qt5, C++11 **Contact:** If you are interested, please, send your CV and cover letter ASAP to [magnus.w.karlsson@hotmail.com](mailto:magnus.w.karlsson@hotmail.com)
That sounds cool
Can't the supposed benefits of modules be achieved in a much simpler way by: a) organizing one's code in to "modules" b) having all symbols "invisible" or "private" by default c) explicitly making entry points "visible" or "public" d) compiling each such module e) referring to the above modules when necessary. f) which don't have to be recompiled. We can. And it's been done this way for 40 years. We have static and dynamic runtime libraries. It's been working pretty well in spite of the fact that the model could use some updating (better visibility attributes, API versioning, etc). Seems to me that this solves all the problems that std::modules purport to solve and the solution is available today! Robert Ramey
CLion for C++ and PyCharm for Python, both by JetBrains. Soo good.
It doesn't really matter: the database is also an excellent source of information about the program. Editors can also use it to trivially find the source of your symbol.
There are lots of libraries that provide span or string_view.
vim
Visual Studio + CMake Visual Studio Code + CMake
&gt; Actually what you're saying is partially false. Compilers will not, in practice, generate bad code when you violate alignment rules. Another poster in this thread provided an actual example of this happening, FWIW. :) &gt; When you need to parse a buffer and the word you need to read may occur at any arbitrary byte boundary Also a concern in games (via hyper-optimized networking messages, data streaming, GPU buffer, etc.). For the most, just use `memcpy` instead of direct variable access, and let the compiler optimize that to the correct instructions. &gt; ARM uncached reads are the only modern platform that comes to mind MIPS is a "modern" platform used in a vast plurality of embedded and IoT devices and requires aligned loads/stores.
I lived in Texas for a number of years and learned to say "y'all" aka "ya'll". My rabbi had a plaque that said, "Shalom, ya'll" ( I don't remember which way the plaque spelled it.) I suggest this as an alternative to "guys". I use a mix of vim and emacs.
This works great if you ignore templates. Templates can't really be stored in static libraries and so you need to include them everywhere, i.e. what we're doing right now. With real modules you don't need this.
QtCreator
With YCM
Tune in next week, when the same question will get asked once more.
Well, this is basically what would happen if my approach is adopted, except you also get the benefits while you are compiling the module itself. And I'm all in favor of having symbol names default to TU-local (as if they were declared in an anonymous namespace). I would actually prefer to see three types of global symbols: TU-local (as default), project-local, and visible to external consumers. Currently there is no (standardized) way to express project-local; once a symbol escapes from a TU everyone can see it. However, this would be breaking change, as it changes the way you define either a global or TU-local symbol. 
That's great and all, but I don't think anyone really cares one way or the other..
Kate
Considering you are using Windows, check out Visual Studio. Put some effort in seeing how CMake Projects are written. It would substantially help you in the long run as CMake based projects remain compatible and supported by all IDE's including VS For a more cross-platform solution, check out Qt Creator
It's easy to construct situations where the syntax itself, rather than just its meaning, is ambiguous. For example: a * b; // does this introduce a symbol `b`? Or worse, something like this: struct S : T&lt;V&lt;1&gt;{} // ... more tokens here ... Is `V` a value, being compared with `1` to produce the argument to `T`? Or is `V` a type template, instantiated with `1` and then constructed with `{}` as the argument to `T`? In this particular case you can probably tell by the next token (`;` means it's the first interpretation; `,` or `&gt;` the second). But actually using that information requires backtracking, which makes the compiler slower, and is not always possible anyway. In fact, templates *already* have to deal with this problem. Before instantiation, you don't know if template-dependent names are types or values... and so the language forces the program to specify. This is what those extra `typename` and `template` keywords are for, when sprinkled around in template definitions. So if you want to be able to find all the definitions in a C++ program without doing name lookup as you go, you need some way to disambiguate this stuff. You could force *everything* inside module-using TUs to add those `typename`/`template` disambiguators, or else change the syntax somehow so they become unnecessary, but both of those are highly unlikely.
Instantiations of templates can be stored in libraries via the mechanism of explicit instantiation. The works well in many cases. It does require that one invest some effort in (re)factoring code to decouple code in distinct translation units. But that is a small price to pay for dramatically reduced compile times and code decoupling and isolation. Trying to invent a system which achieves these benefits without the developer having to consciously design his application for build/maintainability will fail. Standardization of visibility/import/export/versioning attributes would be much simpler than trying create a whole new mechanism (modules) and would be available much sooner. 
During the first compilation stage it doesn't need to know how to expand it. It just knows there is a symbol that is declared in a certain way, which is enough. And during the second compilation stage we have all relevant information available. &gt;It does not fully solve the problem of dependencies, however it greatly simplifies the problem. I agree it would be a step forwards for the current proposal, but it still leaves the problem of cross-dependencies on the table. I don't think that's something that can just be ignored. I'm not sure why introducing symbols in the module would be a problem. It's how software is made: each TU adds a few symbols for the other TUs to consume. Are you mentally mapping modules to single classes? Because I feel that that is really too narrow a scope. 
\+1
Right. I think your ideas might be more influential and interesting if considered the context of enhancing the utility of library build and linkage. The idea that modules would not be a "breaking change" sort of surprises me. Technically that might be true in that it doesn't break old code. But in order to benefit from the facility, it seems one would have to alter his build practices. It would be a big change. To summarize it would be interesting to see a proposal for modest enhancement in support of static/dynamic libraries which would address: a) symbol/function/class import/export/public/private etc. b) help for those who need/want to maintain API compatibility c) maybe better support for PCH - I don't know if that's part of the standard. d) some support for syncing/registering build settings which need to be compatible across translation units. I don't know which of the above the current modules proposal addresses - if any. I know, I know, I should read the proposal. But maybe someone here already knows the answer and can give us the short version
P1427 is the latest paper pointing out how much modules breaks build c++ and most tools currently in use. And there's a paper with evidence that we only get build time improvement at low parallelism, with some initial data. 
[One](https://www.reddit.com/r/cpp/comments/9v5lbq/text_editor_vs_code_or_get_an_ide/), [two](https://www.reddit.com/r/cpp/comments/7ve6x2/what_ide_do_you_use_for_cc_development/), [three](https://www.reddit.com/r/cpp/comments/8du1oo/c_and_tooling_code_completion_for_us_mere/), [four](https://www.reddit.com/r/cpp/comments/6z8oy9/ide_and_indent_style/), [five](https://www.reddit.com/r/cpp/comments/7gnoa4/good_text_editor_for_c_development/), [six](https://www.reddit.com/r/cpp/comments/68lghb/what_ide_editor_are_you_guys_using/), [seven](https://www.reddit.com/r/cpp/comments/4b1kvl/which_ide_editor_do_you_use/), [eight](https://www.reddit.com/r/cpp/comments/61mvsl/text_editor_or_lightweight_ide_suggestion/), [nine](https://www.reddit.com/r/cpp/comments/5vut37/what_software_to_use_when_practice_coding/), [ten](https://www.reddit.com/r/cpp/comments/3ouuj2/ide_or_text_editor_i_suppose_for_c_with_code/), [eleven](https://www.reddit.com/r/cpp/comments/2kdpee/what_is_a_good_cpp_code_editor_other_than_code/) and [twelve](https://www.reddit.com/r/cpp/comments/2lfafc/favorite_cc_ide_for_2014/) results just in the first page for the search "ide" on this subreddit.
On Windows it is Visual Studio. 
&gt; During the first compilation stage it doesn't need to know how to expand it. It just knows there is a symbol that is declared in a certain way, which is enough. And during the second compilation stage we have all relevant information available. My point is that all it can know is that *there may be some symbols* declared in a certain way, but it cannot know *which* without actually performing the expansion. If you need a fine-grained mapping of which file declares which symbol, expansion is necessary.
Something I've been toying with for a while is a template specialization cache. Unless the stl's headers change, one vector&lt;int&gt; will be the same as another vector&lt;int&gt;, but it has to reprocess the source code every time you compile, rather than being linkable against a .o file. I'd like to be able to generate such a file automatically. 99% of the time spent parsing header only libraries is duplicated effort. 
Hey, are you also hiring for junior/new grad developers?
We'd typically take junior devs with 1-2 years experience or more, and we run a graduate scheme closing in Sept 2019 to start in Sept 2020. We like talented junior devs and grads, and training and mentorship are high priorities for us, but as we're a small firm we're limited on how many we can hire around the same time.
I've bought Ivan's book and I can safely recommend it. Nice entry to start thinking in a more FP way.
Yes, the hardware may allow unaligned access in some cases (certainly x86 does not allow it in all cases!) - but you can't reliably access that feature from C++. In particular, you suggest a macro like PLATOFORM_SUPPORTS_UNALIGNED_STUFF, which I understood meant you could right some code that might "ignore alignment requirements" as the OP asked. You also mention that on some platforms unaligned access is OK - which it may be at the hardware level (sometimes) - but not at the C++ level. There is no exception to the language rules about aligned access just because you think the underlying platform sometimes supports unaligned access!
What spoon?
Added code snippets to readme
I'm not keen on adding ifdefs to my code for multiple versions of these types. One user uses string\_view from lib A and another from lib B. I could just support one non-standard version, but there's still ifdefs between that and the std version. There's no shortage of competitors and they look for anything to try to hammer you with. Ifdefs? ugly. There's some truth to it so I try to avoid them.
&gt; If a compatible version of CMake isn’t detected the first time you build your project, you will see an info-bar asking if you want to install CMake. With one click you will be ready to build and debug on the remote machine. It would be great to be actually able to kickstart this process manually. I think with "compatible version of CMake", what they mean is a version new enough to work with VS - and I believe that's 3.10 or something like that. But let's say my project requires 3.12 or 3.13. Now running CMake on the target Linux machine will still fail but Visual Studio thinks the CMake version is new enough and doesn't offer the option to install a later version. And what version is installed in any case *if* VS's mechanism kicks in? I hope the very latest? Is that configurable as well? The day that 3.14 comes out, I want it!
Got it, thanks! I guess I'll be applying later on in 2019 then, since I must have missed the 2018 application :) 
Clearly _my_ way is the only way, that being to always write `const T` but also `auto const`.
Of course gcc can't assume that objects or arrays will be *over-*aligned - I never said that! gcc will assume the arrays are as aligned as they are required to be, which for your example of double arrays, would be 8. So obviously code won't be generated that relies on 16-byte alignment because the guarantee is only 8. What I'm saying is that gcc can and does rely on the *actual required alignment* and optimizes based on it. In your example, having 8 byte alignment perhaps isn't particularly useful to the optimizer, so it may happen that the code also works with any alignment less than 8, but that just means you got lucky - gcc will generate code that breaks when the alignment is lower than required, at its whim.
KDevelop, QtCreator, Code Lite, Clion...
It would be amazing if it was feasible. But any other language with modules decided that it is not, so I doubt it. Consider the sheer amount of TUs you had to scan. How do you even resolve conflicts? I really do not understand what's so hard about introducing modules to C++. The concept is literally decades old and has been subject to thorough practical and theoretical consideration.
!remindme 1day
!remindme 1 day
But that means getting paid to learn on the job. 1. Do you really want to be using important software written by someone who was learning the language as he wrote it? 2. Are companies really going to pay you well to do something you don't really know how to do well? Not that your point is invalid. But there are a lot more practical considerations than you are making out. Writing really high quality usually means you have done something quite similar to that before and you have learned not just the language syntax, but the pitfalls, both short term and long term, that make the difference between something that fails to fail and something that really works and is a viable base for longer term development. If you are a very accomplished C++ developer and making good money and suddenly you can only get a job as a Rust newbie, that's going to be tough probably. 
It should not be the responsibility of compilers to locate BMIs, it should be the responsibility of the build system. This paper documents a simple protocol through which the compiler can inform and ask the build system about what module it is compiling and where the BMI is located. The build system no longer needs to parse the .cpp files to located module dependencies - it is done by the compiler. The compiler does not need to know where the BMIs are before it starts compiling - the build system tells it when it encounters an import declaration and can produce the BMIs on demand.
I haven't watched this, but I found an earlier version of this to be pretty funny and I'm an advocate for east const: [http://slashslash.info/eastconst/](http://slashslash.info/petition/)[http://slashslash.info/petition/](http://slashslash.info/petition/)
Here is a non-exhaustive [list of examples](https://godbolt.org/z/q1MSUi) off the top of my head. In each case the compiler makes assumptions about the pointer alignment to generate code that will fail if the actual alignment at runtime is less that it should be based on the language guarantees (i.e., if you pass an unaligned pointer). For most of the examples the failure mode is a crash (segfault), but the malloc example the wrong answer is silently returned instead. You can find plenty more if you look: for example, consider pointer math: if you have `int *p, *q` what is the result of `p - q` when p or q are not properly aligned? It's not an integer! So you can't even represent the correct result: you can construct plenty of ways for programs to fail based on things like that.
I would very much prefer this over the current proposal. Actually, I've thought about something like this. This would also completely remove the necessity of forward declaration, and order of declaration in general. Modern languages like C# have solved this, and can be used as a reference for ideas.
Thanks, even with your instructions it took me a minute to find it. How long has it been there?
Any conflict you run into would have already been an ODR-violation anyway, which is UB. Except now we can detect it (when the definition of a symbol already in the database is different from a newly scanned one, I mean), and give a decent error message instead. 
First, r/cpp_questions would be a better venue for this. Second, this has been covered many times, and the advice will always be the same. Search is your friend, and saves you from downvotes and ridicule while getting you the answer you're looking for.
Browsers got a feature called "bookmarks", and it works for other sites than Reddit too. Try it out!
Yeah, but I am using the mobile app!
&gt; as I mentioned, ARM uncached reads are the only modern platform that comes to mind ARM uncached, ARM vldr/vstr, ARM ldm/stm, ARM atomics, x86 aligned mov, x86 atomics, and that's just off the top of my head. Your mind is woefully undersupplied with information on this topic.
I don't understand why such arguments are so over-engineered and over-complicated? A server? Wtf? Why don't we borrow from c# which has a good module (her... Assembly) system and it works good! With imports and so on... 
post meeting mailing?
Yeah, no approach that adds the absolute requirement (or close to) to have and IDE or another external tool should be considered. Text Editor + Compiler should alwayd be possible and making that easier should always be a goal IMO, especially with the tools available. Most of the time the features oriented towards making code editing as text easier make it even easier for the IDEs to do their job :)
Of course not. I mentioned it for completeness; the code you see, what problem you find in it?
Yes, it varies between microarchitectures. The trend is that the implicit penalties are decreasing over time rather than increasing.
It's been there as long as I've used RES and that's at least 4-5 years.
Which *fringe* group is this exactly? 
Lool, 12 years ago priorities were different, and UIs were not so rich as today. The company is market leader in steel industry software, and they have developed in Java for the past 20 years, but never cared much about performance, until now, because today, people want everything instantly, and UIs to be super rich at the same time. This is where .Net shines, and Web apps are catching up, but Java is just not fit for purpose. Java is also in decline, if you read most recent reports, you will see. Btw EVERY major OS is written in C/C++, and NONE are in Java/.Net - talk about performance. As I said, .Net shines in many areas for quick and efficient development, even though it lacks performance, but Java is just dying, because companies can't afford to maintain server only coders.
- "Sorting and locality", I haven't measured, but maybe the following could improve `std::list` performance: - Don't call `std::list::sort()`. - Construct `std::vector` from `std::list::begin()` and `std::list::end()`. - Sort the helper vector. - Construct a new `std::list` from the helper vector's `std::vector::begin()` and `std::vector::end()`. - Call `std::accumulate()` on that. - L1 cache - An interesting way to show how cache affects performance: - Make two arrays of size X. - Populate both with random data. - Iterate over one sequentially. - Use the value of the first vector as index of the second vector whose value you will read. - Start with a really small vector and slowly increase the size. You will be able to see performance drop whenever any CPU cache becomes too small.
&gt;The main issue is that the bar for a good language keeps getting higher Yeah. &gt;and C++ is struggling to keep pace. As Rust matures C++ needs to fix its threading, module, editor tooling and packaging story. Agree with some of that, but imo [on-line code generation](https://github.com/Ebenezer-group/onwards) has a bright future. So it may be Rust that is [caught off-balance](https://idioms.thefreedictionary.com/caught+off+balance).
Modules are effectively really fancy precompiled headers.
*waits to be standardized*
tHe dEeP sTaTe
.net can get close, and a low-level dotNET language would probably be competitive if AOT compiled. Java never will. The JVM bytecode is too simple and drops way too much context.
The reply was a bit lengthy and to cover everything from A to Z would taken it even longer. Probably something that would be worth spending more time on and making it into a blog post instead in that case and cover more ground and be more detailed and specific. The compiler (extension) intrinsic instruction of course allow compiler specific non-UB invoking unaligned memory access where the API is available. So for the record: of course, unaligned access by standard's point of view is totally UB and not something you would want to invoke. This is the reason in the posted code you won't find such constructs; if you do point out the errors to me so that I can fix them. 
It seems that your proposal was already considered in [this paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1300r0.pdf). Have you read "Dependency graph dynamism" for why this proposal does not work?
&gt;Anybody else fearing this? No, primarily because I've been preparing for the future as a prophet/entrepreneur of on-line code generation. If my efforts go well, I hope to open an office in Israel. &amp;#x200B;
The code looks good, I don't see any alignment gotchas since memcpy is always used to copy to/from the char storage. It was more a common on the prose at the start of your reply, but it is also possible I understood it.
My understanding is that it’s places like google a Facebook and microsoft
Is the database easy to read in just a text editor, like vi or emacs? Because there are times when developers have to use a text editor instead of an ide. 
The reply was a bit lengthy and to cover everything from A to Z would taken it even longer. Probably something that would be worth spending more time on and making it into a blog post instead in that case and cover more ground and be more detailed and specific. The compiler (extension) intrinsic instruction of course allow compiler specific non-UB invoking unaligned memory access where the API is available. So for the record: of course, unaligned access by standard's point of view is totally UB and not something you would want to invoke. This is the reason in the posted code you won't find such constructs; if you do point out the errors to me so that I can fix them.
It gets worse. Everyone by now is aware that templates are turing complete. Way fewer are aware that because of this C++ is *turing complete* to *parse*. Take the following example: template&lt;bool&gt; struct a_t; template&lt;&gt; struct a_t&lt;true&gt; { template&lt;int&gt; struct b {}; }; template&lt;&gt; struct a_t&lt;false&gt; { enum { b }; }; typedef a_t&lt;sizeof(void*)==sizeof(int)&gt; a; enum { c, d }; int main() { a::b&lt;c&gt;d; // declaration or expression? } To properly parse this, you need to evaluate `sizeof(void*)==sizeof(int)`. But you could change this to an arbitrary compile-time expression - Turing complete.
I find this quite interesting. I don't understand why if you are going to need to use the file system to load the files into compiler why don't we just use the file system to search for the modules. Is there any docs on why these module mapping systems are needed? What is the use case for the name of the BMI file having nothing to do with the name of the module? IE what problems is this trying to work around? It seems to add a level of indirection that I can't see the use for. I have seen the pattern in C# and it got in my way. I wanted to use C# as a scripting language but I could not know what module was in what assembly. So why do we want this in C++? 
I was about to add some references, so I write them here.. why I did not go in detail what the PLATFORM_UNALIGNED_BLAHBLAH could do is because it is quite detailed but I am compelled to shed some light into it. For example, the Intel SIMD has these intrinsic we already sort of covered so no more about those. There other intrinsic like this: http://processors.wiki.ti.com/index.php/C6000_Compiler:_Memory_Access_Intrinsics# http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.faqs/ka15414.html Etc. etc. there are plenty of compiler specific ways to go about. But I did not want to go in details into them because it is very involving topic and outside of scope of just advising how you would go about doing it in C++ according to the Standard (= you wouldn't). Since I don't want to steer anyone onto that path I just mentioned that option IN PASSING (that "there are ways about it", or something to that effect). Oh, we did a lot of those things with compilers and toolchains for different game consoles and mobile platforms back in the days. The C and C++ compilers were just tools to and end, the goal was not to write code for "pure abstract c++ state machine", but for real hardware. So compiler specific extensions, which WERE legit and valid were used. 
Fair enough, I probably misunderstood the thrust of your reply then.
*" These met initial modest needs, but failed with the first customer, Boris Kolpackov, who wanted to have an arbitrary mapping and per-compilation control of the output file. Options were added to control mapping files and output names. "* &amp;#x200B; Why on earth did Boris want to do this?
Can't wait for the brexit outcome?
If I had money, I'd give you gold. 
Do they have "filesystems that don't allow file-endings"?
your suggestion about helper vector to sort the array content is good. it would certainly improve performance since a new list being created has batter locality than a sorted one.
&gt;It is generally about the possibility of formulate hypotheses and some correlations for my and other research. Where, how often and by whom C ++ 17 is used, etc. The research sample is too small to draw strong conclusions, but large enough to be suspected something. Then others can investigate whether it something really going on. I promise to answer you in detail as soon as I finish my research.
The BMI is a compiler artifact. The compiler decides for its name, and surely will be treated like other artifacts. The BMI however is not reusable between compiler version or vendor. Think of it as a compiler generated cache.
&gt;10) You're a woman? Thank you for your answer. Of course, you're right - some questions are weird - it is used to filter results. Answers to this specific question will not be taken into account (this is a suggestive question). I'm not interested in gender - I did it for myself, for relaxation maybe. ;-)
Visual Studio Code + tup ;)
Unfortunately, no one can be told what the Matrix is.
&gt; The day that 3.14 comes out, I want it! The version they use is a fork of CMake, most likely to get all information relevant for IDE-integration (like targets and their sources) out of CMake. The log shows Visual Studio connecting to the CMake process at the end of the configure step. So until those changes are upstreamed or CMake gets equivalent hooks you won't be able to use a vanilla CMake version.
&gt; Except that's just not allowed, strictly speaking. :) A void* is not guaranteed to even be able to hold a function pointer (as in, sizeof(&amp;funcion) &gt; sizeof(void*) is allowed). See the answer at: Yes the article makes that clear.
Hiya! I’m trying to build cmake from source for MirBSD, and getting a weird behavior. Anyone know why the Apple section is still being emitted by the preprocessor rather than the MirBSD section? https://github.com/mcandre/vagrant-miros-cmake/blob/master/i386/fs.c.patch
Google's system is [Bazel](https://bazel.build); it's developed in-house. It's not some archaic thing we're trying to get rid of. It's open source, actively maintained by a dedicated team, lightning fast and scales up extraordinarily well. Lots of other companies have adopted it too. I don't know what Microsoft and Facebook do. :)
Auto has its place... Just not in my code :)
Visual studio, full stop.
Every day we stray further from God's light. To post such non-dank memes in the year of our Lord 2019...
On the brighter side, the companies who desperately need C++ specialized programmers may pay big IFF what you say is true. Because as stated by many here, C++ is currently irreplaceable in many fields of computing.
I bet This is THEE absolute evil "Replace the semicolon(;) with greek question mark(u+037E) in your friend's javascript code" [https://twitter.com/benbjohnson/status/533848879423578112?lang=en](https://twitter.com/benbjohnson/status/533848879423578112?lang=en)
&gt;Couldn't really find out from matrix.org - does "Matrix" provide video and screen-sharing facilities? According to http://matrix.org/, yes.
Visual Studio is pretty good of course, but I've had some issues with Intellisense in large projects (it tends to be quite slowabd useless), plus the solutions and projects always seem to be wonky. Other than that, Visual Studio is a great IDE with a great debugging interface. CLion is great too, its got great CMake integration so it works wonderfully for most C++ projects. I find CLions error checking and autocompletion to be much more reliable than Intellisense, but it has it's quirks. Its a really great editor, but it lacks a debugging interface like Visual Studio. However it's much more lightweight than Visual Studio, taking up something like 1 or 2GB on my system compared to like 14+GB for Visual Studio. If you're on windows, its probably best just use Visual Studio unless you're okay with not having an integrated debugger with your IDE. If you're on Linux like me, CLion is the best option. Eclipse is garbage compared to literally every other IDE that exists, other than Dr. Java and maybe Notepad.
We use C++ `auto` production code, and it's fine. We use Python's automatically assigned types in production code, and it's fine. We use Swift `var` and `let` in production code, and it's fine. 
In the right places, it is great. Using it everywhere (for non-generic code) can hurt readability a lot.
neither swift nor python can ever be used for mission critical code would you fly on an airplane which avionics are controlled by python software?
You should post graph and details in addition to the brief summaries you provided in your post.
Yes. We use Python to automate some parts of our build system. For example, we use it to automate publishing GitHub releases. Conan is also written in Python and we lean on it quite heavily to manage our third party dependencies. Right tool for the right job.
Then they are not templates anymore.
Have you tried PCHs? They remove the parsing time.
&gt; I think with "compatible version of CMake", what they mean is a version new enough to work with VS I think they mean `cmake_minimum_required(version ...)` but I haven't tried. It'd just make the most sense.
Except if there's ambiguity it won't compile. So good luck including an ambiguous auto! 
I'm glad I could help (but rather donate to Against Malaria).
r/programmerHumor ???
`std::map&lt;std::string, std::vector&lt;std::string&gt;&gt;:: iterator` would like a few words with you. 
&gt; Number of bugs I've seen in shipping code caused by `auto`? # ZERO
Please submit links as links, instead of text posts. (And give them useful titles, and don't submit three of your own links at once.)
Removed as off-topic.
Would you fly on an airplane which avionics are controlled by C++...? I wouldn't...
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/amg52p/which_editoride_do_you_guys_recommend_for_cc/efmxdun/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Posts that don't help people write more effective C++.
hmm almost all avionics today are coded in C/C++ or Ada. Perhaps you should get more info from professionals in the industry
strawman there are better ways to do this
exactly!
&gt; I've seen in shipping code anecdotal
Graphs don't usually capture the results well. And it takes days to weeks to write up all the analysis - which I post on the wiki on gitlab.
Might auto be one of them? 
 using StringVector = std::vector&lt;std::string&gt;; using StringVectorMap = std::map&lt;std::string,StringVector&gt;; then StringVectorMap::iterator c = someUnknownFunction( args ); is way more clear than auto it = someUnknownFunction( args ); Just a little discipline goes a long way. 
You do need to specify the mapping in C# via the compiler option `/reference`
This approach has lots of issues with it that we couldn’t solve. Some attempts involved declaring members of incomplete types. The crux of the issues is that current C++ is declaration order dependent.
It is possible with languages with context free grammars, and that are not declaration order dependent.
Agreed.
They give a trivial amount of speedup. Like 15 or 20 percent. 
Also, mods have access to it in their subreddits.
The data are being disputed by /u/berium who had the opposite results.
That was a fun read and also a correct title: I never wanted to know any of that. Do not recommend. ;-)
Perhaps you should take a lesson in respect. I never claimed to know anything. From what I've heard Ada is the one that's used for the critical stuff. If we're just going by what's used in avionics regardless of what's critical or not, even Python is very common. :) Regardless, you can't seriously be suggesting that C++ is a safe language. If inferring the type with `auto` instead of being explicit about the type is enough to cause a plane to crash, you have a problem.
You got it right.
Ah yes, I love myself some clear one-letter variables.
That is not the complete story. Exported templates are parsed only once. Instantiations cased in the containing interface unit happen only once and reused. And that is already lot of saving. So, yes.
Exported templates are parsed only once.
Exactly.
&gt; Perhaps you should take a lesson in respect. Just get off your high horse dude, this is the internet &gt; I've heard Ada is the one that's used for the critical stuff. it was &gt; you can't seriously be suggesting that C++ is a safe language it is, specially if you erase all the academic bullshit https://en.wikipedia.org/wiki/Embedded_C%2B%2B http://www.esa.int/TEC/Software_engineering_and_standardisation/TECRFBUXBQE_0.html 
&gt; one-letter variables. off point
&gt; Just get off your high horse dude, this is the internet It's the internet so respect goes out the window...? &gt; https://en.wikipedia.org/wiki/Embedded_C%2B%2B That's more like a modified C++. But fair enough.
Is it? It seemed to me like you were fine with not properly naming the variables just because you can see the type. It's just a bad argument. You know that `it` variable is an iterator because it's called `it`. `LinesMap::iterator it` would be redundant so you decided to name it something abstract instead just to prove your point.
You're just being too sensitive. I guess that's what's in 2019 for us. Yes, some call it "Orthodox C++". It is definitely a subset more than a modification. If you look at the [JPL Coding standards](https://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf) item 2 (predictable execution) you will see prohibition to features we commonly use like unbounded while loops, recursion, even malloc. 
it is off point because you know I put it there almost as an after thought, it was not even to be there in first place
Bazel :( I’ve chosen not to use google projects because of that. Install jvm? I don’t think so. 
C++ is a tool not a profession. 
I’ve never had any such experience. Perhaps you’re working for the wrong companies if they are asking for language expertise. 
Can't believe I haven't seen this until now. This looks awesome. 
Hello. I read your article. I think you are totally wrong. I have tried the same feature in D. It is used as import("filename") &amp;#x200B; I save one step when compiling, I do not need to fit in strange ways syntax that is by nature non-c++. This can happen not only with your resource, but with json files you want to embed and constexpr-process and others. This features is one of the top small features I want to see. Maybe the other is a for... syntax to expand tuples (like D's foreach/static foreach). I do not think there is a good argument to add a middle step when it can be done without it.
It does imply knowing what the types will be ahead of time, though.
I'm still trying to understand the easy stuff. I'm usually the guy that loves the gory details, but cmake's intricacy makes some of the easiest concepts seemingly impossible. Our team has been annoyed to the point of tears multiple times while trying to construct an overarching cmake framework to build and install clang and libraries using the same mindset as we have with our in-house make based system. I understand this isn't the forum for complaints, but I like getting it off my chest and into words sometime :)
(Linked post author here.) There have been similar proposals in the past. This approach is fairly radical, and I wouldn't expect it to be well received by compiler authors. Nevertheless, I encourage you to join us in SG15, specifically in the mailing list and in the #sg15_tooling channel in the CppLang Slack. Even through the bemoaning of the sorry state of our ecosystem, we have a lot of productive (and sometimes fun) conversation! Lots of us are currently having brainstorming discussions on the modules topic. SG15 even had its first teleconference meeting last week. ("First" since I've participated, maybe the first ever.)
SG15 has seen this paper for quite a while, and I was aware of it when I wrote my "Dead-on-Arrival" post. Much of SG15 consider it a non-starter for a variety of reasons. I would encourage all interested parties to join in the discussion. Several SG15 participants (including myself) are very active in the #sg15_tooling channel on the CppLang Slack. You may also want to join and subscribe to the SG15 mailing lists.
Java is so much dying that it runs in 80% of world smartphones and some car infotainment systems, which C++ UI framework can claim the same market size? My original point which was sidetracked with all this Java discussion, was that C++ has lost the war against managed languages for doing apps, being corned into the niches of HPC, Fintech, GPGPU, OS, a bit like SQL is never used alone. I provided a list of major OSes, while written in C and C++, those languages are only used for the kernel, drivers, audio and UI composition engine, with everything else only exposed to managed languages and in some cases the APIs are even painful to call from C and C++, but I guess talking about how those managed compilers generated code quality will never reach parity with C and C++ compilers is a better feeling. 
Did you read the doc introduction ? It's well written and clear imho : https://cmake.org/cmake/help/latest/manual/cmake-buildsystem.7.html
Can you enumerate a few reasons why it is considered a non-starter? GCC already has this capability. On windows, I can easily imagine MSBuild and VC++ adopt a similar protocol.
Thanks! I tried, actually, but was almost immediately flagged as spam by the mailing list, and unable to interact with it afterwards. As I understand it this will be fixed in the near future so I can try again.
Oh very much so. These are the simplest building blocks, and work quite well. Funny thing is: The CMakeLists we have uses almost none of the commands documented here. They are a blob of ExternalProject_Adds followed by various custom rules and installation commands. We let the projects build themselves however they want (via make (in-house libraries), cmake (llvm/clang, libc++, etc.)), and use the top-level cmake to attempt to glue them all together. To give a specific example, when the artifact of the llvm/clang project (the clang executable itself) changes, we should completely wipe out and rebuild libraries. We, for the life of us, can't figure out how to make that happen. I think a solution might exist in such a way as to create some pseudo-target which depends on the artifact, and is a dependence of the library project, with a custom command that does the wiping out. I haven't had much time to dig into it, nor do I really want to, because I've had such trouble trying to google things. Normally when that happens, I feel I've completely misunderstood the feature (ExternalProject). From the docs, it seems like I have, since it's documented as being something that doesn't get changed during normal development. However, I don't think there's another good way to handle the paradigm. 
I've left the format unspecified, as I think it is something that should be open for optimisation. If this ever comes to a formal specification, I'd rather specify it as a series of capabilities than as a specific format. That way it will be possible to make a plugin for vi or emacs to perform the necessary queries. 
Oh, now I see it. I didn't realize there was more write-up beyond what was on the Reddit post. Gitlabs mobile site doesn't appear to have any indication that there is a wiki, unless you know to go looking for it.
For me it sounds like add_custom_command already does the trick. You can actually provide it a file as parameter to retrigger the command (e.g. trigger a clean ). I use that a bunch of times and it works like a charm. 
Hmm, didn't know that - guess I'm always looking at it from a desktop system.
Have you seen beast? https://github.com/boostorg/beast 
Yes.
&gt; Note: Big thank you to Flask. It inspired me to create that API. A top-notch project to get API inspiration from. The created API looks like a dream to use!
If companies pay well and have good hours, they are the right companies.
Are you on Linux?
Windows user here
It's a good point. At the same time... I'm fairly sure we can find a reason why _any_ change won't work, leaving us only with what we already have. There will always be some weird thing someone is doing that just won't port to the new situation, no matter what it is. In this case, wouldn't the generator be able to run between the two compilation stages? That means it has access to all known symbols, but it can still add additional symbols of its own. Or maybe it doesn't even need all symbols in order to generate code? Or, if no solution can be found, perhaps they need to accept that they won't be able to use modules - at least for the generated part of the code. That means we will have two types of TU: module-TU, and non-module TU. There is something to be said for this: I would very much prefer for global symbols to have a default visibility of TU-local, rather than global (I want the default to be as if all symbols in a TU are in an anonymous namespace, with explicit keywords for exporting symbols outside the TU). That would be a breaking change, but one that could be introduced if we accepted that there are two types of TU: old-style and new-style. 
It should be pretty similar. Launch VS Code Quick Open (Ctrl+P), paste the following commands, and press Enter: &amp;#x200B; \- C/C++: \`ext install ms-vscode.cpptools\` \- CMake: \`ext install twxs.cmake\` \- CMake Tools: \`ext install vector-of-bool.cmake-tools\` &amp;#x200B; Alternatively, you may fish these packages from the extensions marketplace (Ctrl+Shift+X). &amp;#x200B; Install \`cmake\`. On Ubuntu, for instance you would run: \`sudo apt-get install cmake
Since I'm on windows instead, I will just download the cmake zip file from here: https://cmake.org/download/ and extract it. Do I just get the CMakeLists.txt from the extracted folder and place it into my project folder? 
And your opinion is based on facts, such as ... and ..., right?
Oh, I feel your pain. I spend some time converting my game engine and various other projects to CMake a few months back, and the experience felt unnecessarily brutal to me. You'll see a property documented, but with no explanation at all about what values are appropriate for that property. I've literally had to dig through source patches to find answers, which is appalling for a "defacto standard" C++ build system. There are arguably much better and cleaner systems, but because everyone is using CMake, it doesn't make much sense to use anything else if you want to interop with the rest of the ecosystem. At times, even reasonably simple tasks are maddeningly difficult. Commands for custom targets are so badly broken on Windows that in order to sign binaries, I need to generate a batch file, then execute that file, because the command can't handle quotes properly. I have no idea why executing an arbitrary post-build command seems to be so difficult for CMake. But I guess it says something good about CMake that, so far, I haven't found an insurmountable problem yet, no matter how painful or obscure the solution was. There at least WAS a solution. Even relatively obscure features, such as invoking Microsoft's HLSL compiler, are often supported (if not documented worth a damn).
As usual one has to wonder why build systems have so badly designed languages. What stopped the cmake authors from realizing that it would be far more powerful and simpler to just embedded a tiny lisp engine? Also there is lua, expressively designed for the purpose of embedding. Cmake is such a great progression over the Autotools for multi platform environments and it seems like it has way more support when it comes to the ecosystem of modules. But regarding the actual implementation language it is not a single step better than autoconf/automake...
I think you cannot do that as cmake, to my knowledge, only uses the compiler command to determine whether a target needs a rebuild, not the compiler's content or timestamp. You could try an artificial dependency, though. Or some fake argument to clang that changes with every build, like -DCLANG_MTIME
I tried the VS CMake Linux support with VS2018 very recently and while I got the remote building working, the IntelliSense thought that my code is C++98/03 despite CMakeLists.txt setting it to C++17 via the standard method. No way to fix it, so it was useless to me.
No they don't, that's exactly what I wrote. If your `cmake_minimum_required` is 3.13 or something, it just fails.
Consider doing a header only library like https://github.com/yhirose/cpp-httplib
I'm the person who wrote std::embed and the paper seems a lot fatter than I had ever originally intended ("This will be a good first paper, since it should be so easy to do..." HAAAAAAAAAH famous last words), and as the author it was my job to make sure I took everyone's feedback into account and all the corners of the industry. There are several problems with the criticism: 1. C++ compilers are trash at processing large binary files as array literals. Start here, work through the thread. [https://twitter.com/oe1cxw/status/1014330034142654464](https://twitter.com/oe1cxw/status/1014330034142654464) Because of VC++'s string literal limit, portability is also ruined despite the person finding the "fast" way to write it for C++. Another library's example -- noninus, the benchmarking framework -- is also linked from the paper, demonstrating this, but maybe I should just add this tweet directly and the Article's own admission that they get exponentially fatter compile times for linear increases in file sizes. g++, clang++, edg, and vc++ all chew through 5+ MB files no problem in seconds that are actual C++ code (just run the preprocessor on some simple C++ programs and look at the massiveness of what comes out: why are we paying 2+ minutes for asset files when compilers eat much bigger files as appetizers??). 2. That simple makefile is entirely deceptive: anything more complicated than the most basic processing is much more involved than that. Also, portability: write the same thing in CMake, without relying on file2c or some non-portable, non-globally-installed software utility. (Admittedly, python would probably be simpler, which is what MongoDB settled on.) 3. The paper already discussed the "ld" solution that is referenced in the paper, which creates an object file. It doesn't require 200+ lines of LLVM-ish code, but do look at the Appendix for it and behold the sheer ugliness required to make it cross-platform. Also, it removes the ability to optimize algorithms with constexpr data, and depends solely on Link Time Optimization / Link-Time Code Generation. I am not interested in depending on High Compiler Arcanery to know my algorithm has been optimized, when constexpr and consteval gives me in-language, non-compiler-specific guarantees based on the simplest optimization ever: constant folding. 4. incbin is not cross platform and requires an additional build-step for VC++. Why is this status quo acceptable, exactly? Nothing in the article shows me that assets can be handled in a proper, cross-platform manner without giving up either constexpr-processing, losing optimization opportunities, or thrashing compile-times. I appreciate the criticism, but it's wholly unconvincing. I will continue to push for std::embed in the C++ Standard.
No I think this is incorrect. What you mean is the CMake on the *local* Windows machine. It may be that they still use their own fork for that but I don't think they require many changes anymore, if at all. But this is different, we're talking here about the CMake on the "target" Linux machine, where you'll always have a vanilla CMake version.
There is no VS2018, do you mean 2017 or 2019?
First make sure you have CMake installed. Then, whenever you have a new project you will have to write your own CMakeLists.txt and save it to the root directory of your project. Do not worry this is actually quite easy with modern CMake. [Here are some resources to help get you started](https://gist.github.com/mbinna/c61dbb39bca0e4fb7d1f73b0d66a4fd1).
Probably 2017, the latest stable as of a 3 weeks ago.
Oh, right. I almost forgot about dependencies: it's not that big of an issue to start with, and I already have a paper to solve that problem in a cross-platform and scalable manner that clues the build system in on what is happening: https://thephd.github.io/vendor/future_cxx/papers/d1130.html Unfortunately, there's no way _this_ is getting into C++20. The chances of p1130 surviving EWG -- right now -- are pretty slim, so I need to actually implement it before anything moves forward on that front, unless the Modules Gurus™ bless my paper. I don't see that happening...!
How much C++ do you know? If you're entirely new, I'd say skip cmake for now - it's good for organising projects, but when starting out you really only need to build a single file, there's no need to learn an entire build scripting language just for that. Just invoke the compiler directly on the file you want to compile. Assuming you're already used to C++ and builds and what not, so don't need an explanation for how compilers work (and you're on windows): 1. Install cmake (download the msi installer from the cmake website, not the zip file). During install, select the "add to current users path" option (it's called something like that). 2. Download and install VS code 3. Create a new directory where you want to have your C++ project (I'd recommend making a subdirectory in your Documents `C:\Users\&lt;yourname&gt;\Documents` for this purpse) 4. Open command prompt in this directory (either `cd` to this directory from an existing terminal or shift+right click into that directory in explorer and select "open PowerShell window here") 5. Open the directory in visual studio code by typing `code .` in the command prompt 6. Create a file called `CMakeLists.txt`. 7. In it, add the following contents and save: ``` cmake_minimum_required(VERSION 3.13) project(my-first-cmake-project) add_executable(hello-world src/main.cpp) ``` 8. Add a new file `src/main.cpp` in your project directory (fill it with whatever C++ code you want, but keep it something short and simple for now) 9. Create a new directory called `build` in your project directory (really, you can put it wherever you want but for now it might be easier to keep build and project close together) 10. In a terminal in that directory, type `cmake &lt;path-to-project&gt; ..` (on windows it's going to default to creating a visual studio build, if you want MinGW you have to specify that with `-G MinGW Makefiles`) (if you created `build` in your project directory `&lt;path-to-project&gt;` is just going to be `..`) 11. If that succeeded, you can now build with `cmake --build .` 12. If it didn't, you messed some step up along the way
just curious... why not windows? 
&gt; UTF-8 in `char*` (and `std::string`) just works, unless you want do to anything resembling string manipulation, and if you want to do that, tell your students they are idiots for wanting to do that. That sure is a take.
Exactly! What's wrong with that!? 
I also missed this little gem the first time around &gt; (I admit this answer would be far less reasonable in a class being taught to non-English-speakers. However, those students would likely already know how to configure their systems for correct display of non-English text.) surprise motherfucker, that's most of the classes in the world. And the setting differs per language and per OS.
1) CMake installation instructions here: [http://tulip.labri.fr/TulipDrupal/?q=node/1081](http://tulip.labri.fr/TulipDrupal/?q=node/1081) Use the 64-bit installer, and make sure you add CMake to the system path. Once you install open command prompt or powershell and type **cmake --version** \-&gt; you should see the version number (3.13ish) displayed. 2) Good videos on CMake and VS Code: (from the author of the VS code CMake extension) [https://www.youtube.com/watch?v=wP4cwAtU-g8&amp;index=7&amp;list=PLK6MXr8gasrGmIiSuVQXpfFuE1uPT615s](https://www.youtube.com/watch?v=wP4cwAtU-g8&amp;index=7&amp;list=PLK6MXr8gasrGmIiSuVQXpfFuE1uPT615s) &amp;#x200B;
Generally I wouldn’t recommend using string literals that contain utf8. Sometimes editors will be like “let’s convert that into something else when saving it to disk.” Other than that, great advice! Also check out http://utf8everywhere.org if you didn’t already.
Yeah sure then students will start doing nextchar = mystring[i+1] and everything breaks... It's not true that utf8 just works, unless you just use the string as container to tranfer data: in this view it's true that for beginners it just works
It's also ironic that the committee goes in very detail for very complex and advanced things and accepts such an horrific state of the art of what concerns strings and unicode...
There're a lot of platform-specific low level stuff used, and since I'm not a windows user at all, its hard to implement and debug all these things for this OS. Apart from that there's a [blink](https://github.com/crosire/blink) for windows
We don't, we are working on it :)
I'm sorry. Text handling is not trivial. C++ doesn't provide the necessary tools yet, it will. Arthur's advice only applies to English (with limitations, after all, `café` is an English word and `strcmp` doesn't always work https://wandbox.org/permlink/4knJTNC4n66P86Qj :) ) So yeah, teaching Unicode and text is very important, because unless we do, people will keep getting it wrong. 
It works great for concatenation and replacing things, fine for searching and depending on what you want good enough for ordering. Most string-manipulation beyond that has little application anyways.
That's true; I guess I just don't associate such cases as "template heavy, header only libs." To me that means things like processing a Spirit.Qi grammar or something like that, where the cost of instantiation dwarfs any parsing cost. As long as the instantiation depends on the importee I don't think modules could hope to solve that problem.
&gt; Sometimes editors will be like “let’s convert that into something else when saving it to disk. Well, I don't know which editors do that, but the answer is simple: Don't use editors that suck!
But those are different strings, how could you possibly ever expect that they compare equal? /s
It is visual studio, hard to avoid since it's really the only usable IDE on Windows for me :-D
Thai is the part I also don't get. Why are people so afraid of just letting the build system tell the compiler directly what files to use as an input. Isn't that exactly what we are doing already (*"that o file is created from that cpp file and with those include paths"*. *"That library is the result of linking these .o files together"*, *" That executable is created from these source files and those libraries"* etc.)
I might be wrong, but I thought Visual Studio did save in utf-8 if it sees any utf-8 characters.
&gt; It works great for [...] replacing things In general, it does. For languages based on the Latin alphabet, there's a single code point for pretty much every combination of diacritic + letter that is actually used in practice, and your text editor should use this single code point. There are languages, or editors, which will lead to grapheme clusters composed of multiple code points, and there "replacing" can give very funky results :/ 
I wholeheartedly disagree with the fact that text just works with the minimal primitive tools we have in C++. On the other hand, I don't wish C++ to be fully-Unicode aware. In fact, I don't wish *any* programming language to be fully-Unicode aware; I just wish they would be encoding aware, able to translate from utf-8/utf-16/utf-32 to a sequence of code points, and vice-versa. --- The fact of the matter is that there are many, MANY, weird rules in natural languages that have in turn led to a Unicode specification that is both **massive** and **evolving**. And both of those points make it challenging to have a programming language be "Unicode aware". I very much doubt that embedded developers would appreciate a `std` library containing MBs of Unicode data just because they used some text manipulation on an ASCII string which happen to have a Unicode mode which prevents those MBs from being pruned from the final binary. However, even if there was option to shed off this bulk... The fact that the Unicode standard is constantly evolving is very much an issue for backward compatibility of a programming language: - The programming language can use the latest version of the Unicode standard at the point it was created. Good. Except that 10 years later it's very much obsolete. - The programming language can switch to the latest version of the Unicode standard every release. It's a breaking change though. And one that may not be obvious until the normalization rules' change lead to a different result for a small subset of clients. Either extreme option is bad. The application needs to be able to choose a version, to be able to plan a migration from one version to another if it needs to. Which is why, for me, it makes more sense to deliver this functionality as a separate library. This lets the client application able to move forward on both the language version and the Unicode version *independently*. This lets the client application able to embed *multiple* versions of Unicode for the purpose of migration code. Let's not make the mistake of tying a version of C++ to a version of Unicode.
Pre-VS2015 maybe. Not after that.
I tried to see how far I could get with compiling a minimal console c++/WinRT program with MinGW g++. First, I found that before including the Microsoft headers I had to #include &lt;stddef.h&gt; // nullptr_t #include &lt;cstddef&gt; // g++ nullptr_t using std::nullptr_t; // ditto #include &lt;string.h&gt; // memcpy_s But further progress was halted by these errors: ./winrt/base.h: At global scope: ./winrt/base.h:8293:31: error: declaration of template parameter 'D' shadows template parameter template &lt;typename T, typename D, typename I&gt; ^~~~~~~~ ./winrt/base.h:8287:15: note: template parameter 'D' declared here template &lt;typename D, bool&gt; ^~~~~~~~ ./winrt/base.h:8305:31: error: declaration of template parameter 'D' shadows template parameter template &lt;typename T, typename D, typename I&gt; ^~~~~~~~ ./winrt/base.h:8297:15: note: template parameter 'D' declared here template &lt;typename D&gt; ^~~~~~~~ ./winrt/base.h:8308:19: error: declaration of template parameter 'D' shadows template parameter template &lt;typename D&gt; ^~~~~~~~ ./winrt/base.h:8297:15: note: template parameter 'D' declared here template &lt;typename D&gt; ^~~~~~~~ ./winrt/base.h:8730:19: error: declaration of template parameter 'D' shadows template parameter template &lt;typename D, typename I, typename Enable&gt; ^~~~~~~~ ./winrt/base.h:8312:15: note: template parameter 'D' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:8730:31: error: declaration of template parameter 'I' shadows template parameter template &lt;typename D, typename I, typename Enable&gt; ^~~~~~~~ ./winrt/base.h:8312:27: note: template parameter 'I' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:8733:19: error: declaration of template parameter 'D' shadows template parameter template &lt;typename D, typename I&gt; ^~~~~~~~ ./winrt/base.h:8312:15: note: template parameter 'D' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:8733:31: error: declaration of template parameter 'I' shadows template parameter template &lt;typename D, typename I&gt; ^~~~~~~~ ./winrt/base.h:8312:27: note: template parameter 'I' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:8915:19: error: declaration of template parameter 'D' shadows template parameter template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:8828:15: note: template parameter 'D' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:8915:31: error: declaration of template parameter 'I' shadows template parameter template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:8828:27: note: template parameter 'I' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:9961:35: error: declaration of template parameter 'D' shadows template parameter template &lt;typename T, typename D, typename I&gt; ^~~~~~~~ ./winrt/base.h:9954:15: note: template parameter 'D' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:9961:47: error: declaration of template parameter 'I' shadows template parameter template &lt;typename T, typename D, typename I&gt; ^~~~~~~~ ./winrt/base.h:9954:27: note: template parameter 'I' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:9964:23: error: declaration of template parameter 'D' shadows template parameter template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:9954:15: note: template parameter 'D' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:9964:35: error: declaration of template parameter 'I' shadows template parameter template &lt;typename D, typename... I&gt; ^~~~~~~~ ./winrt/base.h:9954:27: note: template parameter 'I' declared here template &lt;typename D, typename... I&gt; ^~~~~~~~ 
Why can't it be `auto linesMapIt = getMyFavoriteLineMap( args );` ? Most of the time you operate on a variable probably don't actually see its declaration.
Why not just generate a build system outside of IDE (cmake -G ...) and open the solution then?
In mission critical code you can't rely on prior experience as a data point since the events are although rare, catastrophic. You got to assess risk based on technical forecasting. For example, nobody needs to wait for x-ray machines built with C# firmware to kill people to conclude that this is not a good idea.
&gt; &gt; &gt; There are languages, or editors, which will lead to grapheme clusters composed of multiple code points, and there "replacing" can give very funky results :/ With replace I mean the part that is not finding stuff. And yes, it absolutely sucks that: * There are sometimes multiple representations of the same grapheme-cluster in unicode. (I mean: I am German and ä,ö,ü are a thing here; at least the unholy abomination that is „ß“ has only one representation.) * Combining characters are littered everywhere instead of just one plane only used for them so that checking is easy. I don't love unicode, but it is the best we have and utf8 is the only valid encoding to use for pretty much anything.
Well here is the rule of thumb for code maintainability that I have developed Over 20 years doing this shit: a gentleman out of college has to be able to unequivocally figure out all the types involved as well as the intent of the code on the screen after only 15 seconds looking at it. That is the "associate test" which ends up also fitting like a glove in these days of devops. Auto is like goto. One does not make a difference. But clump 10 of them together and You have enabled a potential complexity trap.
Phew good thing I'm Buddhist
Ha perhaps Im just not a fan of farming karma
Sure you can save your files with UTF-8 encoding in VS2017: File &gt; Save as. 
That doesn't really answer my question. Besides, if you want to be super strict about it, `LinesMap::iterator` obfuscates type information from the reader anyway. I have no idea what kind map it is, what are "Lines", or what kind of iterator this is. Maybe the types aren't that important in the first place, and if they are, you can enfore them via type system in other points in code (e.g. accepted function arguments) instead of explicitly typing them out everywhere.
Add the following comment at top of every source file: // Source encoding: UTF-8 with BOM (π is a lowercase Greek "pi"). Also add the `/utf-8` option to every project's compiler invocation command. For console UTF-8 i/o in Windows desktop you can use libraries like my Wrapped Stdlib. I aimed that library in a slightly ungood direction, thinking I could provide workarounds for MSVC idiosyncrasies, not realizing the would add more, and more... Still it's usable after doing as the MSVC warnings say to silence them. 
I think more importantly you know that it is not a reference or a pointer or a tuple right. Notmuch about the type itself but the edge cases that auto hides.
The first tgree chapters of Effective Modern C++ are dedicated to dealing with the deduction rules for auto - and it barely scratches the surface. There are enough blogs online talking about the pitfalls of using auto with say std tie, references and shit like that. auto per se is not bad but like oxygen it is an enabler of potential complexity bombs
If it sees any character not in Windows ANSI. 
VS2017 is clearly not Pre-VS2015 so I'm not sure what are you trying to say. There are/were ways to force VS to save everything as UTF8 before, but the proper C++ support for both source and execution charset didn't come until [VS2015 introduced -utf-8 switch](https://docs.microsoft.com/en-us/cpp/build/reference/utf-8-set-source-and-executable-character-sets-to-utf-8). 
Ummm....this is nice and all but why the need for `boost::interprocess` semaphore? This could easily be implemented using `std::condition_variable` and a simple non-atomic counter, gaining the benefit of using standard components (which everyone already understands). What am I missing?
Not my point, once I figured out what the issue was, it was fixable. Figuring out why it was broken was the issue. You generally don't know what you (or your colleague's) editor outputs on disk so avoiding unicode in your file is always the safe option :)
What about IDEs? Would we need to trigger build system to be able to jump to function definitions in modules?
Ugh... how do I unlearn all of this now???
Yeah; strings are fine, it's chars that don't work. Things like `toupper` don't work on chars. `toupper('ﬁ')` should be `"FI"`.
We already need to do this to get accurate results for all but the most trivial cases. How do you think the IDE knows where to find the definition of a function? Even if you know the correct headerfile (for which the IDE needs to know the correct list of include directories and enough of the (preprocessed) context to identify the correct overload), it doesn't tell the IDE anything about the source file the definition is in. With modules there is at least no more ambiguity on that part. And don't forget: It is called an IDE, because it brings its build system with it, so that is really not a big burden.
I took a shortcut. didn't want to clutter the post with additional utility classes.
CMake is improbably old, and build systems have odd requirements (it sort of makes sense to have a new variable scope for a new subdirectory, for example). I don't think anyone thinks CMake's language would be what they'd design now, but things are where they are.
You should try Bazel and then CMake looks like a teddy bear from a childhood. 
If I remember correctly, handmade hero had a few episodes early on about doing this in windows. If you're commenting because you're looking for a solution, perhaps check there. If you're just curious, then ignore me! :)
I question the need to design a new language at all. I understand that it might be too hard to pull a complete general purpose language with all runtime libraries and tools (scons does it, no?). But the pure language, syntax and semantics, could be just off-the-shelf. Like when you have special requirements, you can either extend an existing language or encode them in some special objects. 
I updated the post :)
i'm good. i have a custom system that works well for me. windows was a pita though. (especially that you can't call back into the parent executable easily). i still think it's the most important desktop os out there. 
Comparison of Unicode strings is notoriously difficult. If the strings have not been [normalized](https://unicode.org/reports/tr15/), graphemes that should compare equal do not. But there are multiple normalization algorithms defined by Unicode, so both strings have to be normalized using the same algorithm (and code must know that). Case-insensitive string comparison is also a nightmare: the words in the strings must have the same human language, because the case-folded comparison rules are language-dependent. For example, in Western European languages, lowercase ‘i’ (U+0069) uppercases to a dotless ‘I’ (U+0049), but in Turkish, lowercase ‘i’ (U+0069) uppercases to a dotted uppercase ‘İ’ (U+0130), and a uppercase ‘I’ (U+0049) lowercases to a dotless lowercase ‘ı’ (U+0131). So in Turkish, ‘i’ (U+0069) is not case-insensitively equal to ‘I’ (U+0049) as it is in other languages. Instead, ‘i’ (U+0069) is case-insensitively equal to ‘İ’ (U+0130), and ‘ı’ (U+0131) is case-insensitively equal to ‘I’ (U+0049).
There is a concept of [scope](https://en.wikipedia.org/wiki/Scope_(computer_science)). Basically variable's become unusable once they go outside of scope. This gives the compiler the ability to use memory/registers more efficiently and reduces bugs.
"should IDEs be integrated?"
The biggest difference to C# is that in C# the smallest compilation unit is a library/.dll and not a single .obj file like in C++.
Yep understood but can you explain it in a bit more detail? I'm away of local and global variables. For example, why can't longestWord and shortestWord be put inside the loop since those variables are only used inside there and not elsewhere in the code. Or, if comparingMax and comparingMin is put in just before the for loop, when x iterates why doesn't it know to change the x's? longestWord and shortestWord values can be changed outside the loop. I know this may seem like a trivial question but I still don't understand why even after reading about global and local variables/ scoping etc.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
This whole argument seems to assume 1. That there is no good reason to do string manipulation, and 2. If your students try to do string manipulation anyway, they'll automatically know to learn all the specialities of Unicode. Neither of these are true.
(Saw you talk on sol at cppcon, and really enjoyed it) 1. Agreed on the file size limit. I measured similar numbers, which were included in the article. However, there still isn't an answer about whether this is a matter of optimizing the compilers, or if C++ compilers are the best tool for compiling binary files into an object file. 2. Not clear why implementing the build chain in CMake will be more difficult than the example. You are right that whatever the approach, it will require addressing portability. It is worth noting that the solutions cited are fairly small, so you can see how they adressed portability. I suspect that you would need to be very familiar with the internals of gcc or clang to get the same appreciation. That said, the compilers already have abstractions to deal with these issues, and std::embed could leverage that. 3 + 4. I feel like you are being selective about where you draw your boundaries. As an example, there is some equivocation between ld the tool and ld the approach. I will just refer back to the previous approach.
A few years back I would have said CMake language is better because you write in one bad language instead of four bad languages. Then they added `generator expressions` which is another bad language. I guess two is still better than four, but the gap narrows.
Unless you are building by hand, saving a step doesn't seem significant I assume that "strange ways syntax" refers to the intermediate C file. Please note that you don't need to read, write, or even look at that file. We don't worry about the readability of object files (.o) either. Some files are too big. My tests put the limit at approx 10MB and higher, but it depends on the machine. Also, I only checked gcc. May I ask, are doing constexpr processing on your embedded assets?
I don't understand why the C++ community has decided to just live with the CMake hell. Is "everyone is using it" a good reason to stick to it? I primarily code in Ruby, Python and Javascript and whenever I try to get to, I will read some CMakeList file and just go back without even giving it a try. Why is a general purpose language like Python, which is easy to learn and use even for beginners, not a consideration for build scripts. It can still be declarative without all this insanity. Why is it always a new language for build systems? Especially with difficult syntax like CMake or Make. 
Emoji function names? Sounds like you spent a lot of time trying to make your build system not work.
&gt; As usual one has to wonder why build systems have so badly designed languages. Premake is built on top of LUA. Never got too much traction 
First - thanks for writing the proposal! I've used binary embedding before and set it up at my current company (for Go as well as C++, which is a slightly different set of problems) and I suspect a lot of people are missing out because they don't know they can do this, or don't know how to make it work. Fully agreed on your first point; the output of `xxd` is expanded by a factor of 6, which is fine for a lot of cases (embedding things like certificates or single small images), but for large files that's unacceptable. We have a binary right now with 280MB of embedded data, generating a 1.6GB C file and forcing a compiler to parse it would be unacceptably slow - even if the compiler is fast (which I suspect it won't be enough), just writing a file of that size takes time (and I am not convinced by the argument that it "needs to exist only long enough to be fed to the compiler", intermediate outputs usually do hang around). `constexpr` for this stuff is interesting although not something I need right now. Definitely also sympathetic to the cross-platform argument for `ld`, getting that to work on Linux is OK but doing OSX as well was a pain, and I can only imagine supporting VC++ would be harder still. The main thing I'm sympathetic to in the article is that describing this via a function call in the source seems a bit unprecedented, and it seems like it might be a bit awkward for the compiler (that it has to know that this particular member of std needs special attention). Definitely happy to see this getting some attention though! 
For what it's worth, I used to actually be really opposed to the Always Auto idiom as well. I think there's a lot of power in a type's name. But that power is eclipsed quickly by the variable's name itself. Consider the most simple case: `int n = 0;` vs `auto employee_count = 0;` It's trite code, for sure, but it illustrates that names of variables convey intent far more than type names do. So if you find yourself being confused by `auto`, it's likely that naming schemes are suffering in other places in the code. However, this is acceptable as naming is often the most difficult thing in programming. Also, don't worry. If we stray further from God's light, we're also straying from the shade of the Bodhi Tree.
&gt; illustrates that names of variables convey intent far more than type names do. Not the types though. I am also opposed to using "int" and "long" by the way - folks use always use int32_t and int64_t for example. "int" "short" and "long" are also ambiguous and can cause serious problems. My real problem with auto is actually the lazy coding style that it promotes. Same case with exceptions and threads. With auto, you give up thinking about types and space out on important decisions when you should be in fact considering overflows, temporaries and such at all times. With exceptions, you give up thinking about a good reporting mechanism and throw an exception, in practice procrastinating a decision of what to do with that special case. With threads, you defer to the OS control over when to process that particular code statement when you should be considering all your execution paths holistically and making a proper design decision. 
&gt; Case-insensitive string comparison is also a nightmare: the words in the strings must have the same human language, because the case-folded comparison rules are language-dependent. There is a language agnostic algorithm which is good enough if you just want an ordering. &gt; These language-dependent case-folding rules require the thread doing the comparison to set its locale) Only because C legacy and bad design. nothing forces the locale to be a global state so that library code doing the comparison know the comparison rules, but that requires the code to know the human language of the strings Strings don't have language per say. People do. You can't have foreign words or sentences in the same text or a list of names coming from different cultures. One of the mistake people do is to assume languages are well delimited or non overlapping, which they are not. So you would sort according to the user local (user being the entity that will ultimately read the text) - machines don't need collation. 
Wow, I'm glad I don't work with you if that's what you care about.
Broken link.
There is scons if you want a python based build system for C++ Generally you can find build systems for C++ in many languages, they just haven't caught on for various reasons from speed, memory use, how quickly they support new targets and community momentum. CMake has a lot of resources online, and supports from project targets very quickly from when they're released. It's also pretty lightweight. They're also doing smart things with having a CMake server for allowing better ide integration
I know that it may upset you, but some people choose this job just because it pays a lot, not because programming is in their soul. You want to fix that? Change the market so that I could work in what I'm interested at and get the same pay and hours. It would really be nice if people who like their job won't go on crusades against those who just work to survive.
Don't they use some kind of Source Control tool? It'd be weird if it didn't pick up encoding changes. Also, you know what their editor outputs if it's part of the project settings.
there is https://buckbuild.com which is used by major companies like Dropbox, Facebook and AirBnB. It uses a declarative Python DSL and guarantees reproducible builds. Additionally we also released a package manager that uses buck as a packaging format: https://github.com/LoopPerfect/buckaroo
You probably want /r/cpp_questions. This sub is for discussing the language.
Cool. I will check that. But still what will I do about all those projects that use CMake
Even if Unicode handling is part of the standard there is no need for it to be neccisarily part of the freestanding subset for embedded. However if you are in the unfortunate situation that you have to deal a lot with non-ASCII languages having a single standard is useful. Right now many libraries ignore it or pick one solution making I teroperability between libs complicated and expensive. Having a good default is beneficial.
Over 320 libraries have been already ported to buck here: https://github.com/buckaroo-pm Furthermore we are working on buildinfer that automates the transpilation process: https://hackernoon.com/announcing-buildinfer-for-c-3dfa3eb15feb 
&gt; Here’s how you create an ASCII string, and do ASCII string searching and ASCII string comparison in C++ I don't believe that the system on which this was made uses ASCII encoding. As in, **no way**.
VS allows specifying the encoding since a long time (2010 I think) and UTF8 is one of them.
I don't know if build systems do computation that are CPU intensive themselves. I thought they only verify the host system for things like dependency checking and offload all tasks to the compiler and linker. How much memory efficient and fast does the language have to be? Can you give some pointers? If you have an easy language like Python, I don't think a lot of resources are needed. From what I tried to read on CMake, it is very difficult and the unfamiliar syntax is an eyesore. I have tried scons once and I was able to do something immediately from the get go and the documentation was just there, easy to grok. 
Cool that looks promising. 
Alright thanks
I am left hanging here... The file linked to implements dual numbers, which is rather boiler-platey. Where's the bit about automatic differentiation?
A build systems speed can mean the difference between being fairly instant to adding a few seconds or more to the build. That really adds up over time. To even spin up the python interpreter is a lot more memory consumption and time than it takes to execute common basic CMake scripts.
I've taken the approach that my in memory respresentation will be UTF-16 (local endianness) and flattened format is UTF-8. I don't do anything special to deal with surrogate pairs in UTF-16. That means my stuff may have issues in China and a few other places. But a world where strings are not indexable, and characters are variable byte count in memory, is just an umlaut too far for me. It becomes extremely impractical. For specialized document manipulation, then sure. That's always doable with ad hoc code specific for that need. But for the all day, every day code where there will be almost uncountable places in a large body of code where strings are iterated through, indexed, sliced, cut, diced, searched, sub-stringed, tokenized, etc... it would be ridiculous to try to make all of that variable character size aware. And the performance hit would be huge as well. Not to mention the testing complexities would multiply out of hand. I'm happy to cover the bulk of the world. And I mean, how many people actually PAY for US software in China anyway, right? I'm being somewhat facetious there but that not THAT facetious. &amp;#x200B; If there was broad native OS support for UTF-32, I'd use that. But it doesn't seem likely to happen? Since I do wrap all OS calls I could transcode to/from UTF-16 in and out, but it would be a significant performance hit, I'm guessing. I just don't think it's worth it. &amp;#x200B;
I don't think it is as big of a problem as you make it to be. You just spin up the Python interpreter only once. And adding half a second won't be a problem for most people I guess. I don't know if you are taking about memory constrained systems but I hope it won't be much. 
I'm curious what kind of codebases you're dealing with. A build systems overhead definitely adds up for large code bases especially. It's not just for memory constrained devices. The time a build system takes to refresh is one of the aspects to developer iteration time.
As I told I am not maintaining any C++ codebase, except having written some small GUI applications in Qt and trying some header only libraries. But I fairly compile all of the applications that I use and install it in a custom path. For example, vim, postgresql, mysql, ffmpeg pretty much all libraries like jpeg, png, ghost script etc. Almost all of them use configure, make, make install. I am just trying to understand how booting up the Python interpreter only once adds up to the build time? Does a build system supposed to do something intensive like Parsing CPP files. I thought all the heavy lifting is anyway done by the compiler and linker. 
Did he already edit his post? I can't find that quote.
What is the shortest c++ code to read one UTF-8 character and append it to a string
You have to initiate the build system everytime you add files to your system, everytime you kick off a CI build, and more advanced build systems track which files have changed between runs that means you start it up everytime you hit compile. Additionally your build system is usually also a project definition. For CMake, it can generate projects for your various IDEs which is something scons couldn't reach parity with and some build systems don't even try to do. CMake can also be used directly by an IDE to be the project definition system. I think this is something you need to try and spin up a few projects with to see the strengths of each build system. Specifically try using them with an IDE 
If you're curious how a modern programming language should deal with text processing, have a look at Swift: https://docs.swift.org/swift-book/LanguageGuide/StringsAndCharacters.html
String reversal: poor man's riming dictionary.
What about emoji which can be 5 codepoints in some cases?
These seem like some advantages of CMake. I can only hope the Python based build systems get there. 
I'm sure that's what they'd do, now. But back then the world was a different place. As the authors commented, if they had chosen to use an existing language, it might well have been Tcl.
There are literally millions of use cases for this. Any Id system that uses numbers. Names, units... The use cases are literally endless. 
You don't normally multiply or add IDs, so no, this is not the case of inherit features from the underlying type.
That is the point. You "inherit" from the int type and specify that you can only compare them. It's useless to specify a strong typedef that has NO properties of the underlying type since you will then have to reimplement everything yourself anyway.
If you want to deal with such things you just have to fend for yourself. The majority of code out there probably assumes strings are indexable and the number of code points is the number of characters. Going beyond that, for the vast bulk of software, is way more than is justified. The complications of modern large software is already on the edge of manageability. And the overhead it would introduce would be significant. My position is always not to introduce major complications or overhead to deal with the uncommon cases. I'd rather serve the 85% with code I can manage and maintain and extend reliably. Let the 15% use tools specialized for the task. &amp;#x200B;
I replied to this: &gt; If you don't need to support all the operation of the underlying type then you can implement your type the old way. Strong typedefs are useful only when it is meaningful to inherit features from the underlying type. The poster of that comment uses the word "inherit" like it is normally used in C++ ("provide the entire parent interface and then some"). You are using it in a totally different sense ("cherry-pick parts of the parent interface you want"). Please use terminology consistently, otherwise I cannot keep track. It would be rather difficult to specify that you only want to compare and not add. C++ has no syntax for that and implications of adding this feature are rather unclear. The linked article reads like a collection of ad hoc rules invented on the spot without even a shallow consistency check. Specifying physical units and dimensions in the core language is yet another can of footless yellow earth-worms.
Anyway, you can wrap fundamental types in a class template *once*, and then inherit it *privately*, exposing only features you need. No need to create a dubious language extension for that. class ID : private fundamental_type&lt;ID, int&gt; { // CRTP here public: using parent = fundamental_type&lt;ID, int&gt;; using parent::operator==(ID); using parent::operator!=(ID); using parent::hash(); using parent::show(ostream&amp;); using parent::read(istream&amp;); // whatever };
&gt; and it seems like it might be a bit awkward for the compiler (that it has to know that this particular member of std needs special attention) `std::launder` sets precedent for that, as well as any "library" functions that are also compiler intrinsics (e.g. basic math functions).
Where does `fundamental_type` template come from? It's most certainly not a part of the standard.
&gt;class ID : private fundamental\_type&lt;ID, int&gt; { // CRTP here public: using parent = fundamental\_type&lt;ID, int&gt;; using parent::operator==(ID); using parent::operator!=(ID); using parent::hash(); using parent::show(ostream&amp;); using parent::read(istream&amp;); // whatever }; Where does this \`fundamental\_type\` class come from? 
Thanks, looks interesting. Commenting so I can read it when not so tired.
Incrementing the string index is just broken period. Doesn't work in utf16, even in utf32 there are weird combining characters and other stuff to worry about. Just pick a good string library and don't write string algorithms yourself.
There is no such thing as "one UTF-8 character." I think the blog post is pretty clear on that with the "black male farmer emoji" and "entire Arabic phrase squashed into a single codepoint" examples.
UTF8 with BOM is the work of satan.
This is maybe the first function that `g++ -MT` has to treat specially, though!
I accidentally hit an alt-key combo and it dumped in a Unicode character and I didn't notice immediately. Things escalated from there :v
I'm pretty sure they just decided to make that a convention and make it look like an operator.
This is really quite impressive. On the topic of multi threading, what problems are there with it? Will it work if all threads are locked on a mutex before reloading? 
It shouldn't be in RES, they've said they won't implement reddit gold features unless that's changed? 
Sure it will. The main problem here is in general non-intrusive solution where application code shouldn't know anything about "hey threads, your code will be reloaded know, do smth with it". But if you will manage thread suspension yourself (as a lock on a mutex), it will work fine. In this case the scenario should be like: - Wait for threads to become locked on a mutex - Call `Live::tryReload` - Receive `ILiveListener::onCodePostLoad` - Release lock The main point here - no user (I mean your application) code should be executed during code reload.
&gt;The majority of code out there probably assumes strings are indexable and the number of code points is the number of characters That's called a bug. For an optimisation (indexable strings) that might not even be useful most of the time as short strings are parsed quickly.
Cool. I'm definitely going to use this in my game engine project, this will save a lot of time. Having to lock my threads during reload is a small price to pay.
[https://stackoverflow.com/questions/31272561/working-with-unicode-code-points-in-swift/31483262#31483262](https://stackoverflow.com/questions/31272561/working-with-unicode-code-points-in-swift/31483262#31483262) Looks nice indeed
How would you do that? Are you strings all "lorem ipsum..."s?
It would be defined by a library. Not a terribly difficult thing to do, and doesn't require any language extension. A bit tedious, but you just do it once. Could be a part of boost and then of the standard library if it turns out to be generally useful. 
Don’t post to the community if you don’t care about it other than your money. Go be miserable my yourself. 
No, it's not even written correctly. It should be `while(--i &gt; 0) { ... }`
Do you know for a fact that IDEs call the compiler to do this? How do you think IDEs provide code introspection on first launch and first look at your code? Have you watched to see if your IDE launches compiler processes to do this?
Sure, go ahead. Feel free to open an issue if you find any weird stuff
This paper isn't a proposal. It's just one gcc implementer who did a thing and has no intent actually trying to standardize it. One of the problems is that you easily end up with a lot of idle gcc instances waiting on their dependencies, all the way done. I'm not sure it's a good match on a single machine, and on a distributed farm it makes BMI build everywhere. It adds a burden to compilers and build systems alike (without solving the module discovery issue, nor the fact that the build system must scan every file to find a module). Overall, it's a halfway measure between letting the build system do everything and the compiler do everything. At that point, we would be better off going full cargo and let the compiler build whole libraries in a single invocation
I had to use resources in a small game I coded. So I started using bash with xxd. It did its job for a while, later had to port to Windows. Because I did not want to introduce a dependency such as Python or Bash, I run my own resource maker. Written in C++, like the game. This took me an hour and a half to debug.Later I had to check also how it did in Windows. Total time of checking + building my tool: hours (modulo bugs). &amp;#x200B; With std::embed it would have been a couple of minutes.
It is important to note that this is a *single* producer *single* consumer queue. Nothing wrong with a SPSC queue - it can often be faster or more efficient, but it is important to document that it has those limitations. (P.S., in this case, it doesn't really use its more narrow focus to gain any efficiencies.)
It's just a restriction. All software has some. And there's lots of quite long text in a lot of cases, and complex parsing and manipulation of text involved in a lot of code. And just the testing requirements would be crazy in a really large code base, which would eat up time not spent on more and better features. Not all software has to be all things to all people. If you live off the beaten path (an alphabet with a bazillion characters), then accept that you might not be able to use some software. 
that should work, let me try it and report back
we've heard this feedback before, thanks for your feedback, please open a feedback ticket on https://developercommunity.visualstudio.com
the CMake on the remote machine is also built from our fork, to support the references feature, for the Targets View; if you use a vanilla CMake version, Targets View won't work well; we are working to "upstream" that with Kitware, but Linux distros are usually behind
One important step that's missing here, windows C++ compiler isn't on the system path by default, if it's even installed. For CMake to work correctly and find the compiler, you need to launch it from "x64 Native Tools" (or x86 for 32 bit builds). If you don't have these shortcuts in Start, you don't have VisualC++ installed in Visual Studio.
[CppCon2014: Bill Emshoff "Using C++ on Mission and Safety Critical Platforms"](https://www.youtube.com/watch?v=sRe77Mdna0Y) 
I'll give you some feedback on that feedback page: It feels pointless posting there (even after you'll probably now reply to me and reassure me that the feedback there is being read and considered), as usually stuff doesn't get upvoted as there's rarely other users searching/viewing those issues, so they'll stay at 0-1 votes and you'll get a standard reply from Microsoft "Thank you very much, we're currently prioritizing issues that affect a large number of customers" etc etc. Recently that message was sometimes changed to "We'll get more information and post again here in a week", and you'll find this on tickets a few months old where a follow-up was never posted. Don't get me wrong, the stuff the VC++ team is currently doing is absolutely amazing, but in terms of customer feedback system, that team has a long way to go. One very positive thing though: That blog post contains a direct email address for contact, which is awesome!
Ah right, I'd meant to mention that but I must've forgotten.
Oh I see! Thanks for that explanation! But in principle if I download the cmake.org 3.13 binary and place it in my WSL /home/user/cmake/ and add that to the `PATH`, I'll be fine, the targets view might not just work that well? Also do you have (a) link(s) to the MRs to cmake's gitlab, so we can track in which cmake version these will be in upstream? Thank you!
&gt; I propose that we split compilation of a project into two phases: the symbol scanning phase, and the compilation phase. During the symbol scanning phase, each translation unit (TU) is scanned for symbols that are visible to other TUs. All discovered symbols are stored in a project-specific database. During the compilation phase, the contents of the database are used to provide all the information the compiler needs. This could work for a subset of C++, a "well ordered" kind. But then I'd expect Modules to in the future spot "well ordered" code, and parallelise the use of such Modules. Let me give an example of non-well-ordered C++ code. In Outcome, there are a few occasions that we call an ADL discovered free function which does not exist yet, can accept arbitrary arguments and returns an arbitrary type, and can have arbitrary overloads in one or many namespaces. In such code, which free function actually gets called depends on the declaration order of third party user code long, long after Outcome's source code has been compiled and first phase bound. On the second phase of binding during template instantiation, only then does the compiler consider the available options as according to the lookup rules and the given two phase lookup environment at that point of time and in that use point, and chooses some implementation, which gives a return type, which lets the rest of Outcome's templates finish being instantiated. This sort of use case is 100% legal C++, but it blows up every Modules implementation I've currently tried it with. I'm sure they'll get to not ICEing eventually, but it'll be very likely be by giving up i.e. when a Module does weird shit like that, kick out Modules state and restart everything by parsing as-if source from the beginning. Ergo, I am deeply convinced that Modules using Outcome across Module boundary will see a large *decrease* in performance. Modules wholly incorporating Outcome internally I expect can be as good as PCH. But I have seen no evidence yet that any build performance increase can occur from Modules over PCH. And Outcome is not a complex library. Those sorts of delayed ADL discovery techniques are throughout any STL implementation. And most C++ programs use the STL. So, until compilers start special casing large chunks of the STL - which surely is inevitable anyway if we are to get Ranges not murdering compile times - I think Modules v1 will disappoint most people with current STL implementations. I do want to reemphasise that I am 100% behind the current committee's approach to Modules. Modules v1 makes possible Modules v2. No Modules v1 means no Modules. So we need Modules v1, even if its practical use cases in the real world for most people will be very limited to the extent that nobody uses v1 outside really, really large projects where a multinational is rich enough to refactor tens of millions of lines of code to fit the v1 design limitations, because build is so painful for them. But let's not worry about that. I am very sure Modules v2 will be far more exciting, and I hope to lend a hand to its creation if all goes to plan. We need v1 Modules over the wall first, and better than proposing alternative designs at this late stage would be to go try out MSVC's Modules implementation with your code, and report successes just as much as failures to the committee folk doing the work. **That** would add lots more value than constant "what if"-ing. 
Hot reloading on windows is not that difficult, there are only a few easy to use functions. 
Where did you put your project files? I would've created the project somewhere under my own user's directory, to be sure I'd have permissions to create objects and exes.
is the workspace meant with that?
Would the code produce an output? 
Eclipse looks like it has a "workspace" as a container for multiple "projects". So, yes, you should make sure that the workspace and all of the projects inside it are created somewhere where your user has write permissions.
Sounds like you might've put your project in a directory that you don't have write access to (for example, directly in `C:\` or somewhere in `C:\Program Files\`). Sounds like you're a student (high school or university I guess?). I'd recommend getting a teacher or a fellow student to help you out with your project setup. Meanwhile, you can still try your code out without project setup in an online IDE, like [this with the code from your question for example](https://tio.run/##bY/LbsIwEEX3/orbdBMWSEFVN@TxL5YzhJGcSRTbsED59jAEWhG1XvnMnaNru3Hcd84tyyeL86klVDyEOJHtG5MCSwexPYXROkKIbfka6vV4dEOKmwFJ67cbLKUxLBG9Zcl3uD3JosahKDRrB3Mz0KOraBrYciU@5RYVit1Ka65lqCpkQp2NfMke8Cx8xOQDqQXVmn@1cQj8V/tRf2Fblbx/E@brmT3l@vqPWjtKM1FMk0D/MWNZvsz@2xR3)
Yes. At least, it does with g++ 8.2.1
Are you talking about `LoadLibrary/GetProcAddress`? If so, there's not only "open shared library and use its' functions" under the hood. If you want to implement this approach on windows, you should implement: - Parsing of PE/COFF binary format - Figuring out how sections and relocations are organized, what is the content of the sections, etc - Dealing with linker and its' options - Dealing with compiler and its' options - Manually loading `dll` with new code into the process' address space, resolving relocations by yourself (cause on windows you have no `--export-dynamic` linker flag), which is hard So basically there's a lot of work there
That is excellent! Just one minor nit (lol), I would pass a predicate to `condition_variable::wait` instead of putting the loop outside, like this: ``` m_cv.wait(lock, [&amp;]{ return m_count &gt; 0; }); ``` 
Is there an alternative? Changing the project directory does not work. It is saved somehow in the MingW directory. 
I remember some trick with complex numbers where if you evaluate a function at x+ i*eps and divide by eps you get the derivative. I think this is similar.
I was not familiar with this technique before. Thanks for posting it. &gt; I'm already considering leveraging the code to test ffmpeg quality settings Testing encoding doesn't require no-refrence however, and ffmpeg has vmaf available already, and x264 can calculate psnr/ssim during encoding. Not sure why Brisque would be preferred. It would be interesting to know if Brisque would correlate with vmaf however.
Automatic differentiation is based on dual numbers of the form f(x) + eps \* f'(x), if eps is the root of zero added to the real numbers. Then multiplication of two dual numbers of such form is equivalent to the dual number of the function multiplication (\[fg\] = \[f\]\[g\], if \[f\] = f + eps \* f'). So at least for multiplication dual numbers are cool, not sure what happens when you start thinking about other operations such as exponentiation. For example, you would derive x\^2 by replacing all x-es with x + eps and evaluating the expression. (x + eps)\^2 = x\^2 + 2x \* eps, therefore the derivative is 2x.
Just add an emoji, it will force UTF-8 no matter your locale.
&gt; ffmepg-to-opencv conversion Is that YCbCr-&gt;RGB conversion? Cause you can use external memory in `cv::Mat` just fine. OpenCV is quite limiting though, since it has no support for planar formats outside of converting from them. And documentation won't tell you what format it wants half the time, so you either have to check the asserts in the code or pray.
 // meneldal2 said to put this here: 💩
You might want to recheck your assumptions. And yes, it is just a convention, though a silly one IMO – postfix operators are hardly confusing enough to warrant such tricks.
Awesome, it automatically recompiles your changed source files and links them. This is a game-changer.
There are already multiple solutions for this platform, AFAIK.
On the contrary, it ensures that Windows tools, in particular MSVC, will interpret the file correctly. Some archaic tools such as g++ from ten years ago, can't deal with it. Using such tools is very counter-productive, to put it mildly. If you have such problems, just stop using the archaic tools. Arguing against the most portable format, especially with purely emotional and/or social arguments founded in social inertia from the time of the now archaic tools in Linux, is IMO to sabotage others; please don't.
I think you could eliminate the separate BATCH mechanism, because there doesn't seem to be any ambiguity if the client simply sends multiple requests before waiting for the responses.
That's what I do. I use libswscale to convert from YCbCr that pretty much ever video I've ever looked at seems to be encoded in to BGR for OpenCV. I'm building up a pipeline of boost::signal2 signals in various objects, so my decoder notifies my frame2cv object that it has a frame available and the frame2cv object processes it and notifies downstream listeners that it has a cv::Mat available. For my brisque example, I just attach a callback function to the frame2cb signal and run the brisque assessment on anything that comes out of it As far as I can tell, OpenCV mostly just operates in BGR. You can convert to other formats, but all the internal operations seem to be in BGR. I probably could just use the ffmpeg support in opencv to get that far, but I'm planning to do some other stuff with this library in a bit, and I'm very comfortable with how it works at the moment. So far, I haven't needed multiple formats for anything, so I haven't built any objects into my media library that use them. One of these days I'll probably get around to encoding video and will probably have to throw down a few objects to support that. I'm also planning to do some stuff on the audio side -- there's already an object that tries to use PocketSphinx to do some speech recognition. Although I did successfully get it to recognize a phrase in my unit test, I found it's not so good for continuous speech. I think it'd probably be better to try to recognize syllables in a stream and then try to put them together in a context-sensitive way to form words, if I want to do continuous speech recognition. I should also note that I really haven't made a study of anything opencv does, image quality assessment or audio recognition. I am just pretty good at integrating stuff and presenting it all in a (hopefully) useful fashion.
That's true. I did build the netflix vmaf library and run it on some test videos. It seems fairly tricky to set up and didn't seem to present an easily-useful API. I didn't spend a whole lot of time in their code, though, as at the time I was looking at videos that I wouldn't be able to get reference video for. In my brief testing with the brisque example, it seems that the brisque score does degrade as I degrade video quality (By re-encoding the video with ffmpeg and some bad quality parameters.) I'm planning to do some more extensive testing in the next few days, but I'm quite encouraged by what I've seen so far. If it's just an easily-accessible and moderately accurate measure of the kinds of distortions that are typically represented as encoder artifacts, that's actually a huge win for some of the other stuff I'm doing.
this may well all be true, but it doesn't contradict what pjmlp has said at all
You're right using the ffmpeg utilities to do the conversion, OpenCV can't even resize a `cv::Mat` using `int`. Ffmpeg definitely doesn't have the best documentation for the API, but I had less bad surprises than OpenCV. I find a lot of processing the BGR is just a waste of time, because many algorithms just process black and white images so you get another conversion you would have avoided in OpenCV accepted planar formats without hacking it around.
Unless it actively defends against that 'restriction', it's a bug.
This is pretty neat stuff. Just a few remarks: \- your include guards should probably be just "ICECREAM\_H" because names that begin with an underscore then a capital are reserved for the implementation: [https://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier](https://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier) \- I'm not sure why "Icecream" and "print" are objects. It'd be much more clear to me for everything to simply be namespaced functions. There's no state to manage (maybe keep "Icecream" as a class if you choose to have a state later). \- You're doing a lot of tuple manipulation when keeping everything fully variadic seems much more straightforward. You probably wouldn't need any of those helpers. \- With any logging facility, it'd be nice to configure the output stream, like "ICECREAM\_CONFIGURE\_STREAM(file)", and also be able to disable it completely. \- Looks like the python package this is based on has a few other bells and whistles; are you considering adding some of those features? \- You have a notice in the source as well as a COPYING file, but most people look for a LICENSE.txt file: [https://help.github.com/articles/licensing-a-repository/](https://help.github.com/articles/licensing-a-repository/) I'd definitely consider using something like this. Its quite simple, but would be very nice to have around. 
By the way, does any one have any up-to-date info on what's wrong with codepage 65001? I just remember it doesn't really work.
Whats the difference between using your lib and the ffmpeg backend in opencv?
Your use of semaphore is abstraction impedence. Just drop it. Use a cv for "has_room" and "has_data". Share a mutex (with the data). Use thr count as your condition in the cv. For example: std::lock_guard&lt;std::mutex&gt; lock(m_cs); has_data.wait([&amp;]{ return m_count&gt;0; }); item = m_data[m_popIndex]; m_data[m_popIndex].~T(); m_popIndex = ++m_popIndex % m_size; --m_count; has_room.notify_one(); 
Your semaphore abstraction added independent counts, extra mutexes, and a pile of extra lock and unlocking. 
Maybe who ever wrote it just wanted to make a language. Design choices are rarely wholly rational. At every company I've ever worked at there are lots of decisions made based on what people think will be cool or fun. The reality is most of us have to work for other people for a living, so you kinda have to sneak in cool work when you can, even if it's not the most practical.
I really just prefer to use Makefiles and will special case them for different systems. The simplicity makes it so that anyone with an odd system can easily modify it. This seems to me to be a lot better of an option than adding so many abstraction layers which I do not have enough time to understand. This won't work for all projects, but it does for many... and I'm sort of confused why it isn't more popular. When I see a project with &lt;100l Makefile I'm happy because I know I can get it to work almost if not immediately. This isn't the case with any of the other 20 build systems where I need to google a bunch of weird bs to figure out what the issue even is. 
It is 'defended' against. When the text was transcoded in from whatever external format it's in, it would cause a surrogate pair and that would cause an error, because I don't support them in my internal UTF-16 text format. I have a full text transcoding framework, which handles transcoding all the supported encodings to/from UTF-16, and the code that takes in the UTF-16 watches for UTF-16 surrogate pair leading characters. You can ask the transcoder you are using that bad characters be replaced with a replacement character, like a space or whatever you choose, so that you can import as much of the text as is representable. That might not be much of it's almost all extended characters, but it won't do anything dangerous, just throw an exception or replace the unrepresentable characters. &amp;#x200B;
Exactly. It's the paradigm that is broken, unicode is counterintuitive for beginners so correct behavior should be forced and teached at the beginning. Almost all developers I know just think string as a sequence of since byte/word characters.... 
According to their own statements, Visual Studio use intellisense, which uses the EDG compiler frontend and QtCreator uses Clang nowerdays. And I also know the difference between the auto complete quality in VSCode before and after you e.g. install the CMake Plugin. Oh, and if you are using the "open folder" functionality in Visual studio on a cmake based project, you can even see how Visual studio runs cmake in the console window. So yes, I happen to know for a fact, that at least some IDEs rely on an external or internal compiler+build systems when possible and I have first hand experience with the quality degradation for things like autocomplete and goto definition (or complete lack thereof) if the IDE lacks the necessary build information. I'm not saying they don't have fallback mechanisms / heuristics and no, I haven't looked into their source code, but the ones I used sure as hell behave as if they first have to compile the code before they provide **accurate** support.
Somehow I never envisioned modules to map only to a single file either.
Am I blind or is there no link to the repository?
&gt; Commenting so I can read it when not so tired. You know reddit has a feature called "save".
Windows has has [hot patching](https://jpassing.com/2011/05/03/windows-hotpatching-a-walkthrough/) mechanism. I think it can be also used for hot-reloading. Live++ supposedly does this. 
https://github.com/WG21-SG14/
&gt; don't write string algorithms yourself. Or do, and learn how to do it properly, and from then on reuse what you wrote.
&gt; A string is a series of characters The very opening sentence is incorrect... A string is a series of Graphemes, which are composed of CodePoints, which are composed of CodeUnits (in whichever encoding you prefer). You can't just decode a codepoint and be like "good enough", because it's not.
Why UTF-16? You are aware that Unicode is a format that takes up 21 bits per codepoint, right? UTF-32 is the only logical way to internally handle Unicode.
&gt; Almost all developers I know just think string as a sequence of since byte/word characters. Because that's exactly what it is. Anything with more inherent meaning, especially encoding, is not merely a string, it is _text_, and text needs different handling. Part of teaching beginners is teaching them to distinguish different subsets of functionality. Strings are low-level things, and they _should_ be regarded as such.
I'd really like to understand the downvotes. This page really helped make CMake "click" for me and I took a lot of time before stumbling on it so I thought that it would be an useful share.
lol
Two questions as I find myself unable to follow the development on modules: - Are preprocessor statements allowed to influence what module is declared in a particular file? - Are they allowed to influence the set of imported modules?
Thanks
My job has a custom build system written in ruby. I rearchitected some of it, and a build that could take 24 hours or longer now takes under 20. *shrug*. Build systems can add a lot to a build if they aren't careful.
&gt; With threads, you defer to the OS control over when to process that particular code statement when you should be considering all your execution paths holistically and making a proper design decision. I'm sorry, what? Do you actually know what threads are typically used for?
Yes. Do you know how they are implemented? I have 15 years of experience with Multithreaded application development. I know how this sausage is done.
I think the bigger issue is in non-identical but overlapping definitions. When do you decide to stop looking and start binding? Or so I understood from [this comment](https://www.reddit.com/r/cpp/comments/amcti9/we_can_fix_modules/efovhzl/).
I've been digging through a system which I consider to be a form of EC while re-implementing an old game engine - Dark Engine from Looking Glass Studios. &amp;#x200B; The engine had properties (various data types with data fields each) attached to objects by numerical IDs, and had links that had two IDs (source+destination) and data fields. &amp;#x200B; What it also had was a kind of inheritance link (called metaprop) that injected properties from archetypal objects (non-spawned object templates). This seems to have been done to further empower the data driven nature of the system and simplify game design by removing duplication and allow easy changes. It also allowed runtime masking by adding additional metaproperty links with higher priorities. &amp;#x200B; As I see this as an opportunity to ask a question - is this kind of data driven approach comparable to EC/ECS systems? More specifically is the archetypal/inheritance system used these days?
&gt; This is pretty neat stuff. Just a few remarks: Thanks! &gt; - your include guards should probably be just "ICECREAM_H" because names that begin with an underscore then a capital are reserved for the implementation: https://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier Old Habits Die Hard. You are right, I sure should use that. &gt; - I'm not sure why "Icecream" and "print" are objects. It'd be much more clear to me for everything to simply be namespaced functions. There's no state to manage (maybe keep "Icecream" as a class if you choose to have a state later). The `print` must be an class, because the empty `IC()` macro will expand to: ::icecream::print{__FILE__, __LINE__, ICECREAM_FUNCTION, "",} There is no way of get rid of the trailing comma without compiler specific extensions. So, if `print` were a function, a trailing comma would be a compilation error, but in a list initialization a comma is not a error. The `Icecream` class is expected have state soon. The customization options (like output stream, prefix string, etc) will be on there. &gt; - You're doing a lot of tuple manipulation when keeping everything fully variadic seems much more straightforward. You probably wouldn't need any of those helpers. All tuples and macros are variadic, those helpers are there just to iterate on all `N` items. &gt; - With any logging facility, it'd be nice to configure the output stream, like "ICECREAM_CONFIGURE_STREAM(file)", and also be able to disable it completely. Yes, that is a planned option to add to the `Icecream` class. Soon :-) &gt; - Looks like the python package this is based on has a few other bells and whistles; are you considering adding some of those features? I expect to mimic all possible functionalities from the Python Icecream. I have used the Python lib for some time now, and it is really useful. &gt; - You have a notice in the source as well as a COPYING file, but most people look for a LICENSE.txt file: https://help.github.com/articles/licensing-a-repository/ Agree, I think that the LICENSE.txt name would be clearer too. 
I'm curious why having BOM is useful for Microsoft. After all utf8 literally has no "byte order". 
It's only a sequence of Graphemes for the purpose of interactive text selection. It's a sequence of Glyphs (composed of CodePoints) for rendering and a sequence of Collation Units (composed of CodePoints) for ordering.
It’s not in Swift, which is kinda the point.
I accept that, as most people do. If you want to restrict your user base for such a silly reason, that's not my problem at all. How many times do you have to access the nth character of a localised string for such a choice to seem sensible to you?
yes and yes
Because the default narrow encoding is Windows ANSI, *any* sequence of bytes is valid as ANSI-encoded text, and like *nix Windows does not have any convention for meta information about files, such as their encodings. And also because the Visual C++ compiler uses an originally slightly better scheme than g++, where different source code files in the same translation unit can have different encodings. In particular UTF-16, once a not so outlandish choice, is supported. Today that technical advantage is nullified by the nearly universal convention of UTF-8 (or pure ASCII) source code, but it's there. So, without the recently introduced `/utf-8` option (or `/source-charset:utf-8`) the Visual C++ will **mis-interpret** the source code bytes of an UTF-8 file without BOM, as Windows ANSI. Recent: not sure of version but these options are still not part of the Visual Studio 2017 project settings. They can be set manually as text. The UTF-8 encoded BOM is necessarily also valid as Windows ANSI-encoded text, but it's extremely unlikely to occur at the start of an actually Windows ANSI-encoded file. It's much, much more unlikely than the `MZ` magic number that, at the start of a text file, will cause Windows' `cmd.exe` to regard the file, regardless of filename extension, as a 16-bit executable... :) 
Thanks! Yep, the map intersect is where this very naive approach reaches its limitations quite quickly. For any real-life scenario where you need to intersect more than 4-5 tables in a critical section, performance might just not be enough. However, this simple approach can be made to work by being a bit attentive to the data structures used for your maps. In my actual code, I'm not using unordered_map, but a custom map-ish container implemented with std::vectors on the inside. An intersect for me is now a linear iterative operation on N amounts of cache-friendly `std::vector&lt;EntityId&gt;`. My plan is to introduce this method in a future blog post, which admittedly makes the code a bit more complex on the inside, but on the outside is still very much an approach of "just a collection of maps". Thanks for the link-back!
Holy crap.
I like your Mutex design for it's simplicity and the security it provides. I like it so much that I wrote my own based on it =) &amp;#x200B; There is one tiny thing that I added for increased security : `U &amp; MutexGuard&lt;U&gt;::operator-&gt;() &amp;` Notice the '&amp;' in the end, it prevents the caller to access the protected data trought a temporary MutexGuard.
Expecting the whole industry to switch to BOM utf8 is broken. So users need to be able to use non BOM utf8. And once they can skip the BOM, there is no reason to use it at all. If you don't specify /source-charset, msvc will default to the user's default code page. Solution: set your code page to utf8. No other encoding is needed.
The later is probably necessary, as we don't have the tools to have conditional imports otherwise. I'd rather that modules have conditional export only and for example, if you do `import microsoft.win32` on Linux, it would compile and the module would be empty. However... it forces a bottom-up approach that people seemed deeply uncomfortable with when I brought it up. The former ( conditional module identifier ), is... yeah, holy crap In either case, the declaration can be expanded by a macro and that's... completely pointless and basically forces build systems to invoke the compiler to parse the files.
how is it a single producer/consumer queue? it can be used by multiple producing and consuming threads.
try now. I was doing maintenance on the server :)
thanks. corrected the semaphore code.
If you have the source available, you'll get much better outcomes with a full reference algorithm than a no-reference algorithm as measured by SROCC if you look at the literature. I've been working on a IQA lib for OpenCV that you may find useful, I would suggest an algorithm like GMSD which is performant and more accurate than more basic algorithms like psnr/ssim: https://github.com/opencv/opencv_contrib/pull/1959 or standalone C impl https://github.com/clunietp/libgmsd I would like to implement a no-reference algorithm in the library. I will definitely be looking at your implementation, thanks for posting!
It enables support for multi-config generators, which can break certain \`Find\*.cmake\` scripts. For example, it'll give you the debug version of the OpenSSL \`.lib\` files all the time, no matter what.
I am a long Eclipse user and despite all it's past hate it's getting better and better. Currently the built-in C++ parser is better than VS without ReSharper, it fully understans SFINAE and other hard things. Really extensive realtime code analysis and no false negatives. pros: - really good code parsing/highlight - when going to definition, unlike IntelliSence, it will not ask you which template to choose because it does understand which specialization takes place - some refactoring tools like in the ReShaper but for FREE (renaming a class automatically adjusts includes) - works with any GCC distro out-of-the-box (also on Windows), for Clang you need to change 1 thing only - works with GDB, hard to tell how well (not much experience with other IDEs in debug) - good autocomplete if you know that things like `u_p` will suggest `unique_ptr` - has a lot of dark themes (and useable theme edit interface compared to VS's XML of 1000+ lines) - macro debug: you can see the text expansion at each step (could be very useful when you use/develop some X or other fancy macros; `BOOST_FUSION_ADAPT_STRUCT` - type containing 3 variables has 4400+ macro steps) - good interface for compiler/linker options - not like tons of different settings windows in VS - no longer "plugin delivery system" - now all is integrated in 1 application cons - build button: still no key shortcut (there is workaround though) - runs on Java - built-in parser does not (yet) recognize fold expressions, `if constexpr` and user-defined literals (underlines as syntax error), C++17 library headers (filesystem, optional, variant) work anyway
I am not sure such a thing should even be standardized. But it does solve the problem at hand. The C++ standard doesn't say anything about how include files are found either, but compilers seem to have converged on a practical standard. &gt; One of the problems is that you easily end up with a lot of idle gcc instances waiting on their dependencies Why is this a problem? Only reason I can think of is memory consumption, and memory is pretty cheap. &gt; on a distributed farm it makes BMI build everywhere. I am not sure I follow. The build system can simply hand a network path to the compiler, or copy the BMI from the remote machine. &gt; It adds a burden to compilers and build systems alike The protocol is a 2 page protocol. Is the burden that much, especially when compared to the alternatives (build systems incorporating at least a preprocessor, or compilers becoming the build system)? &gt; (without solving the module discovery issue, nor the fact that the build system must scan every file to find a module). Why do you need to know in which file a certain module is located? Only reason I can think of is IDEs, and IDEs usually require a full compilation anyways before their browsing works. &gt; Overall, it's a halfway measure between letting the build system do everything and the compiler do everything. Isn't that what we want? Compilers should be compilers and not become build systems, while build systems need not incorporate a compiler. This seems to hit the sweet spot.
Was it the version given at CppCon? &gt;The Bad Big Wolf Meets Riding Hood Little Red - Borislav Stanimirov [https://www.youtube.com/watch?v=Dw0UBuTKHHg](https://www.youtube.com/watch?v=Dw0UBuTKHHg)
Expected some info and examples of pointer aliasing optimizations and how it could be improved. Still, not dissapointed.
&gt; Use the value of the first vector as index of the second vector whose value you will read. I don't get this. This will be UB if values are out-of-range indexes unless the first vector will be just asorted 1-n numbers.
&gt; Let's not make the mistake of tying a version of C++ to a version of Unicode. It shouldn't be. Leave freedom to refer to a later Unicode standard if available.
The attitude perhaps?
This is something to do with two-phase templates and a lack of argument dependent lookup (ADL) - because your overloaded `makeUse` function for abstract::OneOf is _after_ the template that uses it, (`template&lt;class T&gt; using MakeUse = decltype(makeUse&lt;&gt;(T{}));`) it can only be found via ADL - which requires the function to be in the same namespace as its argument's type.
I'm just going to post a guess that's it's caused by tie-breaker rules which probably rank functions from an imported namespace lower.
Yes, I wasn't explicit about that. Let's name one vector `data` and the other `indices`. You'll have to make sure that generated random values in `indices` are never larger than or equal to `data.size()`.
(CMake developer here) \&gt; Commands for custom targets are so badly broken on Windows that in order to sign binaries, I need to generate a batch file, then execute that file, because the command can't handle quotes properly. What command? There is the \`VERBATIM\` option to \`add\_custom\_command\`. \&gt; I have no idea why executing an arbitrary post-build command seems to be so difficult for CMake. There's no standard you can rely on to figure out how arguments will be parsed on Windows. There is the one provided by the standard library, but enough (important) tools don't use it that it can't be expected and say "sorry, use the standard" for those that don't. \&gt; &lt;documentation woes&gt; Please file issues where documentation is lacking. There are things that are not used often by upstream developers personally and these are more likely to be the poorly documented bits. But, not using them ourselves makes us blind to that lack.
And honestly, Tcl, Perl, and those used by autotools (which generally have more portability issues) are the only languages that haven't broken compatibility more than CMake's guarantee since CMake's start. Basically, a nicer language would mean that CMake's backwards compatibility story would be near non-existent.
\&gt; What stopped the cmake authors from realizing that it would be far more powerful and simpler to just embedded a tiny lisp engine? I imagine LISP wasn't on the author's minds at the start. Tcl was a possibility…and I'm glad they didn't go that way.
I would I go about structuring a project which is supposed to be consumable as a library but also as a commandline tool? I would like to write a library with a C API that will offer optional Python/NumPy bindings but also comes with a commandline interface which allows the user to access the library's functionality from the commandline? I noticed some of the Rust projects do that. They tend to split commandline projects into library + cli so that the functionality is also consumable as a library. Another example that comes to mind is a video encoding library that may want to offer a cli on top of it.
\&gt; Why is a general purpose language like Python, which is easy to learn and use even for beginners, not a consideration for build scripts. It can still be declarative without all this insanity. Given's CMake's age and backwards compatibility goals, that'd mean Python 1.x. Plus, Python is hard to contain and disallowing binary modules to have a hope of a Python2 uplift while maintaining backwards compatibility would have been near impossible. Then it would have happened again with Python3. I do like Python, but its backwards compatibility story is not as good as CMake's which is something very useful in a build tool. I do agree the language has its…warts. But everyone says "should have used X!" while assuming the language was made in the 2000's and not the 1990's when many things were different.
Please file the issue upstream. [https://gitlab.kitware.com/cmake/cmake/issues](https://gitlab.kitware.com/cmake/cmake/issues)Reddit is not a bug tracker and we (upstream) don't treat it as one. That said, this is in libuv, so some work with libuv developers will likely be necessary.
And if that works for you and your project, that sounds great. The issues arise from supporting other platforms or compilers where conventions vary wildly. Raw makefiles usually assume compilers have GCC-compatible flags. Which is true for Clang and…no others. You're missing Intel, IBM, EDG, MSVC, PGI, and probably others I'm forgetting right now. Do you not care about those? Sure. But not everyone can do that and having to respecify things as basic as "how to make a shared library" on all those compilers is handled behind by CMake for you.
... I don't understand, sorry
 &gt; My machine at home is windows 10 pro and these are on 7 pro. So I can't use a flash drive to carry files back and forth. i don't understand: why is it not possible? besides from the fact that you should have used a version control system (let that be a lesson to you) hosted on a remote server.
None of my drives will transfer between them and I don't know why. Maybe it's because of the ridiculous amounts of security on the school machines. I always make backups at home. And look what happens the one time I don't have a backup. Serves me right I suppose.
&gt; There's no standard you can rely on to figure out how arguments will be parsed on Windows. For quoting: https://blogs.msdn.microsoft.com/twistylittlepassagesallalike/2011/04/23/everyone-quotes-command-line-arguments-the-wrong-way/
ah, so those machines don't accept usb drives? that makes sense.
It's started as a simple declarative language.
They do but windows 10 can't read what I put on them, and vice versa.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/an2tp3/learning_resources_for_a_beginnerintermediate/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yea that's unfortunate. By reading all the comments of this thread I realize it's pretty much impossible.
oh.... never heard of such a thing. not saying is not possible, but i just never heard of it. 
Neither have I. I wouldn't think it would cause an issue, but I was wrong. And now all my stuff is gone.
&gt; The later is probably necessary, as we don't have the tools to have conditional imports otherwise. I guess I would prefer some solution that comes down to "import this, if a particular flag is set on the command line to the compiler (or based on some macro instrinsically defined by it" not something that is dependent on the state of the preprocessor after preprocessing got knows how many lines of code. But I see, why this is important in practical terms. 
I would rather change my codebase to a new better build tool than having to deal with all the technical debt acquired for two decades. Not trying to say old is bad, but if it is as unpleasant as CMake then it should be changed for greater good. 
That only works for tools which use \`CommandLineToArgvW\`. Turns out I was inaccurate in saying "enough (important) tools". Apparently it isn't common to find tools these days that don't do it, but many DOS tools (including \`cmd\` itself) and Borland (not important today) do not use that functionality. \`VERBATIM\` is the way to say "I know what I wrote; don't try and fix it" for when CMake's rules don't do what you want (though personally I try to get it right, I agree it can be more finicky than anyone wants it to be).
Sure. But CMake doesn't have to be unpleasant. I think many of the issues pointed out above are due to dealing with complex applications. Simple applications or libraries are really simple. Here's a library I wrote a while ago: [https://github.com/mathstuf/eventd-plugin-journald](https://github.com/mathstuf/eventd-plugin-journald) Looking at it now, the version handling at the top is made easier by passing \`VERSION\` to \`project\` and the \`pkg\_get\_variable\` function is now upstream, so that can be removed as well. The documentation generation is a bit messy, but I don't think it'd be too much \*simpler\* with another tool. Yes, when you have a complex application, CMake gets complex. But I think any build tool will unless you enforce things like "no per-source flags" and "no per-target flag differences except symbol export controls". If you can do that, your CMake can also get cleaner by factoring things out behind your own \`add\_library\` wrappers.
Cmake is the defacto standard for C++ projects. I find it quite bad myself. I prefer Meson. Scons is quite slow.
C++ in general doesn't rely on function composition as much as Haskell/OCAML (from which I guess you took your example). This would introduce yet another coding style into C++, and I'm not sure what's the benefit of this, except for looking nicer to seem people.
At my last two workplaces, yes.
The "continuation" is named value_or.
I don't really know the rationale is but it's simple enough to implement it on your own. I do feel it would be nice to have it standardized though.
I can't give you any of my actual CMake code, but it has this: set(CMAKE\_CXX\_STANDARD 17) set(CMAKE\_CXX\_EXTENSIONS OFF) 
Move the definition of MakeUse to the point just before your using A = .... declaration and everything works fine.
I've been writing more Java recently, and the ifPresent and ifPresentOrElse are awesome. This would still be pretty C++-ish to pass a lambda to an optional, e.g., std::optional&lt;int&gt; value; ... value.ifPresent([](int v){ std::cout &lt;&lt; "value is present: " &lt;&lt; v &lt;&lt; std::endl; });
Having seen the module once, it is surely faster to look it up from a cache than to search the filesystem in each instantiation of the compiler. Worst case, the module mapper could just search the filesystem. So it's better to describe an abstraction than the implementation.
That is proposed in [P0798 Monadic operations for optional](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0798r3.html). It will be discussed in Kona, so there is a realistic chance that it might be in C++20. 
&gt;You're doing a lot of tuple manipulation when keeping everything fully variadic seems much more straightforward. You probably wouldn't need any of those helpers. &gt; &gt;All tuples and macros are variadic, those helpers are there just to iterate on all N items. I think what he means is that instead of using tuples you could directly use a recursive variadic template. I guess it would like: &amp;#x200B; template &lt;typename First, typename Second, typename ...Rest&gt; auto print_all_args(First&amp;&amp; arg_name, Second&amp;&amp; arg_value, Rest&amp;&amp; ... rest ) -&gt; void { this-&gt;print_arg(arg_name, arg_value); if (sizeof...(Rest) &gt; 0) { std::cout &lt;&lt; ", "; this-&gt;print_all_args(std::forward&lt;Rest&gt;(rest)); } } &amp;#x200B;
Agreed. How would you implement it on your own? Or would you have to roll your own wrapper around std::optional (or implement it yourself)?
How is letting the compiler build whole libraries better in a distributed build? This paper was specifically intended to make the interaction of the compiler and build system as clean as possible, without either having to take more responsibility than they want to. The default module mapper provided with the compiler might be inefficient without build system support, and in effect be an integration into the compiler. The build system can replace it with something cleverer. It should work pretty well in a distributed environment, certainly a distributed build system is something Nathan had in mind when he defined it.
Not only does it look nicer, but it also reduces boiler-plate and allows continuation chaining. Take a look at the blog post I linked at the end of the post for an example in C# that is greatly simplified as a result of continuation chaining. I agree that it may take some folks that aren't familiar with functional styles a little bit of time to get used to, but once you have warmed up to this style I would imagine it would be hard to go back to the procedural style.
`value_or` is basically the opposite of what OP wants
You can do something like this, but its only benefit over the style you showed is that you \_could\_ mark s as const: ```c++ optional&lt;int&gt; i = 7; optional&lt;string&gt; s = i ? to_string(*i) : optional&lt;string&gt;(); ``` I think your style is probably better.
Yep.
I do 
A free function template would work fine. It just so happens i posted a meme on r/programmerhumor that includes the implementation of a Maybe class template. It's not very nice (I made it mostly as a joke for a friend that likes writing haskell) but it gets the job done
When you realise that "server" here could be a short shell script that is included with the compiler and therefore by default part of the compiler, it sounds a lot less over-engineered. It's actually quite an elegant solution.
That is not a continuation. That returns a different value if the optional does not have a value. For a continuation, you would pass a callable object that would only be invoked if the optional has a value. The result would either be an empty optional (if the initial value was empty) or a new optional with the result of the callable object. The resulting optional may contain a different type than the original, depending on the callable passed.
A free overloaded operator would be next level :D
Windows doesn't support an UTF-8 locale, so setting the ANSI codepage (which is the relevant here) to UTF-8 can wreak a lot of havoc. That would not be smart. Setting UTF-8 as active codepage locally in a console (which doesn't have anything to do with editors) can be useful for simple personal tools's output, but (a) multiple lines of non-ASCII output does in some cases cause a persistent error state, and (b) console input of non-ASCII characters with UTF-8 codepage doesn't work at all down at the API level, you just get zero-bytes. So, it's ungood for the global ANSI codepage, and just marginally helpful, and then for personal tools, for the OEM codepage in a console. 
!remindme 5 minutes
[http://wg21.link/p0798r3](http://wg21.link/p0798r3)
I will be messaging you on [**2019-02-04 16:59:20 UTC**](http://www.wolframalpha.com/input/?i=2019-02-04 16:59:20 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/amsjod/using_sg14_libraries_a_simple_and_performant/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/amsjod/using_sg14_libraries_a_simple_and_performant/]%0A%0ARemindMe! 5 minutes) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Yay! This is what I was hoping to find here! For future references, is there a reasonable way to search for standard proposals?
That's true. Still a lot of extra boilerplate, though.
All the time, man
&gt; In the age of SCons Did I miss something or has SCons had a big revival in the last few years? Last I saw this used in a C++ project was nearly 10 years ago, and even back then, that project was being migrated to CMake. Your question is really weird anyway. In the same way, you could ask: &gt; "In the age of Docker, do people still manually write Docker files?" Yes of course they do, or did you invent a way yet to auto-generate Docker files or have a build system or IDE create them for you? Sure, a basic Docker file can be automatically generated, but anything bar a "hello-world", and you need to hand-write a Docker file. So yes of course people are "still" manually writing CMake files, and they will be for a while.
Is jetlive like Visual Studio code and continue? [https://docs.microsoft.com/en-us/visualstudio/debugger/edit-and-continue?view=vs-2017](https://docs.microsoft.com/en-us/visualstudio/debugger/edit-and-continue?view=vs-2017) &amp;#x200B; But, very very kickass. I want to make this happen for unit testing. Have you tried it? Any cmake-fu or flags needed?
I like the C# syntax with LINQ, ?. operator and all other facilities. The code is simple and straightforward. The problem I see with continuation on optional is that the code is uglier (even if I like lambdas) and more verbose than the procedural code.
good bot
By starting with "Did you read the doc introduction" it sounds like you are insinuating that the OP didn't do the most obvious first step, or somehow failed to understand/appreciate it. If you had formulated it like you did in your second post it wouldn't read so RTFMy, and might be appreciated much more.
I haven't looked at their code for it. I wrote my media library as much to learn my way around the ffmpeg internals as anything else. I know my way around it really well so that's what I'm using for this. I'm still slowly adding features to the library as well. If I want to do anything with the audio channels, I don't even know if OpenCV supports that. But you can use the brisque library with anything that can generate an OpenCV Mat, so their backend will work just as well for that, if you're more comfortable with it.
Sure. I use emacs for all my development. So I write my cmake files in emacs. I only jumped on the cmake bandwagon last year -- previously I'd been doing fine with plain old makefiles, but cmake seems to do a much more reliable build and will handle building Linux packages for me, so I switched to it when I needed some packages built. It's pretty awful, but it's less awful than anything else I've tried.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/an3sas/im_going_into_a_job_interview_for_c_programmer/efqhsxf/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[IsoC++](https://isocpp.org/) usually links to the mailings as soon as they are out, and they always show up on [OpenStd](http://www.open-std.org/jtc1/sc22/wg21/). The mailings always go up before and after the in person meetings, in practice that means every two month. This is however the "raw data", if you want to get an impression on what the state is the various trip reports are probably the best way. [Bryce](https://www.reddit.com/user/blelbach) writes a short overview after each meeting (e.g. this one after the last: [San Diego Trip Report](https://www.reddit.com/r/cpp/comments/9vwvbz/2018_san_diego_iso_c_committee_trip_report_ranges/)) or you if you want more detail read the ones from [Botond Ballo](https://botondballo.wordpress.com/2018/11/30/trip-report-c-standards-meeting-in-san-diego-november-2018/).
TartanLlama has and extended optional and expected: https://github.com/TartanLlama/optional https://github.com/TartanLlama/expected
there're IDEs can write cmake for you?
You mean that either msbuild or writing scattered Ruby scripts to build every project *isn't* standard? Huh. Though my portable version of msbuild works pretty well. Faster that actual msbuild on Windows, also runs on Linux. Wrote it to build MIPS, AVR, and ARM projects which were using vcxproj files. Not really as powerful as CMake, though - you'd have to thoroughly define targets to match the behavior.
I think `i ? to_string(*i) : { } ` should work aswell, right?
Are you not loading up a special VM to execute build commands for you?
Clion is a quite helpful in writing cmake scripts.
I think that the majority of people writing portable code are using cmake and manually editing it when needed, yes.
Someone either doesn't understand what CMake does or doesn't understand what docker does
Indeed, SCons is deader than dead; I do not know of a single maintained project using it. And (modern) CMake is the de-facto standard today -- rightfully so, despite its flaws. So I'm wondering if the OP is serious or just trolling, especially because Docker is seemingly unrelated.
Here's an example: https://godbolt.org/z/bm-aKw #include &lt;functional&gt; #include &lt;optional&gt; #include &lt;string&gt; template &lt;typename Src, typename Dest&gt; std::optional&lt;Dest&gt; maybe_apply(const std::optional&lt;Src&gt;&amp; src, Dest (*func)(const Src&amp;)) { if (src) { return func(*src); } else { return std::optional&lt;Dest&gt;(); } } template &lt;typename Src, typename Dest&gt; std::optional&lt;Dest&gt; maybe_apply(const std::optional&lt;Src&gt;&amp; src, Dest (*func)(Src)) { if (src) { return func(*src); } else { return std::optional&lt;Dest&gt;(); } } void demo() { const std::optional&lt;int&gt; first = 3; const std::optional&lt;std::string&gt; second = maybe_apply(first, +[](int i) { return std::string{std::to_string(i)}; }); } The ugly unary plus is to force the lambda to decay to a function pointer.
There is a section for `cmd.exe` in the link. That should be enough for 99.9999% cases so if CMake doesn't do it currently just because it can't cover that 0.0001% (and instead opts to cover 99%), that'd be an issue.
I'd prefer to accept function objects by value instead of a function pointer to make it easier for the compiler's optimizer. Also, one could do value-category based overloading and allow the source value to be consumed if you pass an rvalue `std::optional`.
I think CMake generally does pretty well with \`add\_custom\_command\` escaping. My issues usually arise with multiple commands or when you're trying to pass semicolons around (a wider CMake issue due to its stringly-typed variable system). I've also seen issues when trying to get quoting \*just\* right for tools which have weird calling semantics (e.g., FFmpeg's configure taking C flags on the command like instead of through the environment…). But, if you find somewhere that CMake is munging quoting really badly, an issue would help us track down the issue and, if warranted, get a policy added to do the proper behavior.
Would you mind providing an example for `std::function`? I tried but couldn't get it to deduce the types. Agreed on additional overloads -- a proper system like this would need quite a few more overloads than what I gave.
you can deduce the types yourself, no need for function pointers. \`\`\` template&lt;class T, class Fun&gt; auto apply(std::optional&lt;T&gt; o, Fun f) -&gt; std::optional&lt;decltype(f(\*o))&gt; { if (o) { return f(\*o); } return {}; } \`\`\`
I have to deal with CMake files sometimes when working on other people's stuff (porting, etc.), but I mostly work with Meson, which is awesome.
Every time I tried using the VERBATIM command, the quotes were mangled nonetheless. If there was a way to do it, I sure couldn't figure out, even after hours of trying. I eventually gave up and wrote that string to a batch file, then executed the batch file, like this: set(signtool_release "\"$ENV{ProgramFiles\(x86\)}/Windows Kits/10/bin/x64/signtool.exe\" sign /d ${project_name} /fd sha256 /t http://timestamp.digicert.com /a \"${CMAKE_CURRENT_BINARY_DIR}/Release/${project_name}.exe\"") file(WRITE ${CMAKE_CURRENT_BINARY_DIR}/SignRelease.bat ${signtool_release}) add_custom_command( TARGET ${project_name} POST_BUILD COMMAND $&lt;$&lt;CONFIG:Release&gt;:SignRelease.bat&gt; WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR} ) As for documentation, this one was a bit vexing: [https://cmake.org/cmake/help/latest/prop\_sf/VS\_SHADER\_TYPE.html](https://cmake.org/cmake/help/latest/prop_sf/VS_SHADER_TYPE.html) So VS\_SHADER\_TYPE sets the shader type? Great. But what about a list of valid parameters? All it's similar ilk are the same, although fortunately most are easier to guess at. Again, I point out that, despite my gripes, so far I *have* found a working solution to all the issues I've run into. Building my own cross-platform game engine, I probably run into more corner cases than a typical pure C++ project, so it's impressive that I haven't hit a complete blocker yet.
Does it work with `data.lock()-&gt;call();`? It's something I use actually pretty often (a single delegated call), and here `MutexGuard&lt;U&gt;` is temporary.
Honestly, I've never used Edit and Continue in VS. And I didn't get what do you mean saying "unit testing"? I just tried it in gamedev-related things like visuals and game logic. About flags, yes, you can check CMakeLists.txt, there're comments describing what each flag do.
Of course, forgot about `decltype`, thanks!
SCons is still used a lot in the industry; my employer (&gt;10000 employees) uses scons for pretty much all of our internal projects. IMO it's a great build system and no other build system can match it as far as flexibility. It's just that the learning curve is pretty high for non trivial projects.
Because otherwise it would require transcoding to and from every single OS API on Windows, which is UTF-16. That would be an unacceptable performance burden, IMO, particularly in the UI. And 'Unicode' is not a format that takes up 21 bits per code point. It's a standard that defines multiple formats, UTF-8, UTF\_16, and UTF-32. If you want me to use UTF-32, convince Windows to make that its native format instead of UTF-16, and I'll happily do so. In the meantime, this has never, ever, even once, come up with any customer or potential customer in two decades. So why on earth would I put in a huge amount of time, up front and in ongoing updates/testing, to do this instead of the things my customers are actually wanting? I don't know how big your code base is, but mine is very large, and half of it general purpose where it cannot make assumptions about performance or size of text and so forth. It's not at all a remotely straightforward thing for me to do. &amp;#x200B;
Personally I kinda find the second more readable. I would even use if(i.has_value()), maybe it is more verbose, but still I think it way easier to follow.
you can also use `std::invoke_result_t&lt;Fun, T&gt;`
&gt; invoke_result_t Learn something about C++ every day, especially 17. I imagine I'll actually make some good use out of it. Appreciate it :)
This doesn't belong here. Go to StackOverflow.
If you don't care about the range checking and the support for fixed size spans, you can write a very simple version of it in a few lines of code that doesn't influence compiletimes significantly. Also about passing sub- ranges to functions: The magic function here is `subspan`. You create a span over your container once and then create and pass sub spans using offset + size, with the advantage that they can be range checked. If nothing else I prefer passing around pointer+size pairs instead of separate arguments 
Again, the same gamedev story. It's a trend now.
It's far more than just accessing the nth character. The length of a string is no longer necessarily the number of characters in the strings. Just that one thing would break a huge amount of code out there in the world. Lots of code pulls out a substring of X characters, which can no longer be done by simple and efficient memory copy of chars\*charsize bytes, and various other similar operations become much less efficient. And the caller can't assume they will fit into a buffer of that size. There just reams of similar things that, in each case if it's just a few instances it's not that a big a thing, But in a large code base, where there are literally thousands of such places that would have to be dealt with, and where there's zero help from the compiler to make sure that the right thing is done, so that you can only hope to deal with it by doubling or more your testing burden for almost everything (since almost everything uses text), it's a huge thing to deal with. Unless you use UTF-32 as your internal format, then every single call to the OS has to be transcoded back and forth on Windows, which could be a serious performance burden in some applications, particularly in the UI. If I were going to address it, I'd definitely go with UTF-32 internally and do the transcoding back and forth. I could in theory do it since I wrap every single OS call in my virtual kernel layer. But, for folks who don't have that luxury, it would be enormously annoying to have to deal with that in a large code base. And, even for me, the work and the overhead are such that I just don't see the point unless it's costing me, and in two decades the issue has never come up once.
\&gt; &lt;quoting&gt; Interesting. Filing an issue for the attempted code and what the outputs were would be helpful. Though, for that specific case, IIRC, there is work in progress for getting Apple codesigning to work. I don't know how generic its CMake interface is, but Windows codesigning may fit with it. \&gt; &lt;VS\_SHADER\_TYPE&gt; I think that may be due to the values likely being MSVC or Visual Studio specific. I do agree that a list of known values could be listed there, but the caveat that the valid values are specified by the tools in use should be mentioned. Also, I'd say this is another issue of upstream not doing much HLSL stuff personally, so it's a blind spot. Please feel free to file an issue for this and the other properties you're referring to here and we'll work to provide better documentation. Thanks.
Related to an RTTI improvement (since it uses some of the same machinery), would we be able to get simpler/neater representations for member function pointers, 'this' offset adjustments, and similar?
&gt; Overload `operator &gt;&gt;=` for extra Haskell points This does not work well because of operator precedence in C++. ((optional x{5} &gt;&gt;= fn1) &gt;&gt;= fn2) &gt;&gt;= fn3 As opposed to optional x{5} &gt;&gt; fn1 &gt;&gt; fn2 &gt;&gt; fn3 
In push() after `m_openSlots.wait();` you assume there are open slots. If another thread was also calling push(), those open slots could be gone right after you stopped waiting. Oh, wait, my mistake. The semaphore prevents having more threads active than open slots. So, yes, it is MPMC.
BTW, to self-correct myself on a point. It had been a while since I looked at the transcoding stuff, so I questioned myself, and in fact made a mis-statement below. When the transcoding system brings in external text, it doesn't reject surrogate pairs, but it lets you choose to replace them with a replacement character if you want. If you let it import surrogate pairs, it's up to you to deal with that. None of the general purpose code is going to do that for you. Of course a lot of it wouldn't care one way or the other. But if you access the Nth character, the string class is not going to scan a MB of data to find that. It's going to index the Nth UTF-16 chunk. If you ask for a substring at 10,5, it's going to pull out 5\*charsize bytes at 10\*charsize into the string buffer. Having to rescan that block of text thousands or tens of thousands of times to find particular characters or sub-strings would be enormously inefficient. Ultimately, if I dealt with this, it would be to move to UTF-32 internally and handle transcoding to/from the UTF-16 OS APIs. That would suck, but it would suck vastly less than variable sized characters. Though, I wouldn't bother with that unless there was a business reason to do so, and there never has been to date.
This is trivial to write yourself. My codebase at work has such a function. I actually don't use it super often. However, I do find myself casting from optional&lt;a&gt; to optional&lt;b&gt; where some conversion exists. this is similar to your casting int to string. I think static_cast&lt;optional&lt;string&gt;&gt;(optionalInt) would be nice.
While I find functional style code satisfying, and enjoy writing it, it tends to be pain to debug, on average it's more difficult for others to understand (for cultural reasons among C++ devs), and these days I find myself questioning whether I just like it for subjective aesthetic reasons, rather than it being practically better.
It would be nice to have that. For the record, there is an idiom for complex initialization which is this. auto s = [i]() -&gt; std::optional&lt;std::string&gt; { if (i) return std::to_string(*i); else return {}; }(); Not as clean as you'd like but I find it much nice than the default initialization plus assignment alternative. It also works for classes with no default constructors and even `const` objects.
I guess that is up to opinion. I personally prefer the continuation-passing style, provided I don't have to capture too much ugly crap in my lambda.
I wonder if this will shift. Once futures are standardized, a lot more C++ devs will become familiar with the continuation-chaining style. I think that there are other benefits besides it being aesthetically pleasing. The main one, for me, is the separation of core business logic from error and edge case handling. The example I gave is pretty simple, but imagine there are 4 or 5 more continuations chained (like in the blog post I linked, or in [p0798R3](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0798r3.html)). It really shines in those cases where all of the boilerplate error handling is hidden.
Or maybe, one day, we'll get `|&gt;` :D
You can also use \`std::nullopt\` instead of \`optional&lt;string&gt;()\`.
That's not the same though. It's not a member function. You can't chain, i.e. `a.then(...).then(...).then(...)`. Equivalent with `apply` would look really ugly (and potentially buggy).
It's definitely trivial to write. But one of the benefits is the ability to chain continuations. For this, it either has to be a member function or an overloaded operator, which is less trivial to write yourself - off the top of my head, the best option seems to be just wrapping the entire `std::optional` class
That's good to know (and very JavaScript-y :p)
Also don't forget wg21.link/index.txt
This reminds me of a project I have worked on which can also output the type of variables, and can output almost any stl container's content. It does not use the icecream format, but it could provide food for your thoughts. See [https://github.com/pthom/cleantype/blob/master/demo.cpp](https://github.com/pthom/cleantype/blob/master/demo.cpp) And, if you are interested in output stl containers values without requiring additional coding from users, you can take inspiration from [fp\_show.hpp](https://github.com/pthom/cleantype/blob/master/src/include/cleantype/details/cleantype_fp/fp_show.hpp) Note: you can try this without installing anything [on gitpod](https://gitpod.io/#https://github.com/pthom/cleantype/blob/master/demo.cpp) (just type `make`then `./demo` into the terminal)
do you object to auto final = with_optional( opt, [](auto n) ..., [](auto s) ..., ... );
I should have mentioned it previously, but the tip comes from [here](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Res-lambda-init). There's a lot of good stuff in this document if you like cleaner more abstract code.
&gt; Please feel free to file an issue for this and the other properties you're referring to here and we'll work to provide better documentation This bug has already been filed, and according to one CMake dev, is working "as intended". [https://gitlab.kitware.com/cmake/cmake/issues/18062](https://gitlab.kitware.com/cmake/cmake/issues/18062) "1. Verbatim inappropriately quotes arguments, adds backslashes." This is what eventually convinced me to seek an alternate solution. I simply couldn't figure out a way to pass in a command string without those backslashes gumming up the works. I'll consider sending in a bug regarding the documentation, though.
I think that's better than some other options, but that also requires having all of the continuations at the initial call site - you can't easily chain continuations onto a function that returns a `std::optional`. So using this style may impact reusability.
I don't think that's on our radar at the moment. We'd need a bug report detailing any current deficiencies.
yes it is not, it is just a response to a comment that got edited.
&gt;a reference can be NULL No
This would have some fairly serious build automation implications. The "compilation phase" of **every** TU would depend on the "database" of exported symbols. And the "database" would depend on the symbol scanning phase of **every** TU. This kind of *dependency bottleneck* is a headache for build automation. Consider an incremental build automation system (either `make`-like or something more modern that uses checksums instead of timestamps). Every "compilation phase" step would need to be re-run any time the database changes. If a module only used by 1 TU changes its externally visible symbols, all other TUs will need to be re-compiled as well. You might even re-run every TU's compilation if nothing substantive changes in terms of externally visible symbols, depending on the build system and the structure of the "database". You can mitigate this somewhat if the database is sorted and deterministically bitwise identical as long as the source files are the same and regardless of the order in which the "symbol scanning" phases are run in. Another problem is parallelization of the "symbol scanning" phases of the TUs. Can they be run in parallel? How will the "database" handle concurrent updates from multiple parallel "symbol scanning" runs? Is the "database" both an input and an output of each "scanning phase" run (i.e. can its initial contents affect the "symbol scanning" phase, including how it modifies the "database")? If it is both an input and an output (and I can't see how it wouldn't be if it's a file being read and modified by each "symbol scanning" phase), the dependency situation gets even worse because now each TU's "symbol scanning" phase depends on every one that ran before it. Then there's the fact that instead of **N** compiler invocations, you now have **2N** (2 per TU). That doubles the work of the build automation tool in terms of dependency checking, determining whether a step should be run or can be skipped, and of course process creation (which can be a significant cost).
By unit testing, I meant build an executable using gtest or catch and then run only the unit test that you are modifying. 
Let's peek at the Standard... 8.3.2/1: "A reference shall be initialized to refer to a valid object or function. [Note: in particular, a null reference cannot exist in a well-defined program, because the only way to create such a reference would be to bind it to the “object” obtained by dereferencing a null pointer, which causes undefined behavior. " Behold; no null-references w/o UB.. but yet, a reference can dangle: int *ptr = new int(7); int &amp;ref = *ptr; delete ptr; // this guy here will "create" a dangling reference I read the article. I got the impression that the wording wasn't exact and he *meant* a dangling reference. It is important to be precise or the language police will pull over. :) 
These monadic extensions are good, but like variant it's a PITA without language support. Is there work being done on that too?
No, it doesn't. &amp;#x200B; In my case, I often have the following pattern : `auto lock = m_concurrentState.makeLock();` `State &amp; state = lock.get();` [`state.foo`](https://state.foo) `= 1;` [`state.bar`](https://state.bar)`();` And I want to prevent the following horror: `State &amp; state = m_concurrentState.makeLock().get();` &amp;#x200B; The only way I found to prevent such code in a generic way is trough `&amp;` ... maybe another way exists.
I just know that I have it and don't have gold so it's either one or the other.
No he didn't, because right after he says that with pointers he'd put a null pointer check assert.
if you have to ask this question you have already failed the interview from my point of view
Thank you! This is a very good explanation. It just explains everything about this behaviour. ADL for the win!
Thank you for the hint. It works in this oversimplified example. In the real world our generation is recursive. This trap lead us to two days of wasted time on this. Using ADL correctly leads to a working solution that also allows for recursion.
You'd get the exact same problem with a copy of the pointer anyway...
Didn't work for me. Tried it on [https://www.onlinegdb.com](https://www.onlinegdb.com) with C++17. Seems {} is not allowed inside ()? : ;.
That sounds a lot like ECS! The "metaprop" sounds very similar to [prefabs](https://github.com/SanderMertens/reflecs#prefab) in [reflecs](https://github.com/SanderMertens/reflecs). Prefabs are just like you describe, "archetype" entities which contain a set of components *and* component values, which can be reused across entities. In reflecs, they can be added to entities just like components. I believe [Entitas blueprints (deprecated)](https://github.com/sschmid/Entitas-CSharp/wiki/Entitas-Blueprints) did something similar, but I'm not aware of other ECS frameworks that have this feature. You will see the term "archetype" here and there ([for example in Unity ECS](https://forum.unity.com/threads/a-few-questions-about-archetypes.524567/)) though this usually just refers to a predefined list of components, not the component values.
Ah, thanks for the link. Yeah, Brad is the lead dev and points out corner cases in all kinds of things. Given CMake's backwards compat guarantees, changing old behaviors is hard, especially for something as intricate as argument escaping.
The thing is that I don't do all that much heavy chaining, because it's useful for both communication and debugging purposes to give intermediate things names. Also, when you do a stream of chaining like this (with optional specifically), you actually lose the information of which one failed. In real codebases (as opposed to toy examples) you're almost always doing something with that information, for example logging (yes, messy, impure logging). I feel like the value of this chaining, at least for optional specifically, in real codebases, is pretty exaggerated. It's a nice to have but not more than that. 
That's very cool. Is the thesis public? I'll add the github link to the faq.
Do you mean the number of new comments? that's RES. We're talking about this blue background marking new comments: https://i.imgur.com/IeCXRc7.png
Game devs?
&gt;2. The most dangerous part — a reference can be NULL or even reference to some memory that was allocated on heap using pointers and then deleted. Can you imagine something scarier? Dangling reference that you have no way to ensure its correctness? You will not even suspect that it’s what crashes the app. We had several times in last project that its what happened. After some pointer magic + references, a memory was deleted, a pointer was nullified, but a reference left behind, and then it was passed to a function that crashed. Its really hard to find such things in big code-base. So at least with raw pointers we KNOW that it can be true, and we put assertions in the beginning of the functions to validate that its not NULL. This problem exists with pointers as well. The rest of the points are legitimate.
boost::optional have map and flat\_map: [https://www.boost.org/doc/libs/1\_68\_0/libs/optional/doc/html/boost\_optional/reference/header\_\_boost\_optional\_optional\_hpp\_/detailed\_semantics\_\_\_optional\_values.html#reference\_optional\_map](https://www.boost.org/doc/libs/1_68_0/libs/optional/doc/html/boost_optional/reference/header__boost_optional_optional_hpp_/detailed_semantics___optional_values.html#reference_optional_map)
If the main talking point here is around game development I can chime in on this: I'd say the code is poorly structured and some other system used if it needs to frequently populate a vector of anything. The whole point is performance: dynamic allocations are expensive and filling a vector with anything pretty much guarantees you incur multiple allocations. Now it depends on what the logic is doing but that "vector of integers" seems like a prime case for some generator-like object and just using the sequence of integers directly at the call site instead of going through the temporary vector - skipping the heap completely. I question any performance-critical game code where you need to frequently fill a vector with anything.
not sure I follow. isn't the optional itself enough to chain more one? 
Believe me, I'm glad you guys take backwards compat seriously, because that saves developers from future grief. That's very much in the spirit of C++ as well. But it's still frustrating for new users who are probably not aware of those rules, because in this particular case, I just want VERBATIM to leave the args alone and pass the string as-is. In many cases, trying to be "smart" about handling arguments (especially in Windows) actually ends up doing the wrong thing. Maybe it would be possible to create a flag like LITERAL that does absolutely no transformations, or perhaps introduce a string decorator like in other languages that signals CMake not to muck with the strings. Also, I'm glad to hear you're working on supporting Apple cert signing, because that's something I'll eventually need support for as well (although it's certainly possible to do it on the command-line). Despite the complaints, I do appreciate the work you guys do in supporting this tool. Now that I've got through the initial trouble of learning how to use it, my projects are a lot easier to manage.
Interesting use-case btw) I think it's achievable. The library provides 2 events: `onCodePreLoad` is fired just before code loading routine start, and `onCodePostLoad` - right after all magic is done. So if you manage to re-run your test when `onCodePostLoad` is fired, you'll get what you want.
Ah yeah, I guess you could pass the result of the function directly as the first argument to `with_optional`. That would definitely work. I still prefer a first class solution, but this is better than writing your own wrapper.
Good to know. Thanks
&gt;Windows doesn't support an UTF-8 locale So glad I dont use windows anymore. I'm starting to agree with the people who complain Microsoft doesn't support unicode. I disagree about the strawman. If your code only works in the presence of a BOM, you won't have interop with the rest of the industry unless everyone gives you that BOM you crave. You're initial complaint with my satan joke was that I was advocating against using it.
I agree the second is more readable; IMO the first's advantage is more that it's harder to accidentally remove the (implicit) has_value check when refactoring.
Probably because with pointers you CAN check for nullptr, but it still doesn't prove that the pointer points to a valid object (of course). There is a possibility for correlation with his intent but not really provable either way. I just chose the charitable interpretation where you didn't, no biggie. 
The dependencies are hardly a problem. Yes, we'll need some infrastructure to support it, but that's all fairly trivial stuff. The database needs to store the timestamp (or hash, whatever you prefer) of each TU, so it can tell the build system if that TU needs rescanning in phase 1. And for each TU we need to store a list of hashes for each symbol it consumes (this is information the compiler has anyway), which we can use to tell the build system that that TU needs recompilation in phase 2 after a change. That list of hashes could be stored in the corresponding object file, or in a file dedicated to that purpose. Symbol scanning can run in parallel, but updating the database depends on how that is implemented. If a 'proper' RDBMS is chosen, those support concurrent access anyway, but usually require a bit more effort to install than might be convenient for a compiler. There are plenty of alternatives though: symbol scanning processes could deliver their symbols to a dedicated database writer, which is responsible for streaming it all out to disk, for example. The database does not contribute symbols during symbol scanning, although of course the database from a previous compilation cycle is important to determine what needs recompilation and what doesn't. And finally, yes, you get 2N compiler invocations, but the amount of source each invocation sees is much, MUCH smaller than it is today, and symbol scanning is not nearly as computationally intensive as actual compilation. And each of the two phases has clearly defined dependencies: For phase 1: if the timestamp (or hash) of the TU is greater (or different) from the value stored in the database, rescan that TU. Otherwise, leave it alone, as it is up to date. For phase 2: if the timestamp of the TU is greater than that of its object file or its hash file, OR if the object file or hash file is missing, OR if any of the hashes in the hash file differs from the database, recompile. Otherwise leave it alone. Note that phase 2 is much more fine-grained than what we have today, where the decision is made the header file granularity, and might very well be triggered by changes to symbols that have no impact on that TU. For example, a change to a header file full of constants can easily trigger a large number of TUs to be recompiled, but under the proposed system would limit recompilation to TUs that actually require the changed constant. If the cost of process creation is really an issue, keep more in memory. I was under the impression that compilers do that anyway by storing most of their own code in dynamic libraries that remain in memory between compiler invocations. This proposal also makes it possible to keep the entire set of symbols in memory, since it is identical for each compiled TU, so that cuts down even further on IO. 
Game developers, embedded developers, people working with legacy code bases and/or people who need to interface with C, developers working on platforms with highly constrained stack size, people to whom compile times are of vital importance and, admittedly, also people who are simply stuck in their ways. 
Of course, the pointer can be dangling as well. The point wasn't that, though, it was that we can have a dangling reference. I think we got that established quite nicely there, wouldn't you agree? Your question is interesting but leads to sidetracks; while interesting, perhaps some other time.
Wait that's a thing? How does this work without a lambda. I'll have to give it a try 
Thanks for the reply! I'll dig through those. I don't think there's any kind of high level write-up about DarkEngine, but I can try to sum it up in a few paragraphs. Objects were identified by integer IDs, with positive IDs given to spawned entities, and negative IDs given to archetype values. [Properties](https://thief.fandom.com/wiki/DromEd/Properties) were attached to the objects either directly, or via inheritance. Metaprop links were used for inheritance in both archetype and from archetype to spawned objects (I don't think those were ever used between two spawned objects). Metaprop link had priority that allowed on-the-fly masking of Properties (components) with different archetype sourced ones. There were other different kinds of [Links](https://thief.fandom.com/wiki/DromEd/Properties/Links) with different data structures attached. Archetype objects were stored in databases that were separate from the game mission implementation, and common for all those for one game - these defined the abstract nature of the world, with missions defining the concrete places within it. The engine implemented some of the properties as is probably usual with this kind of a system. Others were purely data storage. [Scripting](http://thiefmissions.com/telliamed/scripts.html) (also [here](http://thiefmissions.com/telliamed/scripts1.html) and [here](http://thiefmissions.com/telliamed/scripts2.html)) was done using dynamically linked files (named .osm, in fact a .dll file) that implemented object oriented scripts of different names that could be attached to objects. These scripts subscibed to and listened to various engine events, and translated them into reactions to them (either directly, or by using timers, etc).
This is a lambda. It is created and called on the same spot. Notice the `()` on the last line.
that's what I had in mind. I agree that something like JS's `then` looks better tho
Oh right my bad. Reading those posts on mobile is quite a pain 
\&gt; Maybe it would be possible to create a flag like LITERAL that does absolutely no transformations This sounds like a good alternative to trying to fix \`VERBATIM\`. This is also much easier to implement now that commands have access to the quoting present in the actual source (done for the \`if\` command to in order to implement \`CMP0054\`). Thanks for the praise. We understand the documentation needs lots of love, but finding time to fix it is hard to do since it's always at the bottom of the priority list with everything else going on :( . Filing issues helps to give weak points awareness and contributors can fill in where our we can't spend the time or lack detailed enough knowledge of the specific use cases for a variable or property.
TL;DR - keep the data where it's at and SLICE it.
(or, keep it simple, just return reference to the data, like..) // read-only const std::vector&lt;int&gt; &amp; But I think the use case in question was that the function was synthesizing the data.. streaming it in, loading it off a storage media.. something like that, in that case the question how to "return" the data is still valid. btw. love Factorio, TOP-10 game in my steam library, easily. GJ^2 !!! 
Never create nullreferences, I saw a codebase that used them a while ago as a sort of bootleg optional before C++11. It was a pain.
You could also change your macro to something like: #define IC(...) ::icecream::print{__FILE__, __LINE__, ICECREAM_FUNCTION, std::string_view(#__VA_ARGS__), __VA_ARGS__} then use something like void print(string_view v, T&amp;&amp; a, Args&amp;&amp; ... args) { int split = v.find(','); std::cout &lt;&lt; v.substr(0, split) &lt;&lt; ": " &lt;&lt; a; print(v.substr(split + 1), args); } to get each argument name to avoid the recursive macro depth limit.
Oh, ok. Much better solution indeed.
&gt; Not only does it look nicer, but it also reduces boiler-plate and allows continuation chaining Continuations don't reduce any boilerplate, and they imply lambda nesting (or defining code elsewhere with an interface adequate for chaining). Then take into account naming of temporaries, non-local code flow, etc.
&gt; The main one, for me, is the separation of core business logic from error and edge case handling. Bad idea. See exceptions. If your software is non-trivial, you want to see error paths right there they happen.
I don't see the parallel with exceptions. `optional` indicates that there is a non-exceptional chance that the function does not return a value - think parsing user input, or querying a database for a single key. Continuations then allow me to write the program as if I had that data, and it automatically does the right thing if I do not have that data. Sure, in some programs you may want to translate an `optional` to an `expected` so that you can return additional information when you reach the unhappy path. But that will often be at the boundaries of your application.
Continuations absolutely reduce boilerplate - with `optional` you no longer have to litter your code with calls to `has_value()`. And in a well-structured continuation API you should not have nested lambdas either - if anything, it does a better job at flattening out your code (as opposed to the arrow anti-pattern).
Have you guys considered adding Bazel support? It’s very similar to Buck and it’s what Dropbox actually uses ;).
&gt; Game devs? I can assure you, not all game devs. &gt; Yes, yes, I know that I can write custom allocators for *std::vector* and emulate same behavior, but why to write more code and make compiler work hard when I already have it working with simple pointer passing? Why indeed use a straightforward way to get good performance and memory safety when you can do it ad-hoc and dangerously? In my own game engine, I use a custom slab allocator with all stl containers which ensures that I can make lots of small memory allocation with very little overhead. Frankly, I'd much rather make the compiler "work hard" than trust myself not to make stupid mistakes, or have to rely on external tools to prevent stomping on random memory. &gt; Overall I think that pointers are NOT that dangerous, and trying to avoid them at any cost introduces more problem and maintenance headache that you don’t really need in big projects where everything changes all the time (games). IMO, it's *precisely because* everything is changing all the time in games that safer, more modern techniques are so valuable. I almost never use raw pointers (except in non-owning capacity) in my own code these days, and I don't miss them at all. Well, each to their own, I guess.
based on the build times, i see why the author prefers pointer length in that use case. some straightforward use cases for using in/out parameters are mentioned, like reusing the same buffer over multiple calls, or modifying the same range over multiple function calls. in those cases i would also use an in/out parameter but in my case the bounds safety of span/vector is worth the build times. Something like "fill_buffer" i would use something like vector&lt;T&gt;&amp;. As the name suggests, i am modifying an existing range. But something like "getDeadRobots" i would basically never use vector&lt;T&gt;&amp; and always simply return the vector. no offense but i was kindof expecting a discussion of RVO, but instead i feel like i got "my code has many uses cases of in/out buffers, and vector and span are too expensive for my build times." I still enjoyed the article, just didnt find the RVO discussion i was expecting. on another note, i am very curious to find out how one person can say buffer overrun isnt a problem while also being so afraid of "null references." my thought is like, you can trust your caller to always pass you the correct length to a valid buffer, but you cant trust them to pass a valid reference?
Can't really give a date, but we're in the process of open-sourcing an SDK that comes with this, which allows you to integrate the events with other build systems and tool.
\&gt; I really think that you are just partial in your assessment, you are not looking at the whole picture. &amp;#x200B; Funny, I felt the same way. Everyone is pretty focused on \*this\* as the solution.
Very nice! With that all the preprocessor metaprogramming code could be removed. I'm sure will take that approach.
Thank you. I will for sure try it out and see how to get it working for unit tests. That would be awesome. 
&gt; If your code only works in the presence of a BOM That's a strawman. 
Direct link to said meme: https://www.reddit.com/r/ProgrammerHumor/comments/amk50f/when_youre_a_haskell_programmer_writing_c/
I really wish we had UFCS or even something like extension methods for this so that it wouldn't have to be part of the standard.
The representation seems to be a little slower and a little bulkier than on competing platforms. But it's possible that better representations would be a natural consequence of making RTTI faster.
I can't think of a situation where that would make more sense than using a pointer like an optional.
Out of curiosity I created a small benchmark program in C to test the effect of vectorized vs. non-vectorized code. When code can be vectorized, compilers can in some cases use SIMD instructions, which are optimized for doing operations on large amounts of data. Details are in the repository readme: [https://github.com/SanderMertens/vectorize\_test](https://github.com/SanderMertens/vectorize_test) Disclaimer: the benchmark attempts to measure "typical" storage scenarios (AoS, SoA, Heap blocks). For each of these scenarios, the benchmark attempts to approximate the behavior of an actual application. However, there is an infinite amount of knobs to turn, and so these measurements shouldn't be taken at face value. Having said that, there are a few clear (and unsurprising) trends: \- SoA vectorized code is faster than code that reads individual heap blocks \- Loading data from the CPU cache vs RAM has a much bigger impact than using vectorization
What about Tessil robin and hopscotch maps? https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html
You should also benchmark against Tessil's robin map : https://github.com/Tessil/robin-map
Not yet, but I'll try to add it to my benchmark suite tonight
 Interesting-- Some feedback on the benchmarks: The Find for integers timing is including insertion, and there doesn't seem to be any benchmarks solely focused on Find. Perhaps add: -benchmark for only Find with the current 50% chance -benchmark for only Find with 100% chance it is present -benchmark for only Find with 0% chance it is present The insertion benchmark also doesn't really need to include calling clear and then inserting again. 
&gt;There is no way of get rid of the trailing comma without compiler specific extensions. On C++20 there is `__VA_OPT__` for this :)
I had all of the benchmarks you mention as well, but they did not give any different results in the rankings so I've decided to just use a single one.
How can you create a nullreference ?
I am on mobile but I think it's something like `int&amp; ne=*(int*)nullptr`
Well, that is UB (and in such an obvious case, every compiler should complain).
If I remember right the codebase rule was that pointers transfer ownership therefore passing it with a pointer would transfer the ownership to the function. References we basically borrows (pardon my rust) that was before unique shared ptr.
Yes absolutely, the code base was very old at least 10 years, I am not sure when it was introduced but remembering how wide spread the usage was, it must have been a good 5 or more years ago. I am pretty sure compiler at that point weren't that helpful as they are now. The only reason it was actually removed a couple of years ago was because at that point the optimizer of our supported compilers would see `if (&amp;nullref == nullptr){...}` and say "well that can't happen" and remove all these code blocks causing random crashes. I think it took half a year of refactoring.
Well: `void fun(int&amp;);` `void fun2(int* ptr) { fun(*ptr); }`
Ah ok. I feared there was a legal way through some strange edge case of the language. 
&gt; the performance will not only degrade, the map will simply fail with an exception lol.
aka you're relying on the schizofrenic standard library instead of taking on a dependency with a sane workflow, or simply writing your own.
Why UTF-32? UTF-32 won't resolve any of the problem you mentionned as most characters can be created by combining several code points, which is why most programs stick with utf-8. Length of strings that the end user will see depends on the display fonts installed as well, so I don't know why it's of such an importance to you to be able to miscompute such things, but to each his own I guess. From my experience, most of the time the length of a string is not important. When you need to store it into a DB, you should only care about its byte length, not the number of characters in there..
I clearly missunderstand something. You say to use the BOM. You say the compiler uses the BOM to know it is unicode. Then you insist the BOM is not being required.
Right. 
In my opinion for most second approach is more readable because we got familiar with it. It was not common to use monads and follow functional programming way. Yet in my opinion first version would be more readable for someone who is new to the field. 
This looks great. Any plan to support unordered sets?
haven't seen one, probably because competitive programming isn't that different from just programming and the usual sites that let you compete usually have a decent enough forum or chat. 
It's planned: https://github.com/martinus/robin-hood-hashing/issues/7 But I didn't yet get around to implement it yet. I want to do it without duplicating much code but have not found a way to do that cleanly
isn't it possible to do: `std::optional&lt;std::string&gt; s = i ? std::to_string(j) : std::nullopt;` that feels a lot nicer than the lambda. &amp;#x200B;
you'd prefer to write out a lambda?
Have fun nesting that.
Here's an "interesting" use case where `absl::flat_hash_map` was beaten by `std::unordered_map`. https://old.reddit.com/r/cpp/comments/aha5nn/is_c_fast/eee8gwx/
It would be interesting how my map fares in that benchmark. I think `std::unordered_map` is so fast here because it keeps all nodes in lists, and iterating them is quite fast. In your case the data structure `std::pair&lt;std::string, std::shared_ptr&lt;...&gt;&gt;` is also quite large, about 48 bytes: https://godbolt.org/z/63-14d so using a flat map instead of a node based map will bloat memory and could lead to more cache misses. 
Cheers. Yes, the thesis is available here: https://github.com/SuperV1234/bcs_thesis
You might be interested in my [`scelta`](https://github.com/SuperV1234/scelta) library, which adds monadic operations to both `optional` and `variant`. 
I didn't try any node based maps for that benchmark. Perhaps I should reconsider that. I did play with the set a lot however. I tried `absl::flat_hash_set` which was terrible, then I tried `std::set` and `std::unordered_set`. Benchmarks of that are [here](https://gist.github.com/bstaletic/0075d814deadf6c0280e4ce873cd7c75). I initially dismissed node based maps, because I don't care about stable iterators.
[string_view::find()](https://en.cppreference.com/w/cpp/string/basic_string_view/find) returns `size_type` - not `int`. Tip: use `auto`. 
&gt; Have you guys considered adding Bazel support ? Supporting multiple build-systems would negate the benefits of an unified build-system. The more interesting is why we've chosen Buck instead of Bazel. Overall we perceive Buck as a better designed solution. Here a couple points (Buck vs Bazel): * Deep Trace vs. Restarting Build https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems-final.pdf * explicit header-maps vs. shadowing headers Buck forces you to explicitly define a map between "include-string" and path on fs. This approach enforces disambiguation of header files by the user and eliminates many hard to debug build issues in projects with many dependencies. In Bazel the include order determines which header files will be included and is in large projects hard to predict. * differentiation between public and private headers Making this conscious choice again gives clarity to the consumer of a library. Stating that a header is not public implies that it is just an implementation detail. This discourages wrong usage of libraries and makes a clear statement about the api. Furthermore Bazel encourages the usage of custom includePaths using "includes" option. I'm aware that nothing prevents one to "-Iinclude/path" to Buck but at least you can discourage one from such practice by enabling "untracked_headers = error". * Language Support Buck has language support besides C++ and Java. It also supports Go, Haskell and a few others. IN the long run, we hope Buckaroo will be a first choice for Polyglot projects. Finally I need to note that both build systems are an excellent choice and the ecosystem would be improved by either gaining more adoption. It should also be noted that they are similar enough to translating builds from one to another is a possibility.
Nice work! I've raised this in an issue on the github project, but it would be really nice for you to include conan support.
If i have a look at the alternatives section [https://github.com/martinus/robin-hood-hashing](https://github.com/martinus/robin-hood-hashing) it states that absl::Hash is 30% faster for reads. Is that information outdated?
ah yes, thanks for finding that. This is outdated and was about my previous version
I'm gonna piggyback onto here. It's does seems to be a nice hashtable but I do agree that the benchmarks _really_ needs some more work. If we tune the benchmarks we can make any implementation be the fastest etc. First off plotting memory usage over runtime makes no sense to me. I want to see how fast a hashtable is with x elements, _not_ how fast it is when it uses x bytes of data. Plots should include other implementations as well, beating std:: is not really an achievement. And while you include the total runtime of other implementations there's a huge difference for HTs when you fit in L3 and when you don't, how much the perf varies over number of elements etc, graphs are necessary. If the HT is in cache also makes a huge difference. Also there's no benchmarks for removes, I havn't gone through your code but some RH hashtables pollute the hashtable with gravestones which causes the perf to degrade over time. Not plotting this is a bit worrying. Essentially I want all the benchmarkes that the creator of ska:: shows https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/ Until then I have to sort of assume that there is some case that you either don't know about or don't tell me about where you're much worse. Fastest all categories don't exist and your claim to be that needs MUCH more evidence. 
Thanks for the feedback! I've tried hard to make the benchmarks as unbiased as possible, but there sure is lots of room for improvement. Plotting memory over runtime is, at least to me, very helpful because one can clearly see memory spikes, when rehashing is going on, at which times the map allocate, which are otherwise impossible to see. That's at least helpful while developing and optimizing. I have other benchmarks where I continuously randomly insert and erase elements, there the gravestone issue should become apparent. Benchmarking only removes is difficult, as it's not possible to accurately measure the runtime of a remove due to timer precisions.
I've done the quick and dirty benchmark with your hash maps. I can't guarantee that it's 100% comparable with thte other benchmarks I've done, but anyway... IdentifierCompleterFixture/CandidatesWithCommonPrefix/1/0 742 ns 741 ns 942682 IdentifierCompleterFixture/CandidatesWithCommonPrefix/16/0 5281 ns 5273 ns 131917 IdentifierCompleterFixture/CandidatesWithCommonPrefix/256/0 111656 ns 111441 ns 6339 IdentifierCompleterFixture/CandidatesWithCommonPrefix/4096/0 2054511 ns 2050212 ns 314 IdentifierCompleterFixture/CandidatesWithCommonPrefix/65536/0 47617037 ns 47464291 ns 14 IdentifierCompleterFixture_BigO 45.40 NlgN 45.26 NlgN IdentifierCompleterFixture_RMS 1 % 1 % IdentifierCompleterFixture/CandidatesWithCommonPrefix/1/10 751 ns 749 ns 890324 IdentifierCompleterFixture/CandidatesWithCommonPrefix/16/10 5072 ns 5062 ns 138301 IdentifierCompleterFixture/CandidatesWithCommonPrefix/256/10 73475 ns 73319 ns 9088 IdentifierCompleterFixture/CandidatesWithCommonPrefix/4096/10 1156726 ns 1154258 ns 602 IdentifierCompleterFixture/CandidatesWithCommonPrefix/65536/10 23739504 ns 23675316 ns 30 IdentifierCompleterFixture_BigO 22.64 NlgN 22.58 NlgN IdentifierCompleterFixture_RMS 0 % 0 % 
&gt; people who need to interface with C This, this and this. C ABI is the lingua franca of libraries, OS interface and drivers.
`std::chrono::high_resolution_clock::now()` is NOT suitable for performance testing as in many platforms (eg Linux) it is just a wrapper around clock_gettime which can block for hundreds of nanos. You are also counting all the loop times. You should be using a lightweight counter like __rdtsc() (yes c++ does not have a standard fast timestamp like java's nanotime) and benchmark the call alone. You also have symbolic links into your home folder which makes the project unusable without much rework out of github
Insert / Remove is good but you need to show these benchmarks aswell, not just say that you have them ;) And you can definitely see reallocations in time over elements as well. After reallocation perf should increase quite drastically. But memory over elements is also very good where it's quite obvious. Building a hashtable of size x and meassuring time to remove all elements is certainly doable. 
Yes, because so many in C++ community pretend embedded systems and interfacing with C ABI don't exist. Not that this particular article is correct, but still.
While you are at it, you might also want to try `robin_hood::unordered_flat_map` and `robin_hood::unordered_node_map`
"removing all elements" might not be a valid benchmark. In my implementation I check if the elements are std::is_trivially_destructible, if that is the case removing all elements with `clear()` will mostly do nothing :)
All elements one by one. I agree that clear is a bad way to measure erase haha 
The benchmarks starts to be readable from 500k elements,... any chance to have benchmarks for some common cases of 1 to 1000 elements? (for example).
Are you commenting on https://github.com/martinus/map_benchmark? You are right this is currently unfortunately very messy. I didn't get around to cleaning this up properly. It's also difficult because absl has so many dependencies so I don't really know how to do this properly.
As far as I understood `robin_hood::unordered_map` is `unoredered_flat_map`, so I just need to change that to `unoredered_node_map`?
Id also consider that 95% of string hash maps time is spent in string comparison alone and only 5% on the actual hash map algorithm. A benchmark like callgrind with sampling would give very interesting insights. I should alsopoint out that if you are after performance then you should consider perfect hashing which avoids the underlying type costly comparison and can speed up hashing thousands of times