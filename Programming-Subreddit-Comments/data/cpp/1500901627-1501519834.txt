Following on from your example: using namespace MyNewWorld; using namespace SomeOtherNamespaceWithAnArrayDefinition; int myarray[5]; // ??? Presumably, that would produce a compiler error... So adding code to a file can break existing syntax. Awful. 
&gt; You're quite welcome to define (and implement; talk is cheap) check out what I posted on GitHub. I was generating executables, spitting out LLVM. i demonstrated blending 'c++ style overloading' with rust style syntax and rust style inference. now thats just me. I don't have a consensus for a team to support it. it would be more efficient to get ideas back into a mainstream compiler. The point is the work is not actually SO hard, the problem is actually getting consensus. which is why I'm resigned to putting effort into these arguments, realising my time actually writing that language experiment was wasted.
&gt;&gt; So adding code to a file can break existing syntax. hows that any different to the existing situation with symbols that can be redefined by namespaces remember in C++ the symbol definition can affect if it's supposed to parse as a template or not, e.g. ```a&lt;b&gt;c()``` can parse completely differently depending on how "a" is defined. (was 'b' a template parameter , or the RHS of a compare operator? namespaces can change that!) so you're complaining about problems that we already have. and yes, I've seen 'vector' defined by a compiler as something machine specific that doesn't have type-params..
I've seen tons of code that could be reformatted to be more simple. I like that part of ResharperC#, it suggest you things like, you can write your if like so, you can avoid nested conditions, that else statement is useless. And I would really like something that would tell the C++98-familiar folks suggestion on how to simplify or use modern C++
Unpossible. Everything is legal and will compile into something. Rub your face on the keyboard? Still compiles. Try compiling the binary? Still compiles.
here we go, try this little gem. namespaces already change the behaviour of '&lt;' and '&gt;' :) #include &lt;iostream&gt; using namespace std; namespace X{ template&lt;typename X,typename Y&gt; class a{ public: a(){ cout&lt;&lt;"hello from a";} }; typedef int b; typedef int c; } namespace Y{ class Z{}; Z a; Z b; int c; int d; bool operator &lt;(const Z&amp; a, const Z&amp; b){ cout &lt;&lt; "hello from &lt;"; return false; } } int main() { { using namespace X; a&lt;b,c&gt;d; //what does this do? } { using namespace Y; a&lt;b,c&gt;d; // what does this do? } return 0; } 
&gt; check out what I posted on GitHub. Which you started in late 2014. You've been "working" on this idea for less than 3 years and it isn't in the standard yet? You don't say... Have you even submitted a formal proposal? Does your prototype compiler correctly compile all (or even almost all) exsting C++ code without problems? &gt; would be more efficient to get ideas back into a mainstream compiler. You have a fundamental misunderstanding of how C++ is specified. Language-level things go into the standard _first_ and are then implemented my compilers. Sometimes libaray additions are implemented by third parties (e.g. Boost) and are later submitted, but that's not usually the case for language features. A proof-of-concept implementation may be used to back up a proposal, but is pointless without one. Write a formal proposal and submit it to WG21. &gt; which is why I'm resigned to putting effort into these arguments, realising my time actually writing that language experiment was wasted. Reddit is not WG21. Talk on Reddit is even more "wasted". It's pretty obvious that you haven't thought through the full implications of your proposed language change and seem to take observations of (potential) flaws as personal attacks. Maybe work on that.
You misspelled unique_ptr =)
&gt; namespaces already change the behaviour of '&lt;' and '&gt;' No, _templates_ change the behaviour of '&lt;' and '&gt;'. However, the line `a&lt;b&gt;c;` is a no-op in C, so no _useful_ behaviour has actually changed.
&gt; hows that any different to the existing situation with symbols that can be redefined by namespaces Symbols can be disambiguaged by explicitly specifying the namespace. (e.g. `std::vector`, `mylibrary::foobar`, etc.). Your syntax cannot. Only macros can redefine existing language-level constructs (e.g. `if`, `while`, `int`, etc.) and that's already considered a very bad idea. &gt; so you're complaining about problems that we already have. Saying "similar problems already exist" is not a good justification for adding more problems... &gt; I've seen 'vector' defined by a compiler as something machine specific that doesn't have type-params Then you've seen a broken compiler. `vector` should never be defined _by the compiler_. It might be defined by one or more `#include`d headers, but `std::vector` should always be unambigous.
Bad bot.
&gt; Then you've seen a broken compiler. better tell all those people who played games on PS3's it was a keyword used in a different context.. but the point remains.. syntax can vary wildly
1. This is absolutely brilliant! I love it. 2. But if anyone actually uses this on a project I work on, I will kill them.
&gt;&gt; Your syntax cannot. ok, so never do this in conjunction with 'using namespace', in legacy code. other people in this thread have said "they've never used foo[N] in years".
&gt; other people in this thread have said "they've never used foo[N] in years". Good for them. There's still massive amounts of existing code that uses it... Code that still needs to be supported and updated without being heavily modified or rewritten.
&gt; No, templates change the behaviour of '&lt;' and '&gt;'. ... and templates can be brought in by namespaces... &gt; However, the line a&lt;b&gt;c; is a no-op in C, so no useful behaviour sure, but these are possibilities within C++ syntax. I updated the example, try ```foo(a&lt;b,c&gt;d)``` is that a function taking two bools? this is why C++ is hard to parse, you need to know how the symbols resolve before you can parse it. you can't assume what &lt; means, without consulting whole program context.
&gt; better tell all those people who played games on PS3's Relevance? Some special compiler has (according to you, I can find no evidence of this; more likely it's a library and only broke code that had `using namespace std;`) a built-in extension that had a naming conflict with a standard library construct. That's pretty much _why_ we have the ability to disambiguate names by specifying the namespace (i.e. `std::vector`). &gt; syntax can vary wildly C++ syntax is regorously defined and specified. It _cannot_ "vary wildly". You seem to have difficulty seperating language-level keywords (which `vector` is not) from standard library symbols (which `std::vector` is).
&gt;&gt; according to you, I can find no evidence of this look harder, it wasn't a library it was declaration of intrinsic vector types. http://bullet.svn.sourceforge.net/viewvc/bullet/trunk/Extras/vectormathlibrary/include/vectormath/ppu/cpp/mat_aos.h?revision=743&amp;view=markup https://books.google.co.uk/books?id=LlLSBQAAQBAJ&amp;pg=PA220&amp;lpg=PA220&amp;dq=sony+ps3+vector+gcc&amp;source=bl&amp;ots=h8VsF-zbFc&amp;sig=nTpQ1T5mDHUFaSOC-Xab6P59Vmg&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwiJ0OrahKLVAhUIqxoKHUhMA0AQ6AEISDAG#v=onepage&amp;q=sony%20ps3%20vector%20gcc&amp;f=false &gt; seperating language-level keywords (which vector is not) ... unless you were porting C++ games to the PS3... anyway thats an aside. The main point is , **in standard C++** you can't correctly parse &lt; and &gt; without namespace dependant context. every time you see either, the compiler has to check definitions to know if it's parsing a comparison or a type parameter. There *are* examples that legally compile both ways. you can use 'bools' as type-params, and you can generate bools from &lt; or &gt; ...
&gt; ... and templates can be brought in by namespaces... And so can more or less everything else... Guess what, if you have `std::string foo;` in namespace `bar` and `int foo;` in namespace `bar2`, different `using namespace` lines can change what `foo` means! &gt; `foo(a&lt;b,c&gt;d)` In C (assuming no macros), that's a function taking two "boolean" parameters. In C++ it's either that or an error. (If a is a template and b and c are types or compile-time constants, it's an attempt to define a variable called "d" in a function call; not allowed.) However, we seemed to have turned a corner into problems with C++ parsing, which is a different topic to "why it's a bad idea to allow built-in syntax to be redefined within a C++ program".
Look toward the bottom of the code on github. The author creates and populates an equivalent instance and then compares it for equality.
There is no complete or even standard-compliant port of the standard library for Arduino. 
there are some more evil examples which are valid either way. the 'no side effect comparison' isn't used, but its within the definition of the language, so the compiler has to check definitions to rule it out. 
I do use both of them, and I like R# more then VAX. Killer features for me are Resharper Build and Test Explorer. Built-in code inspections are great too. although VAX now has some of them too. The most noticeable drawback of R# is huge resource consumption and much longer solution load time.
Um, pretty much everything from second line and on is quite confusing to me. How do you have a decrement operator between a paranthesis and array index operator to start.
&gt; ... unless you were porting C++ games to the PS3... Actually, [looking a bit deeper](https://gcc.gnu.org/onlinedocs/gcc/SPU-Built-in-Functions.html), the actual keyword defined was "__vector" and "vector" was a macro "defined in &lt;spu_intrinsics.h&gt; and can be undefined." Double-underscored names a specifically allowed as vendor-specific compiler extensions. `vector` was not defined by the compiler. All anyone porting code needed to do was `#undef vector`. &gt; The main point is , in standard C++ you can't correctly parse &lt; and &gt; without [...] context. So? How does that support the idea that `int myarray[5];` should also be context-dependent? Saying "we have one problem, so we may as well have more" is not a good argument.
&gt; You've been "working" on this idea I quit after a few weeks, I realised writing a new language alone was futile. I am merely demonstrating the theoretical possibility. Similar has been done elsewhere, SPECS, and rust demonstrated various ideas. The point is it is demonstrated that we CAN have the semantics of C++ without the fugly legacy syntax. It should therefore be possible for the world to do some sort of rolling refactor.
Is it cross-platform or windows only? What are the dependencies?
&gt; you haven't thought through the full implications of your proposed language change and seem to take observations of (potential) flaws as personal attacks. nope; you insist that this would *break* code; you fail to admit that you *can* devise a restriction in how the option is selected that *wouldn't* do that. I'm showing the template examples of how namespace selection *can* already change parsing (hence, a headers choice of symbol uses *can* break code already) So it's no different to those existing hazards, surely. Every angle bracket is a place where the compiler has to check something radically different, depending on whether the symbol was a variable, a type, a function.. all you'd have to do is *not* bring this into source files that already have legacy uses.
qcolor-from-literal could be just constexpr.
What about std::vector, std::array and &lt;algorithm&gt;?
&gt; I am merely demonstrating the theoretical possibility Consider it demonstrated. Now write up a formal proposal. &gt; The point is it is demonstrated that we CAN have the semantics of C++ without the fugly legacy syntax. It should therefore be possible for the world to do some sort of rolling refactor. Unfortunatley (for your proposal; for the vast majority of real C++ programmers this is a good thing), WG21 has decided on a stance that they will (almost*) never make breaking changes to the lagauage. \* The only exceptions I can easily remember are removing default-int (something long considered bad practice even in C and rarely used) and changing the meaning of `auto` (something almost never used and redundant). Even then, the decisions were not made lightly.
I can't tell you what's in or out at the moment, but I know that many standard functions I've had to re-write myself, like `std::move`, etc. Also, had to create classes to replace `std::function`.
well there you go, #define can do even worse &gt; Saying "we have one problem, so we may as well have more" the hazard already exists, and we work around it: most people say 'don't do using namespace in headers'. If this was controlled by namespaces and we avoided that, it's use would not 'leak', affecting legacy code in other headers. I had another suggestion which is to tie the behaviour of [] to the type itself, e.g. in this example ```int my_array[N]``` the '[]' can ask the 'int' 'what type of array do you declare'. This is analogous to how Rusts '~' worked. ~ was not itself a type , or template, rather a modifier that consults the 'contained node' to determine what actual type to declare. so what I imagine there is *new types* enabling new syntax. if that generates problems, i'm sure someone can figure out a workaround. there's many ways to do it. What if it was only done 'post modules', and it *never* escaped into headers?? 'only enable this definition in this module ..' wont most of the legacy []'s be in 'extern "C"{..}'
The performance tradeoff for using valgrind/asan/ubsan/debug stdlib in live production systems is great enough to offset any benefit you might get from using C++ in the first place.
&gt; you fail to admit that you can devise a restriction Of course, it _can_ be devised (consider that an "adimission"), but you haven't done it and haven't demonstrated that it can be done in an "elegant" and consistent way. That's your responsibility, not mine. You also haven't really shown that there's really anything wrong with writing `array&lt;int, 5&gt; myarray;`. Words like "ugly" are purely your personal opinion. &gt; I'm showing the template examples of how namespace selection can already change parsing (hence, a headers choice of symbol uses can break code already) You keep using this stupid justificaiton of "there are ways to break things already, so it doesn't matter if I come up with more". Stop it. And no, apart from via macros, headers _cannot_ redefine parts of the _language_. Only user-defined symbols. When it does happen, it causes a compiler error in all but the most contrived and unrealistic of examples, rather than silently changing behaviour in incompatible ways (i.e. causing a link error, prevently a shared library from working correctly, etc.) as your proposal would. &gt; all you'd have to do is not bring this into source files that already have legacy uses. Easier said than done. What if my "legacy" code uses some library that gets an update to add this feature?
&gt;&gt; never make breaking changes to the lagauage. this isn't a breaking change. it changes nothing unless you 'opt in' by declaring something differently. there is a possibility of a new source file where you opted in 'breaking' old source that includes it with sloppy leaky namespaces, but in that case, just don't use it.
You're proposing changing the meaning of `int array[5];`. Nothing has been declared differently. The "opt-in" might be deep in some included header somewhere. It might be in a library that I depend on that's just been updated. My code might compile just fine, then fail to link (e.g. because you're also changing the meaning of `extern int array[5];`) or, if I'm building a shared library, another program that hasn't been touched might start crashing (because it's passing incompatible parameters to my unknownly redefined functions), etc. That's a breaking change.
I've been using visual assist for a long time, and I love it. I've never experimented enough with Resharper to compare the two fully, though. I downloaded it once, but didn't put in the time to customize it or fully test it. 
If you have to ask then yes.
&gt;&gt; The "opt-in" might be deep in some included header somewhere. yeah but the opt in only appears by a manual change. a 'breaking change' like the change in meaning of 'auto' refers to the possibility of breaking *existing code*. I fully understand why that is ruled out. one person may make a change that then breaks another persons code who includes it - but thats' a regular hazard with C++ thanks to #defines, possible using namespace in headers, etc etc. only put these opt-ins in *new* namespaces, then they wont break any existing code surely? 
&gt; That's a breaking change. but it's not imposed by this. you have to opt in. "I will use ... []". extern int array[5]; thats a symbol in a namespace - if this opt in is namespace specific, this change wont change what it expects from the namespaces in the object files this 'extern' refers to; isn't the use of namespacing to insulate separate libraries from such changes...
&gt; \#define can do even worse I think we've already agreed that that's evil and I've repeatedly said that the presence of one problem is not justification for creating more. &gt; most people say 'don't do using namespace in headers' And I agree. You do know that, in C++, there is a "global namespace" outside of any `namespace{...}` blocks, right? What happens if someone uses your new construct there? Even just having `using namespace` in source files will cause problems under your scheme, since there is no way to disambiguate a C-style array defintion (I did suggest `T var namespace::[n]` but that's super-awkward). &gt; tie the behaviour of [] to the type itself That's a better idea; similar to how overloaded operators require a user-defined type. &gt; wont most of the legacy []'s be in 'extern "C"{..}' No. Take a look at any big C++ project, they're there. Also, `extern "C"{...}` only affects _linkage_; it basically turns off name-mangling for that block, it doesn't stop you using normal C++ features. `extern "C"` can also be used as a prefix on a function declaration, it doesn't need to be a block.
You might be interested in https://github.com/taocpp/sequences And here's the presentation I did about avoiding recursion and what difference it could make: https://github.com/taocpp/tuple/blob/master/Variadic%20Templates.pdf TL;DR: Test program creates a tuple with 265 elements via multiple tuple_cat-calls. libstdc++: depth 3719, 19.6s down to depth 26, 1.2s when avoiding recursion. libc++: depth 514, &gt;70s down to depth 15, 1.7s. EDIT: Fix typo.
What about the global namespace?
&gt; only appears by a manual change. But not necissarily by the end-programmer. It could be as part of a third-party library update, as I've mentioned. &gt; only put these opt-ins in new namespaces Unenforcable.
I've used both extensively, I definitely prefer R#. Unfortunately performance is poor for large solutions, so the only way to use it on large projects is to partition your solution into smaller solutions.
&gt; If you read an expression like -3*4+22==a()+b[42], anyone should be able to infer what it does. Otherwise, your language isnâ€™t good. what if your background is RPN calculators ? 
..."[SPOILER](http://i.imgur.com/dl5f6pM.png)"?
+1 to an opt-in flag.
Sorry this was my first reddit post. I don't know how I have added this and I don't know how to remove this.
&gt; qcolor-from-literal could be just constexpr. having a function being constexpr absolutely does not guarantee that it will be executed at compile-time. It's only the case if you evaluate it in a context that requires it (e.g. `SomeTemplate&lt;QColor("#001122")&gt;`). edit: for posterity: #include &lt;array&gt; constexpr int from_hex(char c) { if(c &gt;= '0' &amp;&amp; c &lt;= '9') return c - '0'; else if(c &gt;= 'A' &amp;&amp; c &lt;= 'F') return 10 + c - 'A'; else throw; } constexpr int from_hex(char msb, char lsb) { int lsb_i = from_hex(lsb); int msb_i = from_hex(msb); return msb_i * 16 + lsb_i; } template&lt;std::size_t N&gt; constexpr std::array&lt;int, 4&gt; make_color(const char (&amp;col)[N]) { std::array&lt;int, 4&gt; argb{255, 255, 255, 255}; if constexpr(N == 5) { argb[1] = (from_hex(col[1]) * 255) / 16; argb[2] = (from_hex(col[2]) * 255) / 16; argb[3] = (from_hex(col[3]) * 255) / 16; } else if constexpr(N == 6) { argb[0] = (from_hex(col[1]) * 255) / 16; argb[1] = (from_hex(col[2]) * 255) / 16; argb[2] = (from_hex(col[3]) * 255) / 16; argb[3] = (from_hex(col[4]) * 255) / 16; } else if constexpr(N == 8) { argb[1] = from_hex(col[1], col[2]); argb[2] = from_hex(col[3], col[4]); argb[3] = from_hex(col[5], col[6]); } else if constexpr(N == 10) { argb[0] = from_hex(col[1], col[2]); argb[1] = from_hex(col[3], col[4]); argb[2] = from_hex(col[5], col[6]); argb[3] = from_hex(col[7], col[8]); } return argb; } int main() { static_assert(from_hex('0') == 0); static_assert(from_hex('A') == 10); static_assert(make_color("#FFFFFF")[0] == 255); static_assert(make_color("#000")[0] == 255); static_assert(make_color("#000")[1] == 0); static_assert(make_color("#DD1255")[1] == 221); static_assert(make_color("#DD1255")[2] == 18); static_assert(make_color("#DD1255")[3] == 85); } notice that if you remove constexpr and keep it inline, the compiler inlines it exactly the same
Then you are probably as old as I am, went through the AOS vs. RPN war, and bought (and still own) a HP pocket calculator ...
Yup, there is a NDC 2017 Oslo talk where the presenter provides an example of how to do it.
&gt; So, is it possible to use C++17 on Arduino? Some. But the compiler is pretty far behind so I decided not to. There is an LLVM for avr but I haven't tried. If you can get regular old clang trunk to compile for avr you would get all of C++17 or at least most. &gt; Are there any limitations, for example in the standard library? You don't have exceptions. That pretty much kills use of std for now. Also, in embedded development use of the heap is discouraged. The ~~malloc~~ `new` operator functions in the arduino IDE version of libc is limited to C++11 as well. Wouldn't be hard to fix but still...the standalone might also be more up to date. Edit: also, the arduino library itself is pretty C like. You won't get a lot of modern features and actually there's a lot not to like so I decided to make my own. Really slows down my ability to play with the electronics part for now, but it'll speed up and I'll get to play with modern features and some stuff that's just...weird.
I'm 25 and just happen to like digital archaelogy :p
It almost looks like the pattern matching syntax found in Erlang or Ocaml.
Probably pretty crazy. Don't make a typo ;)
Then you went too far :-p
Regardless what you think about this article I think we can agree that the precedence of `.*` and `-&gt;*` is outrageous. At one point I think /u/STL said he was going to ask Bjarne what the deal was with the precedence of those operators...
So far it only supports Windows. It has no dependencies :)
I stick with VAX. It does what it says and doesn't get in my way. I feel to a certain degree that VAX slowly becomes obsolete â€” more and more of its features are integrated into the IDE itself and its understanding of more advanced/modern C++ constructs is often limited. But there is still enough value to keep it. I tried Resharper as well. It has tons of features. In contrast with VAX it feels loud and somewhat intrusive, but it is likely the first impression only and matter of getting accustomed to. The showstopper though is performance. The IDE becomes unresponsive, there is a visible lag when typing text, and debugging is nightmare (apparently because of VS being 32-bit and memory pressure issues). This is just unacceptable for a plugin that is supposed to make my work easier. Resharper might work well on small projects, or the ones that don't use much templates or heavy third party libraries (like Boost or Qt). However, unless they improved performance at least by an order of magnitude in the last release, I don't think there's any value in it for me. While the features are certainly interesting (more interesting than VAX's feature set), I can't really use them in non-trivial projects. However, if the performance issues are solved, I'd certainly like to give it one more try.
I installed the 15.3 preview today, and it still gives an error: "Package management initialization failed. You can get more information by examining the file '...'" The file then lists the same cause of error: "Failed to process PkgDef file c:\...\DSLTextTemplatingRegistry_x86.pkgdef" (8007001f), followed by "PkgDef loading aborted". As before, I can open this file using notepad. So now it's a known error instead of an unknown error, but I would like to point out that the goal should probably be to get rid of the error entirely, rather than just classifying it correctly ;-)
Personal story: I got bitten once by operator precedence at the beginning of my professional career. It's so simple and yet just tricky enough: **I refactored a `+=1` into a `++`. Program bugged afterwards.** No operator redefinition. Issue was I was incrementing an int pointed by: int* ptr = getPtr(); *ptr++; // was *ptr += 1; (Note : I hardly developed in C before, I wasn't used to the many `*p++`) Lost more time than I can admit staring at my screen, knowing the issue was on that line, without understanding why. Gotcha is the dereference operator precedence is between the `++`and the `+=`operator.
It sees `|` between two `function_set` values and merges them. Then it sees a `--` and decides that matches the postfix decriment operator in `function_set`. Then it creates an assigner that will do the work from then on. `assigner` has 3 variations: unset, one set, both set. There are three arguments but giving that resets the assigner and appends to the collection. Unset: compiler sees `(...)` and desides you're starting a next assignment. Stores the first value and continues. First set: compiler sees `--` or `[]`. `--` just returns itself. It's syntactic sugar that doesn't mean anything now. If it sees `[]` it expects you're giving it a pair of indices. Stores them and moves forward. First and second: sees `--` and ignores it the same way. Sees `(...)` and expects you're finishing. Now it creates the new entries and stores them in the collection and resets to the awating version. Dereferencing an assigner that hasn't started yet gives you the collection. This then gets assigned to `x`. There are three ways to make an assignment pair (two indices to assign to): comma operator between, or subtracting one of `U` or `_` and then subtracting another index from that. They don't actually do anything different but they give me the ability to draw the chip but like it looks, with the divit on the top. It's actually not all that impressive when you know what expression templates are. Took a bit playing around with syntax to see what was possible, but that's it. It's just kinda cute.
It's a spell that summons Satan himself.
Most operators can return pretty much anything. You're limited in `-&gt;` because it HAS to return a type that responds to -&gt; or is a raw pointer. You can't just use that because the compiler keeps calling `-&gt;` until it gets to a raw pointer... I couldn't think of a way at least and I tried because I wanted that syntax. So `--` returns a type that has `[]` overloaded. It's postfix so it's used on the type before the `--`. Go ahead and try it: make a class that has `--` overloaded and return a vector.
None of it. There's a sort of non-standard version of the STL floating around somewhere but I haven't found. What's stopping it really is that exceptions don't exist on this and many other embedded architectures. You can write most of the rest of the stuff, including new/delete, but you can't implement the exceptions the standard requires. *Maybe* LLVM will be able to.
My guess is "soon", few weeks or so.
Debatable. Ever screw up a `bind` call? I wouldn't expect it to generate anything remotely that bad. Deciphering template vomit is a necessary skill for C++. I could probably clean it up a bit and make use of static asserts. For the most part though I think I'd expect some sort of operator unavailable error that might be tough to interpret and the options there are probably limited in getting someone a better message. On the other hand...I know this doesn't look like C++ but it seems like it ought to be intuitive enough to be able to look at and see what's wrong if you're familiar with the domain. A lot of modern C++ is going for the EDSL thing...so I'm going to experiment with this a bit and see how far it can go and whether the result is easier to use, harder to use, or neither.
I think you should clarify that point to further differentiate capturing by value and capturing by reference (but imo you should use `[&amp;a]` instead of `[&amp;]`). I've done this to get that behavior on purpose, so it's worth knowing about at least.
&gt; But not necissarily by the end-programmer. It could be as part of a third-party library update, as I've mentioned. ... then you can go back a version, and report the problem to your library vendor. if the library does not take into account the problems of it's users, it will go out of fashion. 
&gt;&gt;" "global namespace" outside of any namespace{...} blocks, right? What happens if someone uses your new construct there?" we could say it's a compiler error if you try? I would have thought a recommendation would be enough though. your concern appears to be *libraries*, so a library vendor will care enough about this if he wants to stay in business.
Do you remember, by any chance, error code it was returning?
&gt;&gt; in source files will cause problems under your scheme, since there is no way to disambiguate a C-style array defintion (I did suggest T var namespace::[n] but that's super-awkward). if you need to disambiguate, just use the templated form, and I did explain there should be a template alias that recovers the __raw_array&lt;T,N&gt; - I know you need access to that to *implement* . &gt; No. Take a look at any big C++ project, they're there. ok then. for codebases which contain such legacy code, don't bother using this feature. for codebases which are being actively worked on, and you've been able to move over to the c++11 array&lt;T,N&gt; you can do this. aren't there clang based refactoring tools these days for updating? Remember 'arrays' are not the only issue here. there's * and , to improve. 
&gt; "only put these opt-ins in new namespaces Unenforcable." in this age of GitHub , pull requests, forums, the information relating to damage from a change is going to get back quickly enough
This is roughly what I've been preaching for a while as well, but it is nice to have it written down in a thorough and complete fashion. Two things however: 1) If we were designing the language again, instead of forbidding the chaining of comparissions, we should make it behave in a sane way so that `a &lt; b &lt; c == d &lt; e` [**edit:** this was `d &lt;&lt; e` which was obviously a typo] does exactly what one would expect. I believe that there are some languages that already to that and implementing it in C++ would be trivial as well, by returning a `bool` *and* the reference to the right operand which will then be used by the next comparator to do the obvious thing. 2) The precendence of `&lt;&lt;` and `&gt;&gt;` is arguably very sane, maybe even perfect, if you consider them to be mostly stream-operators. Personally I think all those bit-operations should simply be functions so that the operators are unambigously available for things like working with ranges and strings which is a much more common task. (Also: What these operators are currently doing with the types of their arguments might have ended up more sane as well. Plus there would be a better chance to get more of them, since quite a few bit-operators are missing (rotate, popcountÂ¹, getting the highest set-bit, ...). [1] Yes, you can get popcount in a portable way with `std::bitset&lt;N&gt;::count`, but this is really a lot of work in some situtations.
I don't understand this feedback. Care to explain?
Regular priority for an STL-needed feature. Only a select few features, like variadic templates and `if constexpr`, get burn-the-world priority :-)
I did. As I recall, he said that it was so long ago, he didn't remember why, and that it did seem to be wrong in hindsight. Seems like it's a case of "even Homer nods".
I wish I would understand when or where to apply template meta programming in my day to day work.
If anybody is curious, I recently needed (ok, wanted) to use lambdas recursively in a couple of places. The syntax is a little odd, because you can't use auto (the lambda body is its initialization, so you can't use auto and try to have it call itself because it isn't initialized and so won't have deduced its type [seems like it could/should work, but I digress]). Here's a contrived example: // Function that needs to visit children, but also remember the // original node. We could make this function directly recursive, but // to remember the original parent we'd have to add second Node // parameter that the user won't care about. We could put a recursive // helper function somewhere, but nobody else anywhere will need to // call it, so we'd rather not expose its interface anywhere at all: Result DoSomethingWithADescendant(const Node&amp; originalNode) { // Declare a std::function... std::function&lt;Result(const Node&amp;)&gt; Recurse; // ...and capture it while you initialize it. I can't really // explain this, it's weird. I chose to capture originalNode // instead of pass it in, not sure if it makes a difference. Recurse = [&amp;Recurse, &amp;originalNode] (const Node&amp; currentNode) -&gt; Result { if (currentNode.IsWhatWeWanted()) return Result(originalNode, currentNode); // Found it! if (!currentNode.HasChild()) return Result(); // Didn't find it return Recurse(currentNode.GetChild()); }; return Recurse(originalNode); } I just thought it was kind-of neat and weird. Tell me if you see anything wrong with the approach. edit: I guess this technically makes it not a lambda, because it has to be named, right?
I don't know man. If something makes you think, "How is that even valid C++," will get you to look at it...if you're even interested (and you may not be if it just works). On the other hand, there's a lot of other constructs that at least *seem* like they should be valid C++ to some people, especially novices, that just won't point themselves out. For example: it++++++++++++++++; // if it's an odd number it's not supposed to be. I've seen it. Edit: In fact, not only have I seen it but I used it when I was still stupid. I was doing a homework problem with `std::list` and we were supposed to get the n'th value. I wrote something like the above, put a comment, "// ICK!!" I got an A. Teacher wrote "I agree" on it... and he didn't suggest `std::advance`. So...I don't think there's a moral but if there is one it's not one I like :p
You should checkout https://github.com/MCGallaspy/dr_strangetemplate, MCGallaspy gives some pretty good examples of when you could use metaprogramming in day to day work 
&gt; so that a &lt; b &lt; c == d &lt;&lt; e does exactly what one would expect What exactly should I expect that expression to do? And why is it objectively correct to have that expectation? 
&gt; void* userdata I have doubts whether this is C++ way.
It wasn't.
C1XX (MSVC), EDG, and Clang all support `__make_integer_sequence` now, which is the most efficient way to implement it (you can't do better than the compiler).
taocpp/sequences is intended to use the compiler's `std::make_integer_sequence` when it is known to be efficient, so I'll need to check for more versions to use it (can you provide the check for MSVC? And others if you happen to have them at hand... thx). But the real saving is not just from creating sequences, it is all the other algorithms running on top. Running over those sequences recursively over and over again costs a lot of resources. Somehow everybody seems to ignore this and just focuses on `std::make_integer_sequence`... :-/
QtCreator is too expensive! 
Visual Studio has a vim extension haah
VAX: * ++ Speed of code completion - it's amazingly fast, it's instantaneous! * ++ Quality of code completion - it uses the context perfectly and the variable that you want is usually the first on the list so you just hit "Tab". * ++ Debug step filter. * -- It lacks a few nice features of Re++, VAX's development is somewhat stale. Re++: * -- Code completion was extremely slow on even a small/medium project - it was faster for me to type long stuff by hand * -- Context doesn't seem to be used at all, it almost never gets the prediction of what variable is needed right. Some weird STD or BOOST macros appear at the top of suggestion-lists. * -- No debug step filter, it debugs into all std:: types and functions and no way to disable it (no, I don't want to go into std::string's c'tor each time...) * ++ It has a few very nice features and development seems lively, they're working on cool stuff! Overall, VAX clearly wins because all three negative points of Re++ are clearly no-go's. I really wish though that either VAX would add more cool stuff too or Re++ get their stuff together and improve upon all their minus points. As somebody said it in another post, slightly modified: "It is just unacceptable that I have to wait for code-completion to happen and then get non-contextual suggestions and spend more time than I would have by just typing it by myself. The plugin is supposed to make my work easier, not wait for it." I tried this on several solutions and they weren't even big (I'd say medium-sized at best).
Hey Gnome boy, I've been using KDE as a daily driver for more than 10 years no big issue at all.... Keep your personal preference out of discussions! 
This was four months old. It's not a personal preference to not use software that is so unstable it is actually unusable. Also you do realize that the KDE gui is different from this new release of a KDE IDE right?
&gt; The precedence of the binary bitwise operators (&amp;, |, â€¦) is lower than that of the comparison operators (== or â€˜&lt;`). &gt; &gt; I donâ€™t know why and I hate the decision. Because `&amp;&amp;` and `||` are newer than the bitwise operators. Originally the bitwise operators were also used for boolean logic. Or at least that's what I've heard. Anyway I strongly agree with the principle of partially ordered operator precedences. I've used this concept a couple times for DSLs and I think it was a win for maintainability.
Can you make a static analyzer that enforces these rules? ie enforce brackets whenever commonly considered "ambiguous" Do Core Guideline checkers do this?
Well, a &lt; b &lt; c = d is common mathematical notation, so I'd guess most people with a math background would be comfortable with the (a &lt; b &amp;&amp; b &lt; c &amp;&amp; c == d) interpretation. Since it doesn't make sense to left-shift a boolean, I assume the overall interpretation should be (a &lt; b &amp;&amp; b &lt; c &amp;&amp; c == (d &lt;&lt; e)).
No it isn't. I do bitwise operations all the time, much more than stream operations. The fact that &lt;&lt; and &gt;&gt; have been co-opted for streams and other new-fangled library stuff is fine, but you can take the bit shifts from my cold dead hands.
Great blog. At some point, during the conversation around default comparisons and fold-expressions with the comparison operators, it was suggested to actually make `a &lt; b &lt; c` do the sane thing. I wonder how viable that change would be, since without a doubt there is some code out there that actually relies on the current behavior. Though without a doubt there is code out there expecting the same behavior and silently doing the wrong thing. It's pretty awkward to do chained comparisons without multiple evaluation. It was in Herb's original spaceship operator paper, but got removed in the next revision... 
So, according to the author, `&amp;b[1]` and `!b[1]` are unacceptable because unary precedence should be higher than binary precedence. I can see it going down well that the analyzer will require this ccode to be changed to `&amp;(b[1])`
&gt; but I think there is a current GCC bug causing a failure to generatestd::array-based code less efficiently than raw array code Right, it's a bug, but that doesn't mean that `std::array` intrinsically introduces runtime overhead. GCC just botched this.
Strong objection to objection: don't delete anything, ever. 
As [my changelog](https://blogs.msdn.microsoft.com/vcblog/2016/04/14/stl-fixes-in-vs-2015-update-2/) noted, VS 2015.2's `std::make_integer_sequence` was enhanced to use the compiler hook. I forget the corresponding `_MSC_FULL_VER`, but I could look up 2015.3's if you really need it. Definitely agree about avoiding variadic recursion when possible. I reimplemented `std::tuple_cat()` a while ago to avoid runtime recursion (although our variadic implementation was primitive enough back then, I didn't attempt to totally avoid compiletime recursion when generating the indices).
&gt;Ever screw up a bind call Only when I use one.
Touche :p
&gt; yes, absolutely. And why should that surprise you at all when we already have all sorts of overloading and namespaceing going on I have a couple thoughts on this: * "using namespace" is already frowned upon, particularly in headers, for exactly this reason. People are expected to play nice and not do this. * operator overloading can only be defined for user defined types. It's expected that people will play nicely and not change the operator behaviours of types that aren't theirs Can your proposed type declaration redefining be achieved in a way that can "play nice"?
I hate that suggestion. The biggest thing that drew me to C in the first place was that an expression is independent of its context. `a OP b OP c` absolutely has to mean either `(a OP b) OP c`, or `a OP (b OP c)` , or be rejected as ambiguous. Anything else is just opening a massive ad-hoc can of worms. 
* except sometimes
`*ptr++` increments the pointer, not the int. You changed the code to increment the int instead of the pointer. Perhaps it is good that a bug occurred here, if you were mistaken about what the original code did and this led you to find out. 
Objection to objection: don't randomly steal ownership from a unique_ptr ! (And pass it by const reference instead of non-const reference).
If you see cases like this where the profiler says it matters sometimes you can help the compiler out with `__assume` -- which is much less invasive than trying to make TBAA work globally.
Why would you do that? It doesn't matter how the object is owned at that point - pass the underlying type by reference (const or otherwise) and dereference the unique_ptr as it's passed in. Your function is now much more flexible. If it could have been a nullptr, pass a raw pointer instead of a reference. 
Okay, so what would be the C++ way? How could I improve that?
That's the point. I wasn't mistaken about the original code (I've written it myself), there were no other instruction on the same line - a decent static analyzer would have pointed that out, I just quickly replaced a `+=1` by a `++` during a quick refactoring phase that became not so quick.
If you really want to do this, you should use a y-combinator to get rid of the type erasure.
&gt;Why would you do that? *I* wouldn't, but I entered this comment chain to rebut the claim: &gt;I don't pass unique_ptr around, because somebody could steal ownership from it. (with the author of that comment implying that he avoids unique_ptr in the first place because of such concerns). 
Yes, absolutely. For example, I work in C and C++ for safety-critical systems, and we abide by the MISRA-C (and C++) coding guidelines. And we use multiple static analysis tools, although the only one I deal with is Gimpel's PC-Lint. Anyway, PC-Lint can be configured to check for the MISRA C (and C++) rules, one of which addresses your concern: MISRA-C 2012 Rule 12.1: "The precedence of operators within expressions should be made explicit". So an expression like "int x = 1 + 2 * 9 / 3 + 4;" will elicit a warning message such as: Note 961: Violates MISRA Advisory Rule 12.1, dependence placed on Câ€™s operator precedence; operators: â€™*â€™ and â€™/â€™
Oh wow you're one of the PEGTL devs. Just wanted to say your library is really awesome!!
Isn't using templates for computations outdated now we have `constexpr`?
You meaning people generally. By which I mean to imply that the advice I wrote is the real rebuttal here. 
Honestly I agree, Python has this operator chaining behaviour and I don't like it. The worst example is that `a in b in c` is treated as `(a in b) and (b in c)` which rarely makes sense. I wouldn't mind `a &lt; b &lt; c` being an error, either a syntax error or from a stronger type system.
I$ MKPI over the roof... 
I always make it super clear what i am doing when dereferencing. Never trust anything. Also makes it more readable and easier to make small modifications to without messing up imo. Either: *(ptr++) or: (*ptr)++ Never: *ptr++
You should pass normal arguments like std::thread can without that void* casting. http://en.cppreference.com/w/cpp/thread/thread/thread
Quick, somebody make an angry mob template system that will accept a constexpr of torches or pitchforks at compile time!
Is there anything like Rust's [`core`](https://doc.rust-lang.org/core/) that tries to add as much of the standard library as possible in a constrained environment?
What?
I'd blame compiler defaults for that?
Yes, there are some attempts to recreate the standard library. Even though they seem like valiant efforts, they don't exactly match the standard, aren't current and very incomplete. Believe me, I've searched far and wide; I've found that it was better/easier to create the functions you need yourself. In particular, the standard library functions that allocate memory from the heap, like `std::function` need to be rewritten anyway to allocate memory (probably) with placement new using your own buffer. This is for a couple reasons: - Not a lot of heap space. - Heap allocation is perilous in the context of interrupts. I've found [this resource](https://arobenko.gitbooks.io/bare_metal_cpp/content/) immensely helpful.
GCC has the flag [-Wparentheses](https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html), which warns about these situations.
ThisðŸ‘†. Parentheses. Use them generously. 
`_MSC_FULL_VER` for VS2015 U2 was `190023918` (U3 was `190024210`).
Should note that clang does not support memoization for constexpr currently.
"In the case of a well-known conversational programming language I have been told from various sides that as soon as a programming community is equipped with a terminal for it, a specific phenomenon occurs that even has a well- established name: it is called "the one-liners." It takes one of two different forms: one programmer places a one-line program on the desk of another and either he proudly tells what it does and adds the question, "Can you code this in less symbols?"--as if this were of any conceptual relevance! --or he just says, "Guess what it does!" From this observation we must conclude that this language as a tool is an open invitation for clever tricks; and while exactly this may be the explanation for some of its appeal, /viz./ to those who like to show how clever they are. I am sorry, but I must regard this as one of the most damning things that can be said about a programming language." From /The Humble Programmer/ by Edsger Dijkstra (CACM, October, 1972)
Better hire a witcher ...
Would be nice, but a &lt; b &amp;&amp; b &lt; c isn't too bad of a compromise.
It really depends on the operator. For something like `+`, sure, `a+b+c` has to mean one or the other (and they mean the same thing anyway). But `a&lt;b&lt;c` can only ever sanely mean `(a&lt;b) &amp;&amp; (b&lt;c)`. `&lt;` is *fundamentally* different from `+` and it does make sense to have them behave different in code. In math, relations are chained all the time and nobody ever means for `3&lt;x&lt;7` to collapse into `true`, regardless of the value of `x`. It's not an ad-hoc can of worms - it's basically just "do as math does and everyone will understand you."
I assume you meant to write `a &lt; b &lt; c == d &lt; e`? That is, `d &lt; e` at the end and not `d &lt;&lt; e`?
&gt; it was suggested to actually make `a &lt; b &lt; c` do the sane thing. Besides existing code that may depend on the current behavior, what kind of operator structure would this be? Should it be translated into something like this? B const&amp; temp = b; return a.operator&lt;(temp) &amp;&amp; temp.operator&lt;(c); I'm trying to pick some problem with it, but that seems workable enough. Hmm...
sure... ;) There is actually a surprising benefit to allowing arrays to outlive their parent objects, or scopes of origin, without explicit syntax. Once you reduce the number of shared pointers to where their cost is negligible, lifetime concerns all but disappear.
The author's main point is that operator precedence should be partial instead of complete. The details are up for discussion. I am fine with [] unambiguously binding stronger than &amp; or !, as in the above case. But to be fair, I have myself put parentheses around expressions like these, to be absolutely sure.
wat? O_o non-zero return value *is* the error code. Do you remember what it was?
yep, I've seen unix guys using it :)
Result DoSomethingWithADescendant(const Node&amp; originalNode) { auto Recurse = [&amp;originalNode] (auto&amp; self, const Node&amp; currentNode) -&gt; Result { if (currentNode.IsWhatWeWanted()) return Result(originalNode, currentNode); // Found it! if (!currentNode.HasChild()) return Result(); // Didn't find it return self(self, currentNode.GetChild()); }; return Recurse(Recurse, originalNode); } y combinate. Also auto y_combinator=[](auto&amp;&amp;f){ return [f=decltype(f)(f)](auto&amp;&amp;...args)-&gt;decltype(auto){ return f(f, decltype(args)(args)...); }; }; makes the last line return y_combinator(Recurse)(originalNode); which in theory also lets you return recursive lambdas, not just use them.
The implication of passing a unique_ptr is that you are passing ownership so I don't really understand this argument. If you didn't want something to take ownership, you'd pass it by const reference
Thanks, I've updated our config accordingly.
Currently, everything that's valid in a namespace is also valid outside of one. Let's not introduce arbitrary exceptions. 
What's that IDE?
I must say, a &lt; b &lt; c is cristal clear to me. but someone using that in the actual context gives me headache for the lucky maintainer ...
&gt;... then you can go back a version, "Sorry, customer, we don't support the latest version of your OS, database server, hardware, etc. because of a technical issue that you don't understand or care about." "Oh, we're switching to your competitors product then." &gt;if the library does not take into account the problems of it's users, it will go out of fashion. You've obviously never actually worked on a real software product. If a platform is successful, its programming libraries can be as awful as they like. See MFC, for example... 
Better to avoid the post increment if it is not necessary, no need to remember precedence with the pre increment: ++*ptr;
/u/mattgodbolt's [Compiler Explorer](https://gcc.godbolt.org/)
And GCC trunk now has `__integer_pack`.
I agree in general. VAX is the *clear* winner in real use. If you look at a list of features, R# looks *extremely* competitive--but in real use, VAX works brilliantly, and R# is almost completely unusable.
A common mistake new programmers make is: cout &lt;&lt; x &amp; y; This parses as (cout &lt;&lt; x) &amp; y which throws a hundred or so lines of errors from basically every compiler. 
If you're going to consider the behavior of other languages, you might want to consider how APL works. It has no operator precedence at all. In the absence of parentheses, it evaluates *everything* with strictly right to left grouping (i.e., everything is right associative), even when/if that violates well known rules, such as multiplication and division taking precedence over addition and subtraction. This may confuse absolute beginners, but once you become accustomed to it (even slightly) there's never any question about precedence. At least in my experience, getting used to its complete lack of precedence is utterly trivial.
With the current implementation that is not possible. The queue is a pre-allocated buffer of JobInfo (the struct you are referencing) elements.
At some point we might be able to add this to our compiler options: -Wcore-guidelines That at least helps a bit.
The point is, the code doesnt make sense, this loop never entered.
there's a module system coming which will free us from certain constrains in the compilation model. if there are problems that really couldn't be solved, what if we design this feature in a way that is only useable in conjunction with modules? ('this redefinition only works inside this module') but with everything I've seen demonstrated elsewhere: I flatly refuse to believe this is an unsolvable problem. 'we cant' use this because someone *might* use it in a way which will break something' is what you're basically saying. If it's an opt-in, it doesn't matter. Just use the opt-in where it works ok. if legacy code can't be refactored, surely it can be compiled in a way that is also insulated from new changes. I really don't get the objection.
Good follow-up. The truth of the matter is that by the time changing an if from expressive to something more complex would significantly speed up your program, you've long left the realm of readable code and mortal men.
Weird end to the video in this one. In his exemple, would it be better for his function to take a copy of a stringview or is the const&amp; the right choice ?
&gt;&gt; jmpq 4049a9 &lt;if_if(benchmark::State&amp;)+0x69&gt; &gt; which corresponds to a â€œjumpâ€, the implemenatation of an if statement in assembly code. That's an unconditional jump though, I don't see what that has to do with any if statement.
&gt; The implication of passing a unique_ptr is that you are passing ownership Yes, that is why I don't pass unique_ptr around when I don't want to transfer ownership. I said that already. &gt; If you didn't want something to take ownership, you'd pass it by const reference That limits me to using only `unique_ptr`, moreover it wouldn't allow me to pass a reference to a `unique_ptr` with a custom deleter.
Math and programming are fundamentally different too. In math `a &lt; b` doesn't "evaluate to true" in the first place; it's an inequality. &gt;It's not an ad-hoc can of worms - it's basically just "do as math does and everyone will understand you." https://xkcd.com/927/
&gt; I flatly refuse to believe this is an unsolvable problem. Of course it's not "unsolvable". The problem is, the "solution" is far more effort (and creates weird special cases like features only available in namespaces or modules) than just accepting the very minor "problem". You've repeatedly failed to acknowlegde the "programmer confusion" problem; `std::array&lt;int, 5&gt; myarray;` tells the maintenance programmer exactly what type `myarray` is. Hiding that information is not a good idea and goes against the philosophy of C++; information should only be hidden when you don't need to know it. It's even worse if you redefine what pointer defintions mean; one programmer decides that `T*` should be a `std::unique_ptr&lt;T&gt;`, another decides that it should be `std::shared_ptr&lt;T&gt;` and then some Windows programmer decides to use it for `CComPtr&lt;T&gt;`, all of which have very different semantics. Try maintaining a large system with that going on. Sure, someone could already "hide" the information behind a macro (evil), but at least `POINTER(T)` is not chaging existing syntax. You might say that `auto` "hides" some information, but again, it's not changing anything that already existed (the old meaning of `auto` being so rarely used as to be not worth considering).
&gt; The biggest thing that drew me to C in the first place was that an expression is independent of its context. Heh. C is the wrong choice if you want a language where expressions are not context-dependent. Forget `a OP b OP c`, often you don't know what `a OP b` means without context. Take the famous example of `a * b`
I have a licence for Resharper C++ and find the code inspections and quick fixes particularly useful when refactoring legacy code to C++11/14 BUT I generally have the extension disabled in normal Visual Studio use as it slows things down too much and is a real memory hog.
&gt;&gt; one programmer decides that how's it different to any other redefineable symbol. We're talking about a language where *bitshift operators* got redefined to mean *streaming* FFS. The use cases I invisage involve far less semantic shift than that.
sorry if I wasn't clear. The problem is relative paths, they are just wrong.
And here I am stuck on gcc 4.8 :(
What's more, that jump actually just jumps to the next line! It's essentially a long NOP, and could probably be better described as a code gen error than anything intentional.
Ah, I hadn't even paid attention to the offsets in the jump since they were stripped from the lines themselves. Good catch!
&gt; how's it different to any other redefineable symbol. Because it's basic syntax, not a symbol. The only "symbols" in the line `int myarray[5];` are `int` and `myarray`. The fact that syntax has been redefined is invisible. &gt; bitshift operators got redefined to mean streaming They're only "bitshift" operators to C programmers. In C++ they're streaming operators, except in the very limited context of integers (for C compatibility and low-level programming). You may as well point out that the `-&gt;` symbol now has two meanings in C++ (postfix return types and pointer member access). And once again, I can't believe I have to keep repeating this: Pointing out that other problems exist is not justification for creating more! How many times do I have to say it?
already discussed here https://www.jetbrains.com/resharper-cpp/documentation/resharper_cpp_vs_visual_assist.html
yes.
because of work policy ? 
You can do that perfectly fine while following your rule: template&lt;typename T&gt; struct comp_result { // Temporaries live long enough for that pointer to stay valid within // one expression, if you keep comp_result longer, problems are your fault const T* value; bool truth; // assume that we will at some point get operator auto: bool operator auto() const {return truth;} }; template&lt;typename T&gt; comp_result&lt;T&gt; operator==(const T&amp; lhs, const T&amp; rhs) { return {&amp;rhs, lhs == rhs}; } template&lt;typename T&gt; comp_result&lt;T&gt; operator==(const comp_result&lt;T&gt;&amp; lhs, const T&amp; rhs) { return {&amp;rhs, lhs.truth &amp;&amp; *lhs.value == rhs}; }
Operator precedence *is* broken. The reason and/or/xor precedence is so weird is because back in the earliest days of C, and/or did double-duty as both bitwise and logical operators, because there were no logical operators then. Instead of fixing this, C went with backward-compatibility and left them with horrendous precedence. The compiler could have detected ambiguous use of and/or/xor after it added logical operators and warned of the change for a decade or so. And instead of *other* languages fixing this when they started with logical operators, they all copied C's precedence and associativity tables. (except of course for special PHP that managed to botch associativity of ternary operators, that now everyone with PHP is stuck with as a fun surprise gotcha.) But claiming there is no good precedence table, and no one should be expected to learn it, is absurd. This isn't some protectionism of trying to keep programming arcane and out of the reach of mere mortals: young students in math classes everywhere learn that multiplication and division happens before addition and subtraction. Programmers should learn precedence and associativity as a basic competence in their profession. Really, it only takes an hour with flash cards. Then repeat it a day later, then a week later, then a month later, and you won't forget it. Worst case, print out a little cheat 3x5 card and look at it for a few days. Seriously, parentheses are a crutch like looking at the lettering on your keyboard instead of committing to learning to touch type. Whether anyone here agrees or not, other programmers *will* omit parentheses, so you need to learn it regardless of how passionately you feel about it. Of course, this would cause a little confusion if someone were frequently programming in several languages with very difference precedence tables. But I still think other languages shouldn't have copied C's mistaken oversight from 40+ years ago. Just saying, "Is it C? Treat bitwise operators as having stupid precedence. Otherwise, use standard precedence." wouldn't have been much of a cognitive burden. FWIW, I don't go too crazy with omitting parentheses in my codebase, but you are expected to know that in C/C++, mul/div/mod &gt; add/sub &gt; shift operators &gt; comparisons &gt; bitwise operators &gt; logical operators.
They are nice for the streams, but my main-focus in that statement is actually on ranges. I would assume that the number of jobs where you are working more directly with the bit-operators than with containers and sequences is rather low. 
&gt; You may as well point out that the -&gt; symbol now has two meanings in C++ (postfix return types and pointer member access). good point :) the meaning of the -&gt; symbol has completely changed. &gt;&gt; They're only "bitshift" operators to C programmers. that remains their default use, and c++ gets used for low level cases where you do still use bit shifts to pack/unpack values, decode compressed pointers or whatever. **I consider it an open issue**: now that we have *variadic templates*, I'd prefer to kill off those streaming library interfaces off. Lets say ```file.write(a,b,c,..)``` instead of ```file &lt;&lt;a &lt;&lt;b &lt;&lt; c```... if anything, free up the chevrons for yet another use like the monadic chaining stuff from haskell. &gt; Pointing out that other problems exist is not justification for creating more! i point out how those problems are not insurmountable. if we could achieve these syntax tweaks, we could make c++ easier to use. if we don't modernise it, the next generation might want to kill it off altogether. It looks *fugly* after exposure to modern languages (so I can fully understand why people learning programming for the first time want to purge it from the earth), yet I still prefer its semantics (whilst I find rust looks great, it's a pain in other ways. it goes *too* far in discouraging raw pointer use, e.g. having to write both *mut or *const , having to cast twice, reserving [] for *safe* arrays all the time, and the go too far declaring overloading a misfeature so you must micromanage a cats cradle of traits for generic code)
&gt;Originally the bitwise operators were also used for boolean logic. Or at least that's what I've heard. IIRC they were used that way in C's predecessor, B. B had 32-bit ints as its only type - you could dereference them like pointers, used them as bools, and string manipulation required special functions - you couldn't directly index characters, they were packed 4 to an int, which is also the reason why you can put up to 4 symbols in a "character constant", getting back an int which contains all 4 characters, in C. The fact that "everything is an int" in B is also the reason for C's "implicit int" behaviour, where a variable is assumed to be an int if the type is omitted. C is largely compatible with B code because of these insanities.
&gt; I refactored a +=1 into a ++. Like, why?
404
Compilers optimize quite a lot and they are very efficient in doing that. But I think you shouldn't **rely** on any of these optimizations. For a small snippet like this you can simply investigate the assembly. But for actual production code that's not possible. Also remove the benchmarking code from the assembly.
I am not talking about valgrind/asan/ubsan/debug, I am talking about the tools the language itself offers. 
According to Dennis M. Ritchie (https://www.bell-labs.com/usr/dmr/www/chist.html ): &gt; Rapid changes continued after the language had been named, for example the introduction of the &amp;&amp; and || operators. In BCPL and B, the evaluation of expressions depends on context: within if and other conditional statements that compare an expression's value with zero, these languages place a special interpretation on the and (&amp;) and or (|) operators. In ordinary contexts, they operate bitwise, but in the B statement &gt; if (e1 &amp; e2) ... &gt; the compiler must evaluate e1 and if it is non-zero, evaluate e2, and if it too is non-zero, elaborate the statement dependent on the if. The requirement descends recursively on &amp; and | operators within e1 and e2. The short-circuit semantics of the Boolean operators in such `truth-value' context seemed desirable, but the overloading of the operators was difficult to explain and use. At the suggestion of Alan Snyder, I introduced the &amp;&amp; and || operators to make the mechanism more explicit. 
They are essential for type computations (like implementation of std::common_type). I used sum as an operation on integers only for demonstration purposes. It is easy to understand and test.
L1 Instruction cache, Misses Per Kilo Instruction over the roof... Templates aren't free
&gt; This time the second version is about 2% faster, certainly because the execution doesnâ€™t always reach the inner if. Shouldn't short circuiting in ``&amp;&amp;`` behave the same way? If half the calls to ``getNegative`` were being avoided by only one version, you'd expected an almost 25% performance difference. [edit] Tested there changing ``&amp;&amp;`` to just ``&amp;`` which doesn't short circuit and it is a lot slower.
And, no word about the possibility to use string_view to avoid implementing over 9000 overloads of functions/methods if you have several types of strings in your project, like std::string, QString, CString, whatever else is out there. For example, recently I had to implement just the same logic two times: for std::string on server-side in linux, and for CString on windows/ATL client. Tho if we had c++17, I could avoid that.
Lucky you! I'm using gcc 4.3 :(
&gt;The C programming language - and thus many derived languages - has a great example of â€œbad precedenceâ€ that annoys me anytime I use it. The precedence of the binary bitwise operators (&amp;, |, â€¦) is lower than that of the comparison operators (== or â€˜&lt;`). &gt;I donâ€™t know why and I hate the decision. This is indeed borked (for my definition of borked :-)). What were K&amp;R thinking? *Any takers?* **Anyone?**
One thing I've learned over the years is that my code, once compiled, looks **nothing** like what I actually wrote... Like, not even remotely in some cases.
&gt;Templates aren't free Err.. you need to do some reading.
Wow. I would have really liked that, though I'm not surprised that it was removed, given that it would break some existing code. That said, there are other languages that implement it that way. In Python, `a &lt; b &lt; c` is equivalent to `(a &lt; b) &amp;&amp; (b &lt; c)`, with the addendum that `b` is computed only once.
Which of these is the more understandable if statement?
This is compiled with `-O0`, which is "disable optimizations". There is no surprise the code is suboptimal. 
Not forgetting raw strings if you want to be efficient (it's a waste to instantiate a heap allocated std::string etc for literals).
Huh? It is an inequality, whose meaning is boolean. Of course `3 &lt; 4` evaluates to true, mathematically. And that xkcd is totally unrelated to this discussion... there are no competing standards - there is the C++ standard today and there is the C++ standard that we might, or might not, want tomorrow.
and you expect us to click that link?
So you do constant substitution, function inlining, loop unrolling, variable re-use, register spilling, memory access coalescing, inter-procedural instruction re-ordering, *et c.* yourself? Your code must be pretty hard to maintain.
&gt; But for actual production code that's not possible. How not? This is perfectly possible.
I always though the reasonable thing to do was to structure if's in such a way that it relates to the logic of your code. if(x &amp;&amp; y) if x and y are related if(x) { if (y) { if x and y are not necessarily 'related' or if there is an else after the if(y) statement. So for example: if(condition_is_meet || debug_flag_on) Seems more correct than two separate if's. Benchmarking if outside of a performance critical section code seem silly, and even then, if you are nitpicking if performance your actual problem is probably the fact that your code is no parallelizable onto multiple machines... 
Thank you!
Thank You all for your questions. Here is the Interview - https://www.mappingthejourney.com/single-post/Interview-with-Bjarne-Stroustrup
I apologize and thank you for the feedback. Can you please check now?
The takeaway is to not worry about these things; just compile with optimizations on. Code should be written for readability.
Great. I've enabled `_GLIBCXX_RELEASE &gt;= 8` as the current library-based solution in libstdc++ &gt;= 6 is log(N), but still much slower according to my measurements. (1.7s ours, 7.6s theirs for `std::make_index_sequence&lt;100000&gt;`)
Sometimes this is true, sometimes it is not. A good example, is trying to use a branch to avoid modulo division by a runtime integer, which can be a reasonable thing to do. If you code the modulo without a branch, it doesn't generate a branch. If you code it with the branch, it generates a branch. The code does the same thing in all situations, yet how you code it produces different assembly. Compilers will often default to generating assembly more similar to your code if they can't reason convincingly from a static perspective as to what is faster.
All these optimizations require specific conditions that the compiler carefully evaluates. Loop unrolling (for instance) in gcc is done for small loops &lt;= 3 iterations. Anything bigger is not unrolled, unless you specify a compiler flag. Same applies for function aligning or reordering: you know that the compiler does these things, but can't really tell when and why. Don't get me wrong you shouldn't do any of the optimizations by your own. Just don't write code based on the assumption that "the compiler will optimize it".
Exactly my thoughts. The logical AND is more readable. If the point of the IF is "do the following if BOTH this and that are true", then that should be right in the IF. Separating them into two lines is NOT more readable.
Enligth me, please 
in the example he gives the cv qualification of the argument doesn't matter the function isn't actually called no matter what.
I know, because he's using a string constructed from a literal (and with optimizations enabled). The compiler cannot guess the length of a string he doesn't know the content of. So if you read the string from a file, and call the function on it, does the fact that it's a reference to a const string_view change anything ?
This may just be related to branch prediction. With -O0 optimisation branch prediction may behave differently for the conditionals as opposed to when there is a single statement to evaluate for the if.
Oh, OK. Whatever then.
Looks interesting, but just a forewarning to anyone else, you have to disable ad block, pay to download the videos, and pay to download the project resources. 
let me follow up with Art and the team. sorry about that.
In AFIO v2 page, links to bost.custom and boost.outcome are bad
thanks. i'll look into it for sure.
Do you know why that loop was in the code at all? Like what was the original author reasoning?
I suspect it was due to madness ;) Seriously, i think someone might have had a misconception that signal could cause pthread_mutex_lock to wake and break things.
It seems more like it is there for debugging purposes. 
I must add that trying to do the micro optimizations by yourself may get in the way of the compiler, resulting in hard to read and also slower code. Doing them without running a profiler and measuring results is just a waste of time. Not even mentioning a change may make it marginally faster (less than 5%) for certain CPU model, and slower for everything else.
I'd have expected the extra line in the if version were that the case (because the source has more statements) but it's in the &amp;&amp; version!
If it is Windows only, then it has a pretty big dependency; Windows!
You're likely to be more affected by poor command of the English language. 
!removehelp!
No, YOU need to make a concrete claim. 
Because `&amp;` performs `binary and` on values on both sides.
plausible since i am not sure what i wrote wrong.
but i am discussing c++? 
It's entirely possible, with limitations. The simplest answer is to use `std::function` instead of pointers to wrap both the job function and the job payload. A more complex answer that might be more amenable to your situation is that your pre-allocated `JobInfo` can include a buffer of space for storing arguments. If you require that those arguments are trivially destructible (and I'd `static_assert` that they are), you're pretty much done at that point. If you want to support non-trivially-destructible types, you need to also store a thunk to a deleter function that can invoke the destructors. You can take this a step further and use that buffer and thunks for handling the actual function to invoke, too, basically just like `std::function` does under the hood, allowing users to just bind lambdas as jobs, giving you an interface like: `spawn_task([value]{ do_something_with(value); });`. The advantage of rolling your own for this use case is that you can guarantee that no extra allocations or excessive function dispatch overhead is present. The `delegate` type we use for instance guarantees 3 machine words of space for payload and `static_assert`s if more is used, letting us use clean and simple lambdas; if anyone needs a bigger payload, they can allocate it themselves and pass it along in a smart pointer, which is preferable just because it makes it explicit and obvious that an allocation is going to happen rather than hiding it away and doing it implicitly like `std::function`; plus the buffer size is guaranteed rather than being an implementation detail like the SBO many `std::function` implementations employ for small lambdas, so we get consistent portable behavior across all compilers/stdlibs and platforms we potentially have to port to.
It depends which one best represents what we're doing. If there's nothing to do in either of the individual else conditions, then the logical AND is the simplest. If they each have an independent meaning, and there's other things that need to happen inside the first condition regardless of the condition of the second, then nested is the most understandable. 
What formatting markup do you use for the boxes around some of the text?
"my meritocracy"... maybe try "proficiency". 
Guess i should really check for auto correct mistakes. thank you i will change it to: &amp;nbsp; "can one's c++ proficiency level affect someone's ability to transverse the ladder in the computer information system field"
Yeah. No. You're screwed. 
I post for discussion and advice, and you reply with short non helpful replies. I would appreciate some advice if you have any, if not good day sir or madam.
Maybe understand the meaning of words before you use them. Like, "transverse". 
whats wrong with saying across the ladder?
The author of one of the proposals talks about it [here](https://www.youtube.com/watch?v=TZs8b3FGo5A) as one of the things he most wants to get in to the standard. It seems there is just a lot to get through and not enough volunteers right now.
Transverse doesn't exactly translate to across. Also it is "move up the ladder" not across.
/u/johannes1971 what Version are you running of Checkpoint? our understanding is this is fixed in E80.61+. 
Look at WG21 papers list. Proposal P0707R0. Metaclasses, reply to: Herb Sutter (hsutter@microsoft.com). If that is not enough for you look at chapter 4: "Applying metaclasses: Qt moc and C++/WinRT". C++/WinRT and C++/CX are explicitly mentioned several times in the proposal. We have some ground breaking features - Modules, Concepts, Ranges, Coroutines all planned for C++/20. Maybe Reflection. That is a good list in my opinion.
I see their point then, in that case I did use it wrong . I meant for it to mean across. (i get that it sounds weird, but I mean it in the way of i will take whatever job pays the best even if it means going "down" the ladder. I have a friend who got an offer from a rival company to get paid more for a lower position job, and he struggled on if he should take it because his goal is to climb the ladder. On the other hand, I plan on doing something completely different so i would have taken the offer easily unless of course the company was in danger of going out of business in the near future or something) &amp;nbsp; I know the saying, but this is just my secondary major so that I can pay for school for my main one. I will put in the work to do a job well but I am definitely do not have plans to to spend decades in this field. (school counselor at my school actually push the it fields for students who want to take art, psychology, archaeology, fashion and etc)
My claim is code size will harm I$ locality (specially in some of the examples listed). Make yours... How the compiler avoids that? I$ misses will hurt badly... (a.k.a. front-end stall). 
Thanks for the report. Yes, I know, AFIO v2 is currently being refactored to use post-Boost-peer-review Outcome v2. It's some weeks away from compiling cleanly, but when it does the docs will auto rebuild themselves with fixed info.
What exactly are you saying? Are you criticising the article in some way? I don't know what you want anyone to say in response. 
Using templates is not necessarily increasing code size. Especially if you are using TMP to calculate values at compile-time, this will **decrease** code size and hence make the code faster. Even some people in the embedded world are finally using C++ to generate shorter code with these techniques.
This is _removing_ instructions and replacing them with pre-computed data.
Does the compiler not warn here? The de-reference does nothing.
Got it. I misunderstood your first comment, thought you were forced to write shit like this... :)
Seems completely reasonable. Binaries are great for distributing to end-users, but I'd much rather have the source code available for poking at whenever a question comes up.
This led me to no end of trouble when designing C++ bindings for Lua. When storing a C++ object, I would stash a `void*`, which would later be cast back into the original type. Worked fine, until I wanted to support subclassing. My initial implementation checked whether the output class was a subclass of the original class, which failed hard when there was any sort of multiple inheritance involved. I ended up making each class definition include a `void* (*)(void*)`, to cast a `void*` of the type into a `void*` of the parent type. Still haven't gotten around to supporting full exposure of multiple inheritance to Lua, but it does handle exposing one of the parent classes of a class that uses multiple inheritance.
use ` around the text. For example, \`this\` becomes `this`
All I can say is that picture is colorful.
Because `const` behaves different for pointers whether the asterisk is left or right of the type identifier (https://www.youtube.com/watch?v=7arYbAhu0aw) Also, for passing into functions and other things, the compiler needs to know the type.
Off on a bit of a tangent here, but the C and C++ standards specifically allow for having a larger address space this way. E.g. if `int` is 4 bytes and has 4-byte alignment, then you could have a 32-bit pointer that addresses 2^32 ints, or 2^34 bytes. I don't know if any compiler/architecture combo has ever taken advantage of this opportunity though.
So MSVC makes trivial lambdas trivially destrctible; clang didn't last I checked. So you may want to do the destroyer trick at thr cost if the extra ptr. MSVC std function SBO two std strings; that is a bit bigger than 3 machine words usually
Most C++ STL implementations (libc++, libstdc++ &amp; even MSVC's STL IIRC) allow compiling with exceptions disabled.
Not to mention security! Downloading binaries from a third party creates a trust issue. Downloading and compiling source code does too, but it's a lot easier to identify malicious tampering and a lot less likely to actually happen.
Thanks, that'll be handy.
&gt; So MSVC makes trivial lambdas trivially destrctible; clang didn't last I checked I think I'm using that trick with all the right `static_assert` checks on Clang 3.9, but maybe I'm not recalling correctly. We generally use and require support for non-trivial function objects though so maybe we just got rid of all the utilities that only handled trivialness and I forgot. :) **edit**: at least a quick check indicates that I'm probably not crazy :) https://godbolt.org/g/f7es3f
The very reason why boost is such a heavy dependency is the fact that we don't have a package manager. Look at all the other languages with nice package managers. A simple project depends on a thousand little libraries.
You only really need one reason: *cross-platform binary C++ distribution does not work.* There are just too many variations: [ABIs](https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html), runtimes (`libc++` vs `libstd++`), exception handling protocols (e.g., on MinGW), etc. If you are the author of a reasonably popular C++ library your choices are source distribution or spending endless hours on the mailing list helping people with compile/link/runtime errors. Yes, sometimes things don't work at *runtime* and only in certain conditions, like throwing an exception across library boundaries that happened to use different exception handling support. And to preempt the inevitable "using system package manager just works" remark, no, that blows up spectacularly as well: [here is a bug](https://bugs.launchpad.net/bugs/1588330) in Ubuntu 16.04 LTS that tripped that GCC ABI issue and took about 6 months to fix -- all the while I had to keep answering the same question on the mailing list over and over again. Also, I think better answers to the slow from-source build problem are C++ modules and distributed compilation. Caching only gets you so far since someone still has to build the entire thing for the first time.
Asking this in /r/cpp will be a little biased ;) First figure out what your goals are. If you want to do web development in future, then there's no point in learning c/cpp/java at this moment. If you want to do other software development, then you should choose b/w these. C is still in demand very much where embedded stuff is done. Cpp is in demand particularly for making games, high-perf server backends, maths + physics stuff etc. After this, it depends on where you live and how rich ecosystem many job opportunities you have there.
Quick, somebody make the same thing, but *entirely in the preprocessor* 
Modules don't go far enough. The committee has (had) the opportunity to solve ABI/platform problems with modules, and they totally ignored this aspect. Let's hold our fingers crossed for C++50. Btw, has anybody tried to transport LLVM bitcode files across platforms, compiling/optimizng them on the target machine and running them there? If this is a viable approach, why not build cross-platform binary c++ distribution based on LLVM bitcode?
I think I'll be able to work with C or C++ for the rest of my career. Being able to integrate C and C++ with Java or the various scripting languages also seems like a reasonably good skill to have. You could branch out from there to Android development quite easily if you're really hard up. It really should be what you find most interesting, though.
Click on "formatting help" at the bottom (right-side) of the reply box.
Even though I hate building boost, I completely agree. 
Tried to get it to work for an hour and gave up in frustration, error loading plugin. It would be good if this was packaged for more than Windows.
LLVM bitcode is not like other bytecode formats, it contains machine specific architecture info. There are some attempts to make it portable, specially given its use in iOS and watchOS apps, but nothing relevant so far.
ABI is only part of the problem. What if I ship my module compiled against `libstd++` but you want to use `libc++` in your application? Should there also be a single standard library implementation?
Is signing binaries (or anything) rocket science? I really fail to see a big plus there. If trust is a problem, then signing is a decent answer (for either binary or source).
&gt; The committee has (had) the opportunity to solve ABI/platform problems with modules, Solving the ABI problems would require an in depth specification of every standard library class, which would make all current implementations of the C++ standard library invalid. It would also require an in depth specification of the exact memory layout of every C++ language construct and calling conventions. Everything about that is great when your "cross platform" code runs on x64 or you plan to distribute it with a JVM lookalike. 
Signing the binary you are about to distribute doesn't do much good if your compiler already infected the binary with a malicious payload. Distributing source code (signed or not) allows for the recipient of the code to do their own analysis of the code versus the resulting compilation output and make their own conclusions. There was a research paper at some point detailing a way to avoid malicious compilers by recompiling compilers with other compilers in a specific algorithm, with some cross comparisons to detect likeyhood of malicious payload. Sadly I don't remember the name of it at the moment. 
I was one of the first thing i deleted when i inherited the codebase ;)
I was like you and I tried to be a purist by learning the good old K&amp;R C with its Bible. My advice is to learn C++ instead because you'll learn good C at the same time. The only thing you'll miss is the memcpy that I use daily and that I despise because it's a source of bugs. Web development is very specific and I don't do that nowadays because it's very restricted. I know that there are a lot of languages for the web (Python, Ruby, Perl, even C++ frameworks) but most of the time it's limited to "the web" and that's why I don't really like it. With C++ you can program smartphones, TVs, servers, multimedia stuff, and any kind of application (business, cars, embedded or not). &gt; Is C or C++ still in demand? Yes, I started working in 2005 and have always done C++ one way or another. Java may be used for enterprise or Android, and scripting for various tasks, but C++ will stay for a long time especially with the new versions. C++98 was the standard but when Stroustrup (and his friends of the standardization group) woke up and started to write new specs, we got C++ 11, 14, 17, and now 20. It's almost like a new language and will be used for a long time.
&gt; they've been bitten before by implementing not quite standard stuff that got dropped at the last second by the standardization committee... filesystem,,, changed a bit and now they cant fix it without breaking compatibility IIRC
Obviously, the answer is predetermined by the subreddit. The answers can differ only in the arguments. I will be brief and just give a link to [talk](https://youtu.be/YnWhqhNdYyk) that contains a lot of arguments at once.
VAX had an [update](https://blog.wholetomato.com/2017/03/14/visual-assist-build-2210-is-available/) that adds code inspection and suggests ways to modernize your code. It is still pretty barebones but a step in the right direction imo.
&gt; Distributing source code (signed or not) allows for the recipient of the code to do their own analysis of the code [...] I wonder how often this happens in practice. For example, does anyone actually study a diff for a new version of, say, Boost and Qt to see if there is anything suspicious? 
They're pretty must identical, behavior wise. You should default to passing string_views by value since they're small and should be trivially copyable. In most ABIs will make it the same as passing `(const char* p, size_t len)`. Try toying with it yourself to see the generated assembly differences: https://godbolt.org/g/bzJC3f 'profile first' still applies, though
It isn't though, is it? If you don't fully trust the *author* of the software. I often encounter freeware or apps from some company which I'd like to use for a certain purpose, but I don't, because they don't release the source. Nowadays you can't really trust anyone to not include telemetry, diagnostics, or even keyloggers in every app.
&gt; Take the famous example of a * b Some would say that anyone using one letter type names deserves what he gets.
There's only one real reason: The vast majority of any reasonable C++ library (one that couldn't be replaced with a few C stubs and a "handle") is contained in the templates, which aren't in the binary -- they're used at compile time. Even with a perfect ABI, templates are about code-generation (from a template amazingly), how are you going to do that at any time other than compile time? I'll grant I'm nowhere near as clever as compiler authors or language designers -- but it strikes me that if there was a way to do it, those clever chaps would have done it already. About the only thing I can think of is that the library secretly keeps a copy of the template source (either pre-or post tokenising) so that the source is hidden when it comes to a library-user "calling" it. But that's just an obfuscation, about the equivalent of minifying JavaScript.
Whilst I agree with the actual reasoning behind distributing as source (indeed, I would say that you'd be mad to distribute a library as binary only nowadays outside os specific niches)... after trying the package manager itself I am disappointed beyond reason. First it asks me to install linuxbrew... shady, but, fine, maybe providing a binary is hard, I will bite. Then I install the piece of shit that is homebrew and the first message I get it: " ==&gt; Homebrew has enabled anonymous aggregate user behaviour analytics. Read the analytics documentation (and how to opt-out) here: http://docs.brew.sh/Analytics.html " ... yeah, no, fuck this brave new world of innovative package managers. I will stick to my pacmans and zyppers and downloading C++ library source code from github and sourceforge.
I prefer use library as source code. For example, `-fsanitize=memory` option won't work unless you build every shared/static libray and libc++ have been built using that flag.
Try [`build2`](https://build2.org/), all you need is a C++ compiler.
Hi @George3d6 The Linuxbrew installation process is optional. We also offer a Debian package, and you can always build from source. The instructions are here: https://buckaroo.readthedocs.io/en/latest/installation.html#linux 
Nice too bad 98% of where I work are stuck with VS2005
&gt; It would also require an in depth specification of the exact memory layout of every C++ language construct and calling conventions. so you mean [like this](https://itanium-cxx-abi.github.io/cxx-abi/) ? also, it won't solve any problems. If lib A is compiled with -DSAFETY_CHECKS (which modifies the ABI) and lib B uses lib A and forgots to add the flag, you're doomed anyway
Git does it for me when I pull new commits :) *But yes, I don't double check if the url is the right one and not compromised.*
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; I believe that there are some languages that already Python does. `a &lt; b &lt; c == d &lt; e` is equivalent to `(a &lt; b) and (b &lt; c) and (c == d) and (d &lt; e)` though it will evaluate each expression only once.
&gt; Should it be translated into something like this? That is what Python does yes: &gt;&gt;&gt; class V(object): ... def __init__(self): self.v = next(c) ... def __lt__(self, other): ... print self.v, '&lt;', other.v ... return True ... &gt;&gt;&gt; V() &lt; V() &lt; V() 0 &lt; 1 1 &lt; 2 (note how the RHS of #1 has the same id as the LHS of #2, it's the same object).
Smalltalk is similar although: * it is strictly LTR, not RTL * there are actually 3 levels of precedence in the langage: unary messages, binary (operators) and keyword And obviously concatenative languages (stack-based) don't have precedence either.
Question: if the operator precedence of .* and -&gt;* were changed to be higher than (), would that break any code? I can't imagine that it would, because all the working code is currently in the form (x.*y)(z), which is the same either way.
Beautiful! *wipes away a tear*
On the other hand, taking a&gt;b&gt;c, that means "if I match an a, then expect a b, and then expect a c." In Boost.Spirit, that is. This stuff shouldn't be hard-coded in. It's too useful as it is. Operators aren't just maths.
Git studies diffs for malicious code for you? Do tell where I can get this wonderful version. Because mine surely doesn't.
Ada, ML and CLU solved that problem a few decades ago, it is called modules/packages.
That will tell me the markup I'm looking for? Are you sure about this?
No argument there. I wouldn't suggest to chain all operators named `&gt;`. Just the ones that return `bool`.
You code becomes platform specific as soon as you run a preprocessor, cross-platform bitcode wouldn't help.
&gt; reasonable C++ library is contained in the templates Isn't that oxymoron? 
It's a domain-specific language embedded in C++. DSL's in C++ have been done before and even praised (ex: Boost::Spirit). I'd say you haven't as long as: * The syntax doesn't invalidate other typical code OR the code is only used in limited files. * The library is maintainable. (I haven't looked at it, so I wouldn't know.)
You just need to take one more step: click on the "Markdown" link. 
Not sure, and I won't be home until monday so I cannot check right now. But it's a bit of an old laptop, it probably doesn't have the latest Checkpoint installed. I'm not at all surprised that they broke things though. Checkpoint seems to be the cause of the majority of problems I run into :-(
Either `std::string_view` should allow implicit construction or implicit construction of `std::string` should be removed because it makes no sense to allow it for `std::string` but not `std::string_view`. I'd actually prefer the latter option but have no hopes of it ever happening. 
Is Marshall and @mclow the same person? How does his feedback have any bearing on whether or not implicit/explicit constructors is a good idea? Just trying to gather the context. More questions: It seems like you're trying to prevent issues with lifetimes of data, by declaring constructors that accept non-static data as `explicit`, correct? Can you outline some exact situations in which this problem could arise? It would be nice to have some examples to talk about. The way I see it is that any function today that currently accepts a `const char*` as an argument should be able to accept a `std::string_view` instead and have the exact same semantics. Currently, it is never expected that a function accepting a `const char*` will hope that the string will live much longer than the function call itself unless documented. Usually such functions will retain a copy of the string if it's needed somewhere after the function call is over. Any function that violates this expected behaviour is in the wrong. If the function changes to accept an `std::string_view` instead, the expectations don't change. The function should still not expect the data pointed to by the `std::string_view` to outlive it. Therefore I don't see the benefit to making someone explicitly aware that they are creating a `string_view` from dynamic data (by making them construct them explicitly). I don't see a case where data in an `std::string_view` should be expected to be anything more than transient, but perhaps you could enlighten me.
&gt; template &lt;size_t L&gt; constexpr path_view(const char (&amp;v)[L]) noexcept : _state(string_view(static_cast&lt;const char *&gt;(v), L - 1)) {} I've been hesitant to do the same in my string code, mostly because that will have non-intuitive results when being constructed from a character buffer; it'll bind length equal to the size of the whole buffer, not the size of the string within it.
Git provides: 1) Crypto verification that what's in the repository that you're downloading from is what's now in your repository. 2) A relatively easy to use diff viewer that allows you to see what's changed between what used to be on your local repo and what's there now. For projects that you're serious about tracking, it's possible (though time consuming) to inspect the project line by line at some point, and forever after do a careful line-by-line inspection of what's changed since you last did a git-pull.
I use Resharper on quite a big C++ project and it became much less memory consuming as of late, after finishing parsing it stays in acceptable 400-500 mb usage. But 32-bitness of Visual Studio is a problem in itself for such case of course. I used VAX but their speed of adding new features and fixing bugs was too slow and Resharper devs fixed most of its issues relatively quickly. The biggest hassle I have with resharper is that renaming function with names which are common throughout the project sometimes rtakes several minutes. A lot of time I end up renaming them manually.
I agree. Gonna see where this goes. If it turns into nothing I always have the basic syntax to fall back on. I don't get to do shit anything like this at work. I use a template and people get freaked out...that's what "real" C++ dev work looks like. I also get a bit concerned when operators don't have their usual semantics...but if it's in a specific area for a specific purpose with its own idioms that can be understood, then cool. Maintainable... right now I think it is. It's unusual, but I managed to keep parts fairly simple. Will have to see what happens when I begin to expand on it.
&gt; Just imagine a language where a + b * c is (a + b) * c! There will be bugs everywhere. [I don't remember Smalltalk being that buggy... :-)](https://goo.gl/84YjEr) For the ones not in the loop, Smalltalk have a direct approach to precedence for infix operators: left-to-right, so 1+2\*3 is ((1+2)\*3) = 9. There is zero ambiguity :-)
Depending on the project, I actually do do this. *shrug*. Not all projects, not even most projects, but it's certainly an activity that I've undertaken more than once. For distribution maintainers, especially for source-based distributions such as Gentoo, there's a significantly larger incentive to inspect the source code differences between package versions in order to keep track of bugs and other such issues. When I update my machine, I have the confidence that I can go and inspect the source code used to compile the package, and that the source code downloaded has the same hash as the code used by my distribution maintainer, and that everyone else using Gentoo is probably using the same source with the same hash and also has the ability to inspect the code, and that it's much more likely for someone to raise an objection to something in the source that they can read as a human, versus a windows executable that presents a much larger barrier to understanding the internal workings. With enough eyeballs, bugs are shallow, or something like that.
Re the UTF-8 comments: are you imposing a requirement of UTF-8 as execution character set (encoding), and if so do you have a compile time assert of that?
The more clever template meta-programming tricks I see, the more I believe the language should be extended to support these features in a natural, easy-to-use fashion. I'm starting to feel like template meta-programming, while intellectually gratifying, is just a crutch that prevents real language enhancement from occurring. Why should a developer have to understand these contortions to use them?
It's technically possible. Consider `obj.*func(arg)`, where `func(arg)` calls a function (either a non-member, or a member within the current context) with an argument, and that returns a PMD. In practice, this won't occur.
Not my fault that retard didn't learn to code in 25 fucking years. That piece of shit things there is something like "C/C++" what a fucking idiot. And not surprised at all that imbecile is a "Christian".
but is the compiler smart enough to realize about that? My understanding is that C++17 "constexpr" is there to help the compiler in doing it, right? If with metaprograming you can do the same, why is "constexpr" in the standard?
Note: this entire post is written as I watch the video. So far(3rd example) this seems like a much more powerful/easy to use CRTP. On the other hand though, given we could specify our own meta rules for the classes, it seems a lot like everyone's first examples into operator overloading.. e.g. a lot of the meaning behind classes/operations gets hidden and kinda black magicy. This will clearly go away with time, but it definitely appears it will increase the learning curve substantially for projects using this feature, although any kind of meta functionality will do that anyway.. Rambling thought: Would it be possible to use this feature to force two member functions to have similar side effects? e.g. packing/unpacking a packet or storing/reading data from a file? As far as I know currently you have to throw away type safety when passing things to any kind of file/remote connection, so a way of forcing sanity into writing and reading that data would be great. Given we're able to implement our own 'class' types how difficult is it to create ::is_&lt;new_class_type&gt;&lt;&gt; templates e.g. ::is_pod/::is_integral etc. I guess that's just concept though isn't it? &gt;If the user chooses they can break the mold and implement the entire meta type again. There's probably not a saner way to do that currently... It just seems really painful to have to retype and rematch all the now hidden rules in case you have some minor tweak you wanted to make to the class variant. Say you wanted to make an 'interface' without move operations, either you'd have to implement the entire interface again as 'copy-only-interface' (which you should eventually) but for the first while you'd have to fall back to the current way of implementing the interface(s). So I guess that falls into another topic, is it possible to chain these class reflections together? so you could make a base implementation that just marks all member functions as public pure virtual functions, another that specifies the default copy rules, a separate for move rules, and then combine all the rules into one? Apparently yes (about 37 minutes in). Given we all love chaining things an absurd amount I wonder how difficult it would be for compilers to give a mock example of how the classes would morph with the combined rules, aka I really hope the compiler.debug($instance) becomes an official requirement/feature. In any case I think this quickly tops my most hyped potential feature.
@mclow == Marshall == LWG chair == long time C++ maintainer of one of the open source STL implementations == someone with lots of experience in this area.
"view" typically means (in the STL and in the Ranges TS) something lightweight that _refers_ to a thing/range that is elsewhere. Implied in that is "be careful about lifetimes". Does your path_view follow this pattern? Is the rule that the path_view shouldn't live beyond the path/string/chars/etc? If so, in regards to lifetimes, what is the difference in the scenarios/types you have as explicit/implicit? And/or what are you worried about, if not lifetimes? What "accidental" things are you referring to?
Ok... I'll respond myself: Template approach of the first example (clang++ 4, c++17, O3): https://godbolt.org/g/s7KPhB Constexpr: https://godbolt.org/g/nVyqvQ the answer is in this case the compiler realizes about the answer... but a cost. In both cases determines that 500500 is the final computation... but the code of the template seems quite larger. 
This is likely the main reason why `string_view` has the overload set it does. Good point. I really wish one could place `requires` on an overload's availability based on its input being a compile time expression, this would let one not accept runtime char arrays.
1. You take *one* example -&gt; obviously some cases do generate additional code, others won't. 2. Use a fold-expression with C++17, compare the compile time with your constexpr: https://godbolt.org/g/7y61JX 3. Avoid recursion, see my answer to OP with https://github.com/taocpp/sequences - this can significantly reduce the costs. If you don't have C++17, my library can help with a `sum&lt;&gt;` that works with C++11 and without recursion. 4. Other libraries can also help reduce the cost, e.g. http://github.com/kvasir-io/mpl 5. `constexpr` is useful in some use-cases, TMP in others. Sometimes both can provide a solution, sometimes the right library helps. EDIT: Yes, the compiler must realize that. The example template *must* generate a compile-time value.
Filesystem paths are treated as a bag of bytes with `memcmp()` used for comparisons (with a few exceptions currently being undone e.g. ZFS). AFIO therefore tries to pass through original end user supplied byte strings without modification nor copying as UTF invalid sequences are perfectly valid paths. However on Windows, the underlying filesystem character set is `wchar_t`, so where the user supplies a `char` path view, we need to convert that to `wchar_t` before handing it to the kernel, and in that sole situation alone we ask the NT kernel to interpret the byte string as UTF-8 in order to generate UTF-16. We cannot place compile time or even runtime asserts regarding that char input as malformed input is a valid path, and it is entirely up to the NT kernel for it to decide how best to interpret invalid UTF-8 i.e. it's buried in a syscall, and may change over time. Sorry for the long answer, `afio::path_view` takes a very different approach to `filesystem::path` in that it is always input preserving with conversion done just before the syscall, whereas the Filesystem TS converts on construction. Very different design. But it means the end user is not burdened with ifdefing everywhere to handle `wchar_t` string literals, as the Filesystem TS ends up inevitably forcing on you because on Windows it treats char strings as ASCII, not UTF-8 :(
My first instinct initial design above was intended to maximise implicit construction from compile-time only data sources, and make runtime data sources explicit. Precisely due to lifetime concerns. But Sean makes a great point about char arrays on the stack. You could provide a static asserting overload for non-const sized arrays to trap attempts to use those, but in the end all this mess is due to the continuing lack of the `is_compile_time_evaluated_expression(expr)` trait. If we had that, we could do so much better than at present.
He also was the lead `string_view` advocate at WG21. Most proposals which make it past LEWG usually have a "champion" regularly attending WG21 which gets them into the standard. I will have to suck it down and start attending WG21 meetings from 2018 onwards precisely for the same reason, it's so very expensive for me, but it needs to be done if I have a chance of getting Outcome into the standard.
Two points I noticed while reading your comment : * The paper [P0707R0] demonstrates the possibility to makes your metaclasses inherit from each other to combine behaviors as you are suggesting. * Also, a simple `static_assert` on a `std::is_interface_v&lt;T&gt;` template variable wouldn't allow you to tailor specific default values and auto-generated member functions like the proposal does.
&gt; Therefore I don't see the benefit to making someone explicitly aware that they are creating a string_view from dynamic data (by making them construct them explicitly). I don't see a case where data in an std::string_view should be expected to be anything more than transient, but perhaps you could enlighten me. What C++ currently lacks, and Rust does very well with, is language support for determining if some data source has infinite lifetime or not (i.e. is static storage, or is constexpr generated). You can construct a trait which does a set of heuristics like `std::is_trivial&lt;&gt;` etc to figure out if a data source *probably* has infinite lifetime, but the problem is that the compiler is not required to execute `constexpr` code at compile time if the products of that execution are consumed by runtime code. Because this is not required, you end up in a no man's land not knowing for sure about lifetime. That precludes a bunch of potential optimisations, and makes you enforce much more pessimistic design through an abundance of caution to prevent inadvertent lifetime issues. And that's unfortunate. My Google Summer of Code student Tom ran into the exact same problem of lack of `is_compile_time_evaluated_expression(expr)` in his StaticViews subset of the Ranges TS where he can accept `static constexpr` input, but he cannot accept `constexpr` input for some really fun reasons buried in the minutiae of the C++ standard (and reasons almost certainly not intended by WG21, but hey, we're pushing the standard into new places in that project). If he had that trait, he could do much better than pages of very abtuse error messages with a totally not obvious cause: "you're missing static storage in your constexpr input!". But he can't take the direct route, so we're going to have to do an evil brittle and compile time damaging hack. Sad panda :(
How long do we need to wait until this gets standardized? Maybe it doesn't actually need to be - as long as 2 out of 3 (GCC, Clang, MSVC) choose to implement it, it becomes de facto a C++ feature. I hope to see the day coming that we no longer need to wait for the standard committee for everything.
Been waiting for this!
Yuck. I love this language. :)
I'm not worried about the member functions so much as easily working on just specific sub-types, but that's mostly done in the concepts feature as far as I understand. e.g.... template&lt;class type, std::enable_if_t&lt;is_value&lt;(some_new_value_type)&gt;&gt;&gt; void func(std::vector&lt;type&gt;&amp; sortable_vec){ std::sort(sortable_vec.begin(),sortable_vec.end());} And be able to easily do things similar to that (but more complicated). It probably does work like what I want (assuming concepts + metaclasses goes through), I'm just really bad at explaining it, or its easier to implement slightly different than how I would by default. I've only really been messing around with meta programming for 2 years anyway.
You'd need something like a new overload for function resolution, to allow specific overloads for mutable, const, and data with infinite lifetime. So now we already have void foo (int &amp;a); void foo (const int &amp;a); void foo (constexpr int &amp;a); // new That would also be useful for making a string implementation that doesn't copy string literals.
Mmm. I'm not keen on adding `constexpr` to the type system. We already have to either provide half a dozen overloads per function, or else use metaprogramming to handle all the multitude of const, volatile, reference etc variations. That said, it's the obvious tack forwards.
Source for the prototype compiler is here: https://github.com/asutton/clang It's not all that stable at the moment, and Herb and I are considering some fairly dramatic changes to the syntax in the paper. I'm also reworking the reflection components too (albeit in a separate fork). Edit: wording and details.
[I couldn't help myself.](https://i.imgflip.com/1t3yfp.jpg) At this rate, people will start [disguising C++ as Java](https://redd.it/6oph5h) or some other crazy feat of brutal language disection and disfiguration. inb4 the metaclass system is Turing Complete, TMP will be complimented by MMP (Metaclass Metaprogramming), and people will start designing metatypes to elevate bugs from types to metatypes, as types elevated bugs from run-time to compile-time. @_@ Jokes and memes aside, this is an incredible proposal, and I am very excited to see where this goes. I thought Herb's [Consistent Comparison proposal](https://wg21.link/p0515r1) was amazing, but this is really something else. Thank you Herb for expanding the horizons of what could be possible in C++ yet again.
Has anyone been able to build the compiler from https://github.com/asutton/clang? I'm on linux and the first error is: ``` ClangOptionDocEmitter.cpp:92:63: error: no match for â€˜operator+â€™ (operand types are â€˜charâ€™ and â€˜llvm::StringRefâ€™) if (Name.substr(1, 3) == "no-" &amp;&amp; OptionsByName[Name[0] + Name.substr(4)]) ``` That error is when building with a fairly recent clang-5. When building with clang-4 I get a different error. 
Considering it requires reification, it's going to be a while by my estimates. Probably C++2c at the earliest in my books.
If you read the blog post you'll see that there are changes recommended by the committee, which means that until there is a more "stable" as in "agreed upon" version, no compiler will implement it unless it's an experimental fork. Wait at least for a more refined proposal, maybe a TS , before big compilers implement anything.
So... some times don't decrease code size, right? I'm not saying that templates increases always code size but some times they do. 1- This is a trivial example. The compiler should be smart to discover that. In real life examples, this will no so obvious for us, therefore for the compiler might be even harder. 2-Compile time is not a good metric... mostly, if you use templates. 3- My constexpr is C++11 compliant. 4.- I barely know C++. Perhaps because of that, I hate templates :-) And I don't trust the compiler... 
Am I supposed to compile Qt libraries?
I build the version on Compiler Explorer using GCC and by pinning the versions of LLVM and libc++ to the versions mentioned in the readme. I have a docker build on github.com/mattgodbolt/compiler-explorer-image (typing on phone so don't have full URL handy)
We've discussed the potential for abuse/overly creative usage of metaclasses many times. I'm pretty confident that this proposal doesn't lend itself to the same abuses as TMP does. You have to consider not only the power, but the expressiveness. With templates, there's often only one very weird little formulation that allows you to do something. Metaclasses seem to allow a more natural expression of intent. Hopefully the more natural formulation of programmer intent encourages better, more obvious designs than what we see with some of the more complex and powerful TMP libraries. 
ml
I think op had a great observation and bad proposed solution. Yes we should eliminate the ability to write confusing expressions. So I would just force the use of () when mixing precedence levels. E.g a + b * c would not be legal, you would need to write (a + b) * c or a + (b * c). However a + b + c should remain legal. Problem solved and there never has to be one true operator precedence to rule them all. I think it could be implemented as an optional clang warning. 
Thanks! Progress! I've built it. Under help I do see: ``` -freflection Enable C++ reflection and metaclasses``` However, when I try to build the "base_class.cpp" test, I get:``` clang-5.0: warning: argument unused during compilation: '-freflection' [-Wunused-command-line-argument] base_class.cpp:11:1: error: unknown type name '$class'; did you mean 'class'?``` I'll try again some more after work tomorrow. Thanks again for the help! 
When I heard of this, I scanned the paper but decided to wait for the video. So I'm watching this pretty much cold and commenting as I see it. At this point I'm commenting at the 10:00+ mark. I leave the RHS vs LHS for a reply because that seems to be a separate and more basic topic. As for the second slide, and the basic idea of $class as presented. **It is like AOP or Emacs/elisp.** AOP or aspect oriented programming was a way to ( conceptually ) implement parts of the CLOS-MOP ( common lisp ) in a safe way. The main attempt being to create a version of java called AspectJ. I don't think people hear much about AspectJ or AOP anymore fopr a simple reason. There were a few things where you could really use it effectively, like shutting logging on or off. But there were a lot of things that you wanted to do that you couldn't dop because it was implemented with a few use cases in mind. Let me give you an example of such things. Would you want to specify actions that the $class action be able to do require order methods are called in a $class? Specify premethod and postmethod actions? Specify specific methods? IOW. Will the ability to define $class to include getting a list of all members? Of all static members? All properties of members and functions such as make_public? How about allowing one to specify functions to have default values? Now the big question, will the committee be able to capture all of these --mmm-- metaspecifications? Will compilers be able to implement them reliably enough? So far we have seen two types of outcomes for this sort of attempts. Something like AspectJ which is crippled because it's limited, or something like the CLOS-MOP which is so general that it is considered complicated by the best of the best of programming. IOW it's very open ended, something which makes me leery. The other example I had in mind was elisp. The language is fairly simple, but writing emacs functions can be frustrating because to accomplish something you really have to go deep into the bowels of emacs and the emacs api, much of which is poorly documented. 
As for the interface vs virtual part, it seems like neither person is very careful in looking at it. In the specific example Shape. Most likely you will be viewing a "parts of parts" heirarchy. So you would want to have a "parent pointer". which would either be a parent shape or null. On the RHS, you specify both in the one declaration. In the LHS you would have derive from Shape call it ShapeWithParent. Then you would get exactly the same errors looking slightly different. You have the right hand side with finer granularity ( being able to specify pure method by method ) and a smaller inheritence hierarchy at the cost of possibly a bit more typing ( but not if you have to define RootedShape ) and a different set of errors. It's just a tradeoff. 
Thanks for the thoughtful response. I find this proposal very exciting. One question: I see that .is() and .as() can be used to make metaclasses from different libraries interoperable, but is it possible that this isn't enough? My main concern is that the availability of metaclasses would push frameworks like qt to make their types less and less like standard classes, making interaction of qt and non-qt code even more difficult than it is today. Any thoughts on this?
1. If you have a template function which generates code, and you use recursion, then templates might generate more code. But *never* in the above cases when you use TMP to calculate on either types or values. It is *always* guaranteed to be done at compile time. 2. No, but compile-time is important to make it usable in practice. 3. I can do those things with TMP in C++11 as well - see taocpp/sequences. Yes, sometimes you need a little trick here and there. 4. Exactly. You seem to have a very weird model of how templates work in your head. So maybe don't throw around things like "I$ MPKI over the roof" if it is just hear-say, guessing and FUD. :)
One thought I have about this 23:30 minute mark: how will metaclasses and the preprocessor operate. For example ( in pseudocode) $class OurCompaniesVersionOfClass{ constexpr{ #ifdef testing for( auto f: yada.methods() ) f.accessibility()=public; #endif } ... } 
Maybe we need a generic way to generate all possible combinations as well - at least, when I need multiple versions of the same function they usually end up exactly identical anyway... I think I saw some ideas in this direction here on reddit earlier. Not having to copy literal strings because you already know they are literal anyway seems like a good thing to have.
If you test private functions, you misunderstood the whole point of unit testing. I really hope not seeing this in production code. Btw, you can always use this at this point: #define class struct #define private public #define protected public (Please don't do that)
The preprocessor would always be before.
Declares an array of integers of size two and initializes it to those values?
according to the simplest proposition rule, this is an array of auto(0) and auto(1)
a c-style int array constructed with an initializer list with elements 0,1 :)?
Looks to me like it probably shouldn't compile. A braced init list doesn't have a type, so the compiler generally can't deduce a type from one. 
This looks like: - something that won't pass code review - something that probably should fail to compile - a C-style int array mayhaps? 
How do Metaclasses impact compile times?
"I want to make C++ simpler." Sorry Herb. That ship sailed about 20 years ago. 
`auto x[] = { 0, 1 };` should be equivalent to `auto x = { 0, 1 };`, analogous to how `auto *p = &amp;x;` is equivalent to `auto p = &amp;x;`. `auto x = { 0, 1 };` declares `x` as a `std::initializer_list&lt;int&gt;`. So `auto x[] = { 0, 1 };` should also declare `x` as a `std::initializer_list&lt;int&gt;`. Just kidding.
 Is this flexible enough to implement something like Rust type traits?
&gt; - something that won't pass code review What would be the argument against it?
really not obvious (edit: got autocorrected to "to")
If I were to guess, I'd guess something probably wrong and foolish like an array of two initializer_list&lt;int&gt;. Reason being I know (or at least thought I knew) that a declaration: auto x{0}; Would create an initializer_list&lt;int&gt;
Assign integer array of 2 elements to x
Perhaps not to everyone. It doesn't list the type of the variable, something that should not be done in a typed language due to a lack of readability
The problem in the example you gave is that you wind up with obj owning the callback, which in turn owns obj via a shared pointer, so you have a cyclic ownership. If somewhere in your code was actually keeping a lambda around permanently, it seems to me like it is right for the obj to also remain undeleted.
&gt; We've discussed the potential for abuse/overly creative usage of metaclasses many times. I don't think this proposal would be worth much if you COULDN'T do strange things with it. Part of the power of TMP is its flexibility, and with flexibility comes strangeness. I know that the committee has now spent the better part of 20 years cleaning up after TMP ( type traits, concepts, all that ), but at the end of the day, even without all the clean up, TMP is still worth it. MMP will also be worth it, even though people will do strange things with it, even though the compiler error messages will be tedious.
Ii need some time to digest this. There is something about it all that I cannot put my finger on. I'n the meantime I thought I have to give some sort of summary. I'm disappointed. I thought he had found ways of harnessing the power of MOP with out all the dangers that others who dare to go there encountered. At times he came across as another Microsoftee trying to make C++ look like C#. If all this is about is specifying access of members and certain other properties, then it is way too much complexity for way to little gain. Worse, it destroys locality of code. For those who don't understand, let me explain by a different example. Why do we have lambdas? Because local classes templates could not be used in template instantiation. So you either had to resort to some nasty hacks , or write your function objects far away from the code that used them in nonlocally. I don't want to have to worm my way through code or documentation ( which could be out of date and wrong ) , or use an IDE to tell me if a member is private or public. Now I have only vaguely followed concepts and modules, having an idea of what they are about but waiting for the details to gell. I have not looked at reflection in C++ at all; remembering what the ARM says about RTTI. maybe gaining more information on these may change my mind. I also want to see the implementation of something classx or QClass where some code geneation is involved. One thing. The two people who he used seem to both have come from a background of C# or Java ( lannguages which use interfaces heavily ). Had he done say ST,C then C++ or C,Eiffel, Ruby. OR some other track which did not included interface based languages I would hope that the people he picks for his user have diverse backgrounds. Instead of looking for a guy with ten years experience, maybe a guy with five language experience. Maybe guys with only C++ experience. Or only C experience. 
Erf, meant to right "not" and got autocorrected. I completely agree that it's utterly unreadable.
Better use the C++17 syntax: std::array x{0, 1};
Ill formed programs are easy to validate; they can do anything under the standard!
it was before N3922
interface is simple but meh. value is simple but interesting. QClass is interesting and powerful. A reflectable type, where everything marked automatically generates runtime reflection, is C#esque *but powerful and useful*. I want to be able to do that when I want to do that. Being able to define my own OO dispatch system, and not be tied to the quirks of the particular one Bjarn picked 30-odd years ago, or forced to roll my own as if I am writing C, will be nice. I suspect this will make some easy stuff easier, some hard stuff reasonably posssible. But maybe reflection and reification is enough. 
What a language needs is to execute itself at compile time, in order to allow itself to be arbitrarily transformed.
I'm not sure. I'm leaning towards "It doesn't compile" but maybe `auto` is deduced to be `int`. I was also considering something involving `initializer_list` but then I saw the `[]` and rejected the idea again.
No idea. But trying to guess I would say a C array of ints? Please guys don't write code like that. Use auto only when the left hand side explicitly tells the type. Writing the type doesn't take that long and makes it much more readable and maintainable. ;)
Probably never, on average.
So, all compilers (gcc-7, clang-4, icc-17) fail to compile this, gives a compiler error. What are we supposed to learn from this? If it was valid code, yea, there was something to learn. But I don't see the point of posting random code that doesn't compile.
Metaclass templates don't sound crazy to me. It might help with metaclass composability.
Rust traits serve two purposes: Their primary use is more like "concepts" but they also give you "trait objects" (trait based polymorphism with runtime dispatch). Sean Parent talked about something like this in at least two talks but it required a bit of manually written boilerplate code. With good metaprogramming/compile-time reflection it should be easy to generate type-erased wrappers to support this.. Somehow you'd wanna map a concept to an "interface" at compile-time and automatically implement forwarding. No idea how metaclasses would help here.
Lets see: * 0, 1 clearly contains a comma operator so the value is 0 * arrays decay to pointers, so we have an auto* Clearly x is of type nullptr_t . 
This is reddit... brainless guessing and FUD are important! PD: TAOCPP looks really a great resource. It think cereal is using that JSON library, right? (Cereal rocks!). Those header only things (like Cereal or Pybind11), make me realize how powerful the language is (And that I need to know much more C++ :) 
Do you know what is meant by ownership?
I guess it boils down to safe delete and dereference. In the case of owner_ptr, the safe delete is ensured, while the dereference is guaranteed only if operator bool() is true, and up to the users of the pointer if the operator bool() is false (i.e. non-owning) just like a plain pointer. As shown from the examples above, the safe derefence is statically known even if operator bool() is false.
I also want a smart pointer that may act either like a `unique_ptr`, or like a `observer_ptr`. I won't call it "owner_ptr" though, precisely because it is not always the owner.
I couldn't think of precise and short name and called it ``owner_ptr``. Hope someone suggests a better one. 
I'd hope it means `int x[2]`, fear it means `std::initializer_list&lt;int&gt; x[1]`, and expect it to be ill-formed ! 
Don't know C++ but that looks like an array variable with two elements: 0 &amp; 1. Edit: not sure what the "auto" keyword does. 
Don't like it because the non owning pointer can dangle. So I'd rather actually use raw pointers for non-owning pointers. And I don't see why the first example won't work with just unique_ptr. Don't know about the specifics of boost::multi_index_container, but using this special pointer which becomes non owning just for the time between extraction and erase, which will dangle if the erase doesn't happen, seems like a really dirty workaround for a problem that should not exist.
[removed]
This is indeed a workaround. I wish boost::multi_index_container provides ``extract`` in future. C++17 container (unordered, map, set) have extract functions, so probably, that would be a proper solution, but until then, this is a problem.
I rely that nested inlineable function calls thatcan be eliminated will be. I rely on my compiler using SSA. I rely on my compiler doing dead code and branch elimination when I have `if(compile_time_false)`. I rely on my compiler inlining local `[&amp;]` lambdas fed to control flow routines. I don't rely in it for correctness, but for speed, and to permit me to write cost-free higher level code that isn't full of microoptimizations. 
my comment Herb deleted: What a disaster of a design. Reasons are obvious to anybody unfortunate enough to know what motivates the ISO: generality fetish and keyword phobia. interface should be a keyword(the fact you did not do it for "25 years" does not change that except that it makes it harder from ego perspective), 99% of people would agree what interface means, and 100% of the remaining 1% are wrong. And while Herb tries to sell it as this magical beautiful testable sharable code it is actually a disaster: I can Google/SO what interface means in C#/Java. I can find tutorials for beginners. In C++ go to definition and reading bunch of alien syntax is my specification. Oh and it is quite possible the author of this beautiful testable sharable specification did not write a tutorial for beginners... I mean I am fine if you want to enable powerusers or poor souls who need to write pair implementation tools to enable them to do it easier(BTW QT has CopperSpice fork that needs no moc FYI, but general point is valid), but to claim that this makes language simpler for average developer is a joke. Also the lock/interface language vs lib is a false deceitful example, mutex locking and interfaces have as much in common as banana and the moon. After watching half of the video I wanted sarcastically suggest to Herb that class and struct should be removed from language so you can specify yourself what class and struct mean. Also I wanted to suggest that : used in inheritance should be also removed and provided as customization point, so for example if my organization prefers composition to inheritance Derived: private Base would mean (in my organization) that now Derived has a private member of type Base named m_base_... But later in the video I saw classx so I learned that I can not even joke about bad language design without somebody from ISO already suggesting it. The fact that there was a UX study at the beginning just makes it more funnier, because if you did any real UX study on developers with &lt;5 years of experience they would prefer the keyword solution(especially the ones with prior experience from those small unpopular languages like C#/Java), but hey we are ISO we know what we want to do, user opinions do not matter, but pretending that we care what users think is important to us. who does not have 1 hour of time to watch the video you can watch this (mild NSFW) Onion video where guest (Herb) explains proper interface language design to hosts(Java/C#). https://www.youtube.com/watch?v=hKmDGWv9gRk
The current approach is just quick-&amp;-dirty to prevent arrays. Didn't have a need for them right then, but surely, it can be extended for arrays like unique_ptr.
&gt; to know what motivates the ISO: generality fetish and keyword phobia. He was right to delete your comment for such personal attacks. &gt; interface should be a keyword "many seems to confuse the examples used to illustrate a point with the point itself." - [Bjarne Stroustrup](https://isocpp.org/blog/2014/12/five-popular-myths-about-c-bjarne-stroustrup)
http://blog.cleancoder.com/uncle-bob/2015/01/08/InterfaceConsideredHarmful.html
Doesn't it have the type `std::initializer_list&lt;T&gt;`? `T` would be int here.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6pvoax/complete_beginner_here_help_me/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
When I was thinking about such a thing some time ago I came up with a name dynamic_ptr. ^^^^^^shrodinger_ptr But the whole idea seemed flawed so I just scraped it.
I've been working with libClang to generate metadata to expose a scripting API, this would make it much easier and would let me integrate it into the actual projects that require it. I hope this makes it into C++20.
 &gt;For those who don't understand, let me explain by a different example. Why do we have lambdas? Because local classes templates could not be used in template instantiation. So you either had to resort to some nasty hacks , or write your function objects far away from the code that used them in nonlocally. I don't want to have to worm my way through code or documentation ( which could be out of date and wrong ) , or use an IDE to tell me if a member is private or public. Wat? We have lambdas because they're way more succinct and convenient. C++11, in addition to introducing lambdas, also changed it so you can use local types as template arguments. Unless you're referring to local types not being able to be templated themselves, but lambdas were introduced in C++11 and didn't become polymorphic (templated) until C++14.
I didn't said he studies for malicious version, but he check history corruption. So as long as your remote can be trusted you will get only non-modified source code, and as long as at least one of your remote can be trusted, you will be able to tell if someone tried to modifies the code (you will have multiple heads). I added my remark is italic, because this obviously work only when the assumption "my remote can be trusted" is true.
&gt; He was right to delete your comment for such personal attacks. ISO is not a person. It is full of clowns that do not know how to design language features, but that is not what I said. I said their language "design patterns" are shit. And they are.
Thanks. I didn't though of wikipedia. It's a interesting article.
that article is quite bad and it is missing a point. You do not need a for each if you have for. Point is that interface makes code more readable, it is not about some diamond cornercases... So uncle bob is wrong, but even if he is right he does not contradict me without contradicting Herb. Because Herb explained the need for this language abomination by using interface as one of the things he wants to implement in c++ more easily that it is implemented now. So if you do not want interfaces good luck convincing me that it is important to have this reflection "just" so that people could write library code more easily... 
Another personal attack, by dehumanizing people. Interesting.
```int x[2] = {0, 1};```
I'd guess c int array with the elements 0 and 1. But I can't compile this.
(auto)matic type deduction, rather than giving an explicit type.
I'd have to do some looking to be sure, but I don't think so. If memory serves, it can be implicitly converted to an `std:initializer_list&lt;T&gt;`, but doesn't actually have that type itself.
&gt; Another personal attack, by dehumanizing people. Interesting. Another comment accusing me of being mean mean person without even addressing my arguments. I know it is hard since I am right, but give it a shot. :) If it makes you feel better I doubt you can do worse than ISO.
One thing that I don't see mentioned is that FP code tends to be analytically inscrutable -- the difference between an O(N lgN) and O(N^2 ) implementation can be extremely subtle, maybe even counter-intuitive. Casual use of (e.g.) list comprehensions and lazy evaluation contribute to the problem certainly but there seems to more to it than just programming naivete. The form of the code and the abstraction of data structure almost precludes analysis. The most famous exemplar is [Haskell's Sieve that wasn't.](https://www.cs.hmc.edu/~oneill/papers/Sieve-JFP.pdf) It took analysis by a university professor to realize that the 1-line implementation is not at all what it was claiming to be. This is a concern I also have about C++'s range library -- the resulting code will almost certainly be intuitive and concise (and correct, if that happens to be a priority for you /s), but I wonder if it will all too often just end up obscuring horrendously inefficient algorithms.
I want to say "nonexclusive" but it's kind of lenghty
&gt; One thing that I don't see mentioned is that FP code tends to be analytically inscrutable -- the difference between an O(N lgN) and O(N2 ) implementation can be extremely subtle, maybe even counter-intuitive. Well that should be documented. And I agree it should in many cases be documented much better.
You'll need `-Xclang -freflection` I think. The full arguments CE uses are found at https://github.com/mattgodbolt/compiler-explorer/blob/master/etc/config/c%2B%2B.cppx.properties#L10 and are `-std=c++1z -Xclang -freflection -I/opt/compiler-explorer/cppx/current/include -stdlib=libc++ -include cppx/meta -include cppx/compiler`
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [mattgodbolt/compiler-explorer/.../**c%2B%2B.cppx.properties#L10** (master â†’ df917cc)](https://github.com/mattgodbolt/compiler-explorer/blob/df917cc7cafcaa4ff031767c718d64ffbaa14ff8/etc/config/c%2B%2B.cppx.properties#L10) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dksmfjl.)^.
&gt; This is a concern I also have about C++'s range library -- the resulting code will almost certainly be intuitive and concise (and correct, if that happens to be a priority for you /s), but I wonder if it will all too often just end up obscuring horrendously inefficient algorithms. That can also happen with imperative code. I remember there was a [bug in timsort](http://envisage-project.eu/proving-android-java-and-python-sorting-algorithm-is-broken-and-how-to-fix-it/), Python's sorting algorithm and the default sort algorithm of half a dozen languages more, discovered only when some smart guys tried to prove it's correctness formally. What I agree with is that code can look intuitively "right" but might be harder to understand and in reality not correct. Maybe the compactness lulls people into thinking they understand what they read because "that one-liner can#t be that wrong that I don't see it at once". Or so.
Another issue is that I find that very functional code is extremely hard to debug. Many of these concerns also arise IMHO with the new C++ ranges library, as /u/mcmcc mentioned. If I have a for loop and do various things on data, the advantage is that all of the real work is happening in the present scope. It's very easy to set a breakpoint and see what's going on. If you use stl algorithms here and there for small things, they are both more likely to be correct and you can examine their return immediately after. The big selling point of ranges is composability. So now you start chaining these ranges into one another instead of using a for loop. When you start using ranges, you are now passing lambdas, deep into the bowels of who knows how many layers of ranges implementation details. You can try to set breakpoints but my guess is that it's going to be way, way more confusing trying to navigate it. My guess is that you will ultimately end up needing to change the code to produce some intermediate results, to try to hone in on the problem. I've always loved the approach in python, which has nice list comprehensions, generators, and a great lazy iterator library, but doesn't tend to encourage this kind of massive chaining. Instead you tend to combine those tools with regular iteration to write things as clearly as possible.
Speaking for myself, I try to test the elements of such a chain individually. I agree such expressions can be come quite complex. Regarding debugging, I do not like debuggers very much, my favorite debugging method is printf or whatever the language provides, and testing small functions whether they do what they should. I do not know whether this preference is related to functional programming but I find it quite useful for numerical Python.
You can only document things you actually know. In many cases, even the author isn't able to fully analyse these issues.
Well, the same principle applies with printf debugging. As you said, you have to test the elements of the chain individually. But actually writing the code this way is staggeringly slow; instead of efficiently (say) transforming one vector into another, you are now generating a bunch of intermediate vectors. So you have to do this not-completely-trivial transformation on your code in order to debug it.
&gt; Ada, ML and CLU solved that problem a few decades ago, it is called modules/packages. except no. for instance in all the ML languages, genericity is achieved by storing run-time type information in the module files, while C++ modules must be entirely handled at compile time due to templates. Else it wouldn't be zero-overhead.
I think your characterization of "with flexibility comes strangeness" hits at the distinction I'm trying to make between power and expressiveness. I don't think that TMP is all that expressive, and I'd say it's not necessarily all that flexible. It's powerful, because it can be used to accomplish many things, but it's never exactly the tool that you want. I see TMP as a [Swiss Army Knife](http://cdn.outdoorgearlab.com/photos/11/40/235536_8596_XL.jpg) that has a million little tools that pop out of it. Every time you turn around someone like Louis Dionne has pried another tool out from somewhere. It's amazing. But while you can use a Swiss Army Knife to build something, it's not convenient. The tools are capable, and you can accomplish what you need to accomplish, but you can't use them comfortably in all situations. I'm hoping that metaclasses will be more of a full set of tools. A full-sized set of scissors allows a more "natural expression" of cutting than the little ones that pop out of a pocket knife. They both cut, but you might have to do less weird contortions as you perform the cutting to get to the same result. 
&gt; "many seems to confuse the examples used to illustrate a point with the point itself." - Bjarne Stroustrup This. A thousand times this. 
Yes, we've talked about this as well :) I'm a very paranoid person. Any time I see anything clever I start thinking how people will just go and screw it up. (Maybe I've been at Microsoft too long?) We will end up in a world where there are completely non-standard metaclass frameworks that have built up an ecosystem of their own. And they won't interoperate with each other. And that's bad, right? But I think we, as a cohesive community (stop laughing!), have an incentive to prevent it from being a problem. As an example, we have Boost, which is a non-standard set of frameworks that has become kind of a "training camp" for the standard. And we have radically different OSs, but we have tools like Clang/LLVM and Visual Studio and MinGW that allow cross-targeting. A few frameworks like Qt will build their own ecosystem. And then another UI framework will come around and build something different but more clever and more incompatible. And it will all be ok in the end. Either the second one will die from disuse, or they'll both have strong and separate support. But they'll both work well with the standard library, otherwise they'll die on the vine. And I'm positive we won't let the standard library fork in such a fashion. So I'm paranoid, but a paranoid optimist. I have faith in you clever fools. 
But then there's the security issue that if you discover a security flaw in the library (even one that's entirely internal to the library and has no effect on its interface), you have to update every application that uses the library, because they've all compiled it from source and (most likely) statically linked it into their executables. Compare with a good binary distribution model, where you can just update a single shared library and fix the problem for all applications that use it.
&gt; you can't really trust anyone to not include telemetry, diagnostics Those are good things... Sure, overzelous telemetry can be abused, but in general, it's good for both the user and developer for the developer to be able to see things like which features are most used, which screens seem to be the hardest to navigate and what exactly causes the most common crashes. Obviously, an opt-out option should be mandatory, but including the feature is not a bad idea as all.
Adding print statements can work in some situations, but it has its limits e.g. when analysing a core dump or when attached to a misbehaving process on a production server. And it's not just a tooling issue either, imperative programming is closer to what the machine actually does, so it is inherently easier to map the current instruction pointer to a specific place in the source code.
What does this give me that cmake, scons, gradle, meson, build2 doesn't? 
I understand that Herb is motivated by those examples, however: "many seems to confuse the examples used to illustrate a point with the point itself." - Bjarne Stroustrup Is what I say to you. Bashing him for his previous efforts at Microsoft doesn't seem like a good starting point in evaluating the meta classes proposal.
Good question, I should add a detailed answer to the website. But if I had to pick three features then I would name: - Extensibility: Try to write a cross-platform rule for a custom language using one of your mentioned build systems. It's not that easy. - Multipurpose: All systems you named are more or less specialized systems for c++ compilation (except gradle). If that is all you need, thats fine, but the goal with Cook is to provide much more. - Sane language: CMake has arguably the worst language of the ones you named. SCons is Python, but the way you define targets (with environments etc.) is totally different from Cook. I invite you to take a look at the build scripts of each system. That being said, I am already aware of some downsides of the current systems. I wrote some thoughts down here: https://getcook.org/comparison/
Well then I strike down my original statement that it was a foolish guess (though still wrong): it's poor form no matter the standard or revision, but obviously - other comments be my witness - incredibly confusing, and one wouldn't be considered too highly misguided for believing that. Ignorant? Absolutely.
&gt; That can also happen with imperative code. That's not the point here. The point is that it's a lot easier to tell with imperative code than with functional code - and that's kind of by design. Functional code is *supposed* to be decoupled from operational reasoning and algorithmic complexity is generally determined by operational reasoning. It's a trade-off between abstraction and easily predictable runtime behavior.
That would require both reflection and reification to make it into C++20, and the TS doesn't even include reification.
Well, nothing will save you if you think just zipping and folding and map-reducing everything is elegant. Sure, it can be done in one line, but if you need to construct whole Cartesian products for your every possible permutations of your sublists, then .. you're gonna have a bad time. FP is susceptible to this, because immutability leads down that way easily. But it's easy parallelize. Whereas traditional C pointer chasing is 'impossible' to parallelize because it's full of who knows where aliasing and global mutable state and god knows what. In Java/C++ you have beautiful OOP hierarchies, but you have not a bloody damned clue of what the fuck is going on, only after you've unearthed those 1-1 lines deep inside FactoryAbstractPatternImpl (or SFINAE-driven pockets of hell) classes and packages, and got a paper and pen and figured out what actually gets auto-wired where, because fuck that XML (or cryptic template metaprogramming). But chasing implicits in Scala can be just as bad...
Printf debugging is also difficult on a lot of embedded hardware where a console may not always be an option, and you are dealing with a lot of state. Attaching a debugger can be vital there. 
Something I wrote on the idea a long time ago. I never did anything with it. So far it's not turned from moderate desire to need. https://crazycpp.wordpress.com/2011/01/30/pointer-promises-what-kind-of-things-can-we-state/
To add: I think the rules of good coding style apply to functional code as well. Cramming too much things into a single line, for example, isn't good style in functional code either. That should not make the performance worse - if it does, I think this is a deficiency of the language in question.
I agree that functional code and especially using functional data structures can require a lot more background knowledge about complexity and properties of the implementation. On the other hand, I think what happens less in functional code is that a whole lot of surprising stuff is just going on in some inconspicuous constructor. In the worst case, you'd need to read down every implementation of a class to know what happens and what performance characteristics will be - and in a large project, that can take some time. I think in a language like Clojure, this is less prone to happen.
I think that this proposal will lead to greater convergence between frameworks. AFAICS, metaclasses introduce an extra step in translation phase 7. This requires that its input has to be a valid token stream and its output a regular C++ AST (not a language lawyer, please correct me if I am wrong). This channels metaclass users neatly into Standard C++. Qt and others will be glad to leverage metaclass-enabled C++ compilers and ditch their MOC or other tools so that they can focus on writing useful products. Seems like simple economics that proprietary extension tooling will lose out to standardized solutions. Well, unless of course a company like MS would try it, but you are on such good behavior the last few years ;)
For full composability, you also want them as template arguments / concepts, not just as templatee.
Awesome! That worked (I was missing `-Xclang`). Have some gold.
Oh that's handy. So it probably knows the elements are integers. Thanks for explaining that :) 
Yes, I agree with your point as well. Being able to move off technologies such as MOC or C++/CX is a major advantage of metaclasses. 
I can't watch anything except the introductory video without logging in. If this is a free tutorial, why not just use YouTube like everyone else?
Every time a build system for C++ is mentioned here it gets pretty negative attitude (except CMake of course) because it is [one more](https://xkcd.com/927/) build system incompatible with others to be familiar with. From what I saw your build system is somewhat similar to conan in API. If you'll go to any build system there will be simple app examples or how to build a popular library, so is not quite clear how to use it for anything more complex than a hello world (e.g. a simple app that depends on few external libraries). This is especially hard for windows where you have runtimes, arch, configs (for msvc), what compiler it is supported and how to control each possible combination. Is quite a task to make a new build system for C++ that have more advantages that those already on the market. 
&gt; What a disaster of a design. What a disaster of a comment. &gt; Reasons are obvious to anybody unfortunate enough to know what motivates the ISO: generality fetish and keyword phobia. The attitude of this comment is obvious: arrogant and contemptuous. Appeal to personal attack. You can criticize the committee for valuing generality too much and unwilling to add new keywords. But describing people as fetish or phobia is going too far. It is an act to disrespecting people as people. &gt; interface should be a keyword But why? Isn't this proposal showing us the alternative? The rest of the same paragraph neither provides arguments supporting this opinion, nor showing rational opposition against this proposed alternative. &gt; (the fact you did not do it for "25 years" does not change that except that it makes it harder from ego perspective), How is it related to ego? Can't it be some reasons else? When you attack someone's character, don't just claim; show some evidence. &gt; 99% of people would agree what interface means Where does the statistics come from? And even if it is true, how does this general consensus affect whether `interface` is a keyword or not? Herb's example already shows the `interface` metaclass can be designed to align with the general understanding. Even if `interface` should be a keyword, it is not the same thing as dismissing the idea of metaclass itself. &gt; and 100% of the remaining 1% are wrong. On what basis can you claim that? The word "interface" does have other meanings. &gt; And while Herb tries to sell it as this magical beautiful testable sharable code it is actually a disaster I don't think Herb has described metaclass to be magical in the talk. &gt; I can Google/SO what interface means in C#/Java. I can find tutorials for beginners. In C++ go to definition and reading bunch of alien syntax is my specification. What's wrong with reading code? It is a legitimate way to learn. If you don't understand the syntax of metaclass or how to use the `interface` metaclass, feel free to search on Google or ask on SO. ;) &gt; In C++ go to definition and reading bunch of alien syntax is my specification. If you believe the proposed syntax is not good, feel free to object it or improve it. &gt; Oh and it is quite possible the author of this beautiful testable sharable specification did not write a tutorial for beginners... First, it is a proposal, an early proposal, a very early proposal. The scope and syntax are subjected to change. No one knows if it will eventually becomes part of C++. It is just too early to write a tutorials for beginners. Second, who say there will be no tutorial? When C++11 came out, and even before that, there are a lot of tutorials in the form of talks, videos, blog post, and megazine articles. It is safe to assume the same when metaclass, `interface` metaclass and other common metaclasses become TS or standard. Even if Herb Sutter himself does not give tutorial, we have a big community ready to study and share. Third, although the examples we now have are for demonstration purpose, there is nothing stoping us from learning from these examples. These examples already form a semi-tutorial! The examples, `interface`, `value`, `QClass`, and more, are showing us how metaclass can be used. Of course it is not a tutorial for beginners. Once again, it is a proposal, not for beginners. But experienced C++ programmers can learn from it. &gt; I mean I am fine if you want to enable powerusers or poor souls who need to write pair implementation tools to enable them to do it easier Despite the being disrespectful to call people "poor souls", you are fine with it. You agree it makes things easier... &gt; but to claim that this makes language simpler for average developer is a joke. ...and you immediately contradict yourself. Pick one opinion. You can't have both. &gt; (BTW QT has CopperSpice fork that needs no moc FYI, but general point is valid) That means quite many people agree with this direction: consistent feature sets and compilation process across platform or framework. Agree with metaclass or not, it is an attempt towards this dirction. &gt; Also the lock/interface language vs lib is a false deceitful example, mutex locking and interfaces have as much in common as banana and the moon. You misunderstand that slide. It is not a comparison between mutex lock and interface. There are two comparisons. One between C# `interface` and `interface` metaclass. The other is between C# `lock` and C++ mutex lock. Both comparisons show that C# tends to provide features for special cases in the language and C++ tends to provide general features. The title of that slide is "A difference in philosophy". It is very clear. It is comparing philosophy between languages, not between interface and mutex. &gt; After watching half of the video I wanted sarcastically suggest to Herb that class and struct should be removed from language so you can specify yourself what class and struct mean. Why do you treat it as a sarcasm? It is a completey normal thought, even though we all know it won't happen in a second thought. In fact, metaclasses are aligning well with `class` and `struct`, just like classes are aligning well with primitive types. It is a virtue that library features and equivalent language features are treated the same. Some languages like Java are criticized for treating classes and primitive types differently by some people. Some other languages treat everything as object. It is not the only way to design things but it is also not wrong at all. There is nothing to be sarcastical. &gt; Also I wanted to suggest that : used in inheritance should be also removed and provided as customization point, so for example if my organization prefers composition to inheritance Derived: private Base would mean (in my organization) that now Derived has a private member of type Base named mbase... You can suggest that, nothing sarcastical. Although I disagree with this suggestion, it is a legitimate suggestion. Not sarcastical at all. &gt; But later in the video I saw classx so I learned that I can not even joke about bad language design without somebody from ISO already suggesting it. Actually you can. You can write a proposal and compete with Herb Sutter's proposal. You can even write a paper to the committee to tell them it is a bad idea. Don't joke. No one is joking. Metaclass is a real proposal. If you believe it is a bad idea, there is no room for cynicism. Object it formally if you really believe in yourself. &gt; The fact that there was a UX study at the beginning just makes it more funnier, because if you did any real UX study on developers with &lt;5 years of experience they would prefer the keyword solution I'm interested in this claim. Any source? &gt; (especially the ones with prior experience from those small unpopular languages like C#/Java) C# and Java are not small nor unpopular. This is just false. &gt; but hey we are ISO we know what we want to do, user opinions do not matter, but pretending that we care what users think is important to us. The committee is full of people who really use C++ and sell C++ tools and compilers. It is not a guarantee, but they have business incentive to listen to us. &gt; who does not have 1 hour of time to watch the video you can watch this (mild NSFW) Onion video where guest (Herb) explains proper interface language design to hosts(Java/C#). No. Cynicism does not replace real technical knowledge.
&gt; Another comment accusing me of being mean mean person without even addressing my arguments. Don't evade your flaw. Addressing your "arguments" or not, personal attack is morally wrong. And, that comment is to address your second personal attack. Your second personal attack contains no technical arguments against metaclass. A comment that address your argument against metaclass should replies to the comment that contain it. &gt; I know it is hard since I am right, Why so arrogant? &gt; but give it a shot. :) If it makes you feel better I doubt you can do worse than ISO. The first part encourage me but the second part discourage me. Why so contradictory? &gt; If it makes you feel better Will it make me feel better? Why will it?
That is certainly an option, although something that can be turned on by default is always preferred - otherwise most people would not benefit from it. There are many improvements and new optimizations being done in VC++ right now which will significantly improve codegen quality. All these are always enabled under a flag such as /O2, so they will have a higher priority relative to something that has the potential to break applications and has to be enabled manually.
The same as `int x[2] = {0, 1};`? Like a good old array? Oh, no. It is an `std::initializer_list`... wait. Never mind.
Please login to start watching this tutorial
I have manually approved your comment which was caught by the spam filter. In the future, please do not use URL shorteners - the spam filter hates them because it can't see through them. (I realize that the website probably generated the shortened link for you.)
You are thinking about generating the final executable code. My point was how modules allow for intermediate representations.
It's not really related to what you cram into one line. You can write it out on separate lines, and you still can't debug effectively. You can write something like: post_filtering = filtering(my_vector, &lt;some lambda&gt;) post_transform = transform(post_filtering, &lt;some lambda&gt;) And so on. It's nice that this gives names, but the problem is that post_filtering and post_transform don't actually contain any values, so placing a breakpoint between those lines and inspecting them or printing them is still worthless. What it basically boils down to is that in the functional style you tend to do things to the entire collection at once, and chain these together to get the end result. In the procedural style you tend to have all of the steps that you do on the inside, and iteration over the collection is on the outside. If you do the functional style you use a lot of memory, which on modern architectures means it will be crazy slow. So laziness is basically a workaround, that lets you transform back from doing one operation to the whole collection at a time, to doing all the operations, one element at a time. Unfortunately, accessibility of the intermediate is sacrificed in the process.
Re: the Louis Dionnes of this world. Metaclasses essentially make the `class` keyword a customization point. What about other keywords? Like `virtual`. The Dyno library by /u/louis_dionne/ changes the underlying storage and dispatch strategy for virtual functions. Can this be done in a similar way by making `virtual` a meta-keyword? If that is the case, it would be great to also do stuff like const by default, deduced constexpressnes etc. 
Well, in some languages you are encouraged to sort of forget about the nonstop copying that appears to go on in functional programming, beacuse the compiler helps you express yourself that way without actual copying behind the scenes. When you bring that paradigm into another language you probably don't want that much copying to take place. Or another example is chaining a bunch of maps and folds or doing them in sequence, which looks "elegant" but when they are not loop fused together by the compiler is extremely wasteful. When a non functional language compiler sees this, it can't always make the same guarantees via the type system, and can't fuse them. I guess another is probably the fact that you can write any type of loop as a fold, but folds are not always easy to understand. I see people write tons of folds, and also have to stop myself from making everything into a fold "just because", since I'd like people to understand the code I write. So really, programming in a functional way in non functional language can be pretty crappy as far as performance, and code comprehension. You can do it, but it needs your attention to detail in a way that it probably doesn't in Haskell. Hard to say concretely, since there is a lot to it. I love functional programming, but I purposefully limit the amount of the paradigm I bring into other languages like c++.
Yea, but they're abused more often than not, and in 99% of the cases you don't have any insight of what's really being sent and collected.
The number one complaint I have about functional programming is that it makes your code pretty and concise and very difficult to reason about. I like to mix and match anyway. We can all learn something from the various programming strategies people employ today. I use some functional strategies when I'm writing imperative C++.
I'm not familiar with `boost::multi_index_container`. Why does this line from the first snippet crash when using unique_ptr? `container.erase(it);`
&gt; The attitude of this comment is obvious: arrogant and contemptuous. Appeal to personal attack. You can criticize the committee for valuing generality too much and unwilling to add new keywords. But describing people as fetish or phobia is going too far. Well people who thought that giving decltype different meaning when you add () or that gave us decltype(auto) (seriously WTF do you explain a junior what is a logic behind decltype(auto) - I am like a senior C++ dev, shitty maybe, but I still dont know how to explain it in a nice way) are obviously great. :) &gt; &gt; &gt; But why? Isn't this proposal showing us the alternative? GOTO is an alternative to for, and it is strictly more powerful. &gt; How is it related to ego? Can't it be some reasons else? Herb said it in the talk we did not add it for 25 years, we will not do it now. Really great technical explanation. &gt; Where does the statistics come from? Well believe it or not interface is not some magical concept like mondad that only the chosen ones understood. It is well understood by people that know object design. There is a reason why it is a keyword in C#. &gt; Even if interface should be a keyword, it is not the same thing as dismissing the idea of metaclass itself. I am not dismissing the idea of metaclasses, like I said below it is fine addition to 0.01% of users of the language, and their many many customers(devs using their libraries). &gt; What's wrong with reading code? Productivity &gt; It is a legitimate way to learn. If you don't understand the syntax of metaclass or how to use the interface metaclass, feel free to search on Google or ask on SO. ;) Yes, it is much easier for beginner to learn reflection syntax and decode what interface implementation is than to Google what interface is. You are agreeing with me I am afraid. :) &gt; First, it is a proposal, an early proposal, a very early proposal. The scope and syntax are subjected to change. No one knows if it will eventually becomes part of C++. It is just too early to write a tutorials for beginners. &gt; ...and you immediately contradict yourself. Pick one opinion. You can't have both. &gt; Sure we can, C++ can have interface keyword so that most of developers do not need to write ugly =0; crap to define interface, and metaclasses can be targeted at boost/QT people. &gt; You misunderstand that slide. It is not a comparison between mutex lock and interface. There are two comparisons. One between C# interface and interface metaclass. The other is between C# lock and C++ mutex lock. Both comparisons show that C# tends to provide features for special cases in the language and C++ tends to provide general features. Yes, but like I said it is fake example because Herb used examples of how it can get hairy with different mutex in C#/Java, and I agree with that. Unfortunately for Herb example does not translate: people either want to write interface keyword or not, there is no equivalent of timed interface :) . &gt; Why do you treat it as a sarcasm? It is a completey normal thought No it is not. You are again proving my point. Herb and people here are not "normal" (this is not an insult, one CEO used "you are not normal" to remind engs that they are not average customers so they should not design products for themselves). &gt; Don't joke. No one is joking. Metaclass is a real proposal. If you believe it is a bad idea, there is no room for cynicism. Object it formally if you really believe in yourself. a) I do believe in interface as a keyword b) my proposal would be a total waste of time &gt; I'm interested in this claim. Any source? I remember that I am not normal. :) I have worked with many developers that are not top end or seniors or whatever. A lot of them even hate templates. And they even hated auto until I converted them :P You may laugh, but this are the people that use C++ and Herb can either say we do not care about them or actually do something to make C++ more friendly to them. &gt; C# and Java are not small nor unpopular. This is just false. Sarcasm. What I said is that C++ should not try to be smart, just adopt the syntax from C# and make it easier for people to migrate into C++. &gt; The committee is full of people who really use C++ and sell C++ tools and compilers. It is not a guarantee, but they have business incentive to listen to us. I prefer to not go offtopic, but I would actually prefer if C++ was a language designed in a way like C# or Go are. Maybe then we would get at least one mayor feature after C++11 (6 y and counting of minor releases and TSes). 
It means that you shouldn't write code like this.
shrodinger_ptr is great though. Please propose that for C++20.
We're only talking about pure algorithmic complexity here. Not sure what constructor behavior has to do with this. Nobody is saying that everything about functional programming is more confusing or that is has more surprises when tallying everything up. My comment was just about one single thing: That given a pure algorithm, it will be harder to determine memory and runtime complexity. Because functional programming doesn't expose those things in the same way imperative programming does. That's a feature of functional programming and often a good thing. Not sure what about that is controversial..? You *will* have to be able to tell how laziness, iteration/collection details, stack growth, tail calls, and others all interact. Instead of just using classical loop repetition counts etc.. This is a downside of functional programming (and powerful abstractions in general). Everything has downsides and that's completely okay. :)
There is an interesting comment on this in the embedded use blog: http://www.embeddeduse.com/2017/07/22/ics-on-qtcommercial-fee-is-better-than-free/
That would be a start, though I think there's still opportunity to have over-sized buffers created in constexpr functions for various algorithms. Specifically for strings, I'd wish that string literals had a unique type that decayed into `const char(&amp;)[N]`, though I imagine at this point that'd have all sorts of horrific back-compat problems. For fully-compliant C++11 compilers, the general trick here is to just use a user-defined literal `operator "" _pv` that explicitly constructs a constexpr thing from a literal, e.g. `"/bar/foo"_pv`.
transferable_ptr Because it can transfer the ownership. 
&gt; Try to write a cross-platform rule for a custom language using one of your mentioned build systems. It's not that easy. In gradle it's trivial. In cmake, assuming you have a sane compiler/tool, it's also trivial (add custom target). I also don't regularly find myself needing to manage multiple languages in the same project either. If I want a build system for my c++ project, I'll use one that matches c++ the best. &gt; If that is all you need, thats fine, but the goal with Cook is to provide much more. gradle is pretty much language agnostic. Cmake is trivially usable with other tools/languages. I get that you're saying cook is a mega build system, but I don't understand why that's a good thing. It seems to solve a problem that doesn't exist. &gt; Sane language Agreed that cmake sucks here, but if I want an existing language as my DSL, I can use scons(python), rake(ruby), waf(python again), premake(lua). I had a quick look at the page you linked, "simple, powerful, extendable" are listed as very vague positives, beside "not the best ide support" (I suppose that means none?). You say "fast and parallel" beside "not the fastest", and that it tracks implicit headers beside saying it doesn't automatically handle dependencies. "Path handling (improvements?)" screams issues to me. For me, "not the best ide support", "does not detect dependencies", and "does not verify dependencies" along with "no configuration split" make this completely unusable, regardless of how "powerful" it is
&gt; except CMake of course Even cmake sucks. It's just the least worst option because lots of people are using it.
&gt; Another issue is that I find that very functional code is extremely hard to debug. That's not really an issue with functional programming, it's more due to heavy template metaprogramming in C++ being a nightmare to grok and debug.
Hi Gratian, I understand the rationale behind not wanting an opt-in flag. The general situation as it stands is pretty dire though (although please note this is not a criticism of MSVC per se but more of a C++ criticism) - As soon as we have a write through *any pointer*, we need to reload *all* non-local variables, as they may have been written to? This really is terrible :) Sometimes I think C++ needs to be taken out behind a shed and shot. Btw, did you see my previous blog post / bug report: http://www.forwardscattering.org/post/50 ? This one looks like a relatively easy win to me if that can be optimised, and is another example of code that crops up commonly in practice, including in std library classes (like std::vector constructor). 
&gt; I like to mix and match anyway. I think that's key. Programming paradigms are just tools; use the right one for the job. Sometimes imperative code makes the most sense for the situation. Sometimes functional code. Sometimes declarative, or object-oriented, or so on. Right tool for the job, and all that.
scons is fine for small projects, but anything substantial and it's just painfully slow. Not much has changed performance-wise with scons since day one. I used to be an early adopter, and had a codebase that used it for 10+ years. Dropped it recently and switched to qbs (even though the project doesn't even use Qt).
I would love if you could view generated code somehow, especially in the debugger. It's already sometimes bad when you can't debug and (even more importatly) see compilation error location with generated operator=, and will be even worse with generic code generation. 
&gt; You can statically link your code, always this old misconception... https://www.gnu.org/licenses/gpl-faq.html#LGPLStaticVsDynamic &gt; (1) If you statically link against an LGPL'd library, you must also provide your application in an object **(not necessarily source)** format, so that a user has the opportunity to modify the library and relink the application. 
And now strip `.o`s enough so that they are still linkable but don't leak any information that the stripped final binary doesn't. Probably possible, but is it worth the effort to protect what you manager thinks is corporate IP?
Commercial licensing frees you from ever doing that. Also: is there any tool that lets you create an archive of such object files from your build? Any examples of applications actually doing this?
int array
[VLC Media Player](https://www.videolan.org/vlc/index.html) has the default UI using Qt5. But you won't see all the Qt5Base, Qt5Gui, Qt5Widgets, Qt5... dlls, all you have is `"c:\Program Files\VideoLAN\VLC\plugins\gui\libqt_plugin.dll"` which is 16MB in size. And I don't think VLC is using a commercial license of Qt. [Telegram Desktop](https://github.com/telegramdesktop/tdesktop) only ships only one executable. But both applications are GPL licensed... 
No, this misses the point. The ``owner_ptr`` is unique, exclusive ownership. There's never two smart pointers owning the same object.
&gt; &gt; &gt; Also: is there any tool that lets you create an archive of such object files from your build? ...yes, tar ?
Which OS are you working in? If you're not completely new to programming then I would recommend coming up with a small project and implementing it. As you run into problems you can research those problems, figure out it out, and move on. This way your learning is both practical and directed instead of theoretical and all over the place. 
Well, I guess for GPL a link to the repository is enough...
Not every write through pointers kills all non-local variables: writes to global variables are properly tracked, for ex. When building with LTCG, an analysis tries to prove that pointer parameters are restrict, but that has its limits. Writes of different members of the same object are also properly tracked. But writes through object members that are pointers do usually appear to kill everything non-local, since it's very hard to track and prove that those pointers don't alias with something else. I'm not aware of any production compiler capable of properly handling real-world pointer alias cases. That's how TBAA ended up being used more recently - optimize hoping that the code doesn't break strict-aliasing rules, because it's too hard to actually prove it using static analysis. My opinion is that if Java/C# wouldn't use the JIT model and require all the runtime array bounds/null checks, they would be much better optimization targets than C++, since they have very strict rules for references and the type system. I saw your previous blog post. Handling that cannot be done in general, since (e + i) can overflow and wrap around to 0, and because the values are unsigned, one cannot even rely on undefined behavior like for signed values. GCC produces similar code, with a check inside the loop: https://godbolt.org/g/3uXxyp This case can be optimized though with some more work: the value e is the result of malloc, e is tested against null, then inside the loop the induction variable i is in range [0, N), so (e + i) should indeed not overflow and make the branch useless. This is similar to what the Java/C# JITs have to do to prove that array bounds checks are not needed. 
Nonexclusive as in "I'm not the only one who has this pointer", even though I own it and nobody else should delete it. But obviously the terminology is confusing so it isn't a great name.
In the examples, this is done with compiler.debug() https://godbolt.org/g/59LSSZ
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6pzbyu/how_do_i_start_learning_c/dkteemr/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Well, if you really want to use that argument, and follow through to absurdity, we might as well drop structured programming too, as its further away from what the machine is doing. You aren't arguing that of course. I don't care how the machine is doing it, well, really I don't want to have to care. Machines do things a lot of ways, and its too easy to fall into the trap where you build code for one machine that works and then when you try to port it, it's a pile of garbage. 
Thank you I use Windows and Ubuntu
Interesting. Smart pointers are cool, but I feel like the issue of ownership can't be quite so easily solved. Here are some of my thoughts. - Except for toy programs, ownership is an architectural issue. - This is because of variations in object lifetimes due to unique elements of a particular problem space. - I feel like you have to stub out a good chunk of a system before you can start to see lifetime patterns or the lack thereof. - This is an area where separation of concerns and the right abstractions become really, really important. Is it appropriate for objects to manage their own lifetimes? Should something else do this? Where is the line? - Multiple ownership is evil. Mustn't forget to say this. Which leads me to: - Given the variations in object lifetimes, it's very hard to devise a one-size-fits-all approach. - Smart pointers are great syntax sugar for the problem, but it's incredibly difficult to solve architectural problems with syntax sugar. None of this should be taken as criticism of smart pointers or syntax sugar - I myself have a huge sweet tooth.
&gt; Also: is there any tool that lets you create an archive of such object files from your build? Just use cmake add_library(&lt;name&gt; OBJECT &lt;src&gt;...) Then install this library and finally archive installation dir by your favorite archiver. My be somewhere in docs You also will need to write command line to link application, so when You build it, do this with make VERBOSE=1 and get linker command line from make output (or run other build system in verbose mode).
By a strict reading of the license, merely linking to the repo is insufficient, but that's just an artifact of that the license wording predates public source repositories being a thing, and is not anything that anyone could actually sue over (as they'd have to somehow suffer damages first...).
Hmm, well, it's a pretty new and quickly evolving field - in such fields usually staleness means the project is kind of dead. It would really be nice if Thrust gained more momentum. Actually a lot of similar projects are going stale. Boost.Compute for example also doesn't seem to gain much traction. Maybe this means they're not following the right approach - not sure. Maybe we'll get something similar or better with C++...well... 23 or later probably.
I've been trying out implementing the safe_union class using Godbolt. There are some syntax errors in the paper that are easy enough to work out, but I'm running into a snag when it comes to creating the aligned byte array. `align` and `size` are defined within the `constexpr` scope, so it seems they can't exit the scope to be used in the declaration of `data`. Anyone else worked through that?
Isn't wrapping of pointers undefined? See for example https://stackoverflow.com/questions/30089415/do-pointer-types-wrap-around-their-maximum-value Also in a 64-bit address space, the pointers are going to be nowhere near the maximum possible value, nor will N be.
`auto x[]` means x is declared as an array of type `auto` `auto` would deduce `{0,1}` as type `initializer_list&lt;int&gt;` you cannot initialize a built-in array of type T an initializer_list of type T. However, `int x[] = {0,1}; // x is of type int*` And `auto x = {0,1}; // x is of type initializer_list&lt;int&gt;`
ebmed support like vxworks are commercial only
check the CppCoreGuidelines' support lib [GSL](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-gsl)
Cmake is more of a cross platform build and the best in open source to me. Just curious on why it sucks ?
The last time I checked, it had static notations for ownership mainly for tools, but not dynamic as needed for this case.
I honestly don't know why anyone in their right mind would use C++ as a functional programming language - it would be like rolling your own OOP in C. Use an FP-native (or at least a little bit supportive, like Python) language, and drop down to C if you need some intensive work done. Alternatively if you don't want to go lisping, DON'T use functional programming yourself, instead use a functional programming library and write your code procedurally - like you would in Spark or Flink.
It is considered providing the source to make it available wherever you got the binary from.
I think Cereal is using RapidJSON.
Hint: probably not positively. But you only pay for what you use, such is the C++ way :-). More seriously, better ways of expressing the code you want the compiler to generate will get us a long way towards reducing long compile-times caused by some of the arcane TMP we have today (e.g. `std::tuple` and `std::pair`). That's just what I think, of course, and it's probably hard to tell at this point.
FYI -- SO guys proposed even better [solution](https://stackoverflow.com/questions/45345175/avoiding-extra-move-in-make-unique-make-shared-emplace-etc-for-structures-that-u)
even better [solution](https://stackoverflow.com/questions/45345175/avoiding-extra-move-in-make-unique-make-shared-emplace-etc-for-structures-that-u)
&gt; tool that lets you create an archive of such object files `find` and `tar`?
Please forgive the stupid question but it's a bit like [Breathe](https://breathe.readthedocs.io/en/latest/)?
The license fees are clearly states on the website, $350 / developer / month: https://www.qt.io/buy-product/ Or am I missing something?
The question is not stupid at all. Yes, it is a bit like Breathe in the sense that both Breathe and Doxyrest are Doxygen-to-Sphinx bridges. The way this task of bridging is approached, however, is rather different. Breathe is a Sphinx extension and outputs docutils nodes directly in-memory. Doxyrest is a command-line tool and it produces a set of .rst files (using the Lua-driven string templates); these output .rst files are then processed by Sphinx on the next stage. Both are valid approaches. However, my firm belief is that with the string template approach it's much easier to imagine what the final output will look like, and, therefore, to make necessary adjustments to the templates. That is, compared to looking at and modifying the Python code which is generating a bunch of docutil nodes. String templates are more visual. As for the end results, take a look at the "Samples" sections of both projects and see for yourself. 
I would just change the original function, or when that isn't possible, wrap it in a normal function: some_type get_something() { some_type t; get_something(t); return t; } So why do I think it is better this way? Writing the function takes exactly the same time as lambda, if not less. With a proper function you have a clean interface that can be documented and reused. If you happen to have too many of those functions, e.g. from legacy API, the better option would be code generation.
What I feel certain of is that I don't want to write code like that. Heck, you even created a poll and a follow-up post. Think about it, we are spending time *guessing* and *reasoning* about what this simple declaration should be. Sorry, I will just use: `int x[] = { 0, 1 };` I don't want to rely on fixes in the future version of the language that will maybe "fix" the `auto` syntax to do what I want, or maybe they will "fix" it to do something "better". I don't have time for this &lt;insert your word&gt; and even if I did have time, I don't want to waste it on things like that. I'd rather be solving problems worth solving.
See [Immediately-Invoked Function Expression (IIFE)](https://en.wikipedia.org/wiki/Immediately-invoked_function_expression). It's a common design pattern since the introduction of lambda's. Pretty sure Herb Sutter has done an article on Sutter's Mill and I know Jason Turner and the r/cpp bloggers all have submitted content on them.
Thanks for the answer. This is the kind of project that I could push at work for the documentation.
I always read the acronym as "Initialization Is Function Evaluation" (reminds me of RAII). Anyway yes, this is a known pattern also presented in [Functional C++ for fun and profit](https://www.youtube.com/watch?v=YgcUuYCCV14). I find it a very useful pattern when writing out code. As /u/thewisp1 noticed I too, very often, end up refactoring the pattern so that the lambda becomes a full-blown helper function. I might stop doing it when the pattern stops looking "too clever".
I don't mind whether `auto x[] = { 0, 1 };` works or not, but it's slightly annoying that auto x[] = { std::tuple{ 1, 2, 3 }, { 4, 5, 6 }, }; does not work.
Click on embedded devices, and that transparency is gone.
Good to see that I'm not the only one who had this crazy idea. :-) Looks like I'm in good company.
I found Jason's video, thanks for the pointer.
I respectfully disagree with a couple of these recommendations. I thought Code Complete 2 was a waste of time - I remember it saying nothing that hadn't been said better elsewhere, and it contained many statements that I thought were howlingly wrong. My memories of Modern C++ Design are fuzzy - I probably read it too early, but I recall that it seemed very complicated with dated techniques. I managed to become a professional metaprogrammer without being influenced by it in any significant way. I could read it again and offer a coherent review, but that would be time-consuming. The Effective and Exceptional series helped me enormously (Effective STL especially).
Or you should just write a simple and readable code. And later, when you will benchmark it and it will turn out to be too slow, only then you should try to implement optimizations. Also, you should look at the whole program and do some hard math - break it into separate parts, calculate, how much time in general is being spent in each part, and optimize the slowest parts, that are being run frequently. There is no point is optimizing code that runs once and takes like 1 millisecond. Also, you should consider optimizing the structure of your program / using different algorithms, instead of optimizing the code. So, dont make assumptions about anything, especially about your code being too slow, just write it. Of course, you should make at least a small project before programming, so that you would know what are you doing.
"Effective STL" and "Coding Standards" (although I'm not sure if it's already done for C++11+; the C++98 edition of it won't help much). "The Complete Guide" by Vandevoorde for templates is enough.
Let's be fair, a lot of these issues can be resolved with maturity, the website clearly states that this isn't production ready. My feedback to the developer is that because there are existing solutions, you need a clear vision for what your tool solves that they don't, from the start. And this needs to be something you can state simply and that people immediately recognise as describing today's issues. Otherwise, nobody's going to be interested.
I've had the same issue as you, and I think that's a pretty neat solution. I'm definitely applying that from now on. Thanks!
Bad idea, until you actually re-use the function. Why pollute your namespace with yet another name that no one should ever be referring to? Having it an anonymous lambda makes it entirely clear that the function is used just for one purpose - initializing a variable. In the example, what possible benefit would there be to documenting that function? Don't get me wrong - I'm very in favor of documentation, and have been without exception the biggest generator of documentation in a team, but documenting that function is like commenting `x++` with the comment "increment x". It's just make-work with no benefit to anyone. Later on, _if_ you ever re-use that function, you can give it a real name. Remember, [YAGNI](https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it).
I don't think I've ever seen this topic get brought up and it not be at least a little controversial. I learned from a Sam's Teach Yourself C++ in 21 days book and I think I it was excellent. Most people wouldn't recommend it though. Everyone learns differently and different books appeal to different methods of learning, I think. 
* Including generated code (especially headers) in the project is pain * Everything is a string * It's scripting language that is not a scripting language Just to name a few. With that said I still think CMake is the build system (for C++) that sucks the least and I try to use it everywhere I can.
I wonder why this one was treated as "top secret" for so long. (I mean the video, not the talk itself.)
Personally, I don't often bother making local variables const. I just don't care, and in my experience (20 years of C++) it's just not a common enough mistake to justify the extra gymnastics required. That said, if I want to make some kind of indication, I use a mangled name and a reference. some_type _t_const; get_something(_t_const); some_type const&amp; t = _t_const; Ya, some could write to _t_const, but seriously if your functions are so big that you can't see that, you possibly have other issues. 
Just replying to your latest argument for now: Yes, the table basically consists of statements that I did provide any evidence for, it's indeed very vague. I'll try to fix that. Regarding the IDE support: You are right, there is currently no IDE support live. However, due to the way the system works, it's quite easy to write project generators - locally I have one for CLion, and it already works with autocompletion, compiler definitions and I think almost everything else. Including it in the comparison page but not publishing it was a mistake, I'm sorry for the confusion. I'll either upload the IDE utilities soon or remove that point until I'll do it. I'll also update the rest, you rightfully pointed out that it is confusing. I'll try to elaborate: "Ninja" is probably the fastest build systems right now (besides tup). The [comparison page](https://getcook.org/comparison/) features a performance comparison. It's quite fast, but not as fast as Ninja. Regarding dependencies: It can only automatically detect dependencies if the compiler supports it. Tup traces the file opens issued by the compiler, so it does not need dedicated compiler support. Path handling referes to the fact that paths are always given relative to the current build script (which can be loaded by other build scripts). I experimented with different solutions - right now the rule has to resolve() files that are meant to be relative to the build script. Regarding "verifying dependencies": Bazel is currently the only build system that does this by sandboxing the file system. It has it's upsides, in that you probably get a 100% correct build, but you have to declare headers explicitly for example. So everytime you #include something, you have to edit the build description. If you are using CMake: It does also not verify dependencies. No configuration split is only an issue if the configuration is slow and can't be cached. That is not an issue right now with Cook. Thank you for your critical feedback, it really helps me to think about the project and also avoids confusion for futur readers. :)
Hm. Normally I'd say it defines an array of two integers. But since this looks like a trick question... Maybe an array of one initializer list? :-P
I think modern c++ design is the best book for some one who wants to get the basic idea of how tmp works, but with a warning that if you actually want to use tmp with a modern compiler it's best to look for what is already on the standard or more modern techniques. 
I agree that the only reasonable meaning that `auto x[] = {0, 1}` could have is the one you've given above. But should this be "fixed" in C++2a? Absolutely not. Raw C arrays are bad, and you should feel bad for using them. We definitely should not add anything to the language that encourages their use. If you want a stack-allocated array with known compile-time size, use `std::array`. End of story.
&gt; Personally, I don't often bother making local variables const Then a function you pass your variable to decides to accept mutable references, and the fun begins.
Herb gave some justification for that on [his blog](https://herbsutter.com/2017/07/26/metaclasses-thoughts-on-generative-c/).
&gt; Well, in some languages you are encouraged to sort of forget about the nonstop copying that appears to go on in functional programming, Just one remark... if you write double getval() { const int a = 5; const double b = a * 15.5; const double c = sin(a * b); return c; } This does not copy the values of a and b - they are used once and then replaced with the value for c, the the compiler juggles the CPUs registers. The same is possible with objects in functional languages. For example, Go uses escape analysis which places objects which are only used locally on the stack. I do not know exactly how the JVM languages do this exactly, but it is at least possible to avoid copies. 
This isn't at all related to operator precedence, but a colleague of mine was recently quite frustrated that the compiler didn't warn on this mistake: int f() { int localVar = 0; ... return localVar++; } Apparently he looked at it for far too long before realising what went wrong. It's a rather interesting example where the post-increment operator allows you to modify a local variable "after the function returns". (I realise this isn't technically what happens, but it certainly that way.) Yet another reason to avoid the post-increment operator.
Yeah, in functional style, debugging programs is more centered around operations and values, and many people find strategies like Unit tests and a REPL (read-print-eval loop, like the Python command line) useful. If &lt;some lambda&gt; does not do what you expect, it might be the best strategy to name it and test it separately. I do not see a fundamental problem with this. Of course different languages differ in how much overhead needs to be paid to make such tests, and they are perhaps less needed in statically typed languages (at least that's an argument around the static / dynamic matter). Another question is whether the language needs to create temporal objects for chained operations where the temporal values are directly consumed and not used again. I think that's not necessary but this depends on the language of course. Three different strategies which can serve as an example are list comprehensions in Python (they create intermediate objects), lazy sequences in Clojure (they create a lazy-sequence object which is kept on the heap), and transducers in Clojure (which are an abstraction of function chaining and no intermediate objects are needed here). 
First, I assume that the function is a private member, static member of the class, a member of a pimpl class, or just a static free-standing function in a compilation unit. I don't think that is particularly polluting the namespace, be it a specific namespace or the global one. It would be the case if the function is exposed to the users of the code. When a function is one-liner I don't usually document it anyway, but YAGNI has been one of the most common reason that people refuse to split long functions, gigantic classes, and so on. When you ask, they'd say they don't reuse them. From experience, 99% of such case happens when we cannot modify the original function - or why otherwise should it use out variable, given here we are with C++14 or C++17? If I were to create wrappers for a 3rd party library, legacy code, or system APIs, yes I would definitely document them even for one-liner functions. Last, comments should never be about describing what it does, but rather *why* it needs to be that way.
I wonder how much speed could get /r/rpcs3 with coroutines. 
/r/rpcs3 with loads of threads to emulate the SPU is a good example too :)
We have a custom code generator on our cmake configuration. We use add_custom_command and then add_custom_tarhet to generate files, and make our project depend on the custom target. Works a treat. 
&gt; Effective STL especially That gave me a bit of a chuckle.
I too learned from that book. It was the fist c++ book I read. At the time I thought it was good. But looking back, I was an ignorant teenager and it was a terrible book that helped perpetuate the whole "c with classes" mindset that existed in the 90s. The only really good thing about it is I remember it concluded with the advice to read the effective c++ book series. To be fair though, teach yourself c++ in 21 days was written in 1994, so it's not exactly fair to compare it with what would have been considered good c++ a decade or two later. But still. The effective c++ books stood the test of time in a way that the sams book didn't. 
I just finished watching the video. At the end of the talk, he also mentioned why the video was kept private. (I wrote my initial comment before watching the video.)
At least put the temporary variable and function call in a new scope.
Please read the subreddit rules about help questions.
I think his angle is to have a container of things where the contained type can be deduced from the initializer. std::array can't do that either.
To be fair, when you have the cash to buy VxWorks (the only figure I could find was 16500$ *per seat*), you have the cash to pay for Qt. And embedded on stuff like ARM boards &amp; such is totally free with it.
&gt; I'm curious what you all think of this. I do it all the time to initialize static data too. &gt; Am I being too tricky? No, but the language could lend itself to this better... &gt; Is it worth the slight ugliness to gain the value of const? oh yes !
It feels like I'm stuck in a sort of limbo. I could (and I'd like to) greatly improve my template metaprogramming skills but it feels like most of the good books on the subject are not going to be updated for C++11/14. It's sad. I'd love to buy a C++11/14 version of Herb Sutter's or Andrei Alexandrescuâ€™s books. It feels like we're missing a good "C++ Intermediate to Advanced level" that takes into account recent language developments. 
&gt; Sorry, I will just use: int x[] = { 0, 1 }; but how are we going to make arrays of lambdas (or of `boost::bamboozle_iterator&lt;binalgebraic_diversion, std::vector&lt;decltype(1. / 0)&gt;&gt;`) ! will someone think of the children ! 
&gt; I think his angle is to have a container of things where the contained type can be deduced from the initializer. std::array can't do that either. I'm not sure I follow. In C++17, std::array x = {0, 1}; or auto y = std::array{0, 1}; [work fine](https://godbolt.org/g/xAY3k6).
Can't -- the variable would go out of scope and you would have a dangling reference.
It's true, it's not fool proof and someone could screw me over. But I've never seen that actually happen in practice so I don't bother dedicating my limited mental energy to jumping through hoops to avoid it. Of course, this is the point of const in the first place -- make the machine check for you -- and it's great, that's what we want. But generally, I find my local variables are exactly that -- variables -- so I don't generally dedicate mental energy to making them const unless I feel I need to, in which case I create a simple alias instead of jumping through lamba hoops, or other more complicated tricks.
Thanks! I definitely will.
&gt; Raw C arrays are bad, and you should feel bad for using them. No.
Ah yes. I was thinking of using a unique_ptr with code that takes a pointer to a pointer to return a pointer to the object it has just constructed.
To make an array of lambda you need to use `std::tuple`
Hmm, so what use case does a raw C array cover that is not covered by `std::array`?
I've been reading this: http://www.oreilly.com/programming/free/practical-c-plus-plus-metaprogramming.csp It's a concise introduction to modern metaprogramming and I've been enjoying it so far.
I've mostly stopped doing this. For a local object in a small scope, making it const versus the amount of boilerplate code necessary to do so did not seem advantageous to me. Const-correctness is very important, but not at the cost of tripling the amount of code in a function. If I were to use such an API extensively in a program, I would wrap it in a proper class. As for "extended initialization" like sorting a vector, I find that these short lambdas tend to grow out of control very quickly. I've reverted back to moving the code to a function.
to get better, just read and understand more code.
Don't you mean `int (*sample)()[]` - an array of pointers to functions returning integers, rather than a single pointer to a function that returns an array of integers?
You can't literally make arrays of lambdas unless all the lambdas are the same type, which means they are exactly the same lambda. :-D Are you wanting the type of `x` in: auto x[] = {[](int x) { return x; }, [](int x) { return -x; }}; to be automatically deduced to be `std::function&lt;int (int)&gt;[]`? That seems a bit of a stretch for the compiler, to promote these two different types into one...
So you only have to specify the type for type for the first element in the array initializer, and not the rest? I can't come up with a specific reason why I don't like it, but I don't. :-/
What effects might this proposal cause for static analysis tools and language services, or anything else outside of the 'parse-compile-link' cycle?
Can you give an example of when `std::array` can't do the deduction but you would want it to work?
Whoever voted your post down is an idiot. Having a name for something is almost always better than an anonymous temporary. You're not "polluting the namespace". WTF? The name is already there, you're providing an overload. You're *fixing* a design deficit without having to go around everywhere and change code that may actually depend on the non-mutable version of `get_something`. Probably not, it's probably some unknowing jackhole that thinks they're making things fast and they're doing the opposite...but sometimes it's actually warranted (it will respond to adl for example). This is the *right* way to do it. The lambda is a shortcut because you're being lazy. You can guarantee that if you're actually on a team that's using const correctly you'd either never see the original version or this overload would be provided already. You do this if you're working on legacy cruft and you can guarantee that it will be used again--or just written again over and over. You *want* to name this...or you're on a team that doesn't do this and then it's kinda pointless to try injecting it anyway.
Actually...you couldn't create a dangling reference anyway. How would you fix this? some_type const&amp; t = ??; { //...do your init stuff... }; Your name is either going to be unavailable or you need to use a pointer. Ugly.
Ah, [censored], you are so right. I know that function pointer types are declared inside out and yet I didn't work it out properly. 
&gt; You can't literally make arrays of lambdas unless all the lambdas are the same type I know, this is why I added the complicated boost type :p And I certainly would not want deduction of functions into std::function... but maybe `auto x[] = {...}` should deduce to a tuple-like object instead ? 
There is a really good list on [stackoverflow](https://stackoverflow.com/a/388282).
Ah, that's an interesting idea I didn't think of... but no, because then you can't index the variable you declared with `[]`: auto x[] = {apples, oranges, pears}; // Defines a tuple. auto y = x[0]; // Won't compile
&gt; Bad idea, until you actually re-use the function. That doesn't work in a team or on a large code base. Perhaps if you're making liberal use of code analyzers, and you should be but most don't (PHBs don't care about code quality). Nobody's going to go examine every function to see if someone else did this already. You'll be lucky if they look for the function...hopefully you're using a decent IDE. There's just no time for that kind of thing unless the product constraints actually require it. So name it if you think ANYONE will ever use it or it's so damn trivial that nobody would. In this case you want to encourage this style of coding ... so create the damn function so others use it and don't shortcut out. You need to make your code *easy* to work on. Encourage good style by providing the functions it requires. Don't depend on anyone to notice that you write a lambda in some dark corner of the code that already does what they want to do. Use lambdas for trivial shit that actually expresses things better anonymously rather than having a name or you know has no purpose for anything else...it's not much actually. YAGNI tells you not to overgeneralize or write code that anticipates features that may never come (even if they're planned). It doesn't tell you not to name shit that you're already writing!!!
&gt; auto y = x[0]; // Won't compile ... yet :p in an ideal language (I heard it's being worked on in D) you could even do for constexpr(auto&amp; stuff : x) { std::cerr &lt;&lt; stuff; } it wouldn't be that hard for instance if operator[] was able to take constexpr arguments in an overload : struct array_cpp2097 { auto&amp; operator[](constexpr int x) { return std::get&lt;x&gt;(...); } }
I didn't find Code Complete useful, and it is certainly dated. I'll definitely say Scott Myers' books were useful. I'd also add to this list Clean Code and the Clean Coder. They're not C++ books, and I tend to reach for templating more than the oop design Clean Code is based on. But these were the best books to teach me how to not write... well, really shit code no one can understand. And it at least taught me why I wanted to write tests, and a little bit how to do it. Also, the pragmatic programmer. If you live in front of a computer you should read this book. 
Disclaimer: self-promotion. Try More C++ idioms: https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms. Somewhat dated though. But, you can fix it!
I'm a noob, I read Effective C++ and am reading Effective Modern C++. Can definitely recommend. They can be hard to read (some back and forth between chapters to understand everything) but I learned a lot, especially on move semantics and references. Really well written.
This is exactly the reason I preordered and am eagerly anticipating the second edition of *Concurrency in Action*. It's going to be one of the few books out there for a while tackling an advanced topic using C++14 and C++17.
That won't help if you stored the value of the pointer elsewhere as well. Otherwise not a bad idea.
If I stored the value of the pointer somewhere and then freed it, and then NULLed it, how would the stored value of the pointer be affected? If the value of the pointer was "10 and then some other variable took that variable and stored it? Wouldn't the free pointer not matter? If you look at Webkit's WTF::fastFree(), it just takes a pointer as input and then free's it. No NULL on the pointer. So in theory if you changed this, to automatically change the pointer to NULL we should have less Use-After-Free's and more null dereferences and less exploitable bugs. void operator delete(void* p) \ { \ ::WTF::fastFree(p); \ } \ \
&gt;&gt; I've reverted back to moving the code to a function. So have I. I've adopted a "just because you can, doesn't mean you should" approach with respect to lambdas.
I think you missed the "reply" button :P If you have two pointers to the same object, nulling the value of one pointer doesn't affect the value of the other pointer, so calling `safeFree()` on the first pointer leaves the second dangling. In any case, setting pointers to nullptr after deletion would mask double frees, so there are some tradeoffs to be made.
Why the fuck are we still recommending people old books ? It's 2017, There's been literally 4 new standard releases (and a 5th one being in the making... if we assume people are already mostly thinking of the new 2x). Yes, some things are classic, you may enjoy your mystical man month or the cathedral and the bazaar or even more technical stuff like the c++ object model or modern c++ design... but they should be the kind of recommendations made with caution to a friend. Further more, books like the one I mentioned, are partially still valued since they were at one time or another groundbreaking or dealt with a subject that has changed very little... whilst I like Scot Mayer as much as the next guy Effective C++ is old, half of that book is now irrelevant and half could be better thought, it's an artifact of it's time. Sure, any book can help you learn C++, you can pick up K&amp;R 1st ed and learn C++, but you have a limited amount of time and attention and you should probably pick a few decent, modern books and go through them, rather than wrestle with the dead and deprecated. And not only are some of the books garbage, but you forget to mentioned relevant stuff like: C++ Concurrency in Action ... that's a great fucking book, 300 pages that take you from basically knowing jack shit about concurrency in C++ to being able to design a simple lock-free (that term is arguable imho) list, parallelize accumulate or create a thread poll. Why the fuck is that not there ? Are you telling me Exceptional C++, a book that for all it's merits comes from the previous century, is more relevant than that ? 
I truly understand the desire for consistency, but I try very hard not to engage in programming practices that arise more from obsession than from necessity. From a purely practical perspective, it's incredibly difficult to wrap up most problem spaces in an utterly consistent fashion, and it's usually not worth it. There are at least three scales at which code and intent should be clear, and at which we should care about performance: at the API scale, at the object/function scale, and at the statement scale. I would ask myself if/how *obsessive* const correctness contributes to clarity and performance at any of these scales. In general, I don't think it contributes much. It's okay for something that could be const to not be const. It won't make an API worse or better. From my own experience, it's much better to spend that time making an API nice to use - extra helpers, extra documentation, etc.
During testing / development, masking double frees is bad because you want to catch them and fix them. In the wild "masking" double frees by turning them into a free of NULL is great, because double frees are exploitable, but freeing NULL generally isn't.
1. These days, the correct way is to use unique ptr and reset it. 2. Oftentimes, the deletion is in some destructor, so who's gonna use the non-nulled pointer? 3. Oftentimes, deletion is at the place where the code forgets about that copy of the pointer (general case of 2, really) As the other guy said, the often seen, and unsolved by null-ing, problem are *copies* of that pointer, where the holder of the copy think they should delete it (that is, disregard for ownership). For cases 2 and 3, I wouldn't be surprised to see compilers warning about pointless assignments (efficiency). Reminds me... "In C++, OOP means object ownership protocols". :-)
That doesn't make you better. You can pick up bad practices from other programmers or yourself
&gt; I am wondering why doesn't everyone just create a "safeFree" function that will free/delete the pointer and automatically assign the pointer to NULL to defeat a use after free bug LLVM has a safe_ptr for this I think
Right, you'd need to use a pointer, which is asking for trouble. This is sort of my whole point -- all of these work arounds obfuscate. Using a dumb name + a const ref is simple and has a low probability of error. It would take intentional malice to mess up.
Thank you for your kind words. I think you are right, I should totally work on that. Having a clear vision is not the problem for me, but rather summarizing my thoughts about it. Most of the feedback I have gotten so far seems to be people wondering what benefits this really has - why should you create another build system? I think I will write some blog posts, each dealing with one and only one issue one could have that this system solves. Thank you again for your input. :)
&gt; I am doing research in dynamic memory in C/C++ Which language are you actually researching? &gt; why doesn't everyone just create a "safeFree" function that will free/delete the pointer In C++, a use of "safeFree" would indicate two major errors: use of an owning raw pointer and allowing the pointer to outlive its meaningful scope. Fixing those should be the priority, not covering them with paper tape. Not to mention, as already mentioned, that copies of that pointer would not be nulled. &gt; If the pointer is still accessed it will still crash (safely) The behavior of dereferencing a null pointer is undefined and in practice does not always lead to a crash: compilers drop code, hackers write exploits, etc.
1. WRONG. Don't go preaching nonsense. Correct is not the same as recommended. 
The one I read wasn't first edition. Jesse Liberty actually gave some good advice but the years have erased which advice was his. I added to that knowledge with knowledge I gained elsewhere. It was a good start though and I still believe it. 
In that case I WANT my code to stop compiling. That's part of the reason for using `const`! Edit:. I think I misread. You're saying what I'm saying. Context is important. :)
Yes, it's wrong in some situations (everything is), but why nonsense? For example, holding a member on a heap and owning it? Correct to use unique. Returning an object on the heap out of a function to a client? Correct to use unique.
Do you think that Webkit does not null free pointers by default to not "mask" bugs? 
Finally! 
This list is indeed a really good one.
Yeah, at the time it was a good start. 
I tried reading Code Complete 2 several times as well, and I do not think it is worth its reading time (and the book is really long). You mentioned that you found that it sometimes felt "howlingly wrong". It would be interesting to point out which part exactly. As for myself, nothing struck me as terrible, which is already much better than books like "Clean Code" which do contain things that are truly disturbing (like the peculiar definitions of Monadic or Diadic functions...).
A little aggressive don't you think? Maybe you're just trying to be enthusiastic? 
I was underwhelmed by code complete, although I had really high expectations after jeff atwood gushed about it so hard. [Design patterns](https://www.amazon.co.uk/Design-patterns-elements-reusable-object-oriented-x/dp/0201633612) I don't hear brought up very often but I found it extremely useful. Even if you don't use or even like some of the patterns you are likely to encounter them in your programming career at some point and being able to recognise them is invaluable.
&gt; Don't depend on anyone to notice that you write a lambda in some dark corner of the code that already does what they want to do. Yes, _if_ there is some other reason for that function to have a name, then you should give it a name. The whole premise of this was that there was not - that this is one-use only code. In the example, this is code that is obviously not reuseable. OP's idea was that they wanted a way to do one-time, `constexpr` initialization code with specific values. There's literally no reason in the world to re-use that. I am not arguing against reuse. I am arguing against naming things that you are certain you will not re-use. I'm arguing against naming anonymous initializer functions as a matter of course, and only doing it if this makes your code clearer, or you feel it will be reused - only naming initializers like this _if there is a reason to do so._ 
&gt; Whoever voted your post down is an idiot. Stopped reading there.
Some people have missed my point on statically linking an application. As at least one reader pointed out, the lgpl just requires that you make it possible to re-link and doesnâ€™t specify how an application is actually linked (dynamic/static). For a trivial application, it is easy to make it possible for someone else to statically re-link the application. You provide the â€œ.oâ€ or â€œ.aâ€ with a paragraph on how to link it. However, for a production application, the build process could be much more complex, and could even include licensed software from a third party where the license does not give the application developer the right to distribute the library. But whether you can make it possible for someone else to re-link your statically linked application was not my point. My point is that many embedded developers have regulatory requirements that require the application developer to ensure that the application they distribute, is indeed the application they developed and tested. Think of a medical device that controls the infusion of a â€œcocktailâ€ of drugs required to save a personâ€™s life. That needs to be locked down. This directly conflicts with the terms of the lgpl. This is the reason I suggested that purchasing a commercial license was the appropriate path for a company so that they could continue complying with the terms of the lgpl license.
This is really a matryoshka doll of bad design decisions. First there is a keyword `auto` which doesn't do anything. Then `auto`, despite being a storage class, and having nothing to do with the type of the variable, implicitly also means `int`, unless another type is given. And finally an exception is made where `auto` doesn't mean `int` if applied to an array. You could argue for fixing the problem at any of these levels, or for not changing anything, I can see how this might be too small for breaking existing code.
&gt; use of an owning raw pointer I don't think it's reasonable to classify using an owning raw pointer as a major error. An owning raw pointer is a language feature that has any number of valid use cases. Memory management and lifetime management are architectural issues with a lot of variations across domains, and I feel like an owning raw pointer is an important tool. Finally, owning raw pointers are not even the root cause of memory management chaos; poor project management/memory management practices, including no architecture/ad hoc architecture, is the root cause.
If you did. You are. Its a debatable position and he expressed it reasonably well. If you downvoted you must think it totally wrong and that's just arrogant.
I don't think that there is any "plan" or "schedule". This is mostly useful for absolute beginners to get the first overview of the language. Get yourself a pet project and practice. Don't just read books. Learning C++ (or any language both spoken and programming) is about practicing it. Start small, not big! I.e. start with a small command line tool or with a small Qt GUI application. What about a little todo-list-manager? Just get started. Get it running. Revise and refactor once it's running. Along the way you'll encounter problems. You'll look for help by searching, reading, trying and asking. And, finally, important: Learn to handle the tools you need! Editor/IDE, compiler, **Debugger**, static code analyser and profiler. Set the warning level of your compiler to the highest it can offer and follow the warnings! Don't implement anything new unless the existing stuff compiles without warnings. Today's tools are great in aiding help to get better. I don't want to miss these (especially a decent debugger and static code analyser).
Initial lambda parentheses can be omitted if there's no parameter.
Way too complicated. Here is the easy way: computer: Hardware, chips, etc..... music: Instrument computer: Program - text with list of instructions music: sheet music - text with list of note 
Right, I didn't say that functional compilers actually copy everything all the time. That's why I said that it "appears" that something like Haskell is constantly making copies, when behind the scenes it makes optimizations so it doesn't. It just allows you to express yourself as if copying doesn't matter most of the time. When you compile in C++ at -O3, you'll notice as many locals as possible, that would be on the stack normally are just in registers, like you mentioned. Compiling the above code with clang should actually evaluate `c` in its entirety at compile time and just load it into a register. So I tested this, and it was the case, it also removes the function call to `getvalue()`. #include &lt;stdio.h&gt; #include &lt;math.h&gt; double get_value(){ const int a = 5; const double b = a * 15.5; const double c = sin(a * b); return c; } int main(int argc, char **argv){ double val = get_value(); printf("Value was %f\n", val); return 0; } Compiles to: push rbp mov rbp, rsp lea rdi, str.Value_was__f_n movsd xmm0, qword [0x100000fa0] mov al, 1 call sym.imp.printf xor eax, eax pop rbp ret It's actually placed the already evaluated result in a section of the binary called `TEXT.__const`. I agree with you that functional languages also optimize away copies, but I was stating that they do so to an even greater extent than C++, and are helped by guarantees from immutability, and their type systems.
The main issue isn't really use-after-free, it's object lifetimes. Variations in object lifetimes means it can be very difficult to take a one-size-fits-all or one-place-fits-all approach to allocating/releasing memory. That's why reference counting exists - you don't release memory until the number of non-owning pointers is zero. Another facet of the problem is that you often can't really know/estimate object lifetimes until you've got a good chunk of a system stubbed out. Then you have to consider user stories or use cases or what have you, which add another layer of complexity. But either way, once the patterns become clear, hopefully those patterns will lead to real memory management architecture that makes use-after-free problems go away. tl;dr Frequent cases of use-after-free indicates an architectural defect and/or a poor understanding of object lifetimes, and use-after-free is a symptom, not the problem.
I dont think these belong here in the C++ subreddit
To add to the already excellent answers, one principle of C++ is RAII: Resource Allocation Is Instantiation. Unless you're writing a container/smart pointer, you shouldn't need to concern yourself with raw pointers instances. 
The Design of Everyday Things. teaches affordance. one of the most important concepts in programming architecture. I work with a lot of people who are masters of c++, yet still don't get this concept, and hence their code is not very good. parts of it are good, but on a large scale, not good. 
&gt; In the example, this is code that is obviously not reuseable. 0_o???!!! All I can say to that is, "W0t??" &gt; OP's idea was that they wanted a way to do one-time, constexpr initialization code with specific values. I don't know why you think that. The example used is a very common pattern in the industry that deserves dealing with. Your statement flies in the face of my experience. &gt; There's literally no reason in the world to re-use that. That's an extremely shortsighted assumption. It's really not very often that a type is only ever used once, even less that a function that modifies such a type is ever used in only one place, and EXTREMELY rare that such a state remains for the lifetime of a product. Chances are high that if you're working on code and see this pattern: type val; get(val); It's used elsewhere and more uses will be added. If you want to introduce const correctness into this situation you want to make a new, NAMED function...not a lambda in some dark corner. You want to see `type val = get();` at each of those sites, not a bunch of syntactic noise. 
The thing that you come to realize after a while is that most of these ideas of How to Do X Well are made for people who are not that good at X, by people who are not that good at X, and beyond a certain skill level they do not really apply (and in fact cause a lot of problems). Instead, look at the people who build things you find highly impressive, and study how they did it. this is much more fruitful than reading the output of people who want to spend all day telling you how to build stuff (which leaves very little time for them to build impressive things because they never test their own ideas).
&gt; An owning raw pointer is a language feature that has any number of valid use cases. Over `std::unique_ptr`? Name one.
Thanks for your detailed answer! You're right. I should be looking into little projects I can make instead of focusing on theory. It's just that it feels like if I spent 3h on reading a book, then when I would encounter a problem I could figure it out in a minute instead of 3h of googling I haven't really worked my way through all the little functions in Visual Basic, I should definitely start by reading some tutorial on it. I have no clue what static code analyser and profiler is, is it something implemented in the program?
So I can manage its lifetime with another object instead of unique_ptr.
&gt; If you are using CPack you can get a .deb, .rpm, a windows installer or whatever thing they are using on mac out of the box. This is in fact a hilarious statement, and to understand why it is so I would like to point you [here](https://stackoverflow.com/questions/16596655/cant-configure-background-image-for-dmg-installation-using-cmake). Needless to say I have personally lived through the good times that CMake provided me -- straight out of the box! (In the end, I said "thanks, but no thanks" and used a bash and apple script to create the DMG.) I can give you countless examples like this. Using a libraries in your app bundled as dylibs? You better hope their rpath is set correctly in the built library, CMake's totally amazing fixup routines will not work. Have fun trying to scour the internet for what's going wrong! Want to add resources to your bundle? Yeah, there's like a [9 year old post](https://cmake.org/Wiki/CMake:Bundles_And_Frameworks) on how to do that! Except it talks about frameworks, not apps. So now have fun reading through the OSX manuals to see if there's any difference between the two. Guess what! -- there isn't, and know that you know everything about how a bundle is created (it's literally a just a directory), you ask yourself, what is the point of the awful and poorly documented "abstraction" given to me by CMake? So basically, as I've stated numerous times before: if all you're doing is building a simple unix-like program, CMake is totally amazing.... except... writing your own little bash script to do the same is hardly more difficult. For anything more complicated, at least for me: CMake is a poorly documented clusterfuck of poorly thought out, tacked-on, crap.
"Visual Basic"? o.O Forget about it when you want to lern contemporary C++. Right now! Google the things you don't know or understand: https://www.google.de/search?q=c%2B%2B+static+code+analyzer https://www.google.de/search?q=c%2B%2B+profiler Btw: 3h of googling will teach you way more than reading 3h in a book!
I need to find a way to stop being stuck on c++98
Watch some of Herb Sutter's talks. And in short: keep it simple, only use the features if they allow you to localize complexity.
Wait, so the program inside Visual Studio Community isn't called visual basic? :DDD Sorry for confusion. Yeah I've tried googling and didn't understand what it is, actually. I think it's too early for me for such a thing as I doubt I have the need for it if I don't even understand what it does. Why do you think so?
Happy to see *Large Scale C++ Software Design (John Lakos)* on the list.
That probably depends on what debugger you use. Using VS myself I can't say I've ever had problems debugging any template code.
interfaces that accepts C array reference? Though it is a very narrow case and would probably be fixed in the future C++ standards.
You can equally well manage the lifetime of a `std::unique_ptr` from another object, by simply resetting it when you're done with it - or even easier, just having the other object own the `std::unique_ptr`. 
I was wondering same is there best way to create a learning patch, what to cover and when. But what you suggest sound very true. ðŸ™‚ðŸ™‚ðŸ™‚
Wait, I think I understood what a profiler is. That's awesome.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6q64w1/question_how_to_make_a_plan_for_learning_c/dkv27ux/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'm sorry - it's your _rudeness_ and _unprofessionalism_ I'm commenting on, not the idea itself.
&gt; It's really not very often that a type is only ever used once, I have no idea what you are talking about, but certainly not the article here. The writer is talking about specific, one-time _initializers_ for `const` variables, and not types. The writer wishes to initialize a constant with some expression that cannot be fit into a single line of C++ and is doing this with an anonymous, one-use lambda. It seems unlikely that there is a need for two constants with exactly the same value and type, so it is unlikely that the lambda needs a name. &gt; 0_o???!!! &gt; All I can say to that is, "W0t??" Can the juvie crap, OK? It's embarrassingly bad.
I fail to understand. This is code that is used exactly once, to initialize a constant. Why would you use it again to create an identical constant with an identical type? Why wouldn't you just use that first constant?
Or you can use a raw owning pointer and call delete from the destructor. But I get it, you prefer unique_ptr. That's totally fine! No big deal.
&gt; Or you can use a raw owning pointer and call delete from the destructor. You forgot about the copy constructor. ;-] The rule of five is an unavoidable law, not a recommendation, and it is as error-prone as modern C++ gets â€“ and that's why `std::unique_ptr` _is_ strictly superior.
You are talking about an ideal case, where it appears to be used this way, and used exactly once. Then how about actually go fixing the original function? You can't? Very well, then it starts looking like some of the practical cases, and I seriously doubt that a function that you cannot improve is a function that you or others would only use once. To wrap up, Situation #1: if you control the code being called you should have fixed that code already and the problem is solved. Situation #2: you don't control the code, but still want to use it nicely (you care about const-correctness of that type). Then you should wrap it nicely. Situation #3: you are dealing with something really dirty and probably low level, such as Windows API. Do you really care about type- or const safety there? I wouldn't. Tip: using a proper IDE would lower the mental cost of jumping between symbols, then you might re-evaluate writing a nested function just to be spatially close.
Yeah, I go back and forth on my preference on that. :)
Just as a FYI: adding a line to the method in your code sample to assign p to NULL would actually just be assigning the parameter pointer p to NULL which is a different pointer. The pointer that you used that called this will still have it's value.
Wow, thanks for the information about the rule of five. I hadn't heard about that before! I should probably go double check all my code right now. Seriously, are all discussions on reddit.com cpp going to be this much fun? Do the pedants always come out of the woodwork whenever someone says that it's okay to use a language feature? Will this experience be less painful if I add a title to my name so people will know *WHO I AM* on SO ( StackOverflow? ) and MSDN?
&gt; Will this experience be less painful if I add a title to my name so people will know WHO I AM on SO ( StackOverflow? ) and MSDN? I wouldn't know. But if you're going to be hung up on this sort of triviality then you probably won't enjoy it much here anyway. ;-] Good code mandates pedantry; the word is not derogative.
I'm not the one with the title next to my name.
Same here - if the function is reasonably small, none of those fears would actually be true. But if the function is complex enough, there are more things to worry about than const correctness. There will be logical errors, and there will be bugs around variables - since *something* has to be variable instead of constant. Lambdas in local scopes, especially those with ref-captures, are one of the sources of *shared mutable state* leading to unpredictable / untestable code.
I know. And I've had it next to mine since I started posting here, so I wouldn't know if the experience would be "less painful". Sorry, being pedantic again.
&gt;&gt; Good code mandates pedantry; the word is not derogative. Surely you're not trying to whitewash pedantic behavior as if it's always welcome and never offensive? You're right... the word itself isn't derogatory, but the manner in which it is practiced can be both offensive and unwanted. &gt;&gt; Good code mandates pedantry This is your opinion presented as if it were a fact.
I uh, may have once written code that'd hit that. I don't remember why I didn't just return a reference to the value rather than a PMD, but it was logic along the lines of the following: struct Foo { int a, b, c; }; enum class Field { A, B, C }; void frobulate_thing(Foo&amp; foo, Field f) { foo.*get_field(f) = 5; } 
Or you can assign it any pointer value in the first page (e.g. 0x1) on most OSes. That way you won't mask the double free so you'll get good error reports from users and it's not exploitable.
Oh no there aren't comments yet to explain this to me ðŸ˜¢
A compiler explorer that can compile its own HTML output?
I think c++ primer is a really good book to learn c++. The book comes with a ton of examples, covers lots of std library and the excercises are great practice that keep you engaged. At least I would recommend c++ primer over code complete.
&gt; Then `auto`, despite being a storage class, and having nothing to do with the type of the variable, implicitly also means `int` I don't think it's ever the case in C or C++. (K&amp;R C and ANSI C do have implicit int, but that don't really work in this way.) 
That's true but I don't see how it's beneficial in general. I can imagine some low-level systems programming benefiting from that I guess but I don't have a solid example I can think of that isn't contrived and would be better off replaced by a unique_ptr or some higher level abstraction. Can you expand on this?
You don't get it! It's [current year] for crying out loud!!!
does it suck?
My body is ready. Can't we have all this metaprogramming goodness today?
New edition coming out early next year. 
"The complete guide" is having a new edition released later this year. 
&gt; If the pointer is still accessed it will still crash (safely) That is a typical misunderstanding of what _Undefined Behavior_ means.
no I think he's chuckling cause of his reddit alias (and his real life name abbreviated) being STL.
&gt; it's okay to use a language feature? You didn't say it's okay to use it. You said there are valid cases for using raw pointers instead of smart ones, but that's opaque and without an example. If you're not dealing with low level code, or you have no need to manually handle a resource's lifetime, then a smart pointer is superior to a raw one, and should be used. And, it should go without saying, smart pointers have a better interface and semantic meaning over raw ones (they even get indirect language support like the rule of zero/three/five).
It really would just mean they would need updated frontends.
Only because we don't have constexpr-required function arguments yet. Once we do, `tuple::operator[](constexpr size_t n)` can replace `std::get&lt;n&gt;`.
Language simplicity of not equal to and does not lead to code simplicity.
Testing a private function can be useful, but the far easier way to handle this is to make the test a friend.
&gt;&gt; Manually managing the lifetime of a resource. By using term "manually", you imply that writing your own code for this, for whatever reason, is the same as doing something manually. Clearly, writing your own code for resource management is not the same as doing it manually. Doing it manually would imply that you use new and delete frequently. The original comment said that using a raw owning pointer was an error. It's not an error. It may not be someone's preferred way, and it may not be the best way, but it is not an error.
oh thanks. i should read more.
Sure, imagine something that needs to run on an embedded system with very limited hardware resources - a fairly common use case. The programmer might write a class that has an array of pointers and an array of ints representing ownership and references. In this case the value of the int (0, 1) determines if the memory is released when the object is destroyed. The second integer does reference counting. Simple.
I use C++ and generally in the old days when I was using malloc() and free() if I was calling free() on a pointer that pointer was likely about to be destroyed (because I'm in a destructor) and so assigning it the value of NULL is pretty pointless. On the rare occasion I was calling free on a pointer outside of a destructor there is a good chance we are in a realloc() type situation and I am about to assign a new (non null) value to that pointer anyway.
I can't see a practical reason why one would want to do this. If you have limited resources why would you write a class that does refcounting and dynamically decide whether to return memory or not - instead of embedding that information in the program structure itself? You get the same benefit plus simpler code using shared_ptrs and/or unique_ptrs depending on the semantic you want. If returning memory is an issue, using allocator policies is the best way to handle that in C++.
The STD series was pretty good, too.
One sad thing about such `constexpr` tricks is that it's impossible to turn a given `R"*(...)*"_html` expression into a type-level tree with the elements of the DOM, without storing the expression in a global constant first. To explain further, `constexpr` functions have the amazing potential of reusing code between compile and run-times. But, in order to be truly "native" to the compile time, I should be able to lift the result of the function into a type-level data structure, so that I can use further metaprogramming tricks on it to generate different types. Unfortunately, if you implement your parsing logic inside a constexpr function, you won't be able to provide such a compile time API: auto typeLevelDataStructure = toTypeLevel(R"*(...stuff...)*"_html); That's because, in order to be able to do this, you'll need to pass the `constexpr` `parser` object generated by the `"..."_html` expression as a template parameter at some point, but that requires it to have static linkage.
It's definitely not an error. But you have to consider other points when using a feature as well. For example, using `delete` and `new` to manage your resources is not a better option than using `std::unique_ptr`, because of RAII, semantic meaning (code is for the programmer, not the compiler), and a better interface (`unique_ptr` can manage other resources too, not only memory). A raw pointer has no apparent semantic meaning. You don't know if it's just an observer, or if it owns a resource. Yes, implementing `std::unique_ptr` is manual work: you have no choice other than using a raw pointer under the hood. But guess what? It's minimal manual work, I can use this abstraction elsewhere whenever I want a resource to have its lifetime managed automatically, that's what I'm after.
Please do :) Be sure to create GitHub issues if (or should I say, when? ;) you bump into any problems.
Omg I need `packed`
Note to self: add support for `clang-cl` in `build2`. BTW, how does one set up a command prompt environment for `clang-cl`? For `cl.exe` we have all these Development Command Prompt batch files. Anything equivalent for `clang-cl`?
If you add your streetcred to your name, I reckon the discussion will be even more painful, because that streetcred kinda demands that you explain your point when challenged :-). You still haven't given the "why" for your point. Instead, you tried an argument from authority. That should not fly here, and it does not.
`array.data()` ?
I don't know the limits of code injection but $bitfield example in the paper converts variables to functions with the same name. Similarly, if replacing functions with new ones is possible then one can implement $guarded to acquire a lock_guard as first call. Similar to synchronized in Java but on a class level. &amp;nbsp; Edit: $logged can be useful as well. Though, both of them relies on whether the code injection can replace the existing functions or not
Oh yeah, and also $atomic to make all vars atomic.
I'm not sure I completely understand what you say... It's true that constexpr functions can only create values, not types... Mixing templates and constexpr is not easy as far as my limited understanding goes. Perhaps the title "strongly typed" is misleading - what we actually have is a type that is constrained to a subset of strings (valid HTML) It's coincidental that I just came across this video https://www.youtube.com/watch?v=HMB9oXFobJc I haven't watched it yet, but I think I may learn some more interesting techniques from this. 
It's simple really - the TLDR; is that you have a string, from which you construct an object, but the compiler will raise errors if the string does not conform to the right syntax - in this case HTML. 
My point is simple, I want to parse the string using value-level constexpr functions, but I want to use the result to generate types. Because if you can't lift the resulting constant to the type level, there's practically no difference between a constexpr function and a Python script running as a pre-build step and generating some C++ code. In order to understand the distinction, with pre-build steps, you have to separate your compile time logic into phases, but with regular C++ metaprogramming, there are no phases, just a dependency graph of template instances, as deep as necessary.
What did you do it for? Just... why? This looks to me like an equivalent of that picture where a loaf of bread is turned into an electric toy bus. ([Here it is](https://fineartamerica.com/featured/bread-trolleybus-boriss-mogilins.html), the text is in Russian.)
Why did they do that switch(msvc - &gt; clang)?
It replaces all instances. This is still work in progress, I will add more sophisticated features. Please feel free to suggest any features. I want to be able to get this to render this sort of thing at 10x to 100x faster than any dynamic language 
I've been thinking about something ORM like where you describe your database tables using a $table metaclass. $immutable_struct could also be interesting.
It's better to have a use-after-free crash that's detectable by Valgrind / Asan then a subtle logic bug from reading a null'd pointer. safeFree(ptr); ... // time passes if ( !ptr ) launch_missile() 
&gt; Just... why? Quoted for emphasis.
I will elaborate. Anyone remembers those programs from 80s/early 90s which were filling the screen with 3d effects while being a couple of KBs in size? You were looking at them and going "damn, how are they this fast? woah, did you see those shadows and reflections? how did they manage to fit this ray-tracing-level stuff into a few KBs and make it this smooth??? I want to study their code, I might find something useful for my programs". And if you could get ahold of the source code, you *were* going to learn something useful. There was plenty to learn. Small program size but want to show pretty pictures -&gt; fractal texture generation. Want to show an infinite planet-like surface, but cannot really store any data because of size limitations again -&gt; smooth interpolation from random seeds. Want speed -&gt; palette rotation, stereoscopic images where you render your next image right into the current, interlaced, but it is currently hidden because the colors for it are dim. Etc, etc, etc. This was *useful*. You *learned* from it. You could then readily apply the things you learned in plenty of ways to do *practical*, *useful* stuff. Compare to projects like this which seemingly show-off being able to parse HTML at compile time. Yeah, you parse HTML at compile time rather than at run time. Yeah, fine. I am sorry, but this is just language masturbation.
Why? 1) We want DSLs 2) We want our silly mistakes to be caught at compiletime (I've suffered a lot with typos in django templates that mess up only in production) 3) Template based DSLs are limited - I tried that here : https://github.com/rep-movsd/cpx but it got quite out of hand and the extra noise of "_" in the syntax is sub-optimal 4) constexpr parsing removes the evil called "stringly typed code" - We can use strings, and still have the compiler constrain them to valid ones. There is actually a constexpr C compiler project! 
Could be cool, or a $JSON metaclass that mirrors a json table? $immutable could be very interesting
True - constexpr is not really code generation, unlike TMP I believe constexpr functions can be templates, so perhaps its possible to do what you ask for. Can you give me a simple pseudo code example of how what you describe would be used? Assume we have a simple grammar of balanced parentheses for simplicity. 
If its lifetime is managed by another object, then this raw pointer isn't owning.
It is not language masturbation, although I admit the pleasure is equal or better. My goal is to be able to use C++ wherever I want, without having to resort to another language. Errors caused by syntactical mistakes in strings are the bane of almost all programs. The moment you have a string, that the code needs to deal with, you set yourself up for a runtime error. The philosophy of C++ is to provide zero cost abstractions and as much type safety as is possible. Being able to say "I have a type, which can be initialized only with a subset of the universe of strings" is a very powerful feature - constrained types : https://fsharpforfunandprofit.com/posts/designing-with-types-more-semantic-types/ We can do a lot with templates (see the metaparse library), but constexpr is doable by mere mortals like myself. If I can do string templating in C++ for a web framework, and also not have to write extra build steps, or call external tools to grammar check my templates, and also be able to do it orders of magnitude faster than say python (I hope) then why not? 
&gt; We want DSLs [...] We can use strings, and still have the compiler constrain them to valid ones. If you absolutely want to use strings, but want them to be well-formed, why not write a tool to validate them and flag errors and run that as part of the build - or maybe as part of generating these strings (they do come from somewhere, right? there is a process for making them, so just make the validation by running the tool part of that process)??? The code for the tool would absolutely be simpler than the code for fitting the validation into compile time. It would be much cleaner and concentrate entirely on applying the goddamn rules you want applied rather than on making it work in the context of the C++ compilation. It would have much less limitations. It would be faster. It would be infinitely more extensible. Etc. &gt; There is actually a constexpr C compiler project! Oh, my god...
Thanks - It's been a long time since I wrote lots of C++ code and I wanted to use this project as a springboard to get myself up to date from C++98 to C++17 
I haven't watched the presentation; just read the blog and pdf. After using ANTLR a while back, this feels really awkward. Dealing with transforms directly on the parse tree seems more powerful than this. This seems like its in the partial solution sitting at the mid point between templates and tree rewriting. Granted this syntax is simpler and cleaner than what I was dealing with... and having worked/inherited a few code generation approaches, I understand the value in something directly in the language and potentially much more constrained. Its still frustrating as it feels like an interim step.
&gt; My goal is to be able to use C++ wherever I want, without having to resort to another language. This is misguided. A single language cannot fit all purposes. It just cannot. By trying to use a single language for everything you end up producing worse solutions that are cumbersome, limited, painful, slow and otherwise inferior. I replied [here](https://www.reddit.com/r/cpp/comments/6q791g/compiletime_html_parsing_with_constexpr/dkvmqbk/) regarding the specifics you provided for your case.
 I'd guess.. 1. Stop dealing with MSVC specific bugs/issues 2. Open source so they can improve compiler when they find issues, instead of waiting on MS to maybe fix it if they feel like it. 3. MSVC just isn't up to snuff with optimizations. (for example there was a thread recently where MS dev said they don't have strict aliasing support, and don't even sound interested in adding it..) 
Its opinionated not misguided. Can I replace python for this particular requirement in C++? Yes... Can I also avoid "stringly typed" errors while I'm at it? Yes.... Will it be faster than python? Yes... Is it much harder or uglier to write? Other than the user-literal prefix, no syntactical constraints... Any downsides? Compile time used when templates are edited, but even babel on JS takes a lot of time. Any upsides? My other code not related to the templating is C++ which allows me to do things much more cleanly (IMO) Any lessons? Practicing to use the advanced features of C++ and reason better. Learning to build further such libraries, that almost allow you to have custom language constructs. Like a very crude and limited version of LISP macros So what do I lose b y going this route? 
I didn't suggest using Python for your case, I suggested using C++ differently. The point about a single language not being able to fit all purposes is a general point. Change it to "by trying to use the C++ compiler to do everything you end up producing worse solutions ..." for your case. You are losing so many things, it isn't even funny. Here is an example: A separate tool can do better error diagnostics. If your strings are long, this matters. You will die trying coercing the compiler to do what you want here. Here are some other examples: A separate tool can not just diagnose errors, but it can automatically correct the most common of them where it is abundantly clear what the user wanted. In the same vein, a separate tool can optimize the strings it sees, replacing constructs you don't want to use for some reason with those you do want to use. Or not optimize, but just plain rewrite - for different target platforms, for example, or for testing. A separate tool can look for fragments of code shared between strings. This is useful for tons of scenarios, from detecting mindless copy/paste to reducing the total size of a bunch of heavy strings. If the number of strings is large, a separate tool can validate / transform / whatever them in parallel. Seriously, the list is endless. You are doing something unnatural. Let the C++ compiler do something it has actually been designed to do: compile *normal* C++ code performing a *normal* task, not fake-compile C++ code desperately trying to be a limited version of HTML in order to check whether the HTML string specified at compile time conforms to some rules. It will work better that way. Sorry that I perhaps sound a bit aggressive, but it's just the frustration from too many projects with too much use of latest and greatest language features in search of artificial problems to solve, and solving real-world problems poorly and clumsily. All hat and no cattle.
Cool! Why does it put COLOR and HEIGHT in capital letters? (it was originally specified lowercase)
I think you're referring to the demoscene - it's still active btw. What you can learn from it always depends on what your goal is. I'd say if your goal is to write good, maintainable, bug-free, readable code, then there's actually not much to learn from demoscene-like programs.
For those people asking why.. just why? This would be very useful for certain things like static site generators(where markup remains same once theme has been decided), for validation of markup etc. And before people start saying 'what the heck, who uses static site generator when we have wordpress', just look into jekyll and hugo. I think it's a cool project :)
Didn't microsoft recently announce they were deprecating clang-Cl support?
Wasn't it STL who said recently that clang/cl experimentation is finished and recommended to use clang from llvm for windows instead?
No, they are deprecating clang-c2 support. Clang-c2 is a clang frontend with a Microsoft optimiser and codegen. clang-cl is a translation layer that takes the compiler command line args for Microsoft's cl.exe and translates them into the commands that clang itself expects. From that point in it's fully clang (both frontend and backend)
These tricks are only usefull for library writers. Library users should not notice when they are used. No developer has to understand this as long as she is happy with her metaprogramming library. [Language enhancements are occuring](https://www.reddit.com/r/cpp/comments/6pov29/metaclasses_thoughts_on_generative_c/) but they are too late to be used in a C++14 code base.
No if check when its lifetime ends, no if check on assignment and no leaking implementation details by encoding a deleter in the pointer type. 
I just turn these to uppercase, since HTML is not case sensitive anyway. Might as well make it lowercase if that looks better. 
Everything that a separate tool can do, can be done by C++ and theres no real reason not to try. Why do people use Babel to have a fake ES6 or ES7 upon ES5? Because they get better language constructs. Since this is a library, its invisible to the user. I have a decent IDE and a C++ compiler - thats all I need from the tools side. Metaprogramming to delegate work to the compiler is kind of the philosophy of modern C++ We could very well use code generators written in some scripting language to make our generic types... Why go through template ugliness? But that is not the way most C++ junkies think.
Though it still generates cl.exe ABI-compatible object code/debug info (or at least that's the claim/goal).
That's what they're doing. At the moment, there are two compilers, each with two compiler *drivers*. The compilers are Clang/C2 and Clang/LLVM (same front-end, different back-ends). The compiler drivers are `clang.exe` (with GCC-style options) and `clang-cl.exe` (with MSVC-style options). On Windows, the compiler drivers generate the same binaries, you just invoke them differently. (For bonus confusion, I think Clang/C2 never publicly shipped their `clang-cl.exe`, but I used it internally to test the STL.) We're going to remove Clang/C2 for C++, and we're testing our STL with Clang/LLVM going forwards (currently 4.0.1). If you want Clang on Windows, use Clang/LLVM, with whatever compiler driver you like (either `clang.exe` or `clang-cl.exe`).
clang-cl is part of the LLVM/clang project.
As does the usual clang. I think clang-cl only converts command-line arguments to the form that clang understands.
Oh yes ok I mixed up cl and c2. Thanks for clarifying.
Not sure this is enough info but they mention to use vcvars32.bat for example: https://clang.llvm.org/docs/UsersManual.html#clang-cl 
I would like to see automatic AoS to SoA conversion. Not sure how that would work though.
We can write Qt6.
&gt; &gt; &gt; &gt; &gt; A separate tool can not just diagnose errors, but it can automatically correct the most common of them where it is abundantly clear what the user wanted. Every time I have to use a project that requires "separate tools" I just start looking for alternatives.
* $factory and $registerable: class is registered in a class list automatically. e.g for instance you have a factory FooFactory which creates classes of type Foo. What you want is to register all the implementations available : FooImpl1, FooImpl2, ... in a FooFactoryList. e.g. class Foo { virtual int foobarify() = 0; }; factory FooFactory { using type = Foo; // on second thought the `make` method can be generated using the ctor arguments to Foo: /*unique_ptr&lt;Foo&gt; make();*/ } // where $factory inherits from $interface :p registerable FooImpl1 : public Foo { int foobarify() override { return 1; } }; registerable FooImpl2 : public Foo { int foobarify() override { return 2; } }; and then being able to do : for(auto&amp; foo_kind : FooFactory::list()) { auto a_foo = foo_kind.make(); } * Locating classes by UUID But this would need custom attributes, and attribute reflection in metaclasses: [[uuid="625cac1b-b4e4-440c-ab3a-d556b13e15a0"]] registerable FooImpl1 : public Foo { ... }; [[uuid="9e210968-de18-4cc6-89b9-451c7261b0e7"]] registerable FooImpl2 : public Foo { ... }; std::string uuid = ...; // loaded from a save file for instance if(auto foo_factory = FooFactory::find(uuid)) { auto a_foo = foo_factory-&gt;make(); } a compromise could be registerable FooImpl1 : public Foo { constexpr const auto uuid = "625cac1b-b4e4-440c-ab3a-d556b13e15a0"; ... }; but it's more verbose and creates members for nothing. * UI Generation : Anything that can take struct Foo { int gammaCoefficient{}; float getMirrorEffect() const { ... } std::string banana() const { ... } void setBanana(const std::string&amp;) { ... } }; and generate an UI automatically. e.g. Qt::WidgetsUI FooUI { using data_class = Foo; }; // Equivalent to struct FooUI : public QWidget { Foo&amp; m_model; QSlider gammaCoefficientUI; QLabel mirrorEffect; QLineEdit banana; ... FooUI(Foo&amp; model): m_model{model} { // .... } }; * Opaque types. Currently it's a shitty bunch of macro if you want to make an opaque int or float. * Likewise, network RPC protocols such as Cap'n'Proto, etc... could have their networking code generated automatically since they just send the members of your classes generally. * **no need for SWIG anymore**. Generate Python, Java, `extern "C"`, whatever, bindings automagically.
Thanks for this!
How about metametaclasses to more easily write metaclasses?
I was criticizing a bad piece of work, which was blindly upvoted to high heaven and thus has probably lead to the misdirection of many people who might actually need good books to learn or improve their knowledge of the language. I wouldn't say it's aggressive, a bit crass maybe, but I think my opinion was valid and the questions that I asked still stand. To say that: "Why the fuck are we still recommending people old books ?" Is an aggressive question is like saying that: "Why the fuck are we still using Xorg in 2017?" Is an aggressive question, that is to say, if you're familiar enough with the topic you'll likely agree that the rude nature of how the question is asked perfectly fits the absurdity of any possible answer.
Very limited hardware resource and heap and refcounting? I think this is all wrong for reasons already explained by the other guy here.
You've been tasked with optimising a critical piece of code. It has to be done *today*, or your project's going to miss a deadline. You break out the profiler and find that a `std::vector&lt;std::unique_ptr&lt;Thing&gt;&gt;` is being resized and this is taking a long time. Sadly, though, there's no reasonable value to reserve. Then you remember reading this: https://stackoverflow.com/questions/45089049/performance-of-resizing-stdvectorstdunique-ptrt You change the code such that unique_ptrs passed into the vector have the raw pointer detached, and pulled back into unique_ptrs when read out. Thankfully this fits nicely with the current api. The raw pointers are manually deleted when the vector's owner is destroyed. Performance is improved significantly. Everyone is happy. A superior implementation comes later. Another example, I've had to use a producer-consumer queue which at the time didn't support move-only types. The only way to get that to work with unique_ptrs was to write a wrapper api where the raw pointer was detached, put into the queue, and put into a unique_ptr on the other side. Once the queue library caught up, unique_ptr was used directly. My point is that an owning raw pointer isn't in and of itself a major error BUT it is absolutely right that as a technique it should only be used for very good reasons, which should be made clear in the code. The standard RAII case is not sufficient justification, due to the error prone and overly verbose nature of writing the rule of 5 stuff, as opposed to just having a member which is a unique_ptr. Edit: Apologies for the spam! My browser swore blind that the comment hadn't been posted :(
Would the initialization order be the one from before or after the reordering?
&gt; If you want Clang on Windows, use Clang/LLVM, with whatever compiler driver you like (either clang.exe or clang-cl.exe). And what is shipped with VC15u3p4?
It also sets up some internal ms compatibility so it can find header files and correctly parse them. It's possible to do all of this without clang-cl by passing the correct command line to clang proper. 
4\. Fewer compilers to support.
The vector story is so sad :(
Nah, I'm waiting for metametametaclasses.
So is there a guide anywhere to setup this? I would like to test it without a visual studio installation, I guess I need the MS C++ standard library (windows SDK?). Any cmake toolchain file ready to use?
Boi, we won't even have it in c++20 and it's quite optimistic to assume that it will get into c++23.
Bah, metaclasses will take care of constructors! ;) It can write one that takes the members in the pre-render order, so I don't even have to care about the final order. But if I really want to write the constructor, I think I will just make my code independent of the members order and initialization order. Edit: took my coffee and read the question again
$json (or $xml) for automatic, boilerplate free, deserialization of json json Customer { std::string name; int age; }; json Customers { std::vector&lt;Customer&gt; customers; }; Customers result = Customers::fromJSON("{ Customers:[{ name:'John Doe' age:21 }] }");
That just returns plain pointer. How would you pass it to void foo(int (&amp;arr)[5]) or even template &lt;std::size N&gt; void foo(int (&amp;arr)[N]) Without some nasty error-prone casts?
Now I want to be able to conveniently read files at compile time :(
Oh god, if the day comes where including Qt is like including a library and doesn't turn your project into a Qt project, I will be so happy.
$mock which automatically creates mock implementations of every virtual function. Have only skimmed the proposal so I don't know if it is possible as it currently stands. 
Instead, you've introduced a different kind of undefined behavior.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6qbdtb/laptop_for_programming_dell_precision_5520_or/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I just want a mock metaclass
You should be able to write to_json&lt;T&gt; free function with a current reflection proposal. Which should be available in C++20
Should be possible, I have gave it some thought as well
I'm something could be done with `#include`.
I'd want something like Rust's `include_bytes!` and/or `include_str!` macros, that pretty much inserts the contents of the given file as a string literal in the code. I guess you could emulate it by reading files when building and passing them as macro constants to the compiler. Not nearly as convenient though.
&gt; 1. Stop dealing with MSVC specific bugs/issues &gt; 2. .. waiting on MS to maybe fix it if they feel like it. &gt; 3. optimizations...MS dev said they don't have strict aliasing support, and don't even sound interested in adding it. &gt; 4. Fewer compilers to support. OK, so clearly I am as biased as they get, but I'm going to push back against all four of these reasons. First, I'll say that I think the reason they've switched to Clang/Win builds is because Google is building most of their code with Clang. In WG21 committee discussions, Google pretty much represents the Clang/LLVM implementer's position. Their infrastructure is building up around Clang/LLVM, clang tools, etc. It just makes sense, even though they have to work on getting rid of a build throughput regression from switching away from MSVC ([See Nico Weber's first comment on the thread.](https://groups.google.com/a/chromium.org/forum/#!topic/chromium-dev/Y3OEIKkdlu0)) The folks at Google have worked a lot on making Clang/Win a first-class product. I know this because we've at MSVC have been talking to them about this for a couple of years. There's a lot of old cruft in the MSVC stack (e.g., the PDB format or our C++ EH/SEH interoperability) that we've helped them to get right. Now to counter these points. And I hope I'm not being an ass, I just feel like my team is being portrayed less than fairly here. 1. With regards to MSVC specific bugs and issues, every compiler has bugs and issues. If your code is already compiling with Clang, then using Clang everywhere makes it more likely you won't hit another compiler's bugs or get burned where you rely on Clang bugs. I will admit that MSVC probably has more specific bugs and issues than Clang--most 10 year-olds have fewer scars and bruises than 35 year-olds. But we're quickly approaching the point where [MSVC will fully conform to the C++ Standard](https://blogs.msdn.microsoft.com/vcblog/2017/03/07/c-standards-conformance-from-microsoft/). 2. With regards to "waiting on MS to maybe fix it if they feel like it", I'd assert that we are *incredibly* responsive to bugs, especially when it comes to companies with bugs in shipping products. As an example, Bruce Dawson, one of the main Chromium developers, constantly provides our team with [amazing](https://randomascii.wordpress.com/2014/03/31/you-got-your-web-browser-in-my-compiler/) [critical](https://randomascii.wordpress.com/2014/03/22/make-vc-compiles-fast-through-parallel-compilation/) [feedback](https://randomascii.wordpress.com/2013/12/01/vc-2013-class-layout-change-and-wasted-space/) that we always address as quickly as we can. (The links are just from a random Bing search for Visual C++ on Bruce's blog--there are probably better examples out there.) 3. [Please read the thread](https://www.reddit.com/r/cpp/comments/6p298m/poor_visual_studio_code_generation_for_reading/) before passing judgment. "They...don't even sound interested in adding it" seems like a simplistic summary to me. Gratian, one of our optimizer devs, clearly says "Sadly adding TBAA and having it on by default is going to break many programs out there - there is a reason why Linux builds with it disabled." Microsoft's business is built upon backwards compatibility and not breaking your code. That fact forces our hand more often than I would like but the fact remains: people have code that just has to keep working. (I would also assert that [the MSVC optimizer is better at whole-program optimizations](https://blogs.msdn.microsoft.com/dotnet/2017/07/20/profile-guided-optimization-in-net-core-2-0) that are harder to point at in snippets on [gcc.godbolt.org](https://gcc.godbolt.org), but that's a different discussion entirely.) 4. With regards to fewer compilers to support, the thread notes that they still build with GCC and will continue building with MSVC, just not on the "waterfall". They are saving some engineering effort, but they are (wisely) not abandoning any compiler that works. As I said, I hope my arguments don't come off as being rude. I understand why a less-than-favorable impression of MSVC might linger in some corners of the C++ community. But I also think we've turned this tanker around and are making it into a world-class compiler toolset. It makes sense to me that Google would use Clang/Win for Chrome because of Clang/Win's advantages in their engineering system. I don't have to find fault with MSVC to explain their move. Engineering is all about tradeoffs. There are benefits and drawbacks to any technology choice. *Edit: Changed the second line of the last paragraph to not indict "the community" who have actually been brilliantly supportive of MSVC's progress.* 
&gt; I've not yet run this through the gamut of compilers to see how well it's optimized, but if the compiler can move the object or do RVO on this it might not even be all that bad for performance. RVO is allowed and with C++17 is _guaranteed_ in many cases. Related to optimization, though, be aware that with C++, making a variable const potentially deoptimizes the code in that you can no longer move from the variable, and you will silently get a copy instead even if you explicitly _try_ to move many types. e.g. ``` auto const v = get_some_vector(); auto const v2 = move(v); // silently copies give_away(move(v)); // silently copies return v; // will RVO, no copy ``` I generally only make it a habit to const-by-default cheap value types where move and copy are identical under the hood, or for types where I know a copy isn't even possible anyway (like `unique_ptr` or the like).
One correction: &gt; We're going to remove Clang/C2 for C++ should more precisely read "We're going to move Clang/C2 to be an add-in rather than continuing to offer it in the main VS setup. We'll continue to support it with bug fixes when necessary, but there will be a very high bar to get work done in Clang/C2."
To answer my own question: looks like only Clang/C2 (I see this option in the installer).
Thanks, I thought VC comes with (optional) clang-cl but now I see it is (deprecated) Clang/C2 and it seem the way to get clang-cl is via llvm.org. Things are never straightforward in the Windows-land, are they?
Will take until Qt8 or so at least :-(
SWIG? You should have a look at pybind11 for Python bindings. It's even better than automatic bindings creation in my opinion since you have very nice control.
Actually they were initially: llvm started making the Windows package for clang but didn't make a lot of noise about it. Then clang/c2 was in VS, now will be stopped. STL's summary to my question here sums it well. Looks like it will all be the same clang in the future so it will be simpler.
This gives me visions of libraries of optimizations... Libraries of experimental language proposals... Optimized domain specific languages... C++ as base expression language for new languages, with built-in optimizations and FFI...
Yes, I use it, but wouldn't it be better to automate it ?
I think that should give a compile-error, rather than re-order the variables silently.
What's the reason for keeping Clang/C2?
I believe [this](http://llvm.org/builds/) is all you need. The compiler will then appear on the list when installed.
That's a different question. The problem with "becoming a Qt project" is not with the Qt reflection (Qt reflection is handled seamlessly), The problem is the one with the QApplication object: it is required by most of the Qt modules.
For what it's worth, this is almost always the wrong way to synchronize modifications to shared state when you have more than one member object to worry about (or when, say, your object as a whole doesn't fit in 8 bytes and modifications can be made in a single CAS loop).
It could be used to automatically generate reflexion data instead of using macros.
Cool! Hmm, I'm not sure actually. I really like the control that pybind11 gives. Only expose the functions and classes that you want to expose, and have complete control over how - yet it is super-easy and requires no effort at all. Just 1 line of code for each type or function. Also it works quite well with custom types - writing type-casters is not too hard. I guess that would be possible with metaclasses too, in a very similar fashion.
abuse: not adding interface keyword properties - I hate setters uses: bunch of cool useless stuff serialization QT 
Backwards compatibility, from Win32 to Xbox One. We can't break people! And it's still useful for C compatibility. We primarily did the Clang/C2 project because we wanted to provide a method for developers to bring their standards-conforming C++ code from other platforms while we were getting MSVC to conform to the C++ standard. At this point, we believe that the Visual C++ compiler is close enough for most C++ code to use. And as we plan to reach full standards conformance this year any issues you hit will be fixed soon enough (we hope!) While we've started on our C conformance work, it's going to come after our C++ conformance is finished. Until our compiler works for C, Clang/C2 is useful for a small subset of Visual C++ developers. Also, there's the Islandwood Objective C project that uses a large chunk of the same infrastructure: https://developer.microsoft.com/en-us/windows/bridges/ios. 
Am I wrong in thinking there are some gymnastics to be done with setting up the MOC, which would require you to change your build setup quite a bit? I could be wrong, I've never used Qt outside of standard QtCreator + qmake combo.
For total beginners as me...yep! 
Dereferencing NULL is just as undefined as dereferencing an invalid pointer so it's not different, it's literally the same problem.
Hopefully this is a step towards QtWebEngine (Blink) on the open source distribution of Qt on Windows. Right now you are limited to QtWebKit.
&gt; Chandler Carruth from Google presented build throughput gains from their experience modifying their build system to automatically convert some common header files to be consumed as Clang modules. Very interested about details on this.
If you see how the main.cpp is written... I use something like: auto parser = #include "somefile.spt" to get the string literal in. This is perfectly legitimate.
Why on earth are you so negative about someone else's efforts? If it's such crap, then why don't you just walk away? 
Re point 2: Since first release of Studio 2017 having container&lt;container&lt;std::unique_ptr&lt;T&gt;&gt; is broken. I made a bug report which is ignored since month. Our 50 developers stick to 2015 due to this. Just this week we decided to re-write our code because we lost hope that its fixed. 
At one point, you will need to interpret resulting program in the context of actual physical hardware it is executed on. That something is not defined by the standard does not mean that the behavior is unknown (or rather, not deterministic). Accessing memory at address zero will cause 'crash' on most popular machines. Its (probably) much safer to access memory at address zero, then to access freed memory (though its not at all obvious that gain would be real in the wild, as we still execute a program from a state nobody thought about). 
There's no paper--and in fact the notes are very short on detail--because this information is proprietary to Google. He mentioned that they had experienced build throughput gains with modules a few weeks before the meeting, and a couple of us encouraged him to present what data he could present in Toronto. He presented with the understanding was that the numbers he shared aren't going to be public. *Edit: Clarification of what actually happened.*
First, bug reports sometimes take a while to filter to the appropriate team. Feel free to do as Bruce does and alert us directly. Second, we really don't want to ignore you but sometimes incorrect behavior in MSVC is so old that it will take forever to fix. Two-phase lookup is like this. We're finally getting it fixed after years of effort (effort that helped in many other ways, but two-phase was blocked on the rejuvenation work.) On this issue, paging /u/STL. 
source? Thanks
`set(CMAKE_AUTOMOC ON)`
Microsoft only ever shiped clang/c2. The other clang is provided by llvm team.
&gt; $json (or $xml) for automatic, boilerplate free, deserialization of json At some time there were xsd to code converters. Sadly all I can find for C++ is either outdated, comercial or GPLv3 licensed. Writting all that boilerplate input validation is just painfull.
Another thing is that for me the biggest problem in a large codebase is understanding WTF is this thing "wired", assuming codebase is not of shit quality. So honestly problems that Haskell solves are not my biggest problems. :) And for my problems IDK how Haskell helps since I do not really care if any specific function is 20 LOC of C++ or 10 LOC of Haskell. 
That's actually a bug in the Standard itself, exposed by our implementation's design choice. The story is long and complicated. First, `vector&lt;X&gt;::push_back()` provides the strong EH guarantee (which was a reasonable idea in C++98, but it became a bad idea by C++11). To achieve this, it needs to ask whether the move construction of `X` can throw, and whether it's copy constructible. This is part of a 3-step process that determines whether the vector copies or moves `X` while achieving the strong guarantee as much as possible. The sequence of questions is: * Is `X` nothrow-move-constructible? If so, I can move it. * Otherwise (when `X` has a throwing move), is `X` copy constructible? If so, I can fall back to copying. * Otherwise (when `X` is throwing move-only), I'll just move it, and you don't get the strong EH guarantee. This relies on `X` honestly reporting whether it has copy/move operations. Next, our STL implementation has a long-standing design choice, where our node containers (`list` and the `map` family; also the `unordered_map` family right now although that will change eventually) have dynamically allocated sentinel nodes. I don't want to delve into this design choice right now (it's the weekend, and few people seem to understand it even when I explain it at length), but (1) it is permitted by the Standard, (2) it provides strong iterator invalidation guarantees when swapping/moving containers, and (3) changing it (which I don't want to do) would break bincompat (which we can't do in the 2017 release series). The consequences of dynamically allocated sentinel nodes are that default construction and move construction can throw. (And yes, I know that's a performance cost.) Finally, the bug in the Standard. The problem is that STL containers don't follow the rules that everything in the STL tries to follow. For example, `pair&lt;F, G&gt;` is copy-constructible if and only if both `F` and `G` are copy-constructible. It also reflects the noexcept nature of the operations. However, the container copy/move operations are not constrained. That is, `set&lt;Y&gt;` looks like it's copy constructible all of the time, even though it has to copy `Y` and that might not be copy constructible. So, here is the sequence of doom: * `vector&lt;set&lt;unique_ptr&lt;T&gt;&gt;&gt;` (where `set` can be any of the sentinel node containers) asks whether `set&lt;unique_ptr&lt;T&gt;&gt;` has a throwing move constructor. It does (as permitted by the Standard, due to our design choice). * Then the `vector` asks whether `set&lt;unique_ptr&lt;T&gt;&gt;` has a copy constructor at all. The `set` claims that it does (due to the Standard bug). * So the `vector` tries to copy the `set&lt;unique_ptr&lt;T&gt;&gt;` during reallocation, but you can't copy a `unique_ptr`, so you get a compiler error. I've tried to fix this, both in our implementation and in the Standard. There's a compiler bug that gets in the way of an attempted fix (reported as "constraining container copy constructors causes craziness") but it's not a blocking problem. What makes this *even worse* is that some STL containers permit incomplete types (in `vector`, `list`, and `forward_list`), and users have unwisely given incomplete types to other STL containers when they can get away with it. Constraining `list&lt;X&gt;`'s copy constructor requires `X` to be complete so we can know whether `X` is copyable. This is most virulent in recursive scenarios, e.g. when a `UserNode` contains a `list&lt;UserNode&gt;`. So at the moment, I don't know what to do, either in the Standard or in our implementation. I've put probably a week or two of work into trying to untangle the issues (and I have a shelveset of changes to constrain the constructors, which would work in the absence of the compiler bug and the user reliance on incomplete types). Special-casing can't solve the problem since it extends to user-defined types with container data members. There is, however, a workaround possible for your code. If you wrap your inner `container&lt;unique_ptr&lt;whatever&gt;&gt;` in a class that manually deletes its copies and defaults its moves (basically telling the compiler what the Standard should do, but doesn't), then `vector&lt;YourWrapper&lt;container&lt;unique_ptr&lt;whatever&gt;&gt;&gt;&gt;` will behave properly (and you'll get moves during reallocation). I'm super sorry for this headache and I wish I had a better answer for you.
Cool, I didn't know of this, thanks!
Thanks for the correction. What I wanted to say was, attempting to use Clang/C2 3.8 with our STL in VS 2017's second toolset update won't work, because I'm going to take dependencies on newer compiler features (notably `if constexpr` and hopefully class template argument deduction and inline variables).
Note that there are (at least) three options, only one of which you need. You need `-fms-extensions` which activates feature extensions like `__declspec(dllimport)`. The ones you don't need are `-fms-compatibility` which activates bug compatibility, and `-fdelayed-template-parsing` which activates non-Standard one-phase lookup. We've extensively audited our STL to be `-fno-ms-compatibility -fno-delayed-template-parsing` clean, which is the maximum conformance available.
Wow! Very nice write-up, thank you very much! Is there more details about ranges? It says "WG21 completed the review". What does that mean? And which part of the range-v3 library will get in? What about the other parts that won't get in now (I think views and these sort of things?) - what's the plan and timeframe on these, people already working on them? And is there by any chance any discussion about array_view or some other form of multi-dimensional array / matrix / tensor?
[removed]
&gt; as its still the good old days of blue screens I wish they were over though. They pretty much came back with Windows 10, at least in mine and my colleague's practical experience.
&gt; throwing move constructor yikes. I know you said you do not want to explain it in details, but can you explain why *move* does anything else beside stealing pointers to heap(when the src is not empty, if it is do nothing)? If it is too complicated enjoy your weekend. 
It's not that bad: https://godbolt.org/g/S7JnFQ template &lt;typename T&gt; struct caster { typedef typename T::value_type value_type; typedef value_type (*sized_ptr)[std::tuple_size&lt;T&gt;::value]; }; template &lt;typename T&gt; auto ptr_to_sized(T array) { return (typename caster&lt;T&gt;::sized_ptr)(array.data()); } OK, maybe it is that bad. 
Nice examples!
My pow: problems string/array_view tries to solve is people messing up the size of some array(assuming string is size of the entire array, not the real size of the string, iterating wrongly with indexes instead of .begin(), .end()... ), plus other things like saving one argument when passing it around, etc... So I think if you allow construction from array you are basically messing up one of the features of the string_view. That being said I may be wrong, but I would not consider this a blocking or critical feature for AFIO, so on meta level I would spend my time thinking about other stuff, and return to this only if a lot of people complain.
After reading the section on modules, a question occurred to me: are we moving to a single file per entity model, instead of the customary two files per entity we have now? In other words, instead of splitting every damn thing over a .h and a .cpp file, will we be able to put that same information in a single module file that defines both interface and implementation in the future? Or is it more likely for the two-files-per-thing model to remain as it is?
I had the same thoughts, the split into header and implementation file was mainly because of compilation speed and having things defined only in one translation unit in the project. But now that the language can understand logical sections of code and not just text insertions by preprocessor, this issues might go away.
I'm disappointed the EWG discouraged further work on the named function parameters proposal. I don't like having to create additional temporary variables or constants just to have readable function invocations.
This happens when a class has an invariant that it always owns a dynamically allocated object. I tried to get C++11 to permit an "emptier than empty" state but was unsuccessful.
array_view was renamed to span - see the latest proposal https://wg21.link/p0122r5 There is also an array_view proposal supposed to support multidimensional arrays, column-major ordering etc. but it seems they made it too complicated so the work is stalled. 
&gt; At one point, you will need to interpret resulting program in the context of actual physical hardware it is executed on. You've already missed the point. :-] If the _compiler_ can see that your code is derefing a nullptr then all bets are off, and it's unlikely that there will be an attempt to access memory at address zero in the resulting program. The compiler can't always statically determine this, of course, but the point is that trying to reason about the resulting program usually isn't worthwhile because most UB occurs during _compilation_, not execution.
Every time you declare an array the data is laid out differently while the way you work with data stays the same. The JAI language has this, I wonder how it's implemented there. 
Yeah as always any comment mentioning properties is downvoted. We need properties in C++. Like, yesterday!
https://www.amazon.com/dp/0321714121
In C++ even forming a pointer to an invalid memory location (other than NULL) is UB, not just derefing it.
Do you have a source on that? I've been unable to find any evidence supporting that claim. Regardless, what you really want is a compiler function annotation where you can express that the arguments are poisoned. It would also probably help with optimizations.
Yea... It's a very big shame that there's no progress anymore in the multidim-array view direction :-(((
Reddit!!
Ah, that is quite funny, so src can not be moved from fully since that breaks invariant and you need to malloc in dest. :) Some days I think your job is cool... not today. :)
We seem to have completely different recollections of what actually happened ;-)
P.S. Why this broke in 2017 as OP says? I mean problems you describe look like they are here since first C++11 VC++ shipped. You refactored some vector code?
No, the programming model with modules isn't moving to one single file per entity. It permits it -- as it has done since the very first design paper I presented. But, this isn't the Java class model. In practice, what happens is that there are certain entities for which the single file model is just fine or even the right thing to do. And there are others for which, from architectural and maintenance persoective, multiple files make sense - even if you theoretically smash everything together.
Yes, I overhauled vector for conformance. Previously we unconditionally moved. I've thought about going back to that behavior, which I might do if I keep hearing about it.
I debug with print statements. Come at me, bro!
This was not the first proposal for named function parameters, nor will it be the last. There is a desire for this functionality in the language but it's hard to see how such a feature fits into the language considering all the very detailed rules that exist today. 
With regards to ranges, I have no idea. I was chained to my desk in EWG the whole time, only permitted crusts of stale bread and sips of tepid water. Wait, no, that's a different memory. But regardless, I wasn't in the Library group at all. I think /u/CaseyCarter was in LWG--maybe he can enlighten us?
Any suggestions on a good book on metaprogramming that uses features from C++11/14/17 ?
Sorry, maybe I was being somewhat unclear. I would think having a single file instead of a pair of files would be an improvement to maintenance, and if the language will permit this in the future without the current issues related to this approach (i.e. the implementations of classes A and B being dependent on the interfaces of each other, forcing code that could easily be inline into .cpp files) it would be the more preferable option. I didn't mean in the sense of 'will it be mandatory?' What will a large .lib look like in the future? Given a hypothetical GUI library, I can imagine it would be a collection of small modules (module button, module checkbox, module text entry control, etc.), plus a single overarching module GUI that merely imports and exports all the others. Is that roughly in line with how you imagine things will be? 
Actually very informative.
What is the answer? I looked at the link and still don't understand.
I've read Stroustrup et al. articles on multimethods, and I personally found this would be a very interesting addition to C++. I'm curious about why it wasn't brought in the language.
Don't you need to know the size of an std::array at compile time but you can have dynamically sized arrays on the heap with new[]?
I really like the fact that Herb is very excited by this. This is a wild idea, and once it hits the barrier that is other people's opinions, it'll be torn apart, and if anything is to come out of this (and I hope it doesn't come out the way Herb is proposing it), it needs a champion. I think the way it appears in this talk is very narrow sighted, and I'd like to think Herb is aware of it (since he's just one person, and such a huge language feature is bound to have ramifications well beyond a single person's foresight). When you say "first-class language features can be implemented in code", I'd like that "code" to be lenient to abstraction, just like any other code. It sounds cute when you can template metaclasses over regular classes, but then, can I template metaclasses over other metaclasses? How will these metaclasses compose with each other? Will I have to use inheritance? But we've been saying for years that inheritance just for code reuse is bad. Another point: Something from the talk: for (auto o : $E.objects) if (!o.default_value.empty()) -&gt; { case o.default_value()$: return E::(o.name()$); } What's the type of `o` here? Will I be able to pass it into a function? And worse yet; what's this `-&gt; { ... }`, will I be able to return it from a function, or anything that resembles a function? Because if not, abstraction has to stop here. Another point; say a library defines a `template&lt;basic_enum E&gt; auto to_string...` that I want to use, but because another library defines it's own `power_basic_enum_3000_ultraXXX` (which is basically identical to `basic_enum`) my enum types are not defined in terms of `basic_enum`. How will I adapt that `to_string` to work with my enum types? Imagine I have `power_basic_enum_3000_ultraXXX T`, how will I wrap `T` so that it behaves like a `basic_enum`? Oh, and there's the point with, error messages; Take a look at 32:40, see at which line the error is reported. Yeah the error message is nice and cosy, but it's reported at the wrong place! We know from regular templates that this is a **very** tricky problem to solve. The way it's currently proposed, the compiler has no hope of figuring out who's to blame for the mismatch. That means whenever you misuse a metaclass, you'll have to dive into the metaclass implementation to try to figure out what went wrong. This is such a **HUGE** proposal that it'd take weeks, maybe months of full time effort to take a glimpse at its implications. But I'm really glad Herb is pushing this, since after years of discussions and compromises, this might turn into an awesome feature.
To add a few points to what Gaby has said, while you can define a non-inline, non-template function/variables in the module interface unit (i.e., there is an object file associated with it), practically and in this aspect modules won't be very different from headers for two reasons: 1. Every time you modify a module interface unit, every other translation unit that imports this module (directly or indirectly) will have to be recompiled. Having such recompilations because you have modified something that could have easily been factored out to a module implementation unit will be a waste. 2. Having a non-trivial amount of implementation in your interfaces will hinder their readability. Some of us go to the pains of factoring inline member functions to separate files to maintain such readability. But, having said that, I am sure there will be cases where it will make perfect sense to maintain the implementation directly in the module interface. As is normally the case with C++, for best results you will have to craft your modules rather than follow a few hard and fast rules.
&gt; Clang modules Just to clarify for those who may not be aware: "Clang modules" doesn't refer to "Clang's implementation of Modules TS". Rather it means Clang's own module semantics (I've seen them being referred to as "header modules", "implicit modules"). They don't require explicit imports (i.e., they work at the preprocessor level), they export macros, etc. See [Clang Modules documentation](https://clang.llvm.org/docs/Modules.html) for details.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6qdw3w/little_advice_to_newupcomming_c_developers/dkx0xrl/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Sure. Static T[N] array -&gt; std::array&lt;T, N&gt;(); Dynamic T[N] array -&gt; std::vector&lt;T&gt;(N);
&gt;You've already missed the point. :-] I haven't. UB doesn't mean you program just blows up and all best are off, especially since its impossible to tell, whether single module does exhibit UB on run-time or not. does following function exhibit undefined behavior?: int foo(int *ptr) { return *ptr; } &gt;If the compiler can see that your code i We obviously do not talk about something that is statically traceable to null dereference. &gt;but the point is that trying to reason about the resulting program usually isn't worthwhile This is simply not true. Its only not possible to reason about the program in the context of C++ language. OP clearly is not interested in only that. 
You're describing a well trodden path that many have been down, but there is light at the end of the tunnel. Much of the most modern C++ design eschews "classic" OO whose class designs tend to feature a complex web of interlocking heap allocated components. Instead it's moving much more towards value based design. For example, it's absolutely clear that both `std::vector` and `std::string` just do the right thing in terms of how they manage their memory. How much can you apply that philosophy to the rest of the design? This leads to designs which don't expose pointers of any kind at the API boundaries, preferring smarter structures like iterators (ranges) instead which can be seen as views onto immutable data structures. Once you can get away from designing a system in terms of "objects" and design instead for "values" then most of your complications just evaporate and take care of themselves. Yes, there will still be places where you need to deal with these issues, but they'll be relatively few and far between.
check https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Res-lambda-init
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [isocpp/CppCoreGuidelines/.../**CppCoreGuidelines.md#Res-lambda-init** (master â†’ 150744a)](https://github.com/isocpp/CppCoreGuidelines/blob/150744a8d3023ea5678e913ec3299e9e0bffb976/CppCoreGuidelines.md#Res-lambda-init) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dkx54ox.)^.
How does ``Sorted&lt;T&gt;`` work for a custom type ``T``? The examples don't show how to provide a comparison predicate (or a hash function for ``Unique&lt;T&gt;``)
It's all analog to std::sort and std::unique, since these are called internally. ( see e.g. Type Requirements here http://en.cppreference.com/w/cpp/algorithm/sort )
But do you think having plenty of global variables would help with understanding that? Or having dozens of GOTOs ? Because I think this are almost the same issues of organization and non-local interaction that functional programming (avoidance of side effects) is concerned about.
I find this may be useful to enforce some contracts in a systematic way; however, I think the current implementation is not flexible. Some options I would find useful: 1. Option to use assertions instead of exceptions (user provided) 2. Disable checks on release 3. Option to keep only O(x) complexity checks. Some ideas from John Lakos [talks](https://www.youtube.com/watch?v=1QhtXRMp3Hg). 
`$agreed`! `$packed`would be nice for all the embedded apps I work on. Would also be nice if there was something like `$packed_aligned` that would pack as much as possible but keep a 4-byte boundary start for things larger than 4-bytes. Example (using ISO C++, typical sizes for built-in types): ` class foo { unsigned char a; unsigned int b; unsigned short int c; unsigned long long int d; // ... }; ` would reorder and pad {a, c, (1-byte padding), b, d}
Cmake isn't a build system; it's a build file generator. Comparing it to anything other than autoconf is comparing apples and oranges.
Both registration and opaque types can be done with crtp alone, even reflection isn't necessary. 
Reading these has taken me off the fence: I don't want metaclasses in the language. Almost everything here can be done with crtp or reflection or both together. Metaclases are an incredibly powerful tool with relatively few uses, and just from reading these posts it's clear people are going to overuse it and misuse it. I really, really, really think we should standardize reflection and give it a good few years and see what demand there really is for this sort of thing once people understand reflection. 
Kudos for trying to take on one of the hardest problems in development tools -- writing a build tool. It's hard because there are so many opinions on the right way to do things, and it's hard to build a one-size-fits-all tool. YSK that the name "cook" is already taken: http://www.ibiblio.org/pub/linux/devel/make/cook.html Cook was written by Peter Miller, author of "Recursive make considered harmful".
How does this compare to foonathan/type_safe?
Views/spans are much more than just a pointer and an extent. They're a whole new class of simplified abstraction. AFIO's entire scatter-gather buffer infrastructure uses borrowed C++ 20 spans. It's a significant improvement in clean design over ASIO's convoluted buffer infrastructure as a result. Anyway, `afio::path_view` now does exactly what `string_view` does, and thanks everybody for the feedback. You can see `path_view` reference docs at https://ned14.github.io/afio/classafio__v2__xxx_1_1path__view.html.
The two seem to intersect, but don't offer the same types. `type_safe` seems to have an additional focus on conversions, while `FlaggedT` has more constrains for containers.
See, for example, how the MSVC team shipped the [STL as module interfaces](https://blogs.msdn.microsoft.com/vcblog/2017/05/05/cpp-modules-in-visual-studio-2017/). The proposal is linked from the post.
Have a look at the GSL (github.com/Microsoft/GSL). It has a gsl::not_null template which functions much like the NonNull tagged type from this one, but uses the GSL's "Ensures" mechanism to check the precondition at runtime. The behavior on precondition failure can be controlled with a preprocessor define. You can choose to terminate, throw or disable the check.
It has been a while since I've done windows, but why can't you put the sections where you might encounter SEH's and put them in separate compilation units which you compile with the /Eah option and compile the rest without?
Isn't the whole point of the SEHs that you aren't quite sure where you encounter then, bein asynchronous and all? So you can't guarantee that you'll catch them in any particular compilation unit? (Really asking, I honestly don't know)
I will admit to having written and used an alternative FREE(), usually a macro, that resets the pointer to NULL, although as you can tell from the NULL and the macro that this would have been some time ago. This was usually done for inherited code that needed to be checked for memory problems and was accompanied by a matching MALLOC() and some counting, etc. After bugs were fixed, the macro returned calls to the standard functions. I think you have a good idea which doesn't need to be foolproof. I've often seen code with repeated pointer = NULL, 0, or nullptr just after the free() or delete and that strikes me as problematic.
Thank you for this! I modified JobInfo to support all kinds of callbacks, as you described. I'd love if you could take the time to have another look :)
All of these could be metaclasses! Wow, I'm really starting to get excited about those...
&gt; Both registration and opaque types can be done with crtp alone, even reflection isn't necessary. yes, they can be done, but with great pain and many macros. (and with CRTP, only if you don't want to have an opaque int for instance since you cannot inherit from this... and in my experience opaque types of numeric types are the most common). Some examples of current solutions for opaque typedefs: * https://github.com/foonathan/type_safe/blob/master/include/type_safe/strong_typedef.hpp * https://gist.github.com/LucHermitte/032b669e1bc9fb486cea etc... just ugly stuff. 
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [foonathan/type_safe/.../**strong_typedef.hpp** (master â†’ 124f398)](https://github.com/foonathan/type_safe/blob/124f398a85e0c8e51c859e85e6fab01b6ec27728/include/type_safe/strong_typedef.hpp) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dkxlfef.)^.
You don't need any macros for either. For registration they don't serve a purpose at all (unless you want to save declaring a string literal with the same name as the class, I guess). With opaque typedefs they can simplify some of the implementation, but that's optional, and it's not user facing. /u/foonathan is only using macros to quickly give users many built in policies/traits/interface to choose from. You can also just write them out; it's not a big deal as there are only so many operators and it's also easy for typedef users to add more.
There are several policy based libraries which provide tools to define constrained types. - Years ago someone proposed boost::constrained - foonathans type-safe library does contain an implementation too, I think - I made a [Concepts-based](https://github.com/maikel/fub_constrained/blob/master/include/fub/constrained/constrained.hpp) one too once, just too play with Concepts and constexpr and more. Cheers
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [maikel/fub_constrained/.../**constrained.hpp** (master â†’ e299b18)](https://github.com/maikel/fub_constrained/blob/e299b18aa2b072c447c64c41e3419d3aef36712c/include/fub/constrained/constrained.hpp) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dkxouj2.)^.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide education, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6qjbiw/programming_problem_solving_with_c_5th_ed_still/dkxptla/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
good god make that code monospaced you maniac
&gt; got excited &gt; saw boost &gt; sad kitten
Something as simple as a lightweight header-only enum library really shouldn't have any dependencies other than a C++14 compliant compiler.
Boost is required for two things: * optional: it can be replaced with std::optional if you can use new libstdc++/libc++ * generating strings: I have an alternative implementation which uses some template magic, but the code is quite complicated and it's an additional 100 lines of code. I'll try to upload a new version without boost dependency in a few days :)
Please and thank you ðŸ˜Š 
Besides the usual suspects (Qt), I'd like a `$class rpc_client` and `$class rpc_server` that auto-generates RPC bindings. Combined with the networking TS, you could write a pretty snazzy RPC library using only standard C++. No more external code generators (ie. gRPC) or preprocessor macro workarounds.
Considering where javascript has gone due to the existence of babel is enough of an argument for why allowing the library writer to tools that work closer with the compiler is good. This seems amazing but also quite light-weight... it seems like it's clearly a middle ground introduced not to piss the old guys off and to make it familiar and easy enough to implement. However, if they just added a bit more to it, this kind of thing could be used to implement all kind of custom compile time magic, including adding stuff like borrow checking and forced exception handling, not to mention a path for compatibility with older compile version. Non the less, if this made it into c++20 or c++23 in the current state I feel like the language would one up any other language that is even remotely used in terms of expressivity and powerful zero cost abstractions. I mean... they guy just showed you how to code an interface in 10 lines of reasonable C++ and he's Herb Sutter... Imagine what some of the crazy metaprogramming guys might do with this stuff.
Is there any language which has widely spread tools that encourage directly working with the parsing trees and didn't get fragmented because of it ? I assume the committee might be reluctant because of possible fragmentation and difficulty using it... I know I'd get lost if I had to tree with the parse tree directly, this is much closer to what an average C++ programmer can understand and write I feel.
&gt; Now that we have co_yield working and understand how it works If you're like me and don't... here's the previous article: [How C++ coroutines work](https://kirit.com/How%20C%2B%2B%20coroutines%20work)
Observable or data-binding-like things
Surely using a GPLv3 codegen doesn't automatically make the output GPLv3?
Yes. The article puts it pretty well: every memory access might raise a structured exception, so it's not possible to separate the code. At least in the general case. E.g. Windows Memory Mapped Files signal fatal conditions - such as I/O failure - through structured exceptions. It is common practice to add /EHa to sections that do access memory mappings. (Which doesn't require a separate DLL, the options can be set per translaiton unit, or ypu can use `__try` / `__except`)
The way I see it, a metaclass would be more appropriate for making new ones. An oversimplified example: template&lt;Arithmetic T&gt; constraint Positive { bool check(T value) const { return value &gt; T{0}; } // constraint generates data, constructor, accessors, etc. }; Of course this would be similar to a policy-based design (again, oversimplified): struct PositivePolicy { template&lt;typename T&gt; using type_constraint = std::is_arithmetic; bool check(Arithmetic value) const { return value &gt; Arithmetic{0}; } }; using Positive = Constrained&lt;PositivePolicy&gt;;
It might claim copyright on a template and everything derived from it. Most also link against a support library, which makes that point moot anyway. 
+1 for recursion
Have fun rewriting half of boost pp.
No.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide education, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6qk6da/are_there_any_decent_udemy_courses/dkxw6xm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
How about waiting a little while for [this one](http://www.josuttis.com/tmplbook/index.html)?
LWG's highest priority in Toronto was to work on completing technical specifications that have been stalled near the finish line waiting for attention while LWG was focused on finishing off C++17. One of those was the Ranges TS, upon which we worked for roughly two full days of our week. LWG signed off on 47 issue resolutions for bugs in the Ranges TS, which together with the 24 issues that were "Ready" coming into Toronto means I have a *lot* of work to do integrating wording changes into the working draft. And I have to get that work done quick, because WG21 voted to send the final integrated document to ISO for publication. As for what's in the Ranges TS: the fundamental concepts library, "concept-ified" iterator adaptors and algorithms, plus algorithm overloads that accept ranges. The best parts of range-v3 - the view adaptors and utilities that reduce the boilerplate needed to implement ranges and iterators - are future work for a TS version 2. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide education, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/6qkcru/compiling_an_open_source_c_folder_into_an/dkxx2pj/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'll be the first to confess that I use code generation (T4) for enums. In fact, with C++, T4 clears lots of hurdles, especially when you want some lightweight reflection capabilities.
If it is the same executable, only one copy of the code (.text segment or equivalent, RO) will be in memory - virtual memory subsystem should take care of it
It would be could to use those functions with any enum. Maybe with the C++20 reflection xD
delete'ing null is well defined though. Deleting 0x1 is not well defined. With enough inlining, the compiler could see a sequence like the following... delete foo; foo = reinterpret_cast&lt;Obj *&gt;(0x1); delete foo; The compiler sees that you would be invoking undefined behavior if this code path were taken. Programmers aren't allowed to write undefined behavior, so from the compiler's point of view, this branch must never be executed, and it is dead code, so it gets deleted. Who knows what happens now. This sequence of code invokes no undefined behavior... delete foo; foo = NULL; delete foo;
I get your reservations but the point of this thread was to go crazy and brainstorm different uses. It'll take a few years for a decent understanding of what should and shouldn't be done -- we've had a week. Personally I would use a metaclass over my current crtp code any day.
&gt; Personally I would use a metaclass over my current crtp code any day. If your CRTP code doesn't have a lot of copy and paste or preprocessor macros, why reach for such an incredibly powerful tool? If your repetition can be eliminated with reflection, why not use that? It's pretty clear that metaclasses if introduced will be at the absolute top of the power tool food chain, yet people are going to get fancy and try to use them for problems that don't really require it. It could be that I have it all wrong and your problem really does require it. But given that you cite serialization as a use (not abuse) of metaclasses, when reflection is a less powerful tool that does a better job (since it can be non-intrusive), It's already unlikely. More likely is that your problem doesn't require metaclasses at all but you will use them anyway. Lots of people start doing this and I'll be debugging some nasty messes.
You still have to comply with an [assortment of licenses](https://doc.qt.io/qt-5/licenses-used-in-qt.html), even when you have a commercial license to Qt. That includes the LGPL if you use WebEngine (e.g. QML) or JavaScriptCore, AIUI.
optional's operator = is a proxy for the inner object's operator = if it's not empty, and obviously you can't assign to const objects the SO post mentions: &gt; But why shouldn't you be able to reset a non-const optional to a new const value, such as in this case: which, at least with std::optional, you can: use the `emplace` member function
I have lots of fun avoiding boost all together. 
(Thanks for the feedback) I would describe the circumstances this way. Programmers are typically **very good** at _detecting patterns_. Right? And C++ programmers will - at times - usually unintentionally - produce undefined behavior. It's probably counter-intuitive, but it's hazardous to do **both at the same time**. I've learned the hard way that once you delve into Undefined Behavior it's wrong to proclaim what will happen next. 
Whoops, you're right. Added the link
C99 designated initializers were added, which are a decent substitute some of the time. Having to define a struct for the arguments is awkward, but the call site just involves an extra pair of braces (assuming they work like in obj-c++; in C proper you also have to specify the name of the struct).
Is it sad that I have had fun rewriting half of Boost.PP?
Don't assume Reflection will be in C++20. It seems to be making good progress, but nothing is guaranteed.
Yes, you can. Though recently I've been trying out vectored exception handlers which are process-wide.
&gt; So you can't guarantee that you'll catch them in any particular compilation unit? They are stack-based.. So if you have, say, a class managing pool of worker threads executing some work, you can compile only the threadpool class with SEH. The worker thread body wraps user function with ```__try / __catch``` and user functions don't need to deal with it.
If the parameters are set in a struct and then in the proper class, do we end up with more copies or moves being made? 
Sounds like Microsoft specific solution. I prefer to use Python for the same purpose. 
&gt;I've learned the hard way that once you delve into Undefined Behavior it's wrong to proclaim what will happen next. Im not contesting that. Of course, reasoning about buggy program doesn't make sense _in general_. We do know from experience, that some problems tend to produce references to invalid memory (and its probably hard to point out big C++ program without such issue). Now disregarding C++ entirely, it seems (to me) that it would be strictly better if we were able to promote all invalid memory accesses to invalid memory accesses (mostly, freed memory) to accesses to first page of virtual memory - this way we would ensure that program stopped instead of 'going wild'. This, of course, is impossible to achieve in full, but zeroing pointers after you are done with them is an attempt to achieve some of that. On this ground it makes some sense - and its easy to show at least couple examples where it would work. On the other hand its easy to show some examples where it can terribly backfire (hence my statement that its unclear where such behavior produces net gain).
yeh serialisation is a stretch, i completely agree, i wasn't trying to suggest that any of those things should be implemented without consideration of better alternatives. we'll have a few years to think about metaclasses and the impact they'll have.
As an aside, since the article says: &gt; The printf function is not marked as noexcept, so the possibility is in play. (Not that you'd expect it to be marked as such, seeing as it's a C function, and C doesn't have exceptions.) Why aren't the C++ versions of the C standard library functions marked `noexcept`? The c-prefix versions of the headers already move the functions into `std::` and the common implementation is simply to use the C implementation, which obviously won't throw an exception, so there doesn't seem to be any good reason not to mark them `noexcept`.
What about container constructors and some member functions which would accept ranges instead of iterator pairs? Is it planned too or there are some issues?
I know, but, reflection and metaclasses: If any of them are added to the standard, it would be cool :p
In his keynote he says its an old syntax of meta classes, which is already or soon to be removed. Also: Meta classes syntax does not have to be valid C++ syntax.
Why would I want to take the performance hit of assigning a value to an object that will never again be read?
&gt; Another point: Something from the talk: for (auto o : $E.objects) if (!o.default_value.empty()) -&gt; { case o.default_value()$: return E::(o.name()$); } As mentioned in the talk, this is actually from the current state of the Reflection proposal. &gt; What's the type of o here? Will I be able to pass it into a function? A descriptor for an element in a compile-time reflected enumeration. Yes, you can likely pass this to a constexpr function. &gt; And worse yet; what's this -&gt; { ... } "Inject this code at the current scope". Basically, this code inspects an enum for all its named values, and converts that into a switch/case statement to convert them to strings, all at compile time.
what does it bring over http://aantron.github.io/better-enums/ ? 
Andrew I can see with Clang/C2 I can target v141_clang_c2 or v140_clang_c2 on my setup (I have both VS 2015/17 installed) I presume this determines the include paths for things like the STL? With Clang/LLVM I just see LLVM-vs2014 (which I assume targets VS2015). How do I get it to use VS2017? Likely not the right place for a bug report but Clang doesn't seem to like _CRT_SECURE_CPP_OVERLOAD_STANDARD_NAMES being defined.
&gt; I would think having a single file instead of a pair of files would be an improvement to maintenance [...] I didn't mean in the sense of 'will it be mandatory?' In some cases, the single file is indeed a preferable solution. However, it is not necessarily a universal solution. &gt; and if the language will permit this in the future without the current issues related to this approach (i.e. the implementations of classes A and B being dependent on the interfaces of each other, forcing code that could easily be inline into .cpp files) it would be the more preferable option. I am not quite sure I understand what you mean here. Could you clarify? &gt; What will a large .lib look like in the future? Given a hypothetical GUI library, I can imagine it would be a collection of small modules (module button, module checkbox, module text entry control, etc.), plus a single overarching module GUI that merely imports and exports all the others. Is that roughly in line with how you imagine things will be? Yes, that is indeed one viable solution. There is also the case of what people call "header-only libraries". They aren't .libs. You can' imagine they map to a single module unit file, or they are better mapped into submodules that are aggregated into an "umbrella" modules via module re-exportation. 
I thought, that metaclasses cannot be added to the standard without reflection being added too, considering it is based on that?
&gt; and it is admittedly redundant to have to repeat the 3 template types immediately, Yes. &gt; but... is it worth introducing a new syntax just for this case? Yes. The repetition quickly wears down. Furthermore, to really support generic programming, the syntax shouldn't merely allows one to express intent in long winded way. Rather, it should allow one to directly express intent. In the merge example, what the natural syntax is saying is "given these three parameters that satisfy the `Mergeable` concept, the `merge()` function takes these and return that." It is short, and to the point. The syntax isn't specific to mergeable. The general pattern is quite common.
For a completely non-biased answer: Yes, you should.
To many, the split into header and implementation files isn't mainly because of compilation speed. For them, it is a software architecture issue: they want to "physically" hide implementation details from interface specification. They don't want the next maintainer reading the interface specification to unconsciously make unwanted assumptions because of (accidental) exposure to implementation details.
As a bit of consolation `vector&lt;deque&lt;unique_ptr&lt;T&gt;&gt;&gt;` is broken in libstdc++ for the same reason.
Right now its probably not worth the effort. There are only a handful functions that don't have good replacement in C++ standard library (printf being one). Given one can include non-c-prefixed version of the header as well, and the fact, that its unspecified whether declarations of c-prefixed ones are spilled into global namespace as well it can become quite messy, for little gain. It would be obviously much better if 'by default' functions had empty exception specification, which would cover C functions as well. Its not something that's possible to change at this point though, i fear. 
OK, done. I managed to do it less than 300 lines. The downside is that C++17 compiler is required now. Generation of string arrays requires constexpr lambdas. Old version is still available on branch boost_version.
Yeah, T4 is a Visual Studio thing, which can lead to problems if you decide to migrate to Rider. Its upsides are that you can use C# as the generating language and the fact it auto-runs the generators on save. You can build very sophisticated things using it, including DSL support.
Maybe but I rode about metaclases as a pure compile-time thing, so
It's way more light-weight: it's only 300 lines (4 times less than better-enum), string arrays require no initialization, they are generated at compilation time. Additionally fwk-enum has type-safe bitwise operations (see readme for details). My library has some limitations though: you cannot set a specific value for each of the enum elements. But with flag support I never missed that feature.
One idea I had would be something like `$encapsulated`, where every public member variable is made private and getter/setter methods are generated (only where they don't exist already)... Is that possible under the current proposal?
&gt;I am not quite sure I understand what you mean here. Could you clarify? Well, why do we split files into .cpp and .h today? There are really only two reasons: compilation performance, and because you might have class A calling functions from class B and class B calling functions from class A. If both class A and B are header-only you have a circular dependency between A and B, meaning it won't compile. Of course this is easily avoidable by moving some of those function calls into a separate body file, which can include the definitions for both A and B. I find the notion of having just a single file per 'thing'(*), instead of the customary pair of files as we have now, to be generally attractive. It means we can keep things like declaration, definition, and documentation together in the same spot, so we have less repetition and less boiler plate code. I'm basically trying to get a feel for how well such a style would be supported by the proposed module system. I guess the build system would have to be sufficiently smart to understand the difference between a change in an interface, and a change to a definition - but maybe that's outside the scope of the proposal itself? 
Well, I'll have lots of fun avoiding your code then. In my experience every C++ program over a certain size either uses boost, or contains a bug riddled, crappy implementation of multiple boost libraries (common candidates: filesystem, datetime, optional, variant, any, hash, PP, fusion, ptree, interprocess).
&gt; the peer review wants a "pure Boost" submission I feel that this is doing more harm than good. This just gives bread to people saying "boost is bloated" because it makes one more subfolder in `boost/`, and takes useful development time. What's the problem with good libraries living outside of the boost shell ? Isn't "peer-reviewed by boost" enough of a justification on the lib quality ? Also, the lib then has to follow boost's release cycle, while some libs may gain from quicker iteration cycles at some point in their development.
No nothing wrong with it, if you are programming for shits by all means. It's just when you want to get stuff done, avoiding it makes no sense. You can put together a decent smart enum in just a few hours with boost PP. Without it, unless you already happen to know tons and tons of PP tricks, it would take days.
Ultimately it's for Boost to decide what criteria they want to admit libraries. The peer review said "no non author written code" and "no git submodules". That pretty much left script generated boost editions as viable. This has precedence, ASIO and quite a few libraries are standalone first, script generated Boost editions. If people want the latest version, standalone is always available.
"size 1 container" is a bad model for optional Containers don't - propagate operator= - propagate operator&lt; et al - compare with their element type (ie `Container() &lt; element()`) - use operator* to get the element - convert to bool - ... The model for optional&lt;T&gt; is "T with an extra special value". But that's not the right model either. The right model is "controlled lifetime. Warning: assignment will assign or construct."
I'm currently reworking standardese to use cppast as parsing, but I unfortunately don't have much time currently (exams), so it will take a couple of weeks still. You can try and see whether cppast parses outcome, and file issues there.
1. Yes, this determines the libs/SDKs you pick up. 2. Clang/LLVM is an add-on to VS from the LLVM folks. You'd have to modify/update their VS extension to change the compiler. 3. /u/STL will probably know more about that one.
&gt; I know those coming from Rust-land feel amazement how long it has taken C++ to replicate Rust's Result&lt;T, E&gt;, but I'm very sure ours is enormously superior to theirs already simply by doing so much less because it doesn't need to. LOL. What a ridiculous claim to make, all the more so by not even trying to justify it. Look, obviously Rust's is vastly superior because of all the additional language support that Rust offers: pattern matching, a better macro system giving you `try!`, and the addition of the `?` statement terminator. Moreover, "doing so much less" is just a fundamentally bizarre claim given how little Result in Rust actually does. It's just a variant of two types with a bunch of member functions, all of whose implementations are tiny. It doesn't do anything. And I'm not even a Rust guy. 
Thanks for the reply. I think I have successfully managed to hack the install.bat file in C:\Program Files\LLVM\tools\msbuild to do what I need. Note: I see the PlatformToolsets folder is now in a completely different place for VS2017 rather than in C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\ for VS2015 (and seems to be tied into the version of VS installed {Professional in my case}) 
Oh I'm definitely a few weeks out from needing to tackle Standardese myself too! The WG21 paper will take at least a week, then another to deal with all the reviews coming in on it. And at some point I really need to go get a job, as much as it's lovely spending all my time with the family and writing Boost and STL code, no income becomes a problem after a while. So I can easily wait.
sorry, for OT but what's "the ? statement terminator"?
&gt; LOL. What a ridiculous claim to make, all the more so by not even trying to justify it. Look, obviously Rust's is vastly superior because of all the additional language support that Rust offers: pattern matching, a better macro system giving you try!, and the addition of the ? statement terminator. The big, and continuing, difference between the new systems languages like Rust and C++ is how much thought and consideration is invested into correct design in C++. And, quite frankly, that is definitely not the case in Rust where they have made some really bad design decisions which are crippling end users with some awful tech debt. Outcome's `result&lt;T, E&gt;` does even less than `expected&lt;T, E&gt;`. Fewer member functions, less type sugar, less complexity. Even simpler. And both are but waifs compared to Rust's `Result&lt;T, E&gt;` which has an enormous number of not well thought through member functions. Neither this Result nor Expected have repeated that mistake, and I expect that both will slim even further if they are standardised. Less is more!
Yes, and the arguments are more likely to end up on the stack rather than in registers. In theory this can all be fixed by the optimizer, but I wouldn't rely on that if it's actually a hot code path.
Writing: T var = foo()?; Has approximately the semantics of: Result&lt;T,E&gt; __tmp = foo(); if (!__tmp) return __tmp.as_error(); T var = __tmp.value(); Here's the [doc](https://doc.rust-lang.org/std/result/#the--syntax)
useless bikeshedding... 1 is sad because it just gives more influence to people who give infinite weight to backwards compatibility since now they can be even more irrational when somebody proposes new keyword... also 5 and 6 are exaggerations or lies to be more precise since C++14 and C++17 shipped without any major features. So what committee should be doing: see how to speed up the process, it is hilarious that Herb presented almost working metaclasses compiler, but in the comments he said no way this is gonna be ready for C++20 because it is only 2 years... LOL 
I think it is interesting that the C++ committee seems to be stepping back and addressing the question as to what the scope of its work should be. It's a good time for this. It's sort of amusing that the statement seems to be modeled on the US Bill of Rights which are the first amendments to the US constitution which limits the scope of it's application. The problem in this is that it only make sense as an addendum to an affirmative statement as to what the committee should or intends to do - which is not explicit here. As I understand it, the C++ committees purpose has been stated as "Codify existing practice" which seems to me to have worked pretty well. Until now. Of late, the committee has embarked upon ambitious programs to design new components. Ambitious efforts to design components such as network TS and ranges are misguided in my view for the following reasons: a) These turn into huge efforts which take years of committee meetings. Consider network TS. ASIO has been available for several (10) years. Now the committee is trying to "improve" it and looks like they'll be done in a few more years. Meanwhile we ... what? We just continue using ASIO. Now when network TS is "out" it may well be obsolete or behind the available technology or practices in some way. This is an example of a huge wasted effort by all involved. It's not going to get us anything. b) It's unclear that it leads to good design. Consider Ranges TS. This idea has been around and has been realized by a boost library - boost.ranges. So far, so good. It has become apparent that there are opportunities for improvement, refinement and improved robustness for design. So far so good. So Ranges TS has been created. And a demo implementation has been crafted. But in order to craft this implementation, some other components were necessary: * a modern version of boost.mpl for template meta programming support * an implementation of concept checking. The standard doesn't include these (yet) so the Demo includes sub libraries for this. This suggests that a standard solution would need to have similar components in the standard or create a ranges component that includes this functionality within as an implementation detail. If somehow this were to be addressed, it would almost for sure need to be improved in the future - but now stuff would be "locked" into the standard. c) It seems a lot is trivial and not worth the effort. How valuable is it for the committee to take up the design of a ring_view (or ring buffer or ring span or whatever)? Most of use can craft one of these in a few minutes. If can't or if we want a more rigorously designed one (with tests, type requirements, documentation, etc.) we can probably find one on git hub. (for some reason Boost doesn't have one). But the committee has had this understudy for years... The above examples suggest to me that the committee has confused the job of "Codifying existing behavior" with the job of library design and development. They are different functions. In society we have institutions which set and enforce rules and other institutions follow the rules and produce goods and services. In general this has worked better than when the same institution tries to do both. At the last CPPCon, I asked Bjarne Stroustrup is opinion of the role of Boost. His answer was off point but still a good one. He said that he felt that the Boost Libraries were too complex. But when I look at the committee's latest efforts, I can't help but wonder if the same observations don't apply. 
Outcome's partial equivalent is `OUTCOME_TRY(var, expr)`. Yes I definitely agree Rust has us licked on that feature, and it'll be at least the mid 2020s before C++ can have an equivalent because the current prevailing wisdom is that `co_await()` needs to use the same mechanism as `TRY`, and that's "hard" (TM).
I think it is an excellent set of guidelines. The first four are basically a guarantee that a long-term investment in source code will not be invalidated, making C++ a viable language for business use. And the last three are a guarantee that the language will remain a living, developing entity, and give us hope that any rough edges might eventually be remedied ;-) As for what the standards committee should or shouldn't be doing, one thing that keeps floating through my mind is that there is room in the C++ world for an extended library ecosystem. Adding everything and the kitchen sink to the standard makes the language seem impossibly complex and imposing. However, isn't there some way to somehow elevate existing libraries to a more official level, without making them part of the language itself? Perhaps through a formal review process of some kind? Oh, and perhaps the committee should adopt an additional guideline along the lines of "we promise to not introduce any forms of UB that could be avoided using a single if-statement". There are way too many of those already... 
A construct that I occasionally use is `std::optional&lt;std::reference_wrapper&lt;T&gt;&gt;`. It offers some decent semantics: void perform_work(int value, std::optional&lt;std::reference_wrapper&lt;std::ostream&gt;&gt; log = {}) { std::ostream &amp; out = log ? *log : std::cout; out &lt;&lt; "Value is " &lt;&lt; value &lt;&lt; std::endl; if(value &lt;= 1) out &lt;&lt; "Done!" &lt;&lt; std::endl; else if(value % 2 == 1) perform_work(value * 3 + 1, log); else perform_work(value / 2, log); } The semantics of this code, then, are "*If you have a specific stream you'd like to use for logging, use that, otherwise use the standard out stream.*". The only thing you have to watch for is that `operator*()` returns the `reference_wrapper` object, not the `T&amp;` object. This implicitly converts to `T&amp;`, which is why my example works, but if you don't "seat" the reference like I did, you have to call `.get()` on the `reference_wrapper` object to actually do work.
&gt; How valuable is it for the committee to take up the design of a ring_view (or ring buffer or ring span or whatever)? Most of use can craft one of these in a few minutes. If I want to use, say, 5 third party libraries in a project, I don't want to see 5 hand-crafted `ring_view`s. More importantly, if I don't have a `ring_view` at hand, I tend to seek for less convenient or less efficient alternatives instead of write one, because I consider the gain in convenience and efficiency not worthy of the effort of crafting a `ring_view`. This might be alleviated if there's a good package manager, but even then I might not want to add a dependency to my program.
Will it support (abuse) `co_await`?