&gt; Does anyone use std::enable_shared_from_this I'd go so far as to say that if you're _not_ using it, you're doing it wrong. :p &gt; It seems to impose some serious restrictions so I don't think I'll be using it. I can think of literally zero limitations it imposes; that is, I can't think of anything you were allowed to do without it that you aren't allowed to do with it. The only limitation it imposes on its own use, really, is that you have to put the managed object into a `shared_ptr` before using the additional feature of `enable_shared_from_this`. And since you should _always_ be using `make_shared` for anything destined for storage in a `shared_ptr`, that limitation is essentially academic.
You'll want to post this in /r/cpp_questions instead.
Your grep was just for "valarray". With a grep of "\bvalarray\b\s*&lt;", (i.e match whole word for "valarray&lt;" )I get 25,039 results. For "array&lt;" I get 78,190 . "vector&lt;" gives 1,327,752.
And include _what_ doesn't work.
Hi, great presentation. Thank you. Looking into MapUtil helpers, just curious, there is protection for temporary default value in case of `get_ref_default()`. But there is no protection against temporary map itself, so someone can write: int v = 1; const int&amp; r = get_ref_default(std::map&lt;int, int&gt;{{2, 2}}, 2, v); and get dangling reference. In general, you are trying to avoid mistakes in most common cases/errors, right ? Were there errors like above ? Do you have some crazy examples of going too far while trying to handle all possible errors you know about ? :) 
&gt; And since you should _always_ be using `make_shared` for anything destined for storage in a `shared_ptr` This is overstated quite a bit; in at least half of my code that uses `shared_ptr`, `weak_ptr`s are expected to outlive `shared_ptr`s and using `make_shared` is a clear pessimization.
As far as I remember it was a modified Tie fighter. The bombers had different shaped wings.
I'm not sure why you say that not doing it is wrong. I'm sure it has uses, but when you don't use it you have the advantage of knowing that anywhere the object is passed by reference or raw pointer, it can't take ownership. I've never really felt the need to use it, I don't see what is fundamentally wrong with that approach. 
Disable precompiled headers
Didn´t work :/
Thank you i try it !
I get the Error "Cout is undeclared designated" 
No you don't.
Yeah, I use this quite often too. Not sure how you could use certain common patterns in asio well without it. At least not without jumping through hoops.
That's basically it. Catch is a C++ testing framework that I find to be easy to integrate with a project and easy to write tests for. It works well, it is being kept up-to-date, and the main developer pays attention to user comments &amp; issues. So I guess a lot of people use Catch. I know I do.
Make a new project with precompiled headers disabled and delete everything related to stdafx
ASIO 1.11 (or upcoming Boost.ASIO in 1.66) now supports move-only continuations, which eliminates the "need" for `shared_ptr` in a lot of ASIO code. :-D
It bugs me to no end that accumulate is called that and not fold or foldl.
Interesting! shared_from_this still has a huge amount of uses. I was just picking the example I was working on today and seemed as good as any! :)
This is low effort bait.
Thats hard because i have the German Language and translatet is so to english :p
I also don't get why it's in &lt;numeric&gt;. It's not at all specific to numeric values.
It's not a very often recurring bug, but I encountered a bug once, where I found a new language feature I didn't know even existed before(similar to std::string(foo); ). We had a line of code similar to this one: std::vector&lt;int&gt; ints((20,255)); What would you expect to be in the ints vector? 20 integers with value 255? The answer is that (20,255) is an operator which evaluates the left argument first and then return the value of the right argument. (20,255) will evaluate to 255 and the vector will end with 255 elements (instead of 20 with value 255).
Didn't quite get that edit thing about thankyou..?
That one has caught me out also. It might happen more than we think. It's pretty unintuitive with regard to the way parentheses work in math, and a lot of people with math background write C++. My favorite "typo that compiler will accept and do something unexpected" type bug is something like this I wrote some time back: class A{ void foo(); }; class B: public A{ void foo(); }; void B::foo(){ A:foo(); } 
The operator is actually just the comma by itself. It's exactly the same as the comma operator you'll more commonly find in loop expressions if you are doing something like incrementing multiple variables. The extra wrapping parens just happen to allow use of the comma operator in a list context where comma otherwise has as special meaning (e.g. a function call).
I don't think I can be clearer than "your thanks post has been downvoted because it should have been an edit." I even explained why it should have been an edit. Please, read my comment again.
I mean what do you mean by "it should have been edit"?, Do you mean i should have edited my question to put it there? Sorry if i sound silly
I faced the exact bug that he mentioned unique_lock&lt;mutex&gt;(m_mutex) Spent a night on that one. Never figured out why that compiles. :) Now I know.
http://lmgtfy.com/?q=c%2B%2B+metaclasses
I've used this for personal projects previously and really liked it. Now that I've worked with Google test, I really appreciate the ability to run tests over vectors holding parameters but also types. I know catch was discussing such an ability; has there been progress on that end? I couldn't identify it in the change log.
Removed. The Who's Hiring sticky is the only appropriate place for job posts.
Yeah, removed this post.
Fair enough, I guess there's a lot of bias in what languages I think are "common" based on industry and problem domain, and my experience is not as generally applicable as I imagine. (And my previous comment is at negative votes so clearly quite a lot of people disagree with me.)
Well, I disagree - this isn’t a random C++ job, it is a job to work on C++ compiler
Why use that over a vector?
It's like complaining you can't upload porn to facebook. No duh man, it's not what it's for.
Why not clang to keep it completely GNU free?
Was there any big changes to compile time?
So, what about libraries? Do you use them? Would I have to convert all the CMake using libraries to this stuff? The main reason why normal people use CMake is because it's popular and better than autotools. You won't change that with something that requires C#. Not very popular, neither in the open source Unix world, nor in the C++ world.
Compilers will warn about unused variables anyway.
Catch 22 will only be released if nobody wants it.
I suspect the median of medians solution has poor real-world constant factors, but haven't implemented it myself. Looking at our implementation we use straight-up quickselect which is technically nonconforming :/
At least, it's missing non-blocking continuations which are necessary for efficient behavior.
Is it on any modern major implementation? Using a pointer allows undesirable implicit conversions from vector&lt;Derived&gt;::iterator to vector&lt;Base&gt;::iterator.
pkg reports no clang package yet, unfortunately
the last tildes have a space between them and the words
When will we have property based tests?
The new parallel version of `std::accumulate` in C++17 is actually called `std::reduce`, which makes much more sense. http://en.cppreference.com/w/cpp/algorithm/reduce
Ever heard about #pragma once? Never used a compiler that didn't support it. 
&gt; Looking at our implementation we use straight-up quickselect which is technically nonconforming :/ I'd say more than just technically. I checked out the GNU STL implementation of `nth_element`. It does a Quickselect, switching to Heapselect. The switch is done if the depth exceeds 2 lg *n*. But that's the wrong way to do it (see [Musser 1997](http://liacs.leidenuniv.nl/~stefanovtp/courses/StudentenSeminarium/Papers/CO/ISSA.pdf) \[PDF\], page 9). So it appears that good implementations of `nth_element` are few &amp; far between.
Hey, quick update from this talk. After I gave this talk, both gcc and clang devs in attendance implemented warnings for bug #6. I've not kept super close tabs on the patches to know when/if they've been committed or on track to be released. But in theory they will both have warnings for code of the form: &gt; unique_lock&lt;mutex&gt;(m_mutex)
Hey, speaker here. Check out my update here: https://www.reddit.com/r/cpp/comments/7ahtuf/cppcon_2017_louis_brandy_curiously_recurring_c/dpb97ly/ tldr: after giving this talk, both a clang and a gcc dev sent patches upstream to warn on this exact line of code. 
&gt; I'd say more than just technically. True. It only "feels" "technically nonconforming" because the number of callers of nth_element is small, and the number who would fall into the n^2 case smaller still :) FWIW I did file a bug to fix it.
You're right. We have no such protections. I suspect as written this would be extremely unlikely but perhaps a function that returns a temporary map, instead, may have this behavior. I'll send a patch to our CI system and see what breaks. 
I learned something very useful from this talk: When a presenter "quizzes" the audience with C++ questions, sit where you can see Richard.
Can you recognize the pattern of calling new at the beginning of a function, and then deleting that object at the end of the function? ie code that could be replaced by putting the object on the stack? (Unless it is a very big object or something.) I see that pattern typically from ex-java programmers that had to call new on everything.
It is meant for numerics. It supports arithmetic operators and is meant to use expression template technique, potentially providing optimized computation of expressions (like 'x = a + 0.5 * b' would be computed in one loop and without temporaries). But it did not get too much traction, and I am not what is the status of optimization in major implementations now.
I bet "jl .myfuncLabel; mov $255, (%rax)" works faster than "cmovge %ebx,%edx; mov %edx, (%rax)" simply because latter uses two extra registers (ebx/edx) with dependency between them. I.e. half of this (decent) presentation is about a problem in optimizer.
[std::put_money](http://en.cppreference.com/w/cpp/io/manip/put_money) and [std::money_put](http://en.cppreference.com/w/cpp/locale/money_put).
Wow! That's awesome, and why it's so important to share these problems as you did. Really enjoyed it!
pragma once isn't c++, and its behavior is obviously very different from the include guards
As a game developer, the talk was interesting; but it feels out of place for CppCon. The only parts related to C++ were them saying they use C++03 for compat, and a short list of C++11 features they might use. Would've liked to have seen some snippets of code of how they optimized they're compression algorithm, etc. 
You might be right, especially given that his timings were worse until he replaced the source of mov from a register to $255. 
yep. and this is why assembler guys were always laughing at claims that compiled code is as good or near as good as hand-written one.
That's because it is off-topic on SO. The two sites don't have the same purpose.
Curious, isn't Dragonfly BSD FreeBSD based?
But without the aches and pains off Boost's MPL. 
Exactly. Its main focus was for mathematical and scientific usage but these kind of programs tend to use specialized libraries anyway. In addition it's not very straight forward to use. I would rather do it in Fortran to be honest, which is meant for that.
Not obvious to me, please elaborate.
Unless I'm misunderstand what you're saying... to be non-blocking, wouldn't we spawn a new thread? And wouldn't we use async for that? auto my_future = async([] () { return 42; }); auto my_future_2 = async([my_future = move(my_future)] () mutable { auto value = my_future.get(); });
It's sane and safe to use. Big difference!
Yeah, everybody will be emitting LLVM byte code and let it do the work. Kind of what binaryen and rust do, if I'm not mistaken.
Can compilers not inline functions defined in module interface files then? Or will that be tied to the inline keyword or a per function export command?
I have seen an identical pattern from kernel devs, where they are concerned about stack usage.
We might push Sharpmake files for different libraries. This is really easy to do and I know some developers were interested in doing that. Internally we had both Premake and CMake usage and most got eliminated on individual projects initiative (Ubisoft is strongly bottom up). For big projects it became a no-brainer. Sharpmake also supports to wrap simply existing project files, generated or not, even if I don't suggest to go that hybrid route. I think you're right about “normal people”, even there if you look at the post on gamedev reddit, some ex-Ubisoft already planned to use it at home, knowing how easier to use it is (and I know actual Ubisoft developers with same intentions). But I think Sharpmake initial adopters will be big projects, since it's so much faster than CMake or Premake. There are companies where programmers waste minutes at each sync of code; if they can change that to a few seconds while having definitions easier to maintain, a conversion to Sharpmake might pay itself in a short time. I have no idea if Sharpmake will be adopted or not; time will tell. It's true C# is not popular on Unix, but I don't think Lua or CMake macro language are so much loved either. C# would probably be more popular if Microsoft would have made it open-source 10 years ealier, but at least now it is. Keep also in mind Sharpmake has been made by C++ programmers for C++ programmers, and the C# usage in it is close to C++ by design. About the C++ community, C# is actually quite popular in the gaming industry, and we tend to have big projects, use solutions like FastBuild, so Sharpmake is a good fit. All that to say, Sharpmake in its current state is already the best solution I know for some C++ programmers, and this is the main reason we make it open-source. Who knows, maybe some will enrich it or write conversions scripts to make it more adopted...
Assuming your active object only has one outstanding io operation...
I don't think `operator[]` is that bad. Sure, there are some cases, where you may not want the insertion of a new element, but on the other hand there are cases, where this is really useful and makes your code more compacy. Imagine for example a `map&lt;string,vector&gt;`. If you had to initialize every vector before first usage, that would make loops like the following a lot more annoying: for (Something e : some_list) my_map[e.a()].push_back(e.b()); Javas maps have a similar interface without [] and they are pretty annoying to use imo.
Maybe we could reuse free standing `&lt;&gt;` like `&lt;my_reflected_variable&gt;` as `&lt;&gt;` is a little bit similar when used with templates. But I guess that would make parsing C++ even worse.
I really wish they'd gone for `public` instead of `export`.
type_index
This is my biggest question as well. I found Catch to be too heavy with respect to compile time and thus I never really found a use for it.
Some obvious differences that come to mind: - you cannot #undef a pragma - you cannot put stuff in the same file outside pragma like you could with #ifdef I think there is a reason why pragma once has not made into the standard yet. You can find a bit more details there, https://stackoverflow.com/questions/23696115/is-pragma-once-part-of-the-c11-standard
&gt; to be non-blocking, wouldn't we spawn a new thread? No, we would want the thread that did the work to go off and do the successor work too. But with `std::async` that could be the first thread that called get() that does the work and that's often undesirable. &gt;I suppose this could spawn a lot of threads all at once (one for each continuation) We want future to be able to express thousands or millions of concurrent operations. Creating a separate thread for each one would be unusable for that solution. ``` auto my_future_2 = async([my_future = move(my_future)] () mutable { auto value = my_future.get(); }); ``` This code has extreme likelhood of causing stack overflow bugs, since the destructor of the outermost future will run the dtors of all the futures in the chain, recursively. And what's worse, all the work of all those futures is likely to happen in the first thread that calls get(), since `async` can return the futures in deferred mode. 
* I feel like using lots of small allocations is sometimes unavoidable, and/or the work required to avoid it results additional classes or strange code. * The most common thing I see in terms of poor allocation performance occurs when you don't allocate a large enough reserve for an array, and then the array requires constant reallocations as items are added. Although this is generally easy to find and fix, I feel like it might be worthwhile to try and identify. * I like the idea of lifetime hints, but there are many cases where lifetime is determined by things the user is doing, or for user convenience. Ex: the user destroys something. But you want to keep it alive for some indeterminate amount of time in case they want to revert. * A tool like this could be useful, but its usefulness would decline sharply if it constantly identified false positives. * I also think that it's important to remember that allocation strategies vary by problem space, and one man's poison is another man's steadfast requirement. There is a comment in this discussion about kernel devs being concerned about stack space. How would your allocation checker know that the new/delete calls were ok in one domain, but not in another? Something that might be generally useful is to write a tool that could somehow figure out that memory was likely to become fragmented. This might be something that was super useful.
You know, I never considered inserting a random string into my include guards, but that's an interesting an idea. After seeing this, I had the sudden urge to add a random function to the [guardonce](https://github.com/cgmb/guardonce) pattern language... but perhaps I should give the thought some time to digest first. I think there are really two advantages. First, you can be pretty sure there will never be any collisions between guard symbols... though, that's true of regular guards too if you include the project name and filepath in the guard. So, maybe just one major advantage: you don't have to rename the guard when you rename the file. In terms of disadvantages, I don't see too much. I suppose the biggest concern is that if somebody copy/pastes some header, it's even harder to notice that two files have the same guards when there's no particular pattern to expect from them. It's also a tad annoying to have to run a program to get a new guard name. I'm not sure I'm really sold on the idea, but it is interesting.
Sorry, I don't know about any other projects use it. Well, I use it in all my projects. :) You made a very good point about copy/paste. However, one could improve on the idea by including a particular patter (file/project name?) just before the UUID. I guess... 
I did that exact same thing many years ago. I'm mostly disturbed that until today I misunderstood what was happening. I thought I was creating a unique_lock temporary that locked and released m_mutex. The idea that I was shadowing m_mutex never crossed my mind.
This is exactly what I thought was happening the first few times I saw it as well. Honestly, I think most people think this when they encounter it. That said, there are definitely ways to accidently have a temporary constructor (rather than a declaration) and have it be bugged. This is partially why I think something like [[nodiscard]] on constructors for RAII types might be useful. 
Good one, thanks!
At the moment, no, but if the free() stack trace is compared to the alloc point then yes, I'm quite sure this can be done reliably. Thanks!
Some good points here, thank you. I hadn't thought of fragmentation, but it might be possible to work that in here as well. The tool does already flag instances of constant/increasing size reallocations. I do agree that in some cases, heap use behavior can be a bit subjective or subject to constraints that the tool cannot possibly know about. In these cases, while the programmer would be presented with the facts and some inferences/analysis made by the tool, they may still have to do a little interpretation of the results. Things like flagging new/delete in the same stack frame could be subject to user-specified size parameters as well, to make things more flexible. Thanks again for your feedback.
About 10% give or take on files with a lot of tests. Another 20% if you weren't previously using `CATCH_CONFIG_FAST_COMPILE`. There also some constant improvements (those that save a fixed amount of time no matter how many tests there are).
The parallel version assumes the binary operation to be commutative though, which makes it useless for a lot of use cases - and it is still in numeric :)
You cannot make it parallel unless you assume the operation is commutative. This is not an issue in std library, it's a mathematical restriction.
That is not true. Associativity is enough. See the boost.compute implementation or thrust or any other for that matter.. .
SO is a QA site. It intends to archive searchable questions. If your question is too broad, it won't be answered for the next person, and if it's too specific it won't be searchable. Reddit is a community-driven discussion board; anything that community finds interesting is interesting here. We are not (necessarily) trying to find answers, but discuss interesting topics to learn, spread cool ideas etc...
Yes, you're right. I mentally executed an algorithm that keeps operating to left, but that doesn't work. Sorry about that.
I just commented you're right. But on a second thought, no just associativity is not enough since if you it won't guarantee which side of the computation is done first. So, associative only functions makes it slower. It seems like they could include both to the std library (like boost compute).
You seem to be right, but they seem to be different algorithms (just associative vs associative+commutative) and the latter is faster? (You do not have to ensure the order is right, so you can just make worker threads execute in whichever order)
If you assume associativity (which is already violated for most IEEE floating point operations) you can compute compute partial results and combine those. This is a must for fast parallel implementations. I genuinely have no idea why commutativity is needed here as this would mean reordering the arguments rather than the invocations of the operator. An example of an associative yet not commutative operation is string concatenation.
Thanks for the detailed answer. I see how it can be useful to some people. Good job releasing it (at least what you're allowed to release). Has somebody tried to building Chromium with it?
Yeah I should have written operation instead of operator.
Andrei Alexandrescu proposed an adaptive quickselect algorithm a few years ago in [*Fast Deterministic Selection*](https://arxiv.org/pdf/1606.00484.pdf). That could be another algorithm usable to implement `std::nth_element` if needed.
BDD (Behavior Driven Development) is one of the ways you can write tests in it and it's pretty awesome - https://github.com/catchorg/Catch2/blob/master/docs/tutorial.md#bdd-style
In what way would that have made a difference?
From the changelog: - Removed legacy generator support - Generator support will come back later, reworked
https://github.com/catchorg/Catch2/issues/849#issuecomment-341844226 - Any news on property based testing? - You'd think my track record would make you think twice about asking for estimates ;-) I'm afraid I can't give a timeline, other than that it's high up in the queue!
you can checkout [doctest](https://github.com/onqtam/doctest) if compile times are a concern for you - it is very similar to Catch ([here](https://github.com/onqtam/doctest/blob/master/doc/markdown/benchmarks.md) are some benchmarks)
I think it's mostly about familiarity when first being introduced to it. Other languages use public (Java, D, others?). And then there's the "export import Bar;" that most people get hung up on before they know what it does. Maybe "public import Bar;" would be less confusing? I don't know.
I honestly never even thought to try that.
Does anyone know if you can put [[no_discard]] on constructors? Is there a legitimate reason to lock a muted and immediately release it?
I installed the YouTube addon in Kodi yesterday, so I could spend my evening watching Chandler Carruth talks. 
One could argue that this is yet another reason to use {} instead of () in variable declarations. `std::string{foo};` doesn't compile. I'm a little surprised this wasn't brought up in the talk, actually.
No, I don't believe the standard library should do this. [] is still an excellent way to put information _into_ maps, and deprecating it would cause massive breakage. 
WHY ?
 std::vector&lt;int&gt; vec = {1, 2, 3}; cout &lt;&lt; vec [3]; // oops In arrays and vectors, the default choice for accessing a non-existant element is UB. Given a choice of a well-defined side effect, and UB, I prefer the well-defined side effect. Besides, it could be argued that if it appears on the right hand side of an expression, it should really be const, so you wouldn't even be able to call []. 
Both `public module` and `public import` would make a lot more sense.
Because I say so
Those are good points. The proposal isn't finalized yet, so maybe the committee is willing to take up your proposal.
I'm writing a genetic algorithm too at the moment! Do you have any other useful C++ features/tips that could help me?
Sadly valgrind / ASAN aren't enough to overcome buffer overflow. #include &lt;vector&gt; int main() { std::vector&lt;int&gt; vec; for(int i = 0; i &lt; 10; i++) vec.push_back({}); return (vec[15] = 1234); } neither valgrind nor ASAN nor UBSan is able to detect anything wrong here
Thanks for the talk, it was useful and fun to watch. What linter tool do you use?
Some of them, I guess, are out-dated: - `_GLIBCXX_PARALLEL` -&gt; `std::execution::parallel_policy` Some are still worth a look: - `_GLIBCXX_DEBUG` is [being used by Chromium](https://bugs.chromium.org/p/chromium/issues/detail?id=65151) - `_GLIBCXX_CONCEPT_CHECKS` performs concept-like checking for containers, but I'm not sure to use it or not since [its documentation](https://gcc.gnu.org/onlinedocs/libstdc++/manual/ext_compile_checks.html) states only C++03 compliance. I wrote a short article about it at [here](https://gist.github.com/htfy96/2056f0f85337c764d28ebf9861c7bc74).
Don't be afraid to write your own STL-like algorithms if it makes your code a lot cleaner to understand. For example, to implement mutation, I wrote a helper function called `sample_and_apply` which takes an iterator range, a number N, a random source, and a callable object. It internally calls `std::sample` to collect N values from the range, stores them in a temporary vector, and then applies the callable object to each one in turn, modifying the original elements in-place. For crossover, I likewise use a small helper function to do rejection sampling over an iterator range. That way I can ensure that my crossover biases itself toward genes with a higher fitness. But the `rejection_sample` function doesn't care about what it's used for. It's just there to do rejection sampling. Writing small re-usable functions like this, my actual implementation of the genetic algorithm is concise and (imo) easy to read and understand.
WHY NOT?
&gt; you cannot #undef a pragma people who #undef header guards should not be let anywhere near a code base 
This is interesting, and a step in the right direction. I also agree with other comments that you might as well strip the formatting string entirely, and keep a side map with ID to string mapping. Most of my experience is writing windows device drivers, and the recommended windows specific logging platform is WPP, which rides on top of ETW events, and is exactly that: the log provider only provides an ID and a buffer of parameters. The buffering is done by an out of process entity (specific OS buffers) and the formatting is done by the client/consumer of the log. While this does entail it's own issues (versioning hell, and having to have a separate tool to enable/disable logging, and parse them), there are very clear performance benefits. Honestly, I'm now convinced that for all software (user mode including), logging facilities should generally be an OS provided service. This solves a lot of issues about log file management, logging app launch and app teardown, as well as access to logs in cases of crash dumps and during debugging.
HL3 confirmed.
Maybe there's no buffer overflow here, due to vectors growth factor. I think UBSAN catches this, though.
Well, that's because (depending on stdlib; let's assume the capacity is at least 16) there isn't anything wrong here. You've violated the (stated but not enforced) contract for `vector`, but there isn't any UB or anything else for UBSan or ASAN to complain about.
This is still UWP only, right? If so that is a trashed, users still expect apps to work on win 7.
The only point of this talk seems to have been "don't even try to keep stable ABI because you will break it anyhow". Not exactly sure why was it worth spending an hour to make this completely trivial statement.
There is a UB and the reasons you pointed out are only a good excuses why it does not catch it. Even if it grew 16 elements, the 15th element is still not constructed (std::vector uses placement new to create new elements in the allocated array) so accessing that is UB. 
I partially agree with his arguments. Is indeed useful to have single meaning functions (sort, findif, reverse, or even addressof, sizeof) that are generic, widely applied and effectively extend other classes. I also believe that the function itself encapsualtes the implementation, while providing a re-usable API. However, while watching I came to the realization that at least half of the issues solved are just a result of daily lazyness of design. We don't go far enough with Single Responsibility Principle. The fact that class X has to implement a private 'resetValues' function is a result of not properly encapsulating the data management of std::vector in a class that acts as a value container,. If were were to really go with the OO design - then unless X's only role in life is to contain a list of values, then I'd argue that X should have a collaborator called 'ValueContainer' whose API includes "resetValues'. I mean, yes, I also don't usually avoid decoupling tiny responsibility chunks from the main class, relying instead on private methods (or even static free functions in the .cpp file). Perhaps the example picked - reset - is indeed a generic term that *should* have it's own global free function. However the WebBrowser example is clearly an API issue. It's obvious the WebBrowser class would have a CacheManager, HistoryManager and CookieManager collaborator classes. I would argue that the WebBrowser class should expose that functionality as a seperate Interface/Collaborator object. The same way that C++ containers expose Iterator objects as a safe and standard way to perform standard tasks relying to enumerating / transforming, the WebBrowser class should probably expose CacheManager/CookieManager objects to safely manage it's inner state. 
Please format your text as code. That aside, I think a separate (sub-)module for each container might be overkill, but I don't really know, what the advantages and disadvantages of a finger granularity are. The level above (std.core, std.concurrency ...) looks imho fine. However, I'd put string in core.
Does MSVC catch this in debug mode?
I also think that public is more intuitive, as there is a certain (although weak) ownership model behind modules. On the other hand, this would imply the existence of a "private" keyword as well. In the end it probably doesn't really matter.
Making as few modules as possible is best. You end up with fewer binary module interfaces, which makes a compiler's job easier (less fragmentation)
brutal... what would you do to them? ;) it's totally legal and you may not even know you did it... boost 1.59... #ifndef BOOST_INTEGER_HPP #define BOOST_INTEGER_HPP GCC uses the leading underscore (is reserved by the standard at least) in &lt;vector&gt; #ifndef _GLIBCXX_DEBUG_VECTOR #define _GLIBCXX_DEBUG_VECTOR 1 
The element type is `int`, so you don't have to have constructed it to assign to it I believe. But if you change `int` to some class type you're right that UBSan won't catch the bad `operator=` call.
Yeah- we already have namespaces for organizational purposes. Modules should be a unit of dependency for compilation and linking.
&gt; Maybe there's no buffer overflow here, due to vectors growth factor. well, it depends how you define buffer overflow. If it's only "what's allocated by malloc", sure, you don't have a buffer overflow. But you still have fairly buggy code.
yes, that's why I wrote 'vec[15] = 1234'. Just returning vec[15] triggers valgrind since the variable is uninitialized.
boost 1.59... #ifndef BOOST_INTEGER_HPP #define BOOST_INTEGER_HPP GCC uses the leading underscore (is reserved by the standard at least) in &lt;vector&gt; #ifndef _GLIBCXX_DEBUG_VECTOR #define _GLIBCXX_DEBUG_VECTOR 1 all that typing ... (
I would guess so, likewise for GCC's -D_GLIBCXX_DEBUG. But for instance clang's libc++ doesn't have one.
My point is that I wouldn't expect valgrind or ASAN to find this, because it looks like safe, valid code. UBSAN is designed to find this type of bug. It's UB to acces vector out of range, as you said.
Why do people keep making the breakage point? Deprecating a feature does not equate removing or changing it. By itself it would have no effect on existing code, except perhaps a compiler warning.
&gt; there isn't anything wrong here. yuck :) I guess you never had to spend three hours debugging because of a situation that looked like #include &lt;vector&gt; struct foo { int* x{}; foo() { x = new int(0); } }; void do_something_with_foo(foo&amp; f); int main() { std::vector&lt;foo&gt; vec; vec.reserve(10); // ... insert some long and boring code here // which used to touch `vec` three years ago but does not anymore do_something_with_foo(vec[15]); }
&gt; because it looks like safe, valid code. you can't be serious :p "safe" from the point of view of ASan, sure, but it's absolutely not safe
The bombers also had two pods - one for the cockpit and one for payload. IIRC, Vader flew a prototype TIE Advanced, which never entered full production due to costs.
None of those are undefs though.
not sure what? you can totally undef them in your code 
Shouldn't this crash with an assert in debug mode?
Thanks for the advice! Which selection methods did you find most effective? (tournament selection etc.)
Yes msvc even would catch if you access outside a area created by = new char[someSize];. On the other hand that makes it painfully slow to use new char for big chunks of memory instead of malloc in debug mode.
Both slow and fast versions were hand written (or hand tweaked). 
Yeah but the point is that you shouldn't, which makes being able to more or less useless.
nope... the point is that your own name could clash or your library users names...
not all compilers have debug mode
Formatted the OP: --- (Disconsider my poor english) As GDR invited the C++ Community to help in naming the standard modules, here I have some ideais. 1 - Let's illustrate with Qt Framework (with hypotetical new names); Considering the Qt Libraries format, they will construct someting like this: // qtcore.ixx module qt.core; export { module qt.core.Object; module qt.core.String; module qt.core.File; module qt.core.Application; // Current QCoreApplication // ... } // qtwidgets.ixx module qt.widgets; export { module qt.widgets.Widget; module qt.widgets.Dialog; module qt.widgets.PushButton; module qt.widgets.Application; // Current QApplication // ... } And the usage will be flexible: // mywidgetsfuncs.cxx // import only one widgets submodule. import qt.widgets.PushButton; void doWork(PushButton *pb) { // ... } // myappmain.cxx // Imports the entire widgets module; // And one core submodule. import qt.widgets; import qt.core.File; in main() { /*...*/ } 2 - Can the Standard have this style? Providing the Standard with this fashion, we will have the choice between minimization of simbols or not How to do this: // std_io.ixx module std.io; export { module std.io.stream; module std.io.fstream; module std.io.stringstream; module std.lang.string; // It can't be out // ... } Usage: import std.io; // imports the entire module and submodules import std.io.stream; // imports only one submodule Others: import std.core; // algorithms, stl, iterators import std.core.stl; // containers import std.core.stl.vector; imports only std::vector import std.lang; // string, locale, regex import std.lang.locale; // std::locale import std.concurrency; // threads, atomics, futures, mutexes import std.concurrency.thread; // std::thread import std.c; // The C libraries import std.c.io; // current &lt;cstdio&gt;
That's why you use pragma once.
`std::exchange` is absolutely wonderful when working with pointers (raw owning pointers in particular, but smart pointers work too). For example, it is a common suggestion to set a subsequently unused pointer to `nullptr` after deleting it. This is typically written as: delete p; p = nullptr; However, with `std::exchange`, you can write it as: delete std::exchange(p, nullptr); When deleting a head pointer and having to set it to some next pointer? auto tmp = head-&gt;next; delete head; head = tmp; `std::exchange` removes the need for that pesky `tmp`: delete std::exchange(head, head-&gt;next); I was really happy to see Ben Deane give `std::exchange` some love in his talk, [`std::exchange` idioms](https://youtu.be/OqJUBIJOojI), where he showed off even more ways `std::exchange` helped clean up his code.
"cmovge %ebx,%edx; mov %edx, (%rax)" version was generated by compiler, afair
That's true, I was only considering the register / constant load versions, my bad. Still, it does show that hand written assembly is subject to performance issues, the same as code generated by a compiler. 
Because SIMD: https://www.reddit.com/r/cpp/comments/6v1gxo/c17_in_details_parallel_algorithms/dlyyyzn/
One use we found for the `std.core.vector` kind of granularity is re-export: imagine you are writing `small_vector` that derives from `std::vector` (and, say, uses a custom allocator). You may want to re-export `std::vector` from your `small_vector` module (for example, because you want to reuse its comparison operators, etc). Re-exporting the whole `std.core` in this case feels wrong. [True story](https://git.build2.org/cgit/libbutl/tree/libbutl/small-vector.mxx), BTW.
My point was that after (at least) 3 decades of progress compiler/optimizer still sometimes makes silly decisions. 
First lines of code I saw: Init = new Node; Current = new Node; Init = Current; that's an unconditional memory leak.
Is that surprising, and is perfectly optimal code generation even a goal? Is it even possible? (yes, the answer is obvious, I know) 
Ah... That is interesting. Also not really important for gpus and hence not required there
It should.
&gt; msvc even would catch if you access outside an area created by = new char[someSize]; Hmmm not as far as I am aware. &gt;On the other hand that makes it painfully slow to use new char for big chunks of memory instead of malloc in debug mode. Got a benchmark showing this?
You know there is already a linked list in the standard? std::list. http://en.cppreference.com/w/cpp/container/list Some notes to help you learn: - don't reinvent the wheel (see std::list above) - your tabbing/spacing is off - makes it hard to read - you have unnecessary variables in your class. For example New is only used inside one function, it could be a local variable - same with Scounter (I think). Also, I don't know what S stands for - naming is important - `counter` appears to only be used for whether you are doing your first insert or not? How about just starting Init and Current as null, then you don't need a separate variable. Less variables == less state == less bugs. Note that if I add the first element and then delete it, counter doesn't get reset to 0. Should it? Should we be back to the same state? In the constructor you do: Init = new Node; Current = new Node; Init = Current; where did the memory of the first `new Node` go? - del() doesn't call `delete`. No where in your code is there a call to delete. That would be good, but only if you didn't have calls to `new`. (So the destructor doesn't delete anything either) - showall() should not be a function of the class - it can be written outside the class, without internal knowledge. And what if I wanted to write somewhere else, like a file or stream? (You could at least take a stream as a param to showall(). ie Let a user call `showall(cout)` if they want. - if statements can have else clauses. Instead of if (counter != 0) { ... } if (counter == 0) { ... } do if (counter != 0) { ... } else { ... } - your destructor calls exit(). Don't you think I might want my program to continue even after I'm done using your class?
I agree that it will just work on all implementations, but I don't think that the standard guarantees that (even if we have guarantee that the element is in range of capacity)
My understanding is that it is just as required for efficient behavior on GPUs, at least according to the docs the NVidia folks sent me: http://research.nvidia.com/sites/default/files/pubs/2016-03_Single-pass-Parallel-Prefix/nvr-2016-002.pdf
circles :) pragma once isn't c++
Right now I'm doing weighted selection for crossover, so that more fit genes will get picked with higher probability than less fit. For mutation, I'm using purely uniform selection, so everything has the same chance of being mutated.
Im going to say it again. export import is silly. Even if you know what it does it still requires a little bit of brain work to see those two opposing words together.
Deprecation is an announcement that a feature is intended for removal in the future. If you don't intend to remove it, what exactly is the point of deprecating it? Just to annoy people who are using it correctly, and I still like to hope that that is the majority, with pointless warnings? 
Couldn't you import all of std.core, but only specifically export vector? I have no idea if the syntax actually allows that, to be honest... 
Valgrind and ASAN are not designed to catch bugs. They are designed to catch undefined behavior. The code snippet you posted is a bug, but it's not undefined behavior.
Arrr was wrong, that was an issue with std::vector!
#1 - wrong, Church of Stepanov crap makes you feel smart, but it does not make you a better programmer rest of it is ok, except I personally do not think attending conferences is productive, although I see why some people may find it fun.
Sorry, I'm not good with markdown. Can you mail me with the core, please? rodrigojose690@gmail.com
Do `export` two times is really need?
Actually, I was thinking the opposite. The standard definitely doesn't allow it (since it's the standard that gives the contract for `vector` after all). But what the particular implementation most of us are using does (namely, allocate up a large enough buffer and write an `int` to a slot in it) is legal C++, so there's no reason UBSan or ASan should complain.
That's exactly what I meant: safe from ASAN's POV. The fact that such code is unsafe is a property of vector that cannot be inferred from the code alone. Maybe if the sanitizer could keep track of lifetimes, but that would be much harder to implement
Or Foly.Poly or Roly.Poly?
Recommend using more range based for and/or algorithms then; if you do that the debug checks will be amortized. (And in the case of range based for, completely eliminated, since you have the whole container we know the iterators can't be transported, etc.) I think I taught the compiler front end to use pointers instead of iterators for range for in 15.3.
Sorry, I got it, I was looking for "-std=c++17" option in the clang-tidy option list, however, it has to be passed as a compiler option, so after "--". 
&gt; UBSAN is designed to find this type of bug. No. UBSAN is only designed to catch misuses of language constructs. UBSAN knows nothing of the library constraints and will not catch violations of any library's requirements except in cases where they also cause violations of the language's constraints.
No, currently there is no support for this AFAIK. There are, however, ideas to use `using` declaration for this: export using std::vector; 
A \_DEBUG build of a standard library implementation will assert on this though. These babies will also assert *sooner* than what valgrind or sanitizers will manage.
Did you try this with UBSAN? I think it won't see it.
They catch more than undefined behavior, eg memory and handle leaks. Those are bugs.
Doesn't the debug implementation of malloc pad those with 0xcd or some such? That detects some buffer overrun-underruns. (Need to write there though, which the original doesn't do :-)).
Yes, it does canaries. But that isn't about new :)
Try creating a compilation database either with cmake or bear and use it for clang-tidy. 
Can anyone explain what is mean by Reflection in one line ? How production code will get benefit from them. Thanks in advance :-)
This. In case you have a project with CMake setup, just pass `-DCMAKE_EXPORT_COMPILE_COMMANDS=On` and just simlink `compile_commands.json` to the source directory (see [How To Setup Clang Tooling](http://clang.llvm.org/docs/HowToSetupToolingForLLVM.html) for more information). Also, `.clang-tidy` config is pretty useful, I recommend creating that.
done that now. 
reflection is the ability to access metadata about your code in itself; eg, list the members of a struct with their name and type, etc
Wow interesting ! It seems like more work to compiler developers lol 
Personally, I think [stackexchange review](https://codereview.stackexchange.com) is better suited for those kinds of questions. That being said, &gt; "In the library the counting starts from 1 and not from 0, thus making it less confusing." That might be true for you now, but I'd recommend you try to get used to 0-based indexing as soon as possible, as virtually any other container you'll find in a c++ library uses it.
Good bot.
Are you sure about that? Because I am 99.9996% sure that TheSuperWig is not a bot. --- ^(I am a Neural Network being trained to detect spammers | Summon me with `!isbot &lt;username&gt;` |) [^Optout](https://www.reddit.com/message/compose?to=perrycohen&amp;subject=!optout&amp;message=!optout) ^| ^Feedback: ^/r/SpamBotDetection ^| [^GitHub](https://github.com/SM-Wistful/BotDetection-Algorithm)
You just indent the code block by 4. Also I would suggest getting [RES](https://redditenhancementsuite.com/)
Certainly having string_view overloads would be good. I have personally found that string_view doesn't work well with legacy code expecting c-strings because it doesn't necessarily have a null terminator. This is the one case I'm aware of where const string&amp; can't be replaced with string_view in a function parameter.
I wrote a zstring_view that is only constructible from either a char* or std::string for just this purpose. It lets me call functions with either a std::string or a char* (without constructing a std::string from it).. and it has a c_str() member function. 
The [mkn](https://github.com/dekken/maiken) build tool is setup to build [boost](https://github.com/mkn/org.boost).context in hopefully a cross compilable fashion. cd ~/tmp git clone https://github.com/dekken/maiken -b master maiken --depth 1 cd maiken &amp;&amp; make nix cp mkn ${SOME_WHERE_ON_PATH} cd ~/tmp git clone https://github.com/mkn/org.boost -b 1.65 boost/1.65 cd boost/1.65 ./mkn.sh mkn clean build -p context -dtOg 0 -a "-fPIC" This will build boost.context for an x86_64 Linux (ELF) system. To build for android/ARM you would need to modify the [~/.maiken/settings.yaml](https://github.com/Dekken/maiken/wiki) file to use a different compiler. And override the properties: boost.sys.arch # System Architecture boost.sys.binf # System Binary Format In order to use different assembly files when building boost.context The mkn command for that would look something like mkn clean build -p context -dtOg 0 -a "-fPIC" -P boost.sys.arch=$newArch,boost.sys.binf=$newBinf I've used mkn to compile using [MSVC through WINE on Debian](https://dekken.github.io/2015/12/29/MSVC2015-on-Debian-with-Wine-and-Maiken.html) before so I hope this is possible.
I use a custom `map` class and it has methods like `get_or_initialize` and `get_or_fail`. I believe that the [] operator doesn't belong to map in the first place. My other peave with `std::map` is that `insert` doesn't insert if the key already exists. It should really be callsed `insert_if_doesnt_exist` :P
zstring_view is also in the GSL. https://github.com/Microsoft/GSL
Updated paper at [P0506R2](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0506r2.pdf)
&gt; stl in not in the syllabus do yourself a favor and disregard your syllabus entirely and learn C++ with a [recommended book](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list)
Yes, you can. The Module TS specification allows that. Nathan Sidwell has a paper to clarify the semantics. It was discussed at the 2017 Toronto meeting. I expect the formal wording to be voted as part of the published TS.
Actually, the exported using-declaration does that. I believe that was also in a code I showed at the Toronto meeting, illustrating how a module projects a view over an existing component that is built with header files.
Fully agreed that we already have namespaces for name organizational purposes. Modules are for expressing more formally the boundaries of a component, its dependencies, and to provide isolation.
It is [not quite](https://bugs.llvm.org//show_bug.cgi?id=32380) ready for C++17
good to know, thanks!
Yes, string should go in `std.core` and we should find a way to disentagle it from IO.
You won't be disappointed :)
OK... prepare yourself for the proverbial "compliment sandwich". I think your question is a good one, and the motivation is sincere. That said, I don't think it will happen, and I don't think it *should* happen. I'll enumerate some of my thoughts and reasons why. BTW, I work in exactly this space -- I consult regarding embedded systems security... cryptography is a fundamental part of security, there is no getting around it. And C++ is my weapon of choice, even thought I am often forced (or really, pulled) back into C-land, considering C, not C++, dominates in embedded systems. OK, my reasoning: * cryptography is hard to implement correctly. I don't think toolset vendors want to take on that responsibility (and possibly liability). * cryptography can appear to work correctly, but still be vulnerable. Take the recent ROCA problem Infineon had. There are many, many more such examples. Timing side channel attacks is another area of concern. Not wiping memory. You get the picture... * cryptography is difficult to use correctly. Even when you think you've used it correctly, you probably haven't. (Thomas Ptacek, who is active both on reddit and Hacker News, has a saying along the lines of "If you're typing the letters A-E-S, you're doing it wrong) Putting cryptography in the hands of someone who doesn't really know what he's doing is akin to handing a Zippo lighter to a pyromaniac. * By standardizing on certain crypto primitives (block ciphers, stream ciphers, hashes, digital signatures, ECC functionality, key exchange, message authentication codes, random number generators) you're essentially endorsing them by choosing them for the standard library. You're essentially trying to look into a security crystal ball, as a programming language standards person. That's just great until out of the blue, the primitive becomes broken (see RC4, MD5, SHA-1, ECC-DRBG, etc.) but now it's part of the language's standard library, and people think it's safe to use like strcpy() or rand() * Once you have block ciphers, you need to provide modes of operation (e.g. CBC, CTR, CCM, etc.) and all the complications that come with them. And I'll bet you anything that ECB would be included, even in 2017, if for no other reason, backward compatibility * /HOPEFULLY/ anyone wanting to do cryptography would also be using TLS. If you're using a TLS library, all of the crypto functionality you would need would be provided by the TLS library * often people using crypto primitives, even without realizing it, are trying to cobble together what would appear to be a "secure" protocol. That is even harder, just ask Bruce Schneier or Ross Anderson. I could continue, but hopefully you get the idea. We could do it, but it might not be the best idea. To paraphrase Chris Rock, "Sure, you can drive a car with your feet, but that doesn't mean it's a good idea". (note that I said "paraphrase"!) Back end of the compliment sandwich: I hope people out there aren't "rolling their own crypto", but my own consulting work indicates (at least in the embedded world) that many are. To the extent that something like what you proposed would help, I'd be for it. But I think it's just trading one set of problems for another.
I wasn't :) Watched my first video from CppCon with Chandler two years ago as procrastination while working on my thesis. Chandler points covers stuff I miss in some CS lectures. E.g. small size optimizations. 
/u/TheSuperficial has a good reasoning of why crypto algorithms do not belong to the standard. However, a standardized `&lt;bignum&gt;` header, both for integer and FP math, would be really nice to have. 
&gt; Has Better gui library Better than what?
Interesting, I can't seem to find anything that talks about *exported using-declarations* either in the TS or other papers. Could you point me to the wording/paper? Also, what would the usage look like in this situation? Specifically, I would like to re-export `std::vector` (in namespace `std`) along with all its associated comparison operators and other free functions (like `begin()` and `end()`).
I understand the benefits of doing this, but having tested making the same change within my codebase, the overhead of passing a string_view (pointer+size) over a const std::string&amp; (just a pointer) was unacceptable for my use case. The paper suggests changes which take string_view by value, by and large. In one case, the increase in code size due to this change caused a function to no longer be inlined, which was really, really bad. I don't see any mention of performance in the paper, so this concerns me. There are performance wins to be had here, but potential losses too. 
Yes, UWP is the future of Windows desktop APIs regardless of the hate, and Windows 7 will be EOL by 2020, about 2 years from now and 4 new Windows 10 updates, assuming current schedule. Many also expect to keep using XP, eventually a cut is needed.
Sorry English is not my first language, but tried to reformat it. Can you have a look again.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7aw0mn/how_to_use_clangtidy_for_c14c17_code/dpdq1gj/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Why are you here if you don't care about improving C++?
Why did the functions become also noexcept in their constexpr version? Wouldn't they throw with a null pointer? Also, `A constexpr specifier used in a function or static member variable (since C++17) declaration implies inline.` so there's no need for the inline in the constexpr version.
&gt; Interesting, I can't seem to find anything that talks about exported using-declarations either in the TS or other papers. Could you point me to the wording/paper? [This](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0721r0.pdf) is the paper in the pre-Toronto mailing. &gt; Also, what would the usage look like in this situation? Exactly what you wrote: `export using std::vector;` &gt; Specifically, I would like to re-export `std::vector` (in namespace `std`) along with all its associated comparison operators and other free functions (like `begin()` and `end()`). It re-exports exactly the name that is named. Use of ADL applies as ever. See section 6.4.2 of the [TS](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/n4689.pdf) especially the fourth bullet of paragraph 6.4.2/4. 
I was a bit irritated that you called it declaration and later in an extended non compiling case redefinition. It's a definition of the variable `m_mutex`.
Another point is that to be secure, crypto library would require prompt and frequent updates. But: - The standardization process is quite slow. Imagine some crypto algorithm is broken some day. It would take years for the fix to reach the standard. - Even after it is standardized, people are very reluctant to update their compilers and standard library. For example, our customers still use GCC 4.4. So another few years until the fix actually reaches all the production systems out there. It is much easier to provide timely updates for the separate library then to the standard library. 
Use Qt
When is it useful except for serialising data? I keep hearing how important reflection is but I struggle to see when I'd use it
A cool fact I discovered playing with gcc and reading n4553 carefully (8.3.5.16 - 8.3.5.17). I was about to actually write a proposal to do exactly that.... stupid me. It's very unfortunate that this notation is currently *not* part of the standard, for no good reasons. Call your C++ committee representative today ( or not, it doesn't work like that ).
This was super insightful and helpful, thanks for the details!
I think the UI has changed since the videos a little, use the "hook" function
Once you get started with this tool its actually very good, I already was able to optimize the code in our project a little. I simply downloaded the prebuilt binary for Windows x64, You start up your process you want to profile, find it in the process list, then load the pdbs (by right clicking on the blue text). This brings in all the functions. You have not know what to search for but you locale the function by class name etc.. then simply right click hook them Its only going to profile what you hook. Once you've hooked a few functions, switch to the capture tab and press X. Now use your app a little then go back and press X again to stop the capture You can now zoom around the firechart looking for functions that are taking more time than you expected it works very well, perhaps takes a little time to get going but once you do its very good. It made me a look differently at code I've been looking at for over a decade, it made me question thinks that I'd always discarded Great tool thanks 
&gt; (Thomas Ptacek, who is active both on reddit and Hacker News, has a saying along the lines of "If you're typing the letters A-E-S, you're doing it wrong) Putting cryptography in the hands of someone who doesn't really know what he's doing is akin to handing a Zippo lighter to a pyromaniac. Could you elaborate on this a bit? I don't understand what that Thomas Ptacek quote is trying to convey.
That would be amazing!
Should crypto libraries be possible for mere mortals to actually build (esp on windows)?
Agreed, future, not present. Which is my issue. I want to target windows, not windows 10 AND windows 7/8.1. If only they brought back the legitimate free upgrade to windows 10 for all users. Then we might be able to get away with it today
I found that building CURL with crypto support was easier on Windows actually, as with CMake you could select to use the WinCrypto API instead of OpenSSL! 
Elaborating on this would take a full article to do properly. Fortunately, [such an article exists here](https://www.nccgroup.trust/us/about-us/newsroom-and-events/blog/2009/july/if-youre-typing-the-letters-a-e-s-into-your-code-youre-doing-it-wrong/).
Difficulties with P0506: 1. that it is an ABI break 2. several of the functions it changes, e.g. locale::locale(const char*), ultimately have to be passed as null terminated strings to underlying operating system (C) APIs in most implementations, meaning changing those to string_view makes a currently non-allocating API allocating. I could see adding overloads to things but removal is going to be a tough sell.
I don't see anything specific to C++ here.
No, not per-se, but C++ devs are generally obsessive about performance and efficiency and C++ is used to build many large scale systems requiring logging. It seems to me that it could be of great interest to C++ devs. Especially since it is such a novel concept. Who knows, maybe we’ll get it in clang or MSVC sometime in the future. Of course, I defer to your judgement. 
The talk seems fantastic, but the audio is such a bummer. Have you considered doing this talk at CPPcon in the future? You will reach a much wider audience and can piggy back on their sublime audio/video capture setup.
There's nothing in those functions that can raise an exception.
I think you can't put cryptographic algorithms into the standard. It may however be possible to standardize interfaces and functions and let the implementation decide e.g. what algorithms and protocols are supported (in most cases just forwarding to OS APIs or the standard crypto library of the system). That would allow toolchain vendors to update / react to never developments without waiting for another standard release. Admittedly, this might be a problem for vendors of embedded systems toolchains that cannot just forward the calls to the OS API.
Ok, approved.
Well, I'm pretty sure that in a lot of places in the standard library (but certainly not all) where you'd use std::string_view, the performance of that doesn't really matter. E.g. if I'm opening a file, the overhead is really negligible. The fact that it has to potentially copy &amp;allocate a string however, because it has to be null terminated is imho the bigger problem.
A standard bignum module would indeed be useful for all sorts of things, but cryptography isn't one of them. Even leaving aside the "if you implement your own crypto, ur doin it wrong" point, which you definitely shouldn't leave aside, the features crypto algorithms want from their bignums are very different in many ways from what other fields want. For example: * Crypto algorithms nearly always work with fixed size bignums; you'd want something templated on the number of bits, while most other fields want a variable length, arbitrary precision integer. * Crypto does everything in unsigned integers; most other fields will want signed ones. * Crypto needs constant time operations, such as an equality operator that always takes exactly the same number of clock cycles regardless of where the values differ. Outside crypto, that would be considered a terrible pessimization. Yeah, you could make a "general purpose" library that provides all of the above, but honestly you're better off making two separate libraries for crypto bignums and everybody-else bignums. Or better yet, only the latter. Just to repeat: if you implement your own crypto, even with somebody else's bignum library, ur still doin it wrong.
Yeah, sorry about the audio quality and thanks for the talk feedback. I don't know if any other conference would accept the talk now. I haven't had a good track record with getting cmake related talks into conferences such as cppcon so I didn't try this year. That's why I submitted it to accu instead. I was so disappointed that they didn't record it. They put the talk in the smallest room and it was jam packed. If you can recommend a (preferably Europe-located) conference, maybe I can submit to I might give it a shot. 
You can try this [boost.cmake](https://github.com/pfultz2/cget/blob/master/cget/cmake/boost.cmake) file from [cget](http://cget.readthedocs.io/en/latest/). Even though you are using meson, it should be easy to create a cmake toolchain file from your cross file. Just copy it to the top-level boost directory as CMakeLists.txt. &gt; when can we expect boost with cmake? There is a draft of cmake [here](https://github.com/boost-cmake/boost). There is more work to be done, but you can try it to see if it works.
C, C++ Objective Questions - http://www.cppbuzz.com/
Use [crosstool-ng](http://crosstool-ng.github.io/) to compile a desired cross-toolchain. Then build boost normally (with b2) with this toolchain.
I'll look at this. Also boost context needs a patched build file to compile (ml..) with safeseh on windows, not sure why it hasn't been fixed yet
&gt; It's very unfortunate that this notation is currently not part of the standard, for no good reasons. As much as I like the notation, there are good reasons why it was delayed. See this paper: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0696r1.html
Some of these questions have spelling mistakes / are outright wrong. By question 4: 1. "Ternarny Operator" -&gt; "Ternary Operator" 2. `sizeof(int) == 3`? Umm, no. From what I've seen, `sizeof(int) == 4` is common, but the size is not guaranteed by the standard; some platforms have different sizes.
My favourite question was &gt; What is currect systax of for loop?
Wow. Very garbage. Much removed.
Removed as this is off-topic.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7axetd/c_builder_vs_qt5/dpej9o3/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I think that won't work. Boost.context for ios arm does not compile assembly files correctly.
&gt; The standardization process is quite slow. Imagine some crypto algorithm is broken some day. It would take years for the fix to reach the standard. Wouldn't updates like that be left to toolset vendors? I would think the extent of the standard on crypto algorithms to refer to the latest version of *their* respective standards? A broken crypto algorithm shouldn't need to be fixed in the C+ standard? &gt; Even after it is standardized, people are very reluctant to update their compilers and standard library. For example, our customers still have GCC 4.4 as their default compiler. So another few years until the fix actually reaches all the production systems out there. I don't think people who are working on security but refuse to get important security updates should be considered. Compliant code Besides, wouldn't they be just as unlikely to update their crypto libraries?
There has been a fair bit of discussion of this on std-proposals, see https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/I4yTB54CctE I'll reiterate my point made there here: if AFIO is accepted in 2018 as the File I/O TS, then its `path_view` design is of likely interest to this design decision too. Unlike `string_view`, it requires the character after the end to be readable. This lets us optimise out copying the string into a zero terminated buffer on POSIX where possible. As these can be up to 32Kb long, that's a fair saving. Such requirements are too strong for non-path string views however. `afio::path_view` can get away with it only because one would hope it would be rare that people be placing filesystem paths in places where reading a character off the end is UB.
&gt; Wouldn't they throw with a null pointer? No, dereferencing a null pointer is simply UB, so it's assumed not to be the case. If a system does throw an exception in that case, it's not going to be a C++ exception anyway.
&gt; And not everyone is using C++17 yet. It's not clear when copying the text, but the [original cppreference page](http://en.cppreference.com/w/cpp/language/constexpr) explicitly only applies the "since C++17" part to static member variables. `constexpr` functions have always been `inline`.
The committee is still debating abbreviated syntax. There are at least four concerns that need to be resolved: 1) whether some kind of keyword or syntax is required to syntactically differentiate function and function template declarations. 2) whether multiple uses of the same constrained type specifier must resolve to the same type (aka consistent resolution as present in the Concepts TS) or may differ (aka independent resolution). 3) whether constrained type specifiers should be handled more like qualifiers such that they can be composed (without having to introduce a new concept name). We have two papers in the Albuquerque pre-meeting mailing that would permit declarations like: void f(Regular Fooable auto p) {} 4) whether constrained template parameters should require ‘typename’ or ‘auto’ to differentiate type and non-type template parameters: template&lt; Regular typename T, EvenInteger auto N&gt; void ft() {} These issues are slated to be discussed at the Jacksonville meeting (they won’t be discussed in Albuquerque). 
&gt; off-topic That's putting it kindly.
It's a part of the metaclasses revolution that is coming. For example, you can ensure that your interface class contains only virtual functions at compile time. Coupled with code injection, that would allow to make getters and setters automagically, which would eliminate the ugly macros used for this.
[C++Now](http://cppnow.org/) actually just had [a talk on CMake](https://www.youtube.com/watch?v=bsXLMQ6WgIk) in this year's session and as you can see they make pretty professional-looking videos, but it is unfortunately not based in Europe (I believe it is located in Colorado every year).
I went through your slides and it looks great. Do you plan to extend it a bit with informations about packaging (CPack) and linters/coding style (cmakelint is the only one I am aware of) ?
You should be using M E T A E T A 
boost should die in a fire
I believe we should be taking out libraries from standard, not adding them. To be more precise -- it is better to split standard into independent parts: language (maybe with minimal library support) and libraries (one standard per library or group of libraries). And concentrate on problems that prevent a library (written for one platform or compiler) to be compiled on other platforms/compilers.
I'm against this in standard. Standard must contain only the most vital things. And I'm not sure that I want "network" in standard, either.
Edited by adding square brackets to the "since C++17" part to avoid confusion.
I would argue that the arguments cited in this paper are baseless. * Some of the reasons, mainly whether the parameter is a forwarding reference or not and whether the function is instantiated for each parameters set is as much a concern for the caller than for the callee. However, there is not and never was a syntax to differentiate function calls from function template calls. * The other issues only arise if the author of the function does not know that the parameters of the function are concepts, in which case, we are back in the scenario where juniors devs type syntax found in stack overflow mindlessly. Or actually, the compiler will give them the syntax, and they will copy them ( as they do for typename, there is a proposal to fix that) ``` void foo(Bar b) ^ Bar is not a type, you meant template &lt;Bar T&gt; void foo(T b) ``` * The author solve the problem themselves : If the functions author want to explicitly decorate the function as a function template, they are free to do so. The set of proposed guidelines is quite sensible. * IDE can further make this problem go away by judicious application of syntactic coloration, although of course we shouldn't count of that. 
Up-to-date OpenSSL but decade old GCC is not at all uncommon. There's places that are using ancient versions because they just can't be arsed to upgrade, but there's also places that have a specific policy of only upgrading things when they have to, not just because they want to. In practice if the standard library had crypto code then the security fixes would get backported to ancient versions and as long as it didn't cause any ABI issues getting those fixes to people running GCC 4.4 wouldn't be a big deal.
I can't imagine anybody standard implementation of `vector` has done it for years. About the only time I've seen it is when people implement their own contiguous containers of various sorts, and by the time they get to writing the iterators, they're tired enough that they use the quick and dirty `typedef T *iterator;` (yes, I'm probably as guilty as anybody of this particular sin).
Not a rocket science, but I found myself repeating that pattern from project to project. Pretty simple, and seems quite efficient. What you use for pending lists / LoopThreadExecutor's / things when you mostly want to read all available elements from queue?
Thank you for the complete rundown, it's hard to find all the arguments in one place 1. [See my other answer](https://www.reddit.com/r/cpp/comments/7aylhq/constrained_types_specifiers_in_abbreviated/dpewqvq/) 2. They may differ. See [p0464r2](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0464r2.html). Thay lay down why very nicely. &gt; Once a developer has learned the basic language rule in Concepts that ConceptName var means that the variable var must have some type that models the concept ConceptName, the meaning of ConceptName a, ConceptName b should be obvious: that a and b model ConceptName — no more, no less. The author further mention that to express the intent of all parameters having a single return type, this syntax can be used: &gt; `R foo(ConceptName a, decltype(a) b);` Which is semantically more correct. 3. That's actually a very good point 4 What about:` void f( ([ConceptName*] [typename|type|auto] identifier) ` ? void f(Thingy foo) void f(Thingy Widgety foo) void f(Thingy Widgety typename foo) void f(Uneven Positive auto number) void f(Uneven GreaterThan&lt;42&gt; int number) void f(Uneven Positive number) Neat and simple Notice than the definition of the concept should probably be enough to model whether the expected template parameter is a type or a literal. `Even` can never not be a value. Maybe I should write a proposal. 
#import is already a thing. Namespaces unfortunately can be both opened and closed multiple times from multiple files, and is parsed after the preprocessor. There are other ideas about the Modules TS proposal coming from many others, and is still a work in progress. There are definitely some rough/confusing edges. I’m sure the committee is listening, and are working towards something that’s acceptable to most (if not all) parties involved in crafting a standardised solution.
could be useful to note where #import is already a thing. I know of [windows COM related import](https://msdn.microsoft.com/en-us/library/8etzzkb6.aspx) and obj-c/++ have it with different meanings.
Did you benchmark this? Especially a comparison to boost lockfree, or https://github.com/cameron314/concurrentqueue would be interesting
Isn't one of the goals of modules to isolate macros in translation units? I mean macro definitions from the importing scope should not leak into the imported module. If that is the case using hashtag as a prefix for that statement would be misleading.
First you propose only a slightly modified version of #include, but the you are talking about exported/internal etc. Which implies the modules semantics of the current TS. To me that seems more like a modification of the modules TS than an alternate approach. That aside, indiscriminately importing all macros transitively is something that should definitely be avoided, so this is not a problem with the current TS, but a deliberate design decision. Admittedly, there are however a lot of discussions if exporting and importing macros explicitly should be allowed.
&gt;Now, that's only 3 lines and there's no repetition. Yes, I'm cheating because I use a macro, but to be fair Folly.Poly also needs macros in C++14 (and Dyno is C++14). I guess the next step is to see whether I can do better without macros in C++17 with Dyno. I don't think I can. I guess there is a trade-off: Poly can do shortcut in implementation, but not customize storage / dispatch etc., and for Dyno it's the opposite? Would you consider supplying a `dyno::erase&lt;Interface&gt;` equivalent to `folly::Poly&lt;IDrawable&gt;
I did not benchmarked it. I only visually saw performance difference compare to std::deque + std::mutex when my ui stop freezing :) [I used it in my ui LoopThreadExecutor] But I would say, than on pure enque / push it should be the same as std::deque / std::vector + std::mutex. So, if believe moodycamel benchmarks, their ConcurentQueue should be much faster. About deque / consume, I really doubt it is possible to have higher performance than this (conceptually), considering you do have data in queue. It literally do nothing, just switch 2 pointers under lock, and you have all data in linear space. All in all - you can't beat the design simplicity :)) But thank you for pointing at moodycamel::ConcurentQueue , I didn't hear about it before. I'll try to use for more general cases.
**Company:** [Scale Computing](http://scalecomputing.com) **Type:** Full time **Description:** Scale Computing integrates storage, servers, and virtualization software into an all-in-one appliance based system that is scalable, self-healing and as easy to manage as a single server. Using industry standard components, the HC3™ appliances install in under an hour, and can be expanded and upgraded with no downtime. High availability insulates the user from any disk or server failure and a unified management capability driven by the patented HyperCore Software™, efficiently integrates all functionality. The result is a data center solution that reduces operational complexity, allows a faster response to business issues, and dramatically reduces costs. We are growing and looking for C++ engineers, from mid to senior level, [see full job description here](https://boards.greenhouse.io/scalecomputing/jobs/179690#.WgAfRhNSxTI). We have small engineering team, so you will have a great opportunity to make an impact on the product, team, and company. **Location:** San Francisco, CA **Remote:** No **Visa Sponsorship:** No **Technologies:** C++11, Linux **Contact:** Apply [here](https://boards.greenhouse.io/scalecomputing/jobs/179690#.WgAeHhNSxTI)
&gt; However, there is not and never was a syntax to differentiate function calls from function template calls. Overload resolution is affected. &gt; The other issues only arise if the author of the function does not know that the parameters of the function are concepts, The paper explicitly indicates concerns with code under maintenance; when the editor may not be the original author. &gt; The set of proposed guidelines is quite sensible. Consider whether the necessity of guidelines is an indication of a substandard feature. &gt; IDE can further make this problem go away by judicious application of syntactic coloration, although of course we shouldn't count of that. Not all developers use IDEs, nor do all development tools have semantic awareness. You state that we shouldn’t count on that; what do you propose we do then?
With regard to 2), there are some prominent committee members who are quite strongly and quite vocally in favor of consistent resolution. Note that: ‘R foo(ConceptName a, decltype(a) b);’ Does not express consistent resolution. That syntax specifies that ‘b’ has the type deduced for ‘a’. Consistent resolution is different; it specifies that the type is deduced from the arguments for all parameters declared with the same type specifier. &gt; Maybe I should write a proposal. Before you do, see: - http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0791r0.pdf - http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0807r0.html
Yeah, I'm aware of those two papers, and they have some nice ideas. I think I can improve on them ( well, it would be an improvement in *my* opinion ). I guess the next relevant meeting is in 6 months ?
Would be great to have, would work best if it's a package in a cargo/pip/..-like repository so there is the possibility for frequent updates, versioning, and it only needs to be implemented once. 
Interesting read! Slides 6/7/8 are scrambled? How they came up with this syntax I can only guess :'( $&lt;$&lt;CONFIG:Debug&gt;:helper_debug.cpp&gt; $&lt;$&lt;NOT:$&lt;CONFIG:Debug&gt;&gt;:helper_rel.cpp&gt; 
I like the idea, but I guess technically it isn't a code contract because it only displays a warning, you can ignore it.
Hi zerexim, in general, we take between six months to a year to allow candidates and our team to get to know each other, to explore if they are a good fit in terms of work culture and skillset, and then make a decision. This usually happens within the first six months. Our new recruits share the office with our Technical Director, who personally guides them through the first few months of their employment. Be assured that our Technical Director would not dedicate this kind of time to on board people we intend to replace. Also, from the company's perspective, let me tell you it is much more expensive to let somebody go and keep recruiting than to pay the 120k that we are happy to do and honor somebody's work since we are a stable and profitable company. We are looking for long-term colleagues, people who want to stay with us and strengthen our team. The decision to let go of an employee during his or her probationary period is never an easy one to make, nor should it be. At think-cell, this decision is not made by any single person, however senior they may be, but by our developer team, based on their experience working with the new hire. We know that think-cell is not an easy company to get into. At the same time, those who make it through the first year stay with us for a long time. And those who stay with us get to work in a team of excellent C++ developers, undoubtedly the best in their field.
&gt; Wouldn't updates like that be left to toolset vendors? I meant situation like "Algorithm X is demonstrated to be broken, we have to switch to Y as a default and introduce new algo Z for the future." That would be an API change. Or even "Quantum computing is a reality now, so all the old algos are broken and we need a completely new quantum API". &gt; I don't think people who are working on security but refuse to get important security updates should be considered. Security is only a part of the product. People don't like to update the toolchain because it may may break some code elsewhere. Updating crypto only is much less of a problem. 
Agreed. Complaints about `export import` are always met with "well, it makes sense because..." answers. It doesn't matter. The reaction people have to it is enough reason to change it, as the dissonance it provokes is a barrier to learning and adoption. I would even say that it makes people think that the feature must be in some way broken or badly designed. This is something that will take up teaching time and I don't have the time to tell people repeatedly to "just get over it" for yet another oddity in the language. Change it to something sane which makes sense to read. 
I've seen it raised before (apologies, but I don't have a link) and the concern was dismissed. 
Oh, that's odd. I'll fix that later when I get home, thanks. The slide numbers are messed up too. All because I was a bit sloppy with building the LaTeX.
If I would give the talk again at another conference I might change the content a bit. I'd probably drop the stuff about policies (I could do a 1 hour talk just about those), and add some other stuff.
Losing that goal would be a shame, but not be a tragedy. As of C++17, the only reason to use macros is conditional compilation depending on your platform - and even that can probably be replaced by `constexpr if`. So you could solve that issue by simply saying, "Don't use macros."
`-Werror` to the rescue :)
I read about it in the article, but that's also optional.
&gt; changing those to string_view makes a currently non-allocating API allocating I thought the point of string_view was to avoid unneeded allocations. Why would it be needed in this case?
Things like that should be enforced by default and allowed to bypass with something like `[[discard]] call()`;
Personally I find *#ifdefs* for conditional compilation a code smell, that always starts with a couple of simple lines and eventually becomes spaghetti code. I always push for separate implementations using the the platform as suffix, e.g. *os_win32.cpp*. No spaghetti code, no pre-processor macros, just lovely.
That is neater in some ways, but you still have to figure out a way to get os_win32.cpp built instead of os_linux.cpp. More, it means that one feature is striped across a bunch of files instead of being in one place. Also, often when you have conditional compilation, it isn't just one setting with a couple of values - there might be a whole bunch like platform, 32 bit vs 64 bit, compiler, DEBUG vs NDEBUG, or "demo version" vs "paid version".
Could you compare Catch to Google Test, except from this?
Never used it before. Can someone compare it with GoogleTest? Never used Catch before...
Well, catch is easier to get going (on Windows in particular) and I liked the way tests can be specified in sections. There's no mocking in catch, I believe. I remember looking at libs like fake it for that. Unsure if there's an official partner lib now. Google test is just huge. There's something for everything. But harder to learn. Compile time is significant. I guess I like both.
you're holding the lock while you copy in the message - if you use a list instead of a vector, you can construct a list outside the lock and then splice them inside the lock, which is generally faster than the copy unless the message is trivial. Also, calling clear might be performing some deallocation even though it's from a moved container so that'll kill performance as well. There are tonnes of better producer consumer queue implementations that use atomic swaps and clever circular buffers to do this much more efficiently by avoiding allocation and de-allocation as much as possible and avoiding locking. Have a look at the Vyukov queue implementations: http://www.1024cores.net/home/lock-free-algorithms/queues
Actually, the four primary goals for C++ Modules are articulated and explained in [the design](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0142r0.pdf), and subsequent [experience report](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0141r0.pdf) back in 2015. I will be updating the latter with what we have learned in the last couple of years.
There is a preposal for that: [wide_int](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0539r2.html)
To summarize, you don't want to use "#pragma once" because it "isn't C++". To make that statement less problematic I will change it to - "#pragma is implementation defined". Using features which are implementation defined isn't a problem in itself. It can become a problem when implementations diverge significantly but if they don't, the problem is only theoretical. Using include guards (which have other problems) to circumvent a problem that doesn't exist seems like a bad idea. Are you just language lawyering or do you have a real problem that requires this? 
&gt; This is the paper in the pre-Toronto mailing. Thanks! What feels a bit fuzzy to me is the namespace of such a re-exported via using-declaration entity. Consider: export using std::vector; // re-export std::vector export { using std::vector; // re-export std::vector? namespace n1 { using std::vector; // n1::vector or std::vector? } } export namespace n2 { using std::vector; // n2::vector or std::vector? } Is only the exported using declaration in the global scope treated specially? &gt; Use of ADL applies as ever. Ok, just for my understanding: a name is visible to ADL even if not explicitly re-exported? &gt; [...] especially the fourth bullet of paragraph 6.4.2/4. That last *[...] even if it is not exported* bit is strange: wouldn't the name have module linkage if it is not exported?
&gt; but there's also places that have a specific policy of only upgrading things when they have to, not just because they want to. then for the love of all thing holy, enforce crypto in the compilers os that they are mandated by law to update their decade old GCC
&gt; ‘#import’ is already a thing. In standard C++ ?
const-by-default, noexcept-by-default, non-copyable-by-default, etc..
Is that really true? How would you make a macro that uses the name of what it is passed?
&gt; When is it useful except for serialising data? I keep hearing how important reflection is but I struggle to see when I'd use it honestly, at least 20% of my code is boilerplate due to missing reflection capabilities. * sending objects through the network * auto-generation of UI given some struct * identification of factories and interfaces by UUIDs for plug-in systems * association of per-type metadata with polymorphism 
&gt; As of C++17, the only(*) reason to use macros is conditional compilation depending on your platform please show us an implementation of Boost.Fusion that does not uses macros.
Call srand(time(NULL)) before your first rand() call.
I don't believe that it is possible to be faster than this on consume. Equal at best case. Calling clear on moved vector will not perform deallocation (will not claim that for deque). On MPSC (you consume from the same thread) case you can use double_buffer - and you will reuse your vectors. Surely push is slow, and almost any lock-free queue is faster than this. But... just std::vector, std::mutex and move ! :)
My experience has been that the platform specific parts are so small that they don't warrant their own compilation unit and often not even their own functions. If you use a separate file, you are pushing it to the build system, where as there are very well defined macros for different platforms and the source code can take care of it more transparently. 
The 'export using-declaration' exports the name -- not the type, which remains owned by its original exporter. The name `n1::vector` is exported as alias for the already exported `std::vector`. Similarly `n2::vector` is exported as alias to `std::vector`. The semantics is really simple and compositional: (1) the using-declaration by itself introduces a name into a scope, as aliasing for the original entity -- as it has always been since C++98. (2) Sticking `export` in front of that declaration renders the declaration exported, meaning that name becomes visible in that context for the users of that module. &gt; Ok, just for my understanding: a name is visible to ADL even if not explicitly re-exported? Yes, especially for the second phase of dependent name lookup. This is a necessity if you want templates as practiced today to work at all -- imagine exported templates that use internal types and helper functions that are not exported. This change is the minimal version to make those existing practice work. To mitigate that effect, I suggested an `internal` mechanism for the programmer to say "this really is internal to this module, and you don't even get to find it in the second phase of dependent name lookup", but EWG did not agree at the 2015 Lenexa meeting. I still think it would be most useful. Interestingly Nathan Sidwell was telling me about that right after the Toronto meeting.
this works. thank you
Hard to learn... Nobody likes to learn. Me too... Thanks, I think I'll try Catch first, then.
Conditional compilation should be possible with modules, supplying macro definitions to each translation unit - so even that would not be a reason to propagate the macro definitions into modules. I think a good reason not to propagate the definitions is * consistency - a compiled module works exactly same reagardless of the importing context * feasibility - process module once, keep the cached binary as long as the environment stays intact (dependency upgrades or compiler change)
If only CMake used a proper language, e.g. Python.
You are right: Conditional compilation is possible and actively supported by C++ Modules as described in the TS.
That is what the build system is for.
It is quite straightforward to do, even with plain makefiles.
So why does unique_lock have a default constructor?
The syntax is odd for sure, but it is better in newer versions of CMake: `$&lt;IF:$&lt;CONFIG:Debug&gt;,helper_debug.cpp,helper_rel.cpp&gt;` With some better formatting, it is alright! But I think this type of build is wrong. You should add both files to your buildsystem and have regular ifdefs in them to conditionally compile the code. If you do that, then odds are that your IDE will be able to search and refactor code in all the files properly. 
The next meeting is in four months in Jacksonville. See https://isocpp.org/std/meetings-and-participation/upcoming-meetings I recommend floating your ideas on the std-proposals mailing list to get feedback before investing time in a paper. See https://isocpp.org/std/submit-a-proposal
I use this pattern a lot. I find it strange that I almost never encounter it in blog posts or texts about multithreading.
If you need null-termination and your string_view isn't null-terminated then you must allocate a string in order to get said terminator. Whereas if you had a string to begin with, it's internally guaranteed to always be null-terminated.
Because the underlying OS API expect a NUL-terminated string, which has to be allocated by someone and get init'ed with the content of the string_view, followed by a NUL char.
I don't think anyone has tried to build Chromium, but I heard once of someone with similar intentions. Who knows, we'll see...
&gt; calling clear might be performing some deallocation If it does then your stdlib is broken. :-]
If it were python, I would not use cmake
I'm sorry, that's me again. No matter how hard I tried I can't get the templated version to work, the test program still crashes when destructing std::string twice on leaving main(). Here is the relevant branch in my test repo: https://github.com/Jajauma/GlobalsDemo/tree/TemplateInit, and the excerpt from static library header for your convinience: namespace detail { template &lt;typename Unused = void&gt; struct Globals { static std::string g_str; }; template &lt;&gt; std::string Globals&lt;&gt;::g_str = "String too long for short string optimization"; } /* namespace detail */ static auto&amp; g_str = detail::Globals&lt;&gt;::g_str; Where did I fail?
I will try to reproduce this tonight or tomorrow night. I'm not very familiar with CMake, maybe I can get it to dump out the commands that it's running. What compiler/linker/platform is this?
https://github.com/bloomen/transwarp
&gt; I find it strange that I almost never encounter it in blog posts or texts about multithreading. Me too. This pattern reminds me opengl/directx double-buffer swap, in some sense.
It's latest CentOS 7.4 with stock GCC 4.8.5 / binutils 2.25, and clang 5.0.0 which I built myself. I managed to reproduce the rest of your talk just great in the corresponding branches on that github repo, that is the only templated version which doens't run as expected (for me).
There's an easier way to get past the warning: `(void)foo();`
The syntax for those generators in general is just plain awful, and you do need them in certain places. What you write here is slightly better than the example I gave, but it should be forbidden to force people to type something like that.
Wait, so you compiled with gcc 4.8.5 or clang 5? Or reproduced it with both? I'll give this a shot at home and see what I come up with.
I've tried both compilers and reproduced with both. The program output looks like this: [d_a@home debug]$ ./StillBoom String too long for short string optimization String too long for short string optimization *** Error in `./StillBoom': double free or corruption (fasttop): 0x0000000001345060 *** ======= Backtrace: ========= /lib64/libc.so.6(+0x7c619)[0x7fd3da42f619] /lib64/libstdc++.so.6(_ZNSsD1Ev+0x43)[0x7fd3dad58e43] /lib64/libc.so.6(__cxa_finalize+0x9a)[0x7fd3da3ebdda] /home/d_a/work/GlobalsDemo/build/debug/libDynamic.so(+0x9e3)[0x7fd3dafa39e3] ======= Memory map: ======== 00400000-00402000 r-xp 00000000 fd:02 27977636 /home/d_a/work/GlobalsDemo/build/debug/StillBoom 00601000-00602000 r--p 00001000 fd:02 27977636 [snip] Note that to tell cmake use clang one should generate the build system like `CXX=clang++ cmake ...`
You would be the first guy that actually thinks cmake's language is good. Everybody hates the language, yet we all use it because CMake as a tool works great. But it could really use a better language.
It will break old code
Your `push` method is rather odd, taking a message by `const&amp;` and then doing emplace. You could do what GP is doing, but my suggestion for that would be to: - either take the message by `&amp;&amp;` and move it in - or make a copy, then take the lock and move it in This way you avoid making the copy while holding a lock. The first one is nice since you'll probably find many places don't need to hold on to the message, so you can move to begin with. The downside is that you need to change all the calling code of course
&gt; Using features which are implementation defined isn't a problem in itself. In general I think it could be a problem if your code are open to everybody and all possible environments. Perhaps "pragma once" is so widely supported that it's ok. 
Ok, got it, thanks!
No, I don't think the cmake language is good. cmake, the tool and the language is horrible, but it's the best we got. If python were the language for cmake, I can only imagine everyone making a poorly implemented package manager for their own stuff, making their own installation and packaging system and whatnot while running the meta build system. I saw enterprise code that a single cmake execution took minutes. At least, it's so painful to make such scripts that only a few make those. What we need is something better than cmake. But I have yet to see it. But again, python is not the solution. Why C++ should need a C++ compiled interpreter that runs a script to output a script that runs my compiler? This is madness. The only viable alternative I see at the moment is build2, but it first need to get ready.
the ```template &lt;class Char, Char... Cs&gt;``` syntax actually isn't standardised. I'm not sure what progress has been made on making it so, but I think it should be noted that your 'std' branch now has non-standard code in it! There are alternative methods to achieve what you want (albeit, using a more conventional function syntax, instead of UDLs) that are entirely standard compliant, but rely on macros. It's really a 'pick your poison' kind of situation right now :(
In C++ almost everything is optional and can be bypassed, optional or not.
Well, using `[[nodiscard]]` is optional; I don't understand your point. It's a tool to help you write correct code if you choose to use it, it's not going to chase you down and tackle you and force you to write correct code if you don't want to.
So I think I figured out my mistake. It looks like like it is important to initialize the class static as a template, i.e. do `template &lt;class T&gt; string Foo&lt;T&gt;::string = "....";`. Why this is true, I'm not really sure. I probably slipped in this change while making the slides thinking that it was a simplification. That said, I'm seeing another surprising issue; when I try to convert my Informer example to use this technique, it actually segfaults because it seems like iostreams have not been initialized yet. This is very very odd.
Yes, the string capturing part is non-standard unfortunately because, as I mentioned in the post, it relies on a GCC extension. I'll definitely need to discuss this in the paper as this can't go in as is in the standard. Do you know any standards proposals that may help solve this?
This conversation [seems familiar](https://www.reddit.com/r/cpp/comments/5n59dn/know_your_algorithms_on_sets_it_really_makes_a/dc9chwp/) :) 
Cmake is good, but it's ugly. Qt Company os working in its own buildtool: Qbs. It's use QML syntax :)
I hoped that someone would say `std::exchange`! I see lots of use of `std::swap` where `std::exchange` would suffice and be cheaper. But if you need `swap`, [don't implement it in terms of `exchange`](https://stackoverflow.com/a/20843994): "At best `exchange` will be just as fast as `swap`. At worst, it can be slower."
Also it's interesting that the UDL-based API itself is standard-compatible and should work on a C++14 compiler, it's just that the compile-time feature will not work without the GCC extension.
[P0424](https://wg21.link/P0424)
That wasn't my point. I just meant that the title of the article is not technically correct. I'm fine with this feature being optional.
See (https://www.reddit.com/r/cpp/comments/7b3z8f/enforcing_code_contracts_with_nodiscard/dpfiqq4/)[here]. 
Thank you very much for your prompt reaction, appreciate that! I've removed the default template parameter, and now the test programs works fine. My code reads as follows now: namespace detail { template &lt;typename Unused&gt; struct Globals { static std::string g_str; }; template &lt;typename Unused&gt; std::string Globals&lt;Unused&gt;::g_str = "String too long for short string optimization"; } /* namespace detail */ static auto&amp; g_str = detail::Globals&lt;void&gt;::g_str; And I'm inclined to consider it even somewhat easier to grasp than the initial version! (At least for template non-guru.) But apparently there is now way to amend your video ¡_¡
Microsoft keeps trying to create their own version of anything, slightly incompatible with the original product...
Oh yes, it would be a tragedy. Because as of C++17, we are still dealing with include files for such things as Windows, X11, and uncounted other libraries that spit their macros all over your source, and we will continue to have to deal with them, indefinitely as far as I can see - since the C language is not going to go away. I want to be able to capture those libraries in modules, using `export using` and thin wrappers for things that cannot be exported, and I don't want to then _still_ leak out all those #defines. 
C++/WinRT is exactly the opposite of that- it replaces C++/CX (the slightly incompatible version of C++) with a set of libraries that use only standard C++.
Use 'public:' and 'private:' inside namespaces or at top-level. No need for 'exported:' and 'internal:'. The import header directive should use a precompiled version of the header, work as if the header contains include guards, and also provide automatic 'using namespaces' for all namespaces in the header. 
Isn't the point of [[nodiscard]] to point out code that's likely broken to begin with? I don't mind breaking broken code.
That compile time comparison is crazy. 2.6 seconds for printf, 47 seconds for fmt (and more for Boost). Is it templates that's causing this? It's such a significant difference that it should be a big thing people consider before using template-heavy code.
Just about all of those functions only work with inputs of a given size (e.g. `PATH_MAX`) and a stack buffer can be used. Even for functions that take arbitrarily-long input, in _most_ cases real-world inputs won't be so long, and the allocation can be conditional on the input length being over some "reasonable" size. And then most of those OS calls are IO routines where the time of allocation is essentially irrelevant compared to the time of the kernel call and IO operations themselves. All that said, using overloads that _add_ `string_view` support, none of this is a real problem. That also avoids the ABI issue someone else mentioned.
It's a great feature. I'm also concerned about the compile time overhead. Compiling complicated template may require large amount memory, while lots of build automation are still on VPS with 1GB ram.
&gt; That said, I'm seeing another surprising issue; when I try to convert my Informer example to use this technique, it actually segfaults because it seems like iostreams have not been initialized yet. This is very very odd. It is perhaps some kind of bug in this version of clang though; in gcc it works fine. Indeed, I can observe the same problem. Placing `#include &lt;iostream&gt;` before the template instantiation works fine w/gcc but not clang. This creeps me out.
No, the point is to address those cases where unused return value is likely an error. It is not always the case, for example when a function performs atomic exchange and you don't care about the previous value. Also real world projects usually mind when something that has worked for many years suddenly doesn't compile anymore, the most likely outcome is sticking with the old compiler.
The numbers you are referring to are very outdated (I need to update the README). Here are more up to date ones: https://github.com/fmtlib/fmt/tree/std#compile-time-and-code-bloat. I don't think we'll ever reach the compile time speed of printf regardless of whether templates are used or not. For example, iostreams are not very template-heavy but they (or rather the code using iostreams) used to take the same to compile as fmt until the recent regression in the latter which I plan to look into (https://github.com/fmtlib/fmt/issues/565).
I have the same concerns and think that an alternative API should be available that is faster to compile but that does runtime checks instead of compile-time ones. And that's what the fmt library does, `fmt::format(...)` does runtime checks and `"..."_format(...)`does compile-time ones.
I don't know of a single API call we make that takes a string length for an *input* parameter except WideCharToMultiByte/MultiByteToWideChar. CreateFile wants null terminated strings. All the locale things want null terminated strings. Etc.
No problem, sorry about that. Thanks for the clarification
A macro switch would be also helpful. User can use same api with compile time check to do the check on a resource-rich machine, and later turn it off to compile on low end machine.
&gt; In one case, the increase in code size due to this change caused a function to no longer be inlined, which was really, really bad. This is just not a proper complaint. If you use PGO function will be inlined if it is hot. If you do not use PGO you do not care about performance. 
&gt; it requires the character after the end to be readable so passing "C:\\a\\b\0" instead of "C:\\a\\b" is UB assuming "C:\\a\\b\0" is the full original string? Seems kind of error prone..., but maybe it is not. IDK since I never work with C strings. 
Shalom y'all, I'm willing to pay for my travel expenses if you would like to hear about the messaging and serialization library that I'm working on here: https://github.com/Ebenezer-group/onwards . I've never been to Israel, but would like to visit. This offer is open to others also, but at this point I'm only willing to pay my expenses to one place.
Please join the group and ping us there. 
&gt; No, the point is to address those cases where unused return value is likely an error. It is not always the case, for example when a function performs atomic exchange and you don't care about the previous value. Like I said, code that's likely broken to begin with. We agree on this, I think. &gt; Also real world projects usually mind when something that has worked for many years suddenly doesn't compile anymore, the most likely outcome is sticking with the old compiler. This part is unfortunately true. I don't mind breaking broken code, but a lot of others would prefer to just stick their head in the sand and pretend like the problem is the compiler.
IIRC the bottleneck in compile time for iostreams are ADL and overload resolution (for the stream operators &lt;&lt;, &gt;&gt;). AFAIK variadic templates should be (a bit) faster especially for common and build in types. 
I will fix the slides before I upload them. Also at some point I will post the same content as a blog post (that's how it started), when I do I will fix it. Also, be aware, the main thing here is not removing the default. It's that you define template for the generic case, not just the specialization. Maybe that's what you meant but strictly speaking the default template parameter is another thing and doesn't play a role here.
Kudos for accomplishing that, but is it really necessary for standardization? Compilers can already warn about incorrect format strings on printf and my guess is that that check is much more efficient than what we can achieve by TMP.
This is one of the most interesting talks at CppCon 2017 IMHO. Slides can be found [here](https://github.com/CppCon/CppCon2017/raw/master/Presentations/Runtime%20Polymorphism%20-%20Back%20to%20the%20Basics/Runtime%20Polymorphism%20-%20Back%20to%20the%20Basics%20-%20Louis%20Dionne%20-%20CppCon%202017.pdf).
It's even supposed to work in clang. 
Thanks for the feedback! The presentation is also available online [here](http://ldionne.com/cppcon-2017-runtime-polymorphism). The online version will contain the Godbolt example at the end, but not the PDF version.
When you say "shortcut in implementation", do you mean there's less boilerplate when defining an interface and/or the type-erasure wrapper?
I really wish we had switches for those...
&gt; It is quite straightforward to do, even with plain makefiles. Not everyone uses makefiles &gt; forces devs to think about it I'm not sure how using separate files makes any difference here or what it forces devs to think about in the first place. With ifdefs you have the very real possibility to make single file algorithms and data structures which take advantage of system level capabilities. That modularity makes a big difference when trying to reuse program parts elsewhere.
Yes, sorry for being unclear, I meant shortcut for users when defining their own type erased interfaces, not for the library implementer. 
I’m so happy about this! We have a classic WinAPI C++ desktop app that I would love to move eventually to UWP and now I can without having to use C++/CX.
It will break `printf("...")`
Just to be clear, I wasn't picking on fmt :) Just thought it was interesting that all alt-printf libs were so slow. I assume it's due to C++ features taking a long time to compile compared to C code, and not simply having more logic?
If, instead of `process(Closure closure)` the interface was something like `getAll(container &amp; container)` Then getAll() could call swap (and clear) on the container. If the caller was doing this in a loop: container&lt;Messages&gt; msgs; while (keep_going()) { queue.getAll(msgs); for (auto &amp;&amp; msg : msgs) process(msg); } Then you get the "double buffering" behaviour for free. It kind of combines both interfaces.
I've written how much I loved this talk on various media, but I can't help to restate how brilliant it is. I was already very impressed by `dyno` when it was released a few months ago - this presentation does an excellent job at explaining the concepts behind it in such a way that programmers of various skill levels can understand them. It was also awesome to see `function_ref` *(previously called `function_view`)* being implemented in such an elegant manner :)
Module-level switch? :)
Until 1.66 comes out does anyone know how this can be used in boost without figuring out how to recompile all of boost from master branch?
&gt; The compile-time checks work on GCC and Clang only, because they requires user-defined literal templates which is a GCC extension. Yeah, I suspected as much before I read this. This whole issue comes up again, and again, in multiple contexts. Another example I've come across is in writing reflection based macros; you can easily write a macro that lets you define a struct, and alongside it a free/member function that returns a `tuple&lt;pair&lt;const char *, T...&amp;&gt;&gt;`. This lets you quite easily do things like serialization and deserialization. However, now let's say you want to implement `get_member`. This is a function that given a reflectable struct, and the name of a field, returns a reference to that field. Well.... it can't be done. In order for the name of the field to control the signature of a function (and the output of this function will be a `T&amp;`, where `T` is the type of that field), the name of the field must encode its value as a type. My example here is with reflection based macros but obviously with actual reflection the same issues come into play. You can see it's a very similar issue. That said, I talked to a bunch of people at cppcon who said that this extension (that gcc and clang both support) had zero probability of making it into the standard, because if this feature would be used heavily it would be brutal for compile times. IIRC the preferred path is to be able to template on the value of a string literal directly, although this raises issues too. I don't know where all this leaves us, but I think it's clear that we desperately need the ability to template on a string literal, one way or another.
Right. My point is the the _allocation_ can be avoided. There would still need to be a copy into a buffer and that buffer can be NUL-terminated. I failed to spell out that in my previous comment; sorry. Even if one does just shove things into a `std::string` to add NUL-termination, that's not generally a huge bottleneck for most things interacting with the OS itself. `zstring_view` is a fine hack for short-term solutions, but it's massively limited. If you need to slice a file (say, a file with filenames per line), you're still stuck allocating with a `zstring_view` if you're passing that around. Even _if_ you're targetting a platform with a more sensible OS API, your application would be stuck allocating NUL-terminated buffers for the lines. Decisions about NUL-termination should be pushed into the leaf functions, aka the C++ internals that wrap the OS layer. It can decide if a copy/allocation is needed and do so efficiently, freeing the application developer to use semantically sensible types like `string_view`.
 * It's Qt * Depending on the platform you targets, look into qbs. or cmake. qmake will be the death of you * Learn how the memory management and signal systems work. * Read the docs, they are great * Depending on what you are doing, look into QML 
Rubbish. PGO isn't a panacea because different code paths hit due to different data sets can cause conflicting decisions to be made. Plenty of people care about performance but find PGO to be impractical for their application. A feature should never be designed to rely on the decisions it may make (and then may decide not to make, in the next release of your compiler).
&gt; IIRC the preferred path is to be able to template on the value of a string literal directly, although this raises issues too. I don't know where all this leaves us, but I think it's clear that we desperately need the ability to template on a string literal, one way or another. I'd prefer this as well. The current solution is more like a proof of concept that uses available tools (GCC extension), but whatever goes into the standard it should't be too hard to integrate it with `constexpr` format string parsing without changing the latter.
LEWG said that they want to see that. Also compilers only warn about built-in types and sometimes incorrectly =) (https://youtu.be/ptba_AqFYCM?t=350).
+1 for the qbs. It's actually not bad. Documentation could be better and there are sometimes compatibility-breaking changes between versions but I'm sure both things will be improved with time.
I know it requires macros, but why not use something similar to https://github.com/ubsan/typeval ? Then it'll actually support msvc, which imo is kind of necessary (as someone who uses msvc...)
the signals/slots system takes a minute to wrap your head around but when you do it's awesome. sadly im stuck learning java now
`printf` is just so simple for a compiler. Just call a function. The only extra work involved is dealing with the variadic arguments: promoting certain argument types and pushing them to the stack. But generating the code to do that is basically nothing. Honestly, there's more overhead in parsing the format string so the compiler can warn about mismatches. I don't think that warning was enabled in the timing tests mentioned, though. And even if it were, it's actually a very quick test for the compiler (most format strings are very small, and it's a quick format to parse regardless). In short, the very reason we want to replace `printf` (it knows next to nothing about types outside of the format string) is exactly why it's so fast. No overload resolution, no template metaprogramming, and only the most basic format string parsing, done natively in the compiler.
&gt; My point is the the allocation can be avoided. Oh, I see. :) Still an extra copy though, which would mean P0506 would cause performance to be significantly worse, not better. &gt; Even if you're targetting a platform with a more sensible OS API Well, I don't know of a platform with a "sensible OS API" by your definition :) POSIX and Windows are all null terminated everywhere. (AFAIK macOS is also null terminated everywhere but since you have to copy to make the NSString in the first place it kinda doesn't matter there) 
In that comment Stephan is talking about the algorithm requirements, I'm talking about MSVC++'s implementation specifically :)
Wish I knew how great c++11 would be, and how awful having to writing Qt code would be, raw owning pointers, copy on write, etc
&gt; significantly worse That was my point though: it's hardly "significant" :) I can't speak for all industries, but at least in the performance-sensitive one I work in, this "copy to a buffer" approach is exactly what many of us do in our OS-layer wrappers (the analogues to things like `std::filesystem`). &gt; Well, I don't know of a platform with a "sensible OS API" by your definition :) Haha, true, hence the "if." :) I hold out hope that the future of OS technology is not going to be limited by the APIs designed by the UNIX and Microsoft folks back in the 70's and 80's. :p I mean, you're probably in a better position than me to go ask the Microsoft OS guys why we can't have an `OpenFileEx2ExPlus` function that takes a length delimiter. :p I can only imagine that'd be an improvement for security purposes, too.
&gt; Not everyone uses makefiles I gave makefiles as an example, because alternative build systems are actually much more capable than them. &gt; With ifdefs you have the very real possibility to make single file algorithms and data structures which take advantage of system level capabilities. That modularity makes a big difference when trying to reuse program parts elsewhere. Abstract data types and functions are the genesis of clean, modular code. I really don't get what is so magic about "system level capabilities." on the C pre-processor, and my first book about it was how to implement Small C.
It's largely the price of having a certain age. The brothers and sisters of Qt, e.g. WxWidgets, VCL or MFC aren't doing better.
I wish I would have focused on Qt earlier and not wasted so much time on VCL and .NET.
&gt; because alternative build systems are actually much more capable than them. It still complicates the build process. If someone wants to use visual studio or xcode, I suppose the solution is then cmake, which is another dependency and language. All of that might be fine for a large project, but it isn't modular. A single header file library can do extraordinary things that aren't in the standard library. &gt; I really don't get what is so magic about "system level capabilities." I'm not sure what point you are trying to make here or why. What are you talking about putting in platform specific files? File dialogs, memory maps, networking are just some very obvious examples.
CoW isn't bad. Thanks to CoW Qt can have UTF16 strings that are part of the executable yet still are regular QString for the user.
Yeah. There is probably no better alternative if you want to make a GUI in c++. Some useful advice: Use stl-containers. Actually, always use the standard alternative when you can. Don't use foreach, Qt keywords can be turned off. Use qt5 connects, and use them very sparingly, preferably only to connect between a GUI action and your logic. You can use exceptions, but there are some caveats. 
I have complained enough on Reddit about the state of some parts of the concept proposal as it is currently that I felt I need to take the bull by the horns and actually propose something that make sense and formalize my thoughts and ideas. An attempt to be constructive, if you will. I hope you like the design, it make sense. To me. Which is great, if you are me. Of course this is still a draft and I have to work on some of the justifications and arguments. The document is not yet final, notably it is missing references and acknowledgments. If you think some ideas are very similar to Jakob Riedle's "Concepts are Adjectives" paper, it's because it was one of the main reference and base I used for this proposal. 
&gt; Some useful advice: Use stl-containers. yes and no. If you're doing a lot of multi-thread communication with big containers, copy-on-write can be cheaper. Likewise, QString have a ton more features than std::string. 
I don't quite agree why contrained fucntions parameter should be different for lambda compared to normal function. If auto is required here: auto func(Sortable auto&amp; c); It should be required there too; auto func = [](Sortable auto&amp; c) { ... }; If the `auto` is optional for lambda, then it should be optional for notmal function too. We should try to make lambda as similar as normal function. Just my two cents.
QString is pretty great, certainly convenient with a lot of nice member functions. 
Not in standard C++ but has semantics and support in GCC and MSVC (and Clang for compatibility). It’s also a preprocessor feature, and not a first class language feature. It would be really bad form if the standard imposed on vendors to change the semantics of existing extensions and features without their buy in.
If you don't want to install your dependencies, then just use `add_subdirectory(foo EXCLUDE_FROM_ALL)`. The last thing we need is more options in buildscripts.
&gt; If the auto is optional for lambda, then it should be optional for notmal function too. We should try to make lambda as similar as normal function. Just my two cents. Agreed 100%, let's call that an editorial mistake. &gt; Also, if auto is optional there: &gt;`Sortable&amp; c = ...;` &gt; `Sortable auto&amp; c2 = ...;` &gt; It should also be optional in functions parameter, just like lambda parameters. auto in function / lambdas parameters is required to flag the function as a function template. Semantically auto is quite unnecessary however a lot of people deemed necessary that a function template should be distinguishable from a non-template function by its signature alone. I felt it was a concession necessary to make in order to get this proposal considered. The gist of it is that auto is required when it means 'template" and optional when it means "deduced". I should add that in the draft. 
I was afraid of the moc system. In fact, moc is great, an advantage, not the opposite. I wish I knew Qt earlier.
Not exactly. If you pass a subset of a zero terminated string, it will copy the subset into a temporary buffer, zero terminate it, and hand it to the OS. If on POSIX, as on Windows you don't need to zero terminate path strings, just tell it the length. If the path view is already zero terminated, it gets used directly, no buffer copying.
I agree, function parameters that cause the function to be template should require auto. However, variables with multiple constraints feel quite hard to read with the lack of auto. I wonder if it should also be required even in deduction context, just for constancy. If `auto` is required in deduced context too, there won't be difference when declaring a local variable deduced type, or a deduced (template) function parameter.
ah ok, idk it has that check for termination, I assumed it relies on programmer discipline. :)
Hey folks, I am the presenter of this talk and the author of transwarp. Please let me know any feedback you may have! Thanks!!
Any words to /r/cpp wrt Preview 3?
If you need a function that accepts an unknown number of parameters of a certain type, here is one way I found to do it: template&lt;typename...T, typename=std::void_t&lt;std::enable_if_t&lt;std::is_same_v&lt;unsigned,T&gt;&gt;...&gt;&gt; 
Compare that to [NanoPB](https://jpa.kapsi.fi/nanopb/docs/), which doesn't need malloc at all. :)
Could you possibly elaborate on as to why not use foreach?
https://www.youtube.com/watch?v=uZ68dX1-sVcD Does it better than I ever could. 
Thank you, I will look into it!
Is Windows 7/8.1 supported?
In my experience, there are too many valid cases where return values are discarded, and having this on by default would add a lot of clutter. This is especially true when function return convenience values that aren't necessary, but might be helpful in some cases.
Actually, I put `const&amp;` just for brevity. There should be universal ref. &gt; Make a copy, then take the lock and move it in Well... I don't know, I personally can't prove that this will be faster... I totally disagree that move = just faster copy.
Check out [Model View (Delegate)](https://doc.qt.io/qt-5/model-view-programming.html) programming. The way I think of it is the Delegates refer to individual items within a view, the View is the overall widget containing items, and the Model is a way of aggregating the data so that it can be understood by the view. Also, you can use non-standard widgets in the designer via [Promote To](https://doc.qt.io/qt-4.8/designer-using-custom-widgets.html). Getting them to display cleanly is unfortunately [non-trivial](https://doc.qt.io/qt-5/designer-creating-custom-widgets.html). Translations and stylesheets are surprisingly easy. If you have some time, consider watching [Effective Qt](https://www.youtube.com/watch?v=uZ68dX1-sVc) from cppcon 2017 at 1.25x speed.
&gt; If, instead of process(Closure closure) the interface was something like getAll(container &amp; container) Good point! Really clever, I actually even update my code with this. The only thing to emphasize, that `container&lt;Messages&gt; msgs;` should be class or global variable, not local variable [that one didn't get to me at first:)].
Because C++11 style range for syntax works fine on Qt containers as well as standard containers.
We’ll need to publish a new table for 15.5, but the table at https://blogs.msdn.microsoft.com/vcblog/2017/08/11/c17-features-and-stl-fixes-in-vs-2017-15-3/ contains most of the info (marked as “15.x”). The extra features we were able to get into 15.5 were: * Splicing Maps And Sets * Inline Variables My CTAD and constexpr char_traits implementations (enabled for Clang, not C1XX yet) are for the toolset update after 15.5.
The answer is to be careful about what you mark with nodiscard. In MSVC’s STL, we’ve tried to be very careful.
Totally agree. I have no doubt that making the `[[nodiscard]]` behaviour the default, like suggested above, would lead to so many warnings that they would just be ignored.
Very interesting talk as always from Louis. Thank you!
thank you
Yeah I still don't know if I should use qmake or qbs?? qmake is the default but it seems qbs is the newer/better build tool?
sounds like a problem for metaclasses
they aren't exactly raw owning pointers - items are almost always parented which is the Qt equivalent of ownership - it's just that they can be deleted from the parent by using the raw pointer as well
You can typedef the constraints with this syntax I assume, so you wouldn't have to actually type 4 constraints in a row.
I just want to make sure, but are you considering easy syntaxes like `typedef MoveConstructible NotCopyConstructible OnlyMoveConstructible`? That's something that would really help making constraints easy to use.
I think what is missing is you can't put different levels. Like "definitely don't allow compilation if discarded" level and "might be a problem, but not as much". For example, anything returning raw pointers should error out if the pointer is discarded (memory leak), but in some other cases it's not 100%.
You need reflection for that, but that's coming in C++20 hopefully.
It's fine if you use it sparingly. If you're just replacing a POSIX call by the equivalent MS one, it's not worth making 2 different files.
But you should remember to cast the container to const to avoid needless detach calls on Qt containers if you do this, since you can't manually call the const iterators. The standard `as_const` or the Qt-provided `qAsConst` calls work fine for this.
No and no. Which is why we haven’t gone UWP just yet, but for the next version we most probably will. If it were up to me we’d drop 7 and 8 now, but marketing and their numbers...
The networking TS won't be much use without TLS though, so doesn't that in effect mean that something needs to be done?
My biggest problem with QBS right now is that there aren't prebuilt modules for any third-party stuff. They are easy enough to write, but it is slightly annoying.
qbs is a far better tool than qmake.
There is no reason to ever have opening raw pointers in qt code. Almost all objects should be managed as part of the qobject tree by setting their parent at construction time, and the rest should be managed using unique_ptr.
If you want to create something more complicated than a few headers/cpps + main, when use anything other qmake. It'll make things much easier for you in the long run.
Another goal of the module system would be giving semantic meanings to C++ translation units so make it more tool-able. This cannot be done without treating a module as a first-class language construct.
Working through it now. See also the comments on the friendly competitor Folly.Poly in Facebook's open-source library: https://www.reddit.com/r/cpp/comments/79prbd/follypoly_a_c_library_for_conceptbased_dynamic/ My initial feeling from looking at Dyno, Poly, and Sean Parent's original talk on the subject is that this sort of thing will drive new features in the language (metaclasses?) in a way similar to how Boost.Lambda pushed the limits of what could be done in C++03 and showed where there was a room to grow the language syntax.
Use clazy to keep your code in check.
In QT Creator, while hovered over a QT class, hit F1 to open the documentation for it.
Just thinking out loud here... If there can be a constraint called 'sortable', can we also have a property called 'sorted'? And then use that to automatically select a search algorithm (linear or binary)? Would it be possible to propagate such a property (same as const is propagated today)? 
Returning a raw Pinterest should never cause a memory leak in c++code, because they should not own anything. Just consider all the standard algorithms like find.
&gt; For example, before we had fold expressions, we had to use recursion and hope for the compiler to inline the code. No, that is not necessary. Regarding the rest of the comment: I'm pretty sure, that the eople working on the reflection proposals are aware of LISP. I'm not qualified to say whether we should strive for the same meta-programming capabilities as in Lisp, but the fact remains, that c++ simply has a completely different grammar, syntax and semantic. So most likely, users will NOT want to operate on code directly, but rather on a more abstract representation of it.
Well is there any instance were you are supposed to return a raw pointer (even not owning) and do nothing with it? Usually raw pointers are evil and should not even appear in your codebase, you usually only need them for interacting with libraries that don7t ue smart pointers.
Surprisingly, at least on my computer (specs at the bottom), it seems `std::exchange` can actually be _faster_ than `std::swap`! Using the Hayai microbenchmarking library, I compared the two by repeatedly swapping two `std::string`s, each with 10K elements, for 100 runs of 10M iterations per run. I tested with GCC 7.2.0 and Clang 5.0.0 (stdc++ and libc++ were used respectively), and here were the results: GCC swap: Median performance: 47.68375 runs/s (1st quartile: 48.20787 | 3rd quartile: 46.81538) exchange: Median performance: 12.27468 runs/s (1st quartile: 12.33555 | 3rd quartile: 12.18970) Clang swap: Median performance: 47.46512 runs/s (1st quartile: 48.18325 | 3rd quartile: 46.52656) exchange: Median performance: 10.02083 runs/s (1st quartile: 10.09060 | 3rd quartile: 9.93620) As expected, the performance of `std::swap` is faster than that of `std::exchange`. --- However, when I tested it with a `std::vector&lt;T&gt;` at 100M iterations per run, I observed these results: GCC swap: Median performance: 4.08057 runs/s (1st quartile: 4.12736 | 3rd quartile: 3.95562) exchange: Median performance: 4.72181 runs/s (1st quartile: 4.75144 | 3rd quartile: 4.68850) Clang (libc++) swap: Median performance: 12.90201 runs/s (1st quartile: 13.24148 | 3rd quartile: 11.58960) exchange: Median performance: 12.52744 runs/s (1st quartile: 12.71920 | 3rd quartile: 12.13824) Note the runs/s is lower overall due to higher iterations per run. In Clang's case, the difference appeared to be negligable, though it still seems to slightly favor `std::swap`. However, in GCC's case, `std::exchange` was noticeably faster than `std::swap` (!!). Curious, I ran the benchmark again with Clang, but using the GNU standard library instead of libc++: Clang (with stdc++) swap: Median performance: 13.44444 runs/s (1st quartile: 13.65688 | 3rd quartile: 13.14506) exchange: Median performance: 12.04004 runs/s (1st quartile: 12.56515 | 3rd quartile: 11.39599) Perhaps this is indicative of a suboptimal implementation of `std::swap` in the stdc++ library? Regardless, thought this was interesting and wanted to share! --- * [Compiler Explorer](https://godbolt.org/g/DnbH1H). * [Benchmark Code](https://spit.mixtape.moe/view/1b38a8e6). * [perf report](https://spit.mixtape.moe/view/b276b630). * Run on Intel(R) Core(TM) i7-4700MQ CPU @ 2.40GHz.
Lol @ think-cell HR trying to dance around the issues that they apparently have. Also, beware of the said Technical Directory. Even positive reviews at glassdoor indicate that TD is a nutjob, who shouts at devs. Source: https://www.glassdoor.com/Reviews/think-cell-Reviews-E710083.htm
Also, ctrl-k
So... Even if everything will be in dyno::local_storage, called method still can not be inlined? I mean, compiler still will do `call`. Because called function is unknown at compile time. When with `std::variant&lt;Ts...&gt;` compiler can actually inline target/"virtual" function set, because all possibilities are known. Though there will be switch jmp-table, compiler have capabilities to optimize and reduce inlined function bodies. Especially visible on small getter-like functions. For example: [variant](https://godbolt.org/g/jZr5gZ) - no calls. [function pointer](https://godbolt.org/g/ooCtxw) - pay attention to call at the very end. Removing indirection to vtable, is understandable performance gain, but as I can see from disassembly at 46:20 there are still `callq`'s. Or I missing something? I mean `std::variant&lt;Ts...&gt;` still should be faster, right? (let alone memory considerations)
I was at the conference and really enjoyed this talk Christian. I love what continuations can do to make code asynchronous. .then will be a great addition eventually to the language. Good thing your library, HPX, stlab etc are highlighting this style. 
Constraints and concepts are compile-time construct. If you want a sorted container, your best option is to write a custom container whose "insert" method would insert sorted. Another option is maybe to have some kind of proxy that sort the underlying data in place when it's casted from an usorted container to a sorted one. Different performance profiles.
Implicit sharing with CoW is actually really bad. I've witnessed multiple cases where QVector breaks in multi-threaded usage due its contents being shared beneath the surface, across multiple instances/values.
While potentially interesting, it seems to use an godawful amount of memory. As it is transpiled from some functionnal language into javascript, I have zero idea where the overhead comes from. For non-trivial uses cases (ie: fed with a sample of 100Kb json files), I get: FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - process out of memory after roughly 30seconds of struggle and 1.5Gb of memory used... In other cases, giving it 85 files to work with, I get 1Gb+ of RAM usage, and: { [RangeError: Maximum call stack size exceeded] undefined: true } after 30 minutes of execution time. 
I don't propose that but a similar proposal ( "Concepts are Adjectives, not Nouns" ) Play with the idea of having concepts as template template parameters ``` template&lt;typename T, template&lt;typename&gt; concept... Cs&gt; concept Or = ( Cs&lt;T&gt; || ... ); // Usage template&lt;Or&lt;Even,Odd&gt; int N&gt; void foo(); ``` And then obviously you can write `using OnlyMoveConstructible = And&lt;NotCopyConstructible, MoveConstructible&gt;;` I'm against baking in logic operations on types in the language, especially when we have this more natural solution ( in that it uses existing c++ construct ) 
What do you mean by break? The CoW infrastructure is thread safe. There can be issues though keeping iterators and references to elemts alive.
If anyone here doesn't know, Tim (OP) is Founder of Epic Games who make Unreal Engine 4, a large popular c++ game engine (who's source code is accessible on github, via a license agreement). If he has concerns, I believe it would be beneficial to all of us to continue a dialogue and find common ground. The game development industry is a one which often roles a lot of their own versions of standard library containers and has sometimes different view to those that the c++ community here on reddit has. If Tim is talking to us, then we should welcome him and definitely listen to any concerns he has about the way the standard is going. I personally believe that game development is the way that c++ is going to (and is) attract new developers to the language.
It depends on the layout of the message of course. If it is just a struct with some primitive types move will be just as fast and you'd be duplicating work, but if it has types that allocate, move can be faster. You know the types so probably have some intuition already =)
Please look at https://www.reddit.com/r/cpp/comments/7asp9d/a_design_for_code_injection_and_metaclasses_based/ it introduces some of the same ideas. But. List macros can not be fitted in C++, they had to be there from the start. Notably, thanks to herb sutter and andrew sutton works, we have a very good model to inject statements and expressions, and I have described a "macro" feature on top of that work that would be able to take in expression and inject either expression and statements. However, I can't find a good model to pass statements to a macro. One of the reason is that statements are not really a thing that you can put in a nice theorical model. In c++ everything that is not an expression is a statement. Expression are nice, they have a type. statements, not so much. You also have the problem of dealing with lookups. Like what if the thing you want to pass as parameter to the macro depends on a variable defined inside of the macro ? And sure, you can find crazyu lookup rules for that but then would the code be easy to read / write / reason about ? Functionals languages have it easier in this instance. But don't worry, people are working on it. 
If you want to be standard compliant you can do that: https://godbolt.org/g/h4HPZR Requires the user to use a macro though and clang seems to have some bugs.
My intuition says - it's not worthy :))
Well, chances are the issue is your code and not the compiler. What does it output? What exactly is it supposed to do? What exactly happens?
I'm trying to compile that thing, If I open the .exe manually it gives me the right program, the one I compiled. If I use F11 within the dev c++ it will run me a program I DONT EVEN HAVE on my hard disk. Doesn't matter if I change the project name or delete and re-compile it, it's the same.
Sure using rvalue ref is by far thr better option 
&gt; specific policy of only upgrading things when they have to, not just because they want to. I would hope security updates fall under the policy "have to"
https://imgur.com/a/8QqFb // RUNNING F11 WITHIN DEV C++, gives me different program. The program I've made is calculatng how many days in a month there were temperatures above 30, in this one that is showing in the image it's saying : Insert three numbers, I DONT EVEN HAVE ANY OF THIS ON MY PC. https://imgur.com/a/kwz4Y // RUNNING .EXE MANUALLY.
&gt; I'm trying to compile that thing, If I open the .exe So, the compiler returns successfully after all? Because otherwise it wouldn't give you an executable file. &gt; it will run me a program I DONT EVEN HAVE on my hard disk. There is a very good chance you have. Where else would it get that program from? &gt; Doesn't matter if I change the project name or delete and re-compile it, it's the same. That doesn't sound like the compiler is acting up, honestly.
//rant on &gt; In short, the very reason we want to replace printf (it knows next to nothing about types outside of the format string) is exactly why it's so fast. No overload resolution, no **template metaprogramming**, [...] I agree with most of what you are saying except that very last point about tmp. Tmp is a scourge that only exists because natively integrating the features achieved by TMP into the language is extremely expensive. Almost any feature that uses tmp could be implemented in the compiler more efficiently, less error prone and with nicer syntax. That is not to say that I don't want a type safe and extensible version of printf as provided by the fmt library, but compile time checking of the format string could and imho should be left to the compiler. I know, it is not going to happen for various, more or less valid reasons and the solution presented here is probably the best we can realistically achieve, but Imho it is far from being ideal //rant off 
&gt; I meant situation like "Algorithm X is demonstrated to be broken, we have to switch to Y as a default and introduce new algo Z for the future." That would be an API change. Or even "Quantum computing is a reality now, so all the old algos are broken and we need a completely new quantum API". I feel like hypotheticals like that are true for any and every solution that will ever be made, ever, and shouldn't be used as an argument against having solutions. Existing Crypto libraries, standard or not, would have the same issue. If a crypto library updates before the standard, people will just use that instead. Algorithms really shouldn't be being broken often enough for it to be an issue with the standard, and if they are i feel like there are much more pressing security issues.. &gt; Security is only a part of the product. People don't like to update the toolchain because it may may break some code elsewhere. Updating crypto only is much less of a problem. I feel like thats a them problem. Maybe i don't have enough compiler experience, but i feel like if your code cant move to a toolset/standard version without breaking, your code is wrong. In an ideal world, of course.. Sadly reality rarely matches, but IMO the language shouldnt be hindered by their bad practices. Should the standard never have new features because some people don't update their compilers?
Sounds like, at worst, an IDE/build system bug. Try running whatever the equivalent of `make clean` is on your system, or manually deleting `.o` or `.obj` files.
The file name in Dev C++'s title matches the output of the compiler which maches the title of the terminal window... Your program is the issue, not the compiler.
Why are you posting this here and not as a bug to the VS team?
I agree, this subreddit should not be a MSVC bug tracker.
I guess you know Rob Pike, Ken Thompson and their role on the C language My way is how Go build system handles platform specific code, https://golang.org/pkg/go/build/ Also how they alongside Dennis Ritchie, designed C on Plan 9 &gt; The traditional approach to this problem is to pepper the source with #ifdefs to turn byte-swapping on and off. Plan 9 takes a different approach: of the handful of machine-dependent #ifdefs in all the source, almost all are deep in the libraries http://doc.cat-v.org/plan_9/4th_edition/papers/comp &gt; I'm not sure what point you are trying to make here or why. What are you talking about putting in platform specific files? File dialogs, memory maps, networking are just some very obvious examples. Everything that is OS specific with hundreds of #ifdef around them.
Because you don't know how do deal with it. On the opposite, I think this is great and safe. Used intensively here!
&gt; Use alt left/right to shift between the most recent files. This. This is a default for all browsers, so it should be the default for all other applications (looking at you nasty VisualStudio).
I tried deleting the .exe and .cpp files and starting a new project but THIS CODE gives me always an old program I've done a few weeks ago. Whole different thing!
So you're not deleting your object files (`.o` or `.obj`)? Sounds to me like you've got a "stuck" (broken permissions, future modification date, etc.) object file that keeps getting used instead of your code. You may want to develop an understanding of the different stages of the build process and the roles of the tools involved...
So where do i find these obj files?
Well, used "intensively" here, too. Frankly, we're minimizing Qt-usage nowadays, basically limiting it to strictly UI. We've used Qt since its commercial license model, so it's not like we "don't know how to deal with it". The ways you can break the implicit containers are very subtle.
Entirely dependent on how your build system is configured. Probably somewhere near the executable.
I think people want to be able to say it with language level because that would make the code smaller and easier to type. And it would feel more natural, like concepts are a first class language feature and not just something thought of later on. Like being able to write `using AnotB= A &amp;&amp; !B` would be great. I do understand it would add burden to the compilers because they would have to deduce that A/B are concepts and not variable names, but once you've gotten as far fucked in the grammar complexity as C++ has, you might as well go all the way. If you make concepts really easy to use, then everyone will use them and that would be great. If it's as much pain as SFINAE can be, people won't.
Just to ensure clarity: this specific rule applies only during the second phase of dependent name lookup. It came up again yesterday during discussion in EWG, who took a painful 4 polls just to ensure the clarity of when this specific rule. 
Usually in a sub folder of the project folder, but maybe there's none to begin with. I compile my programs manually with G++ and I've never even seen a `.o`/`.obj` file appear anywhere. 
8 is remarkably dead, it's just unfortunate 7 is still in such wide use...
You might think it means that, but *_view often also means "hidden copy". On POSIX, almost all syscalls only accept zero terminated char arrays. If the C++ standard blindly replaces `const char *` with `string_view`, it forces implementations to *always* copy the string to an internal buffer - which may even be allocated via `malloc` - in order to ensure zero termination. And that would be stupid, so we best not do that (and we won't).
OK, I know that, what I was saying that it may be confusing to name stuff _view since I assume many people assume _view means what it does not mean... BTW often I have thought how it would be cool as language enabled us to write something like this `constexpr char[] carr= "my constant string";` `void func(const string&amp; s);` `func(as_const(carr)); // as_const produces "const string", where beging poinst to 'm' in carr, and end one past 'g'. ` But the problem is beside obnoxious const_cast that I think in language you can not force arguments of as_const to be only constexpr char arrays that are zero terminated.
As far as I am aware, there are plenty of ways of implementing efficient borrowed views of strings at the language level, but none which permit C language compatibility. So I suspect Rust and Swift et al have us licked on this one thing at least. Of course, if POSIX implemented sized strings, all this goes away. But I'd say that's a long time out. The annoying thing, of course, is that the kernel will buffer copy the string into kernel space anyway during the syscall so it's an unavoidable memcpy in any case.
How?
C++/WinRT contains a proprietary Microsoft library. Microsoft saw no one bought C++/CX, and so they offer another hook, C++/WinRT. What would it take to make code portable using C++/WinRT? right, duplicating WinRT, and all the Microsoftisms of COM. No thanks Microsoft, we don't want it, we don't need it (for writing portable c++ code, that is!). 
Please ask for help in /r/cpp_questions.
Because you'd more likely to dive your project into subprojects. And qmake sucks at properly isolating them. It's hard to propagate proper settings among them and it's even harder when you try to add some other lib to your project, without manually modifying it's files. Also, afaik, there is no proper way to do a lot of post/pre build-steps, like copying files around. There exist some hacks, but they don't really work and they are ugly. And lots of stuff like this. Basically, if your project requires something more complex when just a simple pro file which lists all your headers/cpp, when qmake is a no go (well, the more additional stuff you need to do, the worse qmake becomes).
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
That's constexpr, dunno what the problem is that you're having?
My solution is similar to this, but I'm not happy with it. What I really want is to fall back to run-time checking if the supplied string isn't constexpr (std::string, non-constexpr char* / string_view, etc.) As far as I can tell - there's no practical way of accomplishing this yet (checking for the constexpr-ness of a lambda function). As always, it falls down to "we want constexpr function parameters" - then you could overload the function based on whether or not the supplied parameter is constexpr or not.
Can you give me an example of when you'd like to divide your project into sub projects as well as an example of when you'd like to copy files around post-build? Genuinely curious. I work with embedded systems for which Qt is merely the front end and all the business is handled in separate non-Qt projects.
Hey everyone! I'm the presenter here, happy to answer questions in case there were any!
Cool library, thanks for sharing! Is there a reason the format library has to be a user-defined literal? Have you considered just using a function instead, that can return a string or could be used to output directly through a stream?
&gt; In standard C++ ? No, but we can't just pretend Objective-C++ doesn't exist. For one thing, Apple have seats on the committee and would surely veto any propostal that gratuitously broke compatibility. WebKit etc are rather important to their ecosystem.
making a deep copy of a stl containers instead of a move, can happen subtly too ;)
oh god, you're actually using dev-c++. This software hasn't been updated in... what... more than ten years ? 
Does qtcteator support qbs or cmake? I found that qmake is hard to work together with sub-project not written with qt. 
For example if your project has a modular structure and also consists of a many plugins. Each plugin would when be a separate project. But the resulted binary/dll needs to be copied to the specified folder (near bin) or else it won't be found by the executable. Now imagine that you also want to add 3rd party libs to your project. How would you do that properly? Well, if they are not header-only, you'd like to build them in a subproject. But if they use (and if you use qmake) qmake chances are it'd be nearly impossible to do that without manually rewriting parts of their project files. Furthermore, one very annoying thing about qmake is that in this scenario it doesn't really track libs/include dependencies. I.e. you need to manually add all includes and proper linker flags in all your subprojects, while CMake (and most likely qbs) do that automatically for you.
Could you send me those JSON files, please?
What do I use then? And why tf does everyone downvote everything im posting? Can anyone explain me these two things, thanks?
Just a guess, but does `C:\Users\dnest\Desktop\Scuola\INFORMATICA\TEST.exe` exist?
Wut dude how did you know this wtf?
It does i deleted both the source code and compiled exe and recompiled from scratch it still gives me this error 
Visual studio is a good start on Windows, and you can use QtCreator too. On Linux, I personally use KDevelop, but it's quite easy on Linux to pick CMake and any text/code editor.
point of my example was that it would compile only for char arrays that are zero terminated, so you would get compile time check that user is not passing wrong data, so you would not need runtime checks wrt termination/potential copy.
Because c++ and Star Wars are equally cool! ** As a Star Trek fan myself, I’m concerned that statement undervalues c++ .... 😛 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7bc048/c_compiler_bug/dph40si/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Running literally any software on Windows involves depending on proprietary Microsoft code. Their hook is their userbase, not COM or anything on top of it. (TBH those are probably deterrents for most people...)
Another `constexpr` function is now allowed to instantiate a `Value` and call `set_value` on it.
Yep, just use the *v124* tag: https://github.com/boostorg/beast/tree/v124
I'm stupid. Thanks.
Eh? You're making no sense. First of all - it's a library. Not a language extension. Do you understand the difference? Do you realize that OS APIs are not part of the C++ standard? Obviously an OS-specific component will contain an OS-specific library, and obviously it requires an adapter when making portable code. The whole point of C++\WinRT is exposing a modern C++ abstraction on top of COM, WinRT and UWP API's. This will allow people who use modern C++ and *target Windows* to use standard C++ idioms to interact with native windows APIs using normal modern C++, which was impossible. This will also allow people who develop multi-platform components (ie - the libraries *you* use to write multi-platform code), to have a much better experience when adapting OS-agnostic abstractions to windows. Since the WinRT is a modern object oriented API and is now fully C++ compliant, it will require much less dirty hacks and re-implementations of ugly wrappers. It has nothing to do with C++/CX. Do you know btw, that Herb Sutter was one of the lead devlopers of C++/CX, and probably used that knowledge to improve C++? And while COM is not easy or simple (and I'm far from an expert), it's an incredible tool for runtime polymorphism, and allows handling objects across process and system scopes. The entire idea of coding to interfaces, and relying on factories to provide you with the correct implementation at runtime, is much more OOP than statically linking to system calls.
Don't bother with QtWidgets, dive straight into QtQuick. Even for simple desktop apps.
Not a stupid question. Weird subtlety of an evolving language.
&gt; The traditional approach to this problem is to pepper the source with #ifdefs to turn byte-swapping on and off. Plan 9 takes a different approach: of the handful of machine-dependent #ifdefs in all the source, almost all are deep in the libraries I'm not sure how this contradicts what I've been saying, it sounds like the same thing. &gt; Everything that is OS specific with hundreds of #ifdef around them. Earlier you said: &gt; I really don't get what is so magic about "system level capabilities." So what is it that you are actually saying? Do you even know?
Is this the same as the cpp con talk?
&gt; is there any instance were you are supposed to return a raw pointer (even not owning) and do nothing with it? plenty such instances in the C string library. strcpy returns a raw pointer
That's a terrible suggestion and will make your project eventually explode. It's simply not how CMake is mean to be used. CMake doesn't support namespacing or and encapsulation for subdirectories so some dependencies' CMake files will not be set up for this to work As a simple example.. if your CMake file asks for the project version number it will get some completely wrong values if it's being uses as a subdirectory. A more immediate issue will be multiple targets with the same name (things like "uninstall"). Again... no way to fix it b/c CMake doesn't support namespaces. You'll likely get away with this for small projects with only a few dependencies, but you're abusing CMake. Projects like Hunter are meant to solve directly https://github.com/ruslo/hunter/ (haven't yet used it myself.. would love to hear from someone who has though)
It's worth noting that C++11 didn't allow this, and actually implicitly had `constexpr` mean `const`. This was because C++11 constexpr functions were only allowed to consist of a single return statement, with no mutation of variables. I suppose the huge change for C++14 was down to compiler authors turning around and saying that a much more fully featured constexpr was possible.
Honest question: Almost every time I'm using runtime polymorphism, the function behind the virtual function call is so complex that the overhead really doesn't matter. Is the performance of virtual function calls really a bottleneck? The only actual problem I've encountered in the past is the additional dynamic memory allocation. That being said: According to rumors - in particular when you use pgo- compilers already use speculative inlining.
Here's what you can do: constexpr Value getValue() { Value v; v.set_value(3); return v; } constexpr Value v = getValue();
Fyi, CMake support got merged yesterday.
I copy pasted the entire question as is on Google. Here's the first result: https://stackoverflow.com/q/495021/2104697 Learn to search.
Sorry I did and I came up with the same answer but my professor is trying to tell me you can have a .h and .cpp file with class templates and that was causing me to second guess myself. Thanks for the answer.
You would put class templates in a .cpp file only if no outside source requires them, as you do not #include .cpp files.
Your teacher is wrong. I presume he includes the cpp in his header file. This is also wrong. You can separate the templates into two files, but the implementation is usually in a tpp or hpp file.
The compiler has to know at compile time what the instantiations will be. The simplest way is to put everything in one file and then suffer the compile time performance penalty. I have put the list of instantiations in the cpp file or created a .template.cpp and then included that in multiple files that listed the instantiations. The latter was only done to reduce compile times from unbearable to long.
Constexpr means evaluate at compile time, there is nothing wrong with having mutable compile-time state.
if you haven't bothered watching it yet; yeah it appears to be close to the same (jumping through it looks entirely familiar).
Well, hopefully not global. That's rarely a good choice. It just needs to live as long as it needs to live (obviously). If this code was in a thread that basically processed items and nothing else, then `msgs` could be local to that function that runs the thread.
No I just told him I was using templates in our current project and that I put all the implementation in the .h file because I used templates. Afterwards, he tried to convince me that I should be able to have a .h and .cpp file. Thank you for the confirmation though.
Are the slides available somewhere? Btw thanks for working on this, this will allow me to retire a ton of adhoc code from my debugging toolset. 
All in all, would it look something like this for example? QVector&lt;int&gt; vector = {0, 1, 2, 3, 4, 5, 6}; for(const int&amp; i: qAsConst(vector)) { printf("%d\t", i); } 
This post specifically mentions Google Test which needs to be build from source, documentation which explicitly says to use `add_subdirectory()`. The proper way to avoid to build any random library you don't need or install it and any other 3rd party is using `EXCLUDE_FROM_ALL`. That's it. Don't try to sell your Hunter in a totally unrelated post. More over, Hunter doesn't propagate the build flags properly to what it builds, rendering it borderline useless for any advanced usage that changes the ABI flags. No thanks! And no, my projects don't explode, they are all built from source with their dependencies and don't have any ABI incompatibility issues at all, thank you.
I was tackling similar problem (running DAGs of tasks) last 6 months or so. Decided to not use futures/promises because waiting on it consumes current thread causing excessive context switching. Ended up building my own bicycle from scratch (using C++11 primitives) -- haven't had this much fun in ages. There are curious problems in this area -- like exception safety, early termination, rollback (when your task fails in thee middle and needs to undo before returning error to parent task) and etc. Ultimately I've realized that the only way to have sane code -- is to use stackfull coroutines. Even Gor's baby (which is kinda "inlined" version of stackfull coroutines) is not going to cut here. Unfortunately in C++ coroutines are in their infancy right now (I've heard this is where Go shines). Even when we finally get them right -- there still will be tons of problems to solve (replacing classic mutexes with non-blocking one, dealing with blocking inside of kernel calls, limiting numbers of coroutines, etc). Microsoft tried to tackle this beast in their [Midori OS](http://joeduffyblog.com/2015/11/03/blogging-about-midori/) -- it is a very interesting read, btw. Alas, project ultimately failed (who needs OS written in C# with one-thread-per-process limit anyway? ;) ). 
There are so many things wrong with this video, I don't even know where to start...
Why would you say that?
As OP says, Lisp code is expressed as one of its own central data structures, the list. C++ code is not. But C++ code is still intimately connected with an important data structure (other than text): its parse tree. Of course currently a parse tree doesn't exist in any form accessible to the program itself. Perhaps it exists inside the compiler, completely hidden from the programmer. But it doesn't have to be this way. What if C++ standardised a concrete data type to represent its own parse tree, complete with methods to look up declarations and definitions of names according to the rules of the language? What if we could write `constexpr` functions to manipulate parts of this tree? This is not exactly a crazy innovative idea. Some languages that don't quite resemble Lisp syntactically have metaprogramming facilities just like that. Haskell, I'm looking at you!
Sure, but they contain personal information, so I can’t send them as-is. Give me a couple of days to replace the strings by giberrish while keeping the same structure/occurences.
After reading comments in this post it totally makes sense to say in praise of CMake ; “One build system, to confuse them all”. No one knows how to do things correctly when it comes to CMake, it seems.
Because it's not only a lacking coverage of the topic (I don't expect you to talk about everything, but come on, even some of the nasics are not there), but there are mistakes. Like, that variable was not a char.
I haven't followed the series, but this seems to be about a "strong typedef" class called `NamedType` and adding `operator T&amp;()` and `operator-&gt;()` to it so the underlying object can be accessed naturally. It uses template parameters for policies (no idea why they're called "skills", _policies_ and _traits_ are well established) and CRTP to mix and match those features. And I'll say it: C++ has member functions, not "methods".
I will look into the char*, as I am now confused myself, but what exactly would you add in a tutorial of this type?
I suspect Sirpalee is having some trouble with: * **#include &lt;iostream&gt;** and **using namespace std;** while you are not using anything from iostream or std. Even if you were, it's generally frowned upon to have "using namespace std;" in your code (putting all included parts of std in your global scope is a good way to have a bad time). * **char * b = "Hello";** is A) a string, not a character, B) not valid C++ (conversion of a string literal to a char * in this fashion is forbidden by the standard). * long, short, signed/unsigned, etc are not 'modifiers' exactly, they are seen as completely different types. * Declaring a variable as void doesn't compile. In C++ you probably only want to be using void for denoting the absence of a variable at all, rather than the absence of a type. e.g. declaring a function **void f();** doesn't mean the function returns some magical typeless value, it means it returns no value at all. I may be wrong. I am hardly an expert.
I tested the void part out, I was surprised that this doesn't work in c++, I was sure it did when I did the video. Will add a note inside the video on that to fix that. but why exactly is char* a string? Shouldn't a string be declared like this: string [identifier] = "";?
Also, F4 to swap between .h and .cpp. I absolutely love that shortcut.
Well, I would call any sequence of characters a string. 
They are as of two seconds ago: https://github.com/pacificplusplus/conference2017/
Good examples, though I don't think you should be using `strcpy` in C++ code.
Since you didn't actually get a real answer: `#pragma once` is pretty universal now, but the behavior isn't 100% consistent across toolchains. I can't remember all the minutiae, but depending on OS/compiler, symlinks were handled inconsistently. I know from experience that VS2005 has a bug in `#pragma once` that will not stop a circular include from reincluding the file. Obviously you shouldn't do that, but the preprocessor defines work consistently, at least.
Yes of course but for now you can just make a version of the function that takes the standard runtime time types and the other with a StringRepr equivalent and let the user choose which version he desires by using or not the macro.
Well, you certainly can have ".h and .cpp file with class templates", as well as ".c",".b" and ".&lt;any-extension&gt;". It all boils down to how your translation unit ends up looking like and whether or not you'll end up violating ODR. ".h and .cpp" is just a widely accepted default approach that allows you not to think about this too much. 
If you know the types your template will be instantiated with, you can place the implementation into a cpp file (i.e. a separate translation unit). Otherwise you can still split it into separate files, but in the end, any TU that uses it has to include all files.
Does that mean there's such a thing (in C++14) as `constexpr` functions with `const` arguments meaning basically what `const` always means (for references, the data isn't necessarily constant, but it isn't changed directly via this reference) but at compile-time rather than run-time? IIRC pointers are explicitly disallowed for `constexpr` (with presumably a special exemption for `this`), but not references?
The official documentation for XRay in LLVM is at http://llvm.org/docs/XRay.html. The FDR log format is documented at http://llvm.org/docs/XRayFDRFormat.html.
Thank you! If you install the [development version of jq](https://github.com/stedolan/jq) you can use this command to replace all strings with `"foo"`: jq 'walk(if type == "string" then "foo" else . end)' &lt;in.json &gt;out.json
And if you start talking about variables and modifiers (I'm not sure what's the right terminology here, I never had to name those), talking about const would be the least thing to do. Auto would be a good idea to mention. (or maybe not, I'm not 100% convinced here) Also, there was the issue with using a double to initialize a float (I would have talked about the difference when using the f literal). Defining int as something that stores a number is too vague. Things like this. If it's not meant to be an all around tutorial about variable declaration, that's perfectly fine. Do your viewers a favour and link one that covers everything in the description.
char smt = 'c'; would have been a character. char* smt = "c"; is a string (c style string?). There is a big difference between the two. And the usual way to define a string like that is to use const char* = ...;
&gt; Usually raw pointers are evil and should not even appear in your codebase, you usually only need them for interacting with libraries that don7t ue smart pointers. I totally disagree, but that is a different discussion &gt; Well is there any instance were you are supposed to return a raw pointer (even not owning) and do nothing with it? If you replace pointer with iterator (which often are pointers and when not are at least the moral equivalent) there are a few examples in the standard library: - various algorithms like `std::copy` or `std::rotate` - insertion functions like `insert` and `emplace` - placement new 
I've never liked the idea of including third-party dependencies in my own projects and rebuilding them for each project that needs them. Some of the CMake files I've seen for libraries designed to be included in other projects like that are horribly complex. On the other hand, using CMake find_package in config mode and installing or providing config files for dependencies under some prefix seems pretty easy so I've just been doing that instead. It also keeps my own project build files clean of dependency configuration clutter. 
I'm pretty sure C++11 already broke compat with objective-c++.
But iterators are not raw pointers, they are explicitly non-owning and have semantics attached to them. The issue with raw pointers is the compiler can't know what you want to do with it so it's unsafe. Which is why you should use as few as possible.
You can use a function e.g. `fmt::format("{}", 42)` or `fmt::print(...)` to write to a file. However, this won't work for compile-time checks for reasons explained in https://mpark.github.io/programming/2017/05/26/constexpr-function-parameters/.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
What if C++ just standardised libclang?
So C++ compilers are also interpreters now? Awesome.
Worth noting C++ compilers (the good ones at least) have always been doing this at least to some degree, it's just now formalized in the standard and guaranteed when you use constexpr.
constexpr can manipulate pointers and arrays in C++14 just fine.
Sorry, but from personal experience, that's incorrect. I've tried that way of managing dependencies, and the problem is that EXCLUDE_FROM_ALL doesn't preclude target name collisions during configuration ... It just doesn't build targets that aren't using in the top level. Nor does it fix issues with subdirectories using the project name/version etc.. I'm glad your projects aren't exploding. They must be small or you must be lucky PS: I don't know enough about Hunter to really argue the point, but the documentation seems to say that compiler flags and toolchains are forwarded: https://docs.hunter.sh/en/latest/overview/dry.html?highlight=forward%20compiler%20flags Could you say more? B/c I've been looking at using it in my next project
Yes, though even a simpler `for(auto &amp;i : qAsConst(vector) { ... }` would do the same, you don't also need to add `const` to the variable decl.
OK, now I need to figure out where I got that idea from.
If I want to use other boost libraries with that what do I do?
When i see the setting item ‘iso c++ 17 standard’i know finally, Microsoft realized programmers need a normal useable SDK instead of a SPECIFIC sdk, And programmers has the ability of following the STANDARD without a sweet-MS-Wrapper. And, what does STANDARDS really means. 
Absolutely, yes 🙂
Fully agreed; needing programmers to write the boilerplate is IMO not reasonable, and instead we should generate it automatically by using reflection to look at an interface definition provided in a simple manner. For example, you write: struct Vehicle { void accelerate(); }; And then a library generates the boilerplate under the hood by reflecting on that. Then, you only use something like dyno::poly&lt;Vehicle&gt; vehicle = Car{}; vehicle.accelerate(); and it just works, because `poly&lt;Vehicle&gt;` defines the right member functions based on the interface you provided. That kind of thing ought to be possible soon enough.
In all benchmarks I've done, `variant` is noticeably slower. It was a surprise to me too, as I expected it to be faster. You can check out the benchmarks [here](https://github.com/ldionne/dyno/tree/d386a9f711e8e6d9239654af2df81fd0902e53de/benchmark/any_iterator).
The overhead of the virtual call itself is probably not a big deal in almost all cases. However, the inability for the compiler to see what function is being called is much worse, as it may prevent inlining (after which many more optimizations become possible). Dyno does not really fix that problem, but it may make it easier for the compiler to know what function is being called in some cases.
I would definitely be interested as well, I've used `async` and `future` before but never really took the plunge and learned parallel programming for real 
I might be wrong, but the point of continuations from futures means that you wont block/wait because the completion of a task starts the next one. 
It depends on what you're looking for and if you're willing to pay. If you want a nuts-and-bolts Computer Science approach, some Googling led me to [this site](http://www.bogotobogo.com/cplusplus/multithreaded.php) which has a ton of good info in it but is pretty dense. If you want something less in-depth but still a good intro (and don't mind it focusing on pthreads), [this](https://randu.org/tutorials/threads/) is a good read. If you want a "just get me going on Windows" approach, it's hard to beat [MSDN's PPL page](https://msdn.microsoft.com/en-us/library/dd492418.aspx) (and the associated concurrency runtime pages). If you're willing to pay, there are a slew of books and courses available. Whichever way you go, don't forget that C++ [continues to evolve](http://www.bfilipek.com/2017/08/cpp17-details-parallel.html) and that most examples you'll see, while perfectly serviceable, won't be using the latest-and-shiniest features.
I'd use neither of those for parallel programming. There are a lot of libraries out there that do a better job. Keep in mind, asynchronous programming is not necessarily the same as parallel programming (although they are closely related)
While I understand and agree this is probably for the better, I have a sneaking suspicion that there will be more bugs. Qt's foreach quietly protected you against a few beginner mistakes. I'm definitely expecting to see issues from iterating over a container member variable and accidentally invalidating its iterators through some complex chain of events.
Yes. Qt Creator is also great for non-Qt CMake projects.
C++ concurrency in action by Anthony Williams is a good book. You can find the first edition online as pdf
Basically yes, or something very similar that. The essential part is to provide an interface to this hypothetical libclang from the program being compiled, at compile-time.
&gt; are very few requirements placed on a constexpr function Dynamic memory allocation/deallocation, placement `new`, and the lack of things like `reinterpret_cast` are severe limitations. There are proposals working on expanding what `constexpr` functions can do, thankfully. --- While I agree that this should be the way moving forward, there currently are subtle differences between `constexpr` and non-`constexpr` functions that should be resolved. As an example, [`std::invoke` is **not** `constexpr`](https://stackoverflow.com/questions/40222989/why-is-stdinvoke-not-constexpr). There is an open related CWG issue, [**#1581**](http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html#1581). I think that all of these problems and limitations need to be properly fixed before we can start thinking about an "implicit" `constexpr`. 
I've been watching every [video](https://www.youtube.com/watch?v=JpVZww1hL4c) I can find by [James Reinders](https://books.google.fr/books/about/High_Performance_Parallelism_Pearls_Volu.html?id=MUZ0CAAAQBAJ&amp;source=kp_cover&amp;redir_esc=y)
[High-Performance Computing in C++](https://www.pluralsight.com/courses/cpp-high-performance-computing) [Pluralsight]
You can use `new` and reinterpret_cast in a constexpr function. They just must not be evaluated when you try to evaluate that function during compile time. As I said, the keyword constexpr itself doesn't mean much on functions. And why do we have to make more expressions usable in core constant expressions before we allow functions to be called in compile time expressions that already satisfy the existing requirements?
CWG 1581 is a great example. CWG 1581 is also why implementations are forbidden from strengthening constexpr at present.
I do :) you could start here: https://steveire.wordpress.com/2017/11/05/embracing-modern-cmake/
FWIW, here are the results I get with Clang 6 trunk on top of VS2017 on Win10 (Ivybridge): string (10K elements, 100 runs, 10M iterations) swap: Median performance: 32.62106 runs/s (1st quartile: 32.67350 | 3rd quartile: 32.00370) exchange: Median performance: 37.36606 runs/s (1st quartile: 37.42389 | 3rd quartile: 36.90361) vector&lt;unsigned char&gt; (10K elements, 100 runs, 100M iterations) swap: Median performance: 12.90294 runs/s (1st quartile: 13.06542 | 3rd quartile: 12.46244) exchange: Median performance: 11.40442 runs/s (1st quartile: 11.52892 | 3rd quartile: 10.98653) The exact reverse: `exchange` is faster for _`string`_. :-]
I don't disagree with what you are saying. The problem is Microsoft doesn't provide a simple raw c++ API and then provide the COM abstraction on top of it. The reason? vendor lock in. I am sure you don't understand what I am saying, so let me give you an example. In Qt, if you want to create a window, you do the following: QWindow window; And you have created a window. In WinRT, you do the following: 1. initialize COM. 2. create the appropriate factory. 3. create the appropriate view. 4. call the view to create an ICoreWindow instance. I was going to write the full WinRT code in the above, but I couldn't find the documentation. Microsoft documentation is horrible. The point I am trying to make is that Microsoft doesn't provide a simple, easy to use, API that uses only the basic C++ elements. It has to provide very complex stuff, and then any C++ API that simplifies the complexity should be a wrapper on top of it. And that's really a big problem since writing wrappers for the very complex stuff microsoft has takes a lot of effort. So much effort, in fact, that it is tempting to ditch cross-platform code and go straight for Microsoft code. And that is what Microsoft hopes people do, in order to lock them in. 
Sure, but other platforms make it easy to write cross platform code and native APIs wrappers. 
If you want to learn about difficulties in parallel programming, go to https://deadlockempire.github.io Note that these exercises are not C++ specific.
Interestingly, I was thinking about an idea for an 'is_constexpr' after this thread popped up, and came up with something: https://godbolt.org/g/YMASq4 It uses a macro, doesn't work on GCC, and Clang isn't a huge fan of string_views for some reason... other than that, it seems to work? I need to do more extensive testing of course, and try to figure out why GCC isn't happy with it.
Some notes: * Your code only looks acceptable if the text-view displaying it uses 4 spaces / tab; **Consider using only spaces instead**. This will make the code look/be independent on how the view defines tabs. * You define lots of variables that should be local to member functions, in the class; You should not do this. * Constructor leaks the value allocated in `New`. * You use `counter` as a boolean flag, to check if you are adding to an empty list; You can use your pointer to the head instead (`Current` I believe). * Your `del` function is way too convoluted.
D calls constexpr-ness purity, and has weak purity, which is what you propose. A lot of what C++ was doing seems to head in that direction too. But AFAIK constexpr is not lax enough yet.
&gt; In Qt, if you want to create a window, you do the following: &gt; &gt; QWindow window; &gt; &gt; And you have created a window. &gt; In WinRT, you do the following: &gt; &gt; 1. initialize COM. &gt; &gt; 2. create the appropriate factory. &gt; &gt; 3. create the appropriate view. &gt; &gt; 4. call the view to create an ICoreWindow instance. Have you looked for examples of C++/WinRT usage? Because that's one of the things that this new language projection is fixing. Just watch some of the talks and see how they are trying to hide all these steps inside the library. That being said, they are still providing access to this low-level stuff if you really want it but it is not required to use.
Or just use a proper dependency manager like Nix. I know it doesn't work on Windows, but I'll let Windows developers figure that out.
Just make sure that all your targets in all projects are properly named. No `base` target, but `foobar_base` instead, and you won't run into conflicts. It's just the same as writing a C library, you don't create random symbols with a common name in the global scope. Do C developers constantly complain they shouldn't use 3rd party libraries too? Well, there's what Hunter says and what Hunter does. It will try somewhat to pass things to the bottom layer but it doesn't work. Tried again yesterday building GoogleTest with it and it didn't use the same standard as my top level project or the sanitizer flags. Same for Boost, it was built with the default compiler flags. This is ABI breaking level incompatibility. Feel free to rely on a 3rd party complex library if you want, but `add_subdirectory()` propagates flags properly already. You just need to get good libraries that won't add unprefixed target names to the workspace and patch the rest (then submit patches upstream).
Hmm, I think one possible issue is that it puts the additional strain on the compiler to check if every function invocation can be done constexpr. Probably not a problem, but for huge projects, it might be significant. Also, since solving compile time is the exception rather than the rule, I think it's better to make it explicit. There may be some operations which you want to do at runtime, and to change the default to constexpr would require a lot of code being revised. In theory, a system clock operation could be done at compile time, but it's very unlikely that is the intention.
How do you use address sanitizer on your project to find bugs if you don't have an easy way to properly rebuild everything with it? How do you deal with cross-platform development too?
Many people know how to do things properly and there have been numerous talks recently about it. Then, there are experts promoting their own CMake library and patterns who disagree on some details.
If it misses one huge population of users and developers, it's not even worth mentioning.
I realise this is OT for this particular thread, but do you have any resources on the "right" way to handle install commands and third party dependencies, and on writing custom Find modules? It's an area we dont really have any good solutions for at the moment, so we're just totally winging it.
How do you handle incompatible flags between your third party dependencies and your project? The canonical example is conflicting CRT versions on windows (/MD vs /MDd vs /MT vs /MTd), but there are plenty of others (-Zp for example)
c++ constexpr functions are not pure for any definition I'm familiar with. they can depend on global state, they can modify global state, they can perform dynamic memory allocation, I/Of and they can mutate their arguments. I'm not proposing to change that (too late for that) I'm proposing to no longer require a keyword that only enforces a very small set of restrictions which are satisfied by most day to day functions anyway. If constexpr meant "any path thought this function can be executed at compile" time things would be very different.
I don't think (but might be wrong) this would force the compiler to perform any checks it doesn't already have to perform now. Can you give an example?
The conflicts are ofcourse between dependencies, not with my root project. That would be trivial to solve. Sounds like you know it's a problem and your solution is patching and maintain other people's CMake files... I guess if your flair is "I like build tools" ... to each his own :P
Custom Find modules are easy. Have a read of some of the simpler ones provided by cmake, and copy them. Example: `FindZLIB.cmake`.
Well, mutable state wasn't possible in `constexpr` until C++14, so it's easy to see how this has lead to confusion.
Build the complete collection with the same options, but do this at a higher level outside this individual project. Don't embed or download and build anything within the individual projects other than their own code. All you then need inside the project then are the needed `find_package` calls to build and link. It keeps things simple, and it's conceptually no different than building everything by hand in order. The top-level project can itself be written entirely with cmake using `ExternalProject` to pull in the needed dependencies with the appropriate ordering (i.e. a "super-build").
I'm not sure what you mean. As a Qt user and contributor i'd be very, **very** happy to see the moc go and be replaced with something in core C++, and i'm sure most if not all of Qt guys agree. If i had to guess i suppose the defensiveness is more directed to the committee, which does not seem to like big changes or additions.
Cool, thanks :)
Shouldn't be too hard to do as most of the implementation will be the same, just the "compile-time string" capturing part will change. Note that the current implementation compiles with MSVC, it just doesn't provide compile-time checks.
&gt; And I'll say it: C++ has member functions, not "methods". Do you want everyone to say "free store" instead of "heap"? Standardese can be a bit awkward.
The way I'd imagine the compiler deals with a function call, and I may be wrong, is something like this: * Is this function constexpr? * If so, can I resolve it at compile time? If things are constexpr by default, then question 1 is yes by default, so then it needs to try to resolve every expression at compile time. This might be trivial, or it may require a pretty deep recursive analysis. You can probably get around significant recursion if you keep tabs on all the variables I suppose.
Hey you can learn parallel computing by learn and there are many open source projects available. One mention is hpx library. It is a c++ parallel computing platform for high performance computing. 
&gt;Just watch some of the talks and see how they are trying to hide all these steps inside the library. He also needs to check Sutter's talk about metaclasses. There is a reason why C++/CX came to be and it still has clear advantages over C++/WinRT (that he is trying to eliminate with that proposal).
You can add to your list generating string from enum. To sum up, anything close to the word communication with anything but C++.
Well of course I patch problems when I encounter them. I don't just give up on an otherwise interesting library solving my problems. If the changes are small enough, they're easy to submit upstream or just continuously rebase.
And a new edition is due in December 
Removing constexpr from a function is a backwards-incompatible change to an API -- it limits where that function may be used. What happens if developer A writes a function that is marked constexpr, developer B depends on it being constexpr, then developer A wants to change its implementation such that it is no longer constexpr? Making constexpr implicit would make this scenario much more common. In practice, I think programmers would either resort to commenting whether a function is meant to be constexpr or adding spurious code to prevent functions from being marked implicitly constexpr.
You can implement complete compile-time Turing Machine **only by templates **. [short example](https://blog.galowicz.de/2016/05/15/turing_tape_with_type_lists/). Go and experiment with it - but beware - because template language is turing complete, if you go into halting problem your program might take infinite time to compile.
Huh... how so?
constexpr is a very bad name, compileexpr would be better
&gt; `delete std::exchange(p, nullptr);` Now I'm going to confuse most low-level programmers in my team. 
[`std::tgamma()`](http://en.cppreference.com/w/cpp/numeric/math/tgamma). C++ does not have factorial - it has the Gamma function. For positive `n` it's equal to `(n - 1)!`
Isn't GMP++ lib enough? I don't know much about it.
This has nothing to do with distributed computing, right? I am quite confused on the first sight.
It's a wrapper around GMP which is LGPLv3 or GPLv2 = no-go.
* Mark all functions implicitly constexpr if the conditions are fulfilled Right * Just remove the requirement that a function must be constexpr to be usable in a compile time expression Hmmm - I'm not seeing how this would work. Certainly not every function is usable at compile time. * Repurpose the constexpr keyword to indicate that the function is required to be computable at compile time.
interestingly if you specify const std::vector&lt;int&gt; gcc complains correctly about assigning to a const ref.
Yes, and fixed in trunk.
&gt; but always using `virtual` functions and not customize storage / dispatch etc. `Poly` doesn't use virtual. Virtual requires 3 indirections: 1) Indirect through the pointer to the abstract base to the object on the heap. 2) Indirect through the vtable pointer in the object. 3) In the vtable, index to the right function pointer and call indirectly through it. With `Poly`, the vtable pointer is stored in the `Poly` object itself, so indirection (1) goes away. I don't have evidence yet that custom storage / dispatch is worth the added complexity. I do plan to extend `Poly` to make the size of the internal buffer customizable.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7bjhc0/could_anyone_suggest_a_read_online_course_etc_for/dpizqya/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7bm3m4/possible_gcc_720_bug/dpizru5/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yeah, seems like argument deduction removes the constness: https://godbolt.org/g/jo1QCP Adding &lt;int&gt; to v's type or adding const before the vector in the static assert fixes this.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7bdw15/why_is_it_legal_to_define_a_nonconst_constexpr/dpizto1/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Jesus christ, this looks like a "help post" to you? Is it because there is a question mark in the title? Are you unhinged or something? 
You can use the Boost 1.65.1 release with Beast version 124
So I can not use it in commercial closed-source project? Yeah, that's bad.
...by basically all being the same platform. That's great until you hit the downsides of posix.
Due to the severe issues with the tutorial that you and Sylph mentioned I have taken the video down and will re-upload a correct version of it, since it had many flaws in it. Will look at the things you pointed out and do a re-make of the video in the future, thanks a lot :)
This subreddit is about C++, not about compilers.
I'm not sure if this qualifies, but: https://github.com/GabrielDosReis/ipr Maybe Gabriel can elaborate on that. cc u/GabrielDosReis
Please see our paper http://open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0676r0.pdf
The problem is that even today, `constexpr` doesn't guarantee you that you can use a function in a constant expression for a particular input. That aside: No one is proposing the removal of constexpr I just don't want to make it mandatory.
Not every function is usable at compile - time. That is correct. There is a long list of requirements on that and those requirements should stay in place. I'm just saying that attaching the keyword constexpr to a function should not be a requirement on its own.
There should be "meet-up" somewhere in the title :-) The idea was something like use telepresence to connect two smaller meetups in London and Stockholm into a larger one. No idea how it went, wasn't there and haven't watched the videos yet.
I agree, it is misleading! I cannot edit the title, but maybe a mod can.
It went great :)
I feel lots of his writings are over-engineered.
The discussion is more about the two different workflows for managing dependencies: prebuilt binaries vs integrated builds. This ultimately applies to any build system, and some build systems support one workflow better than the other. Of course, there are strong opinions on both sides.
You could use a portable one like conda or cget.
&gt; auto in function / lambdas parameters is required to flag the function as a function template Why not `template Iterator find(Collection collection)` then instead of `Iterator find(Collection auto collection)`? I think it's more obvious and clear, but maybe this is just some bikeshedding.
&gt; Well, there's what Hunter says and what Hunter does. It will try somewhat to pass things to the bottom layer but it doesn't work. Yea, I don't think Hunter setups the boost toolchain properly. I know the [boost.cmake](https://github.com/pfultz2/cget/blob/master/cget/cmake/boost.cmake) file in cget does try to pass the compiler and flags to the boost toolchain. Of course, it sounds like you've already written cmake for boost, so it should be easy to plug that into a package manager as well. And the cmake-based ones are nice like hunter or cget as you don't have to translate your cmake toolchain to another format.
&gt; How do you use address sanitizer on your project to find bugs if you don't have an easy way to properly rebuild everything with it? Why wouldn't you have a easy way to rebuild everything? You can use a dependency management tool or you can just put it all in a script that builds and installs the dependencies. You ideally only build the dependencies once per toolchain. &gt; How do you deal with cross-platform development too? You just put your settings in a cmake toolchain file, and use that to build all your dependencies. 
I didn't expect it to succeed with Boost actually, but it should have with GoogleTest, and it didn't get built with the proper flags at all either. And yes, I have a project on Github to build (almost) all of Boost with CMake natively on most platforms already.
I use a CMake toolchain file when building all the libraries, and the same toolchain file to build my projects with those libraries. Any compiler flags I want to configure are put there. I don't know whether this is good practice, but it seems to work quite well, and it's what vcpkg does fwiw. If I wanted the same set of libraries but with different compiler settings, I'd setup a new install prefix with a modified toolchain file and rebuild. For cross-platform development which in my case is just CentOS 7 and Windows, the workflow is the same on both platforms since fortunately all libraries I want to use build with CMake. Normalising the workflow on both platforms was one of the motivations for doing things this way. CMake+Ninja gets me most of what I need, the rest is just convention. I realise this doesn't deal with OS-specific packaging and is probably horrible practice in that regard, but I don't see how this would prevent me from creating proper packages when needed. 
See this other [reply](https://www.reddit.com/r/cpp/comments/7b7oe7/4_tips_for_better_cmake/dpj7u5y/).
Of course, it's easy with a proper setup, which isn't what the user above suggested from his workflow at all. You can't build a library once and expect it to work for all usage of the library in various projects, compilers and compiler flags. And relying on some intermediate sysroot is most of the time pure madness, you can't rebuild things from there on demand when you need a different version. And if you forget to rebuild anything, good luck dealing with the incompatible ABI or flags! It's just an error prone process. I want it always correct all the time. Even if that means more upfront work, at least I don't have to deal with the debugging when it fails on a random coworker's machine who forgot to run some manual step. &gt; You just put your settings in a cmake toolchain file, and use that to build all your dependencies. You are assuming that the toolchain file is passed correctly everywhere and there are no global flags in the project or that they are passed properly to dependencies. This is error prone as well and most people swear by tools that I've never seen doing it properly and automatically.
Yes this pretty much exactly what I do, all scripted in CMake. Once I've figured out how to build a particular library, I end up with a script for building it with the options I want in CMake. Then at the top level I call the scripts in the right order - not quite as advanced as your example! This works equally well on Windows and Linux, although I realise it's not the "right way" to do it on Linux. 
Provided the compiler still generates runtime code for any function with external linkage, can it not do this today, under the “as-if” rule?
The simple ones are easy. It’s the more complex ones that we struggle with. Target a depends on b (Which is third party). B has multiple libs, and each lib is 32 bit and 64 bit, and comes in multiple “configurations” (debug and release and development, say). It’s also got runtime dependencies on dlls, which either need platform specific workarounds (rpath) or need to be in specific locations. 
This proposal is a bikeshedding minefield, ( like all proposals I guess ) To answer your questions, `auto` is already valid in lambdas and there are no valid for functions and lambdas to have different signature grammar. Also, `auto` for each template parameter let you know what set of parameters will create a new instantiation of the function 
When DAG is not known ahead of time -- I couldn't figure out how to use continuations. The idea was that running a task may create subtasks (think of depth first directory traversal). I.e. instead of working from bottom up -- you work from up to bottom (DAG root is at the top). So, parent task couldn't wait (in future::wait() sense) for subtasks to complete: because tree can be of any depth -- you will quickly run out of threads in your pool. You need to "relinquish" control of current thread and come back to parent task later (after all subtasks have completed) -- turned out to be quite a challenge in MT environment to do right.
I'm not sure what you're asking. Does https://www.reddit.com/r/cpp/comments/65iyxv/embracing_modern_cmake/dgjamhk/ help? 
Because you have to build the libraries independently with the same toolchain file manually beforehand. Should you update the toolchain file, you'll need to rebuild those again manually. With a large workspace, you only have one toolchain file, no need to specify a "prefix", it's all handled automatically by CMake + Ninja. 
And for those wanting to come to those in Stockholm, just join the Meetup group, next meeting is next week!
Funnily enough, I was the person who requested it in that thread. Unfortunately not. No. My specific issue is writing a modern find module for PhysX. Usually it’s handling shared libraries and making sure they end up in the right place that ends up being the messiest part for us. 
If I understand you correctly, them no. The compiler is required by the standard to emit an error if you tell it to evaluate an Expression during compile time and that evaluation involves calling a function that is not marked constexpr. 
Don't compilers already do this for non-constexpr code? Even if you write `int a = 10; int b = a + 2;`, isn't the compiler allowed to collapse the whole thing to just `int a = 10; int b = 12;`? It can even reorder the statements if it thinks the order doesn't matter.
With the superbuild mentioned in my other post, we build this for various combinations of 32/64-bit Debug/Release and different Visual Studio versions ([example job matrix](https://ci.openmicroscopy.org/view/Files/job/OME-FILES-CPP-DEV-merge-win-superbuild/)). In this example, it's 64-bit only to half the number of builds, but tests Debug and Release builds with VS2013 and VS2015; hopefully will add 2017 and maybe remove 2013 sometime soon. I keep the selection of these variants completely outside the scope of CMake and just pass them in as configuration options when running cmake, and let the CI system handle this part.
Really? Simple desktop apps are pretty straightforward in QtWidgets and don't need much code. Why do you recommend QtQuick for these tasks? I've never used it myself so I'm curious.
&gt; But what does the reality says? sumXY is much faster that sumYX. That is in reverse. The data (and what a C++ programmer on an x86 machine would *expect*) shows `sumYX` being faster than `sumXY`. Since the author's reasoning for *why* the speed was different was correct, I'm assuming this was just a typo (among a number of typos in this article).
When optimizations are enabled, sure. The compiler _can_ do that, but it's not _required_ to do that, and there's no standard guarantee that it will or won't do that. `constexpr` is a semantic that does not in any way rely on optimizations. `constexpr` functions are usable in `constexpr` contexts* as a semantic guarantee, though there is zero requirement for * all inputs are `constexpr` and the result is required to be `constexpr`
It depends if you want to grow your app over time. With QtWidgets restructuring the interface is a chore. With QtQuick it's a fast feedback process, just like in web dev. Generally even a simple app is less QML code than in an .ui file and it's very readable. 
Yes, but if a function is constexpr there's an additional check to see if it's possible to resolve it at compile time. Imagine something like: Foo(bar(a,b)) If Foo is constexpr, then it needs to check if bar is constexpr, then how a and b were defined to see if they're resolved at compile time. If they're literals, that's not too bad, but maybe they're assigned by constexpr functions. In that case, the compiler needs to check if they're resolvable at compile time. If they're objects with a constexpr constructor, for example, you need to check if they can be resolved. Ad nauseum
I assume the author like most people probably glazed over the typo since its honestly difficult to read much of a difference between them. aka do something like sum_row_col and sum_col_row since at least there there's enough of a visual difference for our eyes to go 'what'. As for on topic towards the article: I'm not sure what they point of it is? Of course every abstraction has contracts you are given to use it.. and it could be argued they are 'leaky' since by some arbitrary definition of purity it's impossible to not; but that's not very helpful in the first place. Typically the idea in making an abstraction is to make at least some base assumptions (make those known to the user) and allow less chance of screw ups since something could be easy to screw up. e.g. how often people like to write... for(int x = 0; x &lt; 10; ++x) for(int y = 0; y &lt; 10; ++y) arr[x + y*10] = ...; and you could instead wrap that functionality in some other manner so people do cache efficient traversals with little/no thought.
You must have missed all the discussions and controversy moc has caused over the *years*, with Qt people defending to the virtual death, opposing to change to get rid of it or adapt to loosen the dependencies on moc. Telling everybody they are wrong to even think about doing it without moc. Laughing at Barbara and Ansel (the people behind copperspice) and ridiculing others like wxWidgets for being "behind the times", all while catering to a child of the 90s themselves. As a Qt user, I appreciate it strengths while not blindly ignoring its weaknesses (90s OOP, horrible APIs: QList). I just wish, the contributers/developers of Qt could keep a more open mind as well. 
It's not a problem, since it guarantees that it will either be evaluated at compile time or fail to compile.
Are there even a guarantee that the constexpr will *really* be computed are compile time in constexpr contexts? I mean, under the equivalence rule, the compiler could choose to emit code to do that dynamically, as long as the initialization rules are respected. Maybe the current static and dynamic linker stack lack some stuff to do that, but I doubt that the standard itself prevent it in theory (what wording could be used to achieve that effect?) 
So what? if you can put what you want in constexpr marked function, and just need to avoid forbidden stuff at "compile-runtime" in constexpr contexts, that will continue to be the case under the as-if rule, because the proposition is not to create more constexpr contexts, only mark all functions constexpr by default.
&gt; But what does the reality says? sumXY is much faster that sumYX. Maybe because array don't abstract locality of data and really primitive? Maybe because a 2D array is *not* an abstraction over a matrix and you should expect that way to iterate it to be slower? If you have a matrix class, a resonable abstraction of a matrix, you should be able to iterate it only one way: the way specified by that class. That way, the matrix class is responsible either you traverse the matrix by column or rows, and is responsible to have the fastest memory layout for that way of iterating it.
I had some code that had a leaky abstract. I made a long ago my `AnyType` class, that was constructible from any movable type. However, I had a constructor that took a `void*`. The `AnyType` would take up that pointer as it's internal pointer. That lead to a lot of problem, because we were leaking the fact that we held the object as a `void*`.
&gt; Of course, it's easy with a proper setup, which isn't what the user above suggested from his workflow at all. You can't build a library once and expect it to work for all usage of the library in various projects, compilers and compiler flags. I dont think that was what he was implying that. Of course, there are compilers and flags that are compatible as well. Gcc and clang can be interchanged. Adding `-g` or most sanitizers wont cause ABI problems. &gt; And relying on some intermediate sysroot is most of the time pure madness, you can't rebuild things from there on demand when you need a different version. You can put the build scripts for dependencies into make files, similar to what [MXE](https://github.com/mxe/mxe) does. So when you change a version it will rebuild any downstream dependencies. Or if the scripts for the dependencies are in dockerfiles, it will cache the upstream libraries, but downstream will be rebuilt when you update the version. Of course, I only mention these when you decide to not use a package manager which can automate this for you. &gt; It's just an error prone process. Rewriting build scripts can be an error prone process as well. &gt; at least I don't have to deal with the debugging when it fails on a random coworker's machine who forgot to run some manual step. You can just have a machine build the dependencies automatically, and put it on a shared drive. This way the developers don't need to build the dependencies locally. Ideally, you would include the toolchain file to use those set of dependencies, so they all build with the same flags. &gt; You are assuming that the toolchain file is passed correctly everywhere I don't see why it wouldn't be. Especially if you are using a dependency tool that handles it for you. &gt; there are no global flags in the project I don't see how a integrated build would fix that. In fact, it seems more problematic with a integrated build. &gt; that they are passed properly to dependencies You should be passing the same toolchain file to all dependencies. &gt; most people swear by tools that I've never seen doing it properly and automatically. What tools have you tried? Most package managers make sure the scripts are built in the correct build environment, if not there is a problem with the package script. Furthermore, cget should work as the package script and the build script are the same, and the description of the build environment is the cmake toolchain file. So there is less room for error, when everything is built with cmake by default. 
&gt; but it should have with GoogleTest, and it didn't get built with the proper flags at all either. Sounds like a problem with hunter.
C++ TMP and LISP MP have quite different goals. C++, the goal is performance, and rigorous static type checking. In Lisp, the goal is expressiveness, and a way to get very complex features while keeping the core language extremely simple, and make the language fit "the domain of the problem". I would go so far to say as there is little overlap in their uses for MP. That said, I do wish that C++ had better code generation abilities, at runtime. In the rush to move everything to compile time for more type safety, I feel like it's been forgotten that there are many things that happen at runtime, that could be exploited to generate code then and be more efficient. This is noticeably true in any domain with cheap "startup" costs: HPC, HFT, for examples. C++ is great at zero cost abstractions but if you want to generate efficient code based on something you read in out of a config file, have fun. You can use clang/llvm or libjit but it's very hard code to write and maintain and barely anyone is doing it (in relative terms). I'd love for C++ to support runtime code generation first class.
Sure there has been opposition to it being removed, since there is no other better alternative, as of now. The only other alternative currently available is to litter the code with macros, and that is arguably worse than having moc. I'm not sure what you refer to with 90s OOP and QList, those have nothing to do with moc, and anyway have been improving. But you cannot ignore that Qt has a long history and cannot just break compatibility just for being modern sake.
It is pronounced cute! [1] [1] https://www.youtube.com/watch?v=NbTEVbQLC8s
TMP has no goal. It wasn't designed with goals in mind, it was discovered. I am not talking about the existing functionality that TMP allows, but the bigger potential that a future C++ standard could have in terms of meta programming. I don't understand what you mean by code generation at runtime. Wouldn't you have to interpret or compile code at runtime then, effectively making the compiler part of the program? Using string manipulation to create or modify code and a compiler at runtime indeed feels clunky, it is the worst of scenarios. That is not what I would consider meta programming.
The distinction is pretty fuzzy and I might be wrong, but my understanding is that, parallel programming refers to techniques that allow you to complete a specific task faster, by efficiently distributing your work across multiple cores/execution units. Asynchronous programming is mainly about being able to respond to events coming from multiple sources outside of your program (hence asynchronously) instead of waiting for a specific event - E.g. you don't want to block your UI, while your program is loading a file from the internet. instead you start a download on a background thread and get notified when the download is completed, while at the same time being able to do something differently. Sometimes, asynchronous programming doesn't even require multiple threads - you just use a event loop and callbacks or state machines - whereas parallel programming without threads is pretty meaningless (unless you count vector instructions). 
thanks, I didn't know about potential issues with symlinks... makes sense
&gt; Are there even a guarantee that the constexpr will really be computed are compile time in constexpr contexts? Where it semantically matters, sure. For example, `static_assert` places a pretty hard requirement on `constexpr` evaluation that would be hard to delay to runtime. Though if you're considering cases of linker magic and OS dynamic code, we're really blurring the lines of what "compile time" even means. :p
If it makes you feel better, you can replace the phrase "the goal of C++ TMP" with "the goal of people who are doing TMP in C++". It doesn't really matter. The problems that we solve now with TMP, and the problems we want to solve better in the future, are better performance and type safety. Obviously we also want to do these things in a way that minimizes boilerplate, but I would guess that's just a given. In many cases in C++, if I didn't care about static type safety or performance, I would just do something differently. Lisp is neither statically type safe, nor highly performant, so its reasons for doing MP are quite different. I never said anything about string manipulation. And yes, the compiler would be part of the program. If you program in lisp, you should be used to that. eval is nothing but calling the lisp compiler (details depend on which lisp of course), and it's perfectly safe because of how lisp is structured. This is nothing but meta programming in it's purest form; why should programs that operate on programs be restricted to run, purely before the rest of the program? Imagine you have a json file that describes the configuration of your program. From a performance point of view, it would be amazing to read in that json file, parse it, build up some structure representing what you want to run, and *then* compile it; with all of the things read in from the json as hardcoded constants. In lisp, you can do this quite easily, but lisp isn't that fast to start with. In C++ you can do this but it's a huge pain. If C++ could do this anywhere near as easily as lisp, it would be quite amazing.
Hm obviously my brain skipped small details like static_assert and template params. Embarrassing :p I was only thinking about some global variable init using constexpr. However the lines already have started to be blurred from what they used to be with traditional compilers, e.g. with LTO, one could maybe consider it reasonable to defer static_assert and template params to static "link" time (where "link" in that case would mean pretty much everything except some first parsing phases)
I was just discussing today how you can't write a single line of modern C++ code without pissing somebody off, and use of auto was one of the key triggers.
&gt; Adding -g or most sanitizers wont cause ABI problems. Well, only ODR violation issues. Also, you may be mixing parts of libraries that are header only with some that are compiled without the flags, you can't do that. Some sanitizers will require you to rebuild *everything* too. &gt; You can put the build scripts for dependencies into... Yes, you can do it right. You can also mess up and do a lot of manual steps and forget about one. It's error prone and shouldn't have to be done. CMake should be handling the rebuilding automatically, not you. And most package managers, won't do it right. &gt; Rewriting build scripts can be an error prone process as well. It's easier to detect when it doesn't build as compared to the alternative where it doesn't use the right flags because of some hermetic boundary. &gt; You can just have a machine build the dependencies automatically, and put it on a shared drive. This removes the developer the freedom from rebuilding everything with a different ABI flag that's not supported by the scripts on the machine. It requires a lot of preparation. The better way is to have some networked cache (lookup sccache) to accelerate the build. That way, you don't depend on a single piece of infrastructure and can just build locally too. There are no problems with using global flags in the top level project, but they need to be propagated. Not everything can be a plain toolchain and you can't just expect all the tools to pass all the required options to the sub-builds. They just don't do that all properly and will miss something. And when CMake changes and introduces something new, they will break again! Really, if build systems can handle building something like chrome nowadays, they can handle your project. It's possible to have everything in one big workspace and get it to build in a reasonable amount of time.
As long as its damn obvious what the type is. Auto certainly can make code harder to read.
The point is that making all functions constexpr by default introduces implicit API contracts, which a library developer might not even realize they are doing. If some header-only library contains a function, which happens to be possible to evaluate at compile time given constant inputs, it can be used as a template parameter in clients' code. If the library developer changes the function in their next version, such that this property no longer holds, it can no longer be used this way, and thus it's an implicit breaking change. Requiring constexpr solves this problem, because removing constexpr is an explicit, deliberate breaking change.
I use auto when: &amp;nbsp; 1) it is perfectly obvious what the type is. &amp;nbsp; 2) the type could be one of many, but they all behave the same, so it isn't very important &amp;nbsp; 3) the type declaration is huge and it is impractical to alias it &amp;nbsp; 4) whenever I feel like it
lol. It sure is...
In theory, the standard does not prevent an implementation to use interpretation (as contrast to ahead-of-time compilation).
Basically my rules as well. I don't use it when I want to highlight the type and make sure the user knows what the type is going to be. Also, a lot of new programmers think "Hi" has a type of string, and get unpleasantly surprised when it's a const charstar. 
Just the opposite, IMO. Auto is best when the type is completely unknowable.
5) When I don't care what the type is. This is a variation on your second rule.
For case 2) you want to replace 'auto' with a Concept. Hopefully in C++20. Not as clear whether you can do that with your rule 5).
It's not even const char star. It's const char array of length strlen("Hi").
Or completely irrelevant. More often than not, knowledge of the type does nothing to help you understand the algorithm. It's not helping by being there, so why have it?
This is a breaking change. int f(int) { /* ... */ } template&lt;auto&gt; struct constant; template&lt;auto x&gt; constant&lt;f(x)&gt; g(int); // #1 template&lt;int&gt; int g(long); // #2 g&lt;1&gt;(0); Currently `g&lt;1&gt;(0)` calls #2, but it might calls #1 if `f(1)` can be evaluated in a constant expression. If the body of `f` is complicated (e.g. if it calls 10 other functions, each of which in turn calls 10 more functions), the compiler might have to spend a lot of time before it determines whether `f(1)` can be used here. Though this is already the case if `f` and all functions it directly or indirectly calls were `constexpr`, it's unclear whether relaxing the rule will imply significant added compile-time costs, i.e. violate "compiler performance stability" in [“The C++ Programmers’ Bill of Rights.”](https://isocpp.org/blog/2017/07/what-should-the-iso-cpp-standards-committee-be-doing).
In a way, `auto` is just the most generic of all Concepts.
I like and use auto but disagree that knowledge of types is irrelevant. 
Excellent that worked. I had tried using Beaster latest commit with Boost 1.54.1 but it didn't work.
&gt; Well, only ODR violation issues. There is no ODR violations with flags like `-g`. &gt; Also, you may be mixing parts of libraries that are header only with some that are compiled without the flags, you can't do that. With flags like `-g`, yes you can. &gt; Some sanitizers will require you to rebuild everything too. Like memory sanitizer, yes it does, but it is not required to rebuild everything for address sanitizer or undefined sanitizer. &gt; Yes, you can do it right. Yes and it seems easier to do than trying rewrite projects build scripts. &gt; You can also mess up and do a lot of manual steps and forget about one. Add this alias: alias cmake='cmake -DCMAKE_TOOLCHAIN_FILE=toolchain.cmake' Then you won't forget adding the toolchain file when installing dependencies manually. Of course, usually, you have script so its reproducible. &gt; It's error prone and shouldn't have to be done. I dont have any problems with it. And it works better than rewriting build scripts, where I have gotten wrong. &gt; CMake should be handling the rebuilding automatically, not you. No, I dont want to rebuild all the dependencies just to install your library/application. Especially since it can be combined with collection of other libraries/applications that are using the similar set of dependencies. &gt; And most package managers, won't do it right. Like which ones? How does cget not do it right? &gt; This removes the developer the freedom from rebuilding everything with a different ABI flag that's not supported by the scripts on the machine. The developer can just re-run the scripts with a new toolchain. &gt; It requires a lot of preparation. cmake -P install_deps.cmake --prefix ~/my_deps -DCMAKE_TOOLCHAIN_FILE=my_toolchain.cmake I dont see how that is a lot of preparation. &gt; There are no problems with using global flags in the top level project, but they need to be propagated. Global flags are always propagated. The same for global flags set in the toolchain file. &gt; Not everything can be a plain toolchain and you can't just expect all the tools to pass all the required options to the sub-builds. What are talking about sub-builds? You mean passing toolchain settings to non-cmake builds? 
It’s like with every feature in the language: it has to be used with care by people that know what they’re doing. Sensitive use of auto will make your code better. 
Auto is great when you're writing code, but it sucks when you're reading and modifying somebody else's. I'm sure I'll get used to it, but when you see a whole block of code where each line returns an auto, it's really hard to tell what the F is going on.
Well, I made my own benchmarks about this. To make conceptual things clearer. At the heart of dyno lies using c-like functions. So I compared function pointers vs variants. function pointers faster indeed! Not that noticeably, 2 times at max, but observable. I must admit - there is no performance gain in fiddling with variants... All theoretical performance gains will be eating with branch mispredictions. Variants become 1.5x faster then functions if you always call the same type:) Then I decided to check how slow using vtables really are. I compared virtual classes placed in linear space (equivalent of dyno storage local) with function pointers. +-10% The same!!! Obviuosly we DO NOT "spend 95% of time acessing vtables". [http://coliru.stacked-crooked.com/a/38fcf354a89c87ab](http://coliru.stacked-crooked.com/a/38fcf354a89c87ab) And to compare usual classes in heap. On my machine approx. 4 times difference with c-like functions. Observable gain. [http://coliru.stacked-crooked.com/a/ff5ea9ab8ecf2905](http://coliru.stacked-crooked.com/a/ff5ea9ab8ecf2905) Difference to direct call is astronomical, approx. 100 times on my machine. I think CPU detect tight loop, and enable loop-aware mode:)) Well, I do understand we will not get this speed with any kind of run-time polymorphism... So ... All this fiddling with vtables... I would like to see clear cases, where difference is observable, otherwise its all just wild guesses. vtable for class placed in static storage, and it will be in L1 code cache for the second function call... There is even no need in prefetch, its just plain old LRU. About compiler optimisations - well, again, I would like to see this in clear cases. P.S. Don't get me wrong - I think we need dyno's value semantics in standard and Sean Parent's non-intrusivity looks nice too, but I'm not buying on "vtables is slow" per se.
I use auto for heavily templated iterators only. Writing the types out is a pain. Could imagine to use it for similar cases to hide templates where the behavior is clear though.
I understand that you're trying to submit useful stuff, but this video contains information that is already available in numerous books, videos, and online courses. The video also doesn't really cover the full complement of operators, and it doesn't even discuss operator precedence. I feel like you use some fairly non-standard language ( according to your video, &amp;&amp; is the "and" operator, but it's actually the *logical inclusive and* operator ). * You don't discuss the full complement of operators. * You don't use the correct names for the operators. * What little explanation you do include uses pretty non-standard terminology. * You don't discuss precedence. * You don't mention operator overloading. Overall, I think this is pretty light in terms of effort, and fairly low in terms of usefulness. You might try writing a script or storyboard in order to figure out a good way to get complete coverage of this subject.
My rule: use `auto` all the time, and if you want a specific type, just declare it like that: `auto foo=std::size_t{3}`
 auto lam = [](){}; Tell me how you're supposed to get a valid type from that for in scope usage. that's not std::function&lt;&gt; or some other meta hackery.
Why didn't you template the constructor? Something like this (without worrying about the moveonly thing) class Any { public: template&lt;class T&gt;Any(T* a) :m_ptr(a) {} template&lt;class T&gt;T* get() { return (T*)m_ptr; } private: void* m_ptr; };
Keep finger crossed this Friday :)
Is it really that much of a big deal? can't you just use an ide to tell you what type it is?
Great talk! The table on slide 61 showing how generator expressions expand made it click for me in a way that the CMake help pages could not. That should be in the docs site :) If you don't mind, I have some questions: What did you say [here](https://youtu.be/JsjI5xr1jxM?t=40m48s)? I can vaguely make out something about makefiles but the audio quality make it hard to pick out. Can you add `::` to a name with `add_library` from the get-go so you can avoid having to create an ALIAS target? How does that interact with the `NAMESPACE` directive in `install()`? In your example for creating packages, what exactly is happening here? Is mylib being built, and then you're telling it on which local path to put the build library binaries? (slide 90 in the video, slide 89 in the slides pdf from your site). It's not really clear to me how `install` is used for IDE projects. Makes sense to me that for the makefile generator, the `install` command would generate steps for `make install`, but if you're building a desktop app from Xcode or Visual Studio, what does `install` do in that context? From what I've read, CPack is what you use for making an app bundle or installer. Can you recommend any blog posts to read on creating import targets? Or maybe even just projects with cleanly written CMake files that incoporate prebuilt binaries into a build system? I can hack together shell scripts (or Lua functions if I'm using GENie or Premake) to do things like put prebuilt `*-d.dll` files in the debug config, but it seems like CMake has a better solution for it and I just don't understand what that solution is. --- Sorry for the massive question dump. It's just that every time I see something you or others link/write about CMake, I go back and try to learn how to do anything beyond basic compilation with it, and get stuck on something related to using external libraries or bundling apps, and then go back to GENie, Premake, or manually maintaining IDE projects. The CMake docs are a really great reference, but can be a little hard to decipher if you don't grok one of the underlying concepts or see where it fits into the different phases. The amount of outdated information on CMake in the world (good to know I should avoid the wiki!) makes it challenging to go beyond the basics, so thank you for giving this talk and posting it online, it makes a big difference. As I said above, this talk helped me understand generator expressions for the first time. 👍
Recently, I have been thinking about whether we could / should go further than that. My idea was to have compile timer containers ( including a string-like class ), that would be growable ² shrinkable at compile time. It would work by being a compile-time only object implemented via the use of a bunch of intrinsics to create and delete elements in your constexpr code. And then, either the object was used to compute a compile time value, so you don't need it and it's gone. Or you want to get it's content in your program, and you do that by the use of a method that would convert the compile-time structure to something usable such as an `initializer_list` or a `const char*`. What do you think ?
Exactly. If you're juggling ownership with naked poiners yourself you're doing something wrong.
The thing that bothers me about this right now is how difficult is to generate code based on strings. With constexpr you cannot create new types. For example, let us say I have a bunch of scripting code from a game. I would like to be able to paste it and translate it to something that is embedded in C++ directly without runtime interpretation. So I could have a very fast development cycle using normal scripting and when done, embed it and generate some kind of expression templates. Without this it is impossible. Would that extension allow me to generate expression templates such as the CT regular expressions I saw in CppCon 2017? 
The problem with auto: * when I use it, it feels at the right place. * when I read someone else code, it feels often at the wrong place! 
`class T` (or `typename T` if you prefer) is the most generic of all Concepts.
Pdf invalid format on android. What does it say?
No idea... some problem with the format it seems.
My favourite so far is [step-through feature in the debugger](https://visualstudio.uservoice.com/forums/121579/suggestions/4078610) that can go directly to the function invoked by `std::function` instead of stepping through the internals. There's also a warning about [initialization order](https://visualstudio.uservoice.com/forums/121579/suggestions/2553854) since 15.3, probably my main source of warnings when I port over to gcc.
&gt; Hopefully in C++20 Coming to you in the real world in 2025. Hey, only 8 years to go!
That sounds... a bit scary. It means that suddenly there's the idea of a temporal ordering in your compilation phase. It means that a type name might behave differently, not depending on scope, but depending on "when" you reference it in your compilation. It also has other consequences. What if you use `using` to create a type alias and then the "value" of the underlying type changes because it has grown or shrunk? Does the type alias have the original "value" or the new changed "value"? There's a similar question around `std::is_same`. Don't get me wrong: I see what you want out of this, and it has some aspects of desirability but I feel the consequences are too grave...
He means, "What are the contents of the paper?"
Personally, I'd prefer something like a `constexpr array&lt;T,10&gt; array&lt;T,9&gt;::with(T)` to a growable and shrinkable compile time container. 
But auto is the worst addition to c++, period. It is very much useless, makes code harder to read, and if you dont like types, then go write javascript...
String literals as template parameters. template &lt;auto &amp; str&gt; void foo(); foo&lt;"string"&gt;(); 
Nah, sorry, it's not what I meant. Imagine a regular Literal Type valid in any constexpr context. But with a pointer to some kind of memory that is neither stack allocated or heap allocated, but rather "compiler allocated". It would have a rather simple interface ( push, remove, clear, at, etc ), be iterable. The underlying object would be Literal values, and of course you wouldn't be able to access a pointer to the "memory" since the memory would be like a bunch of ast nodes in the compiler. The actually object from the point of you or your program may have sizeof(void). It would just encapsulate intrinsic for each operation. Imagine a "list_initializer builder". 
As a author of the CT regexps from CppCon, I say it's possible. It's about writing parser and generator of something which contains same semantics as the input string. You can look into my library there is CT LL1 parser of RE and mathematical expressions. But practically parsing something very long would be impractical from compile time perspective.
It's still all statically type checked but you don't have to write the type anymore if it's obvious
std::unordered_map&lt;type1, type2&gt;::iterator and friends would disagree. Nobody is claiming auto lets you ignore types, or anything of the sort. Using auto doesn’t immediately let you pass strings instead of pointers, but it does let you reduce your coupling without losing any safety. Like anything, if used excessively it’s harmful but the same can be said about pretty much every modern c++ feature
vim/emacs people will strongly disagree, they consider using an IDE akin to being brain dead.
6) When I’ve already written the type once on the other side of the assignment &amp; really don’t see the point in writing it out twice.
I'd much more prefer to have actual compile time functions instead of going through the tmp madness. Constexpr was a step in the right direction. Let's not go back to where we came from.
`auto` is fine, but many gripes would go away if IDEs would show the type at your convenience in case you have any questions when reading the code.
Opinions are like assholes, and vim/emacs people...
Nice factual arguments there!
I still don't see how that is possible without a datatype that is different at different times in the compilation... We do have one proposal out there for such a thing - [metaclasses](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0707r0.pdf). In those cases, there's a specific and well-defined time that you can do type rewriting and modification, and the pre-modification class is never visible outside the class (if I understand the proposal correctly). 
See https://stackoverflow.com/questions/3960849/c-template-constructor : Issue with templated constructor is you cannot manually specify the type, thus the many `make_xyz` in the stl, or the static factory methods in frameworks like Qt.
I feel like the more C++ evolves the less sense that statement makes.
When reviewing a PR you cannot use an ide. Your code should always be readable as plain text without special tools.
This fucked up my team for a week: https://eigen.tuxfamily.org/dox/TopicPitfalls.html We THOUGHT we were getting a matrix with the results of a matrix-matrix operation, but it was actually an expression. The values were correct for about the first 1000 iterations, but then small floating point errors appeared in the values. We thought originally that it was due to FP accumulation errors from multi-core processing, but when we restricted it to a single core it still happened, and at different epochs. Debugging this took several days, until we found that website/docs. It never occurred to us that `auto` was causing it. If we had used `MatrixXd c = ...` instead of `auto c = ...` it wouldn't have been an issue. As a result, I'm a lot more careful about using auto now, especially in code that is going into our prod trading system.
If I read initialization order correctly it needs /Wx which is higher than /W4, isn’t /Wx overly verbose? (Equivalent to all for gcc / clang)
First, I probably work remotely on the train ~10 hours /week, so it is SSH+vim for me there. Second, what if you are using an external lib that returns this object. Presumably you need to USE it for something. How do you know what to do with it? What member variables and methods does it have? You need to know what kind of object it is to use it, right? Just declare the type! Future you and other maintainers will thank you for it! Now, on top of it, what if a function header returns an `auto`? At that point you might as well be writing fucking python. I love python, but the biggest con for me is the need to maintain a huge mental map of the project because I have NO idea what any of the types being passed around are. Typed variables in c++ is a strength, not a weakness. I use `auto` for iterators and lambdas and similar situations. Otherwise, it has to be explicitly typed.
Got a power outage and lost the long answer I was typing. Short version: Of course `-g` is safe. You get ODR violations when you mix sanitizer and non sanitizer templated code, or code in header only libraries. Super common in Boost for example, leads to tons of false positives. The rest is not automatic, so error prone, I don't want it. cget doesn't build Boost properly. Most tools don't propagate build flags properly even to CMake projects, so are not worth mentioning. I don't want to be chasing bugs in a 3rd party tool when you can already do the same with CMake already properly. Especially when CMake changes, all 3rd party tools need to be updated (and they won't).
DRY? Say I want to use an explicit cast. auto j = static_cast&lt;std::size_t&gt;(i); Why should I repeat the type of j on the LHS if it alreadys says it on the RHS?
Expression templates? They're one of the few times where AAA is bad, but they're also very rare outside of math libraries.
The same exact conflict arose around the `var` keyword in C# when it was introduced. It had to be mitigated by providing users quite detailed ReSharper settings so that individuals or teams could define exactly what their policy was, and the IDE would enforce it. Personally, I'm OK with `auto/var` everywhere. No reason not to :)
That's what you get when char[N] is not a value type...
I didn't know this existed.
It is if you use good variable names. For example a student variable is probably going to be a student class if you have one. Secondly, the chunk you are reviewing could easily not have the class type in it, so the benefits seem pretty limited.
lambda&lt;()&gt;::blablabla =)
That's how I interpreted #1. What do you see as the difference, if I may ask?
The Microsoft response was partially incorrect. MSVC’s /Wall enables literally all warnings, like Clang’s -Weverything. (MSVC’s libraries do not attempt to be /Wall clean.) MSVC’s /W4 is the highest level that our libraries attempt to be clean at (similar to GCC’s -Wall -Wextra, kinda). MSVC’s /WX is orthogonal, treating warnings as errors, like GCC/Clang’s -Werror.
“Inclusive and”? What would “exclusive and” do?
For template parameters, yes. But concepts can also be used for variables, in which case `auto` is the equivalent. And then there's lambda parameters, where `auto` creates a template with `typename T`, leading to the controversial proposal to allow this in all functions as part of the abbreviated concepts syntax. If that holds, `auto` is essentially the same as `typename T`.
When working on a big source base, one is going to have hard time without an indexer, regardless of emacs/vim. rtags is the best, IMO.
auto username = user.name() Don't really need to type std::string here for example 
That is, of course, a toy example; can you find a non-toy situation where one might go and call a function that isn't `constexpr` in a `constexpr` context and rely on it failing? Because adding a *method* or changing any signature or adding a function to a `std` library type is a breaking change thanks to the ability to ask "does X not compile" we have with SFINAE. The existence of a theoretical breaking change **cannot be sufficient to ban changing the standard**, or otherwise basically no changes can be made anywhere in C++. 
One cannot do stuff like auto foo( ) { struct S { }; return S{ }; } auto bar = foo( ); without auto
No, that isn't what `constexpr` does.
You're joking, right? I mean if you really feel that way maybe you should go back to C, or at least stick with comfy C++03. 
&gt; to build upon the latest C++ standard (currently C++11) Something tells me that's not quite true.
Shuup, vim doesn't have such hover-overs! You should program differently so that I can keep using *my* IDE of choice!
&gt; rtags Neckbeard allert! :) 
Same thing. You expose the pointer. Only values should be sent, like `std::any`. 
Outdated, more like. I should update the library and the website. 😁
"if" ? I thought pretty much every IDE does that.
"Implicit API contracts" caused by users of a library assuming the particular implementation details are guaranteed and using them happen all the time. All abstractions leak. This particular case isn't special. It depends if you think "can maybe be called constexpr in some contexts" is a first-class highly important API declaration on the level of "virtual" or "pure" or "final", or not. 
&gt; They're one of the few times where AAA is bad, Hence the first _A_ in AAA. 
It's not an `std::function&lt;T&gt;`, but if you set `T` correctly, or use `std::bind` it will work. You can also run lambda instantly: `[](){}();`
&amp; inside template &lt; &gt; yikes... Is there any reason why now at compile time we use &amp;? u/louis_dionne do you care to defend yourself? :P Beside that if Louis says we need this in the standard I believe him. Unless Niebler objects. Notice how my standardization process is better and faster than ISO one? :P 
1 big benefit of `auto` - it always deduces the type from the expression. This means if you write `const auto&amp;` you will never get a converted/sliced copy. This helps in range-based loops over maps because people forget that `std::map&lt;K, V&gt;::value_type` is `std::pair&lt;const K, V&gt;`. If someone writes `for (std::pair&lt;K, V&gt; p : m)` they are making unnecessary copies of nodes due to type mismatch. `auto` saves from it.
This is my rule as well. It's been working out good so far.
 auto foo() { struct S {}; return S{}; } using F = decltype(foo()); F bar = foo(); 
What are the other triggers?^(I'm happy my team has pretty lose style and generic conventions)
I guess my 6) is a particularly egregious special case of 1) :)
AFAIK modern compilers evaluate some non-constexpr functions at compile time as a form of optimization.
Xcode doesn't seem to. At least it doesn't in my code. Visual Studio does, but it's a tooltip, so you can't click on the type and hit F12 to go to its definition.
`decltype([](){}) lam = [](){}` obviously! (or in this overly simple example, it's just a pointer to a function taking no params and returning void)
`operator&lt;=&gt;` seems interesting. I have briefly read the proposal - but I'm unsure how would I implement it? Return -1, 0 or 1?
You can now use auto in templates - declares the template parameter as a value parameter of unknown type - previously the best you could do was `template&lt;typename T, T val&gt;`, now you can do `template&lt;auto val&gt;`!
That actually doesn't work - every lamda has a unique type... that's two lambdas - two different types.
&gt;You can also run lambda instantly: `[](){}();` There's a propsal for templated lambdas that IIRC would allow: `[]&lt;&gt;(){}();`...
The golden rule of `[[` and `]]` was that such attributes *do not change the meaning of the code*, they simply add extra information that compilers (if they understand) can use as part of the code's contract. Ie, if the compiler doesn't understand the `[[` `]]` contents, the code should work perfectly. If it does, it can assume additional things about the code in question. User-defined attributes that are visible on reflection do not have this property. 
It's things like this that the "operator auto" proposal is supposed to fix - but it's unfortunately not a thing yet.
Yes. Exactly. 
This isn't really the place to post basic language tutorials.
https://youtu.be/v3dz-AKOVL8?t=12m55s "Thats because assignment never propagates the allocator... and never should" Why is it the case that assignment should never propagate the allocator? I would expect both move and copy construction to propagate the allocator, which appears to be the case. With the typical (move/copy) assignment defined in terms of the corresponding constructor (below), I would likewise expect the assignment operator to generally propagate the allocator. template&lt;typename U, std::enable_if_t&lt;std::is_same_v&lt;T, std::decay_t&lt;U&gt;&gt;, bool&gt;=true&gt; T&amp; operator=(U&amp;&amp; other){ this-&gt;~T(); new(this) std::forward&lt;U&gt;(other); return *this; } For classes like std::string or std::vector&lt;T&gt;, I would expect that an element-wise copy should be necessary to avoid allocator propagation, e.g. v.erase(std::copy(v1.begin(), v1.end(), std::back_inserter(v2)), v.end());
C++17's decomposition (structured bindings) makes that even better: `for (auto&amp; [k,v] : m)` - k and v are references to the key and value
The only viable criticism is if the function returns the auto. Otherwise, you can always check the actual type that you get from the function declaration.
As Rakete1111 said, any sequence of characters could be called a string. I can go into some more detail though. Technically **char** * is neither a string nor a character. But rather a pointer to a character. In C, such a pointer is usually used to point to the first character of a null-terminated string. This type of string would be known as a c-style string or c-string. **std::string x = "bla";** (or just **string x = "bla";** if you have **using namespace std;** in your code) would create an instance of the standard library's string class. Which is kind of like a convenient wrapper around a c-string (this is a bit of an oversimplification, but it'll do). This is often the first thing people will think of when talking about a string in the context of C++, and probably what they mean if they say "C++ string". Small tip, remove the **using namespace std;** from your code. Not only is it generally considered bad practice to have it in, but right away it will also give you a better idea of what comes from the standard library and what is built-in, you appear to be unclear on that currently.
Only use auto for iterators. Problem solved.
I like to have the double check that a type is what I think it is when I write the program. So I avoid using auto whenever I can. In practice this means that I almost never use auto.
C++ needs a major refresh. The problem is we’re stuck with either incremental updates that don’t break too much and often add to the language complexity or something completely different like D or Rust. It’s like HTTP/CSS/JavaScript for web applications. The community is just too large and entrenched in existing code to do anything about the issues.
&gt; First, it does not have a random access iterator. This case is believed to be fairly minor, since the ordering of parameters is typically more important than ordinal location. Please... in your desire to use "zero-cost abstractions" to improve the C signature you've forced people into copying into another container to support a common usage. Maybe try again if array_view becomes standard.
Hahaha I had the exact same problem in eigen! I had an auto x =A*B, then was doing some operations on x. Every one of those operations calling x(I,j) was recomputing the matrix product. 
Thank you!
I use auto freely to obtain the result of a function. Otherwise if it's an expression, I'll probably tend to use the actual type I expect.
VS Code (with the official C++ extension) can show auto-inferred types when you hover over variables. I uses clang's static analyzer under the hood.
The real problem with argc/argv is that you can't `std::ofstream(argv[n])` or `std::cout &lt;&lt; argv[n]` (see Boost.Nowide). To defeat all the C-ism do this: std::vector&lt;std::string&gt; args(argv, argv + argc);
&gt; You get ODR violations when you mix sanitizer and non sanitizer templated code, or code in header only libraries. Theoretically its possible, but I have yet to see a library with ODR violation using the sanitizers. Even grepping for `__has_feature(*_santizer)` over several hundred libraries shows no ODR problems. &gt; Super common in Boost for example, leads to tons of false positives. The only case in boost is the Boost.Move library when using C++98, so I dont see that as super common. There can be issues with libraries like gmock(because it uses some low-level hacks to detect stack growth). I usually never use those libraries, so I can enable address sanitizer without needing to rebuild my dependencies. You can also blacklist the false positives as well, which can be faster than rebuilding dependencies. Furthermore, those issues are only affected by address sanitizer. The undefined sanitizer works perfectly fine. Now, the memory sanitizer does require you to rebuild all your libraries including the c runtime. &gt; cget doesn't build Boost properly. It should. It forwards the cxx flags to bjam. How does it not build boost properly? &gt; Most tools don't propagate build flags properly even to CMake projects, so are not worth mentioning. What tools? I mean the most popular is conda, which uses environment variables that will always be propagated to cmake/autotools/meson/make. Cget passes the toolchain directly. I would assume that other tools would work in a similar fashion(although conan and hunter do not work that way).
&gt; Especially when CMake changes, all 3rd party tools need to be updated (and they won't). Cget doesn't need to be updated when cmake updates. I am not sure what you are talking about.
i'm skeptical that this problem actually deserves a solution, especially if it has extra cost on startup. c++ programmers really should be able to understand c strings and arrays it's easy enough for the application itself to wrap the arguments in a string_view to simplify their processing. but if the runtime does that for you (as the author proposes with std::initializer_list&lt;std::string_view&gt;), you lose the explicit guarantee that the strings are null-terminated. so if you want to pass it back to something expecting null termination, you'd have to copy it into a std::string and call c_str() on it
Does anyone knows why std::string_view keeps the string length as a member? To support non-null terminated strings? If not, wouldn't keeping only a cons char* would suffice?
&gt; This fucked up my team for a week: https://eigen.tuxfamily.org/dox/TopicPitfalls.html Really? That fucked up your whole team for a week? I encountered that issue, alone, during my undergrad and it fucked me up for like 5 minutes.
This is the worst argument out there. This claim only holds, if explicitly writing type information is helpful for type-safe programming. Haskell is arguably the language with most advanced type system among the ones commonly used, and Haskell has a pretty powerful type inference so that you don't have to write type information in your code. Types are not good because I have to write `std::unordered_map&lt;type1, type2&gt;::iterator` every time I want to write a for loop. Types are good because they provide a formal framework in which program correctness, upto some point, can be efficiently proved by the compiler in compile-time. Ideally, you should write auto almost anywhere and let compiler figure correctness out; just like you don't write the explicit type every time you do assignment or declare a function in Haskell.
5) Almost always
It's so you can have a partial view into another string. Consider `strtok`. It adds `'\0'` at the end of each token, modifying the original string. Instead, we could write a version that returns a `std::string_view` for each token.
* Smart pointers are a huge trigger, especially shared_ptr. People have aneurysms over shared_ptr. Alternatively, using naked pointers triggers the opposite group. * Using pure virtual classes. People don't understand why you'd ever want to use them. * Using pimpl. The same people that don't get pure virtual classes will happily use a pimpl pattern. * Using Factories. Who needs a factory when you have new? Or God forbid std::make_shared (see above about std::shared_ptr!)? Seriously, some people can't wrap their head around them or their use cases. * Using singletons. * Using RTTI. Not using RTTI. * Using exceptions. Not using exceptions. * Using Inversion of Control/Dependency Injection (wait, isn't that a Java thing?! Why are you doing this?!) 
An `array_view` of `string_views` seem good to me. Presumably it would be optional (e.g. the signature of `main` would still be your choice, but now there is one more option).
Code should never depend on explicit type information. Code should depend on type correctness, which has nothing to do with explicitly writing types (most of the time). Just look at some Haskell code; it's possibly much more type-correct than C++ code, but doesn't have type names spread all over the code base. This is because types are most interesting when you can just code and compiler can check them for you; and then you think in terms of them every time you create one or define a relation between them.
Supporting non-null-terminated strings is required to support substrings, which is far more interesting.
If it's going to use the library to solve it, it needs to use the library to solve it. Here's my suggestion to replace the entire proposal... I think it compiles at least. for( std::string_view s : gsl::make_span( argv, argc ) ) { // ... } This puts the unavoidable strlen in the application's court rather than in the black box that is pre-main(), solves the proposer's issue about icky C and only depends on gsl::span, which I guess might become standard as array_view someday. And fwiw random access might not be important to the author but it's a silly thing to remove and likely many programs rely on it.
My rule as well. I think this is the best convention for code bases that aim for high type correctness and facilitate some bit of metaprogramming.
This is hardly more readable (I still have to check `foo` to know what `S` is) and now namespace is littered by a weird type `S` that will be used only once for `foo`. OC is better and if I saw your code written by me or one of my coworkers, I would go ahead and fix it to OC.
In hindsight it's obvious, but this is a trading research code base with tens of thousands of files and millions of lines of code. http://cloc.sourceforge.net v 1.60 T=157.08 s (182.1 files/s, 52570.4 lines/s) -------------------------------------------------------------------------------- Language files blank comment code -------------------------------------------------------------------------------- C/C++ Header 18881 593350 889671 2768729 Python 8205 510691 769500 1784479 C++ 77 25261 86761 312600 HTML 479 10433 4676 131208 C 90 10543 39518 87610 The unit tests still passed, because the problem didn't surface until it had been executed thousands of times. It started when our integration tests started failing, so we started looking for areas where floating point issues might have been introduced. It was compounded by the fact that it was a quant researcher who was writing this code for research, before it was "productionized" by the prod devs. So, he was writing C++ no one else had seen before, based on numpy/cython code, and when we went line by line through the code, the matrix multiplication had NO reason to stand out to us. I shouldn't make it sound like the ENTIRE team devoted a week to this. The quant worked on it for several days, and the devs gave suggestions for where to look, along with several house of pair programming. It was probably a week of man hours all told. So, yes, if we only had a handful of files to look through for a university assignment, and everyone was familiar with every line of code that had been written, it might have taken &lt;10 minutes.
&gt; C++ needs a major refresh Does it?
Consider the following: * Object is allocated in library code that wasn't using ASan. * Object is deallocated in user code that's using ASan. What happens then? You get a false positive ASan error! Consider the following: * Object is allocated in templated code * Object is deallocated in templated code as well * Some instantiations of those templates are in compilation units using ASan * Some instantiations of those templates are in compilation units NOT using ASan * Linker gets many instantiations of the same templated function that are all marked weak, picks one randomly * Kaboom 
&gt; i'm skeptical that this problem actually deserves a solution that was my thought as well.
That being a subjective opinion. I’m sure there are people who like it the way it is. 
We just need a proposal for a time machine to get through.
I really don't get how this reduces the mental load required to understand the program though. If I write the code, put it down for a few months or years, and then need to modify it, having auto sprinkled everywhere makes maintaining it that much more difficult. And god help any other person learning the codebase for the first time. For lambdas and iterators, fine, whatever, that is awesome. But in this case, I have to first open the header with the function, get that returned object, then go to another header and get the object declaration to see how to actually use it. Without auto, I only need to go to one file. If this is a rare instance, its not a big deal, but if I have to deal with 50 autos, that extra cognitive overhead hurts. I know I'm in the minority here, and a lot of very smart and skilled people advocate AAA, but I still don't think it is as obvious as it is being presented.
Hey, thanks for taking the time to take a look in this tutorial and for the feedback. Now I must admit that I am more interested in doing things like algorithms and more specialized topics, however I would still like to improve myself at how I present different topics by starting out with some easier tutorials (and for the sake of providing a full documentation in video form). Now the language is a problem as I often fail to find the right words to explain some things, thus resulting in situations in which the instructions given are unclear and not accurate. Operator precedence is an important part of operators but I decided to do a separate video on that so I could get through the whole list, instead of adding 3 minutes in this video. Basically tried to keep it short while cutting out stuff. Overall, I agree on your points and will be working on them in the future.
&gt; c++ programmers really should be able to understand c strings and arrays I agree with this statement, you really should understand c strings and arrays, null termination and all that great stuff. However, I'm on the fence with where C++ really should sit alongside C these days. There is a solid argument (which I think the author of this is really getting at) that *modern* C++ is very much its own language and though it's a powerful feature to be able to "drop into" C-land at any point, there really should be no reason to in this day and age. For the same reason that people generally agree you shouldn't use raw pointers any more in favour of make_unique, it does make sense to have a C++ specific entry point as well. 
This. I spend way more time reading code than writing and the number of times auto has confused me easily outnumber the times it has helped. 
What is considered as "basic"?
you can have a method "extract", which would be the only available method on runtime. not counting copy or move constructor maybe.
A lot of new programmers get unpleasantly surprised when they can implicitly convert a `const char[]` to a `const char*` without a diagnostic.
Yeah, we wanted to go this way, but arrays will decay into pointers when used as template parameters. :-(
What you're most likely talking about is `constexpr` parameters. Talk to implementers about problems with this. This is highly non-trivial to get right, and I don't think we can have this for C++20. My proposal is to give a reasonable solution to a concrete problem as soon as possible, since people are already using the non-standard extensions to achieve the same thing.
We can't pass the array by value because it decays to a pointer. The only option to pass-by-value would be to pass a class type, but that would require expanding what can be used as non-type template parameters. This is a much larger proposal (although one is in the works).
Thanks for the feedback! I'll admit that you were the one to open my eyes to `function_ref` in a blog post of yours; without this I might not have tried to generalize to non-owning storage :-).
That's one opinion. I find I don't care at all about substrings, but I care a great deal about being able to call external APIs that take null-terminated strings. For that reason we will not be adopting string_view. 
I'd prefer having `main` be simply `auto main() -&gt; int`, with some std function which returns an iterable of all the arguments. #include &lt;args&gt; auto main() -&gt; int { for (auto&amp;&amp; arg : std::args()) { std::cout &lt;&lt; arg &lt;&lt; std::endl; } return 0; } That way, the cost of putting the raw arguments from the OS into some container and `strlen`ing the strings would only be incurred if you actually called `std::args`, and the proper container types would be made visible in the `&lt;args&gt;` include. It also makes the `main` signature less confusing for new programmers.
In my talk, the guideline I provide is to not fiddle with vtables since the benchmark results I got did not show any noticeable improvement for various vtable policies. I also don't feel like I'm overselling the technique in the documentation, but LMK if you think I do and I can tone down the documentation. Also, all of this is a work in progress and I'm planning both better documentation (with inlined benchmark results) and more vtable policies. One thing I'm thinking about is to implement a vtable with a switch statement instead, which might allow placing polymorphic objects in memory mapped files or serializing them. So it's not only about efficiency, but also eventually about functionality.
I don't think that eval is a good match for C++. Adding compilation/interpretation to the runtime would not be a simple and elegant change like I was writing about with macros. The idea is to make a change that doesn't require a lot in terms of infrastructure but would have a huge effect, like I described. Also, I have to disagree with the statement that lisp isn't that fast. Especially the abilitiy to write macros allows to defer work to compile time that would have to be done at runtime without lisp-like macros. Ofc, due to dynamic typing there is a performance hit, but macros don't depend on dynamic typing. Maybe that is your misunderstanding.
Using `std::string` instead of `auto` could even incur an allocation if `name()` returned `const char *`. Worst case scenario, using `auto` is as expensive as writing out the full type.
Is [this proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0784r0.md) what you are thinking about? (sorry for the raw markdown, for some reason it was included in the mailing un-rendered)
I thought you couldn't use lambda literals in unevaluated contexts? Did this change?
That’s nice and simple but does involve creating copies of all the arguments.
&gt; modern C++ is very much its own language and though it's a powerful feature to be able to "drop into" C-land at any point, there really should be no reason to in this day and age. At this point, shouldn't what you describe as "modern C++" just fork? I mean, the more I look at the situation, the more it feels like there is a divide between one part of the community that doesn't consider null-terminated strings or raw pointers to be obsolete or an issue at all, and another part that seems almost ready to shed off most of grandpa C's legacy and break backward compatibility. When one part of a language is basically never used anymore because it's not "modern" enough, why not move to multi-languages programming then?
Well, I don't think it has to be an either/or thing. I don't think there's a solid case for breaking compatibility just because, nor do I think you should absolutely never use any C because *it's not C++*. And that's where I see this new entry point fitting in. It's, as C++ has always done, an addition and one you don't have to use. It doesn't harm C by being there, but there are some benefits to it (especially for beginners).
That's totally fine! That's no reason not to have `string_view` at all, though. Especially given that it would be ideal for those external APIs to eventually move to using explicit string lengths.
interesting... let's see how far we can get... although we already can `[](){[](){[](){[](){...}();}();}();}();`
I am curious to know in which use cases start up time is so crucial to the application that this slight increase may pose a problem.
Take advantage of templates, avoid all these design decisions: Specify that main is called as if by a braced-init-list of strings and let implicit conversion do the work. A little extra magic required to resolve overloads for each list length, but it’s worth it.
&gt; because it decays to a pointer I know normal function arguments do that but why would that be required for this template version? Is there any benefit of allowing pass by ref and pass by value in this case? If not just make pass by value syntax behave as pass by value. nobody will cry about fixing decay abomination at least for this case.
I think that many people (who are against modern constructs) should rather stick to C. C's commitee has similar attitude against certain features (and will probably never standarize them).
I wonder if this wart of the language can ever be fixed? I mean std::array is great, but it's not a primitive type. Same goes for std::string_view vs nul-terminated arrays of characters.
Good luck breaking the ABI of the C world.
I can't upvote this enough. I play around in over 600k lines of HTPC subpixel image processing and high precision sensor simulation code and I can't be bothered running around the code base trying to figure out what the heck "auto" means.
Weird. "Go to definition" seems to work fine for me in VS: https://i.imgur.com/Fw5wid2.png
Nooooo.... copying, allocation...
another rule to make your life easier: When only "auto" appears (not auto&amp;, auto&amp;&amp;), its deduce type is always T (no type qualifiers, no '&amp;' or '&amp;&amp;' )
Definitely this will help as it will help with inline lambdas. I recall finding out about this limitation of "for" pretty early on after switching over to c++11. Explicit iterators, while a HUGE pain to type, etc, did take care of these type traps.
[Graphics Programming Black Book](http://www.jagregory.com/writings/converting-and-preserving-michael-abrash-graphics-programming-black-book/) 
Well, I started programming ~2013/14 so C++11 was "the state of now" during learning. So eg I wrote `nullptr` since the beginning. Now I understand how some things could be painful for poeple in the past.
&gt; MSVC’s /W4 is the highest level that our libraries **attempt** to be clean at... Wait, is there any currently-supported MS library that doesn't compile with /W4 /WX?
That's even better that what I imagined. I'm glad you are working on it !
I mean, "it would be ideal" doesn't mean "let's throw everything out and start from scratch. It means "when we can, let's migrate to the better way a little bit at a time."
And at least one interpreter actually exists: https://root.cern.ch/cling 
Oh , haven't we all fallen for this one!! 
&gt; The golden rule of [[ and ]] was that such attributes do not change the meaning of the code Nobody has actually justified that rule that I've ever seen. It appears to be absolutely arbitrary to an observer like myself. :)
Can you cite that?
Ha, true, but chances are, the ABIs we speak of are so hard to change (too many clients), that changing will end up in a mess of old stuff, new stuff and duplicates. That's hardly better overall. Road to hell is paved with good intentions and all that jazz :-).
And most importantly in my experience, that the C library will free using `free` or resize using `realloc`. Also of use is the case where you get a raw buffer you know is formatted like some structure from some unknown API. `laundry_pod` will make a real instance of `T` exist there.
There is zero guaranteed that an ill-formed program will be rejected at compile-time. The largest guarantee the standard provides is that sometimes a diagnostic must be issued. There are plenty of mentions of "ill-formed, no diagnostic required". Practically, the difference is that compilers are expected to be permitted to fail to build ill-formed programs, while it is somewhat unexpected for a compiler to refuse to compile code that provably generates undefined behavior when the program runs.
Sure, but does it seriously matter you call malloc one time when your application is booting and you copy roughly 30 bytes of memory to your heap? I'm not disagreeing with you but usually that much efficiency is not needed; besides your compiler might optimize it.
On a UNIX/Windows, it doesn't matter, but imagine more constrained environments. Also it's not one malloc, it's possibly several for the vector and one for each string. All that said, it's just a C++ Stockholm syndrome and you're right :-).
By far the biggest benefit of c++11 was the addition rvalue reference. Made a very clear impact on the performance of our code base, as I recall perhaps 20% or so faster across the board. I probably need to go back and look at doing a better job of converting push_back to emplace_back amongst other small things. I still am finding a few places mostly related to 3rd party libraries that need switching over to nullptr. Another advantage to NOT using auto is during refactoring, especially when I want to inspect consumers of a specific type.
`push_back` has 2 overloads. C++11 to `const T&amp;` added `T&amp;&amp;` overload. Smart compilers should automatically select new overload for temporaries.
Readability was not the point. Just defeating "cannot do" was.
Cppcheck should give a warning about wrong initialization order and is really easy to integrate in Visual Studio. You should give it a try.
&gt; there has been opposition to it being removed, since there is no other better alternative, as of now Qt people have not been working on minimizing moc to eventually phase it out. On the contrary, Qt is moc dependent more than ever. Your bedtime stories about majority of Qt contributors wanting moc gone... are just that, bedtime stories from an alternate reality. &gt; other alternative currently available is to litter the code with macros I really dislike macros, but compared to moc, I consider them an improvement because unlike moc they are a language construct. Every time I see moc, I honestly reconsider wxWidgets... Next time, I probably give copperspice a go. And btw, regarding macros all over the place, the thing about the Q_OBJECT mess.... &gt; not sure what you refer to with 90s OOP and QList, those have nothing to do with moc Correct, but I didn't say that. I just mentioned them as weaknesses. &gt; But you cannot ignore that Qt has a long history and cannot just break compatibility just for being modern sake. Funny you mention this. I have been using Qt of every major release, beginning at 1.x. Every major release was somewhat incompatible but the latest joke was to require a C++11 compiler in a minor release update (5.6-&gt;5.7). This is a braking change. Why not do a real upgrade of the whole package, make it *really* C++11 (or even C++14) friendly and release it as Qt6, while rework on the atrocious interface as mentioned above... It seems the Qt people have missed the entire last decade of language and standard library evolution. But Qt evangelists cannot be wrong in a Qt-centric universe, can they!?
Oh, you do Go To Definition on the `auto`... right. That genuinely never occured to me. Presumably I've just been trained into automatically dismissing the very idea of doing Go To Definition on a keyword...
Macros would not be a simple and elegant change either, it's actually pretty far out there. Also, some of your conclusions of utility are inaccurate: lisp homoiconicity + macros, and reflection, are two separate features. You can have either one without the other. There's no misunderstanding. Lisp just isn't that fast. It is pretty fast for a dynamically typed language, yes, but it's nowhere near as fast as C++. Even if it could be in theory, there's no lisp whose implementation has a fraction of the man hours invested as C++ compilers (unless, you count the JVM of Clojure, of course). It's definitely not fast enough for HFT, or AAA game dev, etc.
If you're *that* constrained, maybe C++ isn't the right language anyway?
Xcode sounds weak sauce to me. Eclipse provided this functionality years ago (even with auto), I'm sure Clion does. If you use vim/emacs then ycmd/rtags will print information about a symbol at point, including its exact type. Although it seems like neither ycmd nor rtags will goto def on auto, I guess that is a very small usability disadvantage. I must say I don't remember being annoyed by it and I read auto in code extensively.
Oh but it should be. The alternative is C, and C++ has it beat in every conciveable way :-).
I hedged because I don’t really know anything about ATL/MFC.
Yes, you can have either without the other. And that is exactly the point of this post: why not have a simple elegant feature that enables tons of useful stuff, instead of adding complex features one by one. I don't understand where you are going with the performance argument. Are you saying that the idea of lisp-macro inspired features can't be added to C++, because of the tons of man hours that have been put into C++ compilers?
I can't really see a system that constrained that also uses arguments to main. If you are thinking barebones embedded systems they really never use these arguments anyway. 
We have the same issue when using our math libraries and that's a thing we tell every new employee and it's part of our coding guidelines. Don't use auto on results of math library operators. I feel your pain, since that's such an easy to overlook mistake.
One where the application is launched very often and it's execution is very rapid. e.g. the "test" utility. 
You have given just about zero explanation on how one of the most sophisticated language features out there (lisp macros) would "simply" integrate with one of the most complicated languages out there (C++). Even having a statically typed lisp, is a non-trivial and relatively unpopular undertaking, and that is only a small fraction of what it would take to integrate lisp features into C++. Err, it was never a "performance argument". I simply said that lisp's features would in principle be useful for performance (the very features you feel would be inelegant to add to C++), but lisp taken as a whole is not a good high performance language. You disagreed, and I explained to you that you were wrong. That's all.
It's the verbiage in the standard about "object representations" (which bit values that exist in the hardware) and "value representations" (the bit values assigned by the language in the hardware). Section 3.9.4 of the C++ standard, which specifies in a footnote that this "value" vs. "object" representation construct is intended to ensure compatibility with the C memory model.
The odd thing is that Xcode's its code browsing is fine otherwise. In fact, it's one of the few bits that Xcode generally does well on. And it's driven by clang, so it'll surely have all the info to hand...
eh. i'm sure i't's possible to make a vim tool for that.
before someone pings me, yes, I see it. we're looking. -- Steve@MSVC :)
May I ask why? Moving to DSA in OpenGL and using Vulkan otherwise has made the "current" state-machine model in graphics programming feel archaic, let alone the stuff you listed
In which case, why are you using arguments in main? that's pretty rare in things like embedded 
Oh! If only find modules were that easy. There is a comment in that FindZLIB.cmake file that says that it will search in ZLIB_ROOT first. But I've found that to be always true (although it may be since version of cmake). On *nix systems that call to find_package can find zlib in a system path even if ZLIB_ROOT correctly points to a directory that contains zlib. I've seen other find modules that make two calls to "find_path" or "find_library" , the first of them always with "NO_DEFAULT_PATH" to prevent the behaviour I just described. And the second as a fallback. I've even seen find modules finding the include directory in one place (e.g. system) and the library in another, causing no end of barely-traceable headaches (such behaviours can result in compile errors, link errors, or runtime errors, depending on the degree of compatibility). This one for zlib also doesn't give you control of whether you want to find the shared object or not, should both be present. I presume cmake always favours the shared object. Some find modules contain options like "XXX_USE_STATIC" to give it a nudge, but the logic involves limiting the search to certain extensions (.a on *nix), or to look for a different filename altogether ("zlibstatic.lib" on windows). So to shield yourself from all these things, the resulting find module ends up being a little too long. Don't even get me started on those libraries that package binaries on windows in different subfolders (x64/vc14, etc), with very little consistency across libraries, or the fact that LIBNAME_ROOT may have a meaning in module mode, but LIBNAME_DIR has a meaning for config mode. I still love cmake tho.
&gt; Just for fun, I'm curious how it looked back then I was Googling for some DirectX 3.0 for instance but found literally nothing
It is not minimal cost. Also, one of the principles of C++ is: &gt; You don't pay for what you don't use; This goes against both.
Afaik it's not going to take away the old signature, you can still use it if required, so it still is "don't pay for what you don't use"
What about custom allocators and nomalloc environments? What if the initial allocations fail? `array_view&lt;string_view&gt;` is a better solution and I'm not even sold on that.
What other choice do you have? C? Some Assembler you never heard of? A malloc might not even be possible when you only have 2KB RAM and no MMU.
Oops, missed that in your original description. You can maybe use something like libgen.io to find textbooks for those graphics APIs? You'd have to find the name of the book you want somehow, then feed that to libgen.
This feels like the right direction. Also this integrates well with non-std types. It should be possible to allow user defined types (mostly) everywhere the std types are used.
In such an environment you probably can't use standard C++ library anyway. If you're writing for a platform that has 2KB RAM with no MMU that forces you not to use dynamic allocation, it might have a quirky enough C/C++ implementation that you can't apply "normal" C++ idioms.
&gt; Readability was not the point. Then what was the point? It's cool to write equivalent programs without using `auto` keyword (which, you used too :-); but if it's not a better program from any metric then why would you write it?
Because it was said it can't be done, as I said before.
Is there a vim tool for using spaces instead of tabs? My manager tried using his vim preference as a reason to use tabs when everyone else wants spaces.
The current pre-main() already needs to do a lots of things, but one advantage of not involving it in a change is that said change can more easily be backward compatible, although maybe it is not that important, I believe that on most systems there always is at least some part of the pre-main() code statically linked by your toolchain?
Nothing ever requires vectorization, unless you need it to be faster. 
Yes, python has a better library system than C++. And that gives python an advantage.
&gt; Smart pointers are a huge trigger, especially shared_ptr. People have aneurysms over shared_ptr. How often do you really need shared_ptr instead of just unique? I'm working on a very legacy code-base, and even there shared_ptr real need seems to be extremely rare. &gt; Using pure virtual classes. ugh; that's basic C++, not even modern black magic. &gt; The same people that don't get pure virtual classes will happily use a pimpl pattern. What's wrong with that when you do need it??? 
You don't even need a plugin for that, it's supported natively http://vim.wikia.com/wiki/Converting_tabs_to_spaces
He's a damn dirty liar!!
`set expandtab`
You're right about that. Hmm.
I think I still prefer p0424r0. What happens if you pass the same string literal to the same function multiple times? Do they deduce to the same value and are the templates instantiated only the first time? I.e.: func&lt;"foo"&gt;() func&lt;"foo"&gt;()
Not quite. Often, explicit types help you understand the code you read and sometimes it is crucial for code correctness to know if you e.g. have a const char* or a std::string. And why do people always refer to Haskell, which has totally different syntax, semantics and patterns. I'm not saying you shouldn't look at other languages to see how they solved problems, but just because a solution works great in one context doesn't mean it should be used in a completely different one. All that being said, I'm a huge fan of auto.
Use a proper IDE and this should be relatively easy.
Why is this better than `std::size_t foo{3};` ?
Looks like rust code. 
Isn't there a bum plugin that allows you to go to definition?
&gt; You have given just about zero explanation on how one of the most sophisticated language features out there (lisp macros) would "simply" integrate with one of the most complicated languages out there (C++). Well, this is what I came up within 10 minutes. It's not exactly rocket science. It might not be perfect, but you catch the drift (I hope). Define a simple data structure for code (like an AST): // All operators get a value representation enum class rator { @+, @-, @*, @/, @{}, @(), @[], @,, @;, @new, @return, @delete, @class, @struct, @template, ... }; // All operand types get a value representation enum class randtype { @name, @number, @boolval, @string, ... }; // All operands get a value representation struct rand { randtype type; union { const char* text; // note: raw pointers might be ok, because these exist at compile time only const rator* sub; }; }; // All expressions get a value representation struct expr { rator rator; int randcount; rand* rand; }; Define quote and unquote (equivalent to backtick and comma in lisp): +{quoted stuff} -{unquoted stuff} Define a macro definition syntax: namespace mymacros { auto @declint123(auto varname) { return +{int -{varname} = 123;}; } }; Example usage: int main() { mymacros::declint123("x"); return x - 123; } The macro expansion will do this: int main() { int x = 123; return x - 123; } Define a syntax to get the representation of a previously defined symbol: int main() { int x = 123; expr myexpr1 = @"x"; expr myexpr2 = +{int x = 123;}; // myexpr1 and myexpr2 will now contain the same data } 
The part that came out of the discussion is that any such gobal is very succeptible to races. In general, that idea had some pretty negative feedback (but not nearly as much as the paper itself!).
Well, the current language allows specifying an array as a non-type template parameter, and it decays to a pointer. "Fixing" this is a breaking change. I think we all agree the language would be better if this was fixed, but there is a large cost to fixing this due to the breaking nature of the change.
Wouldn't the arts be const? Where exactly would that lead to a race?
Interestingly, in discussions during the week, many shared these issues. The paper as presented ended up proposing "std::argument_list", where argument_list has an implementation defined representation, and that the implementation would be free to lazily evaluate the arguments if it so chooses. It also has the advantage of being able to preserve non-ascii/current code page command line arguments based on the individual implementation. &gt;i'm skeptical that this problem actually deserves a solution About half in EWG stated this as well. Most of the other half (as well as myself) disagreed. So, *shrug*.
The design of this proposal was reviewed and it was received positively! This is by no means a _guarantee_ that we are getting this in the language at any point in time, but the proposal is making progress.
Yep, that is exactly my opinion on it as well.
And where exactly would you store the array of string views over which you want to create an array view if not on the heap?
This seems like a unnecessary change for a problem that's not really that big of a problem. Also something for people to get all religious about where the best solution isn't really that much better than doing absolutely nothing.
The args aren't const (since argc/argv are not) in a situation like this. I was told it was a non-starter to make them non-mutable. The race ends up being when a function called in an initializer would change the value before main, or potentially could cause a thread to do so, etc. Essentially, it is a 'global state' that would likely be modified either via 'main' or via any of the users.
&gt; but LMK if you think I do and I can tone down the documentation. "4. Slow 95% of the time, we end up calling a virtual method through a polymorphic pointer or reference. " Sounds like exaggerating... It's not THAT slow. &gt; One thing I'm thinking about is to implement a vtable with a switch statement instead... You don't win in performance against std::variant with handrolled switch (I tried) - at sizes more than 8 - compiler generates the same jmp table (it always do this thing in if-else cascade, if can detect that you compare ascending integer). Hence - you rather don't win in performance, by replacing vtable with a switch statement, because as we saw variant performs not faster than vtables on random types. How you will collect types for swicth? 2 years ago I was thinking about replacing part of virtual classes with my home-grown variant implementation in my pet project. I wanted all variants to have "auto-deducted" list of types. I end up with macro near class definition, which should add that class to tuple (by making new one), and through halfy-hacky solution I can get the latest tuple with all class names. Plus I needed to include all of them before use... All in all the solution was that much ugly, that I abandon that project for good :) And concluded that I needed compiler support for things like that - either reflection to get all types; either compile time updatable tuple... And you still don't have access to meta-programming. &gt; ... or serializing them. How this help with serializing? It's impossible with upcoming reflection proposals? &gt; ... but also eventually about functionality. Please, do investigate the technique itself further. Like type that implementing several concepts, concepts inheritance, concept cast, etc... Even conceptually. I think this is more important.
This would be incompatible with many C libraries that are still used from C++. For example, [MPI](https://www.mpich.org/static/docs/v3.1/www3/MPI_Init.html).
Epic triggering right here. Well done! :-D
I see what you mean, but at this point that's a C++ limitation, nothing you can do about it.
It's strictly equivalent obviously. I think the advantage is `auto` makes it easier to see variable declarations and differentiate them from other statements.
&gt; What happens then? You get a false positive ASan error! No you dont. I suggest reading the asan paper to understand how it works [here](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37752.pdf). The instrumentation provided by asan overrides loads and stores to check if the address is valid, but the shadow memory is handled at run-time by replacing malloc and free. Thus, there is no need to instrument every external library. I even tried your scenario you described locally, and asan shows no problem. &gt; It forwards CMAKECXX_FLAGS. What about CMAKE_CXX_FLAGS&lt;CONFIG&gt;? That is a good point, which can be simple to update. &gt; What about the directory level compilation flags? And defines? For a toolchain, usually you define it using `CMAKE_CXX_FLAGS` instead of using those.
Assuming he's not calling main himself, as that's considered undefined behavior.