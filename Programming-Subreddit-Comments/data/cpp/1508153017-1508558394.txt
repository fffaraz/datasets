They are available in "straight C" as well if you `#include &lt;iso646.h&gt;`; I've used them in some embedded code previously. Unfortunately, they are simple aliases for `&amp;&amp;` and friends. I say that because (IMHO) Perl does it better where the English ones are absolute-lowest priority, meaning a leading `not` will come last if the rest of the line is `&amp;&amp;` &amp;c without a parenthesis party.
I deliberately chose an example where you would (presumably) maintain variables that need to be reassigned, or kept as pointers. It doesn't make sense to me to have something that tracks memory allocations, where you convert from allocated memory to references (because the API requires it), then internally you take the addresses of the references to store them, then switch back to references to use it. This is not a lifetime management issue (class doesn't allocate or deallocate the memory, just observes it).
I specifically said "old LISP dialect", what constitutes old here is debatable. However that's a can of worms I won't keep opening because there are people that will hang on to dire life to pre-R6RS scheme and claim the newer versions are ugly and bloated and untrue to the core principles.
You can't.
Is Fortran really better than using eigen or Julia?
They're simply alternate spellings for the symbols, so no.
I'll just stick to `&amp;&amp;` and `||`. 
Use `-Wbool-operation`
Fortunately C++ is not Perl.
I tried that too, but it looks so verbose (particularly because you can't write `not` directly in front of the condition, you have to put a space, making it look like something different). I wish there'd be fonts to make the `!` thicker or something.
I recently contemplated changing all "!" to "something == false". Didn't even think about using "not".
I think Clang's convention is to not recognize `-std=c++17` until the standard is published, in case it becomes C++18,. So that still isn't a good metric for when to use the C++17 support. Just because ISO publish the document doesn't mean the implementation in the compiler is any more complete.
I also love and prefer words than symbols. But as it's very uncommon to see these keywords I also don't use them. But perhaps one day I'll change. For some operations it's still quicker to use symbols though: if (not x and not y) { } if (!x &amp;&amp; !y) { }
s/C++/C/g
Just use a reference instead of taking a pointer.
How to you fix the call site, in a function that makes use of the new keywords calling function that happens to be in a binary library, using a structure named as the newly introduced keyword? The answer is lots of fragile pre-processor magic, doing multiple renamings. Not something that I wish anyone to debug when it goes wrong.
I did the same thing about three days ago for the same reasons. 
Huh. Does that mean we have to marry?
Well, an already established way of doing it is And and AndAlso from VB.NET The first one is bitwise and the second is logical + short circuiting
Company: Viacom Type: Full time Description: We’re a leading media company and we’re looking for more engineers our one of our most important projects. Viacom Media Networks is looking for an experienced software engineer to work on critical development projects related to broadcast television distribution. As part of the Broadcast Systems Development team, this individual will work to develop essential content authoring, review, and playout applications. Candidates for this position should be driven to deliver quality software suitable for the high-availability nature of television broadcasting. Location: New York, New York Remote: No Visa Sponsorship: Yes Technologies: C++98/03 Other: Windows / Intel IPP / Video Codecs Contact: Apply here 
How about this? template&lt;typename T&gt; class AllocationTracker { public: void track(gsl::not_null&lt;std::shared_ptr&lt;T&gt;&gt; p); void stop_tracking( gsl::not_null&lt;std::shared_ptr&lt;T&gt;&gt; p); };
&gt; The physicists that care enough to teach themselves to code properly generally become very good at it though, you just have to love programming enough. In my experience, that's still pretty debatable. I've worked with several scientists that love coding in python and even a few who love C++. All of the code I've ever seen from them is one character variables and code that is absolutely impenetrable unless you know whatever equations the code is derived from. Zero comments, naturally. And several of these are people who have been coding for longer than I've been alive.
not_null is extremely useful. It causes failures as early as possible (at compile time, or at the moment a null value is passed to something that cannot handle it). It's most useful property is that it communicates that the a function interface that uses it will not accept null values nor will it ever return them. References are not a replacement as they communicate different things, references typically tell you that the function intends to hold onto the referenced object only for a short while (no longer than it takes for the function to return) while a raw pointer will tell you that the function will hold on the object beyond that without any assumption of ownership. Finally, not null also works with smart pointers which references definetly cannot replace. 
What is an um wrinkle?
Throw a little De Morgan in that and write `if (not (x or y))` instead :p
* A separate traits class means you can define traits for built-in types, like `int`. * Defining traits per-class would require all classes to implement the trait member, or generic code would fail to compile for unsupported classes. As you say, a separate traits class permits a default value to be supplied when the trait isn't specialized for a particular class.
It's not entirely impossible to make your own font. Start with a popular font, grab the ! out of the bold characters, and overwrite the regular ! with it in a new font file.
Though if `nor` was defined that would save one character. Still I think its better to just use one set rather than a mix of words and symbols. And since the symbols are the most common...
Classic De Morgan.
When a piece of code redefines sprintf, you go yell at whoever wrote that.
I thought these were a GNU extension?! How long have they been in the standard?
Use an editor that has an option to bold all symbols. 
Don't do that. 
They've been standard since the beginning. MSVC requires you to explicitly enable this feature, last I heard, but has supported it for a very long time.
Let me put in another good word for not_null. In addition to the reasonable examples made [here](https://www.reddit.com/r/cpp/comments/76p8y9/how_not_null_can_improve_your_code/dofqcye/) and [there](https://www.reddit.com/r/cpp/comments/76p8y9/how_not_null_can_improve_your_code/dofqajk/), I think it's worth mentioning another point: **creating a reference from a null pointer is undefined behavior**: void SomeFunction(int&amp; i); int* ptr = nullptr; SomeFunction(*ptr); // undefined behavior This means, SomeFunction might casually be called. To avoid such scenarios, the callers of SomeFunction are required to create a "valid" reference. I know what you are thinking: "what the hell is a valid reference? References are valid by design". That's the theory. Practically, the story is different, like we have just seen. Replacing int&amp; with not_null, we have: void SomeFunction(not_null&lt;int&gt; i); int* ptr = nullptr; SomeFunction(ptr); // invariant violated (e.g. exception thrown) We have basically **turned undefined behavior into a well-known behavior** (e.g. throwing an exception). not_null is a **fail-fast** tool. It might not be null. Pragmatically, a reference might. We have also expressed very clearly that calling SomeFunction requires a valid pointer, otherwise an invariant is broken. No way we "forget" about that. In addition, not_null works with *owners*, whereas a reference cannot express any ownership semantics. Just realized [this comment](https://www.reddit.com/r/cpp/comments/76p8y9/how_not_null_can_improve_your_code/dofukqf/) contains similar arguments, so I don't go further about this.
That won’t work if you want (or need) to take advantage of short-circuit evaluation.
So instead of checking for null values I have to write code to catch exceptions when not_null throws them? great.
But that wouldn't work for all cases where "!" works. 
I'd prefer to use them, but MSVC doesn't support them by default and some Windows programmers get confused when you show them your code. So I've switched back to using the ugly operators.
`!x` emphatically does not mean the same as `x == false`. Don't do it.
Unless I'm mistaken, if `x` evaluates to `true` then `y` is not evaluated and you've still got short-circuit evaluation.
I'd argue that this is a case of PEBKAC. If you are not specifying a reference, you'll get a copy with non-auto as well. This makes sense and not "hidden".
Well yea. That's why I only contemplated it. I haven't actually done it.
Do you mean the "something == false" method or "not" mehtod (or both)? 
It's been a while since I used C++, but I think it should work similarly to js. In Javascript they're not interchangeable. "something == false" is only when "something" is exactly of value "false". "!something" is any "Falsy" value, like null, 0, undefined, false, empty string, and so on, at least in javascript, I'm not sure if C++ is the same.
&gt; Afaik, partial specializations has nothing to do with being "more specialized". See "partial ordering" [here](http://en.cppreference.com/w/cpp/language/partial_specialization). &gt; And of course you could retrofit the existing STL (in particular the algorithms) with concepts This is discussed in the ["Palo Alto TR"](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3351.pdf), the document that lead to the current design of the Concepts TS and Ranges TS, and also in Stroustrup's paper ["writing good concepts"](http://www.stroustrup.com/good_concepts.pdf). Basically, they tried to do this with C++0x concepts and failed; it led to a whole bunch of micro-concepts like `HasPlus` which basically just duplicated the implementation details of a particular algorithm. The idea with the Ranges TS is to try to give concepts broader *semantic* meaning instead: so rather than `HasPlus` you might have an `Arithmetic` concept which requires not just `+`, but also `-`, `+=`, `-=`, etc. If an algorithm is specified to require `Arithmetic` but only actually uses `operator+`, you can end up in a situation where the constrained version cannot be called but the unconstrained version can, i.e. a backwards-compatibility break. 
And I absolutely agree with you, if you deal with experienced colleagues.
Use `-Wall -Wextra -Werror` if you actually care about code quality.
Personally, I find the logical markers &amp;&amp;, ||, and ! to be easier to read. This may simply be my conditioning to using them, but I don't feel that "and," "or," and "not" actually make code any more readable. I would admit that if they were all caps, e.g. AND, OR, and NOT, then it would be difficult to mistake them for other tokens.
The hilarious part is that the standard is serious when it says the alternative tokens are identical "in all ways" to the primary token, e.g. class Foo() { Foo(const Foo bitand); // Copy constructor Foo(Foo and); // Move constructor void get() and; // rvalue-ref qualified member function void get() bitand; // lvalue-ref qualified member function compl Foo(); // Destructor }; 
Julia is another language altogether. The fact is you can't beat (in C or C++) this kind of thing:. a = b+c And no matter the types of a, b or c (scalars, arrays, matrix) it will do the right thing (or give you an error telling you why it can't do) '
[&gt;short-circuit evaluation.](https://vignette1.wikia.nocookie.net/robotics/images/4/49/Johnny_5.jpg/revision/latest?cb=20140422191506)
Wow, yeah, you're right. I should drink my coffee **before** commenting on reddit.
The problem is that 'and', 'or' and 'not' are not portable (standard). So some compilers can not compile code that uses them out of the box. Intel C++ compiler can not compile such code for example. Also having #define or || #define and &amp;&amp; #define not ! looks like a very bad idea. 
This seems to be about C# and not C++ right?
It does not work similarly to js. That's two languages very distinct. [Not and ! are interchangeable.](http://en.cppreference.com/w/cpp/keyword/not)
well thats your problem...java
How long has that been in the standard? 
Pixar did exactly that in their subd library, which did turn out to be a very bad idea and a huge pain in the ass. 
It's in the name. A *trait* is something you can observe in the qualities of a type, not something you need to stamp on types. This is the difference between observing that an object is a car based on its appearance and observing it based on the letters CAR painted on it.
&gt; The problem is that 'and', 'or' and 'not' are not portable. They have been in the C++ standard since 1998. 
Isn't that just because they are literally just `#define`s?
If x is an expression of type bool, then i dont see a difference.
Yep! I remember trying this and it not working, it was because of msvc. Maybe one day. Also after being used to it for so long it reads easier
I work with a code base that allows these with varying uptake depending on the programmer and it is hard to deal with the resulting hodgepodge of two different styles of writing the same thing. These keywords were a mistake in my opinion and I recommend not using them. 
Hi Oliver: Good to hear from you. Thank you for pointing our more recent repo. I'll use https://github.com/boostorg/context/blob/develop/src/asm/jump_x86_64_ms_pe_masm.asm next time. (amd64 on Windows is the scariest :-) ) 2) It is well defined for resumable functions. You always getting a TLS of a thread you are running on. There is no UB, since compiler is aware of suspend points and does not cache TLS page across it in non-volatile registers.
Yes, and or not. 
In C++ they are not preprocessor macros, but baked into the language as alternative tokens. In C, you can include `&lt;iso646.h&gt;` there they are defined that way. 
No, they are not defines. MSVC implements them that way, but it's not correct. Alternative tokens are required to work even when no headers are included, and MSVC fails that test.
That's my main reason to stay away from them. Might start using them at home though, at the risk of slipping them in everywhere unconsciously. 
Well, being in the standard isn't quite the same thing as being portable. Some other examples of that are export templates, two-phase name look up, and UCNs in identifiers. Yes, the 1998 spec allowed full Unicode identifiers. Compilers didn't actually start supporting it until starting around 2013.
If I recall correct, microsofts c++ compiler doesn't support this.
Yes I didn't think about that, you're right :)
These are reserved keywords in C++, so what?
You need to use the [`/Za`](https://docs.microsoft.com/en-us/cpp/build/reference/za-ze-disable-language-extensions) option, and then MSVC recognizes it just fine.
&gt; Also having code like below is very bad idea. ... that's exactly what [C did](http://en.cppreference.com/w/c/language/operator_alternative), actually.
Intuitive!
That's a pretty tautological argument
reference_wrapper then, basically not_null with different interface.
Yet the world continues to use gcc and it still turns to this very day
&gt; I remember trying this and it not working, it was because of msvc. A common refrain.
[removed]
But we are talking about C++ and not(!) about C. 
Separation of concerns is definitely one good point. Avoiding useless redundancy is another. Extensibility is another important point: you can mix and match type traits of the STL with your own and compose them in more complicated type traits *and then apply them to already existing types*. How would you extend the type traits system if all types had to internally specify the traits?
That was a response to a defect report, but I admit lumping it in with "bug fixes" might be a stretch. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/1999/n1191.pdf
Unexpected exceptions can be much nicer than segfaults, e.g. you can handle std::exception in a top level handler to prevent them crashing the entire application. Obviously how much you care about this depends on what you are building.
Overloaded "!" operator.
Use the SHOUTING NOT operator: `!!!`.
For the purpose of detecting this sort of bugs, I **much** prefer a crash: * an exception loses an enormous amount of information compared to a crash dump * exceptions are **not** bug reporting tools
The author thinks "C/C++" is a language. 
Of course. In C++, it's completely standard and portable. It's been in the standard from the very beginning. [gcc, clang, MSVC, and icc](https://godbolt.org/g/e5mUVE) all support it. The only issue is MSVC, which requires disabling compiler extensions (their recommendation has traditionally been to compile C code in C++ mode, so as an extension they turn off the alternative forms for C compatibility). The C committee, on the other hand, didn't want to add new keywords, instead going for opt-in capability by including the `&lt;iso646.h&gt;` header, which has those exact macros. C++ also has the equivalent `&lt;ciso646&gt;` header, which is empty since the language has the features built-in. I think Microsoft recommends that if you want to use MSVC and use these alternative forms and not disable all extensions that you should include this header.
You can do that with C++...
&gt; For example in Qt, an object inheriting from QObject needs a default constructor. In such case you cannot have a reference member; this is where not_null can be useful. Wait am I missing something here? You can't use a reference, and have to use a pointer, because the thing needs to model `DefaultConstructible`. How will `not_null` help then, exactly? What value are you going to default construct the pointer to?
There is no aliasing in Fortran, which can help compiler codegen. C has restrict, but nothing official in C++.
&gt; It's most useful property is that it communicates that the a function interface that uses it will not accept null values nor will it ever return them. Yes, which is exactly what references do. &gt;References are not a replacement as they communicate different things, references typically tell you that the function intends to hold onto the referenced object only for a short while (no longer than it takes for the function to return) while a raw pointer will tell you that the function will hold on the object beyond that without any assumption of ownership. These are meanings you've randomly applied to those concepts: They don't actually mean either of those things.
Looks like it's time to learn about our lord and savior `auto&amp;&amp;`.
That's just too complicated for what it does. I'll keep the concept in mind for other opportunities but in the meantime, I'll just stick to references.
I've seen Eigen beat out *MKL* on a few operations. I didn't investigate in detail, but I'm guessing the expression templates in Eigen avoided some overhead in marshaling the data required by calling out to MKL.
Normative answer: no. For many of the instructors, this is how they make their livelihood, so they understandably wouldn't want to be giving away all of their content for free.
I find it interesting that the example code triggers undefined behavior.
Always. C++98, the first C++ standard, already had them.
Hah, that's actually not a bad idea...
No. You don't catch the exceptions. You fix your code, so that `not_null` is not constructed form `nullptr`. You may forget to add a check, but you won't overlook an exception (except if you have some `try { ... } catch(...) {}` somewhere in the top.
Yea... there are more important things about editor choice than this though... :/
Not really random, it is the meaning that the c++ community mostly has been gravitating towards. 
&gt;And if he forgot to check before dereference, he also got a SIGSEGV. Dereferencing a `nullptr` is UB so it may or may not cause SIGSEGV.
&gt; Not really random, it is the meaning that the c++ community mostly has been gravitating towards. It is simply useful to see hints at what kind of lifetime the called functions except of your arguments when you call them [...] This is dangerous. This is what documentation is for. Rather than trying to apply dangerous and wildly divergent concepts onto elements of the type system that are completely orthogonal to the meanings you're trying to apply to them **document it**. &gt;if you pass a pointer you can see so directly in the code when you go back to the calling code, while references are transparent. This is some Google Style Guide level bullshit. Let's review the ways in which pointers and references differ: - Pointers can be reseated - Pointers can be incremented - Pointers can be null None of these things have anything to do with lifetime, validity, et cetera. Transparency at the call site is irrelevant: If you're that ignorant about the mechanics of functions you're calling, you shouldn't be calling them. Use pointers when you want the properties of a pointer, and a reference otherwise. Don't use a pointer because you arbitrarily decided to ascribe semantic meaning to pointers that they don't actually have and don't enforce, that's just a way to shoot yourself in the foot.
it's not not not a bad idea
&gt; It's in a parent comment. There's a link to an issue, yes, and said issue shows _pseudo_-code, not real code. &gt; I would appreciate no further exchange. Of course you do, because you're obviously just guessing. If you don't want people calling your FUD what it is then don't post on the internet!
This seems backwards; I'd rather declare that a pointer might be null, at which point I might as well just use `std::optional`
&gt; "something == false" is only when "something" is exactly of value "false". You're thinking `===`, `==` will try to coerce the type e.g. 0 will become false. In C++ null, 0, false, will all act as false for a bool. Empty string isn't a thing in a C++ bool and strings won't be automatically coerced without a manual type conversion. Undefined is undefined, the compiler may make you burnt toast in this case.
it's inherited from 80s c it's for people in foreign countries whose keyboards don't have the relevant symbols "digraphs" and "trigraphs" round out the set
For external code? Always read the documentation, true. But storing values past in as references violates the principle of least surprise I would say. Holding on to them can do things like making your object not properly copyable (since they cannot be reassigned). No, a not_null wrapper removes any ambiguity that a reference would have. 
God, you're obnoxious. *Exactly* the kind of person the world can live without. I can be helpful, but I'm *really* not going to bend *anywhere* for aggressive and abrasive ego maniacs, which you are. If you behave like a dog, you belong in the doghouse. Go be where you belong.
I saw plenty: A = (/ i , i = 1,100 /) B = A(1:100:10) C(10:) = B double precision, dimension(-1:10) :: myArray subscripts = (/ 1, 5, 7 /) B = A(subscripts) log_of_A = log(A, mask= A .gt. 0) where(my_array .lt. 0.0) my_array = 0.0 real, dimension(:,:), allocatable :: name_of_array allocate(name_of_array(xdim, ydim)) Can you write a C++ library with classes that could provide all that syntactic sugar through gnarly macros? Yes. You can do it. I can do it too. But why would we recreate Fortran in C++?
Haven't thought about that, that's a good point!
The world also continues to use WiFi, and there's more slavery in the world than there has ever been, and the Buddhists in Myanmar are committing genocide against the Muslim minority, and yet the Sun shines and the world turns to this day. People using GCC does not make it a safe tool.
There are a few more preprocessor differences like behavior of the `defined` operator and `##`/`#` after macro expansion. Microsoft won't be bothered with details. 
I think C++14 or so removed trigraphs officially.
&gt; MSVC rec It doesn't work if your project needs to include windows.h https://docs.microsoft.com/en-us/cpp/build/reference/za-ze-disable-language-extensions 
IIRC, the original reason for this was that some keyboard layouts don't have '&amp;' or '|'.
&gt; No, a not_null wrapper removes any ambiguity that a reference would have. No, it doesn't, because pointers and references can equally be maintained past the invocation of a function. You've gone ahead and convinced yourself that references and pointers have semantic meaning beyond what the rules of the language implies (they don't) and are using the supposition to infer the value of `not_null`. class MyClass { public: /// Creates a MyClass instance /// which does not write to a /// @ref Log. MyClass() noexcept : log_(nullptr) {} /// Creates a MyClass instance /// which writes to a @ref Log. /// /// @param [in] log /// A reference to a @ref Log to /// which the newly-created instance /// shall write any status messages. /// Must remain valid for the lifetime of /// the newly-created object or the behavior /// is undefined. MyClass(Log&amp; log) noexcept : log_(&amp;log) {} private: Log* log_; }; There's nothing wrong with this code. It would not be improved by using `not_null` and (conceptually) a pointer.
Call it a &gt; union
the int is initialized to zero, if that's what you're pointing out.
Do you have a source for that? All I've heard is that you **should** use that flag, and that Microsoft will never make the default mode compliant (i.e. remove non-compliant vendor extensions, implement ISO646, etc).
Since a tautology is always true, I think that means we have to get married. 
Surround it with backticks/grave accents
FontForge is great :)
It's technically correct, definitely. But like it or not in c++ the typical use of references has moved towards being used for arguments that are not held longer than until the called function returns, hence it cause surprise. I don't see any advantage of this over not_null. 
holy crap, i just looked it up yes, c++17 did. that's ... ugh
&gt;&gt; callcc()/continuation does only exchange stack pointer (register) and instruction pointer (register) Can you clarify this? My understanding was that P0534R1 is suspending entire stack, thus, callee saved registers have to be preserved together with stack base, TLS page and other registers associated with the thread (different platform may require different things to switch). Essentially P0534R1 requires to run one of the asm routines from: https://github.com/boostorg/context/tree/develop/src/ &gt;&gt; why could the mechanism of stackless thread_local access not be applied to stackfull one? In the general case, that would require some kind of marker (like await) near call to the functions that can suspend or, pessimize thread local access for everyone by invalidating the register storing cached TLS page before every function call. Note that I am talking about the general case, in some cases, if compiler can see inside of every function in the call chain and it knows that a particular library function does a suspend it can infer that property and propagate up the call chain at compile time. &gt;&gt; compatibility with the third party code that can get confused when you switch stack underneath &gt; why? for the caller the call stack looks like an ordinary call stack. The problem with third parties code is that is doing thing that you did not expect. For example, they can grab stack base and stack top and remember it (to find roots for garbage collection), if someone switched the stack underneath it will break them. I heard of a runtime that does exactly that ;-) and cannot interoperate with fibers (Windows Fibers). &gt;&gt; we have had an implementation of architectures using sliding register windows (SPARC) Good to know. How expensive is the stack switch?
Why would you still want trigraphs?
No, not quite. Specifically, this is a compiler error: foo.h: struct Foo { /* ... */ } bar.h: // forward declarations class Foo; void someFunc(const Foo&amp; val); If they were both just `class` with different default "public-ness" ( I know there's a better word for that but it's escaping me at the moment ), then this code would be fine
I learned this a few days ago, and I was under the impression it was better to use &amp;&amp;, ||, !! is it just a preference of the coder? (I'm only a C.S. student) 
Let me quickly define an "um, wrinkle" -- you take your (arguably) regular presentation, and with a bit of rhyme, just a sprinkle, turn it into Dr Seuss Appreciation Station.
for the same reason i originally did in combination with that there's no good reason to take them out, and now the test sets are that much more complex
I love how 'requires the following code' is a link to a site called 'C Programming Notes'. They mentioned C several times in the article; one would think they knew it was a different language...
You just can't stop beating that drum. Like it or not passing a reference doesn't actually mean that reference will not be maintained past the lifetime of the function, nor does it guarantee this is the case. Therefore being surprised when it is the case (because you didn't read the documentation or the implementer didn't write any documentation) is illegitimate. Your entire argument is premised on trying to shoehorn meanings into the type system which simply are not there. References and pointers have an overlapping but unequal set of features. Your argument is to use pointers where the the problem domain is contained completely within the feature set of references because you've decided that references carry additional syntactic meaning. And now you want to continue your shoehorning by creating a type that makes sure that pointers don't do something **that references don't do by default** because you're hellbent on making pointers mean something that they don't. It's perverse. Pointers and references actually have semantic meaning from the language, and you want to throw that away and pervert it to ascribe to them semantic meaning that they don't actually have at all! Besides which if references communicate that a reference is held, how do you know when you can actually invalidate any pointer you've passed anyway? **You have to read the documentation.** Which means you're reading the documentation anyway, so you could've just read the documentation, used a reference, and then gotten clearer, more meaningful code, without the noise of ampersands everywhere (and what if `operator&amp;` is overloaded? Better get used to typing `std::addressof` in anything that's a template), without inventing a type to contort pointers to mean something that they don't actually mean, and without the mental gymnastics required to glue arbitrary, orthogonal meanings onto pieces of syntax. I think it's just a deep seated terror developers have at the idea of writing, reading, or being held accountable for documentation.
Lets focus on the issues we as software engineers have control over. People use GCC because it is effective at what it does and delivers an acceptable level of satisfaction for most people in most use cases. Sure, undefined behaviour has security consequences, but lots of people don't care. In many cases, the risk is low, the worst case outcome is not that bad, and the cost of caring about security issues is higher than it's often worth. People do what they do because of money. They get by with an acceptable level of risk by using the same tools they always have, the same teams they always have, and the same static analysis tools they always have. If they make the switch to a new safe™ compiler for security issues they don't care about, they're a sucker. They have to expend a bunch of resources to change their workflow and build infrastructure. All for gains that don't have a huge impact on their own projects. I can tell you that 99% of people don't care about perfect security. Companies whose business is security, on the other hand, are probably already investigating things like what you mention, and I've already read about C compilers that define behaviour for many cases that the standard leaves as undefined. You can be as angry about the status quo as you want to be, but nobody is going to be moved by that.
&gt; creating a reference from a null pointer is undefined behavior Incorrect: You don't create references from pointers. It is undefined behavior to dereference a null pointer, whether or not the value is used, whether or not the value is bound to a reference. What you're proposing to do with `not_null` doesn't really make a lot of sense: `SomeFunction` doesn't (logically) take a pointer as it (apparently) doesn't increment/decrement that pointer, and doesn't accept `nullptr`. What you actually want is: void SomeFunction(int&amp;); // ... int* ptr = nullptr; // ... assert(ptr); SomeFunction(*ptr); All you're doing with the construction you proposed (featuring `not_null`) is complicating the call site of callers which don't synthesize a reference to a pointer: int i = 5; SomeFunction(&amp;i); Which becomes even worse in templated code: template&lt;typename T&gt; void CallSomeFunction(T&amp; t) { SomeFunction(&amp;t); // Incorrect, what if operator&amp; is overloaded SomeFunction(std::addressof(t)); // Correct, verbose, hard to remember, unnecessary } Moral of the story: - Use references, pointers should be almost never used - Check for UB/logical errors where they occur rather than shoehorning them into places they don't occur and to which they have no relation
It is coming from Bjarne, therefore it is totally C++.
yea i can grep it way better with not
what is the difference between &amp; and &amp;&amp; in cpp?
I'm still surprised that restrict hasn't made it into C++.
Why would you use macros?
&amp; is the bit operator. &amp;&amp; is the logical and.
&gt; semantic meaning beyond what the rules of the language imply These are called 'idioms', and are generally regarded as a good thing. ;-]
So I'll just refer to lvalue references as bitwise references and revalues as logical references then...
&gt; for the same reason i originally did Which would be...? Not having a keyboard with the symbols? :P 
or just for(auto&amp; v : myarray) v = std::max(v, 0);
Except in this case the supposed "*idiom*" is completely orthogonal to the feature set of the language features in question, which this `not_null` discussion indicates: The idiom shoehorns developers into using pointers (which can be `nullptr`) for parameters which actually can't/shouldn't be `nullptr`, so they then try to contort the language to get dynamic checking for `nullptr` rather than using a language feature which can't represent `nullptr` (i.e. a reference). `not_null` isn't a good thing, nor is it a fix, it's a hack that's a symptom of a disease. If something can't be `nullptr` it probably shouldn't be a pointer. Even if you're reaching for a pointer for the iterator-like properties you still probably don't care if it's `nullptr`: In that case all you care about is: assert(ptr || (size == 0)); or: assert((begin &amp;&amp; end) || (begin == end));
keyboard layouts haven't changed since then
What about forwarding references?
Watch cppcon every year (one of the best sources for learning about new features in C++), read this subreddit (and of course blog posts linked from it). If i need more info/reference then I look at cppreference. You don't really need more to stay up to date.
Usually, every major revision gets a wave of blog posts summarizing the changes. Continue subscribing to this subreddit and you should remain in the loop. 
&gt; /Za is C1XX’s option to enable extra conformance, but it also enables extra compiler bugs in rarely-used codepaths, so we discourage its use. from https://blogs.msdn.microsoft.com/vcblog/2015/12/07/stl-fixes-in-vs-2015-update-1/ Or of course you could just ask /u/STL and he'll tell you himself.
[An old email][1] from /u/STL. [Here's][2] a more recent comment from him that things in their standard library implementation have been fixed, but that the flag still isn't recommended. [Here's][3] some further discussion that also mentions a planned replacement for `/Za`, which some quick testing indicates has the correct behavior. As long as it's still tested and recommended it looks like `/permissive-` is the flag to use, and my statement that MSVC doesn't correctly support these alternative tokens was out of date. [1]: http://clang-developers.42468.n3.nabble.com/MSVC-Za-considered-harmful-td4024306.html [2]: https://www.reddit.com/r/cpp/comments/3ikcli/why_cant_you_run_a_single_c_file_in_visual_studio/cui01nc/ [3]: https://www.reddit.com/r/cpp/comments/55gugf/cppcon_2016_carroll_moth_latest_and_greatest_from/d8e3mld/
also put them to use with side projects
That's a lot shorter, yeah. But the nice thing about the algorithm is that once libraries implement C++17, it's trivial to make it parallel for really big data sets, which since we're talking about high performance number crunching might be desirable. You could use OpenMP with the explicit loop after making some changes since OMP doesn't play well with range based for loops, and it's just as verbose and ugly. Smart thing if it's a common task would be to wrap it up in a function that hides the implementation details like those.
&gt; there's no good reason to take them out, There is, actually. It messes with strings. You write `"??!` and nonsense comes out.
I understand, but am sad. The workshop looked interesting.
Why would/should the lexer recognize digraph tokens inside a string?
Beware dangling references … I'd like that to work, enough to write P0066 and https://github.com/potswa/clang. But last I knew, the leadership would prefer to make `auto` the uniform recommendation, over fixing `auto&amp;&amp;` to do the right thing. 
I remember coming across this a while ago and having a good laugh. The article does seem to have been improved since then, but it's still pretty poor. The whole "heap allocations in containers" thing is clearly nonsense. The "iterators" section claims that "iterators are hard to implement efficiently", which may have been true 20 years ago but I doubt any current C++ compiler has trouble with them. It mentions that "ranges have been proposed for the standard library", without mentioning that the whole point is that range are implemented *on to of* iterators. The "uniform initialization syntax" section actually makes a good point. The whole not-actually-very-uniform construction idea was probably the biggest mis-step in C++11, and now we're stuck with it. Exceptions... well that debate has been done to death here and elsewhere. Either you like them or you don't. But fair enough, people do criticise them. While I agree that C++ could use much better Unicode support, the criticisms in that section seem a bit misguided. There's no one single answer to what "length" means for a Unicode string, and the number of code units (which is effectively what `std::basic_string::length()` returns) is one possible answer. I'm not sure what's going on in that example either. 
Because they weren't just for programming syntax. The symbols were considered to be part of the standard alphabetic set. &gt; The ASCII special characters [, ], {, }, |, and \ occupy character set positions designated as alphabetic by ISO. In most European national ISO-646 character sets, these positions are occupied by letters not found in the English alphabet.
Forget C++11, the author doesnt seem to be aware of C++98, or even C++ at all.
No one really uses it for C++, for Python though you have to use 'and', 'or', 'not', you can use '! =' though for example.
Regularly checking on the LLVM status pages (clang, libcxx), MSVC blog and STL tweets in my personal, free time. I have to compensate for the WinCE development I do at work from time to time …
Yeah, `/permissive-` is tested and recommended.
IBM opposed removal very much, reporting they sill support systems using EBCDIC encoding that has problems such symbols. See [N4210: IBM comment on preparing for a Trigraph-adverse future in C++17](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4210.pdf)
 Strictly speaking, these are not keywords, these are alternative forms of lexer tokens for those operators. 
Join the standards committee :-) Actually, that's just worst - you then need to keep up with all the latest features as well as all the almost-features. ie all the proposals that in the end, don't make it into the standard. It is actually not possible to keep up.
And they were off by default, so that wouldn't happen unless you went out of your way to turn them on. And that's very easy to handle. In the meantime, the test sets still have to account for this
I've unfortunately found it quite difficult. Most C++ jobs are limited in a way that makes using modern constructs an uphill battle to say the least. Kinda sucks. C++'s long legacy could keep C++ down forever.
I just stay up to date with a few versions less than the latest and greatest. Anything further than c++11 right now isn’t very practical to keep up with for me.
I see!
&lt;insert obligatory sales pitch about how you should come to CppCon in person next year&gt;
I'm keeping up with the new additions to C++, Java and also setting my foot in Python for linux tooling. Relearning C++ turned out more time consuming than learning other programming languages. 
&gt; enables extra compiler bugs Sounds like a feature to me!
&gt; And they were off by default That depends on the compiler :/ &gt; the test sets still have to account for this What test sets?
Be careful, trying to follow the latest features quickly becomes a drug. The deadline for the next mailing was yesterday and I wish I could already read the new proposals :o
That's easily solved by project style guidelines. I would recommend the opposite, use the keywords. But whatever you do, be consistent within a project.
IMO that's too vulnerable to typos. 
In addition to the specific guidance below not to do this, consider putting the constant first in equality tests. That way if a typo eats the '=', you get a compiler error instead of a bug.
If you're going to argue like that then `x` also means the same as `x == true` so please start using the latter everywhere. (No. Don't.)
This is one of the very few cases where I think verbosity is good and improves clarity (I generally avoid verbosity religiously).
Along with what others have mentioned I like watching Jason Turners C++ Weekly on youtube. 
Could they still be processing?
If it's an overloaded operator!(), then you'll be surprised.
my bet is they don't want to release them all at the same time, but instead keep them coming day by day - even the current pace is overwhelming if you watch every single one of them
I will do that if it improves readability.
Id argue that if you overload operator! for bool in the global namespace, you have bigger problems.
Ignorance: for people who don't care about understanding.
C++17 w/ Boost.Hana: std::replace_if(std::par_unseq, begin(myarray), end(myarray), hana::_ &lt; 0., 0.); with ranges: std::replace_if(std::par_unseq, myarray, hana::_ &lt; 0., 0.); Succinct enough for me.
Sure, it's not portable, but that's because of non conforming compilers, not because it's not standardized. 
That's probably because you normalize English words as communication over other words.
Symbols are words.
&gt; I like watching Jason Turners C++ Weekly on youtube. Thanks for the recommendation! Just subscribed to him.
Bullshit. That is a good feature. If the coder is clueless about how to use references he should be humble and learn, or just find another job. 
they expose too much
I don't think you're asking the right question – you need to first know what a trait _is_ before asking why they look the way they do. ;-] /u/TemplateRex wrote a good overview in an SO answer: [What is the difference between a trait and a policy?](https://stackoverflow.com/a/14723986/636019)
My grandmother used to sometimes criticize my grandfather because "he likes too much salt on his meat". While I don't doubt that somebody, somewhere has criticized C++ on each and every cited basis, quite a few of them have about the same relevance to the world at large as the difference in taste between my grandparents.
I very much doubt that's what they meant... It's a not-unusual operator to overload for UDTs.
&gt; Empty string isn't a thing in a C++ bool and strings won't be automatically coerced without a manual type conversion. String literals will. `if ("foo" == true){ x(); }` will call `x` (and `if ("" == false){ x(); }` won't).
Right, and the original comment was "it's not portable." Not "it's not standardized." GP: 'and', 'or' and 'not' are not portable. OtherGuy: They have been in the C++ standard since 1998. Me: Being portable and being in the standard are different things You: They're not portable because of non conforming compilers, not because it's not standardized. 
Fantastic talk!
You're doing something wrong if you don't have these 3 flags set at minimum.
&gt;The other day I saw a bug in production code where `&amp;&amp;` got mistyped with `&amp;` yielding an unexpected result. I wonder if using `and` and `bitand` respectively could prevent that from happening. That's exactly why I've been using them for years. It matches your inner monologue better. 
But why? For me it's far easier to understand ```!x &amp;&amp; !y``` than ```!(x || y)```. For the prior I can easily see that the expression is true only if x and y are both false. But for the latter, I need to think what x || y is, and then 'not' that. In other words I can comprehend the prior in one pass, but the latter takes 2 passes. Do you comprehend it the same way?
When's the last time you said 'not a and not b' out loud, vs. 'neither a nor b'? `!(x || y)` just flows better for most people. They're semantically identical though, so it's ultimately subjective.
Captain DeMorgan
Yeah it's definitely a matter of taste. The last time I said it out loud was in reading that expression haha. But it's interesting, you say "neither x nor y" but for me when I hear that I think it means ```!x || !y```, which is not ```!x &amp;&amp; !xy```.
All the more reason it should `abort()` instead of throwing an exception. 
I wish they'd move it to implementation-defined.
Maybe we need an editor that magnifies the ! character. In any event I tend to agree with the idea that it is sometime shard to pull that operator out of text. In part using ! directly in front fo the conditions is often the root cause of readability issues. I wold lean towards verbose.
Any decent debugger will break on an exception throw so you don't lose any information if you debug. And you might not want to crash your whole program over it.
You can even make it way bigger, but you wouldn't have a monospaced font any more.
If you use the feature it wouldn't be obscure. Frankly I don't think it is obscure. In any event you sort of prove one point here, using this feature makes your code easier to understand for people coming form other languages. In a mixed environment you can gain productivity if you avoid the more cryptic approach to writing C++ code.
yep a bit of air space and real English words actually reduce the parsing load on the reader.
Well I have a solution for you: `#define nor ....`
Well if even half the libraries compiled without warning at `-W4`, maybe I'd think about it.
Yes, of course, I am talking about when my code is running without me around (production).
&gt;In addition, not_null works with *owners*, whereas a reference cannot express any ownership semantics. What? Why not? You can call delete on a reference. And it'll fail a code review - just like calling delete on *anything* would (in our codebase anyway). 
I would probably buy a keyboard with the symbols I use on it. 
But that' the entire point. with `not_null` you can get this behaviour and it'll be fined and consistent. With the regular references the bug may persist in you program for a long time. Basically, instead of constantly checking for `null` (pointers) and hoping you didn't forget to do that and hoping that whoever supplied you the reference did his checks (references), since there is no way for you to find out if you are already in the UB territory or you are fine, `not_null` allows you to enforce the `not null` property at the time of the creation (so if it throws, you immediately know where to add a check). After that it's just acts as a regular pointer/reference but you can be 100% sure that it's correct.
You can do this in any Electron-based editor.
Cool story, bro. They did.
Looks like it's time for ... (((((x == true) == true) == true) == true) == true) == true ...
&gt; You can call delete on a reference. No.
Oh my, I completely overlooked it.
[Are you sure about that?](https://godbolt.org/g/CcyoZq) Granted, that doesn't mean I didn't hit UB in there.
You're taking a variable's address – that's deleting a pointer.
Include [`&lt;ciso646&gt;`](http://en.cppreference.com/w/cpp/header/ciso646) or disable language extensions: &gt; *Properties &gt; C/C++ &gt; Language &gt; Disable Language Extensions* Alternative tokens (digraphs) are supported but the language extensions makes MSVC non-conformant ([lex.digraph]).
I dunno, but I've never run into the problem that `not_null` is supposed to catch. Maybe it's just the kind of software we write doesn't hit the cases where null pointers can creep in. 
Sure. I misspoke. What I meant to say is you can call delete on the address-of a reference. Which was the only reason I could think that the other guy would say that references can't encode ownership semantics. 
http://en.cppreference.com/w/cpp/compiler_support http://www.open-std.org/jtc1/sc22/wg21/docs/papers/
have an upvote
That's NOT easily solved with project style guidelines because those are routinely ignored. 
Thanks man, appreciate the advice.
Step two, convince all your coworkers to install your new font so they don't miss your nots.
The deadline was yesterday and I wish I could have already written my new proposals. :-(
`delete &amp;expr;` is probably wrong 99% of the time no matter what 'expr' is... The fact that it's technically possible doesn't really mean much because it ought to stick out like a sore thumb. I'd be surprised if there's not a lint for it.
I saw code like this just yesterday: ``` if (!something-&gt;foo()-&gt;getSetting() == Setting::SomeSetting) ... ``` Note the ! on the front. :-( On an enum. Of course the enum it really wanted was 0 and SomeSetting was 1, so it "worked". (This was the result of `isSetting()` (boolean) being replaced by `getSetting() == SomeSetting` and in one place `!isSetting()` got replaced by `!getSetting() == SomeSetting`.) (This is also a result of `!` being hard to read AND having so many foo-&gt;bar-&gt;next-&gt;thing... that you can't even see the beginning of the line)
Don't not !do that.
&gt; Always. C++98, the first C++ standard, already had them. That's crazy. Hmm... Learn something new every day.
No need to, still using VS2013, and will not upgrade for at least a year.
It doesn't.
There's an easy fix for that. T *p = &amp;v; delete p; // :) 
&gt; 'Undefined' isn't a thing in C++ Not undefined value, [undefined behavior](http://en.cppreference.com/w/cpp/language/ub) &gt; and neither is === Sure but [deleted] was talking about Javascript in that quote.
&gt; Intel C++ compiler can not compile such code for example. Um, what? https://godbolt.org/g/HDBAvB C++ Operator names are part of the C++98 spec and are supported by all but MSVC.
Boo for deleted comments. ;-/
To me, 'neither' implies a grouping of things that will be all be false, which is most easily expressed with `!(...)`. :-]
Obviously it won't help in this case. I was thinking about functions or objects using these members. If you have inner functions, or objects used by a QObject, enforcing usage of not_null in their interfaces may help.
The cost of doing so, if not paid by a company, is prohibitive to quite a few people, I imagine. And from what I understood there really isn't much point in sending in proposals without also having someone at the meetings to defend them. 
2) Yes, the problem of callcc()/continuation - P0534R1 - is that it lacks compiler support. I'm sure that the same optimization as for resumable functions could be applied to call-cc/P0534R1 especially for TLS (but then its not a pure library-based solution)
That particular error was caused by the code like: x = char(tape &amp;&amp; 0xFF) which incorrectly evaluates to 1 for all non-zero `tape`. The intended form is obviously x = char(tape &amp; 0xFF) As you can see the logical operator converts its arguments to booleans, while bitwise doesn't.
On top of the nice blog post that are mentioned here, I often peak a look at the C++ Support in gcc and Clang, If you think it's overwhelming at first, it's alright, the list is not updated too frequently, eventually you will have sound knowledge about every items mentioned in their list - [gcc](https://gcc.gnu.org/projects/cxx-status.html) - [clang](https://clang.llvm.org/cxx_status.html)
Yeah that is definitely something you need to learn! However I did not expect it when I started using references and added `auto`.
P0534R1 - call-cc suspends the associated stack. Because boost.context is a pure library solution, the code could not know which callee saved registers are used before the context gets suspended. so it has to preserve all callee saved registers. P0534R1 could benefit from compiler support as resumable functions do, e.g. the compiler does know which special callee saved registers are in use before suspending the context. In an extreme case no callee saved registers are used and thus only stack pointer + instruction pointer hast to be preserved/restored. SPARC support has been removed (was not ported to call-cc semantics) but was working. I did not measure on SPARC; on X86_64/SYSV a switch takes 11 CPU cycles (including preserving all callee saved registers).
Then enforce them through code review. This can even be automated. Reject commits to master that don't conform. I know plenty of cases where style guidelines are successfully enforced.
&gt;Error, class Foo is not Agile, consider using Agile&lt;Foo&gt; instead for extra performance overhead and no benefit. Got to love some of MSVC's 'warnings', the crap ones are on-by-default and the good ones are off-by-default. 
I think even with all the mistakes one has to admit, that even with libraries like eigen, There are some syntactic feats you can't quite accomplish in c++. That being said, it seems the main reason for still using Fortran is the large existing code base. But to be fair: the only reason a lot of programs are written in c++ is for exactly the same reason (huge amounts of legacy code)
CMake compiler detection fails for me: λ cmake -G Ninja .. -- The CXX compiler identification is Clang 5.0.0 -- Check for working CXX compiler: C:/Program Files/LLVM/bin/clang++.exe -- Check for working CXX compiler: C:/Program Files/LLVM/bin/clang++.exe -- broken CMake Error at C:/Program Files/CMake/share/cmake-3.9/Modules/CMakeTestCXXCompiler.cmake:44 (message): The C++ compiler "C:/Program Files/LLVM/bin/clang++.exe" is not able to compile a simple test program. It fails with the following output: Change Dir: C:/Users/User/Documents/cpptest/build/CMakeFiles/CMakeTmp Run Build Command:"C:/bin/ninja.exe" "cmTC_a4980" [1/2] Building CXX object CMakeFiles\cmTC_a4980.dir\testCXXCompiler.cxx.obj FAILED: CMakeFiles/cmTC_a4980.dir/testCXXCompiler.cxx.obj C:\PROGRA~1\LLVM\bin\CLANG_~1.EXE /nologo /DWIN32 /D_WINDOWS /W3 /GR /EHsc /MDd /Zi /Ob0 /Od /RTC1 /showIncludes /FoCMakeFiles\cmTC_a4980.dir\testCXXCompiler.cxx.obj /FdCMakeFiles\cmTC_a4980.dir\ -c testCXXCompiler.cxx CLANG_~1.EXE: error: no such file or directory: '/nologo' CLANG_~1.EXE: error: no such file or directory: '/DWIN32' CLANG_~1.EXE: error: no such file or directory: '/D_WINDOWS' CLANG_~1.EXE: error: no such file or directory: '/W3' ...
This was my first thought too, but the article links a Stack Overflow question which has a reasonable answer to this: equality on `reference_wrapper` is equality on the contained type, whereas equality on `not_null` is pointer equality.
Youtube displays _this video is unavailable_ for me. No hint to a private Video.
Well you better remove the "xx was not inlined" and "xxx padding was included" among others. MSVC is trying to change for the better I think, but they have a big responsibility with large companies not to break their existing non conforming code (which is mostly their fault, but it's too late to fix VS2012-). Since 2013, there has definitely been big steps towards conformance, and we're finally going to get templates right apparently.
Watch CppCon and C++Now. Follow the C++ blogs and Channel 9's going native.
Every time I need to integrate C++ code into our Java or .NET applications, it usually looks like it would compile just fine with Turbo C++. It is quite sad how many just don't care about moving forward.
Yeah, but those two are only enabled at /Wall (which is the silly level ALL THE THINGS). The one I described is a constant pain in C++/CX if you have /Werror.
Thanks for the recommendation.
I wasn't saying you couldn't but maybe it is a good to wonder if you should in the first place :P
Well you should obviously never use macros in decent C++ code, if you really need something harass the committee into making it a codeword.
&gt; Your entire argument is premised on trying to shoehorn meanings into the type system which simply are not there. No it isn't. Using pointers in situation X because they have a property that's considered useful for X (in this case, call site transparency for output parameters) does not in any way imply that the _definition_ of pointers is about X.
You always have to filter some warnings for /Werror with any realistically sized project. Especially if performance is critical.
&gt; provide all that syntactic sugar through gnarly macros? No need for macros. auto A = make_array(1, 100); auto B = make_array(A, 1, 100, 10); auto C = make_arrray(B, 10); typedef Array&lt;double, -1, 10&gt; myArray; auto subscripts = make_array({1, 5, 7}); auto B = make_array(A, subscripts); auto log_of_A = map_array(A, log, [](auto a){ return a &gt; 0; }); for_each(my_array, [](auto a) { return std::max(a, 0);}); shared_ptr&lt;dynamic_array&gt; name_of_array = std::make_shared&lt;&gt;(dynamic_array(xdim, ydim)); The above code is very readable, there is no need for macros. &gt; But why would we recreate Fortran in C++? Because C++ has a lot more to offer than Fortran. 
Although the article doesn't mention aliasing, in practice C++ popular compilers can see, in most cases, that there is no aliasing and optimize code on par with Fortran. 
I have been using them for a long time and I really prefer them to the symbolic ones, especially since the symbolic ones are not that intuitive to begin with. Aside from the big advantage of being more pleasent to read especially in the more complicated expression, I'd like to point out, that at least vim will highlight them in a different color thereby increasing the visual structure even more. Aside from people having problems with Microsoft apparently ignoring the standard for now (I'm not using Windows and therefor not VS, so I cannot verify that) I would definitely recommend to use at least `and` and `or`. 
So you think it is better to teach people to return a pointer to a member instead of a reference (which is completely unidiomatic in c++) than to teach them how auto works (which they need to know anyway)?
So you think it is better to teach people to return a pointer to a member instead of a reference (which is completely unidiomatic in c++) than to teach them how auto works (which they need to know anyway)?
No! where did I say that? I wrote the complete opposite: _Yeah that is definitely something you need to learn!_
&gt; But why would auto become a copy of the object rather than the reference anyway? It has the same rules as template argument deduction (except for `std::initializer_list`s, but that's not really important). If you want references to deduce as such, use `decltype(auto)` instead of `auto`.
it's very simple: if the code using the keyword as an identifier is inside the binary, then no worries. If the code using the keyword is in source code, then a simple #define before the inclusion of said header and an #undef after the inclusion is more than enough. 
`arrray` the contiguous buffer class that is also a pirate.
&gt; Well, given my understanding of inline, it makes 100% sense to me. It makes sense because you are not using the word 'inline' to convey information about what it does, you already know the meaning. 'Inline' means 'inside the line', which is totally meaningless for the one definition rule. &gt; What alternative do you suggest? Every definition in headers to follow the ODR without any keywords. Why would I ever want to to have multiple copies of the same function inside my program? 
&gt; It has the same rules as template argument deduction That's what I found as well, though I did not look at those, yet. &gt; `decltype(auto)` Thanks for that hint! I did neither know about this nor expect it to work. But it works. And it also looks horrible. I'll rely on learning and teaching.
Type traits are implemented the way they are to enable meta-programming: - you can easily pattern match on types using template specialization - you can easily write generic meta-programming code that works on any type trait because all follow the same `::type` interface (this is true even in post C++11 meta programming libraries, and the same can be said about `::value`).
In the end this kind of choice will always have to be made based on the organization's/team's/project's preference. I.e. you do what the code base you work with does. But personally I will always value human-readability far higher than having to type less. And I also want to point out that there is a tendency amongst new programmers, CS students, computer nerds etc. to use way too much and way too intricate lingo. This often makes code unnecessarily complicated and error-prone for the sake of the coder appearing knowledgable. 
Is this true with the latest version of visual c++?
Clang has it default: https://godbolt.org/g/qQX5GV GCC also has it default: https://godbolt.org/g/wUMs45
*Should not use macros for stupid things. Macros are unfortunately still useful in some cases.
Yes, unless you compile with `/permissive-` (which you should if you can) or `/Za` (just don't).
I will be asking you questions, please do not answer to them, remember, you can't engage in "further discussion". When I ask: &gt; Name one open-source project that does this, please. And your answer is: &gt; Why? Don't you think it is ridiculous? I'd expect to get such an answer from clown. Are you clown?
Except for the fact that -Wextra contains a lot of warnings that are just borderline retarded. 
If you use the convention that references are always passed const, and you use pointers for "mutable references", then not_null makes a lot of sense.
Yes, and `and` is intricate, or `or` is not, not `not` is an option compared to `!`!
Stop that. We live in the era of modern C++. Follow DRY, and use fold expressions over parameter packs of bools all knoen to be true. (x == ... == trues); 
Read WG21 mailing lists, conferences, blogposts, Slack, StackOverflow, etc...
&gt; But it works. And it also looks horrible. Agreed, it's horribly verbose for local variables. -- &gt; I'll rely on learning and teaching. That's all any of us can do, friend. :-]
There were well over 100 presentations this year, plus lightning talks, etc. The folks at Bash Films spend a good bit of time in post production for each one. I expect they are releasing them as soon as they are ready.
Apparently this only goes there with examples. Lets pick an example with a breaking keyword change, for example before noexcept was introduced and after. // old library, before noexcept was a keyword class noexcept { public: noexcept sum (noexcept&amp; data); }; // Now noexcept is a keyword, that I want to use noexcept process_data(noexcept input) noexcept { noexcept other; return input.sum(other); } Feel free to use a simple #define to pre-process to noexcept identifier to something else, while keeping the linker and compiler happy. No source code available to the library, other than the header file. 
&gt; Every definition in headers to follow the ODR without any keywords. Why would I ever want to to have multiple copies of the same function inside my program? My experience in a big code base with 100 programmers is that people often make a mistake and put something in a header file that's not intended to be there. By default, they get an error and either need to mark the function as 'yes, I intend this to be inline', by adding the inline keyword, or move it to a cpp file. I like this mechanism because it prevents mistakes. 
did you learn it here? https://www.youtube.com/watch?v=ovxNM865WaU&amp;feature=youtu.be&amp;t=50m
May be on *nix intel compiler support this but on windows inside of VisualStudio this does not compile. Probably because intel compiler trying to mimic VS compiler behavior. Also using '/Za' to allow such code is really bad idea. 
It won't cause SIGSEGV at the call site because it isn't a "real" (machine level) dereference. 
Yeah, that makes sense. But I don't feel like set&lt;T*&gt; with pointer comparation would be a very good idea. Using pointer values as identifiers can be limiting, and can only get you as far as you don't start passing references or start using threads and want every thread to have thread-local version with the same id. But if not null works for smart pointers (or the other way around) then I agree with its usefullness.
I'm already not a big fan of `auto` popping up everywhere. `auto&amp;&amp;` is an abomination.
Some areas of C++ are not fit for mortal men to know of.
Nope, found out by accident. I'm surprised that so many people know that this is a thing, never seen it 'in the wild'.
Got any examples?
Have a cpp project in your spare time. Outside the confines of a day job you can install that latest bleeding edge compiler. Just need to think of something challenging enough to use it on.
I subscribe to the isocpp.org RSS feed. They usually share blog posts not only about new language features, but also about techniques, patterns useful tools etc.
I'm stuck in the past and only get to focus on opengl es 2 right now :(. Glad to hear that the modern apis mirror the design though.
I know they are, but the language is trying to get new features in so that macros aren't necessary anymore.
That's my kind of talk.
`if (__LITTLE_ENDIAN != __BYTE_ORDER)` is obviously wrong. Should be `if constexpr (...)`. And if you are not Google (chances you aren't), do not leak memory from functions like `MyConstant`; if I had 10 libraries doing this, I'd have 100 leaks thrown at me by Boost.Test, and what do I do? How do I know if they are real leaks or not? How do I find my own leaks? Google might have fancy tools to answer these questions, you don't have, so you shouldn't leak like that. If you are small company, use constexpr std::string_view at global scope.
A blog post about mundane uses of a 20 year old feature.
The fundamental reason why type traits are written this way, is exactly the same as the general reason why you should prefer free functions in interfaces over members unless you have a specific reason: - an interface that depends on free functions can be implemented for built ins. See, for example, begin(v) vs, v.begin(). The first form can work even if v is a C array. This is esp important for type traits because so many type traits deal specifically with primitives (is floating point, is integral, etc) - An interface that depends on free functions can be implemented for types non-intrusively. That means I can define the trait for a specific class (specialize it) even if I don't own that other class. The biggest exceptions btw, where you would use members, are either because the function needs to access private state, or to access virtual dispatch. Neither of these considerations apply for compile time traits.
&gt;I'll just stick to `&amp;&amp;` and `||`. You mean &amp;&amp; &amp;&amp; ||
If they could stop making the language larger ever year, that'd be great :p
&gt; But why would auto become a copy of the object rather than the reference anyway? You can't "copy" references since they aren't objects. This is also why you can't e.g. have references to references, or pointers to references. Also, if it became a reference, how would you make it a copy of the object instead? It makes perfect sense to me that `auto` is never a reference and `auto&amp;` is always an lvalue reference. In both cases, `auto` becomes a type without ref-qualification, just like a deduced type does in templates. `auto&amp;&amp;` is the only confusing one here, which breaks that rule.
I liked the bit about versioning patches coming from library authors, but I'm not sure that's something Google can control.
not by default. valarray might do the job provided that it were actually maintained.
I guess MSVC will get this in... 20, 30 years time? :(
I suppose on my first point I'm corrected. To me this seems to make the situation worse, rather than better.
Reference wrapper is just annoying to use for class types because you can't directly access fields/functions with `.`, you have to do `.get().`. That's a really long way to type `-&gt;`.
Honestly `auto&amp;&amp;` in non generic contexts is a horrible idea. If you are going to mutate something, it makes a semantic difference whether you are mutating a copy or not. `auto&amp;&amp;` obscures this and can allow behavior to silently change during refactoring. Basically, your options should be: - `const auto&amp;` if you aren't going to mutate. If you aren't going to mutate something anyway it doesn't matter whether you received a copy or not. - 'auto&amp;' if you want to bind to something that you want to mutate in place - 'auto' if you want a copy of something, and then to mutate the copy - 'const auto' for rare situations where you are dealing with primitive types, aren't going to mutate, and care about performance.
It's not about performance. I'm sure that with correct compiler flags any idiomatic C/C++ can be as fast as Fortran. It's about ease of use.
It already has incremental LTO; not exactly the same, but it's naive to think MSVC's LTO is anything but first-class.
I read the papers published and follow the evolution of the different proposals there and on the public discussion groups. It takes time but if you are interested enough it's more interesting than cat pictures.
I realize that this being cpp reddit people will tear these physicists a new one, but as an ex-physicist I left a comment there that might be somewhat informative to some here: Physicists are not stupid; the average physicist is quite a bit smarter than the average programmer (source: I've been both). It's just that physicists are spending so much time absorbing other new knowledge, about their actual field and domain, that it can be hard to try to absorb more. I realize that this doesn't make sense, you can always say that instead of programming for 2 hours Thursday you should have spent 2 hours learning C++ so that the rest of the month you are more efficient. But it is just more difficult, both in actuality and psychologically, to spend those 2 hours learning C++ when you already spent 6 hours that day attending excruciatingly hard classes and reading excruciatingly hard papers. Paul Graham has a pretty good essay: The Top Idea in Your Mind. He talks about how as soon as his startup or whatever went into fundraising mode, technical productivity dropped a lot. It wasn't because fundraising took so many raw hours. It's because, he would wake up and think primarily about fundraising, not solving technical problems. It's the same with physicists. Yes, it would make more sense to learn to program better. But it's just not the idea a the top of people's minds.
Yes, as you can implement a very complex data structure with pointers in Fortran. But I don't want to have to mantain that.
you could be hurt if you watch some of them unprepared.
Love the built-in routing. How do streaming responses work?
I use the following resources for keeping up-to-date with the latest C++ features: Follow Conferences on YouTube - CppCon - BoostCon - code::dive - ACCU Awesome Speakers - Chandler Carruth - Stephan T. Lavavej - Andrei Alexandescu - Bjarne Stroustrup - Herb Sutter - Scott Meyers - Jason Turner - _many more..._ Mailing lists - Boost developers - SG14 And finally, I try to contribute to C++ projects on GitHub.
MS Visual Studio
It's the fucking schools! They're still using books written in the 90's if they're teaching C++ at all.
Its a fun api, and I will raise a drink to the pain of being stuck with OpenGL ES2 :(
My apologies if I was too terse with my Why? response. Let me expand on it a little. This was in the context of the discussion about limitation of stackful coroutines, and one of the limitations discussed was inability to access thread_local storage safely if you multiplex M fibers/stackful coroutines on top of N kernel threads. I provided you with an example https://godbolt.org/g/BQXSHq that demonstrates that compilers may cache TLS page in callee-saved register that are not reloaded after suspend/resume. After I gave you this example you asked to find an open source project that uses boost::coroutines/fibers in this manner. I interpreted your response as tacit acknowledgement that you recognized the limitation and now shifting your argument from "problem does not exist" to "problem does exist, but it is not relevant since nobody uses stackful coroutines in this manner". In this context my "Why?" meant "Why? If such project exists it has a latent bug, if all of the projects never migrate stackful coroutines from one thread to another or if they do, they don't use TLS or libraries that use TLS under the covers, they are probably aware of the limitation and learned to live within those constraints. Presence or absence of such projects does not make the problem of using TLS in stackful coroutines disappear. Therefore I see no reason *why* should I start looking for such projects. Presence of absence of such projects does not invalidate my point that stackful coroutines constrain the developer on what facilities you can use in them. TLS being one example. Stackless coroutines have no such constraints. Hopefully with this clarification the sentence I actually wrote would be more clear: &gt;&gt; Name one open-source project that does this, please. &gt; Why? My point is that stackful coroutines constrain the developer on what facilities you can use in them. TLS being one example. Stackless coroutines have no such constraints. 
&gt; How do streaming responses work? I'm not sure that I get you right, but if you mean what is the mechanics that takes place when you call *.done()* on a response builder then it depends on a type of builder. For default one the following logic is executed (simplified): * The header is serialized to a raw buffer (its a std::string, but it is an implementation domain and might change in future). * Response body is considered as it is, it can consist of one or more buffers. * So a vector of buffers is formed and an write-activation callback is [dispatched](https://chriskohlhoff.github.io/networking-ts-doc/doc/networking_ts/reference/dispatch.html) on *asio::io_context* restinio is running on. * Write-activation callback knows http-connection context object and passes (moves) provided buffers to it, so a socket write operation can be initiated. If underlying socket has no write operation running at the moment - a write operation is initiated, otherwise buffers are stored by connection context and will be sent later. I didn't mention how timeouts and pipelining are involved here, but this still gives an accurate picture of what is going on.
CLion is also from JetBrains and in my opinion is much better than Visual Studio, at least if it doesnt have any plugin like Resharper C++ or Visual Assist X from tomato software
C++, where folds are only half baked and hidden in numerics. After std::future::then the second most obvious example that this community lacks a lot of functional programming experience... Jokes aside: if you can spare the time make a vacation in monad-land :)
That is the same sub list of YouTube for C++, i also has NDC Conferences wich is a general programing con but usually it also has some C++ stuff and it keeps you update with new tech and interesting stuff Is a waste that Scott has retired from C++, he was by far my favourite speaker and i really like his books
C++ support of NetBeans is is surprisingly good.
Yes, of course, I'm sorry.
With VisualAssist
The [overview page](https://bitbucket.org/sobjectizerteam/restinio-0.3#markdown-header-what-is-it) you linked to is a beautiful example of how I wish all intro pages for a software library were constructed. Your post here is very intriguing because the example you used is just so remarkably simple. I had trouble believing that such a framework could be created in C++, be portable, and be fully *embedded* especially just using headers only. Although you mentioned ASIO, I had no idea what it was. After a quick skim of the project description, I see that ASIO is a heavy duty networking library, and the implementation of RESTinio also requires nodejs and http-parser 2.71, in addition to a few others. I'm not complaining. Rather, initially, based on your example, I just thought RESTinio was too good to be true. Now, I understand how it can be robustly implemented and still be portable. If I'm implementing GUIs, I'm typically working mostly in JS using a framework on the client and on the NodeJS server. However, many times, I'm coding numerically intensive middleware in C or C++, and for this layer, there is no GUI. Even then, I typically have to use JS at a minimum in order to wrap my code to make it available as a REST API. *For these kinds of applications, could I use RESTino directly from my C++ code to implement a REST API without having a separate Node instance? For a consumer of my REST API, would it look just like any other Node server?*
&gt; Should be if constexpr (...) Yes, that will obviously work in C++11.
Try clang-tidy, or an IDE that supports it.
`not_null&lt;T*&gt;` is more about a contract. You say: this thing can't be null, and if it turns out to be, then something wrong happened. Useful to find the exact place the assignment to null occurred.
Thank you, for the feedback. &gt; requires nodejs and http-parser 2.71 You do not need nodejs, it's only an [http-parser](https://github.com/nodejs/http-parser) project. Yes it is a part of nodejs project, but it is fully self contained, and nodejs is just a part of projects name. This dependency is a bit heavy, but it is a well tested and popular http-parser, so it is worth an effort to rely on it. &gt; For these kinds of applications, could I use RESTino directly from my C++ code to implement a REST API without having a separate Node instance? Yes, you can. &gt; For a consumer of my REST API, would it look just like any other Node server? I'm not an expert in Node, but I think yes, because it about to be an http server, restinio just follows the protocol. In our practice it is always the case when client-side are implemented with a different stack of technologies, and there was no issues with this.
Nothing comes close to QtCreator with ClangCodeModel. Basically same level of productivity as Java/Intellij.
Contracts are a better way to express that something shall or shall not be something else. In fact, there's a paper out there ([N4415](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4415.pdf)) proposing a language-wise feature for them.
You should use the msvc compatible driver, clang-cl. clang++ only accepts gcc style flags. Try: cmake .. -G Ninja -DCMAKE_CXX_COMPILER=clang-cl
Looks cool. I really liked your approach to using restinio::traits_t in the router example. If you don't mind, I'm curious about a few design decisions. Why did you choose a builder pattern? Do you have any benchmarks? Are there any applications out in the wild using restinio? 
Then don't... the idea is sane defaults with explicit overrides.
Yeah this is a little half-baked I'll admit... I just think it's far too easy to accidentally copy things and far too hard to intentionally move things in C++.
A little off-topic, but "to make it more expressive", I prefer to write non integral numbers as `0.0`instead of `0.`.
What's "legacy memory management"? Do you mean just regular management, or some specific 80s-old malloc-type implementation?
LOL I know it's like he saw some sample C code from the 80s, or assumed the standard library is something nobody uses. So much of my office uses FORTRAN to do aerodynamic simulations. It's actually respectably fast for computation! But don't get me started on code hygiene. That's a fairly esoteric concept to most physics PhDs.
&gt; If you don't mind, I'm curious about a few design decisions. Sure, welcome! &gt; Why did you choose a builder pattern? You mean response builders? &gt; Do you have any benchmarks? For 0.3 version currently there is no actual benchmarks, we have a [separate project](https://bitbucket.org/sobjectizerteam/restinio-benchmark-jun2017) for 0.2 this week I'll update benchmarks with latest versions of (boost::beast, cpprestsdk, pistache, restbed and restinio). Also we have plans to push restinio to [techempower benchmarks](https://www.techempower.com/benchmarks/). &gt; Are there any applications out in the wild using restinio? Previous versions of restinio were released under non-free license, so it didn't get much users and version 0.3 is released only today, so for now there are no such application. Hope some part of community will like restinio and use it.
Yeah -Wextra has several that we disable.
"I fear not the developer who has written 10,000 libraries, but the developer who has rewritten one library 10,000 times." - Bruce Lee (from Jackie Kay) Alisdair is that developer.
KDevelop
&gt; Is Fortran really better than using eigen Oh god yes. And I've used eigen every day for the past 5 years in high performance computational physics code. It's great for what it is. No C++ library comes close to fortran's matrix/vector/multidimensional array handling in terms of clean expressiveness. No other language really does either, apart from Matlab. Python's numpy is reasonably close. I choose to use pure c++ in my work because what fortran is painful for (everything other than the core numerical work) tends to be much larger in terms of complexity and lines of code than the core numerical work the more it grows, and I don't want the added complexity of multi language development. So in the end I tolerate existing c++ linear algebra libraries as the least-bad option. 
&gt; It is quite sad how many just don't care about moving forward. What's the problem with that? I would use C constructs if it gets the job done. No need to use modern features just for the heck of it. Code is more often read than written and read by programmers less experienced in C++ than you as well. A lot of C code is far easier to understand (and by understanding I mean understanding how it works down to the Assembly level) than some of the modern template magic atrocities I've seen. While they are a very good thing if you actually need them, I suspect they are often just over-engineering. (Unless the C approach is much worse of course. For example I won't use void*-style generics in a C++ project - i.e. if I need generics - if there is no good specific reason for it.)
Given the way C++ is usually taught, lots of people who've never heard of them could use a basic introduction to the algorithms.
The point of schools (or universities) is to teach programming rather than a specific language. Languages change all the time and even if they would teach modern C++, it will probably be obsolete by C++35 or so anyway...
RESTinio sounds amazing! Thank you for the helpful reply, and keep up the great work!
The problem is people writing code that contributes to the list linked below, which I rather not have tainting our Java/.NET projects, when C++ offers language constructs to avoid it. https://www.cvedetails.com/vulnerability-list/opmemc-1/memory-corruption.html
&gt; You mean response builders? Yes, sorry for not being explicit about my meaning. It seems a builder is also used when setting server instances in the restinio::run function. I generally like the builder pattern here because the syntax stays compact, and my code doesn't get littered with type specifiers. Thanks for sharing!
Can you use that for non-Qt projects?
Doesn't meet the "Free" requirement, unless you are talking about one of the community editions?
&gt; If a parameter is ever changed in the code, the compiler returns an error. In C, there is something similar called a_ const:_ &gt; &gt; double const hbar = 6.63e-34 &gt; &gt; The problem is that a ‘const real’ is a different type than a normal ‘real’. If a function that takes a ‘real’ is fed a ‘const real’, it will return an error. It is easy to imagine how this can lead to problems with interoperability between codes. Gahhh!!!
This looks like something from *Numerical Recipes in C*. Good algorithms; terrible programming.
You could make it double width to at least preserve character alignment!
That seems very reasonable. Although I'm not entirely sure how to avoid them except for the obvious solutions like using std::string instead of char *, using the standard data containers by default and doing bounds-checking. I may have to do more reading on C++ features that help mitigate this problem. My main gripe is with people overcomplicating and overgeneralizing things just because it's faster to write and "hip" by modern C++ standards, up to the point only C++ experts can understand the code. I somewhat feel like C leads to people writing simpler code in general because it's very painful to do sophisticated abstractions in C.
This would be a subset of [this](http://open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0095r1.html) proposal, right? Also, I like the name `union class` better than both `lvariant` and `enum union`!
You welcome! About response builders. We considered different different strategies for body output: * Simple (*restinio_controlled_output*). Body is fully determined before sending a response. Response header and body are transmitted to peer as one group of buffers. * Customizable (*user_controlled_output*). Header and response are set as group of buffers that are spread in time. And we can send, lets say a header and a part of body first and then do a series of sending of remaining parts of body. * Chunked-encoded (*chunked_output*). A way of sending body for which it is hard to determine length in advance. * Compressed (not implemented now). This strategies are pushing to have different API for output builders and even imply different limitations on header fields values. So builders seemed to resolve the issue nicely. And using [CRTP](https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern) in builders comes from the following: * all builders must have an API for working with header; * for a [fluent interface](https://en.wikipedia.org/wiki/Fluent_interface) API a base class needs to know its derived class.
Yes, I do it all the time
Yes. You need one of the latest releases of QT creator. Install the ClangCodeModel plugin and then configure your dev environment in the Kits setup page. It should start working. 
Community edition provides a lot of goodies, more than enough for personal use
Fun article! You might enjoy these: https://accu.org/index.php/journals/2182 ...which is inspired by Graham Hutton's "A Tutorial On the Universality and Expressiveness of fold": http://www.cs.nott.ac.uk/~pszgmh/fold.pdf
Basically every IDE has been mentioned but I will add one: [Cevelop](https://www.cevelop.com/). This is very important to mention, because it does have tons of cool features for c++ and has [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md) support. [Presentation about it.](https://www.youtube.com/watch?v=q3WiZu8N7Tk)
That could still mess up shit though.
I've found `-Wmissing-field-initializers` to be counter productive in some cases, although perhaps rare enough to make `diagnostic push pop` viable. `-Wcomment` is also when you want to comment out some code that contains comment. (Although that is enabled by `-Wall`).
Visual Studio Code is free, it also has C++ language plugins.
Whoa! Be careful, you made me rethink a data structure I've been working on for years! :O Very insightful talk. I think I'll borrow some of these techniques!
Qt creator is fine but "nothing comes close" is quite an exaggeration. 
&gt; half baked How so? &gt; Hidden in numerics I disagree. See the following C++17 example: template &lt;typename ... Values&gt; constexpr auto sum(Values ... vals) { static_assert(std::conjunction_v&lt;std::is_arithmetic&lt;Values&gt;...&gt;); return (vals + ...); } 
Eh that's true, all they had to do is adding `-&gt;`. But with full respect, I won't pick my data structures based off syntatic sugar.
Seems like everybody has their own half-ass C++ HTTP server these days.
That is indeed interesting. How do you ensure associativity (is_arithmetic obviously prevents all the fun applications)? And how do you replace + by actual binary functions of relevance? I didn't really look into c++17 folds which i guess this is. In other words, how do i e.g. realize a simple gram-schmidt with these folds?
Question is, can you start sending the response before being done building it. i.e., "Transfer-Encoding: chunked". And what about content-encoding (compression)? They're sometimes used together, with chunks being sent as gzip, etc., does buffer flushes.
So why is this half-ass? What other modern C++ header-only HTTP libraries are there? Beast? Anything else?
When is ```-Wmissing-field-initializers``` counter-productive? It's telling you that you have not initialised some members of your struct/class. I'd always want to be told this since it would indicate I've got a bug waiting to happen with an uninitialised member. The only time it's not helpful is when you use C-style partial initialisation such as [here](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=39589), where the warning is effectively useless. Fair point on ```-Wcomment```, I can see it being more annoying than useful. 
Read the sidebar: questions go to /r/cpp_questions. 
But, alas, CLion is not free.
IDE itself is more or less the same regardless which package you use.
Maybe... I tried using it, but didn't like it at the end. But it is certainly very popular -- can't deny this
Dang. Sorry! Thanks.
The first thing Meredith talks about is implementing `type_trait` in terms of `type_trait_v` like so: ```cpp template &lt;typename T&gt; using is_function = bool_constant&lt;is_function_v&lt;T&gt;&gt;; ``` That's non-conforming for a C++ standard library because this fails: ```cpp template &lt;typename T&gt; struct awkward : is_object&lt;T&gt;, is_enum&lt;T&gt; {}; ``` But couldn't it be done with a little utility: ```cpp template &lt;typename Tag, typename T, T v&gt; struct tagged_integral_constant : std::integral_constant&lt;T, v&gt; {}; template &lt;typename Tag, bool v&gt; using tagged_bool_constant = tagged_integral_constant&lt;Tag, bool, v&gt;; ``` So you could just write: ```cpp template &lt;typename T&gt; using is_function = tagged_bool_constant&lt;class is_function_tag, is_function_v&lt;T&gt;&gt;; ```
Gotta be born into royal family. Legitimately! Or assert your right by force, if you have it. Or you could check https://isocpp.org
Removed as duplicate.
&gt; And how do you replace + by actual binary functions of relevance? I'm not sure I'm contributing, this is not the direct answer, but... you could theoretically wrap Value with wrapper that replaces binary operator call with +. It could be a template, like `template &lt;typename Value, typename BinaryFun&gt; struct add_operator {Value v; /* constructor, operator + calling BinaryFun etc*/ };`
Who uses alignment, anyway? ¯\_(ツ)_/¯ 
You don't use that beautiful `alignas`?
uWebsocket has better compilation times and memory consumption than Beast! I wonder if Beast performance is impacted by the use of Boost ASIO. In the benchmark, did uWebsocket use Boost ASIO(since it is optional)?
That's based on eclipse right? I only have 32GB of RAM right now.
For me just reading this sub and looking for interesting blog post shared here was/is enough. Reading all kinds of C++ Standards Committee Meetings/trip reports might help to stay up to date.
Am I the only person who found the "obvious" assumptions/conclusions Titus talked about not so obvious or intuitive or even logical?
* https://github.com/ipkn/crow * http://cpp-netlib.org/ * http://siliconframework.org/ * https://github.com/loentar/ngrest * http://pistache.io/ 
&gt; Although you mentioned ASIO, I had no idea what it was ASIO is very likely to be the basis for the standard networking library. It's worth acquainting yourself with if you're a C++ developer.
Could you elaborate why?
Cevelop looks good, will give it a try. Thanks!
It is not. All the other Parsers are literally broken. Particularly considering Build system support. VS and CLion is the only ones with viable Cmake support. But both have shitty parser which cannot parse and suggest simple libraries. Let alone something like Boost.Hana .
See prior thread [here](https://www.reddit.com/r/cpp/comments/720twh/bringing_clangtidy_magic_to_visual_studio_c/) for tools, etc.
You have to challenge one of the sitting members to combat, but the challenged may submit a request in writing within 14 days of receiving notice of the challenge by the committee chair requesting an ad hoc subcommittee be formed to nominate a substitute champion to take their place on the field. Nominations are decided by simple majority of the subcommittee and may be returned to committee for reviewer at most once. In any case, notice of acceptance or rejection of the nomination by the substitute must be made no later than 20 days after the the ad hoc committee meets at which time the applicant is given 10 days to respond in writing is they so wish. In practice these timelines tend to be quite pro-forma. The ad hoc committee often doesn't even meet in person, they just take a vote over email-if the sitting member even requests a substitute at all. As most members typically sit on the committee as part of their duties in their position of employment, the contest venue is typically arranged by the sitting committee member in a conference room close to their office. However, this is not universal. If melee weapons are to be used (which use must be specified in the original challenge), a parking lot, open courtyard, or even a wide hallway is usually selected. Herb Sutter once denied an application through the eye with a dirty butter knife in the office break room/kitchenette. A quorum of two thirds of the committee members is required to accept an application that replaces a previously sitting (but obviously subsequently deceased) member which replacement takes immediate effect excepting for the obvious case that health issues delay the start of the new committee member's duties. Often an easier pathway to membership is to apply for a seat that has already been vacated. A quorum in that case is just 50% of committee membership to accept an application, and in the event of only a single applicant, combat is replaced with the less intimidating feets of strength and a requirement that the applicant endures the Trial of Unblinking Pain, basically just a template metaprogramming debug sesh. Empty seats come up more often than you'd think. Usually it happens when an application is denied, but just barely, and the sitting committee member who met the challenge hangs on for a few days more before permanent retirement. It's a bit of a crap shoot, though, because if there are multiple applications, applicants are reviewed simultaneously, usually in the alleyway where deliveries are made behind whatever conference center is hosting CppCon that year, until a single victor emerges. That's always a grueling bureaucratic process. The winner is usually the one who hides behind a dumpster long enough to only have to face a couple of already wounded Google employees. 
I attended this talk, and it was good! Note, I am the author of Beast, one of the libraries reviewed.
Beast supports abstractions for the stream and dynamic buffers so compile times are necessarily longer. The current implementation of beast websockets uses Asio's proactor pattern, while uWebsocket uses the reactor pattern. This can result in better performance and less memory consumption. Beast doesn't claim to be the fastest websocket library. At least, not yet :) As this is a new library, the emphasis is on correctness for the first official Boost release. 
ASIO was indeed the basis for the [Networking TS](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4656.pdf), which was published in March of this year. ASIO [has since been updated](http://think-async.com/asio/asio-1.11.0/doc/asio/history.html#asio.history.asio_1_11_0) to reflect the TS, so if you learn ASIO now then you're effectively working with an implementation of the standard interface. (This is much like [HPX](http://stellar-group.org/libraries/hpx/) had an implementation of the Parallelism TS available well before C++17 was finalized.)
Have you seen /u/VinnieFalco's new HTTPKit library? It does message serialization and parsing without any dependencies on ASIO or Beast, just Boost. I'm not sure whether that would be a lighter dependency or not; most of its Boost dependencies are just for C++03 compat, but the reliance on Boost.Intrusive appears critical. :-/ ^[1] [Announcement](https://lists.boost.org/Archives/boost/2017/10/238945.php) ^[2] [Repo](https://github.com/vinniefalco/httpkit)
&gt; can you start sending the response before being done building it. i.e., "Transfer-Encoding: chunked" I think you can find the answer [here](https://bitbucket.org/sobjectizerteam/restinio-0.3#markdown-header-chunked-transfer-encoding-output-builder). &gt; And what about content-encoding (compression)? They're sometimes used together, with chunks being sent as zlib, etc., does buffer flushes. Compression is not implemented yet. We plan to implement it in some of the future versions. 
Very nice. I think it wouldn't be hard to adapt Boost's compression streams to make `append_chunk` calls, I've done something similar before.
Feature-wise, CLion is really appealing. But everytime I try it out, it literally crumbles to the ground on anything which is not a simple C++ project. I wish they get the performance right one day, but to me it seems like a lost battle. 
There are more to mention: * https://github.com/Microsoft/cpprestsdk * https://github.com/Corvusoft/restbed * https://github.com/facebook/proxygen But if you look closer then you can view that: * not all of them are header-only; * not all of them are actively developed now; * some of them can have problems with performance (RestBed, C++REST SDK on Unixes); * some of them can have problems with cross-platformness (like Proxygen); * almost all of them leave to much routine tasks on the shoulders of developers (like management of IO-related or/and request-processing timeouts). So we think that the more C++ HTTP/Websocket frameworks the better.
Yes, Herb is surprising nimble, resourceful (as you noted) and possesses the strength of many men (possibly including some of those he vanquished on his way to the top). Also ruthless, but that's obvious. I would suggest challenging some other member.
You show up.
&gt; Herb Sutter once denied an application through the eye with a dirty butter knife Confirmed.
Would be very cool, if the tool could offer the clang tidy suggestions as quick fixes in the editor.
Can you give an example of what you mean by &gt; improving my knowledge of java in terms of good practices and idioms. Afaik there are very few c++ tools that will give you non-trivial hints about how you should rewrite your code. The only tools I've seen with some capability in that direction are clang tidy (which is a command line too) and cvelop (haven't used it myself though). Admittedly there are a lot of other tools I haven't tested yet.
Wondered why you hadn't shown up lately.
Example: replacing try-catch with try-with-resource
See https://isocpp.org/std/meetings-and-participation In particular the section "How to Participate at Face-to-Face Meetings" Basically, just show up (and let the host know you are coming via email or something). If you show up more than once or twice, you should become "official" by becoming a member of your national body, which is a different process depending on each country. But note that the U.S., keeping up with its capitalistic tradition, just needs $1950 a year to be a member, no other "qualifications" necessary, I think - you don't even need to be American.
QtCreator is also muuuch snappier than any java-based IDE I hav ever tried (eclipse, intellij, ...). And unlike VS, loads of goodies are included by default (refactoring, code completion, clang-format, etc). I use it all the time, for all my C++ projects (I seldom do Qt development). QtCreator also has pretty decent CMake support: just open a CMskeLists.txt file and your project is set up and properly indexed.
I believe he was checking the qualifications of another applicant. They came up short.
I would like to take this moment to deny that being a member of the ASCIIlluminati provides an easier path to membership, or indeed that there is an ASCIIlluminati. You need not try to begin your challenge with any kind of secret handshake, should you know of one, should one exist, which it does not.
&gt; ASCIIlluminati I _knew_ there was something holding back a modern `&lt;codecvt&gt;` replacement...
Exactly, I forgot to mention that part. Java productivity with C++ quality level software. (Way snappier, lighter than any Java IDE I have come across).
In the case of embedded systems, template magic can be great for enabling things like logging utilities that compile down to nothing for release builds, but still work for debug or emulated builds.
&gt; feets of strength I concur, you can't do a thing without these...
You have to implement compile time C++ compiler via template metaprogramming.
At least that's what they told me.
The problem with -Wextra warnings is that they have many false positives, and these are very common. For example `-Wuninitialized` sometimes complains about a variable not being initialized when it _always_ is because it cannot understand any control flow that goes beyond the ternary operator (and no, initializing to zero just to shut up a warning is not a solution). The same applies to the others. If the warnings wouldn't have false positives that are too common, they would have been moved to -Wall instead of being in -Wextra. There is actually a category even more annoying than -Wextra, and that is -Weffc++. 
 double totalWeight = std::accumulate(begin(group), end(group), 0. [](double currentWeight, Person const&amp; person) { return currentWeight + person.getWeight(); }); Because writing a for loop is too easy, doesn't use three extra function calls and a lambda, and doesn't give the opportunity to make a bug by skipping a `.`
Also forgot to mention: I have become quite used to having real-time compiler warnings and errors as I type (clang). It's something I really miss when I move to other editors/IDEs.
Great suggestion (pun intended) ! I would definitely like to see that myself :) It’s already on our roadmap, but it requires some serious engineering effort in VS code editor framework to pull it off. Definitely doable, but it will take some time. Stay tuned for updates. 
Not sure if stuff like this exists in the c++ world. I you find something, please let us know. Most answers here suggest the people are already happy if auto complete works correctly and the IDE offers some basic renaming / function extraction capabilities.
Wow that was a good talk, especially in terms of delivery. Does the speaker have more stuff like this?
At least without payed plugins, msvc imho has little more than the most rudimentary refactoring support. Let alone giving actual useful tipps for improvement. 
I have been trying to learn and build something using the LLVM framework. I guess this would be a good project to work on in my spare time.
It doesn't seem very fast.
https://www.reddit.com/r/cpp/comments/772f9h/cppcon_2017_victor_ciura_bringing_clangtidy_magic/
[removed]
uWebSockets has support for `epoll` `libuv` and `asio` as it's event loop. I used raw `epoll` given that it was available on my platform.
It wouldn't be a mistake if every definition was implicitly one across the final compoled program. Then it wouldn't matter if you put the definition in the header or the cpp file, the result would be the same. 
hur hur!!!! :-)
 #define __CPP_2003 #include "noexcept.h" #undef __CPP_2003 
FWIW, with range-v3: auto weightLens = [](Person const&amp; person) { return person.getWeight(); }; double totalWeight = ranges::accumulate(group, 0., ranges::plus{}, weightLens);
Which fails to work in cases like the one I provided, being one of the reasons why ANSI C++ members don't introduce new keywords lightly and the general opinion among them is not *"They should have put in new keywords, it wouldn't hurt anyone."* as it can be seen by reading proposals and the respective comments from national bodies.
FWIW - I heard from Victor Zverovich that (optional) compile-time type safety is in the plans for std:: proposal... 
Pretty sure she was on an episode of cppcast a while ago. She's a great speaker.
Depend on what you mean by "like this". Kate Gregory gave a talk about teaching C++ and not C at CppCon 2015, and AFAIK gives talks regularly.
You might also want to check out [juCi++](https://github.com/cppit/jucipp).
The complaint is about verbosity and using external functions (even if they are in the standard library) and more complex language features in favor of simple language features. I see it as a "I am very smart" kind of programming. Efficiency is another thing, I think I've read somewhere that std::accumulate can be faster than a conventional loop, but I may have confused things.
Video is out: https://www.youtube.com/watch?v=Wl-9ozmxXbo 
In C++17 you change one argument and it can be parallelized and/or vectorized. &gt; I see it as a "I am very smart" kind of programming. Beside the fact that it's far more readable once composed with other algorithms instead of sitting alone in isolation, anyone with a math background sees it as "duh", not "I am very smart".
I'm not arguing against usage of `accumulate` and other std algorithms. They have their place, especially when you composing things (although the range-v3 library offers much better composition options). It's just that snippet in isolation takes me 10 seconds longer to parse than this. double sum = 0; for (auto&amp; person : group) sum += person.getWeight(); And I do have a functional programming background, trust me.
It sounds like we're in agreement then – they both have their place. :-] That said, given that one scales better than the other, if I'm not writing one-off code, I stick with the algorithms, personally.
It can either be done with a left fold or a right fold. Unfortunately only built-in operators are permitted so you’d have to overload one of them. If I can realize gram-schmit I’ll post the code, but I’m a little stuck right now given that a fold doesn’t permit intermediate storage but there is an intermediate storage requirement (without excessive recomputation).
It matters for compile times. 
Oh it's easy, already did it while I was at university. It's still compiling tho.
No need, just needed a rough hint on how to approach this. The new std::reduce I just learned about in a cppcon talk will probably be the more sane (as in coworker-friendly) approach in most of the daily cases anyway. Still in numeric for some reason though...
Well a downside of fold expressions is the pack size must be known at compile time. reduce is hardly different than accumulate. It needed a different name because of slight behavioral differences to accumulate with the “parallel” algorithms (which as of October 2017 have not been implemented in libstdc++ or libc++)
Oh nevermind, std::reduce assumes commutativity...
[I'm bookmarking this](https://i.imgur.com/f0Iu0xE.jpg)
I forgot to mention that you can add clang-tidy support for any IDE that uses libclang to parse your source files. For instance, if you want to try clang-tidy through libclang in juCi++: CXXFLAGS="-Xclang -add-plugin -Xclang clang-tidy -Xclang -plugin-arg-clang-tidy -Xclang -checks='-*,clang-analyzer-core.*'" juci &lt;path to project&gt; If you already have a build directory prior to running the above command, choose Recreate Build in the Project menu. The advantage is that you do not need to parse your source code twice (once using libclang, and once for clang-tidy), but instead libclang is extended through the clang-tidy plugin. 
Interestingly we have no parallel fold in the standard then - only commutative ones. I wonder why they didn't choose the algorithms boost compute used (their reduce only requires associativity). I also wouldn't call this "hardly different" at all. Simple things like string concatenation or matrix multiplication are not covered this way.
Because the fold expressions as I highlighted are really only useful for those dealing with template meta programming. The average C++ user will only need std::reduce or std::accumulate As for hardly different, relaxing the reduction tree order to me is hardly different. An associative operation could be done in any valid order. It’s mathematically equivalent. 
Yes, but reduce assumes operation *argument* order invariance, i.e. commutativity.
So you’re upset that a non commutative operation cannot be parallelized? I highly doubt boost.compute had accumulate do that. I believe boost’s accumulate requires commutativity. See: http://www.boost.org/doc/libs/1_62_0/libs/compute/doc/html/boost/compute/accumulate.html r.e. reduce optimization
 At 00:41:32,she talks about "not_null&lt;&gt;" wrapper, a feature that was discussed two days ago [here.](https://www.reddit.com/r/cpp/comments/76p8y9/how_not_null_can_improve_your_code/) Those who were not convinced of the usefulness of the class can listen to her arguments and see if they are convincing or not. 
Did you read it yourself? boost::reduce assumes *associativity*. It's mentioned in the link you provided. In fact i wonder why one would even want to permute arguments in an implementation as it wouldn't be necessary for partial evaluation.
Good stuff, competition can only help drive us forward. Some thoughts besides the point: what I would really like to see, but I'm fully aware that's a completely different scope, is all the other parts needed to create a functional web server. When I take python's flask as a reference, you have an eco-system that gives you user logins and associated cookies, with proper password hashing, and authentication and encryption of messages, ORM if you want to, easy generation of swagger documentation, options for marshalling responses, templating engine, ... The web server is only step one of the story, and the other steps are so much work if you need to go through them yourself. Without all of that, I don't see myself using C++ for tasks like these, unless for a project that is strictly inside of the company and where speed is of paramount importance. And even then...
https://www.reddit.com/r/cpp/comments/6hr46f/full_httpwebsocket_server_framework_c11/
I don't think that it's a good idea to compare tools like flask with libraries like RESTinio, C++REST SDK, Pistache or Beast. I think flask can be compared with Wt, CppCMS, TreeFrog and so on. They solves a task of building traditional Web-applications. RESTinio (like C++REST SDK, Pistache, Beast and several others) solves different task: you already have or want to build a C++ application which must communicate with other applications via HTTP-based protocol (REST API as an example). In this case you need a lightweight embedded HTTP or Websocket server which can be easily encorporated into your application.
It's helpful when some fields are uninitialized by accident. It is counter-productive when some fields are uninitialized intentionally. As I said, it's a rare case, but even if such low level optimization is beneath you, it might not be for people who write inline functions for the libraries that you use.
Youre right of course. Ill look into the examples you named, I was only aware of several other server frameworks, and the beast examples i saw didnt include user authentication, could be my lack of knowledge.
&gt; ~~Somebody~~ Titus, who doesn't like the feature speaks at 00:53:57.
I'll try to simplify your search: * http://cppcms.com/wikipp/en/page/main -- CppCMS * http://www.tntnet.org/ -- Tntnet * http://www.treefrogframework.org/ TreeFrog * http://www.webtoolkit.eu/wt -- Wt AFAIK they include much more functionality for building Web-applications in C++ than RESTinio and similar lightweight libraries.
https://repl.it/ is nice but it's stuck with gcc version 4.6.3
The benchmarks look promising, but does it support std::shared_ptr?
I'd suggest you add your library here: https://github.com/STEllAR-GROUP/cpp-serializers.
Besides all the other HTTP server libraries/frameworks mentioned, I'd like to see a performance comparison with [Poco](https://pocoproject.org/)
QtCreator is not the only one that uses clang for parsing. I used spacemacs with ycmd, and rtags, both use clang to do the parsing. rtags offers clang based code navigation, which Qt didn't have last I checked (only uses clang for auto complete and error checking), and last I check ycmd had much better performance than QtCreator for auto completion and syntax checking. QtCreator choked for me on large files last time I used it. Maybe it's gotten better since then though. Clang code model is also not a silver bullet, it's quite slow compared to other parsers. For some people this doesn't matter for others (depending on project size) it's not acceptable.
She talked about this "null pointer exception", is that a thing in c++? I don't believe so. On Windows you probably can catch a Structured Exception but it's not portable. Did I miss something obvious?
Nice work! A thing of note though: You are making a number of agressive assumptions about the inner workings of the target container: std::memcpy(std::addressof(*_outIt), data, size); You really need to be asserting on these assumptions, lest this explodes in someone's face when they try to use it with a std::deque. 
In my quick benchmark test, Wt performs better than RESTinio :-). Of course, I'm not sure if I built RESTinio with the right options to get the most out of it. (I used `-std=c++14 -O3 -DNDEBUG -march=native` on both Wt 4 and RESTinio. Of course, Wt does not offer a nice way to create RESTful interfaces (it's quite verbose), and that's something we should look into for a future release (someone here as already done some work on a branch, but I still have to review it).
It will be interesting to see the code of the benchmark. If expressjs-like routers were used then there could be a reasonable performance penalty because of the slow std::regex implementation.
No, that's not a thing in C++, but if she was talking about GSL's `not_null` in particular, it does throw if constructed with a null poniter if `GSL_THROW_ON_CONTRACT_VIOLATION` is defined; so there would be an exception upon null pointer, but it wouldn't be a 'null pointer exception' per se, as it's just a generic GSL exception that derives from `std::logic_error`.
Performance aside, every std::regex implementation is quite buggy in some way or another at present; I wouldn't rely on it without some way of letting the user choose a different implementation.
The addition of expressjs routers to RESTinio was more like to proof-of-concent. We wanted to try and see what it goes. It lead to interesting results: * routers are great feature and they simplify the development of REST API significantly; * but the performance of our first implementation on top of std::regex is not good; * representation of routing params as strings is also not good. In modern C++ we can (and want) have more type-safe representation. Because of that we want to refactor or even redesign routers in RESTinio. What it will be we don't know now. May be it will be a pluggable module with different implementations (for example on top of PCRE/PCRE2). May be it will be something similar to routing DSL from Silicon framework. That's the area for further development.
Her "stop teaching C" talk is a classic, and should be mandatory viewing for anyone teaching (or even learning) C++. https://www.youtube.com/watch?v=YnWhqhNdYyk
I slightly modified the hello world example: #include &lt;iostream&gt; #include &lt;restinio/all.hpp&gt; int main() { restinio::run( restinio::on_thread_pool(8) .port(8080) .address("localhost") .request_handler([](auto req) { return req-&gt;create_response().set_body("Hello, World!").done(); })); return 0; } I compared that against the plaintext benchmark in Wt: https://github.com/emweb/wt/blob/master/examples/te-benchmark/benchmark.cpp I ran that benchmark with `../../build/benchmark/examples/te-benchmark/te-benchmark.wt --docroot . --http-listen 0.0.0.0:8080 -c wt_config.xml --approot . --no-compression --accesslog=- -t8` from within `examples/te-benchmark` in the Wt source tree (the build of Wt was done in `build/benchmark`). I used wrk as follows: `./wrk -c 16 -d 30s -t 8 http://localhost:8080/plaintext`. Of course, I recognize that this still a very rudimentary and quick test. It was surprising to me too that I got 148000 requests/s for Wt and 109000 requests/s for RESTinio.
She has a great talk where she and James McNellis talk (amongst other things) about the C standard library on MSVC, and how printf is implemented. There's a lot of printf variants, snprintf, wprintf, etc. It was done using macros and totally horrific. They redid it; this is the point where I learned that even the C standard library can be advantageously implemented in C++. Link: https://www.youtube.com/watch?v=LDxAgMe6D18.
Actually I have BufferAdapterTraits for this, and it is only specialized for buffers, that has contiguous underlying memory layout. (std::vector, std::array, c-array, std::string), so you wouldn't be able to use std::deque as your data buffer.
I added bitsery to this project, and made pull request. But this project doesn't really measure real world situation, because testing data is very poor, it serializes two vectors, one of which is just memcpy by most serialization libraries
ideone.com , though I wouldn't call it a proper "IDE". It's just an editor with syntax highlighting and ability to compile and run your code on different compilers. No fancy IDE features you usually expect.
HTTPKit has not been published yet, at this point it is just an idea that is floating on the mailing list.
Wow, awesome, thanks!
Very nice library!
A project of this scale may be a little much for "learning C++". I highly suggest you put together some smaller projects and experiment with some of the core concepts of C++. That said, if you're stubborn (like me) and insist on going right for a large project... Here is a list of things that you'll want to look into for learning the core language itself: * Compilation and Linking (Visual Studio makes this a little less complex than other compilers) * Passing arguments by reference or value * Pointer mechanics * [Const Correctness](https://www.cprogramming.com/tutorial/const_correctness.html) * [RAII](http://en.cppreference.com/w/cpp/language/raii) * [Stack vs Heap Memory](https://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap) * [Dynamic Memory](http://www.cplusplus.com/doc/tutorial/dynamic/) (Ties in with stack vs heap) * Classes and Polymorphism Once you get some of those things down and you've written a couple of small projects to experiment and understand them, you'll want to look into: * Windowing/UI Libraries * Rendering Libraries * Serialization Libraries (or rolling your own for data storage) * Vector Mathmatics (Either writing your own, or using a library)
I am definitely stubborn. I'm going to take very small steps. But this is exactly what I was looking for. Thanks for the great information. I appreciate it.
In this sample default [traits](https://bitbucket.org/sobjectizerteam/restinio-0.3#markdown-header-traits_1) traits are used. And it goes with 2 options that impact on performance greatly: * Real [timers](https://bitbucket.org/sobjectizerteam/restinio-0.3#markdown-header-timer_factory_t) are used, so for each request timers are scheduled and canceled 3 times; * request handler is stored as *std::function*. A more efficient but verbose version would be: #include &lt;iostream&gt; #include &lt;restinio/all.hpp&gt; struct req_handler_t { auto operator() ( restinio::request_handle_t req ) const { return req-&gt;create_response().set_body( "Hello, World!" ).done(); } }; int main() { using traits_t = restinio::traits_t&lt; restinio::null_timer_factory_t, restinio::null_logger_t, req_handler_t &gt;; restinio::run( restinio::on_thread_pool&lt; traits_t &gt;(8) .port(8080) .address("localhost")); return 0; }
To perceive an array as a pointer is like to perceive a container as an iterator, which seems fine when we are already used to it but is actually an antipattern, like when a vector degenerates into an iterator. It does confuses beginners. You are supposed to experience as much syntactic difficulties when you get a pointer from an array as when you get an iterator from a std container.
Last time I checked MSVC was prertty useless without VisualAssist (code completion, navigation, refactoring...), and even then it was not on par with QtCreator, but that may have changed?
You can probably get a better environment than QtCreator if you are ready to configure, install plugins, customize etc (I have seen pretty impressive vim setups for instance). My favorite aspect of of QtCreator, however, is how you get loads of features out-of-the-box, without bloat. Whenever I get started on a new machine (Linux, macOS, Windows) I just install QtCreator and I'm ready to code.
How does it compare with boost::serialization?
I think it could be a good idea if you plan your small steps to be functional projects on their own. Something like a library that you will be able to utilize for your CAD software, but that you could also use to write a cool little demo program. I suggest this strictly because it's nice to see a finished product every once in a while. It helps to maintain motivation.
https://gcc.godbolt.org/ it does not run the executable, but show the compiler output. Running the executable is planned though.
That does seem to make a big difference (183000 reqs/s for RESTinio vs 152000 reqs/s for Wt). Interesting. Of course, It's not quite the same test yet, I wonder what would be the result if I leveled the playing field, e.g. Wt was transmitting 21 MB/s vs 13 MB/s for RESTinio, because Wt generated larger responses to comply with the TechEmpower framework benchmarks specification.
She also has a lot of content on Pluralsight.
Yep. Great talk.
Short answer: no, we don't have it now. I'm currently working on simple benchmarks and will consider Poco for comparison. Some more words to say. In general performance comparison is a tough question. Any comparison depends on its scenario. I've used Poco myself and I can say it is a really great framework (not only http stuff). But Poco didn't give an asynchronous request handling, so response must be determined inside a handler call, and in my practice it was a source of pain: need to stay in a handler call, hence occupying one thread in a pool and use some kind of promise-future mechanics to put response data back on the context of a handler when the data is ready. 
&gt; If you use the convention that references are always passed const, and you use pointers for "mutable references", then not_null makes a lot of sense. You can make up a terrible, ill-conceived convention to make a lot of terrible things seem acceptable.
It's important to note that if you don't specify the grip type in your challenge (one-handed vs. two handed) it can lead to undefined behaviour.
I can imagine that's true if you use Cmake or qmake. But if you don't, you need to generate various files out of your build system and feed it to QtCreator so it can index properly, which is basically the lion's share of the work with rtags/ycmd as well. Spacemacs vastly reduces the amount of work involved in using emacs, everything outside of the C++ parsing itself works out of the box (finding files, git, vim emulator, etc). So I think for people who don't use Cmake/qmake, Spacemacs + rtags + ycmd is not substantially more work.
I apologize if I'm being dense, but I'm not seeing it, `OutputBufferAdapter` seems to allow resizing containers, but `OutputBufferAdapter` always does a memcpy. Maybe you have a specialization of `OutputBufferAdapter` that's enable_if'd for non-contiguous types, but I can't find it in your repo. 
Can you, please, geve the output of *curl -v http://127.0.0.1:8080/*, and I'll do modifications to serve the similar responses, but still without routing. 
I know Eclipse has a few, such as: Orion https://orionhub.org/mixloginstatic/landing.html?redirect=https%3A%2F%2Forionhub.org%2F&amp;key=FORMOAuthUser And Che https://www.eclipse.org/che/ I haven't tried these out yet, so I'm not sure how they handle C++
Looks fantastic at a glance. Is the primary advantage over cereal speed and simplicity? 
Here you go, this is Wt: * Trying 127.0.0.1... * Connected to 127.0.0.1 (127.0.0.1) port 8080 (#0) &gt; GET /plaintext HTTP/1.1 &gt; Host: 127.0.0.1:8080 &gt; User-Agent: curl/7.47.0 &gt; Accept: */* &gt; &lt; HTTP/1.1 200 OK &lt; Date: Thu, 18 Oct 2017 16:05:10 GMT &lt; Content-Type: text/plain &lt; Server: Wt &lt; Transfer-Encoding: chunked &lt; * Connection #0 to host 127.0.0.1 left intact Hello, World! I've also toyed around with RESTinio, making the responses more similar, and it was indeed still faster than Wt without the timers. I tried to disable our timers, too, to see what would happen, but the result wasn't nearly as dramatic. I wonder why the timers make so much of a difference for RESTinio. I should check Wt against some of the others some time. I see that you've already benchmarked many others: https://bitbucket.org/sobjectizerteam/restinio-benchmark-jun2017. I'm not necessarily looking to beat other frameworks, because Wt does a lot more. Even, if other implementations are better, I wonder if Wt could use them.
currenty pointer serialization is not supported. It requires some linking context on both ends (serializer and deserializer) between object and pointer address to correctly serialize it. One possible implementation would be via extensions that would use linking context using *context()* method from serializer/deserializer. BTW, contributions are always welcome;)
Will they be recorded ? With proper audio ?
Thanks, it's a big pleasure to hear it from Boost.Beast author.
That's a great idea. Maybe you can answer this for me. As I've never made a windows program before I don't know how I should structure things. I saw there was .dll files you could create for your program but I don't even know how I would do that. Do you know of any good tutorials or books that explain those things? Like libraries in general.
It's conditionally-supported with implementation-defined semantics, so both are correct. http://eel.is/c++draft/expr.call#9.sentence-5
Interesting... I personally really don't care about refactoring tools -- all I need is decent editor, syntax highlighting and Intellisense. And few years ago MSVS Intellisense had no equals. Not sure about now
Why are you trying to do this? Use variadic templates?
Well that's not *all* my code, I promise you it makes more sense with context :)
No it is silver bullet, considering how much other IDEs are bad at this job. I don’t know what you have you used and see to came to the conclusion of “clang parser is slow”. In my experience it is not. I have used it for a cross compiling a project which was using more than 10 libraries (Cryptopp, Boost, and so many other libraries which I don’t remember their names at the time). And it was anything but slow. It was not instantaneous. Of course. But considering how many libraries I was using it was more than acceptable. It is not right comparison. You are comparing a tool which literally takes less than a minutes to install and run it to something which does not have official support nor strong community behind it and would take hours or day to configure. QtCreator does support every kind of step/automation before running CMake or QMake. It is extended configurable. You have to just look and edit/delete steps before cmake.
Damn, C++ some days... Thanks a lot for the quick reply!
&gt;When you don't have access to the body, and thus type, of the coroutine (cf closure) on the callee side, in order to specify the type of the argument without resorting to type erasure. Hmm, I still don't get it.
I suggest to dig into similar open source projects, e.g. https://github.com/LibreCAD/LibreCAD You could also start by contributing to that in order to acquire some domain knowledge. 
This one would be closer: #include &lt;iostream&gt; #include &lt;restinio/all.hpp&gt; struct req_handler_t { auto operator() ( restinio::request_handle_t req ) const { return req-&gt;create_response&lt; restinio::chunked_output_t &gt;() .append_header( restinio::http_field::server, "RESTinio" ) .append_header_date_field() .append_header( restinio::http_field::content_type, "text/plain" ) .append_chunk( "Hello, World!" ).done(); } }; int main() { using traits_t = restinio::traits_t&lt; restinio::null_timer_factory_t, restinio::null_logger_t, req_handler_t &gt;; restinio::run( restinio::on_thread_pool&lt; traits_t &gt;(8) .port(8080) .address("localhost")); return 0; } 
&gt; cereal speed and simplicity Some cereals are simpler than others. Are we talking Luck Charms or Cheerios? 
Assuming you can use C++11 (which seems to be the case since you didn't bring that up), unless you are interfacing with legacy codebases, there is absoultely nothing that varargs give you you cannot get with variadic templates.
True, and yet varargs provide a very elegant way to de-prioritize a function overload w.r.t. a template overload. I was SFINAE-detecting if an argument had a certain method: template&lt;typename T, typename HasIt = decltype(std::declval&lt;WithFoo&gt;().foo())&gt; constexpr bool HasFoo(const T&amp;) { return true; } constexpr bool HasFoo(...) { return false; } Again the real situation was a bit more convoluted than this so the simplicity of `...` seemed worth it compared to adding template parameters to the second `HasFoo` overload. Which I eventually did to side-step the issue discussed in my post :)
I personally don't use much fancy refactoring myself for C++. However i use some "small" refactoring tools all the time, like rename-item-under-cursor (edits all affected files in the project) and auto-update-method-signature (edit method signature in header file and automatically apply changes in cpp file, or vice versa, including renaming arguments in the function body). Both of these are on handy shortcuts. For navigation I use CTRL+click to follow any symbol or include file, plus the incredibly useful CTRL+K for instant search of anything in the project (file, class, function, method, constant etc). None of these were as accessible, fast and powerful in VS+VisualAssist when I last tried it.
Actually it is good idea, to additionally assert on `ContainerTraits&lt;Buffer&gt;::isContiguous` in buffer adapters, thanks :) But `std::copy` is slow and has no optimization for contiguous containers. Also it makes no sense to use non contiguous container as buffer.
The C++ Core Guidelines are a good place to start
You may want to double-check that assumption: https://godbolt.org/g/MqCTHG
&gt; a reference cannot express any ownership semantics #HA HA HA HA HA HA!!!
&gt; But `std::copy` is slow and has no optimization for contiguous containers. It isn't guaranteed to by the standard, but it would be considered a huge quality of implementation issue not to.
So I understand what /u/WeRelic means by saying you should try some smaller projects - but I don't think they have to come first. I'd say do them concurrently. My learning C++ assignment was making a slicer (stl to gcode processor) at work. But, a huge chunk of my learning C++ was done at home by working on personal projects after work. I'd recommend [C++ Primer](https://www.amazon.com/dp/0321714113/) as the best beginner book for learning modern C++ (it only covers C++11 really, but this is where most of the big changes occured), followed by Effective Modern C++ for covering C++14 features. C++17 features are harder to find info about, and the only thing I can immediately see being useful for you is the Filesystem experimental stuff. The best thing you can do for yourself, imo, is leap right into using Modern C++ features as using old ones can build bad habits. First, I'd say you should write yourself some kind of software design document. Don't make it super serious, but start setting some kind of scope for your project, a few key requirements, and lay out your architectural design visually a bit. Consider reading things like ["Clean Code"](https://www.amazon.com/dp/0132350882) - this has been a favorite of mine lately, and has instilled some better habits in me that don't just "feel" good: they've had a direct effect on making my code easier to maintain, understand, and test. When it comes to looking for windowing, rendering, and UI libraries I've enjoyed using GLFW, OpenGL (vulkan now, but don't start with this lol), and ImGui for the GUI. GLFW just works. OpenGL is easy to pick up - but you may want to look at a higher-level rendering library if learning graphics programming isn't for you (if it is, http://learnopengl.com is a great resource). Also, all the learning and reading in the world isn't going to be great if you don't get out there and code. Ultimately, what matters most is that you just keep programming, improving, and developing your skills as much as possible. Constant work got me from part-time making an application to completing that application and getting a full-time offer (which let me drop out of school, thank god). C++ is a tough language because it's feature dense, and nowadays it's dense with excellent features that can make your life *loads* easier (e.g I just learned about `std::valarray`). Further, consider getting design and code inspiration from open-source projects. Synthesizing and re-writing code that other's have written (even if you're just transcribing it, really) is still a great way to learn and expose yourself to software design and development practices, and lets you see how other's use C++.
In C++17, `std::pair` (among others) has [conditionally explicit constructors](http://en.cppreference.com/w/cpp/utility/pair/pair), depending on whether the constructors of the contained types are explicit or not. I seem to recall a talk by STL where he explained how the conditionally-explicit checks are done, but I can't remember the details now (Cppcon '16 maybe?). It sounds like it might be what you're after? (Modulo list/non-list initialisation differences that is).
Check out /r/cpp_questions.
But the question was not: "what is the best C++ IDE?" ( We can discuss whether VS deserves that predicate elsewhere) but "Is there an IDE will help me learning better c++". And imho neither msvs nor qtcreator shine in that area. 
Well, the clang parser is slow compared to the Eclipse parser, or the CLion parser, because it's a true compiler frontend and is designed to be 100% correct. Eclipse takes shortcuts like only parsing each header file once, that clang cannot take. You didn't understand what I said at all. I said that QtCreator does not support compile_commands.json, which is a standard approach to specifying all the correct compiler flags for every single translation unit. Have you ever thought about how you would specify includes for a non-qmake, non-cmake project? How would you specify the correct compiler flags for every translation unit so clang can give correct diagnostics? As far as I know, if your project is not qmake or cmake the situation is very bad (you can specify one set of includes globally in a &lt;project_name&gt;.includes file, which is pretty bad). Also, as I said before: Qt *only* uses the clang code model for auto-completion and error checking. Not for goto definition. And not for find references. It still has its own parser, which is quite poor, worse than Eclipse or Clion in my experience. So something like find references actually works *worse* in qt creator than any other editor I've used. Meanwhile, I get clang based analysis even for find references, because of rtags. QtCreator is a fine IDE, but its absolute strongest point is auto completion and error checking for CMake &amp; qmake based projects. As soon as you start talking about other types of projects, or about code navigation, it is weaker than much of the competition.
Thanks for the great info. I'm currently in the process of writing my design document which is why I made this post. I started seeing what I was going to need and I wanted to ask here so I can get the right answers and look ahead to the future at what I was getting into. I want to take a step by step approach while also programming things in a certain way where I can easily implement future code instead of having to rewrite it all.
What is the reason for using a parser which is literally broken? (Eclipse and CLion). BTW QtCreator is using Clang to index the *whole* project. 
You could pass a pointer to your vector: std::vector&lt;int&gt; v; foo(&amp;v); Inside `foo`, you can use the pointer if you cast it to the correct type.
That's a good content but I cannot judge anything objectively that encourages default arguments. IMHO explicit &gt;&gt; implicit!
I'm not sure what your question is, so here's an overview of what I'm thinking: In the current system, calling a coroutine heap-allocates its associated `promise_type` along with enough space for its cross-suspension state, and then extracts a return object from it. This return object includes a `coroutine_handle`, which contains a pointer back to the heap allocation so that the caller can retrieve the return value. This means that, when compiling the caller, you only need the definition of the return object's type. The code that does the allocation, the body of the coroutine, and the code that drives the coroutine, can all be in another TU- the caller just has to link to them. --- Similarly, creating a closure requires enough space for its environment. Unlike coroutines, this space is *never* implicitly heap-allocated- it is an anonymous type that can be used directly, e.g. passed by value to a template function. This means that, when compiling the user of a closure, you also need the definition of the closure. It can be obtained via a template parameter, or via type inference, both of which only work if you're in the same TU as the closure. In order to bypass this requirement, you can instead accept a type that *is* defined in your TU- `std::function`. The TU with the closure can heap-allocate it and then pass you a `std::function` instead of the closure itself. Does that make any more sense? Coroutines have forced all use cases to go through `coroutine_handle` (a type-erased coroutine), while closures can additionally use their anonymous type directly when within the same TU.
Yes, that is what it means. And you can target them to Windows, Linux or both.
QtCreator is great when you're typing out code, but I ran a small experiment and I found that this is the minority of the time spent in development, for me. Most of my time is spent thinking, stepping through code, debugging, reading through code/docs, etc etc. For most of that, I've found VS to be better, but I haven't tried Qt recently so i'll have to go try it since you recommend it so much. In VS I use a lot of the the debug/diagnostic features. Automatic symbol resolution, Heap/CPU Profiling, etc, etc.
&gt; An array is literally a pointer, and I don't just mean in it's backing definition, it's literally a pointer as it's interface. I thought this to... except it isn't true. [see here](http://c-faq.com/~scs/cgi-bin/faqcat.cgi?sec=aryptr) for a somewhat helpful explanation, and [see here](https://stackoverflow.com/questions/6385850/pointer-array-extern-question) for a more succinct explanation. I came across code similar to the above SO question, spent several hours debugging this, was confused by the assembly, asked our principle engineer, who then opened up the C spec and quoted line and verse how wrong the code was.
That pesky type safety always getting in the way!
&gt; I don't see why C-style arrays should even exist. Super useful for dealing with hardware. I can create a pointer to a memory mapped address, oftentimes memory on some peripheral, and access it like an array. With raw C, you can just take the supplied memory address (known constant), initialize a pointer to it, and start the party. I am not sure if std::array can do this, haven't looked into it. :) C style arrays are also nice because they are trivially understandable. If I need to DMA (direct memory acccess) copy some memory from point A to point B, it is easy to grok how to do that with a bog standard array (or pointer to some memory), and the amount of magic going on in the language is exactly 0, which means any debugging is now limited to magic going on in the DMA engine. In general, the raw C structures are useful when you don't want the abstractions because everything else is already confusing. Building up abstractions later is fine. After reading bytes out of hardware, if perf isn't a problem, moving them into a safer data is definitely preferable. (And yes, these examples apply to a very small proportion of programmers!)
&gt; I think it's just a deep seated terror developers have at the idea of writing, reading, or being held accountable for documentation. This is so true it hurts.
I didn't think of it. It's somewhat common. http://web.archive.org/web/20160415020756/http://www.insomniacgames.com:80/core-coding-standard/#id.1f28bf8e99aa https://google.github.io/styleguide/cppguide.html#Reference_Arguments Seems pretty reasonable to me. If a team finds that adding visibility to when arguments are intended to be modified is helpful, then this is one way to achieve that. And now not_null helps clarify nullability.
Working implementation here: http://coliru.stacked-crooked.com/a/3e292b14cb165d60. Basically, you declare a function like this: template &lt;class T&gt; void helper(T t) Then, if you consider something that is templated like: template &lt;class To, class ... From&gt; You can get sfinae friendliness by doing: decltype(helper&lt;To&gt;({std::declval&lt;From&gt;()...})) That's the gist of it, the rest of it is boilerplate a la your favorite technique, I use the void struct specialization trick you can do it also with the hana approach of trailing return types and elipses functions.
thanks for the suggestions! what I ended up doing was substituting the `...` with the `const T&amp;` template parameter plus a set of variadic template arguments, which will always be empty but decrement the priority of the overload. a bit more clutter than the varargs but it does the job :)
&gt; We are well aware that you could claim the “bad” examples more logical than the ones marked “OK”, but they also confuse more people Some people might be confused by a more logical notation. Those people shouldn't be computer programmers.
Try this overview: https://arnemertz.github.io/online-compilers/
!!RedditSilver RobertJacobson 
###[Here's your Reddit Silver, robertjacobson!](http://i.imgur.com/x0jw93q.png "Reddit Silver") *** /u/robertjacobson has received silver 1 time. (given by /u/flashmozzg) __[info](http://reddit.com/r/RedditSilverRobot)__
A library could be structured in many different ways. It could be just a collection of C++ header files that you include in your project (this is the most straight forward), or it could also be a collection of source files that get compiled into a static library (usually a .lib file on Windows) or a dynamic library (.dll file). Obviously, a collection of header files is the most straight forward to deal with. A static library is something that can be compiled by itself and then connected with your project at compile time (via a process called linking). DLLs are like static libraries except they are linked when you start your program. As you may guess, that's not really a useful advantage unless you have specific needs, so I wouldn't worry about DLLs for a while until you get a grasp of the basics of building projects. You can create successful projects without DLLs. I unforunately don't have any recommendations on reading material, but what I would do is first learn about how the process of compiling a C++ project works, then how to use a build system like cmake (which helps for building projects that are larger than just a few source files), and finally how to structure your project. Those are things that should be relatively easy to google. But to be honest, I wouldn't worry about those things just yet. Learn some C++ and start writing code. Once you've written something that you like, you can then focus on tidying it up and using the techniques learned in the above mentioned topics. It's never too late to reorganize, and it's best to fiddle with how your project is organized when you already have source files to organize.
Unlike the guidelines about raw pointers etc, this one is prefaced by (at the top of the NL section) &gt; These rules are suggested defaults to follow unless you have reasons not to. 
Core guidelines have to make some choices so everything is consistent. This is a popular notation choice.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Your citations are a site that doesn't exist anymore and therefore has to be linked from an archiver, and the Google Style Guide which is widely accepted as being terrible? Making something a pointer raises more questions than it answers: Can this thing be `nullptr`? Is it expected that it will be incremented/decremented? So you want call site visibility, ostensibly so you don't have to actually know anything, write or read documentation to understand that something may be modified, fine. So you're solution to that is to then raise call site questions about nullability and the range of memory which is expected to be valid (since that pointer could conceivably be incremented or decremented), and then you propose to answer one of those questions **not at the call site**. This entire thing stinks of a cargo cult. People have told themselves call site visibility is important for a long time, and now it has kinetic energy since people have a vested interest in not succumbing to the belief that all the code they've written for years is ugly, disgusting, and more C-like than it needs to be because they were chasing a false idol. Saying that you need call site visibility to determine whether something is modifiable or not really raises a few possibilities to me, none of which are positive: - Your developers don't have very good working memory - Your functions are too long (so it's important to be able to quickly unpack the meaning of statement because there are so many of them) - You're not using `const` correctly - You're using a lot of out parameters (so the likelihood that something modifies its argument in a non-obvious way is high) Really this should be a non-issue if you have developers with half a brain, aren't using out parameters all over the place, and use `const` correctly: It's a symptom of a disease.
Okay, I see where I'm going amiss in saying they are the same. Yes a pointer gives you a single size_t sized address. While an array gives you a statically sized contiguous block on the stack. When I say array, I should probably be saying array handle. But this contrast only exist in so far as to what your memory declaration is. When you declare a char b[], b is not a char array. It's a char\*. b never decays into a char\* although that is how it's often described, it was always a char\*. char\* b = "hello\0" is saying, allocate a pointer in my current stack frame that points to the first char in the static string literal in the data section of the binary. The only difference between that and char b[] = "hello" is where that string literal is stored. You can't change the former, while the latter you have mutable stack memory. In either case b is still a char\*. The thing that must be remembered is that index notation is merely sugar for offset arithmetic. When using it you aren't working with an array, you are working with a pointer that was initialized relative to a stack allocation. An array declaration is the syntactic sugar for array allocation, and stack allocation is a first class language feature compared to heap allocation because it must be static and thus will be resolved by the compiler. For this reason the heap allocs are implemented as part of the standard library because they operate on run-time provided arguments and thus have no business being first class to the compiler. Talking about how arrays decay to pointers is a nice pedagogical way to frame things, but what people really mean to say is that it de-sugars. To say "it decays" acts as if b was once an array&lt;char&gt; and now it's a char\*, which is not true for C and not true for C++ given it's compatibility. I know you're not the one I original responded to, and I know I wasn't even completely right, so I thank you for the correction. But I think the point I wished to convey still stands. It's important that people don't "run off" so to speak with the idea of pointer decay. If those people don't want to use C arrays because they won't stop thinking in terms of pointer decay, then they should be using std::array. But even then you still have the issue of off buffer access, which just goes to prove that pointer decay is not the issue making that happen. It also demonstrates that people are being taught to wrong interface to C arrays, which is skewed by contemporary mental models of arrays which are hidden behind some sort of smart pointer.
!remindme 14 days
I will be messaging you on [**2017-11-01 20:08:40 UTC**](http://www.wolframalpha.com/input/?i=2017-11-01 20:08:40 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/cpp/comments/772icg/how_does_one_become_a_member_of_the_c_standards/dok00oi) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/cpp/comments/772icg/how_does_one_become_a_member_of_the_c_standards/dok00oi]%0A%0ARemindMe! 14 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dok01d5) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
&gt; It is widely used, yes, but is this really an good argument? That would be a bad argument, but that is not their argument. &gt; We are well aware that you could claim the “bad” examples more logical than the ones marked “OK”, but they also confuse more people, **especially novices relying on teaching material using the far more common, conventional OK style.** This argument is even worse if you ask me. Novices need to know how the `const` keyword works in both cases AND they need to be thaugt to write it after the type it should apply to, because you can always use that rule (whereas I wish you good luck defining a const pointer to an int with the other style).
Ok, I tested it again now (on my home computer), and I get: - 133000 reqs/s for Wt - 142000 reqs/s for RESTinio without timers - 96000 reqs/s for RESTinio with asio timers Why is the performance hit when using timers so high? Wt handles timeouts as well, also using asio steady timers, but it doesn't take nearly as much of a performance hit. When I disable timeouts in Wt I get 140000 reqs/s.
To continue to be pedantic, compilers do consider them two different things. A lot of automatic conversions are specified between the two, but in the C spec, arrays are not the same as pointers. To more clearly see this, in char* b, you can take the address of b, and there is, assuming a really bad optimizer, a char* allocated in memory taking up size_t memory. with char b[] = "hello", there is no symbol b allocated separately. 'b' is not an addressable modifiable thing. There is [a picture](https://i.stack.imgur.com/2Q7En.gif) in the linked Stack Overflow showing the difference in memory layout 
I don't think there is an objectively better version here. I prefer `const T`, as it is closer to natural language and I prefer to optimize style for the common case and not corner cases (how often do you have constant pointers to const?)
&gt; Wt handles timeouts as well, also using asio steady timers, but it doesn't take nearly as much of a performance hit. How many timers per connection do you use?
Two.
It's arguable the NEED to know it. Like, if we all follow the guidelines, then we start having compilers throw warnings, code formaters move const, then the new users won't ever need to know about the other notation. After all, that's a major point done by Kate Gregory in her CppCon speech https://www.youtube.com/watch?v=XkDEzfpdcSg that some guidelines should be followed more to avoid bikeshed effect than because one side is really better than the other.
`T const` all day every day.
While a lot of programmers consider "const T" a more natural expression (at least if they're English speakers, where adjectives come before nouns), I think there are good stylistic reasons to prefer "T const", besides the universal applicability of the postfix form. 1. Putting the main type first makes it more prominent and easier to recognise. Example: Poison const&amp; fetch(); const Poison&amp; fetch(); 2. It's easier to change value types to const&amp; types. You only have to edit one place in the code, rather than two (see previous example). 3. When a member function is const, the "const" keyword comes after, so that's another precedent for postfix const. 
We are using three timers and create/destroy them dynamically.
In our case, we have `Connection` objects owned by a `shared_ptr`, which have two `asio::steady_timer`s as its members.
It seems that we should redesign our work with timers for the next version.
You hate auto too I guess. And template argument deduction.
That makes me sad.
I find const at the beginning more natural to read. One refers to these things as 'constants', so starting them off with that designation makes sense. Doing it the other way around makes it sound like Yoda has been checking in code. I also don't think of this as 'old' or 'C-style' or 'legacy' or a 'design flaw' or whatever nasty words you want to throw at it, and I don't agree writing it differently is somehow better. But ultimately the whole discussion reeks of tabs-vs-spaces: a pointless stylistic difference. 
About his `is_integral` implementation: What am I missing? http://coliru.stacked-crooked.com/a/3029b4fb832d24de Gives me true, false, true.
The archived page was up until very recently, it changed because Insomniac rebranded and I guess they didn't feel the need to migrate their engineering blog. The nullability tradeoff seems reasonable because an assert firing at a call site is immediately identifiable, whereas an unexpected mutation is not. I honestly have a hard time seeing this as any more than six of one and half a dozen of the other. There are cases where I agree that `&amp;`s make the code unnecessarily noisy, and there are cases where I'd the distinction would have been nice.
how does this differ from being a paid member https://isocpp.org/about/membership
Great talk as always from Roland Bock. The best talk so far from CppCon this year.
Very nice talk with some interesting tips. Regarding coding conventions, Alisdair and I are on the same wave-length. In particular, he has convinced me that functions should be declared auto f(...) -&gt; T or void f(...). Nice consistency and no longer a problem if the return-type is overly complicated. 
Why does the not null slide use a backslash as a path separator in the include statement? That's horribly non-portable and in addition a pain to type on non-english keyboards (on a Finnish keyboard it's either altgr-plus on Windows and Linux or alt-shift-7 on Mac).
In this case, you should create your own wrapper like std::array, so that you never have C-style arrays in your actual code. It's a shame you can't initialize std::array with a pointer, even if I understand why they designed it that way. In the case where you need to refer to always the same memory, it works pretty well and allows debug-time checks in case you need them, and no overhead in release if you don't want them. I worked with hardware before, and I wished I did that because that would have made solving some bugs when I messed up my pointer arithmetic and accessed the wrong memory. For DMA, it is indeed more tricky, I think they should have an overload for `std::memcpy` that would work with safe arrays without the need to cast them, with optional range checking if one so desires. Anyway, I think even in those cases there are ways to get rid of the danger of raw pointers/arrays and this should be preferable. Or did I miss something?
Proposal for C++20: make everything `const`, and require `mutable` instead for when you want to change the value.
&gt; There are cases where I agree that the extra `&amp;`s make the code unnecessarily noisy Except in any templated context where they not only make the code noisy, but also probably technically incorrect. But sure I mean let's throw away the language feature that is correct by default, does exactly what we want, and gives us a static guarantee of correctness, because we want to hire engineers who can't read documentation and have no working memory. It's not six of one and half a dozen of the other, it's just mind bogglingly terrible. You're trading semantic accuracy, hard guarantees, and the ability to reason about code, because seeing `&amp;` (which is incorrect in templated contexts, but good luck getting people to remember that!) is the warm blanket people need.
&gt; Anyway, I think even in those cases there are ways to get rid of the danger of raw pointers/arrays and this should be preferable. Or did I miss something? Eh, my argument is that for those few cases when dealing with actual raw memory, that arrays are not too bad. That said, I wish there was a simple way to have bounds checking on arrays, without losing the simplicity of abstraction. Some sort of "when I'm directly indexing into this I need some bounds checking, but the second I pass it off to be shoved into a hardware FIFO to get written over a bus, treat it like raw memory". There probably is a way to do all of this, and it probably involves C++ templates. The question becomes, is the overhead of abstraction and figuring stuff out worth it? Especially on embedded, where code size is still important. &gt; and I wished I did that because that would have made solving some bugs when I messed up my pointer arithmetic and accessed the wrong memory. Embedded is weird, the systems often provide stronger promises about memory layout, SRAM has O(1) access, and being able to futz around RAM at will is fun, and of course things are memory mapped left and right. Being able to write to random address that you know will do something special is super useful, because that type of code is often write-debug-leaveitalone, there isn't much cause (or benefit) to adding a bunch of abstractions on top of it. Until that one big bug that takes a month to figure out and all of a sudden one starts to wonder if maybe using a higher level language might've been worth it. I want something in between Rust and C, or some of the safety the fancier C++'s templates offer, but built into the language w/o the need for templates. 
That's just a Microsoftism. People on Windows are so used to type backslashes as separators that they keep it up in `#include` directives.
Errr?... What?...... Sorry I must have dozed off. I work in a safety critical industry like him, but luckily I have never met someone quite as boring and nervous. 2nd worse presentation of the year.
Is there a proper way to obtain an offset at compile time?
If you need a boilerplate script to create files, just change this one: https://chromium.googlesource.com/chromium/src/+/085507ab319a3daf13ec34dfe06bfa3d7d1390bd/tools/boilerplate.py
Not in strictly conforming C, as far as I know. Most compilers have builtins (google __builtin_offsetof) that do not rely upon undefined behavior, and simply query for information the compiler already knows.
&gt; how often do you have constant pointers to const? If you work with people who can't remember which const does what, a lot!
What I mean is that instead of declaring a `int[5000]` for your memory block, you could do something like a placement `new` on this part of memory (without forcing initialization if you don't want to), which gives you optional bound checking later. The overhead for a std::vector is minimal, you're just using 4/8 more bytes to store the size/address of the end. All accesses should be able to use direct addressing if you're not using debug. At least for x86 there is no overhead (easily checked with Godbolting).
Would be so great, but will never happen.
I know. But one can hope.
It's not just a warm blanket, these guidelines came to be because somebody had the rug pulled out from under them enough times in the past. In templated contexts, are you talking about overloaded operator&amp;? I'd presume people are aware of what they're doing and would correctly use references or std::addressof. If you're not just talking about that, then please enlighten me. I don't regularly write templates.
&gt; I'd presume people are aware of what they're doing So you presume that people are aware of what they're doing when it supports your position, but you don't presume that people are aware of what they're doing if they don't. If people are aware of what they're doing then: - They will write functions which don't use unnecessary/-obvious out parameters - They will read documentation and look at function signatures to understand what a function is doing and whether it mutates any arguments Therefore you should use mutable references, not pointers, since mutable references give you all the guarantees et cetera that you want, and none that you don't.
Out of curiosity, what was the worst?
It's reasonable to make the exception for templates because most code is not being written in a template context. Isn't that the C++ way? Library wizards and plebeian users? :P (I think this is bad, but the way the language is, it's hard to avoid that situation). I'm not defending out parameters and I don't think it's useful to accommodate people not reading function signatures and docs, nor do I think it's useful to accommodate people who don't understand the language. You are failing to convince me that mutable references are objectively better than not_null pointers. Don't worry, if I ever work for you I'll pass parameters in whatever way pleases you most.
Yes.
All the more reason I prefer const T since it gives const to the thing and not the pointer which is probably what you intended to do.
&gt; I prefer `const T`, as it is closer to natural language Is it though? Isn't, say, "integer constant" a more natural sounding expression than "constant integer"? I guess it depends on whether you use "constant" as an adjective or as a noun.
I've used a similar technique to implement (what the Standard would call) is_nothrow_convertible for use in is_nothrow_invocable_r, which performs an implicit conversion from invoke's result type to the specified R type. Asking what would happen if I called a function like your helper is the only way I know how to phrase this check.
We detect explicitness by asking is_constructible (explicitly) and is_convertible (implicitly). When they have different results, that's when we're dealing with explicit constructors. We implement what in a sane language would be `explicit(condition)` with overloaded explicit and non-explicit constructors, constrained appropriately.
`int mutable i;` or `mutable int i;`?
I would say that 1 barely matters in the scheme of things because the type is instantly recognisable in both cases. 2 is a rare operation, at least in my experience, and again the overall contribution to effort is minimal. 3 is not a good argument - the placement of that const is necessary because if it was prior to the function declaration it would clash with the return type. Any arguments between the two styles always come down to nitpicks. I think the const-next-to-ref looks ugly and I see it less often. Those are much better reasons. 
That is such a bummer... 
Show me how to do lazy evaluation of function parameters without macros. 
Let us know how you get on. Last time I tried it, every feature it had in addition to the standard Eclipse CDT either just didn't work, or crashed the IDE. 
That's for membership in the _Standard_C++_Foundation_ (See https://isocpp.org/about/) not membership in the ISO C++ Standardization committee WG21.
I've been playing around and reading closer, I think I agree with you know. However, I'm not quite there. I understand that if b was never used in such a way that it would "decay" into a pointer, which is basically always for the arrays in local scope, I see that it's symbol would be optimized away. Leaving only an immediate address embedded right into the instructions. With an offset computed from some stack allocated index variable. I imagine the same might be possible with a `char* const b`, but I'm not sure. Then you have the case where a function takes an array as a parameter. In that context, char b[] is actually synonymous with `char* b`. Because the function can't hardcore an immediate value, it needs to bring in the address. So this adds a layer of indirection. I suppose this is what is actually meant by pointer decay. However since pointers use index notation as an arithmetic sugar I'm not really sure that it's a problem that decay happens. It's necessary. Perhaps C should use the `char* const` and index notation would apply the offset to the constant base. However, you claim that b (back to `char b[]`) is not an "addressable modifiable" thing. I agree it's not modifiable, however it is addressable. Because b is synonymous with the first element of an array, and certainly any pointer decay would necessitate obtaining the address of the array base. Now what underlies my new confusion is that even an array of size 0 has an address for b. I'm not sure why one would want a zero size array, but it seems to actually just be an array of size 1. At any chance b is addressable.
To expand on this slightly, clang-tidy runs on the command line against one source file at a time, and although it is a static analysis tool many of the checks also suggest changes to your code. For example, there's a check which will find old style for loops and suggest changing them into range-for loops. It can even make those changes for you automatically, if you feel brave (I find this isn't always 100% reliable especially when applying many different types of fix at once). I know that CLion isn't free, but the latest version will run clang-tidy in the background and show display any warnings in the editor, which is very useful. 
In my opinion, I really don't think it makes that much of a difference. The difference in cognitive load is next to zero. I think the only difficulty that exists with reading it is if you're not familiar with how const works when pointers come into play. And if that's the case, either syntax is pretty difficult to read. The recommendation is simply because it's inline with the most commonly used style.
Well, either is fine, just enforce your preferred option in the standard.
Not in english. "Integer constant" to me sounds wrong. Not wrong wrong, but wrong enough. "Constant speed", "constant force", "constant integer". You don't say "force constant", but instead " force (applied to) is constant" . 
&gt; hen you have the case where a function takes an array as a parameter. In that context, char b[] is actually synonymous with char* b. &gt; I agree it's not modifiable, however it is addressable. The symbol 'b' does not have an independent address, I am not sure of the proper phrasing here. This idea took me awhile to wrap my head around... sorry for the poor explanation. Basically if you go char b[] = "XYZ" &amp;b You get the address of where 'X' is stored in memory. There is no symbol 'b' that you can take the address of. If you take a look at the raw assembly (or a really good symbol dump), you'll see that with a pointer, you have memory allocated for the pointer and the array, for the array, memory is just allocated for the array. To refer back to what you said earlier: &gt; I see that it's symbol would be optimized away. for char* b = "XYZ", b is bound to a variable that contains an address of the array. For char b[], b is bound to the array itself. for arrays of size 0, it seems like this is a [GCC extension](https://gcc.gnu.org/onlinedocs/gcc/Zero-Length.html). The spec itself says this is not allowed &gt;&gt; If the expression is a constant expression, it shall have a value greater than zero. Flexible Array Members are an exception, allowed only in structs. I haven't looked into the underpinnings of how they work, so I can't comment on them. :) 
Oh I just end up with nothing being const ever. This is not good either, though.
Nice talk. I think the concern over virtual function calls is a bit ridiculous really. 1. branch predictors work pretty damn good. 2. Stinks of premature optimization 3. We’re calling out to the cloud because it has resources not available locally. If a couple virtual calls is too much latency then you have other problems. 
This is really bad.
[Integer constants are an actual thing though](http://en.cppreference.com/w/c/language/integer_constant). In fact, almost all of the results I get when searching for "constant integer" are for "integer constants". The speed/force examples do sound pretty wonky, but I can't really put my finger on what it is that makes them different.
Everything is good compared to Boost.Serialization.
I have been eagerly awaiting the release of this talk in particular, thank you! I hope to be able to follow in his footsteps, let's see how it goes...
So it's just the case that b is synonymous with b[0], then taking &amp;b is synonymous with &amp;b[0]. Yeah, I was always under the impression that b was really &amp;b[0] therefor \*b was b[0]. In which passing b was passing a char\*.
[removed]
Because in that case, 'integer' is the attribute and 'constant' is the subject. In C++, though, const is the attribute.
So we're going with white for the bikeshed?
Reading overly-verbose code is like being talked down to like a child; I don't enjoy being patronized, personally.
Hear, hear! I have no idea why not_null is gsl material. It seems like a completely redundant concept for what the language already provides: references. I am very open to learning what the value of not_null is, but no comment in this thread, nor the points made in the article, are particularly convincing. 
Indeed. That entire section is prefaced by a long pre-rebuttal to posts like this specifying all the weaseling that is reasonable. &gt; We present a set of rules that you might use if you have no better ideas, but the real aim is consistency, rather than any particular rule set. It's pretty much a given that 1) no matter was picked people would complain and 2) picking nothing would cause an endless stream of issues
It is my understanding that in any decent implementation std::copy will be optimized to memcpy/equivalent where it could be used. Put more trust in the implementation and optimizations. And profiling. Especially profiling.
Can't tell if 'woosh' or another joke. :-S
It's even more a Visual Studio-ism, as the #include autocomplete defaults to backslash. It's one of my pet peeves as no one I know uses backslashes in includes even on Windows and it's always one of the first options I change on a VS install. 
This would break every single existing C++ program, probably without any exception. So, impossible for committee to accept.
If I have a constant integer value, I write it like I speak it, a const int. Or, maybe I'm dealing with a constant reference to an integer. That's how I say it in English so that's how I type it: const&amp; int. I write code in the way I think and reason about it. I think that's a pretty decent reasoning. OP is saying this is a bad guideline but doesn't give any actual reason why they think it's bad, other than to say "We know how it's better." No, I don't. How is it?
Now I'm self-conscious, lol. I assumed they were complaining about not being allowed to pass a const value to a function taking a non-const reference (which is obviously disallowed for good reasons). Did I get wooshed?
&gt; You are failing to convince me that mutable references are objectively better than not_null pointers. 'Better' isn't the word – they entirely obviate the need for `not_null`. ;-] I'm not anti-smartptr by any means, but `not_null` is literally only there to assert or throw when one screws up, not to enforce any real invariant or accomplish anything useful in properly-written code. I like the idea of knowing when I screw up, but altering my design and avoiding natural, idiomatic language features to accomplish that is extremely iffy (for me).
Since I consider const a qualifier on a type (therefore, an adjective) then no, "integer constant" isn't more natural for me as a native English speaker.
gcc and old Linux is my horror story as well (14:40 is where he touches that, not the only time either). He apparently had customers on RHEL 5, me, 6. The default gcc is **way** too old there and the support for new versions is **way** too short (2 years). I would not mind living unsupported, but the decision is not mine and there are formalities, even legal ones, that forces companies out of that. RHEL 6 goes out of life in 2020, mind. gcc version is 4.4. That means using c++ 2003 - in 2020?! Nuts. Luckily I am not there, I can move, but... really?!?!?!
No references involved here, just values, so the latter it seems. ;-D
But they must have had something stop compiling at some point, or they wouldn't have mentioned this, and that's not possible if the function just took a double by value.
1. there's also 'const&amp; Poison fetch()', which is how I would write it because that's how I would say the type name, a constant reference to Poison. 2. This version also makes your #2 a non-point, because making a value const&amp; is just as easy. 3. Constness of member functions comes after because that's how all qualifiers on function types are done, like noexcept. It doesn't take much reasoning to understand why, because it could lead to declarations like: const* Poison const noexcept fetch(); The precident here due to the impossibility of the compiler to determine which form is desired.
Maybe, but they must have misremembered it before writing the article, because what the article has to say about `const` is patently false for both C and C++.
Referring to [isocpp.org again](https://isocpp.org/std/submit-a-proposal), there's a lot more to submitting a proposal than just writing the proposal and mailing it somewhere. There's socialization and iteration with the community. Some of those people will be in the committee. And if you can't attend meetings for whatever reason, some of those people would likely represent your paper for you. Proposals that are presented by people who possess a passing familiarity with the idea and aren't enthused or excited by the potential improvement to the language face a very high bar. But I've seen many a successful proposal written by person X and presented by person Y. If you're working with the community on creating your proposal you ought to be able to find one person as passionate about the idea as you are. If you can't, you'll likely face an uphill battle getting a working group in the committee to be passionate about your proposal. TL;DR: The inconvenience or expense of attending a meeting usually isn't what kills a proposal's chance of success. 
Right, that's why I assumed they must have *meant* to talk about references, even though they didn't mention references explicitly. Wrong either way, just not sure how. 😛
I know that. You can't do that big changes in an existing language unfortunately.
in Visual Studio 2015 create a macro with this text and assign it to a keystroke/menu-item/toolbar-button: function pad(num, places) { var zero = places - num.toString().length + 1; return Array(+(zero &gt; 0 &amp;&amp; zero)).join("0") + num; } var d = new Date; var s = dte.ActiveDocument.Name.toUpperCase() + '_' + d.getUTCFullYear() + '_' + pad(d.getUTCMonth() + 1, 2) + '_' + pad(d.getUTCDate(), 2) + '_' + pad(d.getUTCHours(), 2) + '_' + pad(d.getUTCMinutes(), 2) + '_' + pad(d.getUTCSeconds(), 2) + '_' + pad(d.getUTCMilliseconds(), 3) + '_H_' s = s.replace(/[^0-9a-z]/gi, '_') hdr = '#ifndef ' + s + '\n' + '#define ' + s + '\n\n' dte.ActiveDocument.Selection.StartOfDocument() dte.ActiveDocument.Selection.Insert(hdr) ftr = '\n' + '#endif //' + s + '\n' dte.ActiveDocument.Selection.EndOfDocument() dte.ActiveDocument.Selection.Insert(ftr) When you run it -- it'll add guards to current file. Older versions of VS can be scripted in similar way
This is something I never understood and I think it is inherited fron the premature optimization that thrives among C devs, which brought it into C++. Never did bounds checking or virtual calls affect my work in C++ or other languages. To this day we get people using mysticism and feelings, instead of profilers.
Well you can make your own meta C++ template system if you really want this feature? Something that compiles easily to C++ and looks like C++ (isn't this what Qt does?). But imho it's a bad idea since other people won't know which language you're writing.
I think library [motivation](https://github.com/fraillt/bitsery/blob/master/doc/design/README.md) sections answers your question.
added boost serialization to my test project: bitsery is 8x faster on gcc and 6x on clang.
The main issue is that you lose the portability. At least we might get pure functions soon. I guess that would be good enough for me for the time being.
It's funny you first mention raw pointers, since this is only an issue for raw pointer types. 
That's true. I guess I got carried away. The closest thing to "suggestions" for C++ that I have seen would be (again in QtCreator): 1. [Code completion](http://doc.qt.io/qtcreator/creator-completing-code.html). 2. Real-time compiler warnings and errors (semantic and syntax), with color highlighting and popup hints on mouse-over.
bitsery was tested mostly on gcc and clang * `std:copy` is same as `std::memcpy` on gcc 7.1.0 * `std::copy` is 20-30% slower than `std::memcpy` on clang 4.0.0
Wouldn't it work if compiled on other system with static std library?
It would, unless some dependency, stdlib included, uses code that's only available on the newer system. There's a question of support for dependency "version 2017" being supported on system "version 2010". Not a fan of static linking, it is less efficient for big widely used libraries, takes more disk space, prevents dependency updates for security/bug fixing reasons...
Even if you would like Boost.Serialization you would use cereal as the sane version of it :)
Well these sort of things are what makes C++ faster than Java/C#. Sure it might not matter much in practice for lots of uses, but then again the performance is the reason lots of people choose C++ in the first place.
I haven't seen the talk, but if and when virtual functions are a performance bottleneck, it is usually not due to the indirect function call itself, but because the compiler is probably not able to inline it. In many many cases it also entails the baggage of more dynamic memory allocation.
Video is out: https://www.youtube.com/watch?v=Wl-9ozmxXbo 
Video is out: https://www.youtube.com/watch?v=Wl-9ozmxXbo
&gt; ... and not corner cases (how often do you have constant pointers to const?) So const reference is also a corner case? :)
This is a standard library optimization; compiler is not entirely relevant.
Video is out: https://www.youtube.com/watch?v=Wl-9ozmxXbo
Video is out: https://www.youtube.com/watch?v=Wl-9ozmxXbo
Good luck ! I hope our tools can help you. If you encounter any issues along the way, please submit a bug report in our GitHub project. Feedback &amp; suggestions are welcome.
Yes, exactly, the "zero cost abstraction" of templates is not just limited to avoiding the cost of a vtable lookup. It could also mean things like your memory is on the stack instead of the heap.
Actually, in this case, I would suspect the compiler. The difference would most likely come from clang not being able to satisfy aliasing requirements, and possibly switching to a memmove instead of a memcopy in some scenarios, which cannot be optimized nearly as well. Non-aliasing inference is definitely one of the areas where gcc edges clang out IIRC.
Yes, that worked! In combination with the fact that I had to be in a visual studio command prompt. Otherwise I got rc errors. Apparently the toolchain still depends on parts of the msvc toolchain.
Barely white, or sail white?
We read from left to right. Seeing "const" first is the best recognition pattern to draw the attention to the reader that some "const stuff" is being involved. What stuff that is, may require some more attention, at a second stage. This is why the guideline makes sense to me, from the cognitive psychology POV.
I also strongly disagree with that guideline, for two reasons. 1) You want the most important thing to be seen first. The data type of the value is more important than its constness (IMO). 2) Having const-on-the-right makes _everything_ intuitive: template&lt;class T&gt; using KT = const T; KT&lt;int*&gt; t; // Intuitively, this would map T to int*, making const int*. Intuition here is wrong. template &lt;class T&gt; using KT = T const KT&lt;int*&gt; t; // Intuitively, this would map T to int*, making int* const. Intuition here is correct. Similarly, within const member functions (which are const-on-the-right), all members also have const applied to the right: struct X { int y; int* z; void f() const { // intuitively, the type of y here is int const. Intuition is correct. // intuitively, the type of z here is int* const. Intuition is correct. Const-on-the-left is intuitively incorrect here. } }; By teaching const-on-the-left, we teach the exception rather than the rule. And there we lose the intuition and gain only confusion.
&gt; how often do you have constant pointers to const? Not often enough. I've seen a lot of times where people write: static const char* some_compile_time_constant[] = /* some array */; Here they forget that some_compile_time_constant is assignable, which can cause subtle errors.
`const&amp; Poison fetch()` is a compiler error. You certainly don't write that. On top of that, the notion of a constant reference is a tautology. All references are constant (which is why applying const to a reference causes the const to dissolve) template&lt;class T&gt; using KT = T const; static_assert(std::is_same&lt;int &amp;, KT&lt;int &amp;&gt;&gt;::value); What you really mean is a reference to a constant int, which is `int const &amp;` read from right-to-left.
Couldn't have Expressed it better myself.
Sorry, I don't get your meaning. Other than with `const T* const foo` there is no internal consistency argument about where to place the const with `const T&amp; foo`, as there is only one const.
References are the same story, though. The only real invariants they *actually* enforce is that they can't be initialized to null, and they can't be reassigned. The compiler doesn't require you to do a null check before initializing a reference from a pointer deref without additional analysis...analysis which could do the same thing for `not_null`. At least, as you said,`not_null` lets you know when you screwed up. I don't hate mutable reference params (I probably hate flipping between `.` and `-&gt;` more :P), I'm just not sold on it being the objectively better way. If the pro-mutable-reference-params argument boils down "it's the convention", I can accept that. Convention is more powerful than technical merit.
If it is a compile time constant, there should probably be a constexpr in front of that, but I get what you mean. However, do you think the error would be spotted more often , if people would write static char const* some_compile_time_constant[] = /* some array */; ? Honest question.
You're totally right, I'm not sure what before bed me was smoking.
You can also change gcc or clang (whichever easier for you) source code to implement pure function (if it is not already implemented) while waiting for it. If it is standardized people will merge your branch to master, otherwise, you can choose to use it even if not standard. Up to you.
GC latency and "memory for performance tradeoff" is the reason to chose C++ over Java.
`const int&amp;` reads quite correctly as "reference to constant integer." Sorry, but whichever way you try and spin it, both forms make sense, this kind of justification is pointless. 
*wistful sigh* I wish I had the opportunity to give you empirical evidence on that. But does that look like a compile-time constant to you?
exactly
It's actually less consistent than the uniform rule that const applies to the left. So if the real aim is consistency, OP position stands.
You could make the field private and make the graph a friend class.
... yes, that's my solution '1.' and it has problems that I describe shortly afterwards.
I think its not possible to statically link libc. 
It depends on the use case. I did some work where it definitely make a difference. Indirection, lack of inlining, looping and yes vector bounds checking all have a significant cost over the alternatives and in an inner loop executed millions of times per second those costs become obvious.
Or just RAII, deterministic release of resources is not something java excel at. It has finally blocks as its only real tool for this, because any given finalized might never run. The simple way RAII ties resource lifetime to a scope makes C++ suchban ideal tool for managing resources in a way I have seen in no other language.
Also, this ought to be compatible with the metaclasses proposal so that for instance one could restrict access of some members programmatically. eg. `my_metamethod.set_access(graph, ...)`. 
you need to be delusional and altruistic...
Well I don't really have the knowledge in compiler programming to make a change like that, and I bet many people much better than me for this are already working on this.
Ahh yes, I was reading on mobile and missed that. I would argue that if it's something that only `graph` needs then why are you trying to put it in `node`? Specific "class access modifiers" aren't very maintainable or extensible - you're tightly coupling the `node` with `graph`. I think what you really want is an interface. The interface lets you have `graph`'s caching fields whilst only allowing access to those fields to things that are aware of that interface.
&gt; if it's something that only graph needs then why are you trying to put it in node? Many reasons for this. For instance it can be to fit stuff better in the CPU cache. Or because putting it in graph may require additional dynamic memory allocations (eg at the minimum you'd have a std::vector&lt;int&gt; the size of your nodes set. While in theory this doesn't change the memory usage, in practice if you can call malloc once for your node instead of twice it's generally much better). &gt; I think what you really want is an interface. yuck! this is quite verbose, requires to find additional names (one per interface), and also remove some control on the data layout since now your cache is necessarily at the "top" of your class (cue introducing additional intermediary classes to do the class layout but at this point I laaargely prefer the "key class" solution). You'd have to do class graph_cache_interface { friend class graph; private: int cache{}; }; class node : public graph_cache_interface // yuck, but has to be public if we want to give graph access to it { public: void set_color(int); }; while I'd like to do class node { public: void set_color(int); graph: int cache; };
Why is it so bad? Sorry, never used Boost.Serialization.
You can have the same bug as with the *accumulate* if you use a `auto` in place of the `double`. *accumulate* is not really the culprit here :)
Eiffel has a feature similar to this with export clauses. If I recall correctly, and casting to C like syntax, it would look like: class node { export&lt;Any&gt;: // equivalent to public void set_color(int); export&lt;Graph&gt;: int cache; }; Of course, if "public" was used in place of export, and the default was equivalent to "Any" (which is the base of all classes in Eiffel), then that would work fine. public&lt;node&gt; is equivalent to protected. public&lt;None&gt; is equivalent to private.
aah well, even better if it already exists somewhere :p &gt; instance private allowing parametrization of this would be nice too. but it would be easier if the whole access modifier part was reified in some way. 
Fun fact: 1988's *Bloodsport* starring Jean-Claude van Damme was actually a low budget documentary about Dr. Stroustrup's time in grad school.
Honestly I don't want more access specifiers. C++ is, more than anything, moving away from Object programming and it's a good thing. If really this is something that you want a better solution would be to have a "friends" attribute for member declaration : struct A { void m(); }; struct B { private: [[friends (A)]] int i; int j; }; void A::m() { B tmp; tmp.i = 42; ... };
&gt; If really this is something that you want a better solution would be to have a "friends" attribute for member declaration well, if it was up to me, public / protected / private would also be attributes. However I don't understand how access specifiers relate to object programming ? it could even make sense in plain C, to allow only specific functions to access a given member of a struct.
Is there a pdf available? Didn't find one on the github repo.
It is a very interesting idea, that has complex implications. First of all I think from a parsing point of view there should be some sort of anchoring keyword to indicate what you are doing. But it sounds that this could be something deserving of a write up and then sent to the ISO mailing lists for judgment by real experts. What do people think? Is the entire modules, namespaces, types and access specifier story in C++ consistent? I sometimes feel that C# and Java have some good ideas in this area with packages (as modules AND as namespaces), I don't think access specifier per method and field is particularly helpful nor their insistence on not having functions without classes, but I like that namespace and module are tied together even if I understand why the same is not possible in C++ without breaking compatibility. I saw an idea recently maybe it was on /r/cpp even that maybe there was room for a language that took C++ but remained compatible with its core design ideas but broke with C and allowed for the creation of a language with the same core tenets and very very similar syntax but allowed to remove some of the problems. It would have to be like C++ so we can't just go to D language or rust. Is that a good idea or would it too little close to D and rust? or serve no purpose?
https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Friendship_and_the_Attorney-Client 
well, all this boilerplate is what I want to reduce.
I was thinking eggshell
Some misconceptions there. Java also has try-finally blocks, and lambdas make it possible to extend to types that don't implement Closable. Which is a common pattern in functional programming languages, for example *handle* in Haskell. RAII as used by C++, was also present in Modula-3, Object Pascal, and was introduced in Ada 95, D, Swift and Rust.
I don;t understand silly arguments in this thread about intuition and such. To me the `const` (and any other attribute` always followed the rule of thumb: if it's to the left of the `*` then it applies to the pointee, otherwise - to the pointer itself.
I agree, but unless one is doing tight loops for HPC, Fintech or 3D rendering, for 99% of the population at large it barely matters.
Whilst this could save some you some typing, it does not leverage your buildsystem. Furthermore I think it is a good idea not to store generated artifacts in version control. Do you save the output of parser generators in version control ? 
What about having second vector for cache, or storing pairs?
The real problem isn't that `const` is in the "wrong" place, it's that C's syntax means that types need to be read "backwards". If we wrote types left-to-right like the rest of the code, then nobody would ever get confused about which `const` applies to what. Imagine if we could write: auto p : * const * const char = nullptr; // p is a (mutable) pointer to a const pointer to a const char auto foo(a : &amp;const int) -&gt; float; // foo is a function taking a reference to a const int, returning a float C's syntax gets even worse when you introduce function pointers, requiring the reader to "spiral" around to work out what's going on. And even if you know the rules, complex types can still be next to impossible to decipher without an intermediate typedef. This is a legal line of C++ (and C), god help us: int *(* (*p)(int (*p)(int (*p))))(int (*p)); // what the hell is this? 
&gt; What about having second vector for cache, or storing &lt;node, cache_val&gt; pairs if you want to keep them in one place? In both cases you loose the possibility to arrange the data layout however you like, if for instance you want to do tight packing of the node structs or stuff like this. Having a second vector could cause cache misses since it may end up being allocated at a different place in memory from the nodes. 
Depends on which libc you use. If you use musl libc, you can statically link it in its entirety. If you use glibc, then it depends on which functions you use from it, as some of them require linking to a shared part of the library which youcan't statically compile in.
Sure, it works for integer, but the problem that's being dicussed is that it doesn't generalize.
I think we should extend the standard to allow duplicate `const` specifiers and get the best of both worlds: const int const x = 42;
On slide 28: Can't this simply be reduced from if constexpr ( constexpr auto check = check_order_by_arg(expressions...); check ) to if constexpr ( constexpr auto check = check_order_by_arg(expressions...) ) ?
Understandable. But this more about talking to the compiler like it's a child, not other programmers.
Not when using an opt-in mechanism such as metaclasses!
White? I thought we agreed on black?!
If you,re really desperate about data packing then you have inheritance
&gt; compilers may cache TLS To me it looks like a compiler bug. Is it a bug or is it allowed for compler to do that? Please explain. &gt; If such project exists So, you didn't mean some really existing thing. We are discussing things from your imagination all this time. &gt; I should start looking for such projects I don't expect you do that. I expect people do their searching **before** talking, not **afrer**. For now I see no **evidence** of their existence. At this point it would be much more sense to discuss UFO or Santa Claus, as they have ton of **evidence**. &gt; from "problem does not exist" to "problem does exist..." I'm open for new things. If such a project would exist, it would prove that I my assumption about your example was incorrect. But there are none. Nobody did that. Nothing. Except your imagination. 
Yeah sometimes I resort to cpp and hope for the bets 
Version 1.3 released today. https://github.com/Caphyon/clang-power-tools/blob/master/CHANGELOG.md 
Version 1.3 released today. https://github.com/Caphyon/clang-power-tools/blob/master/CHANGELOG.md
I had to double check that I was on r/cpp. I did look like r/programmingcirclejerk for a second.
That's not refactoring, that's literally rewriting.
This is my kind of talk.
Regehr is considered a specialist in the field of UB, for anyone who hasn’t heard of him. He teaches university classes about UB. 
Your post has been automatically removed because it appears to be spam. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/77ftk5/the_insertion_performance_of_a_singly_linked_list/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This "speaking out loud" is inconsistent when read left-to-right, while it works for everything when read right-to-left.
Just reversing the order does not solve the actual problem, namely that in certain situations const has the same semantic in multiple places.
I agree with this point, but reading right-to-left itself isn't my natural way of reading things. At this point, my point is just opinion and personal preference, but I do see where reading from right-to-left results in a consistent reading of all type variations. I appreciate following this discussion because it's given me more to think about.
Great talk. Also [his blog](https://blog.regehr.org/) is worth reading. Possible starting point: [A Guide to Undefined Behavior in C and C++ (2010)](https://blog.regehr.org/archives/213)
I just dropped a little tool for those who don't/can't use tools you describe in your post. (for the record: I didn't downvote your comment) 
I mentioned try/finally, but they are a kludge. They just add one more layer onto the places you have to handle exception safety. That is both good and bad. If you just need to sure to close/release a resource after using it briefly this is great. But if you have two resources and they each might throw on close/release it is very hard to deal with this and I am unaware of a graceful way to handle it in Java. I forgot about Rust having RAII and never used the others
Off-topic.
I would argue that the type is the more important piece of information, rather than the immutability, especially since I prefer to make most of my variables const.
`clang-tidy` is such a lovely tool, but like most tools like this it feels built more for linux devs than Windows devs. Any help evangelizing for its usage on Windows is good stuff, imo I develop primarily on Ubuntu now that I'm able to, but clang-tidy and clang-format have been *so* helpful in modernizing and updating this codebase written in 99 (lol). Going to have to remember to add your video to my watchlist!
Well that's two rules: one for pointers and one for everything else. Putting const on the right reduces it to a single rule, improving consistency (by a very small margin).
How would one go about building intuition for when this would be true? Or is it a (super) case by case thing where we can only see by benchmarking?
I don't know the history, but I assume the reason C allows "const int" is because it's more intuitive to English-speakers, who put adjectives to the left of nouns. If types had been left-to-right from the start, we wouldn't have needed (or wanted) the option of writing it both ways because the only way to write it would be with modifiers on the left.
I’m glad you like the idea. We’ve been hard at work on our tools to help on this path (PowerShell scripts and Visual Studio extension). You can explore these on GitHub (link is in this thread).
Simpler solution: 1. Use pragma once. 2. Stone anyone who puts symlinks inside a source repo. 3. There is no step 3.
Thank you! Really appreciate it :)
That proposal was last revised early this year: https://www.dropbox.com/s/x37mtgjh5vgadud/D0288R2.pdf
I'm not a fan but I use auto occasionally. It can be handy. Default args is another level. To me every function with a default argument looks like a bug waiting to happen because someone at some point will forget providing that last value and lose time over it instead of a compile error.
[removed]
You only introduce a single new name per type; you can reduce that boilerplate down to a single mixin, and optionally an alias template to avoid `typename` noise in generic contexts. This is minimal enough for me.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/77h5yc/i_seriously_need_help_just_finding_a_program_to/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
is it a white-colour bikeshed, or a bikeshed coloured white?
So we aren't getting rid of the cpp files with modules? We still need a mpp file (for modules) and the cpp file for the code implementation? Does this work the same in clang / vs implementations? Why can't we just have mpp files, which would have the modules declarations and code implementation like say Java or C# do?
Could you explain how does this differ from std::tuple's use of EBO? 
I think at least part of the reason is to avoid having to make significant language changes. The current changes apparently add nothing in terms of language features.
Except the software I use often feels so sluggish. The android phone I'm writing this on is horribly slow. Efficiency matters.
Luckily redhat had devtoolset so you can easily use the latest compilers while still maintaining compatibility with standard rhel6
Another reason is that just being able to say `p.first` (or `p.first()` as in this case) is nicer than having to say `std::get&lt;0&gt;(p)`. I hope that `std2::tuple`, if such a thing ever happens, has a specialisation for two elements which adds `first()` and `second()` member functions. Then `std2::pair&lt;T, U&gt;` can just be a straight alias for `std2::tuple&lt;T, U&gt;` and everyone will get the benefit of a compressed implementation for "free".
Encapsulation is one of the main tenets of Object programming. "Encapsulation is an object-oriented programming concept that binds together the data and functions that manipulate the data, and that keeps both safe from outside interference and misuse.": Wikipedia Object programming. I don't say that it's bad but over-relying on it leads quickly to headaches. For a language like Java that enforce this at runtime that might be interesting but for C++ where it's all compile-time checks that can be overridden by the user by change the header... As for making public/protected/private attributes that's not a great idea, the section idea is pretty great for simple access specifiers and avoid text retyping, the thing is that your idea address some niches problems and so case per case is a better approach here. Also using the same syntax to describe the accessibility of something and who can use it is confusing and seems to imply that the current class couldn't use its own members. 
Having to keep your interface and implementation separate, or else recompile the world when you change an implementation detail, absolutely sucks. Surely, *surely*, in 2017 we can design a module system that knows whether or not you've changed the public/exported interface, and therefore whether it needs to recompile dependent modules? Why do I, as the programmer, have to take care of this myself?
I actually raised the GH issue that prompted this. Whoops. I'm an advocate of the following styles: ``` T T const T &amp; T const&amp; T * T const* T * const T const* const ``` Reason being is that `const&amp;` and `const*` are actually special tokens themselves, not merely references or pointers to actually `const` objects.
Except it's not int a = 42; const int&amp; aRef = a; cout &lt;&lt; aRef &lt;&lt; "\n"; ++a; cout &lt;&lt; aRef &lt;&lt; "\n"; If it was really a "reference to constant integer", then its value wouldn't change.
You mean header files?
&gt; But if you have two resources and they each might throw on close/release it is very hard to deal with this and I am unaware of a graceful way to handle it in Java. Java 7 added [try-with-resources](https://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html), which is pretty graceful I think.
What I mean is that without modules we need hpp and cpp files, in the video seems that with modules we will need to have mpp and cpp files. What I am asking is why we can't have a single file with modules declarations and the code implementations instead of having two different files for each one.
So, when will VS get modules support (and I really mean VS and IntelliSense, not MSVC)?
Well, fair enough on the API front of things. My point was more along the line of: OP needs to clearly explain why his class is preferable to: template&lt;typename A, typename B&gt; struct tight_pair : public std::tuple&lt;A, B&gt; { using std::tuple&lt;A, B&gt;::tuple; A&amp; first() { return std::get&lt;0&gt;(*this); } B&amp; second() { return std::get&lt;1&gt;(*this); } A const&amp; first() const { return std::get&lt;0&gt;(*this); } B const&amp; second() const { return std::get&lt;1&gt;(*this); } }; If he wants people to make active use of it.
&gt; Could you explain how tight_pair differs from std::tuple's use of EBO? Note that `std::tuple` isn't required to perform EBO.
I've deleted my comment because any further discussion is a waste of time. 
Aaaah, good point. I've really been taking that for granted
Maybe we'll be able to take an ABI break sometime in the next 300 years and implement compression :/
100% agreed -- I'd just typed up [this example](https://godbolt.org/g/j8nkuD) on godbolt.org to ask the very same thing...
How cam modules reduce PIMPL usage? Given the following code, will it be possible to convert it to a module without polluting the importer with Windows macros `MIN`/`MAX` or Linux macros `minor`/`major` etc.? // header =============================== #include &lt;memory&gt; struct window { window(window* parent); private: struct impl; std::unique_ptr&lt;impl&gt; impl_; }; // source =============================== #ifdef WIN32 #include &lt;windows.h&gt; struct window::impl { HWND hwnd = nullptr; }; #else #include &lt;xcb/xcb.h&gt; struct window::impl { xcb_connection_t* connection = nullptr; }; #endif
did you just assume the paint color i want
yes
Yeah, I was like "Wow that guy sure sounds like Titus!"
This looks awesome. Can’t wait to try it out!
In order for a consumer to put an object on the stack it needs to know the size of that object at compile time. 
Maybe I can clarify. I agree that putting virtual calls in the middle of a tight loop could be disastrous, but the talk was about the design and implementation of a cloud service SDK. To be clear, a list of things you should not do on every iteration of a tight loop when perf is paramount: - virtual function calls - start threads - allocate/free memory - call std::this_thread::sleep - while(true); ... - kick off a request to a cloud service
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The list of root causes is very long. Indirect function calls are not in the top 10
Not sure if sarcastic...
It's a bikeshed **colored** white.
`const` in C++ is a qualifier, not an actual constant (as in the noun), so yea, it makes more sense to be a prefix.
&gt; You want the most important thing to be seen first. The data type of the value is more important than its constness (IMO). The problem I see with that is that you could easily read the type and then forget to read the rest of the line (ie. the const) which would be problematic. If you start to read a type and see `const` you're forced to keep reading to know what the type actually is. It's nigh-impossible to misread the type that way.
The problem with that is you can easily read the type and forget the rest of the line (ie. it's immutable). Having the const first means you're forced to keep read the _entire_ type.
Yes, that's a valid question. I just thought that, in your first sentence &gt; So we aren't getting rid of the cpp files with modules? You meant hpp instead of cpp, since people usually want to get rid of header files.
I never got how this differs from lock free. I know I went to a talk in 2015 where this implementation was just called lock free.
A pattern I've used to sort of solve this issue before is to define a pure virtual class that your graph class would implement, declare all the methods that potential classes (e.g. your node class) would want to use as public member functions in that pure virtual class, and declare them in your graph class as private member functions. This way, nodes can access your graph through the interface that they know it as; meanwhile it restricts any access to classes who know graph by its direct type. These nodes would need to be passed an instance of the interface reference. One downside to this approach would be creating various interfaces for various bits of functionality, and the slight performance hit that comes with virtual methods and such. It's *a* solution that's currently do-able, however.
The problem is support. Only gcc 4.4 has long term support on 6. Besides, with C++11, the compatibility had to be broken in glibc++.
The implementation of such needs often ends up in having the "base" function who deals with all that can be thrown at it. Otherwise, say hello to copypasta(duplication). When that is the case, multiple overloads are largely noise. "Explicit &gt;&gt; implicit" is fine, but it's not the only consideration.
Best. Guideline. Ever.
There are many reasons for it to happen, that is why we have profilers.
While the solution is elegant, I for one detest having generated source files (headers and cpps alike) in my build system. 1. There is no "right" version when you're editing files. You typically want to "see" the generated file, but edit the original file. Similarly the IDE needs to use the generated file for indexing and the code model, but should only navigate and open the original files. 2. Compiler warnings/errors have the wrong file names and line numbers.
This is actually a matter of implementation. Specifically, if the compiler produces identical BMIs for changes that do not affect the module interface and the build system is able to detect this and skip recompiling the module's consumers, then it can work exactly as you wish. To put it another way, nothing in the current Modules TS specification prevents this. Specifically, with modules (unlike headers) you can define non-inline functions/variables in the module interface file. In fact, it would be interesting to check which compilers already do this. I suspect some of them may store location information (line/column) which will get in the way.
The compilers in devtoolset for rhel6 still use the old ABI. You don't need to install anything on the machines where you run the binaries so I fail to see the problem.
You often end up with software that is slow yet has no hotspots. All the small inefficiencies everywhere add up
Really good question! Yes, modules will do the trick: #ifdef _WIN32 # include &lt;windows.h&gt; #else # include &lt;xcb/xcb.h&gt; #endif export module gui; export struct window { ... private: #ifdef _WIN32 HWND hwnd; #else xcb_connection_t* connection; #endif }; In fact, we do something like this in our [`butl.process`](https://git.build2.org/cgit/libbutl/tree/libbutl/process.mxx) module.
When you export the `window` struct (like in my answer to OP), the compiler knows everything about it, it's just `HWND` or `xcb_connection_t` (or any macros mentioned) are *visible* to the consumer.
Ok, I've done a couple of quick tests: 1. Change exported function implementation (i.e., a line in a non-inline function body defined in the interface unit). 2. Change exported function argument name. 3. Add a comment (extra line) before exported function. With VC only #3 produces a different BMI (so my suspicion that some of them store line/column info is correct). With GCC and Clang all three result in different BMI though I vaguely remember hearing that at least Clang stores a timestamp in the BMI.
Yes, but there are many decisions that don't have anything to do with compiler efficiency as well. Using C++ to implement a sorting algorithm won't help if the developer just codes away some bubble sort implementation. And if C and C++ compilers are somehow seen as the pinnacle of compiler performance in 2017, that wasn't always the case going back to their early years, when reading books like Zen of Assembly Programming was compulsory and the percentage of inline assembly more than half of the application code.
I completely agree. I misunderstood your 3rd point (I thought this was about something running in the cloud, not to access the cloud). Btw.: I'm sometimes surprised, how much tmp people are willing to accept just to avoid runtime polymorphism. Use the best tool for the job.
Afaik You still can't use newer (c++11 and later) standard libraries, can you? 
That's how redhat devtoolset does it. The newer parts of the stdlib not found on standard glibc on rhel6 is statically linked in. That way you can compile using the latest GCC and have it run on vanilla rhel6
Sure, and the point still stands. Virtual functions and pointer chasing in general can absolutely have a noticeable effect on performance.
Awesome, thanks! 
Even if the compiler stores (line/column) it could just recompile the current module without recompiling the dependent module if the public interface didn't change. There is one very important question. How fast can the module interface get extracted from a module that includes all its code in the interface? Because this needs to happen very very fast in order to update syntax highlighting and code completion of dependent modules in real time. Especially if I change a module very deep in the (acyclic) module graph. Also as one of the million end users of c++ I really don’t care if the compiler may not/might/can/should/will/is become a build system! I expect (hopefully very soon) that my IDE either has a ‘build system compiler’ or a ‘compiler and a tightly integrated build system’ that just solves all these problems. 
Get off... that's high treason over here.
It isn't preferable, it's clearly written at the top of the README: *« It is not meant to be anywhere near serious, but it was a fun little project [...] »*
Great. Must dependent modules be recompiled if the size of an object changes (eg. adding a private member variable?). I assume so. 
Apart from the fact that `std::tuple` is indeed not required to perform EBCO, it can't fully perform it (inherit privately from the stored element types) because if one of the empty classes has a conforming `get&lt;I&gt;` method, it will be found during the structured binding lookup before the namespace-level `std::get`, and since the tuple would inherit privately, you would get an error because of structured bindings preferring the non-accessible `get` method from the base class to `std::get`.
Yes, since you have changed the exported entity then you have changed the interface.
I don't want to change the comparison back, it was the only slightly original and actually *fun* part of the whole project :'(
There are two broad software development philosophies: "*I want things to work auto-magically*" and "*I want to understand how things work*". In my experience the *auto-magic* approach never works out for any non-trivial piece of software.
This is interesting. So a BMI can contain additional information aside from the interface? Meaning that a build system can't rely on the hash of the file itself if it wants to support minimal recompilations of dependent modules? Then the BMI should include an internal hash over all content that is relevant for external interface. 
Sure you can. And it will run on standard rhel6 since the extra bits in the stdlib is statically linked in 
&gt; Then the BMI should include an internal hash over all content that is relevant for external interface. Yes, that would be one way to do it. We would need a way to query it (the format of the BMI is implementation-specific). Or we could ask the compiler (with an option) to print it (to STDOUT) while compiling the module interface file.
I fully agree. I think you misunderstood me. What I wanted to say is that a complete system that delivers all the expected services needs to be very tightly coupled anyways. Thus as an end consumer (who of course needs to understand every tiny detail of it) I just don't care if I get this system directly with my compiler, or if I need to install an separate build system (that is specially designed) for my compiler. 
What about users that need to target more than one compiler? With your approach they will need to write and maintain buildfiles for every compiler-specific build system (or use the *least common denominator* approach like CMake/Meson).
FP people are like [vegans](https://www.google.hr/search?q=when+you+are+a+vegan+and+haven't+told+anyone) of programming, the first example that is "WROOOONG!!1!1!!!" is perfectly fine beside the name. No need to bother people with partial app and FP. I always give my predicates "question" names (is_bla, has_bla, valid_bla) but I would just call it a good naming, not some magical outcome of my enlightenment.
Yes, but it should not have to know all the internal (private) details. Unfortunately it has to know private function signatures due to the (imho broken) overload resolution rules and if you want to default the special member functions it even has to know all the details about private member objects. I hope this doesn't continue with modules.
&gt; So creating a new package + build tool wouldn’t solve anything today. Uh, I guess I will go cry in the corner... Seriously, though, if anyone wants to get a feel for what using a well-integrated C++ build toolchain can look like, check out the [`build2` intro](https://build2.org/build2-toolchain/doc/build2-toolchain-intro.xhtml#intro). And, just for the record, most of what the author claims can't be done (like a build system discovering which modules are being used), is working pretty well in `build2`.
&gt; If it was really a "reference to constant integer", then its value wouldn't change. It is a "constant reference to an integer" and it is quite clear what it means - "cannot change referenced value" and not "referenced value is a constant".
Seems like mpp files are hpp files with a slightly different name.
&gt; Python has pip, JS has npm, Rust has cargo, Ruby has gem. Heck, even Perl has had cpan for decades. What does C++ have? `rpm`, `deb`, `ports`, etc. Of course Windows is a bit deficient in this area, but every other OS is well covered. Since the article mentions cURL and openSSL, I certainly don't want dozens of copies of security-sensitive libraries included with various applications with no centralised update mechanism.
&gt; FP people are like vegans of programming, Knock this off, would you? I'm not a vegan, but my wife is and so are several of my friends. She's quiet and doesn't make a fuss about endless jokes like this, but I personally get really tired of this. And let me say that the people who are really vocal about their eating habits, at least in my circle, are people talking about eating meat. If I hear one more person going on about their bacon... Keep it professional. Make your point without beating on some group or other, particularly one that has nothing whatsoever to do with programming.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/functionalprogramming] [Think of Function Objects as Functions Rather Than Objects • r\/cpp](https://np.reddit.com/r/functionalprogramming/comments/77l2r0/think_of_function_objects_as_functions_rather/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Wow what a sour grape of a human.
Using system-installed libraries works well for mature ones (like those you've listed) where you usually have no need for multiple or even the latest versions. Where we need a C++ package manager is obtaining and building (from source) rapidly-developed libraries for which you may want to keep multiple versions, built with the same compiler(s)/option(s) as your project, etc.
uWebsocket has a backend for asio as well and I'm fairly sure the author does benchmark based on epoll/kqueue so asio is def the culprit there.
There is also "I know damn well how it works, but I really don't want to be bothered by it unless absolutely necessary." Or as AmigaOS put it, "Simple things should be easy. Complex things should be possible." 
In principle it should only have to know if a special member function is trivial or not. If it is - great, no problem. If it isn't, there must be an implementation somewhere that must be called. 
&gt; Seriously, though, if anyone wants to get a feel for what using a well-integrated C++ build toolchain can look like, check out the build2 Introduction. Sorry, but after reading the Introduction I have no idea as build2 can be used, for example, for development of a library with several dependencies and how to compile and test it by several compilers (or several versions of same compiler). Where sources of library should be placed? How to store list of dependencies under Source Control? How to switch from one compiler to another? I don't say that `build2` is useless. But I don't see how to use `build2` from this Introduction.
disclaimer: this is not portable. For instance clang doesn't consider ((Type*)nullptr)-&gt;operator()(), not to a be a constexpression. Also the function conversion operator is also not constexpr for now with clang meaning there is no correct way to do this with clang.
I am not sure if you've read the introduction until the end, I believe it answers all of these questions (except, perhaps, about the source control) towards the end. Also, if you rather prefer looking at example, you can grab the packages (which are just `.tar.gz` archives) from the [hello repository](https://build2.org/pkg/hello) and look inside. You can also take a look into their [git repository](https://git.build2.org/cgit/hello/).
How can you tell that someone is vegan? You don't have to, they'll tell you.
And what if applying AAA? (More like Always Auto with C++17) In this case, `auto` is like `var` in other languages, and `const` relates to the variable declaration. What should be preferable in this case *and why*? `const auto bikeshedColor = Color::white;` or `auto const bikeshedColor = Color::black;` P.S. Or maybe use `#define let const auto`?
I could certainly use this. Something like this: class foo { public: ... friend class bar: ... friend class bar, baz: ... }; It's quite a common thing to have a complex subsystem spread over numerous classes. For functions that are related to the internal workings of the subsystem, you can either: - Put them in the public section, and thus grant access to everyone and their dog, even through it is strictly internal and none of their business. - Make the other classes friends, even though they only realistically need a handful of functions for access. - Put together some complex organisation using not-quite-private pimpls in which access to specific features is cleverly hidden from the outside world. Yes, it works, but it's a pain to deal with. So yes, having additional access qualifiers would certainly fill a niche. 
&gt; it answers all of these questions Not in my case unfortunately. I don't understand where are source files and where build diriectories (I mean `hello-gcc5-release` and `hello-vc14-release`) must be created, and were build commands must be run. May be if you add directory names in your Introduction then it makes things more clear. 
Got the opposite experience. A lot of "magical" stuff always "just worked" for me and allowed me to make stuff really quickly.
But then if this changes the ABI breaks, which is if I'm not mistaken the n°1 reason for pimpl.
*insert Shia LaBeouf here*
Not sure what the point of the article is. Use verbs to name your predicates instead of nouns? Also it talks about partial functions but then immediately dismisses std::bind?
The `hello-gcc5-release` and `hello-vc14-release` directories are `bpkg` (package manager) *configurations* (i.e., a place where you build things with the same compiler/options). They will normally contain sources for packages that `bpkg` downloads from the repositories (in-tree build). You can also build your projects in these configurations but in this case you will normally keep your sources somewhere else and only create build directories there (our-of-tree build). Let me also readily admit that the way `build2` does this is very different from the convention so it might take some time to wrap your head around the mental model. But there are good reasons (like cross-compilation, ability to easily maintain multiple builds of the same code, etc) for doing it this.
I'm in favour of sandboxing, but not at the expense of having a single distribution mechanism, controlled by MS, with policies that are unrelated to app safety (i.e. censorship by the Store provider).
&gt; The hello-gcc5-release and hello-vc14-release directories are bpkg (package manager) configurations (i.e., a place where you build things with the same compiler/options). Can you explain this on simple examples? Something like: I clone repository from my library on my new laptop: [~]$ hg clone https://bitbucket.org/eao197/some_my_library Then I enter into directory with my library: [~]$ cd some_my_library And what then? Should I call `bpkg create` from this? Like: [~/some_my_library]$ bpkg create cxx config.cxx=g++-5 config.cxx.coptions=-O3 And then call `b` to make build? Or should I do something like: [~/some_my_library]$ mkdir build_gcc_5 [~/some_my_library]$ cd build_gcc_5 [~/some_my_library/build_gcc_5]$ bpkg create cxx config.cxx=g++-5 config.cxx.coptions=-O3 [~/some_my_library/build_gcc_5]$ b I'll like to see step-by-step instruction which includes names of directories involved in build-process. &gt; Let me also readily admit that the way build2 does this is very different from the convention so it might take some time to wrap your head around the mental model. I've seen different build tools and package managers. I even made own build system and use it for long time. So there is no problem to study yet another build system. The problem is that your Introduction is not as clear as I want.
So you're just making use of the static function present in lambdas without a capture-list ? why not just store the function pointer address via 'auto non-type template parameter' and build the macro around that? e.g. https://godbolt.org/g/DEJhDy (note, GCC fails to take the function pointer address as a template argument, I believe this is a bug)
I'm not sure I totally understand what you're saying. It's certainly doesn't seem like something that I've experienced.
Dude, you think you're tired of it? I'm a level 5 vegan; I haven't had a meal in two years because I've been searching for something without a shadow. These jokes make me sick to my very-empty stomach.
Vcpkg works ok. Package selection is limited and I had issues with some 64 bit builds and some updates but when it works it's good.
It makes no sense to break heaps of code for no gain. &lt;hottake&gt;Go use PHP if that's your fetish.&lt;/hottake&gt;
Ok, fair enough. Let's say your library depends on `libsqlite3` which you would like to get from a package repository. And you would like to build everything with GCC and Clang. This is how you could do that: $ hg clone https://bitbucket.org/eao197/my_library # Create a gcc configuration and build libsqlite3. # $ mkdir build_gcc $ cd build_gcc $ bpkg create cxx config.cxx=g++ $ bpkg add https://pkg.cppget.org/1/testing $ bpkg fetch $ bpkg build libsqlite3 $ cd .. # The same for clang. # $ mkdir build_clang $ cd build_clang $ bpkg create cxx config.cxx=clang++ $ bpkg add https://pkg.cppget.org/1/testing $ bpkg fetch $ bpkg build libsqlite3 $ cd .. # Create out-of-tree build of my_library/ in build_gcc/ configuration. # $ b configure: my_library/@build_gcc/my_library/ $ b build_gcc/my_library/ # The same for clang. # $ b configure: my_library/@build_clang/my_library/ $ b build_clang/my_library/ # Develop my_library some more and test changed with gcc &amp; clang. # $ nano my_library/source.cpp $ b build_gcc/my_library/ build_clang/my_library/
Ok. I think I've took the picture. But as I can see your approach is not an easy one. An user must do too much actions which can be done automatically by build tool and dependency manager.
The point is that if you think of a functor as a predicate or function instead of a class, a better name will naturally emerge for it. Although (if you make an effort) you can come up with bad names no matter how you think about it :).
So, as I understand it, we gained nothing with the proposed module implementation except compile time? We still have to separate declaration and implementation into two files? For me the redundancy of writing code two times (declaration and implementation) was always the biggest drawback of C++. If this implementation of modules goes through to be the final version we will probably never get rid of the good old two files per implementation thingy and that makes me sad. I learned to love C++ since the C++11 standard came out. I started to be a modern and usable language again, but the need for hpp/cpp (and now mpp/cpp) files is something we shouldn't have in the year 2020 (when the next standard rolls out). SAD.
Thanks for this, I was reading the build2 introduction last night and I had a similar question. Presumably in the above example `my_library` could state in its config files (manifest?) that it depends on `libsqlite3` from cppget.org, to save users having to add/fetch this repo manually for each build config? CMake's `ExternalProject` is pretty flaky in my experience, but when it works, it makes this nice and easy: I can simply create a build directory, `cmake /path/to/source/` to configure and then `cmake --build .`, with my dependencies being checked out and built with appropriate compile flags. &gt; `b configure: my_library/@build_gcc/my_library/` What does the `@` symbol here mean?
Even simpler solution: use IDE that support include guards, like Qt Creator (will create them automatically).
&gt; For instance clang doesn't consider ((Type*)nullptr)-&gt;operator()(), to a be a constexpression. Because it's `UB`. 
Wow, so I guess the only people more tiresome than vegans are people married to vegans.
I was referring to the second part of your statement where you implied that `const T* const` is rather a corner case. What I've tried to imply is that `const T&amp;` actually implements such 'corner case' semantics. Maybe I misunderstood you in a sense that you meant that not many people use `const T* const` in C++ world but rather `const T&amp;` which is what I definitely agree with.
It may not be one-click, but it is flexible and without magic; you can see clearly where things come from and where they go as well as when happens when. Also note that the things that require multiple commands (like setting up the configuration) are normally not performed very often.
Isn't there opt-in EBO in MSVC since 2015? I thought that it would be opt-out in the next ABI-breaking release.
Agreed. No other comparable language requires the programmer to duplicate things like C and C++ do -- Java, C#, Rust, Swift, Go, Ada, Fortran etc etc somehow manage handle having the interface and implementation in the same file. The idea that even in a module-enabled world we're going to have to continue to write everything twice, flicking between two files, editing things in two places, making sure everything is sync, makes me very sad. By all means provide a method to split interface and implementation into separate files, if this makes it easier to modularise legacy code. But make single-file modules the default going forward. It's 2017, for goodness' sake. We shouldn't still have to deal with 1970s limitations.
&gt; Presumably in the above example my_library could state in its config files (manifest?) that it depends on libsqlite3 from cppget.org, to save users having to add/fetch this repo manually for each build config? Yes, but not exactly. `my_library` can specify that it depends on `libsqlite3`, the required version range, but not which repository it comes from. Given this, however, you can already reduce the setup steps to (no need for `b configure:`): build_gcc/$ bpkg add https://pkg.cppget.org/1/testing build_gcc/$ bpkg fetch build_gcc/$ bpkg build ../my_library/ In the future, however, you will be able to also specify the repository in the `lockfile`. And in this case it might not even be a `bpkg` repository but rather, say, a `git` branch. &gt; What does the @ symbol here mean? It means *at*, as in "configure me `my_library/` source directory in `build_gcc/my_library/` output directory`.
For comparison [here is how you would do it with Meson](http://nibblestew.blogspot.com/2017/07/managing-build-definitions-of-big.html).
Hi, I'm new to C++. Would you like to explain how are you going to interface between dozens of package managers of GNU/Linux, Open/FreeBSD's pkg, NetBSD's pkgsrc etc? Hence how can you handle the cases where the required version of the said libraries are not available in the OS's known repository? Hence how would you ensure that the required package version does not conflict in compatibility of the OS itself? If it fails do experienced C++ programmers resort to git-submodules or subtrees? 
Can you provide the equivalent Meson steps for [the example above](https://www.reddit.com/r/cpp/comments/77kqdq/simplifying_build_in_c/domx4o0/)?
To this end, a thought: could we say that in an exported class, a member function defined in-class is not automatically inline (unless declared `inline` or `constexpr`, or is a template)? 
This is your top submission this year now for everyone to see.
&gt; We still have to separate declaration and implementation into two files? You do not have to. You can define a non-inline function/variable in the module interface file and thus (unlike with headers) have a single file. There could be some performance drawbacks in going this route which could also be addressed by a clever implementation. See [here](https://www.reddit.com/r/cpp/comments/77fgbw/cppcon_2017_boris_kolpackov_building_c_modules/domj8be/) for details.
&gt; FP people are like vegans of programming, the first example that is "WROOOONG!!1!1!!!" is perfectly fine beside the name. No need to bother people with partial app and FP. That's the point of the article, I'm not sure if you read it all the way through. It was a confusing article though because when I read that first line too, I was like oh cool that makes sense. The body of the article is helpful, but the intro/conclusion were a little different. The reason FP people talk about it so much is because its new and cool to them, and since not many people use it, it makes sense to talk about it more. Can be annoying but FP is pretty neat for small stuff like this.
No, I see this in a quite opposite way. The first drawback of your approach: I should repeat the same commands for different toolsets. It means that I should do: $ mkdir build_some_toolchain $ cd build_some_toolchain $ bpkg create cxx config.cxx=compiler-name $ bpkg add https://pkg.cppget.org/1/testing $ bpkg fetch $ bpkg build libsqlite3 $ cd .. again and again. But my library is dependent only on libsqlite3 and I don't want to fetch libsqlite3 for every toolchain. The second drawback: my library should depend on a particular version of libsqlite3. And this version must be extracted from some manifest file automatically. User should to issue commands like: $ bpkg add https://pkg.cppget.org/1/testing $ bpkg fetch manually. These commands must be executed by dependency manager automatically. And last but not least: &gt; Also note that the things that require multiple commands (like setting up the configuration) are normally not performed very often. It depends. For example, for development of one of my libraries I have almost a dozen versions of MinGW GCC on my Windows machine. Sometimes I need to check my code by gcc-4.8, then by gcc-5.4, then by gcc-6.3, then by gcc-7.1. Then I can make a fork of my repo or switch to another branch, change one of the dependecies, make changes in the code and recheck again. I'm afraid your approach requires a lot of manual work. PS. If you understand Russian [here](https://youtu.be/xtUr6RtAILI?t=12057) is a lightning talk with description of our approach to dependency management in C++.
I can do even better and point to [our test case](https://github.com/mesonbuild/meson/tree/master/manual%20tests/1%20wrap) which does roughly the same. The build steps are the following: cd into source dir meson builddir ninja -C builddir 
&gt; You do not have to. That's good to hear :) I was just rather alarmed by the presenter in the video (you?) advocating such a split, and presenting it as the "proper" way to do modules. We should be designing and implementing modules from the get-go as a single-file solution, that doesn't require me (as the programmer) to repeat anything that the compiler can work out for itself. Separate iface/impl modules should be the exception, not the norm. 
Hey, I've heard a lot about build2 and it sounds great. But I'm still not convinced how it can improve my project. If you have the time could you try to pitch me why I should use build2? I'm currently using CMake to create 3 projects: core utility engine. And I have a few dependencies such as Assimp, DirectX 12, Vulkan and Bullet physics. I've a lot of different build configurations. The biggest problem I have with CMake is currently that the team has to "understand" cmake to use it. Another problem is that adding dependencies clutter my visual studio solution (and my cmakelist because I have to disable tests for example). I looked at cppget.org but it doesn't have any of the dependencies I need. It only has 16 packages? Are so little people using build2?
&gt; a member function defined in-class is no longer automatically inline What is the problem with that?
The idea is really interesting. I've done a lot of workaround to overcome the lack of constexpr function parameter. I'd be curious if it's possible to do without undefined behavior. However, being able to do this would be fantastic: void test(constexpr std::string_view sv, constexpr int i) { std::array&lt;int, i&gt; arr; // i useable // do meta parsing on sv } Even better, template&lt;typename... Ts&gt; struct tuple { // ... constexpr auto&amp;&amp; operator[](constexpr std::size_t index) { // index known at compile time } }; auto tup = tuple{2.3, 5, "potato"}; std::cout &lt;&lt; tup[2] &lt;&lt; std::endl; Although there are meany caveats to overcome to be able to implement that.
What you are looking for is what I would call a `lockfile` approach: your project contains a reference to a specific version of `libsqlite3` at a specific location. What I have shown is a `manifest` approach where you specify a version range, say, any version after `3.18.0`. Each approach works better in different situations: `lockfile` is handy when you need to depend on, say, unpublished libraries that reside in source control repositories. But it won't work if you want to publish your library in some form of a central repository (like [cppget.org](https://cppget.org)) and expect it to be usable in combinations with other libraries (which might also depend on `libsqlite3`). And I will take a look at the talk, thanks.
Back when I was in academia I preferred the second option as it has more room to play. Now that I’m on strict business schedules I definitely prefer the first option. But I also agree with you that a universal build system would be a great improvement Sorry it took a while to answer. But since you are trying to improve the build system mess I will feed you with a couple of ideas. Hopefully they are helpful and maybe you can support some of them in future version of build2? That would be really great. =&gt; I comment at global scope as it is a quite long one and I hope for an extended discussion 
this may answer this old SO question: https://stackoverflow.com/q/14309245/1000282
Well you also didn't have to write hpp/cpp files and could write everything into hpp files, but that was not recommended and 99% of people didn't do it. If we end up with having the recommended way being to have mpp/cpp files instead of just mpp files just like the presenter hinted at 99% of code bases will still have two files per implementation. I just hope that the standard way of developing WILL become having just a mpp, but after that presentation I am a little pessimistic.
That's not quite the same: your test case contains a hard-coded version/location for `libsqlite3`. I also see no referenced to different compilers. Does Meson always build everything with gcc and clang and in the same directory?
&gt; What is the problem with that? You mean, what problem am I trying to solve with the suggestion? Basically, I don't want to have to repeat myself: I want to be able to write export class my_class { public: void my_func() { /* implementation... */ } }; and not have my module ABI depend on the implementation details of `my_func()` (unless I explicitly mark it as `inline`). As I understand it, under the current proposal I'd still need to write export class my_class { public: void my_func(); }; void my_class::my_func() { /* implementation */ } separately to avoid fragility, which is less than ideal.
I as such fully agree with you on the new language front which is why I was so doubtful. But I will say that the file by file pragmas most likely would not work either because of the same problems we are seeing with the entire migration between headers and modules, where the halfway solution is much more complex and we do not get the advantages of other languages where there is only one single file to keep syncrhonized instead people look like they have to make module interface files (headers in a new form) and then we are no where closer. Halfway measures and compromises could in the end water down or completely remove any advantages to the stuff. As for the module interface stuff I think in general it would be better if the interface file is just produced by the compiler on request if you are making a library then have it spit out the interface of the module and its classes in one go.
There shouldn’t be any need to write build files at all (except maybe a global library configuration). And I really think this is possible. Sure the committee won’t agree on build standardization. This must happen from the community. There exists only a very limited amount of useful project structures. And with modules this narrows down even more. If you follow a given default structure the build system should be able to build your project out of the box. I assume 95%+ of projects could use this approach without any loss. Most people will agree that the CppCoreGuidelines are a good idea. There is really no reason why there shouldn’t be a similar default advice for build. --- I know this will never reach consensus… But I will still start the discussion on a default project structure. Please note that the following is only a very first suggestion (!!!) to get a discussion started. Each proposed rule has the following structure: - Shortcut: MBd.x-A.Name (MBd for module build in development. Also MB is not used in the core guidelines yet, to prevent name collisions of rules. x is running number. Use –A.Name to propose alternative design for discussion - Rule: Short description - Required: (to support default build without build files = ‘mandatory’ or ‘strongly suggested’. If the rule is not needed in terms of automated build support, build speed, or build simplification, there is no need to have the rule. Less rules are better) - Reason: Explanation of Reason (required!) - Example: (optional) - Hint: (optional) - Build system support features: (optional) - Exceptions: (optional) - Open Questions: (optional) MBd.0) No interference with other build systems - Rule: Proposed default structure may not break or interfere with other build systems/approaches - Required: Mandatory (!) - Explanation: Following the default suggestions should simplify build but not prevent or hinder non default approaches - Open Questions: This approach targets zero build files. Still we need a place to put some configuration and that should be invisible to other systems (e.g. no cmake files). (See also MBd.8) MBd.1) Map modules to directory structure - Rule: Each module has its own directory. The directory structure is flat with 1 level (for small project) up to 3 level (for extremely large projects). Only the deepest level (module level) can contain code (files). - Required: Mandatory - Explanation: Modules form an acyclic graph by design (current TS doesn’t allow cycles). A graph cannot be mapped to filesystem tree. Thus a flat directory structure is the best alternative. Three directory levels to group code into modules, libraries and larger sub-systems should be enough even for very large systems - Example: See MBd.5 for structure example, see MBd.2 for module naming - Build system support features: The build system needs to visualize the module dependency graph (flat structure -&gt; graph) - Exceptions: Modularization on class level can live in the same directory of the parent module (Also see MBd.4) MBd.2) Map module naming to directory structure - Rule: Directory is named after modulename. Each module has a module interface file named modulename.mxx in its directory. (Additional interface files per module are allowed see MBd.4) - Required: Mandatory (? As current proposal only supports one interface file per module) - Explanation: This eliminates one level of indirection and therefore unnecessary complexity for the programmer. There are no useful applications to have separate names. - Open Questions: Any complains? / Upper Lower case problems? - Build system support features: If no modulename.mxx is handwritten it get auto generated by including all other .mxx files in the module directory. It also gets marked with [[modulebuild::autogenerated-module-interface]] to allow regeneration MBd.3) Modularize physical structure of your code - Rule: Each module directory is self-contained (coupling with other modules only over imports, not over the directory structure) - Required: strongly suggested - Explanation: True modularization at ‘source level’ and ‘physical structure’. - Hint: Imports get automatically resolved by the build system. No need to couple directories by hard links. (See MBd.5) - Open Questions: Only possible for header less modules? (See MBd.8) / Resources? (see MBd.9) MBd.4) Keep interfaces and implementation together - Rule: If interface and implementation is split, keep mxx and cpp files together in the module directory. Also use the same name for both files (1-to-1 mapping) - Required: strongly suggested - Explanation: There are three strong indications that code and interface belong together. o 1) The current proposal doesn’t require an separate implementation file o 2) Interface is carried in the generated binary module interface (?) and headers don’t need to be distributed (?) o 3) Code with headers and cpp files having a 1-to-1 mapping is easier to modularize, thus seems to be the correct design - Example: Hint: Use MB.2 to auto generated interface if you want to split your code on class level into separate files. - Open Questions: I guess this point will be controversial. MBd.5) Help the build system to locate your source code - Rule: All module directories are located under directories named ‘source’. (There can be multiple source directories, see example) - Required: strongly suggested - Explanation: Helps the build system to locate source and automate build. - Build system support features: Given a list of root directories, all modules are located automatically and build. Generation of (static or dynamic) library borders can be chosen on modules, libraries or sub-systems levels (see MB.1) - Open Questions: Subdirectories of ‘source’ may only contain modules? / Directories without source are not allowed to be called ‘source’? - Example: (2 root directories; Organization=SubSystem level) o ExternalLibraries\LibraryA\source\ModuleA (Uses 1Level) (&lt;- Bad?) o ExternalLibraries\OrganizationA\source\LibraryB\ModuleB (2Levels) o ExternalLibraries\source\OrganizationB\LibraryC\ModuleC (3Levels) o MyProject\source\Subproject1\ModuleD (2Levels) Hint: Only the part after source directories belongs to the module name and have a standardized directory design. (e.g OrganizationB.LibraryC.ModuleC). Also see possible problems with name clashes by using only 1 level. MBd.6) Keep generated content local - Rule: Generated content will get generated either inside the source tree in a ‘generated’ subdirectory per module or generated out of the source tree in a ‘generated’ directory that replicates the source tree structure. - Required: strongly suggested (?) - Explanation: Keep generated content local to module helps build system to simplify keeping track of dependency changes. - Hint: Also see MBd.7 MBd.7) Use common pattern for build customizations - Rule: Code itself should specify its need for special preprocessing. If a library needs code to be processed by a custom build step this should be handled by a default build system extension plugin - Required: strongly suggested - Explanation: Any of the many different special build customizations (e.g. Qt Moc) can be generalized into the following 4 actions (?): o (1) Run a custom tool at a certain position in the build sequence (2) on a specific file to modify it or generate new source files (3) and optionally include these new files into the build process. (4) Optionally also include original source into the build process. - Build system support features: o Offer an extension Api o Automatically execute custom build steps (See open questions) o Possibility of automatic installation of build system extension after library build - Open Questions: Non brittle integration without interfering with other build systems (MBd.0). By default file name extension? By including [[attributes]] into the source code? Scan source files for tokens? MBd.8 Use policy based design for (build) options. (Controversial with MBd.0) - Rule: The build system should provide a common structured (!) set of build options that get passed in. Libraries can register their own structured (private and public) options. (If possible do not rely on the preprocessor in a post c++17/20 build system!) (See open questions for discussion) - Required: mandatory (?) and controversial (= bad) - Explanation: Global variables/defines as in CMake are awful brittle, as they are not structured and not standardized. Defining a common set of default options is a better design (on a 90% common denominator that can grow over time). Libraries can still use their custom set of options and migrate to standard ones once available. - Hint: This will also greatly simplify setup as libraries only needs to define their special options. Most of these will settled around optional enabling of modules, that can be further solved by allowing [[modulebuild::requires-module]] and [[modulebuild::optional-module]] attributes. - Build system support features: Offer an ‘build options’ Api - Open Questions: This is complicated. I will start with a first idea how to solve it. o Each module can optional #include &lt;ModuleBuild&gt; and/or import Module.Build o If using an alternative build system these files/imports just resolve to empty dummy file/modules. o However using default build these files get passed in by the build system. #include &lt;ModuleBuild&gt; offers preprocessor token. import Module.Build offers a clean api that can get used with if constexpr to trigger conditional compilation. o As long as libraries do not follow default options names, it is possible to define a mapping. MBd.9 Resources (tbd) =&gt; Also see MBd.7 
&gt; What I have shown is a manifest approach where you specify a version range, say, any version after 3.18.0 My complains are not about manifests or lockfiles (I agree that they are for different cases). I don't like to issue `fetch` and `build` commands for every dependency and for every toolset. I think that dependency manager can read `manifest`/`lockfile` and download an appropriate version of dependency automatically. Then this dependency should be built automatically for every toolset I use.
I'm technically invoking a pointer to member function with a nullptr "this". The static function would be the alternative but there are no static way to access that function (see : http://en.cppreference.com/w/cpp/language/lambda) Having a lambda used in a template parameter like you do in your first example is not standard compliant. I believe it's technically worse than relying on an UB. That being said Louis Dionne's working on a proposal to allow that. As for f2, I've found that yesterday and was a bit in shock. I'm not sure if that standard compliant, would be interesting to check. I think it is though as it's basically the same thing as this: https://godbolt.org/g/dfAviH (using clang). A good alternative, but a bit of a weird one, if we believe the above is valid: https://godbolt.org/g/jDV6Vj
For integers, you can do this, you just need a templated operator[] taking an integral_constant, and a user defined literal. template &lt;std::size_t I&gt; constexpr auto&amp; operator[](std::integral_constant&lt;std::size_t, I&gt;); And then: std::cout &lt;&lt; tup[2_c]; For strings, you can do something similar but only with a compiler extension that allows you to interpreter a user defined string literal as a `Char&lt;...&gt;`, supported on both clang and gcc.
This might not be a popular suggestion, but I wonder we should have a reverse-domain-name convention for module names, as used for Java packages and D-Bus names on Linux (with an exception for `std`). So for example you'd say import org.boost.Hana; import io.qt.Core; This seems like a good way to ensure that module names are globally unique. 
UB is valid C++. invalid C++ is code that goes against explicit rules established by the language. UB is a rule that's not defined, that's implementation specific. Anyhow do you know the section in the standard where it's mentioned ? Also do you know if a constexpr const member function called with a non-constexpr 'this' can yield a constexpr result if it doesn't use 'this' ? GCC handles it that way but clang doesn't whist it does for a normal function with a non constexpr pointer as first argument : https://godbolt.org/g/dfAviH 
I get that part (though I have to admit the split in hpp vs cpp never bothered me). I do not understand what problem is caused by member functions being automatically inlined when defined in-class.
These are exactly one of the work around I talked about ;) However, with C++17, you can have constexpr lambdas. One could do this: auto sv = []{ return "test"sv; }; callConstexprParam(sv); This is quite different than passing the string as a pack of chars. This is much more lightweight. There is one template parameter. The problem with this approach however is even if I have many identical calls, if the lambda is a different one, I get an instanciation per usage instead of per string view values.
There is no problem today: in fact it's a good thing. But in a module-enabled world, it would mean that my module ABI would depend on the implementation of the member function. This seems like it should be opt-in, rather than the default.
[Nothing better like a good vegan pizza!](https://www.youtube.com/watch?v=0MpL1KfYEJg) Of course you can just eat regular pizza and get ass cancer. 
Regarding the standard proposal for a C++ version of Java's default and C# internal access modifiers, as a daily user of those languages, I fail to see the need for it when we already have friend access. What Java and C# offer is just a lightway version of friend, constrained to the same package. So just name the functions on the namespace that are supposed to have the access as friends. Given that namespaces should not escape libraries, the set of friends is anyway known at compile time and relatively easy to update.
which still means that you can't for user-defined types. And if your int value is not a literal it requires to use: constexpr auto res = expr; tup[std::integral_constant&lt;decltype(res), res&gt;]; 
UB makes your program's execution unspecified by the standard. As does an ill-formed program. In some cases ill-formed programs must issue diagnostics at compile time, but an executable can be created that does whatever the compiler wants.
I aggree. Maybe a little simplified. This is also similar to the exampes i suggest in MBd.5 (Organization).Library.Module.(Maybe Submodule) 
Re Vscode oin Linux: the two main issues for me : 1. glibc 2.18 dependancy of the cpp tools (mentioned already) 2. parsing a folder structure with cyclic symlinks still hangs (after some time) I don't like cyclic symlinks, but can't prevent them in legacy code either...
&gt; I had to download 3 things... If you are using VC, you only need two packages (baseutils and the toolchain source code). As described in the [Installation Instructions](https://build2.org/build2-toolchain/doc/build2-toolchain-install.xhtml). &gt; First when running build-msvc.bat it couldn't find cl.exe. You need to run from the developer command prompt. As described in the Installation Instructions. &gt; I already prefer CMake because the installation is 10 times easier and faster. I am not sure how you are installing CMake (probably a binary/installer) but with `build2` you are bootstrapping the toolchain from source and also getting a `bpkg` configuration for future upgrades (the toolchain builds itself from packages). It is a bit of extra work initially.
Here, I made you [a version that works with valid C++17](https://godbolt.org/g/KFkyCR) constexpr lambdas really are useful! However, while doing that, There were error I didn't understood. If I take a lambda with constexpr `operator()` by reference, I cannot call `operator()` in a constexpr context, it tells me that `this` is not useable in a constexpr context.
I think a better idea would be to improve the `friend` syntax such that you can make something be a friend of only certain members. 
That is up to you how to structure your code. Module TS does not impose on you how you decompose your module into individual files. If you want, you can implement your entire module in the interface file (thus you will have C# like experience), or you can partition your module into an interface and one or more implementation files.
I'm not using a lambda in a template parameter - I'm using the unary '+' operator to decay it into a function pointer (the static function equivalent for non-capturing lambdas) and passing that. I don't see any reason why that's disallowed (other than being somewhat arcane). In C++17, we were given the ability to take addresses of functions and objects as non-type parameters without linkage (though GCC doesn't currently implement this properly), meaning as long as it's locally static it's a valid template value argument - it's the same trick people are using for taking string pointers. Unless I'm mistaken here?
&gt; UB is valid C++. invalid C++ is code that goes against explicit rules established by the language. That's mutually exclusive. UB =&gt; ill-formed program. You probably confusing it with certain constructs that may (or may not) invoke UB. RHose are valid (like integer math, since it may cause integer overflow, which is UB). So compiler always assumes that UB doesn't happen. In this case you are dereferencing a `nullptr`, which immediately leads to `UB`. It might work in some cases, it might fail to compile in others or it might lead to all kinds of unexpected results. That's the nature of UB.
Right. This is a neat approach actually, this could be useful for reflection emulation macros in C++17. Since you're using a macro anyway, dumping the string literal into a lambda is easy. Right now my reflection basically just provides a tuple of pairs of string literal, reference to member. This is fine for most applications like serialization, but because the string literal is type erased, it doesn't allow a good implementation of say copying fields between two different structs, when those fields happen to have the same names and types.
TIL: I need to learn to read.
Well, based on the feedback in this thread, I need to learn to write ;-)
I dont think splitting needs to be the default or should be. It should be 'relativly?' simple for any compiler to check if the public api of an module has changed, even if the code is not separated into an implementation file. The big question (I already posted above) is how fast the module interface can get extracted from a module that includes all its code in the interface? Because this needs to happen very very fast in order to update syntax highlighting and code completion of dependent modules in real time. Especially if I change a module very deep in the (acyclic) module graph.
An alternative might be valid, it needs to be checked though. (constexpr const method call with a non-constexpr "this" might be constexpr compliant if the member doesn't uses "this", works with GCC). As for the constexpr args proposal, actually I believe that having forced constexpr functions would be more interesting. It would be easier to implement (no operator== , mangling, linking,etc... issues) and could also be used to address the demand for constexpr specialization. I have a proposal idea for such a thing: //arguments are forced to be constexpr //test cannot produce assembly for itself and doesn't introduce as mangling scope. //not constexpr compliant code will produce an error instead of falling back on the runtime version. constexpr(true) void test(std::string_view sv, int i) { std::array&lt;int, i&gt; arr; //... } constexpr(true) auto&amp;&amp; operator[](std::size_t index) { return std::get&lt;index&gt;(*this); } //partial constexpr function template&lt;class... Args&gt; constexpr(true) auto func(Args&amp;&amp;... args) { //normal lambda, will produce assembly relative to the last non constexpr(true) context in the call-stack return [](auto&amp;&amp;... runtime_args) { //args usable as constexpr values. }; } func(/*compile time args*/)(/*runtime args*/); constexpr(true) int func(int arg) { return arg; } constexpr int func(int arg) { return arg; } //constexpr ignored, considered as "inline" func(42); //compiler can't use the constexpr(true) for optimization, must use the runtime version. constexpr int i = func(42); //explicit constexpr context, constexpr(true) version used. 
That is a very BSD/Linux centric point of view, there are other OSes out there. Also I certainly don't want to repackge a library for all OS specific package managers under the Sun.
I was hoping this would be put up, I saw it in the github slides and scrolling through it there made me want to see more context than just the slides Feels odd having been a music producer for so long and not having done a lick of audio programming :v
Yes a small (standardized) Api over all compilers, that can query information from the vendor specific BMIs sounds like a good design. A standardized BMI would be even better, but can that happen or is this even possible? Is there a current effort on this? 
Wonderfully informative, every C++ programmer needs to know this!
Ya, I didn't express myself clearly. Lambda expression are forbidden in unevaluated context (such a template parameter list). You can use a lambda in an unevaluated context but not declarare/define it in one. I believe this is an implementation error of Clang. Gcc's behavior here is the correct one: https://godbolt.org/g/vSBpKs 
&gt;Also I certainly don't want to repackge a library for all OS specific package managers under the Sun. I don't want to install an application if it isn't properly packaged for my OS. 
Calling a member function doesn't dereference the this pointer here. If the member is virtual yes, other wise no. It simply call the member function with nullptr as first argument.
The compiler is decided when first setting up the build dir. To support many different compilers you set up different build dirs, each with their own settings. In Meson all generated files go to the build directory so you can as many different build dirs for each source dir as you want. That test is also specifically written to use a self built version. The recommended real way to do it is this: sql_dep = dependency('sqlite3', fallback : ['sqlite', 'sqlite_dep']) Which means "get sqlite from the system (with e.g. pkg-config) if it is available and if it is not, download and build it as part of this project".
Crazy, thinking-out-loud idea: could/should the BMI be embedded in a module's compiled object file? If the BMI depends on what compiler options are specified, and if even pure interface modules generate a object file, it seems strange that two separate files are needed. This seems like it would solve the problem of needing a well-known location for BMI files (the compiler already needs to know where libraries are located), and AFAIK is the approach taken by Rust's "rlib"s and some implementations of Fortran modules. We would need to write some tools to be able to extract the BMI for IDEs and build tools to use, but this doesn't seem like it would be impossible. For example, GLib provides a [tool](https://git.gnome.org/browse/glib/tree/gio/gresource-tool.c) to do this for its GResources system. Of course, the fact that none of the current implementations do this is probably a sign that it's a terrible idea with obvious problems...
I'm pretty sure that calling a member function on a null pointer is UB. 
This can easily be worked around if you accept to pay 1 byte for a `tight_pair` of empty classes: just use EBO on a `tight_pair_impl&lt;T, U&gt;` which is contained as a data-member of `tight_pair`. This way, `tight_pair` doesn't inherit from anything, problem solved. If you wish to go the extra mile and actually have `tight_pair` qualify itself for EBO when it is stateless, then things get trickier indeed. In the absence of strict aliasing, I'd fake it with `tight_pair_leaf&lt;T&gt;` class which either contains `T` (if stateful) or nothing (if stateless), then inherit from those. The problem is to conjure a reference to `T` from thin air in the stateless case. You can certainly do so by `reinterpret_cast&lt;T&amp;&gt;(*this)`, and it won't trample on any memory since `T` is stateless to start with, but it's not strictly compliant because of strict aliasing rules. I guess what we really need is a `std::zero&lt;T&gt;` which takes 0 bytes when `T` is stateless, then we could just have data-members taking 0 space and stop desperately struggling to get EBO kicking in.
C++ should be like scheme and allow question marks in identifiers. 
Actually the point of not using the lambda directly was that the value could be used in the template argument list, be passed as argument to template argument to structs and template variables, used in the argument list, etc... I [relly](https://github.com/DaemonSnake/unconstexpr/blob/4490c27196a1cfc22fc6d68f7db1fdf702302063/unconstexpr/meta_var.hpp#L120-L125) on such things I my [unconstexpr library](https://github.com/DaemonSnake/unconstexpr)
This! There's also the problem of *dependency hell*. Just because *one* application requires libfoo 3.4 doesn't mean *another* application instead requires libfoo 4.1, and of course they have incompatible ABIs (thus the major version change). Also, even if two applications are both compiled against libfoo 3.x does not mean that they can both use it. In an ideal world, this would not be a problem, but in the real world it does happen that A requires x &gt;= 5 (new functionality) while B cannot work with x &gt;= 4 (an incompatibility was introduced). And of course, as we talk about C++, we also need to talk about ABI issues: newer versions of libstdc++ let you choose between CoW strings and SSO strings, which are ABI-incompatible. So even for a single version of a dependency it may be necessary to have two `.so`: one for each ABI. OS-level package managers, for sanity I suppose, generally try to enforce that a single version of a library be present. This works pretty well if you stick with what *they* manage. But that's pretty limiting.
At the end, he says he'll take some questions, but that's no on the video. Nor is it at the start of the second part... shouldn't these have been part of the recording?
&gt; Is there a current effort on this? I recall /u/GabrielDosReis saying that MSVCs module interface format is based on his earlier [IPR](https://github.com/GabrielDosReis/ipr) library, and that they were planning on open sourcing it at some point. IDEs will also need to be able to understand BMIs if they're going to be able to provide completion suggestions and error squiggles etc, so it seems very likely we'll get a standard format (perhaps per-platform) at some point.
There are many issues with system-specific package managers: * It is hard to publish a library. You need to do it differently for every system. * Different systems have different versions. I had pleasure to write code which works with different versions of ffmpeg (and libav, because some morons replaced ffmpeg with libav on Ubuntu). Also sometimes you need a specific version and just can't use the one in the official repository. * If you found a bug in the library you can't just start debugging it, you'll need to download source, read readme, install dependencies, build system, etc.
`__declspec(empty_bases)` fixes a number of bugs where the compiler wouldn't perform EBO on your behalf in some edge cases with multiple bases. `std::tuple` though can't take advantage of that until an ABI break because a TU compiled with 2015 RTM that makes `tuple&lt;empty, empty&gt;` expects to be able to link with a TU compiled with 2017 15.5 and have the layout of that type stay the same.
I Don't argue against (but quotes from the standard would be welcome). I'm arguing that it's not the same thing as a normal dereference of nullptr and will not "work in some cases, it might fail to compile in others or it might lead to all kinds of unexpected results". GCC and Clang are consistent on that, if the member function is not virtual. The standard says that : Note: Undefined behavior may be expected when this International Standard omits any explicit definition of behavior or when a program uses an erroneous construct or erroneous data. Permissible undefined behavior ranges from ignoring the situation completely with unpredictable results, to behaving during translation or program execution in a documented manner characteristic of the environment (with or without the issuance of a diagnostic message), to terminating a translation or execution (with the issuance of a diagnostic message). Many erroneous program constructs do not engender undefined behavior; they are required to be diagnosed. Evaluation of a constant expression never exhibits behavior explicitly specified as undefined (8.20). —end note ] 
As it happens I was playing with build2 last night (after watching the video in the other thread) and I had similar thoughts. The bootstrap process takes quite a while and is not all that simple if you need to change the defaults -- for example writing to /usr/local doesn't need sudo on the Mac, but I couldn't work out how to disable that without going through the whole four-stage manual process. By comparison, on the Mac I can just `brew install cmake` or `brew install meson` and the new build tool is there, ready for use. On Linux I can similarly use the system package manager (though I may get an old version). On Windows, executable installers are the norm. If it's a case of build2 still being in development, and these things are planned but simply not available yet, then fair enough :). But it's probably worth pointing out that the installation process is currently a *significant* barrier to entry for most people -- at the moment I would be very reluctant to use build2 for any of my projects for this reason.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/77nqyd/c_in_finance/donau2f/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thanks :) I have an update coming up that will make it [fly](http://ibb.co/jMq1mR) using this pattern. Nice jobs by the way.
&gt; Calling a member function doesn't dereference the this pointer here. If the member is virtual yes, other wise no. It simply calls the member function with nullptr as first argument. ``` 5.2.5 Class member access [expr.ref] ... The expression E1-&gt;E2 is converted to the equivalent form (*(E1)).E2; ``` So `((Type*)nullptr)-&gt;operator()()` is equivalent of `*((Type*)nullptr).operator()()`, which dereferences `nullptr`. Furthermore, `this` can never be `nullptr` without invoking some sort of `UB` and most recent compilers (clang, gcc) use that to optimize (breaking some non-conformant code in the process). Regarding `ill-formed` vs `program with UB`, I agree that I was wrong to say that they are exact equivalent. They are not from the standards point of view. But in practice there is little difference between `UB` and `ill-formed no diagnostic required`. In fact `ill-formed no diagnostic required` =&gt; `UB`.
&gt; The bootstrap process takes quite a while For the upcoming release we have added support for bootstrapping with GNU make which will speed things up quite a bit. &gt; for example writing to /usr/local doesn't need sudo on the Mac, but I couldn't work out how to disable that $ ./build.sh --install-dir /usr/local &gt; If it's a case of build2 still being in development [...] Yes, platform-specific packages will come. We do still want to make it relatively easy to bootstrap the toolchain from source with just the C++ compiler and without needing brew/python/etc.
That's weird... if you want your library used on some OS, surely you want it packaged for it? 
How about CrossFit enthusiasts?
I have only one word for the author: "Thank You!". *Note: wait, was it two? I wonder what's the behavior of his library is some arguments are unused.*
Only for libraries. In my case, it's just to not pollute the consumer with system and library macros. And speed up compile times, of course.
Quoth the standard, 5.2.5, Class Access, 2: &gt; For the first option (dot) the first expression shall have complete class type. For the second option (arrow) the first expression shall have pointer to complete class type. The expression E1-&gt;E2 is converted to the equivalent form (*(E1)).E2; Since that's the case, anytime you do `-&gt;` you are dereferencing a pointer and it's UB. I also expect that: struct Foo { void print() { std::cerr &lt;&lt; "hello world"; } }; Foo * y = nullptr; auto&amp; yr = *y; yr.print(); will work without segfaulting.
Another questions - are committee members required to know all of the parts of the language (i.e. the whole ISO standard)? Or is it possible to be a specialist in some particular area/aspect of the language while having vague knowledge in other parts?
Good to know thanks, I was wrong. By the way the section is no longer 5.2.5 but 8.2.5. That being said it use can be replaced: template&lt;class H&gt; struct lambda_holder { static constexpr auto value = H::get_fn()(); }; template&lt;class T&gt; constexpr auto func(T const &amp;t) { constexpr auto fn = (std::invoke_result_t&lt;T&gt;(*)())t; //is that an UB ? Ok working GCC, not with Clang struct H { static constexpr auto get_fn() { return fn; } }; return lambda_holder&lt;H&gt;{}; } Or even as gracicot noted (might become standard if Louis Dionne proposal on lambdas in unevaluated context was accepted, working now with Clang): template&lt;auto Fn&gt; struct lambda_holder { static constexpr auto value = Fn(); }; #define carg(x...) lambda_holder&lt;+[]() noexcept(noexcept(x)) { return x; }&gt;{} 
Is it asking too much to add to the language/library some kind of `T reinterpret_as&lt;T, U&gt;(U u)` function which will statically assert if the conversion is not possible on a given platform? float val = 3.14; //Will fail to compile if type punning is not possible //Will also fail to compile if floats are not 32-bits uint32_t representation = reinterpret_as&lt;uint32_t&gt;(val); representation += 15; val = reinterpret_as&lt;float&gt;(representation); //val might now have a trap value `reinterpret_cast` doesn't make guarantees that the behavior taking place represents defined behavior, whereas this `reinterpret_as` hypothetical function would.
I don't get it, why think of something as of something else? There are languages where functions are actually objects, C++ is not one of them. You are right that a unary predicate is best named "IsX" or "HasX" instead of "XChecker" but it has nothing to do with function/object distinction.
Well, Herb was always a show/front man, so being a committee member is his essence in some sense... While, for instance, for John Lakos - it's just a place to promote his allocators. If you take away the membership from John, he'll just continue his life building large scale systems...
Nice
[Godbolt of his four different methods](https://godbolt.org/g/NAnX7X). It's very frustrating to me that there aren't any better ways of expressing the concept of type punning in C++. It's not like this is a rare thing to do!
It is not that easy: Defaulted special member functions are inline functions, so the compiler has to translate them in every translation unit that uses them.
It is packaged for the compilers used in the said platform. Not every operating system has package managers with repositories, including UNIX variants.
some people here are VS PMs so if you care ping them...
&gt; In C11 non-active union member access is well defined In C++, this is undefined behaviour. Is it because we are relying on platform-specific details?
`0x7F80'0000` What is the `'` notation?
I don't see how it is remotely closer to IntelliJ. It is too permissive, even with level 4 warnings. 
Very interesting, thank you for the video ! For those who are searching for an existing library which embed all these concepts ([reflection](https://www.qxorm.com/qxorm_en/manual.html#manual_70), [serialization](https://www.qxorm.com/qxorm_en/manual.html#manual_60), [ORM](https://www.qxorm.com/qxorm_en/manual.html#manual_30)) used by several companies at production level, try [QxOrm library](https://www.qxorm.com/).
I completely agree. Techies get in over their head way to often about in the end inconsequential stuff. Just follow the convention even if it is technically not the best. It has no bearing on the result of your code and makes it easier to understand for a lot of other programmers.
It's a digit separator. The `'` is basically ignored by the compiler, so the literal is `0x7F800000`, but C++14 lets you put in a separator to enhance readability.
That's why we spell "constant reference" as `const&amp;` without sticking the type in the middle of it! And by extension, that means `const` goes after the type. :)
&gt; // constexpr auto fn = (std::invoke_result_t&lt;T&gt;(*)())t; //is that an UB ? Ok working GCC, not with Clang Hm, it compiles just fine on the godbolt, though `C` casts are ugly and could easily lead to UB if you are not careful about what you are passing. Btw, your original example also uses non-standard extension: `As a GNU extension, G++ supports explicit template parameter syntax for generic lambdas. This can be combined in the expected way with the standard auto syntax.`, so this is another thing stopping it from being portable. Also, the second example compiles just fine in `g++ 7.2`. What is wrong with it? I thought that in C++17 the requirements for template parameters were relaxed which allowed almost any constexpr expression there (i.e. like casting lambda to pointer).
You're spot on. Vegans believe there is only one true way to eat. This guy thinks there is only one true way to write C++, even as he preaches that C++ should be viewed as a federation of different paradigms. In every chance he gets to explain the juicy details, he just quotes Effective C++. Why are we bothering with this blog when we can just go read the textbook and understand it ourselves as opposed to taking at this guy's "for details that I won't get into here..."?
Whether or not questions should be part of the recording is undefined.
It parses fine with Clang but doesn't compile when used : https://godbolt.org/g/9qmHRA . As for templated lambda it's part of C++20 now but that feature is only used as an example because it's short. The point of bringing C++17 this "hack" relies on a C++17 addition : constexpr lambda. Not that the code is pure C++17. As for the second example it won't compile because you can't declare a lambda inside an unevaluated context : https://godbolt.org/g/ccPgmP GCC =&gt; error: lambda-expression in template-argument Clang =&gt; ok
This talk about tooling is essential viewing. Thank you [cpp_red_lion](https://www.reddit.com/user/cpp_red_lion) See also the [Previous thread](https://www.reddit.com/r/cpp/comments/720twh/bringing_clangtidy_magic_to_visual_studio_c/) for some more discussion. 
&gt; Why are we bothering with this blog In general this blog is good, but the problem is that author is a bit of a fanboy wrt certain things and I feel he forgets that. :) 
For the second example - but you don't need to do that. AFAIK, `constexpr lambda`s should have C++ linkage in C++17 and as such you should be able to use them in template arguments in this way: https://godbolt.org/g/wZrJvn But it looks like `gcc` fails here too.
C doesn't have destructors
I see. That makes sense. Does that mean, theoretically, for trivial types (in which dtors don’t have to do anything), we can make this behavior defined?
Yea, I think this will have a major uphill battle in getting adopted. Currently, a C++ package gets installed with a configure, build, and install command(using commands for that library's build system). Changing the workflow to query, configure, build, and install, will need a change to every library out there, every buildsystem out there(as there is no build system currently that does a query step), and many package managers like nix, conda, cget, and hunter would need to be changed to support this. Also, users who would want to install packages manually(like the linux from scratch folks) will not like this workflow at all because now you have to pass in a path for every dependency there is(even it would be the same path). I think the idea of standardizing some kind of package spec and build interface would be useful for package managers, but it needs to build on top of existing practice if it has any hope of adoption. I understand the goal of having the query step is to make it DRY, so dependencies don't have to be listed in the build scripts and the package file, but if we have a standard spec for soem kind of package file, build systems could just read the package file to avoid the duplication.
Heck, they'll even get their friends and family to tell you on their behalf!
Sorry, I really didn't give enough context with my original post: The one argument for `T const` I agree with is consistency in cases with multiple levels of CV qualifaction such as `T const * const` vs `const T * const`. However, I'm encountering such cases so rarely that I don't think it makes sense to base a decision about every day coding style on that. And with references you just don't have that (syntactic) issue even if they might semantically be very similar to pointers. In the end, I think it is a matter of personal preference and the objective advantages/disadvantages of each version are such minute that the best course of action is to just following the wider established practice (which is imho what the core guidelines did) or just not standardize it at all. 
Unspecified ^^
Yeah, GCC doesn't currently implement this properly.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/motivelang] [Learning from C++ in Hindsight](https://np.reddit.com/r/motivelang/comments/77q15e/learning_from_c_in_hindsight/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
I don't get it, whats wrong with `#pragma once` and an include guard?
I think that would be an interesting project. Metal/Vulkan/DX12 are definitely much nicer to use, and it seems like current middleware is very very state-based. I have to admit I'm not too fond of his proposed audio API, but I assume he kinda threw it together to make a point. For example the `voice::add_effect&lt;&gt;` call suggests that one would have to add the effects in the order you expect them to be performed.
Stanford has some great c++ libraries for audio production a d DSP. Also puredata is written c and allows for lower level c code. 