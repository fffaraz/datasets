Good point. I think he probably forgot where he started with the title and opening text! (Just speculation) That said, I think if you just remove the cast-to-uint32 operator, it becomes write-only (since any other cast will yield a compile-time error). &lt;&lt; Just did refresh on page and saw that author updated article &gt;&gt; One thing that's interesting, that's not covered (which is fine), is what kinds of registers are typically write-only. For variables, I can't think of any... but for memory-mapped I/O (i.e. registers), one example would be the "kick the watchdog" register, which typically requires you to write it periodically, often with a specific "magic" value. Good article showing showing some modern C++ features (I learned something new about C++17 inline) with example code.
[removed]
Please check the updated version for the implementation. The goal is not to optimize, but to restrict the read operation at thr compile-time
I agree. I switched jobs a few years ago, and most of our new system uses underscores. It was a PAIN moving from camelcase, and I felt pretty unproductive for a while. There is an extra character, two rows from the home row AND almost in the corner, PLUS you need to hit Shift. It just seems to inefficient to me. But it is arguable more readable.
_GLIBCXX_DEBUG enables assertions in std::vector (and others), so it can catch out of bounds accesses etc. when the vector is used. But it cannot handle cases where we have a normal pointer to the data int* p = v.data(); return p[1]; as p[1] is dereferencing int* -- the vector is not involved, so its assertions cannot trigger.
Yep, and [there's research to back this up](https://www.researchgate.net/profile/Bonita_Sharif/publication/224159770_An_Eye_Tracking_Study_on_camelCase_and_under_score_Identifier_Styles/links/00b49534cc03bab22b000000/An-Eye-Tracking-Study-on-camelCase-and-under-score-Identifier-Styles.pdf).
Ah I see. I'm using `#ifdef 0` for this (or just comment out the mains that I don't want).
Yes, buts that more work.
On the contrary: a 20% speedup when performing a *sequenced* sum of a *small* set of numbers strikes me as almost implausibly large. This is a crazy speedup. Imagine what you might expect for larger data sets, with more complex operations and unsequenced parallelism.
Isn't changing `0` to `1` acutally *less* work than moving `233534534` around?
_GLIBCXX_DEBUG checks the index in `operator[]`, but it can't help with e.g. `vec.data() + 10` because `data()` has to return a raw pointer. _GLIBCXX_SANITIZE_VECTOR marks (annotates to asan) the range from `data()` to `data() + size()` as valid while marking `data() + size() ` to `data() + capacity()` as invalid. 
interesting... is there a way to adapt the mechanism for custom containers ? 
/r/cpp_questions
Actually took me a while realize what "Casels" was. I thought you were making a pun on hassle at first glance.
alright
The .h files contain code shareable between multiple compilation units. The .cpp files contain the code for a single compilation unit.
But if the thing is harder to read, then you pay more attention to what is written.
I wonder how long it would take for someone not familiar with statistical terms when they saw names like `student_t_distribution` and `fisher_f_distribution` written in camel case.
We are now in the process of figuring out the best way to add a banner stating you are not viewing the documentation to the latest version of CMake.
you are correct ( on what modern CMake is ).
Adding to my todo list to strengthen the wording in `EXPORT(PACKAGE` to make it clear it should rarely be used. Maybe one day the default can be to disable user package registry ( https://cmake.org/cmake/help/v3.12/manual/cmake-packages.7.html#disabling-the-package-registry ).
Such optimizations are certainly in for POD types. Not sure about dynamic allocation - I know that C++11 and 14 did a lot in this regard but probably it's still not allowed by the language rules to do everything because **dynamic allocation is a barrier for as-if rule**. One common example I'm aware of is string concatenation - repeated operator+ is inefficient and it's not allowed for the compiler to inject reserve call. Linear algebra libraries use expression templates for lazy evaluation - apparently even for POD types it's not always possible.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8trybf/cpp_vs_h/e19t684/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I agree it would be great to have at minimum a whitelist of global properties that are mapped to options such as `CMAKE_INSTALL_PREFIX`.
With that many custom targets I would expect to see a performance increase as that was one of the things we improved the performance of. You can find more information on some of the changes we did, and the improvements we found at : https://blog.kitware.com/improving-cmakes-runtime-performance/
I haven't seen that before, thanks for the link.
Eluding dynamic allocations is absolutely allowed (at least in 17 and maybe much longer)
&gt; It is not valid to subtract pointers that point into different objects. Hm, is this always the case? If the two objects are e.g. in a linearly allocated container, the pointer difference effectively gives you the relative index location. This can actually be useful in some circumstances. Or am I missing something?
&gt; because dynamic allocation is a barrier for as-if rule. Huh, why? Do you have a std citation for that? 
In principle such optimizations are allowed by the c++ standard and there are very contrived cases, where compilers do eliminate construction of a container. But in general, you are completely right: Current optimizers generally have no idea, what a `std:: string` or `std::vector` is (other than e.g. 3 pointers packed together) and only work on sequences of function calls, where optimizations like this become next to impossible (I'm simplifying here of course - I'm not a compiler expert).
can this be solved by class design? If two libs are using the same custom type, should that type be contained in one of the two libs or its own lib and thus the specialization is done once and lives with the class definition? hopefully I'm understanding this concern correctly. Maybe this is a case where you can't change the custom types definition or lib code. Then you could run into issues.
Not a strict barrier but allocation optimizations are not as good as they could be
The standard describes this as "two pointers to elements of the same array object are subtracte".
I was only speaking in terms of what is permitted under the as-if rule. I completely agree that compilers rarely do a good job of optimizing them. Although I don't know if the allocations themselves are what's problematic, or if optimizers are just bad at tracking what data got stored there.
You could call the same API as libstdc++ uses to pass information to ASan. But I have not found any good documentation on how to use it...
That's not how it works.
Also, without knowledge of details of `fillSubvaluesVector` and `outputSubvalues` its impossible to follow as-if rule, as `capacity()` is pretty much bound to differ in `f` and `f2`.
No idea. I know that optimizers have problems with aliasing and complicated control flow - they can't for example optimize algorithm complexity.
Research has been done, but with "readable" and "unreadable" fonts, and the results speak for themselves.
Omg, say it ain't so.
Thank you. This is a nice overview of all the proposed syntaxes for concepts, and it really clarified some for me, like the Bjarne minimal solution. I didn't thought he proposed each concept identifiers to map to multiple types.
Hmm. Good point. I hadn't factored in `capacity()` which is kind of like a user observable implementation detail. Although the docs for both `reserve()` and `shrink_to_fit()` seem to imply that neither function makes any guarantees on the exact value of `capacity()` after a call, so I'm not sure if this conflicts with the as-if rule or not.
Superbuild is a overloaded term. Internally to Kitware the term is meant for projects that are composed of `ExternalProject` calls and do some or all of the following things: 1. Produce a final relocatable/installable package for a products release 2. Build all the dependencies of a project for a developer ( CMB's developer mode ) The idea behind the separate repository is that a project should be able to tag a release, and not have to move that tag when it is discovered that the package doesn't build or needs a dependency updated due to an environmental regression. This idea came from a world where building the final releasable package was a bear and was done infrequently. Now all of our projects build a nightly installable package this separate repository structure isn't as needed. 
The "convenient syntaxes" seem like the least interesting and least useful parts of the concepts proposal. Outside of really simple functions, I'm not sure you could use them anyway... regardless of which one we end up with. Just... doesnt seem like a good use of time to pursue.
My understanding is that any transformations performed would have to respect those platform specific behaviors when invoking as-if rule. That would mean that the optimization is legal only under very strange implementations (such that give the same results on `capacity()` in `f` and `f2`). In practice, id expect `capacity()` to be `0` in `f`. And id be pretty pissed if it wasn't (at least close to that), as `std::vector&lt;int&gt;().swap(v);` is pretty much an idiom to force what `shrink_to_fit` does (kinda). Id get quite angry if my compiler decided its fine to ignore this.
I like Herb's syntax, but `Container{}` should just be... `Container{auto}`. * `Container{T}` -&gt; I want a `Container`, and name that type `T` * `Container{auto}` -&gt; I want a `Container`, and I don't care about naming the type 
There's also the fact that `reduce` has inherent limitations in terms of how parallel it can be. That contributes to the low speedup along with scheduling overhead.
&gt; template&lt;class T&gt; &gt; struct wrapper &gt; { &gt; T t_; &gt; bool good_ = false; &gt; }; Is this indentation style on purpose?
Hi y'all, I was working on a CSV parsing library and though some of you might be interested in it. I was originally motivated to write this after being disappointed in the speed of some Python scripts and utilities for data processing. I originally tried to use some existing C++ libraries, but I wasn't satisfied with many of them. For example, many required loading the entire file into memory, hard-coding column names, etc. I also liked how Python's CSV reader was capable of guessing the dialect of files, which is something I've implemented here. Lastly, I wanted to be able to calculate statistics over potentially very large files. I can post some rough benchmarks if anybody is interested. It was my first real C++ project, so I committed some performance sins like populating a ton of small strings. On my computer, it's faster than Python's CSV parser and the statistics calculations are faster than xsv's (a nice Rust tool I found https://github.com/BurntSushi/xsv). I decided to solicit some feedback before pouring more time into this project.
why?
Right, I didn't take that into account.
I don't have a general recommendation as the final deliverable / deployment of a project really drives this. But I will try :) 1. You should always use find_package to find third party libraries you expect to be have been built externally ( system or however ). This means if you are writing custom find modules don't hardcode the expected locations whenever possible. 2. If you are going to build a third party library as part of your build allow the user to explicitly disable this and use an external version. 3. Provide some automated way to build/download/install all dependencies you have. 
that's because operator new / operator delete can throw. If you can allocate with malloc / free, the compiler can optimize much more freely : https://godbolt.org/g/SeSnHa
...and that's why half of the people compile without exceptions
Just to be clear: The original question wasn't if there are other languages with conditional compilation, but wether they use a precompiled HLIL as a platform independent distribution format. AFAIK most languages either compile to binary directly (rust) or run (at least conceptually) on a VM and thus have a fixed ABI to code against (c#). In the case of c# I don't actually know ith the conditional compilation expressions are evaluated on the target or when generating the cli.
"One main difference is that subjects were trained mainly in the underscore style and were all programmers. While results indicate no difference in accuracy between the two styles, subjects recognize identifiers in the underscore style more quickly." That's not very decisive for snake_case
Of course they can change algorithmic complexity. A trivial example is changing: int i = 0; for (; i &lt; n; ++i); into: int i = n; 
Can contracts possibly help with this? You're giving more information to the compiler about your class invariants, so it could technically do higher level optimizations.
Aren't gettters/setters optimized during LTO?
Actually, the compiler will generate almost identical code if you deactivate exceptions
Looks good, got *only* 3 things that could be improved: - don't typedef `ull`, it scared me when I saw that in function signature (expected `0ull` or sort of) - missings `const`s - a lot, moslty for member functions - you can simply printing 2048 logo by using raw string literals - you will not need to escape backslashes
Are you sure exceptions are the problem? If you compile with `-fno-exceptions` the code changes very little.
 *[shaking the magic 8 ball](/r/Magic8Ball2k7/)* No.
&gt; reading a different member of the union than what was written which in my understanding is undefined behavior. By the standard it is, although major compilers know unions are used for type punning and compile it as implementation-defined. Recently there was a thread about Linus compiing some module without strict aliasing and with union-based type punning. &gt; This makes me question whether it is indeed possible to write an optimal SSO in standard C++, without requiring a bunch of memcpy's everywhere. Then it would require `reinterpret_cast`s. At lest I can't imagine it without any of: union-based type punning, reinterpret casting, memcopy &gt; If that is the case, is this an instance where the standard needs to be relaxed concerning accessing union members? Linus wrote some hate even against C standard, naming it useless when it is vague about type punning and aliasing
no surprise
So why should this be a reason to deactivate exceptions then? Or what did you mean by &gt; ...and that's why half of the people compile without exceptions 
Thanks. I think this makes the sanitizer check more difficult to achieve to avoid false positives.
I misunderstood your post. The "almost identical to" was ambiguous
Ah, sorry for that. I edited the post
That result doesn't replicate: http://datacolada.org/wp-content/uploads/2016/09/Meyer-et-al.-2015.pdf
I used to do combined, but now I prefer the split layout because it prevents library users from accidentally `#include`ing a source file or such.
Yeah, you can use it to share one resource between multiple allocators. I'm doing that in my own code where I would rather use a pre-allocated stack for my std::maps than use heap allocation 
&gt; In additon Typo. &gt; GCC/Clang Compiler Flags: -pthread-O3 -std=c++11 Did you intend to have a space before `-O3`? &gt; CSVReader reader("wierd_csv_dialect.csv", {}, format); Typo. Your CSVFileInfo has `int n_rows;` so it appears that you don't handle &gt;2B rows. (&gt;2B columns is probably pathological.) &gt; const StatsOptions ALL_STATS = { true, true, true }; This struct-of-bools is unreadable. Consider a bitmask type, implemented as an enum class with constexpr operators. &gt; enum DataType { Also consider an enum class here. &gt; DataType data_type(const std::string&amp;, long double * const out = nullptr); Top-level const on value parameters in declarations is ignored. &gt; CSVFieldConcept(const std::string&amp; value) : str_value(value) {}; Semicolons after member function bodies are unnecessary (occurs repeatedly). Should this constructor be explicit? &gt; value(new CSVFieldModel&lt;T&gt;(val, str_val)) { Consider using make_shared. &gt; CSVField(const std::nullptr_t&amp;) Taking nullptr by const ref is pointless. &gt; bool is_null() const { return (type() == 0); } You are inconsistently parenthesizing your return statements (I recommend against doing so). Your switch has `return` followed by `break` which is totally unnecessary. Why does CSVReader take a string by value? &gt; std::vector&lt;int&gt;_subset = {}); Missing space. &gt; CSVReader&amp; operator=(CSVReader&amp;&amp; other) = default; Naming "other" is unnecessary and inconsistent. I find it distracting that you have inconsistent ampersand placement for references, e.g. read_row() versus index_of() (I prefer the latter). &gt; const CSVFormat get_format() const; &gt; const std::vector&lt;std::string&gt; get_col_names() const; &gt; const int index_of(const std::string&amp; col_name) const; You should never return by const value. It's ignored for scalars like int, and it inhibits move semantics for things like vectors. &gt; CSVGuesser(const std::string _filename) : filename(_filename) This is definitely inefficient.
Hi, I really appreciate you taking your time in reading my code. Some of this is new to me, although some other mistakes were the result of coding way too late at night. I'll be honest, the idea of the number of rows in a file exceeding the capacity of int never crossed my mind. The biggest file I was thinking of was probably 10GB.
Those are not "sanitization checks". The post is about AddressSanitizer, which is nothing to do with the additional runtime checks done by the libstdc++ Debug Mode.
Dynamic allocation means observable behavior. You can't change the observable behavior of a program. http://eel.is/c++draft/intro.abstract#footnote-4
Okay, now find a nontrivial example. :)
In the section *Using a C++ class in Lua*, you show how to invoke a C++ member function from Lua using Sol. Is there a native way of doing this from within Lua? For example, like the [`Inline`](https://metacpan.org/pod/release/INGY/Inline-0.80/lib/Inline.pod) module for Perl or `ctypes`/`cython` for Python?
&gt;Dynamic allocation means observable behavior. Observable behavior is actually defined in the standard, and performing an allocation does not qualify under that definition.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8tvf0e/help_for_cs_student/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Calling new isn't considered to have side effects in the execution environment anymore?
It is difficult to ascertain from csv_parser.hpp how to use the library due to how cluttered it is. Consider moving similar constructs out to their own file, this includes separating implementation specific code from the interface the users of your library will use and only exposing the later. Two differently named functions to read a csv from a file or from memory. Consider keeping the function names the same and differentiate between the two by parameters...or at a minimum have the names be more descriptive (eg parseFromFile() / parseFromBuffer()). A better option would be to refactor to a data source class that provides an interface that can read from a file source or memory source. Consider providing your own mechenisms for users to iterate through csvs instead of returning vector/deques (eg implement your own iterators to traverse the data). There is excessive use of strings and vectors. These allocate memory and will kill performance. Keep data contiguous and avoid allocations. Use string_views to the contiguous data. Reduce the number of branches in your parser code. Despite what is described, the library essentially reads the entire file into memory (10000 characters at a time). If you want to read near unlimited file sizes, consider using memory maps. It would be the most efficient in terms of both io performance and memory usage while also simplifying your fileio code. Note that subsequent queries will not be as fast as if all the data was parsed into memory. If you forgo memory maps, then consider reading in a memory page at a time instead of 10000 characters. Your worker thread implementation looks to have a few issues. Possible deadlock in read_csv_worker() when breaking out of the while(true) without unlocking the mutex. Consider using scoped_lock or a concurrent container. Avoid naked new. Consider using make_unique()/make_shared() instead. Not saying this is applicable here, but check out this blog post for something similar https://chadaustin.me/2017/05/writing-a-really-really-fast-json-parser/ 
It is kind of true. The high level information is lost. But, the examples above are not so hard to figure out without information (if the constructors/destructors get inlined) and might happen. But for instance, if you have a class that represent a matrix, and an operator that do matrix multiplication, the compiler won't use the associativity to balance a matrix multiplication expression. While it would do so on scalars.
I had the same issues as you, and also built a parser as my first real C++ project here: https://github.com/AriaFallah/csv-parser. It's less fully featured, but maybe you can draw some inspiration.
It's unspecified/undefined behaviour in the general case. If you have a custom allocator or something like what you said, it can be totally fine and defined (often implementation-defined though so be careful).
Hmm I did a quick search and found this: https://www.lua.org/pil/8.2.html https://cs.brynmawr.edu/Courses/cs380/fall2011/luar-topics2.PDF Not sure if this is what you’re talking about. Basically you make c code, compile it into a library, and then reference it from your lua code.
Eliding dynamic allocation is perfectly okay. [Clang is pretty good at it](https://godbolt.org/g/3x2hDo).
I just posted an update. /u/tohammer Doubles were a mistake, I swapped that out for a template. One double was needed and that was for adjusting the size.
I just posted an update. /u/ChatFrais I use "re.h" so I don't need to use an iterator to get the regex content to a vector. Also, Each iteration gives you surrounding content which takes time to parse through, re.h sorts that out for you also you get re::slice which works the same as a python slice.
Online assessments that are done right can be excellent, even from a candidate's perspective, but most are plain awful, annoying, and pointless. From a candidate perspective you need to be very careful and actually put thought into designing/choosing it or you'll just annoy your hires. I recently took a devskilled assessment. It was like a cheaper, less user friendly hackerrank with unclear directions, unclear task requirements, and layout. Unlike hackerank, it did not give you the option to pause to experiment with a demo to figure out how their site interface works. The test material was supposedly provided by devskilled and was clearly not written by someone who'd coded in python, which was what the test was checking. Not only that, when hitting return it was indenting with spaces, but that made a major headache because the test was refilled out with tab indenting and those cannot mix.
Wow, that's nice to know. What's the word that allows it?
I was in a hurry and had to go, so I'll try to explain it better now. I have more than one (and more than 2) main ()'s in 1 cpp file, for testing, exploring ideas etc... `233534534` is just an example of **Monkey Coding**, i.e. I hit the number keys like a real Jerry Lee Lewis, the result is a random number. The brain is less stressed and I keep focusing on the problem at hand. If I would use consecutive numbers, I would need to keep track of that. Why don't I use `#if 0`? Because in this approach the code keeps on being compiled, so I know something goes wrong, if that happens to be code that is only called in that monkeyfied main. Another advantage is that when I `#if` it, the code gets darker (on a black background) and becomes unreadable.
10GB of single character rows already exceed int ;) (assuming \n) 
I'm not convinced that it's necessarily more efficient to write `f2` instead of `f`. https://godbolt.org/g/YDTWvS - `f2` definitely generates more code and without a quality benchmark of the use cases, i'd hesitate to say which one is actually better.
https://en.wikipedia.org/wiki/Indentation_style#Whitesmiths_style
sorry, I don't really understand your post. For me, a sanitization check is any check that asserts that everything is fine, be it done at runtime through instrumentation, or with simple assertions of pre/post conditions.
http://eel.is/c++draft/expr.new#10
&gt;though disfluent fonts slightly increase response times From the paper. I am not claiming unreadable font/name does boost your analytical thinking, that's quite a leap.
Hi, thanks for your question. Honestly, I don't get why a lot of the readers have so many problems with my indentation. Yes, this is on purpose, I find it more readable to have scope braces indented just as much as the code in the block they define (aka [Whitesmiths](https://en.wikipedia.org/wiki/Indentation_style#Whitesmiths_style)), the template preamble is also a part that is dependent on the main definition, so it is indented so that only the line that introduces the main symbol in a given context starts on the leftmost column, what could be controversial here is by how much, by experience I found out that double indentation works better here for me (that is, two times two = four spaces, I never could understand why I would need as much as four for regular indent). And I just love new function syntax, for a mathematician there is nothing more natural than to write f : D -&gt; V. And no, I don't force this on my colleagues and into established codebase, I can adapt, but the blog is where I am free to choose. 
Maybe for you, but for everyone else that would refer to the checks enabled by the various -fsanitize=xxx options.
&gt; the compiler won't use the associativity to balance a matrix multiplication expression Not sure what kind of optimization you have in mind, but I don't think matrix multiplications are associative because depending on how you group them the intermediate results might or might not overflow.
IIRC the only docs are in the ASan source. At least, I think that was true when I was figuring out how to use it for libstdc++. 
AddressSanitizer (and related sanitizers such as UndefinedBehaviorSanitizer, ThreadSanitizer, MemorySanitizer) are specific compiler features for detecting certain classes of errors. For AddressSanitizer the compiler essentially instruments allocations and deallocations with calls to a runtime library so that it is able to track things like buffer overruns, use-after-free, etc. This comes at a non trivial runtime and memory overhead so you'd only use them in a specific development build configuration but the amount of errors they catch makes them worth it (especially when you combine their use with coverage directed fuzzing). 
&gt;I can post some rough benchmarks if anybody is interested. It was my first real C++ project, so I committed some performance sins like populating a ton of small strings. On my computer, it's faster than Python's CSV parser and the statistics calculations are faster than xsv's (a nice Rust tool I found https://github.com/BurntSushi/xsv). How does it compare to the Perl [Text::CSV](https://metacpan.org/pod/Text::CSV) module (with the [Text::CSV_XS](https://metacpan.org/pod/Text::CSV_XS) backend)?
https://www.reddit.com/r/cpp/comments/8qcfcm/interesting_book_the_modern_c_challenge/?ref=share&amp;ref_source=link
Good points, I see :)
&gt; My confusion is that find_dependency isn't really doing anything special. Well, nothing special compared to the more verbose `find_package()`, but putting `find_dependency()` into the config file for each dependency is a critical step that allows the `INTERFACE_LINK_LIBRARIES` to get interpreted as cmake packages when the main project calls its `find_package()`. If a given item in `INTERFACE_LINK_LIBRARIES` doesn't have a corresponding `find_dependency()` in the config or consumer, then it gets silently converted into a `-lxyz` link flag, loosing its transient dependencies and thus breaking recursion. It would be really nice if cmake could add these automatically for us (and I know [I'm not alone](https://stackoverflow.com/questions/46836767/generic-transitive-behavior-in-cmake-package-configuration-file-find-dependen))... It doesn't seem like this should be a hugely difficult problem? Based on the name and the description, I was briefly hopeful that `check_required_components()` could do that for us, but that doesn't seem to be the case. I'm a bit clueless what the purpose of that function is actually...? 
That makes it harder but it's not a rule against optimizing. If the compiler knows the semantics of new/delete it could basically elide the first delete and second new and just in-place construct. The second new was never going to throw an out-of-memory exception because you just released some memory so it works under the as-if rule. Granted, the code has to handle the case of the constructor throwing, but it's not impossible. It's also a problem if objects are cont constructed and destructed in a LIFO order (say, some long lived object is constructed before the second version of the vector) as then the as-if rule doesn't apply. Of course this is such a special case we might not see this optimization for a long time.
Even for plain C (gcc optimizes this): ``for (i = 0; i &lt; strlen(s); i++) { // non-trivial stuff that doesn't modify the string }`` In this case, the optimizer can perform code motion to move strlen out of the loop condition. This may get the complexity down from O(n²) to O(n). I guess this is possible because glibc marks strlen as a pure function or something like that, so gcc can safely eliminate multiple calls to it.
I don't, just saying that I like their banner: "This is the documentation for an old version of Boost. Click here to view this page for the latest version."
On the other hand it is possible to follow the as-if rule if capacity is not called? Of course that only works if the compiler has the comple
Checkout [Godbolt's Code explorer](https://godbolt.org/).
Clang targets also allow to display optimizer output and give you reasoning behind why clang did/didn't optimize stuff: https://godbolt.org/g/egZ59H
Im fine with just that, but then `template` is slightly misaligned wrt braces everywhere, which ticks me off.
I'm rather against the current draft syntax where `template&lt;Unsigned I&gt;` names a _type_, when ideally (IMO) you'd want concepts to be used as replacements for types - if `Unsigned` was a typedef instead of a concept this would be a non-type template parameter instead... Only Bjarne's and the adjective proposal really solve this. But the adjective syntax has this lovely property: template&lt;Iterable Container typename C&gt; Even if you know _nothing_ about the concepts proposal, I think you can work out what that means. It's just beautiful!
&gt; A more "modern" solution would be to ~~not use explicit for-loop and instead use ranges I guess:~~ obfuscate the solution more. &gt; 
I've been considering for a while to make a merge request to include that module in CMake, but it would require a big effort for writing unit tests, and unfortunately I don't have enough time. It would be really great if someone from kitware would take care of that...
[Sometimes](https://godbolt.org/g/JzxpVD).
Is "static lifetime" the right term here? The issue doesn't seem to be with the lifetime of anything, more the creation of a very large number of function invocations - calls to emplace originally, std::string constructor calls in the later versions. The best versions both use char* and actual construction of the strings is handled by a loop (inside a (possibly not inlined) function), so there aren't many invocations, just the one.
I can't help but think you'd do just fine with a vector of `const char*`s. Why construct tens of thousands of const std::strings? For that matter, why a std::vector either? These structures are designed for dynamic data. They allocate to the heap. Why not leave all the static data in the static data section of the binary where it belongs?
Is there a list somewhere of things that are secretly static objects? It makes me not want to use initializer lists anymore...
This is correct
Aren't you getting an indirection when storing const char*'s ? If you have strings with sso and only store small strings, access could maybe be faster.
Initializer lists are not always static. I looked at assembly from gcc a while ago and saw the initializer\_list on the stack. I think there is a stack limit to the size, but I cannot find it in the documentation.
There is a very good chance that `std::string` will become constexpr in C++ 23, like `std::vector` is currently hoped to be for C++ 20 (if not, definitely C++ 23). Another change which may come is vectorised `new`, which is technically already allowed by C++ 14, not that I know of anyone implementing it, but essentially it would let the compiler optimise lots of individual string allocations into a batch allocation. I know this merely reorganises rather than fixes the problem, but initialiser lists are in a tricky quandry. You should actually avoid using initialiser lists for anything not trivially copyable, just to be sure no performance surprises will turn up.
&gt; The second new was never going to throw an out-of-memory exception because you just released some memory so it works under the as-if rule. Hang on, the heap is a shared resource. How can this argument possibly be made in the context of multiple threads?
&gt; then it gets silently re-interpreted as a -lxyz link flag, loosing its transient dependencies and thus breaking recursion. This is one of the side benefits of using targets that are namespaced. If you use 'PNG::PNG' but it isnt defined after the configuration step CMake can error. It can't error on 'png' as it can't tell if you mean a target named png that is missing, or a library named 'png' that should be in a system directory. &gt; It doesn't seem like this should be a hugely difficult problem? You effectively need to record the state of all find_package calls ( Components, etc ) including squashing duplicates, and be able to dump them when requested. &gt; I was briefly hopeful that check_required_components() could do that for us, but that doesn't seem to be the case. Yes this was meant to solve the problem of making sure all components that the user requested do exist. Personally I prefer modules that just import all components as targets rather than making me list which ones I want through components. You can do something vary similar to `check_required_components` that makes sure a predefined set of targets exists when you import yourself allowing you to work with targets that are not namespaced.
Just look how many "C++ killers" we have had. How many of those are forgoten? How many displaced C++ at all?
What is "vectorised new"? I tried to google it, but didn't manage to find any reference.
This is a job for `string_view`! It has constexpr constructors that take full advantage of the newly constexpr char_traits. If all the strings are static, then you would never need to even copy them to a std::string and could just put the string_views into the map directly. If you aren't on 17 yet it is easy to roll your own string_view and use a UDL to get constexpr string length.
Sorry, I'm late. Usually I'm in Horgen and Pfäffikon, but was in the canton of Valais for the last two weeks. Someday I'll meet all of you and get your autographs. :-)
Unfortunately explicit calls to operator new and delete can't be elided. And since that is how std::allocator works, container allocations can't be elided.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8tzyc9/resources_to_learn_c_from_java/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
If I'm not mistaken, they are talking about [N3664 - Clarifying Memory Allocation](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3664.html), which was accepted in C++14 and allows compilers to perform new optimizations related to allocation and deallocation such as fusing some allocations in specific scenarios.
&gt; essentially it would let the compiler optimise lots of individual string allocations into a batch allocation That's it right there. Today if you create a vector of N elements, it does N allocations. Its only necessary to do a single allocation of size N * sizeof(element) though. This can be much much faster. 
Correct, and I believe the wording was further loosened for C++ 17. I am unaware of any compiler which takes full advantage of the 17 wording yet though.
That's allowed, but also so is fusing a sequence of calls to `malloc()` into a `batch_malloc()`, the latter of which can allocate N individual allocations in almost the same time as a single `malloc()`. I am unaware of any compiler which currently does this, however, despite that glibc's allocator has had `independent_comalloc()` since nearly forever, as does the MacOS and FreeBSD allocator. Windows' allocator however has no such function that I am aware of.
Do you think this creates 3 integers at runtime? void foo( int x ) { auto a = x; auto b = x; auto c = x; } it doesn't. There are no observable side effects of creating `a` `b` or `c`, so *they don't happen*. The same can be true of calls to `memcpy`. You do have to check that the compiler isn't doing something dumb (like actually copying stuff), but we are talking about high optimizatoin code here. You always have to check. On top of this, you have the out that you can always access things through `char*`. What is there is implementation defined, but not undefined behavior. You do have to rely on implementation defined layout information, however. 
Why use `string` instead of `string_view`? I have a parser which uses X-macros to construct a hashtable of keywords, like this: #define KEYWORD(kw) { #kw ## sv, Keyword::kw}, const unordered_map&lt;string_view, Keyword&gt; keys = { #include "Keyword.inc" }; If your strings are const, you do not need to create a `string` out of them. 
Really? I don't remember if any specific proposal for C++17.
AFAIK it never was.
There are still way too many doubles.
We now have a banner warning that you aren't viewing the latest version of the CMake docs.
What do you mean by std::string will become constexpr? Does this mean that someone can make a constexpr std::string?
I'm trying to figure out how you make `std::string` `constexpr` without `constexpr` overloading...
Is it currently supported in any compiler, if disabled?
Neither do I. I was told this is the case during a conversation at the ACCU conference. A side by side diff of the standards would say for sure. The loosening could have occurred at Core, or even due to the editorial process. After all, the original proposal was written by the standard's Editor!
Wouldn't that only work if the compiler can prove it will be `batch_free`'d?
I prefer my library's `string_view` which I implemented before the standard had it. It handles `const char[N]` implicitly and this can have its data and size used in `constexpr`.
Currently, only `std::vector` is on track for constexpr usage, and its lifetime is confined to constexpr i.e. it can't "leak" from constexpr into runtime. It is a fairly obvious small jump from constexpr `std::vector` to constexpr `std::string`, just need the locale stuff into constexpr which people are already working upon. So I can see it is just a matter of time before constexpr `std::string` gets proposed, and indeed constexpr editions of all the main STL containers for that matter. But there is no current proposal for constexpr `std::string`, to my knowledge. I'm just speculating on a likely future.
Because `std::string` is safer and can be more efficient?
I think that translations are best managed as data files (the format of which can be more or less efficient of course). I want to be able to add additional languages or update existing messages without recompiling the program. That doesn't mean there shouldn't be some code for each type of message, that can help with static safety if done right (e.g. checking that the right number of format arguments are used), but there shouldn't be compiled code for each message for each translation.
I'd rather have things as static objects than on the stack, as they can be put into a separate section and mapped out by the kernel after they are used. Also don't have initialization overhead.
What's the point of putting the sort call inside a lambda?
Both GCC and MSVC list the feature as N/A (not providing any optimization is also a valid implementation), so I'd wager they don't perform any optimization. Clang lists it as implemented, but as for the other they could also implement it by not changing anything to their compiler. There aren't footnotes anywhere, so I don't know anything more about whether any major (or minor) compiler actually optimizes anything.
&gt; I think there is a stack limit to the size, but I cannot find it in the documentation. Isn't it, like almost everything else related to performance, an implementation detail?
I feel like it *could* be implemented. VS's NATVIS files let you define types as arrays, strings, lists, *etc*, you just tell it how the data is accessed. Could do similar with the optimizer. Then it would understand an underlying semantic to otherwise opaque types.
Maybe we need an explicit punning union... `punion`.
There's no observable side-effect to creating `a`, either. Function will compile to nothing.
I use Allman-style unless the codebase imposes otherwise.
Wait, it accepts that syntax? My life has just drastically changed, and it's all thanks to you.
No, each individual allocation returned by a batch malloc call like `independent_comalloc()` is individually freeable. clang may, we think, may aggregate batchs of allocations if, and only if, it can statically prove they are always aggregate freed. Other than that, as Morwenn points out above, none of the compilers implement these optimisations permitted by the standard yet. As an example of the potential gains, imagine PIMPL code like Qt where instead of lots of fiddly little allocations, you could allocate all the PIMPLs in a single `independent_comalloc()`. That would be an amazing performance gain. Doesn't help you for destruction of course, but half of lots still halves.
I see you're using the emotive extensions for C++.
Modules were in there too, but nobody is aware.
That will surely be solved when they implement constexpr `std::vector`, which also has overloaded constructors?
Thank you, wonder why this wasn't detected when I was posting.
I wish the syntax I wanted for tuples ended up in C++. `[bool, int, float] bar () { return {false, 0, 0.0}; }` `[void, int foo, other_var] = bar();` `if (bar) {} // first element of implicit tuple or captured tuple used for conditional expressions if `bool` or implicitly convertible`
`std::tuple` feels like such a hack. Tuples should be a language-level feature.
Then they have a deathmatch battle to determine who is right. C++ errata are written in blood.
I'll check the source when I'm home from work (hard to explain looking at LLVM when my job is enterprise Java) to see if there are any explicitly-disabled optimizations.
I'm not sure - I assume it's to prove that there's no GC magic going on? I don't do D tho
For some uses, if the compiler can prove that deallocation is batched, a unified batch allocation would be more efficient.
How do you overload constructors on `constexpr`? As much as I want it, C++ doesn't let you overload on `constexpr` contexts or arguments.
Sure. I mostly meant the general concept of a constexpr-constructable string_view-like type, rather than `std::string_view` specifically. 
clang definitely implemented elision (matching new and delete annihilate each other), which extends to libc++ library types lke std::vector: https://godbolt.org/g/r8gfqv
I believe integer and fixed point matrix multiplications are associative (they are just working on a finite field). But you are right that the much more common floating point matrix multiplications aren't. Unless you enable fast math optimizations that is, which assume you don't care about rounding issues. But it is more of an issue of the underlying "field" not being a field.
I thought this was an r/vancouver post :)
Just to be clear: I'm not talking about the mathematical concept, but the implementation in c++. Let's say multiplying A*B*C (where all three are matrices) as ((A*B)*C) yields (0*C) as intermediate result, the final multiplication will never overflow and the result will always be 0. However B*C might overflow, so evaluating (A*(B*C)) might give a different result, hence the compiler must not change the evaluation order in that case. 
`explicit union`, `union compl`, `union friend`, `union class`, `mutable union`, `volatile union`, `virtual union` are better I think
`pun`.
My `string_view` is constexpr-constructable, so no reason the standard one cannot be.
 // This is a good method because we can get all the files (with or without folder) recursive or not // from a target directory, and then have all those elements placed into a vector for easy 'for' // loop usage and functional parsing. vector&lt;string&gt; scan_dir([...]) It is not a good method because you allocate memory for each file name. That's why filesystem iterators are on-the-go and read things from the OS only when necessary I don't get the point of the library, code like `scan_dir("./","-r","-f", rec_vec);` is all missing type safety and input validation. Also, your library pollutes global scope with usings to whoever includes it. It's lacking const, no RAII and has messed up references.
Overflow behavior, while implantation defined at C++ level, are well defined in the compiler and follow 2's complement arithmetic. The compiler is allowed to do that transformation at IR level.
&gt; This is a job for `string_view` (unless you need null-terminated strings)!
You better not to see them ;) most of the "real life programs in c++" I've seen through the years were terrible mess of c and c++ a-la "c with classes" and tons of legacy code which nobody understand how it works ;)
An `unordered_map` of `string_view`s send a chill down my spine. Something with value semantics containing things with reference semantics. I know here the references are to static data, so it's safe, but the type scares me a little :)
Well, pulling the data into the binary might ease the deployment, but I agree that I'd keep the strings in a data file with a format independent of the language, and then use a preprocessor at build time to inject it(possibly by code generation) into the binary (if that's really needed).
Yes it is possible, given a good compiler. [Observe this](https://godbolt.org/g/xU9xFw) I believe this is completely legal use of unions (common initial sequence and all that). It's a quick and dirty implementation of the basics of SSO handling. GCC optimizes away all these ugly bit shifts and produces clean nearly optimal code, similar to what could be achieved with type punning. Other compilers are not that smart at the moment but give them time.
I suggest you search this subreddit for posts like "Examples of good modern C++ open source projects". This has been asked a few times before, with good replies. You better use these as good examples than any company code. Btw I'd say there is probably no such thing as "elementary C++ program" and "used in a real life company" - most code bases would be of at least medium complexity, and not elementary.
&gt; On my computer, it's faster than Python's CSV parser and the statistics calculations are faster than xsv's (a nice Rust tool I found https://github.com/BurntSushi/xsv) Given the extensive use of `std::vector` and `std::string` in your parser and BurntSushi's obsession with performance I am very surprised at this statement. Could you expand on the parameters of the benchmark? Useful information would involve: - compiler options (for both), - input files, - benchmark methodology.
lol My bad. I'm just taking the course, and I missed some classes. Thank you for noticing, though. :D
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8u1pzz/can_someone_direct_me_toprovide_me_with_any/e1bwqaw/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Libc++ does not invoke undefined behavior simply by virtue of being part of the **implementation** of the C++ standard. Or otherwise said, you cannot assume that C++-looking files of `std` are actual C++ ;) --- That being said, the most packed SSO implementation stores 23 `char` in 24 bytes: alignas(alignof(void*)) char mStorage[24]; Where: - for a long string, one stores the usual pointer/size/capacity... with the latter having `0xFF` where it counts, - for a short string, one stores 23 `char` with an extra NUL `char` (for `.c_str()`); the last `char` is used to store `23 - size()`, which is helpfully `0` when all 23 `char` are in use, doubling up as the NUL `char` then. (I think Alexandrescu was the first to come up with this in `folly`?) In practice, using a `union` and ensuring that the `0xFF` byte aligns with the last `char` will probably work. In theory you'd need a `mempcy` to pull out the pointer/size/capacity... which the compiler would probably optimize out. --- If you are keen in keeping with the standard, you should be able to go down to 22 bytes of useful storage: struct Long { char kind; std::uint32_t capacity; std::size_t size; char* data; }; struct Short { char kind; char storage[23]; }; union { Short sso; Long heap; } rep; Checking the `Short` vs `Long` is just branching on `rep.sso.kind`, using the common prefix subsequence rule of `union` access. The trick is that since you are in control of allocation size, you should be able to get away with encoding the capacity information in 32 bits. For example, if you double the size at each allocation, you can store the `log2` of the actual capacity after all.
Beyond the compile-time cost, one should not forget the run-time cost. That `std::initializer_list&lt;std::pair&lt;const std::string, std::string&gt;&gt;` will require the allocation of a bunch of `std::string`, and... "leak" them: 1. The `std::string` allocated there cannot be stolen by the `Map` constructor, a second call to the function would not work then, 2. The `std::string` allocated there will live until the end of the program, even if only ever useful once. On the bright side, it's a "local" `static`, so the cost is only paid if the function is ever invoked. A game using this scheme with namespace-level `static` would load every single language in `std::string` before picking the one to use :(
I think making `std::string` constexpr would prevent Small String Optimization, right?
This doesn't have to do anything with UB. In fact, I made my example with wrap around semantics in mind. If my code doesn't result in overflow and produces result X when evaluated according to the language rules (aka, evaluation from left to right in this case), the compiler can not just change evaluation order unless it can prove that the new code will produce the exact same result X. In my example above, overflow (a.k.a wrap around) during evaluation of (B*C) would result in a different result, hence the transformation is not legal. 
There are a few proposals that I saw flying around /r/cpp that would address this. I suspect that may be what 14ned means.
There are no value for A, B and C that show your behavior. If A*B=0 then (A*B)*C=0, and no matter the result of B*C, A*(B*C)=0. Let's work on an example in 16 bit: - A=9728 - B=2304 - C=6 A*B=22413312=0 (overflowed) B*C=13824 (&lt; 32768) A*(B*C)=134479872=0 (overflowed) This is not a proof, but a special case of the more general result that multiplication is indeed associative on Z/2^nZ (and 2's complement follow that semantic).
All C++ string literals are null-terminated. Putting them into a `string_view` doesn't remove the null terminator. That said, it is really nice to get to a point where you aren't dealing with NTBS very often, ideally only at the boundary between your code and third parties.
&gt; Putting them into a string_view doesn't remove the null terminator. I'd argue that it effectively does remove the null terminator, because that character isn't part of the view. If you have some intermediate function that takes string_view, how is it to know whether it came from a string literal (in its entirety) or just some piece of another string? That information is lost on conversion to string_view. &gt; That said, it is really nice to get to a point where you aren't dealing with NTBS very often, ideally only at the boundary between your code and third parties. agreed
You know we have been talking about matrices right?
Ah yes, thought I'm not sure why the standard is written this way instead of simply requiring .begin and .end methods on class types. ...so lets add begin and end to the list. In my ideal world there would be a short list of "called through ADL" APIs, and other APIs would not be subject to ADL (exact mechanism TBD of course).
Surely one could if constexpr SSO?
The main proposal is internal branching on a constexpr context. I want constexpr argument overloading :)
That is my point. The same is true of `memcpy` when there is no observable side effect. It compiles to nothing. Instead of aliasing, you can copy the bits of one object over another POD one, and examine the other POD one. This is optimized by the compiler to just inspecting the bits of the original data, because memcpy doesn't have to happen. 
I love how every single std::variant post I read (and at this point it's exceed the number of digits on one hand), it almost always... or maybe always... ends in the same implementation of some `make_visitor` function and the implementation. It then proceeds to always ends with the "absurd complexity that C++ is growing."
I feel the same way, I'd rather see everything in the same case. I also hate underscores and the only time I ever use them is if the project uses them.
https://godbolt.org/g/6Xufgs a bit cleaned up.
I had no problem reading it. The only time I am offended by CamelCase is if there are single digit words used, like "GetsASingleThing", that would bother me. What you wrote however is something that got absorbed instantly. However maybe its because I spent countless years doing Java and C#.
Turbo'ing a core? Do you mean overclocking? Or something else? If so I'd like to learn more about this.
So long as the compiler can prove it. You can do a lot that will trip aliasing rules, which is one of the reasons I don't use strict aliasing and prefer using `__restrict` where appropriate.
Why use (I presume non-standard) udl to get the size at compile-time? Just use a function/constructor template taking a reference to an array of char.
Am I missing something or don't you ever actually show that the static-lifetime is the problem here? It is just a lot of code you ask the compiler to generate and optimize
build something
&gt; I'd argue that it effectively does remove the null terminator, because that character isn't part of the view. If you have some intermediate function that takes string_view, how is it to know whether it came from a string literal (in its entirety) or just some piece of another string? That information is lost on conversion to string_view. If it dealt with `std::string` before there is a high chance it didn't rely on the string being null-terminated (and if it did, it was probably a bug). Unless it called c_str()/
Some project that can be useful at your job too.
I wanted to say that this is trivial answer, but maybe I am theorycrafting too much, and I should just code. Thanks.
Yeah, but I want to take part in some big project and see how development goes on bigger scale. I'm already developing 1-person projects in my job.
A nice alternative is this constexpr map : https://github.com/serge-sans-paille/frozen
I'm an entrepreneur and in a somewhat similar situation. At the advice of a friend, I put some of my code on Github a few years ago. That has been helpful. I've received help from people on comp.lang.c++ also. Same friend encouraged me to get on Linkedin. I took that advice also, but am not sure how helpful that's been.
&gt; `std::visit(a, Visitor{});` You have it backwards, the visitor comes first: https://en.cppreference.com/w/cpp/utility/variant/visit
Modern CPUs vary their frequency based on workload. They can run at a higher frequency the more of the CPU is idle, as they can devote the entire power budget to only the cores in active use. This is referred to as "turbo".
Because it is nice to be able to say `"string"_sd` rather than `stringDataFromLiteral("string")`, and it isn't OK to just make the normal constructor deduce the size from an array because that changes the meaning of construction from a buffer. For context, [here](https://github.com/RedBeard0531/mongo_utils/blob/402c2023df7d67609ce9da8e405bf13cdd270e20/base/string_data.h#L211-L213) is our UDL for our pre-17 string_view-like type.
&gt; It is not a good method because you allocate memory for each file name. That's why filesystem iterators are on-the-go and read things from the OS only when necessary I'll add another reason why an iterator interface is the right way to go -- on a slow file system (e.g. on a network), you don't have to wait to read the entire directory to get started, and you can exit early and not wait for the rest. (I'm not sure how much this would help, but I *think* it can.) A bigger annoyance IMO is the flattening to `string` for just file names. On most real systems, you actually get quite a bit more when doing the directory listing than just the filename. On most Linux file systems for example, you also get whether the entry is a file, a directory, a symlink, etc., and there are plenty of clients who will care about that. If all you give back is the file name, then the client program will *have* to `stat` it to get more information -- and unlike the previous point, I *know* this can have enormous effects on a slow filesystem. That can mean the difference between a couple seconds to iterate the files and thirty seconds or a minute to iterate the files, if the client code has to `stat` if you just give it a file name and wouldn't if you give it more information. (Sadly, other useful things *do* require a stat -- in particular, to know whether a file is executable. That's something that in my ideal file system would be stored in the inode, and in my ideal network FS would be returned in a `readdir` query even if requires a `stat` locally. Would make a fully-featured `--classify` or `--color` much faster on those systems.)
It's all c arrays' fault
You should double-check, but `const char*` for static data is a constant. Your assembly instructions would contain the address of the first character of the string, which is as little indirection as possible. As the string gets allocated to the heap, your assembly instructions can only refer to the constant location of the address of that allocation. With sso that's one more indirection and one more logic statement to access the string, without sso it's two indirections plus logic.
You guys seem to have missed the part where reddit eats your newlines. :p
learn by doing - it is the way
Can confirm, I learned the most by doing as well.
There was a nicely developed database, I forget if it was Mongo or some other type, but it was done in C++ and was designed very pleasantly... used modern C++ features, functions were short and concise, code was generally quite readable. I am sorry I forget the name but it does exist.
 \*\*Company:\*\* [Beenox](http://beenox.com/en/) \*\*Type:\*\* Full time \*\*Description:\*\* Beenox is a video game development studio created in 2000. Located in beautiful Quebec City, Canada, Beenox is a wholly owned subsidiary of Activision Publishing Inc., one of the world’s top game developers. The studio is proud to contribute to the development of the Call of Duty video game franchise. Beenox has also contributed to the resounding success of the Skylanders, Spider-Man, and Guitar Hero franchises. As members of the Beenox family, we feel as if we’re part of a group of like-minded people who are great to work with. Our studio is a real open world where it’s easy to have discussions with everyone, including our studio co-heads. Here everyone brings their own unique touch to projects that showcase their talent on a global stage. You could say that video games are in our blood! *Responsibilities* The Engine Programmer has different responsibilities related to the game engine. The first objective of the Engine Programmer is to maximize the game’s graphics capacity for all the different game platforms on which it will be published; The second objective of the Engine Programmer is to support the Art team and drive the development of features/tools related to the artistic needs (shaders, textures, etc.); The third objective of the Engine Programmer role is to ensure the stability and performance of the game’s multiplayer modes; Finally, the Engine Programmer provides technological watch for the Programming team and will actively participate in the improvement of the engine over time; Our studio is currently dedicated to the development of the Call of Duty franchise. *Main Tasks* * Ensure the constant evolution of technology associated with different game platforms; * Develop functionalities of the game engine: graphics, networking, optimization, physics, animation system, APIs); * Ensure the quality and performance of functionalities that were developed; * Support users on developed functionalities. *Requirements* * Strong knowledge of C++ and real-time engines; * Development experience for console and PC; * Good analytical skills; * Ability to work autonomously in fulfillment of his/her tasks; * Ability to adapt to internal tools and changing environment; * Positive attitude and desire to work as a team; * Passion for video games; \*\*Location:\*\* Quebec City, Canada. Our workplace languages are French and English. \*\*Remote:\*\* No \*\*Visa Sponsorship:\*\* Yes \*\*Technologies:\*\* While we mostly use the C++ 98/03 flavor, the C++ version we are using will vary from codebase to codebase. Our team loves to learn and share, and we try to use newer C++ features whenever it is applicable. We are using Windows with Visual Studio for most of our development, and while C++ is a must-have, proficiency in other languages such a C#, Python, or Powershell are nice skills to have. Engine programmers will also have to deal with graphics code, so knowledge of a modern graphics API such as DirectX or OpenGL is a nice plus. \*\*Contact:\*\* You may apply [here](https://activision.referrals.selectminds.com/beenox/jobs/engine-programmer-2283).
One might then instead use a custom `zstring_view` or the like to static `char[]` data. All the speed of built-in strings, all the safety of high-level C++ types. Shame C++ doesn't have anything like that (although it's even more a shame IMO that string literals are of type `char[]` and not something more specific).
It's good to watch "talks" from CppCon but it's better to watch the talks that really matters to improve as a programmer (and not just in a specific area). I would recommend : * Sean Parent's talks "Better code" (all of them), * John Lakos's talks on Software Architecture and Value semantics. I would also recommend reading those books : * Effective modern C++ * Elements of Programming * C++ Templates: The complete guide * From Mathematics to Generic programming They're not for beginners but they're really useful. Finally, the best advice was already given: **do code**. Contribute to a project you like to get your code reviewed. It's better if it's also a project you use for your daily job, this way you can say to your boss "I'm just upstreaming patches/features we need".
You're also better off in /r/cpp_questions for any sort-of similar future questions.
Yup. I started a library that needed TMP to be implemented, so I ended up learning it. I would have never learned it otherwise.
Yes. Matrix multiplication associativity only need the underlying field addition and multiplication to be associativite, commutativite and distributivite. And all those holds thanks to the well defined overflow behaviors in 2's competent. That is, it matches Z/2^nZ. In any case, I am spending way too much time to explain. I do not feel your are interested in being corrected. If you want to know more you can find explanations on the web, as for me, I will stop here. I wish you a good day.
Old standards never made any promises on threads. For new standards I'd have to look at barriers and what not, but in the absence of locking primitives or barriers I'd say the compiler has the right to act as if the race condition went in this thread's favor and still count under the as-if rule.
What did your colleague end up doing? Is it faster to just rewrite the imgproc algorithm from scratch without cv::Mat?
Pick something like Libre Office or *gulp* clang or the Linux kernel, or some Linux utility or gui program you use and would like to improve. You may be disappointed by one or another project - well, keep moving until you find something worthy! 
How is allocating memory on the heap, then copying from static data to this memory faster than just having a pointer to the static data?
You were mistaken
That part is not, even though, AFAIK, it doesn't necessarily allocate on the heap for short strings. But `strlen` is super inefficient, when compared with `std::string::length`.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8u4h4d/magic_square/e1cjcfo/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Where can I read more about this?
About what?
Here are my suggestions: 1) Write code that scratches your own itches. What are your pain points in your software? Is there anything about which you feel "This would be so easy in Python|Ruby|Node JS|C#|Java|etc"?. Develop C++ projects that make those pain points go away. Use C++ abstractions to make your code on the same level of abstraction as good Python|Ruby|etc. 2) Share your projects. If you have a pain point, chances are others will too. Share projects on r/c\++ to get feedback. 3) Local exposure. Find out (or start) a local C++ Meetup. Go to those meetup to find out what is going on. Make friends, discuss C++ stuff in person. Sign up to give a talk about your library. Incorporate feedback and suggestions 4) Attend Regional/National/International C++ Meetings such as C++Now/CppCon/Meeting C++/ACCU. Go to presentations. Talk with the fellow attendees (that is often where you get the biggest benefit). See how they are solving problems. Often you can brainstorm with them. 5) Present at these meetings. Often there will be some type of Lightning Talks where you can talk about your project for 5/15 minutes in a relatively low-pressure setting. If there is good feedback, apply to give a talk the next year. If you want some ideas for example, I can give you some of my pain points where I feel C++ is lacking 1) A Data Analysis framework like Pandas 2) Libraries that encapsulate using web services (for example Couch DB, OAuth, AWS Services, etc) in modern C++ and built on Asio that support asynchronous use.
\&gt;A new, experimental, token-based preprocessor that conforms to C++11 standards (including C99 preprocessor features), enabled with /experimental:preprocessor switch. This will be controlled with macro \_*MSVC*\_TRADITIONAL, which will be defined to 1 when using the traditional preprocessor and 0 when using the new experimental standards conformant preprocessor. Glad to see this land. This was one of the big caveats when talking about MSVC conformance.
This preview contains my implementation of feature-test macros in the compiler and library. (Note that `__has_cpp_attribute` is not yet implemented.) Minor updates were checked in between VS 2017 15.8 Preview 3 and the upcoming production release of 15.8.0, notably adding L suffixes and increasing the value of `__cpp_deduction_guides`.
https://blogs.msdn.microsoft.com/vcblog/2018/06/26/template-intellisense/ Woah. That "Template Bar" is the first of a kind C++ IDE feature as far as I know. Can't wait to get more goodies like this in the future! Good job MSVC team!
I saw that in a presentation they made last month, glad to see it's now landed and everyone can use it. It will make template-heavy code easier.
Do you have an example of code that wasn't interpreted correctly before?
Okay that is some seriously cool stuff, I’m really looking forward to that!
Congratulations, STL! 
Here's what I brought up [last time](https://www.reddit.com/r/cpp/comments/8hpx0q/visual_studio_157_is_out_with_c17_conformance/dymjilh/): #define FOO(...) BAR(__VA_ARGS__) #define BAR(x, ...) (first: x; rest: __VA_ARGS__)
I'd love to see this feature evolve to give you some pre-selectable choices from real call sites in your code. Picking any call site as a default also goes a long way to immediate feedback. Performance might be an issue with many templates in the same file, though. Even a per-template button to go fetch a list of real type arguments would be nice.
Thankfully we have ways to avoid the cancer that vararg macros are now.
&gt; is not possible to distinguish forwarding references from r-value references without knowing the nature of the entity they decorate I'd say there is no way of knowing this at all, consider: constexpr unsigned hour() { char t[] = __TIME__; return (t[0] - '0') * 10 + t[1] - '0'; } template&lt;typename T, typename = std::enable_if_t&lt;(hour() &lt; 17)&gt; &gt; using SomeObscureName = T&amp;&amp;; template&lt;typename T&gt; void foo(SomeObscureName&lt;T&gt;){} Is there forwarding references in `foo`? Depends. 
Chiming in here to say that I have been using Conan for C++ package management for the past year and really enjoy it. It works great with CMake. For someone who likes python it should be a hit since all of the configuration is done in Python which makes it crazy flexible as well. https://docs.conan.io/en/latest/ 
try_realloc 
Well in libc++ the std::string SSO is based on type-puning on an union, I doubt this can be made constexpr as it is UB.
Good news on a weekly basis, thanks go out to the team.
[Here](https://lists.build2.org/archives/users/2018-March/000288.html) is the last one we ran into.
You are probably right, I thought I had a counterexample, but that was just a number screwup. &gt; I do not feel your are interested in being corrected. Why do you have that feeling?
Interesting. I wonder if there are any new features/options? Specifically, I am looking for partial preprocessing, similar too GCC's `-fdirectives-only` and Clang's `-frewrite-includes`.
Sorry, my bad. I mixed that up with a different problem.
Multiple caret support, makes me happy. 
It's just the first half of `realloc`. It tries to extend the block. If it cannot, it returns null.
I'm already familiar with "Effective modern C++", but I will definitely check out the others. "do code" is repeating like mantra in answers, apparently I should focus on practice, thanks. 
For production purposes, we thankfully did not use any OpenCV. But we did manage to extract a fairly small subset for prototyping, after a lot of pain. Rewriting can be extremely difficult in general, because a lot of imgproc implementation relies on cv::Mat internals, instead of just the public interface.
Are there any plans to make the c++ cpu profiler 64 bit? We currently can't use it to run a full profile of our application due to it being 32 bit just as VS itself.
Great job and happy birthday with a 1-day delay :)
Reflection can't come too soon.
If you are using luajit 2.X then it should be builtin: http://luajit.org/ext_ffi.html There are also lua modules implementing the same API for normal lua.
not always
grep for MSVC there : https://github.com/woboq/verdigris/blob/master/src/wobjectdefs.h
&gt; How to distinguish generic functions from the non-generic ones? why would anyone care about this ? 
Omg you guys really are hellbent on 2D graphics :P I admit boost could be a better playground rather than the standard library itself, but a proposal is needed nonetheless. Boost approval process requires a well defined proposal, that will also help you think out of your box and receive feedback on your idea's strengths and shortcomings.
&gt;"This would be so easy in Python | x..."?. Develop C++ projects that make those pain go away Sooooo, write a Python | x.. interpreter? ^^^^^/s
It was already in the previous Preview release, I've had this feature for a few weeks now already! :-)
Awesome stuff! :-) &gt; We’ve also included a key mapping scheme that matches the ReSharper mappings. How about one that matches Visual Assist X? It's the way older extension and I'd wager still more popular (but Re++ is definitely catching up).
Wouldn't the proposed size feedback for `operator new` as proposed by [P0901](https://wg21.link/P0901) be more useful? You never try to grow the buffer, you already know it maximal size.
It's nice as very 1st step. But I do expect a more automatic way where the types are automatically filled based on where the template is instantiated. This bar should be only present to be able to select another type other than the preselected one.
You'd probably want a combination of the two. `realloc` doesn't do quite the same thing. I've seen good results with `std::vector` and `std::string` analogs using `realloc` for trivial types, and `realloc_try` for non-trivial types, performance-wise, for pushing.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8u2p6e/best_way_to_progress_and_best_open_source_project/e1da3fe/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Maybe it's my ignorance of `if constexpr` (I haven't used it yet), but I see no reason why a reinterpret cast in the untaken branch would need to be well formed. So, for example: template&lt;class U&gt; constexpr int *foo(U *x) { // else clause need not be well formed if constexpr is true if constexpr(std::is_constant_evaluated()) { return nullptr; } else { return reinterpret_cast&lt;int *&gt;(x); } } 
Does not the new `bit_cast&lt;T&gt;` already do what you want?
_Awesome_
Using a union in constexpr is fine as long as the discriminant is stored outside the union. For example, using the capacity as the discriminant, 0 indicating SSO: struct string_rep { size_t capacity = 0; union { struct { char length = 0; char data[15] = {}; } small; struct { size_t length; char* data; } large; }; };
Pretty interesting how strict it is: In "a[i] &gt; a[i+i]", the unoptimized LLVM IR loads i twice "from (stack) memory". Only later during optimization will it conclude that nothing there could've modified i, so it can reuse the first "read". As a human I did that unconsciously, "surely since these are all reads, i is i is i is i". But in uglier cases, something like operator[] could be doing nasty things behind its back, so it has to be conservative.
Have you finished the charconv's stuff yet?
It seems that the `/std` option does not affect whether feature-test macros are available. Will this be so in 15.8.0?
after upgrade, devenv.exe freezes from time to time. Reinstall does solve the issue.
Template intellisense is brilliant! Can't praise VS enough for this feature. It will save me so much pain the future 
But it works in a very weird way. If I do it using Shift+Alt+Arrow to select two or more lines any arrow click after selection resets all carets. But if I do this using Edit -&gt; Multiple Carets menu, it works.
This does not feel like C++ to me. Cool utilities, but let's take your slice for example. It works on a single container, but what it does can be extended to anything that is Bidirectional iterable (if you really care about efficiency then RandomAccess iterable). A C++-ish slice for me would take iterators and return iterators (or write to an output iterator).
Anyone knows IDE besides VS that can handle `vcxproj`? Or at least ready key bindings that is similar to QtCreator or CLion? I am from Linux and VS is horribly uncomfortable for me unfortunately :(
Does `bit_cast` return a value or a reference? If the former, it means we cannot alter the value.
See also: [Amdahl's law](https://en.wikipedia.org/wiki/Amdahl%27s_law)
It returns a value, performing work at runtime if necessary to perform the conversion. That is 99.999% what you actually want to do if you're type punning rather than reinterpret casting something back to its original form. This opens the door for future compilers to properly treat reinterpret casting unrelated types as the UB it is i.e. to generate nonfunctioning binaries. Obviously only if the C++ standard version is 20 or higher.
I have a personal project which parses slns/vcxprojs, including conditional expressions, and passes them down your toolchain of choice. Basically a portable msbuild. Could integrate it into an IDE.
C++/WinRT, now part of Windows SDK (current version 10.0.17134.0) is apparently not compatible with this new release: Compiling the following program: #include &lt;winrt/base.h&gt; int main() {} With /permissive- and /std:c++latest generates compilation errors: c:\program files (x86)\windows kits\10\include\10.0.17134.0\cppwinrt\winrt\base.h(2185): error C3861: 'from_abi': identifier not found ...
I wish we could get `auto` deduced in generic lambdas, where I was just lazy to put the type.
Matt Godbolt: How to disprove false statements
It's called a bait title. Although having seen some of this previous presentations by Matt, I am fine with this bait as I am sure the content will be interesting. 
C++ is dead. New programming languages like Rust, Pony, and Jerlang are taking over the programmerosphere and now C++ is the new Cobol. 
I know of two groups that are moving some stuff from Java to C++ because of Oracle's shenanigans. It's definitely not dead.
I see your /s but I think you're going to still get tons of downvotes.
High quality spam only few understand. Too bad it's getting downvotes
When a zen master attains the highest levels of Chi, he can utter phrases to which other illuminated minds receive unassailable and timeless truth, and the majority of dipshits will register it as a shitpost good for a chuckle at best, and the level of upvotes and downvotes be used as feature data for getting a beat feel of how much the bottom feeders have caught on to the ruse. 
C++ is great, but C++ will die if backwards compatibility is the only reason to use it. As he himself mentions at the end of the talk, Rust is essentially catching up to C++ in terms of performance and has essentially all of C++'s safety features and more. And if Rust is too verbose for you too hard to use for certain paradigms (e.g. asyncio), then C++ will probably be too. C++ for systems and complex embedded programming will be eaten by Rust which, within a few years, will be provably just as fast, safer and with more relevant libraries (asyncio is getting there and is going to be implemented in the std soon~ish). And if rust doesn't de throne C++, there are many other contenders appearing. On the other hand, for simpler usecases, C++ is already being replaced by simpler languages. For example, for high speed networking, go, whilst not being "quite as fast", is about 100 times easier to use due to it's native coroutine system, rich and intuitive networking libraries and verbose but easy to understand error handling. For desktop application it's been dying a long death for a while, as speed becomes less relevant. C++ has a foothold in areas like game engines, interpreters and VMs, partially because they need to be fast and they hard hard to write. But that's a question of time. C++ is dying, it was shot in the heart when LLVM became good, since everyone can now have a capable compiler front-end. What we are seeing now is the slow process of the behemoth bleeding out whilst unable to properly breath. And I say this as a fan of C++, as someone who still calls it his favorite language, wrote articles about it and wrote software in it. It's a fucking amazing language, and it's sad to see it go, but I can't image a 2020 where any new team says "You know what language we should use for this new project ? C++".
Your faith is weak. When a zen master attains the highest levels of Chi, he can utter phrases to which other illuminated minds receive unassailable and timeless truth, and the majority of dipshits will register it as a shitpost good for a chuckle at best, and the level of upvotes or downvotes, in a place, at a time, can be used as feature data for getting an authentic beat feel of how many autistic bottom feeders who have been trained incorrectly as a joke, occupy this station. How exciting! How Exciting! More breakthroughs! Daily breakthroughs! 
I don't know where you went just now, but I won't follow
I'm a Java programmer by trade, and was introduced to C++ only a few years ago. I *greatly* prefer C++. There's a few spaces where I enjoy/prefer the idioms that Java uses, but there are so many tasks and so much boilerplate that I have to write in Java that I can abstract away in C++. It often comes down to something as simple as "copy this object", which is a herculean task in Java once you move beyond `public class Person{private String firstName, lastName;}`, but comically easy in C++. Templates make a wide range of programming tasks simpler and more intuitive, in spite of the verboseness and complexity of Templates themselves.
I don't want to learn a totally new low level language. It would be nice if C++ committee start working on a really new C++. No back compatibility or at least not high priority, but maximize all other knowledge which an experience C++ developer already learned. Remove all the pains and keep the good part. 
I don't want to learn a totally new low level language. It would be nice if C++ committee start working on a really new C++. No back compatibility or at least not high priority, but maximize all other knowledge which an experience C++ developer already learned. Remove all the pains and keep the good part.
Am I the only one reading a "VHS vs Betamax" vibe to the "C++ vs Rust" arguments, in that precise ordering? Because it seems like Rust enthusiasts have tons of answers to the question "why is Rust better than C++", and very few answers to the question "why will programmers en-masse switch to Rust"?
Feature-test macros will always be provided regardless of /std. Doing otherwise would largely defeat their purpose. (The definedness and values of various feature-test macros are sensitive to /std, of course.)
Sorry mario, Your Alpha male to get behind is in another castle. 
Schizophrenia, got it.
Awesome news. This has been one of my biggest issues with CLion. Glad to see that clangd is now being used.
C++ being the new Cobol means that 40 years from now I can still make a lot of money as a C++ consultant. More languages should aspire to be like Cobol :)
Compatibility and access to vast numbers of existing libraries is a feature not a bug.
First they need a committee to remove the current committee 
You don't get an exit interview when princess peach rejects you Mario. https://www.youtube.com/watch?v=KV5QlSgq7lg
I prefer Java for solving problems if I have control over the frameworks, libraries, and architecture. There’s nothing wrong with the language or JVM itself IMO. The problem is bloated, bad, and slow frameworks and the mentality of Java developers and teams that create horribly bad solutions that are slow and overly complex. C++ seems to breed more careful and down to earth developers that are more focused on the best outcome.
There's still a lot of perfectly good Cobol code out there. The data management software at most hospitals, the software stack that handles the credit card transaction you used at the gas station today between the oil drillers, petrol refinery and payroll processing systems of the truck drivers. Cobol, Cobol, and more Cobol. I know because sadly I've had the misfortune to gaze into that abyss.
Not yet, but I have some good news for you. My implementation of floating-point `from_chars()` is shipping in VS 2017 15.8 Preview 3. It's derived from the CRT's `strtod()` and `strtof()` but is approximately 40% faster (in addition to conforming to `&lt;charconv&gt;`'s requirements which are different than the CRT's). I got this speed improvement after a couple of months of carefully reviewing the code line-by-line, discarding things that weren't necessary for the STL (e.g. `from_chars()` can assume that it's working with an in-memory buffer; the CRT's implementation handles both memory and `FILE *`), changing various tradeoffs (e.g. the CRT has type-erasure logic to save code size in the separately compiled DLL; my `&lt;charconv&gt;` is header-only and I removed the type-erasure to improve runtime perf at a minor code size expense when someone uses the functions), and making outright improvements which I communicated back to the CRT's maintainers (e.g. I use a lookup table to convert decimal digits/hexits, and that was responsible for a 5% speed improvement all by itself). I am currently working on floating-point `to_chars()`, although I can't promise when it will ship (it's a lot of work and my time is momentarily being divided). This involves 3 algorithms: shortest round-trip decimal, precision decimal, and hex. For shortest round-trip decimal, I'm using the novel Ryu algorithm developed by Ulf Adams of Google; it is *incredibly fast*. (I measure it as 10x to 39x as fast as using `sprintf()` to emit sufficient digits for guaranteed round-tripping - yes, times not percent - and it is also faster than the previous best-known algorithm Grisu3.) As part of this work, I'm contributing improvements [upstream](https://github.com/ulfjack/ryu) and reporting compiler bugs to both Clang and MSVC where I've identified opportunities for codegen improvements. (I'll need to adapt Ryu's code to `&lt;charconv&gt;`'s requirements, but those will be mostly superficial tweaks to the core algorithm.) For decimal precision, I'll need to adapt the CRT's code again. Similarly for hex precision and hex shortest.
My biggest issue with Rust is that it does not have support for variadic templates, non-type template parameters, and template templates (aka Higher Kinded Types). Some of these can be hacked around using Rust macros, but it is still a hack compared to C++ rich template features. Otherwise, Rust is a brilliant programming language. Using types for memory safety is awesome. Making move the default primitive vs copy also has some nice features. Cargo is an awesome build system/dependency manager. Language level pattern matching is great. My feeling is that Rust won't displace C++ as C++ will acquire (either in the compiler itself or with static analysers the best features of Rust).
Network Effects mean that C++ will be alive for a very long time. The biggest advantage of C++ over any "would-be challenger" (Rust, D, Pony, Go, ...) is: - the combination of sheer mass of C++ code, and available libraries, - with semantics so complicated that no other language can readily interface with C++ (short of transpiling to C++, hat tip to Nim ;)). The challengers will progress in term of performance, feature-coverage, etc... but as the experience with D has demonstrated, FFI with a modern C++ library is a pipe dream. To answer your question, it also means that I doubt we'll see any en-masse switch; big rewrites are downright scary. Rust will be adopted incrementally, as new projects spring up, and C++ codebases will live on in parallel.
Does Rust or Pony have on-line code generation? 
There are two problems: allocation and SSO. Allocation we're just making work, and SSO we're going to disable if evaluation is in a constant context with the proposed `std::is_constant_evaluated()`. You don't need to overload on `constexpr`. Indeed, in this case, it couldn't work anyway - `string` isn't a type that could be a non-type template parameter in the P0732 world.
Is the committee waiting until ranges to introduce string handling functions that one typically expects in stdlib? Or is there something coming earlier?
Doing `if constexpr (is_constant_evaluated())` is never what you want, because that's trivially `if constexpr (true)` (since you're evaluating the condition in a constant context).
To be fair, I just want `constexpr` overloading for other reasons. I do a lot of embedded work where integrating optimizations based upon the potential known value of an argument would be helpful.
Here's the sad truth - there are hundreds of millions of lines of code written in C++. Companies and communities around the world won't suddenly drop it and move to the new "better" language if it doesn't have backwards compatibility. 
How did you feel when you realized there is no standardized `string::split`?
I'm a C++ dev too and have lost count of the amount of commercial code I've written in the language. The refactoring pain that Matt talks about is very real. Code bases in C++ take much longer to improve because of it. Then when you throw TDD in the mix and you need fast constant refactoring, you start to wish for a language that allows you to do just that and get on with your thought process. I've been programming in Go for a few years now. I still use C++ (or even C) when every microsecond counts, but I would gladly trade microseconds of performance for the ease of maintenance that Go brings. With Go, the tooling is so good that I can change the signature of an interface for the library that implements it AND for all the code in my workspace that uses it, whether I'm currently working on it, or not. When I say refactor, I mean attempt the change and ensure everything builds. And all this takes a few seconds at most. I could not dream of such refactoring power with C++, even with tools like Visual Assist X, because that would affect only the code you're working on. Some other cool tool that uses the same library silently breaks because you're not working on it right now. Refactoring speed is not the only reason though. It's also simplicity and consistency. For example, in Go the difference between public and private is the case of the first letter - one keystroke. There are a lot more reasons, but they are out of scope for this comment. All I wanted to say was that unless you're doing embedded work out performance critical work, you might find Go to be worth a look. Yes it's opinionated, but you get used to it and the trade off is more than worth it .
&gt; I enjoy/prefer the idioms that Java uses, but there are so many tasks and so much boilerplate that I have to write Check out Scala
Who says it's dead???
So, you are saying `winrt` isn't compatible with `/permissive-` and bleeding edge C++? Calling that "not compatible with this release" seems incorrect.
Programmers won't en-mass switch to rust, much like they didn't switch en-mass to any language. Note that my wording wasn't: "There will be no projects using C++ in 2020", there will likely be hundreds of thousands. I just said no new ones will be made (well, that's an exaggeration, but a likely a very small amount compared to 2 years ago, or even to today). C++ will probably be a language well in use when we are both dead, much like Fortran has outlived dozens of thousands of Fortran programmers. But it will be (I would say it already is) a dying language, it's popularity will be decreasing and it will be kept afloat by legacy code, not by new projects. Rust, on the other hand, will be used for most new projects. The problem of interfacing isn't really a big one, the critical libraries you need to interface with are usually written in C, and are usually easy to interface with.
We currently don't have an equivalent switch for those, but it is on my list of things to do. The preprocessor overhaul is not yet complete, which is why it is under the /experimental family of switches rather than a /Zc switch. There will be another blog in a week or so with more details about the preprocessor changes.
The irony is that a lot of TMP is used to implement things that other languages provide out of the box or code around deficiencies in the language. That is not to say that TMP doesn't give you lots of useful capabilities and let's you do things that are simply impossible in other languages, but one shouldn't forget that it is a means to an end and sometimes it reminds me of compile-time assembler language (maximal power, but ugly as hell and easy to get wrong)
&gt; My biggest issue with Rust is that it does not have support for variadic templates, non-type template parameters, and template templates (aka Higher Kinded Types). Some of these can be hacked around using Rust macros, but it is still a hack compared to C++ rich template features. That's one of my main issues with rust, together with the fact that the tools for writing "unsafe" (e.g. lock free concurrent) code are rather verbose and hard to use. But for most people (I would assume you and me included), that's a drop in the bucket compared to being able to claim "I will never have any concurrency related bugs in my code" or "I will never have an error due to typecasting" or "I will never read from the wrong memory address by mistake" &gt; My feeling is that Rust won't displace C++ as C++ will acquire (either in the compiler itself or with static analysers the best features of Rust). Can that be done without dropping backwards compatibility ?
An alternative design for \`Register\` that does not require inheritance would take \`Read\`, \`Write\` or \`ReadWrite\` as template parameter "tag types" and could \`std::enable\_if\` over those
Hello, I'm the PM on this feature - thanks for the feedback! Several people have suggested that we use template instantiations to help populate the Template Bar. This is a great suggestion and a natural evolution of this feature that I think makes complete sense for a future release. If you want to track this more closely, please add (or upvote) the suggestion on our UserVoice: [https://visualstudio.uservoice.com/forums/121579-visual-studio-ide?category\_id=30937](https://visualstudio.uservoice.com/forums/121579-visual-studio-ide?category_id=30937)
Some of those features are on my must-have list before jumping ship to Rust. Non-type template parameters at least are on the way.
I'm getting the impression that the msvc code base is so brittle they just don't dare to switch to 64 bit.
Probably the same way I felt when I tried to count duplicates in a list in Java, and had to add needless nullchecks and verbosity in the code: //Java Map&lt;Point, Integer&gt; pointCount = new HashMap&lt;&gt;(); for(Point p : points) { Integer count = pointCount.get(p); if(count != null) count++; else count = 1; pointCount.put(p, count); } //C++ std::unordered_map&lt;point, int&gt; point_count; for(point const&amp; p : points) { point_count[p]++; } Obviously, both languages have spaces where "Do task X" is easier to write. We're not talking about differences in kind; we're talking about differences in *degree*. I find these kinds of situations happen more frequently where the C++ code proves more concise/easier to write/easier to understand than the reverse. And again: I say this as someone who has an extra decade of experience with Java over C++.
You can change the key bindings to your looking (but sure if you can completely emulate QtCreator though)
This is a known problem with the 17134 version of the Windows SDK. The problem is that from\_abi is used before it is declared. Given the complexity of the meta programming, neither Visual C++ nor Clang picked up the error, until 15.8 Preview 3 introduced far stricter conformance checking. I fixed this bug in March and you should see the fix in an upcoming Windows SDK. In the meantime, you can work around it by not using the /permissive- option.
&gt; I can't image a 2020 where any sane team says "You know what language we should use for this new project ? C++" I predict in 2020 a majority of new embedded projects targeting systems with RAM between 1MB and 10MB will choose C++. 
I wrote it in 5 minutes and moved on?
I agree. But if there is a new C++, at least we can migrate the old library to the new C++(slowly maybe) and start a new project we can choose whether to support backwards compatibility. Now there is no choice.
The if constexpr is merely there to cause the else clause to be permitted to be UB in a constexpr evaluation context. It may also need a spurious reference to a templated parameter to force that. I must caveat that I have no programming experience with if constexpr, but I think I'm probably correct.
[removed]
[It is called D](https:\\dlang.org), and it is fantastic.
D has been created as the better C++ and look at its adoption. 
Do you test Clang with `-fno-delayed-template-parsing`? They default to one-phase for compatibility so you need to explicitly request two-phase.
Which is really too bad, because D is pretty great
I recommend watching [this video](https://www.youtube.com/watch?v=fV6qYho-XVs) from Matt where he is continually tuning simple 3 liner in C++/C. When push comes to shove, neither C++ nor C are "fast by default".
Note that this is *only* for error highlighting. Not even for auto completion, which is surprising (since a one TU approach suffices, and clangd provides it), and definitely not for features like finding all references. In that sense, IMHO this is still not at the level of cquery or rtags based systems.
Please just reread what I wrote. Also, you don't need to _discard_ the `reinterpret_cast`anyway. You just need to not evaluate it in a constant context. You really just want `if`, not `if constexpr`.
That's a bold statement
... and somebody need to write a proposal to remove the current committee ... 
Yes, Python 3 was a success.
Nice, thanks for the tip!
We're thinking of doing something similar...for imgproc's matchTemplate functions...any advice? 
&gt; "I will never have any concurrency related bugs in my code" That's not what Rust guarantees. It's pretty much impossible to guarantee that as this is equivalent to "I will never have any bugs in my code". Rust guarantees memory safety. That's a large class of bug and makes MT programming much easier/safer but it won't save you from, for example, deadlocks.
Thanks! I was asking because [this](https://developercommunity.visualstudio.com/solutions/252922/view.html) comment by a Visual C++ team member only mentioned `/std:c++17` and `/std:c++latest`.
Don't.
Jennifer's comment is correct - as structured bindings are a C++17 feature, that individual feature-test macro is defined only in /std:c++17 and later options. `__cpp_namespace_attributes` is an example of a C++17 feature that MSVC implemented unconditionally (in VS 2015, before the Standards mode options were added). So, the feature-test macro is unconditionally defined, even in /std:c++14 mode, reflecting the availability of the feature.
To be fair, you could've easily simplified your Java code to the ``` Map&lt;Point, Integer&gt; pointCount = new HashMap&lt;&gt;(); for(Point p : points) { pointCount.put(p, pointCount.getOrDefault(p, 0) + 1); } ``` I'd consider it just as good modulo operator overloading (the lack of it is a major paint point in some scenarios).
Not 2020, maybe 2040. First Rust have to catch up to C++, it will take some years. Then you need early adopters (I mean production-ready projects from more brave teams). After some successful and established projects, Rust will start being considered by more reserved places. This is IMO when it will start rivaling with modern c++. And there will always be C++ conservatists, just like they are for C.
More stuff is definitely planned, however, we'd like not to rush it as a lot of subtle differences in how things are implemented in clang(d) and CLion, and sometimes adopting them as is would result in usability regressions or missing features. We're aiming to avoid it, even if it'll require more work.
Rust helps deal with lots of pains that C++ devs have, so I'd say it's a nice candidate to what you proposed :P
 You are totally correct, but two points: 1. There's nothing wrong with such static inheritance because there are no vtable penalty and dynamic\_cast , everything is being done at compile-time 2. I personally would prefer RegisterRead&lt;address&gt; over Register&lt;address, Register::Mode::WriteOnly&gt; , but it's only a matter of taste. But there's a bit of a problem here. The base class Register cannot depend on the enumerator defined inside of it. So you'll have to store it somewhere outside, which isn't quite good.
Thank you for your prudence and restraint. Please don't break my IDE. :)
As a firmware developer, I can say it's not dead...
Or wishful... 
I think the argument was too many pointers 
There was already a big thread on game tech twitter recently in which people were looking at the .net perf community and wondering when we are going to be able to dump C++ in the performance critical areas for something less fraught. C# has already been popularized by XNA and Unity for gameplay programming and there is active work going on making it a better fit for memory-sensitive work. I don't see C# being able to fully abandon its heap obsession, but C++ shouldn't feel complacent in games.
Hey ArchiDevil, With Shift+Alt+Arrow (Box Selection), an arbitrary click will clear all carets (as it has in the past). If you're doing a Ctrl+Alt+Click after creating the box selection, it should keep your box selection around! If that's not the case, could you send feedback via Visual Studio and attach a video of your scenario so we can take a look? Also to clarify, could you tell me which command from the Edit &gt; Multiple Carets menu you're invoking? I don't quite follow what's happening there.
`points.stream().distinct().count()`?
you're totally right, it's really difficult to make a business case for doing something in c++ anymore. c++11 was a well needed shot in the arm but since then there's not much to aid in actually stuff done, especially on the networking side of things (for me.) Anthing 'big-data' related in written in either java or scala, and that's not an accident.
why? why isn't linux written in c++?
but how much of c++ do you actually use?
sorry, can't upvote anything that uses stringstream
Because there's no point in writing an operating system kernel in c++, any advantages (such as objects and pointer stuffs) would be quickly negated by the fact that you'd have to follow C semantics to allow backwards compatibility, usability by C, and removing name mangling. You can't have RTTI, you'd be limited to only the subset of features you implemented yourself and the \&lt;cstd...\&gt; headers. That, and it'd be a pain in the ass to rewrite [12+ million LOC](https://unix.stackexchange.com/questions/223746/why-is-the-linux-kernel-15-million-lines-of-code)
1. Linux was small and ran in only 4MB -- less than the 10MB upper threshold I specified. http://collaboration.cmc.ec.gc.ca/science/rpn/biblio/ddj/Website/articles/CUJ/1995/9501/roberts/roberts.htm 2. C++ compilers were still very buggy in 1991 when Linus began. Heck, even C compilers were still buggy (though not nearly as bad as in the 1980's). 
Thanks for the feedback! We will keep this in mind with our future planning. If you want to track this more closely, please add your suggestion to our UserVoice: [https://visualstudio.uservoice.com/forums/121579-visual-studio-ide](https://visualstudio.uservoice.com/forums/121579-visual-studio-ide?category_id=30937)
I usually just use Boost's [split()](https://www.boost.org/doc/libs/1_67_0/doc/html/string_algo/usage.html#id-1.3.3.5.9) or a regex_token_iterator...
Why?
There's always a chance a bug is introduced in new Preview build. This had happened so many times for me before. For example, it was impossible to compile `intersect_rect` algorithm in conformance mode without parser messing up with angle brackets, thinking you were trying to use templates. Didn't check this with new build, however.
You're looking for D, actually. I've been messing around with it recently, check it out.
Any eta on the release date? 
&gt; My biggest issue with Rust is that Only i386 and x86_64 on linux are "Tier 1" platforms. Cross compile or even just BSD support seems lacking and does not inspire confidence. 
Symbian os was written in C++ from the ground up. You're basically agreeing with me I think. The parent said C++ will be used more in embedded, I don't think it will. C is sufficient for that.
If you had the ability to analyze languages better than a trolling 4 year old, maybe you wouldn't sound so fucking retarded right now. Next time don't forget to mention the huge range of negatives of Rust and check whether or not Rust is actually winning any popularity content: [https://trends.google.com/trends/explore?date=all&amp;geo=US&amp;q=rust&amp;#37;20language](https://trends.google.com/trends/explore?date=all&amp;geo=US&amp;q=rust%20language)
Rather than using heavy substr + find in favor of search + with its boyer\_moore\_searcher : auto split(const std::string&amp; input, std::string_view delim) { std::vector&lt;std::string&gt; tokens; auto start_point = input.begin(); auto item = std::search(start_point, input.end(), std::boyer_moore_searcher(delim.begin(), delim.end())); while(item != input.end()) { tokens.emplace_back(start_point, item); start_point = item + delim.size(); item = std::search(start_point, input.end(), std::boyer_moore_searcher(delim.begin(), delim.end())); } tokens.emplace_back(start_point, item); return tokens; } It's, IMHO, a little more flexible ([livedemo](http://coliru.stacked-crooked.com/a/4f092b179ed49a50))
&gt;"why will programmers en-masse switch to Rust"? No one (sane) is suggesting that C++ developers will wake up one day and convert everything to Rust. When C++ first gained traction it didn't need to supplant 30 years of technical debt. What might happen is that new projects will be started in Rust that will promote adoption by particular sectors (e.g., the Servo project and WebRender, ease of compiling Rust to WebAssembly, etc). More likely we'll see Rust code enter our codebases little by little. Some people are doing that already. There are a handful of things that are just easier to do in Rust than in C++. Personally I see professional multimedia tooling as the one sector that could benefit immensely from Rust. But that industry moves very slowly. 
It's a slow horrible mess that only exists because it was the first proper functional-paradigm language based on jvm to gain any traction. There are much better alternatives now, like Kotlin. So if you have an option and just want to "check something out" (but more than just a Hello World) better look elsewhere.
Not even VHS vs Betamax. Betamax beat VHS to market by about a year and had a chance to grab an early lead. Both technologies were new so it was just a battle for market share. C++ predates rust by literally decades and there are millions and millions of lines of existing C++ production code. That kind of momentum is really hard to overcome without a seriously compelling argument. Meanwhile, C++ is adding many of the more accessible features of rust which decreases the advantages rust has and makes it an even less compelling choice.
There are so many bugs in your code! 1) `::FindResource` expects NULL-terminated string, `std::string_view::data` does not give you that; 2) after `::FindResource` you have to call `::GetLastError` if it returns `NULL`; 3) your `Resource` class is copyable and moveable, but none of those do the right thing; 4) `GetResourceString` and `GetResource` should be `const`; 5) you don't need to call `::GetModuleHandle`, just pass `NULL`; 6) you have to check return value of `::FreeResource` to catch bugs like in (3); 7) does not compile then `UNICODE`/`_UNICODE` is defined. And btw, in modern C++ you should avoid macros if possible, use normal strings to name your resources `Resource very_important("poem", "TEXT");`.
There's more than just one bold statement in that comment.
&gt;It would be nice if C++ committee start working on a really new C++. No back compatibility or at least not high priority, but maximize all other knowledge which an experience C++ developer already learned. Remove all the pains and keep the good part. Why don't you ask the Python community how that works out? We're very nearly a decade on from the Python 3 break and they still have yet to fully unfuck themselves from that decision.
Please don’t be so rude. 
It's already written in C and it is not good practice to do a major rewrite of something that isn't broken.
[Computation Structures](http://computationstructures.org/videos/info/lecture.html) is a very well produced lecture series in this vein. [Nand2Tetris](https://www.nand2tetris.org/course) is another. No videos but there is a printed textbook.
I like C, but C++ feels like a mess they have just been strapping stuff onto for decades, I just cant get into it, think they need to completely ditch it and start a fresh with just the modern features and syntax or its just going to become useless over the next few years.
Why?
In addition, have you considered some courses available from coursera like computer architecture to start ... you may not be able to find and all in one series but pretty sure you can find all available topics from hardware to the software layer. You do not necessarily have to enroll to be able to access the videos. 
&gt;discarding things that weren't necessary for the STL Talking about yourself in third person again?
Are you looking to understand computer systems in general? I would highly recommend checking out "Computer Systems - A Programmer's Perspective" by Bryant and O'Hallaron. Searching the book name with "pdf" returns helpful results. It covers a lot of ground in what you want. [Bitwise](https://github.com/pervognsen/bitwise) is a project that I am currently following. You should definitely check it out too. 
When did boyer_moore make it into the standard?
Reduce is often give or take N/thread_count(assuming thread count is a core). You do each block on a thread and then reduce the thread_count items that are left.
Just wanted to show a java 8 solution: Map&lt;Point,Integer = list.stream() .filter(p -&gt; p != null) .collect(Collectors.toMap(p -&gt; p, _ -&gt; 1, (a,b) -&gt; a+b)); 
There is a cost for parallelism in both the overhead of startup and the overhead of communication. Ultimately memory bandwidth pinch many algorithms. So if your reduce operation is just a few operations you are not doing enough work. A reduce divides the work well and requires very little communication. 3ms for 6 million items is 0.5ns per item, that seems too fast. Looking at the code https://github.com/fenbf/ParSTLTests/blob/master/ParSTLTests.cpp .It looks like the compiler is probably not doing the work and needs something like DoNotOptimize from google benchmark(or use google benchmark)
Thanks.It's really cool!
There is code being used today that was written in Cobol or Fortran that works fine... commercial code, especially for embedded systems, can live on decades later... C++ is so prevalent that it's not going to become useless in the foreseeable future.
Useless was the wrong word, pointless maybe more apt. For the average programmer today there doesnt seem to be any reason to use or learn c++, maintaining old stuff is not a good reason. Python and D look like the future to me but im not a professional. 
Streams are nice, but slow (though for maps I doubt it'd be a significant factor, but for native arrays they can be x2-x3 slower then the alternative loop code). They are nice in general making a lot of stuff easier though. I hope something like this would be trivially possible with ranges eventually, but it doesn't seem to be the case for the current proposal.
Built-in GC killed D, IMHO.
That's not true. Those are listed as Tier 1: Target std rustc cargo notes i686-apple-darwin ✓ ✓ ✓ 32-bit OSX (10.7+, Lion+) i686-pc-windows-gnu ✓ ✓ ✓ 32-bit MinGW (Windows 7+) i686-pc-windows-msvc ✓ ✓ ✓ 32-bit MSVC (Windows 7+) i686-unknown-linux-gnu ✓ ✓ ✓ 32-bit Linux (2.6.18+) x86_64-apple-darwin ✓ ✓ ✓ 64-bit OSX (10.7+, Lion+) x86_64-pc-windows-gnu ✓ ✓ ✓ 64-bit MinGW (Windows 7+) x86_64-pc-windows-msvc ✓ ✓ ✓ 64-bit MSVC (Windows 7+) x86_64-unknown-linux-gnu ✓ ✓ ✓ 64-bit Linux (2.6.18+)
This is the greatest thing ever. The only reason I've been using CLion is the other C++ IDEs have deal-breaking issues I can't live with, but the default CLion C++ parser is the slowest thing ever. My 8-year-old 12-core Mac Pro with XCode is faster and more accurate in-IDE than my 10-core i7 6950X w/ CLion at present.
Is it just me or CLion performs really bad? I tried to adopt it several times over the years, but i always feel like the IDE is dying.
A quick grep across all of the cpp files says about 1.8m lines. We make windows software that communicates to hardware we make as well. I work on both sides. It's the only language I use every day. I work with vision systems a lot so I end up needing really fast code for processing data. C++ rips through it
C++17 https://en.cppreference.com/w/cpp/utility/functional/boyer_moore_searcher
Try /r/programming 
In same hardware I've seen worst offenders. CLion is not incredibly fast, would like it to be faster, but never reached "unusable" levels of performance.
Coming into C++ from C#, I was pretty surprised to find out that there is no true composable “functional” way of manipulating collections. I have been hoping that Ranges will fix that. What is the problem with the current proposal?
&gt;adding a bunch of `requires requires` clauses in the mix did not improve the situation How many levels of `requires` are you on man? I don't know, maybe 2? You are like a little baby. [Watch this.](https://godbolt.org/g/HEqxQp)
&gt;"I will never read from the wrong memory address by mistake" [SaferCPlusPlus](https://github.com/duneroadrunner/SaferCPlusPlus) (shameless plug) is (at least intended to be) a functional proof-of-concept of a memory safe subset of C++, that supports the technique of using scope lifetimes to achieve "zero-overhead" protection from use-after-free, like Rust. Unlike Rust, complete safety is not yet fully enforced at compile-time, but achieving that wouldn't require a sophisticated borrow checker like Rust's. The library has compatible drop-in safe replacements for the most used unsafe C++ elements, including compatible drop-in replacements for pointers. So most C++ code can be converted directly. (Unfortunately (unsafe) native references don't have a syntactically compatible safe replacement and would have to be replaced with safe pointers.) And like Rust, it's also data race safe. So there's no technical reason why C++ won't have the memory and data race safety (and [performance](https://github.com/duneroadrunner/SaferCPlusPlus-BenchmarksGame)) of Rust. The CoreGuidelines Checkers are also intended to enforce a memory safe subset. Though I suspect that you'll still need some of the SaferCPlusPlus library's elements, or equivalents of some kind, in order to address the checker's (liberal number of) false positives.
Maybe because Python had many problems in the first place? If `print` is a keyword, you're not making a general purpose language. You're just making a better Perl.
I think what /u/Obamurri meant has to do which how much C++ you use that isn't actually plain C or almost plain C. We all see people using a C++ compiler and indeed writing in C++, but it all being almost all plain C.
I want to point out that if you have a custom allocator, you can avoid most of the overhead you'd get from the default `malloc()`. 
As a software engineer in vlsi industry, I can tell you that c++ is here to stay and for a long time. Most of our non-hdl codebase is in c and I know what kind of mess it is, to spend half my week in cleaning memory leak bugs which could have been easily avoided by using smart ptrs instead of creating your own data structures and managing them by hand in c. I have been in several companies that operate in this domain and It is the same almost everywhere. Most of the companies are now resorting to c++ to clean up this mess, at least that is what people who work there say and also that is what my company is planning to do. And to give you some context, this happens once in million years and it takes a long long time. So, if you know c++ and if you are in this domain you can easily thrive for next 10-15 years. 
You are a compiler, you can do as much UB as you want as long as it works in the generated code.
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8ua7tr/matt_godbolt_why_c_isnt_dead/e1f1n3n/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I use virtual classes and objects.... 
There is a course from the authors of Nand2Tetris at [coursera](https://www.coursera.org/learn/build-a-computer).
... and fly to Cologne, Germany to present the proposal, because Internet mailing lists aren't How These Things Are Done.
Not a question so much as a comment... coming back to C++ after over a decade of not using it, I must say that after finding an excellent beginner's guide online to CMake, I really like it. (Before that, I utterly hated it, but spending five hours on that beginner's tutorial really helped.)
One thing C++ has going for it is the fact that it's an ISO standard. We tend to disparage C++ for having many "implementation defined" stuff, but we need to remember that, for all other C++ replacements, D, Rust, Go... *everything* is implementation defined, and there's only one implementation that overshadows all the rest, if any.
That's because functional stuff tends to need a garbage collector in order to implement things sanely. The Ranges proposal hinges on concepts, which cuts down on the convoluted templatey stuff that Ranges would require otherwise.
The older Windows headers used by v140_xp mode have a bunch of them. Invalid token splicing seems to be the more common offense no longer accepted by the new preprocessor: #define _VARIANT_BOOL /##/ You can't splice two slashes into a comment token, comments are parsed and removed before macro processing. 
&gt; after ::FindResource you have to call ::GetLastError if it returns NULL; Why, if you don't actually need the detailed error? &gt; you have to check return value of ::FreeResource to catch bugs like previous; FreeResource() is [deprecated and a dummy routine that always returns FALSE](https://msdn.microsoft.com/en-us/library/windows/desktop/ms648044%28v=vs.85%29.aspx?f=255&amp;MSPPError=-2147217396).
&gt;This does not feel like C++ to me. Cool utilities, but let's take your slice for example. It works on a single container, but what it does can be extended to anything that is Bidirectional iterable (if you really care about efficiency then RandomAccess iterable). A C++-ish slice for me would take iterators and return iterators (or write to an output iterator). I made this benchmark [https://paste.ofcode.org/33Ux6SCNKxEhWfC95FKb3EW](https://paste.ofcode.org/33Ux6SCNKxEhWfC95FKb3EW) Unless I am doing something wrong, it shows that the basic way to copy changed data over is about 25&amp;#37; faster than doing it via an iterator. If there is a better way to make the benchmark, please reply with a "[paste.ofcode.org](https://paste.ofcode.org)" modded code, thanks.
[https://paste.ofcode.org/UHPh9YjjTmZ45yjFbG76Fh](https://paste.ofcode.org/UHPh9YjjTmZ45yjFbG76Fh) If forgot to delete the array in the original one. I for
I like a lot of the ideas behind Go, but I want the ease of the coroutine/threading/async that Go gives, without the loss of control that Go forces with its Garbage collection. Additionally, if err != nil can go die in a fire. Just give me dang exceptions please.
nitpicking: `alignas` accepts types, which are equivalent to `alignas(alignof(T))`.
The problem with D and C++ is that C++'s semantics are ok. What C++ needs is a cleaner syntax for the same stuff, and D isn't that. Give me a cross compilation unit compatibility and I'll be happy.
A lot of those features are on the roadmap. The first of which will come with const generics and the internal representational rewrite going on to support it. 
I don’t see it as a C++ killer it’s just a language that has similar semantics as it, but with different defaults
you said it yourself, not a professional. a huge amount of programming jobs aren't to start a new project, but to maintain an existing one.
Even "C with classes" is still miles better than plain C.
Coming soon to a C++ codebase near you, template &lt;typename T&gt; requires requires (T x) {...} void foo() noexcept(noexcept(T())); [This](https://frinkiac.com/meme/S04E17/922170/m/IFRIRVJFIElTIE5PIEdPRCE=) is the only correct reponse.
Yeah, but people imitate that in C, so it's C 😁. (On a more serious note... the parent insists in a wrong place, that's all).
Maybe it's time C++ programmers start designing Java libraries? :P I've been using C# a lot now, and I feel that its library is more lightweight and straightforward to use compared to Java.
Radical idea: having dabbled in Java and done decent amount of C# work lately, the C++ community and committee need to realize that metadata about the code is the king these days. It's so nice to get an assembly (DLL) and be able to inspect it and use it on the spot w/o any additional headers, libraries, linker flags, etc. Single artifact (file) lets you use it. Refactoring gets easy. Etc. So: since C++ is already defined in terms of an abstract machine, the committee should take the bold step and *standardize* the abstract machine itself to be CLR. It has most, if not all, the features needed by C++. Calling conventions standardized. Suddenly you can write compiler plugins and not bother the committee with, say, coroutines. Etc. This would also resolve packaging and modules. So.. everything would be compiled to CLR assemblies and native code would be optionally generated in the final link step. 
Rob Pike addressed that in a talk. He basically said that manual memory management becomes increasingly complex in concurrent code. Either way, you're not losing much in terms of performance. If I'm not mistaken the [gc](https://golang.org/doc/go1.8) pauses are now on the order of fractions of millisecond, which isn't that much - it's relatively easy to reason about performance and latency with those numbers.
This is more of a proof-of-concept than a production-ready code. Of course, you have to modify the way you presume it'll be used. * You are correct here, that's a mistake; * Since all of the resources are known at the compile-time, it's trivial to create a map of known resources and restore them according to one. All of those error-checking code is surplus, you only have to check the resulting pointer for `nullptr`; * As I've mentioned earlier, it's a proof-of-concept. If you're worried that someone will try to copy an object of this class in your own code, simply `= delete` the corresponding move/copy constructor; * The lack of `const` in data-return methods isn't a bug, but yeah, it's better to be there * `UNICODE` should be handled a bit different, I agree, I'll take a look There is a problem with the last statement, because WinAPI is built with heavy macro usage. You just used them yourself in the above sentences: `NULL`, `FindResource`, `GetLastError`, etc. There is nothing wrong with such enumerated macros, there are no side-effects.
&gt; change the signature of an interface for the library that implements it AND for all the code in my workspace that uses it How is that possible? If you want, say, to feed an extra parameter to a call, you have to get it from somewhere in each of your call sites. 
Sure. And then it won't build and you'll know where. But it you wanted to change the signature to accept an interface instead of a type, or if you just wanted to rename the method, then those just work.
Hmmm, not really. Incremental efforts are the only way... and good luck obtaining a minimal version of cv::Mat.
Brave teams like **[Microsoft](https://old.reddit.com/r/rust/comments/8ub964/microsoft_announces_using_rust_to_build_some_of/)**?
Please no. Read the nana code to understand why. 
I've wondered about this a couple of times: if we could drop backwards compatibility, what would we remove? I couldn't come up with a lot, except for strong typing instead of weak typing.
teams has thousands of independent teams.
My firmwares heavily use templates and constexpr to autogenerate code and decide between algorithms based upon known data tables. Classes with inheritance are heavily-used, virtuals less so, no exceptions only because the ISA doesn't support them.
How much "personal" is that? Is it somewhere on github? Can you share? I would love to make a QtCreator plugin that loads a vcxproj and build it.
It does at least save you from data races, but that is a memory safety concern.
Except Rust is nothing like C++, really.
Let's get to it. I've already proposed doing it in a few threads here.
Having a single "main" (open-source) implementation is actually a good reason for a lot of people to switch from c++ to rust
I'm using C++ with 8 KiB of RAM max.
My Ruby build scripts for C, asm, and C++ are on github (look for the Tuna 3d printer firmware). Those don't use vcxproj though. That one isnt on github yet, is C++, and won't be until I finish the embedded preprocessor and dependency analyzer. It works but doesn't handle complex conditionals in preprocessor expressions.
There are a lot of places where the default is backwards, because that's how it was in C. Mutable unless const. Implicit unless explicit. Might throw unless noexcept (okay, maybe not that one). By value unless marked as a ref. I'd like to see the default be the sane choice... ... also, do-over on initializer lists.
Agreed. Unfortunately. Even with that being phased out, it's too late now. The wrong first impression and all...
The Python community would tell you that, yes, there were some problems along the way but that the move was largely a success, and definitely worth doing. And they could provide advice for how to avoid some of these problems. (Personally I think that, being backwards compatibility breaking anyway, it missed many opportunities at genuinely improving the language but that's another debate.)
I mean, yes, it was.
That's the dumbest thing I have ever heard, people make their own OOP implementation so all of the sudden me using built in OOp is now C? 
&gt; but I can't image a 2020 where any sane team says "You know what language we should use for this new project ? C++". I find your lack of imagination disturbing.
I was there in person and while Matt is a good speaker, it was ~2 hours I am not getting back. Coming to **C++** meetup with evangelism about C++11 being good feels redundant. ¯\\\_(ツ)_/¯
The fact that, because move semantics weren't baked into C++, moving is a non-destructive operation means that there is a finite limit to how closely a static analyzer for C++ can match Rust's borrow checker. That said, C++ does, between its vastly more powerful template system and the increasingly capable constexpr, have a serious leg up on Rust for tunable library implementations.
I added the caveat because my opinion is not an authoritative one, i dont know if c++ is dead or if its dying, and im not the person to ask. But for me as someone studying cs and interested by programming, i cant see any reason to invest time in c++ and id be hopeful we can leave it behind in the future, like religion. Seems to me like its not the best at anything, for higher level stuff with no speed concern it would be insanity to use anything other than python 3.6, which in my unesteemed opinion is the pinnacle of programming languages so far, its the best that humans have created. For low level stuff where speed is most important you use c or assembly. Who knows how things will change in the next 10 20 years but how long are we going to stick with all this old code, it cant last forever, we cant be worrying about backwards compatibility to the 70s in 20 years time. Programming landscape could be very different faster than we expect.
It is slow for me too in a project with half a million LoC. I have to say it is great with a 30k one, definitely would become my main IDE if they could unclog the performance. I already use PyCharm a lot.
In fact, I recently discovered that Rust is, when using the standard library for concurrency, significantly *more* vulnerable to deadlocks than C++, because it is harder to pre-group all required locks and perform a single consistently ordered lock pass. std::lock(lockable...) is a very good thing.
Ah right, good to see them listed. So basically what rust does : )
It's an awful, terribly inefficient class.
I'd say that D's external linkage to C++ is more directly useful than Nim's transpiling, honestly. Neither of them has done much to drive adoption.
Ah. I find it pretty convenient. Anything better in the stdlib now that you'd advise?
&gt; I use virtual classes IMO, it's a bad wording for C++ world, "virtual inheretance" and "virtual functions".
I think your point about `print` is actually quite prescient, although when I think of Python 3 (neé Py3k) problems, I usually end up at slow, unbuffered I/O.
Something like [N4028](https://isocpp.org/files/papers/n4028.pdf) could make that happen. Too bad the committee is allergic to even acknowledging the existence of... I don't even know where to start, maybe name mangling?
Oddly, I'd never heard of Pony before today...
Looks like the era of clang is coming: [QtCreator already switched](https://blog.qt.io/blog/2018/06/05/qt-creator-4-7-beta-released/) to it, now Clion. Hey, Microsoft, what are you waiting for? ) 
Yeah, rust got those things right. The advantage of starting clean, rather than extending a legacy language...
Most concepts do transfer over however, like lifetimes, RAII, concepts, ranges (still to be added in C++), move semantics, `auto`, etc. 
People switch to and from languages for many reasons. People have also been known to switch away from languages with only defining implementation for the same reason.
The WinAPI is not exactly a good model to follow, given its heavy _abuse_ of macros, even beyond what is necessary for C compatibility. It is still a good idea even in Windows-specific code to prefer constants. This particular case is not just about style, though, as the IDR_* macros are generated. You have to use them to cooperate with the resource editor. Thankfully, they are consistently prefixed and low risk, versus horrors like TRANSPARENT and SendMessage. 
Eric has ideas for extending Ranges to support similar design patterns, but it's definitely a C++ 26 or later item.
Judging by your flair, I think you should know just how many scientific packages are *still* not only not converted to python3, but are started as python2 packages in the present day.
And has that been a problem for Python's popularity of usage?
As I mentioned, I don't have much experience here. Are you aware of any reason why constexpr `std::string` cannot implement SSO when not in a constexpr evaluation context?
&gt; By value unless marked as a ref. I actually like this. Meaning, I actually like being explicit about what I want. "Sane" seems like it'd be really hard to figure out automatically, at least to me. If I'm writing something in a language that isn't explicit in that way I always have to waste time looking at what the default will do, and then forget what that was as soon as I stopped. It's a level of automatic-ness I'm not comfortable with when I'm reading or writing non-C++ code, but maybe that's just what C++ has done to me. I'm always like "What's going to happen? Is this expensive? Can I change the parameter for my caller?"
Yeah, but heres the sad reality. those companies and communities around the world aren't moving to future standards, or even compilers, anyway, so it doesn't matter whether C++3000 is compatible with C++98. ***AND***, when they **do** move, compatibility doesnt matter anyway because compilers aren't perfect, so they still have to invest in upgrading their code and making sure it still works right on a new compiler. By all means, don't break compatibility without good reason, and break as little as possible, but likewise don't *not* break it just because. It should be a legitimate option, even if rare. Currently its not really an option at all. It doesn't need to break everything all at once either, which is the problem with *new* languages like D or Rust or whatever Better C++ of the month is out. It's also important to remember: Nobody is forcing anyone to upgrade, and again, many don't, for good reason too. New compilers can have new bugs. Current compiler is already setup up and has whatever workarounds and non standard behavior depended on.(Like, any version of MSVC before VS2017? /permissive is new, and it still isnt entirely compliant.) Compatibility or not, reality makes upgrading a *hard* thing to do for those kinds of codebases.
Could you elaborate? What exactly do you mean by "nothing like"?
All I'm saying is that WinAPI supports loading by a string, your wrapper does not. Do not use `::FindResource`, use `::FindResourceW` [here is why](http://utf8everywhere.org/), it is not a macro, just like `::GetLastError`. So, yeah, like I said, no need for macros.
`GetObject` is my favorite ;)
&gt; Seems to me like its not the best at anything Seems to me like you need to learn more about the topic then, since C++ is pushing the state of the art as far as compile-time programming is concerned.
Well Rust has managed to do it without a GC.
I don't really do C/C++, but with all the automagic going on in so many langs, I wonder if I would prefer forced explicitness. Maybe with *&lt;keyword&gt;:* as in *public/private:*, just to save some typing. I'm not opposed to some verbosity, as long as types are static and the IDE can help me. private mut int x=0; public const int y=0; public: const: int z=0; Sth like that? I dunno, just an idea...
I know that all the important ones fully support Python3.
&gt; For the average programmer today there doesnt seem to be any reason to use or learn c++ Ummm... FUN? Not all my programming is happening on the job, you know.
Unfortunately, this is inaccurate. Qt creator uses their own clang-based backed rather than clangd. it means you can't it with a newer clang for example. I hope they change that at some point.... 
Thanks for the laugh!
That should be enough for everyone.
I... didn't mention anything about the backend.
Well for [embarrassingly parallel](https://en.wikipedia.org/wiki/Embarrassingly_parallel) problems I’d expect a close to linear speedup. Maybe not 400% but 350% is realistic. But `reduce` isn’t embarrassingly parallel (in fact, it’s often used as a teaching example of a non-embarrassingly parallel problem). So expecting a linear speedup isn’t only unreasonable, it’s theoretically impossible.
There are many comments here, and generally in this subreddit, about how C++ is dying and it needs to give up its backwards compatibility fetish to survive. Do people have _specific_ ideas in mind on changes to the language that, despite breaking backwards compatibility, would have a strong positive impact on the language? 
`constexpr std::string` cannot use SSO because you cannot do `reinterpret_cast` in a constant evaluation context. But `std::string` can use SSO just fine. The motivation for `is_constant_evaluated()` is to avoid SSO, and its `reinterpret_cast`s, in constant contexts while still allowing it in non-constant ones. 
It's quite easy to do a small one with std::stringstream and std::getline. Then of course there is boost. 
The idea of C++ is not to create a new language..
heres my question. as someone starting fresh in the industry how hard is it to get a job that takes advantage of c++? i figured its like COBOL where they mostly hire experienced people.
&gt; the increasingly capable constexpr I thought Rust's const evaluator was pretty nice as well since MIRI was merged, anything in particular that is missing?
What does `..W` have to do with utf8?
You can manage to do it in C++ as well - hence why Ranges can work without concepts. It's just not sane to implement, especially when you want speed and minimal memory usage at the same time. The functional stuff I'm referring to is the lazy evaluation at runtime. Lazy evaluation means anything required to do the final computation must hang around. Whether the reference accounting is done with smart pointers (copy-on-write) or an actual garbage collector, or just proper copies, there is garbage collection overhead. The std algorithms are actually very composable and operate on containers in place unless otherwise specified.
&gt; "why will programmers en-masse switch to Rust" Productivity and fun in general, and no more debugging races and segfaults in particular. But personally, I think the Crates ecosystem is the killer feature right now. That, and the fact that it's geared very well towards pulling in Python/Ruby/Javascript/Java coders who want to make part of their code more efficient without risking segfaults. That's a *lot* of coders that have a strong motivation to contribute to the Rust ecosystem who will never consider C++.
Everyone from the Rust subreddit that found this thread. 
To be honest, even if I needed "almost plain C", I'd still prefer to work with C++ for the added type safety and utilities, eg `std::array` over C-style arrays, `constexpr`, `std::unique_ptr` etc
&gt; Personally I see professional multimedia tooling as the one sector that could benefit immensely from Rust. But that industry moves very slowly. (Rust community management here) I know of multiple adopters in precisely that space. It's precisely happening as you describe it and you reflected the position of the Rust project perfectly. It's not about replacing or removing C++. Firefox is a perfect model for this: a huge, working codebase, in which parts of it are replaced by another language that gives a different set of guarantees. There's a lot of work in making that process feasible and we support that. For example, cargo will soon be able to emit a "build plan" which allows you to do what cargo would do, without having cargo around - that has been a huge wish by people that only want one build system for their final product. We're not into sparking a language war - as Matt puts it very nicely in his Rust section: systems programming is becoming hot again and we're part of this. Just as the recent movements in C++ are (and that's great, it's not going away) or other new languages like zig, pony and so on.
A fair point. I think I realised that was going to be the case for some of the audience. I can o it apologize and hope the few non C++ folks, and those watching on YouTube get more from it!
Ok, let me rephrase: Are you aware of any reason why in a future C++ standard, a constexpr-capable `std::string` cannot detect when it is being used in a constant evaluation context, and thus avoid the use of SSO?
While MIRI can execute arbitrary Rust code, that doesn't mean `const fn` can. We're keeping it small and slowly expanding it. Additionally, it's not stable yet, so to many people, it doesn't count.
I have a dream that once module support is in and somewhat widespread, that it'd be practically possible to create a simplified alternate syntax for C++ that fully breaks backward compatibility and focuses on making straightforward *application* development tasks as easy and safe as possible. Let's call it ++C. Example changes are: * No implicitly uninitialised variables * No implicit narrowing conversions * Properly implemented signed/unsigned comparisons * Remove most of the integer types except `int` and the explicitly sized signed and unsigned types * Especially remove `signed char` and `unsigned char` * Make `char` always unsigned and maybe rename it to `byte` * No raw new/delete * Support for `unique_ptr` and `shared_ptr` directly in the language syntax * Simplify structs to be simple aggregates without inheritance, constructors, non-static methods or private members * etc. It wouldn't necessarily expose all the complications that allow one to build crazy template meta-programming based libraries or implement low-level, performance critical template data structures. But because ++C and C++ would be different syntaxes for the same language (and compiled on the same compiler), they would compile down to compatible modules, so complex libraries could still be written in today's C++. Realistically, it might not even be possible to write libraries in a complex subset of C++ and use them from a simplified subset, given how vital inlining is with modern templated code. And of course creating such a reduced feature set would be an epic battle as everyone would have their own couple of semi-advanced features that they "absolutely need" in ++C to make it usable. I now await a dozen comments telling me why it would never work, but a man can dream, can't he?
&gt; Lazy evaluation means ... there is garbage collection overhead. This is *often* true, but not always true. Rust's iterators are lazy, but doesn't use refcounting, tracing GC, or allocation, and doesn't inherently copy either. In some cases, you might get a copy, but not always. When you do, it's because they're small enough for it not to matter.
The If-initializers actually simplify the code, as to get the same behavior previously you would have to define a separate scope around the if statement to control life time. Every new way of doing things does have an associated cost. However, it a fairly simple rule compare to the rest of the language, and can likely be taught along side for loops. If you think about it's not so much a new feature as it is making "if" more consistent with "for". Probably harder to swallow for a veteran than a beginner tbh. 
I'd think the only things which wouldn't readily transfer are templates (Rust's generics are quite different) and constructors (which Rust removes)?
Having a constexpr-capable string means it has to detect that. That's what would make it constexpr-capable.
&gt; especially when a type (or trait) can silently change that behavior… It's not silent since it has to be explicitly opted in; and because rust doesn't have constructor the only change is completely static (the compiler will prevent using a non-Copy type after it's been moved), there is no change whatsoever in runtime behaviour when switching between Copy and !Copy. And since *adding* copy is backwards-compatible but *removing* copy is not, it makes sense that move would be the default, and copy would have to be opted in.
&gt; So I now await a dozen comments telling me why it would never work, but a man can dream, can't he? Your comment reads a lot like Rust, though I'm not sure what you mean by the signed/unsigned comparison bit (do you mean implicit conversions when doing such comparison?). And while narrowings are explicit (so are widenings incidentally) they're not *checked*. And `char` is an actual codepoint, bytes are spelled `u8`. Although Box/Rc/Arc are not part of the core language (not quite sure why they should be either), and structs do have methods (not as part of the struct body, they're added via dedicated `impl` blocks) and private members as Rust doesn't have classes (or inheritance, or constructors).
Imagine how strict it would have be if one wanted too account for multithreading? Externally accessible memory such as a* could not benefit from virtually any optimization at all. Not just the reads, but the order of all the reads and writes... Atomics on small types basically exists to block optimizations. 
Should name it "C!". This way people will sound excited when they talk about it, and drive up interest. 
&gt; Your comment reads a lot like Rust Some parts of it also read a lot like Swift or Go or Nim or a variety of modern languages. I've never tried Rust, but I'm sure there are lots about it I would love. The major point of my post was that an alternate dialect of C++ would be incredibly useful to the thousands of projects (like those I work on) that depend on the C++ ecosystem and have tonnes of legacy code, but would like to start writing new code in a compatible, but much more modern and safe dialect. &gt; I'm not sure what you mean by the signed/unsigned comparison bit I mean that given a signed number and an unsigned number it's easy to determine which of the values is larger, without narrowing either. It's two instructions instead of one, so it's obviously less efficient, but I much prefer correct to fast when it comes to defaults. bool less(int a, unsigned int b) { return a &lt; 0 || unsigned int(a) &lt; b; }
Sure, iterators themselves aren't refcounted etc etc, but to build things on top of them, using closures up the yin-yang, will eventually run into webs of ownership that requires accounting for simultaneous access.
Most iterators’ closures have null environments, so it’s usually only the underlying collection, which is one thing and doesn’t form that web. You’re 100% right, but it’s the extreme minority case, at least in my experience.
Constructors aren't removed. They're just not special enough to deserve their own name and syntax :P Default constructors are still a thing though, which Rust has.
&gt;For desktop application it's been dying a long death for a while, as speed becomes less relevant. Speed is irrelevant on the backend too. You optimize for cost, which usually means optimizing for power consumption in practice. 
I don't believe the claim is much persuasive. Since right now there is no much people use it and very few huge project written by rust. All the words are come from Mozilla community. How do you know rust has no its pain?
&gt;either in the compiler itself or with static analysers the best features of Rust I doubt this will ever happen. Static analysis is really, really hard and it necessarily would trap some valid C++ if it were to ensure memory safety. &gt; My feeling is that Rust won't displace C++ Sure, just like Go won't displace Java. There's a lot of software out there already and it likely won't be rewritten. 
&gt; I will never have an error due to typecasting You can definitely do that in Rust with e.g. `432884328324 as u8` or the like.
We already have early adopters who build production-ready projects, e.g. [ErlyVideo](https://www.reddit.com/r/rust/comments/7u5gxh/rust_talk_at_highload_2017_in_russian/).
Rust was voted the most loved language on Stack Overflow three times in a row, so most of the problems are coming from the tooling and the ecosystem, and not the language itself, and these things can be improved along the language, so it has a lot of potential. &gt; They've failed at making a simpler C++ I'm not sure about that, it's true that the learning curve is steeper, but once you're familiar with the rules, they're part of the workflow. Compared to that, C++ has a lot of tricky edge cases. &gt; they've failed at making a faster C++ If you take a look at the [Benchmarks Game](https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/rust-gpp.html) results, you can see that in some cases Rust is actually faster than C++, and a lot of time it's not, but there are only a few cases where C++ is faster because better code generation. C++ uses SIMD everywhere where it make a difference, and SIMD was stabilized in Rust only a couple of days ago, so the Rust entries don't use SIMD yet. Also, there are cases where a highly optimized library is used in C++, which makes it faster than the Rust version. (So the problems here are more optimized C++ compilers, missing or unstable language features and young ecosystem. All of these can be improved). &gt; and they've failed at making a faster compiling C++ There are not many low hanging fruits left in the compiler anymore, so speeding it up requires significant changes. These changes are happening, but it's a slow process. Also, the initial implementation of some of the new language features sometimes introduce additional slowdowns in the compiler, so at the same time the Rust team also needs to fix these (or leave it and wait for a new implementation. This happened when the MIR (Middle Intermediate Representation) was introduced and it's also happening with the borrow checker). The other significant problem here is that LLVM was primarily a C/C++ compiler, and the current Rust compiler doesn't generate optimal LLVM IR for the backend, which means LLVM spends a lot of time on converting it to a form that is easier to optimize. This is also the cause of some of the missed optimizations. &gt; A C++ fork that breaks backwards compatibility will pretty much instantly destroy Rust A C++ fork has to rebuild its entire library ecosystem from scratch, so I'm not so sure about this.
You should show this off using godbolt.org so that the results can be pinned down better. I'm guessing this is something you are new to since you think there is a chance that msvc would standardize on gcc method of extra function I formation. Most projects make their own export macro that is different for gcc and msvc. Clang might be able to do both, it isn't locked to being gcc compatible.
Tragically missed opportunity for `template &lt;template &lt;class...&gt; T&gt;` - double all the keywords! 
This relates to my recent experience too: you can go from a working program to a runtime crash (but still compiles &amp; links w/o warnings) just by shuffling around how you link (not touching any C++ code). (hint: static initializers)
Rust fangirls.
3 things I find the most annoying in java are: - (almost) everything is nullable - tempates based on runtime polymorphism - constness only by means of immutability (this is most of the time not possible to do due to performance implications). You pass an argument to a function and the function can do literally anything most of the time. (and `final` is a joke) And i've only been exposed to java on basic level.
No, I mean the other situation. When I select something with Shift+Alt+Arrow the selection carets look like multiple carets (blue and the red one). But when I try to use result of the selection via for example arrows, or Home/End keys, these multiple fake-carets always reset to one. I do not use mouse in this case. But when I select something using Edit -&gt; Multiple Carets, true-multiple carets look the same as box-selected-fake-carets (blue and the red one) and work fine with arrows and Home/End keys. This really limits its use to some easy scenarios and is very annoying. IMO, box-selected carets should work the same as true-multiple-carets.
Is there something inherently worse abut rust's memory management?
Hijacking ODR usage is not the way to solve this. That would be a hack. What is needed is a way to describe runtime linking of C++ objects and exporting from libraries within the language. It is done on every major platform, but the C++ standard is completely silent on it. We have many ways to modularize C++ code, including the upcoming modules. None of them match how shared libraries work or are loaded, nor can they replace a shared library. You can see an attempt here: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2407.html 
This issue regarding portable specification of dynamic/static linking is a festering sore for many years. I was pleased to see the paper cited above. But very disappointed to see that it is dated 2007 and hasn't been acted on. This sorely needs attention by the iso committee process. Robert Ramey
Silently in the sense that an implicit cast operator in C++ is a silent coercion. It's silent from the consumer's perspective.
Branch-constrained evaluation works with constexpr. It doesn't sound like a huge deal, but it really is.
Is it possible to use the toolset from 15.8 Preview 3 in a stable 15.3 IDE? Incredibuild will need to be updated for this new version, but I'd like to be able to use the existing IDE and fix up the code to make it `/experimental:preprocessor` clean.
&gt;(Rust community management here) I know of multiple adopters in that space. Out of curiosity, who? I work in that space and haven't heard much noise about Rust yet. But I'm probably biased, our stuff is pretty niche. 
I honestly can't think of a default I like. Java default is always (mutable) ref, except for built-in types. *bad*. Rust default is (immutable) move, unless the type specifies copy. *bad*. C++ default is copy by value, unless the copy constructor does something else. *bad*. Maybe all passing conventions should be explicit...
It's not a bad idea... there are even advantages to memory-grouping the mutable and immutable parts....
My impression is that many people like to complain loudly about their pet peeves, but if you try to go into the specifics you will not find a dominant set at the intersection of complaints. One of the reasons I like C++ is because it seems to be the only language that is attempting a multi-decade, largely backwards-compatible evolution while adopting various modern language features over time. I don't buy into the idea that we need to redesign from scratch new languages each xx years, that seems like an awful waste of resources. It also smells suspiciously like the dreaded "hey let's rewrite this from scratch, this time it will surely be the right one and solve all our problems!" fallacy. I find the C++ evolutionary experiment much more bold and interesting than an eternal rewrite.
It will panic in debug builds but not release, I believe.
&gt; It's a slow horrible mess Maybe I should've said "If you enjoy C++, check out Scala"
It will still cause unexpected behavior :)
The exact rules are: * Overflow is a "program error", not UB * On said error, you are allowed to do one of two things: check for overflow and panic, or do two's compliment wrapping * When the `debug_assertions` flag is enabled (which it is by default in debug builds), it is required to check and panic. This means that, if the performance hit is less someday, we can require panic in non-`debug_assertions` builds as well, but until then, we don't have to.
The problems lie with library support (although it's getting better many major libraries only supported Python 2, and some are probably still that way), people just straight up refusing to learn the new version because the old one works fine, the maintainers having to expend effort at least keeping Python 2.8 up to date on security patches because it has so many users while they develop newer versions that they actually care about, etc.
It’s just standard performance for an application written in Java.
&gt; Although Box/Rc/Arc are not part of the core language (not quite sure why they should be either) Small note, Box is *technically* part of the language, for now, for Reasons. https://manishearth.github.io/blog/2017/01/10/rust-tidbits-box-is-special/ Eventually it won't be.
You might be looking for for r/cpp_questions
&gt;the move was largely a success, and definitely worth doing. It only caused a schism in the community that lasted for a decade and still hasn't been fully bridged, no big deal, right? This is speculation, but I would guess that a) there's way more C++ code out there than Python, and b) the average company that writes in C++ tends to be larger, slower moving (big ship, small rudder effect), and much more technologically conservative than the average company that writes in Python. If I'm correct, it would be even harder to drag the C++ community through a non-backwards compatible upgrade. If the Python 3 break was ugly (and it was), I would anticipate a C++ version of that being far worse. There's a good chance you would end up with two dialects and the communities would never re-merge.
currently it means ==11084== LEAK SUMMARY: ==11084== definitely lost: 8 bytes in 2 blocks 
Here, t2 = t1 will simply copy everything from t1 (there is only ptr to copy in this case). Since ptr is a pointer, the value it contains (and that has been copied) is a an adress to an int. t1 and t2 are two different instances of Test, containing two different pointers to the same int. 
This is incorrect - `as` never panics. Just arithmetic operators can panic.
If I were sure that they were all comfortable about talking about it, I'd have said more. Sorry for that. I'll try to make sure to give you a ping if one of them announces something. I know of mostly audio, so I may misinterpreted the sector you are in? In the FOSS space, GStreamer and VLC are heavily invested.
&gt; Constructors aren't removed. They're just not special enough to deserve their own name and syntax :P And all the other implications of them being implicitly in various contexts. &gt; Default constructors are still a thing though, which Rust has. Not really. You can explicitly implement the default trait, but even it will not be implicitly invoked, you still have to call `Default::default()` explicitly.
Vendor lock-in is also a big factor in some industries... eg. for a new game console it's easier and less risky to provide a toolset for C++ than any other language.
&gt; The major point of my post was that an alternate dialect of C++ would be incredibly useful to the thousands of projects (like those I work on) that depend on the C++ ecosystem and have tonnes of legacy code, but would like to start writing new code in a compatible That doesn't seem to be the case of your comments, unless you meant that "++C" would be a subset/over-check on the existing C++ aka a subset of C++? That didn't seem to be what you were hinting at, but would make sense. 
C++ is, out of necessity, adding them in a tacked-on fashion rather than having them fit directly into the language. Just one example, std::string_view and Rust's 'str' are conceptually very similar, but Rust's type is fundamental to the language (its "base" string type), and has a rich library of operations that can be performed on it. Whereas C++'s version is only sort of interoperable with the rest of the language and really only has a handful of operations available.
If they would update their [daily toolset release](https://visualcpp.myget.org/feed/dailymsvc/package/nuget/VisualCppTools.Community.Daily.VS2017Layout) (\*cough\* /u/AndrewPardoe \*cough\*), that's incredibly easy to use and doesn't technically require an existing VS installation to use (nuget packages are just zip files).
if Im correct it prints 0
Considering that one of Linus's gripes with C++ is hidden function invocation, I don't see why that would be a problem. Might not be as comfy as C++, but it's a whole lot clearer to know when each function is being called 🤔
&gt; which usually means optimizing for power consumption in practice Which usually means optimizing for speed, in practice.
I'm not saying it's a problem, I'm saying stating Rust "has constructors" in a discussion about C++ implies things which Rust's not-actually-constructors don't even remotely do. Hence my statement that Rust doesn't have constructors, fundamentally it only goes further than C in the sense that it has (trait) functions which can be generic in their return type, but that aside it only has "constructors" in the sense that you can build structs inside functions, have those functions returns the built struct, and call that function a constructor.
Subset isn't exactly accurate, since some things would be kept but work differently. The important part is that all the concepts are directly translatable to C++. Rust couldn't be made an alternate front end for C++, because some core implementation concepts differ in incompatible ways. ++C would be a different way of expressing a subset of C++. I guess maybe you could say it would be "cleanly transpilable" to C++. So, for example, ++C could adopt Nim's `const`, `let` and `var` style of declarations, because those would cleanly translate to C++'s `constexpr`, `const` and normal declarations. Similarly, methods could be made const by default, with a `mut` keyword for methods that modify. That concept maps perfectly cleanly to C++ as it's just an inversion of the defaults.
I figured, I work in audio myself (not a secret from my post history) but I'm interested if some of the big multimedia tool companies (Adobe, Avid, Apple, etc) have begun investing in Rust yet. But I know how secretive everyone is. What I meant was tools used by professionals for making multimedia content. There are some gaping holes in that space today, and imho the reason we haven't filled them yet is due to technical debt with our old software (DAWs are a good example). The industry is begging for some disruption, and Rust is the perfect candidate to build the foundation of tomorrow's media software. But that tomorrow is probably years away. 
I think LLVM can be used to compile to PS4 and similar, as more and more they use the same architecture than widespread devices. If the SDK is only available in C++, though, that's an immediate hurdle for whoever seeks to use another language.
Crates is key
It should print 10. After implementing a proper copy-assignment operator it should print 5.
&gt; I'd say that D's external linkage to C++ is more directly useful than Nim's transpiling Unfortunately D doesn't work well with templates: it requires that template methods be instantiated explicitly on the C++ side. So any time you edit your D code, you need to edit your C++ code in parallel... and it also means that you *need* cross-language LTO to have any semblance of performance. Nim, on the other hand, provides a smooth experience. You can use `std::vector&lt;YourNimType&gt;` and it just works.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt;Wow. How could I say something like this. 0 is not even in options :D
I would note that preventing low-level data-races does not mean that it prevents you from accidentally assuming something did not change between two accesses (a higher-level data-race) and other kinds of races. It's really the bare minimum for memory safety (which is great), but still leaves quite a lot of room for logical errors :)
&gt; I predict in 2020 a majority of new embedded projects targeting systems with RAM between 1MB and 10MB will choose C++. Since the parent comment was talking about Rust, I'm curious as to why you believe that C++ is significantly better than Rust in term of memory footprint.
I don't. IEEE Spectrum ranked C and C++ as the most popular for embedded in 2016. I don't see that changing significantly in 2020. I hedged my bets on C++ for small memory, ceding to C (and Rust), and for large memory, ceding to JVM (and Rust). Nothing to do with language capabilities of course, just momentum from developer training and available libraries. 
Writing shared libraries in C++ is a total minefield. Don't do it unless you really, really have to. My experience with it: - random crashes with Boost.ASIO due to distro-supplied dynlibs being compiled with different options from my code - A program compiled with clang failing to start when it tries to load a dynlib compiled with gcc. Compiling the program with gcc makes very work fine (at least it seems so) - Is your meyers singleton really a singleton? I believe the C++ standard defines the behaviour of monolithic executable, nothing else.
&gt; First Rust have to catch up to C++, it will take some years. Actually, it's not that one-sided. C++ is still trying to catch up to Rust in a number of areas; at the very least: - modules, - concepts, - coroutines, - compile-time checked move semantics, - compile-time checked memory safety. Concepts are in the C++20 draft, but modules and coroutines are still out. Due to backward compatibility altering the move semantics seems hard and improved memory safety seems nigh impossible. Now, contrast with Rust: - non-type template parameters are on the way, with initial implementations scheduled by the end of the year (2018), - const fn are powered by MIRI, which simply can interpret *any* Rust code, it's just a matter of policy to extend support and it's dribbling in with a few features every release (6 weeks), - template specialization is in the works, and you can check it out on the nightly channel (still a few kinks to iron out, but it seems realistic to aim for end of the year), - template template parameters is designed (ATC: Associated Type Constructor, think `std::allocator::rebind`), unsure of the date, so conservatively sometimes in 2019, - variadic templates are perhaps the big missing piece... but with built-in tuple support I've yet to miss them. When I look at C++ and Rust in 2020, one seems much better off than the other.
Were you thinking about something like [Nannou](https://www.reddit.com/r/rust/comments/8tuiyh/nannou_an_open_source_creative_coding_framework/)?
Can't disagree with any of that. 
Sure, if you're a) compiling your Nim to C or C++, b) including the generated headers, and c) invoking (and paying for) the Nim runtime in your process. And that's not the useful direction. The other direction looks rather more hairy, especially if your target isn't C++.
C++ is simply a nice inbetween of C and C#. Go C++ and you never go back! 
I've paged /u/AndrewPardoe by mail, posted on slack, but never got any reply. Too bad ...
&gt; Nothing to do with language capabilities of course, just momentum from developer training and available libraries. Ah, I see! I've seen so many "Rust binaries are bloated" (aka, static linking + full `std` included) that I was afraid it was another such hurtful first experience :)
If I remember correctly, GetLastError returns the last error, then clears the error. If you are not interested in the detailed description, you should still call it, so other users of WinAPI functions don't get to see your error. Otherwise they have to call GetLastError before calling any WinAPI function to get the correct error descriptions. 
Or "&lt;=&gt;!". Then we can run around yelling SPACESHIP!
&gt;Then you need early adopters (I mean production-ready projects from more brave teams). You mean like [these](https://www.rust-lang.org/en-US/friends.html)? Some of the most well known from that list: Canonical, Wink, Mozilla, Atlassian, npm, DropBox, Chef, and Samsung SmartThings. And not on that list, but Microsoft just recently [announced](https://twitter.com/maxgortman/status/1012011425353461760) that they're using Rust in the security-related bits of Azure IoT Edge.
It's not a C-like language. I believe, in general, people want a 'better C++', not an altogether-new language with new syntax and rules. There are plenty of those (with differing levels of capability). It isn't a C++-replacement, but rather a C++-alternative.
You mean that it would slow down visual studio due to less cache efficiency? I'm certainly not expecting that a change would significantly improve the speed, but I'm also not believing the inverse until I see hard numbers (or at least representative. However, this isn't just a performance problem that might or might not get solved, but a usability problem and thus I have very little understanding for why Visual Studio seems to be the only major IDE that refuses to switch to 64 bit (unfortunately, Microsoft is/was generally very slow in that regard)
&gt; You mean that it would slow down visual studio due to less cache efficiency? More that it would nearly double the memory usage of the process. Details are on Rico Mariani's blog, though they're likely outdated by now.
MSVC's STL has supported Clang/LLVM since 4.0.
Andrew left Microsoft.
There will be a blog released sometime next week with a few examples of the breaking changes in the preprocessor.
I'd like more. MCUs are very limited in that regard. Even Cortex M MCUs are RAM-constrained. I want a Cortex-M board that has like 4 GiB of RAM.
&gt; C++ uses SIMD everywhere where it make a difference, and SIMD was stabilized in Rust only a couple of days ago, so the Rust entries don't use SIMD yet. There is an entry that does that (Rust#5), I wrote it yesterday and it was merged today: https://benchmarksgame-team.pages.debian.net/benchmarksgame/program/nbody-rust-5.html But with 20.24 seconds vs 13.12 seconds it is for some reason not faster than the original (non-SIMD) one, however the non-SIMD one has unrolled loops, which might be a contributing factor. I am still trying to figure out why it's so muchs slower, because on my machine Rust#5 is consistently faster than Rust#2 - but maybe I'm not benchmarking correctly. Or maybe it's cache misses (the C++ version throws everything into one chunk of memory, while the Rust version has seperate objects, but in theory this shouldn't matter). All I wanted to say: surprisingly just "throwing SIMD at it" doesn't solve all problems if the program isn't optimized for SIMD in the first place. And achieving that is really hard.
&gt; python 3.6 while we're dumping Hot Takes about programming languages, enjoy your syntactically significant whitespace, i guess
I would like to add two things to the missing-in-c++ list: - Standard build system (cargo) - Standard package/dependency management system (crates.io)
That looks really cool, thanks for the link!
Indeed, this is the only reason I know of
Not too sure. I suspect it will be a few weeks before an update is available here: https://www.microsoft.com/en-us/software-download/windowsinsiderpreviewSDK
Oh. Well any chance you can ping his replacement and let them know about the nuget packages? They **finally** got integrated into Compiler Explorer (VS2017RTM was all that was available previously), and now the daily packages are stale. :-[
&gt;They've failed at making a simpler C++, they've failed at making a faster C++ (we NEED this), and they've failed at making a faster compiling C++. I can't speak for others, but I don't use Rust because it's *faster* than C++. I use it because it *crashes* less than C++, because when it compiles, there's a good chance it actually works. If you're working on truly time-critical software, go ahead and use C++. It gives you every tool you need to get every ounce of performance out of it. I agree that I don't see that use case going away anytime soon, and it has decades of momentum behind it. But for all the cases where we just need *similar* or same order-of-magnitude performance, I think Rust is a great fit for better software. Consider Firefox: Rust code makes the browser code safer and more secure, possibly the most important property of a modern browser. The latest versions of Firefox with the new CSS engine are at least competitive in speed, so even if it's not strictly better it's good enough. &gt;A C++ fork that breaks backwards compatibility will pretty much instantly destroy Rust. If it breaks compatibility, I think there has to be a sufficiently strong reason to rewrite your code. I think D is a good example of this: it had stupidly fast compilation, good metaprogramming, C interop, and even native C++ link capabilities. But my opinion is that D never got the adoption Rust did because it didn't have a killer feature that would offset the time lost from rewriting C or C++ code.
&gt; the combination of sheer mass of C++ code, and available libraries, This is true only in part I'd say. It is definitely true when it comes to larger stuff such as GUI toolkits, game frameworks, various SDKs, etc. However, when it comes to mid-sized to smaller everyday libraries, such as parsers for various formats or various other utilities, avilability of good C++ libraries is surprisingly bad and those in Rust is surprisingly good considering the age and adoption of both languages, plus it also needs to be considered how easy it is to use &amp; manage dependencies in Rust versus what a freaking nightmare it is in C++. 
&gt; You should show this off using godbolt.org so that the results can be pinned down better. godbolt only shows the content of object files, not of shared libraries
Just for completeness, one can enable panics on release builds using `-C overflow-checks=on` or by enabling `debug_assertions`. It just isn't the default behavior.
&gt; Cross compile or even just BSD support seems lacking and does not inspire confidence. For what is worth, FreeBSD, OpenBSD and DragonflyBSD are tier 2, which means that we test that cross-compiling Rust to those platforms works correctly. For Tier 2 we don't run the whole Rust run-time test suite, but we do run some parts of it (e.g. `libc`, `stdsimd`, `jemalloc`). Also, clang/LLVM is the default compiler of many BSD distributions, so if there is a BSD distro currently not having a default Rust target, you can probably still just cross compile to it by defining the target yourself (e.g. using `xargo`).
To be fair, Rust traits are "concepts" + "concept maps" + "virtual concepts" + "existential types". C++ is getting Concepts Lite in C++20, but concepts map were dropped from C++0x because they were too complicated, and virtual concepts has a draft but a paper was never submitted. C++ does have existential types already (kind of: `auto foo() { return []{}; }`), but it does not have a way to make that interact with concepts.
It can be done, as companies are using Rust on PS4, but without official support it takes a huge level of commitment from an organization to do all of the groundwork necessary.
&gt; What is needed is a way to describe runtime linking of C++ objects and exporting from libraries within the language. well, yes, but I'd like to see a solution before I have grandkids - if there was a paper in 2007 which did not go anywhere, I don't see what could make it work today. 
You're not wrong. But it doesn't necessarily have to match rust to win. Rust is fighting a seriously uphill battle and they will need a seriously compelling case to beat out C++ for even many brand new projects. Like it or not, C++ doesn't have to be better, it only has to be good enough.
Clang has different modes to be compatible with both gcc and msvc.
Anyways, I thought that Ranges in C++ will be somewhat similar to what Rust does. Is it correct or will it be something else? I encountered problems in the current C++ even with such simple things as filter and then map (IIRC no straightforward way).
yes but its msvc compat is only available on windows, right ? On windows even GCC supports `__declspec(dllexport)`
&gt; those companies and communities around the world aren't moving to future standards, or even compilers All big companies I worked at not only updated their toolchains meticulously, but actively participated in development or beta testing of all compilers they used. Because the more code you have, the costlier it is to fall behind. &gt; Current compiler is already setup up and has whatever workarounds and non standard behavior depended on. That's a business doomed to die, unless it's small enough to drop everything and update when (not "if") the circumstances force it.
I believe so, but my interest is just saying what rust does, not suggesting it’s better than C++. As far as I know, they should be equivalent in this regard. The closure stuff already is.
What is the problem? You don't want to make a 10 line macro? You could have done it in the time it took to write these comments. 
find on a multimap will only return the first match as documented here [multimap find](http://www.cplusplus.com/reference/map/multimap/find/). &gt; Notice that this function returns an iterator to a single element (of the possibly multiple elements with equivalent keys). To obtain the entire range of equivalent elements, see multimap::equal_range. pair&lt;const_iterator,const_iterator&gt; equal_range (const key_type&amp; k) const; pair&lt;iterator,iterator&gt; equal_range (const key_type&amp; k); For your case use it like below std::pair&lt;std::multimap&lt;int,int&gt;::iterator, std::multimap&lt;int,int&gt;::iterator&gt; rangeItr; rangeItr = x.equal_range(0); // Replace 0 with KEY for (auto it = rangeItr.first; it != rangeItr.second; ++it) { std::cout &lt;&lt; (*it).first &lt;&lt; ":" &lt;&lt; (*it).second &lt;&lt; std::endl; } 
In that case, I don't quite understand what that previous commenter meant by "I hope something like this would be trivially possible with ranges eventually, but it doesn't seem to be the case for the current proposal."
I'll ask around.
How about something like this? `#define STR(x) #x` `constexpr bool CheckDefImpl(const char* value, const char* expected) {` `int i = 0;` `for (; value[i] != '\0' &amp;&amp; expected[i] != '\0'; ++i) {` `if (value[i] != expected[i]) return false;` `}` `return value[i] == expected[i];` `}` `#define CHECK_DEF(value, expected) CheckDefImpl(STR(value), expected)` `#define MATCH abc` `#define NO_MATCH def` `static_assert(CHECK_DEF(MATCH, "abc"));` `static_assert(!CHECK_DEF(NO_MATCH, "abc"));` And this way you don't have to do a test from the build system like suggested in the forum
&gt; You could have done it in the time it took to write these comments. yeah, the macro took 15 second to write. It's using it in the 500kloc codebase with 25 different shared libraries each with their own export macro that takes time.
If you are returning the struct (or vector of those) to the user, it only makes sense to make the struct public.
Yes, sorry. I've run off to graze in bluer pastures. I expected that my Microsoft email would bounce, but it appears that it just goes into a black hole somewhere. I also am not doing much with C++ anymore so I haven't paid attention to the Slack channels. 
FWIW, I put together a document and shared it with Mark and Daniel (dev lead, not PM lead.) And I still have all the passwords in my password manager in case they've been lost.
&gt; you can't it with a newer clang for example You can't it what? Accidentally 93MLOK of C++ code? QtC updates it regularly to the latest stable version so it lags behind for a few months at most. Also, I think they were talking about adding clangd support.
&gt; They've failed at making a simpler C++ Rust is vastly simpler to use correctly than C++.
https://www.reddit.com/r/cpp/comments/88nlpv/whos_hiring_c_devs_q2_2018/ and many other places. It's not that hard, but definitely not the easiest out there.
Writing libraries it usually result in the following setup for me: * one C export function returning a boxed void pointer * some template for returning a proper ABI interface from the void pointer * only primitive data types or self defined structs Any non primitive type makes problems (e.g std::string and so on), especially on Windows. The compiler output and the cpp libraries are somewhat compatible in Linux environments, but on Windows they change with every version (at least name mangling). 
I'll bite. * Eliminate header files. * Assignment is always a move operation. Deprecate std::move, change std::copy to copy a value, not a range. * Pare down the STL containers to `std::list`, `std::vector`, and `std::map`. * Incorporate the concept of public/private to exported symbols from a source file to the linker * Define a calling convention as part of the standard. 
Thank you. 
Yes I want general knowledge on all computer systems in order to have a wider view of the field than just that a programmer sees.
Thanks guys. 
The main reason D failed was the mandatory GC. Many people at low layers of the stack consider it unacceptable (whether it makes sense or not).
Well, you could return a reference to the vector, even if `S` is private. When something is private in C++, only its name is private. A user could access members of the private struct with no problem, and `auto` will take care of the name.
That only works if the thing you want to switch on is something you can do in the compiler rather than the preprocessor, so it's not as fully general. I'd guess that if you want to do this in the first place, it's reasonably likely to *not* be possible.
Did he mention [Boost PolyCollection](https://www.boost.org/doc/libs/1_67_0/doc/html/poly_collection.html) [??](https://github.com/Ebenezer-group/onwards/tree/master/poly) He mentioned several Boost libs and other libs, but I didn't hear anything about PolyCollection.
&gt; Well, you could return a reference to the vector And to OP, I'd strongly encourage a *const* reference if that's not on your radar.
I see. Do check out the book. It will definitely help you. 
Great.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8un2oi/newbie_question_on_struct_in_class/e1gqlrp/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8umq75/is_it_possible_to_find_if_a_specific_unique_pair/e1gqmdi/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Use the undocumented compiler option `/P /d1PP` to preserve macro definitions.
I have waited for the day where I can say "I code daily in spaceship" and their minds will insert an **a** between _in_ and _spaceship_, further adding to the coolness. 
&gt; Use the undocumented compiler option /P /d1PP to preserve macro definitions. Oh boy, could we get some more compiler switch documentation on those things then? ;) Although I guess I could always troll through the compiler itsself and dump all the strings to find them...
There are a few ways to do filter then map in a straightforward way. `copy_if` or `partition` for filtering. Then with the resulting iterator range, either a `for_each` or a `transform`. You can also easily implement it with lambdas, without having to wait for the language. Although, nothing wrong with a simple range-for with a conditional. I love those functional styles of things as much as the next functional programmer, but sometimes a simple loop will do.
True, but you shouldn't do static initialization and rely on the order of other object being initialized first
It's also a talk for people who aren't currently using C++ or familiar with how the language has been changing.
Unless it significantly impacts performance (thats why I mentined cache efficiency) I don't really care if the process needs a few more GBs (my workstation has more than enough of it) if that means that I have les OOM problems. 
Thats just CMake with extra steps.
undocumented usually also means unsupported and or/unstable
&gt; All big companies I worked at glad to hear personal anecdotes equal worldwide industry standards. /s. Lucky you, but sadly the rest of us dont always get to work on modern toolchains. &gt; but actively participated in development or beta testing of all compilers they used. In that case they won't be caught unawares by any breaking changes and will have plenty of time to both comment on how it affects them, the best way to *minimize* breakage, possible alternatives, and plenty of time to migrate if a breaking change is the best way to do it! &gt; That's a business doomed to die, In your anecdotal dreamland, sure. Plenty of businesses make and support software for legacy systems, which won't *ever* upgrade, even if they were capable of it(which they may not be) Embedded is one area that often has lacking compilers and standard conformance, for example. I guess all embedded devices are doomed to die?
I simply downloaded the 64-bit for Windows (MSVC) that BurntSushi provided. My programs were compiled with /Ox (maximum optimization) also with MSVC. I tested two programs built with the parser (that can be built using the CMakeList) csv_info and csv_stat. The first program counts the number of records in a file while the second computes statistics such as data types (although the program currently doesn't print them out), mean, variance, etc. These programs have direct counterparts in the commands `xsv count` and `xsv stat`. The two test files I used were: * worldcitiespop.txt (147MB, https://www.maxmind.com/en/free-world-cities-database) * cc-est2017-alldata.csv (143MB, https://www.census.gov/data/datasets/2017/demo/popest/counties-detail.html) I measured the speed of the commands by using Measure-Command in Window's PowerShell. For fun I've also added benchmarks for a simple Python (3.6) script that simply counts each row in the CSV that it readds. ## Results (in seconds) File | Python | xsv count | csv_info | xsv stat | csv_stats --------------------------| --- |---|----|----|---- worldcitiespop.txt | 4.7 | 0.6 | 3.8 | 8.2 | 5.9 cc-est2017-alldata.csv | 4.7 | 1.7 | 3.8 | 17.8 | 7.25 I think these results show that xsv definitely has the faster parser, although something weird is happening when it calculates statistics. I haven't read through the source code carefully nor do I know a lot about Rust, so all I can do is guess. Based on that fact that this (https://github.com/BurntSushi/rust-stats) is a dependency, it seems like his statistics calculations are also multi-threaded like mine. Personally, I was able to get a massive performance increase (2-3x) in my own statistics calculations by replacing std::stold with a custom written function. I was pretty shocked that something I wrote could outperform a standard library function by that magnitude. Perhaps something unexpected is behind the performance differences here as well.
Also, nearly double sounds like a gross overstatement.
another approach is to use virtual classes. if(dynamic_cast&lt;HealthProtocol&gt;(character)) { HealthRenderer renderer(character); renderer.render_or_whatever(); } Or you can even simpler move the dynamic_cast into the HealthRenderer and overload the bool operator. So you can do if(HealthRenderer renderer(character); renderer) { renderer.render_or_whatever(); } The next part of the talk he talks about having a different AI for the character. A common pattern for this is called a Strategy pattern. character-&gt;setAiStrategy(someAiStrategy). And internally the character will call the someAiStrategy to ask what to do. I'm just giving more options to what he provided. everything have their own advantages and disadvantages.
[Go's not that fast though](https://news.ycombinator.com/item?id=9454142), and [not because of GC either](https://www.reddit.com/r/golang/comments/6ypwui/go_does_not_inline_functions_when_it_should/dmpbefb/). Their high premium on compiler turn around time means they're not even in the same ballpark as LLVM. Which is fine; if you're using it the same way Google does, then you care more about context switching time than whether some math kernel got vectorized. Also, if you're talking to a separate language with a GC (like C# in Unity or JavaScript in Servo), then you don't want to have to make two garbage collectors play nice. Servo's GC integration is already complex as hell; it would be worse in Go.
D has support for variadic templates, non-type template parameters, and since pretty much any symbol can be a template parameter, you can have template templates (unless I'm overlooking something). Unfortunately, no affine types.
Rust is vastly simpler ~~to use correctly~~ than C++. Yes, really. [Rust doesn't have to backtrack when a parse fails so that it can try a second template instantiation.](https://en.wikipedia.org/wiki/Substitution_failure_is_not_an_error) In fact, it can parse and type check its "templates" before it instantiates them. [Rust doesn't have an undecidable grammar.](http://blog.reverberate.org/2013/08/parsing-c-is-literally-undecidable.html). Probably the worst parse is in match arms, where it has to check if a constant exists, and, if it doesn't, make it a variable declaration instead; but that's closer to The Lexer Hack than the Most Vexing Parse. [Rust doesn't run library code before calling main.](https://isocpp.org/wiki/faq/ctors#static-init-order) [And there are way, way more](http://yosefk.com/c++fqa/) flaws in C++ that Rust just doesn't have because there's no reason to put them in there. 
Hey! What's wrong with this question? I am discussing a C++ fundamental problem. Of course, any questions need the answers are likely to be "help" posts. If you want to monitor the subreddit precisely, please be thoughtful! Thanks!
Usually it's stable enough (or else they would simply remove it entirely), but it is likely to change what it does or disappear in the future, so you shouldn't depend on it. Matlab is for example full of undocumented features that you need if you want performance (like changing an array in place with external code).
&gt; Maybe all passing conventions should be explicit... I actually thought about suggesting that but then I figured you're still going to be relying on custom copy constructors so I didn't really see how it'd improve C++ for me in particular, though I guess I'm just comfortable with that convention. &gt; C++ default is copy by value, unless the copy constructor does something else. _bad._ I'm not sure this is terrible... imo it's the least complicated (and easiest to understand) thing you could do by default. The negative implications of doing it when you shouldn't are reasonably easy to understand, but then again there's not really much helping you choose to do the right thing. I suppose even given the _potential_ for abuse/lies/mistakes in custom constructors I still wouldn't mind being explicit about it in parameter definitions somehow, sometimes.
Didn't watch the video, but my answer is, Because we aren't dead.... yet. :)
That's already a thing.
This subreddit is not intended for newbie questions, please read the sidebar. /r/cpp_questions or StackOverflow are more appropriate.
Wow, downvotes. Very mature. I'm writing Rust in production. I've written dozens of concurrency frameworks in C++, including contention-free allocators, fiber-like task/numa-node processing for high performance services, and distributed (R)DMA coherency management. I'm not dissing Rust because I'm some fanboy. This is a real flaw in the standard concurrency primitives (RwLock, Mutex) compared to their C++ counterparts... and, yes, I'm working on "doing something about it".
Nope, GetLastError() does not clear errors. If you call it twice, you will get the same error code even if it is non-zero. It's not an atomic get+clear like glGetError(). You have to call SetLastError(0) to clear it. That's almost never needed because nearly all WinAPI functions return a success/failure flag directly and only set last error on failure. This also replaces any previous error code so that leaving an old error code is not a problem, it'll get overwritten by any later failures. 
Alright! I'll certainly rectify the code for the first point. Could you elaborate on where and when to use the `const`s? Should we use it *whenever* we know the value can't and won't change? I'll look into raw string literals, thanks for that! :) 
Can you elaborate on the issue? I'm not sure I understand, and I'd like to.
Converting existing vcxproj to Cmake? Please show me
Essentially, because the only way to acquire a lock in Rust is the operation that simultaneously gets the lock and borrows the protected resource, you're left with no way to perform a consistently ordered acquisition of multiple locks. Not only no built-in of this: https://en.cppreference.com/w/cpp/thread/lock, but even with a convoluted macro with allocation of a mutable Vec, sorting in an unsafe context, iterating, and capturing to a tuple, you're still left with a solution that sort of works in the most common case and is rather painful ergonomically. Obviously, if you can avoid ever having to acquire multiple protected resources with undermined order of precedence in the same scope, this isn't an issue... but neither are deadlocks.
&gt; I simply downloaded the 64-bit for Windows (MSVC) that BurntSushi provided. The Rust compiler defaults to a very minimal baseline x64 target that disables SIMD among other things; if you want actual apples-to-apples, you'll have to build it with `-target-cpu` set (moral equivalent to `-march`) so that you get vectorization. If you want I can build a copy if you let me know your microarchitecture, but installing the Rust build tools is extremely painless, too... &gt; My programs were compiled with /Ox (maximum optimization) Just FYI, [`/Ox` is a subset of `/O2`](https://docs.microsoft.com/en-us/cpp/build/reference/ox-full-optimization), not a superset; for full optimizations, use the latter. &gt; also with MSVC FWIW xsv isn't built with MSVC at all, just targeting the MSVC ABI (it may use MSVC's linker, but that isn't necessary with recent LLD).
https://www.reddit.com/r/cpp/comments/7639sf/what_would_you_change_in_c_if_backwards/
I'll chat to Mark and Daniel in the morning - Chris asked me to pick this up.
I guess things are getting reinvented, over and over (not a bad thing), as requirements and approaches keep changes. To further explore this topic, I highly recommend the https://www.amazon.com/Art-Metaobject-Protocol-Gregor-Kiczales/dp/0262610744 which goes further and presents a language (a meta language) to implement a concrete OOP system (in this case CLOS, the standard Common Lisp OO system). Another topic related to the talk is AOP (Aspect Oriented Programming), which simply explained is: Install a hook, which gets called (say before, after, or around) when this message (or function call) gets called, and matches: "print*" - these hooks gets installed as part of the application, system, etc. - with the goal of not directly modifying the existing system, but letting subsequent "changes" from outside. I guess you won't get the best performance out of it, but allows one to tweak/customize business needs. In a way - monkey patching.... Or another form of OOP through cloning objects, and adding/removing methods as see fit (like Javascript/Lua, others) But for C++ :) Thanks for the video!
 Niche trick, but I fear this will break under maintenance.
How can I get it to work? When I try this: struct Foo { int a; }; std::vector&lt;Foo&gt; v; std::find_if(v.begin(), v.end(), [](auto&amp; elem) { elem. }); I get no completions at the dot and IS tells me the type of elem is `auto&amp;`.
VS Code ([https://code.visualstudio.com/](https://code.visualstudio.com/)) has a bunch of key mappings that you may find more familiar: [https://marketplace.visualstudio.com/search?term=keymap&amp;target=VSCode&amp;category=All&amp;#37;20categories&amp;sortBy=Relevance](https://marketplace.visualstudio.com/search?term=keymap&amp;target=VSCode&amp;category=All%20categories&amp;sortBy=Relevance) \- of it doesn't have a mapping you are familiar with it will allow you to customize the mapping manually. While it doesn't currently have an extension to directly parse `vcxproj` files, it does have tasks to kick off the msbuild command line invocation and debug the output, so the only thing you'll have to deal with is either running VS to update the project files or editing them by hand.
Compiler Explorer supports Rust too, and someone is working on Pony support
I didn't even notice the comma until I read the explanation below the code. Without a comment eventually someone would surely "fix" this and replace the comma with a semicolon.
If you are on VS 15.4 and later (sorry I didn't manage to get the changes into 15.3) you should be able to import the props file from &lt;unpacked package root&gt;\\build\\native directory and it will set up the build to use the compiler and libs from the package. If you use the Nuget Package manager in the IDE to install the package it will do that for you.
I have a piece of code here that calculates a few hundred million values and writes them to files. Imagine my surprise when I found out that the bottleneck was not the database retrieval, not the calculation, not the file writing, but the conversion of the final result to text! Moral of this story: that improved to_char is totally welcome. Uhm, I need the one where I can specify precision, please ;-) 
This can be made even nicer when you can use gcc/clang extensions. Statement expressions are pure beauty. https://godbolt.org/g/2eEtfU
&gt; Could you elaborate on where and when to use the consts? For variables - always, whenever possible, this includes situations such as const int val = get_something(); return compute(val); for member functions - when it makes sense as the operation is designed to not modify the object state class foo { public: const std::string&amp; get_name() const { return name; } private: std::string name; } All getters should be const. If they are not const, they are not true getters. const foo f("text"); f.get_name(); // error if getter not const Also, don't make the mistake of const illusion: T&amp; get_t() const; // this is wrong - it creates an illusion of const, instead, there should be 2 overloads: const T&amp; get_t() const; T&amp; get_t(); This is what all containers do with their `operator[]` overloads - 2 versions, each consistent with constness of itself and return type. `std::optional` is even more precise in this regard due to it's intended use: constexpr T&amp; optional&lt;T&gt;::value() &amp;; constexpr const T&amp; optional&lt;T&gt;::value() const &amp;; constexpr T&amp;&amp; optional&lt;T&gt;::value() &amp;&amp;; constexpr const T&amp;&amp; optional&lt;T&gt;::value() const &amp;&amp;;
I might be missing something but what makes this preferable to using std::variant?
You don't even need the mutex. The first async returns a future and futures created by async block on destruction. The first async line will block until its lambda is executed! That's a bug ;-)
The applied formula to compute the array sum by Clang? https://godbolt.org/g/vSRi2A
https://godbolt.org/g/CvjJdh
For precision I expect to be able to do a little better than the CRT, although not too much (40% again would be astounding). Do you really need exact precision? It matters for things like large, exactly-representable whole numbers. Otherwise, shortest round-trip preserves all of the information that’s there.
There's not much branching in the original source to begin with. Anyway, you can change the ints to floating point types to see even better transformations.
https://godbolt.org/g/TcK2NG
The most impressive I remember is Gor Nishanov's presentation on coroutine allocations being optimized away by his implementation. And I also recall Bryce Lelbach had a similar presentation using coroutines to implement multi-dimensional array iterators which also generated better output than conventional iteration.
This is really cool. Took me a little to realize what's going on. The function is supposed to calculate the sum of all integers from 0 up to (but not including) N. The clang code calculates (N - 1) * (N - 2) / 2 + N - 1 which simplifies to (N - 1) * N / 2, the correct result. (And checks for N to be greater than 1). So, we can state that the compiler is now as smart as the 9-year old (Carl Friedrich Gauss)[https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss]: The teacher of Gauss wanted the class to be busy for a while and told them to sum all integers from 1 to 100. Young Carl Friedrich had the following brilliant idea: The sum of 1 and 100 is 101, the sum of 2 and 99 is also 101, and so on. There are 50 of those pairs, i.e. the sum is 50 * 101 = 5050, or more general N * (N + 1) / 2.
I remember Matt Godbolt's CppCon talk "What has my compiler done for me lately" shows even more than the sum example.
clang and GCC in C++ 17 mode optimises away memory allocations if the compiler can prove they cannot "leak" outside of its view. This goes for `const std::string`, or anything similarly not modified, you'll see strings converted into `const char *` in the output and no memory allocation done at all. That's a consequence of the glvalues addition to the C++ 17 standard. I'm not saying it's not impressive, but it's also not transformation of many branches into branchfree as the question asked for, if you see what I mean.
Heh, that's clever. Surprised GCC didn't get it too.
That's more constant input folding surely?
Sure, but I only mentioned the allocations as an aside. I was more impressed that apparently the coroutine yields and resumes could also be optimized away to a great extent.
I don't quite get this. A variant holds a single value from one of several possible types. A \`dynamix::object\` holds multiple mixins (components). It's entirely different
Which optimization is this? I tried it with having the sum not starting at 0, but at a parameter N1 and going to another parameter N1. Clang is still able to calculate the (I suppose) correct result without a loop. You can even sum the squares of integers, like this: https://godbolt.org/g/sQYypA Now, there is an interesting constant in the code, 1431655766.
I didn't. My bad. I definitely will in next instances of this talk if there are any. Basically PolyCollection is a way of accomplishing some of the features of the library. Namely multicasts arranging the data in a cache-friendly contiguous memory block. One of the main problems with it is that the members of the collection are not "aware" of the collection itself and thus inter-component polymorphism isn't possible. 
This is one from ARM's own website demonstrating the elimination of a branch in the core of a loop: https://godbolt.org/g/K5DgjM. Makes use of ARM's condition instructions. 
By the way there is an earlier version of this talk (which is very different save for the demo). It was never held in public. In it I explore classic alternatives in more depth. I had to drop it because there wasn't enough time for the other things I wanted to say, and too much time was spent on useless information. If you're interested, here it is: [https://www.youtube.com/watch?v=wROukSz20fQ](https://www.youtube.com/watch?v=wROukSz20fQ)
Well, it removes the if statement
I’d be tempted to use a macro rather than a comment here; something like `#define SEQUENCED_WITH ,`, or `#define SEQUENCED(a, b) a, b` (can be extended to arity &gt; 2 with PP hackery). Not sure this is a good idea though.
&gt; It is worth noting that Rust modules support the whole Rust language, including macros. Not currently the case with macros. This will change really soon in Rust 2018 edition to be released in 4 months, but for now macros are in a global namespace.
Welcome to modern C++
You could probably replace C++ with **{language of choice here}** and the above article would still hold. Why post this? It's too generic and is more suited for something like /r/programming
I *think* that might have been a reference to https://quoteinvestigator.com/2011/09/08/640k-enough/
Simplified summations. Your example can be reduced to [this](http://www.wolframalpha.com/input/?i=sum(a%5E2,+i,+k,+n)).
Thanks! But I think you meant this: http://www.wolframalpha.com/input/?i=sum(i%5E2,+i,+k,+n) Interestingly, I tried also the general form with the exponent as a parameter "j": http://www.wolframalpha.com/input/?i=sum(i%5Ej,+i,+k,+n) Then Wolfram alpha uses something called the Hurwitz Zeta Function, https://en.wikipedia.org/wiki/Hurwitz_zeta_function. This is probably what the clang optimizer uses, because I tried different exponents and it seemed to always be able to optimize the loop away.
A stupidly fast SECDEC ECC implementation I wrote many years ago popped into my head: https://godbolt.org/g/sCXCnM ECC calculators are painfully slow because you must process each bit at a time of the input, and for each set bit you must XOR in an item from a lookup table. That implies there is a test and branch for every single bit in the input, and that tends to not go fast. However, recent out of order CPUs can do many of those in parallel, so if you process the input in 8 byte chunks, you'll dispatch 3.5 opcodes/clock if I remember rightly. Indeed, GCC does generate lots of `cmov`'s, which stall on the result of the preceding bit test. Probably the fastest option, and still branch free. However, clang does something quite different: it transforms all the bit test and branches into a branch free integer arithmetic, which is very neat. Though undoubtedly slower, as far more instructions are dependent on their preceding instruction. Still, an excellent example of a compiler completely rewriting your code into something totally different from what you wrote.
Just to make sure we are talking about the same thing, I need this overload: std::to_chars_result to_chars(char* first, char* last, double value, std::chars_format fmt, int precision); Specifically with the formats for fixed and scientific. Is the version without precision much faster? If so, I can talk to the customer and see how they feel about always using that instead. 
Oh yea, I missed the squaring being dependent on `i`. That is pretty nuts though. Regarding the magic value, it's `0x55555556`, so I think it's probably some kind of bit trick.
so it's just recognizing a pattern and apply it just to show off or something?
It drives me crazy that the author doesn’t use the Oxford comma. When you have a list, don’t just forget to add the last comma: Oranges, apples, pears, and grapes. Not Oranges, apples, pears and grapes. As a programmer the author should know how important specificity is. There is ambiguity in the requirements for at least project #2 because of it.
What other languages would a project revolving around refactoring C++ templates be relevant? Not all of these are C++ specific but some are. All will help you get better at C++. /r/gatekeeping
The article looks like the author had one thing about C++ and decided to add on 6 other things, so in the end only 14% of the article is really C++ based. And for that 1 out of 7 topics, taking what you said: &gt; What other languages would a project revolving around refactoring C++ templates be relevant? [I found this language that uses templates by spending an excessive 2-3 seconds on google](https://dlang.org/spec/template.html) In short, if you consider that &lt;= 14% of an article has to be about C++ for it to be worth posting here, especially when /u/vormestrand spams this place with blog posts all the time... you and I have fundamental different definitions of spam.
&gt; It only caused a schism in the community that lasted for a decade and still hasn't been fully bridged, no big deal, right? If by community you mean people who are involved and interested in the language, and wanted to write good code, then no, there was no schism. If you take community to mean anyone who used a package sometime and wants it to stay the same forever, then I suppose you will always find those people. As it is, all major projects run on python 3, and nobody really thinks that's a bad thing. It just took a little time for things to transition naturally.
I was wondering why that constant is there. I noticed that when I change the code you provided from `for (int i = N1; i &lt; N2; ++i) {` to `for (int i = N1 + 1; i &lt; N2; ++i) {` the magic number is still there, but when I extend the non-plus-one line of code above to have the following under it `if (i == N1) continue;` It outputs different code and the magic constant is gone. Makes me wonder if there's something obvious I'm missing or if there's an optimization it is missing.
But wouldn’t the comma be replaced by AND given that they are all exceptions to the rule? So the exceptions are oranges and apples and pears and grapes. Otherwise he would have written oranges, apples, pears or grapes.
&gt; Edit: Don't forget the -march=haswell people, compilers will do lots of cool new stuff on a new enough CPU! Do Intel compilers and libraries still check for Geniune Intel and give you poor optimisations if they detect AMD?
There is a nexus of problems here. Package management, modules, and dynamic linking are all connected, at least in my mind. I'm hoping that modules will lead to package management, which will lead to dynamic linking. 
As I understand it yes, although I haven't verified personally. They have a disclaimer that Intel products perform optimisations for non-Intel CPUs, even if applicable, and that instruction sets count as optimisation. Or in other words - they don't use advanced instructions on non-Intel CPUs.
Hi, I implemented this thing. Limitations like what?
Recent Intel CPUs can retire 2 AVX adds per cycle, so ~8 doubles added per cycle. At 4GHz (Coffee Lake), that should be ~0.03125ns per double. But this is hitting the memory bandwidth wall fast.
We implement par_unseq as par, so if you see differences between those two it is noise in your measurement.
par is running at about 16GB/s; what's memory bandwidth look like on this test machine?
Everything this guy writes is about c++. I've been following his articles forever and have never seen anything that wasn't about c++. Maybe his context is just so c++ focused that he didn't really think of the context outside of c++.
&gt;It is a pseudo-B-tree Wait. Why are you calling it a vector?
You need to realize that you are being very trendy right now. 3 years ago no one used the oxford comma and now the lemmings like you are acting like only retards don't use it. It's a non-issue. Go find something important on which to take a stand.
When you are at that point, just write a regular function-template, which will remove the need for macros and overloaded commas entirely.
To be honest, I'm not really sure what the difference between the two is supposed to be. If the compiler can inline the function, it can auto-vectorize it (thus par becomes par_unseq), and it it can't, it can't vectorize it anyway (thus par_unseq becomes par).
This will be fixed for real with macros 2.0, but you're totally right that this is the situation today.
To show off? It's making the code faster, which is kind of the purpose of the optimizer. 
This has nothing to do with overloaded commas.
That's probably a limitation of optimization pass ordering. It would have to run a pass that splits loops based on branches that flip between always/never taken before it runs the pass that does summation substitution. IIRC, GCC has such a splitting pass, I don't recall if LLVM does or not, though.
It matters for GPU-like implementations with vector "lanes"; where a "thread" executing one branch can prevent another thread from ever making progress, like CUDA. We are a CPU targeting implementation, so we do not care.
&gt; Go find something important on which to take a stand. East const forever! &lt;/troll&gt; ;-)
It is mostly thanks to Scalar Evolution analysis. Also, the constant you see is to replace a division by a constant (multi cycle operation) into a multiplication by a constant (modular inverse) and a shift. This rely on 2's complement overflow behavior (which is well defined at assembly level). If you want to know more, you can run: opt -scalar-evolution -analyze On the bytecode you get with: clang -O1 -S -emit-llvm You will see the compiler predicting the value of the scalar accumulator for each iteration of the loop, and predicting the number of iteration of the loop, therefore computing the exit value.
They got in enough trouble for this that they are now required to link [their disclaimer page](https://software.intel.com/en-us/articles/optimization-notice#opt-en) on nearly every page of their developer website. Check the link at the bottom of [this article about C#.](https://software.intel.com/en-us/articles/code-sample-new-unity-entity-component-c-job-system-and-burst-compiler)
The B tree is an implementation detail. The interface it presents, to all intents and purposes, is that of a vector, with effective O(1) complexity for random access. In addition, there is `flex_vector` which also presents a vector-like interface, but with O(log n) insert/erase. 
&gt; The interface it presents, to all intents and purposes, is that of a vector One *could* argue that `std::vector`'s guarantee of contiguous storage is a vital part of the interface as well, and this won't provide that of course.
This may be the case, but it doesn't make it any less generic.
https://godbolt.org/g/7GbkN3 Note that this only works for this particular formulation of the loop. I tried writing it in a couple of different ways and the compiler could not reduce it.
I guess it depends on your definition of "support". I think this is a reference to the fact that C++ modules are blocked because there are multiple opinions on how macros should be dealt with, and no consensus. In this sense, Rust modules support macros. Maybe in a hacky way for now, but at least it has modules and macros.
&gt; avilability of good C++ libraries is surprisingly bad The lack of package manager (and repository) leads to a lack of discoverability here which is really annoying. Most libraries are just github repositories, poorly documented, and it's not always obvious whether (1) the functionality is correct, including edge cases, and (2) the performance is on-par. For all you know, it was just a week-end project for the author :(
I was just referring to the fact that you can't do all the combines in parallel, unlike something like map where it can hypothetically be done independently for every item of the iterator. I was referring to the inherent limitations of `reduce` as an algorithm, not any specific implentation of it.
So that it can be implemented using `memset()` when the value type is trivial. See Louis Dionne's proposal paper [here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0107r0.pdf).
I'm of the opposite opinion, I wish CppCoreGuidelines was more like PEP8 and like all other modern languages establish idiomatic formatting. It's frustrating that C++ programmers unlike other developers to such a high degree insist on inventing their own conventions. Just like the comment in the link says, formatting and naming conventions doesn't matter much, so please just stick to what the standard library and the language authors use.
That makes perfect sense, thanks! Can't `std::fill` be implemented that way too for trivial types? Any idea why that was okay to make `constexpr`?
Yes, the overloads that don't take `precision` are *ridiculously* faster. My profiling indicates 10x to 39x as fast, depending on platform bitness and float/double, when compared to using the least `precision` necessary for round-tripping (i.e. capturing enough decimal digits that you can recover all of the bits in a `float` or `double`). You will be able to request always-fixed, always-scientific, or switching between the two, for the non-precision form. In addition to being way faster, and often shorter (compared to always using the worst-case number of digits for round-tripping), the output is also the prettiest for humans while preserving the bits. I would say that the only reasons to use the precision overloads are (1) if you are dealing with an inflexible format that really requires exactly so many digits in fixed or scientific form (unlike strtod which will accept flexible input) or (2) you are formatting numbers for human display and you want to avoid emitting lots of digits, at the cost of losing information (e.g. displaying numbers as `0.333` instead of blasting out digits until you exhaust `double` precision).
Yes, it is. We're going to need compiler builtins for it (same rationale as constexpr char_traits). Which means that array::fill can be constexpr after all.
Yeah, but it's 99% embarrassingly parallel.
IIRC libc++ implemented constexpr std::fill by removing the specific overload that called std::memset because Clang's optimizer already performed the optimization.
&gt; Can't `std::fill` be implemented that way too for trivial types? Yes, and likewise for `std::copy()` and (the iterator version of) `std::move()`, which can be optimised to `memmove` in some situations. &gt; Any idea why that was okay to make `constexpr`? My *guess* would be that the library folks decided that either * `constexpr` support was more important, or * compiler implementors would give them constexpr callable versions of `__builtin_memmove()`and friends, or * core would approve `std::is_constant_evaluated()`, which would allow this optimisation to remain during runtime execution.
That seems like a pretty strange concern, given gcc does fold explicit loop as in OP to `memset()` starting from version 4.9 (which was released a year before the paper you link).
You briefly mention having objects consisting of both c++ and scripting mixins. Do you know if there are any readily available libraries to do that? 
It has more to do (sorta) with utf8 then `..A` version (which you may get if you use un-suffixed API. WinAPI kind of sucks.
I think I have a better understanding now. Thank you.
To my knowledge no. There is at least one proprietary one. It's not that hard to accomplish if you know the inner workings of the library. Exposing messages and objects to a scripting language is really easy. After all they are simply functions. The relatively tricky part is registering mixins from the scripting language. You would need to fill the \`mixin\_type\_info\`-s for them appropriately and the \`message\_infos\` inside. Actually creating some manual mixin registration functions is probably not a bad idea. It even exists in the roadmap, but I haven't prioritized it. Come to think of it though, it could make for a cool demo, so I'll try to find some time to make it.
Sorry, I wasn't clear and typed it wrong, I think you are an expert on this anyways as you wrote the MSVC implementation didn't you? The point I was badly attempting to make is that there isn't enough work to get past the cost of adding the work to the threading system or task system. Doing std::plus&lt;&gt; on a bunch of doubles is really really fast. So the costs are concurrency are relatively high so to benefit you need more work per item or a lot more items. Like reduce of an array has very little coordination to slow it down(A latch I think) and should be one of the best displays of parallel if the work is there to take advantage.
I don't know about entirety of PEP8 but on certain points people are far from agreement (as an example [tabs vs spaces](https://stackoverflow.com/questions/119562/tabs-versus-spaces-in-python-programming)). 
Luckily tab vs spaces doesn't matter since it's only a setting in your editor. Even as a user of basic vim I don't really notice when I edit a tabs files vs spaces file.
* question B : why isn't there a way to have a constexpr memset (rhetorical answer: because we can't overload on constexpr, which leads to a subsequent "why" question) * question C : same than question B but for everything in &lt;cmath&gt;
&gt; I'm of the opposite opinion, I wish CppCoreGuidelines was more like PEP8 and like all other modern languages establish idiomatic formatting. It's frustrating that C++ programmers unlike other developers to such a high degree insist on inventing their own conventions. oh god please no. the main reason why I'm using c++ is that we don't have all these useless rules. This kind of choice should be optional and per-code-entity, with optional per-project guidelines, not per-language.
bout fucking time
Yeah, having all Python code being legible without having to learn the coding style goes a long way. Only problem I see with having a PEP8 for C++ is that there hasn't been one for so long so people have all kinds of different styles, and the language is so big that it might not help the same way.
I just watched the talk. Very insightful. I can recommend it to anyone else wondering what you would need an immutable data structure for.
This flexibility is also a major reason why build systems for C++ are so crappy. They really have to bend over backwards to cater to all the random whims C++ devs come up with. The reason things like Cargo works so well is that you just stick to conventional directory layouts etc
Most projects have those rules anyway. The only difference is that every project has their own instead of a common one.
Thank you Microsoft, very cool!
Nice! gdb, take note. 
I wonder if they're watching.
`xsv stats` isn't actually parallelized by default, but you can make it use parallelism by indexing the data. No parallelism: $ time xsv stats cc-est2017-alldata.csv &gt; /dev/null real 0m5.618s user 0m5.597s sys 0m0.024s $ time xsv count cc-est2017-alldata.csv 596980 real 0m0.428s user 0m0.388s sys 0m0.040s $ time xsv stats cc-est2017-alldata.csv &gt; /dev/null real 0m5.600s user 0m5.575s sys 0m0.027s Index it (basically as fast as counting the records): $ time xsv index cc-est2017-alldata.csv real 0m0.444s user 0m0.410s sys 0m0.034s Now re-run `xsv stats`. It notices the index and automatically parallelizes it: $ time xsv stats cc-est2017-alldata.csv &gt; /dev/null real 0m0.878s user 0m13.309s sys 0m0.067s The index permits random access into the CSV data (_without_ loading it all into memory), which is why it gets so fast. Looking at a profile briefly, the runtime is primarily dominated by parsing numbers and UTF-8 validation. CSV parsing is a blip by comparison. If I wanted to go all out and tune this, I'd focus on faster routines for parsing numbers, and I'd probably start by just copying them out of Rust's standard library and modifying them to amortize allocation. Looking at your parser, you appear to be using the classic approach, which is quite fast. Rust's csv parser goes beyond this by compiling classic approach (which I call an NFA) down into a table based DFA on the stack along with a few other fast path optimizations. You can see that code here, which isn't terribly clear, but does have lots of comments: https://github.com/BurntSushi/rust-csv/blob/master/csv-core/src/reader.rs Have you found your approach to parallelism beneficial? The approach of "one thread reads from disk" while "one thread does parsing" has always had too much synchronization overhead in my experience at these scales, particularly for sequential reading. cc /u/matthieum 
**No!** You are doing **2 look-ups** for each iteration of the loop :( Use the [`merge`](https://docs.oracle.com/javase/8/docs/api/java/util/Map.html#merge-K-V-java.util.function.BiFunction-) method instead: Map&lt;Point, Integer&gt; pointCount = new HashMap&lt;&gt;(); for(Point p : points) { pointCount.merge(p, 1, (current, neo) -&gt; current + neo); } The [`compute`](https://docs.oracle.com/javase/8/docs/api/java/util/Map.html#compute-K-java.util.function.BiFunction-) method would also work, though has to deal with `null`. I reached out to it first, but helpfully the documentation pointed me to `merge` ;)
Implementing this feature took 2 decades too long.
gdb has had the `skip` command for a while but I guess it does't auto-configure.
The problem is that the they codify personal style preferences which conflict with lots of c++ codebases out there while not providing a clear objective benefit Such rules should not be handled in the same manner as rules that objectively reduce probability of errors or make their detection easier (like "use override"). And no, in a several 100 page document that is explicitly not meant to be read from start to end, it is not enough to just put them in a separate section and put a disclaimer at the beginning.
Maybe it was just forgotten?
Cool, that is definitely useful! I've got a question about the move constructor though - wouldn't that be a that be a use case for std::forward?
&gt; Which optimization is this? I believe for GCC this falls under "induction variable optimizations" (ivopts).
Wasn't there a trick to detect constexpr -ness based on noexcept?
Hah! I didn't know about east const but that comment sent me down a rabbit hole and I think I might be on team east const now.
Would not a stack-allocated array work in this specific case? Or do you start from a `Vec&lt;Mutex&lt;T&gt;&gt;`? I find it interesting that encapsulation here is creating such a conundrum. I have actually ported the `Mutex` API to C++ for two reasons: 1. Reduces the chance of forgetting to lock; although not as perfectly as in Rust, since you can take the pointer to the unlocked data and store it for later use... 2. Reduces the chance of self-deadlock; which occurs when the object locks its internal lock, then call a method which also locks the internal lock... However, I have no idea how to start doing a multi-lock with such API. I mean, if the data is homogeneous and the guard is nullable, then it seems simple enough: /// Returns the guards in the same order, such that result[i] is the guard of mutexes[i]. template &lt;typename T, std::size_t N&gt; auto lock(const std::array&lt;Mutex&lt;T&gt;&amp;, N&gt;&amp; mutexes) -&gt; std::array&lt;MutexGuard&lt;T&gt;, N&gt;; If the data is homogeneous but the guard is not nullable, then `std::array` is out as a return type I am afraid (or one needs `std::array&lt;std::optional&lt;MutexGuard&lt;T&gt;&gt;, N&gt;` knowing that all entries are non-optional? Meh...). And while a `FixedVector&lt;MutexGuard&lt;T&gt;, N&gt;` would work, it's interesting to note that the guards cannot be pushed in order that easily, so maybe you'd need some `std::array&lt;std::optional&lt;MutexGuard&lt;T&gt;&gt;, N&gt;` as an intermediate structure anyway! With heterogeneous data and a non-nullable guard however I guess I'd favor sorting networks (if I wrote it externally). Although it's gonna be painful to write :( The case for 2 is simple enough: template &lt;typename T&gt; std::uintptr_t address_of(const T&amp; t) { return reinterpret_cast&lt;std::uintptr_t&gt;(&amp;t); } template &lt;typename T, typename U&gt; auto lock(Mutex&lt;T&gt;&amp; t, Mutex&lt;U&gt;&amp; u) -&gt; std::tuple&lt;MutexGuard&lt;T&gt;, MutexGuard&lt;U&gt;&gt; { if (address_of(t) &lt; address_of(u)) { auto tt = t.lock(); auto uu = u.lock(); return std::make_tuple(tt, uu); } auto uu = u.lock(); auto tt = t.lock(); return std::make_tuple(tt, uu); } For 3 it gets hairy-ish. And above I'd rather not write it. (Of course, an excellent question is *when* would you ever need to acquire the locks of more than 2 heterogeneous objects)
I think the downvotes were cast because people did not understand immediately the issue you were referring to; I guess few enough developers have ever used `std::lock`...
Why not just use breakpoints? Really, what is the purpose of Just My Code?
What do you mean, things like the naming convention guideline says essentially "stick to the c++ naming convention when you start a new project, otherwise use whatever legacy convention the existing codebase is using". That's entirely reasonable. We want to establish common conventions. What a lot of legacy codebase do is essentially equivalent to #define BEGIN { just because they want to have their own dialect. Please dont do that.
&gt; Either way, you're not losing much in terms of performance. If I'm not mistaken the gc pauses are now on the order of fractions of millisecond, which isn't that much - it's relatively easy to reason about performance and latency with those numbers. I really appreciated their emphasis on latency, however it does come at the cost of throughput. The only good thing is that it's easier to regain throughput (by scaling horizontally) than it is to regain latency (which requires scaling vertically). I still think it GCed languages make sense for most domains, **especially** when as in Go an object's fields and an array's elements are the `struct` themselves, not pointers: - This drastically reduces the number of allocations, - This drastically reduces the number of indirections, - This drastically reduces the cost of adding an abstraction layer. It does of course introduces interior pointers management in the GC, which probably slows it down, but that may be offset by the smaller number of records it has to manage to start with. &gt; And there are better ways of dealing with `err != nil`. bufio.Scanner is an example. Any code sample I've seen has always been fairly heavy on `err != nil` :( I think Go's story would benefit greatly by introducing syntactic sugar for this like Rust did. For example, imagine a `?` operator which operates on a tuple of two elements and returns the second element if not `nil` (and the default value of the first element). Then: func simple() (int, err) { result, err = other(); if err != nil { return 0, err; } return result + 1, nil; } Could be simplified to: func simple() (int, err) { result = other()?; return result + 1, nil; } This would cut down on the boilerplate quite a bit.
THIS IS GREAT
&gt; If you're working on truly time-critical software, go ahead and use C++. It gives you every tool you need to get every ounce of performance out of it. I agree that I don't see that use case going away anytime soon, and it has decades of momentum behind it. Actually, working myself on time-critical C++ code, I'm pretty sure I could write faster code in Rust. C++ is not optimal for writing full-throttle code because it forces a trade-off between fast and safe. Debugging memory corruptions in a multi-threaded program often means staring at gdb assembly and memory dumps far too long for my liking. And it's not very fruitful. [Though sometimes it unearths nice little surprises!](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=86314) This means that most of the time, when writing C++, I'll tend to err on the side of safety. I'll only unleash the full power of the beast on very specific and narrow bottlenecks, and otherwise, for the sake of my sanity, I'll contend myself with what I think to be overly defensive code... simply because I do not have the bandwidth to take the risk. In Rust, I pass by reference all the time, trusting in the compiler to keep me safe. &gt; The latest versions of Firefox with the new CSS engine are at least competitive in speed, so even if it's not strictly better it's good enough. Wait, I thought it was faster? I know [Webrender](https://news.ycombinator.com/item?id=11175258) is much faster (but not active yet), but even [Stylo](https://hacks.mozilla.org/2017/08/inside-a-super-fast-css-engine-quantum-css-aka-stylo/) should already bring performance improvements.
I need this.
It's been a while since Mozilla made most of the Rust news; just today a Chinese company specialized in food delivery announced its use of TiDB (a Rust database) for which they wrote extensions and plugins -&gt; [Ele.me](https://pingcap.com/blog/use-case-tidb-in-eleme/). And there's quite a few others users of Rust [in production](https://www.rust-lang.org/en-US/friends.html). It's not as widespread as C++, certainly, but it has graduated from being experimental 3 years ago.
Compile-time move semantics :( It's *so* annoying to have to bake in a "null" value into the type just to be able to run a no-op destructor.
Any idea if this could support skipping certain kinds of functions declared in your own code? E.g. let's say I have a wrapper for Alloc and I know it runs fine, so I have it auto-skip instead of having to move the mouse to skip the call.
&gt; especially when a type (or trait) can silently change that behavior... Note that, semantically, whether you pass by copy or move is identical for the client. It's only performance-wise that it has implications when used on large `struct`/arrays.
Reading the article could help you answer this question. &gt; What this means in practice is...you can stop juggling giant lists of breakpoints spread all over your codebase.
&gt; but if you try to go into the specifics you will not find a dominant set at the intersection of complaints. I remember a tongue-in-the-cheek article about a technical journalist being asked to check out a new Word clone, which implemented 80% of the functionalities of Word. This seems like a good idea; after all, the journalist themselves certainly use less than 80% of the functionalities! The journalist decides to dog-food the program by writing the review using it. Everything goes smoothly, the program is responsive, etc... so the review is positive. Finally, come submission time, the journalist searches for the number of characters in the review, as it's a statistics they need to send along the review for publication. It's not immediately displayed. Hunting down in the menus reveals nothing. The documentation is silent on the issue. The journalist finally contacts the developers, asking them where they managed to hide the words/characters count! Their answer, however, is unexpected: "Nobody used it in our user tests, so we did not develop it". Opening Word, the journalist writes a scathing review of this new clone, which doesn't even bother to implement such basic and important functionality as words/characters count. TL;DR: Just because no-one ever used more than 80% of the functionalities does not mean that everyone used the same 80%...
&gt; For more details on the .natjmc file format, see the C++ Just My Code documentation page. Note that the .natjmc format also supports marking code as non-user code based on function name, but for stepping performance reasons, we do not recommend using this functionality for functions that are called often or for large group of functions (‘Function’ rules are much slower than ‘Module’ or ‘File’ rules). So it appears that if you can isolate your code into a particular file, then skipping that file is efficient.
Ah, ok, thanks, though I would love to be able to define a certain function (possibly in the code itsself maybe?) to be skipped.
Thank you, the Boost license is much more friendly to the Open Source community (and will make your library more popular).
Correction: cmake is a great build system, just an awful language.
I didn't change it; I just noticed it and got excited.
&gt; /JMC is supported only for binaries that link against the CRT. :(
It's definitely something that has pros and cons. The availability of a written specification, is definitely interesting. When behavior must be divined by experimentation, conclusions are empirical and temporary. That being said, I am less convinced about the ISO standard. First, I find the cost of acquiring the standard itself rather off-putting. It's often said that nobody really needs the standard, apart from compiler implementers, and it's suggested to use the drafts, etc... but isn't the whole point of having A standard about ensuring that everybody works off the same specifications? Second, participating in the ISO standard itself is rather complicated. Most notably, it involves physical presence at the meetings (though this can be delegated). At a time where most other languages have embraced remote communication, this seems a rather odd anachronism. Third, as a result of the latter, a fair number of attendants are sponsored by companies. Companies have their own agendas, and it's unclear how much this influences their sponsored personnel. I still remember IBM advocating to retain trigraphs in the language because they are necessary on their mainframes; and only reluctantly allowing them to become a non-standard extension. I find, instead, that something like the Java specifications seem to have all the benefits of A standard, and none of the aforementioned issues of an ISO standard. 
I'm comparing it performance-wise to a vector. Vectors are 2 things; they are a fast random-access container, and they manage contiguous storage. This one is a random-access container that is a bit slower than vector (see talk for more details). It does not manage contiguous storage. It is immutable. The author provides some evidence that the B-tree isn't as expensive as one might fear. For small vectors, the only node is contiguous; for larger ones, the intermediate B-tree nodes are cache-line appropriate in size. It might be better to compare it to a deque; but the horrible std deque node sizes chosen have given deque a bad name. 
Interesting, and thanks for the heads up; I don't think it would have occurred to me to try this myself. My use case is for generating data files for consumption by other computer systems, so I see no problems using a more accurate format, especially if it is so much faster. That we offer the on-screen format as an option for these files is probably more of a historical mistake than a real feature anyway. 
i prefer the boost version, having the ability to write something like: for (const auto&amp; t : vecTs | boost::adaptors::reversed) seems like a better alternative imo
So this supersedes this method? https://blogs.msdn.microsoft.com/vcblog/2017/11/16/improving-the-debugging-experience-for-stdfunction/
Reading, that's hard
yes and no. It would be nice to have a few restrictions like: Do format how you like, but only if you are able to map it to a clang-format file. I use clang-format as an example, but if we had a metalanguage to describe all our individual preferences, than we could build tools to formal test if a file suffices the guidelines and tools to automatically reformat from one style guide to another. So you would have both: individual freedom and unity in the codebase (because you could transformat every external code per your style guide...)
Hexadecimal floating-point should be even faster, although it is not human-readable.
Got it. Thanks for clarifying! I can see how that would be confusing now. I've filed this feedback and I'll be looking at how we can converge these experiences without disturbing those who want box selection to keep it's separate behavior.
Yeah compilers are currently "popcnt stupid". I think they map only very specific patterns to that opcode, instead of doing a more generalised optimisation.
Daveed and I were talking about this sort of stuff in Rapperswill. We' like to start allowing just about ANYTHING in a constexpr function's body (though not executable), so that you could use if (is_constexpr() ) write a constexpr version of anything that requires stuff like memset or inline assembly.
Even if they are, this stuff ain't easy to do. I know that some C compilers for embedded systems specifically go out of their way to produce slow, but predictable, code. One technique is to eliminate as many branch instructions as possible, so basically everything is branch free arithmetics wherever possible. I was curious to what extent GCC and clang could do the same. My suspicion was that only really for the ARMv7 target would they bother. Otherwise modern branch predictors being what they are, the compiler will assume it's best to branch as frequently as possible so the predictor can "learn" the code. That's find for repeated loops, but for cold code it's murder. For cold code, you want as branch free as possible. Not sure if current compilers can be hinted to do this, however.
That would be a nice general solution to this problem.
merge is not guaranteed to make only `1` lookup either, but yeah, for this scenario it seems to be better fit.
If you know a certain chain of recurrsions, say {a, +, b, +, c, +, d}, how do you predict the exit value?
What is the definition of "giant"? I can hardly remember having more than 30 breakpoints. Is it giant enough? Also, there is an upside of having breakpoints: one keeps record of important places in one's code. Visual Studio has another feature for this purpose -- bookmarks, however I find that I don't use it, because I have breakpoints (active or not) on all relevant lines.
I was able to drop my time to parse a 2GB file from 50+ seconds to 36 seconds by using a two-threaded approach. (For others reading, I've implemented a lot of the ideas others have suggested, e.g. string_views and have gotten it down to 24 seconds!) I agree that synchronizing multiple threads w.r.t. CSV parsing is pretty onerous. My solution was just to enforce only one worker thread at a time. The CSVReader class has a unique lock, and only the thread that has that lock is allowed to run. The running thread then pulls a unit of work off a queue (also part of the CSVReader class) and doesn't release the lock until it's finished parsing.
Nice to hear. 
I don't like abusing operators (bitwise or) for purposes they were not designed for... but maybe I am a bit old-fashioned in that regard.
I don't find different whitespace conventions to be a big problem compared to naming conventions. Just stick to conventional brace position and pick a consistent indentation size, rest is just "make it look good". Auto format is even better of course. I find it much more jarring reading code full of Java camelCase. Given that consistency is one of the more important aspects of a coding style, deliberately being inconsistent with the standard library is silly, regardless of personal preference.
Fair enough
That's totally fine until you edit a tsv file in your editor and then your parser reports errors after you save
That's not yet supported but a great suggestion and something we should work on. IntelliSense auto type deduction and class template argument deduction are currently supported, but only in regular functions/lambdas, not generic lambdas. 
What codebases do that?
I'm the opposite, if prefer camelCase for methods and CapitalCase for static functions. My eyesight isn't 20/20 and underscores just get lost amongst a lot of - = -&gt; Actually, reading shipped STL code is incredibly tedious. God know what standard they use, maybe one leading underscore for every decade of c++ development experience
PHP has a similar issue when PSR-2 was introduced but today a great many libraries and frameworks follow this standard. My belief is that its package manager, Composer, as well as buy in from a few popular projects really drove increasing adoption. If a package manager were to finally emerge into common use then that might drive old codebases to update.
I think you are referring to this: https://github.com/brycelelbach/mditerator
Copying the whole container, really?
He was exaggerating but I agree with him. Yeah, we have a lot of code out there using different styles. So fucking what? Just establish a standard rule in the Core Guidelines and recommend it for new code. It's not like it has not been done before (for example the PSR for PHP followed that route and now most code out there is using the "one and truth" naming convention).
Good, I hate accidentally stepping into some STL method call and ending up in a Lovecraftian template nightmare in &lt;xmemory&gt; or similar.
Hmm, yes, shallow, and pedantic.
Out of curiosity, why does this need a compiler flag?
I agree. The err != nil boilerplate can be overused. That said, Go is refreshing in that it makes you think about errors and how to handle them every step of the way. I am of the opinion that the err != nil overuse comes from not designing with errors in mind in the first place. A nil check becomes almost a release at that point. What I really do appreciate though is that they made errors an interface. So starting with a nil check is ok, but you can gracefully migrate to smarter approaches as code matures.
nice. I love c++, so many ways to do stuff.
vcxproj is the extra step. To do this, you would start in CMake. which can then generate a vcxproj. QtCreator supports CMake, and CLion project files *are* just cmake. As for converting, you'll have to do that manually.
The last draft before, or the first draft after the new standard is effectively the same as the published standard, with the last draft practically being identical. That draft is what I gather most people use if they use it. The ISO process is behind the times and costly, yes, but that can be changed, although Bjarne and some others think there are too many committee members now and instead of help do the grunt work, are instead spending too much effort promoting expert features rather than simplifying existing features. So keeping it small, even if it is unfortunately by cost, may be beneficial. As for Java, it's still effectively controlled by Oracle and their shenanigans. C++ is moving faster than Java as a language, and I suspect it's highly due to the fact that C++ is an internationally recognized standard not owned by any one.
If you're willing to use an extension, you can do it by using \_\_declspec(non\_user\_code) __declspec(non_user_code) int f(int i) { ++i; return i; } void g(int i) { ++i; } int main() { __asm int 3; g(f(0)); // Stepping into this call will step into g() but not f(). }
Leaving you with a bunch of different rules that are basically the same, except when they're not. which is worse and more confusing for everyone involved.
The underscores are because those type of names are specifically reserved for use by the standard library. My understanding is because of the history of macro abuse and attempts to extend the std namespace beyond what is allowed by the standard. Double leading underscores and underscore followed by a capital letter are reserved by the standard for standards usage, which are mostly for internals.
&gt; If you're willing to use an extension, you can do it by using __declspec(non_user_code) I didn't know about this, where'd you find it?
&gt; Doing std::plus&lt;&gt; on a bunch of doubles is really really fast. So the cost of concurrency is relatively high. Perhaps, but we're really hitting memory bandwidth walls in this example.
Exactly my point
Yeah, seriously. The lack of destructive move, in general...
&gt; clang and GCC in C++ 17 mode optimises away memory allocations if the compiler can prove they cannot "leak" outside of its view. clang does this *much* better than gcc, currently. https://godbolt.org/g/f9HKbU
Heh. I've done the Rust-like pattern as well... in fact, I once posted an example of that model (with a ref-castable smart pointer return type) on comp.lang.c++, specifically asking if anyone had a good way to avoid deadlocks. This was before modern C++, and back then, I really couldn't come up with a solution other than pre-locking all of the lockable containers, then calling the acquisition method. Now, however? I believe I can solve it. Let me mull it over for a while. I'm pretty sure I can make this syntax work for heterogenous lock types, and I'm utterly certain I can make it work for heterogenous inner types: `auto&amp; [p1, p2, ...] = lock_all(l1, l2, ...);` 
Oh, and with respect to the question of "when"? One case that I've encountered in the wild was a component management service with arbitrary dependent elements, where mutating events could occur concurrently if there were no races between the changes and preconditions of the two events... though that one did gather and order the lists of read and write handles required at runtime, so it's a little different. I'm fairly sure it could happen with sparsely intersecting discreet entities in a large-scale simulation, though systems like that are more often modeled as homogeneous handles to runtime polymorphic types. I first saw this with a large number of synch primitives, for homogeneous types, without proper ordering, implemented in Fortran, causing a rare deadlock (the intersection frequency was very low), and fixed it by sorting the array of primitives inline... I want to say in the mid 90s, on an 8 CPU SGI Octane server. It may not be an everyday thing, but when it happens, the unwary engineer can be severely blindsided. The Rust case I recently encountered (while reviewing a PR) was easily remedied by moving a local from within the scope of the inner Mutex, and decoupling the two Mutexes, but that isn't always feasible. I did once encounter a three way swap of a (same type for each) member of objects of three different types, where all three types had mutex protection. Someone (prior to my involvement with that codebase) had solved it by locking (as in blocking until all other operations completed, and blocking new operations) the entire server before each time this swap was performed. It wasn't a common event, but I was still mortified.
Well, not sure if it's impressive enough, but I've always liked bitfield test merging optimizations: https://godbolt.org/g/YhKPqg Converting switch() based truth table to a guarded bitfield test: https://godbolt.org/g/ZpyGYS 
No need to argue about that, it is vital and std::string now provides the same guarantee.
Kewl.
Ph'nglui mglw'nafh Cthulhu X'memory wgah'nagl fhtagn.
Yeah, trying to get cmake to output the same configurations with the same settings as existing vcxproj files can be challenging. 
It looks like you can't check in the config file in with your associated project? 
Just a note: Since 7.4, you can also use [`skip` command](https://sourceware.org/gdb/onlinedocs/gdb/Skipping-Over-Functions-and-Files.html) in gdb to skip unwanted files/functions based on regex.
I'm not saying that it's not vital to many uses of `std::vector`; it's less obvious that it's a necessary component of a *different* data structure called `vector`, which is a pretty non-standard use of that term IMO anyway.
I'm not saying that it's not vital to many uses of `std::vector`; it's less obvious that it's a necessary component of a *different* data structure called `vector`, which is a pretty non-standard use of that term IMO anyway.
I was always wondering that why the committee decided to limit the scope of constexpr since the beginning. At first, they thought a expression-only version should be enough for everyone and easy to implement, but soon they relax it to most operations, e.g., `if constexpr` and recently-added virtual call. Expect to see a buggy version of [ctfe](https://tour.dlang.org/tour/en/gems/compile-time-function-evaluation-ctfe) in dlang after years.
I have less than stellar eye sight but for me the solution is to use bigger fonts and the problem goes away
It is a polynomial, but is easier to write using sum of falling factorials/binomial coefficients than classical sum of monomial. That is, instead of x^(k) = x\*x\*x\*...\*x you use (x)^(k) = x\*(x-1)\*(x-2)\*...\*(x-k+1)/(k!). So {a,+,b,+,c,+,d} at iteration i is a(i)^(0)\+b(i)^(1)\+c(i^())2+d(^(i))3. It works because (i+1)^(k) \- (i)^(k) = (i^()k-)1 thanks to Pascal's rule. (and can be seen like a finite difference!) Then if you know the number of iterations (as a SCEV) you just plug the SCEV into i.
Cthulhu s'finae!
Not sure if that's appropriate to say here 
The naming and layout rules are a rather minimalist set of rules aimed at bringing slightly more consistency to code from separate code bases. That's a laudable goal (it makes all of our lives slightly more easy) and as such, a good addition to the core guidelines. Of course it is easy to disagree with some of the rules, but that's ok. Existing code can remain as it is, and for new code this will provide a slow convergence to a generally agreed (if not universally loved) way C++ should look, making all of our lives easier over time. 
I'm the same as you. I found the MSVC implementations nicer and easier to read. Whatever one my IDE goes to on Linux makes me want to slowly flay myself and pour salt on every wound. I don't know how anyone even works on that.
IMO, if a "vector" is not contiguous, it's **not** a vector, which is a dynamic array, (array as in c-array), it has to be contiguous (as the C-language dictates).
Interestingly, GCC trunk will generate it with popcnt if and only if you use `-Os`. For `-O1` through `-Ofast`, it generates much worse code.
This isnt related to c++
IIRC GDB python scripting achieved this years ago.
I fear that may also be unreadable to many of the tools used by the next group of people working with the data. When I first heard about hex floats I couldn't figure out who could possibly be needing those, but I suppose for fast data interchange it would make sense. That's not a use case for us though: we transmit data in chunks, and each chunk is a binary blob. Anyway, I'm looking forward to 15.8 and playing with these functions! 
Likely it emits some info into the .pdb file?
Alternatively they could also directly take a buffer allocated by the user, which would notably allow to reuse the same buffer for several calls the algorithm.
That is indeed interesting.
Nice one
You can guess which senior clang engineer proposed the feature allowing malloc elision eh? :)
I'm wondering how this plays together with VAX and Re++'s Debug Step Filters. They don't require a separate compiler flag (they do it purely with natvis as far as I know).
It seems reasonable to make this a customization point, but please don't use the standard allocate model for that
It's personal really. Some people like C-like syntax better, some others. Same goes with how C++ does things compared to other languages.
"The C++17 deduction guides ensure that temporaries will be kept around in the reverse object and not dangle. Non-temporaries will be kept by reference without overhead." `template&lt;typename Cont&gt;reverse(Cont &amp;) -&gt; reverse&lt;Cont &amp;&gt;;`
No copy of the container should happen due to the ``` template&lt;typename Cont&gt; reverse(Cont &amp;) -&gt; reverse&lt;Cont &amp;&gt;; ``` deduction guide. Or am I missing something?
By your argument a dequeue is also a vector. Let's not further misuse the term vector than the standard already does
First of all, doing manual memory management (pointers) and writing fast code is hard for programmers, in general. Then, some of the difficult bits (hoops you have to jump through): declaration syntax, initialization, move semantics, templates, header files, installing/building/linking libraries, preprocessor... Most of the STL is good, but there are some really bad/obsolete parts. That being said, we should start seeing a lot of improvements in the language soon, so the language will become **much** easier to use IMHO. Concepts make templates easier, Modules will replace header files and reduce fully qualified name verbosity, "= T(a,b)" should become a consistent way to initialize variables, Ranges will make containers and algorithms much more pleasant to use etc.
&gt; That being said, we should start seeing a lot of improvements in the language soon, so the language will become much easier to use IMHO. Wasn't that already the promise of c++11/14? (Personally I think it has become easier, but at the same time, none of the c++20 features are imho game changers)
C++11 **was** a game changer. Modules, Concepts and Ranges also completelt change the way we write code.
It's amazing how people will downvote you for a slightly "not nice" tone even if you're right. I don't think you should have to be extremely pleasing and diplomatic in a reddit comment, but I guess everyone else thinks that, even though it worsens the platform as a whole not to let people complain about shitty content.
Might be. The PDB file already contains all the source code paths, so if you combine this with the knowledge the IDE has during debugging should be enough. Who knows 🤷‍♂️ 
I feel like I don't want to get *too* good at C++. Learning its *many* idiosyncracies could push other more useful information into tue very low latency part of my memory hierarchy.
c++11 was a game changer and my post didn't dispute that at all, but c++20? * Modules: It isn't even clear, if we will get modules at all and in which form exactly, but in the end, there is little textual difference between a class whose whole definition is written in a header file and a class that is written in a module (you can omit the `detail` namespace). It doesn't change the way you write your code - it may change the way you structure it. * Concepts: I've played around with the concepts-TS implementation and the only celar advantage they brought was overloading based on the existance of certain members (or more general the validity of certain expressions). Not sure if it comes up often enought to be a game changer and on theother hand it add a non-trivial amount of complexity to the language * Ranges: I'll reserve judgement until I see which parts actually land in the standard. The range based overloads for standard algortihms have been long overdue, but I had my own \`algo::sort(my\_vector)\` wrapper for over a decade and ranges-v3 have also been available for years. A full port of the ranges-v3 library into the standard will certainly be a game changer for projects that couldn't use it so far though, but lets see if we get that
It's not hard to use, in general, but it's hard to use well. The old joke is that "C++ gives you enough rope to shoot yourself in the foot." The deeper you get, the harder it gets. For example: [CppCon 2017: Nicolai Josuttis “The Nightmare of Move Semantics for Trivial Classes”](https://www.youtube.com/watch?v=PNRju6_yn3o)
Yeah that's a pretty nonstandard definition of a vector specific to c++
Changing formatting style is almost always a bad idea when version control comes into play.
The standard library is such a tiny part of the interfaces you are usually using, that consistency alone is not a good argument for it's style, because there are lots of commonly used frameworks and API's out there that follow a different style.
I think one thing worth mentioning is that C++ doesn't ever seem to end. In the sense that it's one of those things where the more things you learn, the more things you see that you still have left to learn. You're happy you finally figured out the difference between lvalues and rvalues? Thought you could get rid of that feeling of incompetence you felt for not knowing? Sorry, now you get that feeling about xvalues, glvalues, etc. Proudly applied some std algorithms? There's about 100 more you could and should probably be applying. This means that in C++ not only are there always N ways of doing X, but some fraction of those ways are unknown to you. Knowing this can be a little frightening, bad for confidence, and sometimes highly demotivating.
If you are talking about internal STL identifyers: they have to start with underscore+capital letter, because any oder name could be a macro defined by the user.
It's all about familiarity. I find the camelCase frustrating to read because I rarely do. But all languages have their own conventions and it's better (and easier to read) if you stick to whatever style the language uses.
Yes and I think that we shouldn't give up just because all these legacy libraries use their own homegrown styles. We should strive to follow common conventions, not make things worse.
Exactly my thoughts as well. The guidelines are mostly aimed at new code and the whole purpose is to bring a little more order in the wild west c++ community, something we all would benefit from. 
int i = 4; i = i++ + ++i; // What's i value? Yeah, you are right, C++ syntax is so easy!
&gt;I think one thing worth mentioning is that C++ doesn't ever seem to end. The only languages that end are the ones not worth using for anything real. Take Javascript, for example - yes, the language is simple, but nobody is just using the language; everyone is using these giant frameworks, and a new one appears every month, and you have to keep up... The cognitive load really isn't any less. 
Original STL did have many more versions of the algorithms than the c++ standard library currently has. The designer of STL, Alexander Stepanov, thought it to be a good idea to give users many options on what kind of algorithm they use. One of those algorithms was I believe stable_sort_with_buffer, to which you pass the regular arguments you would pass to stable_sort, plus the random access iterator which represented the buffer. Sadly the standardization committee didn't agree with him. The wanted only basic versions of algorithms; presumably thinking that most users don't know what even the those basic algorithms and it would be challenge enough for them to learn them; those extra version of same algorithms would only confuse them(bad decision IMO). You have full lectures of Alexander Stepanov [YouTube](https://www.youtube.com/watch?v=k-meLQaYP5Y&amp;t=8s), where he talks about programming in general. In one of those videos he talks about sending a buffer to algorithms.
If that's the reason people hate c++ then we don't want such people anyway.
Nice anecdote, thanks :)
Modules will remove the include mechanism which is quite a game changer. 
Not really. If you have a look at the requirements on a std::vector::iterator, you'd see a vector has to be contiguous (or emulate the whole think with excruciating detail). We also have the `T* std::vector&lt;Y&gt;::data()` member-function (observe the non-constness), which makes little sense if the pointer points to things that are not contiguous, without knowing how the other bits hang together with the first bit.
Because C++11 and onward has nothing to do with C++98 or 03 which where the reputation comes from.
I wouldn't bet on it with the issue of exported macros. I don't want to get into any debate here (you can see plenty elsewhere), but some people want `#include &lt;foo.h&gt;` to give you the module + macros while `import foo;` gives you the module, whereas some people want macros built into modules. This is still a rather contentious design point and we'll have to see what the final design is, keeping in mind that this issue will be revisited after C++20 whether it has any modules or not.
The value isn't determined by syntax. If you're alright having `=` be how you assign something, `+` being how you add things, and `++` being how you increment things, you're fine with the syntax. Semantics are a separate aspect that fit into the OP's question, but you shouldn't try to mix the two.
Whoa the first one is very impressive. Especially when you consider that GCC needs 5 branches where Clang reduces it to a single \`and\` instruction.
No what I'm saying is that those properties are all highly specific to c++ and in programming in general 'vector' means something different. C++ is the one that is abusing the name vector.
Well, if we can do everything else with modules and have only one single header for macros then it's fine for me. 
I prefer [`fmt::print()`](https://github.com/fmtlib/fmt).
Because is C++ *is* difficult :) The syntax of C++ may indeed be terser than Java's (not much to brag about...), however it's also full of quirks: - The Vexing Parse: `Type variable();` is not parse as invoking the default constructor of `Type`, it's parsed as declaring a `variable` function returning `Type`... - The [Most Vexing Parse](https://en.wikipedia.org/wiki/Most_vexing_parse): Most surprisingly, so is `Type variable(Argument());`! All the more vexing that with a function scope you're not even allowed to define functions to start with. - C++11 introduced the Uniformed Initialization Syntax to solve the issue: use `std::vector&lt;int&gt; copy{source};` and ~~the problem is solved~~ you unwittingly invoke the Initializer List constructor. Uniform Initialization Syntax, the fix which was not. Those are **basics**, every day issue. If you break out templates, you get more fun: - `typename` is mandatory when accessing nested types in *some* contexts, but not all, - `template`, likewise, because otherwise `this-&gt;get&lt;3&gt;()` could be interpreted as comparing `this-&gt;get` with `3`... The *some* is of course the funniest bit; refactor a bit and suddenly the compiler is barfing because *now* it's mandatory. Sprinkle on top a heavy dose of semantic rules (with lots of edge cases), manual memory management and undefined behavior galore, and you have a language which is very difficult to wield properly. Powerful, yes, but definitely not easy.
Profile, experiment and measure, repeat.
The topic is the complexity of c++ \&gt; Modules, Concepts and Ranges also \*\*completely change the way we write code\*\*. an imho modules don't really change how you write code or make c++ magically simpler. What they hopefully achieve is making build times faster and protect us from transitive macro includes (\`windows.h\` anyone?). In that regard they are a game changer - yes.
I would make sure there are appropriate tests in place so that I don't secretly destroy the whole code base because of some obscure thing someone wrote 25 years ago.
Very nice paper, I like how Louis kept the scope narrow.
It is /r/cpp ffs.
"The deeper you get, the harder it gets." This is a general statement. It just so happens that C++ goes deeper, therefore exposing harder problems which require harder solutions.
C?
General direction: from high level to low level. First try to optimize the algorithm &amp; data structure, then write tests &amp; benchmarks to perform module-level optimization. Profile-guided micro-optimization should be the last resort.
Understand the problem the code is solving, make your research in search for algorithms that can solve it with better computational complexity. If it's possible then rewrite it. If not only then do what @Pragmatician said.
1. Make sure there are unittests with good coverage, so that your changes do not break the code. 2. Check if they used the right algorithm for the task. For many tasks that can naively implemented with O(n^2) complexity there are algorithms to solve it in O(n log n). This can often give immense improvements for litlle work. 3. Profile the code 4. Try to improve hotspots. Common techniques to do this: - Cache calculations - Look Up Tables - Make the code cache friendly - Lazy Loading/Computation - How much precision do you need? Can you use Approximations ? - SIMD code - Prefer moves or references over copy After each change profile the code (on hardware similar to the target hardware !) and check if your change improved it. 
Sorry, but I will never use snake_case for typenames.
Why does that matter? I'm sure C++ devs are interested in computer science and programming in general.
Measure, analyze the code in the hotspots, make a plan for improving the code, modify, test, ... back to step 1. Errors/missteps should be picked up by linters and compilers. 
My point is that the consistency argument might actually work against the standard library style and IIRC even the fire guidelines recommend to follow whatever the established style at your company or project is. In any case: I don't want to argue for or against a particular style, I just agree with the GitHub issue that formatting is on the one hand too controversial and on the other hand not important enough to be part of the Cpp**Core**Guidelines. That doesn't mean the core guidelines can't say something like "we follow style X for all our examples.
Can you show me how to do this with gdb? Is there any documentation?
&gt; Can anyone tell exactly (with code if possible) where and how C++ is difficult over other languages. Figuring out how to sort a vector in C++ for someone who's used to just do `myData.sort()` or `sort(myData)` is like a mini-project in itself. Usually they try it the obvious way, which doesn't work, and then try to decipher template error messages for the next half hour. Some languages go to great lengths in providing convenience overloads that do what you expect them to do. C++ is not one of them.
skip doesn't do that, it skips over a function *and every function called from it*. This is exactly what we don't need. 
Those syntactic rules are corner cases though mostly covered by compiler warnings, and no one does manual memory management unless you have highly specific needs. Which if you do you're already highly competent
For me Java and C# leads to harder to understand code because everything is effectively shared_ptrs. Value semantics help locality. I mean in c++ we say mutable shared_ptr is almost as bad as global variables, so in these languages are all variables effectively global variables with hidden hard-to-reason-about global data structures?
May be you can start from [http://www.agner.org/optimize/optimizing\_cpp.pdf](http://www.agner.org/optimize/optimizing_cpp.pdf)
Yes, I presume they are, but when we discuss a vector, it is contiguous, because that is relevant to cpp-devs. "Other concepts vector" are relevant as well, but they just don't call them vectors.
 sort() could have had a better syntax. Even more surprising is that C++ actually allows you to do some stupid stuff. #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; using namespace std; int main() { vector&lt;int&gt; A = {4,3,2,1}; vector&lt;int&gt; B = {5, 6, 9, 8}; sort(A.begin(), B.end()); for (auto &amp;i : A) { cout &lt;&lt; i &lt;&lt; " "; } return 0; } This gives no warning / errors, but a seg fault later. Something like sort(vector&lt;T&gt; &amp;A, iterator first = defaults to A.begin(), last = defaults to A.end(), comparator : defaults to &lt;) would have been better though.
This is really nice for students, especially. I've seen students at the "what's a for loop" level of understanding reel back in horror after getting tossed into the STL by the debugger.
Thanks I've already found this book. I hope it will be helpful! :)
Thanks for good hint! I didn't remember to make sure about it! 
I'd say profile before checking for algorithmic complexity. Both to identify what parts are worth working on (no need starting optimizing one thing if it takes 1% of the time and another takes 50%), but also to get a baseline to compare to. I've been burnt before with algorithmically more complex things that still are faster up to a higher N than needed because the actual implementation is just so simple &amp; fast. 
Profile to figure out hot spots. Then read those with an eye towards algorithmic complexity. Any code above O(n log n) is a candidate for further inspection. Once that's done, check for: - Ill-advised memory allocation patterns (allocations in tight lopes, repeated vector.reserve() calls, ...). - Expensive copying (COW containers being passed in a non-const manner, passing around shared_ptr without using a reference, ...). - Bad API use (having an endless series of endl's in text output, inserting data in an SQL database but failing to use the multi-valued insert, map when unordered_map would suffice, single-byte IO, ...). - gratuitous use of data structures that don't play well with the cache (list instead of vector, bad use of the top 64 bytes of your object, ...) - unwarranted cleverness (bitfields!). Measure before you change anything. Measure again after you changed it. Ultimately optimisation happens on different levels. In some projects, allocating memory is already too much, and optimizing might mean manually inserting specific CPU instructions and rearranging data so you get more cache hits. Other projects stress maintainable, readable source base over this kind of micro-optimisation. No matter what, reducing algorithmic complexity is always good, and that always starts with having the right underlying data structure. 
Thank you for this tips, especially for the last one! What do you mean talking about precision? You mean using float vs double? Or thinking about it I have to go deeper? :D
&gt; and no one does manual memory management unless you have highly specific needs. template &lt;typename T&gt; T const&amp; id(T const&amp; t) { return t; } int main() { auto const&amp; s = id("Hello, World"); std::cout &lt;&lt; s &lt;&lt; "\n"; } Manual memory management in action. You're welcome.
Yes I agree see my original comment, I mention that for a c++ container if you name it 'vector' should probably make it behave like std::vector to avoid confusion
Thanks for general advice in particular regarding R&amp;D. I think the problem should be divided to undivided parts and solved separately but we should keep in mind that whole program should be kept in one data structure. I mean that we should avoid keeping the same data twice in two different structure in order to make computation faster.
C++ has a lot of complex moving parts; sometimes they interact in clean and intuitive ways, and sometimes they don't. Worse, sometimes when they don't, everything breaks spectacularly at compile-time with an error message (often simple and descriptive, but occasionally long and nightmarish and difficult to parse), but sometimes it *doesn't*, and you get a program that appears to work but that is incorrect in a subtle and potentially dangerous way, or that is correct but unstably so, and a tiny change mighy break functionality in a seemingly unrelated part of the code. Sometimes C++ is just unintuitive. struct X { X() = delete; }; auto x1 = X(); // error! auto x2 = X{}; // perfectly fine auto v1 = vector&lt;int&gt; (3, 2); // [2 2 2] auto v2 = vector&lt;int&gt; {3, 2}; // [3 2] struct Good { int i; }; struct Bad { const int i; }; auto good = new Good{5}; auto bad = new Bad{5}; new (good) Good{10}; new (bad) Bad{10}; do_something_with(*good); // perfectly fine do_something_with(*bad); // undefined behavior! template &lt;typename T&gt; void foo(T); // (1) template &lt;&gt; void foo&lt;int*&gt;(int*); // (2) template &lt;typename U&gt; void foo(U*); // (3) int i; foo(&amp;i); // calls foo&lt;int&gt; overload (3) — // not foo&lt;int*&gt; specialization (2)! This is just scratching the surface. As others have noted, the complexity is fractal, and you cannot really hope to ever know imall there is to know. Of course this is true of every language, but C++ has it worse than most, because it is so complex to start with and because many of its features weren't designed well, were imported from C and not changed, or weren't designed to work seamlessly with other features.
The STL is only worth examining, if there is a suspected bug. But commonly, STL is assumed to be working code - otherwise it wouldn’t be a standard. Is this going to “skip” imported libraries from other projects? Could it be set to examine the imported project bu skip STL?
There are lots of problems that have expensive algorithms that give exact answers, but which have alternative algorithms that give good, approximate solutions for much lower cost. You brought up floats. That is a good example. Floating point numbers and arithmetic is an approximation of real numbers and conventional arithmetic. Real arithmetic is not fast (an example would be Mathematica), and floating point is literally millions of times faster. There are edge cases when floating point gives very bad answers, but most of the time it's close enough to be functionally indistinguishable from an exact solution.
Sometimes data redundancy allows making faster code, but it's very case specific.
Float vs double should not really matter on modern hardware. I mean that in some cases it does not really matter if you find the perfect solution or a solution that is close to perfect. (Especially for optimisation problems). 
I doubt it's used any more, but an example of sacrificing precision for speed is [the fast inverse square root](https://en.wikipedia.org/wiki/Fast_inverse_square_root).
Concepts: Another advantage of concepts IMHO is that we can capture errors with template instantiation efficiently and more clearly in case of lengthy, unreadable error messages or surprising UBs during runtime. I think this will be profoundly game changing if (and only if) libraries including `std` "conceptify" themselves. But the problem is that part of current code will be broken due to constraints violation and I wonder whether or how the Standard Committee will head on it. Ranges: A small part of Range-v3 lazy adaptors is on the way: [Range Adaptors and Utilities](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0789r3.pdf) , and I'd like to see some other fancy stuff like `view::cartesian_product` and `view::zip`. Looking forward :&gt;
How is that manual memory management?
Where did I say that I do not stick to whatever style languages use or think that we should not?
Initialisation. 
This is actually a really good idea. For example, we could have new versions of `stable_sort` that look like: template &lt;Readable I&gt; using buffer_t = span&lt;iter_value_t&lt;I&gt;&gt;; template &lt;RandomAccessIterator I, Sentinel&lt;I&gt; S&gt; constexpr I stable_sort(I first, S last, buffer_t&lt;I&gt; buf); template &lt;RandomAccessIterator I, Sentinel&lt;I&gt; S&gt; constexpr I stable_sort_nonallocating(I first, S last); (with appropriate comparator and projection defaulted parameters, and a range overloads). Then the overload taking a buffer will use it if it is large enough, otherwise it will delegate to the (less-efficient) non-allocating version of the algorithm. These functions basically need to exist anyway as private helpers given the current spec, so there's not much to be lost by making them public.
We could also require that std::stable_sort runs in O(n log n) without ever allocating, but that probably wouldn't be as performant x)
Personally I think this is a bug in the standard. I have several dozen places in my codebase where I had to write a variadic template constructor to work around not being able to change access with a "using" directive. Can anyone explain why this rule was put in place originally?
He gave a bad example, because the "Hello, world" string is guaranteed to never get freed. Change "Hello World" to a local stack-allocated variable and you'll understand.
This is only the most basic advise on optimization. Many times if someone new finds what is slow, they won't understand why. The sequence I follow is: 1. Minimize memory allocations - one big is much better than many small 2. Structure memory access. Linear access means prefetching, which hugely reduces stalls due to cache misses and memory latency. 3. Multi-thread (this is a rabbit hole in itself of course). 4. Use SIMD (This will go hand in hand with how data is structured in memory. ISPC is the best way I have found to take advantage of SIMD so far). All of these together are exceptionally potent, but the cliche of 'premature optimization is the root of all evil' can get in peoples' way if they don't see the full picture. The truth is that you have design and architect for performance from the beginning. This can be done after a prototype that works correctly, but it will have to happen at some point. The micro-optimizations that likely prompted Knuth to make that quote in the first place are things that I barely worry about. The compiler takes care of so much, that almost all of the speed gains I've gotten have been from higher level (relative to worrying about instructions) design decisions about memory layout and concurrency.
Can you give an example. Using will only work if the name is accessible from the derived. 
&gt;And I would profile code looking for the function which takes the most of the time and improve it. If you said this, it's almost certainly the answer he was looking for. Profiling is by far the most important thing and what you should always do first with optimization. If you don't know what's slow, you will inevitably end up "optimizing" code that doesn't actually need it/make any significant difference. 
Translation for the lazy. &gt; In dead cthulhu x'memory home wait
I find it worthwhile, since CMake is a heck of a lot easier and more reliable to maintain and understand for me than whatever vcxproj does.
For me, it's the opposite. I have a lot more experience with vcxproj, and Cmake seems to do a lot more hidden work. I'm sure with time I'll get better at it. 
Yeah, I hoped it was good answer :)
No 'skip file' skips files just like this functionality. I use it all the time to avoid stepping into shared_ptr
'skip file' skips the current file. Give it an argument to skip other files
1. Profile hot spots 2. Profile hot spots 3. Inspect algorithms 4. Profile hot spots Don’t optimize without knowing what needs to be optimized. The actual optimization can vary widely depending on the application. - Is disk IO eating a lot of time? Cache data in memory if you can rather than reading/writing with every change - Is it a DB query? Profile accordingly for the DB and optimize the query - Is it a non-constant-time algorithm? Look at simplifying algorithmic complexity and minimize recomputation of the same work - Is it just a shit ton of operations in an algorithm that has already had optimized complexity? Look at multithreading, minimize branching, modify data structures to minimize LX CPU cache misses - Is it a lot of complex math or simulations? Try SIMD or offload to GPU