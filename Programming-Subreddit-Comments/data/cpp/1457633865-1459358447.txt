&gt; D is just not going to happen - it's replacing C++ mess with another mess. Including GC in that kind of a language was a fundamental design error and working out of that is more trouble than worth (the whole nogc thing and std lib ports and whatnot) - and what's the point in switching to something that's fundamentally flawed from the start - especially since they are an OSS language that can't throw millions of dollars on a GC implementation like Java/.NET did, or at anything else for that matter. D's memory management story is indeed a mess at the moment, although it is slowly getting better. As for the lack of development resources, though - don't count us out just yet: the D community has been experiencing rapid growth the past few years. The next DConf already has [more than double the registrations](https://forum.dlang.org/thread/nbnl53$lb0$1@digitalmars.com) compared to last year, with two months still to go! (I am a D contributor.)
So can I install the Windows SDK to get the headers and then use the Clang Windows installer to make a working toolchain? Or do I *need* the Microsoft C++ tools as well? I ask because I installed the Windows SDK but none of the Microsoft C++ headers were installed (iostream, etc.). You are right I am all over the place :( 
Thanks for the response. I totally understand your reasoning and your decision. &gt; Without the ability to specialize the base case, you'd get infinite recursion during concept instantiation. Jup, ran into that while testing :D &gt; My advice: Do metaprogramming in metafunctions. Use concepts to specify simple logical constraints. I wouldn't actually recommend to do metaprogramming in concepts! I just found it worth sharing.
Pre lexena meeting mailing that is, thats why I didn't cover it. You might find more information in the post lexana mailing, but not all proposals are usually covered at a meeting. Its an interesting approach, maybe it was dropped in favor of the current leading paper P0194R1. Looking at things, history wise its: 4111 -&gt; 4428 4113 -&gt; 4451 -&gt; P0194R1 But its also possible, that there will be a follow up in the next meeting.
&gt;&gt;My advice: Do metaprogramming in metafunctions. Use concepts to specify simple logical constraints. &gt;I wouldn't actually recommend to do metaprogramming in concepts! I just found it worth sharing. Good post, BTW :) I enjoyed it.
&gt; p0255r0 I didn't take detailed notes on this section so I'm going entirely from memory. I'll try to answer your question but I really, really hope I'm not misleading (and anyone who remembers better feel free to correct violently). There was some discussion on the hijacking of the pre-existing keywords and how we'll inevitably want more "kinds" and run out of keywords to hijack (this lead to the usual discussion about how to work around those problems and then a discussion about not discussing the details of the syntax :). As for the core mechanism, in the end, people just seemed to prefer a new operator that returned a meta-type that could be poked at. Obviously that meta-type could still use the parameter packs idea as outlined in this paper.. so it seemed like a more general core mechanism for reflection. People liked the end parts of the paper talking about how to extend the "querying" and how it might improve compile-times (because this proposal lets you subset what you are introspecting early). IIRC there was a good deal of talk about how these ideas might look in the other proposals. So a bunch of the core ideas were well-liked but people thought they weren't uniquely tied to the core reflection mechanism. 
&gt;&gt; and EXTREMELY huge disadvantages. The disadvantages can be eliminated by tweaks to the proposal The advantages are ending this bouncing over styles. The a.foo(b) is ubiquitous. it reads better and writes better. Languages like Rust &amp; D prove it's benefits are possible without the hazards of OOP
Does anyone know why clang does not support OpenMP on OS X? Is Apple's clang fundamentally a different project?
.o files can be created during complition in order to merge (link) them altogether to create a binary or library. Once you have your exe you can delete them if you don't want them Please take further questions to /r/cpp_questions
Exclude all the good features and leave in the cruft? Didn't we do this same kinda of blase update with C++14? Why bother with this?
Is C++19 planned ? I thought it was going to be c++20/21 after 17.
Anybody knows why asio didn't make it to the list ? Is it because of some dependent feature not making into c++17 ?
I've seen exactly one person say something about a new two-year release cycle. I can't remember whether it was on Reddit or a blog, but it was probably someone who went to the meeting. Edit: https://www.reddit.com/r/cpp/comments/48zp05/what_we_added_to_the_c17_working_draft/d0o5bmo &gt; Also, it looks like we will be moving to a 2 year release process. So, we may be doing C++19, not 20. It sounds like it could be nice if there isn't too much extra "boilerplate work", but it doesn't sound finalized.
right, but to hold back until the "great" features are ready, is also not a solution.
While C++19 would be nice, its not clear which could be the next standard. Some in the committee tend towards a 2 year shipping model, others, especially implementers might not like it so much. Also it is the question, how often you can release an ISO Standard.
Oh, okay. So if it fails, we can just blame it on ISO ;)
operator dot was approved by EWG for inclusion in C++17. It got an initial review by CWG in Jacksonville, FL. We didn't get time for a second review before Friday plenary, given all that was in the queue.
Yes. C++ is on a time-based release schedule (now), not a feature-based one. If a feature isn't ready in time, it will not ship in that standard.
Wait. Did f(x) to x.f() get accepted or was the whole thing rejected? Last I heard (late last year) was that x.f() to f(x) was the only rejected half due to the possibility of creating unstable interfaces and that it would be revisited if/when modules were approved.
C++14 was intended to be a small extension over C++11, featuring mainly bug fixes and small improvements.
I suppose he was referring to the fact that you can use both UFCS and wrappers with overloaded dot operator to decorate existing classes easily. 
you are saying that all the files(cpp) are merged into a .o file then an .exe is created based on that library(.o)? further questions will be on /r/cpp_questions 
nobody knows
start by downloading visual studio or CLion and following some tutorials (here's a great bunch to follow along with http://www.cplusplus.com/doc/tutorial/). Make sure you understand inheritance, functions (and class methods), public/private/protected, pointers &amp; references, the operators, file i/o, memory management (new/delete) static variables, constants, scopes, and namespaces. C++ is an enormous language, good luck!
As someone taking an intro class in C++, when do I learn about memory management? Is that a commonly taught thing at lower levels?
Ya that isn't really "basic c++ programming skills", programming in an IDE is much different than just learning the language. 
Indeed. I was just pointing out C++14 was intentional, but C++17 isn't. To be honest it was kind of to be expected. There was way too many features to be included in such a short amount of time, at least considering past C++ updates.
As with any requirement, you should ask for clarification/details from those that set the requirement.
I disagree. I've been programming for a long time and doing that text editor GNU command line stuff is just so old school and slow. It's the 21st century and we have great tools to get us up and running! 
Wait, it costs money. Good luck with that.
"Knows enough to fuck everything up but not enough to be useful", or "normally wouldn't be hired ". Unless you come out of a C++ school or have a lot of personal experience i don't think there really is such a thing as "basic" in C++...
&gt; As it looks like, C++ will focus on a model, where major features get implemented in the major compilers first, and then get standardized with the feedback from that experience We can test modules already? How?
When you learn about pointers, usually.
If you use MSVC, see this link: https://blogs.msdn.microsoft.com/vcblog/2015/12/03/c-modules-in-vs-2015-update-1/ I presume there will be more modules stuff in the forthcoming VS2015 Update 2, but I don't know if /u/GabrielDosReis can tell us about that yet :-) 
Yes, VS2015 Update 2 will improve significantly the module experience -- thanks to feedback from early adopters, many of you lurking here no doubt :-). 
Inheritance with a non-virtual destructor is fine, if the destructor is protected.
Pls, no. I'm tired of these "visual studio operators". They can't do basic things if there is no button for that in vs.
Yes, one of the goals (but not the only one) of modules is to improve compile-time. That is essential. The design that is being examined by the C++ committee fully supports "header-only template libraries." The main point of discussion is whether macros can be exported from modules, and if so how. My recommendation is that you can use macros within a module (just like any source file or translation unit), but you can't expect macros that were active when a module was compiled to suddenly materialize when the module is consumed (e.g. imported.) That is "macro isolation." 
The gist is really to never use new at all unless you absolutely need to. I'm always amazed how many times students came to me and had trouble completing an assignment because they were just told to new/delete all the things. 90% of the time a simple stack allocation will work fine, produce simpler code and is easier to reason about or explain. 
Underrated comment.
Like I mentioned above, you need at least Microsoft's linker and stdlib, which come in one package with the compiler ("Common Tools for Visual C++ 2015")
Yes, and if you are using c++ 1y prefer smart pointers over raw pointers - note I said *prefer*.
15 years experience
I'm not sure what you mean. I've been programming professionally for 10+ years and 99.99% of my coworkers coders use IDEs. Syntax highlighting, autocomplete, and a robust debugger are wonderful tools that help you spend more time solving problems and less time fixing spelling errors and hunting to remember function names. I'm sure OP would appreciate you making suggesting on how to learn the basics of C++ quickly rather than questioning my capabilities.
I mix working and learning everyday! That's what being a programmer is all about. Also, I'd argue syntax highlighting, linting (real time error checking), and a debugger are extremely helpful with learning. Programming is very hard, btw :)
You've named some features. And the paradox is that the student doesn't know yet what features are important. The student sees only a subset that some specific IDE provides (while also hiding some part of the processing).
I would pick up both a data structures book and a C++ book; for instance, [*Data Structures and Algorithms in C++*](http://www.amazon.com/Data-Structures-Algorithms-Michael-Goodrich/dp/0470383275/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1457720311&amp;sr=1-1&amp;keywords=data+structures+and+algorithms+in+c%2B%2B) and [*Programming: Principles and Practice Using C++*](http://www.amazon.com/dp/0321992784/?tag=stackoverfl08-20). Of course, you can use any data structures book you like; some are better than others, but they all teach the same stuff. But when you're learning the abstract stuff at the same time as basic programming, it can be nice to see examples in your language. *Principles and Practice* is one that I wholly recommend, though, as an excellent introduction to modern C++. Also, be aware that there is way more bad C++ material out there than there is good C++ material. If in doubt, check out the [semi-official book list](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) or ask around here.
Want to learn to code? Want to learn C++? Struggling to follow your lecturer or books and tutorials written for experts? [Jumping into C++](http://www.amazon.com/Jumping-into-C-Alex-Allain/dp/0988927802)
Wow that has some great reviews, ill check it out thanks! Im still open to more suggestions too.
I have no degree at all and operate as a Senior Engineer with C++ and Assembly, so I worry that your methodology would underrate me.
Have you seen [this SO discussion](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list)?
My only real experience so far is with new grads. I would weight experience years similar to school years. With a senior title I would have increased expectations even that though.
Thanks Ive heard of the programming principles and practice as a good beginner book, I have been thinking about getting that one or a different one if someone had a good experience with a book. 
Not if they weren't struggling to answer the ones laid out. If they breezed through everything I had, sure, but if you're at the point where you've breezed through what I had preprepared, you don't need to answer harder questions. Really people of different experience levels will answer similar questions to varying degrees of completeness. The completeness and the method is what is impressive. People don't ask you how to do something like traverse a BST because they don't know how, they want to see how you feel out the problem as presented, how you are able to communicate your process, if you seek a thorough understanding of the problem before plowing ahead, etc. So asking for harder questions isn't gonna piss me off, but it's not really gonna win you any points with me either. I picked the questions I did ahead of time because I want to see how you work, the problems themselves aren't the point. So if you sat silently for five minutes staring at a problem and then wrote only the absolutely correct thing wordlessly, you would be far less likely to get a recommendation from me than if you took ten minutes and talked through a logical process and arrived at an answer that wasn't perfect, but acceptable. I might be impressed by the silent perfect answer, but I probably don't want to work with a silent perfection machine.
From what I see, proposals are typically discussed in the mailing list before being submitted to the committee.
They've just done that: [Add Reactions to Pull Requests, Issues, and Comments](https://github.com/blog/2119-add-reactions-to-pull-requests-issues-and-comments)
ah, at long last. awesome.
check out [MIT openCourse](https://www.youtube.com/watch?v=HtSuA80QTyo&amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb)
&gt; I have met precious few software engineering candidates with masters degrees who could do basic pointer manipulation. How does one pass an operating systems course without knowledge of pointer manipulation? Seems pretty key if you are hacking on some Linux kernel source. 
&gt; (I like currying but I wouldn't propose retrofitting it to C++ because it would be hell with overloads) Hell is an understatement; if this was a solvable problem, Don Syme would have solved it for F#.
And then have to `friend` every (now free) function that controls the type's invariants? Seriously, how does this help anyone?
This is exactly why we don't want `yield` in C++. 
They are, but only a single "version" of the proposal is discussed. And the discussion is only by a handful of people. In particular one cannot dynamically see there the feedback being incorporated into the proposal. This is important because changes lead to more feedback.
What specifically, and who's we?
&gt; if constexpr to allow branches that are evaluated at compile time. This is very powerful. Concepts UltaLite =) Looks nice, if it get adopted. &gt; Template parameter deduction for constructors This please - make_* functions are understandable design choice by anyone who using C++ for a long period of time, but for newcomers tend to think - "why they can't deduct types at the initialization site?!" &gt; Defining the order of expression evaluation Removing another WTF is always lovely =) &gt; operator. (dot) I thought it was rejected? Anyway - I still not sure how I feel about this. Can one define free function just like now you can define `operator&lt;&lt;`? It also hides object internals, and you can't acess them in any way. But from the proposal I get the sense that this can be bypassed using cast ref-to-val. &gt; Defaulted comparisons Hmm - I am not sure about this either, but we'll see. 
A few points of advice: (I tried to number the points below but reddit has a horrible markup, sorry, I don't want to fight it at the moment) (Point 1) Name your files *.cpp, *.cc or *.cxx, these are the widely used extensions for c++ source files, and it's quite weird for others when you don't. The most obvious issue here is github not syntax highlighting your code. (Point 2) You have undefined behavior in your code, when you say: int loopreset; loopreset = 0; for(int loopreset; ... You are actually defining two distinct variables named loopreset in two different scopes! And what's worse is that the inner loopreset is uninitialized so you get a random value in it. The correct way would be to just use: for(int loopreset = 0; ... // you don't need the previous ones. In fact, it's unidiomatic C++ to define a variable first and initialize it somewhere later in the function. Initialization is very important in C++ it has so much meaning, just take my word for this at the moment. (Point 3) This looks very ugly: float posx; float posy; float posz; float pastposx; float pastposy; float pastposz; float relposx; float relposy; float relposz; A much better alternative would be to define a struct like this: struct vector3d { float x, y, z; }; Then define your local variables as: vector3d pastpos, pos, relpos; Have fun, and be patient, it takes years to be a proficient C++ programmer. The language is not designed to be easy to learn or easy to use. It was designed to be awesome :)
The "basic programming skills" (in any language) requirement for interns almost always means that you are expected to understand language syntax and facilities, even if you don't actually know how to use them. This also implies knowledge of fundamental concepts like control flow, memory, variables, functions, classes, templates, etc, to the extent of knowing what they are and how to use them, even if you don't know how to use them effectively. A higher level explanation of the above would be "we want you to understand what we teach you." For example when you attend a seminar, or have an senior engineer/developer trying to educate you about template instantiation details, or the cost of virtual functions, or move semantics, you should not be asking what a template is, or what virtual functions are used for, or when copy constructors are invoked. With that being said, it's always a good idea to actually ask them what they mean when they say "basic skills."
&gt;Defaulted comparisons I really hope these will be explicitly declared `= default` or something, at least. Having the compiler define more stuff behind one's back sounds like a really bad idea to me.
Is this equivalent to Alexandrescu's static_if? edit: I see, it's a clarification / reduction of it. 
Seems there will be voting at Oulu: https://mobile.twitter.com/AlisdairMered/status/706192971662827520
[**@AlisdairMered**](https://twitter.com/AlisdairMered/) &gt; [2016-03-05 19:01 UTC](https://twitter.com/AlisdairMered/status/706192971662827520) &gt; Two more candidates for \#Cpp17 to be reviewed at \#CppOulu: A joining/simple\_thread class, and adding variant to the library rather than a TS ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) ^(Starting from 13th of March 2016 /u/TweetsInCommentsBot will be enabled on opt-in basis. If you want it to monitor your favourite subs ask its moderators to drop creator a message.) 
the universal call proposal was rejected, operator dot seems to find its way into C++17 likely.
What's the danger with these? If you don't use (call) them, then they won't be generated, if you use them, then you get sensible defaults. Nothing like the default copy-constructor breaking classes with e.g. raw owning pointers by default.
The releases aren't waiting for the great features - they come as scheduled. The great features just don't get included in a release until they are ready. The language standard isn't running on a continuous integration cycle - there isn't a new standard every time a new feature is added.
Because if I didn't declare comparison operators, it should signify that I didn't think about what equality means for that particular entity. Who knows what makes sense for one particular class, besides the author? Maybe, for some reason or external limitation, I just don't want a certain object to be comparable. Maybe there's a 1000 element array embedded inside a certain class, and whoever isn't aware of it may decide to compare them inside a loop. Nevermind whether it's a good idea in the first place, I'm sure someone somewhere wrote this kind of code, and maintainers now have to put up with its implications - I'm sure there are other reasons why comparisons may be costly, like trees or whatever. `bool operator==(T const&amp; rhs) = default;` is practically nothing, so why introduce extra implicit behavior, when it can be an opt-in feature?
yes, that's actually great news.
This code is structured uglily.
Well, looks like you get your wish. At least it's proposed to be opt-in only. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4126.htm 
Eh, it's useful for writing iterators quickly. Really it just lets you treat function state as persistent between calls, which can be nice, but not really necessary as classes are good for that too. 
constexpr does require compile time evaluation for constexpr variable declarations like "constexpr int = f();". if constexpr works analogously to this.
If you don't declare copy and and assignment for a a class with a 1000-element array member today, are you signifying that you didn't think what copying means for this particular entity? Equality and ordering are fundamental properties of types.
I'm not sure that I don't want it https://www.youtube.com/watch?v=_fu0gx-xseY
As far as I understand, Hunter is intrusive. To use packages from hunter, I would need to add `include("cmake/HunterGate.cmake")` to my cmake. With `cget`, instead I find packages the usual way with cmake, and then list my dependencies in a 'requirements.txt', to have `cget` automatically fetch them. People may not want to use `cget` to build the package, perhaps they would prefer to build the package manually. This is possible and doesn't require me to change my cmake(nor write `if(CGET)` in the cmake file). The other advantage of it begin non-intrusive is that other build systems could be used. Obviously, cmake is required for the distribution of the package, however, a project could use whatever build system they wanted. I don't see how you could have a non-cmake project(not package) work with hunter, but perhaps I am wrong. And finally, with it being non-intrusive, it can already build a lot of packages already. Both the cmark and zlib library was not changed to be built using `cget`. So, cmake projects that have no dependencies can already be built. However, with hunter, it looks like it requires changes to the project to be integrated into hunter.
Looks cool, gunna try and mess around with this next week
&gt; do we need a 'constexpr if' We need it, because it's not quite same as regular `if`, it's conditional compilation. And having a way to explicitly say that we want exactly this and nothing else is good.
For `vector` there's std::vector&lt;B&gt; bvec; std::vector&lt;A&gt; avec( begin(bvec), end(bvec) ); Not _terrible_.
I strongly disagree. This is useful, and will speed up lots of code, and ranges might even be able use it in the implementation details. It does not depend on ranges or concepts at all. And Herb Sutter blogged today, he expects a speed up of factor 2-4 for refactored code with this: &gt; And with parallel STL often you can just add std::par or std::par_vec, and your algorithm will speed up by a factor of 2-4 on ordinary hardware; http://herbsutter.com/2016/03/11/trip-report-winter-iso-c-standards-meeting/
Parallel algorithms will be in namespace `std` in c++17. They had their own `std::experimental::parallel` sandbox for the technical specification.
Before I watch the talk, have the authors looked at [STAPL](https://parasol.tamu.edu/stapl/)?
I fully support your point and I actually had asked the question on [std-proposals](https://groups.google.com/a/isocpp.org/forum/?utm_medium=email&amp;utm_source=footer#!msg/std-proposals/0Yb4SnPoAYk/JDcxxBJ2BwAJ), but I haven't got any compelling answer thus far.
I just find it clearer. It matches the conditionals in the C++14 loop more than connections of `&amp;&amp;` and `||`.
Is patching required because packages are doing something bad (and avoidable) in their cmake files? Is there a set of cmake guidelines which guarantee that a package will 'just work' in Hunter?
I agree, this seems like an oddball compared to other sorting parts of the standard library
What do you mean? You *can* pass a lambda or just a normal function as a comparator to a `priority_queue`. Or you can define an `operator&lt;` for Thing.
 struct ToastCompare { bool operator()(const Toast &amp;t1, const Toast &amp;t2) const { int t1value = t1.bread * 1000 + t1.butter; int t2value = t2.bread * 1000 + t2.butter; return t1value &lt; t2value; } }; Ewww. If there are any C++ newbies reading, don't do this. I assume the idea is to sort on `bread` first, and then `butter`; but what if I have a `Toast` with 1001 `butter`? The best way to write a less-than operation in modern C++ is to use `std::tie` to create a `tuple` from the struct members, which are then sorted in order: return std::tie(t1.bread, t1.butter) &lt; std::tie(t2.bread, t2.butter); This is both shorter and more correct. It's also arguable that it would be better to specialise `std::less` rather than use a custom comparator, but there are arguments both ways on that one. 
&gt; E.g. I need to do one step (just build) instead of two (build dependencies, build local project). It is one step with cget: `cget install .`. However, it can be two steps as well, which allows the dependencies to be managed by a system package manager, which can grab binaries instead of source files. &gt; If you want package that depends on non-cmake package No, I am talking about a project. That is I use `cget` to grab my dependencies(ie packages), then I can use GNU Autotools, or Meson, or Waf, to build my project. Also, I don't if this is possible with Hunter, but I can use cget without a project. So I can just install the packages to get executables. When I write `cget install jqm/cmark`, I can now run the cmark program. 
Hi Paul, thanks for sharing. Just one question: After reading your readme I have found some similarities with conan.io. Mostly: - Package retrieval. Don't care about build systems, just pick my dependencies. Conan has a similar spirit. - Easy-use cmake integration. Conan also generates a cmake file so integrating Conan deps into your existing cmake project is as simple as adding that file. - requirements file. As long as you are just defining dependencies, conanfile is a python file as simple as a dependencies list. - Written in python. The last item is key I think. We can talk with conan devs about common points and, if you like, integrate cget into conan as an addon or rewriting conan cmake tools by means of cget. What do you think?
"someone" here :-) We're keeping the lights on for LuaWrapper, steadily fixing some bugs here and there. PowerDNS relies on LuaWrapper, and we love it.
You don't mention what OS you're using, but some general observations: * On Windows, Visual Studio is *the* standard IDE. The ~~Express~~ Community version is free to download and use. Its "intellisense" is second to none. The only downside is that the compiler doesn't support the latest standards as well as Clang and GCC. * I use a Mac, and I can highly recommend CLion by Jetbrains (it's also available for Windows and Linux). The only downside is that it's a paid product (although they do offer a one month free trial). * QtCreator is another multiplatform IDE that is widely used. I've found it to be faster than CLion, though it's missing some handy functions that CLion has. It is free, though. * Lastly, if you're using Linux or MacOS then many people swear by Emacs. (Many other people swear *at* it, though.) It's not an IDE in the traditional sense, but it can be configured to do just about anything, if you're the kind of person who likes tinkering with that sort of thing.
On Macs xcode is pretty much the standard ide. Not saying that clion is a bad choice there or anywhere else though.
I have never used xcode personally, I just see a lot of people using it. I'm surprised it would have bad completion though, isn't it clang based like QtCreator?
May be solutions to following problems ? At least realization that such problems exist and we need solution for them. ## Exceptions (Why do not use them?) 1.) Slow, especially on hardware that is not optimized for exceptions. 2.) Code bloat, memory consumption. (Embedded systems) 3.) Hard to reason about program flow. (hidden flow) This about problems with variant proposal and strong exception safety. One need always to assume that everything can throw. 4.) Legacy code (but modernized) that do not use exception for decades now. 5.) Hard to implement. (Clang and windows exceptions.) 6.) Impossible to implement because there is no hardware support. Think about GPU (OpenCl 2.1, CUDA ) 7.) Exceptions across DLL boundary. ## STL (String, Containers, why not use them?) 1.) Exceptions. Allow not only to disabled exceptions but also to replace with custom system. (assert, debug_break ...) 2.) No ABI. Can not use across dll boundaries. Especially if compiled using different tool-chains. (libc++, libstdc++, MS VS2012, VS2013, VS2015 ...) 3.) Run-time guaranty. 4.) Slow speed. Streams are slow. Integer and especially floating point conversion to string can be extremely slower compared to other solutions. 5.) Everyone already have their own string. Partially because of Unicode but there are also many other problems. [QString](http://doc.qt.io/qt-5/qstring.html) [Unreal Engine String](https://docs.unrealengine.com/latest/INT/BlueprintAPI/Utilities/String/) and many more.
Xcode it standard IDE on OS X but it support for C++ is pretty bad compared with other languages. So CLion could be better alternative. 
We have at least one thread like this every week, go figure.
&gt; Package retrieval. Don't care about build systems, just pick my dependencies. Conan has a similar spirit. Yes and I looked at conan before writing this. However, for finding dependencies in a build-independent way, I think its better to use pkgconfig rather than write a new dependency tool. Especially, since pkgconfig is already integrated with many build systems already. &gt; Easy-use cmake integration. Conan also generates a cmake file so integrating Conan deps into your existing cmake project is as simple as adding that file. However, using the generated cmake is a little intrusive. Instead cget creates a toolchain file with the configuration, and places everything in the same directory so its easier to find(it actually symlinks everything into the same directory so it know what file belongs to what package). &gt; Written in python. Yes, however, for windows cget requires python 3 because of the symlinks. Support could be written for python 2, if it was necessary, however, I don't think it will matter because windows is planning to include python 3 in the future. &gt; The last item is key I think. We can talk with conan devs about common points and, if you like, integrate cget into conan as an addon or rewriting conan cmake tools by means of cget. Yea, we can definitely look at integrating conan and cget together. The nice thing about conan is the ability to install binaries. I would like to support that at some point.
This looks nice - will check it out on monday :)
&gt; I know what you are trying to say, and I think its a poor example of that It's not poor, it's simple - to demonstrate technique. Actually it's just a way to start discussion, see more questions below :) What about build options of 3rd party packages or platform switches, now you need to introduce "new language"? Why not use CMake? &gt; In the future, I want to add support for writing the requirements as a 'requirements.cmake' Just for your information user can load cmake module `config.cmake`. Will looks like this: https://github.com/headupinclouds/gatherer/blob/d246be354c2a4b9d786752d212aee4cf8ef9fa83/cmake/Hunter/config.cmake ? &gt; Then build it using cget install $DEPS . Does this build two variants of root simultaneously? Can I use both on my local machine, say root-A and root-B? If so how my project know what root directory I need to use exactly?
No. I'm fine with combining Qt and boost/std in my code.
Multiple naming styles really does not bother me. I do get irritated with libraries that have non-standard iterators and containers. For the closest thing to an official style guide, take a look at https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md 
The functions `new_userdata` and `set_userdata` now have different names (`new_usertype` and `set_usertype`). If you were using the develop branch of sol that I was maintaining, this was a change from over a year ago and you shouldn't be affected. I also believe `table::create_table` is now just `table::create`, with support for passing in arbitrary key/values to initialize the table with.. Everything else is not only identical as far as API is concerned, but orders of magnitude faster in speed. And yes, LuaJIT integration is seamless. It requires 0 changes, and we even provide a compatibility layer on top of LuaJIT (it's talked about in the docs in the api reference manual -&gt; compatibility.hpp).
&gt; It's not poor, it's simple - to demonstrate technique. Yea, but in this example it doesn't demonstrate its usefulness, since with CI you would just use a different variant in the matrix. &gt; What about build options of 3rd party packages or platform switches, now you need to introduce "new language"? Why not use CMake? Thats what 'requirements.cmake' would be written is cmake. Also, I may add the ability to add some conditions in the requirements.txt, like this: ``` boostorg/boost@1.58 --when FOO_WITH_LATEST=On boostorg/boost@1.57 --when FOO_WITH_STABLE=On ``` &gt; Just for your information user can load cmake module config.cmake. Will looks like this: https://github.com/headupinclouds/gatherer/blob/d246be354c2a4b9d786752d212aee4cf8ef9fa83/cmake/Hunter/config.cmake ? That looks horrible. It looks likes that should be done in the toolchain file. &gt; Does this build two variants of root simultaneously? You wouldn't built it simultaneously when using CI. Each one would be a separate configuration in the matrix. &gt; Can I use both on my local machine, say root-A and root-B? To use different variants, you need to use a different prefix. So you will need to write `cget install -p cget/A .` and `cget install -p cget/B .`. I may add in the future a way a better way to manage multiple configurations, I am not sure what the best way is. &gt; If so how my project know what root directory I need to use exactly? Because the toolchain sets the `CMAKE_PREFIX_PATH` to the root directory.
&gt; That some people insist on using Pascal, Java or C# naming conventions is frustrating and distracting. Go research C++ libraries from the 90's before Java and C# were born.
&gt; I've found it to be faster than CLion, though it's missing some handy functions that CLion has. Can you elaborate what are those handy functions?
It does slightly bug me when I see multiple different naming conventions in a single project, but it can also be useful for knowing what function/variable came from which library. Of course, this is what namespaces are for, but hey.
You're not alone op. I learned and used Java a lot before I looked into c++, and using underscores instead of camelcase feels weird (probably a very unpopular opinion ITT). Also, classnames without a capital first letter would be very hard to make a habit for me...
Lua is much, much easier to sandbox. The only functions that are available are functions that the surrounding program makes available to Lua. I don't have experience with V8, but embedded python is notoriously hard to sandbox. This means that while it is great for running configurations, it cannot be used to run untrusted code. As an example, a while ago I was writing a game in which players could define functions to make different bots. Rather than making my own language for the bots to use, I was able to use Lua for it. It also makes it very easy to place restrictions on the amount of memory and computation time that can be used by a script, which keeps unruly scripts under control.
In my personal experience, xcode's main shortcomings is incredible buggy IDE with c++ projects. Xcode really struggles with syntax highlighting and code completion with c++. Not only that, it also places breakponts on the wrong line, same goes with warning and error highlighting. And this issue existed literally since version 4. 
In the examples, isn't this: &gt;bopvalue = beep.bop() meant to be "beep***:***bop()"?
Ooh, very interesting. I had run into a similar issue about a year ago and needed to write my own bindings, and so it is always fun to see how multiple people tackle the same problem. Out of curiosity, how did you handle the type-checking when converting between Lua userdata and a C++ object? Curious because that was the part that I found the hardest when writing the user bindings.
From the docs: &gt; If you turn exceptions off and are also completely mad and turn off run-time type information as well, we fallback to a id-based system that still requires you to specifically list the base classes as well. also from Line 2454, which takes the no RTTI/exception branch: &gt; // Lol, you motherfucker Historically, many game engines have disabled RTTI and exceptions for a variety of reasons (no vendor support, bloated executable size, slow). As a consequence, it's not unheard of for older game engines to develop an alternative solution that doesn't use either. There might still be RTTI support, but it's likely a homegrown implementation that's more efficient and consistent across platforms. While modern compiler implementations have improved, as well as console hardware, switching over would be a lot of work with little to no gain. So instead of resorting to name calling, you could instead try to understand why a developer might take a route that doesn't quite fit your worldview of C++.
I use Kdevelop as an ide, fast and lots of useful features. Not sure how easy it is to install on windows though
I use QtCreator with Cmake, is pretty good.
I would like it to be possible to remove non-top() element from priority queue as well. Even when I use std::pop_heap directly, I can't do that. Is there a way, without rebuilding whole heap from the removed element position?
Looking at the code? How do you confuse them?
1. Yup, not a standard way to do that. Generally most people want either all unicode or no unicode anyway though. 2. Yep, 3 of them are the same in every locale. Locales change more than code-set conversion though of course -- they also affect thousands separators, decimal points, etc. 3. You allocate them with new, then hand them into a `std::locale`, then apply that to a stream with imbue. Here's an example with a numpunct facet but I believe it works the same for codecvt facets: struct comma_separator : numpunct&lt;char&gt; { virtual char do_decimal_point() const override { return ','; } }; void test_VSO_159700_locale_should_support_user_defined_facets() { stringstream str; locale loc(str.getloc(), new comma_separator); str.imbue(loc); str &lt;&lt; 1.5f; if (str.str() != "1,5") { puts("locale didn't support user-defined facets"); exit(PM_TEST_FAIL); } } 4. Don't think any such good information exists. Strongly recommend avoiding locale and iostreams machinery unless you absolutely have to....
How about `x | g | f` as in the usual C++ range libraries' syntax? Or, rather more extremist, `x |&gt; g |&gt; f` (or `x |&gt; (g &gt;&gt; f)`; or `(g &gt;&gt; f) x`; or `(f &lt;&lt; g) x`; etc.) as in F#? IMO, if we're being idealists anyway, the `.()` are all a bit noisy and we can do better. I.e., your proposed chaining syntax doesn't really satisfy either side IMO (or me, anyway &gt;_&gt;).
Yeah, it's absolutely abhorrent, and everyone should adopt CamelCase. Underscores are obnoxious and stupid. A couple years ago, I wrote a whole library in underscore_case, to try and get over my distaste. After that experience, I want to burn underscore_case with fire. It is a *lot* less expressive, and yet, *longer*.
Great for users, basically untenable for compiler/stdlib implementers.
&gt; How about x | g | f as in the usual C++ range libraries' syntax? because we already have | as bitwise OR, and the next popular use is dot-product in vector maths libraries (```(a|b)``` looking like bra-ket notation, which pre-dates unix pipes). Some people have stretched it for piping, 'transducers' but I strongly dislike that. &gt;&gt; Or, rather more extremist, x |&gt; g |&gt; f That's better, but I'd still prefer straightforward extention methods: they do both jobs, and it would make working with existing class base source-bases more pleasant (demands change over time, libraries grow , get split up, or merged). The ```|&gt;``` symbol is harder to type than ```.``` 3 keypresses vs one. There's usually at least one other parameters r.e. the bracket. The common binary functions 'add','multiply' etc have operators already. &gt;&gt; or (g &gt;&gt; f) x; or (f &lt;&lt; g) x; etc.) again those already mean 'bitshift' and have subsequently been abused for 'streaming operators', giving them yet more uses would be awful IMO. My use cases have been graphics, where maths &amp; bit-bashing co-exist. &gt; if we're being idealists anyway, the .() are all a bit noisy and we can do better. If people really don't like ```a.foo(b)``` they might aswell go for an entirely new language , based around the functional ideas from the outset (haskell inspired syntax with spaces separating arguments and so on). The people complaining evidently don't care so much about IDE tools, so they wont mind not having all the autocomplete etc. Alternatively there's jonathan blows JAI language, he doesn't like a.foo(b) either (but I like a lot of his other ideas). I've always seen C++ as a multi paradigm language.. I don't like java-style pure OOP, but there are times when OOP does work. I don't think all the functional ideas (like currying) retrofit into it. There's a whole family of 'hybrid' functional+OOP languages (Rust, Scala, Swift) and I think C++ fits there (syntactically). &gt;&gt; I.e., your proposed chaining syntax doesn't really satisfy either side IMO It's not 'proposed', it's what's there *already*, and it's popular enough that people suffer the coupling hazards to use it. With UFCS we're just trying to fix that hazard. it's less friction an change, and greater usability for existing code.
Exceptions and RTTI are part of standard C++, and have been since before there *was* a standard. If you choose not to use exceptions and RTTI, then you have to accept that you're using a restricted dialect of C++, akin to people working on embedded systems who can't use `new`. Put bluntly, it is game developers who have to adjust *their* worldview and accept that exceptions and RTTI provide useful facilities, rather than just raging at the rest of the C++ world for having the gall to use the language *as specified*. In this case, the library developer has absolutely bent over backwards to accomodate game developers and their dialect of C++. So they buried a cheeky comment ~2500 lines in to their own source file, probably referencing all the extra work that they've had to do as a result. Rather than criticising, I think thanking the OP for putting in the extra work is probably the better course of action. 
i'd like to know it'll be accepted before putting the effort in
&gt; That looks horrible. It looks likes that should be done in the toolchain file. So what exactly makes it better than setting conditions in toolchain? Just for your information some variables not defined in toolchain files and will be only defined after 'project' command executed, example: http://stackoverflow.com/a/31152886/2288008 &gt; You wouldn't built it simultaneously when using CI. Each one would be a separate configuration in the matrix Travis is not only CI in the world. Jenkins share all environment between builds, so everything will be built simultaneously. &gt; So you will need to write cget install -p cget/A . and cget install -p cget/B Just for your information if project Foo use configuration A and B, then Hunter calculate prefix for A and B automatically (see [config-id](https://github.com/ruslo/hunter#config-id) and [toolchain-id](https://github.com/ruslo/hunter#toolchain-id)). And if some project Boo use the same configuration A then root directory root-A will be shared between Foo and Boo (again, detected automatically). So I'm still thinking that intrusive is good approach. &gt; Because the toolchain sets the CMAKE_PREFIX_PATH to the root directory As far as I know not all projects respect CMAKE_PREFIX_PATH (unfortunately). Also what about non-cmake projects?
It doesn't bother me. But it does make me feel more relaxed when an entire source file uses 1 uniform convention.
The short answer to all of your questions is "everything related to `std::locale` is an embarrassing clusterfuck disaster". It's a very poorly designed API that sorta pretends it exposes useful platform functionality, but in practice it doesn't. Converting between UTF-8 and wchar_t is basically it. boost.locale provides std::locale objects that have all the functionality that you'd probably expect to have built-in, but even then locales are basically only useful for imbuing streams, as the API for anything else is awful.
Xcode is *bafflingly* bad at C++. It has to be either still using their pre-clang stuff for IDE functionality or doing something very wrong because autocomplete and jump-to-definition basically just don't work for C++ (the refactoring stuff doesn't even try to work, which is probably a good thing). YouCompleteMe+CTags in vim are dramatically better, and while YCM is pretty good, ctags is a very low standard. One of the weirder parts of writing obj-c++ in Xcode is that you can be witing c++ and getting utter nonsense out of autocomplete, but then the instant you type something that looks like it could be a message send you suddenly get surprisingly accurate autocomplete with documentation.
On Linux, eclipse. Better vim emulation than clion and doesn't just work with cmake. Better indexing and features than qtcreator (unless you're actually using Qt, perhaps). 
Regarding the [order of evaluation proposal](http://open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0145r1.pdf), it says: &gt;the order of evaluation of an expression involving an overloaded operator is determined by the order associated with the corresponding built-in operator, not the rules for function calls. However it does not explicitly mention short-circuiting. Is this also proposing that overloaded `operator||` will short-circuit, or not? It would be good if the paper clearly specified whether it did or did not. 
Ahhh, so close to being perfect! Fixing it up now. EDIT: Annnnd fixed.
Similar project: https://github.com/jeremyong/Selene
We are much faster than Selene (https://github.com/satoren/lua_binding_benchmark/ - but to be fair a lot of frameworks are for simple operations) and, for user-defined types, sport a different interface that (I believe, but this is mostly syntax-pissing contest) is easer to grok and use. Also, last I checked, Selene was struggling to get LuaJIT compat.
I guess you are right, even C11 is not fully supported. But it appears that they have started to up their game lately
To expand on why games often disable these: RTTI and exceptions are well known as causing a cost even to code that doesn't use them itself - RTTI adds memory use by annotating every class, and exceptions add both memory and performance overhead in _every_ function. The latter is especially not appreciated in games, where performance is king, although the former isn't exactly appreciated when you're up against a memory budget - the PS3 only had 256MB of main RAM which had to be shared with the OS! For something the size of a modern game, it very much feels like developing on embedded hardware and a lot of the same restrictions on the use of C++ features apply. Plenty of older games didn't even use new :) I expect use of exceptions and RTTI to go up as newer hardware makes the costs appear relatively lower, but a lot of game engine codebases are _seriously old_.
I guess it's up to the people making the libraries to call them what they want. However, try go looking at PHP code. They have some weird naming inconsistencies in their core language.
Namespaces
I can attest to that. The cost of exceptions on x86 Windows are extremely high, and Microsoft can't change it without breaking ABI. Seeing as the VAST majority of games are compiled for 32-bit hardware, that penalty can be extremely steep. Note that, however, on x64 machines, Windows has a new unwinding mechanism that, from the talk I watched, is supposed to be 0-overhead. I don't know what the state of that on x64 \*Nix machines or OSX machines are. I would assume the unwinding done by them is also fairly fast... but again, most games are run on not-*Nix.
Oh, ok. But how come the standard does not use capitalized class names? For instance std::string ?
Do not forget http://codelite.org/ I use it for cross-platform software (Linux / Win) successfully. I develop GIS software.
OCD as in Obsessive Compulsive Disorder? I hate the coding style at my work with a passion. I can still see the benefits of everybody following the same conventions. If you are looking for a template, the Google C++ Style Guidelines come with reasonable explanations at least: https://google.github.io/styleguide/cppguide.html
So you never use STL?
It's amazing how under-represented Eclipse is in these comments. I love Eclipse CDT, it has the most complete C++14 support of all the IDEs, it's cross-platform, it's free and it has all the neat features you expect from an IDE.
There are no guarantees in life.
There are very few cases in the grammar where this could be a problem. Most of them are gone with C++11 curly bracket initialization, the `T()` ambiguity (default-construct `T`or call function `T` with no arguments) now can use `T{}` in the former case. Another one is `T * x` (define a pointer to `T` or multiply `T` by `x` and discard the result?), and is rarely ambiguous.
How does this compare to build2's bpkg ? (see https://build2.org/ )
Visual Studio is hands down the best, people are making other IDE's to mimic VS but none of them are remotely close. For Linux I use Code::Blocks and for OS X I use notepad/sublime because all other ide's are garbage for OS X. Emacs I felt was not fluid in any way and the few months using it I kept finding work around a for all of its quirks and issues rather than coding.
 int originalDataSize = strlen(str); You are assigning value of type `size_t` to variable of type `int`. uint8_t* compressedData = new uint8_t[originalDataSize * (101 / 100) + 320]; You are using value of type `int` to calculate size, without any kind of overflow check (possibly yielding in undefined behavior) and then passing it to operator new, expecting value of type `size_t`. Both of these are causes of security vulnerabilities. `101 / 100` always yields 1, since it is not floating division. What is the point of such division? Aren't the braces wrong? static int Compress(uint8_t* input, uint8_t* output, uint32_t inputSize); You are using variable of type `uint32_t` as indication of size of something in memory. `size_t` is more fitting for this.
It's not: there were byte order marks in the program: I thought I had fixed almost all of them already, but I may have missed a few. Let me check the files to be sure.
I think it's fine too. Having multiple styles can look a bit messy, but that's as far as the problems go in my experience - and having all the code look the same is no defence against that. If there are any benefits, they just don't seem to add up to anything I've ever found useful. I'm well aware this is a a minority viewpoint, so I am always very careful to lay my code out exactly as specified when people are paying me to write code for them.
this. We arent living in 80s anymore, today, tools are inteligent enough for us to provide some real feedback to the programmers.
Vim + ctrl-P + youcompleteme + ... is actually a pretty good setup. 
These are indeed some handy features, i might have to give a proper try to CLion in the future.
Yeah, they were there. But don't worry: I cleaned up the file and updated the release (and actually double-checked by trying to compile it myself, and it worked). I gotchu, fam.
Yes exceptions are usefully but have also a lot of problems, not only speed and memory penalty. ## Exceptions (Why do not use them?) 1.) Slow, especially on hardware that is not optimized for exceptions. 2.) Code bloat, memory consumption. (Embedded systems) 3.) Hard to reason about program flow. (hidden flow) This about problems with variant proposal and strong exception safety. One need always to assume that everything can throw. 4.) Legacy code (but modernized) that do not use exception for decades now. 5.) Hard to implement. (Clang and windows exceptions.) 6.) Impossible to implement because there is no hardware support. Think about GPU (OpenCl 2.1, CUDA ) 7.) Exceptions across DLL boundary.
You can't implement a parallelized std::accumulate as it is required to perform a left-fold operation. parallel::reduce explicitly lifts this limitation.
In the same token, not having exceptions causes plenty of problems: 1) Forces 2 kinds of error-handling for middle-ware / library developers 1-a) error-propogation - if you can't handle all cases, you have to forward to the user at the call site to handle the errors 1-b) crash - if you get an unknown error and you don't want to propogate, logging and crashing (or not-logging and maybe even continuing silently) is your only other alternative for correctness 2) Thanks to [1], you now cannot write generic code to handle large amounts of work if there are error codes returned: for example, your typical error-code-or-result class will not play nice with `auto`, and will not implicitly convert to the desired result class in generic code, which means you're back to hand-writing or wrapping things just to check errors all along the way 3) error-code-in-out params: overloaded functions everywhere to handle errors (or perhaps not handle them at all?) 4) how do you error-code a constructor or a destructor? Out-params? But then you have an object with invalid state but it "finished" constructing, so by the rules of the language it's a valid object. Now you need `if ( obj.is_initialized() )` everywhere (look familiar?) There's also another kind of error handling that mature C libraries do (libjpeg libpng etc.), and it's basically `longjmp`-ing around... which is like how exceptions work, but without any of the stack-unwinding or safety guarantees. The control flow remains hidden just like with exceptions... but let's be fair: why is the control flow of a piece of library code you may not even be able to see (because you're getting the compiled result) something that matters? Control flow would cut early in an error case too, you just have an infinite increase in the number of 'goto' and 'return' between you and where the error happened. 
Yes but all this problems are already solved to some degree in existing libraries, games engines and so one. Because this problems existed for a long time already. So there is simple no point to spend years to refactor code base to use exceptions. Especially if you simple can not use them because no compiler ot hardware support. &gt; 4) how do you error-code a constructor or a destructor? Just this one, use something like 'make_something' and on the other side it will be discouraged to use exceptions in destructor any way. 
&gt; Was it not just C++17's library part, not whole? Yes, ever since C++11, Microsoft has been playing this little game of announcing their compiler became feature-complete\* (and the fine-print is that it's library feature-complete, which sometimes isn't even possible without the missing language features).
 1. Errors happen. Nobody writes perfect code, and even if they did, hardware fails, memory gets corrupted, etc etc. Error happen, and there are three ways of dealing with that: a. Ignore them. This is arguably acceptable on highly-constrained systems with fixed inputs, but certainly not for general-purpose computing b. Return error codes (or equivalently, use an extra out parameter), i.e. C-style error handling. To ensure correctness, you then need to check the return value of every single function that can possibly fail, and probably forward any error code up to where it can be handled. Sort of like doing manual stack-unwinding, really. c. Use exceptions and let the runtime jump to the appropriate handler, firing the necessary destructors along the way. Of course, not checking for errors is going to be fastest. It's also the wrong thing to do in the overwhelming majority of cases. Of the other two options, I would be very surprised if exception handling on modern systems is slower than having `if` statements after every single failable function call. I recall reading that the way exceptions are handled in the Itanium ABI (used on Linux and Mac) causes zero runtime overhead if an exception is not thrown. I suspect this is not true when correctly checking all error codes. 2. Sure, on resource constrained systems there are all sorts of limitations. There are systems where you can't use `operator new` or `malloc()` for example. A 2016 gaming rig with 8 cores and 16GB of RAM running Windows 10 is not a resource constrained system. 3. This one is perhaps arguable, but I'd note that programmers in Java, C#, Python, JavaScript and many other languages don't have a problem following their program flow, and exceptions tend to be used much more pervasively in those languages than in C++. 4. Exception-unsafe legacy code is of course a problem. But as with so many legacy code issues in C++, I don't think it should prevent us from using best practises in 2016. 5. Perhaps they are difficult to implement in the compiler/runtime, but this seems to be a solved problem. I'm willing to bet they aren't the hardest implementation detail the C++ standard demands, in any case. 6. I don't know about OpenCL, but CUDA and (for example) the Metal shading language do indeed restrict you to a subset of C++ within that code. For example, it's generally not possible to use `new` in GPU code. Does that mean we should ban free-store allocation in CPU code too? 7. I'm afraid I don't know what "exceptions across DLL boundary" means :-) [EDIT: Formatting]
It depends entirely on what you want to be doing with your career. Not all fields require working on GUIs. As general advice, though, I'd recommend familiarizing yourself with [Qt](http://www.qt.io/developers/), at least, since it's fairly ubiquitous, if not quite universal.
Besides of what has been written in regards to Qt, in terms of GUIs C++ role has been moving down the stack with the GUI code written in Lua, JavaScript, Java, C# with C++ providing that last mile in terms of graphics performance when the respective code quality of the JIT/AOT compiler isn't up to the required performance. On games, nowadays C++ is usually used at the engine level,with game play, UI and scripting done in another language. On mobile OSes only Windows Phone gives first class treatment for gui applications written in C++ (check C++/CX, C++ WRL and XAML), iOS and Android relegate C++ code to library code as none of the platform APIs are really designed with C++ in mind. However Qt rules on automation control and car infotainment systems. So it is really a matter into which direction you want to build yourself.
I never thought of using std::tie for this. Neat!
Of course not checking for errors is really really BAD ! &gt; causes zero runtime overhead if an exception is not thrown Yes but some times they throw and this cost a lot of time as I know. Rust language show that Error code can work as well if there is language support for it. Finally I do not want to stop using exceptions. I only want that exceptions user recognize that there are a lot of C++ code where exceptions are not used. And that it is simple not possible to force exception into this code. And yes I want to ban naked `new` and `delete` :) &gt; I'm afraid I don't know what "exceptions across DLL boundary" means :-) Throwing exception in one dynamic library and catching it in another.
It's a nice thing to learn. Not required for all fields, but hey, you're younger and won't lose anything learning it. Most GUIs work in similar ways in most languages, so you still would have some basic understanding of how they works and knowledge would be translatable or at least, relatable.
Adding support to the Qt sentiment here. Qt is widely used and useful beyond GUIs, so familiarizing yourself with it will be useful for your skill set.
I actually like this benefit too, but only to a certain degree. It can definitely get unwieldy if you have too many styles.
Piggybacking on this - you should try JUCE - it's a great cross-platform development platform. In my own experience it's been a lot better than Qt. I was recently put in charge of a new app project at my company and using JUCE for it was one of the best decisions we've made. It also makes GUI development a lot easier than similar frameworks I've come across.
I think the main difference is that `bpkg` uses the `build2` build system while this uses cmake.
What about emacs + projectile + cmake-ide + rtags + company-irony? 
Emacs is an IDE. 
I'm not saying I don't use STL. I'm saying its stylistic choice is categorically inferior. Which person in their right mind decides to sacrifice 26 out of 63 perfectly useful symbols, and pretend they don't exist? If you allow for uppercase &amp;ndash; like normal people who aren't shooting themselves in the foot &amp;ndash; you can do this: struct A { int a; }; A a; How do you do this with underscore_case? You don't. You're constantly tripping all over yourself when you're naming things. The lack of uppercase vastly reduces flexibility. It requires consistently using longer and uglier names, and it's not obvious from a name whether it's a type, or a method, or a member.
Would you be going over some of the techniques/Designs/modern features, you may have used in this library? 
A compiler is not a program that you can "open" inasmuch as they are not typically run interactively; they're usually invoked once, either manually or by some other tool, producing a library or executable given some source code. All that said, you're going to have to be a whole lot more specific if you want us to help you with this issue. What operating system are you running? Which compiler(s) did you download? Where did you download them from? How did you install them? Are you using an IDE?
&gt; Windows does not and never will (to the best of my knowledge) provide a UTF-8 locale Never say never ;)
Got you, fam: check the latest release for the functions that work like you expect them to.
We cover the features we've implemented in the documentation, but we don't talk about implementation techniques. It can be summed up as: templates templates templates templates templates templates templates templates templates templates templates templates templates templates templates templates templates templates templates templates.
Welcome to 1995.
In all seriousness, though, a lot of this library does rely on template metaprogramming techniques. At the core, we have stack abstractions with are templated by type and have SFINAE used to enable using single functions from the lua C API to cover many of our use cases. We then use compile-time booleans propogated into classes (see `typedef table_core&lt;true&gt; global_table`) that give the implementation hints for potential optimization points. After that, we use templates to cover both the entry points and the exit points of lua, making sure to use the same types on both sides so that rather than guessing at what type it is by using a switch of `lua_type` or something, we instead assume the user knows what their doing and that the signature of functions indicate exactly what a user want. This works out extremely well, as C++ is a type-rich language. The best part is, there's some additional performance we can get that we've left on the table because there's a certain feature that hasn't been standardized in C++ that I am hoping will, and if it does we can burn function pointers into the assembly at compile time and basically avoid transporting them through some various weird ways in lua. Everything from there just builds on top of that, exponentially. For example, `int arf = mytable["arf"];` generates a proxy type, and that type is templated on the key you use (`"arf"`). Based on whether you set or get something to that proxy, we can infer the type you want and Do Right Thing, giving us a kind of return type polymorphism. Same goes for function_result and other nifty things. Finally, we perform further optimizations by grouping things together, taking advantage of the fact that if you want to get 5 different keys from the same table, calling `std::tie( a, b, c, d e ) = mytable.get&lt;int, int, std::string, bool, double&gt;( "a", "b", "c", "d", "e" );` will only push the table once, get all the values, and then pop the table, rather than push the table, get a value, pop the table, etc... this is essentially a form of Batching, and like any high-performance system, batches are KING when it comes to increasing throughput and getting performance on the up and up. The other form of batching we do is for "chained" or "tunneling" queries, where someone does `mytable["a"]["b"]["c"]`, and they just burrow into a table. Well, before you would get the proxy for the first operation, save the table, pop off the table, then push that same table, get the next proxy, and all the way down to the end... We enabled lazy evaluation here, so group the keys into one tuple, then perform a single `traverse_get`, which puushes teh target table once, and each subsequent table only once, before popping them all off the stack at the very end. It's very nifty to do things this way.
If you wish to avoid their special macros, then perhaps FLTK or GTK would also be fairly acceptable. Qt is a nice one though, I'd recommend learning it because eventually you'll want to learn how to write guis for your applications because console interaction is comparatively limited or difficult for more complex programs.
It used to bother me, a bit. Not anymore.
Actually, the Qt guys seem to focus more and more in QML leaving C++ for the infrastructure. This is quite visible in mobile OS support where only Quick Controls are being updated, with C++ widgets left in their desktop world. But Qt wasn't like that, you could write applications in pure C++ in older versions.
Independently verified.
Awesome .. I will def. check it out... 
&gt;Emacs is an IDE. Emacs is an OS. FTFY.
Depending on your platform. - Windows: Visual Studio - OSX: Xcode - Linux: probably Code::Blocks.
GUIs change too much and don't take a lot of CPU time. Build the core of your app in C++ and integrate with some scripting language (Python, Lua) for the GUI.
Seems like the good advice in this thread is already getting upvoted, but I would advise you to learn UI and UX in general if you're interested in creating interfaces. I've never done any interface stuff with C++ but I would encourage you to look into HTML/CSS/JS if you're truly interested in this stuff. Web interfaces are pretty much the new standard and even desktop apps are utilizing the web stack thanks to Electron.
I'd be very happy to be wrong!
Technical hint: https://readthedocs.org/ is much more powerful than github wiki
Making GUIs is one of the least rewarding forms of programming. It is tons and tons of difficult but uninteresting work to make something that is merely OK. You really don't learn that much more than how to use the API of whatever toolkit, which will probably change loads a couple years after your experience. Using a particular C++ GUI API is not really going to teach you how to design a better interface. Good design and GUI programming are two different things.
No need to learn GUI programming, everything anyone wants to use will be in the cloud soon. /s +1 for Qt, great toolkit. And don't accept too much of the FUD about "it's not c++" or "it uses a code generator". 
You need to consider the original purpose of textdomains. The same string, in different programs, might deserve a completely different translation. Within a program, you can use contexts though ...
I personally agree that gui is the least rewarding of things I've tired, but I know people who love it (although none of them happen to be particularly strong c++ devs). You can learn a ton about even handling, threading, etc.
I don't see how something contains more meaning just because I know weather it's a type or a variable. Camel case is harder to read. There is a study where eye trackers were used to compare the two styles: http://www.cs.kent.edu/~jmaletic/papers/ICPC2010-CamelCaseUnderScoreClouds.pdf Camel case identifiers took 20% longer to read, which severely impacted code comprehension.
&gt; would I need to use GUI development? Honestly, I'd suggest learning how to construct user interfaces using HTML/Javascript. You can then implement performance or library-specific functionality and extensions using plugins, or use NodeJS/Electron for complete browser-independence. The future is quickly becoming multi-platform with an emphasis on mobile phones, tablets, smart TVs, and browsers at the front-and-center for consumer UI. Modern HTML techniques can make for a seemless cross-platform experience. &gt; I plan on being a C++ developer in the future (I'm 16 now), and I already know a good amount of C++. It's just a language. Focus on understanding fundamental principles of design and analysis. Put these principles to use in whichever language you prefer for practice, but always be prepared to switch things up to meet the needs of your customer and the job.
any decent understanding of C++ should also come with decent understanding of how Operating Systems work. There should be a class for that when you study Computer Science. Operating system covers topics of memory management, threads, processes, synchronization, I/O. All the under the hood stuff that C++ programmer should be aware off
Yes, and DO use Qt. If for no other reason, it will force you to learn event-based and asynchronous programming. Also, Qt is not only a GUI library; it's a nice platform abstraction layer (processes, files, networking, etc). I use Qt extensively at work and it's OK. Many people object to its 'keywords' (slots, signals, meta-macros, etc) and precompiler (moc), but you won't even notice moc if you use Qt with cmake. Things I mostly ignore in Qt are its 3D classes (QVector3D, QMatrix4x4, etc.; for that I use glm) and containers (whenever I can I use STL; even though Qt's containers have added STL methods like begin and end).
thanks, I'll check them out and yeah, I'm primarily interested in STL tricks, not gen C++ ones
Thank you very much dude! I hope to be able to test it in this afternoon \^_^
"Scripts" are interpreted, by an interpreter (a script is literally a set of instructions to be followed by some other program, the "interpreter"). C++ being a compiled language, the source code is generally referred to as "code" rather than a script.
Yeah sure. The benchmarks are for multicore as well as for multiple nodes just like a usual mpirun executable. I've run it on hundreds of processes on more than 20 machines with qsub.
&gt; CLion will offer to add #include &lt;vector&gt; at the top of your source file if it's not already there QtCreator does this too (but in a more manual way) : if you use a type which isn't included and right-click on the type it will propose to include the file defining this type. &gt; CLion can automatically generate a skeleton implementation for a member function in a cpp file, given a declaration in a header. QtCreator does this too : write the prototype of the function, right-click on it and it will generate its body in either your header or a matching .cpp. However it won't intelligently add the `return nullptr;`. Also you can write your code inline in the header and by right clicking in the class name you can refactor to move all the definitions to the .cpp. &gt; The current beta version has support for going the other way too: if you write a member function definition in a source file, CLion can add the declaration to the header QtCreator does this too. &gt; CLion is just great at code generation generally. Getters and setters (albeit with unchangeable lowerCamelCase Java-y names) for private member variables for example, or a constructor taking all members. It can do these inline or separate source and header, as you choose. QtCreator does this too (add a Q_PROPERTY, right-click, "generate missing member functions"). The others are indeed concerns :) 
Have you considered adapting it to work with hpx (https://github.com/STEllAR-GROUP/hpx)? Or would you consider them more as competitors?
The reason why I even ask. For Java eclipse is so inconsistent, that it quickly becomes an unusable mess. Take one of the most popular builders - maven. What would you expect from an IDE that claims to support it? I expected two things: That it knew where is the generated code and that IDE tools would integrate it. None of that. Even better: Most people would advise ditching maven integration and building outside of IDE. Why would I use an IDe then?
Your stuff looks interesting. Are you involved with the iso SG7 group (e.g. https://groups.google.com/a/isocpp.org/forum/#!forum/reflection) looking into reflection at all? 
I would like to get it running on hpx, it will be cool collaborating with. From what I know about hpx, it can provide great runtime extensions to easyLambda. It will be exciting to have easyLambda interface and data-flows on top of hpx.
Where can I find his talk on "How transistors work" (He mentioned it at ~2m10s)
I was just reading through the overload documentation, and came across the following in the example lua code: pup:bark("meow") -- picky_bark, no bark pup:bark("bark") -- picky_bark, bark In the preceding c++ code I didn't see picky_bark being in the list of overloads though. How does this work?
That's because I can't into writing: fixed it.
&gt; I don't see how something contains more meaning just because I know weather it's a type or a variable. You understand what you're saying is this? "I don't see how something contains more information just because it contains more information." &gt; Camel case is harder to read. Completely dependent on experience. I find underscore_case unintelligible. I can't tell where an identifier begins and ends, because underscores look like punctuation. *But I could get used to that,* if it wasn't for that underscore_case is objectively less expressive. This paper outright states: *"One main difference is that subjects were trained mainly in the underscore style and were all programmers."* They even summarize another study, that used more participants trained in CamelCase: *"Their findings show that camel-cased identifiers lead to higher accuracy among all subjects, and those trained in the camel-case style, were able to recognize camel-cased identifiers faster."* Of course people are going to do better in the style they are used to! But objectively, underscore_case is less powerful. Given that we can get used to either, underscore_case is a weird choice.
I just changed open_file() calls for script_file() and done, everything compiled nicely using all in one sol.hpp. Again, thanks for your great job! :-D
very nice. too bad it does not work with vs2010 (and even worse that i have to use vs2010 ;) )
I guess it is from CppCon 2014.
Nope http://cppcon.org/conference-program/
I think this is it: https://www.youtube.com/watch?v=mYrbivnruYw
Try the C++Now 2014 videos, he talked about this back then AFAIK.
Woah, this parsing of __FUNCSIG__ is clever. Horrible, but clever.
&gt; Also the supposed unique id that `.hash_code()` returns is only guaranteed to be the same for equal types, but is not guaranteed that different types yield different hashes. Why would you expect a hash code to be unique?
Note that the common initial sequence is only of use when accessing multiple types stored within a `union`. It's not to be used through pointers.
Can you expand on why?
It is actually only the "first 10min" of another talk (the title and summary probably won't mention anything about it). I think it was the now raw loops talk (goals for better code?), but am not sure (it was a longer talk not a lightning one).
Fair enough. I called it script because it was nothing complicated and did nothing without user interaction, mainly - I consider it to be at the level, if barely above, batch file code.
&gt; Why do you think that some one may want to change what throw do ? Because the next thing you say is: &gt; But like int the library above you can use MACROS to replace throw by assert or something else. Which means that you want `throw` to somehow be _replaced_ by "something else". Whether you do it via a macro or internally inside the compiler is irrelevant. &gt; The funny thing is that there are already many solution for this not actually problems but they are not standard. So how can they be standardized? You say "`assert` or something else" but `assert` is not provided on all platforms, so what is that magic something else that works everywhere? &gt; Just look at 2 big projects that do not use exception and try to understand this. LLVM/Clang and Unreal Engine, there are many other. Have you actually looked at their solution? What they do is they implement their own fundamental libraries using standard C++, reusing as much of the standard library as possible. This is the solution that the standard recommends, and the solution that these projects follow. In particular, because LLVM and Unreal have different platform specific issues, they have different solutions to these problems (that's why they don't share some common standard library implementation). IIUC you want the standard to standardize portable behavior of C++ programs over platforms that do not implement all of the C++ standard correctly. If after reading the previous sentence you don't see why this doesn't make sense I cannot help you.
Yeah, it's horrible. I had been thinking on moving `pretty_function.hpp` to `ctti/detail/limbo/lust/gluttony/greed/anger/heresy/violence/fraud/treachery/pretty_function.hpp`
thank you
Of course I don't expect a unique hash code, but a hash function guaranteed to be good enough to not have (much) collisions.
I would think building a wrapper around _every_ matrix library would be quite difficult. While each matrix library is going to implement generally the same kinds of operations, they all have different APIs for accessing the raw data, to which you would have to adapt your wrapper for each library you want to encompass. That being said, it seems like many libraries store their matrices as a flat array of data and use another array to keep track of the step size offset in each dimension, a la [OpenCV](http://docs.opencv.org/2.4/modules/core/doc/basic_structures.html#mat). Things would probably get a little tricky when dealing with row- versus column-major orderings.
&gt;Also your post doesn't mention namespaces at all. Umm... &gt;&gt;&gt;&gt; Duplicating all of &lt;algorithm&gt; seems like something that could have been avoided with some thought. &gt; 
In my mind, the factory approach is a non-starter. Here's how I would approach it... Create your own namespace: namespace My { and add standard typedefs/aliases for your types: typedef ... Matrix; template&lt;typename T&gt; using Vector = ...; ... as well as free functions that encapsulate the operations you're trying to abstract (you might even get math operators for free): Matrix make_square_mat(unsigned dim) { return ...; } Vector make_vector(T*) { return ...; } Matrix mult(const Matrix&amp; l, const Matrix&amp; r) { return l*r; } ...; ... and now your client code looks like: using namespace My; Matrix m = make_square_mat(4); Vector v = ...; Vector r = mult(m,v); PRO: Switching implementations affects only the My namespace and its orthogonal API CON: Maintaining a truly orthogonal API can be tedious It's not a perfect solution but it can get you a long ways...
Reading from even a network stream or distributed storage even a sensor is possible. Since, rise just takes a function that is required to return {row, isEndOfData} or a vector of rows in which case empty vector implies end of data. ezl::readFile is a function object that does it for files that can be read as usual. If it does not work for any storage type then surely it can be added to the library. You can check examples/demoRise and algorithms/readFile for more on it. Yeah, you are right, fault tolerance is a needed feature. Although, I'm not pretty sure if that needs to be added to easyLambda itself. Since, MPI 3.0 is expected to support fault tolerance by default. But instead of waiting for MPI 3.0 fault tolerance support, its a good idea to run it on top of HPX (@tortoise74) or some other system that provides good runtime support on top of MPI. Since, the implementation of parallelism is confined to a few classes, I think different ones can coexist. Right now, the sender of a process waits if the receiver has not been receiving for too long. So, the program essentially halts in case of a node failure. There is no writing to disk or spawning new processes if the intermediates do not fit in memory. However, there is ordered() property that can make the results of a reduce flush based on the ordering of a column, which I don't think is useful in a example like wordcount but is useful if the data is ordered on some column such as time-step in a simulation or experiment or date or some other value in a log. So far I was focused to get the interface, parallelism, ease of use, composability etc in place, but I hope in future a lot of work gets done for these aspects. I hope with the community development things will move faster.
There's a few big firms like Bloomberg that can't hire enough of them.
I don't consider myself an expert in the topic, so I'm not sure I could give useful feedback there. IIRC we didn't touch very much the reflection proposals during the pre-Jacksonville meeting we had in Madrid, but if I continue working on the engine this way I would consider giving more comments on reflection in following committee meetings, even sending notes to the SG. Completely off-topic: I'm the first one that thought some bad sci-fi jokes regarding teleportation and alike when reading about the concurrency study group? 
Hi is the example on page 7. not leaking ? the old _data is not deleted, should there not be a delete [] _data before before pointing to something new? pencil &amp;operator=(const pencil &amp;other) { if (&amp;other == this) return *this; _data = new char[25]; strncpy(_data, other._data, 24); _data[24] = '\0'; return *this; } 
Looks interesting. Thanks for posting.
An alternative is to simply disallow signals to be sent across threads, as is done for most simply (non-queued) signals in Qt. I'm afraid this mutex approach might scale poorly for the kind of servers that prefer the signal architecture.
https://github.com/haptork/easylambda ezl has a lot of cool application of different concepts and meta-programming capabilities introduced in modern C++. You will surely find a lot of things to improve and contribute. When I saw this post, I thought only if I had my library uploaded, so just came back to the post when I've it uploaded. :)
Yeah the malloc(3) pointing at a struct and a half at the end was something that should never be compiled...
Are boost and Qt signals designed to be thread safe in the first place?
Firstly: efficient matrix calculations rely on direct access to the underlying data structures. If you go ahead and completely encapsulate storage (as shown in your code) then you're going to have to implement your own matrix operators, which do everything via the public interface. You'd be throwing away most of the underlying matrix library and writing your own horrifyingly slow operators on top of its storage. As /u/mcmcc says, this is a non-starter. The next problem is that different matrix libraries actually have quite different contracts. For example, OpenCV matrices use shared storage with reference counting, and handles element type dynamically at runtime. Eigen uses static types, and does lazy evaluation via template expressions. If you try and paper over these differences with wrapper functions, you'll end up with a lowest common denominator API which does nothing very well. On the positive side, different matrix libraries interoperate with each other surprisingly well. Say you have an cv::Mat when you really want an Eigen::Matrix: no problem, you can use Eigen::Map to give you an object which looks just like a normal Eigen matrix, but is actually backed by the storage in the original OpenCV object. So, in summary: * Pick the most appropriate library for the task at hand, and work directly with its interface. * Don't feel you need to pick one library to use everywhere; make the right choice locally. 
&gt; What I don't like about most of the signal libraries is, that the signals are members of each object, taking place in them It's not the case for Qt, signals are implemented statically too (moc writes the boilerplate)
&gt; Some modern micro controllers are more powerful than those MS-DOS PCs, specially if one thinks about the COM executables (64kb). It's a funny mix, they're often substantially faster, but with less RAM. For example the nRF52832 (I happen to be looking at that one recently) is a 64MHz ARM Cortex M4 with hardware floating point support, but it only has 64kKiB of RAM. Even the bottom end XT had double that but a much weedier 4.77MHz 16 bit processor with no floating point support. Digging through easily available specs, in terms of raw compute, it would probably have seriously destroyed my old P133 in some compute tasks (that was the last computer I owned which ran DOS and of course Windows 95). It appears the M4 has single cycle 32 bit MAC, whereas on the P5, a 32 bit multiply is something like 10-11 instructions. On floating point performance, the is either equal or slightly better on most instructions and much better on others, never worse, but my PC has a 2x clock speed advantage of course. For other tasks, well, the arm has better DMips/MHZ, but half the MHz, so my long lost P133 might have won that round! Compute wise, I think we can call it a draw. Of course my machine had 72M of RAM vs 64k for the NRF chip. Now bear in mind this NRF chip is for embedded bluetooth low energy and is very small, very low power and very cheap. It's a next gen chip compared to the previous M0 based offerings from Nordic and 32MHz 8051 based offerings from Texas. 
I'm not 100% sure precisely what you want to do. If you want to use facilities from OpenCV and Eigen, then you'll have to present the data as OpenCV and Eigen matrices respectively. CV::Mat is, like most matrix libraries, a not especially deep wrapper round a block of data and some strides. You can get OpenCV to populate Mat for you, or you can populate it with data you've allocated yourself. Eigen is similar but a bit more involved (though the underlying data is the same). Basically pretty much all other matrix libraries are similar (mine is too), which means that you can convert from any one to any other by extracting the data pointer and the row and column strides from library A and populating a matrix object from library B with those values. From that point of view, it doesn't matter which library you're using natively as you can wrap/convert to any others very efficently. Once you get beyond using the the underlying memory allocation only, then all the libraries will have mildly different ways of doing common things. operator+ will probably work for all of them, but transposing is going to be slightly different across the board, so you'll need to write a wrapper for each of those. At that point, you may as well write transpose() etc yourself based just on the data block, strides and sizes. What I'm sure you almost certainly don't want is to have all the access through a virtual function. Premature optimization is evil etc, but it will be horribly, horribly slow. Plus, that sort of thinga allows runtime polymorphism. What's the use case for making something runtime polymorphic over the underlying matrix object? 
VS2015, finally!
I mean, I'm not saying that textdomains are broken or bad. But I do think that for many small projects, you don't really need them.
I worked in Java a decade ago before making the switch to C++. Switched back to Python for something, Java for something else, and obviously, I was obsolete. After checking back on C++ occasionally, I'm just going to say 'eff it and stick to one language for good.
Yeah, even with clicking that, I get $79/month. Edit: oops, looks like I need to use the StartupIntro discount code Double-edit: Oh... "Subscribing to a term agreement is ideal for short-lived development projects of products that have no maintenance needs after distribution. In other words, once your subscription has ended and you no longer pay term fees, your commercial product development rights will end along with your access to Qt Support." I'd love it if they had a Jetbrains type scheme here: if you pay for 12 months, you get the current version for life. Otherwise I'd have to pay every year even if I'm not using the newest version.
Do you know of any references to the C++ rules (or differences from C)? With regards to the compilers ability to optimize a function, much of what is covered in the article is aligned with my understanding of the rules in C++. I'm probably have some misconceptions here.
this++, I do a lot of work on cortex-m3 and cortex-m4f chips where you end up having 120MHz clock rate but 32k of RAM. C++ is absolutely suited to these environments IMO, with RTTI turned off, and exceptions (most times) turned off.
Quality ;) Just a few month they discontinued the previous Indie licensing program. I feel like, they want to concentrate with commercial customers mainly that are able to afford their full licensing.
I guess it's relative. It has been unaffordable for indies for so long that it has been pretty pointless to try to target mobile. Personally, I don't really want to program in C# when I can program in C++ and Qt targets far more platforms than Xamarin if I remember correctly.
You must be joking if you mean quality in terms of mobile OS support. I was burned with decision to try out Qt 5.3 for a mobile project, decided to move the UI code to Android Java, C++/CX with plain C++ and boost for the business part, after Qt failing to provide the necessary support. At least Xamarin provides me full access to OS APIs provided by each major OS, no need for force me writing my own wrappers. How is the quality story now with Qt 5.6 in terms of iOS, Android and WP support without forcing me to write my own wrappers?
Not on mobile. Xamarin provides full 100% coverage of mobile OS APIs, whereas Qt forces you to write your own wrappers for all mobile OS specific APIs. There isn't any support for application life-cycle, background workers, inter-app communication, native widgets (the most used ones are emulated via QML), address book access, calendar, OS services, intents, ... This was the situation on 5.3, and from a quick glance of the documentation it doesn't seem there was much improvement there.
To each its own. I felt the same way trying to use Qt 5.3 and having to write my own C++ wrappers to have file selectors and native UI widgets.
I understand what you mean now. I haven't used Android-specific services, so I can't vouch for that. I guess it depends on what you're doing.
I'm glad you're liking the Clang/C2 functionality. We've been seeing more and more people using it for cross-compiler testing. As for refactoring tools, we've looked into it but there's nothing I can promise at the moment. For the time being using add-ins is the best option. 
Well, since objects of the same class may notify different handlers, you can't actually get rid of the handlers collection. It may be stored inside the signal like in wigwag and boost, or inside the base class like in Qt and, probably, GObject. So, if noone connected to a signal, you still have that overhead of an empty handlers list with any approach. Regarding sharing a single mutex between signals, bo_on_software is right: it is quite easy to do that in wigwag. You can find the example in the following tutorial section: https://github.com/koplyarov/wigwag/wiki/TutorialAdvanced#signal-constructors
&gt; But, really, I dont care. Im sure deploying to such constrained systems like game consoles is hard. But, come on I think this is a common case of bias like the exceptions are slow topic. Of course YMMV, but from my experience exceptions and RTTI worked pretty damn well on embedded devices. In previous console generations, the compiler providers explicitly told devs not to use exceptions (to the point of telling devs not to bother reporting bugs in exception code gen as they weren't testing it themselves). Thats no longer the case on current consoles. Two issue that may still come in to play: * Executable size is still a big deal (both in terms of storage and cost of cache misses) * Last time I checked, dynamic_cast performance was still not all that great due to the sheer generality it had to cover. Removing the use of dynamic_cast ditches a major perceived justification for paying the cost of enabling RTTI in all modules. 
Why's that? (Personally I would just overload operator&lt; ...)
Indeed. Qt signal/slot are specifically designed to make threads easy. You just write the code with signals and then, depending on the thread where the objects are created at the beginning (or to which thread they are moved), same signals act as direct calls or as message queues.
I don't think the OP necessarily wants it runtime polymorphic. I've been thinking about the same actually, but at compile time - it would be awesome to have the ability to swap out a matrix library with another one, just by snapping one's finger. So that you can basically have a library that uses some matrix math, and depending on your use case or platform, you could just switch all `cv::Mat` with `Eigen::Matrix`. (of course only in the cases were both libraries support the same functionality) The answer is (sadly) most likely what https://www.reddit.com/user/KennethZenith said: it's not reasonably possible, for the reasons he gives.
I get it. Basically, if it's compiled to do low-level interaction it's code, if it's ran to do high-level interaction it's a script?
I don't know, haven't used it.
Not quite sure what you mean by scalability problems. Could you please explain in detail?
As far as the compiler would be concerned, those two programs are identical. (EDIT: or they would be if you use `(*i)++`, since otherwise the ++ increments the pointer, not the int) However, a common rule of thumb when passing something by reference to a function that will modify it is this: If the thing is optional, (that is, can be null) pass it by pointer, and check for nullptr in the function. If you want to guarantee that it cannot be null, pass it by non-const reference. ^By ^the ^way, ^starting ^in ^C++17, ^another ^canonical ^way ^to ^pass ^in ^an ^"optional" ^parameter ^is ^to ^use ^[std::optional](http://en.cppreference.com/w/cpp/utility/optional). ^Some ^compilers, ^like ^g++-4.9, ^already ^provide ^this ^as ^std::experimental::optional. If you want to just pass something in without copying it, but you're not modifying it, use a const reference. 
I know, it's always pointed out, yet, the headline is misleading every single time. That is not to say I'm not appreciating the tremendous effort Microsoft has been putting into VS in the last couple of years, I really do.
Thanks for your answer. I was just studying pointers and was doing some experiments like this, so just wanted to be sure if I understood it well.
Because all users expect std::less to mean `operator&lt;`.
I was experimenting with pointers, so want to fully understand them.
That's the best way to learn, is to experiment! :) Though asking questions like these is good too, because with the abundance of undefined behavior in the language, experiments aren't everything. As another aside, if you're experimenting with pointers, I highly recommend you take a good look at [std::unique_ptr](http://www.drdobbs.com/cpp/c11-uniqueptr/240002708) and its cousin, [std::shared_ptr](http://stackoverflow.com/questions/6876751/differences-between-unique-ptr-and-shared-ptr). They'll save you the hassle of remembering when/where to delete your new'd pointers, and can generally make your programs a bit safer.
Why are you being downvotted for stating your personal experience?
I have removed your post, not because it is a bad question, but because beginner questions are off-topic for this subreddit. Please direct such questions in the future to /r/cpp_questions.
Certainly. Holding a mutex is a costly operation compared to simply not holding one. You can find plenty of discussion on this under the subject of lock-free programming in the context of scaling a web-app to thousands of concurrent users. One overlooked area is GUI programming, imagine how much slower your code would be if every-time your software queries a button it needed to go through an atomic or mutex. A much simpler approach is to limit the program so that it can't interact across threads, except with explicit queues. this is whats done in Qt (which has signals and slots).
You have both options. First of all Xamarin provides 100% covering of platform APIs, something that Qt doesn't do on mobile OSes. No need to go writing wrappers for native OS APIs yourself. Second you can use Xamarin.Forms which make use of XAML and provide integration across all major mobile OSes, again with native widgets integration. Qt only provides emulation of look and feel via QML on Android, and last time I checked iOS and Windows Phone emulation in QML was still to come.
In a way that's true, but in a way it's not. If you use any library, even libc, chances are you're using textdomains behind your back.
I used biicode and still use it in one of my completed projects until I find a good package management replacement. Conan seems really promising and I will certainly give it a try as soon as possible and hopefully it will provide a much better experience. My biggest concern is how easy it will be to package a library yourself. Until a package manager is used by a lot of developers and thus containing almost every known library package in its online database, missing libraries have to be packaged by users. This was a major hassle in biicode and I lost a lot of hours on this until I decided to give up on some of them and install them from the OS package manager (apt). I wish best of luck to the developers, C++ package management is major drawback of the language and the moment this is fixed the whole C++ ecosystem will improve a lot and many new users will join in and possibly contribute with their own (small) reusable libraries.
Their site is vague to me. Basically, if I want to develop and release my application on iOs and Android official app stores, I have to pay a license fee from $350. Am I right?
Indeed, but the non-mutex assumption should be default. The benchmarks you posted look very interesting, and quite good. I'm wondering where I can find the source: For example, the version here doesn't seem to include qt: https://raw.githubusercontent.com/koplyarov/wigwag/master/src/benchmarks/benchmarks.cpp Anyways, this is still very impressive work, and I wish you the best of luck.
I decided to make the default specialization the safest and the friendliest one. :) If a person finds out that he or she loses some performance, it's quite easy to switch to a faster version. E.g. in our project (STB middleware) we use two versions of signals. The multi-threaded core uses threadsafe signals, and the single-threaded UI uses much faster specialization with minimal overhead. You can find the full benchmarks code in the develop branch. Unfortunately, the disconnection code for Qt is not the optimal, as I realize now, but I will fix that soon. https://github.com/koplyarov/wigwag/blob/develop/src/benchmarks/benchmarks.cpp
[removed]
Could you post the errors? They are really useful for working out what's wrong. 
My recollection is that Stepanov's advice (which sadly I can't seem to find now) is to implement `operator&lt;` etc if a type has a "natural" (mathematical) ordering, and to specialise `std::less` otherwise, so the type can still be put in a `std::set` etc. This seems sensible and easy-to-follow advice, from the master himself. In what way is it wrong?
What Not To Do
Great article! Thanks! nit: class string { ... private: const char* _str; std::size_t _length; // &lt;== _size } 
Do you work for Forbes or what? Here's the real link: https://www.quora.com/What-are-the-main-weaknesses-of-C%2B%2B-as-a-programming-language
Oh, all right, I stand corrected. 
I would add that it may be a good idea to read the overviews for the [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines). Especially the material from Stroustrup/Sutter at C++ 20, in the Talks section of the link above.
It's mostly not about differentiating variables but about having a lot of places where variable having different name from type doesn't make much sense. Usually it happens when similar object will never ever appear near the first one in its context. And I mean if there's not a lot of `..._t`, `m_...` or `..._arg` in your code when you should feel great but I never actually met code like this.
From looking at https://isocpp.org/blog/2016/03/jacksonville-approved-papers-and-issues It looks like Generalizing the Range-Based For Loop was approved in Jacksonville. In the article, Bjarne says that it is to be decided at the Oulu meeting. Can anybody who is involved in the standards committee clarify the status of that? Having this will make the Range TS much more usable in regular code without having to use a RANGE_FOR macro.
These answers are so bad I almost want to fucking kill myself. Jesus christ some people are so stupid. --- &gt;Due to the lack of variety in brackets and parentheses on a regular keyboard, the syntax of modern C++ sometimes gets tricky. And not only for humans, but for code highlighters too, which should tell us something. Code highlighters? Is this person actually a programmer? Nobody calls syntax highlighters 'code highlighters'. And why would a language being difficult to parse for a computer 'tell us something'. I hate it when people talk about it. "There's a good reason that X, Y, Z." is another one. If there's a good reason, **say what it is**. Except of course people say that when they believe there's a good reason but don't actually know one. The author of this awful Quora answer doesn't know why or really even whether this "should tell us something", or they'd say what it supposedly tell "us". &gt;Array indexing. And lambda definition / capture list. Completely unambiguous, just like `auto x = {};` vs `{};` are completely unambiguous and `foo(1);` and `(1);` are completely unambiguous. &gt;{} : Code blocks. Only code blocks, right? Wrong. Also initialization. And the modern Standard makes a heavy push towards {}-based initialization. Again, completely unambiguous. &gt;/* */ : Comments. Unambiguous, right? Wrong. At times "/*" can be a legal language construct outside the comment: int* pa = &amp;a; int* pb = &amp;b; int c = *pa / *pb, and we suddenly have a place where C++ requires a whitespace between operators. I can't think of a language where whitespace between operators isn't sometimes relevant. e.g. `a + +3` vs. `a++ 3` where the latter is a syntax error and the former adds `a` and `3`. &gt;On the one hand, I'm happy C++ folks are making heavy use of existing semantics, and are not trying to reinvent the wheel. Haskell, Ruby, and F#, where the functionality of adding new operators is widely [ab]used, often scare me by their syntax. Not being used to something doesn't mean it's "abused", it just means you're narrow-minded. --- Different answer: &gt;Most of the weaknesses have to with the grammar. C++ grammar is context - sensitive. This makes it difficult to write parsers, sure, but the main weakness is that this makes it generally impossible to prove a program is correct. Every widely used programming language has a context-sensitive grammar, and that has nothing to do with whether or not it's "generally impossible to prove a program is correct", given that doing so is generally impossible in any even slightly complex cases. &gt;But the language overall is incapable of proof. Just like every other programming language, programs are proofs. &gt;A huge weakness, is that strings are dumb arrays of smart characters. This makes internationalization very difficult and confusing. And C/C++ are just too married to streams to just simply adopt the Unicode standard, like Java, etc al. Lol. People that write "C/C++" as if they're the same language should be killed, but even apart from that, C++ has had good support for Unicode for years and years. Too married to streams? Too married to bloody streams? What does that even mean? &gt;Another annoyance is that angle brackets should not have been used for templates. Anything that requires template disambiguator so that the compiler doesn't get confused, well, enough said.... No, not enough said. There's nothing ambiguous about the syntax of templates in C++. --- Another answer: &gt;Over reliance on template metaprogramming - its wonderfully efficient, but horribly non-intuitive and ugly No, it's not 'horribly non-intuitive'. The word is 'unintuitive', for a start. Secondly, C++ template metaprogramming is very, very rare. Thirdly, C++ templates are generally quite lovely once you get used to their semantics, and very powerful. --- Another answer: &gt;1: complete lack of a binary ABI. C figured this out what 30 years ago and C++ still doesn't have it. Hahaha, classic. God some people are so dumb. ABIs are a property of an operating system, not a language. If you want C++ to have a 'stable binary ABI' then talk to the GNU people, talk to Microsoft. Don't blame C++. &gt;2: no separation of interface from implementation. All of the private vars and functions also need to be in the header file. How can someone be this stupid? &gt;3: can't change internal implantation without breaking code -- if you add or remove a private var , all existing code breaks and needs to be recompiled . Oh my god, how can someone really be this incredibly stupid? Complaining about lack of a stable ABI, calling it a 'binary ABI' as if 'binary' isn't already evident from the fucking 'B' in the name, and then fucking complaining that when they make an ABI change they need to recompile. &gt;4: no language level support for matricies or multi dimensional arrays float a[4][4]; // how can someone be this stupid? &gt;There are a miriad of other problems, but 1, 2, 3 is why c++ can't be practically used for creating shared distributable libraries. rofl &gt;Microsoft however solved all these problems with COM however I'm actually laughing out loud, god this guy must be a troll or something holy shit.
I like a simple setup. I'm using Sublime Text (https://www.sublimetext.com/) for writing and Coati (https://www.coati.io/) for navigation and understanding. They both work on Windows.
Modules... :/ Hopefully most compilers will at least implement the TS as soon as possible.
&gt; If you want C++ to have a 'stable binary ABI' then talk to the GNU people, talk to Microsoft. Please don't, if I wanted to use a stagnant language that is stuck with a 30 year old ABI and corresponding limitations I would use C. If we had the same for C++ exceptions would still use longjump, GCC would never have adopted C++11 strings, etc. . 
Mostly just legacy code: [http://stackoverflow.com/questions/7448262/why-are-c-names-shortened](http://stackoverflow.com/questions/7448262/why-are-c-names-shortened) [http://stackoverflow.com/questions/31526626/standard-c-function-names](http://stackoverflow.com/questions/31526626/standard-c-function-names). For modern code, you generally wouldn't want ro choose such short names. For example, here's [Google's C++ style guide](https://google.github.io/styleguide/cppguide.html#General_Naming_Rules)
Some of those legacy UNIX headers date to a time when C only guaranteed 6 unique characters in identifiers. Even after that stopped being true, a lot of UNIX programmers felt that succinct identifiers, especially for locals, made for more readable code than SomeReallyLongIdentifierForASimpleCounter-style code. Most would consider ```socket_file_descriptor``` excessively long for something so common and well known. 
It's old code, it won't be used in production, I just want to learn how it works to migrate some of it to Unity. Thank you for your quick and awesome reply though.
Style.
IDEs which provide autocompletion and intellisense are relatively new - especially ones that are available for free. Such a long identifier would take a long time to type and so increase the rate of typos that are only found during compilation. Since compilation can take a long time amortized time lost due to very long identifiers easily outstrips the time lost to learning the common acronyms.
um, C doesn't have an ABI either. cppreference has some ABi lists, for C: http://en.cppreference.com/w/c/links#C_ABIs and for C++: http://en.cppreference.com/w/cpp/links#C.2B.2B_ABIs 
&gt; IDEs which provide autocompletion and intellisense are relatively new And they don't always work well. I used to have to turn off 'stupisense' because it always got shit wrong and took up way too many resources on the computer. That was in 2010, and it's improved a lot since then, but the term still leaves a bad taste in my mouth.
It was approved in Jacksonville as CWG Motion 9 and merged into the C++ working draft by this commit: https://github.com/cplusplus/draft/commit/55025ba48d48820425ca46e322ce9096d0ffc954
It looks like they have updated that recently. The last time I saw their style guide I had a hard time agreeing with some of the advice, but now it looks reasonable.
&gt; Even if fd in C is a fairly common abbreviation for file descriptor, I would argue that making a longer, more descriptive identifier doesn't take anything away from anyone (other than the 6 unique character limit you mentioned). However, abbreviating it does take away from someone who is not a seasoned C developer, like me for example. I didn't know what fd was. I had to spend a while trying to find out what it was since I've never seen fd anywhere. That's a pretty common complaint from newcomers, but it tends to fall away over time. Kerninghan and Pike, who were heavily involved in the creation of UNIX and very influential to its style, wrote a book called *The Practice of Programming*, and had this to say about naming: &gt; Global functions, classes, and structures should also have descriptive names that suggest their role in a program. By contrast, shorter names suffice for local variables; within a function, n may be sufficient, npoints is fine, and numberOfPoints is overkill. Local variables used in conventional ways can have very short names. The use of i and j for loop indices, p and q for pointers, and s and t for strings is so frequent that there is little profit and perhaps some loss in longer names. Programmers are often encouraged to use long variable names regardless of context. That is a mistake: clarity is often achieved through brevity. People coming from other languages, especially Java-style ones, will likely disagree and find this alien, but at this point UNIX style is what it is, so you tend to get used to it.
Benefits of shorthand version are quite subjective, while benefits of long version are objective.
It gets fairly regular updates, and apparently the initial public version which was full of awful rules was actually significantly out of date even at the time of release.
I use longer descriptive identifiers, but I still always use `fd`, and a few other shorthand terms that in my mind "programmers should know". If you don't know it's a file descriptor it's because you're lacking domain knowledge, which is fine if you are just learning. Also most of us have learned this from the book Unix Network Programming by Richard Stevens, (which we abbreviate to UNP because programmers abbreviate everything :P) Anyway, this happens to all programmers at some point in a foreign program, and it just means you lack domain knowledge and need to learn it. I agree that in this day and age people take abbreviating a little too far, but some things have historical names, like `fd`.
So books are containers ? They are part of STL? Are they webscale?
It's extremely annoying when inside a driver (drivers are written by the C people): you have a mix of device-specific notions and register names that all squeezed into 3-letter abbreviations.
Just because the probability of collisions is low does not mean that they will never occur; though. Remember the Birthday Paradox: the chance of two people being born the same day is 1/365.25, yet with only 23 people you have 1/2 chance that 2 of them are born the same day!
I wasn't aware that it's licensing situation had improved so I've not considered it in years. I suspect I'll stick with Qt, but I'll definitely take another look at JUCE.
I'm not sure I really like the example of using a file descriptor. Because a fd is not a C thing... it's an OS thing and is so common that I don't have a problem with using fd. It's kind of like having an int i for an index in a for(;;) loop. I think it is a better argument to make using variables that are specific to a domain or your program itself... then I thing the argument is much better for having descriptive identifiers.
Compile time minor slowdown for a library who's whole goal is trying to make core features as bulletproof as possible? Pretty worth while exchange for *most* applications.
Well I wouldn't want to download a large library just to use one aspect of it, but someone mentioned earlier that you can compile and use individual pieces which is nice. Regardless I'm sort of doing this project just as a learning exercise. I very much enjoy working with concurrency and networking, and I think there's some value to learning the standard libraries to an extent. 
I wish the preprocessor had a way to handle lower vs upper case. 
I wish I didn't have to use the preprocessor at all
 You can install Asio without boost. Boost is what you will see in standard library. Filesystem, thread, chrono, random generators came from there. 
Or things that you can't do at all with templates.
There are proposals for reflection that don't use the AST, what specifically in the AST is needed?
Have you worked with Common Lisp?
&gt; how to do compositional code generation without macros For my part I now generate code with CMake instead when such things are required.
It basically does what you want: code that manipulates the code. If you try to make another language that does the same - it will be Lisp, but with slightly different syntax.
Except Smalltalk, which does exactly the same kind of thing and is the epitomy of an OO language. 
Have you worked with a profiler?
For performance/optimization reasons, I've come across a very small number (2-3)
I used to work in the same team as Dima at MSFT  he has well above average C++ skills, don't doubt. ;-]
For me, it's all about the amount of context I can hold in my head at once. If I'm working on code that has a lot of very long variable names, it's harder for me to load the entire context into my head. If I have a small function and I need to keep track of the number of points, I'd prefer 'np' over number_of_points because it's just easier to read and recall. Another reason for me to prefer shorter variable names is bc I prefer to stick to 80 character wide code. In fact I'll rename variables if I can (to something reasonable) to enforce that rule.
Good one. :)
Yeea I definitely believe that. I just don't see an issue with a bit of [](){}. I mean actually he says it by himself that he's glad C++ doesn't use contructs like `&lt;* ... *&gt;`, which would be kind of even worse. He does have a point that for example {} has many uses, which I'm sure could be considered confusing to a beginner - I just never thought about it in this way, it hasn't ever bothered me. Maybe I was too harsh - sorry to Dima ;-)
&gt; imagine how much slower your code would be if every-time your software queries a button it needed to go through an atomic or mutex. Would it really be that slow ? Assuming no lock contention it's just a few atomic operations ? Doesn't JS DOM have similar order of magnitude kind of overhead because JS VM -&gt; C++ context switch is also not free ? It works relatively well. 
All power to the forward adblockers! Hold out long enough to activate the hyperclosebutton!
length of identifiers cannot be judged in a vacuum. long identifiers are in general clearer than shorter ones, but may cause excessive line splitting and this reduce readability of the code. also, long identifiers used only in small context hamper readability more then helping. and last, very frequently used 'nouns' in the specific code base can get away with shorter names. For instance clang, decently written code, has many one letter identifiers (like T or L for the lexical analyzer, iirc). This helps quite a lot: they're chosen careful and makes function calls and declarations concise making the important parts stand out. If all identifiers are long, you lose this kind of expressiveness and finding which parts are more important becomes harder. For socket_file_descriptor, I'd probably go socket_fd (I don't see why shortening socker, and 'fd' is reasonably universal for file descriptor). Similarly, I wouldn't have any problem in using 'id' instead of 'identifier' pretty much everywhere. The long version doesn't add anything to the readability.
Yes absolutely implementing IN c++. Where was that ambiguous in my post?
I use [garbage collection](http://hboehm.info/gc/) in C all the time. Claims to support C++ too, though I've never tried it.
&gt; The only way I have known how to do something that is similar to GC in c++ is using smart pointers, and shared_ptr in particular. Sounds like you want GC for C++ to me.
`__attribute__((always_inline))`
The Boehm-Demers-Weiser GC works reasonably well. Be aware, however, that the heavy/widespread use of (and dependence on) deterministic destructors in C++ makes it hostile to garbage collection to an almost unique degree. To paraphrase Wirth: "If you think you need a garbage collector, what you really need is to learn how to program."
"Hey John Carmack, you really need to learn how to program."
Lua is implemented in C and has garbage collection, you could look at the source code and see if you learn something there.
Consider using jinja2, texthon or chetaah instead of a raw python script.
https://www.reddit.com/r/cpp/comments/48c11t/wxwidgets_310_released_better_support_for_high/
It won't be a problem for much longer as we'll be getting C++ Modules soon as a TS (technical specification). Learn some of the Boost libraries, they are powerful and useful.
A switch on an enum with 120 values. Even if you extract all of the actual logic to separate functions such things are pretty common for dispatching window messages in Win32 code.
&gt; That's a pretty common complaint from newcomers, but it tends to fall away over time. I've been writing C++ since the 80s, and if anything, I prefer things much more explicit and clear now than I ever did - for example, I just never type `using std;` any more. For one thing, I'm working in very many more realms. In the last week, I've written C++, Python and Javascript - so I simply have a lot more names to remember. For another, C++ itself has grown greatly. There are some parts in C that I barely use. I can't remember the last time I directly used a file descriptor. It's 2016. No one pays you any more to just stay in the small area where you're constantly using file descriptors and a few other things - and each day you were a different hat. Use long names, you'll be happy you did.
The spam filter removed your post for reasons unknown to me. However, someone else has already posted about CLion, so I will let their post stand.
I edited my cookies so I could leave it on. 
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0067r1.html If there are other facilities you think are missing, please, help out and write a proposal for a library addition. The committee does not do original design work on its own. They only approve papers and perform editing and such. All changes are driven by contributors.
If you want minimal dependencies, you'll need to roll your own. If you don't want to roll your own, use Boost and be done with it. 
I'd recommend [cppformat](https://github.com/cppformat/cppformat). It's completely self-contained, very fast and very flexible. It would be great if the standard library had something like this.
Last time I checked, the functionality was in the iostreams. Maybe we should put that and std::regex inside of the std::string too?
Well we should be able to get that in C++19/20 - I have a sample implementation at https://github.com/faisalv/clang/tree/literal-type-template-params (to see test code that compiles: https://github.com/faisalv/clang/blob/literal-type-template-params/test/CXX/literal-nttps/literal-nttps-1.cpp) Hopefully, I'll get around to proposing it once the dust settles on C++17. Let me know if you'd like to contribute to the effort.
Simplest example: #define debug(x) std::cout &lt;&lt; #x &lt;&lt; ": " &lt;&lt; x &lt;&lt; std::endl
does it support Make yet?
1. i'm pretty sure it was mentioned somewhere that they plan to support build system other than CMake (in fact, i believe Makefile was mentioned explictely) in their future builds 2. i am currently working on a large project with a complex Make-based build system, and i have absolutely no intention to waste my time porting to CMake. 3. maybe i prefer Make over CMake
What's [this](http://blog.jetbrains.com/clion/2014/09/clion-answers-frequently-asked-questions/) then? Or [this](https://youtrack.jetbrains.com/issue/CPP-494)?
IMO I prefer short, but not trivial, terms for readability: ~4 to 10 characters. Having to type the same name over and over again is tedious. Thanks to the modern auto keyword, it's less a problem with type names. It's does make a steeper learning curve when you try to learn an API by looking at the code, but when you use the same concepts every day, it's not a problem. (Anyway, the auto keyword, cause as much as learning barrier.) Also, there's a lot of coding styles that enforce a maximum of 80 character per line of code. I know Google follow such style from reading their coding standards. 
Doesn't the same apply to regular constexpr floating point math? Just stick with what was decided there.
Actually, inplace_merge() is one of 3 STL algorithms (the others are stable_sort() and stable_partition()) which are mandated to attempt to allocate memory, but fall back to an asymptotically slower algorithm if memory isn't available. The "inplace" refers to the fact that the source [first, middle) and [middle, last) ranges overlap the destination [first, last) range. This is unlike the plain "out-of-place" merge, where [first1, last1) and [first2, last2) are pure inputs, and the algorithm scribbles into a non-overlapping [result, result + blah). The Standardese is N4567 25.4.4 [alg.merge]/8: "`template&lt;class BidirectionalIterator&gt; void inplace_merge(BidirectionalIterator first, BidirectionalIterator middle, BidirectionalIterator last);` `template&lt;class BidirectionalIterator, class Compare&gt; void inplace_merge(BidirectionalIterator first, BidirectionalIterator middle, BidirectionalIterator last, Compare comp);` Complexity: When enough additional memory is available, (last - first) - 1 comparisons. If no additional memory is available, an algorithm with complexity N log(N) (where N is equal to last - first) may be used." Source: I am a guy on the Internet.
Wouldn't call boost "minimal dependencies". If only for the compile time. 
Why not?
i knew about that already - i actually played around with clion not two weeks ago as part of an investigation task for my team, since we're mostly split between qt or vim (based on personal preference), and while i do like clion (honestly, it's probably the best IDE that you can run on a *nix environment), i'd rather wait until they support Make, since at this point in time, it would take too much time porting our build system, especially seeing as you actually have to pay for the license. i'm guessing (also hoping) they'll have make supported soon enough.
Fair enough. I'm the only CLion user at work, everyone else uses an outdated version of Eclipse. It's a lot easier to put up with quirks if you don't have to then sell it to the rest of the team. At best, I can encourage changes that make the codebase more friendly to CLion and other editors.
honestly, if were starting a new project, everyone would have been fine with clion (especially after qt), but as is, it just doesn't seem like it's all the yet. pretty sure it will be soon though, so that's nice.
It is interesting how arrogance and ignorance act in pairs.
Would you mind sharing which theme you used to achieve this result?
While nice, it seems like ranges would solve the need for index-based for loops: &gt; Traversing multiple sequences in the same loop, e.g., A[i] = B[i]. `zip(A, B)` &gt; Referring to elements before or after the current element, e.g., iter[0] = iter[1]. `adjacent(A)` &gt; Performing computations based on the position in the loop, e.g., A[i] += i % 2 ? 1 : -1; `enumerate(A)`
Yes, that's correct. We are considering adding Makefiles as a next project model, however we still have quite a lot of problems with CMake that we need to fix. Otherwise these would be common problems for all project models. So we are still undecided about Makefiles even in the next release.
&gt; While nice, it seems like ranges would solve the need for index-based for loops I absolutely agree. The committee felt however that it might be a good idea to have something more reminding plain for-loops.
&gt; The range itself was trivial to write using view::for_each This is partly because range-v3 doesn't support segmented ranges. So unfortunately, `view::for_each` is going to be costly. Also, `view::stride` is not built the most optimal for random access ranges either. And with segmented ranges, `view::stride` can be built more optimally for non-random access ranges as well. 
 auto tmp = std::make_unique&lt;char[]&gt;(n * sizeof(T)); T* begint = reinterpret_cast&lt;T*&gt;(tmp.get()); // ... std::move(first, middle, begint); This is broken if `T` is non-trivial. `move` calls the move-assignment operator of `T`, but no `T` has been constructed yet. You could use placement-new, or `uninitialized_copy`. Unfortunately there is no standard `uninitialized_move` ( no idea why )
I gave it a try. Seemed nice. The python worked apart from when I tried to run pycuda in the interpreter. The only thing still holding me back is the license fallback to the the version you had 1 year ago if you cancel subscription. I'd prefer something similar to what unreal engine had before they made it free. You keep the version you have if you cancel subscription but don't get any updates until you start again. I'm a hobbyist coder so hard to justify the price.
Take a look at websocketpp.
Good call. I've added some explanation. Hopefully `uninitialized_move` will come soon (see [P0040](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0040r1.html)).
You can emulate `unitialized_move` with `make_move_iterator` and `uninitialized_copy`.
The editor colorscheme is 'KDE' (under editor config for KDevelop and Kate), the option on the bottom of the dialog allows you to use it by default. It's shipped by default on every installation I've tried. The Application theme (for all kde/qt) applications is either breeze dark on the new plasma desktop, or obsidian (IIRC) on KDE 4. Again, both are stock.
yeah their IdeaVim keeps getting worse for me, its an awesome product but that sticking point is getting increasingly aggravating.
That is Robin Williams, and this is a rather famous meme. If you actually find this offensive then I suggest strongly reconsidering which web site you're posting on.
Build and Git on Ubuntu VM. Edit code with Visual Studio on Windows via a shared folder.
I use Codeblocks. I have CLion with my student license, but I can't use it because my laptop isn't good enough to run it. :/
Geany. It's fantastic, very light, fast smooth, low memory intensive. I can add filters easily as it just pipes what you have selected into a command utility and replaces it with the output. Cross platform. Not dependant on any build system and doesn't try to invent it's own.
Code::Blocks. 
Sublime with clangcomplete
Qt Creator; the best cross-platform IDE I've tried. Works well with CMake. I also use Sublime Text, Visual Studio and Xcode. I find Eclipse to be terrible and CLion promising but slow.
[Emacs](https://www.gnu.org/software/emacs/) with [r-tags](https://github.com/Andersbakken/rtags) and [company-mode](http://company-mode.github.io/). I work in terminal-mode managed by a [screen](https://en.wikipedia.org/wiki/GNU_Screen) session. I've used Emacs for a long time, when I switched up from vim. One of the great benefits of this approach is that I can simply ssh into my workstation from anywhere and pick up exactly where I left off.
CodeBlocks.
Just switched to rtags and company-mode with irony after using auto-complete and gtags with emacs for a long time. I also started using cmake-ide and flycheck in c++-mode as well. I personally prefer tmux. 
&gt; And while that new code might be "better" (or even just smaller) is it worth stalling development for 6 months (a number out of a hat) to do it? If it's going to take them longer than 6 months to make their C++ parser C++14 compliant  and I'm sure it will  then yes. On top of that, it's an investment in future development costs when it's time to implement C++17, C++19, etc. parsing, since they'd get it for free.
Sublime + lsyncd to build on a remote host. Strength is speed and responsiveness, weakness would be not a lot of C++-specific features. I tried SublimeClang, but it completely kills the aforementioned speed.
You can try to solve some problems on project euler: https://projecteuler.net/
As evidenced here, the main weaknesses of C++ are the users.
The very first post in this thread was [Visual Studio](https://www.reddit.com/r/cpp/comments/4b1kvl/which_ide_editor_do_you_use/d15ca1x).
[juCi++](https://github.com/cppit/jucipp): fast, lightweight, simple, cross-platform, excellent C++11/14/17 support through tight libclang integration, standardised warning/error messages on the fly, uses gtkmm as GUI library, stable, debugging through lldb, cmake support (no IDE specific project/cache files at all), no problems with using external libraries (on Windows installs in MSYS2 for easy access to precompiled library packages), open source.
Visual Studio at work. CLion at home for hobby programming. In both places I tend to switch between the IDE and Sublime Text 3. ST3 is better when I want to edit code as text (especially its multi-cursor editing) and I have several commands for code generation there that I use regularly. 
What? I like eclipse. Exceptional navigation and code-structure awareness (also handles Qt), unique keybindings (copy/move line up/down, goto last edit), easy integration with command-line tools. By the way, there is a nice method of working with CMake+eclipse, when you don't generate an eclipse-project from CMake, but set up cmake invocation via the 'Make Targets' feature of eclipse. Then you can build from the editor. (downsides: default panel organization scares people away)
Thanks! I'm not using the KDE Desktop, but a tiled windows manager, so it's a bit of a challenge for me to get the theme correctly (the 'KDE' colorscheme is there already, but it only changes the text color in the editor).
You're not missing the middle-click paste?
Emacs. It's fast, responsive and makes it really easy to edit source code. irony-mode gives you excellent semantic navigation and auto completion backed by libclang. I really tried several IDEs (Visual Studio, CLion, Eclipse, QT Creator) but I was always missing the speed and versatility of emacs, so that's what stuck over the years. A big plus for my work is also the ability to run it on any remote server over ssh as easily as locally.
&gt; for(int i:view::ints(0, 100)) Yes, but in that case it kind of depends of the context, e.g., `view::ints(a, b)` desugars first into `view::iota(a) | view::take_exactly(b - a)`. The compiler happens to vectorize these in simple contexts but in more complicated functions it does give up. I remember that the whole range-v3 constexpr excercise started because I thought that making these constexpr would help here (and it did help).
Doesn't systemsettings do the setup correctly? BTW, there are a few tiling scripts for kwin, they provide simple tiling that may be good enough.
You *might* be able to add to the end of a chunk obtained with `malloc()`. To be more specific, when you call `realloc` it's allowed to return the same pointer that was passed into it. You're right that you can't *count* on that happening though. As an aside, `std::string` doesn't normally use `malloc` to allocate its memory. You could instantiate an `std::basic_string` with an allocator that called `malloc`, but the default allocator will use `::operator new` to get raw memory (though this makes little real difference to the point you were trying to make).
Works fine here, on a project with a moderate amount of CMake (about 2500 lines, &amp; 100k lines of code with north of thirty libraries built)
Qwt is easy to use, but it is build on top of qt. [Vtk](http://www.vtk.org/) is the professional way to do data visualization.
&gt; By the way, there is a nice method of working with CMake+eclipse... Thanks for the tip. I'll have to look into this.
The author or [cppformat](https://github.com/cppformat/cppformat) here. I'm thinking about writing a proposal to the standard (library) after improving the API for formatting of user-defined types.
Can you please expand on ROOT and your experiences using it?
Do you have any good sources for how to information?
http://www.gnuplot.info/help.html
What do you mean reddiquette wasn't followed? Also please stop using vulgar language on /r/cpp. The e-word is not appropriate in a place where people have been scarred for life from using that horrific "software". It still sends shivers down my spine and the last time I used that abomination is 15 years ago. 
I've looked at it a little bit, it's designed to have "your applications" run within it, more than using ROOT in your own applications. An environment like python notebooks. I'm interested to hear if /u/gematrik has a solid way to work with it inside your own programs though..
ROOT is a science analysis suite developed and distributed by CERN. In addition to plotting it does data manipulation and statistical analysis. I haven't used ROOT for plotting in ~5 years. It's got some amazing functionality, but it's also a massive tool. It was written for nuclear physicists to analyze the data from particle accelerators, not for aspiring programmers to l3rn2c0de. The scientists I work with are moving away from ROOT to focus on matplotlib and python instead, because it's easier to share code and collaborate. For that reason I'd probably recommend avoiding it.
Check out [RInside](http://dirk.eddelbuettel.com/code/rinside.html), it allows you to execute R inside a C++ application, and thus gives you access to Rs immensely powerful plotting libraries (such as [ggplot2](https://github.com/hadley/ggplot2)). This does require a separate installation of R with the required packages; but unlike gnuplot it can be easily controlled from within your program. A minimal example would look like this: #include "RInside.h" #include &lt;vector&gt; int main() { std::vector&lt;int&gt; y{5, 4, 3, 2, 1}; RInside r{}; r["y"] = y; Rcpp::NumericVector rx{(SEXP) r.parseEval("seq_along(y)")}; r["x"] = rx; // To store the plot: //r.parseEval("pdf('path/to/file.pdf')"); r.parseEval("plot(y ~ x)"); //r.parseEval("dev.off()"); }
Ehm... shameless self plug, recently had the same problem. Wanted to plot performance data, with small lightweitght solution. After trying multiple solution I ended up writing a gnuplot interface. *** Pros: Very lightweight 1 header file only, fast compile Gnuplot is well documented and has many tutorials Easier to use than plain gnuplot and has interface for plotting data stored in std::vector *** Cons: No type safety and as it is launching another application, may cause weird errors Gnuplot has to be installed on the system *** Here is the link: https://github.com/Voultapher/Vool/blob/master/GNP.h The repository is also holding unit tests, so if you want to understand its functionality and functions this would a place to start. Note: It compiles with vs2015 and clang 3.7 on windows, no idea about g++. Linux should work. Mac no idea, you may have to modify it. 
I work with pretty large codebases (millions of LOC) using QtCreator and CMake on Linux and it's super fast. I recommend using ccache to speed up rebuilds but it's not specific to any IDE.
Hopefully your next project model will allow integration in to the standard IDEA package. I would not have any problem buying all of your licenses just to get a single IDE + a single build system for a project where I need to use C++ and say Emscripten, TypeScript/HTML, Kotlin/Java, Objective-C for front-end, Python for tool integration and server side work. Having separate CMake build for C++ is not the end of the world but when I have to use CMake + a separate application for C++ development why would I buy your IDE over a free one like QT creator - their code parser is even better than yours because they use libclang and you use your custom implementation which gives many false positives (at least last time I tried) and refactoring broke my code (changed include statements - tried to incorrectly "simplify" them). Having one IDE/build system to handle my multi language cross platform project is a selling point for me.
It's a good editor, yes, but I wish I could use Visual Studio. It's somewhat ironic that because of differing whitespace styles I can't use that even though I'm technically on the Visual Studio team.
Thank God someone mentioned CodeLite. It's an amazing IDE for C++, compared to the other free and open-source IDEs.
&gt; The compiler happens to vectorize these in simple contexts but in more complicated functions it does give up. Yea things like [this](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/join.hpp#L83) combined with [this](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/view/join.hpp#L115) or [bounded advance](https://github.com/ericniebler/range-v3/blob/6600e6054513202e61a067de48c4a05ca2b11099/include/range/v3/utility/iterator.hpp#L177) which is called during iteration with `view::stride`. All this makes it difficult for the compiler to figure out how to optimize. Instead nested looping is going to be much clearer for the optimizer and its going to express the intent much clearer as well. However, without support for segmented ranges, there is no way for the algorithms to know how to do nested looping when views are given. &gt; I remember that the whole range-v3 constexpr excercise started because I thought that making these constexpr would help here (and it did help). Hmm. I wonder if it was constepxr or perhaps reaching an inlining limit. Perhaps using `__attribute((always_inline))` would've helped as well. 
I'm not sure what you mean, you can include the ROOT libraries in your own c++ programs. you can also use it interactively, but it's not a requirement.
Have a look at [matplotlib-cpp](https://github.com/lava/matplotlib-cpp), it's a wrapper around the python matplotlib so it needs python installed. Not sure whether it works on Windows. Somebody else mentioned it already, but I'd have a close look at QtCharts and QtDataVisualization, Qt recently released these modules as open source. There are the options I'd be looking at if you want to plot directly from within C++. Otherwise I'd stick to Matlab, it's just too good at plotting.
I will try ccache thanks. 
The things you are proposing are features that would be used by 0.00001% of all C++ programmers. &gt; I cannot operate with the AST of my program at compile time to add/modify something Having an AST is not a requirement of the language. An AST is a _tool_ used by compiler developers, but the standard doesn't say your compiler needs an AST, you're free to make a C++ compiler that doesn't use one.
So basically, it allows for the file to be read by the program? (I know I'm probably not using the correct terminology for some things, but hopefully you get what I mean)
If you want something embedded directly in your applications, I'd just get a graphics context and write it (but I like writing plotters). If you're just doing debugging, I'd popen() gnuplot and fwrite() commands to it...
The biggest ones for me were always the navigation assists and syntax coloring., e.g. Ctrl + left-click to open includes/go to function definitions, etc. Every once in a while, having the code snippets and refactoring tools was useful. The jump-to-definition shortcut is available on F12, but having a universal "go to the thing I clicked on" is far more convenient, in my opinion. I do a lot of code exploration/discovery, and that's probably one of my most-used GUI features. Newer versions of VS have better syntax highlighting, so it's not as big a deal, but VAX is far more configurable in that regard.
VS's white space behavior is configurable, so I'm curious: what particular thing is it that VS cant' do that Sublime does? 
If using Qt there's QCustomPlot
ROOT is two things. In one way it is a C++ library with a bunch of classes and, IMO, the most useful part is how easy it is to save objects to files. For example, using a `TFile f;` you could have a histogram, say a `TH1D h;` and save it to a file with `f.WriteTObject(h);`. Then you could quit ROOT, open the file again and read the histogram in with `TH1D* h = dynamic_cast&lt;TH1D*&gt;(f.Get("h"));` (assuming `h` was originally created with the name `"h"` - more on this later). In the other way it is an environment. If you run `root -l` (no splash screen), it dumps you into an interactive C++ shell. With ROOT 6 this is powered by Clang. Yes, interactive C++. It has serious problems with `std::vector` or any template that isn't pre-compiled as it can't find the definition and compile it on the fly. So `vector&lt;int&gt;` works, but `vector&lt;MyClass&gt;` is nonsense, even if you `#include "MyClass.h"` in your interactive session (which works). The interactive shell can compile C++ code into a shared object, eg, if you have `MyAnalysis.cxx` then you can interactively execute `.L MyAnalysis.cxx+` and whatever functions you defined become available as compiled code. It creates `MyAnalysis.so` for you. If you close it and re-launch ROOT then type the same `.L MyAnalysis.cxx+` it detects nothing has changed so it just loads the library instead. In this way you do *not* need an `int main(int, char**)` to be defined - it can be whatever you want and you can execute it directly from within ROOT after loading the shared object. You could wrap this in a C "macro" (not a `#define`) which is simply a script meant to be interpreted. Here you'd have something like `{ gROOT-&gt;ProcessLine(".L MyAnalysis.cxx+"); Analyze(); }` -- as your entire file, no function name. You'd then run this as something like `root -b -q -l run.cxx`. The downsides are the memory management. It's not clear who owns what. For example: TFile* f = TFile::Open("test.root"); TH1D* h = dynamic_cast&lt;TH1D*&gt;(f-&gt;Get("myHisto")); delete f; By default, this code has no memory leaks! Because `h` is "attached" to "f" when you `delete f;` it calls `TFile::~TFile()` which calls `TFile::Close` and deletes any object created within/from that file. See, `TFile` inherits from `TDirectory` and there's a *global* `gDirectory`. By default histograms "attach" themselves to `gDirectory`. That is, all `TDirectory` objects store a list of attached objects - and since everything in ROOT is ultimately a `TObject`, this means a `TList` which is like a `std::vector&lt;TObject*&gt;`. Hence histograms attach themselves to the directory and the directory would therefore `delete` the histograms, so, for example: TFile* f = TFile::Open("f.root"); TH1D* h = dynamic_cast&lt;TH1D*&gt;(f-&gt;Get("myHisto")); h-&gt;Draw(); delete f; causes a blank canvas to load. It did draw the histogram, but then the file was closed and therefore the histogram was deleted. The way out of this is to add a call to `h-&gt;SetDirectory(nullptr);` before the `Draw()` command. This detaches the histogram from the directory it was attached to, as histograms also know which directory they're attached to in addition to the directory knowing which histograms are attached. This attaching mechanism also works for `TTree` - a very powerful way to store event-based data. It could also work to think of this as the rows in a CSV file, except some fields (columns) can be `std::vector` of, ultimately, arbitrary objects (though `int`, `float`, `double`, and `std::string` are most common and work "out of the box"). Now as far as naming goes, we have things like this: TH1D* h = new TH1D("h","test",10,0.,10.); creates a histogram pointed to by `h` with the name `"h"`. You could then define a function, eg, TF1* f = new TF1("func","exp([0]+2.0)/TMath::Gamma(3.0*[1])",0.,10.); which creates a function (something taking two parameters, `[0]` and `[1]`) and then you may fill the histogram and then try to fit this function to it. You could do this with h-&gt;Fit(f); or h-&gt;Fit("foo"); The latter goes and looks for any `TObject` named `"foo"` which is attached to the directory, again relying on a global, and then uses it. In this way it can become confusing whether you're looking for things based on variable name or the `TName` attribute that almost all `TObject`s also have.
http://cppcast.com/2015/07/aleksandar-fabijanic/
From the title, it's not immediately obvious whether this is just about the POCO libraries or if it covers OSP as well. Can you confirm that there's discussion of OSP in there before I spend time listening/searching for that content?
All good, did the gtags-auto-complete for a long time until clang-ac, then irony, now r-tags caught up. I do embedded work and tmux doesn't support serial terminals (boo). Also I've had some serious issues with tmux and key input with urxvt. Luckily, most of customization crap that people do with screen and tmux doesn't matter, because I can do window splitting and customization on emacs. :)
That was on Ubuntu 14.04 LTS. clang was from the official llvm ubuntu ppa's, I believe I used 3.7.0, and I'm also using the Ubuntu toolchain-r ppa. Maybe LLVM/Clang on OS X use the gold linker by default?
Aren't the Power Tools for C# and VB only (possibly managed C++)? And peek definition is handy, but the VAX shortcut is generalized, and will open includes/find types/go to functions/etc.
I don't know about OSP, but my experience with POCO has been pretty negative. I worked on a codebase that used POCO for XML handling and a few other things, and it was the source of several annoying problems. Most notably it threw an exception inside a destructor, unrecoverably crashing the application (since the exception was thrown whilst unwinding another exception). Also its XML API was awful. Our use case was searching for all of X's child nodes of type Y. POCO had a function to do this, and it returned a "NodeList" (paraphrasing from memory). NodeList had a `size` method, and a `operator[]` method, so the results were accessed using a simple for loop, much like iterating over an array. The problem was, whoever implemented this decided that NodeList should have lazy evaluation, so when you ran the search POCO did nothing. It simply instantiated a NodeList with a pointer to the node whose children are being searched, and the type of children being sought. The child-by-child search was run from scratch on **each** call of `operator[]`. The performance was horrific. When we diagnosed this, we just performed the search manually, doing a `nextSibling` traversal. I'm sure it's not all bad, but my entire experience with it has left me very dubious of the POCO libraries.
Thanks for the info -- my code seems to build on Ubuntu 14.04 with LTO enabled. Digging under the hood there is some regression related to lto_plugin not identifying itself as GPL licensed in binutils 2.25.1 [1]... go figure. [1] https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=799581
OS X has a different executable format from linux (mach-o rather than elf), so it uses a completely unrelated linker named ld64.
It still looks bad, see: http://stackoverflow.com/questions/31355692/cmake-support-for-gccs-link-time-optimization-lto
Hm, that's too bad. That's the first distinctly negative thing I've heard re. POCO. Thanks for the input!
Make your own custom toy image file format and try to make it portable on different CPU architectures. You'll learn about: * Using STL streaming classes and their performance implications * Issues related architecture endianness * Issues related to type safety and conversion * Designing data structures for accommodating images in different colour formats * Data transformation problems * Data organisation in memory and in a binary file * Memory management (especially because you'll deal with large data) * Problems related to large data ownership transfer and their potential performance penalty (or the lack of) * Buffering and memory safety, including issues related addressing large multidimensional data * Manage a project for cross platform targets * And if you are adventurous, explore data compression algorithms Some of this may sound advanced, so keep your toy image format simple for a start. 
&gt; It only ports declarations for which the type of the left hand side matches the type of the right hand side without conversion. I approve of this. 
The VS debugger is just very powerful, if not one of the best IMO. Persistent watch lists to compare between runs, pinning variable values inside the code editor beside the name while stepping, and also being able to expand arrays/container classes to view data inside them seamlessly. I don't know if Linux IDE's have these features, but I can't remember seeing them. Though its been a while since I last used one. Built in source control is also nice. I can see where other collaborators have made edits to the code from within the editor, and then go and view/compare history of code blocks. I can of course commit, manage branches, etc from within the IDE. I think eclipse has a Git plugin, but I don't know it well enough to comment on it. It's also very stable. Last time I used Eclipse (which was long ago, so grain of salt), it crashed very often on large projects. I also have plugins like Nvidia Nsight for graphics debugging from within the IDE, which helps with game dev for profiling/performance. VS projects for C++ are also just very easy to use and create build systems to control directory structure and making building a project quick and easy, especially when shared with others. You don't need to recompile a ton of dependencies if you just share static libs with your project. I can just download a VS solution and build it outta the box regardless of dependencies (usually). CMake is pretty good and cross platform, but older projects that use heavy plain make files are just really messy to me. C++ just doesn't have a good standard build system, but that's a whole other issue. There's just a lot of quality of life features in the VS ecosystem, and many I haven't touched on. Even MSDN is just a fantastic resource on all the Microsoft API's. This is something Microsoft has overall done well.
Operator new almost always ends up calling malloc unless you're using a specialized allocator, at least in all the stack traces I've looked at recently.
Ok. Why?
Consistency with the [most vexing parse](https://en.wikipedia.org/wiki/Most_vexing_parse)
This is one of my reasons for deciding against almost always auto. https://www.reddit.com/r/cpp/comments/3m0d41/writing_good_c14_by_default_herb_sutter/cvgopk4
It's all stuff gdb has but a little nicer with a UI. Hovering over symbols to get a little readout, pin a little watch symbol dialog to the editor somewhere, dynamic breakpoints you don't need to write code for. Admittedly you need to use a mouse to get a benefit for a lot of this stuff, but I don't feel like trying to type it out each time I hit a breakpoint. Anyway, it's things that the cli can do too, there's just less effort to get the data. Maybe someone else can give you a more indepth answer. Interestingly, I prefer ipdb to an IDE for Python. 
Is QtCharts still commercial only?
gnuplot can be invoked as a sub process. thats how we use it.
&gt; Visual Studio on ... Android. Remote desktop?
&gt; The things you are proposing are features that would be used by 0.00001% of all C++ programmers. well library writers are at least 0.1% and many of the new c++ stuff is intended mainly for library writers
So you use VS **for** Android development not on Android.
Of course. The only on Android IDE is AIDE and is still miles away of a proper developer workstation experience. 
No worry, I will:-)
Thanks! 
I'm hesitant just because the concept is to new to know. It's such a dramatic shift in coding style, and we don't have enough experience with it to know what the cons might actually be. The devil you know vs. the devil you don't.
What would help you get to that point?
For C++, CLion. The 2016 version is finally fast enough.
The lack of per-project whitespace settings has always confused me. It seems like such an obvious feature to have but neither of the IDEs I use regularly (Xcode and VS) support it.
&gt; Now someone who is for using auto everywhere will share some nicely written generic snippet using only obvious standard library idioms that everyone is familiar with and assert that it's quite obvious what is happening without types. That's exactly why I used the tool to port Qt. I'm sure you can find examples there and make claims one way or another, but with the advantage that they are not 'manufactured snippets', but very real code.
I applaud you for trying it out in a real project and for the technical challenge and for the alliteration. That's not really my issue though. As you say, I'm sure I can find examples where readability is and is not harmed by using auto. And I'm even more sure my opinion on where it's okay or not will differ from other peoples - particularly depending on their experience level with QT (I have none). But even if a loss of readability is rare I don't consider whatever advantages there are to be gained by using auto to be worth it.
Weaknesses IMO: * Lack of simple asynchronous I/O interfaces. * Lack of template templates. * Complex rules for working with parameter packs. * Lack of pointer to rvalue. * const&amp;&amp; * Macros, preprocessing, headers. Especially forward headers. * No native uint8 type (uint8_t is usually an unsigned char). * Poor UTF8 support. * C syntax * Initializer list requires const... * No native enable_if * No parameter pack expansion in inheritance * No dynamic reflection for more complex types. * No native go-style interfaces. (other than std::function, but this only works for functions.) * Sequence points. * Lack of fast select-style interfact for std::future. * Lack of template or auto overloads for member functions on references of constness of this type. * Lack of transaction safe stamdard containers. * Lack of constexpr std::array. * Lack of flat maps, ARTs, etc.
Variadic template support! Finally!
I wonder if they should just bundle Clang and use it for in-IDE source parsing. The *only* reason I'm using CLion is it is one of the very few C++ IDEs that let me group my files in my project exactly like how they're layed out on disk. Most IDEs will split the .h and .cpp files into separate trees in the project view, which pisses me off. **I** organize my files. Not the IDE. Me. Grr. I miss XCode, but lack of Vulkan support and broken thread_local (thanks, Apple!) is forcing me to jump back to Win/Linux. :(
It's pretty neat. Simple, yet elegant. My favorite part: template&lt;typename Fun&gt; void wait_for(const Fun&amp; fun) { while (!fun()) { yield(); } } I'm stealing that. Edit: I Guess fun is short for function, but I prefer the way I interpreted it.
I use Qt Creator(MinGW &amp; MSVC) and Visual Studio 14 as a complement . 
&gt; I applaud you for trying it out in a real project and for the technical challenge and for the alliteration. Haha, thanks! Yes, this is something that everyone has a different opinion on.
Consider posting this on /r/gamedev, there should be at least a few people interested :)
kdevelop doesnt do that. other IDEs (that I know of) do though.
Eclipse does not do that either.
It's really not as simple and awesome to use clang for indexing as people think. Clang is a full on compiler, it has to be perfectly correct, even if it's slower. For instance, clang has to (in general) reprocess every file that #includes file.h if file.h changes. Eclipse and probably CLion only index each .h file once, they don't index it in place in each .cpp file where its included, because this is too costly. But because of the preprocessor, a given .h file could actually expand to completely different things in different .cpp files (if different macros have been defined by earlier includes, for example). This is just one example, there are others. It's an interesting fact that QtCreator has integration with clang, and yet only uses it for finding errors in the current file and auto completion and syntax highlighting. They said it's too slow to use for code navigation.
This is annoying, but I haven't seen it come up often enough to be worth adding additional complexity to the language. const-overloaded member functions are relatively rare and typically have very small function bodies, and the workaround (just write the stuff out) isn't very obnoxious. The one time I wanted this was in bind()'s function call operator. In contrast, explicit-overloading appears to be increasingly necessary (as tuple, variant, and other wrapper classes have found), often applies to complicated constructors, and has a very obnoxious and spammy workaround. So I think that `explicit(COND)` would be worth the increased language complexity.
I'm currently trying to implement my own coroutines based on [this article](http://www.akira.ruc.dk/~keld/research/COROUTINE/COROUTINE-1.0/DOC/COROUTINE_REPORT.pdf) (It's a different concept of coroutine - but works). I'm still wrapping my head about how storing the stack works there so I can do it on my own, but I've got the control logic laid down. It uses setjmp and longjmp.
The C++17 proposal (http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3708.pdf) seems based on boost, and thus has the same drawbacks except, of course, by being standard the problem of portability would in theory be moot.
The topic is the language, not the standard library.
Kdevelop. Runs fast, excellent C++ support and doesn't get in the way.
I agree - standard C++ badly needs this. I really love printf-style formatting, and this is how I get that for std::string: https://github.com/emilk/emilib/blob/master/strprintf.hpp https://github.com/emilk/emilib/blob/master/strprintf.cpp
Do you happen to have where in the standard that these unusual overloads are speced? I'm unfamiliar with them and would definitely like to read up on it.
As long as there's some correspondence between code style and the project structure it shouldn't be too big of a deal to split them up into different projects all in one solution (and with the given examples you'd probably want them in separate projects even if the IDE didn't force you to). If you have fooA.h and fooB.h that are right next to each other and are the same "type" of header but have different formatting then putting them in separate projects would be excessively weird, but at that point I'd argue that you're well past the point where it makes sense to bite the bullet and reformat them.
gnuplot-iostream is a nice library for calling gnuplot from your programs
Just take it for free, VS 2015 compatible: http://pastebin.com/r5mhzqEU
Another thing that modules can do is allow Foo to drag in Bar for its definition, but importing Foo won't import Bar (unless you want it to). This is something that is not possible (for templates) with the inclusion model - if I want vector to use lexicographical_compare(), I need to drag that in, and it's visible to my users. (Unless I try to get sneaky by dragging in a common internal helper, but you're still going to have to compile an equivalent amount of machinery.)
That example is somewhat more convincing than classic ones like vector op[].
[Clang has its own module system](http://clang.llvm.org/docs/Modules.html), but my understanding is that this isn't being actively proposed for standardisation. Rather, the plan is that Clang will adopt the Microsoft proposal once it's sufficiently mature.
Just curious what your goal here actually is? Why not just create a struct? Is it because you want generic iteration or something like that? Also, why inheritance and not encapsulation? You could also just define an enum with levels channel_info and user_info, which would make it more clear what you're doing when you call std::get.
&gt; You could also just define an enum with levels channel_info and user_info, which would make it more clear what you're doing when you call std::get. One can use `std::get&lt;channel_info&gt;` and `std::get&lt;user_info&gt;` already in C++14.
Well, it's actually std::get&lt;bar&gt;, std::get&lt;baz&gt; in the above example, but yeah. That obviously only works if they have distinct types though, I'm assuming that's not always the case.
Haskell person thinks he knows something.
this sounds interesting to me, but I'm not quite qualified cause my experience has only been with Windows graphics apps. I have great interest in learning to use and apply the new Vulkan API for cross platform graphics. What do you think of Vulkan?
thanks :)
Hmm not really. I may lack some installed package, but via systemsettings I can only set the GTK style for applications (GNOME Application Style). I can change the Qt app styles with qt-config-qt4, but I don't have the themes you describe. I am also looking to set up a local (per-app) setting, so I doesn't screw up the theme of all my other apps. And I really can't live without my current tiling wm, so switching to KDE is not an option :p
I don't, no. I could learn I guess
Reading that you are evaluating writing a proposal already makes me quite happy ;) Would really be nice if you push this as much as possible.
As a GNU/Linux-user my preferred way is getting a pasteable list of package-names that I should install, but I am perfectly fine with simply a list of the dependencies as well, as long as they are not too exotic. I strongly dislike language-specific package-managers or software that carries (likely outdated) copies of the used libraries for a multitude of reasons.
+1 for Boost.Coroutine. Proper, leightweight and portable coroutines. To me, OPs implementation is more like an abstraction layer for std::thread, which I wouldn't really call coroutine.
What exactly are those drawbacks you are talking about? I find Boost.Coroutine very easy to work with. It only has advantages in my point of view.
I find it pretty useful to augment the expressiveness of the language for a specific domain. But I agree that when used abusively it can be hard to understand. In the case of silicon I find it pretty minimal and I did not find any problem with it. Note that I wrote the library so I may be biased.
This is an excellent post. Thank you. Just a comment about this: &gt; This should significantly speed up compilation times. I think Borland's C++ already optimized this by keeping precompiled headers in cache, that was 15+ years ago. I'm guessing other modern C++ compilers do the same? It'd be pretty stupid if they didn't.
With the compute power available now, I can't believe that we worry so much about compile times. There are other reasons for modules, but compilation time shouldn't be one of them.
Are there any detailed comparisons about the two proposed module systems and their respective pros and cons?
Have you ever tried compiling, say, WebKit or LLVM from scratch?
Myself and one other are developing a mod for a game, 2 hour compile time unassisted, 15m with 8 core incredibuild. Lotta source mang.
Does anyone used some of the module system? Any experience with the reduction of compile times?
&gt; The only thing it can't have is preprocessor macros. I thought it _can_ have them, but using macros in your module won't export them (like how using macros in an include will bloat your code right now).
Not that I am aware of. Basically Microsoft's proposal adds new keywords and excludes macros. To use macros you will need to include them separately. Clang's approach requires external module definition files that are given as extra arguments to the compiler instead of extending the language. They also support macros.
Was it an issue with compiling Boost.Context for iOS / ARM? It should work fine as far as I know, but might need tweaking of some flags.
Some, but fewer and fewer with each version of the standard.
Agreed, but I just don't see much benefit in removing it.
If you appreciate this video series, please consider purchasing it from O'Reilly http://shop.oreilly.com/product/0636920049814.do
I learned all I know about SDL from [Lazy Foo](http://lazyfoo.net/tutorials/SDL/). His code is not exactly modern C++ (you won't find a single unique_ptr anywhere), but the tutorials are pretty comprehensive.
&gt; One downside, though not major, is that there are additional dependencies in the build system: C.cpp and main.cpp can no longer be compiled concurrently. I think this is pretty major. Not being able to use/implement parallel compilation is a non-starter in my books.
The pros and cons of clang modules based on my experience with using then in obj-c: Pros: * They sometimes just work with zero code changes Cons: * They don't actually do anything useful. While they hyped big compilation speed improvements when they announced modules at WWDC, I've never seen a speedup worth caring about from enabling them. AFAICT they're actually just a Swift compatibility layer that was sold as a useful feature so that obj-c libraries would work in Swift from day 1. I also think that Apple's module definitions for their system libraries make a pretty good argument against the approach they chose. With modules enabled, including any system header will import the `Darwin` module. The `Darwin` module defines macros named `check`, `verify`, and `require`, because of course those couldn't possibly be names that existing programs might use.
We are working on [build2](https://build2.org) which does this (or will do soon). &gt; will "just use homebrew, yum, or apt" when available, and then download, compile, install when it is not I've been actually thinking about this idea. The `build2` build system already falls back on a system-installed library if you haven't provided an explicit import (and it's not bundled with your project as a sub-project). Calling `apt`/`yum` would be a natural next step. Though I think it should be done by the package manager, not the build system. The build system just needs to have a flexible-enough import machinery so that the package manager can plug in a step.
&gt; How do you think the library can help the compiler in these cases? Should for_each detect "segmented" ranges? Yes, so `for_each` would need to be written something like this: template&lt;class R, class F&gt; void for_each(R&amp;&amp; r, F f); template&lt;class R, class F&gt; void for_each_impl(R&amp;&amp; r, F f, std::true_type) { for(auto&amp;&amp; x:r.get_segments()) for_each(x, f); } template&lt;class R, class F&gt; void for_each_impl(R&amp;&amp; r, F f, std::false_type) { for(auto&amp;&amp; x:r) f(x); } template&lt;class R, class F&gt; void for_each(R&amp;&amp; r, F f) { for_each_impl(r, f, has_segments(r)); } Here is the paper on segmented iterators from 1998 where this is based on: http://lafstern.org/matt/segmented.pdf 
You'll still get parallel compilation, but just with more dependencies that reduce what can be done in parallel. If your code is big enough for parallel builds to matter, there will still be plenty that can be done in parallel, don't worry.
Thank you for finding the source, I have removed this post.
And g++? My cpp development is mainly on Linux / mint. Thanks for the information in anycase! 
The question then is why not use SFML? witch is made in C++ and not C like SDL. http://www.sfml-dev.org 
Putting library headers in precompiled headers is bread and butter of a build. One puts iostream in the pch and pulls that MB in only once. Works wonders.
Well yes, but one puts 3rd party headers in. (3rd party being most of anything not being part of the lib/module being worked on).
Macros I think.
I was talking about Microsoft's version. I dunno how it works for Clang's. In the Microsoft case (where those `include`s are actually `import`s) the module simply doesn't see `FEATURE`.
Thanks for the information.
I haven't looked at KDevelop in ages. I'll try it again and see how it compares to CLion. Thanks!
It is tested on linux only. But it is supposed to work on windows if compiled with a working c++14 compiler (see clang on windows). Silicon contains only portable c++14 code.
No macros are used in silicon. GET and _procedure1 are two variables and the operator / build an object representing the HTTP route.
So they overloaded the / operator? That's pretty interesting. 
Thank you. Where can I find that operator overloading in the source?
I think your's it's a fair question, I don't understand the downvotes. Anyway SDL2 seems more portable than SFML
Already implemented in GCC 6, see https://gcc.gnu.org/projects/cxx-status.html#cxx1z
&gt; While they hyped big compilation speed improvements when they announced modules at WWDC, I've never seen a speedup worth caring about from enabling them. I've never used them on a large C++ project, but even on a small C++ project that included a bunch of standard lib headers I saw pretty significant improvements. If you've only ever used them with Obj-C then perhaps that's why you didn't see anything significant. &gt; AFAICT they're actually just a Swift compatibility layer that was sold as a useful feature so that obj-c libraries would work in Swift from day 1. It was primarily Google (Richard Smith, specifically) that drove them forward on C++, and swift compatibility really couldn't have played a role there. &gt; I also think that Apple's module definitions for their system libraries make a pretty good argument against the approach they chose. With modules enabled, including any system header will import the Darwin module. It's true that in order to make modules enableable with no source changes the module maps do end up replicating the indirect imports that are implicit in the normal #include system. That is a bit disappointing to someone looking to actually detect and correct places where they're accidentally relying on indirect includes. However this is not something that's set in stone and can't be changed. It's simply how they chose to write the module maps. Right now you could write different module maps that don't have these implicit exports and get strict 'include-what-you-use' behavior. I think it should be changed, and the module map system should be enhanced to support both cases; migration to modules with no source changes and also strict 'include-what-you-use' behavior. This could be done with a new module map keyword to distinguish whether a module is supposed to be exported or whether it should only be exported for compatibility.
&gt; Clang's approach requires external module definition files that are given as extra arguments to the compiler instead of extending the language. They also support macros. The module map files are only to support legacy (or backwards compatible) libraries; the idea all along is that there'd be a source level interface to support modules natively. Module maps don't typically appear as extra arguments; clang has a method of finding them based on what files are included. Also, 'they support macros' is too broad a characterization. Clang modules can export macros, which is necessary to support libraries that provide part of their interface in the form of macros. They do not import macros defined anywhere in a translation unit, and so are protected against a user doing something like `#define FILE`. This means that the stdlib implementation no longer needs to use __double_underscore identifiers everywhere. They do support importing configuration macros, as required by some libraries, but only when defined on the command line, and a module can be completely isolated from any macros they do not explicitly declare as a dependency.
&gt; I guess it depends on what you mean by public. Work continued in the open and clang modules has supported C++ for some time now. Besides the WWDC talk when modules were introduced and some LLVM talks on the matter, the modules ISO C++ mailing list was pretty silent and the clang documentation hardly changed between releases. Given that I spend most of my time on Windows, I hardly played with them.
`template&lt;typename T, int Foo, int Bar, char C&gt; struct MyAllocator { /*...*/ };`? This obviously implies that the values must be known at compile-time, which I would find odd for a 'handle'. I suspect what you really want is to follow /u/mtclow's suggestion.
My two bits: It's impossible to say without knowing you much better, but if you're new to programming, it's going to probably be a bit uphill no matter what. :-) If you're about to take two semesters of C++, then get a head start and learn C++. C++ and Java look similar, but have hugely different semantics-- you're best off treating them like separate animals. Likewise, learning C first probably isn't the right way to approach C++ in 2016. Bjarne Stroustrup's "Programming: Principles and Practice in C++" sounds like it will be about perfect for your situation.
Why not pass the "handle" to the allocator's constructor?
Every type that uses an allocator also takes one as a constructor argument. I.e., you would need to pass in an instance of `MyAllocator&lt;&gt;` when constructing the vector.
Thanks, both of you. That did it. Unfortunately, it looks kind of ugly, especially the code duplication since I have to pass the type twice now, when constructing a container: template &lt;typename T&gt; using MyVector = std::vector&lt;T, MyAllocator&lt;T&gt;&gt;; MyVector&lt;int&gt; myvec{MyAllocator&lt;int&gt;(my_handle)};
&gt; It's true that in order to make modules enableable with no source changes the module maps do end up replicating the indirect imports that are implicit in the normal #include system. That is a bit disappointing to someone looking to actually detect and correct places where they're accidentally relying on indirect includes. AssertMacros.h is not an indirect import of anything. There's zero system headers that include it, but because the modules were originally too coarsely defined (it appears to have been fixed in the modulemap shipped with 10.11), enabling `-fmodules` resulted in *more* things being dragged in, and consequentially required source changes to work around the resulting name collisions.
Aren't all those tutorials still using SDL 1.2? SDL 2.0 changed a lot of things.
Well, one of the things is that you're not always writing templates. Another thing is what /u/sakarri said, although you can limit what is allowed for `T` via SFINAE, but the error messages aren't exactly nice, nor is it nice to write. And in [this talk](https://www.youtube.com/watch?v=wQxj20X-tIU) Scott Meyers explains the rules that go with type deduction, thus including auto. And it's rather complex, I personally find not using auto is less complex and more readable.
C++11 tests and explanation with quotes from the standard [cppquiz](http://cppquiz.org) 
While this is neat, and also was discussed here [0], I don't know if doing this within `for_each` is something we want because it makes the range-based for loop "weaker" somehow. Also as Eric points out there, it basically requires a second version of every algorithm which is a lot of work and I think it sucks (there is probably no way around it though). This would be a nice GSOC project actually. [0] https://github.com/ericniebler/range-v3/issues/83 EDIT: re-reading the paper (once again) I still don't know why the non-segmented iterator version is slower. Why can't the compiler transform one version into another? Is it just that we haven't bothered trying or is there a significant limitation? The paper doesn't explore this in any way, and I don't see why such a transformation is not possible.
There is only one proposal for modules, as I've said on numerous occasions, not least right the days after the Jacksonville reports. Chandler Carruth and Richard Smith wrote a proposal (also discussed in Jacksonville) about various amendments. I would encourage you to read it.
Here's the GCC commit: https://gcc.gnu.org/viewcvs/gcc?view=revision&amp;revision=234191
The module proposal is fully backward-compatible with C++. I don't know there is a second module proposal - some people invoke it on The Internet, but I have not seen it. What did materialize in the pre-Jacksonville mailing is a set of amendments proposed by Chandler and Richard; they were discussed at the Jacksonville meeting. But, it does not amount to a competing proposal. Please, have a look at the paper. Also, *these amendments do require source changes.*
After overusing `auto` a lot I now only use it when "i don't care", while prototyping or when writing very very generic code. Knowing what the types are (as in being able to read the types) does help me a lot to reason about my code. The main problem is that `auto` tells me absolutely nothing. In particular, people should think _thrice_ about using `auto` in function signatures. Don't be lazy, write the damn return types, this: auto returns_vector_foo_it_or_not(); is just horrible documentation-wise, it doesn't tell me anything. There are some situations when you have to return `auto` (e.g. like returning a lambda or an anonymous struct from a function), but I really hope that concepts will kill `auto` in most situations. IMO: RandomAccessIterator returns_vector_foo_it_or_not(); is much better than ` auto returns_vector_foo_it_or_not(); `, and this: RandomAccessIterator it = returns_vector_foo_it_or_not(); is much better than this auto it = returns_vector_foo_it_or_not(); With concepts I at least know what `it` is supposed to be, with `auto` I have to ask my IDE or start "following the code".
For my part, I've consistently explained that there was only one proposal... At the Summer 2014 meeting in Rapperswil, where I first presented the design, I didn't see or feel any expression of desire to have a competing proposal. The day after the presentation, Doug Gregor, Richard Smith, David Vandevorde and myself got together at lunch to discuss where we wanted to go next, and what technical problems needed more investigations, etc. At the Lenexa meeting, Spring 2015, Jason Merrill, Richard Smith, and myself got "locked up" in a very nice Indian restaurant, trying to find ways forwards with the module design under discussion. And much progress happened there, as reported elsewhere. All these people I mentioned participated in the reviews, they provided good feedback. I've tried to acknowledge them in the design paper. If I omitted anybody, let me know so I can fix that. But, I kept reading about competing proposals on The Internet, every now and then. Please have a look at Chandler's and Richard's paper. 
https://www.brainbench.com/ - c/c++ online certifications
What part of SDL do you want to know about? The API wiki on their website is pretty straightforward, with plenty of code examples. Their 2D renderer is very simple to use. The audio stuff can play .wav files pretty easily, but you're left to your own devices for real audio mixing or using another library (like SDL_mixer) 
In my case I have a "protocol_signaler_socket". Long story short it's a bunch of templates that allow me to write, e.g.: using socket = iev::ip4::udp::iev_protocol_socket&lt;protocol::connect, protocol::message, protocol::disconnect&gt;; using packet = socket::packet_type; And then connect it by writing the functions in my class like: void receive(iev::ip4::address addr, iev::ip4::udp::port port, protocol::connect) { ... } The quickest way to get this working is to subclass tuple, which the (de)serializer understands, and hence changing the network protocol is as simple as adjusting a few class members or adding a new type to the protocol definition. As I prefer to use .user_info() over std::get&lt;0&gt; etc, I want to make it as painless as possible. 
Every time I read sock_fd I always imagine a "sock file descriptor". Like it's writing to a file to keep track of socks. Much easier to organize pairs if computers keep track of where each sock is.
I like sublime. It's fast and you can navigate code quickly. I'm working on my vim fluency but sublime has less of a learning curve while still being powerful. I use cpplint or cppcheck.
Robotics engineer here. Also C++
After you get started with the language, I'd start watching talks on C++ from conferences like Cppcon, especially ones that talking about using more modern features of the language. You dont have to immediately try to learn everything they are talking about, but having simple exposure to language features really helps when learning. Eventually you'll hit a situation where you go, "wait didn't I hear about this somewhere?" Then you can go back and start to better understand the concepts as they come up. In general, it's better to have a list of unknowns when learning as opposed to not knowing what you dont know. As far as whether to learn C before C++, at this point in time they are completely different languages which only look they same. One of the reasons C is a very important language is that the meaning of the code you write and how it maps to the hardware is more or less obvious. C++ has the philosophy of trying to provide high level abstraction while still having one of the fastest runtimes. It is much easier to start with the natural solution to a problem and bend C++ to fit the problem than it would be in C. Also, if your class progression is leading you towards Java, then C isn't going to help you much.
Checkout [Sanfoundry.](http://www.sanfoundry.com/) They have 1000 code snipets for each of the major programming languages including C, C++, C#, Java, PHP, Python, R, etc. Each of the 1000 code snippets is followed by mutliple choice questions asking what the snippet will do. Here are the [1000 C++ multiple choice questions](http://www.sanfoundry.com/cplusplus-interview-questions-answers/) organized by language feature. 
Code Blocks and VS
For anyone, like me, used to programming in visual studio and notepad++, in linux there's nothing like it. They all program in vim or emacs or basic text editors. It's really frustrating for me when I have to deal with linux now. They barely know what a debugger is. They use print lines to debug stuff, insane. Code::blocks is the closest you could get to ide, but it has it's own fair share of problems and debuging is nothing like in windows, it sucks. I'd like to work with linux, but it seams open source is stuck at console, script file and command line tool ages. Linux is like an alternative universe where people instead of inventing guns and machines and all that stuff that makes war 100x more efficient just made increasingly better and fancier swords and just dismiss guns ans "unmanly".
It is both. First, you have everything to build a RESTfull HTTP server: - Parameters in the url - POST and GET parameters There is actually a meta SQL REST api here: https://github.com/matt-42/silicon/blob/master/silicon/sql_rest.hh#L57 It is also the second one because Silicon provides a generic C++ HTTP client. You can see how it is used to test the sql_rest api here: https://github.com/matt-42/silicon/blob/master/tests/rest.cc Note that libcurl_json_client generates an object with one method matching each API call, this is why it takes the api as argument. This is done with compile time static introspection of the api. The implementation is here: https://github.com/matt-42/silicon/blob/master/silicon/clients/libcurl_client.hh 
If you thought this was bad, the next post &amp;ndash; [How to crash your PC](http://sayangoswami.xyz/blog/how-to-crash-your-PC/) &amp;ndash; is even worse. I... just... I can't even. He seems to think runaway memory allocation will crash a modern OS, and he thinks the most effective way to do that is `new long double`. Just... WTF.
Now all we need is for range-based-for to have some way to unwrap iterators. As it currently is, I still use std::for_each simply because it performs better in DEBUG. 
Since C++14, you can use [this](http://en.cppreference.com/w/cpp/string/basic_string/operator%22%22s). It comes in handy in situations like [this](http://ideone.com/B4x3oy).
You mean if you want to customize the module with preprocessor macros? In that I think the module should just `#include` a config file, where you'll set those defines.
I used QtCreator for a little bit, but the "flat" project view isn't what I want. :( Good IDE otherwise.
xcode
Try to write something non trivial or read the source of a project on github, I think your shortcomings will be exposed in a much more practical way.
KDevelop 5 with clang parsing looks amazing, but building it is such a pain.
Any reason why? I found it to be quite useful in gcc.
Great news. His "Better Code..." series of talks (starting with "C++ Seasoning" at Going Native 2013) have been excellent, I look forward to the next instalment.
&gt; left to your own devices I see what you did there. Nice.
Thanks for pointing this out. That paper is exactly the sort of input I've been looking for from the implementers of modules in clang. For everyone's convenience, the paper is [P0273R0][1]. [1]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0273r0.pdf 
Nah, it may have been a reply from STL in reddit but I don't remember. I think the main point might have been about the default behavior, if `for(e : elements)` behaved like `auto&amp;&amp; e` then that can be unexpected because the first looks like "value-syntax", i.e. one might expect a copy of the element, while it would actually be a reference. I might remember wrong though.
[Here's][1] a post explaining why. [Here's][2] a reddit thread posted about the proposal by the author. [Many][3] of the [responses][4] [reflect][5] [exactly][6] the [issues][7] that eventually resulted in the proposal being rejected. [1]: https://www.reddit.com/r/cpp/comments/2xe1yx/llvm_36_released/cp06ixx [2]: https://www.reddit.com/r/cpp/comments/1vxgeo/rangebased_forloops_the_next_generation/ [3]: https://www.reddit.com/r/cpp/comments/1vxgeo/rangebased_forloops_the_next_generation/cewzzqe [4]: https://www.reddit.com/r/cpp/comments/1vxgeo/rangebased_forloops_the_next_generation/cexo4ky [5]: https://www.reddit.com/r/cpp/comments/1vxgeo/rangebased_forloops_the_next_generation/cewq8m8 [6]: https://www.reddit.com/r/cpp/comments/1vxgeo/rangebased_forloops_the_next_generation/cewqx4q [7]: https://www.reddit.com/r/cpp/comments/1vxgeo/rangebased_forloops_the_next_generation/cex4oyc 
pkgconfig is probably the simplest light-weight way to do this. Most libraries these days ship a .pc file that lets you use pkgconfig.
well, they could've kept &amp;&amp;/&amp; just omit the auto keyword. But whatever, it's just some extra sugar and it's not that important.
Interqiew has some interesting C++ tests: http://www.interqiew.com/tests?type=cpp They also have C++ based design pattern questions: http://www.interqiew.com/ask?ta=tqdp02&amp;qn=1 
 [Papers and Presentations](https://github.com/sean-parent/sean-parent.github.io/wiki/Papers-and-Presentations) by Sean Parent.
Just because you stated you were new to programming, Im going to explain something that I really really really wish someone had outlined to me when i was first beginning with Java. This is the hierarchy of interacting with a computer. It must be understood that by "programming", you are literally manipulating raw hardware through levels of abstraction. This hierarchy will progressively move away from hardware, but it all boils down to 0's and 1's. 1) Hardware - this is the lowest layer in which all abstraction is based on 2) Assembly level - these are very low level commands that everything must be explicitly "told" to the computer. There are no "functions" or anything like that. These are just raw instructions that get send to the processor to perform. 3) C - this is the lingua franca of computer science. Anyone that tells you knowledge of this "isn't needed in the industry now-a-days cause of Java/C#" is an underachiever and will never truly understand the ART of computer science. Yea, they might be a good programmer/have a good job/whatever, but this is a necessity to master the art. 4) all other languages - these are all built on the constructs of C and "blackbox" C procedures in an effort to simplify the life of the programmer. ABSOLUTELY ANYTHING YOU CAN DO AT THIS LEVEL CAN BE DONE IN C. Do I recommend this? Absolutely not. That's like using a screw driver to build a house instead of using a power tool. But non-the-less you can do it. My personal suggestion would be to learn object orientated principles through Java. Do not worry about remembering the syntax(as your goal is C++ in a very short time). Even if you have to look up how exactly to create array, for example, thats fine because its going to be a little different in like every language and once you know 3 or 4, its just dumb to remember the fine details(memorization will come with time, and more importantly, practice). Just make sure to understand the concepts. Just know that this is a very "safe" language, meaning that it blackboxes some constructs that allow you to truly understand how programming works. But this will teach you the concepts(such as Inheritance, Polymorphism, and Abstraction) very well. From there, I would take literally 2 hard days learning Computer Architecture. (if interested, i can provide links/resources) TRUST ME, BEFORE VENTURING INTO THE LAND OF C/C++, YOU MUST UNDERSTAND THE MEMORY MODEL. If anyone tells you otherwise, trust me, they dont understand the true capability of C/C++. You dont have to understand how to build a processor or anything like that, just need to understand how a computer works under the hood. Then take 1 week learning C. Most of the beginner stuff like data types(char, int, double) and control flow(if, for, while) wont take long at all. The important differentiator comes when looking at arrays. Wont go into detail here about the specific difference here between Java and C/C++, but THIS IS WHERE THE DIFFERENCE IS. Once you learn arrays and pointers in C(dont worry about the term "pointers" now, if you understand the memory model, this will be cake. JUST PLEASE REMEMBER THIS WHEN YOU GET TO THIS POINT... THE NOTION THAT POINTERS ARE HARD IS A MYTH!!!). You will then be able to fill in detail for C++ from both Java and C. It will only be a matter of learning the syntax at that point because C++ uses a ton of stuff from C and Java is essentially the butterknife to the concepts of C++. Things to keep in mind... I know you are stressed for time, but i cannot stress this enough. Learning C++ is a major investment into your career. It is not something that should be rushed through. It is also not something that can possibly be taught in a semester. It takes 10 years to master C++. Even if you cannot find the time to complete what I just wrote up before your deadline, these skills are essential to mastering computer science and should be learned as soon as you can. Lastly, in case youre wondering what in the hell is the difference really: C is not an Object Orientated language. It is Procedural. A third option is called Functional. There is a huge difference here but to sum up why C++ is the best possible language to learn is that is a multi-paradigm language. You can program procedual-ly, functional-ly, or object-orientated-ly. This is powerful. 
No weirder than lambda captures.
I want to see a book from this guy. 
which is why im waiting for my distro to release the packages.
Sure. A graph is sometimes represented as a collection of nodes, plus a collection of edges, which are pairs of references to the nodes. For example, template &lt;class T&gt; struct graph { using node_type = T; using node_id = std::size_t; // index into `nodes` using edge_type = std::pair&lt;node_id, node_id&gt;; // {a,b} = edge from a to b std::vector&lt;node_type&gt; nodes; std::vector&lt;edge_type&gt; edges; }; `node_id` could be `node_type*` too, of course. Is that what you were asking?
You can't really have a linked list where the nodes don't have a `next` pointer. That's kind of the definition of a linked list. But, for example, you can have a binary heap stored [entirely inside an array](http://www.cse.hut.fi/en/research/SVG/TRAKLA2/tutorials/heap_tutorial/taulukkona.html) with no pointers. 
I don't understand why you would want to program like this...
I agree, to a degree. auto is convenient when it's obvious what a type would be from a function return or expression evaluation. decltype is underrated, I think, and adds a lot more readability to code. It says more than just matching the type of another variable, it says, "I want this one's type to match this one's type" and that's way more powerful than just having two ints. I can see auto being abused into oblivion but in small doses, it's kind of nice, I think.
C++ is great! But it's the largest and ugliest language to learn. There's a lot thrown at you at once and it takes years for it to actually settle in. Learning C++ is an ever-continuing journey. C++11 looks nothing like C++98, for example.
What got me to start using it more is the Projucer  they've made a bunch of changes lately (probably after being bought by ROLI).
Emacs does terms poorly, so very, very poorly. I even have an outstanding bug that discusses the breakage between ansi-term and bash for environment sharing. All of the options suck: eterm, ansi-term, serial-term. Eventually characters get dropped,misinterpreted and lines start disappearing. "reset" generally fixes the problem. Serial terms and ansi terms in gnu screen never need such upkeep.
What's "c++ OOP"?
&gt; no way to set working directory when debugging The working directory for run/debug was changed to the top-level project path a while back. &gt; setting variable values when debugging Use menu item Debug, Run Command, and for instance: "expr variable_name=123". See http://lldb.llvm.org/lldb-gdb.html for more lldb commands. 
I'm glad that you like it, we need more convinient tools to get more fun from coding :). See this issue for tips and tricks for editor integration https://github.com/cyrus-and/gdb-dashboard/issues/20 . It's defenitly not complete, I think we can get much more from integrating dashboard with vim and tmux.
Good to know that it worked on os x too :) I just fixed the typo. Thanks 
Does Tick work on MSVC (say, 2015)?
The Coroutine one seems so fundamental it is a pity its no even going to be a TS for 17 
This: http://www.nicolasdanino.com/tongji/OOAD_Booch_3rd_Edition.pdf 
For technical detail on how the majority of C++ compilers choose to actually implement objects, Lippman's old but still good "Inside the C++ Object Model" WAS excellent. Understanding what's happening on the inside adds significantly to one's ability to use it effectively from the outside. I say WAS because it is now twenty years old; I suspect it's still accurate as far as it goes, but in the last twenty years, C++ has come a long way. Late edit: quoted it in an interview yesterday when I was asked about the typical implementation of VTables in C++. Thanks, Lippman; nailed it.
Cool! Thanks for the info. I'll have to check it out.
http://q.viva64.com/
More generally, this should work: (it allows multiple parameters to be passed to the allocator constructor if needed without naming the type) MyVector&lt;int&gt; myvec({my_handle});
Interesting, that makes sense and fills in a few gaps, thanks.
Here are commonly used solutions for such problems. [1.:](http://en.cppreference.com/w/cpp/container/vector/reserve) pre-allocate array `arr.reserve(max_size)` before loop, of course this is not always possible. [2.:](http://en.cppreference.com/w/cpp/container/deque) use block/chunk array, that do not need to copy memory at all, by only allocating small memory blocks. Of course the second solution has overheads and should be avoided just like linked-list. Now try implement your idea correctly and compare (benchmark again) it this 2 solutions :) Something that may be related [FBVector](https://github.com/facebook/folly/blob/master/folly/docs/FBVector.md)
Your idea sounds a lot like the Extendible Array from Keith Schwartz. See http://www.keithschwarz.com/interesting/code/?dir=extendible-array The implementation is in Java, but the algorithm is described very nicely in the comments section at the top of the file. If you are interested in doing it in C++, this would be a very good place to start and then adapt to C++ and the STL. By the way, there are some nice implementations with explanations of some cool algorithms in a variety of languages (including C++) at http://www.keithschwarz.com/interesting/
Well, Qt is a good choice if you are coming from Java. I've written an overview a few years ago: http://meetingcpp.com/index.php/br/items/an-introduction-into-qt.html
They were already here in QtCreator 2.8 three years ago...
&gt; &gt; no way to set working directory when debugging &gt; The working directory for run/debug was changed to the top-level project path a while back. Yes, but I'd like to specify a custom working directory else have to type the full path to all input files in the debug command. 
You also add extra cost (the check, higher chance of cache miss, fragmentation, etc) to every usage of the array, so the array get, push back, remove, etc is no longer simple. If you look to try this besure to benchmark it. What works for one usage might not for others. Additionally you could focus on how to make your items move faster (not copy)
Can you comment on the differences between the two? Ive been doing some preliminary research and would love to hear some thoughts
nice work. Unfortunately, I'm on windows for work. I'll keep it in mind for linux. have you done any testing to see the speed bump is when calling the lib directly? the clangAutoComplete isn't to my liking. It seems to grab types instead of the actual member names, also it's goto def didn't work. maybe someone can comment but I set the includeFilesFolder to true and all the source code for the completions i was testing should be there. 
Thanks! Yes I'm mainly interested in QWidgets at the moment, QtQuick is too different to learn at the same time. Also I know I might need C++ / Qt in work at some point which is why I'd like to focus on Qt and not some other framework. 
I know that under clang's -Weverything there is a warning which will ping you every time they pad out your structs. That said, this may or may not be what you want - it complains if your structs aren't as small as possible, but you might *want* to order the fields with gaps if it lets you put hotter fields at the front, etc. I'm afraid I don't have an answer for a performance-based static analyzer in general.
With Widgets the tree of the GUI elements is built by creating C++ objects of corresponding classes (like Button or Label) and setting their parents, so they are visually one inside the other. There are some classes called Layouts that exist only to position their children in some specific way. The GUI objects can be created in C++, but there is also a visual designer that saves *.ui file with the definition of the GUI tree. Interaction with the data is done by connecting to signals of the GUI elements. For list/tree/table data structures there is a Model-View mechanism. There are widgets that can show your data if it implements one of QAbstractModel interfaces. There are a lot of Widgets for various things. To make a custom one, you override the paint method and do some raster graphics. I've heard complaints from the mobile developers about the QWidgets support for this kind of OSes. ***** In QtQuick/QML, the object tree is defined in QML language. So, the tree contains the GUI objects and your data objects (underlying implementation for the classes of the data-objects is to write in C++). Defining the interactions between the visual elements and data is done by connecting their signals/slots in the same QML source code. Your data objects also may implement the QAbstractModel interfaces for tables/lists: there are visual elements that can use it. TreeView was not implemented, but maybe it exists already. Until Qt5.6 there was a lack of visual Controls. But they are very easy to make because of the composability of QML objects: there are basic things like Rectangle, Text or MouseArea that are used to make very complex Controls. For the specific GUI elements you have to deal with 3D API in the C++ part (QtQuick runs directly on the 3D API), but it's mostly happens when you integrate your 3d scene anyway.
Well, you have namespaces, so it really a problem to drag lexicographical_compare()? 
So my first reaction was that instead of resizing and copying, you could chain multiple contiguous chunks... and then transform the indexes in your operator [] to pick the right chunk... This would allow you to extend your vector without copying... HOWEVER, I think this is basically what the deque&lt;&gt; container is! Further thinking about this, you might say that if you extend a vector enough times... such that you have many many linked chunks, you would start to have serious overhead in the index transformation process... I agree, but this makes me think you need a skip list... So, a skip list of vectors... But a skip list is actually similar to a tree... :) SO, you need a tree! :) std::map&lt;&gt; 
I'd suggest asking on /r/cpp_questions :-)
I will stick with CLion to be honest but Qt Creator is a really great IDE though, as it is really lightweight compared to Clion which uses like tons of memory just to open a small project containing just like 6 small files. But the problem with Qt Creator is the libclang library, it simply doesn't feel responsive as Clion/VS and the semantic analysis is much better in Clion which is a big surprise for me. The libclang integration needs much more improvements until it's really ready to go but the thing is, that most of the bugs I came across are in clang itself for example when parsing complex code bases I am getting internal compiler errors. So when the libclang segfaults you probably have to have for the next release of clang to eventually get a fix.
Anybody not comfortable using raw pointers should stay away from smart and raw pointers and use references for their own good. 
That it is also faster because the stack loves the cache and no thread synchronization is needed for the stack. :)
Needs more README. If I can't tell what it's intended to do I'm probably not going to read source to find out.
README has been updated
thanks man I'll get on them
The website seems to be broken on mobile, menu blocks everything.
Got the hamburger and it goes away.
Very interesting subject to me. Saving for a later read. Thanks in advance.
A colleague at work is using the latest 3.x version on OSX and I find the debugger awful to the point that I prefer using lldb from the command line when he asks me to help debug something. The debugger's output cannot always be trusted, sometimes it refuses to display variable values, and its ergonomy is generally awful. Plus, he experiences frequent crashes. 
I don't get it, I thought Windows didn't give you a choice of window manager?
you're right. It's a wrapper around the Win32 window manager that allows you to manage multiple OpenGL windows on both windows and linux 
Regarding module name and namespace: see the [design paper](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0142r0.pdf), section 4.3 (page 6). In existing C++, namespace span across translation units; so any attempt to tightly couple module name and namespace can only add complexity. And that coupling is not necessary. When one imports modules `std.containers` and `std.algorithms`, I suspect most people still want the containers and the algorithms to be in namespace `std`. Regarding transitional scenarios and macros, see this other [paper](https://isocpp.org/blog/2016/03/p0141r0) examining the issues and suggestions of possible paths. Please, abstract over the particular compiler switch syntax. --- I also want to take this opportunity to highlight an aspect of the WG21 process and design for C++ in general. What follows isn't a comment directed at you, it is a general observation since I've seen the pattern in many many posts, blogs, etc. so don't take it personally. I frequently read phrase like "Microsoft module". It is natural to try to label ideas. I would like for us to do that in ways that do not appear to pit various groups or corporates against each other, or to incite "competing proposals" when there is none. If I had been employed by Google or Facebook or Red Hat or Apple or Intel or academia, etc. I would still have made the same design suggestions as the ones currently being considered by WG21. For me, the need for a module system for C++ is a problem that the C++ community faces -- independently of who my current employer is -- so any good solution has to be something that primarily removes the pain points from the community at large. I would like the community to coalesce around good ideas than be distracted by labels of employers of who is making the suggestion. That is, in essence, why we have the ISO committee and the standardization process. I would not deny that working at Microsoft gave me the opportunity to have a certain view into how destructive macros are for the C++ developer community (hey, my team is custodian of MFC, and I've got to collaborate with Windows architects -- custodian of `&lt;windows.h&gt;` on a daily basis), but my views on macros were formed long before I joined Microsoft and they were public. Yes, I know macros can be useful; I've abused of them on occasion (see my GCC's `libstdc++` valarray implementation for example) :-)
It looks like that CMake it is.
What's the difference between TinyWindow and GLFW? Any advantages/disadvantages?
In general, exception handling support adds footprint to the binary output which may not be acceptable for some embedded platforms. Some other C++ features (RTTI) are similar in this regard.
Good work! Glad too see you spreading the word, will send more feedback this weekend
In addition to the speed and size considerations already listed, exceptions also make for less-deterministic behavior. A subset of bare metal software is safety critical and real time software. In those worlds, being able to predict how long the software will take can be critical -- completing too soon can be as difficult as taking too long. There is also the difficulty to ensure state at the end of a function if you're not sure which lines haven't been executed yet. 
I may be wrong about this, but I thought that the decreasing cost in exception handling was partially due to hardware changing? If so, that would suggest plenty of people may still be wring code for hardware where exceptions are more of a speed penalty than they are on modern PCs.
Now that I have found the link, and on re-reading it, I would like to backtrack on my original statement by a bit. But, I was not wholly wrong if the results are to be believed. http://h-deb.clg.qc.ca/Sujets/Developpement/Exceptions-Costs.html &lt;Can be bit tough to follow on small screen.&gt;
Okay but that is very simple explanation of class composition by inheritance and would work even without the templates. What about when I need to share member variables between these functions? How about the situation where the count and exact type of these member variables increase? What about if these functions may need to call member functions that themselves may or may not exist? Passing them in as parameters is not an option as I require a consistent interface. Also with macros I can place all the ugly stuff in a header and whenever I need to make a class that employs this behavior I end up with something like #include "macrologic.h" #define behavior1 #define behavior2 #define hasproperty1 #define hasproperty2 ... Sure I have one ugly header of macros that handles the behavior, but the tradeoff in simplicity for the 100 or so other headers that are just a list of properties far more than worth it.
Actually it allows you to provide your own shell, but the majority of people don't care. The only shell replacements that had any reasonable amount of users were a Windows version of AfterStep and another one, made by the company that did Stardock.
Please considering adding [WIN32_LEAN_AND_MEAN](https://support.microsoft.com/en-us/kb/166474) or VC_EXTRALEAN. Also NOMINMAX prevent `min` and `max` macros that conflict with `std::min` and `std::mac` and any other `min` and `max`.
Check the sidebar for the link to the recommended books list. I wouldn't trust anything in the dummies series. 
Thanks for the constructive review - I learned something!
Doesn't VC_EXTRALEAN only apply to MFC applications?
I think the Booch et. al. book is really great for getting a solid foundation in Object-Oriented Programming; but, remember that it's only one of many tools for solving problems with C++, you'll want to be able to draw on a variety of strategies.
Rather than about hardware, it is about hardware support in software, and more precisely compilers. Modern platforms typically have or come with modern compilers that implement exceptions properly. However, the only compiler available in some platforms is a fork of a very old version of some compiler that doesn't implement exceptions properly. So "exceptions" on that platform are slow, but it is a software problem, not a hardware one.
This is why having Concepts as a TS was a good idea -- figure these issues out before the syntax gets set in stone.
From the David Stone's [Writing Robust Code](https://meetingcpp.com/tl_files/2014/talks/robust_code.pdf) page 34: Performance of exceptions when not thrown * Tested on gcc 4.9.2 * Numbers relative to ignoring errors * With no destructors  12.8% overhead for exceptions  32.8% overhead for return codes * With destructors  6.3% overhead for exceptions  18.7% overhead for return codes And page 35: Performance of exceptions when thrown * Tested on gcc 4.9.2 * Numbers relative to ignoring errors * With no destructors  900% overhead for exceptions * With destructors  750% overhead And some benchmarks done by Bogdan Vatr in this thread: [What kind of airplane we want to build?](http://thread.gmane.org/gmane.comp.lib.qt.devel/24619)
Note about MS: the 32 bits ABI still suffers from a non zero-cost implementation as far as I remember, only the 64 bits ABI has been switched (for backward-compatibility reasons).
&gt; template&lt;typename T&gt; &gt; concept C = &gt; Regular&lt;T&gt; &amp;&amp; // requires-clause &gt; requires (T t) // requires-expression &gt; { &gt; typename T::type; // type-requirement &gt; requires X&lt;decltype(t.dm)&gt;; // nested-requirement &gt; }; Why not go all the way and base it closer on class/struct syntax: template &lt;typename T&gt; concept C { typename T::type; requires Regular&lt;T&gt;; requires (T t) { requires X&lt;decltype(t.dm)&gt;; }; }; The less "variations" in the syntax, the better, as far as I am concerned.
I thought about that and played with some options, but couldn't find a solution that I liked. The issue is that the constraints implicitly form conjunctions in the form that you presented. How would you specify disjunctive constraints? My attempts to do so always ended up leading me back to making conjunction explicit.
The #1 thing ALL these libraries lack is Windows support. This one is no different. Color in the terminal on *nix platforms is so trivial you don't need a library. Color in the terminal in a cross platform way is what I want from a library. It's not hard, just use the SDK functions for conio [I mean the SDK functions, not conio.h] I really should go write this one properly myself...
Digging around a bit, I was thinking about the x86 vs x64 ABI changes. As that impacts calling conventions, it does a bit beyond what I compiler can do without breaking compatibility. You are correct though - it wasn't a hardware specific change. A newer compiler targeting ABI compatibility with the older standards seems like it may be stuck following the older, slower way of implementing exception handling.
https://github.com/Armadow/ProgrammingIdeas/blob/master/README.md 
Any context? What is the game? How is this more impressive/insane than any of the other umpteen thousand games written in C++?
I have written a function that supports a subset of VT100 ESC sequences in Windows console https://github.com/aspectron/jsx/blob/master/src/console.cpp#L569
How do you make graphics like that in C++
Same way you do them in any other language? 
Hell nah. With C++? Are you joking me, I've never found a tutorial on doing stuff like that.. or even basic graphics.
There are a few SDKs that give you the ability to use the power of your graphics card to draw 3D graphics in a fast and powerful way. I would suggest starting with OpenGL (3.4+) or DirectX 11. OpenGL is available on most platforms and DirectX is only available on Windows platforms. Its been a really long time since I started learning graphics, so I'm not familiar with the best learning and tutorial sites today. Heres a couple of links I found to possibly get you started. https://open.gl/ http://d3dcoder.net/d3d11.htm
There are several engines in C++ that can do that. For example [Ogre](http://www.ogre3d.org/gallery) is a free, open source 3d engine that's written in C++
Bravo sir. I will keep these things in mind, especially computer architecture, and the memory model. And if you're reading this, I will take the links. 
I wasn't in the Library Evolution Working Group when this was discussed, but I think it was just because the function didn't do anything that couldn't already be expressed using shared_ptr's API. I agree that it would have been a nice convenience.
Given the advanced state of the `await`proposal (already has standard wording), a first version of the Coroutines TS containing just that could still be published in 2017.
I like this class-like syntax to group all the requirements. Should something like `template &lt;Regular T&gt; concept C { /* same as before, but without requires Regular&lt;T&gt; inside */ }` also work? Or would refinements of `Regular&lt;T&gt;` be more intuitive with inheritance syntax like `template &lt;typename T&gt; concept C : Regular&lt;T&gt; { /* same as before without Regular&lt;T&gt; inside */ }`? 
Lets hope so
The flat design is really beautiful. Note: the official release for Windows is only 32bit (I have managed to compile a 64 bit version with clang code model)
&gt;C++ Primer, 5th Ed, by Lippman, Lajoie, and Moo And make sure not to accidentally get C++ Primer **Plus** by Stephen Prata. It's a totally different book and it's terrible. 
The website is so bare metal that it's written in assembly
Where your program is the OS. Advantages (speed) and disadvantages (lack of ... everything, filesystem, networking, etc. unless you implement them yourself).
Here's a macro that facilitates this kind of thing. The first argument to this macro is the user-facing member name, and the second argument is the name of the static internal implementation, which takes a universal reference representing *this. //&lt;library code&gt; #include &lt;type_traits&gt; #define OVERLOAD_ALL_DETAIL(name, impl, qual) \ template&lt;typename... Args&gt; \ decltype(auto) name(Args&amp;&amp;... args) qual { \ using this_t = std::remove_reference_t&lt; \ decltype(*this) \ &gt;; \ return impl( \ static_cast&lt;this_t qual&gt;(*this), \ static_cast&lt;Args&amp;&amp;&gt;(args)... \ ); \ } \ /**/ #define OVERLOAD_ALL_QUALIFIERS(name, impl) \ OVERLOAD_ALL_DETAIL(name, impl, &amp;) \ OVERLOAD_ALL_DETAIL(name, impl, &amp;&amp;) \ OVERLOAD_ALL_DETAIL(name, impl, const &amp;) \ OVERLOAD_ALL_DETAIL(name, impl, const &amp;&amp;) \ OVERLOAD_ALL_DETAIL(name, impl, volatile &amp;) \ OVERLOAD_ALL_DETAIL(name, impl, volatile &amp;&amp;) \ OVERLOAD_ALL_DETAIL(name, impl, const volatile &amp;) \ OVERLOAD_ALL_DETAIL(name, impl, const volatile &amp;&amp;) \ /**/ //&lt;/library code&gt; #include &lt;iostream&gt; struct foo { OVERLOAD_ALL_QUALIFIERS(operator(), print_qualifiers) template&lt;typename ThisRef&gt; static void print_qualifiers(ThisRef&amp;&amp;) { using no_ref = std::remove_reference_t&lt;ThisRef&gt;; if (std::is_const&lt;no_ref&gt;{}) { std::cout &lt;&lt; "const "; } if (std::is_volatile&lt;no_ref&gt;{}) { std::cout &lt;&lt; "volatile "; } if (std::is_rvalue_reference&lt;ThisRef&amp;&amp;&gt;{}) { std::cout &lt;&lt; "&amp;&amp; "; } else if (std::is_lvalue_reference&lt;ThisRef&amp;&amp;&gt;{}) { std::cout &lt;&lt; "&amp; "; } std::cout &lt;&lt; '\n'; } }; int main() { using F = foo; using CF = const foo; using VF = volatile foo; using VCF = const volatile foo; F f{}; CF cf{}; VF vf{}; VCF vcf{}; f(); cf(); vf(); vcf(); F{}(); CF{}(); VF{}(); VCF{}(); } output: &amp; const &amp; volatile &amp; const volatile &amp; &amp;&amp; const &amp;&amp; volatile &amp;&amp; const volatile &amp;&amp; 
I colored mine but this http://i.imgur.com/3rBaiBd.png
thanks for the info!
Since you're obviously an absolute novice, what on *earth* gives you reason to think you have any standing to question what /u/SemaphoreBingo told you? The command prompt has nothing to do with the programming language, it's simply the first place many tutorials (regardless of language) begin, because going any further would be pointless without actually understanding the fundamentals. 
Allow two forms of definition: C { ... } // conjunction of nested requirements C = ...; // whatever... My guess is that most disjunctions will not appear in { ... } defined concepts. They seem to be fairly conventional (conjunctional?). Every time I write a disjunction, it's always an || of two "normal" concepts (Arithmetic is Integral or FloatingPoint). Edit: stuff.
Intriguing. But `and` and `or` are alternative tokens for `&amp;&amp;` and `||`. So we could also write: || { P &amp;&amp; { Q; R; } } It might be syntactically unambiguous, but yikes. Now we have LISP syntax for constraints. We'll be the envy of the functional world :) I'd rather see the variable form win out too. 
How hard did you look? http://learnopengl.com
Yes. Not in terms of performance, but in terms of code space. Unwind tables are massive
&gt; That no longer looks like a class/struct anymore. Well, syntactically it's a "struct" with single *nested-requirement*. As for your example, it can be written like this requires requires { requires Option1&lt;T&gt; || Option2&lt;T&gt;; } || requires { requires Concept3&lt;T&gt;; requires Concept4&lt;T&gt;; }; Which is not very pretty, because of redundant `requires`, but i think it is possible to define grammar of *requires-expression* in a way that we could get rid of them, like this: requires { requires Option1&lt;T&gt; || Option2&lt;T&gt;; } || { requires Concept3&lt;T&gt;; requires Concept4&lt;T&gt;; }; But, of course, it can be shorter: template &lt;typename T&gt; concept C = Option1&lt;T&gt; || Option2&lt;T&gt; || (Concept3&lt;T&gt; &amp;&amp; Concept4&lt;T&gt;); template &lt;typename T&gt; concept C { requires Option1&lt;T&gt; || Option2&lt;T&gt; || (Concept3&lt;T&gt; &amp;&amp; Concept4&lt;T&gt;); }; And, as we can see, both variants practically the same.
Bare metal projects during my career as an example: - hospital bed movement control &amp; remote - pump control for thick liquids like honey and cremes - networked heating system for vacation homes - hypermarket cooling control system - air conditioning control system - reefer cooling control system
https://en.wikibooks.org/wiki/X86_Disassembly/Floating_Point_Numbers#Calling_Conventions This talks about the different calling conventions that can be used.
Interesting. Thanks! I sincerely appreciate you taking the time to explain
You're asking things kind of the wrong way, which is why people are not taking your question seriously. This being said I struggled for a while when I started choosing with pretty much the same question, so let me answer it as best as I can. You've found a lot of tutorials on c++. They all start by making you write stuff to a terminal. That's normal: c++ is a generic programming language, not limited to making games or graphical stuff, so tutorials will start with generic examples. Writing text to a console is easy to understand: one function call and some text appears in the console. Nice, easy to explain, ready to adapt to many situations. From that, tutorials will work their way to explaining how to do computation in c++, then how to organize your code to perform more complex tasks. All of that is still pretty generic. Here's the thing about drawing stuff programmatically: it's 1) harder than writing text and 2) dependent on what kind of graphics you want, what platform you want them on, and a few more things. 1) the easiest way to draw stuff is pixel by pixel. It's kind of like writing a line of text to a console, your function call takes the pixel coordinates in the window, and the color of that pixel. But that's pretty limited, if you want to render 3d stuff, you need to do complex computation to determine the color of each pixel based on what should be on screen. There are very complex libraries that do this for you. To speed up rendering, it's common and even necessary to use dedicated hardware (video cards) which add a lot more complexity, still mostly abstracted away in these libraries. 2) so of course to program something that shows some 3d stuff, you'll need to pick a library, maybe even multiple libraries. All of these will have complex concepts to understand: how do you open a window? How do you represent a cube? A triangle? A group of thousands of triangles? Turns out these are really important questions with complicated answers due to how 3d rendering works (with hardware acceleration, complex algorithms to make 3d fast, etc), but that's outside of the scope of this answer. The libraries may differ depending on what platform you are programming for: some will work only on Windows, some will work for consoles (you can program for many consoles in c++!). So that's why c++ tutorials don't take this topic. This isn't about teaching c++, this is about teaching 3d, and a specific 3d rendering library. You need to first understand c++ itself, and then turn to learning about a c++ 3d library. Yeah, that means working with the console for a while why you learn the language itself. That also means you need to pick what library and environment you want to learn how to program 3d stuff for. If you just want to learn how 3d rendering works, the most popular choice is probably OpenGL. If you have specific goals in mind ("I want to make a 3d game for the PlayStation 4") you'll need to learn about that platform and what tools are available there. Good luck! It's a complex subject, and it can be overwhelming at first. But it's fascinating, and it's worth the effort, I guarantee it!
What you're asking about is the calling conventions. In order to work out which one to use, you need the follow information about the compilation environment (assuming x86). * Is it 32 or 64bit. * Name of the calling convention. * The width of your data types. If you're working on your home PC, most likely you're running x86_64. And luckily, there are only 2 primary conventions, the sys V ABI, and Windows. In both, the first floating point argument is put into xmm0. see https://en.wikipedia.org/wiki/X86_calling_conventions#x86-64_calling_conventions Just to ask the stupid question, are you doing this in assembly for fun/school? Because &gt;take a latitude value and convert it to an x position for a bitmap image can easily be done in C or C++.
Is there any reason you're writing the entire `latitudeToX` function in assembly? If you write the function prototype in C and have inline assembly for the body, it makes it easier to get calling conventions right.
I don't know why I did that, stupid me. Probably wanted to do a ".out" extension and never really paid attention to that gif. I'll change it soon :)
I hang out in the QBS IRC channel and it is certainly still an active project. Honestly, I really like QBS, and find it much nicer to work with than cmake or qmake.
Here it is : http://unix.stackexchange.com/a/113696/102320 :)
I had tried writing inline but i couldn't get it to work right for whatever reason. I had my professor look over it but he couldn't get it to work either and suggested I just write that function completely in assembly.
Oh thank you Ill look into calling conventions! Yes this is for school we're taking a binary file of lat,long points and converting them to a heatmap. However for the conversion to coordinate points our professor wants us to use assembly, If I can get this to work Ill probably go ahead and try to get a SIMD function to work. Thanks for your response!
why use conio here? windows.h already contains SetConsoleTextAttribute method which should be sufficient. Is there anything about it that I might be missing? because I was going to code windows support that way. http://stackoverflow.com/a/25560218/2648679
I think it was probably written quickly as little more than an example, and not something that should be copy-pasted as a solution. That's good to point out though. The calling convention page might be better.
With whom?
I think it's extremely powerful in the way that Perl is extremely powerful. It can be very difficult to comprehend code that falls into this rabbit hole, although it's certainly fun to push the limits. I think the C preprocessor is the most hilarious success in the history of language design. C says "I can't handle what you really want to express, so here, take this chainsaw and go crazy." If we could use the C preprocessor by default in other languages, we would. And nobody would be able to make sense of anything. Templates can compound complexity by astronomical factors. I really appreciate the art of clean C++ code, because it's so terribly easy to write unreadable C++. My snippet above is definitely not what I'd call clean C++. Edit: words, formatting
For the simple way to get the right prototype, implement a function like it in C and compile that to assembly (compile argument -E). Then look at that how it passes its arguments and know that. Alternatively, look up the ABI for your target and use the calling convention exemplified in there.
I read almost all blog posts on mobile while I'm commuting. But anyways, you can click the menu away, so it works.
You're free to improve it.
Calling convention varies based on architecture and compiler, but it looks like you are on x86. On x86 calling conventions, floating point arguments are pushed on the stack (probably in your case at esp+4). So the answer is that they are not in a register! My suggestion to you is to step through the disassembly of your program in your debugger, and see where the caller is putting the value. Depending on calling convention, you may also need to clean the stack before returning. (add esp, 4)
He's on x86 (note his use of ebp and esp instead of rbp and rsp), so likely pushed on stack and not in a register.
If you're really just after a float to int conversion you can use the _mm_cvtss_si32() intrinsic. They basically map straight to the ASM anyway, look at these instructions: movss cvtss2si It's about as fast and simple as you'll get. Newer compilers will generally prefer to use the XMM registers over the FPU registers. If you _really_ want to use the FPU for whatever reason, you can look at the fist instruction
Both the examples linked in this thread so far show something that annoyed me as a learner, in that they show the assembly listing of the functions but not the context in which they're called. Which from a begginer RE perspective only gives you half the story. For example in the wild I've seen code that loads FP arguments onto the FP stack and follows each argument with a push of ECX, I presume as a dummy value. Then the call happens and in the body of the function the arguments are popped off the FP stack. I've not found any reference to this method of doing things anywhere and it confused me for a while. 
Wait wait, about your 2nd point, please see the function supportsColor() once again - inline bool supportsColor() { const std::string Terms[] = { "ansi", "color", "console", "cygwin", "gnome", "konsole", "kterm", "linux", "msys", "putty", "rxvt", "screen", "vt100", "xterm" }; static const bool result = std::any_of(std::begin(Terms), std::end(Terms), [&amp;](std::string term) { if(const char *env_p = std::getenv("TERM")) { return std::string(env_p).find(term) != std::string::npos; } else return false; }); return result; } `static const bool result` as well as `return result`
Single headers are a bad idea due to increased compile times, when compared to a PIMPL implementation. For example, "windows.h" is going to be included everywhere. Can you please separate them into two files?
actually the project that TinyWindow grew out of uses PIMPL implementation, though I would not recommend using it as I haven't updated it in over a year. https://github.com/ziacko/Window-API
Ok thanks for the info. Has been fixed in latest commit 
Conio is depreciated(it looks to me), so this is the better option. It's also not accessible to most open source compilers, which is a good reason not to use it.
Fwiw I upgraded to PyCharm 2016.1 yesterday and that fixed my IdeaVim problems.
This is another concurrency framework tending towards message passing, like the C++ Actors Framework, correct?
Do the agents have the ability to communicate over the network within the bounds of the library?
Fixed the title on the website but can't fix reddit titles. Oops.
No. SO-5 doesn't provide this functionality, it dispatches messages just inside one process. It is main design decision because different tasks require different protocols. For example if parts of distributed application sends big binary blobs each to another then there should be rather different protocol then in the case of exchange of large amount of small messages. Because of that inter-process communication is done via external tools (like AMQP or MQTT message brokers).
What do you expect - its VC++
I tried it this morning and i was able to fix a few bugs thanks to it. It could be better integrated though. You have to run the analysis on a per-project basis, you can't have a per-file analysis or have it run in the background. it also do not show the error in the editor, only in a separate view, with a link to the file+line of the error
Okay, that's good to know.
Are you implying that the same wouldn't be true when porting such an application to clang or gcc?
There are other VC devs (and dev managers) who post here, although I appear to spend the most time on Reddit.
This is useful as I have my own implementation of `function_ref` too (I didn't know LLVM also has one). I'm not sure `signature` is a good name for that, IMO, `function_ref` better conveys the idea. I'd like to see this in a standard proposal, something like this should be used in the API to accept a synchronous (non-deferred) callback instead of `std::function`, although with `std::function` the non-allocating guarantee can also be made by passing `std::ref(f)`.
 server.handle("/", [](const request &amp;req, const response &amp;res) { res.write_head(200); res.end("hello, world\n"); }); It doesn't feel right that *response* is const here. Besides that, this seems like a nice library!
I find it frustrating when people conflate these things. Whether or not lines of code at the end of a function will execute is a matter of whether you have early exits of any kind, not anything particular to exceptions. Early exits in non-trivial functions are quite common, either because an error has been found or because the inputs define a simpler case for which an output can be returned early. The only difference is whether those exits are explicit or not. In either case, the best way to ensure state on function exit is via RAII and ScopeGuard, not by putting actual lines of code at the end.
When I interview someone, I'm looking for things like "how do they approach a problem", "do the look verify they have sufficient requirements before starting", "do they address those requirements", etc. Basically, I want to see if the candidate "can think" or do they just know how to "regurgitate old material". I care very little about how fast they are and my primary focus is that someone that can "think out loud well" will be likely to not only solve problems well but communicate well when working with others on solving problems.
I'm assuming you mean the second should be extern "C" { extern int foo(); extern int bar; } to make them functionally equivalent? If so, that's an unfortunate trap your coworker fell into!
It is improving, certainly. But in absolute terms of specification conformance it's still lagging. Example 1: I tried doing something with Boost.Preprocessor last week (nested for loops to expand into a nested switch blocks). Worked perfectly with GCC. Worked perfectly with clang. Failed horribly with MSVC. Why? It's preprocessor is not standards conforming and misbehaves, leaving a whole set of macros unexpanded. You can see the code in a unit test [here](https://github.com/openmicroscopy/bioformats/blob/develop/cpp/test/ome-xml/enum.cpp#L489) if you want to try it for yourself. Example 2: As an alternative, I write an equivalent using variadic templates to expand all the cases at compile time. Works fine with GCC. Works fine with clang. Again, fails horribly with MSVC. And that's with MSVC2015. That's two examples of utter brokenness from last week. And I run into this type of thing *all the time*. Very very occasionally I run into a problem with GCC or clang. But it's a rarity. Once or twice a year if that. The ongoing cost of supporting MSVC in a cross-platform product is *huge*, and yes, I do think that it's a subpar compiler. The frequency with which I hit compiler bugs, nonstandard behaviour, and odd limitations is many times higher what I observe for the other major compilers, and since I'm building my code on all of them on multiple times per day, every day, on a whole host of platforms, the trends are quite clear. Note that the problems above were in the compiler and preprocessor, not the standard library which tends to be much better. 
The variable bar in B becomes a declaration and definition.
 extern "C" int bar; is the same as: extern "C" { extern int bar; } not extern "C" { int bar; } So presumably you had a problem with multiple definitions of this global variable. Though I'd be bit surprised if there weren't any compile or link time indications of the problem; [Here's an example][1] of clang's output on a program containing an incorrect global definition in a header. If there weren't, you might want to look into the practices that catch this sort of thing. [1]: http://melpon.org/wandbox/permlink/DAvUKQhUQ9JpnDzg
Did you report the variadic template bug?
VS 2015, VS 2015 Update 1 or Update 2?
In our case, "int bar" was never meant to be defined at all in this program, only declared as an extern. It was defined in a shared library that was being linked to the program. extern "C" { int bar; } was creating a global variable that was being used instead of the extern variable from the shared lib. Sadly, no compile time warnings or errors were generated. Something like this... foo.cpp // foo.cpp extern "C" int bar = 42; main.cpp // main.cpp #include &lt;iostream&gt; //extern "C" int bar; // program output = 42 extern "C" { int bar; } // program output = 0 int main() { std::cout &lt;&lt; bar &lt;&lt; '\n'; } compile and run: &gt; $CXX -fPIC -shared foo.cpp -o libfoo.so &gt; $CXX main.cpp -L. -Wl,-rpath=. -lfoo &gt; ./a.out &gt; 0 (or 42) 
Easy to fall into that trap. Congratulations on fixing the issue.
Not yet. I'll have time next week to create a minimal testcase and submit that once I have a release out of the door.
I have no idea. The "function style syntax" and "variable style syntax" both look absolutely terrible, and I'm pretty glad that concepts isn't in C++17 now that I think about it. They look like placeholder syntax, designed to be easy to retrofit into GCC to do some testing of how the concept works (mind the pun). The syntax of saying that `a &lt; b -&gt; bool` rather than `bool operator&lt;(T, T)` is actually better. It's saying that when you write `a &lt; b`, that should be contextually convertible to bool. I much prefer that to explicitly requiring an `operator&lt;` that exactly returns bool and exactly takes a `T` and a `T`. But `concept bool R() { return requires (T a, T b) {` is fucking awful.
Yeah agreed. That seems very odd. But does seem like a cool library.
If the code actually declares (or tries to declare) an entity from a shared library, I would say that's the primary problem. That declaration should be provided and verified by the providers of the shared library. If that's a third party vendor and the library is closed source, then they need to provide the appropriate header. If this is just another module that you also control, then this is an example of the importance of the rule* that all implementation files include as their first header the paired header file containing the corresponding declarations for all external entities. This is what verifies that the declarations in the header match the definitions in the implementation file. Here's an [example][1] of the error produced by this technique. Gcc and clang provide warnings to help enforce that entities with external linkage are declared in header files, and that definitions have preceding declarations. -Wmissing-declarations will catch functions for which this mistake is made. For variables, clang has -Wmissing-variable-declarations. I don't think gcc currently has any similar warning for variables, but some cases can be caught by using the `-fno-common` flag. This flag will produce [link errors][2] in some cases where this mistake is made. Strict discipline in this area has always been important, but another reason to care is coming up with C++ modules: Declaring entities that are owned by another module will be completely broken, and code that does this will have to be fixed to make use of modules. --- \* _Large Scale C++ Software Design_ contains these four "Major Design Rules" in chapter 3: - Logical entities declared within a component should not be defined outside that component. - The implementation file of every component should include its own .h file as the first substantive line of code. - Avoid definitions with external linkage in the implementation file of a component that are not declared explicitly in the corresponding .h file. - Avoid accessing a definition with external linkage in another component via a local declaration; instead include the .h file for that component. [1]: http://melpon.org/wandbox/permlink/3Z3M8a0ZJpVSO68n [2]: http://melpon.org/wandbox/permlink/vh2vmUW0OgVx8vnW
I would like to take the opportunity and ask why did they switch to VC++? Any links with a detailed answer or something like that? Thanks in advance, ppl.
My question is part of the bigger, more general and complex subject of what is the state of the major C++ compilers right now, but regarding things other than compliance with the standard, like, as you pointed out, binary result. But before, given the fact that it's a broad and complex subject, is it asking such thing a waste of time?
As a request for help, you should be sending this to /r/cpp_questions.
Not a waste of time, certainly, but very difficult (at least for me) given for example the plethora of unique compiler options that can be specified for each and every library/project you build. I'd imagine very few people are experts in the finer details of more than one or two of the popular toolchains, or at least not in enough depth to give advice that could apply to most codebases.
That's a very good question. Here's why: Each method makes a certain assumption about what 'this' points to. It can be anything, really, as long as it is consistent. You make this assumption because it is then known (at compile time) at which offsets from 'this' you can find your variables. Since 'this' pointer is different between 'Father' and 'Child', the thunk-method offsets 'this' so that there is only 1 implementation of the method Does this answer your question?
I had a look at the generated assembly and the difference has nothing to do with allocation and everything to do with `std::vector` zeroing the values. With your custom allocator, for whatever reason (probably having to do with alignment, or perhaps just missing some specialization) the compiler generates code which writes a zero byte into each element one at a time. With the default allocator it calls `memset()` on the whole array, which can use all the tricks in the book to fill in values very fast (e.g. vectorization.) That's also also why your `MyArray` seems so much faster, as there's no zero-filling. Everything you're measuring is unrelated to the actual allocation. Actually, if you look at library calls with `ltrace`, your `MyArray` version is performing 50% more allocations. For that case, it has to allocate a `std::vector` on the heap, then a `std::function`, then the actual data, and then free all three of those. The other two cases only require two allocations and two frees. (There's really no point in using `make_unique` in your test harness, which is just adding about twice the work for the heap.) But despite being by far the worst case in terms of allocation overhead, `MyArray` wins in overall time, which indicates that you aren't measuring what you think you're measuring. 
Ah, interesting, that makes sense. Thanks for looking into it! I'm not really interested in allocation/deallocation time, I was concerned with creation/destruction time, so measuring the memset vs individual zeros is definitely part of what I wanted to measure. I realized the make_unique's were unnecessary, they were left over from me reducing down to this test case and I just left them in. Calling the placement new in MyArray was an attempt to zero-fill the array like std::vector would, but I guess that was unsuccessful.
Hey, thanks for the gold. To get `new` to zero-fill you'd have to write `new(allocator-&gt;allocate(size)) T[size]()`. Or in other words, `new T` performs default initialization (which for T=int[] means uninitialized), whereas `new T()` performs zero initialization. I suppose in the post-C++11 world it's probably better to write `new T{}` to use uniform initialization syntax.
Weird. I managed to get the repro case down to this with the online compiler at gcc.godbolt.org: #include &lt;new&gt; const unsigned array_size = 1&lt;&lt;17; char *p; int main() { char *q = p; for(unsigned i = 0; i &lt; array_size; ++i) new (q+i) char(); } This is the boiled down version of the vector&lt;&gt; ctor calling __uninitialized_fill_n_a(), which is triggered by the custom allocator. For some reason, gcc is just unsure enough that it fails to convert this loop to a memset(). VS2015 also failed, but Clang was able to convert it. Change the set expression as follows: *(q + i) = char(); ...and memset() appears. Same with replacing the loop with an array placement new. I wonder what's going on in the optimizer. 
&gt;Disclaimer: everything written here is implementation specific, may change in any future version, and should not be relied on. We look into this for educational reasons only. This cannot be upvoted enough. :-) Anyone knows how gdb does know about things like vptr$Parent etc? I mean, does it know how the particular compiler implements a class, or...?
How about using Boost's unordered_map implementation? You can extract the headers you need rather than use all of Boost with bcp, apparently (I've never needed to do this): http://stackoverflow.com/questions/13418918/using-boost-unordered-map
Indeed, though I understand synchronisation inside the destructor isn't as uncommon as one might hope, I recall watching an ear!y video demo of asan and tsan where they highlighted tsan could detect a vptr race but apparent!y they had to disable the warning in cases where the vptr had been written but the value hadn't been modified (which would happen on entering the virtual destructor of the most-derived class) because it was too noisy and there had it triggering on a lot of code, which is itself concerning. I haven't been able to find that particular video again though
wish somebody finds it, was it LLVM euro video or something different? 
[Here's the video](https://channel9.msdn.com/Events/GoingNative/2013/The-Care-and-Feeding-of-C-s-Dragons), TSAN section starts at 1:13:00, the part I mentioned at 1:18:45
https://github.com/electronicarts/EASTL/blob/master/include/EASTL/map.h
I bet they have a wonderful using namespace std around there.
&gt;Also, no single compiler is 100% conformant. That's something people don't seem to grasp. Comeau?
Usually the reason for that is because you're using code/libraries that were built/tested for Clang/GCC. C++11 support is also fairly recent in VC++ and thus it's normal for it to have more bugs on new features than other compilers. Being open source also most likely makes it easier to find and fix bugs.
 return static_cast&lt;T*&gt;(::operator new(n * sizeof(T))); As soon as I saw this, I knew what the answer to the benchmarks was going to be. Forget about `operator new`. See Andrei's [CppCon 2015 talk](https://www.youtube.com/watch?v=LIb3L4vKZ7U) to see why. If you are allocating lots of vectors of a known size (maybe based on a function parameter), then try to use `std::vector&lt;T&gt;::reserve` because it does a placement new that uses uninitialized memory.
Looks like an interesting talk, thanks, it's on the queue! :)
Do you happen to know if gcc uses the same scheme as clang?
[BDE](https://github.com/bloomberg/bde) provides a tested C++03 (and mostly C++11) compliant map implementation. For an added bonus, it also implements the upcoming `std::experimental::pmr` semantics (which are optional).
That's what I suspect as well. I also wonder how clang works on windows, since it also aims for ABI compatibility with MSVC as well. So it might just happen that clang implements both schemes internally.
You're probably aware, but if you just want to time the creation/destruction, there's no need to wrap it is `make_unique`. You can just create the vector on the stack and within that scope it would be created and destroyed. This is even closer to what you want as it avoids whatever marginal overhead there is to call `make_unique`.
Is there any reason to use virtual inheritance other than issues related to the diamond problem?
I imagine it is purely debugging symbols generated by the compiler (clang in my case)
I have removed your post because questions like this should be sent to StackOverflow, as the sidebar advises.
Some people fall into the trap of thinking, "if I don't get a job a the three or four most competitive companies in the entire industry, I must not be very good." I'm sure many other companies would scrambling to hire you right now, but you are competing against many thousands of applicants at the top companies. I unsubscribed from r/cscareerquestions a long time ago because the obsession with "the big 4" (or whatever) was so tiresome. Seriously, don't let that get you down.
Is your uint32_t *not* a 32 bit unsigned integer? Because if it is, then yes it is easy. Wherever you put that typedef, include &lt;stdint.h&gt; instead. You'll have this problem with any good library you find because they use the standard types as well. 
That was an example. I'm pretty frustrated with our codebase decision to not have the ability to use STL. For the moment I'm trying to tide over with a super simple hash map. I think I'm gonna have to write one ... shudders. 
Oh I like this game! It makes me think. We should play this more often!
That may have just been an example, but I assure you that your time would be better spent redefining your in-house types to not stomp on the standard ones than writing a super simple hash map. This is going to be the first of many problems this causes, because like I said, you're trying to use names that are reserved by the language standard itself, not the STL. You're going to get burned by this time and time again.
I think partial support for constexpr lambda has just been landed in clang. https://github.com/llvm-mirror/clang/commit/a46d5cd16e126e77646365b8a5c6f3d0db28b5d0
What are the down sides to Meson in your mind? 
Have you tried using the Clang/C2 toolset? It might solve those weird issues. (Not that I generally think it wouldn't be nice to use VC++ just to find these bugs, but if you need a working Windows build while also using their backend, that's what I would try.)
Chromium always used VC++ because there is no alternative on Windows. clang-cl is too new to be production-ready. MinGW is no good because - no support for PDB (Windows debug info); no infrastructure for postmortem debugging. - no support for Windows-specific libraries like ATL/WTL. - std lib is poorly implemented - from what I recall locales support only "C", random_device is just mt19937. There could be other non-implemented features.
Yeah, I'm definitely inclined to just have libclang and that's my focus. As for executables, the main thing for me is to to have clang-tidy and friends available. I'm not sure if its possible, or would even make a difference to try and build libclang without the clang executable.
That clarifies a lot. Ty!
&gt; Recently I've been looking into conan and I'm thinking it could be a real game-changer for C++ developers. I haven't really heard of Conan outside of reddit, so I honestly doubt this will be a game changer any time soon.
&gt; I've considered a low count of dependencies a very desirable thing for quite a while now. The recent npm-debacle can serve as a great example for why this is my opinion. I don't think it is this black and white, though. There is a lot of space between npm's extreme philosophy of one-line libraries and dependency counts in the hundreds, and C++'s lack of any accepted community standard(s) for package management. I work on some side projects in both C++ and Python, and invariably getting new collaborators up and running with dependencies in C++ is way more of a headache than in Python, where I can give everyone a couple of package names to pip install.
Since clang uses standard install with cmake, it already can be installed using [`cget`](https://github.com/pfultz2/cget) from github, like this: cget install llvm-mirror/llvm llvm-mirror/clang Of course, you can't get clang extra tools. I think it would be great to have an out-of-source build of clang extra tools. Then they would be able to be installed with just `cget install llvm-mirror/clang-tools-extra` as well.
&gt; I'm not happy about new concepts being basically function templates or variable templates where you have to remember what kind of concept you deal with in order to be able to use it properly. Do I need to write LessThanComparable&lt;T,T&gt; or LessThanComparable&lt;T,T&gt;()? Well, it depends. Is LessThanComparible a function template or a variable template? If it was a defined like a function, you need the additional () at the end. Screw that! You'll use it as in the following: template&lt;typename T, LessThanComparable&lt;T, T&gt; U&gt; void is_less_than(U a, U b) { std::cout &lt;&lt; (a &lt; b ? "yes", "no") &lt;&lt; std::endl; } There are other ways of managing concepts, but I can just recall this one.
&gt; I just wasted the better part of my afternoon trying to track down a bug caused by someone changing A to B in a header file Maybe you already do this, but, pro-tip, if you don't: Binary search your source repository versions from "last known good" to "broken". I long ago figured out this is much faster than trying to actually debug shit. 
Would love to see some (admittedly micro-) benchmarks of the before and after code. Who wants to bet the STL versions are faster?
That would be interesting to see. In general, STL algorithms are thin abstractions over raw-loops, so there shouldn't be any noticeable difference in performance.
First off, nice blog! Couple of questions, though. 1) Why are you doing the `rotate_right` on reverse iterators? It will give the same answer as the regular `rotate` on the original iterators. 2) Your `insertion_sort` does not work on empty ranges. You need to either test for non-empty ranges, or do the main loop over `[first, last)`, not over `[next(first), last)`. See also [this StackOverflow Q&amp;A](http://stackoverflow.com/q/24650626/819272) (disclosure: I'm the OP on that Q&amp;A). 
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You might even call its coverage 'encyclopedic'
This would be a much easier read if you didn't assume `using std;` (which is pretty bad practice in 2016, given the large number of symbols in `std`) and spent the extra few characters to tell us which of your symbols came from the standard library This would be particularly useful here since this is, in fact, an article teaching us about the STL so you can't assume we know that we know without thinking that e.g. `make_reverse_iterator` is in `std::` if you don't write it `std::make_reverse_iterator`.
Are you sure this initial allocation is a problem for you? I ask because people can think it's a problem without realizing that it's a fundamental trade off. If the maps didn't allocate on init, then they would either need to allocate lazily, which means every operation on the data structure would pay for that branch, or the data would need to be part of the class, making it larger. IIRC, not allocating also causes issues related to exception guarantees, but that wouldn't apply to the environment that eastl is intended for. 
But I didn't use 'using namespace std;'. Everything here relies on argument-dependent lookup. Besides, I think adding std:: to every symbol would make the code harder to read, especially when it's intended for educational purposes.
It's resolved by argument-dependent lookup. When you write std::cout &lt;&lt; 4; how is the ostream operator&lt;&lt;() resolved? Using argument-dependent lookup. That's the same thing.
https://github.com/Xecutor/htmap Hash Tree Map. 
One is an array of pointers, the other is a pointer to an array. In any case, this is not the appropriate subreddit for this question  you want /r/cpp_questions
I'm looking for a way to check for a variable's existance. How would I do that? Just using table::get&lt;int&gt; returns 0 even if the value does not exist. The problem I'm actually trying to solve is to use default values if the lua interpreter does not have an alternative in the global table. EDIT: nevermind I see it is in release tag v2.1.0
I thought Concepts are a form of type (HKT?). If so I don't see the need for special syntax.
Such insertion sort won't be `O(n log n)`. Using `upper_bound` is not enough. Each `rotate` will still use `O(n)` time on each call. The same problem with merge sort. `rotate` ruins everything. Each `merge` call is `O(n^2)` because of it, with total complexity of `O(n^2)`
Thanks. I actually added the if-statement after TemplateRex's observation above. If the range is empty, then first == last, so next(first) == last + 1, which makes it an infinite loop.
I don't know of any algorithms that do in-place merge sort faster than `O(n log^2 n)`. And they are not exactly simple... Regarding this implementations of `merge`. Consider merge of `1, 3, 5, 7, 9, ..., 2 * n - 1` and `2, 4, 6, 8, 10, ..., 2 * n`. Each `rotate` will work in `O(n)` with total `O(n^2)`. First `rotate` will move `2` into the second position, second `rotate` will move `4` in fourth position, and so on. The total complexity of such merge sort will still be `O(n^2) = n^2 + 2 * (n/2)^2 + 4 * (n / 4)^2 + ...`.
Using the` reverse_iterator` for insertion sort also gratuitously changes the iterator requirements from forward to bidirectional (both `upper_bound` and `rotate` only require forward iterators).
So, how would you express merge without rotate() such that your example runs in less than O(n^2)?
Yep, the upper_bound version no longer uses reverse iterators. In the linear search version, I'm keeping them to mimic the behavior of the raw loop version, but technically, they're not needed. The search can be done in the forward direction.
why did you implement inplace merge, when there is a [std::inplace_merge](http://en.cppreference.com/w/cpp/algorithm/inplace_merge) in the STL?
Because the purpose of the post is to show how raw loops could be replaced with STL algorithms. I even thought about implementing the partitioning algorithms for quicksort but decided to keep it short.
you're venturing into *undefined behaviour* there (google for it). Basically, using an array out of its bounds or using memory after it has been freed is undefined behaviour, which means that the program is allowed to do anything (which includes crashing, playing britney spears out of your speakers, or "work" without an error message). If you use low-level constructs like that, you are responsible for following the rules. If you want safety nets, you can use other, high-level interfaces (std::vector&lt;int&gt; x(2); x.at(3) = 3; will error out).
In-place merge? It is not very easy, but it is possible. std::inplace_merge works in `O(n log n)` in worst case. But my point is, that it is a little misleading to call this algorithm "in-place merge sort" without explicitly telling than it is not `O(n log n)`. 
It is. I'm however keeping it this way for pedagogical reasons. Using reverse iterators at this point would obscure the loop even further.
I was informed of a way to write it without reverse iterators, so it's now fixed. Thanks.
perhaps then you could change it to while ( *i &gt; key ) { *next(i) = *i; if ( i == first ) break; --i; } the advantage obviously being no crash (or perhaps just put a comment in)
&gt;The problem with this syntax is that a concept will take the place of a type, making a template function look like a non-template one. I've heard this a lot. Can someone explain why this is actually a problem?
Ok, thanks. I agree. I'd also say that multiple inheritance is a code smell, especially for bases that have more than one non-private member.
I just saw this another place - looks pretty cool!
I believe the http router should handle routes before verbs. This way you can return the http error code 405 Method Not Allowed when the route exists but the verb is not supported.
I don't think the code for insertion sort is efficient. My code: template&lt;typename IteratorT, typename PredT&gt; void InsertionSort(IteratorT start, IteratorT last, PredT pred) { for (auto cur = std::next(start); cur != last; ++cur) { auto v(std::move(*cur)); *std::prev(std::move_backward(std::lower_bound(start, cur, v, pred), cur, std::next(cur))) = std::move(v); } } 
(author's here) Nope, I do not provide a websocket implementation yet. For cross-thread message passing, the framework is not really intended for that but I'm using a lock-free MPSC queue internally to communicate between threads. If you're interested, I have several mailbox implementations: https://github.com/oktal/pistache/blob/master/include/mailbox.h However, I would recommend that you come up with your own messaging/actor system for cross-thread communication
&gt; If a library author can detect a better path either via a specialisation or some other means, then the optimizer/compiler being used should also be able to detect such patterns The library author may have extra information that is difficult to pass to the compiler in idiomatic C++. For example, the compiler may not know the "`result` shall not be in the range `[first,last)`" requirement of `std::copy`.
Why not use boost asio?
This looks really nice from the examples. How are incoming requests handled from the main listener/accept loop? If one was going to do blocking IO (like making several requests from a DB server) would I need to spin up a thread? Am I already in a thread? Is there a threadpool, etc?
You can do the former, and it would be correct, but the better option would be to use `std::vector` for a dynamic array and not have it contain owning pointers if possible. So a `std::vector&lt;ListPair&gt;` unless you absolutely need pointers inside. At that point, `std::list` is for special cases and might fare better as `std::vector`. To possibly back up my first point, do you know what the rule of three/five is? Are you implementing it correctly? Are you sure?
Although I have been C++ programming for 20+ years, I have worked with many team members who come from other languages. To help them come up to speed I am currently recommending: http://www.amazon.com/11-Programmers-2nd-Deitel-Developer/dp/0133439852/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1459179897&amp;sr=1-1&amp;keywords=c+11+for+programmers As for QT I personally use their website and the examples in the SDK itself: http://doc.qt.io/qt-5/qtexamplesandtutorials.html 
I let all that deletion to my friend }
Perhaps we could move bashing to a dedicated forum, /r/c-- perhaps? ;)
It's actually not. All methods on *response* are *const*.
brutal
The usage of `new`^1 and `delete` is inversely proportional to the knowledge and discipline of a C++ developer. There were *some* instances where it would make sense to use `new` in C++03, though much fewer than most assume; `delete` however is unnecessary (hand over the memory to a smart pointer, forget about it). Starting with C++11, the single appearance `new` would make was in writing a `make_unique` function in "business code". Starting with C++14, with `make_unique` being part of the standard, there is no reason to call `new` in "business code". As it is, in the "business code" I work on daily, I have rejected any pull request using `new` or `delete` in the last 4 years, suggesting to use standard facilities instead. And that's a C++03 code base. Now, there are some places where `new` is necessary still. Usually in the depths of technical classes (writing a `unique_ptr` sibling or a `vecdeque` or whatever data-structure your mind can conjure up). However such code is very rarely written, and is best kept apart from the regular code base. ^1 *for allocating memory, placement `new` can still be desirable though it's a very specific tool.*
Yea, an OpenCL backend would be nice. But it looks like a really awesome library and a great effort.
No, the module proposal does not require LTO or LTCG or any technology of that sort. In the module design paper, it is explicitly called out that a program that uses module should not its runtime performance decreased. An exported inline function must be defined in the module interface unit. Same for exported templates.
I'm officially excited now! :D Thanks for the work on this much needed feature.
As far as I understand a compiler specific internal representation is used for the code of modules. That means the compiler does not have to parse the file again, instead it can do a lookup directly  la: "Give me function foo()" It then retrieves the internal representation which could then be inlined etc. This also means that only what is actually used will be pulled in.
Thanks ! To answer your question, you have the choice to run the acceptor loop in the main thread if you call serve() on the Endpoint or you can choose to run it inside its own thread if you call serveThreaded. From there, the endpoint will spawn a bunch of I/O threads (configured when you init the Endpoint). Once a new connection comes in, it is *accept()*-ed by the acceptor loop and immediately dispatched to one of the I/O thread. HTTP requests are handled by the corresponding I/O thread and the handler is called in the context of this I/O thread. You should not block the request handler, meaning that you should avoid doing any blocking I/O in the handler itself. Instead, you can spin one or multiple worker threads and offload processing to this worker thread. So yes, you need to spin-up a thread to treat your I/O. The framework does not provide a threadpool, I hope C++2x will come with one at some point :)
&gt; Why does the following work It doesn't. It may look like it works, but that memory past the end of your array belongs to somebody else. When they try to use it, they will either read your value instead of theirs, or they will write their value on top of yours which will be lost. &gt; Why doesn't the post-delete assignment produce an error here? Basically the same problem. You have said, "I no longer need this memory, you can give it to something else" but then you kept using it. Eventually it will be given to something else and your data will be clobbered, or else break that other thing. You lied about being done with that memory address. You can generally write to any memory address mapped to your process's address space. The problem is that something else probably thinks it owns that memory so you will clobber some data, or get your data clobbered. "new" is just asking that the system mark you as the owner of some memory, and let you know which memory it marked as belonging to you. You do that so everybody else knows not to write there, but it only works when everybody voluntarily follows the rules.
I would like to see a standard library constexpr function notation for retrieving the object representation of a value, probably directly as an array of std::byte similar to what it done in the GSL implementation of span), but the std::byte proposal needs to clear the CWG border patrol, after clearing the EWG immigration control in Jacksonville.
I am simultaneously impressed and horrified that someone went to that length to figure this out. Really cool though.
std::cout &lt;&lt; std::abs (std::cos (std::rand))) + std::pow (std::sin (std::rand (),2) &lt;&lt; std::endl; Vs. cout &lt;&lt; abs (cos (rand ())) + pow (sin (rand (),2) &lt;&lt; endl; The top version looks like someone vomited colons all over the screen. The bottom is easier to read and parse. All those stds convey zero semantic or syntactic information, but require mental processing (as the human mind can only handle a half dozen tokens at once). So it's not good coding, and I'd only do it if I was prevented from using namespace std, such as in a header file.
Apparently std:: is in popular demand :) .. Added them.
The user who redirects cout *wants it redirected*. I think there is no need to be smart about this.
When C++ reaches 18 it can vote for its own issues, smoke, and serve in the military.
I decided to write my own server after playing around with WebSocket++, libwebsockets and Node.js's ws. This library is only a week old but already pretty solid and passes all Autobahn tests that are supported. It massively outperforms all other implementations I have tested and I'm going to add SSL support via OpenSSL and permessage-deflate via libz. If you are interested in following my work that would be awesome.
&gt;The module proposal does not require LTO or LTCG or any technology of that sort. It doesn't *require* it, but what about the combinatorial possibilities of the various types of (possibly ABI-breaking) binary outputs modern compilers can generate. For example, I work principally in HPC where numerical algorithms reign supreme. If I compile a module for, say, an AVX2/FMA3 architecture but it ends up running on an AVX architecture, do I need to have multiple versions available (one for FMA3 and one for AVX)? If so, is there a mechanism in the current module proposal to handle these kinds of fine-grain issues?
What do you mean with no functions? Do you mean actual functions (like void foo() {}) or std::function? If you're meaning the first one I'm sure you did something wrong. No template and lambda support is utter bullshit: https://www.khronos.org/assets/uploads/developers/resources/Intro-to-OpenCL-C++-Whitepaper-May15.pdf (section 5) Also I don't understand what you mean with "no need compiler support", OpenGL and OpenCL use JIT compilation (the kernel/shader gets compiled in the moment you load it) but can also be precompiled. The fact that you exclude a massive part of your potential user base and throw any chance of portability out of the window by using CUDA is already a more than sufficient argument against it.
The only case coming to mind is if somebody is working in a system with very limited space, and an instantiation of a template function could use a significant portion of that space.
How would that be possible anyway if `Sortable` is a concept rather than an interface (virtual functions in a base class called `Sortable`)? 
A couple errors: at the end of section 6, you have uint32_t significand = (a &lt;&lt; (lz + 1)) &lt;&lt; (64 - 23); with a left shift of 64-23. It should be a right shift. Interestingly, this is correct in the full code, but there is a missing parenthesis there. Every single shift in your `count_leading_zeroes` is also backwards. This is made even worse because you shift some value to the left and then use it to index into a size-64 array, guaranteeing undefined behavior (unless the last 6 bits of the multiplication happen to all be 0).
&gt; Please don't use OpenCL. OpenCL is missing some useful features, but there's literally nothing else that can replace it. OpenMP is CPU only, OpenACC and C++AMP have worse performance, and CUDA is nvidia only With the newest OpenCL spec we get C++ as a kernel language which is super useful OpenCL 1.2 is definitely barely acceptable, but the latest version is pretty great. When nvidia catches up and implements it (eventually), itll be by far the best choice. At the moment, its simply the best choice due to it being the *only* choice for cross platform shenanigans 
For anyone who doesn't know what this is, boost::compute is essentially a thin C++ reference counting and usability layer around the opencl api (which is extremely useful). It also has a few other things I think, but I mainly use it to make the opencl api more friendly If you want to enable shared cl/gl contexts on windows, you have to hack it in yourself and edit the headers a little, but other than that i've had a very positive experience with it. Its also super easy to mix boost::compute and raw opencl which is a huge plus, and you can mix opencl cl_mem types that boost::compute doesn't support (eg image arrays) and put them into boost::computes generic reference counted wrappers
OpenCL 1.2 is worse in a lot of respects than CUDA. The main reason for having an opencl backend is that it works cross vendor, so there's not really much choice
Sorry for the pedanting, but... The first edition of The C++ Programming Language by Bjarne Stroustrup was published in 1986. Based on that, the public availability of C++ is at least 30 years old. C++ back then didn't have templates, but it did have I/O streams. Luckily there were no wide character issues back then - a single `ostream` class was enough. As far as I can tell from a quick skim through the index there was also no multiple inheritance, no member pointers and no exceptions (it was basically C with classes), but `new` and `delete` existed and could be overloaded. Templates and exceptions were both present by 1990, the publication date of The Annotated C++ Reference Manual by Margaret A. Ellis and Bjarne Stroustrup. The preface refers to a (non-annotated) reference manual and says "We hope that this reference manual will provide a firm base for the further evolution of C++. It has been chosen by ANSI to serve as a starting point for the formal standardization of C++.". So based on that, C++ as an ANSI-standard-in-the-making is still at least 26 years old. **EDIT** Oddly, chapter 19 ("ANSI/ISO Resolutions") states... &gt; In December, 1989, the American National Standards Institute's committee for the &gt; standardization of C++ had its organizational meeting in Washington D.C., USA. &gt; In June, 1991, in Lund, Sweden, this committee formally joined with C++ standards &gt; efforts in other countries such as France, Germany, Denmark, Japan, Sweden, and &gt; the UK under the auspices of the International Standards Institute. This chapter &gt; summarizes the major resolutions by the joint ANSI X3J16 and ISO WG21 &gt; committees for their draft working paper for a C++ standard as of March 1995. Minor &gt; clarifications are incorporated into their respective chapters rather than presented &gt; here. And sure enough, double-checking, I found that while the copyright date was 1990, the edition I have was "Reprinted with corrections April, 1995". Oops - but that mistake doesn't affect the at-least-26-years-old claim. 
What he is trying to say is that more experienced developers would use a smart pointer instead of new/delete. I really can't think of a valid use of new other than placement new unless you're dealing specifically with memory allocation (such as in an allocator).
Maybe this is how things are done in the STL echo chamber, but I am seriously tired of operator shaming, especially since not every one can ( wants to ) use the STL. It's also important to note that understanding memory allocation and lifetimes is an incredibly important/valuable skill, whether or not you use smart pointers or STL. Frankly, the shrill pronouncements of "how to C++" are starting to sound just a bit cargo-culty.
This is outright SPAM.
&gt; Luckily there were no wide character issues back then - a single ostream class was enough. That kind of pains me. There's not much lucky about it, wide character issues already existed then especially when dealing with various Asian text encoding. Multi-byte and variable length encoding are far from new, they just were ignored more often and people cared less about them. Yes, Unicode is huge and sometimes a pain but it's lucky that we finally stop ignoring that stuff and embrace proper localization. "Ascii only" and "plain text" are huge lies and already were back then.
For me it is about being regular and not surprising in the syntax. template &lt;SomeConcept T&gt; void f(T); With concepts: void f(Concept); Both above are a template. But one of them is completely "hidden". void g(NonConcept); The NonConcept one is not a template. I think that being a function template vs a function is a fundamental difference... but maybe I am not sure about this :p I will let the experts decide. Concepts and types should not be mixed in the same contexts? Actually it does not feel ok to me for some reason... 
Doesn't look like spam to me - the link is to a GitHub project, containing actual C++, not some clickbait site serving ads. I believe this is on-topic and will therefore leave the post up.
I certainly hope it won't be. Moving to a shorter release cycle of 3 years has been very disappointing. Moving to an even shorter one would be the final nail in C++'s coffin.
17 certainly is a minor release.
&gt;Conversely, C++17 wont be a major release on the scale of C++11, but neither could it be because C++11 took nine years to develop. And C++17 took six years to develop. Don't pretend it was only 3 years. Lots of things could have been in C++14 but were pushed back to C++17 "because C++14 is a minor release". And then aren't ready for C++17. C++17 is a failure. You need to accept that and work out how to prevent this from happening again.
That's a really stupid example though, because if `NonConcept` isn't a concept, why is it written like a concept? If it's a type, it should be `written_like_a_type`, not `WrittenLikeAConcept`. 
&gt;is MyConcept a concept or just a type? It's a concept, that's why it's in PascalCase.
Looks neat. Anything specifically you did to improve the performance so much or anything the other libraries are doing poorly?
Do you have any idea what gives uWebSockets its performance advantage? 
-Warray-bounds (gcc) should do it.
Also curious about this. Is a big part of the difference ASIO vs libuv? Did you profile the applications when you benchmarked it? Also, I'm assuming all benchmarks were on a single thread? or multiple (some implementations scale better with more threads, for encoding and writing for example)
Great work, I love the simplicity of your API. What would you recommend to have blocking calls (i.e. db request, or hard drive read...) inside the onmessage handler without freezing the websocket server thread ? Also, do you allow a HTTP failback callback ? Something similar to this would be great to serve for example the JS and HTML code of the websocket app: http://www.zaphoyd.com/websocketpp/manual/reference/handler-list/httphandler 
Follow-up questions to understand better: 1. Do you think LTO should be required? 2. Help me understand better the relationship between your scenario and LTO. Could clarify the links?
You shouldn't have blocking calls in the handlers, but nothing is stopping you from doing that (but it will freeze the event-loop). You need to solve that yourself by using a thread pool or any other solution that works. This is the case for all async servers.
Yes you can (and I do) run multiple servers, one per core, and let them do all the parsing and SSL stuff in their own core. You can either expose a port range (1 per core) or simply have your own load balancer and call server.upgrade(int fd, const char *secKey) to move the connection into the server on the least loaded thread.
Yeah thanks, but you are missing the point: I get vomit attacks and high blood pressure from using Windows. I will do my best to make it as cross-platform as possible but if it comes with performance loss I cannot do that.
Yes, this is the reason why I want windows support.
You can use proxygen as HTTP server and call server.upgrade(int fd, const char *secKey) to move the (upgraded) connection to WebSockets if you want. Proxygen is not a WebSocket server. Edit: or is it? Well in that case, bring on the benchmarkings! Edit2: if you have a proxygen WebSocket echo server I would gladly accept it as a pull request so that I can benchmark it.
&gt; I can look at the language that a Rust library is written in (that is, Rust), and be extremely confident that it is perfectly memory safe. The same can't be said of C++. Rust was designed for this since the beginning. :) Now try to write a serious piece of software and good luck, it is what young languages have. Did you see at the *actual* ecosystem C++ has? It is *really* impressive. C/C++ libraries of industrial strength, linters, IDEs, updated compilers... this is really difficult to beat.
Couldn't you provide a virtual method for each of the verbs, and have the default implementation return a 405? Similar to how flask-restful does it. This would be cleaner anyway as now you will always have if/switch inside onRequest.
Cool to see swagger support! Swagger is awesome.
&gt; Lots of things could have been in C++14 but were pushed back to C++17 "because C++14 is a minor release". Please name three.
OK I found a good emulator that helped me to implement support for enhanced mouse-wheels. (and hopefully precision touch-pads :)).
&gt; There's always the performance reason. `std::unique_ptr` should have no performance penalty. Optimizers should be able to inline everything since it's so trivial. `std::shared_ptr` does have one. But for the problem it solves, other solutions would need some ref-counting somewhere too. &gt; And a pointer doesn't always imply ownership (in the sense of sharing) `std::unique_ptr` ensures at compile time that only once instance owns it, changing ownership can only be done through moving it (still one owner). &gt; it could be used purely for polymorphism and the like. From C++14 onwards `std::unique_ptr&lt;Base&gt; ptr = std::make_unique&lt;Derived&gt;();` is valid. Before that, you'd have to `std::move` it. Runtime polymorphism is the same. The main point is, just about nothing is lost by using smart pointers (especially `std::unique_ptr`) but you gain a lot (like custom deleters and RAII).
I'm the author of this library. I also released major versions in 2011 and 2013, and each time this same OpenCL debate breaks out. Running on hardware from multiple vendors is a virtue, but it's not the only one. And for a lot of HPC programmers its not even an important one. If your business depends on high-performance computing, there are a lot of considerations that go into cost. The possible savings from being able to pivot to a cheaper GPU is one factor, but it's not much when weighed against the salaries of developers who program these clusters and the sys admins who maintain them. What's the cost of supporting another API compared to its advantages? Getting everyone onto the same gpu architecture, driver, CPU and operating system saves money and improves productivity. For many of us CUDA is a good choice, because it's a stable platform with a large community, good libraries, good drivers and (finally) a very good compiler. Do we absolutely lock ourselves into NVIDIA by choosing CUDA? No. If there was a compelling reason to switch to another hardware we'd find a way to do it. But the virtues of cross-vendor execution are small compared to the advantages of CUDA's very convenient, very tight device-host integration. On the subject of OpenCL, it's not a convenient language and it won't be until it becomes single-source with the host code. In CUDA I can write a statement like transform([]MGPU_DEVICE(int index) { printf("I'm GPU thread %d\n", index); }, 500, context); anywhere in my normal C++ code. The code inside the lambda gets executed on 500 threads on the GPU. Closure lets me capture variables directly from the enclosing scope. All the generic programming features of C++11 are supported here. It's easy to build libraries when this capability is available. The user can define functors or lambdas anywhere and specialize library code with them. What do you do in OpenCL? OpenCL 2.0 supports a lot of advanced features, but that's only inside the .cl files. How do you specialize a template function defined in a different translation unit in a different language? CL requires the host code to bind a kernel (defined externally, or in a string) by its string name, manually push arguments to its call stack, and dispatch it through a command queue. This just isn't flexible enough for the kind of generic programming that is available in C++ 11 more generally. Even AMD has conceded that a lot of HPC developers aren't well-served by OpenCL. They are working a CUDA-like compiler called HCC: https://github.com/RadeonOpenCompute/hcc There's an accompanying CUDA-equivalent runtime called HIP: https://github.com/GPUOpen-ProfessionalCompute-Tools/HIP HCC is single-source and uses the same syntax as CUDA. In theory it's possible to sanitize CUDA code and build it for AMD's architecture with HCC. I'd be all for using that, but the compiler and runtime is just not mature enough for production use. But it's too early for organizations that really depend on their compute to adopt. HCC is undergoing rapid development churn and CUDA has been stable for years. Still, I'm keeping my fingers crossed for HCC. Maybe in a few years we can have a compute platform that targets all hardware backends. Also, I'd encourage you guys interested in GPU computing to check out the new moderngpu. The library really does make programming the device much more productive. A lot of segmented operations like joins and graph and sparse matrix operations are very easily dispatched using the high-level transforms it provides. My library implements dozens of cool functions and the entire source is less than 5000 lines. The C++11 features in CUDA 7.5 make for very easy, very concise programming.
Some talks look really interesting, starting with the Keynote. I hope that they will be recorded. And people would be grateful if they are. But, please.... no potato quality, it's $current_year. I have no idea of the cost of renting proper recording equipment, but... pristine sound with sync slides would be great. If the camera work is poor / shaky or inexistant, It wouldn't be too bad. But clear, high quality sound is a must. 
OpenSSL is not set in stone, but I think it is the most used one so it will probably be that one I target first. But yeah, I know OpenSSL has got its reputation damaged from the latest incidents. But if I wrap things up it should probably be very easy to swap (libwebsockets supports many different SSL libs).
I don't see the issue you are trying to resolve. &gt; A concept will take the place of a type, making a template function look like a non-template one. So ? if you try to apply f to s, does it really matter if the type of S is an actual existing class or not ? I mean, in both case, either the type of s matches the requirement of f, or, it won't compile. 
It is easier than you think. You basically need to launch multiple instances of the server - either via multiple processes or via multiple threads. This is very easy in C++11 and it is like 2 lines of code, literally. But I will look into improving this so that it becomes easier for users. Utilizing multiple cores is not the problem here - the problem is writing a fast parser and having low cost connections. When you got that, it is simply a matter of multiplying the performance by the number of cores, as they run completely separated.
Let me know if you find some medicine for that.
There is another one https://github.com/mattgodbolt/seasocks, if you want to add it to your benchmarks.
One server per process/core and having each server listen to a specific port makes it very scalable in fact. You can then spawn as many servers as you need to scale as you go. This is used in [staged event-driven architectures](https://en.wikipedia.org/wiki/Staged_event-driven_architecture), where you use queues and load balancers to simplify the concurrency needs of your system, simplifying the code as well (since your code is single core and closer to your business logic).
&gt;but there's literally nothing else that can replace it. Isn't [SPIR-V](https://en.wikipedia.org/wiki/Standard_Portable_Intermediate_Representation#SPIR-V) a low level cross-platform API for OpenCL-like computing ? So you can write your own tools -&gt; SPIR-V - which sounds insane but with things like libclang and LLVM it's not entirely impossible.
Last time I checked - "commercial purposes" implied that you have some sort of revenue. We have people from VC team here - maybe they can answer this question?
Yes there are many implementations. I included the most used ones in my benchmarkings. I cannot benchmark all, but if they claim to scale better and perform better then it would be fun to benchmark. But you can find many more. cWebSockets is another example. I cannot benchmark all (that would be impossible for me). The ones I used are known for their performances and their scalings.
You seem to have a very well-informed opinion and I know you also have a great idea of C++11/14/1z. I would very much like your opinion. Reading your post, what would you recommend - using OpenMP pragmas, or Thrust? And is Thrust your "favorite" library or would you recommend another one, like vienna-cl or so? I'm looking for a cross-platform solution (Win &amp; Linux, preferably phones too) and it has to support as much of "modern C++" (C++11 and upwards) as possible.
It is still very impressive. At least I am extremely impressed. Good job!
The videos from 2015 are [up](https://www.youtube.com/user/BoostCon) and they're pretty good. I would expect them to record the 2016 sessions as well, in a very similar fashion.
Hehehe, this is very bad code really. Since I use bitfields to get bits from the header, I need to make sure the struct is packed (otherwise the compiler will most probably padd it somehow). I should port this into using portable bitwise operations (and, or, etc).
I'm just not sure how the that line of code works. Where is packed from and what does it do? Can you link me to some material? :) 
&gt; I do not want to pollute the uWS.h header with internal stuff Well, that's more or less the nature of C++. If the concern is overhead of the include dependencies, then I would argue that you're already paying a penalty for &lt;string&gt; and &lt;functional&gt;. If it's really an issue, the pimpl idiom is typically used in those cases. &gt; void pointers instead of uv_poll_t pointers This hurts the readability of the code. As I said before, it doesn't seem like you need to dynamically allocate these. Isn't "server" getting leaked anyway? &gt; I have this "transferOwnership" boolean I see. On first glance, it looked like write() was a part of an external library, and not a member function. &gt; Bounds checking is not really good for perf How much overhead do you feel it will add? At the very least, it's something that you should probably add (via asserts) for your own sanity in debug builds.
You can google it :) It is a GCC extension so it is not portable C++. If you pack a struct it becomes as small as its content (it has no padding). If you do not pack it, it can be larger because of padding.
The modules proposal doesn't really change the story for delivering binaries. If you're relying on inlined functions in headers, with modules that code goes in module interface files. If you're delivering a binary and relying on LTO, you'll continue to do that with modules, and continue using whatever solution you already have to deal with ABIs. In particular, you _don't_ 'compile a module' into some new kind of output to be delivered to users. Visual Studio's experimental implementation does produce a .ifc file, but you can think of this as being similar to .obj files. For distribution you're going to build a regular .lib, .dll, or .exe from modules. If you're distributing a library, you'll distribute it with module interface files instead of headers.
As i understand from what Bjarne said is that there are no more minor or mayor releases, every next version will have everything that is ready and done so if there are many new feauteres you can think as a mayor release He said to expalin why concepts or modules are not in the release and there will be in the next release as soon as it are finished and everybody is happy with them
Very interesting, thanks
&gt; Server gets deleted in the uv_close callback when you call Server.close() What if the user doesn't call that though? I would expect the server object to still clean up its resources when it's destroyed. 
&gt; Do real C++ devs not use new IRL? In real life developers' C++ knowledge and style varies widely. Many C++ developers, particularly ones that haven't learned new idioms as C++ has advanced do continue to use `new` in real code. However, this is not a good thing, and new developers should not be taught that this is good practice. Routine C++14 code should not use `new` or `delete` at all. They should only be used in the implementation of new resource management strategies, strategies not covered by the existing smart pointers or other resource managing data types. As an educational exercise it may be appropriate to use them, but ideally you'd learn to use them correctly, for the correct purposes. IME however most courses teaching C++ do not do this, and instead encourage incorrect usage. --- You mention that you're not allowed to use `std::vector`. If `std::vector` would be appropriate otherwise, then probably what you should do is implement your own vector type and use it instead. Otherwise you end up having to write over and over the same code for tying together an allocated buffer and the buffer's size, and for managing the buffer's lifetime. The same goes for other standard library components. Although using a vector or some close substitute is probably the right thing in your case, here's an example using `unique_ptr` to eliminate usage of `new` and `delete` and make the code exception safe while preserving the same data structure. using ListPair = list&lt;Pair&gt;; using ListPairPtr = std::unique_ptr&lt;ListPair&gt;; std::unique_ptr&lt;ListPairPtr[]&gt; _table; // this goes where the _table member is declared, replacing it _table = std::make_unique&lt;ListPairPtr[]&gt;(_size); for (int i = 0; i &lt; _size; i++) _table[i] = std::make_unique&lt;ListPair&gt;(); 
The Server.run() function blocks, so the only way to shutdown the server (without killing the process) is to call close, which deletes any resources that is not being deleted in the destructor.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/downvotesmcgoats] ["This is outright SPAM." \[-61\]](https://np.reddit.com/r/DownvotesMcGoats/comments/4cho6v/this_is_outright_spam_61/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Interesting, but not the case. Almost everywhere in the code of *operator-&gt;()* overloading, *AbiPtr* is used that is alias template for simple pointer... There is no recursive calls to operator-&gt;() for the result of call to operator-&gt;() ... This is just the same usage as we see for something like smart pointer. But thank you for the answer
When I'm implementing a generic algortihm, how do I decide whether to use a virtual concept or a compile-time concept? Or do I provide an implementation of each? Would it be possible to forgo virtual concepts altogether and allow a function template to be instantiated with the type-erased wrapper, like so: void F(Shape s) { // only one function template, using plain old concepts. cout &lt;&lt; s.get_area(); } int main() { Rectangle rect; vector&lt;Shape&gt; v = { Rectangle(), Circle() }; F(rect); // F instantiated for Rectangle, as usual. for (auto&amp;&amp; s : v) F(s); // F instantiated for type-erased Shape wrapper. } 
We have always recorded sessions, and we always will. Speakers can choose to opt out if they wish.
&gt; Yeah, people who don't follow your style guidelines are stupid. People who don't follow THE style guidelines set by the standard are stupid. &gt;Stroustrup's style is specifically in favor of My_concept. And he's incorrect. The standard library explicitly uses `MyConcept`. The standard library is correct. 
Concepts should have been in the release immediately following C++11 but weren't. 
&gt;Not all code was written yesterday. You cannot assume so much when working in real-world code: Qt does not follow these conventions, wxWidgets does not, OpenCV does not, just to name a few widely used libraries. And those libraries are old legacy code. We can't do anything about that. We can make sure that modern code is correct.
Concepts was ready enough for me in 2010. 
The [unified coroutines proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0073r1.pdf) is something that `await` could be built on top of. It's not mature enough yet for the committee to be able to give direction to reformulate `await` on top of it, but direction was given to develop the unified proposal further, and `await` is going into a TS rather than C++17, so it could still happen.
&gt; I think that being a function template vs a function is a fundamental difference... why? I mean there are some technical differences (which could lead to confusion when using the terse syntax), but why do you belive there is a *fundamental* difference? 
Write a proposal.
It could conceivably help them in that every last one of them wouldn't have to defend having support for it already if it were in the standard. Just one less thing, you know?
Not yet, but I'm definitely willing to accept any contribution in that way :)
Well OP is asking someone else to write it and argue with the committee about it, and is clearly more interested in it than most of the rest of us. I could write it, but like most people in this thread the compilers I care about already support it so I don't really care. Maybe when I don't have a handful of other proposals I'm working on I'll consider it, but this proposal literally doesn't affect anyone expect the person who is writing it and the committee members who debate it. Possibly any fringe compilers that don't support it.
The C++ committee seems dead set against changing the preprocessor in any way for the foreseeable future. They don't want to improve it, because they think it's a dead end, and they don't want to remove or degrade it for compatability reasons. As for adding pragma flags, it appears that only 3 flags are required to be implemented, and they're all from C, so if you really want this, you're more likely to convince the C committee, and then receive it in a C Stamdard update in C++. Although by then, we'll likely have modules. Also the committee, nor compilers need to defend having it. Pragma is explicitly for implementation defined behavior, and it just so turns out that most implementations like the once capabilities. I suspect that if a compiler doesn't have it, it's unlikely adding it to the standard will sway them, as they likely have other issues if they haven't supported once in all this time. 
If someone is against this proposal, he should take the time to list all the cons he found. Sounds great to me.
Well if `#pragma` is implementation-defined, add a new preprocessor that is explicit...e.g `#include_once` or something.
Interesting. I've been playing with https://github.com/cesanta/mongoose recently, but might give this a shot aswell.
I think your case study is a great set of requirements for a clang-tidy rule!
Absolutely - it should be quite simple to argue for its inclusion - every compiler already supports it. The standards guys are quite open to proposals - they just have a lot on their plates. Of course that will involve checking that the existing implementations behave exactly the same - for example what happens if macro definitions are different between two inclusions of the header.
See [Boost's auto link](http://www.boost.org/doc/libs/1_56_0/boost/config/auto_link.hpp) feature.
Looks cool. I am hoping be there.
Hi, I've added your project to [CPPAN](https://cppan.org/): [link](https://cppan.org/pvt.cppan.demo.uwebsockets/version/master). This videos show how it works: [1](https://www.youtube.com/watch?v=c_rKUpD16M4), [2](https://www.youtube.com/watch?v=LcQ9deIjB_4). For more info about cppan see this reddit [thread](https://www.reddit.com/r/cpp/comments/4c6s5f/c_archive_network_cppan/).
Does it still screw up tools that use clang for analysis?
Thanks for your help. So is there a standard c++ networking library today or not? By standard I mean something that comes with the language, like the string class.
I think you missed the point that the list on stack overflow appears to be in order of most recommended/used to least. Boost.Asio is my recommendation. 
If it's a dead end what's their solution to this problem? Are they going to implement a way to do it without the preprocessor? 
No
That suggests how much you know about taking advantage of the C++ language by itself. :)
Interesting. I hadn't given much consideration to the separate compilation issue. For me, the appeal of type erasure is an alternative to inheritance, in which interfaces and virtual functions aren't tied to class definitions. If I'm providing a library of classes, concepts, and algorithms, I don't know how my users will be using them. Chances are some will need heterogeneous containers, and others will want compile time binding, so I'll have to supply virtual and non-virtual versions of all my algorithms.
Sure, it's a poor solution to a problem that already has an alternative proposed, that being the C++ module system. Also it's not clear what's stopping this developer from using `#pragma once`. It's supported by Clang, GCC, MSVC, Intel, IBM, and a host of incredibly obscure compilers. Feel free to use it.
I mean, I get his point but sounds more as an excuse "if we write this part on the compiler wrongly". 
I am a beginner and currently on the 5th chapter. Loving it
The current modules proposal doesn't make headers completely obsolete. And as long as we still have them, adding a better mechanism than include guards is fine by me.
...Those aren't bugs. Duplicate names are exactly what the `#ifndef` and `#define` parts are for. Typos are user error. Would `#pragma oncw` be a bug?
&gt; include guards have unfixable "bugs" as well the author categorized these issues as fixable, because the programmer can change the names of defines &gt; set up the build system in a sane way how many real projects have you found with a completely sane build system? :)
This could really save C++17 for me SCNR :)
Assuming it gets added to the standard in a way that isn't `#pragma`, mistyping it would generate an error. Mistyping include guards _might_ generate a _warning_...
&gt;If someone is against this proposal, he should take the time to list all the other cons he found. That's not how the world works, if you want to make a change you should do the work, not tell others to prove you wrong. 
Update the pragma to take an optional name #pragma once [optionalname] Presto, fixed! Now it has the same drawback as guards as far as duplicate names but: a) it can be fixed the same way, editing the name and b) you only type it once, instead of the 3-lines-2-must-match.
Kool, but I see that you are connecting with a web browser (HTTP). You should try with the websocket.org example client or something. I'm currently working on differing between HTTP and WebSocket so that it wont trigger a connection if you connect with HTTP.
Thank you very much. Do you mind explaining the quote below? I did not know that in C++ you could choose to program without header files. Is that what they are saying by this quote? &gt; If you prefer the convenience of header-file-only libraries then using Asio over Boost.Asio is suggested.
At this point, it seems the only major compiler that doesn't support it already is [Solaris Studio](https://en.wikipedia.org/wiki/Pragma_once). Making it part of the standard would make it ... standardized. Make sure it has the exact same meaning across all those compilers (or at least specify which differences are implementation-defined behavior). Considering how broadly supported this is already, it seems like a no-brainer to standardize it.
Mooooooodules.
The only thing I really want to "fix" is the appeal to authority (it's not standard!) used to argue against #pragma once.
So do I put a link to this thread in a pdf and mail it in or what?
Our build system is maybe 40% sane, but it's not dumb enough to do something that would break #pragma once, fortunately.
I suppose I meant to say I've never seen such a case implemented in any project I've ever worked on, but it would make sense for libraries like boost or STL. Anyhow, new proposal: #pragma twice
I don't _think_ so, what did it screw up?
Do want.
That build environment falls into the same category as trigraphs. Yes, somebody may depend on it, but is it really worth making the rest of the world suffer?
&gt; I'd kill for some "simplified" subset version of C++ There are loads of attempts at such subsets out there. Of course they all pick a different subset, and if your desired subset isn't in there then you either compromise on some important feature, or you go back to C++. Bjarne said in some talk that he constantly has people come up to him describing their perfect C++ subset. However after listening to a few he noticed the subsets are all slightly different, and the only broader set of features which would satisfy everyone is full C++.
Eh, but you're pointing out cases of user error, whereas the comment in question is pointing out *inherent* errors due to the way the operating system reports paths.
What good is a new feature it I can't have confidence it solves my problem? Why would you ever propose a feature and say, "eh, if it doesn't work sometimes, that's fine"?
It's *still a user error*, not a problem with the operating system reporting on paths. The problem is that your build system lets the same file get picked up twice. It's a problem created by the user. It would be *nice* if the compiler and operating system could talk nicely and detect that you made this error, doing the right thing so the file is only included once. But as you said, because of how paths work this isn't always possible. But relying on the compiler to work around a user's mistake isn't the right fix anyway.
That's actually how all features work. Few features include no error cases. Few make no assumptions about the environments they run in.
**Company** TUNE **Type** Full Time **Description** We're looking for a Sr. Software Engineer to join our Dataflow Team, which solves hard concurrent and distributed programming problems. One of the most established engineering groups at TUNE, they implement the complex back-end systems that make enormous volumes of advertising-related event traffic manageable. Dataflow does the hard work so our products can be simple and deliver value to customers. **Location** Seattle **Remote** No **Visa sponsorship** H1B Transfer **Miscellaneous** The environment is primarily Linux. Here is a link to the Job Description - https://goo.gl/95HN8U
This seems like a good idea to me, I hope someone with more knowledge in the area responds.
No, that's not the place where we need to make it slower. :)
Actually, if you look at my other project, I have a zero-copy interface that could easily use &lt;insert any transport system&gt; with zero-copy. Ofc, these are features I will port over to this project.
But we need more features or C++ will become a dead language! It should use an AI trained by scraping github to automatically correct compile-time bugs too ;)
It's just slow, is all.
Thanks for this post - was looking for a modern c11/c14 book - happy to have found both stroustrup books listed.
 (_) ( _)&gt;- (_) ( ##)&gt;-
No. One is a problem of the compiler making a mistake. The other is the user making a mistake. Mis-typing the path to the header file is a user error. The Windows filesystem not guaranteeing an absolute pathname is not.
The compiler is making a mistake because your build system fooled it. Making your build system copy and link files with a similarly ambiguous search path is a user error.