If only there was a way to cause some function to cause an abnormal exit from its parent's stack. It would make things so much clearer. Suppose in "pseudo-rustese" that we have a function that returns a possible error: int? get_number(); This is equivalent to `expected&lt;T&gt;` discussed in the presentation. Suppose, then, that you want to use it: int? foo() { int? value = get_number(); return *value + 3; // or possibly just "value + 3" } If the returned value is a proper int, then it is used as such, but if it is an error, then trying to dereference the value would cause the error stored in the variable to be returned. As a final piece if you have this: int foo() { int? value = get_number(); return *value + 3; } Then it would be a compile error, because the return value is not an error type. Thus any function that returns no errors would be forced to handle all its error cases. Thus all errors would be explicit (which is what people opposing exceptions really want) but the "happy path" would be almost completely free of error boilerplate (which is what people who like exceptions really want). Rust almost has this, but it fails at the last step by littering the code with tons of `!` and `unwrap` boilerplate. It would be great to have this in C++, but since it requires language changes, not just library, it seems unlikely to happen. :(
That example in Rust would have neither `!` nor `unwrap`. What are you referring to?
 &gt; But at the end, I should not care that much about how the libs I use are configured. Right, your use case is different than mine, for sure. I do care about these things though *shrug*. Emerge, amusingly enough, doesn't require that I care. It lets me install things with the default options. It's just that it still gives me the power for the 10-20 packages I want or need to have power over. &gt; This is the core of the issue, I think. The fact that one CAN do all that should NOT mean that I HAVE to do it, nor that I have to understand it for the libraries I use. Your lib may be extra complex, but if I want to use it, I should be able to say "give me" (mostly) and have something "reasonable" (ie: usable). I'd love for things to be that easy, but not at the cost of the configuration options that I'm accustomed to having available. Emerge handles what you want, and what I want, at the same time, today, on a laptop right in front of me. &gt; The price we are paying is that developers will move away from C++, which is already considered legacy by many. What pains me is the fact that this huge necessary complexity is pushed all over the place, instead of being constrained to where it is needed. It should not be complicated by default. Yes, I agree, we shouldn't force the complexity on people. *normally* I just want to click and forget. Unfortunately, that's not always an option. My biggest concern is that the C++ community keeps wanting to take the easy, shiny candy, way out. Vcpkg is dangerous because it's curated by one of the worst companies in the world for consumer privacy, industrial ethics, and all around Embrace, Extend, Extinguish. They've made massive strides toward being good guys in the last 5 years, but that doesn't forgive 30 years of bullshit. And while Vcpkg seems to be the popular package manager w/ the feature set that's closest to my expectations, it's still unable to do half the things that Emerge is, like installing specific versions of a package, or rolling back to previous versions (on Linux, anyway. Maybe their windows support is better). So why should I care about it? It's inferior to what I already use! Conan, I believe, doesn't support compile time configuration options, maybe I'm wrong on that? Could be. Either way, neither of them support acting as the system wide package manager, only as c++ package managers... *shrug*. &gt; I don't know how it should be adressed (more specifically all the ways I can think of have major trade-offs), but I do know that there is a big C++ usability problem here (that even impacts me, so I can't even imagine how alien it is to newcomers), and that the first step to fix a problem is to admit that it exists. Personally, I don't think that the C++ standards committee should be getting involved in defining a package manager. Just like I don't think they should be getting involved in defining a graphics library. What they should be doing is defining a standardized format for describing all the things related to package management that are relevant to C++. We've got * dependencies * compiler options * linking behavior * and conditional build steps * and all of those interact with each other in screwy ways. If the c++ standards committee defined a machine parse-able format that could be used to describe these things, that didn't suck to work with (big if, i know), and was agnostic to compiler and linker implementations (even bigger if, probably biggest if), that would overwhelmingly cut down on the shit people would need to deal with to package a given library. Then it wouldn't matter much what the "official" package manager was, because as soon as I release a package that has one of these files, every (compatible) package manager automatically works with it. Now people would be able to do *myfavoritepackagemanager* install https://url/to/my/package/ my-configuation-choices-go-here and it would just work, because the package manager could read that file, and see "ahh, this package requires the following dependencies (with the associated configurations for those deps) based on the configuration options specified.", and go get those and install them, and then build the package and install that. The URL could be mapped back to named packages in that PMs repo that, themselves, have more explicit settings for things like pre or post install hooks, and so on. Doing something like this would be a strict super-set of the information needed for the majority of other languages out there, so it could, theoretically, be the one dependency-description format to rule them all. Or not, who knows. But it's an overwhelmingly hard problem, because there's an overwhelmingly large number of ways to skin this cat. Every time you add feature X to your problem set, you make 10 other features go from "No way, not our problem" to "well, we're already doing X, and doing this isn't really much different...". All of the proposed solutions that I've seen so far don't support the features I need. But even my proposed solution, Emerge, doesn't support features someone else is going to need. And we'll just go around in circles forever. But we can all agree that having some kind of standard description format is the absolute lowest level (or pretty damn close) to all of these other things. So if the standards committee wants to involve themselves in this problem space, lets have them solve the lowest level problem first, instead of jumping straight to the top of the mountain and causing an avalanche. I mean, shit. Look at how many compilers there are, with special snowflake options. Linkers, with different special snowflake options, make-like programs (Gnu make, nmake, dmake, ninja, so on and so forth), build generators (cmake, auto tools, meson, i don't even know the whole list), package formats (dpkg, rpm, ebuild, again, i don't even know the whole list), and EACH ONE OF THOSE has it's own set of distinct, meaningful, and impactful commandline and configuration file options. And a package manager needs to support all of the above, PLUS MORE!!!! &gt; Anyay, thanks for the reply, and have a nice day ! You too! It was fun.
https://cppeurope.com/wp-content/uploads/2018/02/Andrei_Alexandrescu_Expect_the_expected_slides.pdf
There's also the question of whether it's slower due to QoI issues or a fundamental misdesign. That said, it's not necessarily designed for high-perf IO needs. There's the WIP [afio proposal ](https://ned14.github.io/afio/) which aims both to offer useful async IO as well as very very high-performance IO, all based on modern C++ (e.g., usable with ranges and coroutines and executors and all that as they come online). The difference between the two is of course that `&lt;filesystem&gt;` is _much_ easier to use for the basic operations.
I would agree I was looking at that and I was like is that really what I should be doing 
You can use them to tell if a value has changed.
be very careful relying on the MS GSL. It's a very immature library with many glaring flaws that don't get actively addressed by the maintainers.
The fact that you're learning programming in school (even on an antiquated platform) puts your education way ahead of my (American) education. Most advanced 'computer' classes I was offered in high school were 'A+ Certification' (basic IT troubleshooting. Put the logic board in the slot and see if it POSTs, etc) and 'Digital Electronics' which was designing basic circuits in a simulator. My first introduction to programming was through an extra curricular Robotics club I was part of. On weekends we would go to the local University and one of the CS professors would basically just babysit us and tell us what to type to get our code to compile. I didn't even really learn what 'main' or 'void' meant.
I don't know about Rust, but to me this seems similar to the checked/unchecked exceptions debate in the Java community. Some people wouldn't like the type system to be so strict as to force the user to deal with all possible exceptions/errors. Some would.
What about cross-compilation, installing libraries per-project instead of system-wide installation, supporting other platforms, etc? None of these tools solve these problems. There are some package manager like build2, vcpkg, Conan, Hunter, Meson, etc but they have their issues too and none of them seems to be a great solution.
Typo. I meant `?`. As in for example this snippet from the Rust book: File::open("hello.txt")?.read_to_string(&amp;mut s)?; Having one ? there is annoying, two is aggravating. Real world code can easily have even more. It would be nice if the common case was "in case of error, propagate".
I know they use the same three letter acronym but are there any actual collisions?
Rust actively discourages and avoids implicit behavior; as explicitness goes, having to type one character is about as painless as it could get. C++, being not so averse to implicitness, could make different choices here.
That looks delightfully evil.
I'll direct you to the conversation I was having with /u/F54280 in the other part of this thread. Cross-compilation isn't even something that we talked about in that rather expansive discussion, and thus falls under the same arguments I made of "so many cats, so many ways to skin them" that the C++ standard has no justification for getting involved. The existing solutions already solve existing problems. Emerge, in particular, supports cross compilation like you're referring to.
That‚Äôs the dream, we‚Äôre still [stuck with GCC 4.6.3](https://imgur.com/gallery/xEX45br) . It‚Äôs so painful because you‚Äôre stuck with C++0x instead of C+11 which you quickly learn is not the same thing, nuances popping out of the woodworks at the worst time. 
...except for NaN.
What's ubuntu is that? 12.04? Isn't it severely outdated and unsupported?
Are you talking about C? There are plenty of books and references on C and there hasn't been a new ISO standard since 2011*. That said, learning C99 will get you through the vast majority of C code out there. *There's a minor "C17" revision in the works, and an expected "C2x" major revision.
Yep, 12.04 LTS, in the industry I work in its not uncommon for installations to be in place for 10-20 years or even longer. I know we even have a tiny portion of installs that run fedora 8 which is even older. All the meanwhile we provide updates to the client code on the machines as well as on our backend. There is the faintest talk of having multiple release branches, one for backwards compatibility and one that can start taking on new features that we will only pitch to new installs but it‚Äôs only talk at this point. Lots of preprocessor macros and makefile fuckery checking for GCC version at the moment. We have installs dating back even further still running (80s and 90s) where clients refuse to upgrade hardware but are still paying monthly fees so that‚Äôs also an interesting endeavor. 
He truly is a gem in the C++ community.
&gt;many glaring flaws Just curious, like what?
Gcc generates so many false warnings though, this wouldn't work for me.
RHEL (or CentOS) provide a modern compiler tool chain that produces backwards-compatible binaries. It's in the "devtoolset" package. They did some ABI "magic" which basically allows you to use the latest C++ features and the resulting binaries will run against ancient libraries (including ancient libstdc++.) It's definitely worth a look, even if you don't intend to use it in the immediate future.
There's a branch if you want to try it out: https://gcc.gnu.org/wiki/cxx-modules
Why not use something with appropriate support time? Like RedHat/CentOS? 
`-m32` doesn't work here?
We had GCC 4.4 at my old work ~a year ago and it was so painful. I left because of other reasons, but damn they didn't give a shit about upgrading the compiler. I'm absolutely certain my productivity was lower in the end because I'd think of how to write code in C++11/14/17 and then only upon implementing it realise that I couldn't do it that way.
\+
Not a big fan of the camera action. Need the projections as part of the view constantly. 
Why even use the old stuff? Compile on new compiler, deploy with new C++ library, be done. I‚Äôm using current clang for code that runs on ancient Zultys phones on MIPS. We didn‚Äôt touch the kernel, just replaced the userland as that was easy to do. 
I remember working with barycentric coordinates on affine surfaces (a plane in affine space) for my 4^th year project in college... those were dark days... cold, dark days it's a difficult topic to wrap you head around and even more difficult equations to understand (which wasn't made any easier by the fact that I couldn't debug my code any other way than by hand with pencil and paper ^^and ^^it ^^was ^^heavily ^^multithreaded ^^to ^^boot )
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8gmv9f/looking_to_learn_c_read_please/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Isn't this being fixed as we speak (based on your work, no less)???
If your project is already `-Wall -Wextra` clean, I think it's reasonable to use that as a starting point. But I'd turn off specific warnings when I run into ones that I find useless
This is not ideal on platforms where gcc wraps "system" headers in extern "C" (at least OpenBSD I believe). I still do it though.
What syntax do you imagine for using the actual value instead of auto-unwrapping it? How would `??` types work? If I have a function that returns an `int??` and I return an expression with type `int?`, what happens? If there's no `int`, do I get `None` or `Some(None)`? Having the semantic of evaluating an expression depend on the type of the expression sounds like a pain for generic code. Suppose you have this impl for `std::vector&lt;T&gt;::insert` iterator insert(iterator pos, const T&amp; value) { T copy = value; // this is copied because if value is an element of the vector // it might be invalidated when we resize the vector // make hole at pos, move copy into hole, etc. } Now if you have a `std::vector&lt;int?&gt;`, the evaluation of `value` would silently unwrap and presumably cause a compiler error since `insert` doesn't return an `?` type. It seems like generic code would become littered with boilerplate-y "don't do any magic here" annotations.
I once dealt with a case like this in a rendering engine. Got a bug about very subtle weird shadows appearing on objects randomly, and tracked it down to someone using a tolerance check in code just like this. It caused objects to occasionally fail to hit full alpha and get stuck drawing very slightly transparent. Backed out the unnecessary tolerance check and bug was fixed. "Never use == on floats, always use a tolerance" is dangerously simplistic advice. 
I can't figure out how the specific 1.3f example given would fail, though. Long double and double are supersets of narrower types as given by x87, and so the implicit in-register promotion shouldn't affect the value of any single-precision finite value. It'd compare equal to itself even if promotions differed on both sides of the ==. The only plausible scenario would be if the compiler stored 1.3f as a double or long double _and_ the stored constant had more precision than a float, which would seem like a bug. Straight 1.3 would be different, that would obviously allow for the bug.
Yes. But I'm trying to set the expectation with people that GSL is talked about like it's at an implementation level similar to std:: and that it's far from it and worse, far from getting there. 
Have you considered liberating your toolchain from your distro? You should check out nix as a package manager on your OS, getting the latest GCC will be one of a billion nice things that might come out of it.
&gt; working on constexpr allocators and std::vector. Is there any proposal, or is it just people discussing it? I'd really appreciate a link.
&gt;Randen is empirically random, computationally infeasible to predict and backtracking-resistant. For more details and benchmarks, please see the paper "Randen - fast backtracking-resistant random generator with AES+Feistel+Reverie". Has anyone looked up the paper? Feels weird they don't just summarize it in their readme
I worked on a project that's still using 3.4.6. That's right, a 12 year old compiler. And that's after upgrading from 2.95 about three years ago.
Definitely. Although it often seem like the audience doesn't get a good half of his jokes. Might be his stature and accent; When I first saw Andrei I was like "Who is this Spetsnaz guy?"
This here is the solution! Amazeballs
The [Phoronix](https://www.phoronix.com/scan.php?page=article&amp;item=gcc-clang-eoy2017&amp;num=3) Apache build test disagrees. Do you have benchmarks more recent (or for a different source tree) than December 2017?
Three compilers? Clang and g++.. what's the third? 
So the conflict is in code not written by either MS or GNU. It does seem a bit much to ask MS to change their code in case of third parties not knowing what they are doing. I am not seeing much benefit to MS to changing the name. They are unlikely to be using the GPLed GNU Scientific Library in their products. They definitely won't be using third party wrappers. The "solution" mentioned in the issue of making the build rename everything is pretty complex with lots of preprocessor use. I don't see much value in that myself and can understand why a project maintainer won't want to add that to their code. It is all open source, MIT license, so if you have the conflict if you can always fork.
The Visual C++ compilet.
&gt; faster than Mersenne Twister... Duh! Since when was MT fast, and since when was it good (it has a long period though)? &gt; Real-world applications (shuffling and sampling) indicate a performance advantage over pcg64_c32. The formulation of this claim (...real world...indicate...) makes me suspicious. Last remark, why not provide the STL &lt;random&gt; interface... A RNG is half the work, good distributions are the other bit.
that's not my experience, some examples?
MSVC
Couple remarks. This code: using U64 = unsigned long long; is unportable. You should include &lt;cstdint&gt; and use std::uint64_t instead. These two lines: static constexpr T min() { return T(0); } static constexpr T max() { return ~T(0); } assume that T is an unsigned type (if `T` is signed, `~T(0)` is probably negative). This is probably a safe assumption, but adding a static_assert to check that would be even safer. By the way, relying on std::numeric_limits&lt;T&gt;::min()/max() would be my first choice over the cast and bit_not operator.
&gt; The only plausible scenario would be if the compiler stored 1.3f as a double or long double and the stored constant had more precision than a float, which would seem like a bug. AFAIK MSVC does this for x86 ‚Äì all FP values are stored at 80-bits of precision regardless of type.
&gt; Last remark, why not provide the STL &lt;random&gt; interface... A PRNG is half the work, good distributions are the other bit. Actually `Randen&lt;T&gt;` satifisfies the requirements for a uniform random bit generator. It does not satisfy all the requirements for a random number engine, however: some ctors, seed() overloads, comparisons and stream operations are missing. Shouldn't be difficult to add them, though.
I would love to quickly trial this in one my my projects but I can‚Äôt because the interface isn‚Äôt the same as the STL interface and the project doesn‚Äôt export any cmake targets (or even use cmake for that matter).
Thats not how it works, please post links as links...
[P0784 ‚Äî Standard containers and constexpr](https://wg21.link/p0784)
&gt; has an ISO standards committee that values backwards compatibility, is implemented by multiple compilers, some commercial and some open source. I know you said "stable" but how long of a timeframe do you have in mind for this to be something you consider!? Poetry would be written about any software that makes it that long: *"When you have long past and nothing beside you remains. When they come astride this antique land and the great continents hath reformed, the sneer of cold command of the ISO C++ committee will still deliberate on these lifeless things -- ne'er to make uncompatible what was once backwardsly so!"*
Feedback: QtCreator has a presenter mode, would make it easier to follow the actions in the IDE. Fontsize for the code should be increased for better readability.
Social media is not the strongest part of "The Qt Company", I mean look at the Qt Creator twitter account: https://twitter.com/qtcreator :)
Does the standard require that calloc and malloc allocate from the same pool of memory? Because if not then, hypothetically, a compiler can use some address range for calloc (where e.g. some bank switching can be used to have objects larger than 4 GB), and another address range for malloc. In such a case the elimination of calloc size test would not be a bug, as the limits of calloc might not be relevant for malloc, and the calloc'ed memory is never used.
Well, the code-quality doesn't really strike me as stellar. * non-standard-naming-conventions * `using U64 = unsigned long long;` is where a job-interview should end * Use of plain C-arrays (`std::array` anyone?) * Huge ifdef-maces * ... 
Just to be clear, my post was an ironic summary of the posted article, not my opinion. I do like exceptions, although I understand people who don't. What makes me sad (and I totally agree with u/guepier, here) is reading people saying that "C++ is bad" just because of exceptions, when as you correctly pointed out... you can simply not use them.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8gqdav/intro_to_c_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That's awesome! I wonder if this means we'll see a wave of open source devices with improved UIs?
This is so good. Thanks for sharing it.
This looks great; languages like Rust have shown that it's reasonable to provide strong randomness by default so the faster that can be the better. I always feel a bit weird about RNGs that depend on AES hardware acceleration, though, since platform-specific hackery is never the nicest requirement. Looking forward to the paper.
When I hear "microcontroller", I imagine things like "2kb RAM" and "2mhz" :P I'm getting old.
We need a vocabulary update, I program ‚Äúnano-controllers‚Äù with 1k of ram...? Do ‚ÄúPico-controllers‚Äù have 24 bytes of instruction rom?
&gt; Also, being an attribute, the compiler will be super picky about where you put it ‚Äî and passive-aggressively quiet if you accidentally put it in the wrong place (because unrecognized attributes are supposed to be quietly ignored). Why would it be quietly ignored if it's recognized? It *is* recognized, so putting it in the wrong place should give an error?
&gt; using U64 = unsigned long long; is where a job-interview should end I mean I get that there's `&lt;cstdint&gt;` and `std::uint64_t` but would that really be an interview ending event considering [the reference](http://en.cppreference.com/w/cpp/language/types) shows that in most cases it's correct?
&gt; A known-key distinguisher on 10-round, 128-bit AES Not a big deal, in practice makes possible brute attacks near four times faster. Right now brute force attacks against AES-128 would take billions of years, even in a fabulous super computer with billions of cores. 
Does the left side of the page somehow interacts with the right one? If not, is the purpose of such layout to manually search for answers in either of them? Or to confirm answers from SO? I'm trying to understand the use cases.
Ah, it loads papers only after clicking on the green text fields. Thanks for the hint.
yes exactly, the quotes that can be found are matched against the three drafts n3337, n4140 and n4659. I am working on adding it also vice versa so that you can browse inside the standard and jump to questions talking about this section.
You're right, thank you for the correction, but even in that case, you've still gained information, and in most cases the use of the equality operator with floats can still be useful. If I'm using the equality operator to tell if something's changed, then any change, even a change to NaN, will yield false, unless of course the original value was NaN...but there's no reason why I would be using that as the initial value I was testing it against.
You know this is a system I could get behind, though picocontrollers sounds unneeded
IDK. :) You could be right. 
Thank you for the link! There are multiple Fastware talks. These slides are new. New to me, at least.
No it doesn't: https://godbolt.org/g/CkNQbE It loads float constants as float and double constants as double, and the promotion to 80-bit is implicit in the FPU. It also truncates significant bits when preconverting float constants to double, as can be seen here (0x3FF4CCCC0000000). 
It's less about whether the specific case is likely to work and more about what it tells about the authors approach to portability and good code. My impression is that people who write something like this tend to have the mindset of someone who wrote unportable C-code a couple of decades ago for one highly specific machine without consideration whether it will work anywhere else. People like that are not likely to ever care about using modern idioms or the standard-library to any non-trivial extend. So yes, I think this is where an interview should end, unless there are other highly compelling reasons for the person.
To extend on that: AES is a horrible algorithm if you want to implement it securely (using existing instructions is not ‚Äúimplementing‚Äù in that sense), since it practically BEGS you to introduce timing-attack-vulnerabilities. In addition to that there are apparently versions of Salsa or Chacha that when used with SSE can outperform even AES-NI. And implementing those two is quite easy: If you just do what the paper tells you to, there won't be any real issues.
I am pleasently surprised they actually even made the distinction between tiny mcu's and beefy mcu's. Sadly though, the resulting requirements are single digit megabytes of flash and ram. And probably the need for a full frame buffer in memory. 
`&lt;cstdint&gt;` doesn't inline the std namespace. Even if it did, writing its types without the std prefix in library code doens't sound like a good thing to do.
Loading a PDF file of the standard feels troublesome. Wouldn't it be nice if it instead loads a webpage like http://eel.is/c++draft/ ?
awesome, thank you very much. I have been looking for something like this actually but did not find it. I will look into switching to this HTML version.
QtCreator has a startup option -presentationMode, then all functional key presses etc. are visible on screen, like when you press F4 to get to the header/cpp file of a class your viewing. Easy way to visualize what you are doing with the IDE.
&gt; How would ?? types work? What are those? Something like expected&lt;expected&lt;T&gt;&gt;? Probably that would have to be forbidden to retain sanity. &gt; the evaluation of value would silently unwrap Not really, since the type of `T` would resolve to `Class?` and copying those can be done without unwrapping. &gt; insert doesn't return an ? type Presumably `iterator` would actually be `iterator&lt;T&gt;` which is `iterator&lt;class T?&gt;` which would be again fine. Or possibly the`?` could migrate out somehow to get `iterator&lt;class&gt;?`. But yes, there are corner cases and surprises here that require careful thinking and planning.
Yeah I was thinking that. Though the chips they picked do definitely qualify, they are basically the most high performance chips that I would consider microcontrollers anymore. Also you may be getting old but tiny 8-bit machines are still in common use, so maybe not that old ;)
&gt; Also you may be getting old but tiny 8-bit machines are still in common use, so maybe not that old ;) are there 8 bit machines that would be able to drive a 800x480 touchscreen ? :p 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8gsjwr/new_to_c_a_bit_of_help_trying_to_return_a_string/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Keeping the model data out of the model itself and in a "backend" class is easy enough for list models (and not that bad for table models), but I can't really picture how it works for tree models. My tree model data always lives inside the model class, but there are times when a further separation would be desirable. Does anyone have a nice, clean example of this? Do just end up having to create your own QModelIndex equivalent class for the back end and all the operations just constantly convert back and forth? I imagine that's got to be a tonne of boilerplate.
It sounds somewhat wrong to me too but I guess the logic is something like this. Unrecognized attributes are ignored which allows compiling new annotated code under older compilers without them screaming about it. A similar thing would be possible if an attribute's allowed usage places are extended later and used. An older compiler can still use it wherever it knows its meaning but won't scream where it doesn't because it may just be too old. I suppose it's for kind of backwards compatibly. It also sounds like compilers might want to have a warning about it.
This is rad.
I think I saw something like this on Atmega644 or similar, so wouldn't surprise me.
The PDF's section numbers are completely messed up.
There's no content after 12/2017... was 2018 not a year for C++ ISO standard questions?
True, that is caused by the injection of my markers into the latex that allow for the jumping. There are many obvious improvements and I have a packed to-do list but I wanted to get a first version out quick to see a first round of feedbacks
That is unfortunately caused by the way how I inject the markers into the latex to allow for the jumping. There is a lot of room for improvement and my to-do list is packed. I wanted to get a first version out quick, however, to get an initial round of feedbacks . Thanks to the feedback of another commenter the next version might use the html version of the std and make my life much easier 
There is nothing wrong apart from the missing cast. It is obvious that whoever wrote the article doesn't know the language and was expecting something else, maybe an expensive conversion from int to string instead the cheap conversion from int to char.
In my opinion it's generally better to be explicit and show exactly where each type comes from rather than rely on the global namespace like in C. That way everything that comes from `std` explicitly has "std" in front of it so that it is consistant with other namespaced library code such as `glm::f32vec4` without giving the standard library "special attention".
Wow Qt really has NIH syndrome.
&gt; improved UIs &gt; Qt Pick one. :-P (I'm not entirely serious, but SCNR.)
I'm glad to see M4Fs being used, instead of the usual "isn't a Raspberry Pi a microcontroller?" posts, but I would have liked to see an M3 as well. It sounds like you're not even using the floating point built into the M4F, so there wouldn't be too much difference in performance, but M4F is pretty high-end for a microcontroller. The M7 ones are practically stratospheric. Not a lot of products can allocate ~$10 (in quantity) for just the microcontroller alone, especially when SBCs like the Raspberry PI Zero are in the $5 to $10 price range, and that includes far more than just a processor, ~1MB of RAM, and some tiny amount of built-in flash. Obviously, different tools for different applications. The M7 is significantly more power efficient compared to an SBC like the RPi0, and microcontroller software tends to turn on "instantly", compared to waiting a minute for Linux to boot up. It's still painful to allocate that much budget to just a microcontroller.
Is "I needed a type that was atleast 64-bits wide" not a good enough reason to use `unsigned long long`? I mean if we're being really pedantic about portability `std::int64_t` is only provided if the [implementation directly supports the type](http://en.cppreference.com/w/cpp/header/cstdint) so to pass your interview would an interviewee be expected to use `std::int_least64_t`? Honestly I'm just surprised someone would end an interview for using something that is correct by the standards definition.
&gt; pcg64 (there's no official variant called pcg64_c32... maybe they meant pcg64_k32?) typedef pcg_engines::ext_setseq_xsl_rr_128_64&lt;5,16,false&gt; pcg64_c32; typedef pcg_engines::ext_oneseq_xsl_rr_128_64&lt;5,128,false&gt; pcg64_c32_oneseq; typedef pcg_engines::ext_mcg_xsl_rr_128_64&lt;5,128,false&gt; pcg64_c32_fast; 
Not listed in [the docs](http://www.pcg-random.org/using-pcg-cpp.html).
True, but if you want GUI you'll already have to allocate for LCD, probably with a touchscreen.
Thank you! We try our best to be responsive and to help our users. It's not always perfect and some feature requests / wishes can not be granted as we are developing the PEGTL in our spare time. It's still nice to see that our effort is recognised :\) About being "battle\-ready": The PEGTL is, unsurprisingly, used in the company I'm working for. It is used in several programs and is processing a large number of requests 24/7. In all the years we are using it, the PEGTL never caused any problems for us \- in fact it is a huge help, which is also connected to the next point: About writing your parsers by hand: One of our users wrote a very nice blog post about why you should never write Ad\-Hoc Parsers \- and how the PEGTL helped him. It's a good read in general and obviously a nice advertisement for the PEGTL ;\) If you want to check it out: [https://neopg.io/blog/no\-ad\-hoc\-parser/](https://neopg.io/blog/no-ad-hoc-parser/)
Tesla Model 3 run Qt UI, and it looks pretty neat
Raise that to 20mhz and you've described an arduino. The small stuff still lives.
I can't agree. Here's a google image search on the subject. https://www.google.com/search?q=qt+gui+example&amp;newwindow=1&amp;client=firefox-b-1-ab&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=0ahUKEwing6vx4OraAhXvqlkKHXZZD3gQ_AUICigB&amp;biw=1920&amp;bih=942
That's not a false warning. It's perfectly legal for Enum1 to have a value other than E1, E2 and E3 (one can argue that's not a good practice in general either).
East const forever.
Spending $X for a touchscreen doesn‚Äôt justify spending an additional $Y for a microcontroller. You might *only* be able to afford the $X touchscreen simply because you‚Äôre **not** spending $Y.
That is a substantial difference- especially given that gcc-8 was generally building faster binaries in those Phoronix tests, as well. I am quite surprised. Have you compared to gcc 8.1 yet?
You are right, my bad. I was under the impression that it's UB for an enum to have a value that doesn't correspond to one of its elements. Thinking about it, it makes sense from a security point of view to put a guard at the end of the function. (I have dozens of such functions in my code). I wonder why clang doesn't trigger a warning here.
PicoBlaze is a soft core processor for FPGAs. 8 bit registers, 16 of them, 64 bytes of scratch space, a 16 deep call stack (return PC only, no data), and 1024 instruction memory (all opcodes are the same size and execute in 2 cycles). Has an integer ALU but no multiply (unless you add one yourself). It's Also redicously tiny in FPGA resources. 
I thought the article was also about C++ because of the reddit thread name, but even if it wasn't, it was a great read.
In the post: &gt; 256 MB of RAM; &gt; 500 MHz CPU (1 GHz preferred); &gt; OpenGL ES 2.0 support. It is like a desktop in early 2000s. I feel old too.
&gt; POSIX-compatible operating system &gt; C++11-compatible compiler These two eliminate most microcontrollers (in the traditional sense of the word). Looks like what we have is mini-fied PCs masquerading is microcontrollers and elbowing into the price point previously occupied by low power uCs :)
&gt; kind of backwards compatibly forward compatibility :)
&gt; - Use of plain C-arrays (`std::array` anyone?) I can't see any obvious benefit of `std::array` over C-array in this specific case. But I can see a (probably neglectable) burden of `#include &lt;array&gt;`.
And this is not as "low level" is commonly understood. And one can program chips at low level in c.
üòø
&gt; commonlz understood The article details mentions significant consequences that require questioning that "common understanding". E.g. an essential property of low-level languages is that a simple 1:1 - translation is efficient w.r.t. use of execution ressources and close to the optimum translation. That's patently false on modern desktop processors. To put it differently: there's no point in sticking to a definition that once worked well when the definition became meaningless. (and yes, there are processors for which C still remains a low level language. Doesn't make a dent in the points the article raises.)
Given the [dozen or so](https://www.fluentcpp.com/posts/#strong-types) articles you've written about strong types, most recently [here](https://www.fluentcpp.com/2018/04/06/strong-types-by-struct/), why not just: using WearsAHat = NamedType&lt;bool, struct GoblinTag&gt;; class Goblin { public: explicit Goblin(WearsAHat ); }; Goblin bill(WearsAHat{true}); What's the benefit of providing named constants? The fact that somebody _could_ write: Goblin bill(WithAHat); doesn't really prevent everybody else from writing: Goblin alice(false); ?
You also program against that abstraction in assembly though.
Brilliant article and excellent argument. I thought the title was going to be clickbait and not only was it not, but he convinced me. I've had the experience of having to optimize c++ code. Thinking about the cache, using struct of arrays, worrying about pointer aliasing, etc. Up until now, I have been thinking that optimizing for the low level is just simply difficult and that's that. I didn't consider that it was due to how c/c++ worked. If the languages themselves were built so that those low level features were implicitly built into the language, you wouldn't have to keep twisting code around and mentally simulating how it would work in the cache and the generated assembly.
It isn't tho. 
Yes, they are. Also: they have **not** spent one single second thinking about this at all and are generally not as smart as you, all of them combined. 
Also if i cannot change fhe code i usually do something like: Goblin(!"wearAHat");
&gt; just uint64_t Not C++ (not saying that's an issue!).
The non-triviality or the default destructor really puzzles me. Intuitively I'd try to specify that a defaulted destructor is trivial if all owned resources' destructors are trivial. If anyone could enlighten the naive me or point to discussions on that I'd be very thankful.
That‚Äôs because they didn‚Äôt care enough to slim it down. A properly hacked Qt build can run on an Atari ST emulator with a tad more memory. It takes a bit of effort to make it fit, but it‚Äôs eminently doable. A feamebuffer-backed QImage can be painted on in 500k of RAM or so (just the painter machinery, no QObject nor anything else). Default Qt builds and preset config options are limiting. Once you don‚Äôt mind editing the source code, you can make Qt do with very few resources. 
The old-fashion way would be using flags. Goblin my_goblin( WEARS_HAT | WEARS_PANTS ); I think that still works nicely in a lot of cases. You don't need to keep the actual flags around, btw, you can use them for that one function only and convert them immediately to bool members. Ofcourse this only works for bools while the issue is a lot larger. I often run into cases where a constructor of function needs a lot of string arguments. This is easy to mess up by switching the order, certainly when refactoring. C++20 might include designated initializers. That would make it possible to do Goblin my_goblin({.wears_hat = true, .wears_pants = true}); if you define a struct to contain the arguments. This would cover the issue properly. I really hope that passes.
The old-fashion way would be using flags. Goblin my_goblin( WEARS_HAT | WEARS_PANTS ); I think that still works nicely in a lot of cases. You don't need to keep the actual flags around, btw, you can use them for that one function only and convert them immediately to bool members. Ofcourse this only works for bools while the issue is a lot larger. I often run into cases where a constructor of function needs a lot of string arguments. This is easy to mess up by switching the order, certainly when refactoring. C++20 might include designated initializers. That would make it possible to do Goblin my_goblin({.wears_hat = true, .wears_pants = true}); if you define a struct to contain the arguments. This would cover the issue properly. I really hope that passes.
I can understand UCs not exposing the POSIX API, but a c++11 compiler ? You can target PIC32 and various ATMega32 stuff with modern C++ standards.
That is only for ARM cores with GCC support. They are plenty of older MIPS/PowerPC cores running supporting older GCC versions (or IAR/Keil before they had modern C++ support). Most designs in embedded are long term, like really long term (10+ yrs is usual)
&gt; you can make Qt do with very few resources. interesting, thanks for sharing :)
It's not the default destructor that is non-trivial. It's the disabling of the "triviality" of the destructor by providing one defined as `{}`. `{}` is not a trivial destructor, because the language doesn't care that there are no statements in the destructor.
&gt; If the languages themselves were built so that those low level features were implicitly built into the language, you wouldn't have to keep twisting code around and mentally simulating how it would work in the cache and the generated assembly. The problem is not all processors have the same low level features, and exposing that through a language like C or C++ may make some programs unnecessarily unportable. C and C++ still has to work with microcontrollers without threads, cache or branch prediction.
&gt; Huge ifdef-maces A spelling error! The interview must end here.
That sounds like a very insane thing to do.
It does apply to C++ as well - it has the same "low level" limit as C, it just builds higher abstractions on top.
KDE has a [nice policy](https://community.kde.org/Policies/Library_Code_Policy#Flags) about boolean arguments: use flags instead. I have been applying this policy in my own code for years and it works great.
&gt; AVR in production is still a dream. Have you looked at C++11 in IAR or Keil (industry strandard compilers)? IIRC IAR added it only in the last year and only for newer versions (requires an expensive license update). Embedded systems in production is very different from the hobbyist grade stuff.
I'll pay more attention once the compiler is MIT &lt;3
The motivation is [N3791: Lightweight Drawing Library - Objectives, Requirements, Strategies](https://isocpp.org/files/papers/n3791.html) that, IMO, [has not been addressed by SG13](https://www.reddit.com/r/cpp/comments/89q6wr/sg13_2d_graphics_why_it_failed/). I called it HMI because that's the name of SG13 even if it could have been called "windowing", "graphics", "rich IO", or something else (naming things is difficult). The main use cases are: provide a simple drawing API for teaching, and provide an API that can be used by experts to get a window and create a drawing context (e.g. games). 
&gt;The implementation is based on SDL2 and GLES2 So you need them in a standard conforming compiler?
&gt; The C restrict keyword can help here. It guarantees that writes through one pointer do not interfere with reads via another (or if they do, that the programmer is happy for the program to give unexpected results). This information is far more limited than in a language such as Fortran, which is a big part of the reason that C has failed to displace Fortran in high-performance computing. What exactly does Fortran have?
&gt; Who said I said, and the author. And I stand by it: This is not a definition, but an implicit / intrinsic property of low-level languages - it is even "in their genes", so to say: being only a small abstraction above the processor's machine language. This e.g. results in trivial compilers, largely trivial compilation-reversal, and in close control over the execution. FWIW, a definition - whatever definition you want to rely on - exists in a context, and when the context changes, the scope of the definition changes. &gt; variety in processors I would claim they were architecturally similar, at least w.r.t. the fundamental shift in architecture that the article discusses. A lot of the "implementation-defined" rules in C and C++ can be traced back to exactly that variation of processors that existed back then, sacrificing some concreteness in definition to allow native instructions to be used for the respective operations (register sizes, overflow rules, etc.) 
Which definition? (I didn't intend to make one, partly because discussions about definitions tend to become pointless quickly) And yes, as mentioned [here](https://www.reddit.com/r/cpp/comments/8gvfux/cc_is_not_a_lowlevel_language_acm_queue/dyfaml3/), I know that there are many processors to which the article does not apply. I don't see why this seems so important, though. 
Now I'm wondering - are there any optimizations or something that is allowed in C++ but not in C?
No. You can choose whatever API you want. Another implementation could use the Windows API with Direct3D. A Linux implementation could use Wayland and Vulkan. The proposal is just an API (as everything else in the standard). This implementation is just a way to show that the API can be implemented on many systems. Now, if the question is "do we need this type of API (windowing) in the standard?", my anwer is: yes, I think we need it. Window creation and event handling is not bleeding edge technology, it has been here for so many years and yet, there is no standard for this. It is high time to simplify the work of many people and have a common API, whatever the system. So "do we need it in the standard C++ library?", my answer is still yes, I think it's the best place for it for acceptation and broad use.
Which I would say is exactly the point of the article: even if you go down to machine code, i.e. the "public interface" of the processor, you are still multiple abstractions away from the actual execution engine. 
Yes, return value optimization.
Really? I understand that since C has no notion of moving, it doesn't offer passing pointer resources, but does it also mean that C unnecessary copies structs of non-pointers?
Yup, that's why every C course heavily discourages returning structs.
I always thought of high/low level as a relative thing. Java is high level compared to C++ and C is low level compared to C++, until we get to ASM and straight up bits. Arguing about what is high and low level as a language on its own is a waste of time.
TIL
this is so cool... really hope fmt will be part of C++20
The output on your main page is wrong. I can't find the line my_struct [ 13, my struct ] in example code above it.
I was curious about what he meant by that as well, having spent a lot of time with fortran. I'm not aware what more "information" fortran gives. The language spec does guarantee that there is no aliasing, which AFAIK is worth no more or less than the restrict keyword.
&gt; about what it tells about the authors approach to portability and good code Total bikeshedding bullshit. Just about everything matters more than the stuff you mentioned. Getting lost on details like this says a lot more about yourself than it does about them.
&gt; The language spec does guarantee that there is no aliasing, which AFAIK is worth no more or less than the restrict keyword. `restrict` just guarantees that two pointers in the same scope do not alias; AFAIK Fortran guarantees are _far_ stronger than that.
This won't be confused with [ufw](https://wiki.archlinux.org/index.php/Uncomplicated_Firewall) at all.
That's entirely fair. C itself was created to be a high level language at the time so that developers weren't writing assembly everywhere,but nowadays it's seen as relatively low since you're working with pointers as memory addresses (as opposed to object references in Java/C#) and can work on byte-level data more than what we now see as high-level. It's an interesting article nonetheless
The article mentions that whether language is low-level or high-level is a continuum, but then conveniently ignores the fact that, after assembly, C is the lowest-level commonly used language. What makes C low level is not how close it's to the metal. It's how lower it is compared with languages like Python, C# or even C++.
Thanks, fixed now. 
&gt; this is extension, did you consider to propose your idea to author of fmt? Yes I did this already.
I thank you :-)
&gt; AFAIK Fortran guarantees are far stronger than that. Okay, but what are those guarantees?
There is this for the iostreams: https://louisdx.github.io/cxx-prettyprint/ It uses {} for sets, [] for sequence containers and () for tuples, which matches the mathematical notation. Maybe do that as well?
Great article, agree on most points. One nitpick; In the case of loop unswitching, isn't it the case that any unswitching done, could in fact be represented by some C code? i.e. for(;;) { if(x) { a(); } else { b(); } } would become if(x) { for(;;) { a(); } } else { for(;;) { b(); } } That seems more like a case _for_ the expressivity of the language to me... maybe I missed something?
Exactly this; I think this is actually more a critique of processor and compiler designers than the language, i.e. intel catered to how C programmers wrote code for their chips, rather than forcing a language design change by simply focusing on fast chips. Having worked with very small embedded cache-less systems, C does map closer to these chips, much more like the PDP-11 example in the article.
https://en.wikipedia.org/wiki/Uncomplicated_Firewall
To extend on suggestions for the output-format: Whitespace that seperates the braces from the content looks a bit silly and also doesn't match what most other languages do. Compare [ 1, 2, 3, 4, 5 ] [1, 2, 3, 4, 5] [ [ [ 1, 2 ], [ 3, 4, 5 ], [ 6 , 7 ] ], [ [ 8, 9 ] ] ] [[[1, 2], [3, 4, 5], [6, 7]], [[8, 9]]] I'd say the second version looks more readable then the first, though I admit that both aren't perfect.
`void` is, essentially, a unit type, that the language artificially handicaps by not allowing explicitly creating instances of it. I am not aware of any compelling reason for it to be forbidden other then historical cruft.
So what's the "fun" part of working on such a ~~micro...~~ desktop machine?
What you are proposing is a version of an Immediate Mode Gui. I've use one (Dear ImGui by Ocornut) for some month in a research domain with quite a bit of success, so maybe my opinion matters. In theory, everything work in a smooth way and you can be really fast at implementing features. Credits goes to Ocornut for making his library very easy to use and adding custom widget with weird behavior is surprisingly simple. You are however dependant on your rendering API to work and this is not trivial. Do you have a GPU ? Around me at this moment there is 2 computer without one. My job require me that some features must be interact with on any hardware, so i cannot use it in production. It's fantastic for debugging however. Do you have a good GPU ? This is the tricky part. In theory, Immediate mode Gui are quite fast and lightweight. The trade-off is that you must update your display every frame, or if you are lucky you can draw only when your data is updated. If you begin to lag, your whole IMGUI become less expensive. Technically, you renderer function is API versatile ( not independant)since you base you implementation on a simple OpenGL/Direct3d/other shader function. However, nothing prevents someone to add a special rendering function with optimization and at one point their will be a shader function with different implementation depending on the hardware. I've had this problem on non-Gui related display where on NVIDIA it returned 0 in case of error and on Intel it crashed. Both cases was an edge case of the same function, but their is difference in API that cannot be ignored. It's one of the challenge of the proposal N3791. However it could be akward to implement a library and it crash because of some hardware differences. Do you have a good CPU ? You are updating your display every frame, or managing your update yourself. On a less-capable computer I had to only update my display when i was moving the mouse or clicking or using the keyboard. The data shown was rather static so nobody saw the difference, but we cannot ignore cellphone and other devices with a battery that the number of instruction per watt is important. On your implementation in HMi, i see that your example is waiting on windows event to draw. In my cases the data updates range from almost never to high frequency. Sometimes it's not trivial. Let me tell you that blocking function can create some interesting ( explosive ) behavior. TL;DR : I've use one of those library in my code and i really love it, often recommending it to my colleagues but i'm somewhat against implementing it in the standard library. I require knowledge of Rendering API process, hardware dependency and implementation experience to understand the bugs. The product that i'm implementing is a best of both world : We use Qt for data-related interaction to our products, and OpenGL with ImGui for the controls of our display. 
Great article. I created a similar set of utilities for one of my libraries, using the name `nothing` instead of `Void`: https://github.com/SuperV1234/orizzonte/blob/master/include/orizzonte/utility/nothing.hpp Really wish we had "regular `void`" in the language...
DEY TUK UR NAMES!!!
Use inline functions instead, unless there's a really, really good reason not not.
I remember R++ offering functionality to expand a macro one step at a time.
agreed - however the code base I'm stepping into uses a lot of macro functions.
&gt; I can't seem to find where my macro was expanded to To find the line where the macro is expanded, search for the code immediately before or after your macro.
C is a low level language if you are running on a PDP11. Other than that, not really anymore. 
C++ also provides stronger alignment guarantees, which allows use of SIMD instructions in places where it wouldn't be possible in C.
**Company:** Freedom Scientific **Type:** Full time **Description:** We create accessibility software for individuals who are blind or have low vision. This software includes the #1 screen reader, JAWS, and magnification software, ZoomText. We are looking for mid-level software engineers with experience in the Windows operating system. **Location:** We are located in the Tampa Bay, Florida area but have offices in California and Rotterdam, Holland. We will consider remote workers as well. **Remote:** Yes **Visa Sponsorship:** We are not currently sponsoring for visas. **Technologies:** Visual Studio C++, Standard Windows libraries **Contact:** Send resume and cover letter via email to careers@freedomscientific.com
http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-gsl
Any example? I don't that much about alignment and padding.
It doesn't but the cost of the MCU becomes much less proportionally so it's safe to assume it can be allotted a bit bigger budget.
There was a CppCast episode 21st of December with Matt Calabrese as a guest discussing this proposal.
I was doing a bit of research after reading this article and came across [this] (https://blog.erratasec.com/2015/03/x86-is-high-level-language.html) article, which complements the OP nicely.
Only an issue if you are comparing numbers without a precise representation. 
The real issue is not understanding how floating numbers work. Javascript uses only double precision floating point numbers, it doesn't have integers because double is safe for operations involving only integers in the range -(2^53 - 1) to (2^53 - 1). 
Don't most C headers have an #ifdef for C++ where they use extern "C"? You may be able to use that fact so that within extern "C" {} the old meaning of void is kept, and within C++ code, you get the new type where void is regular. 
Sure, a special case might / could be made for code parsed inside of an extern "C" statement. It still leaves existing C++ code as problematic. Likely there'll need to be a 10year+ depreciation period if that ever changes.
&gt; In Fortran, procedure arguments and other variables may not alias each toher (unless they are pointers or have the target attribute)
WTF are you talking about? The ABI for returning structs (of size &gt; 16) is exactly the same as the ABI for C++. RVO is how returning structs is implemented.
Are you sure you know what static mean when using it at namespace scope? Is it really the desired behavior?
The M4F vs M3 could be down to atomics for example. I have seen pretty distinct differences in assembly capabilities on those two, but nothing that couldn't be worked around and M3 should be possible if M4 is. Now M0 would be a complete shock for everyone.
True. His code is just shit, it is stupid to rely on side effects not specified in the [contract of calloc](http://pubs.opengroup.org/onlinepubs/9699919799/functions/calloc.html). 
Well in most cases you need the framebuffer to represent the image so it has some place to render otherwise you would just be pushing the memory cost needed for your screen resolution to a buffer that would have to be out on your screen and that is a less than desirable solution. You could make the entire screen rendered directly to draw commands without buffering but then I would expect you stuff to run with a high draw latency and you'd be likely to have artifacts on your UI as it draws. Besides a few MB of Flash and Ram was cheap in 2008. It is dirt cheap now. I work at an electronics company and all our recent designs have access to heaps of the stuff because of the mobile phone revolution which means larger 4 Gigabit RAM and Nand flash are often cheaper or have much longer promised production availability times than most MCUs. Besides what exactly is the shame in having say 16 MB RAM or something mounted on a design? Are you punishing yourself? In all but the minimal stuff like remote controls and the like you can have more memory these days.
Thank you for your advice. Do you know where I can see open issues for X3? I like to know how many and errors there are when I use a library. Not because I can't use a product without issues (I would not have any compiler in that case!), but because I like to get a feeling of its stability and see how fast the response is to error reports.
Now I have to disagree without knowing your situation. We have some pretty high availability \(like no interruptions ever, try to recover from multiple broken parts, sensors and so on kinda systems\) embedded stuff even very tiny stuff being compiled to... C\+\+14 at the moment. Why well because even if the hardware platforms are from 2006\-2009 the software platforms are maintained and so we have just kept going along. It is fully in production and has been C\+\+11 for years. We are in process of updating our compilers and platforms to C\+\+17 capable versions and will release products with this in a year or two. We don't use STL but that is a different matter altogether.
You could try making a new function with an easily searchable name and using your macro in there. Then search for the function in the preprocessor output.
Agreed.
Even just with a willingness to cut and burn before you edit code you can get it down to a few Megabytes for starters.
That sounds about right. Been a while since I have seen what you classed a picocontroller, but something in that class of system is still used for super simple stuff.
There are tons of reasons for not wanting an external dram ic in your design. For one, it uses a massive amount of power. Your PCB which might have been fine at 2 layer now needs 4 layers. EMI compliance is non trivial with such large and fast busses on a PCB. PCB is larger to accommodate Dram ic and in addition to supporting circuitry like voltage regulator and vref solution. Design is much more complicated due to adding external dram. One more part to worry about being able to source. Cost, that adds an extra two or three dollars. And if you want it to be aeq-100 or better? Oh man, even more. You need a bigger ic in terms of pads just to accommodate Dram, not to mention finding an mcu which can interface with dram in the first place. There are tons of reasons to not put dram in your design if you can avoid it.
Nah, those are static variable at class scope. That's okay. But static variable at namespace scope will affect their linkage to be static, creating *one instance per translation unit*. Which means that `Shape::cirle`, `Shape::triangle` and `Shape::square` will have different values in each cpp file.
&gt; 10+ yrs is usual C++11 is almost 10 years old! What a coincidence!
As far as I see the code relies on this type being exactly 64 bits. Interestingly, implementation file `randen.cc` uses `uint64_t`. So this `U64` thing is probably some leftover. 
&gt; Can we just call something with 256 MB of RAM a "controller" and leave a more traditional definition of microcontroller in place? That's you imagining things. None of the tested controllers had even close to 256 MB of RAM.
Thank you for your reply, Daniel - and for your link. I have skimmed the PEGTL documentation and find it very good. Will begin to play with PEGTL whenever I find the time, which unfortunately is not right now. /Peter
That is "NRVO", which is distinct from RVO.
D'oh, you are right. I had only skimmed the article when I posted that and saw their "Qt‚Äôs current hardware requirements" and misunderstood that to be the hardware the post was about.
As I understand, `const extren AddEnum&lt;Shape&gt; triangle{}` is not allowed in header?
Yeah. It'd be nice if they've also added a nice spec comparison table of MCU's they've used instead of just linking to their datasheets.
In C, unlike in C++, RVO is covered by the as-if rule.
Interesting read, but isn't it very depending on the problem if another architecture would make it faster? He mentions other languages, like Erlang, but the fact that they have not taken over the world indicate they are not actually suitable abstractions for all problems. Many problems are inherently linear, or with low degrees of parallelism. It seems likely that these problems would be slower and maybe harder to program for with another model. Also, isn't a GPU kind of the solution to this problem?
https://github.com/boostorg/spirit
I am down voting you just for spreading "C/C++" fallacy.
Looks interesting, and the interface seems well thought out. However, at this point, I think all c++ networking libraries need to standardize on using asio which is the basis for the C++ networking standardization efforts. With libraries that standardize on asio, it becomes easy for me to use multiple libraries and not have them trample all over each others event loops and other sorts of fun stuff.
If you need ask this kind of question it means that you have no need to use macros. The fact that you are asking it implies that you have limited experience/knowledge of the language and its environment which in turn necessities the fact that you can tackle only simple problems right now. Use of macros MIGHT not be detrimental only when tackling really advanced problems. Ergo, do not use macros (at least until you already know from personal experience how to answer your own question). -A.
I think the distinction should be in on-chip vs off-chip. Microcontrollers tend to be fairly good on their own, without any off-chip memory (and no chip that I know of has 256MB on-chip). If something is designed with using a lot of off-chip memory in mind, then I think it should probably just be called a microprocessor instead.
Op clearly states he understands all this but happens to have to deal with an already existing codebase that uses it...
I have made a variant of the format-library which in many ways are slower, generates more code, is less flexible and not as elegant as {fmt}. It has one advantage, however: support for tuples and arrays. I can write format("{E&lt;fmt&gt;}",t); If t is a tuple, this will apply the format &lt;fmt&gt; for the elements in the tuple. If I write format("{A&lt;fmt&gt;|&lt;sep&gt;}",a); and a is an array, it will write each element of A out using &lt;fmt&gt; and write &lt;sep&gt; between the elements. I have not studied {fmt} in details, but perhaps this idea could be applied?
It might be worth poking around in your IDE to see if it has more targeted tools. I'm unfamiliar with visual studio, but in Netbeans at least you can expand a single macro usage if you right click and open up the correct contextual menus. 
Thanks but what I was really looking for was more of an API specification, if that's the right word for it. I was worried that it might be a case where "the code is the documentation", and unfortunately, I think that's the case.
Definition, property. Doesn't matter. My point is the same. Whatever you called that sentence, it's never been right.
Sometimes it's appropriate. In this case, when talking about mapping to hardware, it is definitely appropriate. It was, and still is, a conscious design decision for C++ to adopt and stick with C's machine model (which is a different goal to adopting and building on the syntax).
designated initializers don't make it easy to modify several bitfields at once though: flag |= WEARS_HAT | WEARS_SUIT | WEARS_GLASSES.
Funny you post this here. I ran into the same problem with qtcreator earlier today... I could have sworn I saw an ‚Äòexpand macro‚Äô earlier in the week, but now I can‚Äôt find it.... I even loaded up vs2017 to see if it could expand it for me, couldn‚Äôt find it there either... I‚Äôm fairly certain I‚Äôve used it in eclipse based ide‚Äôs for various mcu‚Äôs and qnx‚Äôs variant as well.
Lower cloud costs, for one. Turns out that stuff can get expensive.
How does dev time compare to rolling web stacks in other languages though? I‚Äôve taken a look at the examples, they look like there is a bit involve for simple examples. The code looks great - this is not a criticism by any stretch. Just trying grasp where this has a place?
Well you know it depends on what it is. If it's something that gets hit a lot but is relatively simple so say it's a couple of weeks of work in C++ it could very well be worth the effort. For a general CRUD app, probably not worth the effort.
She is an interestings speaker, and I bet she makes some good points that I've love to _read_ about, but after the first few minutes of listening to music and other people talking about other stuff, I gave up. Given the number of comments under this article, apparently I'm not the only one. Let's face it: podcasts are just an incredibly inconvenient format for the web. 
Excellent guide! One of the weakest areas in many UE4 devs.
Some people actually use libraries written in C, and we'd like to keep using them. So, no, let's _not_ break C-compatibility. Why not special-case void just to allow it as a temporary storage of nothing used solely for the purpose of returning nothing in generic code, and leave everything else as it is? 
Shame about void_t. What's in the article is what I would have thought void_t is (like nullptr_t). Maybe it should just be nullptr_t. What really is the difference between foo(nullptr_t x) and foo(void) anyways...
The low up front cost of using other languages often translates into high long term maintenance costs. C++ is typically easier to refactor and has strong types to prevent silly mistakes.
Have you considered making string have quotes in the output? Looking at the examples, I first thought that the `span` was a `gsl::span&lt;int&gt;` instead of `gsl::span&lt;std::string&gt;`.
&gt; ... It guarantees ... The compiler (or C11) guarantees absolutely nothing, the programmer does (and takes responsibility)...
It's a high-level assembler :-P
or........ you could just keep using the compiler version that you're using today which won't magically stop working when a new standard is released
First I made two implementations of the http server for boost.asio and libevent. After the comparison, I saw that the libevent implementation is faster than 2.5 times. Boost.asio is a library with a good interface for me, and I like libevent for speed.
Clickbait++?
That was an awesome read. I always love about stuff like that - and it could help me with one of my projects
&gt; It might have one or two pathological mistakes if it's performing that poorly IMO, and would be interesting to review While the code is not available for review, in the future I will try to show these two test implementations on Boost.asio (boost.beast) and libevent.
&gt; Nothing requires you to upgrade and use a newer standard. What's the point of a standard, if people don't follow it?
The problem with that named booleans is that it is non-zero cost abstraction, because they must be somewhere allocated as variables. I know it's cheap but still :P
Full path for easy understanding without deep learning of the framework code :)
&gt; Today I discovered a neat little trick to create something resembling PDBs on Linux, by making use of objcopy(1). In our example, I already have compiled an executable a.out, which I want to distribute to my users: Or... you can just use gcc or clang's -gsplit-dwarf which will put the debug info in a separate place just like in windows
What you are doing seems to be a nice project for easier GUI-creation, though I don't know how it could be incorporated into the C++ standard library. Granted, I don't know anything about building GUIs(the closest thing I did to a GUI was creating some window 5 years ago, and a ultra-basic javascript site that has one button and prompt), so it might be the case that GTK+/QT already have what you did. &gt; I called it HMI because that's the name of SG13 even if it could have been called "windowing", "graphics", "rich IO" Or better yet: Windowed Graphical User Interface. Human-Machine Interface is waaaaaay too broad of a term, and C++ already has a form of human-machine interface, in the form of &lt;iostream&gt;, doesn't it? Or to be a tad more precise: on it's own, C++ doesn't concern itself with human-machine-interface at all, it's primarily about mangling bytes, with only basic I/O in the standard library. On top of that C++ I/O, the Operating System itself makes sure the user can have a form of communicating with the program.
&gt; C++ local static construction is not guaranteed to be thread-safe on all systems. Some compilers, like Visual Studio implement it in a way that make it useless for use in multi-thread environment. It actually is guaranteed to be thread-safe and visual studio correctly implements that starting with VS2015.
I just added globally configurable formatting, this way user can specify preferred formatting. New step would be to parse formatting `{:(,)}` .
And number of architectural registers is not the same as the number of physical registers... yawn... There is no low level language based on this "expert's" criteria. 
This can globally disabled now by setting `add_spaces=false` in formatting_range&lt;&gt; template in user code.
&gt; What you are doing seems to be a nice project for easier GUI-creation Not exactly. Again, the purpose is to create a window and get events for that window, that's it. Then you should be able to do whatever you want to do with the window, be it GUI, games, data visualization, or anything else. &gt; it might be the case that GTK+/QT already have what you did SDL has what I did: it creates a window. The drawback is that SDL is not C++ and not standard (even has other things that are not necessary for this proposal). &gt; Human-Machine Interface is waaaaaay too broad of a term, and C++ already has a form of human-machine interface, in the form of &lt;iostream&gt;, doesn't it? Well, iostream is quite limited if you want something richer than questions/answers. I chose HMI because that's the name of SG13, but I agree the term is so vague that you can understand what you want. &gt; C++ doesn't concern itself with human-machine-interface at all It could concern itself with machine events like keyboard and mouse, couldn't it? I know there is a strong debate to know if this kind of library belongs in the standard. But it's not me who decided to write N3791, it's some smart people of the C++ committee. There is a Study Group around this topic. So if all this has been done, it's for a reason: there is a need that is not fulfilled. My proposal is just a try to meet the need. From what I can see, it's still very controversial. That's OK for me, I will continue to use SDL, and let many people struggle with such simple thing as window creation. 
Is the struct ‚Äûserialization‚Äú similar to magic_get?
Currently no. User will need to create tuple interface for structs and classes. But I hope to add full structured binding support in the future.
True, but who would know with a title like this? If someone puts nonsense in a title, then it serves no purpose.
I am open to renaming suggestions, 4 letters max :-)
char[128]‚Äã name; ? 
I know... these evil twins!
&gt; What are the typical use cases for these types of frameworks? A framework for creating small services with a REST-like api, for example, as a backend for sites. The most realistic example with a description is in Chapter 5. All the examples considered in wiki can be easily builded from the code from the repository. More complex examples can be found in the mif/examples section. Please, don't forget that these are just examples that show the features of the framework. Everyone can choose how to use it in reality your own projects
Emi compliance is generally simpler with a 4 layer PCB though due to the continuous ground plane. Eh it all depends on how many things you sell, if you sell a thousand of something then spending a couple of bucks on an extra flash chips doesn't matter if it makes your development easier. You probably can't avoid fast buses anymore to be honest. 
&gt;some compilers, like GCC, have the option to disable thread-safe local static initialization code, which makes your code more *cross-platform*. wat
So you mean boost.beast was slower than your libevent based test code ? Yes please share the code if possible. Would be interesting to find where the performance is getting lost.
Seems like you're shit out of luck if it's a private method though for the symbol cracking approach. If you have to redefine another public method you lose that method as I understood it. Technically that is breaking it? 
To evolve the language? Just because not every person in existence is able to use the latest and greatest standard doesn't make it pointless? Theres always legacy code, and legacy hardware with legacy compilers. And they shouldn't hold back the rest of us.
Would you accept videos? * "Simplicity: not just for beginners" (ACCU18) https://www.youtube.com/watch?v=O50qTuM5OT0 * "It's Complicated" (MeetingC++17) https://www.youtube.com/watch?v=tTexD26jIN4 * "Stop Teaching C" (CppCon15) https://www.youtube.com/watch?v=YnWhqhNdYyk
https://sourceware.org/gdb/download/onlinedocs/gdb/Separate-Debug-Files.html
I fail to see how making void a real type could possibly break anything. Since it isnt already a real type, nothing depends on it. All you have to do is not call C code with void? When you call C code from from C++, you get C++ types and calling stuff, so it should be perfectly fine to prototype and use it as `foo()` Maybe i'm missing something. Can you give any examples of real C++ code that would break if void became a real type?(Needing to change `foo(void)` into `foo()` does not count here) Or how calling C code from C++ would break, if you were calling it correctly? Now that i've read the proposal, it even explicitly accounts for this, with `foo(void)` being the same as `foo()` in non-template code, specifically to prevent breakage. So your only real concern so far isn't even broken. Note that `foo(void param)` does get new behavior, but since that's currently invalid code, nothing can depend on it. And from the proposals FAQ &gt; In Practice, Would This Break ABI Compatibility? &gt; No. Because we are changing the void type, it might initially seem as though we'd be breaking compatibility with existing, prebuilt libraries, including C libraries. This is untrue. Our alterations do not change the meaning of existing, valid function declarations, nor do they add any state to the void type that needs to be communicated. The fact that functions with the return type void now return objects from the point of view of those who use C++ does not affect this. Maybe you mean linking C and C++ code together, in which case thats always a bad idea full of hazards and you're on your own.
I think he means that using that option makes your code equally broken on all platforms :o
&gt;Maybe you mean linking C and C++ code together, in which case thats always a bad idea full of hazards and you're on your own. Are you for real? That's the entire POSIX API, all of WIN32, and 99% of the C++ library ecosystem you're casually dismissing there. Without C interfaces you can't even open a window or draw a pixel. Maybe you live in some glorious academic world where nothing threatens the purity of your libraries, but some of us use C++ to do real work in the real world. 
This is fantastic. I did part of Tom Looman's Udemy class and while it's really well done (I highly recommend it) i was really missing a high level overview of the framework - so this really complements his other material. Thank you /u/-Tom-L
I feel bad for commenting this(since I don't have the code as well) but in past, I've also seen boost asio lag behind another http framework based on libuv. Its possible I wrote something that was not the ideal usage of asio but I went through the docs and made it similar to those examples. This was on a linux machine with whatever kernel arch linux had about an year(+half year?) back...
&gt;Again, the purpose is to create a window and get events for that window, that's it. Though when you are asking for creating a window, you have to use the X-windowsystem/some other system-specific API, or is it possible to make it completely non-reliant on any OS-specific windowing system? &gt;The drawback is that SDL is not C++ and not standard I don't understand how it is any more of a drawback, than the fact that C++ standard library doesn't have specialised functions for producing sound or using Ethernet. &gt;Well, iostream is quite limited if you want something richer than questions/answers That depends on what you mean as "richer" and in what environment. For example one indeed can't use the mouse in strictly standard c++ without some form of Operating System's library. If you only mean "graphics", then I hope you aren't stuck on the idea of "GUI = good, CLI = medieval". In particular vast majority of things that a computer programmer needs can be done in a text-only interface, thus there doesn't seem to be as much push for GUI. But someone else might say: it's still very limited, because there isn't any sound. &gt; It could concern itself with machine events like keyboard and mouse, couldn't it? It could, or it could not. As it stands now, C++ doesn't seem to concern itself whether the input is from a keyboard, piano, shell script, or butterflies, and it doesn't seem like it is going to change(whether that's good or bad is a different topic. If I were somehow asked to vote on the topic - I'd vote to make some form of "extended C++ library", where all the different input/video/audio things could be put) &gt;I will continue to use SDL, and let many people struggle with such simple thing as window creation. (Autustic pseudo-coldreading incoming) Mate, you sound like someone who is really frustrated by the GUIs(either because of too much or too little time spent on them). If someone only cares about making a graphical interface - there is already JavaScript+HTML that allows the user to quickly whip out some form of GUI. Creating a window is a fundamentally complicated job, I'd even risk saying that the difference of complexity between anything from C++ standard library vs a movable window is comparable to the difference between assembly-code and C++. &gt;I will continue to use SDL It's good, because that's what SDL(along with GTK, QT, and numerous others) was designed for - to let the programmer build graphical interfaces by solving the issue of communicating with X-server. &gt;and let many people struggle with such simple thing as window creation If they aren't using GTK/QT/SDL/Java-Swing/other-libraries, then they most likely will.
Actors don't own any of that information, it will be routed to the ActorComponents. You can perform call for collision on the actor, it's still the components that form the actual collision information. You could see it as a wrapper for that component collection.
Not helpful. Evolution of the language, and code bases, is important for progress, and security. Telling someone "Well, you don't have to upgrade to a new compiler" is about the same as telling someone "Well, you don't have to upgrade to a car that was designed with seatbelts, an airbag, 50mpg fuel economy, a rear-view camera, power steering, anti-lock breaks, etc". In some situations, there's no choice in the matter. Regulatory compliance, compliance with customer contracts, security concerns, and so on, eventually make upgrading to a new compiler less expensive than alternatives, or sometimes mandatory (Specter? Meltdown? Compiler mitigations are some of the most effective "solution" to that clusterfuck). The question is where that break even point really is. An organization that I work with, for example, can't upgrade to a compiler that supports the mitigation features until they've revisited their entire codebase and verified that it's working with the new compiler. It'll be another year solid before that vetting work is completed, and it'll involve dozens of people. A compiler that causes a huge amount of breaking code, where several million lines of code would need to be changed before the compiler upgrade could take place, is a compiler that makes adoption extremely expensive. Now instead of being able to take advantage of new features nearly seamlessly, an organization might need to invest dozens of man-years worth of work before upgrading is even possible, much less practical. It's not impractical to be cautious about a change to the language syntax and grammar that would break thousands upon thousands of lines of code that I've written. It's also not impractical to point out that C language compatibility (such as it is) is something that a huge percentage of the c++ community take for granted with their c++ compiler. Breaking it is gonna piss a lot of people off. So really, don't tell people "Well you don't have to upgrade to a new compiler". It's a load of crap to say that to someone, and I suspect you can see why.
&gt; using namespace std; *walks away slowly*
Just to be clear, I'm actually quite excited about the proposal that we're discussing. My concern was their forward-looking statement &gt; Ultimately, in a future standard it would be a simplification to the langauge to make a parameter-list consisting of a single, unnamed, cv-unqualified void parameter behave no different from most other object types. That's what I think is dangerous. Maybe you took that statement to mean something different than I did. Perhaps saying "they'd like to see" was a mistake on my part. But what I took from their statement was that the paper's authors think that a change like that would be a good thing. &gt; &gt; The fact that functions with the return type void now return objects from the point of view of those who use C++ does not affect this. This is an ABI break. Functions returning void currently have no space allocated for them on the stack inside of which to do so, to the best of my knowledge. (Maybe I'm wrong here? Don't think I am, but who knows). If functions returning void suddenly start returning an object that have an address, space now needs to be reserved for that returned object. So functions that return void will still need to have a special rule, or it'll be a break to the ABI, and old code can't link any more. As far as I know, there's no existing "empty object return optimization". E.g. returning std::tuple&lt;&gt; still involves allocating space on the stack for that empty tuple. This is distinctly different than returning void, as we do it today. I know that you've struck out your old post, but I wanted to rebuttal one point. &gt; Nothing requires you to upgrade and use a newer standard. Nothing at all. In fact, in legacy code like this, upgrading your compiler, let alone standard, would be unusual, as I understand it. See my reply here https://www.reddit.com/r/cpp/comments/8gypp4/without_form_and_void/dyhz9fy/ 
A big thing to understand is that even if the change to the language is well intentioned, if it breaks basically EVERY PROGRAM that was written with previous versions of the C++ standard in mind, it's not so much a matter of legacy code, as "Well, that's a different language". Changing the semantics of void in the way this specific paper talks about, if done CARELESSLY, could do that change. So while it's true no one needs to upgrade, and thus the language standard can evolve on it's merry way, if a standard gets released that requires significant rework by nearly ever organization on nearly every codebase.... Well, that'll be a Python 2 vs 3 issue, won't it? How's that going for Python? On my linux box, over half of the python packages are python 2. 
It prevents pretty much any optimization that involves the function. 1. It can't be inlined. 2. No static analysis of the function's behavior can be performed. 3. It can't be proven that the function has no side effects. \#2 prevents optimizations where (for instance) there's a parameter validity check but the compiler can determine that the parameter is always valid (or invalid) and so that check can be skipped. \#3 prevents optimizations where data is written to memory, then the function is run, then the memory is read again. If the function can be proven to have no side effects on that memory then the data written can be just kept in a register and the (potentially slow) read from memory can be skipped.
Sorry for the late reply. As dodheim says, it's so that you can add more members and/or member functions to your type. You can also decide that not all members of your type will participate to Hana's view of the struct, etc.
Interestingly, starting from MSVC 2015 the pdb files can be mostly empty, and just serve to index the symbols that are actually kept in object files. This is even the default behavior in MSVC 2017, as it significantly speeds up link operations. It's still possible to create full pdb files, if they need to be distributed. This is the option /Debug:fastlink.
Thank you! I hate it when example code uses namespaces but doesn't specify what they are. Or uses multiple. Just write it out or use namespace aliases!
&gt; Though when you are asking for creating a window, you have to use the X-windowsystem/some other system-specific API, or is it possible to make it completely non-reliant on any OS-specific windowing system? You have to use OS-specific things, like for `std::thread`, `std::*_clock`, `std::filesystem` and maybe others. What's the difference? The standard is here to provide a common interface to many things that are specific to system and architectures, that's the whole point! &gt; I don't understand how it is any more of a drawback, than the fact that C++ standard library doesn't have specialised functions for producing sound or using Ethernet. Luckily we will soon have a networking library for using Ethernet with a nice abstraction for many other network protocols. &gt; If you only mean "graphics", then I hope you aren't stuck on the idea of "GUI = good, CLI = medieval". In particular vast majority of things that a computer programmer needs can be done in a text-only interface, thus there doesn't seem to be as much push for GUI. Why oppose CLI and GUI? GUI = good sometimes, CLI = good sometimes. I can't make a grep with a GUI (easily), I can't draw a picture with a CLI (easily). Both are complementary and have their own strengths. &gt; I'd vote to make some form of "extended C++ library", where all the different input/video/audio things could be put So let's do it. My proposal still stands. But now, this extended C++ library does not exist. Boost is the closest thing we have. And as it is, my proposal could not enter Boost (because I use SDL). &gt; there is already JavaScript+HTML that allows the user to quickly whip out some form of GUI Personnaly, I want to use C++, and make games for fun. I need a window and events from that window. Why would I use another language? C++ is not just for CLI and servers, it's a universal language that can be a solution for many people. And enlarging the audience won't do any harm to those already using it for something else. &gt; Creating a window is a fundamentally complicated job Like creating a thread. And the purpose of the standard library is to handle complexity and present a simple abstraction. 
My preference when the example is very close to the real use case. I think that in the big project the names of entities are the main thing, and sometimes the alias can make it difficult to search for bugs. But these are only my thoughts, not more than
Thanks.
They are an incredibly inconvenient format for the web. But, they are an incredibly convenient format for a walk/drive/bus ride. I love podcasts because they allow me to fill otherwise dead, boring time learning lots of stuff I otherwise wouldn‚Äôt. 
&gt; I'm also really worried because the code generator assumes that using namespace std; is present in the current file. For example, the multiple return simply inserts "make_tuple(" + &lt;your stuff&gt; + ")", which is just... wrong. And I can bet on my head it chokes on the first template I feed it. At the very least, it should be doing make_tuple(" + move(&lt;your stuff&gt;) + ") But it doesn't sound like that's the case.
You know, while I think this project is going in the absolute wrong direction, I could see the benefit of doing something like &gt; Makes all variables that are not prefixed with the "mut" or "mutable" keyword "const" Keeps noobs from screwing themselves.
¬µFW - would be a cool name but unicode character is not supported on GitHub in the repo name. Besides the name what about this code ? I am planning to utilize this tiny framework for my C++17 project on GitHub, I need to bootstrap my app quickly, have easy to use configuration and ability to load/unload plugins as connectors to our partners.
On the other end of things, at my work we have a particular library whose has a windows "release" dll with a PDB file that's strictly larger than 10x the entire linux .so file in "debug" mode (no optimizations, no stripped symbols, extra debug information added). PDB files aren't compressed internally (as evidenced by being able to compress them to about 1/10 the size most of the time), but even compared against non-compressed linux results, the PDB files are still huge freaking massive.
did you repeat your compile tests? gcc benefits from the fact that the files from loaded in memory thanks to clang as 1st test..
change order (1. gcc, 2. clang) and post results here please..
Most distros already handle this for you with debuginfo packages... [https://access.redhat.com/documentation/en\-us/red\_hat\_enterprise\_linux/6/html/developer\_guide/intro.debuginfo](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/developer_guide/intro.debuginfo)
Upboat for brevity and high signal. Thats a skill
Your suggestion is very reasonable in my opinion. I think that bool is a special case because it is possible, and very easy, to list all the possible values of the type, which is why I see value in showing the option of the article. And you don't have to depend on a strong type library (although in the second article you're referring, it's true that you can do strong typing with a struct). Parenthetically, it also leads to a slightly shorter syntax because you don't have to write "true" or "false" (but that's really parenthetical!) But as you're pointing out, it lacks the safety of strong types. I would certainly go for strong types if there is more than one bool in the function interface, for instance.
Haskell does semicolon and brace inference pretty well, so I suppose it could be done for C++. I don't know if CPY is that good though.
Not that far, I wish there was a way to add regular pre-processor macros that use template parameters &lt;&gt; brackets. #define SomeThing&lt;x,y&gt;(a, b) Wrapped&lt;x,y,mixin&gt;(a, b) 
Yes. And I build on tmpfs (in-RAM file system, aka "RAM disk", so there's no storage access.)
How could the compiler do all this optimizations on a function out of a dynamic library? By definition that should be an unknown until runtime.
Precisely. Super vague title with a blog link... Lol, I love how you agreed with me but I get downvotes for calling it out while you get upvotes for explaining why I called it out. 
&gt; PYTHON That's pretty much what the author was aiming for: https://www.reddit.com/r/programming/comments/8h3wht/cpy_code_cc_with_no_redundancy/dyhv9ab
This prevents optimizations of the dynamic library itself.
I see!
I've successfully used this method for unit testing. I needed to test error checking code calling libc functions. Rather than trying to manufacture situations to trigger the libc functions to fail, I intercepted the calls and returned failures directly. The method was basically the same as this article, having my functions listed first in the symbol lookup.
I'm not particularly attached to the name slot map, and the proposal even discusses potential name changes. Independent of that, there's already enough content using the terminology "slot map" that a similar but different container with different use cases could be very confusing for users. Dense map is commonly used to refer to google's [dense hash map](https://github.com/sparsehash/sparsehash), which is one of the faster open source hash map implementations. In both cases it's not that anyone is worried about a name being taken, but rather that using the same terms to represent different concepts creates an unnecessary barrier to entry for someone looking to learn about the subject. If the name slot map gets evolves to mean something else or becomes deprecated but the container it describes currently (and others like it) receive widespread understanding and adoption, I would be ecstatic. I have found the container to be fantastic and it solves very real problems in many domains.
I'd prefer a non-preprocessor feature that solves the problem this is solving.
Why can't you use template aliases? template\&lt;class X, class Y\&gt; using SomeThing = Wrapped\&lt;X, Y, mixin\&gt;;
In this case it would work, I just wanted to make it trivial. What if I wanted to swap template to function params? Also, I'd like to do usual "magic" in the pre-processor as of regular function parameters, like concats and "stringify".
Totally agree. It just to me the pre-processor feels limited when mixing templates.
&gt; Maybe you took that statement to mean something different than I did. Perhaps saying "they'd like to see" was a mistake on my part. But what I took from their statement was that the paper's authors think that a change like that would be a good thing. Thats making a lot of stupid assumptions based on a passing comment in the paper rather than what the paper actually says to do. &gt; This is an ABI break. Funny you should say that, taken directly from the proposal FAQ on how it isnt an ABI break. Now, i don't claim to be an expert on this, but i'm *pretty* sure the proposal is far more accurate on the subject than you, random redditor, so forgive me if i believe it when it says it isnt an ABI break.
Can you explain a bit for who this framework could be useful? In other words, how large of a company or budget do I need to participate in such bidding? Asking because I understand electronic trading reasonably well and now I'm wondering if it's any similar. Where should I look for an introduction?
In all the situations you describe, theres already a large amount of work involved in upgrading, so your perfect never break anything no matter how ugly it is backwards compatibility ideal falls apart. You even give an example &gt; An organization that I work with, for example, can't upgrade to a compiler that supports the mitigation features until they've revisited their entire codebase and verified that it's working with the new compiler. It'll be another year solid before that vetting work is completed, and it'll involve dozens of people. If your perfect never break anything no matter how ugly it is backwards compatibility actually worked, why do they need to revisit their entire codebase and verify it works? And why should the rest of us have to suffer for that? &gt; Prior to me working with them, they were using a 7 year old compiler tool chain. It took 3 years of work to upgrade to something a bit newer. Companies regularly live in "the past" with their tooling, and they eventually get stuck there forever. Careful language design can make upgrading LESS painful than not. Keeping the overall community on the same set of technology. . &gt; Careful language design can make upgrading LESS painful than not. Keeping the overall community on the same set of technology. ..based on every single example you've given, that doesn't seem to be working out so well does it? &gt; A compiler that causes a huge amount of breaking code, where several million lines of code would need to be changed before the compiler upgrade could take place, is a compiler that makes adoption extremely expensive. From what you've said, it's already extremely expensive. They'll still have their developers checking and testing the code unchanged, they can do the programming part of the job and update some of it *if* it needs to be. And it doesn't always need to be. Theres nothing that says they have to break everything all in one go. Breaking compatibility shouldn't be taken lightly, ***but*** it should not be entirely off the table. Breaking compatibility is sometimes `less expensive than alternatives, or sometimes mandatory` &gt; Now instead of being able to take advantage of new features nearly seamlessly, an organization might need to invest dozens of man-years worth of work before upgrading is even possible, much less practical. In literally all of your examples so far, they havnt been able to do that "nearly seamlessly" thing. So from your examples, i gather that breaking or not literally nothing changes. If what you're saying *was* true, that would mean your company, and all your other examples, are choosing deliberately to ***not*** use a car `that was designed with seatbelts, an airbag, 50mpg fuel economy, a rear-view camera, power steering, anti-lock breaks, etc` despite a "nearly seamless" upgrade being possible because of the languages history of non-breaking changes, to which i say thats their own fault and the rest of us shouldn't have to suffer for their/your poor choices in not "seamlessly" upgrading. &gt; It's not impractical to be cautious about a change to the language syntax and grammar that would break thousands upon thousands of lines of code that I've written. It's also not impractical to point out that C language compatibility (such as it is) is something that a huge percentage of the c++ community take for granted with their c++ compiler. Breaking it is gonna piss a lot of people off. it is when the paper you think breaks it explicitly doesn't break it for explicitly that case. Explicitly.
&gt; But is the C code of the form "foo(void)" a function accepting zero parameters, or a function accepting a single parameter of type void? if you had read the proposal you would know the answer to that. Since you clearly havnt, i don't need to bother reading or replying to the rest of your uninformed comment.
I'll use whatever style people pay me to use.
&gt; This proposal would, by necessity, require allocation of space for the returned "void" object. I think this is the key misunderstanding here: If the proposal were accepted, even though `void` would be an object type, its "instances" have size 0. Thus the compile doesn't need to allocate stack space - it is aware of the special case of `void` not requiring any.
That's great information. Thanks for getting back to me. I understand that this is a different space and not related to finance. I guess I'm wondering how an individual can make an impact there. Would I need my own product so I have something to advertise for? Or can I become something like a bidding service provider or consultant? How are you involved with this industry? Are you at one of those major sellers you listed?
Accusing someone who's made numerous quotes from the paper in question of not having read the paper makes you seem like a real winner. Good job. Sometimes people can read something, and come away from reading it with a different understanding than yourself.
&gt; On (certain distros of) linux over half the packages are decades old, so i'm not sure your point. Even if python 3 hadn't broken anything they wouldn't have upgraded. Big surprise, linux distros that favor long term support stability don't upgrade to new versions of things! *gasp. i am *shocked. shocked i say. Every single C++ package on my linux machines are compiled with -std=gnu++14 using the latest available gcc at the time of installation. So, from the looks of things, hard breaks in compatibility result in packages that never switch over, but gradual language changes are more likely to see widespread compatibility with existing code. Honestly, don't really see what point you were trying to make here. Packages that have never been upgraded from a language that is EOL as of Jan 1st 2020 (Python 2.7's EOL date), don't seem like a desirable thing to me. &gt; Now, as a python programmer myself, the python 2 vs 3 issue isnt an issue. It broke some things, but it solved a pretty serious wart in the language, for the better. It took some time for things to switch over, but guess what? Almost everything worth using has already switched over, or even supports both. Except... half the python packages on my system? I didn't install them directly, they're just dependencies of various programs that I do want to use. Clearly someone think's they are worth using? That doesn't seem like a solved problem to me. &gt; New code shouldn't be burdened by legacy code that won't update anyway. If the backwards compatibility ideal worked so well, why havnt they upgraded already, if it doesn't break anything? Because it does, in practice. No matter what the standard says, all the compilers have their quirks, and upgrading those is a lot of work. If they don't want to invest the time to upgrade, then they can keep using legacy versions like they already do. Future standard versions don't affect this group, because they don't use them. Who is "they" in this context? Open source libraries? Closed source projects at a company? It's not a matter of "doesn't break anything", it's a matter of not making huge compatibility breaks between versions, to make sure the ramp between one version and the next is relatively smooth. That could be the difference between walking down the sidewalk and jumping off a cliff, depending on what changes are involved in a particular new release of a standard or a compiler. Some breakages are expected, but not total-rewrite levels of breakages. But new code is constantly beholden to the compatibility needs of old code. "New code" is code that's added to an existing code base, to grow a new feature, or transform a library so that it serves two related purposes so two applications (or more) can consume it. Some of the code I work with has existed in some form or another since before I was born. Things don't get thrown away, and new "pie in the sky" projects are few and far between. It's much more common to evolve existing codebases than it is to create a brand new codebase from scratch. As for companies not wanting to take the time to invest not needing to upgrade... come on, you know it's not that simple. Easy example, company A buys company B. Company B's code is all C++17, company A's code is all C++98. Already you've got a mismatch in standard library ABI, so at the very least you're going to need to recompile one or both sets of code to account for that. And both companies are using different compilers, so that's another thing that needs to be reconciled, and so on. So now, if integration of the codebases is going to happen, an upgrade needs to happen. Or alternatively, company A has a contract with company B to support a given application for X number of years. The contract has a clause requiring company A upgrade tools to the latest version on a regular basis. Now company A is required to upgrade whether they like it or not, even if it requires major overhauls to their codebase to do so. &gt; And there is something important to be said about the Python 2 to 3 issue. It was initially done poorly, breaking more than it had to. around 3.3 is when it unbroke some important backwards compatibility things and made it much easier to support both 2 and 3. Ok, so lets avoid doing the same with C++? &gt; Theres no reason C++ has to make the same mistake when they do break compatibility. They don't have to break everything, and they don't have to do it all at once, and it doesn't have to be done needlessly. it isnt something to be done lightly, but it shouldn't be off the table entirely like it currently is. Great, we're in agreement. Breaking things is generally undesirable unless it's the least-worst thing to do. Why are we arguing? &gt; ...the way this specific paper talks about specifically avoids that level of damage, does it not? So either you aren't really talking about this specific paper, or you're trying to deceitfully frame it as bad and breaking everything and big bad scary changes. I was talking about the forward-looking statement regarding changing the meaning of "foo(void)" to always mean "one argument of type void, not zero arguments", which the authors said they thought would be a good idea, but wasn't included in the paper for sake of compatibility. So no, it doesn't avoid that level of damage. That would instantly cause compiler errors in nearly every code base on the planet. Which is why introducing that language level change carelessly would be a bad idea, and which is why the papers authors explicitly say that they are punting that change to some time in the future, by some other group, writing some other paper. My entire concern is about that specific forward-looking statement, nothing else. 
I am wondering how many discord C++ communities there are now.
I really don't think that that's the case? Reading the specific changes towards the bottom of the paper, where they show the diff between the current standard, and the proposed changes, doesn't say anything about allowing special cases for functions returning void with regard to the size of the returned value. They do explicitly say &gt; Note: in particular, sizeof(void), sizeof(bool), sizeof(char16_t), sizeof(char32_t), and sizeof(wchar_t) are implementation-defined.75 ‚Äî end note ] They also have a section in the FAQ &gt; Why Isn't sizeof(void) Equal to 0? If void is to be treated as just a regular old object, then it *must* have a size greater than 0 (Until that problem has been fixed somehow in future versions of the standard), and it must be possible to take the address of the object (except in the various situations where that's disallowed). So if it has a size greater than zero, and must be addressable, then there must be space reserved for it on the stack. Maybe I missed some specific wording? Could you help me find it?
You know, I just re-read the damn thing, and there's no mention of "extern" "legacy" "c code", or anything else like it aside from the "Existing Practice in Other Languages" section, where they say that C treats void special like C++ does. The only section that I think touches on this at all is provided here, verbatim. &gt; In Practice, Would This Break ABI Compatibility? &gt; No. Because we are changing the void type, it might initially seem as though we'd be breaking compatibility with existing, prebuilt libraries, including C libraries. This is untrue. Our alterations do not change the meaning of existing, valid function declarations, nor do they add any state to the void type that needs to be communicated. The fact that functions with the return type void now return objects from the point of view of those who use C++ does not affect this. So they simply assert that their changes have no ABI ramifications, without providing justification for that assertion. And that paragraph doesn't, at all, touch on C language compatibility. Are we actually talking about the same paper? This is the one I'm reading: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0146r1.html
Eric Niebler's Range v3: https://github.com/ericniebler/range-v3
&gt; Thats making a lot of stupid assumptions based on a passing comment in the paper rather than what the paper actually says to do. Except they bring it up at least 3 different times, though it's rather past my bedtime, so I could have missed one. &gt; The suggested solution to this problem is to not reclaim this syntax, at least not at this time, though only when the void type is not a dependent type. Importantly, we can and should use this syntax when void is dependent, as is explicitly suggested in this proposal, and is thankfully not allowed as a means to specify a nullary function in the present state of the language. &gt; Ultimately, in a future standard it would be a simplification to the langauge to make a parameter-list consisting of a single, unnamed, cv-unqualified void parameter behave no different from most other object types. &gt; It also no longer suggests deprecating the existing usage of T(void) as a means to specify a nullary function, due to concerns that we'd never actually be able to remove that meaning in a future standard, Note that that last one makes it clear that they explicitly wanted to deprecate T(void), and decided not to at this time because of the breakage. So, no. That's not a lot of stupid assumptions. That's a well founded understanding of the direction the authors of the paper wanted to take the language in. &gt; Funny you should say that, taken directly from the proposal FAQ on how it isnt an ABI break. They claim it's not an ABI break, and provide no justification for their assertion. I claim it is an ABI break, and provide justification. It's a rather simple logical conclusion. I'll reiterate for you. The paper explicitly says that sizeof(void) != 0. They also explicitly say &gt; As well, any code that relies on an object's type and address as unique would fail for void types, even though it is otherwise perfectly acceptable. Therefore, given the paper makes no mention of providing a special case for functions returning void not actually returning anything (as is currently the case), functions returning void will be returning an object with size greater than 0, and said returned object can have it's address taken. If it can have it's address taken, it *must* have a specific location in memory that represents the object for that address to point to, and certainly that location won't be pointing to some arbitrary location in memory, it'll be pointing to the returned value from the function. To the best of my understanding of C++, C, and assembler, functions returning void right not have a stack layout that provides no room for a returned value. That stack layout change is an ABI break. I simply cannot understand how the paper's authors are saying it's not. I'd love to see a revision explaining how it's not, because I'm stumped.
&gt;The papers authors clearly state that they think, eventually, "foo\(void\)" should become "this function accepts a single parameter of type void", which has ramifications for ABI, and stack usage. ABIs can and should be defined to effectively not pass anything when a unit type \(i.e. a type with only one legal value\) is passed by value \(like empty classes, nullptr\_t and void if this proposal is adopoted\). So foo\(\) and foo\(void\) can easily be ABI\-compatible. Of course void&amp; would be a different thing.
I've not heard of this before. Can you point me to where I can do further reading?
Curiosity. Is it already proposed for the c++20?
It's been discussed in standard meetings. If I'm not mistaken it needs concepts as a pre-requisite. 
Doh_!_
I actually see lot of merit in this simple library. I like it's split into two components - algebra and windowing so the concepts are clearly separated and can be evolved separately. Algebra lib looks very similar to what I am using in my projects. It advocates short familiar names vec2f instead of point_2d&lt;double&gt;. Doesn't complicate things with abstracting different types for point and vector which don't work in practise. Uses free functions dot, cross like we are used to from math instead of member functions etc. so I have lot of sympathy for that. It feels like it is designed by a person who actually uses it. As for the windowing component this is probably as simple as u can get. I have few notes here - first, std lib uses same names for getter &amp; setter so things like set_title/get_title should be named just title. Second all events are currently enumerated in a variant. All widgets libs allow to define your own events and fire them as needed and since the most important aspect of your lib is to be extensible you should allow it too and come with some different approach. Third simple renderer is way too simple it needs to add support for lines and polygon drawing. And the pain point - text rendering needs to be addressed somehow too possibly only with optional external dependency. Finally it would be nice to start a third component - widgets lib. It can offer only few basic widgets like button, editbox, label but I see it as an important proof that something like that can be built on top of what you designed. If that is demonstrated to work sufficiently well say on windows and android that would be a big plus. I am sure lot of things will be discovered here you would probably need to enhance your renderer by blending, shader support etc. to make scrolling and effects reasonably efficient. All in all I would say it's a solid start. It looks much simpler and elegant than what we got from sg13 so far. And I think it also fills the original purpose better. Most important things is to keep it simple, intuitive and extensible. Do you plan to submit a proposal to see what chances does it have? I remember I read somewhere that the sg13 work is supposed to be scrapped on next iso meeting and Herb Sutter calls for reconsideration. Maybe if there is another competing proposal like yours it would bring a fresh wind and we might finally get something useful although for sure not in c++20. 
Also, only the core part of it. No views and other stuff, if I am not mistaken. A very small (but important!) subset is proposed to date.
Ha! Accidentally stumbled on exactly what I conjectured about above! chip designers consciously chose to look at what code was already being used, rather than design chips for potential code. Lucky find! https://youtu.be/0C2_QUjtif0?t=40m35s
My usual approach when I hit something in the language that annoys me is to write little utility methods to help me out. Turns out it's super handy building your own personal toolkit. :) namespace std { template&lt; typename container_t, typename value_t &gt; void fill( container_t &amp; c, const value_t &amp; value ) { fill( begin(c), end(c), value ); }; } 
Extending namespace std is usually undefined behavior - http://en.cppreference.com/w/cpp/language/extending_std
Huh. I actually did not know that.
This is the right answer, except these belong in a detail namespace.
What is a "detail" namespace? I'm unfamiliar with the term.
Abseil has exactly this: https://github.com/abseil/abseil-cpp/blob/master/absl/algorithm/container.h
Just write the template.
&gt; the PDB files are still huge freaking massive. Probably lots of empty (pre)allocated / reusable space. PDB files consist of different streams, i.e., it's like a mini-filesystem.
It is now a TS (technical specification) http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4685.pdf It is [proposed](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0896r0.pdf) to be merged to the standard, but as others have mentioned, pending on Concepts TS to be merged first.
The base of Concepts has already been merged in. That's enough for Ranges.
http://reddit.com/r/cpp_questions
Should actually be "C++2{" because *we don't bounds check around here*
`(z +1) mod 26` is a.
It's most likely to account for the possibility of more than 3 in a decade. If C++2z comes out and there are still a few years left before 2030 comes around, we'll probably end up with more confusion than simply starting at a and making the fourth one C++2d. It's not like any one person or group is in charge of the naming, but I saw C++2a stick pretty early in the community.
If only there were some convention for versioning numbers in software.
`detail` is a conventional name for pseudo-private namespaces that hold code not meant for use outside the enclosing namespace. ``` namespace my { namespace detail { // code not called directly outside namespace my } // my public interface } ```
I can't find it in the standard right now, but I believe this is undefined behaviour. The alphabet is clearly a signed type to handle capital letters.
If you can convince the community to use semver for the standard, go for it. I don't think its benefits shine through for a C++ standard revision, but it doesn't particularly make things any harder.
(just to be clear:) ...so `detail` is probably not the right namespace for this example. As you probably want lots of other code to call the wrapper stuff. (and, back to how this started, not `std` either)
I feel a bit dirty for saying this, but if all you want is that: #define MY_RNG(container) std::begin(container), std::end(container) and you are done: std::find(MY_RNG(v), 7); 
Every release would be a breaking change, so we'd be on C++ 20 or something by now.
I almost forgot about abseil, thanks for the kind reminder!
See https://www.youtube.com/watch?v=BxwfIINGXgg
Semver doesn't standardize how prereleases and work-in-progress should be named, it only really deals with stable releases. So you could call it "C++ 20.0.0-a", but that doesn't really help anybody, it just adds minor and patch numbers that aren't really used for standards.
Was wondering the same thing. I'm sure some smart people have what they think is a good reason, but I think it's stupid because it violates the "principle of least astonishment".
&gt; Except they bring it up at least 3 different times, though it's rather past my bedtime, so I could have missed one. Even if they do, passing comments by the author don't change what the paper proposes, which is not that. It is entirely irrelevant whether the author things another *future proposal* removing special case `foo(void)` would be a good idea. Because it isnt this one, which is all that matters. The future one will be in the future with it's own discussion, if even proposed. &gt; Note that that last one makes it clear that they explicitly wanted to deprecate T(void), and decided not to at this time because of the breakage. &gt; So, no. That's not a lot of stupid assumptions. That's a well founded understanding of the direction the authors of the paper wanted to take the language in. No, it is not. Again, for the simple reason that *thats not what this paper does*. It doesn't matter what the authors might want to do in a future proposal. This is not the future proposal. This one does not deprecate `T(void)`, simple as that, nothing else matters. They don't control the language, their wanting to maybe deprecate it sometime in *the future* does mean it will happen. &gt; I did in fact graduate from second grade at some point or another. I have reading comprehension better than a 5 year old, or so I've been told. The fact you felt the need to brag about this speaks volumes. Considering your inability to separate passing comments from the author and what the proposal actually proposes to do, i believe your 5 yr reading level. &gt; They claim it's not an ABI break, and provide no justification for their assertion. Sure they do. `Our alterations do not change the meaning of existing, valid function declarations, nor do they add any state to the void type that needs to be communicated. The fact that functions with the return type void now return objects from the point of view of those who use C++ does not affect this.` &gt; The paper explicitly says that sizeof(void) != 0. Who cares? `sizeof(void)` is currently invalid code. A compile error. &gt; That stack layout change is an ABI break. I simply cannot understand how the paper's authors are saying it's not. I'd love to see a revision explaining how it's not, because I'm stumped. I don't claim to be an expert, *but* i'm much more inclined to trust the paper more than a random redditor whos reading of the proposal is questionable at best.
Why would `x` be more logical? x, y, z, x, ... is more logical than x, y, z, a, ...?
That may be true, *but* that does not apply here. This isn't something thats a difference of understanding. the paper very clearly, very explicitly, exactly says that `foo(void)` stays the same as before. You can't have a difference of understanding about that. If you have a different understanding of that, you're simply wrong and/or have not read the paper.
Nice work. One recommendation: `window` should have something like [`native_handle()`](https://en.cppreference.com/w/cpp/thread/thread/native_handle), so we can use this library with more advanced and platform-specific rendering APIs (D3D / OpenGL / Vulkan / Metal). Similar to [SDL_SysWMinfo()](https://wiki.libsdl.org/SDL_SysWMinfo), but each platform should have its own (implementation-defined) type instead of a huge union.
What's UB? Going from `z` to `{`? Wrapping around? You'd just wrap it manually of course, not actually do signed integer overflow.
&gt; Honestly, don't really see what point you were trying to make here. Packages that have never been upgraded from a language that is EOL as of Jan 1st 2020 (Python 2.7's EOL date), don't seem like a desirable thing to me. . &gt; Except... half the python packages on my system? The packages that you think are undesirable? &gt; Except... half the python packages on my system? I didn't install them directly, they're just dependencies of various programs that I do want to use. Clearly someone think's they are worth using? Or.. as i said above, `Big surprise, linux distros that favor long term support stability don't upgrade to new versions of things! *gasp. i am *shocked. shocked i say.` Why are you so stuck on the fact that your system packages haven't upgraded yet? Since you haven't specified what distro or version of it you're using, i'm assuming you're using one that prefers not to upgrade system packages in favor of long term support and stability. But you seem to think there was an active, direct choice, to develop in python 2, which is simply not true. The code likely predates Python 3. They simply haven't upgraded yet. But, as an example, Ubuntu 18.04 LTS only installs Python 3 by default, with Debian having similar goals of Python 3 by default. &gt; Some breakages are expected, but not total-rewrite levels of breakages. Good thing nobody has proposed a total rewrite level of breakage. Even the change you incorrectly think would break things wouldn't be a total rewrite. &gt; Why are we arguing? because you seem to think the void proposal breaks anything in the first place, and that all the complicated special cases for `void` and fundamental inability to make proper generic code is better than the void change? &gt; I was talking about the forward-looking statement regarding changing the meaning of "foo(void)" to always mean "one argument of type void, not zero arguments", which the authors said they thought would be a good idea, but wasn't included in the paper for sake of compatibility. . &gt; but wasn't included in the paper for sake of compatibility. That part is all that matters. Why continue from there? If it wasnt included in the paper, it doesn't matter. Simple as that. You get so hung up on something that isnt part of the paper. Who cares what the author thinks would be a good idea? It isn't in this proposal, so it doesn't matter. &gt; So no, it doesn't avoid that level of damage. That would instantly cause compiler errors in nearly every code base on the planet. *sigh*, and there you go arguing again based on something that isnt even in the paper by your own admission. You can't say it's both not in the paper for the sake of compatibility but then argue that the paper is breaking because of it. &gt; My entire concern is about that specific forward-looking statement, nothing else. And why, again, are you so concerned about something that isnt in the paper? Who cares what the authors think? why? If this scary future paper does propose that change, you can argue against it all you want, when and if it exists. Seeing as it *does not currently exist*, why make such a big deal out of it? just because the authors think it might be a good idea some time in the far future does not mean it will happen if they propose it. The mere idea of it is not some infectious disease that them expressing will force it to happen in the future. It's a passing comment that means nothing at all.
C++14/17 were C++1y/z because there were three standards that decade. If the committee continues to follow the every-three-years pattern, which they very likely will, 2020 will have four standards (20, 23, 26, 29). Thus x/y/z doesn't cut it. Personally I was hoping for x/y/z/Œ± , but a/b/c/d makes sense too.
Why the downvotes? This is clearly marked as bad by the comment. it is however a valid answer. Are we stack overflow here!?!
Remember that c++11 was originally c++0x not c++1x. It was intended to be released last decade, not 2011 but since then things are thankfully moving much quicker. I think there's more of an expectation that releases will now be much more routine, so 3 digits might well not be enough if we have c++20 and then triennial releases.
Perfectly fine! &gt; It is undefined behavior to add declarations or definitions to namespace std or to any namespace nested within `std` U have to reedit ur edit
20.0.0-SNAPSHOT
It's a joke about wrapping around the alphabet from 'z' to 'a' simular to incrementing a signed int with the value of INT_MAX. That is undefined, even if many compilers will happily give you INT_MIN.
Damn maven
'x' ended up being a variable suitable to make C++0x into C++11. So hexadecimal 'B', meaning x=11. (C++1y ended up with y=4. C++1z ended up with z=7.) Since 'x' has already been determined to be 11, C++2x would mean C++ (10*2 + 11) or C++31. 'a' was used as a distinct variable because it won't necessarily be the same as 'x'.
But: ('z' + 1) % 26 != 'a'
I think it makes some sense. Many msvc code bases are legacy so will have been written for an era of compiler that wouldn't have provided static locking. If you're compiling an old code base then it might be reasonable to be able to eliminate this extra overhead. There are far worse options in msvc that are by default non standards compliant.
Not really. If somebody joins the project he will not go through all the compiler options before he decides to use magic statics... He will just write legit C++11 code that will be racy. If you use this in your projects it is a disaster waiting to happen. :)
If you have an existing code base and update your compiler i think it's reasonable to assume that it won't exhibit new behaviour that leads to worse performance. I wouldn't advocate relying non standard behaviour but if you are maintaining legacy code then that's just an overhead of working on that codebase. 
The switch was needed to compile some large code bases with LTCG, otherwise the code would crash :( MSVC was broken for several years that way. 
Life in an ascii centric world must be boring.
Something like the following would probably work for any algorithm of the form `foo(begin, end, value)`. Note that i just wrote this, so untested. template&lt;typename Container, typename Value, typename Func&gt; void wrap(Container&amp; c, const Value&amp; v, Func f) { f(c.begin(), c.end(), v); } Usage: wrap(c, value, std::fill) Which, while a little verbose, is still nicer than std::fill(c.begin(), c.end(), value);
Usually, the "preferred" implementation would be: namespace ext { template&lt; typename container_t, typename value_t &gt; void fill( container_t &amp; c, const value_t &amp; value ) { using namespace std; std::fill( begin(c), end(c), value ); }; } So that it doesn't require to open std namespace to implement begin/end for custom containers.
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8hhr0k/c_socket_accept_list_of_connected_clients/dyjwi9a/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Support for both sqlite and postgres out of the box? argc, argv wrapper? dimsun, +1.
Do you mean `make -j $(nproc)` ? https://github.com/venediktov/vanilla-rtb#parallel-builds 
So will the next version be 2b, or not 2b? That is the question.
Breaks on my iPhone. Looks great for about 3 seconds though.
This. C++0x had originally that 'x' was just a placeholder for a standard in 200x. When it became clear it wasnt going to happen before 2010, 'x' jokingly became a hex placeholder (also maybe to save face).
I'm coming to this thread late. If anyone is still here, I would be interested in knowing more about his objections to std:: optional. I understand the specific limitation he was referring to in the case of communicating error information. But what are his more general objections? Also, why doesn't he like the * operator for optional?
The other people are correct, but let's pretend they *did* use 'x'. What happens after C++2x, C++2y, C++2z? What do they use as the next letter? C++2aa? Now it just looks dumb. It makes sense to start each decade with 'a'.
It's all arbritrary anyways. Would be awkward to go from C++2z to C++2a. The standards committee were also mistaken in their belief that they couldn't release updates quickly or something so more than 3 in a decade wasn't really possible (well, they thought it wouldn't be, but they were wrong so it is)
So what in this industry drives the latency game, and to what point is being faster than the competition worth money?
How are it's compile times?
LOL
I have done similar things, but usually try to put in a little bit of sfinae or static_assert's to give better error messages than that. For example, making sure the container type passed in can have begin and end called on it and that the results are comparable.
The rationale, as I understand it, is simply that whatever name you pick may be used by the standard or by different implementations of the standard. It's not anything "sneaky", it's just that it's not guaranteed to not cause problems.
Can't wait for C++3D
That's quite clever. Without this, you'd need at least the declaration for std::begin/end for the code to compile, but this way, you just need the one for the specific container. What do you even need the using namespace std:: bit for at all? Wouldn't it be available if the container was from std::?
The principle of least astonishment dictates that the C++ community give up and move to plain C or Rust. Continuing to push this language forward is apparently still very astonishing to most people.
/u/urist_mcprogrammer , I hope I understood your question correctly There are 2 type of latencies : 1. Internet latency 2. platform latency If we take 1st one as constant for every competitor then the 2.) is the latency each competitor has to solve ? The problem with platform latency is that if platform only sees 1/2 of traffic, then you may get traffic that is unwanted or less desirable and miss good traffic , by good I mean it is not fraud , it matches your client's criteria or a known to your platform visitor with some purchasing info from advertiser's feedback . Because bidding platform normally records every event and marks known impressions ( users ) with some history this good impression might be skipped by slow platform . Your platform is not the only one on the market there is a lot of competition between bidding platforms. The other problem with platform latencies your ad-tech company has to spend more money on powerful hardware to compete with competitors utilizing optimized software and running it on 4 core 100$ equipment instead of 32 core $25000 hardware . The more features added to the bidder the slower it will become , popular feature for fraud detection is AI , so if AI part of your platform is slow even if you detect 100% of fraud your platform can't bid on behalf of your clients ( advertising companies ) successfully. Your clients are advertisers who trust you with their advertising campaigns and your platform bidding on their behalf must spend campaign budget. I can't directly link latency to success, because success is measured by conversion of clicks to sales ( if it's a product or a service being advertised), however indirectly latency plays big role in ability to process more traffic, to look at better part of a traffic you receive, and skip unwanted traffic ... therefore I think low-latency is a part of success ?
some genius thought xyz would always work.
Because they are filtering the possible funny names. C++0x was already "sepplesox".
C++XP Service Pack 2
Personally I find it to be rather asciilarating. (Yes, I'll deserve the downvotes.)
Thanks for a detailed reply So it sounds like the model here is that: * All traffic (available spots to bid on? completed transactions?) is broadcast to all ad platforms, and keeping up with this data stream is hard * Many of these events affect model and bidding state * It's first-come first-serve when purchasing (or bidding for) an ad spit * User models can be complex (It sounds like the platform is trusted with much of the modeling, and isn't just used to route and match ad spots) This sounds at it's core extremely similar to the modern financial system where somebody using this platform is a broker, except it's an [RFQ market](https://www.investopedia.com/terms/r/request-for-quote.asp), because platforms can't 'sell' a spot before a user actually requests it (no short selling) and ad spots aren't standardized to fit in a small amount of 'securities'? I wonder if some sort of proper order-book market could come into play, where bids/asks on ad spots could always be active and 'selling' a spot to a user gives shows their ad the next time a spot comes up. This would certainly result in more transparent price discovery, but might be too hard to implement. Is there a market for platforms to take a certain amount of money in exchange for a certain amount of promised clicks, and then try to deliver those clicks while paying less than what the client did? Or are most vendors here charging a fee per click/bid/whatever?
&gt; Qt application While its good to see this application, wouldn't it be better to have something like this generate a web page then it can more easily be integrated into a CI system.
Omega.
I don't get this joke?
I think it should wrap around to C++2A
&gt;Wouldn't it be available if the container was from std::? What if you want to use it with a container that's not in std, but provides its own begin and end?
This one is written in js. http://quick-bench.com/DP877zCHW5oBO-5LNCTVxtI3_Dk
I just wanted to do some microbenchmarking, a small code snippet which can run independently. 
There is a QT WebAssembly project so you can run QT applications in browser with almost native speed.
&gt; and people who write foo(void) in C++ were told since forever not to do stupid shit like that Wait, what? Why is that "stupid shit"? I have literally never heard of, or read, anyone ever making any comment about that what-so-ever? Can you point me to something that I can read to understand this further? &gt; They don‚Äôt understand how the language works, and how C and C++ differ. How using foo(void) a misunderstanding of how the language works? In C++ foo() and foo(void) both mean a function accepting zero arguments. Where's the misunderstanding?
Could you tell me more about this, or point me to something I can read about it? I'd *loooooveee* to shrink that PDB. It's like over 1GB. It's nuts.
Breaking the comma operator is probably the most inconsequential break really. I think this language achieves its goal of writing simple code in a simple style. I don't think is aiming to be used for complex template super generic libraries kind of thing 
What, did I miss anything? Are there plans to open source msvc?
No, just wishful thinking on my part. 
Does using optional types make sense? Especially taking STL into consideration. STL is written without optional types in mind. Hence the `find()` operations return an iterator instead of an optional type. Generally you would want to follow STL practices throught your project, right?
One could view optionals as a analytic continuation of past\-the\-end iterators in the sense it return something out of the range that will throw an exception when you try to access it.
Me too. Upvoted.
I found myself doing the same, except that i also found the following macros useful: #define CONTAINER_VALUE_TYPE(TContainer)typename TContainer::value_type And then you can write smth like template&lt;class TContainer&gt; static bool contains(const TContainer&amp; vector, const CONTAINER_VALUE_TYPE(TContainer)&amp; item) { return contains(vector.begin(), vector.end(), item); }
&gt; So what do you propose we use to express something that might not have a value? What have you been doing in pre-C++17?
&gt; When to use &gt; If you want to represent a nullable type nicely. &gt; Return a result of some computation (processing) that fails to produce a value and is not an error. &gt; To perform lazy-loading of resources. You can also use it for optional parameters in a function.
Using `boost::optional` (which is at least 15 years old), or the `optional` from one of a dozen other libraries, or a home-grown one. Make no mistake, this is a basic vocabulary type; that it's new to C++'s standard library is more a reflection of C++'s standardization process than it is of the utility of the data structure.
How on earth is that an improvement over an alias template? Are we talking about only C++98 and I missed it..?
Thanks, good point. Added to the article :)
For algorithms returning iterators, you should return the end iterator instead of optional because the end iterator is special by design. This design also allows composability of algorithms, so there is no need to cram in an optional where everything already works just fine.
How about std::map::insert, where a pair of iterator and bool is returned?
 if (nick_available) return { mStrNickName }; The braces are unnecessary, though perhaps a matter of taste. std::optional oIntDeduced(10); // deduction quides Obvious typo is obvious. auto oComplex = make_optional&lt;std::complex&lt;double&gt;&gt;(3.0, 4.0); Missing `std::`. // will call vector with direct init of {1, 2, 3} std::optional&lt;std::vector&lt;int&gt;&gt; oVec(std::in_place, {1, 2, 3}); Not quite. This deduces and initializes an `initializer_list&lt;int&gt;` from `{1, 2, 3}`, and then passes that object to `vector`'s constructor. The distinction can be seen if the initializer list is something like `{1, 2L, 3}`, which can be used to directly initialize a `vector&lt;int&gt;` but not here. // copy/assign: auto oIntCopy = oInt; There's no assignment in this line. &gt; as optional is automatically converted to `bool`. Contextually convertible to `bool`. It's worth noting that `value_or`will copy/move from the stored value (depending on the `optional`'s value category), unlike `value` or `operator*`. if (auto ostr = maybe_create_hello(); ostr) std::cout &lt;&lt; "ostr " &lt;&lt; *ostr &lt;&lt; '\n'; There's no need for `; ostr`. Probably worth mentioning that assigning `{}` is another way of resetting an `optional`. &gt; but with a few exceptions when the operands are `nullopt`. This is excessively vague when the behavior here can be easily summarized: empty optionals compare equal to each other and less than non-empty optionals. : mName{name}, mNick{nick}, mAge{age} This should be moving `nick`. std::aligned_storage_t&lt;sizeof(t), alignof(T)&gt; _storage; Typo. And no standard library can implement `optional` this way (they need to use a union, because `constexpr`). 
Thats different, because the iterator is always a valid one, the bool indicates if the thing is inserted or was already there. 
No need for name calling or strong language, but the practice has been frowned upon since the beginning \(It has been in the [C\+\+ FAQ](https://isocpp.org/wiki/faq/newbie#void-in-param-list) for a long time\). 
Can you, please, compare your implementation to pure_asio one, that can be found here: [restinio-benchmark](https://bitbucket.org/sobjectizerteam/restinio-benchmark)? It emulates to be an http-server (no real parsing, no allocations, only a standard raw response is served). It is interesting how will perform in comparison with mif. Note: as of today a mentioned benchmarks are not very actual (as many frameworks have been updated since).
For a serious answer, the stories goes: C++11, was originally called C++0x, because it was supposed to be released before 2009. It didn't happen, and was changed to C++1x when it slipped too much. After C++11, there was the need for another names, so C++1y was quite logical. At this point, C++ started to settle on 3 years standard updates, and C++1y ended up being C++14. Obviouslty, the next one was C++1z, and ended up as C++17 Now, there is the need for a name for C++20, before it is official. C++2x would be logical, however, if the 3 years cycle continues, then we'll run out of letters (C++2x for C++20, C++2y for C++23, C++2z for C++26 and, logically C++2{ for C++29. Oops.). So starting with C++2a makes sense. Another question would be, why not C++20 directly ? Well, first it may end up in 2021, and second and much more important, if a compiler start to implement C++20 using std=C++20, then we will have non confirming implementations of C++20 with the C++20 name. Which is a nope, so there is the need for a placeholder name. Hence C++2a makes sense to me.
Well.. I vaguely remember that MS has released some source code, possibly on git, so that llvm could write pdbs. Keywords to search for are llvm and pdb
&gt; At some point, we need to draw a line. Nice one.
&gt; Text, Unicode, geometry and linear algebra libraries are prerequisites of a 2D drawing library that seem reasonable to consider for standardization. This seems to be the most important takeaway. Regardless of how you feel about 2D graphics, these more fundamental pieces need to come first.
which don't ? I use gdb, lldb, valgrind, etc etc and they always work
&gt; So what do you propose we use to express something that might not have a value? I use a possibly null raw pointer, which is of course non-owning by definition.
&gt; You keep arguing with me about the paper itself. I've said several times that I have no problem with the paper itself, I'm quite excited about it. . &gt;There are only two things that I'm concerned about regarding the paper proceeds to list problems with the paper. &gt; The authors forward-looking statement about a future version of the standard changing the meaning of "void foo(void);" Again, who cares what the authors might possibly consider maybe proposing in the future that is in no way guaranteed even if proposed? Why are you so hung up on that? This proposal does not do that, so why do you care so much? You should've just stopped at the "this proposal does not do that" part. &gt; This demonstrates that you understood that I was speaking about something the authors might do in the future, yet you somehow can't differentiate the concept of "something the authors might want to do in the future" from "this paper, right here". Allow me to quote your very comment, a few lines up. &gt; There are only two things that I'm concerned about ***regarding the paper*** &gt; * The paper claims that the ABI doesn't change, but don't provide evidence that this is the case, and the proposed changes to the standard seem like they obviously change the ABI. I simply would like the paper to explain their assertion that the ABI doesn't change. &gt; * ***The authors forward-looking statement about a future version of the standard changing the meaning of "void foo(void);"*** emphasis mine. &gt; but clearly you're unable to unwilling to stay on the one topic. I'm the one unable to stay on one topic? Allow me to quote you again, `discussion about the paper itself and discussion about the forward looking statement?`. two separate topics, in your mind. &gt; Acknowledge that discussion of the authors forward-looking statements about changing the meaning of "void foo(void);" is distinct from discussing the rest of the paper I've been saying the the whole time, you've just failed to understand it. &gt; and a valid thing to discuss. It is not. Not one bit. Who cares about it? Why? You still haven't explained why you have such an issue with something that isn't in the paper. If a future proposal comes out proposing that, you can debate *that proposal*, but until then why do you care about the views the author of this proposal just happens to have? You might as well be discussing their opinion on ice cream for all the relevance it has. The author can have whatever views they want, and they can propose that 20 years in the future if they damn well want, but it doesn't mean it'll be accepted if they do, so who gives a fuck about the mere possibility of it being suggested in the future *now*?
&gt; it needs to allow the existing drawing API to be used easily: it needs a window to draw on. That's why our alternative design has a `std::window` with a `native_handle`.
&gt; after C++2d, will it go to C++3a, C++3x or C++3e? We only have 10 years to brace ourselves for this dramatic shit ahead of us, so it would be prudent to start a committee on that right now. Continuing with C++3e gives the risk of a huge confusion in 2095, as the C++9z standard would be done, and the one in need for an acronym would be C++98... 
This looks good. One small improvement (apart from removing the using directive which has already been suggested) is to change the return type from void to auto and then have "return fill(..." in the body instead of the return. This makes the use consistent (no need to supply a return type for e.g. partition), easier to write and less error-prone. Also, you will not need to change code should some of the std::algortihms decide to return some value in the future. (I have a difficult time imagining this for fill, but there are other algorithms).
While we're talking about std::optional, I have a question triggered by passing comments Andrei Alexandrescu made in his recent "Expect the Expected" talk. (Reddit discussion [here](https://www.reddit.com/r/cpp/comments/8ghtom/andrei_alexandrescu_expected_the_expected_cpp/).) In this talk, he jokingly referred to std::optional as the worst thing that ever happened to humanity. But he did not have the luxury of time to cite specific complaints, other than that he thought the * operator should not have been used the way it was. (But then he used it himself in a very similar way for the Expected type he was evangelizing.) Does anyone know what his specific objections to std::optional are? I have recently started using optional in my new code, and I really like the resulting improvements. I would like to make an informed decision about whether I should make this a long-term practice.
Don't think that just because I did not reply to you, I didn't read you answer with the utmost attention. The one immediate practical thing I learnt is that emerge use cases are wider than I thought. I'll look at it at some point, even if I don't expect it to crazy useful to me. So, thanks for that! &gt; If the c++ standards committee defined a machine parse-able format that could be used to describe these things, that didn't suck to work with (big if, i know), and was agnostic to compiler and linker implementations (even bigger if, probably biggest if), that would overwhelmingly cut down on the shit people would need to deal with to package a given library Sure, this would help tremendously. However, I don't see the C++ standard starting to define file formats, but I have a fuzzy feeling that modules could be a step in the right direction (in the sense that I'd like to use other people modules, not other people's set of C++ files). I have a tendency to think that we are sitting on different side of the same fence. I'd be happy to have a *minimal* specification of such system. I'd have no issue if, for instance, the only supported way of linking was static. Sure, it would suck, but it would be a start. Your sentence "All of the proposed solutions that I've seen so far don't support the features I need." let me think that you'd rather have a complete solution. But I feel that, this is precisely the need to have everything working that prevent the solution to start emerging (pun intended). Who cares if it can only used in 10% of the use cases ? If it works well for those, it can slowly expand. To give you an example I just got today: Someone posted in the sub a [C++11 framework for micro services](https://github.com/tdv/mif). I actually have a few C++ micro services, which run on [civetweb](https://github.com/civetweb/civetweb). I chose this just because it runs internally, so I don't need much security, etc, and I can include it in the project by droping a couple of files in my src/ directory and get them picked by cmake. I'd love to be able to use something more modern than civetweb, but see'ing mif dependecies as "Boost, zlib, jsoncpp, pugixml, libevent, libpq and sqlite" made me stop. It is just not worth looking into it. After having written that, I decided that saying "It isn't worth it" is a cop-out, and actually tried. Here is the result, execuse my rant: I fired up a ubuntu-latest docker, and entered the command to download and building the thing, as per the README, with the expected result: Scanning dependencies of target libpq-project [ 1%] Creating directories for 'libpq-project' [ 2%] No download step for 'libpq-project' [ 3%] No patch step for 'libpq-project' [ 4%] No update step for 'libpq-project' [ 5%] Performing configure step for 'libpq-project' CMake Error at /root/mif/build/libpq-project-prefix/src/libpq-project-stamp/libpq-project-configure-Release.cmake:16 (message): Command failed: 1 './configure' '--enable-thread-safety' '--without-readline' '--prefix=/root/mif/third_party/libpq' See also /root/mif/build/libpq-project-prefix/src/libpq-project-stamp/libpq-project-configure-*.log (I say expected, because when a web microframework starts to download the entirety of postgres to get access to the lib, you know to buckle up) Errors were, after parsing the logs: I don't have bison. Next error: I don't have flex. Next error: I don't have zlib (yes zlib is a dep of mif, but it is ALSO a dep of postgres, so I need to have a zlib installed globally). Zlib is called "zlib1g-dev" because fsck you. Then sqlite requires tclsh, then fails because tk is not installed. So I now need tk, which of course will draw in X11. Then the whole compilation will fail because some weird C++ include is wrong. So you end up hunting on the web, to find that beautiful gem: [@suknight Can you please open sqlite3.h from the root directory and see if it is an empty file? It is possible that an earlier configure / make issue (e.g. missing tclsh) caused the file to be empty, which would certainly lead to many build errors like this. Even if the underlying issue is resolved (e.g. by fixing missing dependencies), the make file will not regenerate it if it is already present, in which case the sqlite3.h file would need to be deleted before a rebuild.](https://github.com/sqlcipher/sqlcipher/issues/157#issuecomment-188407116). Yes. Indeed. So the fcked up non idempotent build process of sqllite is leaking into my face. I then failed about an undefinded TK_SPACE, which according to the net is due to the lack of gmake, but is in fact due to the fcked up build process having generated an empty parse.h file when bison was missing. So, remove all the files, and restarting from scratch finally got me an error with a missing ssl-dev for libevent (not that directly of course, via a cryptic cmake error), and a complaint from boost that it the compiler g++ instead of clang. Fixing that made the process go a bit further, then crash after with a nice: ```g++: internal compiler error: Killed (program cc1plus)``` which a make clean fixed. Took me an hour, and it wasn't even difficult. But my god, what a load of crap. Of course, the result works, but is still unusable in the grand scheme of things, as I'll have to ```make install``` and it will shit files all over the fileystem, so I have zero chance of my resulting code working in a controlled manner in production. How am I suppsed to distribute this ? And of course, this crazy install dance would be a burden for the maintenance of the project, so I'll stay with civetweb. I can't undertand why I cannot do something like adding a line that says : "use mif version x.y.z from mif-url", run some magic command, and start to use #include &lt;mif/whatever&gt;. That is the goal we should strive for. Same thing, mif should not try to import the full boost, or the full postgres, just because it needs part of it. I should not have to end up with X11 included because something, somewhere, needed tcl. Ok, I need to stop my rant now, I think there is someone on my lawn :-) 
&gt; Again, who cares what the authors might possibly consider maybe proposing in the future that is in no way guaranteed even if proposed? I care, for the reasons I've explained. &gt; Why are you so hung up on that? This proposal does not do that, so why do you care so much? You should've just stopped at the "this proposal does not do that" part. Honestly, I wasn't. You attacked me so strongly about it that I wanted to discuss it further. As I said before, I consider you an insufferable prick because of your poor conduct here. You refused to do the two simple things that I asked. Good bye. Blocked.
I think I'd prefer compilers warn about non-optimal packing instead. Member construction order is defined by their layout not their order in constructors so this `[[reorder]]` is more complex than it sounds.
I'm not sure perfect forwarding would make sense here since you need to construct N elements \(N = end \- start\). It would introduce bugs like this: namespace ext { template&lt; typename container_t, typename value_t &gt; void fill( container_t &amp; c, value_t&amp;&amp; value ) { using namespace std; std::fill( begin(c), end(c), std::forward&lt;value_t&gt;(value) ); }; } std::vector&lt;std::string&gt; v; ext::fill(v, std::string { "test" }); The first string in the vector will be constructed using string\(string&amp;&amp;\) constructor, then the next 4 will try to do the same but the string on the right hand side has already been moved.
I've used [Nonius](https://nonius.io/) in the past. It's modern C++, header-only, and easy to use. It targets micro-benchmarking mainly, and it can also make pretty HTML-based graphs.
And if you use MSVC or Clang on Windows you might want to try [my fork](https://github.com/dodheim/nonius) which has some relevant fixes.
His point is the you will potentially do a lot of isolated page faults before returning from dlopen, making the startup of the software slow and sequential. If your variables are in non-static initializer, then, your cost will only be incurred when you use the variable, and, you could paralelize the construction if you wanted to.
Is that so? I would expect expect my ext::fill(v,std::string("test")); to be esactly equivalent to std::fill(begin(v),end(v),std::string("test")); In both cases std::fill receives an xvalue (if I remember the name correctly). /Peter
&gt; I care, for the reasons I've explained. No, you have not yet explained why you consider the maybe possibility that someone dared to think something you wouldn't like might be worth talking about at some point in the future is such a problem to you.
@vanilla-rtb - "u" in the name is exactly for the greek "¬µ". On the subject of trying it in your platform - I'm almost done with the first cut of "topics" -- an indirection layer for cross-module calls. This will allow configuring the concurrency (threads, queues, contexts, affinity, prios) in the config file and inject any sorts of observers for sampling/telemetry. Interested?
&gt; Every single one that I ever saw proposed lacked the most basic security-properties [...] You must have not heard of `build2` then. See [bpkg-repository-signing(1)](https://build2.org/bpkg/doc/bpkg-repository-signing.xhtml) for details.
Possibly that operator* should be checked (i.e. throw/assert if optional is empty). boost::optional's operator* is checked. IMO, the unsafe method should be more verbose than the checked one.
Thanks for pointing me to that. Like I said, I had *literally* never heard anyone, or read anyone, say that before. I'll be reading up on it. If it's really been frowned upon, I don't think it's been frowned upon very consistently, if I've managed to remain ignorant of it for 10+ years.
What do you want to measure? If you are interested in hardware counters, Intel PCM is quite good. https://github.com/opcm/pcm
&gt; Generally you would want to follow STL practices throught your project, right? not necessarily ? 
Apologies for the off-topic, but what is missing in Google Benchmark that you want differently? If simplicity - then I'd just write a few lines of wrapper myself, the key component, zero overhead clock, should be relatively straightforward to do with tsc ([my old tsc_clock.h](https://github.com/mrbald/sandbox/blob/master/ringbuf/tsc_clock.h)), an HDR histogram for sampling I would hack together based on the [Peter Lawrey's Java version](https://github.com/OpenHFT/Chronicle-Core/blob/master/src/main/java/net/openhft/chronicle/core/util/Histogram.java)
"Compiling and running this program produces the exact same results as before, with the important distinction that this program can open even very large files, without allocating a ton of memory." .. as long as you have enough (free) address space to map the file into, that is. A few years ago when Apple went all 64-bit with their mobile devices internet went crazy: "They don't even have 1 GB of ram this is completely useless!!1one" and my head exploded (unrelated). 
Sorry for an old thread reply but .. as i deal with similar issues: would -fno-heap and -fno-virtuals be a bad idea, to complement no-rtti and no-exceptions ? To catch all this stuff at compile-time, rather than link-time as my embedded build setups do.
I'm going to presume we are using the Apple II character set for this, so it's actually C++2[.
Thanks - this is useful feedback. Hearing something like this makes me think that we should have nothing instead of something simple. We definitely can't deliver the full fledged thing you're asking for - and that has never really been the goal of this work.
I have no idea what you're saying... template&lt;class TContainer&gt; using value_type_t = typename TContainer::value_type; Involves no more or less repetition than your macro.
Some benchmarks would have been nice! &gt; By orders of magnitude always sounds nice but still, premature optimization is the root of all evil. Always profile before optimizing anything. I haven't seen static variables that slow down startup times measurably, yet.
I see, thanks, I misunderstood what was happening
Unfortunately that code predates `debug:fastlink` by years.
I think he indicated that his issue was with giving pointer like semantics to a type that is not actually a pointer and potential confusion this could cause. It sounded like he took the liberty of using this syntax in the expected proposal because the precedent had already been set by optional and could therefore been seen as being consistent with optional.
If STL had optional from the beginning, I suspect some of the STL would have used it. I also expect it to show up in new STL stuff in the future. Maybe find() would have been nicer returning an optional. Or add a find_value() that doesn't return an iterator at all. At least for map, I rarely want the iterator; I typically want the value the key is mapped to. I think returning an optional would be nicer than the awkwardness we currently have. (And we don't need expected&lt;&gt; in this case, because the error is obvious. (In many examples of uses of optional as a return value, expected is a better return value. But I don't think that applies here.)) Hmmm, maybe someone should write a proposal adding nice APIs that use optional...
I don't know about PMS, but depending an a POSIX-like shell wouldn't be surprising. That still doesn't completely rule out Windows. Gentoo itself does work with FreeBSD's kernel.
And connecting two points!
In particular, the issue which prevented std::vector::push_back/emplace_back from inlining has finally been [fixed](https://developercommunity.visualstudio.com/content/problem/245067/stdvectorpush-backemplace-back-cant-be-inlined.html).
But how to install it ? I have tested a lot of different package manager but spiked build2 because I could not make it work after extraction. Not that I was truing very hard but any way. Also I still see only 16 Packages. The site seems to be abandoned, only highly unusual git repository show some activity. 
What about range-v3?
True. My point was more about to be careful when playing with perfect forwarding as it can lead to unwanted behavior being "too generic". I should pick up the right example from the start \(of course, don't do that at work \^\^\): namespace ext { template&lt;typename container_t, typename value_t&gt; void fill(container_t &amp; c, value_t&amp;&amp; value) { for(auto&amp; v : c) v = std::forward&lt;value_t&gt;(value); }; } std::vector&lt;std::string&gt; v(5); ext::fill(v, std::string { "test" }); // v = [ "test", "", "", "", "" ]
Question is, whether the described method in the blog post works with those? 
There are word about it here: [https://blogs.msdn.microsoft.com/vcblog/2018/04/26/announcing\-msvc\-conforms\-to\-the\-c\-standard/](https://blogs.msdn.microsoft.com/vcblog/2018/04/26/announcing-msvc-conforms-to-the-c-standard/)
&gt;I have never heard of even one. Every single one that I ever saw proposed lacked the most basic security\-properties How many have you tried? And of those how many have you provided feedback to the authors to add security chain features? How do you manage your own software development security for the external libraries and tools you use? How much validation of that security chain do you do? But most important.. How can you claim that one part of one aspect of software development can invalidate all the rest of it. Since clearly others keep on doing software development without it?
"Hmmm, maybe someone should write a proposal adding nice APIs that use optional..." Better yet integrate it into the ranges library. It has replaced the STL entirely for me anyway...
C++17 Core Language Features | Status --- | --- Removing trigraphs | VS 2010 So quick to conform to standards!
Nope, and it still ICEs on Boost's C++14-`constexpr` test. :-[
Hi chaosmeist3r, thanks for your comment. The article is about avoiding non-POD static initializers because they generate some sort of bloat code. It is not about avoiding static initializers in general.
Right, of course. I mean, we're not disagreeing. My use of "claims to work on..." was merely because I personally haven't verified it, not that I don't believe them. https://wiki.gentoo.org/wiki/Project:Prefix
Range-v3 has always has its own `optional`, in `range/v3/utility/optional.hpp` ‚Äì I suspect it's been fully integrated to the extent they want it to be.
What is it about google benchmark that makes you not want to use it? That would be useful in suggesting an alternative that gives you want you want.. otherwise, just use google benchmark.
Presumably they already know about it, and they want suggestions for things they don't know about?
Please, please, please, let's do linear algebra correctly. Before any half-assed minimal set of linear algebra primitives and operations get standardized, one should consider looking into the de-facto standard, Eigen, and/or maybe Blaze as potential starting points for standardization. Eigen sorely needs some modernization effort to bring it into the C++17 days (and avoid its 'auto' issues), but besides that, it's the best linear algebra effort I know of.
&gt; ... we‚Äôve only just started our major preprocessor conformance effort. -- &gt; We‚Äôll introduce an opt-in switch in a later Visual Studio 2017 release that will allow you to use a conforming preprocessor ...
can't beat the speed at which you managed to post an asinine comment, that's for sure
Still no basic OpenMP 3.0+ support ? OpenMP basic SIMD ?
Yeah, the hostility of that response was pretty uncalled for. I get that years of people going ‚ÄúM$‚Äù makes anti-Microsoft sentiment seem a bit tired, but I mean, if Microsoft feels the need to mention that they ‚Äúimplemented‚Äù removing trigraphs by virtue of not having them in the first place I think that deserves at least a little snark.
probably IBMers
This is pretty awesome news. Congrats!
 You can find in-depth information about the Visual Studio 15.7 releases in the following posts
Have we learned nothing from y2k?
The MSVC implementation of the Standard Library has gained major new features recently
&gt; And if the goal is just to provide pixel buffer drawing facilities, wrap Cairo into the standard and be done with it. Bah not this nonsense again
Congrats!
There are multiple references to 'the next ABI-breaking release of the libraries' ‚Äì /u/spongo2, any timeframe yet? This has been talked about for 3-4 years now; is it actually on the horizon? ([`__declspec(empty_bases)`](https://blogs.msdn.microsoft.com/vcblog/2016/03/30/optimizing-the-layout-of-empty-base-classes-in-vs2015-update-2-3/) _begs_ to be the default...)
That's thanks to Billy's perf work! (The issue was my fault, as when I overhauled vector for correctness, I didn't pay attention to inlining consequences.)
Actually, trigraphs were implemented in MSVC - we simply disabled them by default in 2010. This was because we implemented `regex` in 2008 SP1/2010 and regexes make double-question-marks more likely.
Well, ‚Äúnot having it in the first place‚Äù was simplifying it, as if that were the case it wouldn‚Äôt say ‚ÄúVS 2010‚Äù specifically, but ‚ÄúVS 97‚Äù. Cunningham‚Äôs law really is in effect.
I didn't intend to sound as if I'm disagreeing. I was rather thinking out loud.
&gt; And if the goal is just to provide pixel buffer drawing facilities, wrap Cairo into the standard and be done with it. That's what P0267r7 is, and it hasn't gone well. It's 3 years over schedule, nowhere near done, and of questionable utility. Let's just leave graphics alone.
What is wrong with the preprocessor?
&gt; if Microsoft feels the need to mention that they ‚Äúimplemented‚Äù removing trigraphs by virtue of not having them in the first place I think that deserves at least a little snark. Did they really? Thats hilarious
That's what I said to start. I vote for nothing.
Does this make MSVC the most standard compliant compiler? (Disregarding C++2a) https://en.cppreference.com/w/cpp/compiler_support
The situation where you would actually want to create and destroy threads just to copy data seems a lot more theoretical than anything, which seems to be what they are saying as well. 
Shouldn't parallel algorithms use thread pool instead of creating threads? 
The things objects could have very expensive copy constructors. Like he said, up to the user.
Even thread pooling wasn't enough to save it, at least on our implementation or with HPX's.
&gt;Extend template argument deduction for functions to constructors of template classes; when you construct a class template, it is no longer necessary to specify the arguments. Just a few hours ago I was wondering why this didn't work. Great! 
[I agree. This may help explain why an alternative was important - read the delay va bird in hand paragraph](https://isocpp.org/std/standing-documents/sd-4-wg21-practices-and-procedures#proposals-and-papers)
We've also added STL support, so you can say `std::array arr{ 11, 22, 33 };` producing the type `std::array&lt;int, 3&gt;`.
Oh, this is very exciting! I think I just today discovered a bug with if constexpr and type traits. Let's see if this is still around, hopefully it's already fixed. Also, among new stuff: Templates that are designed to take any type as a non\-type parameter can now use the auto keyword in the template parameter list. Why, why, why is it already midnight and why do I have to work tomorrow...
It's not C++.
If the `if constexpr` bug still repros in 15.7, please let me know - I am *very* interested in such reports.
Can one write a paper for a negative or null proposal? Thus that the proposal says "we should do nothing"?
/u/urist_mcprogrammer , I will try to answer on of your questions: &gt;Is there a market for platforms to take a certain amount of money in exchange for a certain amount of promised clicks, and then try to deliver those clicks while paying less than what the client did? Or are most vendors here charging a fee per click/bid/whatever? * some companies offer a bidder with set of standard targetings say geo targeting , the advertiser's budget is spent and that's it no clicks are promised. * some companies working with advertisers budget promise to maximize number of clicks , maximize spent amount efficiency, this requires constant fine tuning of the bidder , good statistics to rely on, sometimes this process manual and needs daily /weekly adjustment ( think of prop trading ? ) * there are even those companies who have not connection to publishers ( websites owners ) , they connect directly to SSP ( supply-side platforms where publishers push traffic to) and another end connect to DSP ( connected to advertisers ) , these companies charge a small fee and earn on massive traffic - basically a proxy middlemen . 
Just run a small test - `std::copy` serial vs parallel with very stupid implementation - https://gist.github.com/telishev/770d3f7072fd35286225c6d34dd78c6b result with n = 1000000000 *serial time = 1.203000 *parallel time = 0.289000 
I wouldn't say that about the compiler in isolation. Clang's feature tables indicated that they were C++17 feature complete in Clang 5 (with the addition of constexpr lambdas), and their preprocessor doesn't need to be overhauled. Similarly, GCC's table indicates that they were C++17 complete in GCC 7 with the exception of a [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0512r0.pdf](paper fixing CTAD) that shipped in GCC 8. For the library, things are the opposite - all of MSVC, libc++, and libstdc++ are missing floating-point charconv. However, MSVC is now shipping parallel algorithms, special math, filesystem, `hardware_meow_interference_size`, map/set splicing, and launder, which are listed as missing for libc++. Compared to libstdc++, we have `hardware_meow_interference_size` (probably because we target far fewer architectures), memory_resource, and parallel algorithms. (And filesystem on Windows, AFAIK.) So overall, I would say that our toolset (compiler + library) conformance is comparable.
No repro for me.... https://gist.github.com/BillyONeal/d4c9871403b8ebb1ea1bf6289615c2c8
Dual Xeon E5 2630 v3, 2x4 channel ddr3-1600
I agree about `clock` being bad, it's just faster to type for quick benchmarks on windows)
That's interesting, I took your implementation and I don't get the same result at all on a 16 core CPU, running Linux: serial time = 0.288266 parallel time = 3.274555 Going down to 8, 4 or even just 2 threads, serial still wins by a considerable margin on my system. This is two threads: serial time = 0.290894 parallel time = 0.466830
Wow, that is very strange to slow down like that, what is your hadware? 
Well, my hardware is different from yours - you probably have a core-i7 (as your serial time is 2 times smaller than mine, your clock speed must be around 4-4.5k). Mine is Dual Xeon E5 2630 v3 and they have very small clock speed (2.4) but a lot of bandwidth (100GBs), so it needs a lot of threads to achieve its maximum.
Ah, I got it, `clock` on linux works differently, it's better to use `high_resolution_clock::now()` as STL suggested
Very cool! I love these frequent yet meaningful updates! Here is a bug report - the Std module definitions only work for 32-bit builds. Here is what I get for a 64-bit build: ``` C:\temp\modules&gt;cl /c /experimental:module /std:c++17 minimal.ixx Microsoft (R) C/C++ Optimizing Compiler Version 19.14.26428.1 for x64 Copyright (C) Microsoft Corporation. All rights reserved. Experimental features are provided as a preview of proposed language features, and we're eager to hear about bugs and suggestions for improvements. However, note that these experimental features are non-standard, provided as-is without support, and subject to breaking changes or removal without notice. See http://go.microsoft.com/fwlink/?LinkID=691081 for details. minimal.ixx minimal.ixx(3): error C2235: mismatching target architecture for compiled module interface for 'std.core' from 'C:\Program Files (x86)\Microsoft Visual Studio\2017\Professional\VC\Tools\MSVC\14.14.26428\ifc\x64\release/std.core.ifc' minimal.ixx(9): error C2760: syntax error: unexpected token 'decltype', expected 'expression' minimal.ixx(19): error C2760: syntax error: unexpected token 'decltype', expected 'expression' ```
I understand that dual xeons are not the most common configuration, but all AMD Zen cpus have a lot of threads and even more memory bandwith, and I suspect that Intel will go the same way in a couple of 
Oh you're right, that would explain it. I should have paid more attention to the clock call!
There really should at least be basic vector and matrix types, as these often get reimplemented by many libraries. And maybe also n-dimensional arrays / spans, and BLAS operations for linear algebra operations. Maybe an extension/replacement to `std::valarray`, `std::span`, `std::array`.
I believe at the time I did this test I was using a Xeon E5-1650v3 (6C/12T, 4 channel memory) and a Ryzen 7 1800X (8C/16T, 2 channel memory), both of which showed similar 1.6x slower values (though I was using smaller N than this). That test I just did above was on a 8950HK (6C/12T, 2 channel memory). Interestingly, if I copy that benchmark onto the 1950X machine (16C/32T, NUMA, 4 channel memory) or the 7980XE machine (18T/36T, 4 channel memory) (I didn't have those when evaluating std::copy before) I get values closer to what you report: 7980XE C:\Users\bion\Desktop&gt;.\test.exe serial time = 0.611000 parallel time = 0.199000 serial time = 0.563000 parallel time = 0.194000 1950X C:\Users\bion\Desktop&gt;.\test.exe serial time = 0.499000 parallel time = 0.164000 serial time = 0.444000 parallel time = 0.160000 ) so this may need to get reevaluated in the future. (Though I think this value of N chosen here is not exactly common when we're talking about std::copy)
I guess for you I can point only to the transform escape hatch? std::transform(std::execution::par, a.begin(), a.end(), b.begin(), [](int x) { return x; }); 
I really like how the Release Notes seem to have gotten much more detailed! And they actually list the C++-related changes. Very nice. Congratulations on this release. Awesome, and already looking forward to the next. Keep up the awesome work, VC++ team!
:)
there is some details in the blog post about Boost.Hana support. We are tracking carefully :)
Maybe you could use current logic for some other policy (like `std::execution::smart` or `std::execution::ms`) and force-parallelize `std::execution::par`? Or maybe something like for `std::async` where `std::launch::async | std::launch::deferred` means compiler may choose to create threads or not. 
What about a non thrashing memory allocator with multiple threads? Since vs2013 it's a huge pain to install a working allocator.
Still waiting for package for Conan...
Follow-up questions to article from this idea: There are many [[xyz]]-tags that we can use in C++ to make the compiler believe we know what we are doing. How do we use these to tell the compiler what is the likely path of a goto/if/switch? How do they tell the compiler that a loop can be multicored and SIMD? How do we tell the compiler with these tags do not assume a linear workflow? Or is there a better way than with [[xyz]]-tags to do this? Just asking because the article suggests there are better ways of doing things but it never says how. And I don't want to keep maintaining and developing Fortran code because it is a bit. If these tags are not in already (and I cannot find them), is there anyone working on working around the C-machine by some interesting proposal that I can use whenever the oldest Linux LTS distro I have to support is outdated?
The rule we settled on was "copies / moves with no branches (or at least 99% of the time have no branches)." We think std::transform is more like std::for_each here.
"It's been another 3 years and we still can't compile it, but we're still trying."
&gt; `hardware_meow_interference_size` haha Incidentally, can you speak to how the names of those constants were chosen or proposed?
Awesome! Much thanks for your work! 
&gt; two-phase name lookup Wow VC eventually supports two phase name lookup! That is great! But doesn't it break a lot of legacy code? 
I'd love to see a new build on compiler explorer to checkout the coroutine changes... *crickets*
Not sure if you are aware, but the 7980XE is actually a single-socket NUMA machine. In fact Skylake-X uses a memory architecture closer to Xeon Phi than Broadwell-E, which ties in with your earlier comment. You can read a long writeup about it [here](https://www.anandtech.com/show/11550/the-intel-skylakex-review-core-i9-7900x-i7-7820x-and-i7-7800x-tested/5). Also there is this interesting quote from [this later review of the 7980XE](https://www.anandtech.com/show/11839/intel-core-i9-7980xe-and-core-i9-7960x-review/2): &gt; So far the reaction to the mesh method has been mixed. While it offers scalability over using rings, it has not had over a decade of optimization, and some users have pointed to the frequency (usually 2.4 GHz) as being a bottleneck in their software over the faster ring design. Intel is likely to continue with the mesh design for the next few generations, so it will be interesting to see what upgrades are made (if disclosed). I don't have any personal experience tuning for Skylake-X, so I'm no expert, but that does seem to correlate well with what you are seeing. It may be interesting to try measuring the perf on each core separately. I wonder if part of the benefit to parallelism is that if there are differences between cores, you increase your chances of getting on the "lucky core". (pure speculation of course)
sorry. we know we are way behind here. We're going to try to get this done in the next few weeks and also get it automated so we can stop always being behind on this. 
thanks for the report. I sent it to the devs, but if you file it on Developer Community you can track our progress more easily.
no. you have to throw permissive- switch to get the behavior. we've tried to be very very careful about finding the right balance between conformance and breaking people's code.
there is a branch in which it exists. :) We are slowly batching up a bunch of these sorts of things but we don't want to do many of these so we are trying to find the optimal set and there is some work we want to do with regards to RTTI and exceptions implementations that I don't want to miss in our next break. 
&gt; 7980XE is actually a single-socket NUMA machine No, all the cores are connected to the same 2 memory controllers; there's no NUMA going on here. While access time between a given core and memory is not necessarily the same for every core, there isn't any concept of local memory or remote memory owned by another core. It's just that some of the cores happen to be slightly physically closer to the memory controllers and thus have a teensy weensy bit lower latency. This benchmark is not taking advantage of NUMA behavior anyway.
Talk to Windows. We got out of the memory allocator business because everyone hated it so much. You can still define your own malloc and free which will replace the default ones. 
I'm sorry, I must have crossed a few of my own memory wires... I'm pretty sure I mixed up their writeup on threadripper which *does* optionally use numa with the ones about Skylake-X. Thanks for correcting me!
Yup, TR is absolutely NUMA. :) Wish they called it that instead of "creator mode" and similar :/
&gt; Wish they called it that instead of "creator mode" and similar :/ ... "Fall Creators Update" ;)
Excellent, I'm really excited about `template&lt;auto&gt;` and deducing class template parameters. We can finally pass an arbitrary function as the first template parameter for stateless function transformers :D
I usually have to work with bit older gcc versions. What I do is compile the latest Clang version with gcc compatibility mode. \(Compiling clang with GCC\_INSTALL\_PREFIX set\). I get the full range of useful compiler warnings and detailed error messages now. For the release builds, I switch back to gcc.
bummer about range-v3 or boost hana :_(
Don't even get me started on craziness of our public versions...
They're going to focus on C++2a now that C++17 is pretty much done, so hopefully TSes will start shipping soon.
My understanding is that they tried to be self-documenting and I think they succeeded. Constructive interference is when you want members close together so they‚Äôre loaded in the same cache line. Destructive interference is when you have separately modified atomics and you want to avoid false sharing, so you need to keep them out of the same cache line.
I think as an ex-physicist, the term is a bit odd to me still since I think of interference as things "canceling out" in the case of destructive interference or amplifying in the case of constructive interference. Maybe I'm still not grasping the analogy or the words "constructive interference" and "destructive interference" are meant in a domain I'm not familiar with (that isn't signal processing or electromagnetic waves or something). Granted, I'm not sure I would be able to come up with a better name myself. Maybe `hardware_cache_line_size`haha (I'm also not sure I've worked with hardware where the constructive/destructive variants would be different).
&gt; although a lot of the initial work was done in a bar and then on a plane. Mate, can we be friends... I know some pubs...
I'd be happy to get just BLAS in the standard. It's not that many functions, but it is really useful and can hopefully standardize the interface because every library has some differences that makes replacing them difficult.
That's a pretty unhelpful comment, thanks!
If you want notes on a highly-optimized approach to multi-threaded copies, have a look at https://dl.acm.org/citation.cfm?id=2612267 Better algorithms based on the ideas in there might get better results.
:D
Usually, we don't do that.
&gt; some work we want to do with regards to RTTI and exceptions implementations How different is it going to be? I just submitted a [paper](https://api.csswg.org/bikeshed/?url=https://raw.githubusercontent.com/RedBeard0531/better_exception_ptr/master/better_exception_ptr.bs&amp;force=1) that touches that topic and includes an [MSVC-ABI compatible POC implementation](https://github.com/RedBeard0531/better_exception_ptr/blob/master/abi_details.h). Any idea if that will keep working? Any chance it could get better performance (`DecodePointer` is a real bear)?
Personally, I like your work. It is still raw, there is a lot of things to do, but I like it.
EBCDIC is weird . . . The codes for letters are not in a contiguous sequence!
Today is the day I switch to C++17!
Things targeting Xeon Phi are totally useless on any of the hardware we target.
Constructive interference amplifies your performance, destructive interference reduces it. It‚Äôs an unusual metaphor, to be sure.
still in design mode... no code exists and project not officially kicked off, we just know our perf isn't where we want it yet.
Haha well hopefully if you use either correctly it should improve performance correct? Separating atomics via the destructive alignment for example
So.... Are we just ignoring the meow part :) this one is way out of my swimlane, so I have no idea what is going on. 
Last I heard, gcc still tends to result in better executables - ie performance of the resulting exe. Although it is very close. But for someone like, say Google, a few % performance difference probably means millions and millions of dollars.
It still is not our top priority... :)
Yes. I had to rewrite significant chunks of my code every time I built with gcc until I finally gave up and moved everything over to clang. Clang isn't perfect, but it crashes SO much less.
My understanding is that Google uses clang for development, but gcc for production. At least that was the state of things recently. It may have changed.
That would be odd considering how much money they put into the llvm optimizer.
I can only speak to their impact on my projects: * clang has somewhat better diagnostic reporting * clang appears to compile slightly faster * gcc has more precise options (and it's diligently documented) * gcc generates faster code (enough to not ignore) * gcc is available for damn near every platform * they both have differently useful sanitizers * they're both differently behind in stdlib features The LLVM _ecosystem_ has far more tools available that I use (eg, SPIR-V and BPF compilers), but if you're just talking about `$(CC) foo.cpp` then there's not enough in it either way for me. I use both every day, but gcc for release builds. Neither has been sufficiently far ahead that I'd consider dropping the other, and they each expose different issues in my code. Also, I'm not comfortable contributing to a software mono-culture...
C++XP Professional for Workgroups SP3.
So, 8207 at the latest is when 0x will be released?
We will just call it C++98 SE.
I've probably hit 5 different types of ICE over last few years on gcc. I have a bug right now that only exists on gcc, which is even worse and it is due to incorrect implementation of the standard (granted, for a somewhat odd case but still). If you aren't going anything "weird" it doesn't happen so much, but for comparison I've only hit 1 ICE with clang during same time period. But I do some high perfomance work as well and I (almost?) always get better results with gcc- to the point I don't really bother trying clang if that is the goal. 
What these apis ignore is that C++ is a general purpose language... Let's say I have a 32x16 display, does your api treat me as second class? What if my display is actually 8 smaller displays? What if my device does not use rgb? What if my display expresses braille rather than colors? What if it does not display color within the visible spectrum, it is a "display" which emits patterns of ultraviolet? What if the "braille" is just one of many different patterns to display. What if I'm rendering to a non rectangular surface? What if my device does not necessarily take a whole frame, but can operate in lower powered mode where it is possible to update only part of the scene? --- Are these edge cases? Sure... but if you want a standard graphics lib in c++ it should support weird edge cases... because it's c++. Imagine 20 years from now when people wear stupid overlay glasses everywhere and people talk to their computers more than their wives... there shouldn't be this old cruddy graphics api that is stuck around which was designed for dumb displays. But how do you do this in a way that isn't incredibly slow? This is why I can't see such a proposal ever being a good thing. 
Before I used templates in earnest I encountered one bug every few years; perhaps not even an ICE. Now, I get an ICE every couple of months in both clang and gcc. Interestingly I've accidentally discovered more bugs than I first anticipated because I wasn't sufficiently restrictive when invoking `creduce` and ended up resolving a _different_ ICE. I'll give the gcc guys particular credit for being quick to respond to my reports, with fixes landing in stable release pretty rapidly.
The biggest one of those was lack of 2 phase lookup which has been fixed.
FYI OpenMP simd is OpenMP 4.x, and OpenMP 5 might be landing soon.
Does this mean libraries such as Boost.Hana and range-v3 can be used in using VS?
The point is that having them both exist is making them both better.
span-lite has been re-licensed under the Boost license.
seems stiil can't use co_await in catch clauses clang works well
In my experience Clang doesn't compile faster anymore, and GCC doesn't generate faster code. That was true a few years ago but these days they seem very much comparable in both aspects.
But not nearly the only one. I am fairly sure that I have at least one C++98 pure language bug still open, so the asterisk is still there ;-)
Yes, but you have to write it for every template wrapper function, and the macro can be declared only once and used in all wrapper functions, that's the entire (not very important, tbh) point.
&gt; you have to write it for every template wrapper function What does this mean? Why would you need to write it more than once?
Anyone know if there are plans of adding a flag similar to GCC/Clang's -fno-access-control to MSVC?
Build with Clang, release with GCC. Best of both worlds.
I use clang just because gcc is tricky to install on MacOS. 
Ouch, my bug at least was a hard error.
Ah, I took that to mean MSVC specific, since we've had a number of those asterisks for some time. :)
Alias templates: template&lt;class TContainer&gt; using value_type_t = typename TContainer::value_type; static bool contains(const TContainer&amp; vector, const value_type_t &amp; item) { return std::find(vector.begin(), vector.end(), item) != vector.end(); } template&lt;class TContainer&gt; using value_type_t = typename TContainer::value_type; static void Remove(TContainer* vector, const value_type_t&amp; item) { typename TContainer::iterator it = std::remove(vector-&gt;begin(), vector-&gt;end(), item); vector-&gt;erase(it, vector-&gt;end()); } Helper macros: template&lt;class TContainer&gt; static bool contains(const TContainer&amp; vector, const CONTAINER_VALUE_TYPE(TContainer)&amp; item) { return std::find(vector.begin(), vector.end(), item) != vector.end(); } template&lt;class TContainer&gt; static void Remove(TContainer* vector, const CONTAINER_VALUE_TYPE(TContainer)&amp; item) { typename TContainer::iterator it = std::remove(vector-&gt;begin(), vector-&gt;end(), item); vector-&gt;erase(it, vector-&gt;end()); } 
Not yet: Boost-hana: https://www.reddit.com/r/cpp/comments/8hpx0q/visual_studio_157_is_out_with_c17_conformance/dym05xr/ Range-v3 (From the blog OP linked): &gt;Alias templates are used heavily in many Modern C++ libraries. MSVC has bugs with alias templates that prevent some of these libraries from compiling, e.g. Range v3. We‚Äôre re-implementing parts of the feature on the new ‚Äúrejuv‚Äù parser. The new parse trees will help us to fix all the remaining bugs with alias templates in MSVC. (Range v3 is the basis of a proposal to add range support to the C++ Standard. We have a fork of Range v3 that works with MSVC but it‚Äôs significantly behind the Range v3 trunk.)
That isn't valid syntax, so I don't know what point you're attempting to make. This is valid syntax, and obeys scoping rules unlike macros: template&lt;class TContainer&gt; using value_type_t = typename TContainer::value_type; template&lt;class TContainer&gt; static bool contains(const TContainer&amp; vector, const value_type_t&lt;TContainer&gt;&amp; item) { /*...*/ } template&lt;class TContainer&gt; static void remove(TContainer* vector, const value_type_t&lt;TContainer&gt;&amp; item) { /*...*/ }
really? brew should do the job for you 
Do you mean with C++14/17 there's a better way of doing linear algebra libraries than expression templates? If that's what you mean, is there any proven example of it? (with "proven" meaning a project that a noteworthy amount of users has been using for a while)
Maybe, I haven't tried lately. When I did some years ago, things just got confused. It‚Äôs not just gcc, it‚Äôs the libraries and debugger. clang just installs directly. I also distribute on Mac and didn‚Äôt want surprises.
It's actually not, which makes me wonder if people misread it... It's true: MSVC's preprocessor has never been standards-conforming. If you really mean their comment is unhelpful because it doesn't enumerate in what ways it's broken, I'd say you're expecting too much, personally.
Those conditions aren't [value-dependent](http://en.cppreference.com/w/cpp/language/dependent_name#Value-dependent_expressions), so this code is ill-formed.
Really wondering why is [this feedback](https://groups.google.com/a/isocpp.org/forum/?fromgroups#!topic/sg13/gUr98RZMU7M) not being taken into account? I suppose the SG is by now very well aware of that post. Do you not like the direction and suggestions posted there? Quoting the main points from the first post: &gt; 1. An abstraction around a vulkan context and OpenGL context. Why not? Vulkan and OpenGL are open standards, widely compatible, and we can provide a compile time check so the user can determine if it's available or not. At runtime, it can be used to query for valid gfx devices and provide a context if possible. It should be thin and devolve to the vulkan/OpenGL headers as soon as possible, but this interoperability would drastically lower the barrier to doing all sorts of things (as a kid, I would have loved this instead of wrangling with OpenGL extension pointers and proc addresses). For the engine developers that need support for a non-Vulkan/OpenGL context, they already know how to do that, but again, this lowers the barrier. &gt; 2. Texture/image formats. This area is an actual problem in the industry that is difficult to deal with and also lies in a grey area between the CPU/GPU. Different formats compress better for different types of data (alpha, no alpha, normal map, specular map, font, etc). Reading data and writing data in some set of interchange formats that are natively supported by most hardware with fallback conversions for others would be incredibly useful. &gt; 3. Graphics related operations on the CPU that would benefit from a standard existing. I'm thinking SIMD, AVX, usage of ultra-wide registers, etc which could in turn be leveraged in a library like Eigen or BLAS. Minimally, I could see these operators intermingling with standard graphics pipelines or compute pipelines. &gt; 4. Handling OS events (window resize, position change, mouse input events, keyboard events, multi-text input for unicode, etc), with extension ranges for platform specific events. Managing the OS event loops in a cross platform way is a huge hassle but abstractions exist that are ossified enough that I think a standard around it would provide real value (that doesn't depreciate too quickly). I guess you are proposing some of "4.", but nothing of the rest.
This seems to be an artifact of the elf executable format and linux dynamic library symbol resolution. It's not the case on Windows, for example, where dll symbols are not transparently handled and instead have to be explicitly imported/exported.
Nice paper render
I want to use this to implement a webservice on aws or digitalocean how viable?
fair enough :D didnt extensively test it but it seemed working well for my projects
@MSVC people: in the release note it says that the variant compilation time has been decreases by 30%, which technique did you used? Is it this huge function with if constexpr switch? 
\[conan\]\(https://conan.io/\) \+ CMake works well here. \[This\]\([https://docs.conan.io/en/latest/using\_packages.html](https://docs.conan.io/en/latest/using_packages.html)\) should explain the pipeline quite nicely.
Must be ok. If any issue occurs then we'll do best we can to solve it as soon as possible. And anyway feel free to ask for advice on how to use restinio in your case.
Where are all the bugs reported via MS connect? Are they all just deleted?
This was actually an attempt at producing a cut-down repro case for the bugreport, but if it's wrong, my bad! Even still, throwing together something resembling the example on cppreference, it's still problematic: https://pastebin.com/KGbV3u9s Commenting/uncommenting the `#define BROKEN` changes the functionality, despite it effectively having the same result. I guess I still misunderstand something here.
Why is that so hard to get right? I mean, you seem to know about these issues already, so why not just fix them?
I use meson + git submodules + wrap, but it has very few packages right now (though meson covers my needs quite well). Also, if I need to precompile something (packages usually have cmake), it is not a big problem to do something like this (this is what I do): 1. set up a script at configuration time and clone submodules, compile cmake dependencies passing -DCMAKE_BUILD_TYPE. The build type is taken from meson `get_option('buildtype')` and will compile the package correctly at configuration time, which is enough for my use case. 2. declare_dependency(...) &lt;-- to your cmake compiled library Actually you can do this with any dependency and with any build system and I did not feel it is a big amount of work. It is simple. So, all in all, and for my needs, I use a combination of: 1. wrap (meson subprojects) https://wrapdb.mesonbuild.com/ 2. git submodules from source, if need to compile I do it. This has the advantage that if someone gets the project from another machine it can compile the sources from dependencies for its target. It is a one-time operation. 3. meson as the build system. I highly recommend meson to everyone unless you need XCode/Visual Studio high quality project generation. All the rest: sane syntax, documentation, etc. is easier in my opinion. I have also a considerable amount of experience with CMake, so this opinion is quite informed.
I remember a talk from Herb Sutter, it must be 2010 or 2011, where he said the biggest problem of C++ is the lack of libraries. The amount of C++ libraries compared to Java and C# it is ludicrous. As an example I can only refer to `std::filesystem`. It took incredibly 11 years, to get in the standard. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n1975.html So suggesting a graphic library will take how long, 20 Years...? The proposed direction of this paper is absolutely correct. Having a standard packag manger, will solve a lot of problems (including the graphic library one). But I suggest also the creation of a standard build system. Only together it will work smoothly. Having the possibility to easily choose between libraries which fits best for one self is the right solution for this problem. I can only enlighten all user to look for other languages, how they solved this problem. e.g. Rust: https://crates.io/ There are at the moment: 15701 libraries Compared to C++: [VPCKG-C++](https://github.com/Microsoft/vcpkg/tree/master/ports): 702 [Conan.io](https://bintray.com/conan/conan-center): 80
I don't work on MSVC, but I agree with your sentiment. ;-]
Oh, I am not saying he is right, I am just stating his point. I have seen static variables slow down startup times, but that was because they did stupid thing in their constructors (like loading files, etc), or because of some form of run-time code loading (ie: the static vars of library x cause the dynamic lib y to be loaded). also note that on platform with encrypted code (like iOS), the ‚Äúmodern‚Äù loaders will trash all over the cache decrypting code, so there his point about page fault won‚Äôt apply either. 
Good to know, though I honestly can't recall the last time I created a custom iterator.
Seriously, why are people writing something they don't know and can't bother to research properly? [P0174](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0174r2.html#2.1), the paper that deprecated `std::iterator`, clearly explains the rationale: not just the lack of clarity but also general uselessness when used as a dependent base, to the pointer where `reverse_iterator` redefined three of the typedefs yet again in the class body even before the deprecation. Some minimal additional research would have uncovered [LWG2438](https://cplusplus.github.io/LWG/issue2438) whose discussion provides additional reasons for deprecation ("who can be misled into thinking that their own iterators must derive from `std::iterator`, or that overloading functions to take `std::iterator` is somehow meaningful.") And then there's this whole tangent about "some platforms" and defining all five typedefs for `std::iterator_traits`. It's as if C++17 and [LWG2408](https://wg21.link/LWG2408) never happened. You are absolutely required to define all five typedefs, period, for `iterator_traits` to work. (It's also quite misleading to quote libstdc++'s C++03 mode `iterator_traits` implementation rather than its C++11 SFINAE-friendly one without a giant disclaimer.) Again, this is something that only requires minimal research to discover.
On Desktop CPUs (close to) the full memory bandwidth is already achievable with one core, if the code is good (e.g. vector loads/stores).
Strictly speaking, they will never be C++98 conformant because the lowest supported version of C++ is '14. But AFAIK all features that date back to then are now pretty thoroughly implemented (including two phase templates!). Most of the bugs are in newer things like expression SFINAE.
I had to a few times in school until I figured out how auto works (we use C++11).
No it is not. It is quite irritating when people claim that missing features are "just bugs". MSVC has features they did not implement. It is not a bug, it is a compiler without proper C++17 conformance.
&gt; I guess I still misunderstand something here. Ah, no, that one makes things clear ‚Äì definitely a bug. :-] Reduced repro: #include &lt;type_traits&gt; template&lt;typename&gt; struct foo; template&lt;&gt; struct foo&lt;int&gt; : std::true_type { }; template&lt;typename T&gt; bool test(T const&amp;) { if constexpr (std::is_same_v&lt;T, unsigned&gt;) { return foo&lt;std::make_signed_t&lt;T&gt;&gt;::value; } else { return false; } } struct S { }; bool test() { return test(unsigned{}) // fine || test(int{}) // fine || test(S{}); // fires static_assert in make_signed&lt;S&gt; :-[ } Interestingly, if `foo` is removed (i.e. if there's not some incomplete type involved), the error disappears.
CMake 3.11 has now [FetchContent_Declare](https://cmake.org/cmake/help/v3.11/module/FetchContent.html) to download code from git, svn and so on. 
I dunno, never worked with Desktop CPUs. And I doubt that it's true for Threadripper.
Sure thing, here's 16 threads: serial time = 311ms parallel time = 241ms 8 threads: serial time = 304ms parallel time = 233ms And two: serial time = 295ms parallel time = 234ms
Just adding that it also worked fine for scons and autotools for me. It is so close to archlinux's AUR packages that one could almost write a script converting one to the other...
One day they'll even be able to conform to the standard without having to use special compiler flags maybe?
So the most common practice is to just include whatever source code we might need in our project ? I saw this being done in several packages.
I guess it differs from person to person. Right now, I'm using GCC for development because it compiles C++ about 35% faster compared to Clang. However, I also build with Clang from time to time, as it gives warnings for coding issues that GCC doesn't (and vice versa.) Furthermore, Clang has a very nice static analysis tool which I also run often. So IMO it shouldn't be a question of one or the other. Use both.
Something like this `conan search -r all fmt`
IMHO for c++ building dependencies from source (with local cache) is the way to do it.
There is [cget](https://github.com/pfultz2/cget) which can install directly from the source tarballs(ie `cget install http://zlib.net/zlib-1.2.11.tar.gz`) or from github(ie `cget install jgm/cmark`). It can also install binary tarballs as well with `cget install -X binary http://llvm.org/releases/3.9.0/clang+llvm-3.9.0-x86_64-linux-gnu-ubuntu-16.04.tar.xz`. Its cross-platform and builds a local environment to install packages. There is also recipes for libraries that don't provide a requirements.txt file yet.
So just one small question - if one includes the source and uses cmake /make, local caching is available without any other hassle, right ?
[https://docs.conan.io/en/latest/reference/commands/consumer/search.html](https://docs.conan.io/en/latest/reference/commands/consumer/search.html) Generally, the reference is quite helpful: [https://docs.conan.io/en/latest/reference.html](https://docs.conan.io/en/latest/reference.html)
&gt; Seriously, why are people writing lengthy blog posts about something they don't know and can't bother to research properly? Isn't that what blogging is all about?
[removed]
Not that I know of. With C++11 and higher conformance, the team is aiming to drive the ecosystem up, and to reduce dialects and nonconforming code, switches, etc.
You know, that future may not be far away :-)
The framework in-fact provides nginx/apache modules, wanted to abstract all low level code (sql/mongodb/redis/reflection/serialization etc) to a higher level, for eg, if you have a look at this restful service https://github.com/sumeetchhetri/ffead-cpp/blob/master/web/te-benchmark/include/TeBkRestController.h, the json serialization/de-serialization is completely transparent, also in the source file the orm layer abstracts all database calls, yeah so to answer your question, definitely nginx/fgci/C++ has always been there, but frameworks that solve low level interactions/problems and provide easy to use interfaces would definitely help a lot of people. 
Which C++17 features are missing? This is not a rhetorical question; the team is very serious about conformance and I would like to ensure that omissions are fixed as soon as possible.
range v-3 and Hana do not work. This is a known issue, but under MSFT PR speek those are "bugs". In my world those are just things you did not implement. And it it is disingenuous to pretend you did.
That's not how optimizers work. They don't know about anything in particular, they just do the transforms they are able to do. 
You can think of C++ iterators as generalizations of pointers (and therefore arrays). You can always use pointers with STL algorithms, since they are classified as random access iterators and support everything that can be done with iterators in the STL algorithms.
Umm, that guy just gave away his keys!?
Expression templates were originally used to get around the creation of temporaries when doing math expressions on vectors and matrices that allocated memory on the heap. I think the real question is if expression templates are still needed now that C++11 added rvalue references. They may be, but rvalue references definitely confront a major use of expression templates.
I am still getting compiler crashes when using std::forward, somewhat like this: template&lt;typename T, typename... Args&gt; T&amp; InputContext::add(const std::string_view&amp; name, Args&amp;&amp;... args) { static_assert(std::is_base_of_v&lt;Action, T&gt; || std::is_base_of_v&lt;Range, T&gt;, "T must be either an Action or a Range!"); #if defined(WORKAROUND) // this one works fine if constexpr(std::is_base_of_v&lt;Action, T&gt;) { return addAction&lt;T&gt;(name, args...); } else if constexpr(std::is_base_of_v&lt;Range, T&gt;) { return addRange&lt;T&gt;(name, args...); } #else // this one doesn't if constexpr(std::is_base_of_v&lt;Action, T&gt;) { return addAction&lt;T&gt;(name, std::forward&lt;Args&gt;(args)...); } else if constexpr(std::is_base_of_v&lt;Range, T&gt;) { return addRange&lt;T&gt;(name, std::forward&lt;Args&gt;(args)...); } #endif } Also, fold expressions are still totally broken and don't work in 99% of my use cases. Both of those work fine under clang-cl and regular clang (macOS).
All talks by Sean Parent are great, take a look e.g. at [Better Code: Data Structures](https://www.youtube.com/watch?v=sWgDk-o-6ZE) or [C++ Seasoning](https://www.youtube.com/watch?v=qH6sSOr-yk).
I think Sean Parent's [Inheritance is the Base Class of Evil](https://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil) is one of the most eye-opening and enlightening C++ talks out there. Actually, most of Sean Parent's talks are worth a watch. If that talk gives you an appetite for value semantics, take a look at Juan Pedro Bolivar Puente's [Postmodern immutable data structures](https://www.youtube.com/watch?v=sPhpelUfu8Q).
It may be quite personal but I love all of Kate Gregory's talks, mostly because she talks about simplicity in C++ which is something I am a huge proponent of. I'd recommend starting with [Stop Teaching C](https://www.youtube.com/watch?v=YnWhqhNdYyk)
Would it be a trick question to ask for an example that for a given user string input outputs the number of characters in the given string?
I have heard quite a few people mention Sean Parent. I will check these out, thanks a mill :)
What's a character? Don't you need to define a normalization form to get to something so high-level and abstract? I suspect it's more common to want to count code points or even code units. FWIW I think I prefer the design of ogonek. Generic while embedding in the type information appropriate contract like "this range is known to contain valid UTF-32" https://github.com/rmartinho/ogonek 
Oh wow. Didn't even occur to me :)
Right. I wasn't clear. I was referring to the google backend. Search, etc. The stuff where a 5% performance penalty means you need 5% more rivers in the world to generate the electricity to power your infrastructure.
Good talk. Is there anything he missed, anything he said that is now outdated, or anything else I should know and can look up elsewhere?
Some recent talks I have enjoyed: Nir Friedman: What C++ developers should know about globals and the linker: https://www.youtube.com/watch?v=xVT1y0xWgww Chandler Carruth: Tuning C++: Benchmarks, and CPUs, and Compilers, oh my!: https://www.youtube.com/watch?v=nXaxk27zwlk
I like talks by Bob Martin, not necessarily related to C++, but also architecture
I thought the whole point is that iterators \*are\* \(random\_access\) iterators?
I've written a good half dozen recently; not for containers, but for various kinds of sequences. E.g., I've got a row-major order iterator that lets me do things like for(auto [x,y] : box(0,0,10,20)) ... instead of writing the same nested loops over and over.
The last part was, partially because I am still salty about [having to do this contortion](https://github.com/catchorg/Catch2/blob/200d3ad824bb163019a487a44c79f6bc57883c1b/include/internal/catch_test_registry.h#L50-L53) to work-around a MSVC bug, but I have opened bugs against all of the big 3.
I quite like the range_v3 talk - the one that makes a formatted calendar with range algos. Really gives you an idea of how powerful properly expressive C++ can be.
since this stuff is all known at compile time, consider making the interfaces constexpr
I still do not get the downvote. It is because I use Meson and the correct way is CMake? After all wrap *is* a package manager and the solution I use is the same as FetchContent from CMake 3.11, which I just saw in a comment...
Created one recently to retrieve stored objects from file. Works like a charm.
&gt; Sooner or later someone is going to add a value to the enum and forget to add it to the code. What if someone adds a value to the enum and forgets to add it to `ValidParkingPolicies`?
Literally everything by Kate Gregory and Sean Parent. Ben Deane also have several nice talks devoted to funcprog and typisation done right. And Tony Van Eerd's Postmodern C++ because it is brilliant.
also checkout the [awesome-cmake list](https://github.com/onqtam/awesome-cmake)
stuff like std::string and std::find_if aren't constexpr, so it'll take some more work to get there
I am not sure what you are suggesting. It would be hard to make the lookup functions constexpr without going back to making them just a big switch statement. And even if you could, they would be useless for (de)serialization because the values aren't known at compile time. The compiler already does a good job of converting strings in your source into enum values without additional work. 
We did a massive triage and have internal copies of all of them for searching and reference. Many were ported to devcomm for active ones targeting the next few updates. 
The code is stolen from /u/render787, but my own addition to this would be to slap `[[noreturn]]` on it.
Yes you need a definition what a *character* is within a context; [Twitter](https://developer.twitter.com/en/docs/basics/counting-characters) does so for example! I don't think that code points are of any use in most cases! If you want to restrict the length of user input, you do not want to corrupt the text. But if you simply use code points, this could happen. (you need some sort of collation info combined with normalizations) If you have a maximum length constraint by a storage backend - like a relational database - things are getting even more complex, as you need to know how many code units you are allowed to store. So in order to limit the size you must know the final encoding at the GUI or application layer in order to stop user input without corrupting his data. So it completely depend on the context what you need. And in order to satisfy a user it might be a good idea to take a grapheme cluster as base unit. 
I'm hoping the Reflection TS is ready by C++23. The way people currently work around this to make the guarantee is an intrusive, macro-based enum definition, which also isn't great all things considered. 
NICE!!!
and tomorrow?
Might not be the newest, but I have recommended [rand() Considered Harmful](https://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful) to quite a few people who used old C++ material to learn C++.
The `FP_INEXACT` floating-point exception flag may be set by the conversion.
Please don't use URL shorteners - they trigger reddit's spam filter. I've manually approved your comment.
and what do you use for working allocator? what did you try? genuine interest here... 
On an i7: serial time = 0.284000 parallel time = 0.255000 serial time = 0.272000 parallel time = 0.258000 
I took the heavily downvoted comment to mean "The preprocessor commonly used with C++ code is not part of the C++ language, and never has been", as if it were a C-ism that just kind of managed to stick around. In the context of Visual Studios preprocessor specifically, i can see that comment being more helpful.
Have you filed a bug with a repro? Silent bad codegen is high priority.
here's an example to play around with: https://godbolt.org/g/HED96S you're right that it doesn't buy you anything for serialization, but it's still nice that it doesn't generate any code when used in a constexpr context
According to my understanding, Clang's preprocessing ability is built into their front-end and is not obtained from GCC.
If you want to understand Template Meta-programming, concepts and a great deal of the type system, Walter E. Brown's talks are a must (https://youtu.be/a0FliKwcwXE) 
As far as I'm aware, rvalue references don't help with the explicit "vectorization" capabilities that expression templates provide possibilities for. (i.e. computing (a0+b0+c0+d0), (a1+b1+c1+d1), ... instead of computing ((A+B)+C+D), even if it's without temporaries)
Can you file those as separate bugs in Developer Community? That way the compiler devs can keep you updated as they investigate and fix the bugs.
I'm playing with it now, it'd be cool if it supported static builds of the binary so I could just lug the one thing around with me and not worry about setting up LD paths and such, though it seems clang doesn't ship with a static libclang for somereason. Building it myself now \*sigh\*
I don't think this makes any sense. Operators on vectors of a static length could just use SIMD intrinsics. Embree's vector library already does this - https://github.com/embree/embree/blob/master/common/math/vec4.h I don't think expression templates have any bearing here, except for the case of possibly being able to explicitly combine a multiplication + addition into a fuse mult add (fma) SIMD instruction. Either way the lengths of the vectors are known, expression templates would only help with access to an entire expression in the template meta programming. 
That make sense as they have to work on multiple platforms (including ones without gcc) but I'm surprised I've never heard of a clang preprocessing bug.
I do not disagree here. My comment was meant as a guideline when creating wrappers that simply forwards to another function. 
and i should add that i'm sorry about that. It wasn't our team's finest moment in the last year. We lost access to that system and tried to find the best compromise for how to move forward.
can you send me your DevComm item for the one against our compiler? i'll make sure the dev working on that area adds to tests for new preprocessor.
We just fixed this. watch out for it in 15.8p2 or p3. thanks.
\*pointers
&gt; Everything is in the CMake documentation! lol
**Company:** [XLN Audio](https://qa.xlnaudio.com/careers/experienced-c-developer) **Type:** Full time **Description:** At XLN Audio we develop software products for music creation used by professional producers and music lovers around the world. We are looking for C++ developers with three or more years of experience to join our growing product development team in Stockholm (Sweden) and work on the follow-up to our award-winning Addictive Drums, Addictive Keys and Addictive FX line of products. **Location:** Stockholm, Sweden **Remote:** Part-time remote could be okay. **Visa Sponsorship:** Possibly. **Technologies:** C++98/03, C++11, C++14, C++17. Cross-platform desktop application development for Windows and macOS. Bonus (but not a must!) if you're familiar with the JUCE framework, the Lua scripting language, or plugin development for DAWs. **Contact:** Read the full description of our job opening [here](https://www.xlnaudio.com/careers/experienced-c-developer) then send your CV and a cover letter to [jobs@xlnaudio.com](mailto:jobs@xlnaudio.com)
Thanks, fixed.
Thanks, fixed.
I think your \[C\+\+ Seasoning link\]\([https://www.youtube.com/watch?v=qH6sSOr\-yk8](https://www.youtube.com/watch?v=qH6sSOr-yk8) "C\+\+ Seasoning"\) was missing a character.
Videos in this thread: [Watch Playlist &amp;#9654;](http://subtletv.com/_r8hww8k?feature=playlist&amp;nline=1) VIDEO|COMMENT -|- (1) [CppCon 2015: Sean Parent "Better Code: Data Structures"](http://www.youtube.com/watch?v=sWgDk-o-6ZE) (2) [http://www.youtube.com/watch?v=qH6sSOr-yk](http://www.youtube.com/watch?v=qH6sSOr-yk)|[+14](https://www.reddit.com/r/cpp/comments/8hww8k/_/dyn3wh6?context=10#dyn3wh6) - All talks by Sean Parent are great, take a look e.g. at Better Code: Data Structures or C++ Seasoning. [CppCon 2015: Kate Gregory ‚ÄúStop Teaching C"](http://www.youtube.com/watch?v=YnWhqhNdYyk)|[+11](https://www.reddit.com/r/cpp/comments/8hww8k/_/dyn48gq?context=10#dyn48gq) - It may be quite personal but I love all of Kate Gregory's talks, mostly because she talks about simplicity in C++ which is something I am a huge proponent of. I'd recommend starting with Stop Teaching C [CppCon 2017: Juan Pedro Bolivar Puente ‚ÄúPostmodern immutable data structures‚Äù](http://www.youtube.com/watch?v=sPhpelUfu8Q)|[+11](https://www.reddit.com/r/cpp/comments/8hww8k/_/dyn46xl?context=10#dyn46xl) - I think Sean Parent's Inheritance is the Base Class of Evil is one of the most eye-opening and enlightening C++ talks out there. Actually, most of Sean Parent's talks are worth a watch. If that talk gives you an appetite for value semantics, take a ... (1) [CppCon 2017: Nir Friedman ‚ÄúWhat C++ developers should know about globals (and the linker)‚Äù](http://www.youtube.com/watch?v=xVT1y0xWgww) (2) [CppCon 2015: Chandler Carruth "Tuning C++: Benchmarks, and CPUs, and Compilers! Oh My!"](http://www.youtube.com/watch?v=nXaxk27zwlk)|[+3](https://www.reddit.com/r/cpp/comments/8hww8k/_/dyn6aic?context=10#dyn6aic) - Some recent talks I have enjoyed: Nir Friedman: What C++ developers should know about globals and the linker: Chandler Carruth: Tuning C++: Benchmarks, and CPUs, and Compilers, oh my!: [CppCon 2014: Walter E. Brown "Modern Template Metaprogramming: A Compendium, Part II"](http://www.youtube.com/watch?v=a0FliKwcwXE)|[+1](https://www.reddit.com/r/cpp/comments/8hww8k/_/dynewd9?context=10#dynewd9) - If you want to understand Template Meta-programming, concepts and a great deal of the type system, Walter E. Brown's talks are a must ( ) [C++ Seasoning](http://www.youtube.com/watch?v=qH6sSOr-yk8)|[+1](https://www.reddit.com/r/cpp/comments/8hww8k/_/dynky6e?context=10#dynky6e) - I think your [C++ Seasoning link]( "C++ Seasoning") was missing a character. I'm a bot working hard to help Redditors find related videos to watch. I'll keep this updated as long as I can. *** [Play All](http://subtletv.com/_r8hww8k?feature=playlist&amp;ftrlnk=1) | [Info](https://np.reddit.com/r/SubtleTV/wiki/mentioned_videos) | Get me on [Chrome](https://chrome.google.com/webstore/detail/mentioned-videos-for-redd/fiimkmdalmgffhibfdjnhljpnigcmohf) / [Firefox](https://addons.mozilla.org/en-US/firefox/addon/mentioned-videos-for-reddit)
that's *nice* ! currently using basically what is in the article, but with a `std::vector&lt;std::pair&lt;Enum, std::string&gt;`, never thought of using a `std::initializer_list&lt;std::pair&lt;Enum, const char*&gt;` ... frankly I've not see a `std::initializer_list` outside of an argument for a function or constructor; didn't even know they could be used in such a way. I prefer `std::find_if`, and with C++20 it will be `constexpr`; until then, I might use something closer to this.
Herb Sutter's keynotes at CppCon 2015 and 2016 respectively : * [Writing Good C++14... By Default](https://www.youtube.com/watch?v=hEx5DNLWGgA) * [Leak-Freedom in C++... By Default.](https://www.youtube.com/watch?v=JfmTagWcqoE)
Why did you lose access to your own system? That seems very weird
I once had tried design Unicode converting iterator and stump upon a problem that I can't satisfy even forward iterator's requirement as long as reference and value_type is the same. Kind of same problem why vector&lt;bool&gt; can't be a standard container. It seems you have the same problem too.
Uncle Bob? Jesus, no.
Yes C\+\+.
Then use \`stdint.h\`
what's the problem?
&gt; hardware_constructive_interference_size And I, believing you had succeeded, after "zombie", adding "meow" into the standard. :-D
Probably because it's very noisy with minimal benefit, as you pointed out yourself. gcc is technically correct, clang is useful instead.
&gt; Everything is in the CMake documentation! Yeah! The good, the bad and the ugly, it's all there!
Pretty much all talks by Chandler Carruth One from cppcon for example. [https://www.youtube.com/watch?v=2EWejmkKlxs](https://www.youtube.com/watch?v=2EWejmkKlxs)
So the submitted issues are all gone? Anyway, that doesn't sound trustworthy; submitting a bug report (including a test case) takes some time; now starting all over again is... and not known whether the issues are fixed or not. 
He defends terrible ideas that would push the industry back by decades.
The issue was that previously, push\_back was \*huge\* and thus not a good inline candidate. The optimizer made the correct decision to not inline that. If the optimizer gets partial inlining support someday it would have been able to do this but to my knowledge none of the major production compilers do that \(yet\).
That makes sense, thank you.
Thanks, interesting then...
Ugh, I hadn't read the eventually published version of that paper - I collaborated with the authors, particularly on the copying stuff, several years earlier. We were seeing benefits on plain Xeons under 1 MB.
In the C++Seasoning talk, I did not understand the "No raw synchronization primitives" part. Could someone recommend me something to read/watch on this topic? 
such as? I know him for SOLID principles, inversion of control/dependency injection, agile methods etc. which I have in favor
I had to write a few for sorting algorithms and adapters to alter the behaviour of said sorting algorithms, so it might be useful even when you don't write your own containers. That said, it was mostly for use with proxy iterators (where you look for iter_move and iter_swap for specific iterators via ADL, as proposed in the ranges TS). Basically it was mostly to augment existing iterators in a generic fashion with more information. Writing your own iterators falls more into the realm of library writers than application writers.
the issues are still there. it's the web front end for letting the filer checking status that is gone. again, my apologies and we did port many bugs to the devcomm site.
Hm, both repos are by the same author, but the last commit in the ["original"](https://github.com/libogonek/ogonek) is in rewrite branch is dated Jan 2017. The "fork"s devel branch is updated on March 2018. So the relation between these two ins not clear to me. Why create another repository if the author is the same? 
This one from CppCon 2014 is also good: [Back to the Basics! Essentials of Modern C++ Style]https://www.youtube.com/watch?v=xnqTKD8uD64
Ah yeah, totally got that mixed up. Thanks for clarifying! 
Btw, where are the talks from 90s or early 00s? 
&gt; we felt that "MSVC conforms to C++17" was a reasonable one-sentence summary. I don't see what would be wrong with "MSVC nearly conforms to C++17".
Thank you!
A few people have already mentioned Sean Parent, so I will mention that Sean Parent's "mentor", and STL inventor, Alex Stepanov has a lecture series he did for A9, which also includes guest appearances by Bjarne and Sean. Sean gives an extended version of his talks.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8hxynl/boostasio_custom_dns_server_resolving/dyo1pmu/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's simply about trying not to use mutexes and conditions and threads explicitly. If you can, use a task based concurrency system such as Grand Central Dispatch, Thread Building Blocks and such like. Failing that, localize your raw sync primitives by writing your own quick and dirty task queue dispatcher. Even Boost.ASIO's io_service can double as a task dispatcher.
The improvements to `&lt;variant&gt;` were a bunch of metaprogramming changes to reduce the number of class and function template instantiations. The single most important change is the transformation of `_Variant_raw_get`. Previously, `_Variant_raw_get` was a pair of overloads, one of which was linearly self-recursive. That means that e.g. `_Variant_raw_get&lt;2, variant&lt;int,char,double&gt;&gt;` called `_Variant_raw_get&lt;1, variant&lt;char, double&gt;&gt;` which called `_Variant_raw_get&lt;0, variant&lt;double&gt;&gt;` which finally returned a reference to the contained `double`. For a variant `V` with `N` alternatives, that meant stamping out O(N^2) overloads of `_Variant_raw_get` which is expensive even before thinking about the cost of overload resolution. The new code strips off hunks bigger than 1 type at a time - IIRC up to 32 - and `if constexpr`s the two overloads into one, resulting in much faster compiles and MUCH faster overload resolutions for large variants. For small variants, the effect is much less pronounced.
Because it is software? If you haven't noticed yet, software is *hard*.
That's an optional reference (essentially). What if I need it to be owning.
Of course most C++ programmers don't follow the committee's workings, but I do expect people writing blog posts purportedly answering the question "why is X deprecated?" to do basic research (say, a google search) instead of trying to make things up out of whole cloth.
&gt;&gt; The issue was that previously, push_back was *huge* and thus not a good inline candidate. I guess that just putting part of push_back in separate function you call from push_back while leaving happy path should help. And I assume you did that. &gt;&gt; If the optimizer gets partial inlining support someday it would have been able to do this but to my knowledge none of the major production compilers do that (yet). Or he learns about the high level world of C+++. Meaning that he understands .reserve(.size()+x) and then x push_backs mean no realloc. P.S. I just learned that your compiler has a bug there it considers sizeof... result int instead of size_t, do you know about it or do you need a repo? https://imgur.com/a/18H5kop 
`std::mdspan` is in flight.
&gt; I guess that just putting part of push_back in separate function you call from push_back while leaving happy path should help. And I assume you did that. Factoring out the big "what happens if we reallocate" function was indeed the change here :)
If they are bugs in the frontend I'm not really qualified to speak about them, sorry.
Thank you. Here is a repo for the other one also: https://godbolt.org/g/ZfuJiL note that code is not minimal, but when I tried to minimize it bug went away :) and I do not know how MSVC works internally so I can't make educated guesses about how to minimize it so that bug remains. Wrong error is: C2397: conversion from 'int' to 'size_t' requires a narrowing conversion
...those are not C++ features, those are external libraries that do not work due to bugs. Yes, that includes range v3, unless you can point me to the standard text saying it's in C++17.
Thank you! Such feedback is great motivation to write and talk more about it in the future!
I like this recent one: [105 STL Algorithms in Less Than an Hour](https://www.youtube.com/watch?v=bXkWuUe9V2I) it actually delivers! :)
Whooops, really? Sorry, then! Thank you for your answer and time!
Sorry! Thank you for your answer and time! I do appreciate!
I still use tcmalloc ad generally runs fairly smooth and doesn't deadlock with lots of threads. From what I understand google actually takes apart and repackages the MS libc to replace the allocators for chromium.
https://www.youtube.com/user/A9Videos/videos
The easiest implementation for a random_access iterator is a pointer, but sometimes you need to add some trickery because that's not enough. For example, an iterator on the row/columns (depending on how you implemented it) of a matrix. It will jump by a certain number for each value, so you either need to know a compile time or to store a pair of a pointer and the offset between two values.
Seconded. Definitely worth a watch. His talks are also a good resource if you‚Äôre interested in LLVM.
I find posts of fluentcpp are often helpful and misleading at the same time. I am not sure how to feel about it. I just don't have confidence to refer beginners to this blog.
I might be weird but Herb Sutter's [atomic weapons](https://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/). 
You're such a ham
Whenever i read CMake docs, i am reminded of this http://alunthomasevans.blogspot.com/2007/10/old-microsoft-joke.html 
love meson, it just makes so much sense to me
Yes, there are.
Reduced to: ``` using size_t = decltype(sizeof(int)); template&lt;class A, class B&gt; inline constexpr bool is_same_v = false; template&lt;class A&gt; inline constexpr bool is_same_v&lt;A, A&gt; = true; template&lt;size_t&gt; struct integral_constant; template&lt;auto... H&gt; struct if_set_bsearch { static constexpr auto sz = sizeof...(H); static_assert(is_same_v&lt;decltype(sz/2), size_t&gt;); using left = integral_constant&lt;size_t{ sz / 2 }&gt;; }; template struct if_set_bsearch&lt;2, 3, 5, 7, 11&gt;; ``` and filed.
Awesome... Thank you. I guess this is some internal tracking tool that has no access for nonMSFT people? 
https://www.youtube.com/watch?v=rX0ItVEVjHc
https://github.com/ruslo/hunter is fantastic for CMake projects.
My Mac seems to alias `gcc` to mean `cc`/`clang`.
Eric Niebler's ["Ranges for the Standard Library"](https://www.youtube.com/watch?v=mFUXNMfaciE) made it clear why ranges are good, I'll admit I didn't really get them before this. Any talk by Andrei Alexandrescu, he's not only very clever but he's also really clear on his stuff. Not-quite-C++, but Kevlin Henney's [talk](https://www.youtube.com/watch?v=ZsHMHukIlJY) on code organization was really helpful in organizing my code. (Also thanks to everybody who posted their favourite talks, that's also my playlist sorted for the rest of this week!)
It‚Äôs so creepy to that a compiler crashes. That should be the least of its concerns. We're trusting the compiler to do these super subtle code moving and optimizations, sometimes for important apps, sometimes for things that can‚Äôt or won‚Äôt be tested, and the compilers can‚Äôt even perform the basic function of not crashing? It would be like getting on an airplane ready for takeoff when suddenly the tail falls off. You off board, they reattach the tail, and it falls off again. And again. And again. All while sitting in the tarmac. Not sure I‚Äôd trust that plane to fly on.
Last I looked into this was about 4 years ago on Mavericks. I spent a week trying to get gdb and gcc up, never quite succeeded. Some other people just advised me not to bother. 
Yeah, our VSTS; devdiv.visualstudio.com.
If you have boost, this is my take on the issue https://stackoverflow.com/a/35788543/1405424 Drawbacks are that can't assign custom values to the enums and is not very pleasant to the eye. The good part is that the implementation is just a few lines of code, declaring enums in one statement (single ugly macro), and you don't need to maintain two lists enums and strings which is what I cared about. 
Would the answer be useful? Outside of Twitter and really lame interviews, I mean.
Give him a chance and he'll turn your entire unit testing philosophy on its head as well ... for the better.
Where the proposed **Executors** fit in all of this? Does anyone knows?
Is this standard C++, or an msvc extension?
It's Standard C++17. The Standard also requires a diagnostic if the elements have different types, which we enforce via static_assert (e.g. `11, 22, 3.14` is an error here; so is `11, 22, 33L`).
He's fantastic and has a really entertaining style to boot. I wasn't fanatic about organizing my code before this (just adhere to personal and/or company standards kind of a deal), but he made me realise how to write *readable* code. After watching one of his talks, I finally made a clang-format config and have used it ever since to great success. 
It's funny, though, right? Because as much as compilers crash, it's almost unheard of (I'm looking at you gcc 4.9.x) for them to generate incorrect code.
Sure, a use case would be to calculate a texts lix number. - https://en.wikipedia.org/wiki/Lix_(readability_test) - http://www.readabilityformulas.com/the-LIX-readability-formula.php
That inheritance talk was great! Thank you
Looks like the optimizer still has trouble with coroutines. Given a simple case like this: #include &lt;experimental/coroutine&gt; #include &lt;experimental/generator&gt; std::experimental::generator&lt;int&gt; foo() { co_yield 0; } int main() { auto sequence = foo(); return *sequence.begin(); } The compiler is still generating code that allocates the coroutine on the heap and then makes indirect calls to run it and tear it down. That's at full optimization with LTCG enabled. 
I'll reach out to that fellow to see about finding a way to incorporate his feedback.
Thank you for this! That is beatiful
CppCon 2014: Jon Kalb "Exception-Safe Code, Part I/II/III" - https://www.youtube.com/watch?v=W7fIy_54y-w - https://www.youtube.com/watch?v=b9xMIKb1jMk - https://www.youtube.com/watch?v=MiKxfdkMJW8 CppCon 2016: Nicholas Ormrod ‚ÄúThe strange details of std::string at Facebook" - https://www.youtube.com/watch?v=kPR8h4-qZdk 
Since it's header only, it should be fairly easy to create a Conan recipe for it.
This is an early-stage, but already quite usable, project to create a Turing-complete replacement for cpp, which allows for complex parsing, recursion and compile-time variables. You can [try it online](http://exosphere.kafuka.org/macros-test/) in a [wandbox](https://github.com/melpon/wandbox)-based "playground" I spun up, though I haven't stresstested it and so chances are it will go up in smoke the moment more than two people try to use it at once. For an example of the sort of things you can do in it, [here's an implementation of ML-style algebraic datatypes](https://github.com/blackhole89/macros/blob/master/examples/algebraic-datatypes/algtypes.cpp) in it.
It generates slightly more code if you actually do something with the values you compute... [https://godbolt.org/g/kEwFHC](https://godbolt.org/g/kEwFHC)
Exactly what I needed, thank you. But I had to replace std::initializer_list with std::array with VS2017.
The thing is that Steve guy is probably now a distinguished engineer at MS. lol.
Build in internal CUDA support \(like LLVM\). NVIDIA doesn't move on this and I'm still stuck on 2015.
Is that PJ?
I see. Thanks for the clarification.
Ah yes, you are right, this is a better way, thanks. Though when i wrote this code some time back it was anyway supposed to be compiled for systems with C++98 compiler only, as far as i remember
Underrated. His talks are great all around, Stepanov's that is.
I am a big fan of this talk by Mike Acton about 'Data Oriented Design' from CppCon 2014: https://youtu.be/rX0ItVEVjHc
First of all, I'm not dunking on the project itself, great effort and it seems cool. Anything to replace the preprocessor is ++ in my book. But... I think the biggest stumbling block to any adoption are the dependencies. Let's say I start a simple graphics project and say "you need SFML and fmt and spdlog to build this thing". That in C++land is effort enough, but then I say on top of that: "yeah, install Haskell and hackage and the dependent packages" (also you might have to dick about with environment variables to make it go, I know I did). Pretty much no one will do that, which I would see as an impediment to success for this project.
Conan, maybe? ¬Ø\\\_(„ÉÑ)\_\/¬Ø
I think this is because historically platforms used other representations of negative numbers, e.g. sign+magnitude, which wrap differently. It also allows for clamping on overflow.
The current plan is every three years - it's been held to pretty well with C++11, 14, and 17 so far. The problem is if they actually hit their release target for C++20, they'll follow with three more in the _same_ decade: 23, 26, and 29. X,Y,Z,A? Given we already had XYZ, might as well wrap to A now.
Seems really nice, and interesting. I toyed with it online. I look forward to seeing what this will turn up to be :)
While the project has some interesting syntax, it's a little hard to see how this would be any more useful than (or possibly even as useful as) m4 in practice. (Not that I would use m4 with C/C++ in anything other than a limited code generation way, as flex and bison do, but then I wouldn't want to use anything other than the standard C preprocessor for much as it would be too cumbersome to work with the standard library.) 
Thanks for checking it out :)
First of all, this is not a criticism of your project, it's a dependency issue, mainly ghc/Haskell. See, my current dev environment is Windows, so it's manual install time for me. I haven't tried to install Haskell on my Debian build box (stable), but it looks like it would be sorted out over there. I will eventually give it a go, thanks for the notes here. As for the environment, on Windows it didn't set the paths correctly and made hackage unusable unless you manually set the env vars to point to right places. You might want to add that it's tested on Linux/Debian. But I'll give it a proper shot and let you know what you need on Win to make this work. 
I guess you have to do `'a' + ('z'-'a'+1)%26`... You _can_ do it with masks, but because 'a' is at offset 1 in its ascii subrange and not 0 it's a bit weird: `0x60 | (('z' &amp; 0x1f)%26 + 1)` (you would normally subtract 1 from the value of `'z' &amp; 0x1f` to get a 0-based index, butas we're adding 1 that cancels out. We then add +1 after the mod to return to 1-indexed letters) The best code is probably a hybrid approach: `'a' + (('z' &amp; 0x1f)%26)` - which doesn't contain a +1 at all and so is _really unclear_ as to what it's doing!
How does it compare to Rusts `macro!(a, b, c)` system? More, equal amount, fewer features? Deliberately omitted something? Anything C++ specific in there, or could it be used to replace e.g. `m4`?
Well, the criticism that it's hard to set up is valid - but I'm grateful for all feedback! I haven't developed anything under Windows since MSVS6 days (let alone tried to run Haskell on it...), so if you could let me know what it takes to set up an appropriate environment, that would be great. For now, I have added some of this information to the README.
http://reddit.com/r/cpp_questions
Personally, I'd want it checked in debug, fast in release :)
I will look into it. Being on Linux, I'm somewhat in the "package managers that are not the system package manager are evil" camp, but I can see how you would want it on Windows(/Mac?).
Could you just pass `-Dprivate=public -Dclass=struct -Dprotected=public` ? Should make _everything_ public.
in some sense, yes. but you probably want to also look into ccache \(very easy to add to a cmake project, does wonders for compile times\)
The standard doesn't allow for partial deduction, am I correct? So I can't write: `std::array&lt;int&gt; arr{ 11, 22, 33 };` and get an `std::array&lt;int,3&gt;`?
Windows 7 (8 and 10 similarly) * Have git installed (https://git-scm.com/) * You need either Visual Studio or mingw/cygwin installed to build * MinGW: https://nuwen.net/mingw.html * Visual Studio: https://www.visualstudio.com/ (Community Edition is free) * Test on the command line: "nmake" for Visual Studio or "make" for MinGW * for VS use "Tools &gt; Visual Studio Command Prompt" for this * Install Haskell, "Full" installer from here https://www.haskell.org/platform/windows.html * In the "full" install, the prerequisites are already installed, otherwise use cabal-install to fetch those (mtl and parsec) * Use defaults unless you know what you're doing * Now clone the repository somewhere convenient * For instance: cd c:\dev git clone https://github.com/blackhole89/macros.git * Build: * Visual Studio (again, from the "Visual Studio Command Prompt") * cd \dev\macros * nmake -f Makefile * MinGW * cd \dev\macros * make * Now you should have a "macros.exe" in the root of the project(in this example \dev\macros\) * Copy it somewhere that's in PATH * mkdir \tools * copy macros.exe \tools * set PATH=%PATH%;C:\tools * Run "macros", read the documentation at https://github.com/blackhole89/macros
Yes really! Unfortunately, there's still a bug or two preventing the use of range_v3 :(
I think as an experiment it is nice. Though, I think D string mixins with foreach and others are easier to manage and more understandable (for me), since it follows more closely regular language foreach for repetition. I think the way to go should be more similar to D's than this macro system. Of course, the article does not say or suggest anything about standarizing this :) 
interesting, why didn't initializer_list work?
that's the exact same code it generates if you just: std::cout &lt;&lt; "a"; std::cout &lt;&lt; E::A;
What I've heard about the preprocessor begs to differ.
This would fail on: template &lt;class T&gt;
for such a use case why wouldn't you just generate svg file and possibly launch it in a default app (browser)? Adding support for svg rendering is hard. There are tons of details like rendering affine transformations, bezier curves, fonts, text alignment, gradient/radial filling, animations, css styling etc. I don't think compiler vendors are interested in implementing all this. And if they don't it's kind of useless as 95% svg files won't work and people will use real svg library instead. Another thing I don't understand is why to couple svg parsing and rendering into single functionality? Look at nanosvg it parses svg and stores transformed elements in a set of polygonal (bezier) curve shapes each with color, line width and other attributes so it's suitable for rendering. That has a great value on its own but it's the opposite of what I would imagine should go into standard library. Windowing with possible context creation, event handling and independent algebra lib as demonstrated by jube_dev is far more useful and yet much more lightweight. Even without widgets library this could still be used for something useful.
true - but now you should be able to use typename everywhere (since they fixed the specification of template templates).
why waste time say lot word, when few word do trick
What was the warning?
not really... I saw one from Boostcon where he want on some boring useless rant about transistors... But C++ Seasoning is a Modern Classic :D
&gt; gcc has -fsanitize=thread which is insanely useful So does clang. IRC, it got it even a bit earlier. 
Beside mentioned ones feel free to check out videos from [Kris Yusiak](https://www.google.de/search?q=kris+jusiak+c%2B%2B)... 
Honest question: do you understand that code(calendar)?
Stepanov videos are mostly useless and slow and filled with rants. I strongly suggest people to skip them. But sure, if you want to spend 20 hours to see how to write std::find go ahead...
Yeah. It's pretty well explained in the talk as well.
Yes, I am using PCM for cache\-related benchmarking, but it's not well suited for benchmarking functions, which is why I am asking for libraries. (I don't know if PCM can be used this way, though...)
Why not release this as single binary ? At least for Windows this would pretty easy to use then.
This is very interesting, I'll give it a try.
This is exactly what I am seeking. I use Google Benchmark but I am not really liking it mainly because it must be built as a library.
I also love her talks. I also want to make a recommendation for the podcast "cppcast" hosted by Rob Irving and Jason Turner. It's wonderful!
If I could just drop it in my source without recompiling a library that would settle every other discussion about alternatives to Google Benchmark \(which I use\), a header\-only library would be, for the projects I am involved in, better.
Case of sour grapes there, mate. No wonder you get voted down all the time. I'd trust Stepanov and the people who trust him, like Bjarne and Sean Parent, over some reddit no-name any time. I do suggest to others that, if you're looking for homework solutions, do as /u/ZO1dbrg suggests and skip them. Stepanov isn't there to teach people how to code or be cute with tricks. Stepanov's lectures are there for insights into considerations that pass most people by. For advanced programmers, Stepanov gets down to the essence of algorithms and a practical application of algebraic thinking.
That's up to the author I guess. It does look like that the executable built has no big dependencies: C:\dev\macros&gt;dumpbin.exe /dependents macros.exe Microsoft (R) COFF/PE Dumper Version 14.13.26132.0 Copyright (C) Microsoft Corporation. All rights reserved. Dump of file macros.exe File Type: EXECUTABLE IMAGE Image has the following dependencies: dbghelp.dll KERNEL32.dll msvcrt.dll PSAPI.DLL SHELL32.dll USER32.dll WINMM.dll WSOCK32.dll All of those should be standard with Windows as far as I know. Maybe a Haskeller who has done this before could feed in? 
Simply keep an unstripped version of your program - done.
Nicely done. I never thought of using initializer_list&lt;&gt; like that but it makes perfect sense. I don't think anything in the standard prevents it an it alleviates the need for the size parameter to std::array&lt;&gt;. The great thing about the templated lookup functions is that it doesn't matter what container you use (array(), initializer_list&lt;&gt;, etc), the same technique works whatever you give it. Your code uses optional&lt;&gt;s as return values. I can see your point and I disagree but that is a whole other discussion. 
&gt; Your code uses optional&lt;&gt;s as return values. I can see your point and I disagree but that is a whole other discussion. yeah. not because i have a problem with exceptions, just that you apparently can't throw in constexpr functions. feel free to plug in expected&lt;&gt; or other constexpr-compatible error handling
&gt; std::initializer_ I don't know, it gave me C3245 errors, I suppose it's fixed with the last version of the compiler but I'm having trouble to update it. (p.s. yes :))
Thirded. I like this one: https://www.youtube.com/watch?v=fHNmRkzxHWs
Why not just put it into a GitHub repo? Then others can just make a pull request to add stuff.
Why implement something in the language when you simply can ship it as a library?
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8i6ybx/why_are_complex_numbers_implemented_in_the/dypcyyw/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Because we prefer class abstractions, they work like all other classe abstractions.
Exactly. A general theme in C++ is ‚ÄúPrefer library implementations over extending the language even further. If it‚Äôs not possible to implement as a library, extend the language to make it possible.‚Äù
Clang isn't widely available for any of the interesting targets ( cortex-m, xtensa ) 
Still have to include complex.h. The way c++ does it is a template class that can take in a float,double, long double, etc. Also libstdc++ for example actually just encapsulates C's complex anyways.
An example for exactly what? If you are refering towards the manipulation of a string, I can provide you with an example taken from the twitter link in Python3: s = "Cafe\u0301" &gt; 'CafeÃÅ' s[:-1] &gt; 'Cafe' Oops... you cut the string at the *wrong* place (the command tells Python to produce a new string by taking the whole string besides the last *code point*); at least a user would think so, if you mangle his name in you app (the *eÃÅ* becomes a simple *e* without accent!). Even worse if this will be needed for later authentication, for example a plane ticket - your identity card would spell the name differently... bad thing! If your lib is not aware of code points, it gets even worse, as you could produce *invalid* data. In raw C++ you only deal with *encoded* byte strings in ``std::string``. So in order to split a string correctly, you **can't** just *take the left X bytes* in order to satisfy a database field (or some other IO format, that limits the lengths of data, like XML for example) Let's take the same example from above and cut the right part off in order to fullfill an artifical byte length restriction: s.encode("utf-8") &gt; b'Cafe\xcc\x81' s.encode("utf-8")[:5] &gt; b'Cafe\xcc' crippeld = s.encode("utf-8")[:5] crippeld.decode("utf-8") --------------------------------------------------------------------------- UnicodeDecodeError Traceback (most recent call last) &lt;ipython-input-25-ab2276bced8a&gt; in &lt;module&gt;() ----&gt; 1 crippeld.decode("utf-8") So wen can easily manipulate *encoded* data (second command just takes the first 5 bytes out of the ``bytes`` - that is Python's equivalent to ``std::string``) and produce a crippeld byte string, that is no more *valid* regarding its encoding. So a good unicode abstraction layer should give you good tooling to deal with different aspects of the whole topic; especially with providing a view to the *grapheme cluster* level in order to prevent you from mangling strings.
It might help to stop thinking of it as package managers. It's in a completely different problem space after all. 
Indeed, it has been fun working on MSVC for the last four years - but not for the reasons you write here. Oh, yeah, before that I spent more than 16 years working on GCC. You have smart hardworking engineers in all corners of the C++ community and tool providers. You would be surprised by just how much good work and ingenuity goes into MSVC. Hopefully, one day you might be able to see for yourself what I have witnessed. If you aren‚Äôt using MSVC, give it a try and let me know what issues you run into ‚Äî you can reach me at my initials at microsoft dot com.
&gt; It depends on the algorithm. ...and the machine it‚Äôs running on, although most modern CPUs have a somewhat similar architecture.
Do you have a link to all of Stephen T Levavej's series?
ok. I think that's the same command as Ctrl-, f but it would be good if you could confirm that. Is the pause the time between selecting the file in the drop down and how long it takes the file to open? or is it how long the drop down takes to appear? how reproducible is this? would it be possible to capture it using the report a problem tool in the IDE which can grab a perf trace?
&gt; you apparently can't throw in constexpr functions Not unconditionally, but if the `throw` is inside some condition check, the function is still valid in a `constexpr` context as long as that condition doesn't hold.
Correct, that is not yet permitted. Mike Spertus has been looking into adding that, though.
Billy O'Neal.
Not sure if it's _all_ of them, but it's a start: https://channel9.msdn.com/Tags/stephan-t-lavavej
[http://clang\-developers.42468.n3.nabble.com/builtin\-expect\-hint\-ignored\-td4056241.html](http://clang-developers.42468.n3.nabble.com/builtin-expect-hint-ignored-td4056241.html)
Maybe it just decided to ignore it given the function is only 8 instructions long..?
Out of interest and turning things upside down, you can go the other way and insist that cl.exe bundle the debugging symbols into the file rather than spinning them out into separate pdb files, with the switch /Z7 https://msdn.microsoft.com/en-us/library/958x11bc(v=vs.85).aspx
Interesting [https://godbolt.org/g/XTCozk](https://godbolt.org/g/XTCozk)
Great talk - props to him and the community for having a talk like this happen.
thank you very much - that explains my confusion, because i know i've seen it work before
It's mainly the time from hitting enter to until the tab actually shows with the file in it. It's almost the same as CTRL-, I'm not sure if it makes a difference but I'm just using GoToFile (not GoToAll or what CTRL-, is called). I just reported an issue and attached a recording (good idea :) ), I'm not sure how to send it but it's title is "Slow Edit.GoToFile" by srekel. I opened a random file and it probably didn't take a second for it to load but half a second maybe? (There are two attachments in the issue, one of them you can ignore, I was just confused how the recording feature worked)
This is it, I made other branches more expensive and code flow assembly code looks the same: https://godbolt.org/g/4VTA9u
I am slowly realizing, that there are three steps to building a project and since some are already covered with existing tools, it is important to keep them separate: 1. Preparing dependencies. This bit is the biggest problem for C\+\+. However, my projects actually tend to mix languages and a good solution would be able to manage dependencies in language\-independent way, with plugins for pulling from the various existing walled gardens \(cpan, pypi, nuget, maven, ivy, npm, cargo etc.\). 2. Configuring the project. Because everybody is a special snowflake and want some special functionality, a practical solution has to include some scripting capability in this step, though it should still aim to make the common cases declarative. 3. Building the project. This step should be *fast*, so it should work with complete dependency lists generated in the previous step and run minimum logic, just comparing timestamps and maybe looking for new files. The step 3 needs to be compatible with existing IDEs, which effectively means step 2 must be able to generate project files at least for Visual Studio and for XCode, and for their language support to work, it must use the native build steps. CMake does this and for all its issues there is so much work in it that it is not practical to replace. And when it's not generating IDE\-specific build definition, the ninja build tool delivers the raw performance. So what would be interesting is a tool for step 1 that could mix and match existing tools that already handle steps 2 and 3. And again, it does mean more than just C\+\+. I often ended up working on projects mixing languages, whether it was a C# tool for generating resources for the C\+\+ application, or hybrid application with C\+\+ core, HTML\+JS front end and some Java and ObjC glue in Cordova plugins. And in the later case, there are several modules with both C\+\+ library and Java and ObjC glue, so for a package manager to be useful there, it would really have to understand mixed\-language packages. Of course the tool has to understand that different components have different targets‚Äîboth because build dependencies need to run on the build machine, while runtime dependencies run on the target, and because languages running on interpreters or virtual machines have different sets of targets than languages compiled to native code.
Why does it need `wsock32`, `dbghelp` and `winmm`? 
There are things like this https://chocolatey.org/ but there is no official package manager for Windows. It doesn't work like that. 
I don't know why you're comparing ~~apples to oranges~~ GCC to Clang there, but using `__builtin_expect` _does_ affect the codegen, just maybe not as drastically as you would like: https://godbolt.org/g/qjDWJ5
No, sorry; my name just adds to confusion. It also breaks a lot of web pages when you add the last name. :P
Compilers are a law until themselves these days
I was proving your point, if you completely ignore that loop, both clang and gcc do the same thing. test edi, edi jne .LBB0_2 mov eax, offset .L.str ret ---------- mov eax, OFFSET FLAT:.LC0 test edi, edi jne .L12 ret
I misunderstood, sorry.
I can see the argument for the exclamation point and thought about this for a while, but decided in favour my current way of handling it for three reasons in the end: * I consider the ability to define drop-in replacements for functions and keywords to be a strength of the C preprocessor. It helps immensely with debugging (and often refactoring) to be able to, say, `#define malloc(a,b) write_log(a,b), malloc(a,b)`. * If you are including code where some joker could put `#define true false` without you noticing, you have already lost. At the end of the day, you can grep for `#define true` much more easily than for a missing equality sign in something like `if ( userid = 0 ) { /* do root stuff */ }` anyway. * Even if you are not a big fan of overriding keywords at global scope (cf. for instance the `silly-reflection` example with `class`), there's a particular idiom that I find very useful which is enabled by the current way of doing it, namely: @define domain_specific_language_zone { ( { @^$body } ) =&gt; ( /* Overwrite the whole standard language! */ @define case { ... } @define for { ... } @define if { ... } // ... $body // Process the contents of the curly braces in your domain specific language! // ... @undef if @undef for @undef case ) } Regarding code locations, I'm already doing it at the moment (using `#line`), but there is a small weakness in that it is only emitted on newlines (so if you have an error in a macro that looks like @define macro { () =&gt; ( error ) } macro you will get an error reported at the line containing `macro`, whereas @define macro { () =&gt; ( error ) } macro will report one at the line with `error`. I intend to fix that, and may also switch to using the C preprocessor's undocumented but slightly more richer `# linenum filename flags` format (see [here](https://gcc.gnu.org/onlinedocs/gcc-3.2/cpp/Preprocessor-Output.html)).
Seems useful. A time ago I was needed to implement some Haskell paradigms over C++, preserving generality, it was hell. It seems as great solution to design and implement DSL over C++.
I figure the Windows build of `ghc` pulls those in automatically regardless of need... the Linux binary only needs 0x0000000000000001 (NEEDED) Shared library: [libgmp.so.10] 0x0000000000000001 (NEEDED) Shared library: [libm.so.6] 0x0000000000000001 (NEEDED) Shared library: [librt.so.1] 0x0000000000000001 (NEEDED) Shared library: [libdl.so.2] 0x0000000000000001 (NEEDED) Shared library: [libffi.so.6] 0x0000000000000001 (NEEDED) Shared library: [libpthread.so.0] 0x0000000000000001 (NEEDED) Shared library: [libc.so.6] 
This is great, thanks so much! Can I add this as a Windows section in a prospective `INSTALL.md`, and would you like to be credited in it somehow?
Can you give me a pre-built Windows binary? I can't set up an environment for building it myself right now. 
I'll look into it once I get a hold of a Windows machine. (Maybe /u/zom-ponks can upload their binary somewhere?)
Clang is using a branchless implementation, whereas the gcc target code uses a branch. Branchless code can be an advantage because branch mis-predictions are huge performance drains. If a case is sufficiently likely, it can still be an advantage to branch past unlikely-case work. Either implementation seems reasonable with my admittedly very limited knowledge. The hint is after all a hint, not a way to demand any particular implementation. 
Yes - our detection is not perfect (it occurs once, the first time an STL header is included, and we exempt `new` due to longstanding evil), but we do emit errors which point to the offending macro.
Me too, she is my favourite presenter, besides Andrei Alexandrescu.
Can't believe they left out starts_with()
Compilers ignore lots of hints, usually because they know better. The `inline` keyword is a big one that doesn't do anything for actually inlining code these days.
hi. I opened your trace with the devs in question. it looks to me like you are on 15.5 in your trace and this is fixed in 15.6 and later based on the blocking call stack. We think we fixed this around November.
Discard != not parsed and treat that substatement as token soup. What `if constexpr` does is *not instantiate* the branch not taken. Outside of the context of templates with a value dependent condition, we're just not odr-using anything in the branch not taken. But it still has to be valid code. This calls for `#if __cplusplus &gt;= 202001L`
An ugly-ish workaround would be to template&lt;typename StdStringView, typename = std::enable_if_t&lt;std::is_same_v&lt;Buf, std::string_view&gt;&gt;&gt; bool isHttpResponse(StdStringView buf) which allows keeping the remaining code, at the cost of making the signature less clear.
It rustles my jimmies that C++ has to wait until 2023 just for a feature most languages have had for over a decade. I start to feel like modern C++ has everything I require to write good software... until I need to simply convert between a string and an enum. I hate feeling like I'm coding in the Soviet Russia of programming languages.
Thanks! I kind of thought that it could have a connection with the function not being a template.
That would still be ill-formed, no diagnostic required, since the condition isn't dependent.
How 'bout (hurk) template&lt;typename T, typename = decltype(std::declval&lt;T&gt;().starts_with(HTTP_1_X))&gt; bool isHttpResponse(T buf);
Does inline even count as a hint for inlining on modern cpp anymore? Reasonably sure that it only tells the compiler to ignore ODR for functions implemented in headers. 
What if I don't need it to be polymorphic? It's an allocation and a needless indirection for absolutely no reason.
Appeal to authority
In a discussion without clear falsifiable facts, it's a useful shortcut. 
/u/Chippiewall /u/PhilipTrettner that's a myth : https://blog.tartanllama.xyz/inline-hints/ All relevant compilers use the `inline` keyword as a hint for inlining decisions
Keep up the good work! I can't wait for Hana to be usable by MSVC users.
Shhhh - you're not supposed to tell people, or the obsessive inliners might come back. I did have the idea that `inline` is important for header-only libraries even though the relevant functions may well not be inlined, and that most compilers have non-portable extensions to say "please please please inline", so it's a bit surprising really that inline isn't ignored for inlining purposes. I wouldn't be surprised if there was a time when `inline` was ignored, but since then overuse of the keyword has reduced so the reasons to ignore it completely are much less. After reading the link, I do have some concern that extensions IIRC use non-standard keywords, so the presence of an inline keyword doesn't necessarily *the* `inline` keyword, but if that was an error, I assume someone who knows would have noticed by now. 
&gt; a feature most languages have had for over a decade. What other modern language has static reflection?
I meant any kind of reflection in general, and specifically the basic enum features we're talking about, which is something easy to do in C#, Java, Python, etc.
It's also done at runtime, which is an entirely different animal than what C++ is aiming for, even if you can use both to accomplish this particular thing...
Nice article - I've not heard the terms "sum type" and "product type" before, interesting. Variant is so useful I wonder how I used to write code without it. Having to work in C++11/C++14 codebases makes me realize just how restricted I am without it. By the way, I encourage everyone to avoid using `holds_alternative` unless you only care about one type - in general you should use `visit` with an overloaded set of lambdas or a single generic lambda with `if constexpr`s so you can get a compile error on code that doesn't account for every possible type. You can also use variants for static polymorphism with generic lambdas for `visit` that just use duck typing and don't care about the underlying type. This effectively means you can have stack-allocated polymorphism with standard copy and move ctors, no vtables or heap allocation required, no clone pattern needed.
My point is most languages let you go `MyEnum.ToString(value)` or `enum.value.name` or whatever. Whether C++ would accomplish that at compile time or runtime is not important. It's a missing feature in the language and it sucks that we have to wait so long for that hole to be filled.
Link?
&gt; Whether C++ would accomplish that at compile time or runtime is not important. \*sigh\*
Not only .net, they also have a lot of native (C++) packages. Many don' work out of the box with VS2017 because they weren't updated and the assertions they make check for only up to 2015, but a research and replace of the version numbers will work (since the ABI is compatible).
I am not saying what you are talking about is not valid, but your reply to my comment is not directly relevant to my concerns or the context of the thread at large ("Converting enum classes to strings and back"). From my perspective as a C++ user, I don't care about how enum&lt;-&gt;string is implemented, I just want that feature to be present in some usable form (like it is in most other languages).
What I'm talking about is directly relevant to the statement of yours that I quoted; indeed, giving context is the purpose of quoting. What you said is that "C++ has to wait until 2023 just for a feature most languages have had for over a decade"; what I asked, and you strawmanned, is what language has what C++ is planning (compile-time reflection)? The context of the thread at large isn't what I was replying to, and moving the goalposts doesn't help your argument. ;-]
This subreddit isn't for programming help. Please read the rules.
My point remains that it sucks having to wait until 2023 to do enum&lt;-&gt;string. I understand there are implementation details to consider, but other languages dealt with that too. There isn't really anything to argue about without going in circles.
If it helps, do add it in documentation. A link to this post is sufficient for creditation I think.
&gt; so you can get a compile error .... that consists of more than ten thousand letters, longer than can be posted here. ... or see it silently work thanks to implicit conversion.
&gt;Variant is so useful I wonder how I used to write code without it. Having to work in C\+\+11/C\+\+14 codebases makes me realize just how restricted I am without it. Could you give me a couple of examples of stuff where variant helped implement/simplify things? I'm new to the concept.
Her pluralsight course is pretty good.
Right, it's here: https://drive.google.com/file/d/10qCA2RAfDwJ2AFrUusOyXXpzOwzNv6Yu/view?usp=sharing Now, I don't know whether you need the full Haskell runtime for this, but I think it should work without.
I'm happy to build this for you, of course, but does Github accept built executable PRs?
&gt; https://drive.google.com/file/d/10qCA2RAfDwJ2AFrUusOyXXpzOwzNv6Yu/view?usp=sharing Again, do report if it's not working for you, I think it's alright but you never know.
Yes, that sucks (I guess, not ever having felt the need), but not as much as it sucks for users of those other languages, forever stuck with runtime reflection since it's "good enough" ‚Äî we get something objectively better. Yes, it's going to take longer, but in the meantime it's possible to write a &lt;100 SLOC library to do _this_ regardless. I'm not arguing with you; you made a comment with an opinion, and I replied with an opinion. Why are you even posting if you don't want replies? Yeesh...
&gt; Spending 3 hours to write std::find_if is waste of time. If it takes you that long to write a trivial algorithm, that's entirely your problem. That Stepanov's content goes over your head is entirely your problem. That this comment I'm replying to is obviously going to get downvoted into oblivion is entirely your problem. There's a pattern here, and Stepanov isn't the root of your problem.
&gt; If it takes you that long to write a trivial algorithm, that's entirely your problem. I was referring to the speed of Stepanov lectures. I can write find_if quite well, thank you. As for downvotes: mob mentality does not count as truth.
I have to nominate Eric Brumer's talk: [Native Code Performance and Memory: The Elephant in the CPU](https://channel9.msdn.com/Events/Build/2013/4-329)
if you are interested in template metaprogramming then Walter brown's 2 part talk from cppcon (14?) is great. then loius dionne's talks are a cool look at a new way to think about metaprogramming ( making it look like values when it is still type manipulation). Hartmut Kaiser's cppcon talks are great at showing what the new c++ 'futures' will bring to the table. arthur odwyer does nice talks breaking down language features from scratch (lambda's, futures, etc). Chandler Carruth's benchmarking talk is cool. Nicolas Guillemot has a talk on spmd which shows vectorization in c++.
&gt; @gregcons: i missed the part where you were elected in charge of #learn, set everyone's goals, and were authorized to rebuke people who discussed things you didn't agree to just yet My hero.
&gt; Are you gonna cry now? Grow up. If you can't hack any criticism, best just to stop. &gt; Stepanov is outdated and boring. TMP is ugly but useful. Spending 3 hours to write std::find_if is waste of time. Sour grapes. In his lectures, it's amazing how the attendees overlook crucial things for seemingly simple algorithms. That you keep bringing up the find_if examples shows you haven't looked at probably more than one of his lectures. But hey, whatever. Your sour grapes is fully on display here.
the meaning of inline has changed in standard. So it may be better to use something like BOOST_FORCEINLINE or BOOST_NOINLINE.
I watched him spew random nonsense about sorting also... Problem here is that I know he is full of sh*t, while you believe he is some genius, so you dont see his lectures for crap they are.
&gt; Problem here is that I know he is full of sh*t And how do we know you're not full of shit? Because you sound very much like you are full of shit. What work have you done? Put up your own work if you're not scared.
Who #defines `new`? I know of a codebase that #defines `dynamic_cast`.
&gt; What work have you done? Put up your own work if you're not scared. LOL... Like I said STL is amazing, but guy did that 30 years ago... And for the past 20 years he was a delusional old guy that knows nothing about modern C++ programming. If you really saw his horrible lectures you know he also said he does not like Scott Meyers. Between senile clown and Scott Meyers I pick Scott. Hard choice it was, not.
What I don't understand is : why wait until now to use varian ? There has been an implementation for near to a decade in boost and many nice variant libraries came out with c++11 &amp; 14 - mpark variant, eggs variant, etc
Don't cry. Just because he said he didn't like one of your heroes. :) All is revealed. Sour grapes, and a bad case of projection on your part. :) And yes, I did see the bit where he said he did not like Scott Meyers. So? Scott Meyers, by his own admission, has never even been much of a professional C++ programmer, having gone into teaching very quickly. Apparently that's okay for you. Here's a hint: no one is perfect. Alex isn't, and Scott isn't. What Alex says is not gospel, but neither is Scott's books. I found many of Scott's talks to be overblown about difficulties of certain C++ features, and in fact I think has contributed FUD. Again, what have you done? Put up or shut up.
Disliking Scott Meyers shows that Stepanov is a clown that knows nothing about real C++ development. You can try to spin it and downplay it, but it is a simple truth.
That completely disables the function so requires overloading, i.e. the opposite of using constexprif in the middle. As far as I understand the above comment, making a type trait `has_starts_with&lt;StdStringView&gt;` to use instead of the version check would work though. 
&gt; why wait until now to use variant ? Valid question. boost::variant has been around for more than 15 years
Funny how you're the one with a hero worship problem after accusing me of one. You're the clown with a built-in argument-from-authority fallacy. Scott Meyers has not been a professional programmer for a very long time. I would not equate Scott Meyers books or talks with "real C++ development", despite being really helpful with certain language usage hints.
&gt; I would not equate Scott Meyers books or talks with "real C++ development" Well, you are wrong about one more thing... Shocking, not. 
I even need reasons for that? The only real reason is that there's nothing else good
I think the power of visit is that it actually accepts multiple variants. Sometimes it can beautify an ugly mess of nested ifs.
I totally love Visual Studio. I've been using it since 6, so almost 20 years. However, all the recent changes to Windows 10, many of which are absolutely hostile to users, have made me investigate other platforms and IDEs for the first time in my career. In fact, it's been so frustrating that I recently ported our desktop app's UI to OpenGL \(thanks Dear ImGUI!\) in preparation to get the whole thing building and running under Linux. I'd hate to lose access to Visual Studio but there are limits to my willingness to deal with the constant Windows UI changes and ~~spyware~~ telemetry that's installed by default. How is the Mac version of VS these days?
I understand my question will be off-topic here. Though, I have no good idea where to ask. Maybe someone will kindly point me in right direction. I'm curious if MSBuild team is ever going to implement proper forwarding of include directories, compile definitions and some other properties specific to C++ when some project is referenced by another project. It's year 2018 and we still need to write all those directories by hand. Feature exists in CMake since prehistoric times.
I think the mac just gets vs code. Which you can also get for your linux install.
&gt; How is the Mac version of VS these days? Still pretty much what Xamarin studio was
Well std::variant has the same compile time overhead so the original question still stands. Why use this if you didn't want to use the same variant when it was in the boost namespace?
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8hv3eh/d_what_are_some_good_package_management_systems/dyquyps/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
(ignoring the obvious but-what-about-msvc) Thanks for linking that! So it is still a hint (with some questionable effect though: in clang it seems to _potentially_ increase the inline threshold, in gcc it's less clear what it does). If you want to guarantee inlining and get a warning/error otherwise I'd still recommend using one of the forceinline attributes (depending on your compiler).
I like QtCreator as the closest possible competitor on Linux. But honestly I still find Visual Studio to be just better. Still, it's the best alternative I've found.
Oh man I really thought I had updated VS since November but maybe not. I couldn't update to latest VS until yesterday because we had to fix some build settings but that's been sorted now so I'm gonna so that when I get home! If so that's great. Thank you for answering me personally like this, very cool :)
Mac actually gets a rebranded Xamarin Studio. It might _also_ get VS Code.
The "spyware" scare for Windows 10 is _way_ overblown. It mostly boils down to: * Cortana * Smart Screen (a _fantastic_ antimalware whitelist system) / Windows Defender * Crash reporting (also present in Windows 7) * Standard aggregated telemetry (also present in Windows 7) Nothing unexpected IMO.
7++, as a post-increment, only gets incremented after the end of the video :D
Borland C++.
Not quite the same thing, but the intrusive pop in ads as part of the base system were the last straw for me. I can and did turn them off, but the fact that they exist at all in a bog standard default install is a crystal clear sign that they will stop at nothing for the sake of monetization, and that's not something I want in my freaking OS.
I don't really think it's overblown at all, and it won't be long before the amount of information they collect creeps forward like kudzu. That is obviously the plan. To me, it's really about consent. I didn't ask for these services, and some of them can't be removed easily, if at all. I don't want to participate in data collection of any kind, and I don't want any extraneous crap running on my OS. I don't always debug on Pro versions of the OS, and I recently booted a test machine only to find it stuck in Windows Update hell the moment it connected to the network when I really needed to get work done for a customer who was filing paperwork for a drug trial. These features should be opt in.
I even myself was trying many times to use different text editors, but I was always coming back to VS, I missed Intellisense and many other features. Also configuring CMake and build systems and stuff is a pain in the ass, it's easier to do in VS. QT is maybe fine, Netbeans I don't think so. There's also Eclipse and CLion which people use but still, VS is the best one
Ah, thank you. I'm not new to programming, but I am new to C++. Would using ranges be the next best thing?
MFC.
Reason enough not to move - doesn't work on Linux. 
I agree that that's annoying, along with the sheer number of tiles in start in a clean install. But at least it's easily removed.
oh god.
&gt; Variant is so useful I wonder how I used to write code without it. Probably by using OOP with inheritance, virtual functions and tons of pointers. People always contrast `std::variant` with unions but in most code variants are much more likely to substitute runtime polymorphism via inheritance. It‚Äôs no coincidence that the name of the function `std::visit` hearkens back to the ‚Äúvisitor‚Äù design pattern, because that‚Äôs precisely what it implements. OOP + virtual functions *worked*. But even ignoring memory management, it was always messy and often led to over-engineering (not only in C++ ‚Äî I‚Äôve seen this a lot in Java and C# code, including my own). Where it fits, using variant types is a much more elegant solution (and increases type safety, since it restricts the number of runtime types that a variable can take).
#define new DEBUG_NEW Added by Class Wizard in each cpp file it generates. Done to track the line number an allocation was made. Maybe some additional benefits as well, can't remember. 
I totally agree with you. I love Visual Studio more than anything and it makes me sooo productive. 10x more than any other IDE on any platform. But Windows 10 and its constant problems, bugs, updates and "improvements" have made me consider strongly many times to switch to Linux as my main platform. Two main reasons I unfortunately cannot do it are Visual Studio and external monitor support (Linux hasn't in 20 year managed that you can plug in an external monitor and projector and it "just works", including extended mode and PowerPoint presenter view). Btw: Have you guys seen the latest news on Windows' "Cloud Clipboard"? The Clipboard now goes into the cloud (latest insider preview), with all history sent to the cloud and saved. So there's no such thing as a private clipboard anymore, anything gets sent &amp; saved now.
I think it doesn't even have C++ support. VSCode is probably the way to go.
Installing Candy Crush by default is no different in my mind to the preinstalled games earlier versions of Windows had. Reinstalling it was a bug in the first update IIRC, I haven't had it happen since, and I run Windows 10 on everything.
The thing with the rant üòÖ
Boost gets a bad rap because all of boost is really big. And parts get depricated. Even if part of boost is useful, saying "you can use one small bit of boost" is hard, it creeps to more of it, and boost is big.
Well the difference is that Windows 7 or so may have had Solitaire and Minesweeper installed by default, but they were &lt;5 MB executables, and they were hidden in the "Accessories" Startmenu somewhere - not bothersome at all, and far from being bloatware. Now first there's 10 times more of this stuff and second it's real bloatware that actually uses 200 MB++ (yes it matters if you have a 250/500 GB SSD) and third it's very prominent in the start-menu by default, blinking and animating...
I do wish there was a way to globally disable the animated tiles, I always disable them. And honestly, I don't think 200MB matters that much on a 250/500GB SSD - that's less than 0.1% of the disk, and it's easily removed if you need that space.
There are many of us - waiting for Hana and Ranges.
Visual Studio is an IDE. Why do you speak about libraries? You can use Qt library in Visual Studio. And you can write on WinAPI, MFC, WTL, etc. in QtCreator which is also IDE.
Sounds exactly like C++ then, so not sure in what way boost is any different. 
We have different philosophy then, I value stability and least surprises, so I tend to be very conservative. For me it's really important to be able to reproduce the exact same setup on future development machines. With latest Visual Studios this is not possible, you don't get the traditional ISO and specific update separately, you cannot downgrade or stabilize the development environment. My feeling with VS2017 was like being a beta tester, constant updates, fixes; for me that doesn't inspire confidence. Have in mind that the latest is not always the better; for example when I moved at VS2012 for evaluation I enabled IA-32 code generation and there were certain cases that it kept producing SSE. Certainly, I have better things to do than deal with MS bugs on every release, they are really good at fixing 10 bugs and introduce other 10, like the rest of us, etc. 
&gt; For me it's really important to be able to reproduce the exact same setup on future development machines. Are you installing Windows 98 on your customers then? I'm not convinced of how much stability one gets out of outdated build tools, specially when code doesn't run in isolation. I'm responsible for a lot of C++ code on my current position, and we do have a DLL that is stuck on VS6, and stability doesn't go along with that situation.
There is no problem; it's fantastic!
While I love minimalism and Vim and am fine with QtCreator on linux, VS+Resharper is just so superior in means of navigation and refactoring. I haven't yet found a solid replacement for it.
Yes you're right, forgot that. Last time I checked circa 2013 it looked to me that WinRT is just for simple applications mainly for consumers. I didn't see the potential to build complex applications like Photoshop or DAW, etc. I might be wrong at this point since I haven't checked that again since then... 