My negative experience is confined to macOS (three different Macs). I haven't noticed the sluggishness on Ubuntu now that you mention it. I use Visual Studio on Windows, so no idea how it performs there.
The suggestion is to only use `operator==` if it's implemented.
Are they aiming to remove EDG once their compatibility is right or just keep it around forever?
&gt; Distributes caching So ccache-memcached? &gt; preprocessing I'm not sure how you can do that unless you really run the exactly same stuff everywhere. &gt; probably linking. That would be interesting. Do you have more information?
Yes, though this approach only works well for inequality. That is, tuple cannot only implement spaceship via lexicographical spaceship. It has to do == and != separately.
Well, yes. Tuple's == should only call its member's ==s. Not claiming otherwise.
Well this is exactly what Bazel does with the same Remote-Ex backend that goma uses, and from my experience with icecc (local preprocessing kills you machine) and googles work on with distcc to distribute pre-processing it feels like a safe bet that is what is happening here too. If you have to locally preprocess those -j1000 commands in the Chromium docs would joke.
This makes me curious, how will defaulting spaceship operator work? When I call == on a class with defaulted spaceship operator, will it call == or spaceship for each of its data members.
See [P1185](https://wg21.link/p1185)
Thank you very much for your response-- this is very helpful. After reading this, I think I'm able to come up with a more pointed question. In the example, they use the `CallData` object to maintain the state of an RPC call that the server is going to act on. They have 3 states: `CREATE`, `PROCESS`, and `FINISH`. Are these the only states an RPC call would ever have? If not, what other states could there be? Maybe put another way: in the `CREATE` state, the `CallData` is added to the `CompletionQueue` via the `RequestSayHello` function. At the `PROCEED` state, `Finish` is called which again puts it back on the `CompletionQueue`, where it is subsequently deleted in the `FINISH` state. Also in the `PROCEED` state, we must create another instance of `CallData` so we can keep serving. Are there other ways to put `CallData` (or some other object) back on the queue? Say I wanted to break up my `PROCEED` into several phases. In all of these phases, how can I put the `CallData` back in the queue?
Thanks.
[Effective Modern C++: 42 Specific Ways to Improve Your Use of C++11 and C++14](https://www.amazon.com/Effective-Modern-Specific-Ways-Improve/dp/1491903996) &amp;#x200B; IMHO, the best book for understanding C++11/14.
Yup, Scott Meyers.
Scott Meyers
And if `a` is a nullary function returning a one argument function? foo |&gt; (a()) ?
The permutation proposal was great; a C++ program with `#permute` useing the first half of the program to permute the characters of the second, which then permute the first, applied recursively, makes C++ programs of nearly unbounded complexity and has zero practical use.
http://thbecker.net/articles/rvalue_references/section_01.html
C++ and Beyond 2012: Scott Meyers - Universal References in C++11 https://channel9.msdn.com/Shows/Going+Deep/Cpp-and-Beyond-2012-Scott-Meyers-Universal-References-in-Cpp11
https://youtu.be/IOkgBrXCtfo
Any idea if new versions of the book is comming for c++17/20?
Scott Meyers is essentially retired, so I wouldn‚Äôt hold my breath.
Likely not, Scott Meyers has said a number of times that he is retired.
Bjarne Stroustrup C++11 book. Regardless of the fact that he invented the language, he's actually a really good communicator and I would recommend his book anyway.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bevf0j/c_assignment_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
jesus that guy and his style is annoying.
Move semantics from Howard Hinnant (who basically invented move semantics and got it into the language*). https://www.youtube.com/watch?v=vLinb2fgkHk (*although he did have a bit of help from Bruce Lee: https://youtu.be/h0xBh0rzqQ8?t=214)
I'm sure that it could be improved a lot, yes. Thank you for your feedback! I'll definitely try to improve the compile-errors more.
As I've mentioned this library is mainly focused on the "parsing part". It doesn't even know what a character is. But I'm planning a lexer (that will use the "regular subset" of the combinators) that will have utilities like that.
This is my little cheat sheet code: ``` #include &lt;iostream&gt; #include &lt;assert.h&gt; using namespace std; class A { private: int refcount = 0; public: string* s; A(string a) : s(new string(a)) { ++this-&gt;refcount; cout &lt;&lt; "+++++ Constructor invoked. " &lt;&lt; *this-&gt;s &lt;&lt; " at: " &lt;&lt; this &lt;&lt; endl; } A(const A&amp; a) { if (this != &amp;a) { this-&gt;s = new string(*a.s); this-&gt;refcount = 1; } cout &lt;&lt; "Copy constructor invoked. " &lt;&lt; *this-&gt;s &lt;&lt; " at: " &lt;&lt; this &lt;&lt; endl; } A&amp; operator=(const A&amp; a) { if (this != &amp;a) { *this-&gt;s = *a.s; } cout &lt;&lt; "Copy assignment operator invoked. " &lt;&lt; *this-&gt;s &lt;&lt; " at: " &lt;&lt; this &lt;&lt; endl; return *this; }; A(A&amp;&amp; a) { if (this != &amp;a) { this-&gt;s = a.s; a.s = nullptr; this-&gt;refcount = 1; } cout &lt;&lt; "Move constructor invoked. " &lt;&lt; *this-&gt;s &lt;&lt; " at: " &lt;&lt; this &lt;&lt; endl; } A&amp; operator=(A&amp;&amp; a) { if (this != &amp;a) { this-&gt;s = a.s; a.s = nullptr; } cout &lt;&lt; "Move assignment operator invoked. " &lt;&lt; *this-&gt;s &lt;&lt; " at: " &lt;&lt; this &lt;&lt; endl; return *this; } ~A() { --this-&gt;refcount; cout &lt;&lt; "----- Destructor invoked. refcount:" &lt;&lt; this-&gt;refcount &lt;&lt; " at: " &lt;&lt; this &lt;&lt; endl; if (this-&gt;refcount &lt;= 0) { delete this-&gt;s; cout &lt;&lt; "~~~~~ deleted. " &lt;&lt; " at: " &lt;&lt; this &lt;&lt; endl; } assert(this-&gt;refcount &gt;= 0); } friend ostream&amp; operator&lt;&lt;(ostream&amp; os, const A&amp; a) { cout &lt;&lt; a.s; return os; } }; void f() { A a("hello"); // Constructor invoked. A b("world");// Constructor invoked. a = b; // Copy assignment operator invoked. A c = a; // Copy constructor invoked. A d = move(a); // Move constructor invoked. d = move(b); // Move assignment operator invoked. } int main() { cout &lt;&lt; "Entering main." &lt;&lt; endl; f(); cout &lt;&lt; "Exiting main." &lt;&lt; endl; return 0; } ```
&gt;elgselgs Thanks! Btw why are you dereferencing this all over your code
Where exactly did you mean?
Like this &gt;this-&gt;refcount &gt; &gt;Can't you just say 'refcount'
Oh yes I could. Looks like it's not necessary. You are right.
Thanks!
Blog from a Google engineer: https://eli.thegreenplace.net/2011/12/15/understanding-lvalues-and-rvalues-in-c-and-c/ https://eli.thegreenplace.net/2014/perfect-forwarding-and-universal-references-in-c
Oh, yeah, that sounds reasonable. You reminded me of one lecture by Alexander Stepanov. He implemented a simple class template, with only one data member of type `T` and then all interesting constructors and operators. He implemented `operator==` like `x == y` and then implemented `operator!=` as `!(x == y)`. For the inequality operators (not sure it is the right term, but I'm thinking of `operator&lt;`, `operator&gt;`, `operator&lt;=` and `operator&gt;=`), he made a little speech before writing them. Something along the lines of: &gt; When I was designing the standard library 25 years ago, I had to make a lot of arbitrary choices. "Which is the default sorting order?" is one example. Another choice I had to make is what operator to use for comparison. You would have been mad if your type worked with one STL algorithm but not with the other because STL was inconsistent in use of comparison operator. That is why STL only uses `operator&lt;`. You should define all the operators, because that's just being nice to yourself an your colleagues. You won't always remember that you have `operator&lt;`, but not `operator&lt;=`. But the standard library will only use `operator&lt;`. Note that this is not a direct quote, but me paraphrasing Stepanov from memory. He didn't implement `operator==`, because, I think, he wanted to show a clear distinction between `SemiRegular`, `Regular`, `EqualityComparable` and `TotallyOrdered` types. &amp;nbsp; Interestingly enough, Stepanov claims that his original design of `std::min`, the one that we held onto to this day, was wrong. Originally, his implementation was `return first &lt; second ? first : second;`. The problem with this, according to Stepanov, is when `first` and `second` compare equal. In that case Stepanov's `min` would return `second`, not `first`. Stepanov also claimed that by the time of his lecture, `min` was still "wrong" in standard library implementations, though checking it today in libc++ and libstdc++, they both do it "correctly", with `return second &lt; first ? second : first;`.
It's only necessary if you have a local variable with the same name as a member variable. In that case `this-&gt;foo` is the member variable and `foo` is the local variable.
You are correct that you may well want to pause handling of the RPC and resume it again later; in your words the `PROCEED` state could be split up. In fact, it wouldn't be worth using the async API unless you were planning to do this (if you can just return a result directly why not just use the synchronous API?). The way you tell the `CompletionQueue` to resume later depends on what you're doing in the meantime: * The easiest is to send an async request as a client to some other gRPC service. In that case, when you call `rpc-&gt;Finish(&amp;reply, &amp;status, tag);` on the client `rpc` as in [the example](https://grpc.io/docs/tutorials/async/helloasync-cpp.html#async-client), you are queuing up a new tag onto the completion queue. * Another option is you some CPU-bound processing that takes a long time. You'll want to do this in another thread (by sending some sort of inter-thread message using a thread-safe queue; there are plenty of implementations of these floating around the web). Then when that thread is finished it has two options: * Directly call the next gRPC async API from that thread. I believe this is supported but some things need mutex locking and I'm not really sure what they are. This also makes shutdown harder (although good luck getting that right whatever you do). * Send a message back to your gRPC server thread and call the next thing from there. Unfortunately there is currently no API to post an arbitrary tag to a completion queue from another thread; [here is an issue](https://github.com/grpc/grpc/issues/8442) covering that request. There is a workaround for that problem (as a comment on that thread says, and also mentioned in the [gRPC Google Group](https://groups.google.com/forum/#!topic/grpc-io/sAuy4j3hSUA)): abuse the [`grpc::Alarm` class](https://grpc.io/grpc/cpp/classgrpc__impl_1_1_alarm.html) to set an alarm that expires immediately (use a deadline of 0). This causes the arbitrary tag to be posted immediately to the completion queue. Beware that the `grpc::Alarm` object needs to exist until after the handler has started in the other thread (so you can't just create it on the stack), and that these timers don't necessary complete in the order you create them even if the deadline is the same, so you can't use them like a proper queue. * Sending a synchronous message to another process, either using gRPC's synchronous API or some other API (e.g. making requests to a database). In that case you need to use another thread, as you would for CPU-bound processing, so your options are the same as for the previous bullet point. Even if the other API is asynchronous (e.g. you're using `boost::asio`) you need to use another thread as there's no way to hook any other API into the core of gRPC's async processing. The number of steps you break your RPC's processing into depends entirely on your application logic and I could even imagine skipping over some steps, or jumping back and forth between them, depending on the contents of the request or the results of calls to external processes.
Was going to post this. This is probably the best explanation without having to read an entire book...
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bevtjk/cant_set_a_randomly_generated_string_to_a/el918p9/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; local preprocessing kills you machine I don't have any problems with that, but I'm using -j100. It is still incredible fast, and you can compile in a heterogeneous environment. You can even test new compilers, libraries, etc.
I believe the effective c++14 book was his latest one. I'm reading it now especially for the kove/copy semantics. He goes through it in baby steps, points to earlyer topics if something doesn't look obvious, destroys common misconceptions with strong explanations and good examples. I think this is the best thing about copy/move, std::move and std::forward I've ever read. Defenately reccommend
https://channel9.msdn.com/Series/C9-Lectures-Stephan-T-Lavavej-Standard-Template-Library-STL-/C9-Lectures-Stephan-T-Lavavej-Standard-Template-Library-STL-9-of-n Not sure if it‚Äôs still relevant to the current version of C++ but very nicely explained.
Your comparison operator uses == to check for equality, which could become a problem when working with float or doubles. https://bitbashing.io/comparing-floats.html
This book is very helpful, thus it would be a big lose if there was not a new version for 17/20.
May I ask what are the differences and strengths of transwrap are compared to HPX and CppTaskflow? Also, without a proper work-stealing scheduler, task parallelism is pretty inefficient. I hardly suggest to implement one. More advanced scheduling schemes will work even better.
transwarp doesn‚Äôt implement work stealing but can be implemented client side through the executor interface. I‚Äôm not familiar enough with those libraries. Maybe someone else here can provide a quick comparison..
I noticed this! Thanks for pointing it out
&gt;Cmake has to rerun anyway if you want to add a new file regardless of your method - even if cmake was not used to create a visual studio project. Yes, but you would need some manual cmake run because the file didn't change, whereas an edit to the cmake file would trigger a new cmake run automatically. When working on some projects with glob\_recurse that I still didn't "ported", I often find myself adding a blank line to the cmake file just for forcing the cmake run...
I find it easier to manage several file list variables (on large projects, I split the SOURCE\_FILES into several source lists).
With most task libraries the first thing I have to is to implement some sort of progress monitoring, does your library help with that?
Yet another one (from HN) just covering the value types https://blog.knatten.org/2018/03/09/lvalues-rvalues-glvalues-prvalues-xvalues-help/
If you can't use value types vs reference types, then you shouldn't be programming in C/C++ anyway.
Don‚Äôt think of a build system as something that invokes a C compiler and linker. Think of it as something that takes a program and some inputs then makes another output. Once you have that design all builds steps are distributed and everything can be cached. So with Bazel you put the compiler and libraries as part of your build graph and they get sent, only once, because of caching, to the remote build cluster. This means you could have one build with 10 different compilers at once and 500 libraries, it would not matter.
Yep. Especially once concepts are in I imagine c++ codebases changing rapidly. Duck typing is so under appreciated. Atomic pointers will be cool and we'll probably struggle with it for a bit. (A.k.a. Requires good explanation for use and usecases) I would love coroutines to be in too, and more constexpr stuff. But I couldn't care less about constexpr if we didn't get full blown introspection. All with all I see a lot more things for which we need Scott's explanations for. If not for ourselves, we need them so we can talk better with collegues about these features.
Firstly, nice idea and boost-quality codebase. I was going to ask the same thing, but for Intel Threading Building Blocks, especially how it differs from the tbb::flow_graph.
I will miss his talks :(
I refered to case of basic types like integers, that have stricttotalordering even in c++98. With typetraits is\_integral, is\_pointer etc this can be optimised even in c++11
This is very nice, thank you! I have been wanting something like this for years now.
1) As I said: The way it is shown in this video, you have to manually rerun cmake anyway in order to create the new project files. 2) Why you prefer to change the cmake file instead of just - you know - rerun cmake is beyond me 3) I still don't see the problem in re-running cmake manually 4) I don't use it, but in theory, there is `CONFIGURE_DEPENDS`
It isn't hard. Compilers alread map `#include "path"` to text in arbitrary ways. `#pragma once` just requires each block of text generated by `#include "path"` have a unique identifier (we could even expose it) and that if the block of test with that unique identifier is attempted `#include "path"` again, the include does nothing. How that maps to inodes, filenames, whatever; not the standard's problem. Because file search paths aren't the standard's problem. Probably require, if two different `#include "path"` go to the same unique identifier,mthat the corresponding blocks of tezt be the same. Note this is a one way implication. We could also require that the any `#include "path"` rules to find additional text blocks and identifiers would also resolve the same if the include has the same identifier; that would probably require checking with dompiler vendors if it is true currently.
Just FYI: In newer cmake versions you can add files to a target after the fact.
Thanks for clarifying. Do you know how recent this was? I mean, build times are not a big enough issues on the projects I'm working on that 3% would be relevant but would still be interesting to know if pragma once still provides an advantage.
I've never realized that's Howard Hinnant effort. Thanks for info!
X3 is not that old ... or is it?
No, pretty sure I used v2 back when I compared libraries since lambdas were a major pain to use with it (you had to wrap them in an extra function for them to compile or use those ridiculous old school fake-lambdas). It would actually be interesting to test the new version, but my students learn rust now and I have no other immediate need for a parser atm :) (and CTRE is usually my weapon of choice for small tasks). It also seems that x3 is in eternal beta, but that's usually still more mature than most "modern, header-only parsec inspired" libraries...
still probably faster to ship a compressed tarball to the build node and do all building locally and ship release products back. The more contention on the NAS for building (nfs for example, the slower all the builds get).
imo it's a silly requirement. what if you have a double that's Nan?
It's not a silly requirement. That's addressed by [\[structure.requirements\]/8](http://eel.is/c++draft/structure.requirements#8): &gt; Required operations of any concept defined in this document need not be total functions; that is, some arguments to a required operation may result in the required semantics failing to be satisfied. [ Example: The required &lt; operator of the StrictTotallyOrdered concept ([concept.stricttotallyordered]) does not meet the semantic requirements of that concept when operating on NaNs. ‚Äî end example ] This does not affect whether a type satisfies the concept.
Build nodes don't necessarily have their own storage eg blades, or not enough to hold source code and artefacts. In any case, if you ship the source code over you need to use a format that preserves file identity as determined by the compiler ie soft and hard links. One solution is to ship preprocessed code as a single file, but that introduces a bottleneck in the preprocessor.
Probably `foo |&gt; a()()` since we're doing `a()(foo)`?
Personally, [this](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/cpp-value-categories) was one of the best resources I've read on these topics. It was posted here, under a similar question IIRC.
Yes, you can subscribe to task events and then get notified when each task starts and stops. To get more fine grained information you could use the custom data that‚Äôs attached to each task. However, there‚Äôs currently no notification when that changes. I will consider adding that in a future version.
Firstly, your formatting is off. Some of it isnt displaying as code. About your code, the parts i could read atleast :) checking this != &amp;a is completely unnecessary in ctors (copy ctor, moce ctor) for obvious reasons. also im not aware of a situation where move assigning to self would happen.
Just `foo |&gt; a()` unless `|&gt;` has too high a precedence.
Just `foo |&gt; a()` would suffice unless `|&gt;` has too high a precedence.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bf2bcq/suggested_books_as_2019/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Nice talk! May I ask you to elaborate a bit more on the feature toggles stuff? I tried many times vcpkg and conan but I develop for third parties and I am bit nervous to push them the package manager but trying to do stuff with cmake external projects os awful...
To be honest, the code is not really readable... I think that using vector of vectors is not the best choice. Since you know the size you could create two 2d arrays and just change the main one and the other one. You also construct vectors every time from zero. I haven't seen use of references which are safe alternative to pointers. If you have an iterator (*i). is usually the same as i-&gt;.
This is more "serious" subreddit, than "Hey guys check my first project". You can gather necessary feedback here -&gt; https://codereview.stackexchange.com
You define copy ctor and assign. This has two effects: 1) It inhibits auto generation of move ctor and assign. 2) You also didn't declare them with a noexcept specifier. This had the combined effect that your class can only be copied, not moved. And any code that copies objects of your vector class can't be noexcept. The solution is simple, just remove the copy ctor/assign. The compiler will do The Right Thing for you.
number, number 9
Thanks for your work, here it is the link to your talk, i hope you dont mind https://www.youtube.com/watch?v=k99_qbB2FvM And as my personal opinion i hope we get improve this point as it is a wall in terms of using the language and i thing it is a thing that makes people dont look at this and instead choose any other new gens langs like Rust or Go because it is easier to code because they dont has a build system as complex as C++ does. I Hope we can catch up with the "competence" in this point and has a better solution as we has today, we deserve it
Hello! Code looks really clean! I did notice you aren't using any modern (C++11 and beyond) features. Is this intentional? If it is for compatibility reasons, most platforms (including really unusual ones) have at least a C++11 compiler. I also noticed you did use `auto` here and there, which is C++11. As to what it can do for your code, it can turn this: std::vector&lt; std::vector&lt; bool &gt; &gt; cycle(std::vector&lt; std::vector&lt; bool &gt; &gt; * field){ std::vector&lt; bool &gt; toPush; std::vector&lt; std::vector&lt; bool &gt; &gt; newField; for(auto i = (*field).begin(); i != (*field).end(); i++){ std::vector&lt; bool &gt; row = (*i); toPush = {}; for(auto j = (*i).begin(); j != (*i).end(); j++){ int neighbours = calcNeighbours(field, j - (*i).begin(), i - (*field).begin()); if(*j) toPush.push_back(neighbours == 2 | neighbours == 3); else toPush.push_back(neighbours == 3); } newField.push_back(toPush); } return newField; } Into this: std::vector&lt; std::vector&lt; bool &gt; &gt; cycle(std::vector&lt; std::vector&lt; bool &gt; &gt; const &amp; field){ std::vector&lt; std::vector&lt; bool &gt; &gt; newField; int i = 0; for(std::vector&lt; bool &gt; const&amp; row : field){ std::vector&lt; bool &gt; toPush; int j = 0; for(bool isCellAlive : row){ int neighbours = calcNeighbours(field, j, i); if(isCellAlive) toPush.push_back(neighbours == 2 | neighbours == 3); else toPush.push_back(neighbours == 3); j++; } newField.push_back(toPush); i++; } return newField; } You also missed some easy optimizations like reserving the right sizes for your vectors and using move semantics: std::vector&lt; std::vector&lt; bool &gt; &gt; cycle(std::vector&lt; std::vector&lt; bool &gt; &gt; const &amp; field){ std::vector&lt; std::vector&lt; bool &gt; &gt; newField; newField.reserve(field.size()); int i = 0; for(std::vector&lt; bool &gt; const&amp; row : field){ std::vector&lt; bool &gt; toPush; toPush.reserve(row.size()); int j = 0; for(bool isCellAlive : row){ int neighbours = calcNeighbours(field, j, i); if(isCellAlive) toPush.push_back(neighbours == 2 | neighbours == 3); else toPush.push_back(neighbours == 3); j++; } newField.push_back(std::move(toPush)); i++; } return newField; }
being explicit or defining your own type_trait, those are the two options i see. maybe `is_const_ignore_reference` or `is_deep_const` to fully check the type.
Try /r/cpp_questions for help with using the C++ language. :) When you do, I'd *highly* encourage you to actually describe the actual problem in detail. Is it failing to compile? Failing to work? What's the error? Paste any message or errors *verbatim*, do not summarize, and share any and all supplementary debugging information you have available to you. (Also, maybe try a different way of sharing code; I don't know what that ghostbin site is doing when it's "Checking my Browser" before it starts loading your content, but I assume it's trying to mine BitCoins or something and I'm not playing along. Consider using something like [GitHub gists](https://gist.github.com/) perhaps.)
The naming of functions is just a convenience towards understanding what the semantics of the thing are. For my part, I think `sane:is_const` doesn't allow you to reason the same way, because you don't know whether someone else has a non-const reference to it. That means you can't apply reasoning that depends on immutability for things like concurrency and memoization. That's not to say it's wrong, but it connotes a different set of properties than `std::is_const`.
Reread both the post, and the post it replies to. Your "solution" is ruled out already.
That browser check by CloudFlare (DDoS prevention), lol xD
Is `int const*` const? `int const*const*`? `int*const*`? `int(const&amp;)()`? `int (Foo::*)() const`?
to be even more precise?
I'm using X3 on production and it's okay. Although I'm sure we didn't explore all other alternatives :o) . There is something to x3 being in land of eternal-beta software, I'm not sure how popular is it. But hey it's in boost :)
I like the idea of `is_deep_const`: it could also be true for pointers to const.
Changed it! Thanks a lot!
that would make sense as well.
pointer to pointers to pointers......
`std::unordered_meow` ü§î
&gt; Worked around the POSIX deletion mode delete function existing on Windows 10 LTSB 1609 but not actually being capable of deleting files. I'd like to know more about this particularly useful function: what is it called and has it learnt to delete files in the later Windows versions?
Cat noises are less verbose than "`std::unordered_map`, `std::unordered_multimap`, `std::unordered_set`, and `std::unordered_multiset`".
Can't argue with that haha
The string constructor warnings and more granular include headers will make the upgrade to 16.0 interesting/ time consuming, but I'm all for it (I just had the pleasure to help with the upgrade to 15.9.7 on a 38 year old 16MLoc C++ Codebase).
"Many STL internal container functions have been made private for an improved IntelliSense experience". Thanks a lot!
Thanks for talking a bit about the lack of new faces. I watch all of these talks and go to UWE in Bristol, which is 20 minutes from the ACCU. I was really tempted but was put off by the perceived eliteness I had assumed existed. It was quite reassuring to read your post, so thank you.
I'm sorry if this comes off as rude but what kind of "managing" are you talking about? In 10 years of using CMake, the only "managing" of a target's files I've ever had to do was add a line or remove a line once in a blue moon and it feels like having secondary variables would've just added unnecessary noise and complexity.
What the hell? Presumably ported from C at some point, unless you were doing this at Bell Labs... I'm pretty sure the first public release didn't happen until, what, 35 years ago? 34?
`int(const&amp;)()` isn't valid C++. You can't const-qualify function types.
I'd prefer something like `is_modifiable`.
On mobile so can't easily provide detailed reference links etc. but I believe this is probably referring to FILE\_DISPOSITION\_POSIX\_SEMANTICS/FILE\_RENAME\_POSIX\_SEMANTICS.
About the fix of the timing issue in `std::thread`: Is that completely fixed or is it just less likely to happen, because fewer functions are called in between?
exactly. is const means "won't be changed" rather than "cannot be changed by me"
I'm curious when it's useful to see if your reference is const. wouldn't your template signature make that obvious?
This clears up a lot for me. Thank you very much for taking the time to respond. It's making me re-evaluate whether or not I should even use gRPC in the first place. I'm wondering if I should try to roll my own server using `boost::asio` and use protobuf for the IDL (like [this](https://eli.thegreenplace.net/2011/03/20/boost-asio-with-protocol-buffers-code-sample) example).
&gt; wouldn't your template signature make that obvious? [Of course not](http://coliru.stacked-crooked.com/a/bcccc78927d4db0f).
It returns a `span::const_iterator`. What do you think it returns? Note how member and non-member `begin()` are const-overloaded, and note how non-member `cbegin()` takes `const C&amp;`.
(deleted my first, incorrect reply) This looks like a Library Issue - the problem is that non-member `begin()` and `cbegin()` were designed to assume deep const (a const container has const elements) and const-overloaded member `begin()` (so non-member `cbegin()` would work with old containers that provided only member `begin()`). `span` broke both of these assumptions: it is shallow const, and it doesn't const-overload member `begin()`. The compatible, although horrible, way to fix this is to re-specify non-member `cbegin()` to use SFINAE: call member `cbegin()` if it's provided, otherwise fall back to const-overloaded member `begin()`.
https://blogs.msdn.microsoft.com/vcblog/2015/07/14/stl-fixes-in-vs-2015-part-2/ &gt;* The map/set family rejected empty lambdas as comparators (DevDiv#375529/Connect#727957). This was an example of an STL-wide problem ‚Äì we attempted to optimize away empty comparators/allocators/etc., but did so inconsistently and incorrectly (e.g. by assuming that empty objects must be default constructible, which is false). unique_ptr and unordered_meow also had trouble with deriving from user-defined deleters/hashers (e.g. unordered_meow was callable like a functor). I fixed this by implementing a compressed pair with the Empty Base Class Optimization, then overhauling the STL to use it. This centralized compressed pair handles everything correctly ‚Äì e.g. it doesn‚Äôt assume default constructible types, it respects final classes, and it must be used as a data member (preventing the unique_ptr/unordered_meow problems). Here‚Äôs an exhaustive list of what was updated: https://news.ycombinator.com/item?id=15000381 https://timsong-cpp.github.io/lwg-issues/2977 https://twitter.com/stephantlavavej/status/652723647254171649 https://libcxx.llvm.org/cxx2a_status.html
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
You've not done timeouts yet then?
http://kholdstare.github.io/technical/2013/11/23/moves-demystified.html A nice n easy to read article on move semantics that really helped me to grok it for the first time. Thanks to the author!
Did you use System.IO.Pipelines?
The thing is, currently the trait accepts references but does not what one might think it does. I can't imagine someone *actually* using it to check whether a reference itself is const-qualified, because it can't be by definition. If there are any concerns with doing here what the rest of the language does with references (I don't think so, but still) it would've been much better for this trait to reject references altogether (by not providing the value member) than giving a technically correct, but unexpected and de facto useless answer.
I think this was brought up in committee, maybe by Casey? Not sure what, if anything, came of it.
Thanks. If using SFINAE in cbegin is too horrible, maybe allow shallow const, const-overload-less containers to have custom overloads of cbegin (similarly to [std::begin(std::initializer\_list)](https://en.cppreference.com/w/cpp/utility/initializer_list/begin2))?
Unfortunately being ```const``` does not mean that it's not modifiable.
Building upon the shoulders of giants, I think I'll change that to `unordered_rawr`.
Ummmm... are they making the socket from scratch in c#. Because it is like one line of boilerplate - declaration. I‚Äôm not advocating either one btw.
Many constexpr issues still remaining see https://gitlab.com/LIONant/properties
Speaking of timeouts have you look at beast lately?
I'm still waiting for a VC++ build where I can use pointer subtraction in a constexpr function. It's so broken right now, subtract two pointers to a non-power-of-two sized object and you will always get zero in constexpr context.
\`std::ranges::cbegin\` suffers from the same problem in n4810. Maybe it's possible to fix this in Cologne?
Is this why they recommend passing std::span by value?
fuck me I'm stupid. thanks for explaining
You have the sources :) Look at (for example) `C:\Program Files (x86)\Microsoft Visual Studio\ (whatever you picked here) \VC\Tools\MSVC\ (version number) \crt\src\stl\filesystem.cpp` for `__std_fs_remove`. The Windows API we call here is `SetFileInformationByHandle`, with `FileDispositionInfoEx` set to `FILE_DISPOSITION_FLAG_DELETE | FILE_DISPOSITION_FLAG_POSIX_SEMANTICS`. On Windows earlier than Windows 10 1609, this function fails because it doesn't understand FileDispositionInfoEx. On 1609 it succeeds, but doesn't actually delete the file (which is the bug workaround discussed in this blog post). On current releases it actually manages to delete the file or directory of course.
The thing where std::thread waited in its ctor to be signaled by the other thread actually running is completely removed, so at least in the constructor that shouldn't be possible any longer. The longstanding issue where `struct stdext::xtime` is passed over the DLL boundary to control concurrency primitives making `condition_variable::wait_for` vulnerable to system time changes remains; `thread`'s constructor just no longer creates any mutexes or condition variables.
Thank you, that makes sense. I'm guessing the xtime issues was one of those things, that could only be fixed with an ABI break, that didn't happen with VS2019?
When can we expect modules ?
Yep :(
For instance splitting between common source files and platform specific ones.
No need for that frowny-face. The binary compatibility actually helps me out a lot, as I now can use VS2019 in our product, with all the niceties of C++17 and 20, that you implemented. Otherwise I'd still be stuck with VS2015, because of the libraries we have to link against. So while it is probably a big effort to stay ABI compatible and there are some issues, that can't be fixed because of it, I really appreciate it, thay I'm finally no longer stuck on an old compiler and old C++ standard, until we can finally drop support for older Application releases. Especially with all the awesome compiler, conformance and library improvements in MSVC recently! So really, thank you for putting up with that! I'm also guessing, that issue can't be solved with a dual ABI like GCC did with the cxx11 strings, etc?
That seems wrong to be because for references, whether the referenced type is const is the only thing that is meaningful to ask (a reference cannot be const by definition). However, a pointer itself may or may not be const. Also consider that if you're asking if something is const you probably want to know if you can assign to it, and for pointers this is reflected by whether the pointer itself is const.
Thanks, this is really helpful. As you noticed, I'm just getting into C++ and these are things I can really learn a lot from
Is "std::unordered_meow" just a running gag on the standard library team at this point? Cool stuff though. Looking forward to switching over to VS 2019.
Right, even if the OS loader had such a thing, that still wouldn't help us because we support app local deployment. libstdc++ has the advantage that they know there will be only one libstdc++.so in use in the process at a given time.
1. `is_const` is already in the standard with a precise definition, and thinking about how it *should* behave instead is pointless wishfull thinking due to retrocompatibility. 2. If you're going to create a new tool, I fail to see any reason not to make it be usefull in has many cases as possible. 3. Yes, "is it const?" usualy means "can I assign to it?" Is your argument that nobody ever wrote `*p = ...`?
Thanks for pointing that out. It's an issue I've encountered numerous times, but I forgot about it when I defined a cleaner notation [`is_const_`](https://github.com/alf-p-steinbach/cppx-core/blob/master/source/cppx-core/language/tmp/basic-type-traits.hpp) for my *cppx-core* library (C++17, header-only, still evolving). Now corrected.
&gt; is_const is already in the standard with a precise definition, and thinking about how it should behave instead is pointless wishfull thinking due to retrocompatibility. Right, is_const should not change, the debate is about a hypothetical alternative. &gt; If you're going to create a new tool, I fail to see any reason not to make it be usefull in as many cases as possible as long as it stays coherent. You would need to decide whether it either just looks at the constness of the pointer type or the constness of the pointed-to type (and ignores the constness of the pointer type), it cannot magically know what you intended to check. &gt; Yes, "is it const?" usualy means "can I assign to it?" If one asks about constness of T* then it should tell you if you can assign to T*, not T. If you want to know about consteness of T, ask about that.
Using `file.eof()` in a loop condition is almost always wrong because the end-of-file flag is set too late.
That explains it thank you but what can i do to counter this?
Awesome, thanks! :)
To be more precise, the paper says that the bound is optimal for quadrature formulas obtained by variable transformation, which I'm pretty sure Gaussian quadrature doesn't fall under. The error bound of the Gaussian quadrature depends on the growth rate of the n-th derivative of the function, so it's harder to give an estimate. The wikipedia page for tanh-sinh quadrature says that GQ is more efficient for smooth integrands, but that the tanh-sinh scheme "appears to be the best for integrands of the type most often encountered in experimental math research".
Not sure what you mean by ‚Äúnot asking the build system‚Äù, include path set is specified in the command line flags by whoever invokes the compiler, build systems in particular use this facility.
When you use it, you are asking the question ‚Äúif I look at this variable twice, is it always guaranteed to give me the same answer‚Äù It makes sense to be able to ask this question of a reference, since a reference is the sort of thing that you might get the value of twice in a row.
Half the fun in C++ is that it is verbose.
You are only slightly wrong... the first version was written in Fortran, then it was switched to C++ and the Fortran sources were transpiled to C.
boost::regex has partial match support, std::regex does not (sadly). Not to mention boost::regex is a lot more reliable than std::regex (at least on MSVC). CTRE will help, but I've been surprised how many of our regexes at work contain dynamic elements.
I know it's stupid, but... Start type names with a capital, and member names with a lowercase letter ? void MyProject::CustomElement::onThemeChanged() { // Find out what style to use. Style currentStyle = getStyleFromCurrentTheme(); // Set it as our style. style(currentStyle); } Because of this problem, code conventions for C++ should allow to easily disambiguate between types and functions.
I hate that Microsoft always uses capital letters for member functions
[It's a solved problem](https://github.com/kmhofmann/cpp-coding-guidelines/blob/410177803ffaa391ab7411538b418b025ca0f284/guidelines/naming.md). Type names should be upper-case, variable names lower-case.
Use auto on types returned by function call.
Depends on the coding standard. I don't mind snake case since I wrote a few libraries.
Glad to hear it! This might interest you: Networking TS refresher: [https://www.boost.org/doc/libs/1\_70\_0/libs/beast/doc/html/beast/using\_io/asio\_refresher.html](https://www.boost.org/doc/libs/1_70_0/libs/beast/doc/html/beast/using_io/asio_refresher.html) TCP Stream Timeouts [https://www.boost.org/doc/libs/1\_70\_0/libs/beast/doc/html/beast/using\_io/timeouts.html](https://www.boost.org/doc/libs/1_70_0/libs/beast/doc/html/beast/using_io/timeouts.html) WebSocket Timeouts [https://www.boost.org/doc/libs/1\_70\_0/libs/beast/doc/html/beast/using\_websocket/timeouts.html](https://www.boost.org/doc/libs/1_70_0/libs/beast/doc/html/beast/using_websocket/timeouts.html)
C++ core guidelines suggest using ISO naming convention, which ends up having the same problem here, but in any case it's not clear in most editors/code review tools whether it's a member function call or not. Thus we've started calling member functions with `this-&gt;`. No regrets.
Unless you want an implicit construction/conversion (i.e. when working with Boost's XML parser).
I always used to write code with `this` when I first started but stopped when I started writing code professionally because that's what I always saw in the wild. Always wondered why. I mean I guess it's redundant in most cases, and really shouldn't be necessary, but especially when not using namespaces, it helps distinguish which function calls are local to the class when dealing with a large code and poorly organized codebase.
I will not voluntarily use a naming convention that is not used by the standard library of the language I'm using.
Except all types defined by the standard library and other libraries that follow its conventions are lower case. Furthermore, the standard library is starting to use upper case for concepts, so using upper case for types is just setting ourselves up to not be able to distinguish types from concepts.
What about getters?
I picked this up from my travels through Python and likewise, no regrets.
Microsoft surely dropped the ball in C++17. I hope they can do better in C++20.
Too bad it's been solved [14](https://xkcd.com/927/) times.
The standard library is inconsistent in its naming convention and as for concepts, their use is explicit, requiring the use of ```auto```, ie. void f(SomeConcept auto x) { SomeOtherConcept auto y = ...; }
A reference being `const` _in no way_ gives you that guarantee.
Then you're going to have difficulty finding work at large c++ companies.
Hence the "voluntarily". Obviously, any work for hire must meet the specifications of the client.
Module mapper uses socket of similar stuff and compiler asks the build system for the location of each BMI giving the maximum flexibility. With include flags you just pass a bunch of directories and compiler performs lookup by itself. This is very different.
Exactly why it should return false! And does!
Agreed on all counts.
You can use static\_cast as well.
Setters and getters have different signatures, they can have the same name ?
Thanks to everyone for all the inputs. Next post (hopefully on Wednesday) will be about Gauss-Legendre -Integration.
&gt; &lt;variant&gt; has been refactored to make it more optimizer-friendly, resulting in smaller and faster generated code. Most notably, std::visit and the inliner have now become good friends. &lt;3
I'm unsure how that would interact with construction, though.
Because the standards committee is more interested in building a more complicated language than solving the real problems in C++ like having a good packaging system or a standardized build environment. CMake is the closest thing we have, but even that is just a mud-and-sticks cobbled together mess underneath.
https://xkcd.com/927/
The alternative is to pick the package manager that comes closest to what you want and work to make it better.
Implicitly is a pretty bad things. It can benefit you nothing but saving a few letters or maybe a line, but you never know if there would be a human mistake or even a compiler bug.
I think you'll find that the trick is not so much in writing a package manager, as it is in populating it with a useful database and then keeping it up to date. Or, alternatively, getting all those library authors to agree on supporting your format (in addition to the three(?) formats they are already expected to support). Of course it doesn't help that library authors pull so much weird shit. You'd think it would be enough to feed a bunch of .cpp (or .c) files to a compiler, and then link the whole thing together. But nooo - you're expected to \_configure\_ it first (and don't forget to set options like "don't\_randomly\_crash", or it will), then run various preprocessors, some of which you have to build from source as well, then move files around a bit, deal with a mountain of unlisted dependencies that will make themselves apparent as compiler errors, etc. What we need is a task force to hunt these people down and force them to write standard code ;-)
&gt; It is hell to create packages for my own libraries in Vcpkg and am left to Microsoft's willingness to package the libraries I need In what way exactly? I find vcpkg package creation to be pretty straightforward. For most cmake based projects you just need the `CONTROL` metadata file and the `portfile.cmake` file. Even if something is a binary distribution, you can still generally customize the portfile to extract it and install it in a usable fashion. And it's not like there aren't hundreds of examples of various ways to customize the portfile to do various things in all the existing packages. If anything, I'd say we need more cmake/vcpkg integration and better support for Android and iOS platforms from vcpkg, but aside from that it seems pretty solid to me.
&gt;The binary compatibility actually helps me out a lot, I'd be happy to continue working on the current ABI and adding features where we can. The concurrency stuff in particular just makes me sad because we are the platform of \`SRWLOCK\`, which is hands down one of our competitive advantages, but the standard library right now is smearing perf and correctness dumpster fire on top of it. And litearally years ago now I rewrote all that stuff to be awesome but still can't ship it yet.
I had not heard of this tool or OS. This is going to be a very useful article to guide my checking it out. Thank you!
In absence of a language-level naming standard, it's not really a bad thing to have company or project specific guidelines. I love this xkcd, but I don't think it applies here.
I get your point, but sometimes pragmatism just wins over dogma hands down. In my opinion, the Python naming conventions get it right; they are quite like my case 1b), with an appropriate mixture of lower and upper case.
I was mostly talking about things like Boost's XML parser, otherwise I agree. Boost does this weird thing where working with XML nodes is an absolute pain, and half of its "reader" methods don't actually return useful types, you gotta convert them yourself. So I typically end-up doing something like this: // "someAccessorMethod" returns a totally unusable type, so we avoid "auto". SomeActuallyUsefulType myVar = someXMLObject.someAccessorMethod(); myVar.notStupidelyComplicatedMethod();
While I agree that the situation is not optimal, it's not exactly easy to solve for C++. I recommend listening to [The State of Package Management in C++ by Mathieu Ropert](https://youtu.be/k99_qbB2FvM). If you can honestly make and popularize a perfect package manager for C++, then that would be great! I would absolutely love to see the situation with both package management and build systems improve for C++, but I think it needs to be a community effort and the focus should probably be on solving the actual problems rather than just creating new alternatives.
Agreed, we deserve something better and simple, some that simply works, effortless, i hope we get soon any of that
As you already analyzed the difficulty is the interop between CMake and a 'constrained' environment, because CMake was designed as an standalone system and does not offer good interfaces for integration into an higher level package manager. E.g: Cmakes find\_package mixes finding and configuring. If a package manager want's to enforce some aspects, information is defined in multiple places in incompatible ways and that's the reason why updates always break things. Vcpkg has lots of potential. But it's still in an very early stage. So I suggest to support it's evolution.
&gt; I think you'll find that the trick is not so much in writing a package manager, as it is in populating it with a useful database and then keeping it up to date. Well the other issues is that most package managers layer on extra scripting on top of the build scripts, which just requires extra maintenance burden of the package manager. When I created [cget](https://cget.readthedocs.io/en/latest/) I designed it to work with packages directly from the source tarballs without extra scripting. This is by following a common build and install flow. Some packages do not support this correctly, but a lot of times this can be fixed by updating the build scripts upstream instead of me supporting "alternative" build scripts like what other package managers do(although cget does support an alternative build script if necessary, but it is usually not). &gt; Or, alternatively, getting all those library authors to agree on supporting your format (in addition to the three(?) formats they are already expected to support). Three? There are a lot more than 3 package managers for C++.
What?
What?
Clear example, please? The ABI isn't only for interoperability. It also gives compiler implementers a baseline behavior and memory format from which to optimize. If the compiler "can't tell" that some part of your program doesn't need to be interoperable, that's the same as not implementing an optimization. But that doesn't mean you've paid for anything, it just means that the benefit doesn't exist yet.
Are you talking about how stdlib implementations hold off on container optimizations in some cases? About how platform ABIs are sometimes under-optimized for modern hardware? (e.g., needing `__vectorcall` liberally sprinkled around code or the headaches introduced by `/Gv` on MSVC?) Something more fundamental about the language, like aggregate layout/packing rules or something of that nature? All of the above? Something else?
What?
Well for example, P1196R0 was rejected for ABI reasons. Thus I am denied an improvement. However, I do not get any benefits from "ABI compatibility" in any of my projects. There are many examples of useful C++ features that were rejected because of ABI compatibility. We are all collectively being deprived of a better language and standard library because a subset of users care about ABI stability. Those who are not affected by ABI changes are impoverished as a consequence. [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1196r0.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1196r0.html)
Huh?
Why don't you contribute? All these projects welcome contributors, why don't you put your efforts into collaboration?
Anything and everything. Prioritizing ABI stability has two negative consequences. First, that we have to live with some bugs forever, and second that we are deprived of useful improvements. Such as the ones you listed.
I can't take this seriously, Maybe if you aren't allowed to use async await. C# is miles and miles better then asio because of this.
Is that new? This wasn't the case in earlier concept drafts.
Dunno man, just minding my business, waiting for a callback.
Are you talking about a CompletionHandler?
oh boo hoo
OP says: &gt;I can't wait for Networking TS. I can't wait for the new phone books to get here.
That's for you Boost maintainers, fancy people. The rest of us have to live with the word that comes to mind at the moment.
title: "Boost.Asio is easier than .Net.Sockets"
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bfg00o/what_is_a_great_place_to_learn_c_which_is_not/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I bet yours will suck too as well by my standards. I've been avoiding them forever, and they all fail as expected, I just stick to CMake (or maybe meson) for C++ projects, and my system's package manager.
I have contributed about 30 packages + a set of CMake tools for easier usage of Conan. This is not a thoughtless rant. I had hope in each one of these at different points in time. The majority of the problems I mention are not due to development efforts but due to administrative/design decisions which have been taken way before. I could go for radical change, but they would likely not accept.
You're attacking the wrong problem. The real one is the standard doesn't provide enough tools not to write non-standard code. For instance, allow generating code from within C++, then the need for preprocessors will disappear. And yes, I am aware of the spaceship operator in C++20 and the coming reflection and metaclasses.
I would actually suggest that every 2nd or third C++ release (so every 6-9 years) can break the ABI. This could allow for the necessary planning and would mean some things can finally be fixed.
Thanks, mr bot!
&gt; and don't forget to set options like "don't_randomly_crash", or it will Hey, my control key is hard to reach, so I hold spacebar instead, and I configured Emacs to interpret a rapid temperature rise as "control".
Try [build2](https://build2.org/) (do not confuse with b2 from boost).
I would settle for just one upcoming C++ release to break ABI (carefully planned of course).
Man, I know that feeling of not being able to ship some improvements, because they would break something else and now having to always remember, that a part doesn't work that well, but not being able to do anything. Well, MSVC is going to break ABI eventually or you are going to figure out a way to ship both symbols in the standard lib and just requiring to ship the newest version of it with the application (I think that is already required, but there may be intricacies I missed). I'm guessing inline namespaces don't work for you right now, but I've seen so many smart trick coming from the compiler and standard lib teams recently, I wouldn't be suprised, if you figure something out eventually.
I have libraries A, B, C that I will use in project D. B is not written by me and depends on A/1.0.0. C is written by me and depends on A/2.0.0. I am aware that this is bad practice, but it is often not under my control. It happens often when A is an essential such as zlib or fmt. The workaround is to either: \- Downgrade C to A/1.0.0. \- Fork B and upgrade it to A/2.0.0. Create official pull request. Wait for it to be accepted.
Well, I don't have a build cluster to begin with. I have plenty of powerful developer machines and developers that want to distribute their compile load. Icecream is very good for this use case. But I can see that Google has quite a different setup and has to solve different problems.
Tbh I'd rather implement that using std::uuid when it becomes available.
I just think that "meow" is better than "foo".
That would be an ABI break :)
Lol probably. But that becomes very unfeasible when you upgrade from small projects into a dependency list like: \`\`\` requires = (("assimp/4.1.0@RWTH-VR/thirdparty"), ("bgfx/master@acdemiralp/makina"), ("boost/1.67.0@conan/stable"), ("bm/1.0.1@acdemiralp/makina"), ("bullet/2.87@bincrafters/stable"), ("catch2/2.2.0@bincrafters/stable"), ("cppzmq/4.2.2@bincrafters/stable"), ("di/1.3.1@acdemiralp/makina"), ("ec/1.3.0@acdemiralp/makina"), ("eigen/3.3.4@conan/stable"), ("fg/1.1.0@acdemiralp/makina"), ("fi/1.0.2@acdemiralp/makina"), ("freetype/2.8.1@bincrafters/stable"), ("gl/1.1.2@acdemiralp/makina"), ("glm/0.9.8.5@g-truc/stable"), ("hdf5/1.10.2@acdemiralp/makina"), ("HighFive/1.5@acdemiralp/makina"), ("im3d/master@acdemiralp/makina"), ("imgui/1.53@acdemiralp/makina"), ("jsonformoderncpp/3.1.1@vthiery/stable" ), ("memory/0.6-1@acdemiralp/makina"), ("ospray/1.6.0@acdemiralp/makina"), ("parallelstl/20180619@acdemiralp/makina"), ("ra/1.0.0@acdemiralp/makina"), ("rttr/0.9.6@acdemiralp/makina"), ("spdlog/0.16.3@bincrafters/stable"), ("splinter/3.0@acdemiralp/makina"), ("stb/20180214@conan/stable"), ("TBB/2018\_U3@RWTH-VR/thirdparty"), ("uWebSockets/0.14.8@acdemiralp/makina" ), ("vkhlf/master@acdemiralp/makina"), ("zlib/1.2.8@conan/stable")) \`\`\` Which requires you to carry your computer around to show people cool things you have done because they will never bother building that shit without a package manager.
Which compiler? I'm asking because this is outside the scope of the standard.
I was surprised when binary compatibility was announced given the decision to drop XP targeting, which otherwise would have lifted some of the restrictions holding back the CRT.
Conan folks so far are very flexible in changing the design, though it depends on the fundamentality of such, and it absolutely requires input from the community to determine what are local use cases and what's the general practice that can help the community grow and learn. It's not gonna hurt anyone if you put an issue with a discussion about Conan directions in the issue tracker. And thank you for your contributions. The project needs more contributors though since there are so many things to handle from all over the ecosystem.
git modules and/or \`ExternalProject\_Add\` has been sufficient for me.
They _what_?
I wouldn't go that far. Overall they've closed the compliance gap considerably. It's just that there are some continuing lingering problems in places, like constexpr bugs and some of the C99 functions being really slow.
is ABI compatibility inside the scope of the standard?
No, the ISO standard doesn't recognize ABI. A set of members on the committee have very strong opinions and influence on implementations of the standard. That group is opposed to breaking ABI.
&gt; In absence of a language-level naming standard Hun? Do what the language and standard library already does... Yes, it **is** a solved problem. It was solved **back in 1972** when Denis Ritchie picked snake_case.
Proof of why Boost is dying
&gt; a set of CMake tools for easier usage of Conan Are you calling conan from cmake? I'm pretty sure that's backwards.
No, as I just said. What you are asking for is a feature on compiler level, under the control of compiler vendors, and nothing to do with the language or the standard.
Yes, this way I never have to "conan install". CMake does all Conan work for me automatically. And no it is not. Check [https://github.com/conan-io/cmake-conan](https://github.com/conan-io/cmake-conan)
I am recently working on json (rapidjson) implementation for our codebase. It is very similar to XML. Yes, boost XML/json only provide you the basic and all method regarding XML/json. In most cases, you really want to write your own wrapper to wrap around them for each individuals need. It is not a good idea to just call functions from third party library directly unless they also provide the wrapper layer. IMO.
In what way is it inconsistent?
Make Boost Great Again!
I like how it goes to LWG issues. Waiting for meow remarks in the standard .\_.
See also [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1197r0.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1196r0.html) [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1198r0.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1196r0.html) that were also rejected for ABI reasons, and [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1195r0.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1196r0.html) that hasn't been rejected entirely yet, but wasn't accepted for C++20 because of ABI concerns.
Thanks, that's what makes it worth it - the appreciation we get.
No package manager is going to solve that. C++, and other linked languages, just don't allow different definitions for the same symbols.
Yeah for specifically ints and pointers, you could do that. And hypothetically a standard library implementation could go wild and recognize that, say, a type in the `tuple` is `std::string` and directly use `compare()`. You could try submitting a patch and seeing what happens?
What makes this even worse, today, is that if a proposal breaks ABI on even one of the big three implementations, it's basically a no-go. This significantly impedes innovation; it's much easier to add new things to the stdlib than to improve or fix existing ones. (Not surprisingly, that's where everyone's efforts are concentrated. One can only hope that we're immune to the second system syndrome.) &amp;#x200B; ABI stability obviously has its benefits, but it comes at a price.
Unfortunately using snake case for everything doesn't solve the problem, because you can't disambiguate between type and function name that way.
In many many code bases I've seen, standard library names make up the minority of 3rd party, so consistency is not necessarily served, by following that convention. Also, I don't like the fact, that it doesn't distinguish between types and variables/functions.
i would just order a pizza
Yes they will, as long as A is a private dependency and you statically link B and C. You do not expose A to D.
My guess: There where no build systems to speak of when the header lookup rules where decided, and there is no reason to change the mechanism now.
Nevertheless, decisions about what changes are applied to the standard are very much influenced by concerns about ABI stability.
It still does affect decisions in the standardization process.
Have you liked the same paper 3 times?
Aren't iterator and const_iterator the same? If not, why not?
Packaging and build environments has nothing to do with a language standard. No one agrees on how projects should be organized. The committee however is hard at work trying to get modules out the door, but too many people have opinions and not enough facts. And you want to standardize a package system or build environment that works for everyone? THAT is a tremendous waste of time for a volunteer committee working on their own dime. And what most people forget is that the world already has a proper international standard for a packaging system and build environment: POSIX. The POSIX standard provides for `make` etc. And no one is happy with that, judging by how many people end up creating their own build systems. So what makes anyone think it is rational that a LANGUAGE can define a packaging and build system that everyone will use and keep up to date with modern practices? If you aren't happy with CMake being a cobbled together mess, imagine something like that making its way into the STANDARD.
This paper is specifically fixing a mistake where they tied an interface to an unreliable ABI feature. IMHO it‚Äôs more like, ‚ÄúIn standardization mistakes are impossible to fix at all, and WG21 lacks the resources and protocols to contest every poor design choice.‚Äù
Netcraft confirms.
They‚Äôre supposed to use R1, R2, R3 for this.
&gt;I am on the verge of writing the 4th package manager and I am going to do it proper, something these guys couldn't pull off with full teams in multiple years. And can we laugh at you when you inevitably fail to do it proper?
Fixed, thanks.
Sure or you can lend a hand.
WG21 is completely willing to break ABI, and has done so a handful of times. However, the consequences for all users (yes, including you) are much greater than other changes, so that is taken into account as a result. A stable ABI means things like linking works if you ever use a library that you didn't explicitly compile.
Implement parts of the standard library (and from Boost, even). Then you'll see why the language works that way.
The vcpkg FAQ specifically says that if you have fragile or weird version dependencies that you should fork vcpkg and customize them. In your case you'd want to take package A and create two separate vcpkg ports of it: `A` and `A_private`. `A_private` forces a static build and uses the 1.x version and set your B package to depend on `A_private` `A` is just a regular build and `C` depends on `A`.
&gt; I just wanna put "boost/1.66.0" in a text file and want boost in my project? Linux did this years ago. Did it though? What do you mean? `apt get install boost-dev`? That gives me a very ancient version on LTS/stable releases and the situation doesn't look too much better on the very latest distributions. Apart from a few exceptions like arch linux.
 I'd just like to interject for a moment. What you're referring to as Linux, is in fact, GNU/Linux, or as I've recently taken to calling it, GNU plus Linux. Linux is not an operating system unto itself, but rather another free component of a fully functioning GNU system made useful by the GNU corelibs, shell utilities and vital system components comprising a full OS as defined by POSIX. Many computer users run a modified version of the GNU system every day, without realizing it. Through a peculiar turn of events, the version of GNU which is widely used today is often called "Linux", and many of its users are not aware that it is basically the GNU system, developed by the GNU Project. There really is a Linux, and these people are using it, but it is just a part of the system they use. Linux is the kernel: the program in the system that allocates the machine's resources to the other programs that you run. The kernel is an essential part of an operating system, but useless by itself; it can only function in the context of a complete operating system. Linux is normally used in combination with the GNU operating system: the whole system is basically GNU with Linux added, or GNU/Linux. All the so-called "Linux" distributions are really distributions of GNU/Linux.
Hm. You don‚Äôt understand a lot of it, but you know enough to judge it a mess. That seems contradictory to me.
Do you not see how your response is just like the response others have given you for existing package managers? And do you not see how your attitude of cut-and-run is the exact same attitude that resulted in "3" package managers with glaring "sucknesses"? As I see it, you, and people whose main strategy for everything is cut-and-run and start their own new thing, suffer from the lack of plan for what to do when they run into big problems. Because if you had a proper plan, you wouldn't be doing it in the first place. You're doing it hoping you'll magically avoid big problems, which is how problems get to be the way they are in the first place. It didn't work for operating systems. It didn't work for languages. It doesn't even work for myriad independence movements around the world that think they can solve all their problems if they just declare independence, only to find out that the group of people with the same "identity" don't actually agree on anything either.
Tying the ABI to the default C++ standard level seems pretty sensible to me. (That is, when g++ 6 switched to -std=c++14 by default, it could have also switched to -fc++abi=14 or something like that.) So on a distro that uses g++ 6 as the system compiler, you'd get the C++14 ABI (and if you install g++ 9 there, it would default to that, so everything will still link.)
You can always link your program with the same standard library that comes with the toolchain you used to compile your program.
`span` isn't `string_view`; `span&lt;T&gt;` permits modifying the `T` elements (while `span&lt;const T&gt;` doesn't).
That's a very good point. I would expect, that \*if\* ABI compatibility is a concern, then the committee would be ultra-conservative in adopting new features, giving them even more time to bake. Instead we see the opposite, there is an acceleration to adoption, especially in the last ten years.
It's kind of the opposite. If the standard library components are kept frozen for ABI reasons and can't evolve, this allows their Boost counterparts to become non-obsolete again, bringing Boost back to life.
You DO use ABI compatibility. Every time you don't have to maintain slightly different versions of the same code to handle ABI breaks is you using ABI compatibility. I suggest calculating the true cost of not having ABI compatibility. It's like people who complain about social welfare costing them a lot on taxes don't understand how much they actually benefit from it being there even if they don't see where they depend on it.
The library packages on Debian/Ubuntu are all versioned. In the case of Boost, even the -dev packages are versioned (the unversioned ones just install the default version). If you want to use boost 1.69 or 1.70, it's a five minute job to build the full set of versioned packages for your distribution version, and install them, even put them on a custom mirror you add to your sources.list takes just a few moments. Most people can't be bothered to do that, but it's not at all hard to do if you actually want this.
N4810 20.8.4 [any.nonmembers]/8: "[Example: any x(5); // x holds int assert(any_cast&lt;int&gt;(x) == 5); // cast to value any_cast&lt;int&amp;&gt;(x) = 10; // cast to reference assert(any_cast&lt;int&gt;(x) == 10); x = "Meow"; // x holds const char* assert(strcmp(any_cast&lt;const char*&gt;(x), "Meow") == 0); any_cast&lt;const char*&amp;&gt;(x) = "Harry"; assert(strcmp(any_cast&lt;const char*&gt;(x), "Harry") == 0); x = string("Meow"); // x holds string string s, s2("Jane"); s = move(any_cast&lt;string&amp;&gt;(x)); // move from any assert(s == "Meow"); any_cast&lt;string&amp;&gt;(x) = move(s2); // move to any assert(any_cast&lt;const string&amp;&gt;(x) == "Jane"); string cat("Meow"); const any y(cat); // const y holds string assert(any_cast&lt;const string&amp;&gt;(y) == cat); any_cast&lt;string&amp;&gt;(y); // error; cannot // any_cast away const -end example]" (This wasn't my doing. My feline allies are everywhere.)
Those are two different types though. And as const is not transitive (you can use a `const std::span&lt;T&gt;` to modify the underlying elements), I don't see, why you should need two different iterator types per span type.
This is not a productive comment. If you disagree, either downvote in silence, or post a constructive comment explaining why you disagree. Content-free dismissals make communities more hostile, less rational places.
If "my projects" includes Beast, surely you do get benefits from ABI compatibility in that people using Beast do not saddle you with problems around ABI compatibility.
`vector&lt;int&gt;` is modifiable, but you can get a `const_iterator` that only observes. Similarly, `span&lt;int&gt;` is modifiable, but you can get a `const_iterator` that only observes. This seems entirely consistent and reasonable. (Whereas `span` lacking deep const is different than `vector`, and makes it more like `shared_ptr`.)
Yeah I was referring to apt/yum/pkg in a general sense, not necessarily to obtain libraries but as general purpose package managers which at least deterministically do what they are meant to do, are easy to use and almost never break.
&gt;For instance, allow generating code from within C++, then the need for custom preprocessors will disappear. I'm not sure if this takes [on-line code generation](https://github.com/Ebenezer-group/onwards) into account.
Build system is not a package manager, trying to make it into one is a bad idea. It makes it basically impossible to repackage your lib/program for OS package manager if it ever becomes popular.
I've reported this bot for busting.
It depends what your goals are. In maintaining a cross-platform C++ codebase, I've had to maintain and contribute packages and package updates and fixes to: - Debian/Ubuntu - Homebrew/MacPorts - FreeBSD ports - Custom internal CMake ExernalProject-based package builder/installer/manager - vcpkg - other adhoc fixes for Fedora/CentOS It goes without saying that writing a package manager isn't the hard part. It's the ongoing maintenance that will be the time sink. I wrote a fairly decent custom cmake-based tool which worked on multiple platforms including Linux (all common distributions), MacOS X, FreeBSD and Windows. Testing it worked with multiple variants including multiple compiler versions is a lot of work. Maintaining patchsets against upstream and forwarding them upstream takes a lot of work. I did this work predating vcpkg. Windows was the primary driver, since all the other systems have decent-ish package repositories already. Once vcpkg came of age, I ported a few missing libraries and ceased maintenance of the custom tool. Now it's just the occasional port update for vcpkg or one of the others. Since this is all just a means to an end--making, testing and distributing software--the package manager isn't intrinsically exciting. It's a solved problem. A "universal" solution which worked everywhere would be really nice. But it's a pipe dream. These systems all have their own fully developed solutions, and we have to work within those constraints. Taking the time to develop a new tool would be (1) inferior to the systems which have over two decades of development behind them e.g. dpkg, BSD ports and (2) would be an unjustifiable time sink which would detract from my core responsibilities. None of the above is intended to discourage. I just want to put the problem into perspective. Using the available existing packaging systems lets you take advantage of work done by thousands of people. No one person, or even a small dedicated team, can both reinvent that wheel better than they have done and keep it continuously up to date. It's a thankless task, which is best kept to a minimum if you can avoid it. (I also spent over a decade packaging libraries for Debian, so I do have an informed perspective.)
My question is: so what? At the end of the day, so what? No language is without difficult bits. 1. and 3. Just use std::array. 2. and 6. Surely, they're self-defeating complaints? You want passing by ref the default, but you don't want silent passing by ref, which means it isn't the default. 3. 7.
The fact that span lacks deep const is exactly the reason, why separate behavior for iterator and const_iterator doesn't make sense and is inconsistent. Also, there is no vector&lt;const int&gt; and if there where, a conversion between the two would probably be expensive, which is imho the only reason, why you need a const_iterator in the first place. Span encodes constness of the elements directly in the type and you can easily create a `span&lt;const T&gt;` from a `span&lt;T&gt;`, so why would you try to replicate that functionality in the iterators? Make similar things similar and different things different. Please also see my edit in the previous post.
We should perhaps be more careful with the use the words package and dependency when OS package managers come into the chat. This is a setup consisting of a build system (CMake) and a dependency manager (Conan) working in collaboration to build C++ executables/libraries. There are further options for directing the outputs of this pipeline into an OS package manager, such as [https://schneide.blog/2013/02/11/build-a-rpm-package-using-cmake/](https://schneide.blog/2013/02/11/build-a-rpm-package-using-cmake/) .
Just use std::array - well yes, still adds verbosity. 2 and 6 aren't self-defeating. My dream is passing by const ref by default, and passing by ref without const requires some annotation at the call side
I think Scott Meyers' Effective series of books is exactly what you're looking for. Effective C++ Third Edition, Effective Modern C++, and Effective STL are probably the ones worth reading today.
Submiting to who, where gcc llvm ? Just for testing with is\_integral code below fast fix, i think it could be much better writen // This class performs the comparison operations on tuples template&lt;typename _Tp, typename _Up, size_t __i, size_t __size&gt; struct __tuple_compare { static constexpr bool __eq(const _Tp&amp; __t, const _Up&amp; __u) { return bool(std::get&lt;__i&gt;(__t) == std::get&lt;__i&gt;(__u)) &amp;&amp; __tuple_compare&lt;_Tp, _Up, __i + 1, __size&gt;::__eq(__t, __u); } #define __ENABLE_TUPLE_LESS_TT_LESS 1 #if __ENABLE_TUPLE_LESS_TT_LESS template&lt;typename lelem_type, typename relem_type, typename std::enable_if&lt; std::is_integral&lt;typename std::remove_reference&lt;lelem_type&gt;::type&gt;::value &amp;&amp; std::is_integral&lt;typename std::remove_reference&lt;relem_type&gt;::type&gt;::value, int &gt;::type = 0&gt; static constexpr bool __less_by_traits(_Tp const &amp; __t, _Up const &amp; __u, lelem_type lel, relem_type rel ) { if( lel != rel ) return lel &lt; rel; return __tuple_compare&lt;_Tp, _Up, __i + 1, __size&gt;::__less(__t, __u); } template&lt;typename lelem_type, typename relem_type, typename std::enable_if&lt; ! std::is_integral&lt;typename std::remove_reference&lt;lelem_type&gt;::type&gt;::value || ! std::is_integral&lt;typename std::remove_reference&lt;relem_type&gt;::type&gt;::value, int&gt;::type = 0&gt; static constexpr bool __less_by_traits(_Tp const &amp; __t, _Up const &amp; __u, lelem_type const &amp; lel, relem_type const &amp; rel ) { return bool(lel &lt; rel) || (!bool(rel &lt; lel) &amp;&amp; __tuple_compare&lt;_Tp, _Up, __i + 1, __size&gt;::__less(__t, __u)); } static constexpr bool __less(const _Tp&amp; __t, const _Up&amp; __u) { return __less_by_traits( __t, __u, std::get&lt;__i&gt;(__t), std::get&lt;__i&gt;(__u) ); } #else static constexpr bool __less(const _Tp&amp; __t, const _Up&amp; __u) { return bool(std::get&lt;__i&gt;(__t) &lt; std::get&lt;__i&gt;(__u)) || (!bool(std::get&lt;__i&gt;(__u) &lt; std::get&lt;__i&gt;(__t)) &amp;&amp; __tuple_compare&lt;_Tp, _Up, __i + 1, __size&gt;::__less(__t, __u)); } #endif }; &amp;#x200B; The otpimised variant - with clang compare_2(std::tuple&lt;long, int, int&gt;, std::tuple&lt;long, int, int&gt;): # @compare_2(std::tuple&lt;long, int, int&gt;, std::tuple&lt;long, int, int&gt;) mov rax, qword ptr [rsi + 8] cmp qword ptr [rdi + 8], rax jne .LBB0_3 mov eax, dword ptr [rsi + 4] cmp dword ptr [rdi + 4], eax jne .LBB0_3 mov eax, dword ptr [rdi] cmp eax, dword ptr [rsi] .LBB0_3: setl al ret The unoptimised - with clang compare_2(std::tuple&lt;long, int, int&gt;, std::tuple&lt;long, int, int&gt;): # @compare_2(std::tuple&lt;long, int, int&gt;, std::tuple&lt;long, int, int&gt;) mov rcx, qword ptr [rdi + 8] mov rdx, qword ptr [rsi + 8] mov al, 1 cmp rcx, rdx jl .LBB0_7 cmp rdx, rcx jge .LBB0_3 xor eax, eax ret .LBB0_3: mov ecx, dword ptr [rdi + 4] mov edx, dword ptr [rsi + 4] cmp ecx, edx jl .LBB0_7 cmp edx, ecx jge .LBB0_6 xor eax, eax ret .LBB0_6: mov eax, dword ptr [rdi] cmp eax, dword ptr [rsi] setl al .LBB0_7: ret
Outputs, sure, but when making a package for OS package manager, you want to feed the build system of your library/executable with the dependencies it needs from the same OS package manager, and not ones downloaded and built separately. If only to avoid bloat.
&gt; It is hell to create packages for my own libraries in Vcpkg and am left to Microsoft's willingness to package the libraries I need. There's a learning curve, just like the BSD ports or Debian packaging, but there are several thousand packages you can use as examples. It didn't take me long to package a new library. I've submitted new packages to vcpkg, as well as updates, patches and fixes to others. It's pretty open and transparent, and while it's managed by Microsoft staff it's open to contribution from anyone, and so you're not dependent upon Microsoft to package the stuff you need, just upon their willingness to review and merge your PRs. Overall, my experience of this process has been quite positive, and I quickly got vcpkg to meet all my needs. Better yet, once submitted, the packages I submitted have also been updated by others, so the maintenance burden is already reduced.
Yeah, to gcc or llvm.
My main pain point with C++ is with some of the tooling, mainly dependency management and build systems. Points 1,2,5,12 are basically the 1st point reiterated several times. That said, I really like the compatibility that C++ has with C. It ain‚Äôt complete, but it makes life so much easier to consume C libraries including system libraries. I would argue that anything within the std namespace is library-related and not inherent to the language. I don‚Äôt mind ‚Äúusing‚Äù having more functionality, it makes more sense than adding more keywords to the language I believe. It‚Äôs also the keyword used by C# for aliasing as well. The discussion on constexpr if introducing a scope unlike Dlang‚Äôs static if, I find not too convincing. It keeps with the grammar of the language and can be worked around. Glad concepts are coming. Can‚Äôt say the same about modules though! For whatever I didn‚Äôt address in your points, I implicitly agree!
&gt; Every time you don't have to maintain slightly different versions of the same code to handle ABI breaks is you using ABI compatibility. I never have to do that, because I simply require users to recompile everything using the new version. Beast offers no promise of ABI stability, that would be far too constraining for such a young library that is still evolving.
&gt; people using Beast do not saddle you with problems around ABI compatibility There's no saddling; ABI compatibility is "out-of-scope" with respect to Beast.
&gt; No one agrees on how projects should be organized. Java manged this, for the most part. The Maven source layout is a de-facto standard in that world. I agree it's not part of the language standard; you can use javac in a Makefile or Ant script and do it all by hand and use whatever layout you like. But by and large, the whole Java community adopted the Maven layout as accepted good practice, and despite its verbosity it has a huge number of advantages. Any Java developer can open up any standard Java project in an IDE and get going. Sources, tests, resources, generated code, test output, build products, jars, documentation. Multiple components. Dependency management. It's all covered. I do wonder if a similar structure could be adapted for C++. It could certainly be simplified compared with Maven. And build tools like CMake could quite easily have functions written which infer most of the details from the structure of the source tree, making the CMakeLists.txt files minimal and primarily data-driven.
&gt; people who complain about social welfare costing them a lot on taxes don't understand how much they actually benefit I agree that there is likely some non-zero benefit to everyone. But for many people, the magnitude of this benefit is less than the cost. In other words, it is a net-negative.
"The signal to noise ratio of an unmoderated, digital public social space trends towards zero"
If it's a library like zlib or fmt then this is generally a non-problem. These libraries are very stable in terms of API and ABI and vcpkg providing the latest version isn't going to cause any problems.
&gt;Java manged this, for the most part. The Maven source layout is a de-facto standard in that world. I would argue that they haven't managed it. [https://www.youtube.com/watch?v=mBmExt184vc](https://www.youtube.com/watch?v=mBmExt184vc)
Well there you go. You don't have to do that. You require everyone else to have to do that. And they don't want to have to do that. That's why they want the standard to have ABI compatibility, even if it gets in your way. In another reply, you talked about net-negative. Well, I say what you propose is a real net-negative. &gt; For example, many companies developing a proprietary application that does not interface with customer code also have the luxury of not caring about ABI compatibility - they can just recompile everything. That does not work for something that is a standard. As you say, proprietary code does not interface with customer code. But the standard is not proprietary code, and affects everyone. Having the standard break ABI compatibility when it's convenient is like companies dumping all their waste into the rivers and the air. It's cheaper and easier for the company, but everyone else bears the cost. Judging by your reply to my other comment, I guess that doesn't concern you.
&gt; I guess that doesn't concern you I think speculating on what does or does not concern me is unproductive. "Break ABI in every revision of C++" is just as bad as "never break ABI." A middle ground is reasonable. Planning an occasional version where ABI is allowed to change, and rolling up all the fixes and improvements that never made it in because of ABI seems like a good balance between stagnation and instability. While it is true that breaking ABI incurs a cost, there is also a cost to stagnation.
Const means a lot for optimizations. Just not const ref
If const ref is default, how can someone specify that they want to pass by value? Annotating passing by non-const ref on the call side is pointless if a function does not declare that it accepts an argument by non-const ref. So even with call side annotation, the function itself must still declare the argument non-const ref. So you've forced people to have to repeat themselves, when in most cases people would already know from the function signature that any non-const argument may be modified.
I'm working on a textbook for a scientific programming class in C++/Fortran2008. [https://bitbucket.org/VictorEijkhout/textbook-introduction-to-scientific-programming](https://bitbucket.org/VictorEijkhout/textbook-introduction-to-scientific-programming) It includes many small programs. Maybe that's of use to you.
I mostly write C#, Python, and Powershell these days, but reading all this really makes me wonder why anyone subjects themselves to C++ when they could be writing Rust or Go or some even more esoteric languages like Erlang and Haskell.
It might be worth pointing out here that Visual Studio up to 2015 broke ABI with each release. So we do have a rough idea of how things work in the ABI stable world (Linux) and how they worked in the ABI unstable world (Windows).
The comment still performed the valuable service of providing me with a hook on which I could hang my sarcasm.
if you can't google a bazillion of articles that gently walk you through modern c++ code examples while holding your hand and being all pedagogical and shit, then you need to go try and find r/cpp on reddit. it's a place where material suitable for reading is posted all the time.
This is really informing. Thank you for transmitting the experience. I am aware that do it better part will not become reality, at least not alone. I know that I will not be able to develop the standard C++ dependency manager by myself with \~8 years of experience in C++ and its build systems. I am just greatly suffering from the lack of a stable tool, although your experience tells me that there are ways to make them work fine with some effort. It took me a full day of frustration to get Conan/CMake/VS to work, a "stack" which I was using effortlessly several months ago. I had to update several Conan files, get the CMake VS2019 generator to run, and then troubleshoot issues due to VS2019's internal CMake lagging 0.1 version behind, self-conflictingly preventing MSVC142/VS2019 builds. I am just dreaming of a world where no one has to go through occasional days similar to this, press a button, get a build with all dependencies for any C++ library/executable on a Windows/Linux/Mac. You make me realize that this dream is not possible by going solo, but by joining the community effort.
Breaking ABI incurs a bigger cost than stagnation. Have you ever dealt with a customer when you've changed a core aspect of the way they used your software? Do you know how much it costs you if a customer no longer wants to deal with you breaking their workflow, compared to the cost of you not being able to do one little thing that is nice to have? &gt; A middle ground is reasonable. And the standard has broken the ABI when it needed to. The problem is everyone thinks their reason to break an ABI is reasonable. At the end of the day, the reason why Beast is used is because it is written in a language that does guarantee stability. Others use that language for compatibility, and so come to Beast because it's a convenient step. If you didn't have that language, you wouldn't have Beast. Sure, you'd write a similar thing for a different language, but look at all the other languages out there that don't guarantee stability, and see how much abandonware there is because they can't guarantee stability.
And why isn't it doing so after VS 2015?
Unless you wish to dynamically link. Additionally, any time we change the ABI with language versions, we end up having to ship multiple versions of the standard library, then link them based on the C++ version. Its a giant pain for vendors and users alike, so WG21 tends to avoid it unless the change is worth it (or we're breaking ABI anyway).
When it comes to going solo or joining a group effort, the main consideration is one of scope. Solo, you have complete control but limited resources such as time and people. As a community effort you have more resources but less control and have to fit in with existing conventions. As an example [this project](https://github.com/ome/ome-cmake-superbuild) is the internal tool I wrote. It handles first-party and third-party dependencies, including special handling of python2 and 3 virtual environments, recursively computes and solves the dependency graph, and works on multiple platforms. It does exactly what this project needed. But, the number of packages is limited, and the maintenance burden was completely borne by this project team (primarily myself). Being written completely with CMake, you'll probably pick up most of what's going on pretty quickly. The recursive dependency solving is slightly tricky, as is the use of lots of helper scripts with externalproject and passing escaped data between scripts. It's basically a simple form of what vcpkg does. And that's why ultimately, vcpkg was the way forward. Because even if it wasn't exactly what the project needed, it did 95% of it and that was good enough for the switch to be worth it. Now my documentation and advice is simply "use vcpkg and install &lt;package-list&gt;". This is also a bonus because of user familiarity. As with cmake, having commonly-used tools makes things simpler and more accessible. So that was also a consideration too. Ultimately, the entire library collection will be available via vcpkg, both dependencies and all our libraries too, so it's a one-stop shop for everything an end user (developer) will need.
I knew someone was going to say this, and here's my response to it: don't try to solve all problems. Make an 80% solution, and the other 20% can either adjust to be in your 80% or continue doing what they're currently doing. The problem C++ package managers have is that they claim it's hard for C++ because of all these edge cases, when really, just don't support everything that's possible. Imagine a packaging system that's amazing, but you have to do things their way. And over the next 20 years everyone starts doing it that way. THAT is how you solve the "package management is hard" problem in C++. generationally, not by trying to support all current craziness that people do.
What's the difference between this and asserts/exceptions?
Just read D&amp;E.
C++ tries to be expressive at both a high abstraction level and also retain expressiveness close to the metal. There's going to be trade offs. The other option is hard bindings between languages of different abstraction levels, which seems rather inefficient when you have to rewrite portions of your code base when you realize you're operating at the wrong abstraction level. How would you handle the tooling for that? If I would say what's "wrong" with C++ it's allowing too much flexibility, which can cause more cognitive load and difficulty for beginners who haven't developed intuition yet.
/r/lostredditors
In part because they wanted faster and quicker adoption of new VS versions and in part because people bitched about the problem of ABI breaks enough to force MS to change direction. This is my opinion as a consumer of VS and not necessarily what reflects reality.
Static analyzers can be designed to check for contract violations more easily than asserts, and also contracts can be a precondition (so they‚Äôre automatically applied before the function runs) or a post condition (so they‚Äôre applied to the return value, after the return occurs). Or they could be axioms, which state that something must always be true. In addition, there‚Äôs more fine-grained control on when or which ones get run. In release builds, no contracts get tested at runtime. Also, unlike an exception, a contract violation is always bug.
What is that?
We could standardize a way to describe and translate different ABIs to the compiler. Maybe that's too ambitious.
I think a better solution would be to standardize on a decent build system so that we can recompile the world more easily when ABI breaks.
Every person in my team of 12 people had zero experience on C++11 and up, yet we start a project commiting using everything available in c++ up to 17. It is a long learning curve, almost every PR is full of "ST: try xxxx that has been available in c++14,17 for better xxxx bility." After a year and a half, we are only half way their, people are still using raw pointer initially, for example.
Exactly. In the end, most people don't like it when things that used to work don't work. Because when things work, people then build things on top of it that also work, and they hate it even more when those things don't work. It's the Mullerian Two-Step road to irreducible complexity.
Of course one of the benefits they probably don't add up on the tally sheet is preventing social revolution. Communism doesn't come from nowhere, and a large mass of really pissed off and desperate poor people is basically a powder keg waiting for the right demagogue to come along and put a match to.
For simple little projects it's very tempting to just start using namespace std, as it makes your choose more concise. However, the larger your code is, the longer it lives and the more platforms and compilers it supports, the more possibilities arise of some clashes
&gt; because it includes functions that you won‚Äôt being using in your program This just isn't true. Maybe there was a misunderstanding about what the speaker was trying to say? `using` doesn't *include* anything, that's the job of `#include` (and soon to be `import`), and you explicitly include everything that will be in your program The canonical reason why `using namespace std` is bad is, when using it globally (like in a header or at the top of a cpp file), it pollutes your global scope with functions, variables, and classes that may conflict with other things in your global scope, from libraries you use, or other `using namespace` namespaces. For small programs, it doesn't matter, but as your projects scale up you increase the chances of *something* conflicting. It could be a variable named `istream` that represents an index into a stream now conflicts with `std::istream`, or a custom `string` class in a library you included isn't in a `namespace` properly (bad design, but it happens) or was brought in by another `using namespace` statement. The compiler doesn't know which one you want, so it's an ambiguous reference error. That said, you *can* use `using namespace` in a scope, and it will stop being effective at the end of that scope (like in a function), but many people prefer to be explicit and type `std::` before all standard stuff.
The `std` namespace has become so huge and unwieldy since C++11 that it can be trivially easy to accidentally include names that clash with those in the current or global namespace, particularly ones pulled in from another header. The result might appear to be a simple variable of function redefinition error or something harder to track down. Generally, if you're not writing a simple "hello world" implementation or a small homework project, IMHO it would be a good idea to get into the habit of using using-declarations for namespace members instead of using directives for namespaces.
Many are probably working on existing codebases and some of it is probably performance critical and there‚Äôs a lot of inertia behind C++ not to mention it‚Äôs in extremely wide use.
Removed since this is a common question. Check [this link](https://stackoverflow.com/questions/1452721/why-is-using-namespace-std-considered-bad-practice).
&gt; 3. Just use std::array. Huh? You can't use an `std::array` in place of `std::initializer_list`. Not for the standard containers anyway...
I mean if after 5 years one still struggles with what should be basic concepts, yes, you can definitely be enough of a judge that at least some parts are wrong.
&gt; If I would say what's "wrong" with C++ it's allowing too much flexibility It's both good and bad. While I would say that for example C# is better for beginners (and possibly shorter projects), I prefer the control that C++ gives me, so I can code exactly the way I want. If C++ was as restrictive as other higher level languages, I'm not really sure why we would be picking it over them...
Riiight. I will listen for judgment for the person who does not understand it. That makes a whole lot of sense. Note that the statement was not that C++ is large or complex or difficult to understand. The statement was that it is a huge mess. And pardon my stubbornness, but I prefer to take the advice of those who have a clue over those who proclaim they don‚Äôt. :D And I know, r/unpopularopinion.
Seems kinda fucked up to downvote the one person who bothered to answer to your 'unpopular opinion', but have it your way.
Yeah. So does cursing just because you don‚Äôt agree with something.
Or reporting something because you lost an argument? :p
&gt; Just use std::array. bool is_array(const char*) { return false; } template&lt;size_t N&gt; bool is_array(const char (&amp;) [N]) { return true; } void main() { std::cout &lt;&lt; is_array("raw-string-literal") &lt;&lt; std::endl; } The above program prints false. "Just use std::array" is silly advice when the language does stupid crap like the above. In this context it's *not possible* for a non-const, non-array, to select the template function, so the only thing that makes sense is for the second function to be preferred over the first. Except C++ wants to decay an array more than it wants to do template instantiation.
What's more concerning is that 1) dynamic linking is here to stay in its different variants, and that, at the same time, 2) the committee lands on standardizing features in a way that is incompatible with it. A standard that doesn't recognize the reality to which it should apply is a dubious one.
HEY! BUT... *sees username* Oh. This is probably the ~10th time you've gotten me. Have you no desire to accrue those sweet and delicious fake Internet points?
I agree with white wolf. Some of the points raised in OP's post are mostly questions of convenience, and hints at a lack of deep understanding of c++ concepts.
Marking the day on the calendar! ;)
Best I can give you is a `CompletionToken`. Take it to the counter and you get a free `CompletionHandler`, but if you get enough of them you can win a cheap Happy Meal Toy.
I don't get it. Unless we know each other from some old hungarian forums.
Oh. Just self deprecating lame joke. Someone agreed with me, so I mark it on the calendar. Piros bet≈±s √ºnnep. We may know each other if you have ever been to the friderikusz, internetto, index or origo forums in the ancient times. IIRC I was posting as myself there. I mean with the nick ‚Äúmyself‚Äù.
 template&lt;typename T, size_t N&gt; bool is_array(const std::array&lt;T, N&gt; &amp;) { return true; } For new code. Obviously.
For their own code. And if they can use C++17, this also works: for (auto c : std::array{0,1,2,3,4,5,6}) std::cout &lt;&lt; c &lt;&lt; ' ' &lt;&lt; '\n';
&gt; 3. Just use std::array you can't. &gt; This is a wrong complaint. The complaint should be that things are not immutable by default. Generally yes, but not with the stupid way c++ does moves. std::move(something_const) will just silently pass and do the wrong thing(copy) and all the other criticisms of std::initializer_list are valid. its an abomination and should never be used (sadly the std library has to).
The include mechanism is a mess. You have to type declarations twice (in .h and .cpp), and keep them consistent. You have to use include guards. It is difficult to share files between projects. &amp;#x200B; Exceptions are too slow.
How does that do any good for raw string literals? Maybe I didn't explain clearly, as my original reply was lost to a browser crash where I provided more details. The original reason I discovered this issue was specifically with regard to string literals, and determining the length of them at compile time instead of runtime, as an optimization, in a codebase that has many millions of lines of code, and many many thousands of lines of code that directly use a series of custom string handling functions that rely on code such as the two example functions i provided, but for determining string length instead of whether they're arrays or not.
Nice list. I'd add implicitness by default - ctors, conversions, etc.
Having thought about this for a while, I suddenly realized I'm complaining about the wrong language. All of the things I didn't manage to compile are actually C libraries, rather than C++ libraries; the C++ libraries I've used (Boost, Angelcode, several commercial libraries) generally compile just fine out of the box. This might have something to do with C++ authors often throwing in a Visual Studio project file you can open, after which it will compile just fine, while C authors are often Linux-based, typically don't give a rat's ass about Windows, and occasionally go out of their way to be hostile to Windows developers.
Here are several ways to get yourself started. * Read about the c++ core guidelines and Scott Meyer's Effective c++ book * https://github.com/isocpp/CppCoreGuidelines * [https://www.amazon.com/Effective-Modern-Specific-Ways-Improve/dp/1491903996](https://www.amazon.com/Effective-Modern-Specific-Ways-Improve/dp/1491903996) * [https://github.com/AnthonyCalandra/modern-cpp-features](https://github.com/AnthonyCalandra/modern-cpp-features) * The best way to read them without getting really bored or overwhelmed * Is 2 ways (Also this is my opinion) * Read the table of contents for each * Honestly just doing this is a valid tactic. Often when I'm bored I'll crack open the book/guidelines and browse the table of contents and be like "WOAH", "WHAT", "HUH" * Turn up ALL the warnings + more * I work in Visual Studio almost exclusively so check W4 and then combine it with Resharper (Google "resharper c++") You can use clang intelligence thanks to resharper to pick up on even more errors that will tell you that you should be using modern c++ practices. And if you use these flags * \*,-cppcoreguidelines-\*,-cppcoreguidelines-\*,-google-\* * clang -Wall -Wextra -Weverything -Wno-c++98-compat -Weffc++ * Feel free to look these up / add more * You'll slowly start learning some modern c++ via just Visual Studio or Resharper or Clang yelling at you. * Also learning this way you can look up with resharper or with google why the thing you are doing is wrong / not modern. * Extra advice * Often you can just google "how to do X in modern c++" * Example "How to do random in modern c++" * And the top answer will generally get you someone saying something about &lt;random&gt; * From here based on the quality of the answer either trust them, or go find better documentation from either the above resources or from here: [https://isocpp.org/](https://isocpp.org/) * Look at other languages like Rust, Go, Jai * Example rust generics have better error messages than c++ * How do you do this in c++? * Well the answer is in c++ 20 * [https://en.wikipedia.org/wiki/C%2B%2B20](https://en.wikipedia.org/wiki/C%2B%2B20) * I'll let you explore * But my main point is that by looking at new languages you can learn more about modern c++ by asking yourself "Can I do this in c++?". Often the answer is yes but the syntax is gross or in a newer standard. But better that is a heck of a lot better than nothing!
So you're really saying the standard library implementations are slower than a highly-optimized hand-rolled one? Woah
I'm in a love-hate relationship with MSVCs debug iterators. They're incredibly useful to catch miss-used iterators/mis-matched iterators but they're *so* slow because of all the mutex locking.
Amazing idea with compiler warnings
Can it be turned off by changing the value of DEBUG_ITERATOR_LEVEL define to 0 or 1?
Repost of [https://www.reddit.com/r/cpp/comments/aha5nn/is\_c\_fast/](https://www.reddit.com/r/cpp/comments/aha5nn/is_c_fast/)
I don't use to often gcc as on mobile platforms llvm is used thise days so dont have knowlege how they will react, but all my bug reports to llvm are still open after years , 3 bugs are from 2013. This would be a waste of my time. https://bugs.llvm.org/show_bug.cgi?id=17489 https://bugs.llvm.org/show_bug.cgi?id=16977 https://bugs.llvm.org/show_bug.cgi?id=16986 https://bugs.llvm.org/show_bug.cgi?id=17531
Why would you want `operator &lt;&lt;` as a member function? Is `friend operator &lt;&lt;(...)` insufficient?
&gt; How does that do any good for raw string literals? The original question says nothing about raw string literals. Only about arrays decaying to pointers.
Hmmm are you sure? I've been submitted a lot of 'this debug performance is bad' bug reports but I haven't seen a real world case where iterator debugging was the primary cause of debug slowdown. /RTC1 and the debug \*heap\* were usually much bigger impacts. That said, if you're in a situation where iterator debugging creates a problem, we encourage you to set \`\_ITERATOR\_DEBUG\_LEVEL == 0\`. Use of the algorithms library, or range-based for, will also reduce costs because both amortize the cost to per algorithm rather than per element access. And of course, if you have partiularly egregious benchmarks, we're listening over at [https://developercommunity.visualstudio.com/spaces/62/index.html](https://developercommunity.visualstudio.com/spaces/62/index.html) \-- I was able to make the benchmark in this post quite a bit better.
It is unpleasant when you have type things twice, and it even gets more unpleasant when the class is a template. Declaring friend functions of a template is unpleasant. Of course, it is solvable. One can also define a print( std::ostream&amp; out ) const function, and call this function from &lt;&lt; .
I seriously don't understand the massive downvote. I think even in Bjarne Stroustrup's "Tour of C++" he mentions that an assignment/exercise he gives to his students is to reimplement std vector. That alone gives great insight as to how to use even the more advanced parts of the language. Reimplementing parts of the standard library is PRECISELY what this person was asking for: something to see the concepts applied somewhere, and something concrete to study. \----------------------- This just goes to show the massive group think of supposed nerds who, not understand something, massively downvote a reply made in good faith.
Focus on solving your problems in a readable way rather than which language features you use. I stay quite up to date with roughly what‚Äôs going on so that I know what to google for when a new feature might help me. Just reading through the Wikipedia page about C++11/14 might be enough.
Just define the operator inside the class, no need to type things twice.
[discussion on stack overflow](https://stackoverflow.com/questions/3989678/c-template-friend-operator-overloading)
Ah, I wasn't aware of that subtlety. Thanks for the info.
But it also says that one could give the full definition inside the template. I will try that also.
&gt;with regard to string literals, and determining the length of them at compile time instead of runtime It just doesn't work. Even if you remove the non-template overload and thus force the compiler to instantiate your template - string literals are indistinguishable from regular char arrays. Think about something like `char Buffer[256]; api_call(Buffer); auto Len = static_strlen(Buffer);` \- you don't want to get 255 here, but you will. Think about `const har Data[] { 'f', 'o', 'o' }; auto Len = static_strlen(Data);` \- you don't want to get 2 here, but you will. The only way to get such optimisation is to move on, ban raw string literals in your codebase and use `""sv` everywhere.
0
The latest version boost from Ubuntu 18.04 is 1.65.1. I can build boost by myself (using b2), but that's not what I want, that's exactly what the package manager should handle. I am pretty sure I will \*\*not\*\* find out within 5 minutes how to build a "versioned" boost 1.70 with \`apt\`. Also even if, you can pretty much bet that in more than half the cases you try something like that, there will be some compiler error because no one has tested that particular new boost version with the compiler of that particular Linux. You know how often it happened to me that I upgraded MSVC or gcc and the very latest boost version, that was just released, did \*\*not\*\* compile without errors.
C++ doesnt have reflection, sadly.
Hah, gotcha. Btw, no, I haven't frequented those forums.
What's wrong with repeating passing by ref at the caller side? For me, it improves readability. I appreciate this in C# a lot. If you write code, you most likely know the functions signatures. If you just read the code, not so much. &gt; how can someone specify that they want to pass by value ? Special syntax in the function header, making a pass by value explicit. Of course, this way we lose backward compatibility with C, so it ain't gonna happen
5. It means something. For correctness, which is also a thing. 10. "citation needed". Exceptions outperform error codes when used correctly, i.e. for situation that are exceptional, as demonstrated [here](http://nibblestew.blogspot.com/2017/01/measuring-execution-performance-of-c.html). 12. This needs to change, and there is absolutely no reason why it shouldn't ('performance loss on 16-bit x86' is an acceptable sacrifice). It means we can't even use a `set&lt;foo *&gt;` to keep track of a set of foos, for f sake. 13. Totally agreed. The idea that bytes in RAM need blessing, *or the optimizer will get you*, means among other things that C++ is not \_at all\_ compatible with C libraries anymore - since those typically don't allocate their bytes using `new`. The definition of "object", as it is, is far too strict and far too wide reaching; for something like an `int` it is sufficient that it has the right alignment. Having to call an empty magic function to make it acceptable to the compiler is an embarrassment.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bfnero/can_i_have_some_help_with_functions/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt;Exceptions are too slow. No [they're not](http://nibblestew.blogspot.com/2017/01/measuring-execution-performance-of-c.html).
There's this idea out there that package managers and build systems should be separate things, so you end up with N package managers and M build systems and you get this mess where everyone uses something different and nothing works together properly. In my view that's the problem. Downloading dependencies und building software are fundamentally one and the same task. Hell, maybe all of this should be built into the compiler itself. But that won't happen until the comittee is willing to put its foot down and establish a standard project format. People often complain about design by committee (and rightly so), but this is one issue where you have to have someone forcing people to do it a certain way, otherwise the problem will never be fixed. As a last resort, switch languages. I've tried creating my own, but the effort required is monumental.
Do you understand why half of the benchmark is python. It depends on the ratio between failure (exception thrown) and success. If the chance is approximately 50/50, and the nesting level is low (1 or 2), then exceptions are 500 times slower than std::optional. Of course, if failure is very rare (I suppose rarer than 1 / 500 times), then exceptions may be attractive. Of course one might argue that 'exceptions' should 'exceptional', which means rare, but using them for a frequently occurring failure (for example in iterators) is valid design, and the current C++ mechanism doesn't support them. Problem is that an exception can be any class object, which makes that the stack cannot be unwound until the exception is caught and processed.
&gt;This might have something to do with C++ authors often throwing in a Visual Studio project file you can open Or use CMake which is just as good for everyone involved and every IDE worth using! &gt; while C authors are often Linux-based, typically don't give a rat's ass about Windows, and occasionally go out of their way to be hostile to Windows developers. I really hate the fact that in some cases this happens. Oh sorry, this is a real awesome library but it just doesn't build on Windows type stuff. Fortunately, many projects are slowely trying to shift to CMake
&gt;But nooo - you're expected to _configure_ it first (and don't forget to set options like "don't_randomly_crash", or it will), Well guess what - unless you're reinventing the wheel, you will have dependencies. At the very least, that's a compiler and the standard library. Now if you live in a hypothetical world where only "the language standard" exists, then you can build a program without configuration. But in the real world, compilers are weird, dependencies are weird and operating systems are weird. As a library author, you have to iron out all of the weirdnesses to get your library to build. Additionally, they have to deal with different requirements from different users. That's why you have to configure libraries. Your task force will inherently fail, because the reality of the diversity of different platforms will force Library authors to "pull so much weird shit".
I'm eagerly waiting C++59.
Two days back, I rebuild all my dependencies for vc140, vc141 and vc142 with vcpkg (and some custom toolchain files). Total time was a few hours of building, and was pretty easy and automated. It's also easy enough with other more established systems like the BSD ports and Debian etc. (Debian needs a little more work, but ABI changes are absolutely doable.)
I loved Herb's proposal for quite some time. I was under impression that you have to check for error. That's an important point. Otherwise it's not much better than errno.
I'm not sure if it will behave this way out of the box. It might break too much existing code. This is why I tend to believe there will be some way to turn it off. I hope it will act as if [[nodiscard]] is applied to it.
I think you‚Äôll get mostly agreement that string literals are annoying. Sadly such is the price of C-compatibility (which for the record I would personally be happy to drop).
I have checked, and you are right. If function without throws is using function with throws then static exception is transformed into a dynamic exception according to Rules an rethrown. Not the best approach in my opinion, but code compiled without no exceptions should require you to check error manually or mark your function with throws, which what I would prefer.
&gt; Now, we can find 4-lines-long functions headers, often supported with preprocessor macros and helper structs. I don't think Concepts solves that. Rather, it will probably make 4-lines-long functions headers more popular. I mean, AFAIK C++17 does not have template&lt;RandomAccessRange R, class Comp = ranges::less, class Proj = identity&gt; requires Sortable&lt;iterator_t&lt;R&gt;, Comp, Proj&gt; constexpr safe_iterator_t&lt;R&gt; ranges::sort(R&amp;&amp; r, Comp comp = {}, Proj proj = {});
Cool! My dream job would be to work on a cloud infrastructure project where virtual machines are running includeOS.
What's the difference between this and C++ REST SDK?
&gt; Do you understand why half of the benchmark is python? I don't even understand that remark. Is the benchmark written in python? Why would that matter to the discussion? &gt; using them for a frequently occurring failure (for example in iterators) is valid design No, it isn't. Detecting the end of a container is normal control flow, and should be handled as such. Reaching the end of a finite container is not an exceptional situation, it is the expected outcome. Also, std::optional is not a mechanism for error handling. You are mixing up concepts. &gt; Problem is that an exception can be any class object, which makes that the stack cannot be unwound until the exception has been caught and processed. A small exception blocks stack unwinding just as much, size has nothing to do with it. Let me ask another question: what if I return an error return code that is a gigabyte in size? Wouldn't be incredibly inefficient? How can you work with a mechanism that is as inefficient as that? If you think that's a stupid question because nobody does that, keep in mind that the same issue is raised for exceptions: all of a sudden we're supposed to think of what happens if the object is more than a few bytes in size, and use that as our benchmark for the whole mechanism. In other words, the comparison is always between the worst case for exceptions, and the optimal case for error return codes (and sometimes, I suspect, between exceptions and just not checking errors at all).
&gt;We could standardize a way to describe different ABIs to the compiler Like putting a version number in each struct
phew... that escalated
Thank you.
&gt;client/server RPC with more than 250K QPS per core How to test this? I ran `server&gt; ./asio_fibers --logtostderr` `client&gt; ./asio_fibers --connect=localhost --count 100000 --num_connections=8` but I got very slow result. What am I doing wrong? How to achieve the specified performance?
These are fairly superficial complaints. It‚Äôs like saying you wish sentences started with lowercase letters instead of capital letters, and proper nouns were all caps.
 [https://isocpp.org/files/papers/CppDevSurvey-2018-02-summary.pdf](https://isocpp.org/files/papers/CppDevSurvey-2018-02-summary.pdf) Question 7
It appears to be Modern.
What about QA in Canadian Weed Shops?
Source?
Not an issue if you use only the C API. IMHO their C++ wrappers are just horrible.
how did you build it? can you post info logs? to build in release mode, run: ./blaze.sh -ninja -release and cd into build-opt directory. Also, did you run it on the same computer? on different computers? how many cores?
A lot of these issues go away if you don't use references (pointers are much safer, and otherwise identical), use Rust-style `auto x = y`, never use C-style arrays, and be tasteful with templates. This is all ‚Äòcommon sense, good practice‚Äô C++, which I fully expect a lot of people to disagree with, but IMO pretty self-evident. For the remaining concerns, 5\. Const is for the programmer. It's useful for that. 12\. The problem is not UB, but that which things are UB were not tastefully chosen. 13\. Not really sure what your problem is here. 14\. This seems trivial and I disagree anyway. I do agree with 8., 9., 10., 14., and 16.
It's a dream, a vision, something to aim for, but we'll never actually get there. I'm pleased to see that at least someone has thought about these things when proposing the simd wrapper library that is part of the Parallelism 2 TS. When constructing a simd vector object you can choose if you want to be "ABI compatible" (default), or use whatever size is best suited for the specific hardware that you're compiling for.
\&gt; Is the benchmark written in python? Why would that matter to the discussion? It's about C++. The benchmark makes no sense. Benchmarks should be treated with extreme care anyway. &amp;#x200B; \&gt; Also, std::optional is not a mechanism for error handling. You are mixing up concepts. That's an ideological statement. It is not up to you decide what should be used for which purpose. If exceptions would be more efficient, they could be used in place of std::optional, in good quality code. For example, when building python iterators, that throw an exception when they reach the end. \&gt; A small exception blocks stack unwinding just as much, size has nothing to do with it It has to do with the fact that the catcher cannot known what will be thrown, because exceptions are in an inheritance hierarchy, and the fact that exceptions need not have a copy constructor. The C++ mechanism is too heavy. &amp;#x200B; See [deterministic exceptions](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r0.pdf)
Thanks!
hey man cheer up. how about instead we focus on hype for *networking functionality in the standard library* woooooooooo! ‚òÖ im not 100% confident in my understanding of the ABI compatibility discussion but please forgive me for being skeptical that you "dont use ABI compatibility" i mean have you never ever had to integrate code that uses different standard library versions? For me at least, the binary compatibility means its easier to upgrade to a new version and get new c++ features even if some 3rd party code is stuck in the past. I bet it sucks having to work on something new for the language, and get told no because of abi compatibility. but maybe it helps to think that you will reach a larger audience by staying abi compatible with older versions? anyway didnt libstdc++ have an abi compatibility break for c++11? [(from the conan documentation)](https://docs.conan.io/en/latest/howtos/manage_gcc_abi.html) thats a bit before my time time though so idk the details of how that went down. do you have any thoughts on that?
We are always looking for reviewers: j.mp/CppConReviewersGuide Thanks.
As more and more features become available at compile time, where all undefined behaviour has to be caught, it doesn't seem all that unlikely that we'll get something like that some day.
&gt;how did you build it? exactly according to the instructions in readme &gt;to build in release mode, run: ./blaze.sh -ninja -release Yes, build in release mode &gt; did you run it on the same computer? Yes. 4 cores / (8 with HT) (Intel Core i7-4980HQ CPU @ 2.80GHz) &gt;250K QPS **per core** If you declare 250k qps per core, then I can expected to reach 1kk on 4 cores. This is pretty fantastic. Nginx shows 50k qps on 1 core on the same hardware. So your library should be 5 times faster than nginx. I think this is not possible without the use of dpdk. But I will be very happy to be wrong.
Yes, my thinking is that papers which are good but ABI-breaking should be accumulated and every 9 to 15 years rolled up into one big ABI-breaking version of C++ (as I stated earlier). \&gt; you will reach a larger audience by staying abi compatible with older versions This is not true for any of my projects
Does it matter if the creator of the language uses different conventions than the standard library?
C++ has intentionally chosen a path that includes lots of legacy. The path it has chosen is to add things that make it possible to write better &amp; simpler code while keep the legacy. C++ has spawned lots of other languages that have taken issue with that &amp; chosen a different path. For me, there isn‚Äôt much point in dwelling on the problems with C++. It is‚Äîfor me‚Äîmuch better to either focus on making the best use of the good parts or learn one of those alternative languages.
What is sentry support?
I‚Äôm not asking for anything that complicated. Just an equivalent to -fwrapv that applies to all UB. Basically a switch to explicitly forbid the compiler from reasoning based on UB.
 &gt; accumulated and every 9 to 15 years rolled up into one big ABI-breaking version of C++ (as I stated earlier). and you are facing opposition even to abi breaks every 9 to 15 years? is it wrong to say that the abi will have to break eventually? no one can be 100% against breaking the abi right? &gt; This is not true for any of my projects i must be misunderstanding something then. if you dont mind helping me out I have some follow up questions: do you say that because beast is header only? what if i have some post c++11 code that ive written using beast, and i want to integrate that binary with some old code that cant use c++11 or a new compiler or whatever. is that not a scenario where binary compatibility would allow someone to use beast in their project? not std library code but i did experience this example: 3rd party code that depends on boost cannot build with boost &gt;X so i am stuck using boost X with anything that depends on that code. also that particular boost version does not have beast... or outcome &lt;/3
&gt; do you say that because beast is header only? No, I say that because Beast does not provide any guarantee of ABI stability between versions. I reserve the right to change the layout of any and all classes. Perhaps this will change in the future when Beast has reached peak maturity, but for now I need the freedom to evolve the library without the draconian restraints imposed by ABI compatibility - I'm just one developer after all.
&gt; 3rd party code that depends on boost cannot build with boost &gt;X That's unfortunate, and my advice (which I follow myself) is to simply avoid using such libraries, or avoid working at companies that use such libraries. Not ideal, I know, but it sure is less stressful (and more fun).
You can use cool `code blocks` in markdown: ```cpp std::string = "Hey, I'm a cool code block" ``` This will make a post about a mess less messy itself ;)
How did you even get perf numbers? Are you just timing how long it takes to run? ``` $ perf stat ./asio\_fibers '--connect=localhost' --count 100000 '--num\_connections=8' E0421 07:39:32.500056 4317 asio\_fibers.cc:120\] AsioFibers sentry test! Average latency(ms) is 0.350719 Timeouts 1344 Performance counter stats for './asio\_fibers --connect=localhost --count 100000 --num\_connections=8': 86,469.04 msec task-clock:u # 2.435 CPUs utilized 0 context-switches:u # 0.000 K/sec 0 cpu-migrations:u # 0.000 K/sec 2,464 page-faults:u # 28.496 M/sec 47,974,224,292 cycles:u # 554814.145 GHz 60,097,743,377 instructions:u # 1.25 insn per cycle 12,700,593,846 branches:u # 146880313.708 M/sec 90,332,648 branch-misses:u # 0.71% of all branches 35.504242681 seconds time elapsed 35.561604000 seconds user 52.047826000 seconds sys ```
&gt; C++ is A HUGE MESS I don't agree. There are some problems yes, but it's not like the language is some sort of inconsistent mess. &gt; 1. Arrays decaying to pointers I'll add arrays not being copyable to that. Yes that is unfortunate, I agree. Although you can mitigate this by using std::array. Also maybe it's just me but when was the last time you used a function that takes a statically sized array? Most of the time it's either a std::vector or a std::string, dynamically sized containers. &gt; 2. Default passing parameters is by value Well I mean that is a bit subjective, but if the default is by value you would have to mark every pointer parameter with the 'by value' default and I know I wouldn't like that, it would be unnecessary boilerplate IMO. &gt; 3. std::initializer_list - Why would you want to return it? It's a helper class. Don't use it outside of constructors. - Yes that is a very common complaint. Until standard library vendors agree to take an ABI break, this will remain like that. But I'm hopeful that this will get fixed. - you're right - agreed. &gt; 4. Million ways to initialize a variable. I mean that is true but if you're not a language lawyer the rules are fairly straightforward. - T a; // default constructor if T is a class, nothing otherwise - T(); // default constructor or initialized to 0 - T a{}; T b = {}; // initialize with a list of elements Sure that is a lot but each of them have their place. The first is useful for performance, the second if you want to be sure that an object is initialized and the third for when you need to initialize an object with a list. Although some people expand the third so that it is always used. But that doesn't complicate it much. Why would an average programmer want and need to know how those initializations are called? &gt; 6. Silent passing by reference Disagreed, but that is mostly subjective. At least for me it is obvious from the function name or the variable that you pass by reference. If you want to be explicit, you can always use std::ref(obj). &gt; 7. SFINAE SFINAE the concept is very useful, but you are right that the practice of std::enable_if is not pretty IMO. &gt; 8. ADL Yes that is a common complaint too. There is a proposal though to fix it :) &gt; 9. Forwarding reference syntax Yeah that's one of those gotcha's. I don't why this is like. Rvalue references are basically only used in move constructors in you're everyday code :) forwarding without templates doesn't make sense, since you can't have a single function that either copies or moves it's arguments. &gt; 10. Exception system They don't have terrible performance, but they do cause a lot of executable size increase. Again though, there is a proposal for this. &gt; 11. Function declaration is allowed inside a function This comes from C unfortunately :( &gt; 12. Undefined Behaviour as point of optimisation No. UB is great for performance. Like every compiler warns for you're common UB stuff. Making UB ill-formed is a terrible idea because the compiler cannot prove that the UB actually happens in some cases. And for the obvious errors, the compiler already wants! :) &gt; 13. std::launder and std::bless That is mostly expert level stuff. You never would std::launder if you're not using placement new, and even then only if you're doing weird stuff like creating an object of another type in in the storage of some other object with a different type. Same for std::bless. You'll probably never see those two being used in 99% of production code. &gt; 14. constexpr if introduces a new scope. No, this is not obvious at all. It goes against everything in C++ and for that reason it had a lot of push back. &gt; 15. Overload of "using" usage. Like, in a literal way Meh that's pretty subjective and I don't really mind &gt;16. Little UTF support in the language Fair enough, but there are proposals for this.
I tried, and it felt like crashing into a wall. Using it in nested list completely broke formatting, and suddenly different parts of the list had different indentation, also it somehow didn't work on mobile version. Also code blocks looks very bad on dark mode (light grey text on light background). Should I change it anyway?
1. I've run server side on 4 core machine in gcloud. 2. On another machine I've run `./asio_fibers --connect=&lt;server_ip&gt; --count 100000 --num_connections=100` You should play with `num_connections`. s.t. the load on server will reach 90% CPU. For me it was `--num_connections=200` https://imgur.com/ggsFb3r This parameter sets number of client fiber-connections per thread, each one of them pings server synchronously. If network latency is high, the QPS per connection will be lower, thefore in order to load the server fully, you should increase num_connections.
I would argue there are plenty of things that made it into the standard that probably shouldn't have, but that is really a much different argument. I would in the same breath defend c++ like a zealot as I believe it is the best language for performance libraries and bare metal backend work. Rust, go, node, Java, are languages that come to mind were the language defines how to package the software and the build system is integrated into the language (to varying extents). With c++ there is g++, clang++, zapcc, xlcpc, msvcpc. And now we have of and lld that I have seen, but I am sure there are more linkers. Each compiler has different options in code and in the command line. when I compile I have so many macros trying to figure out which compiler I am using the code is itself is no longer expressive and all the other work the standards committee is doing to improve expressiveness doesn't matter. In addition to putting all these checks in code, CMake is horribly complicated by this as well. There is a lot of assistance from CMake/autoconf hiding details, but a lot of the basic difference unrelated to project structure take up 30% of the build file just to get a project to build cross platform. At this point I would settle for a standardized definition of a compiler and linker. These don't control project structure, the just make building the language less ambiguous. Gcc/clang/msvc could still implement different versions, but they would have to conform to the same abi, or at least have the same options and interface.
go to http://localhost:8081 on server node. it shows http status page with QPS numbers. To get 250K per core you need to raise `num_connections` to 100-200 depends on the machine and your network configuration. This is the fan-out factor per thread. Your goal is to increase this number such that the server node will use &gt; 90% of its CPU.
sentry https://sentry.io/welcome/ is centralized error logging system with convenient http API. When your backend prints an error log, you might want to send it to such system. Production systems use this solution or similar
It gotta work for nested lists if you indent code blocks. 1. First ordered list item ``` code block ``` - Second `try` ``` code block ``` - gotta work 2. Second ordered list item ``` code block ```
Server is just running ./asio_fibers -logtostderr I don't have a :8081 port. The only ports open are ``` $ netstat -t -l -p tcp 0 0 0.0.0.0:9999 0.0.0.0:* LISTEN 25315/./asio_fibers tcp 0 0 0.0.0.0:8080 0.0.0.0:* LISTEN 25315/./asio_fibers ```
3. `std::initializer_list` (I guess it is a language, not a library feature after all) - It is tragic, that the standard way of initializing containers is so flawed. - it messes with auto: ``` auto a1{1}; auto a2 = {2}; ``` First one is an integer, the second one is an `initializer_list&lt;int&gt;` 4. Million ways to initialize a variable. ``` 3. `std::initializer_list` (I guess it is a language, not a library feature after all) - It is tragic, that the standard way of initializing containers is so flawed. - it messes with auto: ``` auto a1{1}; auto a2 = {2}; ``` First one is an integer, the second one is an `initializer_list&lt;int&gt;` 4. Million ways to initialize a variable. ```
I do not know what exactly you count in "echo\_qps". The web interface displays large and beautiful numbers. But the client works 35 seconds. For 100k requests it is a lot. 2800-3000 qps. The average latency confirms this - 0.33ms = 3030 qps.
&gt; No, I say that because Beast does not provide any guarantee of ABI stability between versions oh that makes sense but what i was trying to point out is that since beast requires c++11, the binary compatibility between 11 and older versions makes integrating beast easier for potential users. even if beast doesnt guarantee anything about its own ABI , i think you are most likely still benefiting from abi compatibility in the standard library, due to more people being able to integrate your project. &gt; or avoid working at companies that use such libraries such a company exists? :p imo its something everyone will have to deal with regardless because not every codebase can update at the same speed. you cant just drop every 3rd party that doesnt update as quick as you. even in a modern codebase i still appreciate and make use of abi compatibility. regardless im really just trying to say that abi compatibility is useful even if your own library doesnt promise abi stability, even if your codebase is modern, and even if you work at a nice company with a lot of flexibility to upgrade and use modern stuff. but at the same time i think its reasonable that breaking the abi eventually would be necessary for progress.
Dude, the client sends 100k requests per connection per thread. Look at the client flow code - it's not long. So if you have 4 cores, and open 100 connections, it's overall 100K * 4 * 100 requests sent.
I'm a bit late here, but anyway =). \&gt; does the fmt library contain the same or a similar to\_chars method like &lt;charconv&gt;? {fmt} provides a higher level formatting facility which can be implemented in terms of \`to\_chars\` (which is not widely available yet) or other method. For example: &amp;#x200B; `std::string s = fmt::format("{}", 4.2); // formats 4.2 using shortest decimal representation` &amp;#x200B; The current implementation can use either printf or Grisu, but it's easy to switch to any other method such as Ryu. Even the current unoptimized version performs pretty well: [http://fmtlib.net/unknown\_mac64\_clang10.0.html](http://fmtlib.net/unknown_mac64_clang10.0.html)
sorry, in this case localhost:8080. run the client process and refresh to see echo-qps go up.
I'm going to pay it for these reasons: Note that I have an Bs Degree Mechanical engineering (automatic control). I have been taught and studied a lot of theoretical stuff about engineering and control theory. I got my degree at an european university which focused too much in theory. So this nano degree, I think is valuable in providing me practical skills which are useful and demanded in the job market. In addition, I can be wrong but from what I have heard C++ is the language most used in industrial applications such as Aerospace. &amp;#x200B; Note as well, that I have one year experience as a quality engineer in the aerospace industry and want to switch to a job where I get to code. Although I don't expect to become a pro after this nano degree and believe it can provide me with two valuable things: \- A credential. So when I apply to a job where C++ is needed ( which is what I'm going to do, apply to every job related to C++ in the aerospace industry) I can show to the employer that besides my degree in engineering, I have invested time in a certification. \- A blueprint of what I need to learn in order to be a good C++ developer. I could be very well look it up in the internet and learn by my own. But to be honest, I'd rather have a professional lead me during 5 months and be able to focus on getting things done. Regards
BTW, if your average latency is 0.33ms that means you get 3030 qps *per fiber connection*. That means you need ~333 fibers per process. With 4 cores, I would assume you need something like `num_connections=100` to reach 1M qps. I still need to write a document describing the network architecture of GAIA, but basically in this example I open a single socket per thread, and then K fibers share it in order to send requests synchronously. This way, I can fully utilize network socket without locking it.
At --num_connections=128, it segfaults ``` Thread 12 "IoPool9" received signal SIGSEGV, Segmentation fault. [Switching to Thread 0x7ffff7f22700 (LWP 7959)] ontop_fcontext () at ontop_x86_64_sysv_elf_gas.S:57 (gdb) where #0 ontop_fcontext () at ontop_x86_64_sysv_elf_gas.S:57 Backtrace stopped: Cannot access memory at address 0x0 ``` With num_connections = 64, with clients on cpus 4-15 (12), and server on cpus 0-3 (4), the qps is north of 2M (2142517), which would be 500k per core?
The way templates and TMP have become idiomatic in "modern C++", long before there was any way to actually specify requirements on types in a natural way that can be enforced by the compiler; e.g. interfaces or traits. I know concepts is supposed to do this but it's way too late.
Also, pre- and post-conditions are visible from the function declaration.
Yes, sorry, please pull from the master, I fixed it today :)
Just use COBOL lololol
Thank you very much. Now everything is clear
&gt; THAT is how you solve the "package management is hard" problem in C++. generationally, not by trying to support all current craziness that people do. I couldn't agree more! The biggest library repository has probably [Arduino](https://www.arduinolibraries.info/) with over 2000 packages. Unfortunately this approach doesn't have a lot of mainstream appeal. As a result we built many tools for [Buckaroo](https://github.com/LoopPerfect/buckaroo) to [analyze and transpile build-systems automatically](https://hackernoon.com/announcing-buildinfer-for-c-3dfa3eb15feb)
Most of the items on your aren't particularly annoying to me. On the language-side, my pet peeve are the insane implicit arithmetic conversions to/from unsigned. Worsened by the fact that `size()` on containers returns an unsigned number, leading to idiocies like `size()-1 &lt; size()` being false for empty containers. Next pain point relates to both the language and tooling: the header/implementation split, the existence of preprocessor and ABI issues.
Please don't use 1. C++17 node_handle broke it
Not to me. It's for consistency, not some kind of appeal to authority.
Check out thenewboston https://youtu.be/tvC1WCdV1XU . It's really good.
But this isn't even a c compatibility issue. We can preserve existing c compatibility while still providing C++ programmers with behavior that "works correctly" (aka, intuitively). template&lt;size_t N&gt; bool is_array(const char (&amp;) [N]) { return true; } C doesn't have templates. So already we're in non-C territory. C doesn't support references, so there we go again. If the standard was modified such that actual array types (or references to arrays) preferred functions taking references to arrays in template contexts, over decaying to a pointer, the only problems that could possibly happen are that functions that were not previously being called (because programmers thought, incorrectly, that they would be) start being called instead. Yes, that might cause some problems, but eventually the bandaid needs to be ripped off.
You're right, my original comment didn't say anything about raw string literals. I claim "after midnight" as my excuse. Nevertheless, your proposal of using std::array all over the place still introduces lots of copy-constructions, and a whole mess of other possible issues, that you might not have realized. Including not solving some issues related to raw string literals.
btw: r/NixOS/
I suggest you invest all the money first of all in the Bjarne's C++ Book, it covers all what need to be learned of C++, later on you can focus on what you need but this is the basic, no trainer can do a job as good because with the book you can read at your own pace and look for extra info if you need or want Besides the book there are many more books, my favourite is the Scott Meyers series of Effective C++ but there are many more, STL, Threading, Boost, CMake, you name it And since you ask for videos i will put my subcriptions of youtube related to developing, i hope it is what you want -NDC, not focused on C++ but if you are only going to follow one channel this is the one https://www.youtube.com/channel/UCTdw38Cw6jcm0atBPA39a0Q -BoostCon, one of the best C++ focused conf https://www.youtube.com/user/BoostCon/featured?disable_polymer=1 -CppCon, the level of this conf is huge, a must https://www.youtube.com/user/CppCon/videos?disable_polymer=1 -LLVM because knowing the compiler helps to develop better code https://www.youtube.com/channel/UCv2_41bSAa5Y_8BacJUZfjQ/feed?disable_polymer=1 -Meeting Cpp, top conf https://www.youtube.com/channel/UCJpMLydEYA08vusDkq3FmjQ -ACCU Conference, i like it, a lot but the quality of the postproduction audio/video is not as good as other, as an example in todays reveals of Anastasia Kasakova was a glith with the sound and the video for now (i hope it is temp) is removed, a shame https://www.youtube.com/channel/UCJhay24LTpO1s4bIZxuIqKw -Code::Dive, same concept as NDC https://www.youtube.com/channel/UCU0Rt8VHO5-YNQXwIjkf-1g -WeAreDevelopers, another multi conf https://www.youtube.com/channel/UCSD0dLRGQk_T-D3RvpM5aFQ But there are many more, only look what you want or like and let go it
`push_back` (snake case) vs `strcmp` (contraction)
&gt; It just doesn't work. On the contrary, it works just fine. I've got millions of lines of code to prove it. &gt; Even if you remove the non-template overload and thus force the compiler to instantiate your template - string literals are indistinguishable from regular char arrays. Or you can use SFINAE, which was a major convoluted mess of a pain in the ass, but I did get it to work with SFINAE. It's *significantly* prettier with C++17 though, thanks to if-constexpr Note, this is some open source code that I wrote, and I've not had the time to finish implementing it. *shrug*, but it demonstrates the principal succinctly. template&lt;class STRING_T&gt; constexpr size_t string_size(const STRING_T &amp; str) { if constexpr(std::is_pointer&lt;STRING_T&gt;::value) { return std::char_traits&lt;std::remove_pointer_t&lt;STRING_T&gt;&gt;::length(str); } else if constexpr(std::is_array&lt;STRING_T&gt;::value) { // TODO: Throw if the array contains an embedded nul character. // TODO: Throw if array does not end in nul-character. // TODO: Return the static size based on template deduction. return std::char_traits&lt;std::remove_pointer_t&lt;std::decay_t&lt;STRING_T&gt;&gt;&gt;::length(str); } else { return str.size(); } } &gt; char Buffer[256]; api_call(Buffer); auto Len = static_strlen(Buffer); - you don't want to get 255 here, but you will. On the contrary, that's trivial to work around by clearly documenting that static_strlen shall not be used on non string-literals char arrays. When working on massive codebases, perfect is the enemy of the good, especially when you're dealing with an already-in-place convention of forbidding patterns like this, and people expecting the static-size of raw-string-literals to be derived at compile time, and programming conventions adopted that follow from that expectation. Plus, you can throw an exception, which in constexpr contexts will stop the compilation process. Effectively and correctly ensuring that the problem you point out can't happen. &gt; const char Data[] { 'f', 'o', 'o' }; auto Len = static_strlen(Data); Actually, I was able to find several bugs with my C++14 (aka, non if-constexpr) version of the above function. Several places where people had improperly used strings with embedded nuls, or missing nul-terminators with the static string-size function. Those bugs weren't discovered ***because*** C++ was decaying the array to a pointer, and not calling the correct function , therefore not performing these important checks. &gt; The only way to get such optimisation is to move on, ban "simple" string literals in your codebase and use ""sv everywhere. How can they be banned? The only way to do so is to have the functions that could potentially accept a raw string literal (such as the string_size function that I provided above) have a static_assert that detects that you're using an array (aka, raw string literal) instead of a ""sv. But you can't do that, because C++ ***doesn't fucking let you***, unless you write a bunch of ugly SFINAE code at every place where you might expect to deal with array-to-pointer decay. By the time you've done the SFINAE work, you've already done all the work needed to just make raw-string-literals work correctly, meaning you won't end up needing to touch millions of lines of code to add using namespace std::literals; and then sv to the end of every raw string literal. And don't forget, this is a multimillion line code base i'm talking about here. There's a lot of legacy bullshit that comes with codebases that large. In this case, they might have a C++14 capable compiler, but they've got a C++98 standard library (STLPort, for what it's worth). No string_view available. Either way, I no longer work there, so at this point it's simply an academic question for me.
Would a possible solution be to extend pragma once with a unique identifier? So if the compiler sees for example #pragma once "potatis_invalid small_set.hpp" and it has already parsed a file with those contents it knows to stop parsing?
&gt; You have to use include guards. It is difficult to share files between projects. You don't have to, you can use #pragma once instead.
That says that exceptions are allowed in 80% of all projects, and makes no statement about performance. Sorry, I thought it would be clear that I was primarily talking about the performance myth. Anyway, it is disingenuous to say "banned or restricted on 50% of all projects". I don't want to see exceptions for situations that occur regularly on a high performance path, so technically that puts me in the "restricted" cathegory. At the same time, do you get the impression I'm in any way opposed to exceptions? I want them applied sensibly, but I want that for \_every\_ language feature...
&gt; It means we can't even use a set&lt;foo *&gt; to keep track of a set of foos, for f sake. If you are referring to relative comparisons on separate objects (OP 12), I was under the impression that `set&lt;foo *&gt;` is OK because set defaults to a predicate of `std::less`, which is required to work for pointer comparisons where straight `&lt;` is UB. (Though this also means that `std::less` cannot be implemented portably.)
Edited, thanks :D
If you disagree with the benchmark, do your own and post it here so we can discuss it. Handwaving is meaningless. &gt; If exceptions would be more efficient, ... If C++ were Rust, it would have automatic thread safety. If sand was pizza, noone in the world would suffer from hunger. If computers ran at 10THz we could write everything in Python and wouldn't need high-performance languages like C++. What's your point? Things are what they are. Certain mechanisms were developed with a specific goal in mind. Saying that they are bad because you cannot apply them for other goals is either disingenuous or foolish. Throwing an exception at the end of a loop is just weird - that means you have to wrap every loop in a try/catch handler. Why would you want that kind of overhead? Reaching the end of a finite container is not an error. Also, Python is not C++. &gt; The C++ mechanism is too heavy. That I agree with. I could live with some limitations on what an exception could be, but apparently the only way to change anything is to throw out all the existing toys and build a completely new set from scratch... For the record, early C++ compilers implemented exceptions pretty much like what is described in that paper, i.e. as return values. This was eventually replaced by a table-driven approach, as the return value method proved to be extremely bad for performance (perhaps you are too young to remember, but in the early days C++ had the reputation that it was extremely slow). Legislating that very same approach as part of the standard seems foolish to me, but hey, everybody is convinced exceptions are slow so surely this must be better, right? :-( "Those who don't know history are doomed to repeat it"
I freely admit to not understanding these issues as much as I should, so perhaps I should shut up, but my guess is the chance of the type of a string literal being changed from a `char *` to anything else is about 0. Once the type is fixed, it doesn‚Äôt matter that C doesn‚Äôt have templates.
Wow, thanks for that bit of info! I was wondering if I should be ripping out every `set&lt;T*&gt;` and `map&lt;T*,...&gt;` and (somehow) replace it by something safer, but apparently I don't have to. But why not just make `T*.operator&lt;` safe in the first place? It's not as if people are still writing code for segmented architectures in 2019...
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bfsmcw/multithreaded_programming_how_to_learn/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Just curious: have any actual cats chosen for you to be their caretaker? Or are you still waiting for the first feline friend to make his way to your doorstep?
It's true that many classic segmented architectures are no longer relevant, but I'm not sure it's safe to say that there are no current architectures that have don't care or tag bits that would interfere with such a change. For instance, ARM has some extensions to use extra address bits to aid in detection of stale object pointers. So far I have not seen one that would interfere with generalizing `&lt;`, but there may be one.
Yes! I see it looks better now.
this is a total shill which I have no stake in. I strongly advise the c++ courses from baruch's program. check it out at quantnet.com I have a strong background but learning c++ you need a solid treatment. also, get the effective c++ and exceptuional books
&gt; Make an 80% solution, and the other 20% can either adjust to be in your 80% or continue doing what they're currently doing. &gt;The problem C++ package managers have is that they claim it's hard for C++ because of all these edge cases, when really, just don't support everything that's possible. What if C++ is 80% edge cases though?
Defining the `friend` member function inside the class template will avoid all gotchas.
Doesn't seem inconsistent in the way camelCase and snake_case is And isn't that a C vs C++ thing anyway?
I don't know. I only know this because I found comments about it in the EASTL source code.
Unfortunately the type of a string literal isn't char*. Its const char[N]. So the problem is more general than simply the type of a string literal. Its just that strings are a special situation since its very uncommon for there to be a function that takes both a pointer and a reference-to-array for arbitrary types, except for strings.
Their advanced certificate looks promising!
Apart from the other answer, unlike the assertions compiler can use the information provided in the contracts for further optimizations. There was a paper that was aiming to provide the restrict semantics with precondition checks.
&gt;that's trivial to work around by clearly documenting that static\_strlen shall not be used on non string-literals char arrays Documenting that might be trivial indeed, but, unfortunately, no one reads the documentation *as long as it compiles:* &gt;Several places where people had improperly used strings with embedded nuls, or missing nul-terminators with the static string-size function &amp;#x200B; And surely it's not always as trivial as in the example. Imagine a variadic strcat-like function that precalculates the sizes of its arguments to allocate the memory in one go, by calling size for strings and strlen for pointers. You apply it all over the place and everything just works, because those char arrays conveniently decay into pointers. Some time later you decide to optimise it for string literals and... everything still seems to be working, yay. It can take months to even notice that something fishy is going on. And there are no *direct* usages of anything like static\_strlen on any char arrays at all, so happy debugging. For me it was easier to say "to hell with it, string\_view everywhere", but YMMV of course.
comapre -&gt; compare
If it can be that simple, yes.
It's always around threaded logic where containers are being iterated over/accessed randomly and the creation and destruction of the iterators locks an internal mutex which causes any other threads waiting/using that mutex to all wait on each other until someone gives up the mutex.
Hilariously, I‚Äôve never owned a cat myself. My parents got a cat when I was growing up, Peppermint.
Why don't you want modules?
TL;DR - "Look, how I can shoot myself in foot, and C++ is guilty!"
What if aliens invade us tomorrow and it all becomes a moot point because our new overlords won't allow us to use anything but PHP?
This. Criticising an language aimed at providing more performance over safety for security issues is getting old. A more reasonable way to compare safety features is to also introduce how it is done in alternative mechanisms and how much overhead they introduce. More often than not it's already handled by compiler checks or coding rules that forbid unsafe practices.
it's been a while, but when I first came across cget it was about as close to what I would do if I were to try and solve the problem as I've ever seen, so kudos (not saying my solution would be great, just that our thinking here probably aligns pretty well). And the approach your describing is in large part what I meant when I made the [following comment](https://old.reddit.com/r/cpp/comments/bfe9ru/why_do_all_dependency_managers_suck/ele4nyw/).
This. Not everyone wants to suffer the runtime overhead of borrow checking.
Ok, i agree that C++ is not as safe as any other lang where you cant control memory directly. But the question is, do it matter? You provide the binaries of your program and hope the best, if a group of crackers want to crack it, well, if they are good no lang will save you And if it from a security issue of the hole computer, well, until a few years i was a believer but now... Not anymore, the mini CPU at both Intel or AMD that dont follow the rules (it can have access to whatever memory as permisions will not be checked) or all that many backdoors that software and they know makes me wander why bother, i write "secure" code because it means more or less the program as a whole will be more stable and less bugs, you know, no one likes to has a memory leak and be blamed after that hard work of months I undestand that Rust has make the miracle for firefox (i use and love it) but i always believed that the real problem was us, the developers, if you put someone unskilled to code, well, it may work but with a price. Because Rust or similar what really do is limit the developer freedom less knowledge and skill is needed so the code will be better. Yeah, if i try to operate a F1 car i will not be able to drive it, if you quit all controls and left me with a wheel and 2 pedals i can make it but at what price, all this simplification has a cost, Fernando Alonso, Vettel or Hamilton (or anyone other pro pilot racing like Nascar guys) dont want to has 100 buttons in the wheel drive if they can only has 7, if they dont for sure they willnot be as quick as others
Woah, I think the problem with the current package managers is that they ARE already 80%. If you follow tutorials and use them based off their GitHub readme, they work as intended. It's that last 20% where they all fall short. At Facebook we use BUCK and the C++ libraries live in the same mono repo as all of our other targets. BUCK and Bazel (Google's version) are not easy to use or configure but they are scalable and cover that last 20% really well. I think modules will really help with this problem too.
This.
&gt; In particular, I often receive defenses of C++ of the form, "C++ is safe if you don't use any of the functionality inherited from C"[1](https://alexgaynor.net/2019/apr/21/modern-c++-wont-save-us/#id2) or similarly that if you use modern C++ types and idioms you will be immune from the memory corruption vulnerabilities that plague other projects. No one of any repute would be silly enough to claim absolute immunity from memory corruption in C++, although you can do a great deal to mitigate most of the common pitfalls. But it's also a fact that most C++ projects are much older than 2011. Thus, they're going to inherit a lot of older C++ or even C-styled code, with lots of raw pointers in their interfaces, and lots of memory-unsafe practices. I would argue that it's perhaps a bit early to dismiss the benefits of modern C++, because I'm just not sure how many examples of large, complex projects there are to point to as evidence. I can also say with some confidence that, in my own experience, modern C++ practices do help a great deal with memory safety. I wrote an entire game engine + game from the ground up using modern C++. It's not huge by any means, but does clock in at \~100K lines of C++ code. Memory leaks and memory related crashes seem to be vastly reduced (in years of development, I can only recall a few examples, which is sort of astounding for C++). The entire code base uses RAII, smart pointers, and STL containers for near automatic memory management. I very rarely even have to write destructors anymore. It's certainly true that "safe" C++ is an opt-in procedure, and there are clearly still ways to accidentally introduce memory-unsafe code (even if some of the examples feel awfully contrived). That's a clear disadvantage of the language in some ways, but that's also why C++ remains compatible with 30 year old code. It's a very pragmatic balance between compatibility, safety, and performance, and what makes it such a useful language. It's also why companies are willing to make multi-million dollar investments in C++ code for their most critical infrastructure, because they know that code will likely remain compatible for decades more to come.
I haven't really touched Rust but isn't it's borrow checker compile time, not run time?
is this a joke?
When it comes to the replies so far, I'd say yes, but I believe the article is serious.
With the integrated (and live) static analysis tooling in Visual Studio 2019 the first two examples from this latest \*\*Modern C++ Won't Save Us\*\* hitpiece article are caught: &amp;#x200B; \&gt;string\_view example: \&gt;26449: gsl:span or std::string\_view created from a temporary will be invalid when the temporary is invalidated. &amp;#x200B; \&gt;Lambda example: \&gt;26418: Shared pointer parameter 'x' is not copied or moved. Use T\* or T&amp; instead. &amp;#x200B; Re the other two code examples, I don't understand going specifically out of your way to create an uninitialized object. I suppose the functionality is there though and it's something for authors of C++'s rapidly burgeoning and maturing compile time lifetime analysis / borrow checking ecosystem to consider. As for safety, Rust is inherently unsafe because approx. nobody% of devs in the real world outside the internet marketing bubble can program it proficiently or maintain software written in it.
Mostly compile time, but as I understand it, there are a few cases that require runtime checks. For example: let mut foo = Bar::new(); if (condition) { drop(&amp;mut foo); } It needs a runtime check to determine if `foo` still needs to be dropped. That said, handling this sort of thing correctly in C++ is going to involve very similar bookkeeping (e.g. via`std::optional`), so I doubt the overhead is actually relevant.
&gt; My conclusion, based on reviewing evidence from numerous large software projects using C and C++, is that we need to be migrating our industry to memory safe by default languages (such as Rust and Swift). Doesn't Ada fit into this category? Anyway, I think a better way to do this would be to identify the flaws in the existing languages and figure out how to get rid of them. E.g., failure to de-allocate memory in C++ gets solved with smart consistent use of smart pointers. &gt; I would like to credit C++'s smart pointer types, because they do significantly help. Unfortunately, my experience working on large C++ projects which use modern idioms is that these are not nearly sufficient to stop the flood of vulnerabilities. This statement reads to me as: "We know it is getting better, but instead of trying to improve C++, we are going to abandon it." &gt; Any future use of sv is a use-after-free vulnerability. Oops! C++ lacks the facilities for the compiler to be aware that sv captures a reference to something where the reference lives longer than the referent. What prevents this from getting added to compilers?
I was a big fan of C++ for years. Then I tried other modern languages and stopped being one. Now I hate how C++ is unsafe by default. Every function can throw exceptions by default, therefore no one catches them by default. Exceptions break encapsulation, because you need to check insides of definitions to know what to catch. You need tons of external tools to guard you at compile time and runtime against corrupting memory, undefined behavior and thread races - and you still don't have a guarantee you found every problem. You need a lot of expert knowledge and discipline to avoid the minefield of gotchas. I could go on and on about this topic, but the point is I believe C++ shouldn't be used for any safety and reliability critical system.
Does it really if you can just const\_cast it away?
imo this is where static and dynamic analysis help you. im pretty sure the likes of address sanitizer or valgrind memcheck would catch all of those. static analysis can sometimes catch those too. for example the experimental lifetime profiler on clang catches the first example that was mentioned https://godbolt.org/z/FllhKe
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bfreqb/c_training_in_the_us/elgjcfk/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
What is the recommended way to use smart pointers when data structures have cycles? shared_ptr is no good for such things, or at least it's not automatic.
In practice, I‚Äôve never found consistency achievable. Most projects I‚Äôve worked on used other libraries as much or more than the standard library, and I don‚Äôt know that any have ever followed the standard library‚Äôs convention. So, for me, my insistence on following the standard library conventions has been effectively an appeal to authority.
&gt; What prevents this from getting added to compilers? [Nothing](https://godbolt.org/z/qaVrSn). It's just a work in progress.
You missed the point of the author, as well as the point of the whole article in my opinion. Yes, he's showing ways you can shoot yourself in the foot, but when your solution is `JuST WRiTe BeTTEr CoDE`, it doesn't speak to the problem of people currently writing "bad code" from which users (including you and me, since we can't inspect the code of every app we run) will eventually suffer from. It actually proves his point. The cult of "just don't mess up" has resulted in a ton of vulnerabilities, and neither old nor modern c++ helps in this regard. I don't expect to get many people backing my point on r/cpp at all, but at some point, even you must realize "well don't make mistakes" isn't the solution to preventing people from writing "bad code" resulting in vulnerabilities, and language safety matters as well.
&gt; Oops! C++ lacks the facilities for the compiler to be aware that sv captures a reference to something where the reference lives longer than the referent. Hi I‚Äôve never heard of ASAN!
That would be an exception to consistent use of smart pointers. To be clear: My post was more directed at the desire to switch languages because an existing language has a deficiency rather than details on how to address deficiencies.
Increase compile time for something that can be done optionally by a static analyzer aside.
&gt;As for safety, Rust is inherently unsafe because approx. nobody% of devs in the real world outside the internet marketing bubble can program it proficiently or maintain software written in it. Doesn't seem like you know what "inherently" means.
I've been calling those `std::unordered_foo`.
80% doesn't mean captures 80% of C++ users, it means solving the problem of package management only partially. Which means anyone using that system is going to be doing things the way the package management system wants, or they don't use the package management system. Maybe buck does this, I don't know, but all of these package managers are too complicated because they're trying to capture more users by solving more problems. And for the record, a company maintaining their own custom package manager to solve their specific problems is exactly what I meant by "they can either adjust to your 80% or continue doing what they're doing". cget is much closer to what I was speaking of. They have a very specific way of doing things and don't really try to solve everything, but at the same time it's simple to get up and running. Because they don't try to solve everything, when you use cget, you roughly do things their way or you don't use cget. make it simple and wait for people to come. 20 years from now when it's considered best practice to use the tool and do things the way the tool wants, then the problem has been solved. This is the difference between things like C++ and ruby/rubygems. ruby was able to specify very early on what was required of maintainers and users when interacting with rubygems. C++ never had that luxury and needs to back into it. A lot of people are making the mistake of thinking that backing into it means supporting everything/most of what's out there now. And that's absolutely the wrong approach.
CMake is probably the closest thing to a standard we have for C++. I don't like it but haven't found anything better yet.
The future is uncertain and betting on improbabilities is inherently dangerous.
You mean like at the bottom of this file? (Note, there is a known off-by-one issue with this version of the code. But I'm on mobile so can't edit it for you) https://raw.githubusercontent.com/splinter-build/splinter/10-string_concat/src/string_piece_util.h The issue that you speak about was exactly the motivation behind writing the "string_size()" function I pasted into my previous comment, and the string_concat function found in the file. Note though: these are c++17 versions that I wrote from scratch after leaving my last employer, where I had to implement the same functionality in c++14, which sucked really bad by comparison. The answer to your concerns is to throw an exception in the constexpr instantiation context. Then any arrays of char that are malformed result in very very obvious compile / runtime errors, ensuring that jonny+-intern stops writing crappy code
Buck has a concept of header maps and is probably best explained here: [https://buckbuild.com/function/subdir\_glob.html](https://buckbuild.com/function/subdir_glob.html) It is a great feature that turned out to be crucial for packaging in [Buckaroo](https://github.com/loopperfect/buckaroo). Having header maps allows you to disambiguate conflicting include paths and on failure emit an error before the build starts. Header maps are a more high-level description of the build requirements; Include-paths become an implementation detail.
`const_cast` can come bite you with UB if you use it incorrectly. A acceptable way to use it is when you have a const and non-const method in your class, you can implement the non-const version with the const and `const_cast` the result to make it mutable. It works because the actual underlying value wasn't const in the first place.
I'm curious, has anyone tried [gradle for c++](https://guides.gradle.org/building-cpp-libraries/)? It looks promising but I've never had chance to try it out, especially with larger projects.
Can never go wrong with make
As far as I know the primary difference between a struct and class is that in a struct the members are public by default whereas in a class they are private by default. Otherwise you can do pretty much the same things with either. So I use structs in the cases where I am primarily wanting a data type with public access to members, and classes where I want to encapsulate everything.
Until you want to market to Windows devs.
Structs for data. Classes if you need logic.
Well there's your first problem
If std::tuple had a way to name members it would pretty much be perfect for the use-case you describe. IME, such throwaway structs eventually become relied upon and then demand proper interfaces and encapsulation.
If your CMake-fu is strong, you can almost make it behave like npm (grab external dependencies from the Internet). But yeah, it is universally hated and probably the best we have to work with at the moment...
Structs for data, namespaced functions for logic. I find myself using classes less and less in favor of a more functional approach to programming.
I might start with a struct when I'm playing around. Default-public members can be useful when I'm sketching an idea out, before I've really thought out what the visibility/access design should be.
But 'functional' does not imply 'structs and global methods'. You can do proper OOP and still write functional code...
This has been my experience. When C++ was all I knew, it was completely awesome. The instant I tried a language that added automatic bounds checking, I started wondering why C++ didn't allow me to enable a similar feature.
I have tried it a little. I wasn't able to figure it out though, it's pretty complicated because Gradle itself has a very steep learning curve (IMO). In order to use Gradle on any kind of more advanced level, you need to know Java, and Groovy (as well as the nuances of Gradle itself). I don't mean to be discouraging, but my experience of having to learn Gradle in a short amount of time (and then running out of time) wasn't pleasant.
The issue is (as implied by the other comments) that there have been new solutions brought forward, but none of them have really risen to the level that CMake is at. Closest thing is probably meson, but I'm not sure if that would satisfy your requirements or not.
I think the trend is just away from huge OOP classes containing tons of state
This looks really promising
&gt; Nevertheless, your proposal of using std::array all over the place still introduces lots of copy-constructions The OP's complaint was that initializer_list members can't be moved from. With arrays, you can actually move its members. Hardly "all over the place". I specifically addressed the OPs, complaint.
&gt; they claimed that the use of structs has fallen out of favor with the general C++ community in favor of just using classes for everything. I've never heard or seen this. Structs are used when you need...a struct. A named tuple. Which is like everywhere.
Classes for things that have invariants.
I use them all the time. I don't make something a class unless I want to preserve an invariant.
&gt; I would argue there are plenty of things that made it into the standard that probably shouldn't have None as big and messy as build and packaging would be. Like I said earlier, we already had an international standard that mandated a specific build system. It was called POSIX make. It's literally in the standard. But building and packaging had already grown beyond make. Standardization of a build and packaging system will be ignored, just like POSIX make, and the standard will have one big chunk developed and maintained despite not being used. &gt; Rust, go, node, Java, are languages that come to mind were the language defines how to package the software and the build system is integrated into the language (to varying extents). Node's famous npm incident doesn't give a good impression. Java, the language, doesn't have the same compilation and linking requirements C++ has, but that's why people are really hard at work trying to get modules across the line. Standardizing a build/packaging system before that would unnecessarily lock in those problems that modules would solve. And even then, we'll probably need to iron out bugs in the standard once it gets in. As I understand it, Rust's crates have their own problems in the community. Personally, I haven't seen anything from anyone complaining about standardizing build and packaging who has listed all the problems with existing build and packaging systems, and how they propose to fix them before they come up.
Go back to the 70s and stay there, please.
Why is this, if I may ask? I‚Äôm relatively new to c++ build systems, and CMake has been relatively painless. Although, I learned my cmake as the ‚Äúmodern‚Äù version, with targets representing parts of compilation. The best joy thing that‚Äôs been difficult to figure out so far for me is variables across files.
Ah yes back to the dawn of time
Hmm, I haven't written cmake before, it looks really verbose from the tutorials and various projects I've cloned and built with it. Is it really worth it over bare Make?
The article isn't too bad as it highlights common pitfalls a more junior C++ dev would make. C++ as a language is stupid hard and it's good that we document some of these simple gotchas.
&gt;As far as I know the primary difference between a struct and class is that in a struct the members are public by default whereas in a class they are private by default. That's the *only* difference.
It gets pretty gnarly on large projects, especially when build systems start mixing or different CMake assumptions are made.
I didn‚Äôt want to make such a definite statement in case there was some obscure part of the standard I didn‚Äôt know about :)
It's also the base approach by `vcpkg` (which seems to be destined to become 'the' package manager (win/nix/osx)) and also Boost is committed to (not yet) making Boost buildable with `CMake`. I find these 'discussions' rather tiring. Time invested in trying to figure out how to use a one-man-show-build-system is truly wasted time, like "Did you try Gradle?" [seems a popular question at the moment, it appears to be the 'hipster-moment']. No, I didn't, I don't know and don't want to know java [nor use something that targets java].
Nonsense. Structs for types that are 'mostly' open, and Classes for types that are 'mostly' closed (private) or have considerable bits of code that need encapsulation/protecting.
I use them a lot, more than classes actually. I find the syntax and usage patterns around classes in C++ to be too cumbersome. For the type of code I write, structs are generally all I need.
\&gt; If sand was pizza, no one in the world would suffer from hunger. If computers ran at 10THz we could write everything in Python and wouldn't need high-performance languages like C++. What's your point? That is useless rhetoric, I will not react to that. &amp;#x200B; \&gt; What's your point? That the current exception mechanism is designed in such heavy way, that good quality code does not get written. Of course one argue that it does not matter, but it a missed opportunity. &amp;#x200B; \&gt; Reaching the end of a finite container is not an error. The implication is that exceptions are 'error only'. That is still an ideological statement, not a technical one. &amp;#x200B; \&gt; his was eventually replaced by a table-driven approach The current design is such that there must be zero cost when no exception is thrown at the price of a high cost when the exception is thrown. (Note that the link that you didn't read, argues that even this principle is not kept, see top of page 8.) &amp;#x200B; \&gt; "Those who don't know history are doomed to repeat it" Go tell it to Herb Sutter.
I think the whole 'structs for data, classes for logic' thing is maybe academically fine, but impractical in large code bases. At some point, I almost always find that I regret making data members public, almost every single time. And I end up having to back and fix that, potentially in a lot of places with all of the possibility of introduction of bugs that implies. At a very low level in the code base, and for something that is purely internal to a class that needs to hold a little info as a unit, yeh, I'll do a struct in some cases there. But, otherwise, I've been bitten way too many times and just go ahead and make it a class with control over access to members from the get-go. Inline the getters and setters and you don't lose anything, but any of them can be moved out of line at any point if needed, and you can do controlled construction of instances of the things without all of the silliness of the modern "let's pretend we are Javascript" initialization stuff.
I‚Äôm not sure whether you‚Äôre looking for a package manager, build system or build system generator. Also I guess you‚Äôre targeting and developing on Linux only?
I agree with this, but I don't think the ideas are actually that different. A type with 'open' data *can* be interfaced with methods, but it's sort of implied that you are totally free to just access/use the members themselves. A type with 'closed' data, on the other hand, *has* to be interfaced with using member functions. Structs for the data-esque access; classes for thinking in a more logic-driven way - seems to be pretty similar ideas to me.
I'm always entertained by Haskell as well, very clever code, cannot go wrong, productivity 1 line of code a month :-).
Meson is much easier to learn than CMake.
Getters and setters that do no more than assigning (trivially) a value to a class member are useless overhead [or do at least reduce code-readability], making the member public and manipulating it directly is preferable in my opinion.
I second CMake, it's super cool, and I use SOCI, Pistache and Google Test (and pull them all in via CMake) in a project.
Take a look at [https://github.com/acdemiralp/cmake\_templates](https://github.com/acdemiralp/cmake_templates)
I‚Äôd say it is definitely worth it if you‚Äôre willing to learn its ‚Äúmodern‚Äù version. I‚Äôve had no issues with CMake projects since and I‚Äôm developing multi platform library which usually gets really messy in c++. On the other hand, if you like python and would like to check out something interesting take a look at SCons.
Yeah, I get (heh) what you're saying and totally agree. I think two pretty nice examples of this would be `pair` and `variant` - `pair` being a perfect example of a 'data type' where there's no reason whatsoever to use a function to access the data, but the type still provides some functionality (`swap` &amp; `operator=`) whereas `variant`'s entire purpose is that you can avoid accessing a union in an unsafe manner.
I may be biased, but if you care about configurability or being stable across platforms, then it is. It may not be the prettiest, but it allows you to do the job correctly, and there isn't a better alternative. Modern cmake is a step in the right direction, but a syntax improvement might be nice. The interactive cmake-gui and ccmake programs are definitely worth using. It's also pretty good at hooking up dependencies correctly. It's not perfect, but it's not nearly as scary as some would have you believe. (Note it's very easy to shoot yourself in the foot with Turing complete languages such as cmake-script)
I roll my own pairs nowadays https://www.reddit.com/r/cpp/comments/ar4ghs/stdpair_disappointing_performance/ . I don't like `std::variant` one bit [... you can avoid accessing a union in an unsafe manner ..., there are caveats, though, and the accessing is clumsy in my opinion], `std::optional` is better, though.
&gt;What prevents this from getting added to compilers? The fast that in order to do it right, you have to [reinvent the Rust borrow checker, but with a more verbose syntax](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#SS-lifetime). C++ people refuse to admit Rust is better, so instead they shit on it while slowing adding all it's features to C++.
Hm, interesting. I do like `std::optional` (have never had a use case for `variant`). I'm extremely interested by this post about `std::pair`, though, and will definitely keep it in mind - thank you for sharing!
depends, sometimes a type might change over time. Such as a string might be changed into a index in some higher-level cache for performance reasons. If you use getters and setters one can rewrite them to be backwards compatible making it easier to refactor.
My recommendation is to use Conan to manage the third-party stuff and then use Meson or CMake to build your project. There are also a bunch of other ones (all my stuff is built with QBS, which is awesome) but they are far less common, and you are less likely to be able to find solutions with Google if you run into issues.
&gt;If your CMake-fu is strong, you can almost make it behave like npm (grab external dependencies from the Internet). Is there any real advantage to having CMake grab the dependencies instead of using something like Conan to do the job?
Not me. I personally use struct everywhere. It works well with my style, because I like to have public methods at the top of a class definition, and everything private (including data members) below. So with structs, which are default public, I usually need at most one access specifier.
That's called learned helplessness. Let me guess, you've been doing C++ for a decade or more?
What do you find that other tools are missing that CMake handles?
Honestly, it is hard to say. Adding more tools complicates the build process. Death by a thousand little cuts.
It's similar, but the default for public/private inheritance differs as well.
Given the only difference is with the member access specifier default, use whatever. It's the member access specifier that's important. Not whether you spell it "class" or "struct". So it's not "struct for this, class for that". It's "public for this, private for that". Private for the members that have invariants that are not covered by their type. Conversely, you can have public members if you write a wrapper type which handles intra-member invariants. It would be wise for inter-member invariants to be private. Sometimes inter-member invariants implies state changes which may be better expressed as a state machine.
I personally don't use `class` ever, I fucking hate it in fact. You can have private, protected, and public sections in structs too. the very existence of the `class` keyword annoys me, it serves absolutely no purpose.
That is the only difference as far as the compiler is concerned, most people add on other conceptual differences. E.g. if you start creating large structs with many private parts you will violate convention.
Has this ever actually happened to anyone?
Absolutely. And a big advantage of getters and setters is that you can easily add tracing and other debugging features without changing the interface. It's the same reason public methods should be non-virtual and delegate to private virtual methods.
1. Globbing: the only sane way to set source files. 2. Native Visual Studio support (VS can open cmake project WITHOUT generating a solution files. MSBuild will thus not be used.) 3. Android Gradle support only CMake out of the box for native code. (I don't care if Meson support Android or not. I only care if Android Gradle support Meson ot not.)
You can't forward declare a struct as a class or a vice-versa.
Actually nothing will save us, in the end. You can use all the smart pointers or garbage collectors you want, but mostly you are moving the errors from one place to another. Instead of accessing a deleted object, you now have things hanging onto objects that should be getting let go because they in turn hold to other resources that are supposed to be shared by various things but now they are looking at different things, or keeping something locked that should have been released or they are just accumulating somewhere and never getting released and so on. Or you accidentally assign a unique pointer to something and lose the reference and now you are ultimately back to accessing a deleted object, just by indirection. And nothing stops you from incorrectly assigning smart pointers just as nothing stopped you from incorrectly assigning raw pointers. And you can't catch dtor errors and log them in the field for diagnosis, because they don't get destructed until after it's too late in the containing object's dtor (the object can log its own dtor errors but you really want to know where it actually failed.) Not that there's anything wrong with use smart pointers and such when it's appropriate, and I do, but they aren't magic. The just make it somewhat harder to screw up one way and introduce means to screw up other ways. Ultimately the problem is complexity, and it doesn't really get less complex just because you use garbage collection or smart pointers.
Premake seems nice.
Closer to two :)
My opinions aren't as strong as yours, and I have carved out semantic meaning for each simply because they are both there, but I agree that the decision to add the class keyword sort of baffles me.
Obviously being able to 'hook' calls at the base class is very useful in 'frameworky' type base classes. But, for a large class that exists purely to be derived from because it's just providing an interface, it is pretty burdensome to do that, and may not gain much because there's no real 'context aware smarts' at that abstract interface level to apply to the calls.
That's why I change the ones I work on. They tend to grow.
I think the trend is also towards saying the words "functional programming" without actually knowing what that term means, for what it's worth. Now, I'm not saying that's what anybody here was doing specifically, just saying I understand u/AmatanHead's reaction.
I will try, I haven't tried yet.
But it's not in the standard.
I'm totally on the same page as you when I'm doing enterprise work or even any work that I plan to use in the long-term. I'm currently doing a huge amount of rapid prototyping work though, and I work with the constant reality that I'm going to throw a lot of what I do away soon. With that in mind, I've been leaning more heavily on quick and dirty data structures with minimal boilerplate, at least until I need to formalize what I'm doing or pull it up into some more permanent solution.
.
Of course, just using 64 bit number when whole world settled on 128 bit UUID seems strange. We don't want **another** ABI break when going from 64 bit to 128 bit, do we? :P
Please no. It‚Äôs already enough gradle for Android. I had so much trouble with that thing that if this ever becomes a de facto standard build system in C++ it‚Äôs the day I quit C++. Also, I don‚Äôt want my build system taking 2GB of ram to compile 5 cpp files.
Oh, that's great. At least someone took the time to implement this. Nice.
OP had two complaints that you were replying to. The first one was that arrays decayed to pointers. Either way, we don't need to continue pursuing this discussion, I don't think we're disagreeing really, just accidentally talking about different things.
When I started to get at the HAL layer and below, structs were handy. Since the data was simple, structs are easily converted to binary, as long as you are aware about how structs can be encoded (ex: ran into a case where the data had to be packed neatly, otherwise you get extra bytes here and there). Not only that, the structs were easy to use on the firmware, so I just gave the firmware guy the struct
Do you actually mean "struct" or `struct`? I mean, do you mean the C++ jargon "struct", or the C++ language keyword `struct`? Once you frame it this way, you will find there is nothing to argue at all.
Let's speak again where (if) Rust will. Have the same number of programmers of C++. Who uses Rust now is an enthusiast while in C++ there's a lot of people that uses it for work, many not educated as programmers.
I use struct all the time and avoid using class because I don't bother to write the public.
GN build system is focused on readability and speed https://chromium.googlesource.com/chromium/src/tools/gn/+/48062805e19b4697c5fbd926dc649c78b6aaa138/README.md
If you eventually want to give CMake a shot, you may consider using CMake FetchContent instead of git submodules. Here's a discussion: https://www.reddit.com/r/cpp/comments/9284h5/dependency_management_with_cmake_and_git/e33xxh2/
I've done the reverse; removing string interning to reduce latency.
I stand corrected.
&gt; The implication is that exceptions are 'error only'. Yes, well, they are. That you believe they are not shows your lack of understanding. Go learn more about the language first, then you'll have a firmer basis for arguing next time. &gt;The current design is such No, it is not. There is no 'current design', it is implementation defined. This is why compilers could switch from one model to another, when it became apparent the other model had greater performance. &gt;Note that the link that you didn't read I read it when it first came out. Next time check your presumptions at the door.
The worst thing about cmake is the documentation, but gradle's is orders of magnitude worse.
They can throw in an extra 'and' instruction to mask those out. It's not the end of the world, especially since the alternative is to have comparisons that plain don't work. *If* you use one, wouldn't you rather see that it works correctly?
I now use static\_asserts to make sure sizes of certain structs don't change. But you can do the same (File IO) with classes, as long as the layout's the same. It even works with inheritance, as long as there are no virtual functions or virtual inheritance.
You can if you don't care about MSVC. The standard says it's okay, but MSVC mangles the names differently. This is a bug that will probably never be fixed just because of how much it would break. (I don't represent the compiler devs, that last part is just my guess.)
I meant the keyword `struct`, and I agree, it's an absurd proposition - I just wanted to make sure I wasn't wrong in thinking so! :)
Seriously people, what is wrong with just plain make? In my opinion it can do anything cmake can, syntax is simple, is available everywhere and does not need 3rd party dependency (python).
For me, only if the dependency isn't on Conan or if I need a specific revision not on Conan. I actually use [vector-of-bool's PMM](https://github.com/vector-of-bool/pmm) for Conan anyway, which gives the advantage of not having to run Conan myself or even install Conan myself.
It's a small cloud. It's barely the size of a man's hand.
No. base class access is also different :)
It depends. The purpose if data hiding is to give you opportunity to change your data behind the back without disturbing your user's code. For example you might have a member age which you might expose to your users as a member variable. Later on you might change your class to include the birthday data and calculate age on the fly instead. Now figure out if a getter like getAge() was good idea or not. However there are cases where certain data is part of official logic of your class, where setters and getters just add the noise. A classic example is (geometric) vector class in linear algebra. Coordinates x,y,z,w, for example in 3d graphics are part of vector and hiding them behind setters and getters just makes code writing unnecessary verbose and noisy. The hard part in designing APIs and libraries is in making decision what has to be hidden and what can be exposed directly. C# properties are actually nice solution to this dilemma, but unfortunately we don't have those in C++. At least yet. I am surprised C++ people didn't bring those into C++ standard.
Who in his right mind would put the age of someone in a database? So, yes, having a getAge ( ) member function is good as it will do a non-trivial transformation of the data (current_user_date_time - birth_day) [can actually be tricky, if you don't want to be sloppy, day-light savings time, time at user-location etc.]. But a getDateOfBirth ( ) is unnecessary [unless, again, you want to do a non-trivial transformation, like providing different date-formats].
I use it in competitive programming for implementation of nodes in graphs:)
it's all good :-) Like I mentioned in other parts of this thread, i don't even work at the place where I ran into this issue anymore. It's just one of those rage-inducing inconsistencies that we could trivially fix, but won't.
I love C. Yes I can blow my both legs off, crash some occasional ricket and sing one or another boat worh it, but I can choose freely if I wish to pay with my CPU cycles for extra safety and/or convenience. I prefer two thoughts that seems to have fallen either out of favour or out of memory in recent standard updates: the programmer knows best and declaration shell be same as use. The programmer knows best philosophy means that the particular problem is solved best by those who ha e most knowledge of it. Concrete, a general library like malloc can't have same knowledge of your application's memory use like you can and thus can't optimize memory usage as application programmer can. Once you go into realm of high performance applications you will anyways start to optimize memory, CPU usage and so on and then you will be doing lots of stuff you are not shielded from by standard library or compiler anyway. The second rule is my favourite part of C: make declarations look like usage. With other words, make the language and syntax simple. When I learned Haskell I really had hard time to let go the C thinking about syntax approach. Anyway, in C++ I really wonder if some recent addons (lambda for example) needed this syntax. Do we even need so powerful lambda? Couldn't C++ be just good enough with simpler lambda implemented just as another AR (new block on the stack) instead of entire functional object that requires this weird constructor syntax we got with square brackets. Dunno, but I prefer simplicity. I wish we got C+ only :-). A new C with polymorphism, operator overloading , inheritance, simplified template syntax and so on without rarely used features that just add noise and make language more verbose than we really need.
I write C++ that is very much C-style, so yeah, I use them all the time
Programmer knows best only works in small teams, of highly skilled devs, without using binary libraries.
Those that don't use clang, never heard it.
Both operands to the comparison would need to be masked, which then prevents efficient use of reg+mem compare instructions. Personally, I don't usually find much need to do relational comparisons on pointers to different objects, so I don't have an issue with using std::less or implementation-specific casting to intptr_t/uintptr_t for the few cases where it is needed. On platforms that have flat memory addressing this is optimized down to the same as `&lt;` and the only impact is the optimizer knowing that two different objects may be involved. The ugly part is that this means that std::less cannot be implemented as constexpr even with implementation-defined behavior because `(uintptr_t)x &lt; (uintptr_t)y` isn't allowed in a constant expression, so making it constexpr can require compiler magic.
You can't (legaly) const cast the constness away from a const object. Only from a reference/pointer to const that references/points to a non-const object
Can make propagate include paths, defines and compiler flags through dependencies?
Use cmake and optionally support some other build system in addition.
&gt;Who in his right mind would put the age of someone in a database Haha, no idea who would do that :-). It was just a simplest quick illustration I come up with atm, not something to be taken as a real code written. Figure out some better example of a variable you would like to hide behind accessor methods :-).
They do and it is one of the religious battles that human love to fight because of the ambiguity between classes and structures. You know... because if I am right you must be wrong. :-P
Yea but what it can't be is that a Huge corporation is doing way worse than multiple open source projects. If this is not called dropping the ball I am not sure what is. Microsoft should be ashamed, and we the community have the responsibility to point it out.
I recommend Meson. As a second, CMake.
Depends on what you mean with 'high skill'. I had to work with people who didn't know how to use a pointer and on some projects I spent more time teaching C++ and C then doing actual work. In my opinion if you are getting payed for doing work you should know your tools and your craft. I guess you wouldn't pay a woodworker who comes to your house to install a new floor or new window and who is learning how to use a hammer or a tiger saw? Unfortunately I world if programming we are accepting people who expects to get payed without learning neither the machine nor tools they use. Language (compiler) is just another for me to communicate with machine and as a craftsman it is quite clear to me that I have to learn my tools and the stuff I work with (problems and machines I write for).
Members *and direct bases*.
First of all yes, you should use structs. If you don't believe me I hen at least believe the core guidelines. Second saying to always prefer classes over structs makes no sense, structs _are_ classes.
\&gt; believe they are not shows your lack of understanding &amp;#x200B; One distinguish between what is, and what could have been.
Yes! I see no problem with structs but a named tuple will have the advantage that it doesn't need to be defined
What makes it verbose is imho not so much cmake itself (although I'd appreciate a better syntax), but complicated and/or platform dependent build logic (and people trying to use cmake as if it where just a cross platform version of make.
Structs for pod
Because bigger classes doesn't mean better OOP. Believe me, it's far more complicating than saying just functional or classes... There are use case that are very effectively solved by OOP, RAII comes to mind.
The overhead is 1 bit flag check on the stack. It's nothing compared to dynamic memory free time.
In C++ they are actually almost the exact same thing.. The main difference is the default visibility of the members. No need to make a big deal over semantics.
I was using Rust before and I have this issue too in C++. I'm not quite sure which one to use whereas in cargo I could just `deps="version-number"` in the TOML files. Easy enough. Its a decades old language raining with donation from many huge companies and is not low on numbers of experienced contributor yet the problem persist to date. Maybe its due to the language so huge and complex that even the author himself rate his understanding 7/10, I don't know for sure. But again, Rust is currently only usable for web or gui-less program. I'm not writing a libraries from scratch, hell no. For anything else low-level, C++ is a safe bet.
You mean I'm not using asan on gcc right now?
They don‚Äôt appear to solve much, yet introduce a lot of extra complexity.
Getters and setters are very important when coupled with signals. This is how Qt QML updates automatically the GUI which is extremely convenient. Also getters can be virtual which allows to create calculated values while exposing a property.
Except static analyzer also needs its time to run. And you cannot be sure it supports all the intricacies of your specific dialect.
One of the main issues I see is that while C++ has many useful features, the shortest way of writing the code remains the worst and least safe one. You need extra typing to limit use cases. The more limits, the more typing.
Except it's yet another optional feature. I see no way to enforce such 'borrow checker' over my whole codebase and make compiler fail if such 'lifetime attributes' are not used.
I recommend to take a look at [GAIA](https://github.com/romange/gaia). It already has CMake based build system integrated with Google test, Google Abseil frameworks, GLog library and many other third-party libraries.
nice to see this be so much in vogue :p I had a (much less detailed) paper recently where I explored using it for my software if anyone is interested : https://lac.linuxaudio.org/2019/doc/celerier.pdf
Yeah, also if you're using `CMake` to do this this means you'll probably end up re-downloading and rebuilding your dependencies every time you do a rebuild, which can be quite a bit of a problem if you have multiple interesting build configurations and want to test all of them. It also makes it impossible to even configure the build without an internet connection, and it makes it harder to plug your own dependencies (although to be fair, all of those are true of npm as well). My preference would be to just use `find_package`, have a 'default' script that you can run to download and build dependencies (basically `vcpkg` + vcpkg version + a list of dependencies you care about), because then the build script is easy, automatically getting all dependencies is easy and plugging in your own dependencies is also easy... The only problem being is then you're restricted to using dependencies which 1. Are on vcpkg 2. properly export their targets (+ dependencies, for goodness sake!) That's not _nothing_ (for example fmtlib on the top of my head), but it's not a very long list either. There are also other problems, for example maybe I'm just stupid but I could never figure out how to tell vcpkg about other toolchains (I tried setting up MinGW and gave up after a couple of hours).
I believe OP wasn't referring to the keyword, but a class type with public members, commonly referred to as "a struct."
Yes. Unequivocally. I work on mid-size project with both CMakeLists and Makefiles and while the CMake stuff isn't _pretty_, it's _much_ easier to maintain than the Makefiles. And the CMake stuff actually works cross platform, whereas the Makefile build is *nix only.
Fair enough, there are still plenty of other compilers out there, none of them with asan support. TI, HP, IBM, ARM, Green Hills, Intel, Visual C++, C++ Builder, Microchip, PTC, MikroElektronic, ....
I loved meson on linux although I use CMake at work (moderately big, multi-platform projects).
 I'd just like to interject for a moment. What you're referring to as Linux, is in fact, GNU/Linux, or as I've recently taken to calling it, GNU plus Linux. Linux is not an operating system unto itself, but rather another free component of a fully functioning GNU system made useful by the GNU corelibs, shell utilities and vital system components comprising a full OS as defined by POSIX. Many computer users run a modified version of the GNU system every day, without realizing it. Through a peculiar turn of events, the version of GNU which is widely used today is often called "Linux", and many of its users are not aware that it is basically the GNU system, developed by the GNU Project. There really is a Linux, and these people are using it, but it is just a part of the system they use. Linux is the kernel: the program in the system that allocates the machine's resources to the other programs that you run. The kernel is an essential part of an operating system, but useless by itself; it can only function in the context of a complete operating system. Linux is normally used in combination with the GNU operating system: the whole system is basically GNU with Linux added, or GNU/Linux. All the so-called "Linux" distributions are really distributions of GNU/Linux.
`-Werror` would enforce it, as with any other warning. If you want to enforce only this single warning use `-Werror=lifetime`
Wouldn't you get the same problems with a std::tuple (regardless of whether it had named fields)?
&gt; If your CMake-fu is strong, you can almost make it behave like npm (grab external dependencies from the Internet). For 95% of projects, this isn't worth the bother. Most of the time you don't really want updates to external dependencies to happen automatically - because this means that someone else's bad release will make your good code fail. Nearly all the time you want to deliver exactly, byte-for-byte the code that you have systematically tested, not some "very close" version that will "almost certainly" work the same. And nearly all the time, it's not worth doing the new release just for a tiny minor version bump. So for most projects, updating external dependencies is something you will do only dozens of times, and even then most of the work is in the testing, not in the updating.
&gt; I write C++ that is very much C-style, Ah, why? If you don't mind me asking. :)
Struct if the type only has public data members and no bases or derived types. This is pretty universal. Personally I also use struct when every member is public, the moment I have to add an access modifier, it's a class.
"It depends" - basically on the size and complexity of your project. For example, I have quite a few single-header projects, and a lot of them have near trivial makefiles [like this one](https://github.com/rec/tfile/blob/master/test/Makefile), which started as a shell script in my private repo and then got slightly promoted. There's zero to be gained by using CMake here, and it's another dependency and more work. Now, as your project grows, your makefile grows. I looked through my repos, and I found one with a 110 line makefile (posted below with some of the identifying information removed), and to be honest, it reads extremely clearly - BUT that's because even though there are a lot of files and two targets, everything is extremely straightforward, and there are no conditionals, and only one subtarget. I personally in performing "greenfield" development (from zero) have always started with a Makefile and never passed the level of complexity where it became necessary to switch to CMake. Even if you were later forced to switch, it's my claim that this would be easier if you started with a fairly well-organized Makefile in the first place. ---- Here's my example makefile. I edited out some proprietary parts, so I haven't tested it in this form - it's intended as an example only. # # Optional command line arguments: # see http://stackoverflow.com/a/24264930/43839 # # For an optimized, stripped build, use: # # $ make OPTIMIZE=-O3 SYMBOLS="" # # For a C++11 build, use: # # $ make COMPILER=g++ STDLIB=c++11 # COMPILER ?= g++-5 OPTIMIZE ?= -O0 STDLIB ?= c++14 SYMBOLS ?= -g # # Compilation variables. # CXX = $(COMPILER) CODE_GENERATION = $(OPTIMIZE) $(SYMBOLS) -std=$(STDLIB) -pthread DEPENDENCIES = -MMD -MP -MF GTEST_DIR = src/googletest/googletest GTEST_FLAGS = -isystem $(GTEST_DIR)/include -I$(GTEST_DIR) LIBRARIES = -lm -lstdc++ WARNINGS = -Wall -Wextra -Wno-strict-aliasing -Wpedantic -Wno-nested-anon-types DEFINES = \ -DBUILD_TIMESTAMP="\"`date +\"%Y-%m-%d %H:%I:%M\"`\"" \ -DDEBUG \ -DGIT_COMMIT_ID=\""`git log --format=\"%H\" -n 1`"\" \ CXXFLAGS_BASE += \ $(CODE_GENERATION) \ $(DEFINES) \ $(INCLUDES) \ $(LIBRARIES) \ $(WARNINGS) CXXFLAGS = $(CXXFLAGS_BASE) $(DEPENDENCIES) CXXFLAGS_TEST = $(CXXFLAGS_BASE) $(GTEST_FLAGS) # # Files and directories # BINARIES = bin/binary1 bin/binary2 OBJ = bin/obj DIRECTORIES = bin $(GTEST_OBJ) $(OBJ) .deps GTEST_OBJ = $(OBJ)/googletest # # Build rules # .PHONY: all binaries tests .SUFFIXES: .SECONDARY: all: binaries tests pre-build: mkdir -p $(DIRECTORIES) binaries: pre-build @$(MAKE) --no-print-directory $(BINARIES) tests: pre-build @$(MAKE) --no-print-directory bin/tests bin/%: src/project/main/%.cpp $(OBJ)/library.o $(CXX) -o $@ $&lt; $(OBJ)/library.o $(CXXFLAGS) .deps/$*.d $(OBJ)/library.o: src/project/main/library.cpp $(CXX) -o $@ -c $&lt; $(CXXFLAGS) .deps/library.d $(OBJ)/tests.o: src/project/main/tests.cpp $(CXX) -o $@ -c $&lt; $(CXXFLAGS_TEST) $(DEPENDENCIES) .deps/tests.d $(GTEST_OBJ)/gtest-all.o: $(CXX) -o $@ -c $(GTEST_DIR)/src/gtest-all.cc $(CXXFLAGS_TEST) $(GTEST_OBJ)/gtest_main.o: $(CXX) -o $@ -c $(GTEST_DIR)/src/gtest_main.cc $(CXXFLAGS_TEST) bin/tests: \ $(OBJ)/tests.o \ $(GTEST_OBJ)/gtest-all.o \ $(GTEST_OBJ)/gtest_main.o \ $(OBJ)/library.o $(CXX) -lpthread $^ -o $@ $(CXXFLAGS_TEST) clean: rm -Rf $(DIRECTORIES) -include .deps/*.d
I use both structs and classes, simply to distinguish different types of objects (for example a struct for a 2d point structure and a class for an actor that has a 2d position, velocity etc.). As many have pointed out there is no actual difference between them, a part from the default member visibility.
Core guidelines suggest using `struct` for things that don't have internal invariants and class for things that do (makes some amount of sense I guess). My personal take has been to use `struct` for types that are meant to be 'value' types and reserve 'class' for things that use inheritance (so sometimes my structs do have invariants, counter to the core guidelines, but of course in that case I'll make the fields private). So yeah, I can't say I've seen most C++ code, but most C++ code I have seen does still use the struct keyword for some purposes at least. That being said, of course semantically there is really no difference between struct and class anyway, so I could see some community having a guideline to always use one or the other, but I've personally never seen that.
Meson uses pkg-config to find third party libraries on Windows. Might be ok if you live inside msys2, but it's a waste of time if you want to use msvc, which seems like a pretty reasonable expectation on Windows.
Yes. Encapsulate structs Encapsulate tuples Encapsulate everything And then encapsulate encapsulating.
Wouldn't you still need to define the names for the fields, only with less natural syntax?
I usually write very low level performance oriented code in C++, so I don't really care about high level features. I don't like the 'automatic' memory management features in C++, so I do that manually (with a couple of custom memory allocators). Additionally, I am not a fan of OOP for my code. I understand a lot of people find OOP very useful for their large codebases, but for my C++ projects I find that it gets in the way of what I want to do. I do really like some C++ features though (hence why I don't use C). I find operator overloading for vectors and matrices, and function overloading very useful. Also the slightly stronger typed pointers are very nice.
If you're using clang or gcc you can use -fno-access-control to (temporarily!) disable access checks for classes, which can be handy when debugging or during early stages of development.
Well, not quite. structs also publicly derive from base classes by default while classes privately derive: struct Base { int x; }; struct A : Base {}; class B : Base {}; A a; a.x; // fine B b; b.x; // error
Of course. Biggest advantage of cmake are project generation tools written for it. You can generate code for VS,Xcode and so on. You can write converters for make as well if you want, but there is no such tools readily available at least what I know of, if that is important for you. For me it usually is not.
Meh, I'm working with a codebase that is that pattern now, and it just seems to add a bunch of noise for no benefit. A bunch of "init" and "doInit" functions, where the test class is the only thing overloading, i.e. there's no real hierarchy.
Exactly, never write code you don't need right now.
[https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#c2-use-class-if-the-class-has-an-invariant-use-struct-if-the-data-members-can-vary-independently](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#c2-use-class-if-the-class-has-an-invariant-use-struct-if-the-data-members-can-vary-independently)
My dream job would be to skydive or scuba dive all days long without need to touch a line of c++ ever on either AWS or any other platform or any other virtual machine ever :-).
If I were developing on Windows, and were using a package that did everything I needed in every way except that it used Make instead of Cmake, I would not care. Make comes with Cygwin, and there is a good standalone Windows Make too.
Thanks all for your comments and suggestions. I'll dig into cmake!
structs are just classes with everything public by default. Whenever i see a class name{ public: int a int b; }; i want to scream by lungs out.
My understanding of a variant is that it's a union for non-trivial types. As in if you have destructors on union members, union is invalid. Something like Rust's Enum, but I am not too sure. I've had some usecases, but every time I just defaulted to avoiding a union all-together.
What I mean is that if you go for the struct you necessarily have to provie the compiler with a definition: `struct P { int my_var; };`. If you had a NamedTuple you could do something like `NamedTuple&lt;my_var, int&gt; f()` without having to define anything, off course assuming you are only dealing with builtin types.
&gt; If you are getting paid for doing work you should know your tools and your craft But that's exactly the "problem" that modern languages and the more modern C++ concepts (as in ideas, not the new feature) are tackling. Not all code needs to squeeze every cycle out of the CPU, and the vast majority of code doesn't need to reinvent the wheel for even a mundane thing like malloc. If hiring much cheaper developers only adds 10% to our infrastructure costs, why not do it? Especially if the resulting code is easier to maintain and modify.
Something very much like that, yes. &gt;throw an exception in the constexpr instantiation context Yes, we can do that but marking a function as constexpr doesn't mean anything yet and we can't make *every* context constexpr*.* In your example `const auto sizes = std::make_tuple(string_size(others)...);` is not constexpr and it can't be as long as you want to accept not only string literals, but also arbitrary pointers and strings. So the compiler will happily postpone the calculation of string sizes till the run time since it's not needed at compile time, and if you replace `TODO`s with `throw`s it will simply throw at run time even for something like `string_concat("123\0", "456")` which is, obviously, better than UB, but still not the same as the initial goal.
I always felt this would be useful in runtime configured plugins, where you know a virtual function or dynamic lib would be the same every time in a relatively tight loop. Yes, the overhead is not huge, but it would always feel wasteful that I couldn‚Äôt just patch the function call directly.
I consider OOP to be a historic mistake in general, so I actually avoid the class keyword out of almost religious reasons :)
But that's the point he's making. He doesn't want it to take 5/50/500 minutes (because let's be real, it'll take much more than 5 minutes) to install a package, but to write a requirements file and have it work automatically.
For me that's the opposite. `struct` everywhere as it does not make much sense to write `public` every time
Honestly, I'm rolling my eyes...I've had that discussion enough times that I don't feel like having it all over again, but I'll say that it seems like a rather silly hill to settle down on. I mean, contemporary programming is inherently an endeavor in linguistics. OOP is a highly rational response to a complex set of data and behavior grouping challenges with no perfect answers, and it provides a very human interface for a very diverse human audience. Whether OOP in its modern form was a mistake is nearly impossible to quantify as it would mean quantifying the difference in business output (or even entirely missed ideas or opportunities) that would have been spurred by alternatives. That being said, if any of the related or precursory design patterns that are sometimes touted as objective superiors were actually as objectively superior for today's market as many like to claim, the tremendously experimental nature of the software industry means they likely would have risen beyond obscurity by now; alas, they have not.
Would the compiler optimize that code to something akin to a struct?
There's nothing to optimize, that will produce the same code as a struct.
I beg to differ. I seldom see C++ aficionados aggressively shitting on Rust. The other way around though is getting more and more frequent. Rust may well be the future of programming! Meanwhile I have a 2M LOC project to work on everyday and I appreciate learning about C++ without having blatant advertisement on a language that could never make it in our product within reasonable time or resources. Mister Alex from Mozilla may have it easy to refactor his product with a language promoted by his company. Good for him! You also get it partly backward. A lot of the nice and safe features from Rust came from discussions within the C++ community or other old languages (Ada, Haskell, Ocaml...). Take r-value and move semantics, this has been discussed by eminent programmers (Dave, Alexandrescu...) as far as the beginning of 2000. Rust made "move by default", which is extremely nice, but that that doesn't negate prior work on that matter. In return, Rust is certainly accelerating C++ transformation, which is healthy too.
It doesn't work with third party libraries.
Funnily enough, if you look at all the CVEs around, some languages that the author point as safe (javascript, python...) are more frequent in the reports than our dear C++. I am guessing a buffer overflow is more spectacular than trivial permission logic errors in a web server or a bad request parsing in your JSP, so there you go! I would rather burn weakly typed and dynamically typed languages from production than Modern C++.
"Honestly, I'm rolling my eyes...I've had that discussion enough times that I don't feel like having it all over again, but [...]" I'll spare you the discussion then.
Well, this is what's nice about C++: you only have to pay the safety tax for code that actually needs the safety. You don't have to worry about the overhead of bounds-checking affecting your performance-sensitive code, for example.
I mean, obviously I betrayed that by subsequently giving my opinions, for what it's worth. The rest of my response was pretty much a distillation of where the conversation has landed every other time I've had it, but I wouldn't have given it if I wasn't open to it being followed with criticism/discussion. I pretty much just meant I didn't want to get into any sort of technical discussion if it didn't directly answer those points.
CMake, everything else is irrelevant.
I don't think we speak about same use cases. In those cases where you don't care about CPU/RAM/IO performance you maybe don't even need C++. In such cases you can use as well Node or Python or TCL or just simply pack entire browser like Chrome or Webkit into yet another application that would take maybe few thousand lines of handwritten code and let all those hardware achievements of last 10 years be eaten by layers of code, virtual machines, conainerized libraries and what not. I carricature a bit, but little bit on that side are things going.
Indeed.
If your project is a library, keep in mind that anything you choose, you will impose on your users. So being more conservative in the choices (even if X build system features a nicer Y that you'd prefer). My recommendation - use CMake. I'm saying this as someone who maintains ~70 various conan packages that need to be built for 18 different profiles (compiler/arch/os combinations). Those builds that use CMake generally just work everywhere or can be amended easily. Everything else is just trouble apart from some specific platforms where development obviously happens. Also, I'd avoid Bazel just for the huuuge Java dependency, but also because Google might kill it any day.
The biggest advantage of std::tuple over a struct is that you can take advantage of things like std::invoke.
You can't fix C++. There are too many pieces of software that rely on current behaviour (e.g. most 3rd party libraries that you may want to use in your project). This is similar to how Windows can't be fixed (too many existing programs that MS simply must not break). In short: backwards compatibility is too important. Any attempts at fixing the shortcomings of C++ will inevitably create a new language. Many seem to focus on memory issues (unbalanced alloc/free, use-after-free, etc). I think there are equally important issues that exist on an even lower level, such as implicit type casting, unclear types of literals, undefined values, etc, that are much harder fix without major changes to the core language.
Sure. I was simply pointing out that if encapsulation is truly not needed (rare, but it does happen), then std::tuple has built-in library support that a custom struct lacks.
As long as symbols are namespaced and linked properly this can work.
&gt;such throwaway structs eventually become relied upon and then demand proper interfaces and encapsulation. Easy enough, just change `struct` to `class`, and move it to it's own proper file.
But it goes at it the wrong way round by being unsafe by default and the only mitigation is having strict and partly unenforceable coding guidelines or in other words "don't make mistakes".
You could equally have the signal call a lambda which updates the public member variable.
Thanks, I just assumed the compiler added some extra crap around classes.
isn't that what weak_ptr is for?
Why such a liberal usage of \`shared\_ptr\`?
I always prefered the [XKCD](https://xkcd.com/1312/) take on Haskell.
I can tell you that i am not switching to it, i dont like functional at all so it will never be an option, at least Go has data types even it is more or less functional as Rust And i aggre that any new lang has that problem, convincing actual deps to switch, as many of you i has been tempted by so many langs that i am in a point that i dont really care that much and believe in getting a better C/C++ instead of forgeting it forever in favour of [x] ultra popular one
How about we argue about which end of the egg to break? For factual argument, your friend is wrong - there is no shortage of \`struct\`s in the new C++ code.
What does C gives you in a way of CPU cycles which C++ does not?
C++ Builder? Is it still around?
&gt; I would rather burn weakly typed and dynamically typed languages from production than Modern C++ +1
Valgrind does.
Ok, then let's try that. First of all: Of course calling anything a historic mistake is objectively wrong since we cannot branch history and evaluate the different path, but my main argument regarding the undoing of OOP is in stark contrast to this: &amp;#x200B; "the tremendously experimental nature of the software industry means they likely would have risen beyond obscurity by now; alas, they have not." &amp;#x200B; In the last 5 or so years I haven't seen a single new library that is using OOP as a design concept. In fact of all the libraries I use in all the languages I use Qt is the only exception. Even the STL uses traits-based polymorphism (via unenforced concepts). That much about C++. The last few other languages I learned (Go, Clojure, Elixir) and the ones I additionally use (Haskell, Rust, JS), all simply abolished inheritance-based polymorphism. I also have to regularly use python (ML :|) where classes are (in my experience, YMMV) primarily used for encapsulating state with rare sightings of inheritance. &amp;#x200B; Meaning: In my very diverse, current reality (that does not include business-Java) OOP is not only an "obscurity by now", but in fact silently died in favor of traits or monadic approaches. You can argue that you are living in a business-reality that has different rules and laws, but that reality just isn't mine and I base my decisions on whether or not to use struct/class on my own ;)
&gt; I usually write very low level performance oriented code in C++, so I don't really care about high level features. I guess you are talking about "heavy" stuff like exceptions, RTTI, dynamic dispatching or maybe about some STL types that use those or generate very bad code. Apart from those, I would say most of C++ (specially the most widely used part of it) doesn't introduce any performance degradation.
What is the targeted usage scenario? I mean, this is totally cool as a hobbyist project, but I am not sure what kinda of production application it can have. In particular, what's the benefit over, say, python?
Instead of a .busy method/etc, the modern way would be to use futures/promises for the blocking. The performance benchmark should likely compare to other projects, otherwise the timings aren't meaningful. I dont see why the dialects are shared_ptr instead of just stack variables. Aren't there only ever 1? I'm surprised to see the rows use std::string instead of string_view. Having each row store a duplicate of the header seems like a waste. You'd be better off storing one copy of the file, then each row be made up of string_views. You seem to be using mutexes to protect access of a booleans. Look into using std::atomic with compare_exchange instead. It does seem as well like you need to look into your usage of mutexes. The fact that this takes 2 threads is disappointing. Anyone with a better computer will be disappointed that they don't get to use their other cores, and anyone on a worse one will be irritated it takes too many threads. Consider using the ASIO model of a thread pump.
Looks quite interesting. One small comment: You should "namespace" your include directory, i.e. have the directory structure \`include/csv/\[your\_headers.hpp\]\`.
1) If you're asking about C++ reflection itself - then it fully depends on application which uses it. It can be for example - save / load configuration file, it can be encode / decode binary buffer. &amp;#x200B; 2) If you're asking about project generation API - then it's target is to be able to create simple to use API for project generation - currently for Visual studio, but in future might be expanded to other IDE's / OS's / compilers. for (2) I can provide you more details in case if you were asking about it.
After reading the article, here are my thoughts: * String_view potential use-after-free is a pain in the neck. A lengthy conversation is an evidence. One of the solutions might be to configure static analyzer to not allow free-standing string_views at all - only ones which are becoming function arguments. I haven't seen such suggestion in the thread, but I feel like it could be a good thing. * Optional rant is BS. This is UB, and C++ has UBs for valid reason, and optional access is no different from accessing std::vector out of bounds - it is unchecked for performance and 0-cost abstraction. * Span not offering checked `at()` is a regrettable thing, but not a deal breaker - especially since index access is rare nowadays and people mostly used ranged for loops. So after giving me those 3 pointers, one of which is bonkers, another one is industry-acknowledged sore points which people are working on, and the third one is `meh`, authors jumps to very broad conclusion. He is certainly entitled to his opinion, but I find it unsubstantiated.
string_view is only in C++17 and this library is for C++11
I am asking about general idea of using C++ as a scripting language in general. What benefits does it offer as compared to traditional scripting languages of many flavors?
I don't think you are reading my post correctly.
May be I am not, what am I missing here?
Realistically speaking, it might be better, if bounds checking was the default and you could opt out when it matters.
That I am saying I prefer power of low level control instead of language trying to shield me from stuff that might be abused?
After reading the first line, I was thinking "another rust zealot trying to write another article on how bad C++ is and how our lord and savior rust can save you". Looking for rust in the page, was not appointed.
Short answer: \- To have only one programming language, which is fast. Two or more language application architectures suffers from their own problems (how to debug it, etc etc...) \- To establish some sort of standard for C++ project generation. I can provide you also bit longer answer - but please read that document between lines, because it's content is already outdated on some parts I have analyzed and prototyped. &amp;#x200B; [https://docs.google.com/document/d/11Tl3AMtTkd\_qfcgBzcQLCupHmI\_v0iJ1KuH7z\_rpBDw/edit#heading=h.9w0btkdvkjbt](https://docs.google.com/document/d/11Tl3AMtTkd_qfcgBzcQLCupHmI_v0iJ1KuH7z_rpBDw/edit#heading=h.9w0btkdvkjbt)
This might be a little late as I've been looking around reddit to see if there are any other command line interfaces, but I have written a [c++11 command line library](https://github.com/TheLandfill/cpp_cli) that does everything except automatic handling of '--help/-h' options, but adding the help part is straightforward. In fact, I implemented something like both gcc's -W and -D flags. Plus, it also handles subcommands, like "git pull". &amp;#x200B; For adding the help, just create a bool variable for help, create a Command\_Line\_Value for help, and then print help and exit the program if the help variable was set.
&gt;which is fast. Did you benchmark? Can you post the numbers?
 [https://gitlab.com/LIONant/properties](https://gitlab.com/LIONant/properties)
Which Make? Gnu make BSD make Windows Nmake
Only in specific OSes, and that is no longer the same as `-Werror` and also has Heisenbug effect due to the slowness it induces.
Surely, https://www.embarcadero.com/products/rad-studio
string_view or string_ref has been implementable for the most part since C++20. Abseil and Boost both have implementations that can be used/cribed.
C++20 isn't out yet... I presume you meant C++11
I prefer not to discuss benchmarking issues in here, as question-answer thread might get quite heavy. It can also depend on design of application itself - e.g. incorrectly used C++ (e.g. not using pointers or references) can give you pain in #¬§%. But generally C++ is faster to execute than C#. &amp;#x200B; I have also observed development of COSMOS - that's operating system developed on C# - they do perform there quite neat tricks to get optimizations on good level, but from my perspective those are not quite production ready. &amp;#x200B; Now I can get a lot of replies for or against each programming language, but - for example - comparing analogue "logging" frameworks for .NET: [https://www.loggly.com/blog/benchmarking-5-popular-net-logging-libraries/](https://www.loggly.com/blog/benchmarking-5-popular-net-logging-libraries/) Is talking about best performing logging method 100'000 messages in 9 seconds, meanwhile for C++ analogue benchmark: English: [https://weekly-geekly.github.io/articles/313686/index.html](https://weekly-geekly.github.io/articles/313686/index.html) Russian: [https://habr.com/ru/post/313686/](https://habr.com/ru/post/313686/) is talking about 100 ms per 1'000'000 messages. I'm still missing one benchmark framework which would benchmark both C++ and C# logging technologies in same test framework.
The thing is that most CPU optimize for that, so the benefits are relatively minor. Compilers have been poor for a long time and CPU compensated with hardware circuitry. If compilers become good enough that it's not worth the circuitry we could make simpler but faster CPU, or run everything from a GPU.
Oops, yeah, I meant 98 :)
Why do people use downvotes as a way to disagree with the article? I disagree with his conclusions and methodology but this post deserves an upvote because it addresses an important topic, and it should get attention if for no other reason than for readers to understand what parts of his argument are valid and what parts are incorrect.
This is the rule I use as well.
Sanitizers are dynamic tools, that only check code path actually executed with the values provided during that run. That is very valuable, but a far cry away from a static analyzer telling you that a particular piece of code contains a bug during compilation.
&gt; it might be better, if bounds checking was the default C++ is often chosen for its performance. "Safe-by-default" is better achieved by using a different language. The default for C++ should be "programmer knows best."
Couple of times that I checked the generated assembly code. IIRC there was a talk by json Turner at cppcon, where he wrote a long game for his... amiga? There const also had a quite dramatic effect. Thing is: A const object is really const and the compiler knows that everything inside will never be modified after initialization (unless of course it has mutable members - but that is something the compiler know). How much of an advantage that information provides is obviously situation dependent. What most people complain about however, is that const qualification of member functions doesn't help the optimizer and that is correct.
Seems like you are set on C++, but I think Julia is promising: [https://julialang.org/](https://julialang.org/)
The only difference between a struct and a class is whether it is default public or private
Very interesting line numbers mentioned for type\_traits / variant, especially when viewed in hex. &amp;#x200B; Are we likely to see any references to line 15855390 I wonder?
Agree with Paul. This whole 'OOP' is evil thing is ridiculous. When doing large scale software, it's one of the biggest hammers we have to nail with. I wonder how many of these anti OO folks have done a million or two line code base in their amazing new style and maintained it through four or five major revisions?
Awesome project. Could be incredibly useful for development; also when modules are up and running the only part that needs to be jit'd is your own code, all dependencies will be exactly as your production environment.
Thanks for the constructive feedback! Clearly, I have more work to do with this library. And lots to learn :)
Actually it's very useful, if you stick to some sort of strict semantic scheme. Because now you can search the code and find structs vs. classes. Since you are using them for different things (as I do as well), then there's often a good reason to want to do so.
Absolutely agree. It's passive-aggressive childishness.
&gt; such throwaway structs eventually become relied upon And that's good... &gt; and then demand proper interfaces and encapsulation. No! - why would you do that? `struct` typically means "plain old data" - data without behavior. If you start adding interfaces, methods, encapsulation to your struct, you lose all the good things about them - the simple semantics, the fact that they're fast to copy and can be passed by value easy, the simple initialization, etc. If you have an existing struct and you need behavior, either create a free function, or if you need to glue together several structs, create a class that holds the existing structs that you are using.
I tend to agree. I started with Make and added CMake much later. The thing that CMake has helped me with is Windows builds. I still like to use the old makefiles on \*nix.
Looks needlessly verbose. Namespaces would make it possible to avoid lot of typing. Eg. cpp_cli::Var instead of Command_Line_Var (using namespace cpp_cli would avoid all that typing when used inside the function defining the command line options) Why ARG_PARSER is all caps? (Why Snake_Case for classes? CamelCase or snake_case are much more popular) Why ARG_PARSER is a namespace and not a class? It being class would provide some benefits and with the current usage it wouldnt even be more verbose (probably less verbose) Singleton or just simple function parser makes IMO only sense when arguments are automatically registered. See how LLVM's argument parsing works (options are created by just creating static variables of the correct type). Otherwise it is better to have proper class for argument parsing.
&gt; Structs for types that are 'mostly' open, And why would you want a type that is "mostly" open? It's so much easier to reason with pure data, than a type that is "mostly" open.
Not so - inheritance is also by default public on structs.
&gt; main difference isn't it the only difference?
&gt; I personally don't use class ever, I fucking hate it in fact. &gt; &gt; You can have private, protected, and public sections in structs too. "I like to make my code different from everyone else's in unimportant wars, just to fuck with my readers."
&gt; At some point, I almost always find that I regret making data members public, almost every single time. You're missing the whole point of Plain Old Data. Usually `struct` indicates plain old data, which you never expect to put any behavior on at all. Adding public members to classes is asking for trouble; structs are public members and nothing else. Makes for clearer and more correct code.
Good points with the namespaces. I originally used CamelCase, but then my style shifted to snake\_case in general and it kind of ended up a hybrid. It's not too hard to change. ARGS\_PARSER is in all caps as kind of a new thing, but that's not too hard to fix. ARGS\_PARSER is a class with a bunch of static members and functions because I didn't see a need to create an object for parsing, but I see that it's a little verbose the way it is. I genuinely don't understand what you mean by "simple function parser" or "automatically registered." If I were to make it less verbose, do you think it would be a useful library?
Is this (an archive of) the SGI link you are referring to? https://web.archive.org/web/20121225183151/http://www.sgi.com/tech/stl/Rope.html
So your criticism of modern approaches is that it isn't old enough to have proven itself? Fortran has proven itself for quite some time in numerics now - I wonder if all those modern C folks have ever written a robust implementation of the Arnoldi iteration yet...
Thanks! It looks helpful
No, my criticism is of people who claim that OO is bad or outdated or wrong, when the vast majority of the software they use is OO based, and when they themselves have no empirical proof that they can do better with something else on anything beyond fairly modest projects.
&gt; Oops! C++ lacks the facilities for the compiler to be aware that sv captures a reference to something where the reference lives longer than the referent Thats a problem with the implementation of std::string_view. You could easily create your own one that doesnt allow construction from temporary objects. C++ actually gives you the tools to avoid a lot of similar problems.
I also see my local gcc installation has a `ext/rope`file, if you want to find actual code.
Because `shared_ptr` fixes your weird bugs. (I jest, but I recently had a stupid bug to do with a 3rd party library class that had a deleted default constructor for no good reason. Hid it behind a `shared_ptr` and bug gone, onto real work)
Or "I've been writing C instead of C++ for 20 years and I just can't accept the fact."
Ok i made it through the rest of the article and its even funnier. You explicitly chose to capture a temporary function argument by reference and return it. You explicitly chose to dereference the optionals using *. There is no "hidden" vulnerability. You are explicitly telling the compiler "Do this, i guarantee there is a value" etc. You do have the option for safety checks (.at, .value ...) Do you also hate Rust because it has "unsafe"?
Creating an object for the parsing is just one line and it allows specifying the name of the parser which also makes it easy to give it a short name. By automatic registering I mean that the parser would be a singleton and Var class constructor would access the singleton and add itself to the parser options. LLVM uses this approach because it makes it easy to add new really specific options that are only required in one file (that file can just define new command line parameter variable and use it without needing to do anything else). That approach has its benefits and down sides. Command line parsing libraries are useful but there are already many well made and mature libraries for it. You would need to make your library someway better (in some area at least) than the other options if you want someone to prefer your library.
I like some ideas of Rust. I actually enjoy functional style programming. But ultimately it lacks adoption/the C++ ecosystem which is the major reason i use c++. At the end of the day it matters if you can get your goals done, and i certainly can do so with c++, despite its many pitfalls/ugly design choices.
`absl::Cord` will be open sourced not too long from now. Should be a pretty good reference. :)
Well, we never EXPECT a lot of things to happen, but over a decade of supporting a product, our expectations may not end up being correct. As I said, I use them very sparingly, where their use is highly constricted (inside a single file or class) or in very low level code where the are bootstrapping issues to consider. That way I know that, should my expectations prove wrong, the damage will be very limited. Otherwise, I assume the worst and plan for that, and just use a class with inlined get/set methods, so that if I'm proven wrong it's not going to cost me anything particularly.
I've already made the namespace/variable naming changes locally, but I'll have to update the README. Anyway, I should probably be more clear that running parse will clear out everything automatically, as if it was never there, so you can add specific options easily, especially if you want to use subcommands. Also, ARGS\_PARSER is essentially a singleton and the Var class constructor does access the singleton and add itself to the parser options, so I don't really know what to improve upon there.
Furthermore, I think that this article provides conclusive proof that Boost is dying.
You're certainly correct that most calls to the string_size and string_concat functions won't be evaluated constexpr. There's not really anything that can be done about that unless C++ provides a mechanism to detect when function parameters are constexpr. That being said, I'm entirely satisfied with runtime exceptions for this usage. That's sufficient to catch the vast majority of programming logic issues with unit tests.
Not to discourage you, since I'm sure it's nice, but isn't the point of scripting languages mostly to be simple and fast and very difficult to shoot yourself in the foot with? Seems to me the reflection stuff would have other, potentially more interesting and general, uses than using C++ as a scripting language?
The article is mostly correct, except of course for the "and therefore you shall all write your OS kernels in Rust or Swift" part.
Updated the whole project with the shorter names. Now, it looks like: #include "cpp_cli.h" void sample_subcommand(int argc, char ** argv, void * data); int main(int argc, char ** argv){ std::string filename = ""; int recursion_level = 0; std::string show_output = ""; bool standard_input = false; char c_version_of_string[20]; char file_type = '\0'; std::vector&lt;int&gt; list_of_ints; std::vector&lt;const char *&gt; non_options; { using namespace cpp_cli; Var&lt;std::string&gt; filename_var(filename, { "o", "output", "out" }, true); Var&lt;int&gt; recursion_level_var(recursion_level, { "r", "recursion", "max_depth" }, true); Var&lt;std::string&gt; show_output_var(show_output, { "show_output", "s", "no_out", "half_out" }, false); Var&lt;char&gt; c_version_of_string_var(c_version_of_string, { "v" }, false, 20); Value&lt;bool&gt; standard_input_var(standard_input, { "-" }, true); Value&lt;char&gt; file_type_file_var(file_type, { "file", "f" }, 'f'); Value&lt;char&gt; file_type_dir_var(file_type, { "d", "dir", "directory" }, 'd'); Value&lt;char&gt; file_type_link_var(file_type, { "l", "link" }, 'l'); Vector&lt;int&gt; list_of_ints_var(list_of_ints, { "list", "L" }); Parser::add_subcommand(sample_subcommand, "test"); // The third argument argument isn't necessary to set in this simple example. non_options = Parser::parse(argc, argv); } // Other code. At this point, all variables are set. }
&gt; Android Gradle support only CMake out of the box for native code. (I don't care if Meson support Android or not. I only care if Android Gradle support Meson ot not.) I'm stuck with my Android port. I didn't know there's a connection between CMake, Meson and Gradle.
&gt;Not to discourage you, since I'm sure it's nice, but isn't the point of scripting languages mostly to be simple and fast and very difficult to shoot yourself in the foot with? Depends on application itself. Add python scripting to 3d car simulation to drive car - works ? Sure. Multiply same car by 1000 cards to simulate typical heavy traffic loads - oh, slow already ? I'm working on daily basis with C# + C++ - but actually it's C# + C++/cli + C++ - 3 languages. I want to eventually reach only one programming language, whichever is fast and better designed for my need. Currently what I have analyzed - I can help C++ infrastructure, but not C# infrastructure unfortunately.
&gt;Seems to me the reflection stuff would have other, potentially more interesting and general, uses than using C++ as a scripting language? C++ reflection can be used by itself independently of C++ project generation API's - need only to cherry pick right files from project.
"when the vast majority of the software they use is OO based" Sorry, but this is not true. The vast majority of software I use is imperative and I yet have to see the proof that OOP can do better. And me not liking a particular paradigm does not necessitate empirical evidence in an industrial scale. Interestingly this also seems to be the case for the designers of modern languages...
Nope, it doesn't fix 'weird bugs'. It could hide weird bugs (for them to bite you later) or it can workaround third-party bugs which you can't fix.
Need to try it out probably at some point of time. Probably not so widely used language in itself. &amp;#x200B; I once upon a time wanted to recombine natural language with programming language into one language, but that requires deeper semantic analysis of language structure. There exists for example "Toki Pona", which minimized amount of vocabulary words to 137 with flexibility to extend phrases constructing them differently. Maybe when I'll retire I'll come back to this idea. :)
Nothing about encapsulation makes copying more expensive or passing by value more difficult. It also doesn't make a POD type non-POD. It's almost always a good idea to encapsulate data. Initialization is the one area where a `struct` might be preferable but one should think carefully about whether such initialization is really needed and whether the benefits outweigh the drawbacks of exposing data directly.
Does it really matter if it is in the standard if every compiler supports it in the same way, and isn't going to change it?
Define "OOP." That's a critical step often missing from these flamewars.
"OOP" != "inheritance." There are many, many, *many* new libraries that use OOP.
Yes, but then that defeats the purported safety of standard smart pointers. I'll note that Rust doesn't really have a great way to deal with cyclic structures either. It's a hard problem.
Please see the huge benchmark results here: https://martin.ankerl.com/2019/04/01/hashmap-benchmarks-01-overview/
Wow this looks super useful! Thanks for doing this!
What sort of clock are you using that has *attosecond* resolution?
this benchmark shows the average, so total runtime is divided by number of iterations.
Oh no, another homebrew macro-based sequence container. Don't.
How is this not UB? You don't like that conostructors and destructors are called when objects are created and destroyed.. what?
Or use an utility like the one I wrote, where you are done reading the docs in 5 minutes and even have some VERY advanced possibilities like type conversions to any type and parsing of even other things such a lists of texts [https://github.com/Wittmaxi/CommandEr](https://github.com/Wittmaxi/CommandEr)
Take a look on [build2](https://build2.org/) (do not confuse with b2 from boost). It's build system + package manager for C++ written on C++.
This library already has type conversions to any standard c++ type and can easily be extended to do any type conversions you want. My library is also header only, so it's just an include away. Can your library handle subcommands?
As others have said the only difference between \`class\` and \`struct\` is private/public members and inheritance by default. I just use \`struct\` for everything. Public inheritance is usually what you want. Putting your public interface first is usually what you want. \`struct\` fits both of these implicitly so looks cleaner, though I probably shouldn't rely on that since other folks reading the code may not know the difference.
The debate between what to use between `struct` and `class` for some type declaration is meaningless to me. Almost nobody agree on when to draw the line between the two. The thing is that they both are exactly the same thing. The only diferrence is the default access level. I personally use struct everywhere, since the default access level make sense. I always never use private inheritance or when I truely want to use it then I want to be explicit. I want the default for inheritance to be public. I want to put everything that is public first, since someone who opens my header surely want to see what it can do with my type. Structs give me all that by default so it's a sensible choice for me. Others may want to be explicit with everything and set all the default to something one does not want so it has to be explicit. That's a valid case too.
"How to use C instead of C++. Now with undefined behavior!"
Alright what about startApplication -position &lt;vector3d coordinates&gt; Need special typecasting! My docs are - litterally - the readme What do you mean by subcommands? If you mean something like -file hello.txt, then yes, it does that, if not, i'd be glad to find out what they are so I can implement them ;-) &amp;#x200B; No hate, btw, but I think that a library shouldn't be more complicated than what it does. Reading your docs takes more time than implementing it myself
But isn't changing the behavior of such methods, (such as suddenly enforcing an invariant between two properties just as much of a breaking change as replacing a public member through accessories?
Pretty sure `Event::Observer::reset` has a race condition due to trusting the result of [`weak_ptr::expired()`](https://en.cppreference.com/w/cpp/memory/weak_ptr/expired).
Fair enough, the README is a little verbose. I could not find anywhere on your README where you demonstrated the syntax of your code, which would be what docs are. Subcommands are things like "commit" in "git commit", where they act like their own commands. If you wanted to pass in a vector like that, just implement cpp_cli::Var&lt;Vector3d&gt;::set_base_variable(const char * b_v); and you would pass in prog --position=x,y,z
This is not C++. Please, use simple standard primitives instead of this type-unsafe crap
Also, moving an Event isn't safe because an Observer's destructor might get called in the middle of the move.
Maybe, I am not sure if structs work with vfuncs and inheritance etc but they probably do. AFAIK it is the only difference.
I don't need to teach the users C++ syntax, i just say which functions exist. what else do you want? Also, why do I need to explain how my library works? the user doesnt care and likely already knows how to parse a string. Subcommands are nothing than just a "does flag exist". Just add a simple if condition. Okay, fair enough with the type casting both our libraries are on the same page. &amp;#x200B; I looked through some of the code of your lib. The interface looks like (very very overcomplicated) modern C++, but internally, you use char-arrays, stdio and all the old shit. With all its insecurities and vulnerabilities, you might want to update that. &amp;#x200B; Oh well - let's settle the debate there
It might actually be, but you'd have that problem either way I guess. At least if you already wrapped them you don't have to go find all of the places it's used and do the wrapping after the fact. And you already have one place you can add an assert or two to help catch such issues during the development cycle where you made this change, in case you don't manage to find them all by eye. And of course it might not necessarily be adding an invariant, it might be something like some change in the data format, and having wrapped them already allows you to more likely be able to provide backwards compatibility. Or the addition of more members, which raw uses of the structure won't be initializing correctly and can then be defaulted to something reasonable in one place. Or you suddenly need to for some reason be aware if one of the members is changed for some reason, even if it's just for diagnostic purposes. It's easy to do that if it's already wrapped. Basically, a lot of the reasons why encapsulation is an important thing could potentially be applicable, it would seem to me.
I require 2017 C++ in my project due to string\_view, from\_chars and a few other library things. I've been asking compiler vendors to backport those things to 2011 C++, but am not aware of any that have. I'm not satisfied with Abseil or Boost options.
I'm not saying you should explain the inner workings of your library, I'm saying you should explain the interface. I follow the README, and then what? How would I use the parser? No, subcommands actually have totally different flags and options, so you would not be able to implement them with a simple if condition. They are almost entirely independent from each other. There are no insecurities in the char arrays and stdio as I manage my own buffers well. The only way you could cause a problem is if you, the programmer, actually create a non-null terminated char array and pass it in. Even then, something like std::string won't be able to help you if you were to do the same thing. How is cpp_cli::Value some_var(variable, { "f", "file" }, true, "Takes in an input file.") very, very complicated modern c++ syntax?
Also, an Event being destroyed at the same time as an observer is unsafe,
Good catch! I've updated the code to use \`weak\_ptr::lock()\` directly.
Oh damn. If this became a flame war I better stop now. Anyway, OOP for me boils down to polymorphism via inheritance. State encapsulation itself is not enough as monads achieve the same thing using a different methodology. Functions scoped to specific classes (in the general sense of the word) of entities neither, since explicit traits or the implicit approach of Go again achieve the same. What's left (unless I miss sth) is the idea of hierarchical property organization and the partial polymorphism that comes with it (partial in the sense that there is limit - e.g. there is a reason we don't have a "Printable" superclass but instead a trait (operator &lt;&lt;)). You are right that discussions (or flame wars as you call it) are pretty pointless without specifying the topic at hand - although I actually just wanted to make a joke about struct/class :D. Have a nice evening...
Okay, if you don't see how to use the parsers, no doc will be enough Mhh... Interesting I might implement subcommands in my lib! Buffers are bad practice and shouldnt be used nowadays (there are tons of ways in which they could break, you shouldn't make your task harder as a programmer), also, they are inefficient \&gt;Even then, something like std::string won't be able to help you if you were to do the same thing. It would be because it keeps track of how big it is ;-) \&gt;How is cpp_cli::Value some_var(variable, { "f", "file" }, true, "Takes in an input file.") \&gt;very, very complicated modern c++ syntax? I have a doubt, will that compile on clang (assuming that you add a semicolon at the end ;-))? Anyway, this is amongst the simpler things it does and honestly - it is already pretty complicated. You have four arguments to a function. How will a normal programmer which order they are on - or even which they are? This tuple you have (I assume its a tuple, right?) what does it express? also, why use such a big namespace name? You are encouring using namespace cpp\_cli;
That's not the correct way to represent the average, as you shouldn't display more decimal digits than is the resolution of your measuring device. For example, the average of 1.35, 1.35 and 1.36, mathematically, is 1.353333333... but to make a clear statement about significant digits and the resolution of your measuring device (clock), the correct average is still 1.35, from an engineer's point of view.
 I require 2017 C++ in my project due to string\_view, from\_chars and a few other library things. I've been asking compiler vendors to backport those things to 2011 C++, but am not aware of any that have. I'm not satisfied with Abseil or Boost options.
You do realize that the input to the program is the count of the arguments and an array of null terminated const char *s, right? For dealing directly with anything in the arguments, I just need to keep going until it reaches a null. In short, you will not be able to mess up the buffer as a user. As a programmer using the library, you can't mess up the buffer unless you really try, like by intentionally creating a char array that isn't null terminated (which you cannot do by accident) and passing it in as an argument to any function that expects a string, in which case, std::string would also fail because it expects to be set by a null terminated string. It's a constructor, dude. I'm making an object. Also, do you really think that a programmer can't keep four things in his head? The general syntax is cpp_cli::Value&lt;T&gt; some_var(T&amp; variable_you_want_to_set, std::vector&lt;const char *&gt; list_of_flags, bool takes_args, const char * optional_help_message = ""); The names are only long because I'm describing them in depth. Solving long namespaces is easy: namespace cli = cpp_cli;
Thanks for the reply, bookmarking for future reads!
\&gt;You do realize that the input to the program is the count of the arguments and an array of null terminated const char \*s, Yes, I do realize that ;-) i'm not just talking about \*those\* buffers, btw, more like char buff\[2084\] I counted 7kb of heap being wasted in a single function. &amp;#x200B; \&gt;Also, do you really think that a programmer can't keep four things in his head? Yes, i do really think that :) \&gt;The names are only long because I'm describing them in depth. I didn't say that long names are bad. &amp;#x200B; \&gt;T&amp; variable\_you\_want\_to\_set, output arguments? how many states are you changing in a single function in order to need those? &amp;#x200B; \&gt;Solving long namespaces is easy: then do it
Quick, tangentially related question while you're here. If one wanted to use `robin_hood::hash` with, say a tuple of three ints as a key, what's the preferred way to provide a custom hash function, or the ideal technique for computing one?
Brings me back to high school. Haven't thought about sig figs in a while
I'm curious about this, because I remember sigfigs from science class, but then there are methods like oversampling ADCs to gain better resolution than when the hardware provides: [https://www.cypress.com/file/236481/download](https://www.cypress.com/file/236481/download). That seems similar to what he is doing here. Can you (or anyone else) explain what the discrepancy is there?
I think I don't follow. I start a time, perform 50 million operations, then stop the timer, then divide the resulting time by 50 millions. My measurement clock has a precision of about 40ns or so, so when I measure 0.0312718 seconds, which is well above the timer precision, I can calculate that on average each iteration took 0.625ns, even though that 0.625ns is far below the measuring precision.
boost uses a hash_combine function which is quite simple: https://www.boost.org/doc/libs/1_55_0/doc/html/hash/reference.html#boost.hash_combine It works very well and is reasonably fast.
Yeah? What's the average of two measurements, 1.35 and 1.36? Surely it's not either of them but 1.355.
Not this exact case, but come to think of it I did have to refactor a lot of computational code before when the decision was made to go from "store everything as data" to "store as little as possible". Things like replacing every call to object.
char buff[2048] is stored on the stack, not the heap, which is part of the reason why I use char buffers and not strings. I know exactly how long certain things are going to be, and so I use a buffer. When any of the flags provided to a Var/Value are set, it will set the variable in the first argument. That's the entire point. The library takes in a variable, flags, and an optional help string. It then sets the variable once you run parse.
It's a convention for reporting averages. The precision of the average needs to match the precision of your measurements.
Great point! For now I've decided to keep the abstraction, but to move all actual data to a \`shared\_ptr\`.
So in this case, would the canonical thing to do be: write a regular `std::hash` functor using `boost::combine` on the `robin_hood::hash` value for each component type?
There is none, /u/bstaletic is simply wrong.
Resolution of N measurements is increased as a ratio of 1/sqrt(N). So you don't just divide the LSB by N. Furthermore the people telling you that output resolution == input resolution are wrong.
Average is a useless metric. The median is much more useful.
Yeah, you're ok. If you wanted to go the extra mile, you could repeat that same operation many times and then get the standard deviation for the distribution of your measurements. That number would give you the actual "error" in your measurement, not only accounting for the error on your measurement device, but also the variation in the measured object (the operation you're benchmarking for) But hey, we are all out of college, what you did is just perfect for real life. I would actually judge someone who is wasting so much time in something as trivial (from my point of view) as this.
Thanks, should be fixed in the current release.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bg5sco/xpost_from_rgamedev_any_resources_about_job_system/elintwd/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[https://dbj.org/c-strong-duck/](https://dbj.org/c-strong-duck/)
That's where tolerances come into play and is what I omitted from my response above. Yes, in your example, the average is 1.355 (assuming that you couldn't get a more accurate reading even after a larger number of samples), but your measurements were oscillating by +-0.01. In case where most of measurements are at 1.35 and only a few are 1.36 or 1.34, the tolerance for the reads is +-0.005.
A few things: - Your benchmarks are not deterministic, and therefore not reproducible as well as may be influenced by outside factors - You're reporting the average, which is almost completely useless, you should be reporting the median - The results you're reporting deviate quite drastically from my own benchmarks (not including your hashtable) Something else: I never heard of the sfc64 generator, what type of random generator is this, and where does it come from (specifically, who is the author)?
A union with non-trivial members is valid, but its special members are implicitly-deleted (i.e. compiler won't synthesize them, but the programmer can provide a definition). &amp;#x200B; So variant is a union + type tag that indicates which type is stored.
they do
There are some good comments there but let me add a few that maybe are not as good. At this point new development of libraries shouldn‚Äôt be targeting C++11. That is going on 8 years old and may be 9 by the time the library is finished. From the standpoint of a user of CSV libraries, primarily with Python, I don‚Äôt see a huge problem with the user interface. Things that I‚Äôve run into though that might be a problem and thus deserving testing is malformed records in the CSV file. That is records with fields completely missing. It would be nice to have a away to dump such records to user code for touch up before being stored. Beyond that make sure you are Unicode compliant. One of the reasons I turn to Python is that the standard library supports working with CSV files thus there is no need to hunt for solutions. If you are serious about this library; it would be nice to see an effort to get it included in the standard library. Frankly that would make it far more likely to be used. Haven‚Äôt checked boost lately but that would be a good place to get comments on feasibility plus you would get help on code quality, compliance and the like. One feature for reader that might be worth considering is the ability to select fields in the record to actually store. That is I want fields #2, #3, #8, and #12 out of a record that contains let‚Äôs say 40 fields. I only skimmed the md file so maybe this functionality already exists. If not though it offers the user a lot of advantageous over the reading of everything into memory. Memory usage is reduced along with post processing chores.
Unfortunately without this paper http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0593r2.html your code produces undefined behavior after every malloc or memcpy.
sfc64 is from PractRand. It is evaluated here: http://pracrand.sourceforge.net/RNG_engines.txt The C code is in the download PractRand_0.94.zip https://sourceforge.net/projects/pracrand/files/
the stack is on the heap... btw: where are your boundchecks? C++ has the you dont pay for what you dont use. Ummm... so what you are doing here is just so cumbersome...
I'd say that's the safe way to do it. If your data is trivial, you could also just use a murmurhash of it's data. E.g. if you have a large struct like this: struct Foo { int a; int b; int c; int d; }; And have an object `Foo foo`, you could use `robin_hood::hash_bytes(&amp;foo, sizeof(Foo))`.
I do not think I follow. If my clock resolution is one second, and it take me 1 second to perform 1 000 000 operations, are you saying that the average time for one operation is 1 second (precision of my clock)? This seems weird.
If your clock resolution is one second, that's pretty terrible. Thats an extreme example.
Alright, so it's not a new one, it's just a very old one. On a sidenote, you may want to update your knowledge about PRNGs to the year 2019. Start [here](https://arvid.io/2018/07/02/better-cxx-prng/).
Why should I provide an upvote? The article provides valid points, but at the end its an ad for Rust, this is the only sub that is "friendly" towards c++ and we get a lot of negativity all the time, why I should promote more negativity towards c++? If he would have mentioned rust or switf as examples and not as "you should run away from c++ to those lengauges", then, I would have upvoted the post.
I just gave the benchmark a try, with the Majestic Million dataset. On my computer I get these numbers: * 3,060s with `std::unordered_map` * 2,146s with `tsl::robin_map`, as is * 1,763s with `robin_hood::unordered_flat_map`. So you might want to give it a try, get [here](https://github.com/martinus/robin-hood-hashing) the header-only single file
Technically, the median \*is\* an average. I think what you are saying is that he reported the mean rather than the median. Both of those are averages.
Woops. You're absolutely correct. Fixed.
Sfc64 is actually relatively new, you might want to give it a try. It's much faster than PCG in my experience and does not suffer the same issues as xorshift which is really bad. I strongly advise against xoshiro128+ (as does the author now). xoshiro256** seems to be ok but it's also slower than sfc64.
Me too! Since I always put public methods first, and usually inherit publicly, using class just means more typing to override the default constantly.
Maybe it would be more understandable if we use a ruler as an example. If the smallest resolution of your ruler is 1mm you shouldn't be reporting things you measure in micrometers since you can't reliably see how thick things are between two 1mm lines. I believe most people refer to this as the Lease Count Error. Going back to timing an operation, suppose your op takes less than 1 second but your clock only has 1 second resolution. This means that your clock is always either going to report 0 or 1 seconds (since you don't have the resolution to measure between) when measuring the time of your op. If you do 1 million trials then your total experiment time will have taken 1 million seconds. So your average is 1m seconds / 1m trials = 1 second avg. Now what you are suggesting is instead of timing a single operation multiple times, let's try to fit as many operations within one second. While this will give you a sub-second average, I do not think this is a the best test protocol. Since you don't have individual measurements, you lose statistical distribution information such as the median and the standard deviation. Also, your average can get skewed by an outlier and you will never know because you can't detect outliers when you don't have individual measurements. &amp;#x200B; Hope this helps.
I'm using C++ for years as scripiting langaue that runs async tasks (processes). Why C++ ? I didnt have to lern another language. It is easy to write such thig with c++11/14/17, it has very low dependency on other libs, bare linux server is enough. I have to write only small core lib responsible for managing processes with grap dependency. Everything other/scripts are dynamicaly compiled with simple bash runing cpp file.
I would advice to look at [https://github.com/Bagira80/More-Modern-CMake](https://github.com/Bagira80/More-Modern-CMake)
And now we can have static_asserts at run-time
no
Not quite. The standard deviation tells you nothing about the _systematic_ error in your measuring device.
*shrug*, I don't ship or maintain a standard library, so I've got no control over that. However, in my projects I tend to do my own implementation of those under my own namespace conditionally. I did the same with make_unique before 14.
Oh, [this guy again](https://www.reddit.com/r/cpp/comments/3vstha/randy_gaul_hates_the_c_keyword_auto/)...
Ah wonderful, thanks!
std::optional doesnt return an unitialized value if you dereference it when empty. It's undefined behavior. Ive mostly had dereferencing an empty std optional crash IIRC. The whole point of std::optional is that you have to check whether the value is there. It isnt 'modern' to use std::optional and not use it like a std::optional. Modern C++ doesnt turn C++ into Rust, but it's certainly a hell of a lot safer and better than old C++.
That matter was discussed during standartization of \`string\_view\`. The argument against accepting pair of iterators is that \`string\_view\` maps a \*contiguous\* area, and there is currently no way to assure that iterators provided are belonging to contiguous memory. I am not necessarily convinced - it could be just specked out as UB unless they are - but alas, this is what Standard settled on.
100%. I think trying to re-implement bits of the standard library is the most effective way of getting intimately familiar with C++.
It could be extreme, but it goes to show. It is also valid example in my world, where we measure stuff in CPU ticks.
Right, there's some serious noise in this thread. I know Zed Shaw is divisive, but I agree [with this article](https://zedshaw.com/archive/programmers-need-to-learn-statistics-or-i-will-kill-them-all/).
Its a convention in reporting stats, I didn't make it up.
I agree with the single measurement example, but we are talking about average over multiple measurements. I simply can't agree to the fact that you can't measure an average delay when your clock has greater resolution than the delay itself. For example, Linux clock resolution is often microsecond, but our operations are measured in nanoseconds. We have to aggregate and average. This might not be the best test protocol, but this is the one we have.
See above for some discussion.
There is a proposal for it so there is still hope that it will be added before C++20 is released. [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1391r1.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1391r1.pdf)
&gt; You're reporting the mean, which is almost completely useless, you should be reporting the median This is a ludicrous statement. They are different statistics with different uses. Often in benchmarking, you're dealing with a heavy tailed distribution so outliers will be a serious issues, but it's reductive to say something like 'the mean is completely useless' when it's one of the central objects of probability theory.
Ok, the explanation makes sense. Regarding *holding a view into array of characters, and if it is not what you have, than do not use `string_view`*: I use the view as an read-only string (better than `const std::string&amp;` because some objects are literals and allocating them for actual string would be nonsense). Ranges appear because I use some generic boost algorithms so naturally they use iterators. My algos work on simple single input object so I can easily guuarantee that any iterator range is a valid view.
I use make with this template I built https://bitbucket.org/jroddev/cpp-project-template It uses git submodules for external dependencies. And any project specific config goes in a separate file I've named app.config (but it's really just a 2nd makefile).
I think you misread the person you're replying to. They said &gt; it take me 1 second to perform 1 000 000 operations but you're talking about &gt; suppose your op takes less than 1 second but your clock only has 1 second resolution. So you're not adressing the issue.
You can not like it all you want. But that doesn't make it a historical mistake. I seriously doubt that most of the software you use isn't OO based, but giving you the benefit of the doubt, most of the software that most people use these days is. If OO is so horrible, how did that happen and why did it happen? Are all of us delusional? No, many of use came up before OO and we know perfectly well how bad that sucked. I boggles my mind to see people today arguing for using enumerations and big switch statements (or the C++ template equivalent) all over the place. That's one of the key reasons OO was invented to get rid of. I'm no Rust expert at all, but I look at Rust and all of the people constantly asking how to do things that would be trivial in C++ via OO and you have to jump through so many syntactical hoops to do it in Rust. They could have just made OO easy to do in Rust, since you don't have to use it if you don't want. If everyone then wrote Rust without OO that would be one thing. But I'm fairly sure that lots of C++ style OO would get done in Rust if it was supported, because it's a completely obvious way to achieve some very obvious goals. And in fact you don't have to use OO in C++, but most folks do, because it's a no-brainer to use such a powerful tool. As to modern language designers, what are they going to do? If they write an OO language they are immediately competing with C++ and C# and other OO languages. They would be unlikely to get anywhere down that road.
You use case ("because objects are literals") is exactly the use-case for `string_view` which brought it to existence. However, your latter case ("ranges appear because I use generic boost algorithms") is not. You might want to have some glue code to transform one into another.
It's a very good example that illustrates the issue with saying "your reported resolution *must* match your measurement resolution".
I just mean it should in order to meet the convention. Not because of some weird law handed down to us from Zeus. I really don't care, I don't have a horse in this race.
Have you heard of cling? [https://github.com/root-project/cling](https://github.com/root-project/cling)
Thanks. I'll take a closer look.
Never really felt like I needed a glue code. Everything related to input parsing is based on iterators, so it felt very naturally to continue using boost range everywhere.
That's already the case though :(
Yes, mentioned in "C++ as scripting language" document: [https://docs.google.com/document/d/11Tl3AMtTkd\_qfcgBzcQLCupHmI\_v0iJ1KuH7z\_rpBDw/edit#heading=h.tlzm8d3358sr](https://docs.google.com/document/d/11Tl3AMtTkd_qfcgBzcQLCupHmI_v0iJ1KuH7z_rpBDw/edit#heading=h.tlzm8d3358sr) Quoting from there: What I have briefly scanned through - clang / cling provides C++ compilation /scripting out of box, but debugging is not possible. Cling should be able to compile .cpp to .dll, but it‚Äôs not possible at the moment - it uses clang‚Äôs JIT compilation, feature is not present in Microsoft compilers or Visual studio. In longer term perspective it‚Äôs possible that clang / cling toolchain will outrule Microsoft on compilation toolchain, but not clear if that ever happens. (My initial tests indicate that Microsoft linker has faster link speed compared for example to clang based compilers)
&gt; I would rather burn weakly typed and dynamically typed languages from production than Modern C++. Burn everything weakly typed. I tried to work a bit with JS and Python and just couldn't stand the constant question: What the fuck this function is returning? What can be checked at compile time, should be checked at compile time. Period.
You can use cmake for build system. I don't like the submodule way of doing things, It's better if you download all dependencies and build it. It's better to wrap the cmake within a batch/shell script to set environment variables.
[The stack is not the heap.](https://www.gribblelab.org/CBootCamp/7_Memory_Stack_vs_Heap.html) They are fundamenally different. Stack memory is generally faster and it takes care of itself. It depends on which variable you're talking about for bound checks, but generally they're either in for loops where I know the boundary size and never go past it (which is exactly how you would do it in a string, by the way), they're null terminated strings, or the programmer tells the library how much memory it can allocate if you want to modify a char array. Once again, you cannot accidently get a buffer overflow, you, the programmer, must intentionally try to use it incorrectly, at which point no library works. If you can point to a single line of code where using a string instead of a char array would make my code better, safer, faster, etc., then I would love to hear it. Otherwise, it's not a fair point. You can screw up your bounds checking just as easily with a vector or a string. While you're at it, there is absolutely no dynamic memory allocation except automatic cleanup in classes like vector, so I won't get a memory leak. You thought a constructor was some kind of fancy modern c++ interface, you don't understand the difference between the stack and the heap, you hijacked my post to self promote your project instead of making your own post, and you've been excessively rude. Granted, you did point out that my README was hard to read, so I changed it. If you come to the table with something useful, then I will edit my project. Otherwise, I don't want to waste any more time on you.
&gt; The thing is that most CPU optimize for that, so the benefits are relatively minor. They can't. Branch prediction saves a few cycles usually lost to the indirection but CPU can't inline the function which leads to actual performance benefits.
/r/cpp_questions
Concepts. Ugh.
std::optional example is caught during debug builds if you set stdlib-safety on your favorite compiler. The only negative is that this catch is during runtime instead of compile time. Output with -D_GLIBCXX_DEBUG=1 &gt; /usr/include/c++/8/optional:945: constexpr _Tp&amp; std::_Optional_base&lt;_Tp, true, true&gt;::_M_get() [with _Tp = int]: Assertion 'this-&gt;_M_is_engaged()' failed. &gt;Aborted (core dumped) This would therefore also apply to the second example since it is with optional Finally, as per span's operator[] being indexable past-the-end, I only have gcc 8 but this is what happens if you attempt to index past-the-end on a vector: &gt;usr/include/c++/8/debug/vector:417: &gt;Error: attempt to subscript container with out-of-bounds index 2, but &gt;container only holds 1 elements. &gt; Objects involved in the operation: &gt; sequence "this" @ 0x0x7ffc2e37cc70 { &gt; type = std::__debug::vector&lt;int, std::allocator&lt;int&gt; &gt;; &gt; } &gt; Aborted (core dumped)
No thanks
Thank you
This always sounds like arguing over the serving size of sprinkles. Do you want a lot of sprinkling or a little sprinkling over your machine code? It‚Äôs a spectrum and sometimes more is appropriate. Other times less is preferred. It‚Äôs a religious argument but at the end of the day one is going to show more productivity. We have enough anecdotal evidence to show that some languages are better for certain use cases. The Python vs C++ paradigm is easy because it‚Äôs two sides of the spectrum. A binary choice. People like easy choices. Once you start adding in other choices people get their knickers in a bunch because now the decision is t as easy. My point is there‚Äôs no one perfect tool. We should acknowledge that and stop trying to say one is absolutely better or worse. One is better at X. The other is better at Y. Everyone knows that Rust has better memory safety and making contrived examples doesn‚Äôt change that, but it certainly gets people worked up.
Which convention? I think you're missaplying a convention from empircal science that you shouldn't use a greater resolution in your result than your measurements (but you can gain extra resolution from multiple experiments).
Please don't. He's right sometimes the way a broken clock is. But whoppers like this: &gt; Before statistics the belief was that the world fit into perfectly mathematical models, and that any error we find is because we don‚Äôt have the models right Make it hard to take him seriously. He should take his own advice, but about science. He has no idea what he's talking about, yet he goes on about the history of science like what he's saying is consensus. The world of physics was largely separate from formal statistics, and statistics didn't cause big rethinking of the philosophy of science. It's hard to even debunk everything wrong with his opening sentences because his misunderstanding is so fundamental, that his framing of things already takes things for granted which are incorrect. He's "not even wrong", as it were.
I didn‚Äôt bring it up. Someone else did and then deleted it. I was just explaining which convention that original person was talking about.
ask the guy in the original post , he or she would know better than I.
You can use std::async to run the function getting the input and use std::future::wait_until to wait for some time on the main thread. But you have to either ensure that you get the input in the end, or use some async IO library that allows you to cancel it because std::cin will be blocking that thread until it gets the input and you can't cancel std::async. You could use std::thread and detach it after timeout but that's not a "clean" solution.
Isn't it dangerous if the struct has padding which may not be initialized?
In fairness, no clean solution is possible. The question involves ceasing to wait for input without closing the input stream. So the user is racing against the clock.
Absolutely great article!!! The examples illustrate the ability to easily write code with very non-obvious bugs. Seeing these examples makes me realize that this must be a very common occurrence. And don't think that being an expert programmer can save you! To detect something likes one needs to: a) know that there's a bug in there somewhere b) know more or less where the bug is c) step though the code in detail either mentally or with a debugger or both. It's way too easy to write something like this and way to time consuming to prevent it, detect it and track it down. &amp;#x200B; What's missing here are some rules on C++ usage to avoid things like returning reference to a temporary, returning references to underlying types etc. and trapping at compile time when these things are attempted. Robert Ramey
"a language aimed at providing more performance over safety for security issues is getting old" No it's not. Things are getting worse. Reading code these days reveals more and more obscure impenetrable stuff which is justified with speculative assertions that "x is more efficient". I've got a few observations on that. a) If the code doesn't work, it doesn't matter if its more efficient. b) if the code can't be easily read and verified by a human to do what it's intended to do, it won't be. ... and will likely be wrong. c) performance and safety do not conflict with properly written C++ code. If you find yourself in this situation, step back and ask your self how you got on the wrong track. Robert Ramey
&gt;Thats a problem with the implementation of std::string\_view. You could easily create your own one that doesnt allow construction from temporar LOL - where do you get this? or is this another Peter Dimov joke.
&gt; Writing out a growable array shouldn‚Äôt require C++ template knowledge, or compile-time nonsense, or constructors or destructors or any other baggage. Sometimes all that‚Äôs needed is a growable array, and that‚Äôs it. Hah. I had to laugh at this bit. If you're calling destructors baggage, you probably shouldn't be writing c++...
You can static_assert or enable_if on `std::has_unique_object_representations`.
Is this vulnerable to the "O(n¬≤) on external copy" bug that Rust hit?
Only if i don't have to pay the overhead if I'm not using compatibility
I‚Äôm an aerospace engineer and have taken classes in measurements and have been engineering and programming for 13 years. While you are correct about measurement precision, you are not correct about how it should be applied in this case. Python has nanosecond resolution for time (though typically that level is not used). So if three calls takes 0.5, 0.51, and 0.50 seconds, it‚Äôs customary to call the time out to two significant figures. If I have 1 million, I can be much more sure that the timing of my problem is accurate. In fact, it‚Äôs going to be more accurate that what is even worth reporting. Still programming is different than engineering measurements, so it‚Äôs customary to report mean and worst case. For a simple calculation (so not say a sort), the worst is roughly the mean and you‚Äôd report the something like the 95th percentile. Another way to put it is if I have a meter stick that has a 1 mm resolution and I want to measure the thickness of a coin, I can put 500 coins down to improve the accuracy. That tells me the mean, but not the standard deviation. However the timing functions in python does give you all that information, so you can calculate statistics.
I have commented on this issue to boost::string_range (precursor of std::string_view). Back then author insisted on contiguity over flexibility (esp. on generic context). I still don't agree on this decision, so I often subclass string view and add range constructor and use that in my code.
&gt; c) performance and safety do not conflict with properly written C++ code. If you find yourself in this situation, step back and ask your self how you got on the wrong track. This assertion is wrong. Examples include bound checking and pointer conversion, both are dangerous operation if done wrong but no checking is done by default because the overhead is too much (sometimes of several magnitudes). Don't forget the first principal in C is (or at least used to be) "trust the programmer", which means it doesn't prevent programmers to shoot themselves in their feet exactly because of such overhead of safety checking. Note, I'm not saying one should not do these checkings, but there are legitimate reasons to not to do so in some cases.
my new version hash map's inserting performance is 20% fast than before .
I thought my 3rd paragraph addressed what they said.
Sometimes compiler/library vendors decide to implement a Technical Specification (TS) to give users early access to some upcoming features. This usually ends up in the `experimentel` namespace. The audio API proposal has not been implemented by any compiler yet (AFAIK) and it's just available on GitHub. You'd need to install it as an external library in order to use it. They have a "How to Use" section on the readme.
Thanks!
There is no scripting language I have found that isn't difficult to shoot oneself in the foot with, or fast (I'm assuming you mean 'to develop with'). They only give you the illusion of being easier and faster because they "run" without compiling. But the joke is you have to keeping running the script over and over to get the bugs out - bugs which shouldn't be with a good type system and an adequate generic library. You essentially do the compiler's work, but it feels productive because the program "runs" straight away.
Good stuff. I even write simple text processing scripts in C++ these days.
Obviously there can always be 'bugs' in terms of it doesn't do what you intended it to do. But it can be 'bug-er' free in terms of not allowing aliasing, threading, direct memory access, memory leaks, and so forth. My system has an OO macro language called CML. It is purposefully the opposite of C++ so that they can both be used to their own strengths. C++ provides the heavy lifting and CML provides the cream on top more or less. Obviously you can write code that doesn't do what you intended in CML, but you cannot mess up memory, leak memory, access anything that CML doesn't allow you to access, access deleted objects, etc...
And cppcheck will catch the second example: &lt;source&gt;:7:12: warning: Returning lambda that captures local variable 'x' that will be invalid when returning. [returnDanglingLifetime] return [&amp;]() { return *x; }; ^ &lt;source&gt;:7:28: note: Lambda captures variable by reference here. return [&amp;]() { return *x; }; ^ &lt;source&gt;:6:49: note: Variable created here. std::function&lt;int(void)&gt; f(std::shared_ptr&lt;int&gt; x) { ^ &lt;source&gt;:7:12: note: Returning lambda that captures local variable 'x' that will be invalid when returning. return [&amp;]() { return *x; }; ^
Precisely, a flag, which is what every implementation of `std::optional` uses. In fact, I believe it's guaranteed not to allocate.
I really just agree with his first paragraph (and title), in so much that a lot of programmers are very quick to jump to simulation, or running more simulations, without stopping to think whether there's a more appropriate analytical tool.
No you didn't actually address the question. If I measure 1e6 operations in 1 second and my clock resolution is 1 second, what is the average length of operation (or range, or confidence interval, whatever). Obviously this is problematic, but by your logic we can only report 0s or 1s, which is even more problematic.
&gt; I would actually judge someone who is wasting so much time in something as trivial (from my point of view) as this. Good numerical and experimental hygine isn't a triviality.
What does this accomplish over just using a concurrent queue.
I would agree; our University learned Python first then Java. And boy did I have a hard time. Since I've picked up c++ everything has be a lot more clearer in terms of deep understanding.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bgblt8/c_books_and_projects/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Already in favorite üòâ
Use `git subtree` instead of `git submodules`.
Ah, I didn't know about that. Thanks!
What exactly is supposed to be the advantage of those macros compared to putting the exact same code into a template?
This doesn't make much sense. By that logic you could simply increase the resolution by increasing the number of iterations, but in fact anything below 100 picoseconds is essentially measuring noise. Even a hypothetical 10 GHz CPU would take 10 picoseconds per clock cycle to do anything useful.
Which hashmap are your taking about? So you have a link?
https://github.com/rust-lang/rust/issues/36481
*Standard library maintainer walks in and shudders at thought of deriving from standard library types. Particularly just to add convenience functions.*
Note that v140, v141, and v142 are ABI compatible with one another :)
This is not to say we won't ever break ABI again. It just means that we aren't flipping that switch just because the VS version number changed.
So depending on how you call the ram its faster or slower? Interesting!
I don't think `robin_hood::unordered_map` suffers from this issue. In fact iterating and copying in order should be even faster than random insertions because there are less cache misses. But I think having copy benchmarks (one with copy constuctor, one with iterating) would be interesting to add.
The heap is used when you request that the computer gives you some random memory somewhere in RAM, while the stack is known as soon as the process is created and only needs to adjust a pointer to allocate/deallocate memory. Plus, since the stack is contiguous, it spends most of its time in a cpu cache which has even faster memory access than pure RAM. &amp;#x200B; You can read more [here](https://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap) on the differences between the stack and the heap and you can read more [here](https://en.wikipedia.org/wiki/Locality_of_reference) on cache locality.
It's not *necessarily* a no-go, but it is a "this feature needs to demonstrate some extreme benefit to overcome its extreme cost to customers." Not wanting to pick a new name for variadic `lock_guard`, or having a \~200 byte allocation in an uncommon operation in `&lt;system_error&gt;`, or making `&lt;system_error&gt;` safe to use across standard library 'domains' aren't near that cost. Many proposal authors whose papers are rejected on ABI grounds don't realize the changes they propose are ABI breaking, or what the costs of ABI breaking are. It seems certin to me that on some number of standards basis WG21 needs to consider a batch of ABI breaking proposals and let their combined improvement be the reason for breaking ABI, as it seems unlikely that any single feature will justify such costs anytime soon. Unfortunately LEWG et al. seem to be adding more and more virtual interfaces to things like polymorphic memory_resource and the current proposed executors design, which constrain interfaces such that we can't even add things.
This [Lehmer-style](https://gist.github.com/imneme/aeae7628565f15fb3fef54be8533e39c) PRNG is also very fast. It appears to be faster with Clang than sfc64, but slower with gcc. Note that it fails `Practrand` at 64GB, but has a nice smallish footprint. If you don't care about the birthday-paradox violation and need an even smaller footprint [splitmix64](https://gist.github.com/imneme/6179748664e88ef3c34860f44309fc71) is equally pretty good (i.e. fast).
I feel like people who advocate stuff like this wouldn't be equally happy learning equivalently deep stuff about python, javascript, C#, etc. just to be able to read and understand code. Most people who write C++ code are not C++ programmers. Expecting them to be seems like a bad idea.
The issue isn't you not up-voting. That's perfectly reasonable. The issue is people just down-voting something as a form of 'punishment' to people who dare disagree with them or the standard C++ line, instead of straining themselves a bit and coming up with a coherent counter-argument.
Yes, I remember we recently had a discussion [here](https://www.reddit.com/r/cpp/comments/b9va9y/how_i_discovered_the_c_algorithm_library_and/ek8kpnv/) :)
Sorry for the noise, did not remember it was you.
A language is a tool. As such, one needs to understand his tools/weapons of choice, be it python, javascript, c++ or assembly. If we want high quality software, we better expect people writing `$LANGUAGE` to be good (should I say "excellent"?) `$LANGUAGE` programmers.
That's a quite awesome benchmark. Though it seems weird that in the `Find 1 ‚Äì 500k uint64_t` the `tsl::robin_map` is doing more poorly than the `tsl::sparse_map`. On all the tests I did between the two, find 0%, 50%, 100%, `tsl_robin_map` was always ahead. I quickly ran your benchmark with `g++ 8.3.0` and I have some differences with you (which are partially normal due to my processor, a i5-5200U). `tsl::robin_map` is doing better, `tsl::sparse_map` worse. I have to investigate a bit what could the reason be. Here are my results: ./build/bench_tessil_robin_map__robin_hood_hash RandomFind_500000 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "01"; "0% success, 0x00000000ffffffff"; 33571; 12.0469; 37.4141 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "02"; "0% success, 0xffffffff00000000"; 29114; 12.6186; 49.3672 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "03"; "25% success, 0x00000000ffffffff"; 125018398; 14.7996; 49.375 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "04"; "25% success, 0xffffffff00000000"; 125016517; 15.1236; 49.375 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "05"; "50% success, 0x00000000ffffffff"; 250006412; 16.3708; 49.375 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "06"; "50% success, 0xffffffff00000000"; 250004852; 15.5588; 49.375 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "07"; "75% success, 0x00000000ffffffff"; 374997827; 13.4162; 49.375 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "08"; "75% success, 0xffffffff00000000"; 374996290; 13.5138; 49.375 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "09"; "100% success, 0x00000000ffffffff"; 499988041; 11.3071; 49.375 "tsl::robin_map"; "robin_hood::hash"; "RandomFind_500000"; "10"; "100% success, 0xffffffff00000000"; 499988041; 11.203; 49.375 ./build/bench_tessil_sparse_map__robin_hood_hash RandomFind_500000 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "01"; "0% success, 0x00000000ffffffff"; 33571; 13.5068; 11.2461 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "02"; "0% success, 0xffffffff00000000"; 29114; 13.5905; 11.25 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "03"; "25% success, 0x00000000ffffffff"; 125018398; 18.489; 11.5078 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "04"; "25% success, 0xffffffff00000000"; 125016517; 18.6726; 11.5078 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "05"; "50% success, 0x00000000ffffffff"; 250006412; 20.6167; 11.5078 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "06"; "50% success, 0xffffffff00000000"; 250004852; 21.9824; 11.5078 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "07"; "75% success, 0x00000000ffffffff"; 374997827; 22.0287; 11.5078 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "08"; "75% success, 0xffffffff00000000"; 374996290; 20.341; 11.5078 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "09"; "100% success, 0x00000000ffffffff"; 499988041; 20.4317; 11.5078 "tsl::sparse_map"; "robin_hood::hash"; "RandomFind_500000"; "10"; "100% success, 0xffffffff00000000"; 499988041; 19.8583; 11.5078
Thank you very much! Your benchmark as well as your hash map implementation is really useful. &amp;#x200B; One question regarding the code: [https://github.com/martinus/robin-hood-hashing/blob/master/src/include/robin\_hood.h#L1693-L1696](https://github.com/martinus/robin-hood-hashing/blob/master/src/include/robin_hood.h#L1693-L1696) &amp;#x200B; "it seems we have a really bad hash function! don't try to resize again" -&gt; `throw` (no `catch` in robin\_hood.h so I think this will be propagated to the client/application code) It looks like the hash map won't `increase_size` if you have a bad hash function? A bad hash function may impact the performance of the program but it should never kill it, right? Maybe I misinterpret the comment in your code?
good jobs, I think hash map's copy should be added to your benchmarks.
I would have thought the point of using C++ as a scripting language is to also only expose customer-facing C++ interfaces in a safe way. If you wouldn't expose internal interfaces to your CML, why would people expose their internal interfaces to the scripting API in a C++ scripting system?
I(author of emilib1::HashMap) also test on my pc amd 1700, the result is also different.
&gt; Most people who write C++ code are not C++ programmers. No, they literally are. Most people who write C++ might not be very _good_ C++ programmers, but that's a different point.
you are right that seems strange. Maybe g++ 8.2 made some bad decisions with inlining? I compiled with `-O3 march=native`. All my data here: https://raw.githubusercontent.com/martinus/map_benchmark/master/data/all.txt
Trust the programmer. I trusted myself to nice, and it didn‚Äôt end well. Never again making that mistake.
Gradle is a PITA. From a Java guy.
Hi, you are reading it right, for a bad hash function my map can simply fail. When insertion fails because one bucket gets too full, I am doing an `increase_size`, and if that does not help either, only *then* an exception will be thrown.
I'm pretty sure CERN's cling lets you dynamically compile and call template functions, without the need of a language extension or special compiler flags. The downside of cling would be a fairly sizeable runtime dependency, however.
by the way, once you have benchmark results, you can use the script `tools/analyze_bench_log.rb &lt;output.log` to generate one HTML page per benchmark
maybe replace the input hash function with a different hash function is a good choice ?
Not only to spread the code with new and delete, but also MyClass* myObject = new MyClass(....); ... ... delete myObject; All in the same scope
The use of c-arrays and raw pointers is pretty widely taught, but in reality you should only use those in a few rare cases. Raw pointers should really only be used - as iterators, - when working with a C library - when writing your own custom containers But you shouldn‚Äôt just be using them in the middle of a function. Smart pointers are preferable because smart pointers actually clean up their own memory. C-arrays are problematic because they automatically decay into pointers; because you can‚Äôt return them from a function; and many times they‚Äôre used when something like std::vector would be easier and more appropriate
Can you elaborate it, please?
That is true, but tools should still be as usable as possible to avoid errors and make learning and reading the language easier. There are very good rationales for why default functions get deleted in some cases, but I believe they are more due to the incremental nature of C++ (backward compatibility and all), and less because there was no other way to design a language. If someone would redesign a fresh C++ today, it would probably be without the rule of zero, one, three, five and all.
I think (single) out function parameters are still quite heavily taught. In most cases returning by value is even more efficient due to (N)RVO.
Who teaches that?
Except it doesn‚Äôt do what you want if your output is a pmr type.
1. `void main()` 2. `sizeof(array)/sizeof(array[0])` 3. Worse, `#define ARRAY_SIZE(array) sizeof(array)/sizeof(array[0])` 4. Use `new` and `delete` expression directly, unencapsulatedly, unRAIIedly. 5. Runtime endianness check. 6. Use `std::fstream::open` and `std::fstream::close` without a reason. I mean, ever heard of constructor and destructor? 7. `get` and `set` every private data member reflexively. 8. Type punning with undefined behaviour, esp. in embedded software and device drivers, which are supposed to be reliable...
&gt; That is true, but tools should still be as usable as possible to avoid errors and make learning and reading the language easier. Agreed, though all of "rule of X" variations can be replaced with just a single one, that doesn't require that much attention to details: "Try not to mention any of 'the big 5', but if you mention any of them, you should mention all of them". &gt; There are very good rationales for why default functions get deleted in some cases, but I believe they are more due to the incremental nature of C++ (backward compatibility and all), and less because there was no other way to design a language. I can't fully agree with this. If I had a magic wand, I'd just change the rules about copy constructor and copy assignment operator to match those of move constructor and move assignment operator. That is to say, if you mention any of 'the big 5', only the destructor will still be implicitly generated. &gt; If someone would redesign a fresh C++ today, it would probably be without the rule of zero, one, three, five and all. I believe we would still have the rule of zero (if you don't mention any of the big 5, you get all of them) and rule of 5 (if you mention any of the big 5, you should mention all of them). The rule of 3 is there because move semantics became a thing only in C++11.
While there are of course exceptions, the default should be to return by value (imho). I think there is still this missconception taught that returning by value is somehow slower and generates additional copies. &amp;#x200B; Regarding your comment - for quite a lot of cases you could also template your function and deal with the polymorphism that way (well of course there are expceptions... we're talking about C++).
Ok. I guess you aren‚Äôt working in an environment where your code must work with barely functional C++03 compilers. What I was trying to point out is that your assertion is not true in all cases, not even in modern C++. And that‚Äôs why teaching C++ is an art. How do you keep the students writing good code, not shooting themselves in the foot, and yet not overwhelm them with too much information.
Raw pointers can also be okay as references in some cases. One example would be: base *obj = nullptr; if (condition_A) obj = &amp;derived_obj_A; else if (condition_B) obj = &amp;derived_obj_B; obj-&gt;do_stuff(); This is useful if the _only_ place where you make a distinction is here, and the rest of the code is identical for both variants A and B.
2 and 3 are correct for a C style array, but only if it didn't decay to pointer. What's so terrible about that (assuming you are working with C style arrays)?
What's so terrible is, assumption always breaks down silently.
For this case it is way safer to use std::optional if available.
I‚Äôm not sure a queue is comparable to the [observer pattern](https://en.m.wikipedia.org/wiki/Observer_pattern). Perhaps a concurrent queue could be used to implement a thread-safe Event-Listener. Then again afaik we don‚Äôt even have a concurrent queue in the C++ standard library.
What would the added value be? I'd have to use something like `std::optional&lt;std::reference_wrapper&lt;base&gt;&gt;`, which is much more verbose. And the code would look almost identical. Keep in mind that the aforementioned example is code that would be contained *within a function*, so `obj` would not be returned through some public API.
&gt; Raw pointers should really only be used - as iterators Also as optional reference.
Okay, I guess this is something that will practically not happen if you choose a decent hash function. But it does not only depend on the hash function but also on the data - which might come from the user or another external source (unpredictable). Therefore, you can't guarantee that this won't happen, I guess. I think there might be use cases where simply failing is not an option (where you would prefer to have degraded performance/memory usage but still be operational). Do you think there can be other strategies to handle this more gracefully? Just for peace of mind ... (and to not have \`try catch\` everywhere this can occur) Do you know how other implementations handle this case?
I disagree that encapsulating every struct is a good idea. It just leads to people using `pair` or `tuple` as a return type. Those also eventually get relied on, but they are a mangnitude harder to encapsulate, when the need arises. Take `std::equal_range` as an example: it uses a pair of iterators as it's return type. That pair is basically unusable in range for loops and it is harder to fix now. It could have instead used a simple struct with an begin and end member and it would have been a lot easier to reason about. Having a struct there would have also made it easier to specialize `std::begin` and `std::end` for it. Now you have to specialize for a pair of iterators, but you can't know, if that is actually a from an `equal_range` or someone just put two iterators into a pair, which is probably why we don't have that yet. Another example, say you are returning a tolerance of a value: struct Tolerance { double upper, lower; }; is a lot more descriptive than a pair. (Especially if you define upper first, which you probably shouldn't do.) it also makes it easier to extend in the future, if you want to return the precision of the tolerance in addition to the upper and lower boundaries or maybe the original value. If you had used a pair, everyone will have to fix their local variable declarations, probably change from pair to tuple, etc. Of course that only happens, if users of your API consider tuple part of your interface as well as a struct. I just think the mantra "encapsulate everything" pushes people in the wrong direction. If all you are returning is data, don't make it more complicated than it is. And if you really don't want others to use you data container, return an anonymous struct, not a nameable type (but I wouldn't encourage that)! Example: auto f() { struct MyAnonStruct { int a; } s; s.a = 5; return s; }
almost always auto
So far that was not a priority for me because so far it never happened. But I guess I should have a look how others do this. It is easily to reproduce with a dummy hash that always returns the same value instead of an actual hash.
Java programmers
Java 8 use map to replace the same bucke element if collsions is serious.