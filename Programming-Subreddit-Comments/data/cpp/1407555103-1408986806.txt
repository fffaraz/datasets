Support for the new C++11 'for loop' has been in Boost since 2012. An example that should do the same as your file iteration but using boost would look like (leaving out the namespace for brevity): const regex frame_regex( "dat/frame_[abc].*\.jpg" ); for (auto&amp; y : recursive_directory_iterator("/a/path")) { if( !is_regular_file( y-&gt;status() ) ) continue; if (!regex_match(y-&gt;leaf(), frame_regex) continue; std::cout &lt;&lt; " " &lt;&lt; y.leaf() &lt;&lt; "\n"; } (Forgive me if my above example doesn't compile as it was written off the top of my head). It would be a lot nicer if the directory_iterator took a regex along with a set of options to specify which kind of file you are looking for (Ex, symlinks, etc). This would save you the extra 3 lines. But as you can see, the above code was a lot more concise than the StackOverflow example you provided. I certainly agree about the library requirement. Having said that, your library still depends on the Boost headers. I've not seen too many environments where the Boost libraries are not included already on a system where the headers are installed. I do certainly understand where header only would be a strong option if you wanted to store them with your project however. :) While boost doesn't have expected&lt;T&gt;, it does have optional&lt;T&gt;. Your expected&lt;T&gt; is nice in that it carries the exception forward for you. If the error condition itself isn't really important, then optional&lt;T&gt; can still function similarly. While I can't vouch for it's completeness, have you looked at this? https://github.com/ptal/expected Anyhow, I am not arguing that your library shouldn't exist. Quite contrary actually! I think this sort of conversation should be part of the documentation. It's nice to know the authors reasoning when something provides a different interface to the more default (Boost) option.
I thought about this, but the implementation was already pretty involved, constexpr parsing aside. The implementation is conservative in memory allocation in that it doesn't allocate memory unless it needs to buffer arguments to transform them prior to printing. This is because I use boost::string ref to store references to substrings.
Sure, "+" on strings is not commutative. Neither is "*" on matrices or quaternions ...
About 2 - this is to be expected for cchWideChar and cbMultiByte, if you use size/_t there (which makes sense after a call to strlen). This is a friction between the CRT and Win32 API, that happens. Unfortunately, I think, we need to cast to get those to compile. Furthermore, in 64-bit builds, we also need to make sure that string is shorter than 4GB ðŸ˜‰.
This is the first time I look at [Boost.Format's API](http://www.boost.org/doc/libs/1_56_0/libs/format/example/sample_formats.cpp). Goodness, that is arcane. This seems more approachable, although I'm not convinced that `${data}` =&gt; {x}iB is all that intuitive.
Disclaimer: I work for biicode, and I have not tried CPMCPP myself. I will try to be as neutral as possible and point out some (not an exhaustive list) differences: Hosting: - CPMCPP is a cmake toolset (a set of cmake scripts) that contains macros and functions to easily automate tasks, such as retrieving versions from git repositories. It fully works locally, no hosting is provided. - Biicode is more like a traditional package manager, with a client app and servers that hosts code, so the code to depend on must be in biicode servers first. It is VCS independent, it can integrate with them, as the meta-information is stored in plain text files, but does not require them at all to work. Centralized: - Biicode is a centralized repository (as PyPi) which hosts the code, has web access (similar to github) to the code, and search and explore facilities - CPMCPP relies on the search and web access facilities of the hosted code, github or others, or the update of the page http://cmakepm.org/ Building: - CPMCPP builds have to be defined in cmake files by the developer - Biicode auto-generates cmake files based on project structure, which can be changed to add extra configuration One of the key weaknesses of both (and from all C/C++ possible dependency managers) is that they need a convention about building and artifacts. So there is no way that an existing project can be automatically ported or uploaded to any of them, and they require an active community working on them. Dependency Management, conflict resolution: - CPMCPP proposes a namespace change for multiple versions of the same library, so you are able to link simultaneously to them, similar to Node NPM. - Biicode handles dependencies and conflicts more in a Maven sense, only 1 version of a library is linked with in each project. Said that, biicode proposes a file-based approach that actually let biicode to mix files from different versions in the same library if they are not connected at all. Multi-language: - CPMCPP: C/C++ specific. - Biicode: It is aimed as a multi-language dep manager. Now it is mainly C/C++, but experimental support also for node. We have interesting internal developments when you can automatically depend from an existing C/C++ library from python (using cffi). Corporate, open-source: - CPMCPP is an open-source initiative, mainly backed by an individual (James Hughes) - Biicode is a startup, though created by developers with roots in open-source. Right now it is not released (as open-source) yet, but it is something that is definitely in our roadmap. Status, releases, complexity: - Last commits to CPMCPP are from 6 months ago, but as it is a simpler approach, it is not necessarily a bad thing, it might simply work as-is. - Biicode is in beta, and is a much more complex system and thus potentially more likely to find bugs occasionally, but new versions are released every 1-2 weeks based on users feedback and solving those bugs. As you said, the best is to try yourself, I am here for any further discussion. Best
x &gt; threshold is the same as threshold &lt; x, so as they are both valid, it is a bit pointless to debate it?
All the attributes but that one seem fairly sensible and I don't have a suggestion for a better alternative to `data`. Unfortunately the `iB` suffix does not have an easily adaptable name and you do need to strike a balance between length and comprehensibility. It looks like cc::println("Employee name: $.", "Gibble McGobblefart"); // Prints "Employee name: Gibble McGobblefart" to stdout. should be // Prints "Employee name: Gibble McGobblefart." to stdout.
Unrelated to the topic of discussion but related to the presentation... Why do people feel the need to badger presenters at programming conventions? I couldn't even finish watching the one on values from the same con because people in the audience just wouldn't stop no matter what the guy said. I noticed this one was going teh same way and decided I didn't want to try. Just on and on and on over really silly stuff, like using the wrong function call on map--you know what the guy intended to show (or you're an idiot and should STFU anyway). I watch professional presentations in other fields and don't see this sort of thing there. People wait, listen, and ask questions after. Are programmers so ADHD addled that they can't be a polite audience? It gets kind of old to have the whole room start blathering about every slide as someone tries to put on a presentation. There's not a lot of time for the presenter to say what they intend to say, you're breaking the flow of the presentation and greatly decreasing the amount of time he has. So often these presentations end up having to be cut short, or run over and you miss something in another, just because people can't just keep themselves together long enough to just listen to someone for 20 minutes without getting into a coder equivalent of a dick measuring contest with the presenter and everyone else in the room.
There are many, many cases when you really should use a 'using' clause. For example, any time you want to write generic code that defaults to the std:: function overload. You should be making sure to allow ADL to work and you can't do that if you explicitly state which namespace to search for the name in. So for example if you want to call `std::swap` in a generic scope you'd instead do this: using std::swap; swap(a,b); Now depending on whether a and/or b have swap() definitions in their local namespace it will either call that swap, or default over to std's. Judicial, scope limited use of 'using' directives also makes code a whole lot easier to read and write. The alternative is to limit your use of namespaces to organize concepts, which is a bad idea. If you don't do one of those things though you can end up with really long lines of code that are 90% namespace referencing instead of behavior: somenamespace::namespace_inner::utility::cacheing::simple_cache&lt;someotherns::ui::views::whatnotview&gt; var; That's hard to read, but the use of namespaces isn't bad (I struggled to come up with pointless examples, but it's not unusual to have deep namespaces). Some make some good use of using flags so that you can make the behavior part of your code simpler: simple_cache&lt;whatnot_view&gt; cache; You need to limit the scope that you do this in though. Don't just toss everything you're using in a cpp file in a using declaration at the top. Better to limit scopes to functions or tighter unless something else is necessary or more legible.
A guru of C++ eh?
I think the point is simply that in order to store an object in an ordered container, by default one is forced to define operator &lt;, which for some types doesn't make sense and could lead to mistakes when writing mathematical code. The presented solution, which disconnects the concept of 'less' from 'order' is, I think, quite elegant. 
The result it the same for sure, but taking into account the rules of how &lt; and &gt; work (they have an inverse relation) its is not so wrong to say that a &lt; b is equal to b &gt; a I know what you are trying to say. It is easier (more human) to read one form than it is the other. That however does not change that the expression is the same.
&gt; A type-safe printf implementation is **incredibly easy** to implement, just drop the type from the format string and you have a sane 12-line implementation If only that was true... I suggest you give it a try and handle all the specifiers mandated by http://en.cppreference.com/w/cpp/io/c/fprintf
This is really cool. I'd love to borrow some of these ideas for [cavalieri](https://github.com/juruen/cavalieri), which is a event processor for alerting that uses the concept of streams.
I didn't really get the impression that anyone was interrupting this presentation *maliciously* but I have never seen a presentation with *quite so many* questions/comments/interruptions during. Mostly they just seemed to be genuinely ignorant. I did end up skipping a lot, although I'm not sure I was really the target audience anyway. I was looking forward to Chandler's talk, though. :(
hahaha windows.
Yeah, I don't think it's malicious either but that's the second presentation I tried to watch which was just ruined by it. I hope CPPCon isn't like that. There's a lot I think I'll know already, but there's also a lot I really want to hear.
You don't have to use less&lt;&gt; as the comparator. I often overrule that default. I do see that some people are encouraged to do silly things because less&lt;&gt; is the default. They'll override operator &lt; to mean something ridiculous just to fit into a map or something. I've seen operator '==' overloaded incorrectly like that too. I don't think &lt; is an incorrect default though. The assumption there is that in many cases a real less operator makes sense for the ordered or keyed type. You're allowed to easily overrule that in cases where it doesn't. What I would like to do though is use lambda for that comparator more often. I don't like having to build the struct. I'd like something like: std::map&lt;std::string, sometype, [](std::string const&amp; str0, std::string const&amp; str1) { return icasecompare(str0.cstr(), str1.cstr(); }&gt; That should be doable since that lambda casts to a function pointer, but if my memory serves correctly it doesn't actually work.
If you feel that your expected&lt;T&gt; is superior to the current proposal... you might consider publishing a version of your expected&lt;T&gt; as a proposal itself. I think the largest problem right now for usefull STD API additions is just a lack of proposals. This would certainly be worth trying to get into. :)
I should have specified better, a type safe printf without formatting is about 12 lines. If you want formatting it's a little bit more. I've ditched the `printf` formatting and did the C# way and ended up with [this](https://github.com/Rapptz/Gears/blob/master/gears/io/fprint.hpp) which isn't very complicated.
You have been heard (i.e. it is out).
That's really nice. Thanks for sharing. On my side, I updated `PPK_ASSERT` so that a format string / args mismatch now bails out with a compilation error on G++ 4.6+ and Clang++: https://github.com/gpakosz/Assert/commit/0fe62506821deba209828ae2bb3de37c68490d71 That's not C++ type safety(tm) but that's already much useful. Unfortunately, MSVC++ doesn't have an equivalent for `__attribute__((format (printf, 7, 8)))`. There's the `__format_string` SAL annotation but you need to compile with `/analyze`...
 auto r = int{}; Really? I love auto but that is too far.
Two reasons: 1. My distro statically links to libstdc++, while VC defaults to dynamically linking to msvcp140.dll. (This is controlled by the VC options /MD for dynamic linking, versus /MT for static linking. GCC's -MD is [totally different](https://gcc.gnu.org/onlinedocs/gcc-4.9.1/cpp/Invocation.html#Invocation). Note that MinGW always dynamically links to Windows' msvcrt.dll, whereas VC's /MT will statically link to libcmt.lib. Yeah, it's complicated.) 2. binutils doesn't support --gc-sections on Windows, whereas VC has supported /OPT:REF since 2005 (at least). This drops unused code, making binaries significantly smaller.
This is what I thought but if I use a release of MinGW from MinGW-W64 I get binaries in similar size to MSVC compiler. I was wondering what STL changes, if anything, which causes such large binaries. Also I want to note it isn't just this MinGW release I get large binaries with. I get the same size binaries with the TDM releases too. 
&gt; This is what I thought but if I use a release of MinGW from MinGW-W64 I get binaries in similar size to MSVC compiler. They are almost certainly dynamically linking to libstdc++, which as a result will prevent your executables from running standalone on machines without libstdc++'s dll on the path (try it). I hate DLLs almost as much as I hate installers, which is why I've eradicated them from my distro (with the exception of 7-Zip which is at least self-contained within the distro).
&gt; if I use a release of MinGW from MinGW-W64 I get binaries in similar size to MSVC compiler That's because it's linking against a shared libstdc++ and shared libgcc. Compare and contrast: $ g++ helloworld.cpp -Os -s &amp;&amp; size a.exe text data bss dec hex filename 13288 1824 128 15240 3b88 a.exe $ g++ helloworld.cpp -Os -s -static-libgcc -static-libstdc++ &amp;&amp; size a.exe text data bss dec hex filename 549572 28080 2944 580596 8dbf4 a.exe
Cheers Stephan. Out of curiosity is it possible to compile with your distro dynamically linking to libstdc++? I just did a test with MinGW64 (x86_64-4.9.1-release-posix-seh-rt_v3-rev0.7z to be specific) and the output binary was 17KB. Would be interesting to try if possible? Edit: To answer my own question it does not appear to be possible as STL's distro is built with --disable-shared
gcc might generated additional informations for debugging and put them into the executable - MSVC uses *.pdb files for that purpose, also runtime library might be inside the executable, MSVC uses msvcp110.dll and friends, they changed this behavior a bit in next version called so far Visual Studio "14" CTP. [The Great C Runtime (CRT) Refactoring](http://blogs.msdn.com/b/vcblog/archive/2014/06/10/the-great-crt-refactoring.aspx)
Debugging information is controlled by -g which [isn't enabled by default](https://gcc.gnu.org/onlinedocs/gcc-4.9.1/gcc/Debugging-Options.html#Debugging-Options).
Heh yeah I just noticed that myself. I am glad to have an answer though, that was all I wanted so I am happy now :) Thanks again Stephan! 
"MD" argument for gcc means different thing than for msvc. For msvc "MD" argument makes executable to link with shared C and C++ runtime libraries. Meaning your 13.5KB executable depends on msvcr120.dll and msvcp120.dll files (both can be installed with Visual C++ 2013 runtime redistributable). You can make it link to static runtime libraries and not depend on dll files, but executable will be bigger - use "MT" argument instead of "MD" for that. For gcc "MD" generates makefile dependency information. You should be able to link to shared runtime library by using "-shared-libstdc++" argument, but this gcc build doesn't support it (by running "g++ -v" you can see it has "--disable-shared" as configuration option). I suggest you to try build from mingw-builds project: [x86_64-4.9.1-release-win32-seh-rt_v3-rev0.7z](http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.9.1/threads-win32/seh/) By default it links to libstdc++ as shared library (executable will depends on libstdc++-6.dll file, but will have 17KB size). You can make it to link to static libstdc++ library with "-static-libstdc++" argument. 
Thanks STL! I love your distro, it's very nice for easing the use of C++ on Windows. 
You get similar size bloats linking C programs against static libc. Which is why nice little projects like dietlibc exist.
Thank you, sir! This is a great tool to have.
If that were the case it would make gcc almost useless as a C++ compiler, as you'd only be able to compile GPL-compatible code. And this would apply not just to C++ but to all code compiled with gcc, even C, as there is always a dependency on libgcc. All of the gcc runtime libraries (libstdc++, libgcc, libgfortran, libgomp, libobjc, etc.) are licensed under the [gcc runtime library exception](https://www.gnu.org/licenses/gcc-exception-3.1.html) which means that merely using gcc to compile your code does not impose any additional license requirements on it.
Is it? One advantage this syntax has is that r *must* be initialised because 'auto r;' is an error, whereas 'int r;' is not. Food for thought. 
Glad you like it - I provide my build scripts and environment so people can customize it to their liking.
The GNU linker doesn't support dead code stripping on Windows.
Thanks a lot man. I've been using your builds for a very long time now and they're always great.
It'd certainly be less useful, but it'd still be far from useless. Obviously it would not hurt GCC's original intended purpose as the compiler for the GNU OS, and it'd still be an acceptable compiler for many actual Linux and BSD systems (BSDs would probably be opposed to using it on principal, but they would not see any functional licensing problems). If the parent's implication that static vs. dynamic linking makes any difference with the GPL was correct (it isn't) and distributing non-GPL programs compiled with GCC was fine as long as you dynamically linked the runtime, embedded targets would be the only thing that it'd render GCC outright useless for.
Do you synchronize with github? E.g. I have an open source library on github. So every time I make a new release version, I must manually upload it to biicode ?
Thanks for the update STL, though I have a couple of questions: 1. When using the -flto option I get the following: cc1plus.exe: error: LTO support has not been enabled in this configuration 2. Also when can we expect the LFS support to be enabled? c:\Programming\exprtk&gt;g++ -pedantic-errors -Wall -Wextra -Werror -Wno-long-long -O2 -o exprtk_benchmark exprtk_benchmark.cpp -L/usr/lib -lstdc++ -lm c:/mingw/bin/../lib/gcc/x86_64-w64-mingw32/4.9.1/../../../../x86_64-w64-mingw32/bin/as.exe: C:\Users\user\AppData\Local\ Temp\ccNk8TZb.o: too many sections (47715) C:\Users\user\AppData\Local\Temp\ccpqib3b.s: Assembler messages: C:\Users\user\AppData\Local\Temp\ccpqib3b.s: Fatal error: can't write C:\Users\user\AppData\Local\Temp\ccNk8TZb.o: File too big c:/internetdownloads/mingw/mingw/bin/../lib/gcc/x86_64-w64-mingw32/4.9.1/../../../../x86_64-w64-mingw32/bin/as.exe: C:\Users\user\AppData\Local\ Temp\ccNk8TZb.o: too many sections (47715) C:\Users\user\AppData\Local\Temp\ccpqib3b.s: Fatal error: can't close C:\Users\user\AppData\Local\Temp\ccNk8TZb.o: File too big 
&gt; Obviously it would not hurt GCC's original intended purpose as the compiler for the GNU OS Sure it would. There are plenty of non-GPL-compatible licenses out there. OpenSSL is one example. Without the runtime exception, you would not be able to legally distribute the result of compiling OpenSSL with gcc. 
In the case of OpenSSL that might not have been so bad.
Just wanted to pop in to let you know that MNMLSTC Core requires C++11 not C++14. It simply provides C++14-esque library features.
Apologies for the misconception, I stand corrected. I just edited my previous comment to remove that statement.
According to my knowledge, libstdc++ still doesn't have a native Windows implementation of threads, and I have no interest in building pthreads shims. Boost.Thread is a native implementation and conforms to the Standard interface, so I'm using it happily.
Actually, Boost.Thread is different from `std::thread` (it's not a drop in replacement, it'd be a breaking change on boost's side). [Here's an answer from Anthony Williams](http://stackoverflow.com/a/7242294/1381108) stating this. Granted, I'm not sure if this has changed since 1.55. It's close enough though.
I thought you were working for Microsoft!? Why do you help the competitor?
As a Windows programmer, I despise libraries which work only with GCC or only on *ix. Yours does both so I am inclined to ask: if your library cannot solve already solved problems on heavily used platforms, why it exists?
Sounds better yes.
The Format module looks nice... but I cannot figure out how to use positional arguments: println("Hello $1! Hey $1, how are you doing this morning", "Matt"); Apart from reuse, it's also a cornerstone of translating, so should I take it that you did not attack the translation issue at all (it's a tough cookie) ?
Since non-copyleft-licences are well, non-copyleft, there is no problem with just relicensing.
I actually have support for parsing and storing the argument indices, precisely in the way you describe. But the code for this is commented out =( The fly in the ointment is the following: if you give me a variadic template parameter pack and an index during _runtime_, there's no way for me to get the type of the corresponding argument. In theory, this is possible if the format string is parsed during compile-time. This way, I could get the index during compile-time. I don't think this is something that is currently practical to attempt even using existing compile-time string parsing libs, but I'd love to be proven wrong.
I never liked C-style variable declarations, and I don't think I ever will. A unified syntax for variable declarations is honestly (IMO) one of the things that C++11 did to really clean up a lot of "syntactic noise" in C++. I commented about this in a thread that was posted about Herb Sutter's advice to AAA. Naturally, I'm a proponent.
The proper GNU OS would not have any software with GPL-incompatible licenses. OpenSSL's license is pretty much the entire reason why GnuTLS exists.
GCC and MSVC have different goals with some overlap. In a way they are competitors but (I feel) in a healthy way. Improvements in one pushes for improvements in the other. As for STL's reasons for offering a MinGW distro, I suspect, but do not know for sure, that it is to make MinGW and some common associated libraries easily accessible to all. I don't know the history of STL's distro but I would suspect it started for personal use and he saw others would find it very helpful too so provided it for all. Maybe Stephan can answer this himself some time. 
Does compile-time checking really matters though ? As long as you accept `std::string` format strings (and unknown format strings are necessary for translation anyway), then compile-time checking is already out of the equation. Thus, you can instead switch to runtime checking. I believe what is blocking you is a way to "uniformize" the inputs without losing safey (`void*` is not a solution); this can be achieved through a *shim* ([see a question I asked on SO some 2 years ago](http://stackoverflow.com/questions/10161431/more-succinct-way-to-use-shims-in-variadic-templates)). The key part I had was: // // Shim interface // struct Interface { virtual void print(std::ostream&amp; out) const = 0; }; // struct Interface std::ostream&amp; operator&lt;&lt;(std::ostream&amp; out, Interface const&amp; i) { i.print(out); return out; } template &lt;typename T&gt; struct IT: public Interface { IT(T const&amp; t): _t(t) {} virtual void print(std::ostream&amp; out) const { out &lt;&lt; _t; } T const&amp; _t; }; template &lt;typename T&gt; IT&lt;T&gt; shim(T const&amp; t) { return IT&lt;T&gt;(t); } // // printf (or it could be!) // void printf_impl(char const*, Interface const** array, size_t size) { for (size_t i = 0; i != size; ++i) { std::cout &lt;&lt; *(array[i]); } std::cout &lt;&lt; "\n"; } template &lt;typename... T&gt; void printf_bridge(char const* format, T const&amp;... t) { Interface const* array[sizeof...(t)] = { (&amp;t)... }; printf_impl(format, array, sizeof...(t)); } template &lt;typename... T&gt; void printf(char const* format, T const&amp;... t) { printf_bridge(format, ((Interface const&amp;)shim(t))...); } With this, `printf_impl` gets handed down an array, making it eminently more suitable to use indexes. Furthermore, `Interface` may implement everything that is needed for safe printing. Of course, I had not wired format modifiers here; so depending on how it works in your case, some work might be needed.
&gt; Boost supports thread cancellation, C++11 threads do not This is an extension, not a conformance issue. &gt; C++11 supports std::async, but Boost does not [No longer true for 1.56.0.](http://www.boost.org/doc/libs/1_56_0/doc/html/thread/synchronization.html#thread.synchronization.futures.async) &gt; Boost has a boost::shared_mutex for multiple-reader/single-writer locking, which is not present in C++11 Again an extension, and this was voted into C++14 (eventually renamed shared_timed_mutex). &gt; C++11 timeouts are different to Boost timeouts (though this should soon change now Boost.Chrono has been accepted). [Again untrue for Boost 1.56.0](http://www.boost.org/doc/libs/1_56_0/doc/html/thread/build.html#thread.build.configuration.version) if you crank up the conformance to BOOST_THREAD_VERSION=4 as I do. &gt; Some of the names are different (e.g. boost::unique_future vs std::future) [Ditto.](http://www.boost.org/doc/libs/1_56_0/doc/html/thread/build.html#thread.build.configuration.future) &gt; The argument-passing semantics of std::thread are different to boost::thread This one still appears to be an issue. &gt; With a C++11 std::thread object, this will result in a call to std::terminate() and abort the application. [Again fixed by requesting v4](http://www.boost.org/doc/libs/1_56_0/doc/html/thread/build.html#thread.build.configuration.terminate).
There is a problem -- the OpenSSL license contains terms that are incompatible with the GPL. There's no way to relicense around that; you can't just drop terms from the license. It's a fundamental incompatibility. 
There are a [ton of GPL-incompatible licenses](https://www.gnu.org/licenses/license-list.html#GPLIncompatibleLicenses) out there, or at least there used to be before some of them were revised. Creating a free operating system without using any software under those licenses would be extremely difficult.
Slightly interesting: in the other discussions tabs, this page was submitted * Seven years ago as "STL's Mingw Distro (GCC 4.1.2)" * Two years ago as "MinGW Distro: GCC 4.7.0 and Boost 1.49.0 on Windows"
I've been avoiding C++Now 2014 videos because of exactly this. I believe you're talking about Michael Wong's presentation "C++14: Through the Looking Glass"?
Other one I was talking about: https://www.youtube.com/watch?v=YJIaGRDIyEE
No worries! You're not the first person to make that mistake. I should probably make it a bit clearer in the Readme/short description.
Please excuse my ignorance, but what exactly is this? `CCBase is a header-only C++11 library intended to make day-to-day tasks more pleasant. ` Seems like a rather vague description
I really like the speedup I see in build times, I can make a bulk of the library in 10 minutes!
That's because the URL hasn't changed since distro 1.0 on 4/25/2005.
Hard work is not among my values :-)
At this moment, the procedure we follow is to have either a single block within a project in a git repo or the whole project in such repo. After a "git push" of something that is to be shared, we make a "bii publish". Though it is not really a complicated process, this automation is a demanded issue, so we have started to analyse for developing a hook to github to automatically publish to biicode (as DEV) directly and automatically from github after a push. Note that in the past, every publication to biicode was "frozen" and we typically dont want to freeze as a version every push. So we developed the "DEV" tag for publications, which is a version for testing that can be overwritten at every publish, and released this functionality in biicode1.0, just 2 weeks ago. Now we can address this automatic synchronization with github. Nevertheless, it is not a priority issue right now (as it is a matter of a couple of extra commands), so it might be implemented in a few months, not days or weeks as high priority bugs and requests.
Well, the library is a collection of utilities designed to make certain tasks in C++ easier to do (formatting strings, loading dynamic libraries, detecting platform attributes via macros, etc.). I'm not sure how else I would describe this.
&gt; You can get away with ::std most of the time, since it's so common. I strongly disagree. I think there's not a single case where even `using namespace std` is warranted in a header file. I would strongly recommend against it.
I have not heard of this technique before; thanks for showing it to me. I think it should be possible to implement positional arguments now with a little restructuring, and I'm looking into it now.
This is a very nice distribution that I use regularly, but it still has one irritating flaw: I always have to rebuild the PCRE library because the one that comes with the nuwen installer was built without Unicode support. It's 2014, building anything without Unicode shouldn't even be an option these days, let alone the default.
Awesome, as soon as i have some free time I promise to play with biicode. Now it seems promising :)
If you're using PCRE's autoconf script, you need to call ./configure with --enable-utf and --enable-unicode-properties. Those are enough to give you UTF-8 support, which is the bare minimum needed to use PCRE with Unicode. You can also add --enable-pcre16 and --enable-pcre32, which build separate libraries for UTF-16 and UTF-32; those are optional. A lot of people are moving to the "UTF-8 everywhere" school of thought these days, so the extra libraries are not absolutely necessary, although on Windows (where the native API uses UTF-16 strings) having the 16-bit library would save a few conversions. Alternatively, to get just UTF-8 support, you can edit config.h to enable #define SUPPORT_UCP and #define SUPPORT_UTF (look near the bottom of the file). If you're not using autoconf, building the 16/32-bit libraries would require separate make targets. 
Thanks very much, our best current asset is our active users, that are really helping us to shape a better biicode. You canÂ´t imagine the huge improvement we did with version 1.0 compared to last 0.17, and that was done thanks to our users feedback. So looking forward to receiving yours!
after reading the code, I think the title should be 'undefined behaviour leads to surprising results'...
I already have a feature request :) I'm coding a c++ library. And I always like to build API reference to HTML with Doxygen. Usually I host it on my own site. But it would be awesome if biicode would render the built documentation so that anyone could easily access it without cross referencing sites :)
I don't think he talks about it in the 4th edition. You should check out Effective modern C++ by Scott Meyers. It's still an early draft. Expected release in October.
Thanks for your input. I saw Meyers new book and I have a great respect him (I have other books he has written) but his new book seems more focused on "does and don'ts" rather than syntax for the new standard (based on his own words). I want to concentrate on the basics first. According to amazon and reviews on amazon, Stroustrups book is heavily C++ 11 focused... http://www.amazon.co.uk/C-Programming-Language-Bjarne-Stroustrup/dp/0321958322/ref=tmm_hrd_title_0?_encoding=UTF8&amp;sr=8-9&amp;qid=1407752251 What makes you believe otherwise? Have you checked out this title? 
Yes, I think the book is worth reading. Not only for the C++11/C++14 things, but because it covers the entire language very thoroughly. It's most definitely a dry read, and doing it cover to cover takes dedication. It may not be the best way to read the book either, though you will surely learn a lot from doing it. As a reference and to freshen up on particular topics it invaluable imo.
I did not read this new edition, but the previous ones were very good: I hope it will be as good as the previous ones. Scott Meyers' books are also very good, but the C++-11 version is only an early draft.
Cool, thanks for your advise. If this covers then entirety of the language, hopefully I'll be able to skip most of the C++98 stuff.
It's hard to get free &amp; os libs to windows because no dev in their right mind would want to spend their free time developing on such a closed and shitty OS.
Thanks. As mentioned above, I have quite a few of Meyers books. I imagine I'll get his new one when I'm more familiar with the basics. I checked out his preface on O'Reilly and he suggests that his book is more about correct usage with the new standard. A bit like how his effective stl and other books are more supplemental than a canonical basic learning guide.
ok then, I was wrong. thanks for the heads up :)
I would recommend C++ Primer 5th Edition http://www.amazon.com/Primer-5th-Edition-Stanley-Lippman/dp/0321714113 to get up to speed with C++11 then probably Stroustrup afterwards.
Learning C++11 is well worth it. Some of the features are less interesting (Oh look, another three types of smart pointer). Some do nothing to the runtime but make coding easier (override keyword). Some can be a pain to use but let you write some really smart things (constexpr). And some are features that you'll wonder why they were ever missing (user defined literal operator overload). However, I have an old copy of Stroustrup and uh... I don't like it very much. I actually learned to use C++11 by reading the feature list elsewhere (wikipedia has a good rundown), and trying things out. There's also a lot of talks from various conferences that go into the features both deep and shallow that are worth watching :)
C++ Primer by Stanley Lippman is a good book. You can read it before Stroustrup.
Done; let me know what you think. The changes are merged into the master branch, and I tested on a couple of machines to make sure everything's working as expected. I'll write the documentation for this soon. **Edit:** the documentation has been updated.
It looks like a quality piece of software, congratulations. I am looking forward to using it. 
Where's the UB?
C++11 support in VS 2013 is good. Still not complete, but many of the major features are supported. It's definitely worth learning C++11 at this point. I found Stroustrup's [C++11 FAQ](http://www.stroustrup.com/C++11FAQ.html) a very good introduction.
Thanks, I do use configure, so I'll try that.
See my VCBlog post [C++11/14 Feature Tables For Visual Studio 14 CTP1](http://blogs.msdn.com/b/vcblog/archive/2014/06/11/c-11-14-feature-tables-for-visual-studio-14-ctp1.aspx) for the state of support in VS 2013 and the first alpha of VS14.
&gt; Some of the features are less interesting (Oh look, another three types of smart pointer). Given that C++03 had no smart pointers (auto_ptr doesn't count), shared_ptr and unique_ptr are kind of a big deal.
Seconded for a much shorter read than TC++PL. It is an extended version of chapter 2-5 of TC++PL. See [contents of Tour++](http://www.informit.com/store/tour-of-c-plus-plus-9780321958310), [contents of TC++PL](http://www.informit.com/store/c-plus-plus-programming-language-9780133522907). This being said, "The C++ Programming Language" is definitely a great reference.
Very good book methinks.
That's because it is a cool uri :)
May I comment that exists this small gem: https://code.google.com/p/pocketcpp/ It's a compilation of STL's distro (GCC 4.8.1 currently) + Notepad++ + some tweaking to have a small, ready to use and portable IDE. I hope the author will update it with STL's last stuff.
Hmmm.. ok. I've found that shared_ptr is a bit iffy with containers as well, requiring a complete type for its parameter to be able to put into a vector, although unique_ptr doesn't have this limitation. I assume there are good technical reasons for it - there have been for everything in the 11 and 14 specs, but I've no idea what they are in this case :)
Yes. This is a great book. C++ is an ugly, terribly complex language, but Bjarne makes it almost look elegant. His explanations are very clear and his code exhibits the elegant and to the point simplicity of a master. The new standard is a significant improvement. The language is much nicer to use now. I would say its definitely worth your time and money if you program in C++ for a living. However, you might get the gist of the new standard with the much slimmer "A Tour of C++", also by Bjarne, which is a sort of subset of TC++PL. 
I've just finished reading A Tour of C++ about 2 days ago and now I'm waiting for amazon delivery of TC++PL. While the Tour is a good book, it doesn't go in nearly enough detail in order to leran what's going on. It's definitely a good book to get intrigued, but imho it's a bit too short.
Thanks :) 
Thanks, I've just purchased this as well. I'm gathering from context on here that this will give me a general feel for the new standard and his other book will be give me as much depth as I'll ever need.
Thanks for the info, I've ordered both now based on your recommendations and others on this thread. C++ is ugly, you think so? Personally I also think, on the whole, it can be quite elegant when well written though I guess you are given enough rope to hang yourself and create a monster. That said, I've always thought that template syntax is ugly but then again you can do things that no other language (that I know of at least) can do (e.g. template meta programming). Terribly complex I'd probably agree with though :) 
I'm guessing these are similar to the Boost smart pointers.
Thanks, great idea, that could be definitely very useful. I take note, so we can discuss it in next sprint. We also plan to share our development roadmap to get feedback about it, so hopefully you will see it there :) 
I do think C++ is pretty ugly. It is much better than it was but heavy templatized code remains very difficult to read, error messages are often utterly baffling, lack of a module system leads to crazy slow build times, etc. still, I don't know anything better for systems programming. 
It really isn't ugly. Further most people don't use every possible feature. It is possible to write ugly code in Python, C++ just makes it easier. 
I was really hoping to see Unicode string literals in there as UTF-8 handling is still a recurrent pain point for me when developing for Windows. Especially since I recently came up against https://support.microsoft.com/kb/2284668. However I do understand why certain things from C++14 would be considered a higher priority right now. That link is relevant because most of the commercial C++ industry seems to be so conservative that whenever we get a new feature in VS year X we are finally able to upgrade and use it in year X+5~6. I hope to be able to professionally write C++11 before I retire.
I'm working through it now, at a rate of 0.5 to 1 chapter a day. It's super dry at times, but by taking the time to decompose the code samples and really *think* about the accompanying prose, it's improving my understanding of the language features, design, and philosophy tremendously. And this is all after taking three semesters worth of classes on just the language. 
What are some highlights of this book? I hear a lot about its writing, but not a lot of excerpts or examples.
Haven't used it. We've had decent success with UnitTest++ at work, though.
It works pretty well for me, but it's a little slow to compile. It helps a little if you use the option of having the catch "main" compiled into only one object, and then link it to all your test executables.
We used gtest at work. gtest works pretty well. However, I don't like gmock. It was a lot of trouble to set up a mock via gmock, usually it was easier just to create my own mock objects. 
I would definitely recommend it, it's a good reference book. It's actually meant to be both a read-through book on the language *and* a reference manual, so it's a dry read but it's better than a plain manual. As for your worries about the MS compilers, they do lag in compliance, but you *can* plug in both GCC and Clang to Visual Studio, and they are both very up to date (even implementing some experimental standard components, like modules in Clang).
Why at all? Stroustrup's full "language spec" isn't the lightest read. although he might have the most details of any C++ book, that book only works well as a reference, which you can get on the Web for free. If Stroustrup, I'd recommend his FAQ, that is an actually readable selection from his "spec", beginning to end. 
As a single-header, fairly light-weight solution, it's pretty nice. I tend to use the Qt test framework, since I'm usually pulling Qt, anyway, but I have a coworker who has wholly switched to Catch and loves it.
Watching all of the Going Native 2013 talks helped me a lot. https://www.youtube.com/watch?v=D5MEsboj9Fc&amp;list=PLQR34fJnvoYSsyoa-ZqBSXqDWV6QSDtjb
[C++03 wasn't a very major revision on C++98](http://en.wikipedia.org/wiki/C%2B%2B03), so it's likely that you were taught both. While [`auto`](http://en.cppreference.com/w/cpp/language/auto) and [`range-based for loops`](http://en.cppreference.com/w/cpp/language/range-for) are very interesting, and allow you to write much cleaner code, you should be keenly interested in move semantics, namely: - [Move constructors](http://en.cppreference.com/w/cpp/language/move_constructor) - [Move assignment operators](http://en.cppreference.com/w/cpp/language/move_operator) - [Rvalue references](http://en.cppreference.com/w/cpp/language/reference) - The [`std::move` template](http://en.cppreference.com/w/cpp/utility/move) Which allow things like [`std::unique_ptr`](http://en.cppreference.com/w/cpp/memory/unique_ptr) (which, alongside [`std::make_unique`](http://en.cppreference.com/w/cpp/memory/unique_ptr/make_unique) from C++14, completely obsoletes the `new` and `delete` keywords -- you shouldn't see those keywords (except in the case of [placement `new`](http://en.cppreference.com/w/cpp/language/new)) in modern C++ code), and allow you to efficiently pass and return complex, expensive to copy types like `std::vector` by value. You should also be interested in: - [`constexpr`](http://en.cppreference.com/w/cpp/language/constexpr) (especially if you do template metaprogramming) - [Lambda expressions](http://en.cppreference.com/w/cpp/language/lambda) - The unordered containers, which largely supersede `std::map` and friends: [`std::unordered_set`](http://en.cppreference.com/w/cpp/container/unordered_set), [`std::unordered_map`](http://en.cppreference.com/w/cpp/container/unordered_map), [`std::unordered_multiset`](http://en.cppreference.com/w/cpp/container/unordered_multiset), and [`std::unordered_multimap`](http://en.cppreference.com/w/cpp/container/unordered_multimap) - The [`noexcept` specifier](http://en.cppreference.com/w/cpp/language/noexcept_spec) and [`noexcept` operator](http://en.cppreference.com/w/cpp/language/noexcept) - The [`override` specifier](http://en.cppreference.com/w/cpp/language/override) - The [`&lt;thread&gt;` header](http://en.cppreference.com/w/cpp/header/thread), [`&lt;mutex&gt;` header](http://en.cppreference.com/w/cpp/header/mutex), and [`&lt;condition_variable&gt;` header](http://en.cppreference.com/w/cpp/thread/condition_variable), especially the [`std::unique_lock` template](http://en.cppreference.com/w/cpp/thread/unique_lock), which makes it nigh impossible to leak locks - The [`emplace`](http://en.cppreference.com/w/cpp/container/vector/emplace) method which is now on containers, alongside the [`emplace_back`](http://en.cppreference.com/w/cpp/container/vector/emplace_back) and [`emplace_front`](http://en.cppreference.com/w/cpp/container/deque/emplace_front) methods, which are on certain containers - Perfect forwarding, including the [`std::forward` template](http://en.cppreference.com/w/cpp/utility/forward), [reference collapsing](http://en.cppreference.com/w/cpp/language/reference), and [variadic templates](http://en.cppreference.com/w/cpp/language/parameter_pack)
C++11 is really massive. - `std::array` - `std::tuple` - `std::regex` - `std::forward_list` - `std::atomic&lt;T&gt;`. - `&lt;system_error&gt;` - `&lt;type_index&gt;` - Standardised `&lt;type_traits&gt;`. - [New algorithms](http://en.cppreference.com/w/cpp/algorithm) - The `nullptr` keyword - [New ways to exit](http://en.cppreference.com/w/cpp/utility/program) - Hashing - `std::initializer_list&lt;T&gt;` - Uniform initialisation. - `std::chrono` - `std::ratio` And lots and lots of more, but yeah. Just a glimpse at how massive C++11 is. Edit: I guess this got downvoted. I'm sorry for listing things I suppose.
I wasn't trying to give an exhaustive list, I was merely focusing on the things I thought were most noteworthy.
I'm aware. I just wanted to showcase just how massive C++11 is.
I've got it, can't recommend more. &gt;Some have told me Stroustrup is a pretty dry read. Of course it is dry. It's basically a reference manual to one of the most complex and involved programming languages ever created. C++11 and beyond changes a lot (in the best way possible) and you should absolutely get on board with it. If I had to go back to C++03 I would honestly quit my job. The other comments list some of the C++11-only books so I won't go into them here. There is one other book I have about that is more directed towards the std lib, that I would also highly recommend: http://www.cppstdlib.com/
A good place to start is the language creator's [C++11 FAQ](http://stroustrup.com/C++11FAQ.html).
This book is **not** the standard, although it certainly is canonical. The Standard is a document you can get and read. It is useful, but online sources are cheaper and generally more acessible. IIRC, the official ISO document is about $235, so you may wish to stick with this one instead! Understanding all of Stroustrup is a good goal. For learning C++, other choices may be better. If you are new to programming, or inexperienced, his Programming: Principles and Practice Using C++ might be better. It's a bit overwritten and slow, though. Accerlerated C++ is good if you already know programming. 
I disagree that the unordered containers "largely supersede" the ordered containers. The ordered containers are significantly easier to use (writing high-quality hash functions is hard), in addition to being immune to hash denial of service attacks. I recommend using ordered containers by default, switching to unordered only when you need their special performance characteristics.
My take on it is somewhat the opposite: The vast majority of the instances in which I've seen people use the ordered containers, they actually just wanted the associative properties thereof. However, the ordered containers -- while giving the associative semantics -- have the performance overhead of guaranteeing the ordered property. Accordingly, in the vast majority of cases in which I've seen people used ordered containers, ordering didn't matter, which makes that choice of container ridiculous at face value. Sure, writing high quality hash functions is hard, but again, in a large majority of these situations, the key type is a built-in/standard library type. So is the argument here that the standard library implementers implement low quality hash functions? If that's the case, using `std::map` over `std::unordered_map` is something I can get behind, but I usually assume that standard library implementers know what they're doing, and trust the standard library. I believe in selecting data types/structures not because they're "*good enough*", but because their characteristics actually fit the problem in question. If you need ordered **and** associative, `std::map` is your man, absolutely, I won't even try and argue that. But if you **only** want the associative properties, while `std::map` will "*do the job*", and is probably "*good enough*", it's not the optimal tool for the job, `std::unordered_map` is.
Even if your key is a pair&lt;A, B&gt;, you need to write a hash for that. Like I said, I prefer map for ease of use, and it's still pretty fast (log N is almost but not quite constant).
Perhaps I'd be more accepting of an argument for `std::map` in cases where the user has to supply a specialization of `std::hash`, but most of the instances wherein I see `std::map` used -- and this is, therefore, what I'm speaking to in saying `std::unordered_map` largely supersedes `std::map` -- the key is `int` or `std::string`, which have built-in, standard library-supplied `std::hash` specializations. Therefore, avoiding `std::unordered_map` in those situations, given the more favourable performance characteristics of `std::unordered_map` vis-Ã -vis `std::map`, seems like doubting the standard library, which seems like a slippery slope. If the standard library is bad -- regardless of the issue -- you should be reporting bugs and updating/upgrading, not working around the problems with less than optimal solutions. I realize this doesn't **always** reflect the real world, but it's the ideal, and something I'd like to see applied more often.
I'm not saying anything about the quality of implementations, although you seem to think I am. My rationale is based on usability outside of the types that come with standard hashes (a very limited set), and worst-case performance characteristics. When other people hear "expected O(1)" I hear "worst O(N)".
I removed that part because it seemed accusatory when it wasn't my intention (I mentioned this when he asked me soon after) however I definitely didn't insult the person I replied to like you tried to insult me. You could have mentioned this to me without the last sentence telling me to grow up or your overall accusatory tone.
&gt;My rationale is based on usability outside of the types that come with standard hashes (a very limited set) I can definitely get behind that. As I said, however, the vast majority of cases I observe, the key is `std::string` and `int`, which come with `std::hash` implementations. &gt;and worst-case performance characteristics. When other people hear "expected O(1)" I hear "worst O(N)". I suppose it depends on what you're doing. Most people aren't in a situation where the performance of **every** operation matters, they're in a situation where the aggregated performance matters. With a good hash function, and a good rehash policy, those O(N)s **shouldn't** happen that often, and that's the criteria under which I recommend `std::unordered_map`. Clearly there are going to be situations where that's just incorrect. And if that's your situation `std::map` should be used. But I think `std::unordered_map` should be the go to container, with `std::map` as the fallback, in the same way that using something from the standard library is the go to, with rolling your own being the fallback only once you've verified that what you want isn't in the standard library, or there's something that prevents you from using the standard library.
Yea, my bad, but we are on the same wavelength now :)
the 'fermat' function only has a single constant return statement, but it also contains an infinite loop... that combination equals UB. Optimizers may look at the code and reasonably assert that the function only has one possible outcome and optimize the function's content away. That's what the issue is about, anyway :P
Coming from Google Test, I think Catch is a lot cleaner. I have an issue with it, which I think is [filed here](https://github.com/philsquared/Catch/pull/210), but I haven't looked too deep. You can see my [workaround here](https://bitbucket.org/tido/rainbow/src/abfacefc6b463a751d8153415f3602e0a25eb409/src/Tests/Common/Chrono.test.cc). 
I like it quite alot. It seems very straight forward to me. The compile time isn't really an issue with me because I (mainly) use VS2013, which has generally a high compile time on my machine.
When wouldn't you have that option?
I use Catch and I love it. It's had some issues in the past, but they seem to have cleared up lately.
Do you think that the `hash_append` functionality proposed in [N3980](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3980.html) would make it any easier to have a good hash function for user-defined types? Was this discussed at the latest committee meetings?
Why would that be an issue? His code is well-written, and clear. If/when I ever need to work on it, the framework in which is tests are written is the last concern on my mind. We have enough code/distinct products that there's strong ownership of any given set of libraries/applications with only a little time for anybody to contribute outside of their main work, really. I'm actually a bit of an exception in that I design/maintain the build system/environment, so I have an opportunity to get my hands on everybody's work. In my experience, the bigger problem is integration across languages/product lines, not little stuff like which test framework is being used. I'm a big CMake advocate, so as long as I can run: cmake &lt;source_dir&gt; make test I really don't care what framework was used to implement them.
Or this: #include &lt;utility&gt; #include &lt;iterator&gt; namespace impl { using std::begin; using std::end; template&lt;typename R&gt; decltype(begin(std::declval&lt;R&gt;())) adl_begin(R&amp;&amp; r) { return begin(std::forward&lt;R&gt;(r)); } template&lt;typename R&gt; decltype(end(std::declval&lt;R&gt;())) adl_end(R&amp;&amp; r) { return end(std::forward&lt;R&gt;(r)); } template&lt;typename T&gt; struct sink { using type = void; }; } template&lt;typename I, typename ENABLE=void&gt; struct is_iterator : public std::false_type {}; template&lt;&gt; struct is_iterator&lt;void*,void&gt; : public std::false_type {}; template&lt;&gt; struct is_iterator&lt;void const*,void&gt; : public std::false_type {}; template&lt;&gt; struct is_iterator&lt;void volatile*,void&gt; : public std::false_type {}; template&lt;&gt; struct is_iterator&lt;void const volatile*,void&gt; : public std::false_type {}; template&lt;typename I&gt; struct is_iterator&lt;I, typename impl::sink&lt;typename std::iterator_traits&lt;I&gt;::value_type&gt;::type&gt; : public std::true_type {}; template&lt;typename R, typename=void&gt; struct is_iterable : public std::false_type {}; template&lt;typename R&gt; struct is_iterable&lt; R, typename std::enable_if&lt; is_iterator&lt;decltype(impl::adl_begin(std::declval&lt;R&amp;&gt;()))&gt;::value &amp;&amp; is_iterator&lt;decltype(impl::adl_end(std::declval&lt;R&amp;&gt;()))&gt;::value, void&gt;::type&gt; : public std::true_type {}; which I got helped with here: http://stackoverflow.com/questions/25224002/match-iterable-types-arrays-and-classes-with-begin-end But the problem is that this matches with a higher priority than when you explicitly specialize for a certain type, which should also be possible.
Reading the tutorial: unsigned int Factorial( unsigned int number ) { return number &lt;= 1 ? number : Factorial(number-1)*number; } // ... REQUIRE( Factorial(0) == 1 ); I'm thinking, "well, that's too bad; without a `REQUIRE_EQUALS` or something, you won't be able to see the value of `Factorial(0)`". Then, I read on: &gt; Now we get a failure - something like: Example.cpp:9: FAILED: REQUIRE( Factorial(0) == 1 ) with expansion: 0 == 1 Color me impressed! For those curious how this works, `REQUIRE()` expands to another macro, `INTERNAL_CATCH_TEST()`, which constructs a `ResultBuilder` object (let's call it `foo`), which has an `operator-&gt;*` declared, which captures the left hand side of the equality expression (using `foo-&gt;* expr`), then builds up an expression representation using `operator==`, resulting in the entire expression being captured. Nice trick!
&gt;Why would that be an issue? Because both of you need to know two ways of achieveing the +/- same result, and when working on each others code, you need to do a mental switch from one to the other. That might (or not) be a big deal, depends on the context, but "bring your own *anything*" is generally not best the answer in team work.
Yeah, for the most part, I agree. When it comes to tests, though, as long as people are writing them, I'm happy with whichever framework they are comfortable in. 
I really love the simplicity and the straightforward syntax. There is however one piece of functionality I'm unsure whether exists. Perhaps someone can enlighten me. Say you have multiple implementations of an interface or abstraction, and you want to run the same test across a set of implementations. How do you achieve this using Catch? If I'm not mistaken, this can be achieved in other testing suites by using data providers. I guess you could perhaps run sections in a loop (haven't tried), but I vaguely recall someone discussing that this was problematic, though I can't seem to dig up that particular discussion at this moment.
Honestly, this is probably the best possible introduction to the new features. It's also not just about what is new, but why it's there and how it can be used. Highly recommended viewing!
The FAQ, "Why do we need another...," doesn't really seem answered to me. I'm pretty happy with boost.test. I've heard of problems in it but I don't seem to be effected by them. Along with turtle mock it seems pretty complete and easy to use. So why should I try this one out? What does it have that the other's don't?
Maybe because it's not so different and they are commonly used together?
I call "C+" the ANSI C / C+98 hybrid too many people create in their heads and in their codebase (including many CS professors)
thats not completely true. but if people can write in C they can write in C++ (they might not be taking advantage of all the features), also people tend to write a lot of C code in C++ only using select features of C++ that actually justify using it for them. 
Depends on your C++ style and goals. It's possible to pick a subset of C++ that gives you some nice expressiveness/readability improvements while retaining C-like resource management. People are quick to vilify these hybrid C/C++ styles but they can be very useful. For example, an embedded programmer might take advantage of operator overloading, templates, and inheritance-free OOP while allocating everything statically and never using destructors, exceptions, or virtual methods.
There are a couple of hash-improvement proposals; some kind of functionality is needed but I haven't read them closely enough to have an opinion about their specific contents. I believe Library Evolution has been discussing them, but I usually attend Library Vanilla.
I haven't used it, but it looks good. I use Boost's test framework at work.
C++98/03/11/14 incorporates the C89/89/99/99 Standard Library by reference with modifications, but there's no direct relationship between the Core Languages, only suspiciously parallel wording. (And it differs in subtle and not-so-subtle ways.)
"Totally" is too big a word when you consider that low-level features of C++ are C. When you write C++, C is hiding under. Only when/if you climb the abstraction ladder they become "totally different".
Avoiding dynamic memory allocation, exceptions, and virtual functions in an embedded environment might make sense, but avoiding destructors is just silly and IMO worthy of vilification.
Because back in the C++98 era, you could go from C++ to C pretty easily (and almost as easily in the reverse). It's a holdover from that time. Also, C++ was a strict superset of C (I know, it wasn't 100%, especially after C99, but go with me on this). Nowadays, I disagree with anyone who says "they're not all that different". Modern C++ (and Future C++) are so different from C at this point, that they should not be considered the same. I'd go so far as to say "C/C++" is equivalent to "C/C#".
This is one of Stroustrup's pet peeves: http://www.stroustrup.com/bs_faq.html#C-slash
'C/C++' means "C and/or C++". They are different languages but the historical relationship meant at one time that C++ programmers were also usually C programmers. C++ was sort of seen as the next version of C, and the reason to use C++ was to improve C programs.
C is a nearly proper subset of C++ and many employers are looking for people that understand all factors of C, and parts of C++. The basic idea is that the difference between C89 and C99 is about as much as between C99 and C++98 (at least, the parts that most people actually know about and use). Since most people don't even realize there is much difference between C89 and C99 that's not too much.
There's no runtime cost to destructors. It's just a function call (that can be inlined). If you have resources that need to be cleaned up, you might as well have the compiler generate the function call for you instead of writing it yourself. The same code will be generated either way, but only one way removes the possibility of the programmer making a mistake.
But without any dynamic memory allocation and any sense of "end of program" what use are destructors?
Although C and C++ are different languages, they are both low-level, "native" programming languages, having direct access to hardware and OS interfaces. So C/C++ refers to low-level, systems programming or performance-critical programming.
Because memory is not the only limited resource that needs to be managed.
But when your destructors are provably never going to be called.. what point is there? [edit] You're thinking RAII resources... that's also dynamic allocation and if dynamic memory allocation is out of bounds, I'm pretty sure your environments doesn't want any other dynamic allocation/deallocation either.
Before I say this, I want to qualify it. There are probably a lot of people that incorrectly conflate the two languages; especially in respect to areas where the languages are by very definition, incompatible. However, I think a lot of the concepts C was originally based on, are still important in C++. Maybe the most obvious would be direct access to memory. There are other similar areas too though (standard types, storage classes, type qualifiers, linkage, and so on...). So maybe the reason the two get conflated is that some core concepts of the two languages are extremely similar. Although the different semantics and features lead to extremely different styles, which is possibly something more people fail to acknowledge.
&gt; * Easy to integrate - just put catch.hpp somewhere (I embed it in my project inside an External/catch directory). Well, I'm already using boost so it's no big deal to set up boost test either. Just include `boost/test/unit_test.hpp` and provide the right cmake invocations to link. &gt; * The CAPTURE feature is great. You can throw all sorts CAPTURE lines in your tests to capture values of intermediate variables to help with debugging, and they'll only be printed out if a REQUIRE or similar fails (so you only get the output you need). I suppose that could be useful, but then there's the message macros: BOOST_CHECK_MESSAGE(x == y, "Testing if " &lt;&lt; x &lt;&lt; " and " &lt;&lt; y &lt;&lt; " are equivalent."); Of course you can toss in other variables that may have been used as intermediates to get x and/or y. &gt; * The SECTION feature provides a very nice way to do setup/teardown type work in a very simple and local way. How is this better than fixtures? That's mentioned in the readme as a feature, but fixtures seem quite solid to me. Especially in boost.test: struct Fixture { Fixture() { setup(); } ~Fixture() { teardown(); } sometype somevar; }; BOOST_AUTO_FIXTURE_SUITE(suite, Fixture) BOOST_AUTO_TEST_CASE(case) { BOOST_REQUIRE_EQUAL(somevar, somefun()); } BOOST_AUTO_TEST_SUITE_END() &gt; I tried Boost.Test a long time ago and seem to remember it being tricky to set up properly and generally it felt a bit awkward. Depending on how far back I'd agree. Quite a long time ago it was pretty horrible and pretty much entirely undocumented. It greatly improved some time ago though. Since it appears catch always tries to stream the variables in the test, does it play well with unstreamable values? For example in boost test I'd generally prefer the EQUALS postfix macros but sometimes have to not do so because the types don't have &lt;&lt;.
My impression is that this is usually done by people who don't really have much of a clue about C++.
Only mildly off-topic, but LLVM has made huge strides recently in being ABI compatible with VC++ which should go some way in ameliorating this problem.
Maybe. There does seem to be a cargo cult aspect to it.
The reason destructors aren't used heavily in Embedded programming is simple: If you don't create any dynamic objects during runtime, you don't have to delete any. You create everything at start-up time. If it's a shared resource, it goes into a pool that manages it. It never dies. If something never dies, you don't need to destruct it. It (usually) dies during power cycle, but at that point you don't care as EVERYTHING dies at power cycle. You always know how many and where everything is located. You don't have to worry about memory fragmentation. You don't have to worry about the cost of a New/Delete, or running out of memory at run-time, or trying to provide deterministic execution in other threads when you have the OS trying to update memory tables.
&gt; also people tend to write a lot of C code in C++ only using select features of C++ that ~~actually justify using it for them~~ they know about.
There isn't much difference between C89 and C99. Common compiler extensions were standardized (e.g. `//` comments, inline functions, designated initializers, bool, declarations after statements, variadic macro) , and some support for Fortran constructs was added (VLA, `_Complex`). IMO, the differences between C99 and C++98 are much greater.
I'm pretty sure it's to filter out candidates who are too pedantic to be pleasant coworkers.
Hi, It turns out I have a little bit of experience in this. First, I doubt you'll be able to have a dependence-free binary. But, you can make sure that your dependencies are packaged on the targeted environment.' You can check the dependencies of your binary using `ldd yourbinary`. This will give you an overview of what you'll need to do. Some libraries are way harder to link statically against. Surprisingly, using CMake, linking with boost statically is trivial, but I can't talk about POCO (again `ldd` is your friend), for instance, curl is difficult to link statically with. However, I would consider as good practice to have a build server using the *same* system as the production server which will compile and link (and package) your binary/project to be deployed. You can then, if needed, compile your version of the libraries using the good runtime and potentially other dependencies. In my previous job I needed a version of boost newer than the one packaged on the system. I created my own package with the compiler and flags (`-std=c++11`), I installed it on the build server and that was it. Then to help the deployment, I created two virtual packages: `project-dev-dependencies` and `project-dependencies`. `project-dependencies` was mostly trivial dependencies, and the one not packaged were on a private debian package. This was on a Ubuntu 12.04, so I had to install gcc-4.8 on the servers, but that was easy with the ppa from Ubuntu. Edit: The production servers and compilation server had the same runtime (gcc-4.8). If you want to use the C++11, make sure C++ libraries are compiled with the same set of flags (ie. `-std=c++11`), the compiler only is not always enough. Also, the `project-dependencies` could also be the dependencies of your debian/rpm package, this would be even better IMO (this is what I add but having a virtual package has some advantages too). I successfully statically linked `tcmalloc`, `zeromq + openpgm`, `jsoncpp`, and maybe one or two more. The ones I did not even try: `tbb`, `icu`, `protobuf`, `curl`. This was either too complex, or/and the version on the servers were enough. 
Thanks thomas-s. You were right about ldd. That is very helpful! It seems what I need to do here is educate myself on creating packages. I'll research that further myself, but if you have recommended resources, certainly feel free to mention them.
And if I write in C, machine code is under that. And if I write machine code, there are electrical currents under that. Does that mean I should write my program in voltages the next time? There is a reason for abstraction and high level features.
This us a very good point. Although most of the code that I write is modern C++, I still have to interface with a lot of platform APIs and third party libraries, many of which are C. I think this is still pretty common. 
I'm personally a fan of CMake which offers some facilities to generate the packages so I don't have to know a lot about packaging. For example I use it in one of my project and as you can see, the [package part](https://github.com/daedric/httpp/blob/master/CMakeLists.txt#L203-L221) is quite small. It also seems that for C++ project, on github, CMake is quite common. 
What I gather here is that it is advisable to compile/build with the same tools that are on the server and not try to support dependencies in parallel to the system runtime; i.e., deploying later versions of the c and stdlib runtime binaries. So if they are running CentOS 6.5 with GCC 4.4, then I should compile/build with the same GCC tools. My laptop Fedora has GCC 4.8. So developing with the tools on my laptop is just not worth it unless I absolutely need some C++11 language feature not present in GCC 4.4 (which I likely do not). Is this correct, or am I being too narrow?
If you're writing code for your own benefit, then do whatever is convenient to you. But remember that having the app actually *run* on the target machine, without installing a bunch of subtly incompatible newer libraries is very, *very* convenient. If you're writing code to be built from source and run on other platforms, you'll need to adjust it to work with the system libraries those other platforms have. As a minimum you might end up getting comfortable with clang-vs-gcc, libc++-vs-libstdc++ and when to statically link a 3rd party library and when to use the system-installed version (and the same app may do different things on different platforms). Autoconf or cmake or similar can help there (but aren't an absolute requirement). If you're building code for others to install as binary packages it gets more interesting. Learn your native distribution packaging system and make .debs or .rpms. There are packaging systems that'll create various different packages from a single build configuration - the ones I've tried aren't as flexible as you might like, and aren't any simpler than just learning the native tools. Make your code compile and run with the current versions of system libraries distributed on the distributions you want to support. If you can create the packages in an isolated environment (whether that be something like pbuilder or a VM that's reverted to a clean state) you'll know that you're not making invalid assumptions about package dependencies. Having a machine or VM that's near identical to your target system (same distro, same major version) is a must, though you don't necessarily need to use that as your main development platform you have to be able to build, test and debug on it. (I develop server apps that are almost all deployed to Linux or Solaris but I do almost all the development on my OS X environment, switching to linux for QA or if I need to run something like valgrind.) Generally, version of the compiler and so on isn't too critical - but newer compilers will be better at finding bugs, both real and false positive, so expect to have to fix warnings that you hadn't seen before when moving to a newer compiler. Versions of system supplied libraries is more of an issue - if you can stick to a lowest-common-denominator, that's great. If not, you'll need to statically link or distribute shared libraries on some target platforms. If you're supporting users of your app on multiple platforms you'll want all those platforms available. I have at least two or three VMs for each distribution I support (RHEL5, 6, 7, Squeeze, Wheezy, Precise, Trusty ..). One for QA that gets reverted to a virgin snapshot after each test run, one that's a reasonably clean installation to build on and sometimes one that's for actually developing on. Virtual machines are an incredibly useful tool for all this. I use ESXi, but if I didn't have a dedicated VM machine I'd probably use [Vagrant](http://www.vagrantup.com) or vmware workstation a lot.
Yes, C++11 feature however worth the effort :)
We compile and ship all our dependencies as shared objects, that is we do not rely on the package manager. We manipulate the load path to make sure we don't end up loading something from the host. 
*Make your code compile and run with the current versions of system libraries distributed on the distributions you want to support.* As obvious as it may seem, this is what I needed to hear. *Having a machine or VM that's near identical to your target system (same distro, same major version) is a must ...* One thing I have made use of lately is a cloud service provider like www.rackspace.com. I can create an instance of xyz server in approx. 20 seconds ... Thanks for your reply, it was very helpful. 
What would you say to someone who thinks that frameworks are a waste of time and you should just write test programs instead (just using assert perhaps - or CMAKEs test facilities)?
So do you ship your own c and c++stdlib runtime binaries? Edit: I could have asked this a better way. If you compile all your dependencies into shared objects, does that mean you aim to not rely on the host for essentially anything; which would include say the gnu c runtime library. 
I'd say the same things I would to someone who argued that any 3rd party library or framework wasn't worth using, and that they'd just rather write all their own code: "Fine, do it at home. Here at the office, we have more important things to do than reinvent every wheel." Most people who say things like that aren't looking to be convinced, and most of the time I'm more concerned with pragmatic solutions than codesturbation. What do you think said frameworks allow you to do? They provide convenient functionality to correctly write said test programs and organize their execution. Many of them provide output in formats that are basically industry standard (the xUnit family being a popular output format), and nearly all of them hide a lot of crufty preprocessor macro magic in the C++ sphere, at least. Most people aren't rigorous enough to correctly write something as clean and simple as Catch (which in this context I'm considering to be a lightweight unit testing framework), or as thorough as Boost's or Qt's. Moreso, they're probably even less likely to get it right from a cross-platform perspective. Further, what do you think CMake (not CMAKE) provides re. testing? It provides little more than convenience when adding existing test executables to a build, such that one can execute them all and see a report on the results. It's not in-and-of-itself a test-writing utility, even with if you hand write the CTestFiles.
C++ with minimal OOP/restricted features do exist; this is especially true for embedded platforms that have a restricted C++ compiler such as AVR 8 bit micros. The real answer though is that they likely want you to be familiar with both as there is no black and white difference between the two; it spans a wide range of needs and programming styles. C++ is only incompatible with C depending on how you write your programs and there is nothing wrong with writing programs that mainly stick to C features while using a few C++ features.
I really dislike this. I think of very low level code when I think of C, and I think of something somewhere between that and what I might do with Python when I think of C++. Many programmers feel that C and C++ are close together, but they're not. One is a finishing hammer, the other is a sledge hammer, sure they both hit things but you probably don't want to hang your pictures with the sledge.
So, I feel like looking at the syntactic similarity of the languages is misguided here. I am not a wizard by any means, but as I said in my comment (somewhere around here, look for down votes.) They're tools, I think my pet peeve is the professor who would tell me that Python was garbage. Python is not garbage, it's a tool. Now, I wouldn't try to shoehorn python into an imbedded app (though I know some people do) as that seems to me like a place where C is most handy. However, I also wouldn't want to write a GUI heavy app in anything other than C++.
There's still plenty of good uses for RAII. You can still have smart-pointers which allocate from an object pool and release it back on deletion (and associated constructors/destructors there), or lock handles which automatically unlock when the function returns. I'm not saying it's 100% essential, but banning it sounds more like a fear of the unfamiliar than based on any real technical merit.
A simple example which is extremely useful is an RAII lock, mutexes are fairly common in embedded code if you have an RTOS, and that doesn't imply any dynamic allocation beyond what happens on the stack. Dynamic heap allocation is disliked in embedded environments because it's difficult to predict how long it'll take, and it's difficult to prove that effects like heap fragmentation won't happen. Other forms of dynamic allocation (through pools, for example), are still reasonably common if the lifetime of objects does not mesh well with the stack and they cannot simply be global variables.
One thing which may be of help is to spin up a CentOS 6.5 [VirtualBox](https://www.virtualbox.org/) VM on your Fedora laptop. You can then build and test your code with the same environment as it would have in production. [Vagrant](http://www.vagrantup.com/) is an excellent tool to allow you to easily start and stop VMs as you need them You can share a folder on your host machine with the guest OS, so you continue developing in whatever IDE you want, etc, then build under the VM with gcc-4.4 etc. Benefits of this: - You don't have to have your development machine match production - You don't have to maintain a second development server which matches production - You don't have to copy code between your dev machine and dev server - If you have multiple production deployments you can have multiple VM images which match each of the production environments you have to deploy to **Some links** - [CentOS VirtualBox guide](http://wiki.centos.org/HowTos/Virtualization/VirtualBox/CentOSguest) - [List of CentOS VirtualBox images](http://virtualboximages.com/CentOS) - [List of Vagrant images](http://www.vagrantbox.es/)
PS: In relation to other comments in this thread, obviously this doesn't help you with C++11 features. That's another story!
Isn't this the kind of problem that Docker solves? (not a web programmer, but aware of industry hype). FWIW, on Windows you ship a copy of the required C++ runtime DLL, or an installer for same, with your application.
For convenience / portability you can use virtualbox or KVM to make VM installs of whatever OS you want on your local machine. Great for testing, and if you go way down the rabbit hole of build servers a very convenient way to setup a multi OS build environment.
*You can share a folder on your host machine with the guest OS, so you continue developing in whatever IDE you want, etc, then build under the VM with gcc-4.4 etc.* That's a very useful recommendation. That way, you can develop and make sure the code compiles and runs given the tools on your "target server."
*Note that in general glibc is backward compatible, not forward compatible. That is, you can run something built with an older version of glibc on a machine with a newer version of glibc, but not the other way around.* That is interesting and good to keep in mind (not surprising of course). Also, I have recently noted that libstdc++ is forward compatible within its major releases. Needless to say, what I am being reminded of here is the different approach you take when developing/deploying C++ applications. With C++, and native code generally, you either deploy source that compiles and builds on the target machine, or you deploy a binary that you know full well is 100% binary compatible with the target because you already compiled it on an identical machine. 
in my experience you have to lead by example, and be patient. And it will probably be a one-idiom-at-a-time thing, not a wholesale move to modern c++ Do you have a code review process? if you see some code that would be better off using modern idioms you can provide code snippets showing concretely how their code may be improved Some idioms are obvious no-brainers (new range-based for, new auto pointer types and threading primitives, delegating constructors, in-line member initialisation) but curmudgeons seem to really resist certain things such as the 'auto' keyword (probably because theyve spent years convincing themselves that theyre unnecessary as other languages got them), and youll end up with endless arguments about those. You have to accept the fact that you wont win all these arguments. edit: always remember though, modern c++ _is_ c++, and anybody refusing to learn and use new idioms cannot in call themselves a good c++ coder. Sean Parent makes similar arguments for learning all the STL algorithms when relating an anecdote about someone at Google (!) trying to convince him that certain algorithms are too obscure to use
I was going to post there, but there are only 5 people on that subreddit, and 36 on here. My question had a better chance of being answered here. 
Would you recommend Effective Modern C++? I've been writing in C++ for 2-3 years now, and I've already read "Effective C++" and "More Effective C++" cover-to-cover, so I wouldn't consider myself a newbie... mainly, I'm just looking to learn multithreading, and I was considering a book such as [this one](http://www.amazon.com/C-Concurrency-Action-Practical-Multithreading/dp/1933988770).
Lead by example. It worked for the two of us at my employer who are C++ language fans. Also, choose your manager very carefully; if your manager assumes that a compiler upgrade is a problem rather than an opportunity, you're gonna have a bad time. Also see if you can schedule a meeting to show off the labor saving features: the simplified for loop and the fact that if you write C++11 correctly you never write "new" or "delete" were eye-openers. (this is once you've provided a make_unique&lt;&gt; template function, which is trivial anyway)
C++ programmers know C, so are switch hitters.
&gt; Sean Parent makes similar arguments for learning all the STL algorithms when relating an anecdote about someone at Google (!) trying to convince him that certain algorithms are too obscure to use Ha - that's interesting! Thanks for the advice. Patience and leading by example is the approach I am taking, maybe I'm not patient enough! :)
mostly your problems will come from what kernel version your glibc was compiled with and also some symbols that were changed for security purposes. if you compile against one thats too new it wont run on older systems, the loader will just barf. as for glibc symbols your main tool will be objdump: objdump -T &lt;executable&gt; ex: 0000000000000000 DF *UND* 0000000000000000 GLIBC_2.3.2 pthread_cond_broadcast you can do some grep, awk, sort and uniq to list glibc version dependencies. some systems do not have newest memcpy@@GLIBC_2.14 search around for a technique using __wrap_memcpy as a way to use the original. you'll have to tell the linker you are overriding memcpy. gcc compile flag -U_FORTIFY_SOURCE bypasses most of the newer more secure glibc wrappers for calls like setjmp (jpeglib uses setjmp). i see this flag too but i don't honestly recall if it was for this case: -D_GNU_SOURCE i also recall there being some trouble with 'c' libraries using -std=(i forget) which pulls in some ugly symbols as well. sorry this is off the top of my head, i think its been 3 years or so since i went through this exercise, but i have something ridiculous like fedora 7 compatibility with our software. i use archlinux for dev and build and may have lost that compatibility as i used to custom compile glibc with older kernel compat but abandoned that a few years ago. cmake is muderous because it makes it nightmarish to override system libraries. i actually ended up just pulling in jpeg, zlib, png, pcre, etc and just build with our own build tool. if you do cross platform stuffs with windows this is really the only way to go anyways. so why not use a vm to compile?? everything i build is always release mode and always tested on the dev system. what i compile and test myself day to day is what the customer gets to run, even on their old systems. same on windows. i bet its been 14 years since i ever did a windows debug build but that topic is another one altogether.
Wat?
Even in embedded work, you just need to cut out a few things: dynamic memory, exceptions, and *maybe* polymorphism. Everything else is kosher. You can write beautiful, modern C++ in embedded systems. C++11 further makes embedded systems that much easier: lambdas, constexpr and variadic templates all show up throughout my code written for a 32kB 16-bit processor.
I guess you're right - I suppose the trick is to somehow convince them that by adopting modern practices they're actually making their lives easier - less time chasing down memory leaks etc = more time doing something else
&gt; if you write C++11 correctly you never write "new" or "delete" A good motivating point!
Good luck with that. In my experience they don't care. Work is over at 5, how much is accomplished up until that point is irrelevant. They have no stake in it. As long as they get to go home and not have to do or think about work (i.e. programming in general) until 9 the next morning, they don't care.
oh two more things: - you may not be able to convince the other guys to learn new stuff so think long term by getting involved in the hiring process, and doing it well. I wrote an article on this: http://seshbot.com/blog/2014/01/23/the-best-way-for-programmers-to-interview-programmers - consider the possibility that the 'older' guys might be right sometimes (i.e., stay respectful of your co-workers!) If they bring up an argument, make sure you have good reasoning behind your perspective other than a desire to use newer tech. All of the new functionality allows for safer and/or more efficient programming, so make sure thats whats behind your arguments. Things like template metaprogramming for example are often too complicated for anything other than low-level utility libraries.
**Don't rewrite random stuff!** To expand on "lead by example" theme, what I do sometimes is, do anything the better way, find same/similar in the existing code, make a wiki entry comparing the two and explaining why I think my way is better. Basically, explain anything on a practical situation, compare with "old". Be gracious when doing that (I am not ðŸ˜‰, and that has worked against me).
C with Classes was the original name for C++... Source: https://en.wikipedia.org/wiki/C%2B%2B#History
Agreed - if it's not broken don't fix it! Changing something just for the sake of modernising it is not always the best course of action. If you can prove refactoring something will make it more efficient or safer or more intuitive to use, that could be a good case for rewriting it. 
Except when no modern compiler or acceptable quality is available for the embedded system I guess. 
Any dynamic allocation introduces multiple paths, one of which makes you unpredictable when you do have the resource. It's not relevant what resource it is, you've just introduced an unknown and possibly undeterminable delay for when something happens and your RTOS isn't.
Often a big old C++ codebase will basically be C with Classes in the older code and the newer code will be the more "modern" C++. Also it is not uncommon that a completely dedicated modern C++ programmer will have to access a very old C library that requires all kinds of old school malloc style games. And lastly some very modern tools such as OpenCL are still C. (They are working on a C++ version but it isn't in common use). So you might have the bulk of your code in the most modern C++ possible while doing some amazing stuff in C via OpenCL. Then there are areas such as drivers where any direct access to the hardware will almost certainly involve C and might even devolve into inline ASM. So while people can claim to be purists with their modern C++ it is almost impossible for many programmers to do so. So depending upon what exactly the programmer is doing C++ might be the best description, C might be the best description, or C/C++ might be the best description. I use OpenCL extensively and thus my code could only be called C/C++ with the / even representing a dividing line where some parts are C++ and some are C. 
I wouldn't say it's "totally different" considering C++ is a superset of C. Something like Java and Javascript I could see, though.
Okey, another sample: let's say you wrap C library and use it in python. Do you call the resulting code C/Python?
Nevermind. Sorry, it's late. I'll leave the post up, though.
Myers has [Effective Modern C++](http://shop.oreilly.com/product/0636920033707.do) now, available in draft form from [O'Reilly](http://shop.oreilly.com/home.do).
It should be mentioned which algorithm was deemed to obscure: `std::rotate`. `std::rotate`. Seriously, understanding what `std::rotate` does is easier than `std::sort`.
Honest question because I'm genuinely curious - by no dynamic allocation do you also mean no local stack variables? 
It doesn't matter what your style and goals are, C++ still has all that other stuff. You could probably use Python in a pure-functional programming style, but that wouldn't make it a pure-functional language and people would be right to look at you funny if you categorized it as "Haskell/Python". But heck even I have the bad habit of referring to C/C++.
Stack variables yes, but compile-time checked to fit within the stack allocated. That also means no recursion typically.
Ah ok, that makes more sense to me now. Thanks!
Im still optimistic like you are. Im pushing for adoption of C++11 techniques in our everyday code, especially uniqueptr sharedptr because of memleaks. The way I started to get momentum is I found a few people that agree with me and we work to convince other together. Strength in numbers. It helps if you can gain the support of the tech lead or someone else respectes by the whole team. 
&gt; They use the STL and boost etc, but seem scared of building templates themselves, generic programming, policy based design etc. Believe it or not, that's more than you can expect in most C++ shops. In fact, I am going to play a devil's advocate here and suggest that writing templates should in most cases be left to library builders and for most application and system programming it is often better to avoid them. Templates are hard to debug and tend to increase build times.
Not all of them, alas ...
These are the times where I wished I lived in the US!
Look for the utility ClangModernize, run it on a few files and talk it up, showing the benefits of C++11. 
I hit that snag. My company was doing all their dev, for a proprietary DSP architecture, in ASM because they figured a compiler was too difficult to get right. I pulled the latest LLVM/Clang, added our architecture, and voila! Full C and C++ toolchains. Was surprisingly easy, actually.
yeah I should have mentioned that - I think he also mentioned std::partition()
Good question. I see it more of a all-under-one-compiler situation; which doesn't completely apply to my OpenCL example, except that with OpenCL a great trick that I have learned is to develop the C code as a function inside the largely C++ application. This way it is slow but fully tested in a great IDE. Then I migrate that C over to OpenCL which is a royal pain to debug. But I also do OpenCL combined with Python. In that case the C and the Python never really touch. With almost all of programming it is a rule of thumb. For instance I refuse to believe that there is a hard and fast rule as to how many levels is bad. My rule of thumb is the more levels of nesting the uglier and my other rule of thumb is that if you find yourself eyeball deep in nesting then you are doing something wrong. But I would never be so pedantic as to say 6 levels is wrong but 5 is correct. At what point to you switch from a long if-else to a switch statement? So I see C and C++ the same way. When dealing with OpenCL you basically can't feed it a vector of objects but you can feed it an array of structs. Thus the OpenCL begins to C'afy the surrounding C++. Also once you are dealing with a huge array of structs instead of a vector of objects it would be performance bad to try to "clean" up such C like code by converting it into and out of more modern C++. Yes it would be nice to get some better iterators but at a cost of making the code more complex. I will use the best architecture or tool to get the job done; what I won't do is to blindly follow some pedantic rule that makes no sense in the situation I am working on. My case in point is the crazy usage of templates. I see people who are writing code that will never be expanded upon and any maintenance will be to fix a bug or two. Yet they template the crap out of their code allowing it to handle all kinds of data types and whatnot when there is a zero percent chance of there ever being any other use for that code. A case in point is a template I caught in someone's code the other day where the code needed to take in a User_ID (int) and convert it to a string representing the user. They templated the function in such a way that it could handle many data types. But quite simply the user ID will always be an int as these user IDs have been handed out for around 15 years. Why did they do this? They claimed it was the modern C++ and that they weren't a C programmer. 
&gt; the ordered containers -- while giving the associative semantics -- have the performance overhead of guaranteeing the ordered property. Yes. Did it matter, the overhead? (iow... premature optimization?)
Honestly I think you are going way way overboard here. Imagine working for a company that standardizes on Visual BASIC. A version that is several years old. The reason for this stupidity is that you are told that anybody can write VB code. In the end what you get is VB code written by people without a clue. Instead you are working for a company that as you indicate uses C++ with the STL and boost. That my friend is something many people would find to be fantastic. Now the question is should they go all in on using the new C++11 features. The answer is NO!, Emphatically! This especially the case in the maintenance of old code that might not be extremely relevant to the core business. Now if you are generating completely new code or apps this is where you might want to introduce reasonable new features from the latest C++ standards. You can't do this wildly either as everyone involved must be on board with new feature usage. Honestly though I think you are way off board to be whining about some of the features you want to see implemented. There is a lot to be said for code that can be maintained after you have left or are given the boot. If your code isn't Something that a reasonably skilled C++ programmer can't comprehend in a few minutes you will be fighting an up hill battle to get your techniques implemented. Much of what is in the C++11/14 standards does lead to far more readable code in my opinion but I still believe a mad rush to implement some features is fool hardy. A slow migration of the entire team is far more rational than tryIng to force crap code down every bodies throats. By the way I really believe that a team that embraces boost is fairly progressive. But consider this boost is still,transitioning to full use of the latest C++ features. Boost is built by some really smart people so maybe they know something about jumping in before completely testing the waters that you could learn. 
I spent 3 years at such a shop. I had one guy who was interested in diving deep into C++ with me, but almost everyone else was more interested in programming as a 9-5. The way I stayed sane was to take little nibbles of modern techniques and make up 3-5 card slide decks to explain how that concept/object/style could make them more efficient or make the code cleaner. Once a week I would send one of these out to the whole team in the hopes that people who cared might find this more accessible than trying to learn it all at once. In short, our job is to write good software, but sometimes the path to doing that is by being an educator to help your coworkers write better software too. You can't do it alone. All that said, I quit on Monday and am off to a start-up with the hopes that people that have equity in the company will care more. 
I see no mention of that in Annex J.2 (undefined behavior) of the C11 standard. I could be wrong however, so could you kindly point me to where this is specified as UB?
This paper is awesome. Even though it's called "almost final", despite covering a time period only up to 2006, it provides a valuable insight into how the development of C++ actually occurs. Some pearls I have found after briefly reading just one sixth of the paper: Stroustrup quotes Alex Stepanov in D&amp;E: â€œC++ is a powerful enough language â€” the first such language in our experience â€” to allow the construction of generic programming components that combine mathematical precision, **beauty**, and abstractness with the efficiency of non-generic hand-crafted codeâ€. On the other hand, earlier in this paper, he admits: "[Andrew] showed [STL] to me. My first reaction was puzzlement. I found the STL style of containers and container use very odd, even **ugly** and verbose." (Bold emphasis from me in both cases.) Another one: "Beman was (and is) one of the all too rare application builders in the committee. Unfortunately, the committee tends to be dominated by compiler, library, and tools builders."
Certainly didn't get buy in from the whole team, but it was better than nothing. Also, when giving notes in a code review, I was able to point them to a slide deck for detailed explanation/example of how to do what I was asking. And speaking of Code Reviews, with our source control system I was able to sign up for email alerts on every check-in that the team made. That way, I can comment on old-style code, sending people emails out of the blue commenting on the code they were checking in. Being the guy looking over everything gave me a lot of perspective regarding the talent on the team, and being a mere coworker made my opinion matter less. If I were their boss, then it would be micro-managing. I think, and I could easily be wrong, that I was viewed as a helpful overseer. If you let people do whatever they want, then you have admitted defeat. Just keep being the voice of progress and hope for the best. And if you conclude that your company is suffering from the Dead Sea Effect (https://www.readability.com/articles/cykqmkgs) then you might be better off seeking greener pastures. 
I expect to go home at 5. We *should* expect to go home at 5. Everything else is a recipe for burnout, which is a serious problem in our industry. But that doesn't mean you can't or shouldn't learn new things and adapt techniques to new realities.
what's lacking in e. g. QtCreator, with the integrated debugging and analysis frontend? does c# even have build systems? and for java, what is a good build system? maven is an absolute train wreck, ime. at least compared to e. g. cmake. as for static analysis tools, have you tried clang-analyzer, viva64 and coverity?
&gt; what's lacking in e. g. QtCreator, with the integrated debugging and analysis frontend? I'll stop and say that I haven't used QtCreator. My experience stems mostly from CodeBlocks, Netbeans, and MSVC++. Of the 3, Visual studios did the best for code completion and debugging, but played the worst with external libraries. Things may have gotten better, but from the last time I used C++ they weren't all that great. &gt; does c# even have build systems? NuGet? Ok, bad example. But TBH, building C# projects generally doesn't cause a lot of pain. NuGet removes a fair portion of it. &gt; and for java, what is a good build system? maven is an absolute train wreck, ime. at least compared to e. g. cmake. Maven really isn't terrible if you use it primarily for dependency management. It is when you start venturing into the "After I do this, I want to do this" realm that things start to get hokie. CMake is the best that C++ has, and it can be pretty tedious at times to get things just right. It's closest analogy in the java world is ant. C++, however, has nothing that really does dependency management such as gem for ruby, pip for python, or maven for java. IMO, Gradle is the best build tool available for Java. It does a good job of dependency management with the ability to do low level file monkeying like ant. What makes it nicer than CMake is the fact that you can just do "gradle 'taskName'" and it will go through, grab dependencies, run tests, compile, and do whatever else you need it to do. CMake can do most of that, but falls flat on its face with dependency management. The best you can do is tell the user "hey, you need library x and you might need to point me to it as well". The likes of gradle make it easy to build any project on any platform without having to worry too much about getting the user to get everything setup and ready. &gt; as for static analysis tools, have you tried clang-analyzer, viva64 and coverity? Nope. But I know they are there and powerful. &gt; I mean, yes, it does have an impressive array of static and dynamic analysis tools, but the quality of IDEs, debuggers, and build systems are pretty lacking. In other words, I don't question the goodness of C++'s static analysis tools. I know they are all pretty powerful. Java and C# have them as well, but I don't know how they compare.
Thank you for posting this, as a student I am incredibly interested in contributing :D
&gt;You might consider whether they're right. To lack professional pride? I don't think so. &gt;People that have been in this field a long time have learned the hard way that you do what you can, but no more. There's a difference between "*doing what you can, but no more*", and doing just enough to scrape by, the latter being what I'm referring to. &gt;do it their way a while This kind of has the assumption baked into it that "*their way*" has merits. Old style C++ doesn't have merits, it is categorically inferior to modern C++. It's less readable, less maintainable, et cetera.
What's your point? Just because something **can** be done, does not mean that it **should** be done. Denying that "*their way*" has merits does not deny that it **is possible**, it denies that it has advantages over some other way.
In the vast majority of cases I've observed people using `std::map` the key type is `int` or `std::string`, which have built-in specializations for `std::hash`.
Yeah, I can live with "if you already have a hash function for your key and don't order elements, consider the unordered variant of the associative container". ðŸ˜ƒ
I can't say I've a lot of experience on this either as just like you it was my first year. But now when the last 2-3 weeks of my summer holiday came along I decided to build a program which tests everything I've learn the past year and it's been helping with refreshing my memory quite alot.
By CS, do you mean Counter Strike EDIT: Oh crap, you meant computer science. I was like what is this guy talking about? Hack CS GO? Yeah I know what you mean. I'm subscribed to a lot of programming and indie dev subreddits. I see a lot of interesting things.
What do you mean by code "small labs"? I've never heard of that. Sounds interesting. And teaching a friend is also good. I've done that before for math, and it really helps. 
Small labs is just another way of saying, experimenting and playing with different concepts or research, here are some examples from my blog: * [Rasterizer Study](http://www.blog.namar0x0309.com/2012/06/3d-data-representation/) * [Adaptive Resolution](http://www.blog.namar0x0309.com/2011/10/adaptive-resolution/) I keep at least 5 per month, but since going commercial I can't publish publicly, until product using them is out :)
We use Apache Ivy + Artifactory Pro
Well, currently I work full-time during the summer, so problem solved. While I was in college, however, I would work on interesting problems. I wrote a crappy raytracer in C++ and a software rasterizer. I also reverse engineered an image format for a game and wrote a tool to convert it to PNG. Other than that, I worked on libraries, like an open source image loader and a 2D game framework. My latest library is [utf8rewind](https://bitbucket.org/knight666/utf8rewind), an open source library for dealing with UTF-8 encoded strings. Lots of libraries like that exist, but most of them are C++ while mine is written in C. While working on it, I learned about the different UTF encodings, the difference between characters and codepoints and what a surrogate pair is and why they're evil. Besides gaining practical knowledge, I practiced test-driven development (the library has over 200 tests for less than ten functions), added documentation using Doxygen (which took twice as long as actually writing the library) and used GYP to generate Visual Studio projects and Makefiles. The trick is to find interesting problems and to build solutions for them. It doesn't matter if you reinvent the wheel, because you will learn a lot about making wheels in the process.
&gt; What do you guys do to prevent this? Programming? I don't get the question.
Not `std::partition`, but `std::stable_partition`. But I have to admit: The algorithm he created based on that (he called it gather) is very logical, once you understand it, but in the first moment you are more like â€œwait, what?â€.
yeah that was a real gem in the presentation, and he just kinda threw it in there... the other one was slide() I believe
Google's C++ Style Guide is many things, but certainly neither good nor modern. In fact it is a great example for this terrible â€œA good Java-programmer can write Java in every programming-languageâ€-mindset.
Same way everyone keeps any skill set sharp: using them.
when he asked the audience how to slide, my first thought was something along the lines â€œ`std::rotate` should be able to do this, but I'd need to look up the exact paramter-orderâ€. OTOH I didn't have a clue about how to gather.
I'd just like to say maven is one of the few topics I can get as angry about every time. The hate just never dulls. I must go now...
I am not saying it is impossible to use Qt Creator on a big code base - I am saying the code browsing does not work well - i.e. can't reliably find declarations/definitions. In all fairness, I have yet to see an IDE where code browsing is perfect. MS Visual Studio is somewhat better than others in this regard.
The author of this blog post put out [another post with some clarifications](http://blog.regehr.org/archives/161). Going by that post, it seems that his code definitely involves UB when interpreted as C++, but that the question of whether or not the code has UB when interpreted as a C program is a matter of how the C standard is interpreted. (Definitely less cut-and-dry than the C++ case)
&gt; can't reliably find declarations/definitions I haven't had any problem with that in QtCreator.
Gotcha. Thanks.
no, we still depend on the host c and c++ stdlib. we compile everything above that.
From what I'm seeing, the current MCU market largely converges/has converged towards ARM, PIC and AVR, with some automotive/aerospace using PPC, some instrumentation stuff using blackfinn, and some automotive still using msp430s and such. All of those architectures can be targetted by GCC, so I don't think it's really that widespread of an issue, unless you're working with something super obscure. I mean, I guess it can happen, but I don't think it's really gonna be a problem you're going to run into very frequently... In the long term, it looks to me like just about everything is just going to be ARM.
If interested, please email. 
If you know the basics, then you are at a point where you need to start experimenting and learning from projects. Books and websites are good, but experience actually developing will be more useful until the fundamentals are firmly cemented into your brain. Some links: http://osgameclones.com/ - Source code for open source clones of popular games http://gameprogrammingpatterns.com/ - Very cool reference for design patterns used in games http://libcinder.org/ - Awesome graphical framework for gaming, but also has loads of other applications.
$0.02: Please take with a mountain of salt. That said, I learned C++ a *long* time ago. Then, the best was the "Teach yourself C++ in 21 days" (and its sister book for C). I'm not sure what the best resource would be these days. C++ isn't a "cool" language to know these days, so it's under-represented on message boards and forums. Once you get into using various libraries for your game project, you may find that getting support is easier over email, and through email lists. Game programming for a given language is an area of expertise in and of itself. Some languages/platforms make this easy: C++ is not one of those. The problem that C++ has no graphics or GUI support of any kind in its standard library. The easiest thing you can do here is take an existing C++ engine and hack on it. Having a pre-built engine means you can focus on understanding the 3D rendering pipeline, 2D rendering pipeline, drawing/culling algorithms, etc. Once you understand how all that works, then you should consider either embracing that technology or rolling your own. And do not take the DIY route lightly; you may learn a wealth of information by building your own, but it will be difficult unless you are already experienced with the language and/or game programming in general. Engines I've run into in the past are: Ogre3D, Irrlict, any of the open source ID Software engines. A bigger list is here: http://en.wikipedia.org/wiki/List_of_game_engines#Free.2Flibre_and_open_source_software Lastly: don't go it alone. I strongly recommend finding a peer to work with in all this, or simply get to work establishing yourself as a familiar face in a tech forum of your liking. Having people to bounce ideas off of, review your code, accelerate your research, can save you real time (years) on all this stuff.
As with all things, modern c++ features all should be considered tools and be used in sane ways when appropriate. When used in reasonable circumstances I consider basic templates, tag dispatching, policy based design and C++11 features to be indispensable. I work with many developers that have no problem understanding these things. We have no problem interviewing using such advanced topics. Speaking of RAII... Any number of C++ developers using recent versions Visual Studio are automatically exposed to "modern" features like r-value references. The language evolves and developers need to keep learning to keep calling themselves experts. 
As someone with just this same question about a year ago, I would suggest asking questions that test what the candidate would realistically expect in the position. By that I mean, if they are expected to creatively solve problems, then give them some creative problems to solve. If they are expected to be a code monkey filling in code, give them some skeletons to finish. If they are going to be doing some design, then ask them what design choices they would make for various types of problems. Cater the test not only to your company, but also the position. Generic questions only get you so far :)
I also disagree, learning C in the age of modern C++ is not a good idea. Many C styles are considered anti-patterns in modern, safe, C++. C++ is not that hard, but I am old enough to remember when C and Pascal were viewed as the Python and Ruby of the day and real coders only used Assembly.
I was in the same boat for a long time. Knew the language, but the leap from console examples to something useful was huge and undocumented as far as I could tell. Find some simple, open sourced game and get it to build. That will be a bigger step than you imagine. Step through it in a debugger. See how it all works together. Then start modifying it in small ways. That's the missing series of books. After you see how a few things work and add a few changes, try it for yourself.
Wow, you described perfectly where i am now. Thanks, i will look into it. Do you remember exactly where you started, or with which game/s? Thanks dude, really!
Maybe not helpful, but there are two variations on `const`. One is when an object is not observed to be changed, and the other is when all the members of the object have not been changed. In this general case, then, we may need to do something internally that a client can't see. In that case we can mark some members as `mutable` and perform non-const operations on them from a `const` member function. The other form is what you're trying to use, of course, where every member in a `const` function is treated as if it were `const` itself (this fact gets convoluted with pointer members). With an IO sink, I'm thinking of `std::cout`, which is declared as a `std::ostream` rather than a `const std::ostream`. Of course this has observables - the error status, which may be altered any time you call `operator&lt;&lt;`.
**This is a personal project.** I couldn't find too many C++ caching libraries, and so decided to create my own. A tutorial is in the works, but in the meantime, any suggestions / bugs / criticism would be greatly appreciated. Thanks!
Here's two I have reused myself after they were given to me: 1. Write the assignment operator for a class that contains a `char*`. 2. Get rid of all the 7's in this `vector&lt;int&gt;`. Both have their fail/fair/fabulous answers.
const &amp;/\* raises the bar required to mutate some object through the reference/pointer that *you have*, but it certainly does *not* imply global immutability, or safe deterministic behaviour in a multi-threaded context. Imho it's a pretty blunt instrument to catch programmer gaffs, allow for a bit of overloading, and not much more. My immediate thought with regard to your IOSink is, if there's no way to observe any behaviour out of the sink, then why not have an opaque handle type that you use via a non-member function instead of bothering the client with whether or not it holds a const or non-const ref?
Disclaimer: I'm a student and didn't have the joy so far to participate in an interview. In a recent thread there was a discussion about programmers who are unwilling to deal with modern C++, so I imagine that it might be a good idea to ask questions in that direction: * You want to move a subrange of a container to it's beginning, how would you do this? (`std::rotate`) * How would you gather all elements that fulfill a certain predicate in one place in a container without changing relative ordering. (this involves two applications of `std::stable_partition`; if people know about that trick, it is likely that they heard about it in one way or another in one of Sean Parents talks, which means that they are at least somewhat interested.) * When should you use allocating `new`? (in C++14: **never**, in C++11: only ever in the implementation of `make_unique`) * What is the rule of zero? Basically I would try to make sure, that they heard about most of the stuff from the algorithm-header and are willing to use them.
I clicked around and read a lot and still can't figure out what it is or why I might want to use it.
Caching is a technique used to store a temporary copy of data in a small, fast place (eg RAM). The idea is that if this data is accessed a lot, it's much faster to do this than constantly getting data from a slow, large place (eg hard drive). There are different ways to store this data -- but generally speaking there are no programming libraries which allows you to create your own cache (your own way of optimizing data usage) in an expressive way. Moreover, the caching libraries that do exist are (from a very surprised Google search) targeting Java, and none that I could find which are for C++ applications. Thus, I created this framework for C++ devs to create their own cache designs.
You should try and formulate your question in the most simple way possible, without unnecessary information. From my understanding, your whole question is: You have a data structure/class which is logically immutable to the outside but bitwise mutable on the inside. Should its functions be const? Is that correct? If so, the answer depends on your exact structure (the IO sink) but probably it would be "No". There is no exact rule when something should be const, but generally you can think of it like this: You have an instance A of your structure. If you create a copy B of A and then perform any operation on A, any further operation on either A or B will yield the same result. For example, if you have some kind of out stream, the following problem could arise: ostream A ostream B = A A.write("xyz"); // error: A only has 2 bytes in its buffer left A.write("xy"); // ??? B.write("xy"); // ok So write should definitely not be a const method. If, however, you are sure that your methods would fulfill these conditions, making them const is an option. For the thread safety: const methods already fulfill the demand of "const-thread-safety" if you don't have any mutable members. (and of course, as long as the methods don't write on some non-member variable)
What's the desired way of doing those. I know how I'd do it but I'm trying to see how well I'd do in your interview
&gt;&gt;I'm about to enter my second year, but I'm kind of rusty. Sounds normal. I made the mistake of writing a lot of stuff from scratch and picked up a bunch of C style anti-patterns. I would encourage you to use some libraries like CGAL or Qt which will give you a better feel for what paradigmatic C++ is like. 
Not OP, but I think I can point out some of the gotchas. 1\. It really depends on what the `char*` represents. If it's a C-string that's owned by the class, then the assignment operator should allocate its own memory and `strcpy` that shit. If it's a pointer to something not owned by that class, then it should probably just let the pointer alias, and maybe somehow notify the actual owner of the data. 2\. If you call `erase`, you may invalidate the iterator by triggering a reallocation, so you need to be careful with that. Otherwise, depending on whether the code should prioritize speed or simplicity, you should either do: for (auto i = begin(vec), i != end(vec), /* no incr */) { if *i == 7 { i = vec.erase(i); } else { ++i; } } or, for a faster approach (if there are a lot of 7s, it does less copying): auto j = begin(vec); for (auto i = begin(vec); i != end(vec), ++i) { if (*i != 7) { *j = move(*i); ++j; } } vec.erase(j, end(vec)); I'd be most impressed if you gave both, said that the first is easier to read and the second is faster, and to prefer the first unless it's too slow.
Thanks, but for the 2nd problem I feel like the 7 can be an arbitrary element, in which case a linear search can be very slow. What if you sorted it first
Sorting first is good if you're doing a lot of lookups, but if you're doing only one sorting is `O(n log n)` while a linear search is `O(n)` with much smaller constants. Searching for `m` elements is `O(m log n + n log n)` if you sort first and `O(m n)` if you don't, so sorting first is an improvement if m is `O(log n)` to make the second term in the first expression relatively less expensive. In this case, the first algorithm is `O(m n)` (m is the number of 7s), since it potentially does an `O(n)` shift for each 7, while the second one is `O(n)`, since it does constant work for each element, no matter how many 7s there are.
Without giving out the answers straight up... The fair answer for 1. doesn't leak. The fabulous answer takes care of self-assignment and offers some exception safety (and you can tell me why). The fair answer for 2. is done with a loop. The fabulous answer is a one-liner that uses an STL algorithm. In essence, I use these questions to gauge where you stand on the scale of C-with-classes vs. C++. 
The correct answer is: vector&lt;int&gt; v; v.erase(std::remove(v.begin(), v.end(), 7), v.end()); You could also use `remove_if` if you needed a fancier condition.
Also helps you steer clear of legal problems. Basing hiring decisions on a quantifiable work sample test that clearly approximates the job practically squelches any stupid discrimination suits. A very popular idea on here recently for a work sample test was text processing tasks on the King James Bible.
Bonus points if anyone can help me figure that one out.
Its well known that nested templating like this can lead to huge error logs. I only looked at the first few hundred lines, but it looks like a wrong number of template arguments in CssParser.C on line 372: --- /home/svenstaro/src/wt/src/Wt/Render/CssParser.C:372:3: required from â€˜CssGrammer&lt;Iterator&gt;::CssGrammer() [with Iterator = __gnu_cxx::__normal_iterator&lt;const char*, std::basic_string&lt;char&gt; &gt;]â€™ /home/svenstaro/src/wt/src/Wt/Render/CssParser.C:445:43: required from here /usr/include/boost/utility/result_of.hpp:189:8: error: wrong number of template arguments (1, should be 5) struct result_of_nested_result : F::template result&lt;FArgs&gt; ^ /home/svenstaro/src/wt/src/Wt/Render/CssParser.C:165:10: error: provided for â€˜template&lt;class Iterator&gt; template&lt;class, class, class, class, class&gt; struct ErrorReporting&lt;Iterator&gt;::resultâ€™ struct result { typedef void type;}; --- If it doesn't start from there, I would grep through the log file for 'svenstaro' to find out which of your files contains the error.
&gt; text processing tasks on the King James Bible. [Argh](http://www.reddit.com/r/cpp/comments/20kaem/my_c_interview_questions/cg458pm) and [no](http://www.reddit.com/r/cpp/comments/20kaem/my_c_interview_questions/cg46b0t).
^ Here comes a new challenger!
For further reading on that particular piece of code, you can take a look at the wikipedia article on it: http://en.wikipedia.org/wiki/Erase-remove_idiom In general though, I'd certainly recommend Scott Meyer's series of Effective C++ / Effective STL books to learn more about the STL and what not.
You make a good point. Better use the Catholic Catechism as the corpus.
You're going to have to do a lot better than that if you want to join the [major leagues](http://tgceec.tumblr.com/). Those guys can generate gigabytes of error messages from a line or two. 
Niiiiice ;D
Have you tried to compile with clang? It gives me way nicer errors.
they aren't using boost
I'd definitely heard of that idiom before, but I haven't been able to use the STL at my job and my personal programming has been in different languages.
Effective C++ is great. All of Scott Meyers stuff is great. 
They didn't have to.
Lots of candidate expects # arguments, 3 provided ...scrolls to where candidate expects 3 arguments, 3 provided would be... /home/svenstaro/src/wt/src/Wt/Render/CssParser.C:26 Problem appears to originate there. What do you have there? operator()(A0 const&amp; a0 , A1 const&amp; a1 , A2 const&amp; a2) Maybe the syntax is wrong? Can't tell what's on line 26 of your source file though. Edit: Also appears to only want references. Perhaps you're passing in an rvalue and it doesn't like.
OP says boost errors 
Theres more than one error in this paste. The last few lines of each error should give you an indication of what the error is and where in your code the error initially came from. The first few hundred lines are just specifics so you can trace the propagation of the error.
Yeah - libraries are supposed to let you do more without having to write all the code yourself, so anyone using boost to help generate huge compiler error lists should really do better.
Templates, not even once.
Crazy__Eddie, Thanks for the feedback on the C++Now sessions. The culture at C++Now is very much one to encouraging questions, comments, and discussion during presentations. I understand that this can be off-putting to those that assume that the presenter is the smartest person in the room and that everyone else should just shut up and listen. I don't think Marshall would be offended by my saying that it is pretty tough to be the smartest person in the room at C++Now. As a matter of fact, I attended this session even though I'd seen Marshall give it before. I did this specifically because, from experience, I know that Marshall gets the best audiences and gets the best from them. In other words, I attended it specifically for the discussion (interruptions). I also attended Chandler's talk on ranges. I hadn't seen that talk in advance, but we had talked about it. Chandler let me know that he didn't think he had the complete answers to all the questions that he was going to raise in his talk. But he thought it was important that they be addressed and that we get a discussion going on them. He was hoping to get the audience in engaged in a lively discussion. I've spoken with both Marshall and Chandler about these talks after they gave them and neither complained about audience interruptions. Of course I didn't specifically ask about them because I think both speakers expected (and wanted) the audiences to act the way that they did. As for CppCon, I expect that it will have a very different culture regarding questions. This is for a number of reasons. One is that the rooms will be less intimate and the audience will be larger and more mainstream (about one in six will be a speaker as opposed to one in three at C++Now). Also the breakout rooms at CppCon will have standing microphones for audience members to line up for questions. I think these factors will result in a completely different culture about audience give-and-take at CppCon. I hope that you attend either C++Now or CppCon sometime and when you do, please introduce yourself. 
Not sure I understand some/most of it, but it's the internets, everyone has an opinion, even if not based on good understanding of the matter at hand. ðŸ˜‰ My reaction would be: *it does not matter*. Your clients don't observe any state so they don't care if the thing is const or not. I further don't like much that you connect constness with copying, as well with thread-safety (albeit thread safety vs. const should be ok in C++11). And if you want to avoid copying, how about forbidding it through your type interface?
Use clang instead of gcc and you'll have a readable error message.
And I thought making the typo "std::end" instead of "std::endl" with both &lt;iostream&gt; and &lt;iterator&gt; included was bad: http://ideone.com/u2ZGib Try it with gcc 4.7.x and with some preceding output operations, the typo blends in.
That brought it down to a readable 163K error [here](https://drive.google.com/file/d/0BxsvHVm7imYueHM5VG9sd2hIZFE/edit?usp=sharing).
Well I'm only trying to make [wt](https://github.com/kdeforche/wt) build with boost 1.56. Of course, I posted a [bug report](http://redmine.webtoolkit.eu/issues/3530) for upstream. If you can figure that one out and make the thing build, I think the author would be grateful.
&gt; 1. Write the assignment operator for a class that contains a char*. Oh it's easy. First let me replace that member with `std::unique_ptr&lt;char&gt;`, ... 
Exactly. If the goal is test technological aptitude, then you should test for idioms and best practices. The Standard contains many traps (undefined behavior...) but a handful of practices help steering clear of a good chunk of those traps.
Reasons this wouldn't be C: * The handle object can participate in resource management (for example: it can contain a shared_ptr to the sinks resources) * Function overloading * Use of exceptions for a cleaner API
You have exactly two questions in your post: &gt; So what do you think? Should f be a const member function? Constness of a class should be evaluated from that class alone, and maybe from the modules it accesses. Making the status of class members dependant on where the class will be used is bad software design and should be avoided. That and my previous comment together should answer your question. Considering this, I do not see the purpose of all the information which follows your actual question(s).
This! I work my daily 8-9 hour shift, maybe more if I'm trying to finish something, but that doesn't mean I'm not interested in bettering my code and myself. I'm well aware of burnout and have seen it a few times so I try to turn off the code brain when my shift is done and focus on other things in my life to help stay balanced.
Done.
On GCC, you can set `-fmax-errors=5` flag, so it will stop after 5 errors(there is a similiar flag for clang as well). For me, usually I can see the problem within the first 5 errors. There is no need for the compiler to keep on producing more errors.
You can do it with C with the cleanup attribute, although that syntax sure is disgusting. http://stackoverflow.com/questions/21383695/why-cleanup-attribute-of-gcc-clang-can-not-be-used-with-function-parameter
Modern C++ is fairly different than older styles. I would therefore recommend getting the Early Edition of 'Modern Effective C++' http://shop.oreilly.com/product/0636920033707.do 
I don't like connecting constness and copying because to my mind they serve different purposes conceptually. Constness is there to express intent of something not changing. That very loosely relates to copying and making the link stronger looks like juggling more balls at a time than necessary. &gt; Why would a desire to avoid copying have anything at all to do with whether it makes sense to copy. Well first off, in my experience, copying is forbidden in practice to avoid performance hit, first and foremost. As for "makes sense", quite frankly, that can be stretched. E.g a handle wrapper types aren't often copyable. But put some refcounting in and they can be. Otherwise, it really depends on who your clients are. If it's an API for "external" consumption, then forbidding copying isn't the best of ideas because not knowing clients means letting them to their devices more. However, I was under the impression that wasn't the case, that this was for internal consumption. And then, if the intent is to avoid copying (you said "which decreases latency in the copying of arrays of these sinks"), saying so with code is the simplest way. (That last sentence is by a long far the most relevant of what I had to say, the rest is quite pointless opinion weighing.)
With your attitude, you will not get far in life. Breaking down questions and being friendly are key essentials to getting a good answer. Looking at your comments, you are really lacking that skill and should work on it. It seems like you just made this thread to disagree with people's opinion. Anyway, I am not going to bother discussing with you anymore. I gave you the correct answer, but you seem to be offended or whatever and are not actually interested in getting help but rather in defending your own opinion and insult me. Use the advice I gave you or don't, that is your decision to make.
if you haven't heard of it, you should check out rust, it looks really promising.
&gt; check out rust, it **looks** really promising. I agree completely, it looks awesome. But it's not ready for prime time *just* yet.
As a fairly new developer, I'm surprised to hear Stroustrup remark that C++ was intended to be used alongside a scripting language. Although I know and use Python, I don't use the two together very often. I may have to have a look at my workflow.
idgaf C++ 4lyfe
templates are fine, but if someone starts talking about "nested" you should start running.
There are so many paradigms supported by the language. Is there a "best" approach to learn first, or do you need to spend 20 years learning everything to know when to use what? I think C++11, with only exceptional exceptions and strict rules against excessive metaprogramming might be the right approach to modem c++.
It makes a lot of sense. You have two points in a software complexity time line, for lack of a better phrase. On one end there is "hello world" and on the other end there's extremely complex software like operating systems or video games or mathematica, etc. In almost every scripting language, printing "hello world" out to the cmd/terminal is a one liner or so. In c++ it requires around 5 lines of boilerplate and boilerplate syntax around the words itself to even print them. "cout &lt;&lt;" text here\n"; " isn't really... Nice, or pretty, but it's very robust for more complex designs. High level scripting languages allow simple tasks to get done very quickly and with less effort. Super powerful and complex languages allow you to do incredible things with less effort than scripting languages. It's more "using the right tool for the job" than anything. You should use your bike to visit your friend down the street, and you should use your car to visit your other friend who lives 500km away, and you should use a plane to visit your friend who lives in a different country. You COULD use the plane for everything, but that'd be silly. You could use the bike for everything, also, but that's also silly. 
If you know C++ I don't think that the book will be worth it. It's a very good book, don't get me wrong. You should look for the C++ 14, lots of stuff that didn't go into C++ 11 will go into C++ 14 :)
The D programming language aims to be "what c++ should have been". It's also relatively mature as a language (unlike Rust). It's also designed by some of the most respected c++ gurus in the world.
I don't think he meant that he used them in the same program necessarily. Just that some tasks are good for big complex programs, and done are good for quick scripts.
Check out Boost.Python
That depends on what the char* is. You might be better off using `std::unique_ptr&lt;char[]&gt;` or `std::string`.
That's a hard thing to qualify; if my latest commit was the first to use auto, did we just adopt c++11? If we used boost smart pointers before and switched to std, does that really mean anything?
I like it! It reminds me of the [authentication plugin](https://metacpan.org/pod/Catalyst::Plugin::Authentication#NAME) for the Catalyst Perl web framework. It is quite versatile. Twitter, LDAP, DB, etc backends exist. Good APIs make use simple and versatile. =)
No, but if people try it now there's still opportunity to give feedback and shape it before it hits 1.0.
i myself was hoping that was "clay" but it wasnt moving very fast a few years back when i last looked at it...
i havent yet figured out what makes one exceptional. I think an exception should be thrown when an end user actually correctly uses a program as originally intended.
D rubs too many of us the wrong way. I had high hopes for it originally but it seemed to have piled in too many low level features, tons of keywords, way too much unnecessary emphasis on memory garbage collection, etc.
back when c++ was created what you had was shell programming, and thats what you had. perl didn't become widespread until later, python and ruby much later. i think thats part of the reason for the c++ abi problems, way back scripting languages didn't load and call libraries through an abi, they forked and exec'd subprograms and communicated via pipes.
one place where c++ has been failing for me...well not c++ but the c++ stdlib, has been the "you don't pay for it unless you use it". With highly threaded stuffs I was sometimes having unknown problems with performance and contention. It wasn't until I found mutrace that I was able to see locking contention issues for things I didn't need that had shoehorned into the c++ stdlib. I know its not a problem with the language itself but definitely shows some wrinkles.
uhh...i would say don't use boost but its better to be careful with it. It's not very portable, especially if you have to play with exotic platforms and compilers.
While I was in school this was absolutely railed into my head. Every course I took, the professors would explain something, introduce a new language, library, or whatever, and they would end it every time with "Use the right tool for the right job." I'm really surprised to not see that more often in the industry. A lot of developers get comfortable with their stack of technology and then want to apply it to everything. Not that it's really a super bad thing, but sometimes there's a better tool, and it's worth learning! It's just getting someone to pay for the learning, ha.
I became a much happier C++ developer when I started doing my internationalization, database, and front end handling in Python, while relying on C++ for all my computationally intensive algorithms. Using Cython to wrap a C++ library is surprisingly easy, highly recommend it for anyone who's interested in interacting with C++ code from Python.
Java? Was anyone actually thinking it was Java? Maybe Groovy or Clojure or something, but Java?
That "smaller cleaner language" won't have a GC.
Have you tried D? It seems to be an attempt at that. It comes with a GC, but you can turn it off.
Us? Speak for yourself.
Or `vector`, or... but the point is: don't mix technical matters (resource-handling) and functional matters (API etc...) in the same class; and when it comes to technical matters... well chances are that the classes you need already exist.
Me too, whereas if the candidate were to try and handle it with `new` and `delete` (or `new[]` and `delete[]`), I would check my head and surmise this guy would be introducing memory leaks (and crashes) left and right.
[**+Pat Le Cat**](https://plus.google.com/107319216683799590102) [_2014-08-13T19:43:00.867Z_](https://plus.google.com/107319216683799590102/posts/5PCNqHmnz35) &gt; &gt;Quick Announcement: On August 20th, 2014 at 12:30pm EST / 18:30 CET, the father of C++, **Bjarne Stroustrup** will be taking part on a live **Q&amp;A** via Google Hangout-On-Air that I will be moderating. The Q&amp;A session is open to anyone who wants to take part. The event is sponsored by this Google+ C++ Community, +Pearson Education and +InformIT. &gt; &gt;Event Details: &gt; &gt;- When: August 20th, 2014 at 12:30pm EST to 2:30pm EST &gt; &gt;- Where: Here. An event link will be placed to the Google Hangouts event. &gt; &gt;- Questions: Bjarne is open to answering live questions you have about C++ &gt; &gt;**Coding Oracle**: Bjarne is open to looking at selected, interesting problems of C++ code you have recently written or a problem that boggles you in particular. If interested, please send in a complete and compileable code-question with a max of 50 lines in total via [http://ideone.com/](http://ideone.com/) latest by 12:00pm EST on August 18th. Please do post the link to your code into this thread here. &gt; &gt;- Social: Feel free to share this post as much as you want, within any community you want. The more, the merrier! 8-) 
Just comes down to what you're most comfortable with, combined with how much interaction you're going to have between your scripting language and your C++ code. For me, 90% of my code is scripting stuff, and the amount of interaction I need to have with my C++ isn't massive, so I went with Python because I knew it better and could get things done quicker. If 90% of your code is C++ and you really just need some scripting interaction bolted on, it's hard to beat Lua regardless of how familiar you are with something else.
I guess 8 years later, Koenig's spot could be contested by e.g. Dave Abrahams (Boost co-founder, named exception guarantees), Howard Hinnant (man behind move semantics and libc++) or Stephan T. Lavavej (dozens of educational videos, couple of accepted Standard proposals).
For beginners, this is the best book available. http://www.amazon.com/Let-Us-Yashavant-P-Kanetkar/dp/8176561061/ref=sr_1_1?ie=UTF8&amp;qid=1408206526&amp;sr=8-1&amp;keywords=let+us+c%2B%2B Once you are comfortable you can buy C++ by Stroustrup.
He definitely is one of the most important people to C++, but adding yourself to the list is kind of awkward
&gt;Get rid of all the 7's in this vector&lt;int&gt;. void foo(std::vector&lt;int&gt;&amp; v) { v.clear(); } ;)
That's going to be impossible to quantify since most companies obviously don't release their code. Anecdotally I can say that any company that uses the latest visual studio will probably try to use it at least a little. 
I wish there was something like this but in the other direction and working under Android...
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Cargo cult programming**](https://en.wikipedia.org/wiki/Cargo%20cult%20programming): [](#sfw) --- &gt;__Cargo cult programming__ is a style of [computer programming](https://en.wikipedia.org/wiki/Computer_programming) characterized by the ritual inclusion of code or program structures that serve no real purpose. Cargo cult programming is typically symptomatic of a programmer not understanding either a bug they were attempting to solve or the apparent solution (compare [shotgun debugging](https://en.wikipedia.org/wiki/Shotgun_debugging), [deep magic](https://en.wikipedia.org/wiki/Deep_magic)). The term *cargo cult programmer* may apply when an unskilled or novice computer programmer (or one inexperienced with the problem at hand) [copies some program code](https://en.wikipedia.org/wiki/Copy_and_paste_programming) from one place and pastes it into another place, with little or no understanding of how the code works, or whether it is required in its new position. &gt;==== &gt;[**Image**](https://i.imgur.com/YDs1vHL.jpg) [^(i)](https://commons.wikimedia.org/wiki/File:JohnFrumCrossTanna1967.jpg) --- ^Interesting: [^Cargo ^cult](https://en.wikipedia.org/wiki/Cargo_cult) ^| [^Copy ^and ^paste ^programming](https://en.wikipedia.org/wiki/Copy_and_paste_programming) ^| [^Magic ^\(programming)](https://en.wikipedia.org/wiki/Magic_\(programming\)) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cjs5h2e) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cjs5h2e)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
&gt; but in the other direction and working under Android. You mean invoke Java (Dalvik) functionality from C++ apps on the Android platform? The other way round (invoke C++ libs from Dalvik bytecode apps) already - http://search.maven.org/#artifactdetails%7Corg.bytedeco.javacpp-presets%7Copencv%7C2.4.9-0.9%7Cjar .. android-arm and android-x86
I meant ranges as well, but at compile time. 
UTC: 17:30-19:30 Also: At least in Germany we currently have summertime, so don't get confused by CET vs. CEST.
Alexander Stepanov deserves more than just a side mention - we really build on his contribution, whithout which the C++ today would be something more like Java--. I'd put him between the first two (which I consider among the work titans that have kept C++ alive for all this time) and the last three (about which I have rather mixed opinions -- you can't deny their presence though)
minus infinity for your complaint... Boostcon is a gathering of top C++ experts and the fact that they will tear apart any fraud that tries to pretend to be a C++ expert is a good thing. Also less drastic actions are good because they ask cool questions. Also iirc STL and Scott Meyers have also interrupted people who have been plain wrong so it is not some trolls. :) Anyway long story short I love Boostcon how it is. 
How much of the standard library will be still usable without a GC and without producing memory leaks? 
nice, but people should stop using C++0x as a standard name. Feels weird to read that still in an blog entry in 2014.
looks good. dont stop!
I think the popcount bug is a red herring. If it's a 32 bit executable this doesn't seem crazy at all. The only way for a 32 bit processor to add a 64 bit number is to take 2 instructions to do it (hence twice as long). The fact that some of the compilers/processors can optimize the add to make it run at a super scaler rate is pretty impressive. If they are compiling this as 64bit I take back what I said. But the code includes a header file labeled x86. So I'm guessing not.
No. It's called "C++11" now. It's been three years since "C++0x" was a relevant name.
That's possibly the cutest mascot of any lib ever.
If you're going to use C++11 features you may as well just build it on top of std::function. 
Depends. Some signal/slot implementations want to support things like auto-deregistration, where a slot automatically gets deregistered from a signal on destruction. While `std::function` would have its place in such an implementation, it's not sufficient on its own.
Good intro to TMP.
It's 64-bit. See this assembly: lea 0x1(%rdx),%eax [Wikipedia:](http://en.wikipedia.org/wiki/X86#64-bit) " An R-prefix identifies the 64-bit registers (RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, RFLAGS, RIP)" x86intrin.h is also for x86-64 (which is a silly name, x64 is a much better name).
#####&amp;#009; ######&amp;#009; ####&amp;#009; Section 17. [**64-bit**](https://en.wikipedia.org/wiki/X86#64-bit) of article [**X86**](https://en.wikipedia.org/wiki/X86): [](#sfw) --- &gt;Starting with the [AMD Opteron](https://en.wikipedia.org/wiki/AMD_Opteron) processor, the x86 architecture extended the 32-bit registers into 64-bit registers in a way similar to how the 16 to 32-bit extension took place. An __R__-prefix identifies the 64-bit registers (RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, RFLAGS, RIP), and eight additional 64-bit general registers (R8-R15) were also introduced in the creation of [x86-64](https://en.wikipedia.org/wiki/X86-64). However, these extensions are only usable in 64-bit mode, which is one of the two modes only available in [long mode](https://en.wikipedia.org/wiki/Long_mode). The addressing modes were not dramatically changed from 32-bit mode, except that addressing was extended to 64 bits, virtual addresses are now sign extended to 64 bits (in order to disallow mode bits in virtual addresses), and other selector details were dramatically reduced. In addition, an addressing mode was added to allow memory references relative to RIP (the [instruction pointer](https://en.wikipedia.org/wiki/Instruction_pointer)), to ease the implementation of [position-independent code](https://en.wikipedia.org/wiki/Position-independent_code), used in shared libraries in some operating systems. &gt; --- ^Interesting: [^X86 ^virtualization](https://en.wikipedia.org/wiki/X86_virtualization) ^| [^X86 ^assembly ^language](https://en.wikipedia.org/wiki/X86_assembly_language) ^| [^IA-32](https://en.wikipedia.org/wiki/IA-32) ^| [^Intel ^80386](https://en.wikipedia.org/wiki/Intel_80386) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cjsx2kf) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cjsx2kf)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Something I thought about while tiresomely implementing all 12 variants of begin()/end() for a container class i was writing.
Something I thought about while tiresomely implementing all 12 variants of begin()/end() for a container class.
Cheers! Havn't stopped. Just been slow in getting to the next ones as I've been working 60+ hour weeks. Next few vids are laid out though so just need to record them!
Where can I learn more about modern TMP?
That's highly dependent on implementation and context of use. I'm comparing to what the article is using which is using virtual member functions.
Here's some feedback: use boost::program_options, instead.
Spot half of them here, at the first C++ (ANSI X3J16) technical meeting: [pic](http://www.softwarepreservation.org/projects/c_plus_plus/Initial%20meeting%20group%20portrait%201.jpg)
Roll-your-own concepts. Me gusta! 
It would be interesting to compile a list of the people with most accepted core and library feature proposals. Some people don't do videos, blogs, or books, they just work on the language. Lawrence Crowl ([762 hits](https://www.google.fi/search?q=Lawrence+Crowl+www.open-std.org%2Fjtc1%2Fsc22%2Fwg21%2Fdocs%2Fpapers%2F&amp;oq=Lawrence+Crowl+www.open-std.org%2Fjtc1%2Fsc22%2Fwg21%2Fdocs%2Fpapers%2F&amp;aqs=chrome..69i57.9088j0j4&amp;sourceid=chrome&amp;es_sm=93&amp;ie=UTF-8#q=Lawrence+Crowl+site%3Awww.open-std.org%2Fjtc1%2Fsc22%2Fwg21%2Fdocs%2Fpapers%2F)), Hans Boehm (346 hits), Beman Dawes (921 hits), etc .. 
Oh, jeeze, even worse, this is built on top boost::program_options. Now I just look like a jerk.
I had read Kanetkar ages ago, in college, and I could remember spotting many assumptions in his book (such as int = 32 bits, using borland routines like they were standard, etc). I don't believe that Kanetkar's introductory books are good for newbies because he seemed to make many erroneous assumptions.
I really need concepts in my life, hopefully the Technical Spec. will be released soon in the main GCC branch so we can start playing around with it. In the meantime, here is the paper on concepts: https://groups.google.com/a/isocpp.org/group/concepts/attach/df9a57cb574ae9f9/concepts-lite.pdf?part=4&amp;authuser=0, it is not a mess of formality like most technical papers.
Any particular posts on SO that you can recommend?
Thank you very much ;) I would appreciate a little feedback about library itself but I think being not a C++11 stuff it got a lot of downvotes.
Okay, that sounds reasonable. From an API point of view: * I'd prefer passing a function to oberon::Subcommand instead of manually checking afterwards, which removes the duplicate string. This removes flexibility, but it shouldn't be flexible to keep all applications similar. * oberon::SubcommandCollection::finaliseRegistrations() seems like you should rather just have them all within the ctor or call finalize() automatically, when passing on, or let finalize() return an object to be passed on.
Well, to be honest, being C++98 it's also not very attractive to me. The usage looks nice, though things like this Concurrency::Future&lt;float&gt; someValue = Concurrency::launchJob(calculateSomeValue, data); or Concurrency::Future&lt;void&gt; messagesFuture = Concurrency::concurrentFor(messages.begin(), messages.end(), addOK); could possibly be made a little nicer with C++11. I think you designed a nice API and from a quick glance you also took it upon yourself to take documentation serious. I like the library though I'm curious why you didn't rather design a modern high-level C++14-style multiprocessing library instead of a C++98 style one.
"= default" isn't smart enough for this. It's useful if you have a struct that has members that are movable (e.g. vector, string, unique_ptr) and doesn't need any logic in the destructor. struct Handle { Handle(int h) : h_(h) { } ~Handle() { /* destroy resource */ } // disallow copying Handle(Handle const &amp;) = delete; Handle &amp; operator=(Handle const &amp;) = delete; // ...but allow moving! Handle(Handle &amp;&amp;) = default; Handle &amp; operator=(Handle &amp;&amp;) = default; int h_ = 0; }; Basically, the problem here is that you are copying an int. After calling the move constructor, you still have 2 Handle structs with the same h_, and you are generally about to call the destructor on one of them. Ditto for the move assignment, but you also don't destroy the old resource. So unfortunately, you still need something like Handle(Handle &amp;&amp; that) : h_(that.h_) { that.h_ = 0; /*invalid handle*/ } Handle &amp; operator=(Handle that) { swap(that); return *this; } void swap(Handle&amp; that) { std::swap(h_, that.h_); }
argh, this is what I get for making up my examples on the spot! you're right of course, intrinsic types aren't movable. Generally one would follow the 'rule of zero' and let the aggregate members define what copy and move semantics are available. My example is only really relevant if the aggregate type (in this case int) were copyable _and_ movable, and you wanted to disable the copying but leave the moving behaviour as it was. So this would work: struct Handle { Handle(int h) : impl_(h) { } ~Handle() { /* destroy resource */ } // disallow copying Handle(Handle const &amp;) = delete; Handle &amp; operator=(Handle const &amp;) = delete; // ...but allow moving! Handle(Handle &amp;&amp;) = default; Handle &amp; operator=(Handle &amp;&amp;) = default; struct H { int h_ { 0 }; H(int i) : h_(i) { } H(H const &amp; h) : h_(h.h_) { std::cout &lt;&lt; "copying H\n"; } H(H &amp;&amp; h) { std::swap(h_, h.h_); std::cout &lt;&lt; "moving H\n"; } }; H impl_ = 0; }; But of course this is a less likely scenario, though it can still happen. What do you think? I should probably remove the example, because adding the clarifications I just mentioned might confuse the example too much... edit: thankyou for taking the time to read and post this by the way
hey thanks for the comment. yeah, I really just didnt want everything to be in one long list - my thinking on the matter was that these features allow you to leverage C++ to help you write more correct code - let the compiler do more work for you... I'll try to think of a better name... edit: changed!
A better idea would be to make Handle follow the rule of 5 (`= delete` is ok here, but `= default` is not), and then to use the rule of 0 for structs with a Handle as a member. At some point, you still need to define the copy/move operations if you do a custom resource handler, so it's better to handle all of that in the one class without trying to split the logic with inner classes. Your Handle class is a good way to show off `= delete`. A good way to show off `= default` would be for a struct that contains objects of several stl classes, or your Handle struct.
Also, some of your other examples were good. int calculated = [&amp;] { auto l = lock(); auto first = stage1(); auto second = stage2(); return combine(first, second); }(); // notice I invoke the lambda here! I quite like that compared to the old way: int calculated; // have to declare here, but not valid yet. { // create a scope for the lock auto l = lock(); auto first = stage1(); auto second = stage2(); calculated = combine(first, second); }
&gt; The auto keyword should be used wherever possible. Functions should be short and readable, so donâ€™t pollute your code with unneccessary type declarations! Curmudgeons often claim they prefer to see the type written with the declaration, but I think readability and maintainability trumps this. Yes, maintainability â€“ you want to be able to change return values, template signatures, class names and such, and auto adapts without complaint. Dismissing the people who don't agree with you as "curmudgeons" (?) is lame. And the reasons you give for using auto are some of the same reasons people give for not using auto, at least not using it "wherever possible".
I dislike his use of the lambda trick for non-const variables. The following is simpler and produces the same result: int calculated; { auto l = lock(); auto first = stage1(); auto second = stage2(); calculated = combine(first, second); } The lambda "trick" is, however, a nice way to initialize `const` variables, and I use it a lot for this purpose: const auto calculated = [&amp;] { // calculated is const! so you really need the lambda here! auto l = lock(); auto first = stage1(); auto second = stage2(); return combine(first, second); }(); IMO the simplest approach always win. The lambda is more complex than the scope, but simpler than using a function/functor. However if the lambda gets too complex or you want to reuse it in different functions refactoring into a function/functor is the way to go.
I was wondering the usefulness of that particular lambda trick. Or maybe I missunderstood? Can't you bypass that uninitialised state problem by adding your logic and temporary variables in new scope like this: int calculated; { auto l = lock(); auto first = stage1(); auto second = stage2(); calculated = combine(first, second); } Edit: ahh, /u/gnzlbg gave [good usecase](http://www.reddit.com/r/cpp/comments/2dvirt/new_c_idioms_i_use_every_day/cjtkr1m)!
I agree in that we should all be nicer to each other where possible, and that name-calling does not promote healthy discussion at all. On the other hand, when I hear people objecting to using auto it sounds similar to me to Java developers saying they don't need lambdas... I feel like perhaps the person hasn't really tried a language that features them yet, but wants to complain anyway. For a better elucidation of the point, check out this [Scott Meyers talk](http://vimeo.com/channels/ndc2014/97318797) where he covers the matter. In summary, he says to use auto always, except with brace init and when 'proxy types' rely on auto conversions. He lists many problems this avoids, one of the big ones being the danger of the programmer getting the type slightly wrong and ending up with crazy inefficient conversions occurring under the covers. I hope I didn't ruffle too many feathers anyway - I was perhaps being too cheeky
I figure the lambda trick will become pretty popular (I'm sure I've seen other people using it), because there are a lot of 'value' types that for safety reasons have const-only interfaces, or classes that for other reasons don't have an 'uninitialised' state. In general I just really really dislike uninitialised data, and was trying to explain that just before the code sample. Ill update the sample to use const - that certainly makes the intent much more obvious, thankyou! edit: I realised I wasnt clear - my implication was that perhaps this type of use of lambdas will become common enough that it is considered idiomatic... on further reflection though, the reason I like it is that I personally just dislike spreading logic around unnecessarily (unless it makes the code harder to read)
Good stuff, fills a need. Longer term, I think argument parsing should go into the language specification. There is an obvious mapping between command-line options and function parameters, and another between subcommands and functions. I should be able to write, //yes.cpp #include &lt;iostream&gt; #include &lt;string&gt; int main(const std::string s="y", bool help=false) { if (help) { std::cout &lt;&lt; "blah blah blah" &lt;&lt; std::endl; return 0; } for(;;) std::cout &lt;&lt; s &lt;&lt; std::endl; } and invoke it like so: ~$ yes --help blah blah blah or ~$ yes -- --help --help --help --help --help .... I don't imagine it's possible for this sort of scheme to cover everything you might want to use command-line args for (take `expr`, for example...), but it would do for most use-cases, and it would make the language both easier to learn and more useful in unix-alikes.
&gt; The auto keyword should be used wherever possible. Functions should be short and readable, so donâ€™t pollute your code with unneccessary type declarations! Because people need to read the code and understand what's going on, and the auto keyword forces whoever is reading the source code to rummage through the project tree to investigate which type is actually being used to that part of the code. I agree that the auto keyword is a nice feature, but readability-wise if you're not the compiler then what you get in conciseness you do pay in obscureness.
In my emacs, goto definition is one key press and another key press to go back, any capable editor can do this. if you really care about the type it doesn't seem like a lot of effort.
The other thing you can do here is make calculated const. In place lambda calls are really nice for complex initialization of const objects. Also, when refactoring, I have taken to replacing do-once loops with an in place lambda. Then just convert any break statements to returns and the code flow makes sense. 
How does hiding the type improve readability. "Well, this is a great variable. Of course, I have no idea what's stored in it nor any notion of how to use it." The argument that one can change type declaration of the returning function is just dangerous. Because it's not in the declaration that's the problem. It's in it's use. Changing the return type means that you change how the return type is subsequently used and it's not always caught by the compiler. **Not declaring types inhibits readability**. The correct solution is to have refactoring tools that allow you to change types deterministicly.
Isn't there lots of that stuff in boost that should work with C++98?
I use auto almost everywhere. At first i didn't like auto. But its quick to write, and its convenient when you change the name of a return type of some function ... then you dont have to change all the callers. One place I don't like auto is when learning a new library, or reading tutorials. I'd like to be beaten over the head with reminders what type everything is.
&gt; How does hiding the type improve readability. By removing redundant information, which is a pain in C++ especially when using nested types. Which is more readable - "std::vector&lt;T&gt;::iterator cursor = v1.begin()" or "auto cursor = v1.begin()" ? The type declaration here is redundant (Since it's obvious that ::begin() returns an iterator), on top of being irritatingly lengthy. I'm still undecided about any advice advocating excessive use of the 'auto' keyword (Also known as the 'AAA-Style'), but I think it's definitely worth some consideration when dealing with nested/dependent types or doing TMP.
| auto cursor = v1.begin() As someone who might have to maintain that code, I have no idea what begin() returns by looking at that line of code. Having to look for the function definition for *EVERY* return value because someone decided to heavily use "auto" will seriously slow anyone down. When you're look at a project that has millions of lines of code, you have to know what code does at a glance. Any look up just slows you down. leave the shortcuts and the typing speed improvements to your IDE... not your programming language. 
I think good naming is far more important than whether a particular variable has an explicit or implied type. Given this code: auto foo = bar(baz()); Would you only object to not knowing the type of `foo` / the return type of `bar`, or would you also object to not knowing the parameter type of `bar` / return type of `baz`? In my experience, people complain about the new auto feature, but don't mind unknown type names in situations the language has supported for a long time. If anything, the thing that makes my example unreadable is that I used terrible names. If instead my example was: auto isAdmin = HasAdministratorRole(GetCurrentUser()); or auto projection = ApplyProjectionMatrix(GetViewMatrix()); Is my code still equally unreadable? Would it really change much if auto was replaced with `bool` or `Matrix`? Would you also object to directly passing the result of one function to another? What if I did remove the auto and specified a type? Given: AccountBalance lastLoginTime = CheckBattery(Calculate1000thDigitOfPi()); Is this more or less readable than the above examples using auto? I've found that when good names are used throughout, knowing a particular type name doesn't help readability, and when the names are bad, not knowing a type name is the least of my problems.
&gt;&gt; auto cursor = v1.begin() &gt; As someone who might have to maintain that code, I have no idea what begin() returns by looking at that line of code. You also have no idea what v1 is by just looking at that single line of code. Is that a problem as well? Should you throw in a redundant cast just to make sure people only reading single lines of code know what is going on? ^(Edit: adding more context to quoted portion)
This page is still referring to old standard: https://isocpp.org/std/the-standard Download the January 2012 working draft (free). Except only for the final standards/reports, all C++ committee documents are freely publicly available, including all working drafts, many of which closely approximate the published standard. The January 2012 working draft contains the C++11 standard plus minor editorial changes. 
Do you mind listing your 'usual blogs'?
It's somewhat amusing that Python is making efforts to incorporate more strict typing, largely for readability, while in C++ auto is gaining traction, largely for it's simplicity.
&gt; In my emacs, goto definition is one key press How about your book, your code review system, or your web browser?
&gt; One place I don't like auto is when learning a new library, or reading tutorials. I'd like to be beaten over the head with reminders what type everything is. When looking at code you're unfamiliar with you dislike auto? That is a pretty good reason for not using it yourself when someone else may have to maintain your code. Initially I liked it a lot, but the more I think about it the more I think it causes the same issues I've had working on large, unfamiliar python codebases -- specifically the inability to know what type something is in order to actually use it.
And if the types of all the functions and variables inside that function are declard with auto? How far down should you have to go to learn the type of a variable you'd like to use? This is a common issue I have with large python codebases.
The "inline builder functions" breaks one of my personal rules of readability: avoid jumping down the abstraction ladder in a function. In the example, that means: put calculation from the lambda in a separate function. Another example: I have a function that finds an element in a container, then uses it to calculate something and returns a result. rettype calcwhatever(container c, other params) container::valuetype* goodone foreach (elem in c) if elem satisfies condition from params goodone = &amp;elem, break if element is null throw notfoundblahblah return retvalfrom(*goodone) Here, element finding code jumps down the abstraction ladder: it looks at container elements and does whatnot with them, thereby obscuring the intent. Readability-wise, I prefer this to be extracted out: containerelem getgoodone(container c, params) // loop or whatever here, find the good element or throw rettype calcwhatever(container c, other params) auto goodone = findgoodone(c, params) return retvalfrom(goodone) 
It's not really the same thing at all. Auto doesn't remove static typing, it just allows the compiler to infer the type where possible.
&gt; As someone who might have to maintain that code, I have no idea what begin() returns by looking at that line of code. No, that's only if you're playing dumb intentionally. Cursor is very likely an interator to the beginning of a container. If by any chance isn't, you can look the definition up. Also, consider this: type var = whatever; // x lines of code here vary = something else Would you ask people for, I dunno, a cast here, so that you see the type of var?
&gt; In my emacs, goto definition is one key press and another key press to go back Requiring specialized source code analyzer tools just to be able to read the code that's in front of you is the definition of code obscurity. And obscure code is bad code, desperately in need of refactoring.
&gt; And if the types of all the functions and variables inside that function are declard with auto? How far down should you have to go to learn the type of a variable you'd like to use? With the way `auto` is implemented, I don't believe that's a problem. Certainly it's not any more of a problem than the situation we have right now. Consider this code: v1.begin()-&gt;transform().operationA().operationB().operationC(); Someone unfamiliar with the code would have to look at the return types of every one of these methods in succession to determine the resulting type. Luckily, we have things like IDEs that can do all that work for us and tell us what the type is, so in practice it's not an issue. &gt; This is a common issue I have with large python codebases. Luckily, `auto` doesn't make C++ dynamically typed.
Bjarne Stroustrup has a FAQ about C++11 where he covers most new features quickly with examples: [C++11 Language Features](http://www.stroustrup.com/C++11FAQ.html#11) The other sections have links to papers/videos/books that will help you get up to speed: [C++11 FAQ](http://www.stroustrup.com/C++11FAQ.html#11) He also wrote a **quick** tour of C++11: [A Tour of C++](http://www.informit.com/store/tour-of-c-plus-plus-9780321958310) And of course a more detailed look at the language and the standard [The C++ Programming Language](http://www.stroustrup.com/4th.html) 
&gt; largely for readability Why do you say that? The recent proposal by Guido is targeted explicitly at type checking, not readability.
The rule of thumb I use from programming in other languages with type inference (Scala, Rust) is to use `auto` everywhere at first. As I work on it, I add explicit types anywhere I find I'm confused or I feel like it would significantly improve code clarity.
&gt; As someone who might have to maintain that code, I have no idea what begin() returns by looking at that line of code. You do if you see the declaration of v1 just above and if you've ever used an STL iterator before.
&gt; vary = something else &gt; Would you ask people for, I dunno, a cast here, so that you see the type of var? Since good programmers write short functions, any local declarations in functions are usually visible with a minimal amount of scrolling. auto defers the defers the responsibility on the maintainer rather than the writer. It's literally saving a little bit of typing for the sake of a lot of type definition searching. It's obfuscation. I could see the use of "auto" being banned from my company's best practices for such reasons. (I work in code bases that are millions of lines long for commercial products that are used by millions that requires rapid re-factoring and feature addition). 
A handy book might be [The C++ Standard Library: A Tutorial and Reference (2nd Edition)](http://www.amazon.com/The-Standard-Library-Tutorial-Reference/dp/0321623215/ref=sr_1_sc_1?ie=UTF8&amp;qid=1408388817&amp;sr=8-1-spell&amp;keywords=Nico+Josustis). As for something more visual experience I would recommend to watch [Going Native 2012](http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/) and [Going Native 2013](http://channel9.msdn.com/Events/GoingNative/2013) and maybe [C9 Lectures: Stephan T. Lavavej - Core C++](http://channel9.msdn.com/Series/C9-Lectures-Stephan-T-Lavavej-Core-C-) then [C9 Lectures: Stephan T Lavavej - Advanced STL](http://channel9.msdn.com/Series/C9-Lectures-Stephan-T-Lavavej-Advanced-STL). After you get a good understanding of new features will be good to read [Effective Modern C++: 42 Specific Ways to Improve Your Use of C++11 and C++14](http://shop.oreilly.com/product/0636920033707.do), to understand how and when to use them even better.
How do I know it's an STL iterator and not some other data structure with a "begin" function? Might be some custom thread initiator.
\#firstworldproblems
Thanks for the report. That page has been updated.
Like I said, you know *if* you know the type of v1, which I inferred from the original example to be "std::vector&lt;T&gt;".
Yay, more useful features that I can't use at work.
Thanks for the link! Since the standard is going to be updated more often, is there anything we can learn from other frequently updated major languages like C# or Java on communicating changes with developers? Do they do anything special?
Yeah I'm working for a large scientific collaboration and in 2012 we moved up from C++98 to whatever came out in 2010. It's so frustrating that I can't use all of C++11.
My only regret is that I will not be able to attend, having already blown my conference budget on C++Now 2014.
&gt; No, that's only if you're playing dumb intentionally. Cursor is **very likely** an interator See? You don't know. You assume you know, but actually you don't. And that's how bugs happen.
I wish I could suggest something else...
&gt; getting the type slightly wrong and ending up with crazy inefficient conversions occurring under the covers The classic example: std::map&lt;int,std::string&gt; myMap; // I prefer horrible var names // Setup myMap for(auto&amp; el : myMap) { std::cout &lt;&lt; "ID #" &lt;&lt; el.first &lt;&lt; " =&gt; " &lt;&lt; el.second &lt;&lt; std::endl; } So first we need to understand that in this for loop, the element is being picked from the member functions `begin()` and `end()` so if we were unfamiliar with how `std::map` works, we'd need to go look up the return type of `std::map&lt;A,B&gt;::begin()`. Ahh, it's a `std::map&lt;A,B&gt;::iterator`. Fantastic... Digging a bit more we see it's a `std::pair&lt;const A,B&gt;`. That wee little **const** there matters. If we do this, it gets copies all over the place: for(std::pair&lt;int,std::string&gt; el : myMap) { Note we had to drop the reference here. Instead, we could have for(const std::pair&lt;int,std::string&gt;&amp; el : myMap) { which would make sense for the application since we don't intend on modifying the elements. But it still copies every element in your map! In this case, however, the `std::pair&lt;const int,std::string&gt;` can't be converted to a `const std::pair&lt;int,std::string&gt;&amp;` so it is instead copied to a new `std::pair&lt;const int,std::string&gt;` which is a temporary. This temporary is then returned by const reference via the `el` variable in the loop. Now, how does `auto` help us here? The type of `auto` is reasonably deduced as `std::pair&lt;const int,std::string&gt;`. It means there is no copying involved when you go and iterate over the map. this is good, but at the same time you'd never learn that the elements in a `std::map&lt;A,B&gt;` are stored as `std::pair&lt;const A,B&gt;`. Meanwhile, what does C++98/03 have to offer us? Why, this: for(std::map&lt;int,std::string&gt;::iterator el=myMap.begin(), end=myMap.end(); el != end; ++el) { std::cout &lt;&lt; "ID #" &lt;&lt; el-&gt;first &lt;&lt; " =&gt; " &lt;&lt; el-&gt;second &lt;&lt; std::endl; } Ugly? Sure. Long? Yep. Does it copy each element? No. No it does not. In addition, it looks like an operation on a pointer (fundamentally it *is*), rather than a reference/object/value. As a side note, one could also write a generic iterator class for maps. In this case you may have something like this: for(MapIterator&lt;int,std::string&gt; el(myMap); el; ++el) { Which has pretty clean syntax, and seems to describe what you want to do. A simple version of this may be written as such: template&lt;typename A, typename B&gt; // Yes, it's limited to default allocator class MapIterator { typename std::map&lt;A,B&gt;::iterator it; std::map&lt;A,B&gt;&amp; source; public: MapIterator(std::map&lt;A,B&gt;&amp; m) : source(m), it(m.begin()) { } operator bool() const { return it != m.end(); } typename std::map&lt;A,B&gt;::iterator&amp; operator-&gt;() { return it; } MapIterator&lt;A,B&gt;&amp; operator++() { ++it; return *this; } }; (NB: You can write a `ConstMapIterator` class in a similar way, except you don't need to call `end()` to account for modifications to the underlying map, so in this case one simply stores two `const_iterator` objects as private fields, and changes this: `operator bool() const { return it != end; }` and `ConstMapIterator(const std::map&lt;A,B&gt;&amp; m) : it(m.begin(), end(m.end()) { }`.)
&gt; The recent proposal by Guido is targeted explicitly at type checking, not readability. [PEP 3107](http://legacy.python.org/dev/peps/pep-3107/) states quite clearly that one use case for function annotations is to serve as documentation for parameters and return values. That is quite clearly a readability motivation.
OTOH, if you are doing this in a relatively short function to start with then it may not be necessary to remove the variable names `l`, `first`, and `second` from the current scope with the brace trick. Thus for const variables, one could simply have this: auto l = lock(); auto first = stage1(); auto second = stage2(); const int calculated = combine(first,second); Though depending on if this is threaded or not, and if so, how, then this could work too: auto l = lock(); const int calculated = combine(stage1(),stage2()); TL;DR: Initialize const elements later...
I don't really buy the argument for not having to change calling code if you change the return type of a function. I'm suspicious of why you'd even want to. If you're going to make changes like that I'd expect you already carefully examined all of the existing use cases to make sure you're not introducing any bugs or inefficiencies. And at that point the actual effort required to type out the new return type should be nil by comparison.
Thanks for the terms! It's especially hard to look something up when you don't know what to call it (like initializer lists, I was looking for keywords like constructor arguments, and special constructor syntax).
I'm having a little trouble understanding exactly what it is you're trying to do. Perhaps something like: #include &lt;string&gt; using std::string; int main() { const int maxX = 10; const int maxY = 10; string tiles[maxX][maxY]; for (int x = 0; x &lt; maxX; ++x) { for (int y = 0; y &lt; maxY; ++y) { tiles[x][y] = someRandomThing(); } } return 0; } Also shoutout to /r/cpp_questions 
Changing names of types is common when writing new code. Types get extended, split, and a better more descriptive name is found, etc.
&gt; shit I've only barely scratched the surface on what C++~~11~~ has to offer. I'm falling behind. Welcome to the world of C++, where even after a lifetime of continuous research you still feel like a newbie.
That's great! Where can I find the latest draft though?
The C++11 standard was only published in August 2011 and compilers did took their time before they actually supported C++11. Subsequently, libraries and the entire C++ ecosystem had to wait for the compilers and then their developers had to invest their time and effort to migrate to the new standard. And that takes time. A lot of time. There are plenty of solid reasons why your 2011 project was founded on the infrastructure available in 2010.
The big win here is IMO that since lambdas allow you to do complex initialization of variables inline, this allows you to declare more things as const and have less uninitialized values. Before if you wanted to initialize a const variable and the logic behind the initialization was more complex than the ternary operator then you either had to split the logic into a new function, make your variable non-const, or make a non-const tmp variable that you use to initialize the const one. Lambdas solve all this problems here.
But then the lock has the same lifetime as calculated. I guess that the point of the OP was to avoid that.
Oh, the name. I misunderstood. I suppose that does cut down on the places you'd need to update it. Chances are I'm just going to be using find all+replace or some kind of refactor tool anyways though. /shrug.
&gt;With the way auto is implemented, I don't believe that's a problem. template&lt;class T&gt; auto baz(T t) -&gt; int { return 0; } template&lt;class T&gt; auto bar(T t) -&gt; decltype(baz(t)) { auto var = baz(t); ... return var; } template&lt;class T&gt; auto foo(T t) -&gt; decltype(bar(t)) { return bar(t); } What's the return type of `foo(1)`? You have to jump back three functions to find it. &gt; Someone unfamiliar with the code would have to look at the return types of every one of these methods in succession to determine the resulting type. I agree, but I would typically avoid writing code like that, just like I will avoid writing code like my example above. It's harder to understand. &gt;Luckily, we have things like IDEs that can do all that work for us and tell us what the type is, so in practice it's not an issue. Not everyone uses the same tools you do. `git show` with `less`, for example, is not going to have that capability. &gt; Luckily, auto doesn't make C++ dynamically typed. I was referring to the lack of specifically declared variable and return types, which auto allows you to do, see above example. Python being dynamically typed just makes it easier to exacerbate this problem. ------- All that said, I have been leaving out a big part of how I think about writing code, which /u/oracleoftroy brings up in http://www.reddit.com/r/cpp/comments/2dvirt/new_c_idioms_i_use_every_day/cjtqhdl I feel like we're largely talking about return types in a vacuum and ignoring variable and function naming, which can partially alleviate the issues I have, particularly in your example.
The Stephan T Lavavej videos are awesome.
Then I would like to suggest you grab a textbook and go through it yourself. It will really help you get the terms that may have not been covered in the class you took for one reason or another. You can try "C++ How To Program 9th edition" which covers c++11 as well. Some other books/authors highly recommended are: "Effective C++/More Effective C++/Modern Effective C++" by Scott Meyers and books/lectures by Herb Sutter. 
For point one I actually went on a long tangent trying to get the execution of a subcommand to be more integrated with the object itself. So instead of testing at the top level against the name of the subcommand, there would just be an execute() method on the subcommand class itself. This turned out to be more trouble than it was worth as you then need to configure the object with all of the objects, data etc it needs before being executed. I think registering a function would have similar issues and in the end doing a name match seemed the most straightforward way of achieving the goal. I got around the duplication of the name in my other apps by defining a class static constant defining the name of the subcommand in the defining class. finaliseRegistrations() is another interesting case. Basically I wanted the help subcommand to be generated for the user automatically as it rarely varies and this meant the help subcommand needed to know about all other subcommands. The upshot of this is that it has to be registered last and given all of the other subcommand names. I originally had the name for it as "addHelpSubcommand" but settled on finalise as registering more subcommands after adding the help breaks the help. So this is really about removing code duplication for users of the library around a help subcommand, which pretty much everyone wants.
When this happens, contact customer service at O'Reilly, they might give you credit for the discount difference.
Now lets see what we can all do, brilliant!
most IDEs make this a trivial task - often just hovering over the variable name...
That's very optimistic :)
oh, I was talking about the usual C++ gurus - Sutter, Meyers, isocpp, etc...
With C++14 Foo() can be defined like that too! :) auto Foo() {return 42;} It is trivial here, but may not always be.
My god, sometimes I think I'll never be comfortable in this language. There's in that many ways to loop over the elements in a map, and some of them are subtlety terrible in terms of cost/memory because of all those copies. Wow.
\#pragma not even once
Don't let the new and shiny turn your head. As excited as I am about CppCon, C++Now is a better conference for some people. Of course the best way to know for certain which is the better conference *for you* is go to both. ;-) I'll see you at one or both next year!
good point. Where I would want the concept of auto is in the other direction. For example if I had a date class that could be instantiated by passing a string to the constructor: new Date("12-25-2014") and a Holiday class that took a Date, I'd like to be able to automatically have the compiler call default constructors based on the input and the available types of constructors in the target class. So in that case Holiday Christmas14 = new Holiday("12-12-2014"); would return a valid Holiday instead of a compile error about Holiday has no constructor for type string. It could "auto"magically determine that although Holiday doesn't have a constructor for a string, it does for a Date, and Date does have a constructor for a string, and we have a string, so try to make a Date with the string and pass that to the constructor for Holiday. Does anything like this exist in C++11 or 14? 
This is what isocpp.org is for. The C++ users in /r/cpp try to communicate new things too.
Good thing C++14s features compliment C++11s so well!
&gt; The crux of my point is that taking away information doesn't improve readability. That's a judgement call, and I think it really depends on the code in question. In highly idiomatic code like iterators, the types become line noise. Which would you rather read, this? &gt; for(std::vector&lt;int&gt;::const_iterator it = xs.begin(); it != xs.end(); ++it) or this? &gt; for(auto it = xs.cbegin(); it != xs.cend(); ++it) or even this? &gt; for(const auto&amp; i : xs) They're all roughly equivalent, but I'd argue that the latter two are much easier to read and far less error-prone - particularly when the types get more complicated. `auto` can certainly be abused, I won't deny that. There are definitely times when explicit types enhance readability. But in cases where the type is redundant or obvious: &gt; std::shared_ptr&lt;SomeType&lt;SomeOtherType&gt;&gt; x = std::make_shared&lt;SomeType&lt;SomeOtherType&gt;&gt;&gt;(); &gt; &gt; vs &gt; &gt; auto x = std::make_shared&lt;SomeType&lt;SomeOtherType&gt;&gt;&gt;(); I feel like omitting the type is clearly superior for readability. And that's not even mentioning the *type-safety benefits* of `auto`, such as when implicit type conversions could take place by accident. I don't know about you, but I've seen code like this often: &gt; std::vector&lt;string&gt; v; &gt; int size = v.size(); Most compilers will silently allow it...but it will potentially incur an implicit narrowing conversion. The correct type is `std::vector&lt;string&gt;::size_type` (an unsigned int of pointer size), but `auto` would have protected the programmer from this kind of mistake. Herb Sutter wrote a [series](http://herbsutter.com/2013/06/07/gotw-92-solution-auto-variables-part-1/) of [GOTW](http://herbsutter.com/2013/06/13/gotw-93-solution-auto-variables-part-2/) [articles](http://herbsutter.com/2013/08/12/gotw-94-solution-aaa-style-almost-always-auto/) on this topic last year which defend the principle of "Almost Always Auto". He does a much better job than I could.
&gt; "Well, this is a great variable. Of course, I have no idea what's stored in it nor any notion of how to use it." if you have a variable and cannot tell from its name or context whats stored in it or how to use it, then yes that is indeed a problem
I thought we were trying to avoid implicit conversions like that, not allow more of them. Your example can very easily be contrived to have all sorts of issues -- what if Holiday also has a string constructor? What if Holiday can be constructed from multiple objects that all have a string constructor? What if it can be constructed from multiple objects in the same inheritance tree that all have a string constructor? It's better to eliminate these possibilities early at compile time rather than wait for the runtime to hit that specific case and throw. 
Honestly being able to use bools, references, or templates would be a huge step up. I feel like we're stuck in '95 here.
I hear you. Where I work we're stuck with a FLAG macro type (with TRUE and FALSE), pointers, and a pathological fear of templates.
That should be a tattoo.
Of course, but your logic brings you nowhere. By that logic, no function/class/... does what it says so you have to read/understand/debug the code before using it. By that logic, you have to understand anything down to the last bit, which ranges from extremely cost-ineffective to downright impossible, depending on the size of the code. tl;dr no matter how hard we try, software operates in a grey area.
I could suggest CppCon, C++ and Beyond, Meeting C++, The ACCU Conference, and C++Now, just to start.
I feel quite fortunate that I work for an independent dev house with the flexibility of moving onto new tech with minimal fussing about. Right now, basically I'm like, [aaaaw yis!!](http://share.gifyoutube.com/0oH.gif) 
The great thing about the newer C++ language features is that we are seeing some degree of simplification with the language syntax, which should be relatively easy to absorb... assuming you have some experience with C++03.
yeah I feel like I'm cheating when I use something like: for (auto&amp; it: someContainer) { it.something(); } Also, what do you have against protons, huh? I'll have you know that I'm nearly half protons and take offense to this.
Incredible! So you tell me that y is &lt;10 in C++1y!
It's not you, it's me. I'm made out of anti-protons. ;)
Well you may be interested in the [STAR Collaboration measurement of anti-helium](http://phys.org/news/2011-04-antihelium-physicists-nab-heaviest-antimatter.html).
&gt; &gt; &gt; By that logic, you have to understand anything down to the last bit If you read what I wrote you'll be aware that I'm referring to what types are actually being returned by a function. You don't need to understand anything down to the last bit to know which type is actually being returned by a function. If you read up on software development, you'll notice that clear and informative code is an indispensable feature. This is mentioned repeatedly in reference works such as [Code Complete](http://en.wikipedia.org/wiki/Code_Complete).
This is absolutely silly. The use of `auto` should be left to the coder's best judgment. Usually, it really is extremely trivial to see from context what the type is going to end up being. When it isn't, good programmers don't ban useful tools, but use their best judgment to write clear code.
&gt; &gt; &gt; The use of auto should be left to the coder's best judgment. Projects adopt coding guidelines to avoid the problem you're setting up: one coder's best judgement easily becomes the entire dev team's problem. If you ever read reference software engineering books such as Code Complete you'll notice that one of the most basic best practices in software engineering is writing code so that others can easily understand at first glance. Ever heard Knuth's comments on how writing code as cleverly as possible means you're not smart enough to debug it? This problem is compounded if the one writing clever code is not the same one having to debug it. So, why insist on the source of a multitude of problems?
&gt; one coder's best judgement easily becomes the entire dev team's problem. The way to handle that is to have a teachable moment with the team where the problem and its solutions are discussed, not to issue a fatwa. Code style guidelines have their purpose, but mostly to ensure things that are truly just a matter of style (naming conventions, indentation, bracket placement, etc.). `auto` is not a "source of a multitude of problems" â€” I doubt you have ever worked on a C++11 project large enough to even warrant that kind of statement. All of its problems are so far only theorised. Which doesn't mean they're invalid, but it does mean that the resistance towards it is overblown.
&gt; The way to handle that is to have a teachable moment The teachable moment already took place when the each member of the team was educated in basic software engineering practices right in their sophomore year courses, and again when the entire dev team has been briefed on the project's coding guidelines. Clever code is bad code. This is a widely known fact. Complaining that the problems caused by the code you perceived as being clever is somehow someone else's responsibility is a problem in on itself. Competent coders are clearly aware that they need to write code for other people to read and understand. Those who don't understand such a basic software engineering principle simply aren't qualified to participate in any collaborative software development work.
The way you initialise any class - via a constructor: template&lt;unsigned int dim&gt; class Foo { array&lt;float, dim&gt; data; public: Foo( const array&lt;float,dim&gt; &amp; a ) : data(a) {} }; int main(){ Foo &lt;3&gt; f( {0.0f, 1.0f, 2.0f } ); }
&gt; Ever heard Knuth's comments on how writing code as cleverly as possible means you're not smart enough to debug it? Brian Kernighan, actually.
I stand corrected. 
If by that you mean, "The simplest possible implementation of std::function is one virtual call", and, "People have been implementing it with one virtual call since it was first designed as boost::function", then yes. And by that, I mean, what are you smoking, it's been as good or better than a virtual call for a long time.
State of the art!
&gt;If you read what I wrote you'll be aware that I'm referring to what types are actually being returned by a function. I am aware of that. I merely extended your argument a tad further, because doing it shows it's downsides. &gt;you'll notice that clear and informative code is an indispensable feature tl;dr no matter how hard we try, software operates in a grey area. Compare e.g. std::vector&lt;mytype&gt;::const_iterator begin = v.begin(); and auto begin = v.begin(); Perhaps we should have a vote here as to which one is considered clear and informative. Or perhaps not, because by simply adding auto to the standard, C++ standard bodies and the community at large already decided. But hey, nobody is preventing you to have your, different, opinion. You are trying to make a "definitive" explanation/argument. But there is virtually no such thing at all when it comes to notions like "clear and informative". Note, finally, that I never said that "auto" should be used *everywhere*.
You do realize that you just accused the standard library implementations of being bad code? Because they sure as hell use "auto", right? You really need to come down.
Adding on to that, I typically like to typedef templated classes, so I can change the type at any time I want. i.e. template&lt;unsigned int dim&gt; class Foo { typedef array&lt;float, dim&gt; impl_data impl_data data; public: Foo( cost impl_data&amp; a ) : data(a) {} }; Also, if you are just referencing the data, then don't use a std::array. Use a pointer to the data, with the size; or more conveniently an [array_view](https://github.com/rhysd/array_view).
I prefer not to use compiler specific features in my tattoos. 
The virtual function call for `boost::function`'s type erasure is *in addition* to the virtual or indirect call on the passed function pointer (if it's wrapping a function pointer).
And keep in mind: Qt Creator is an excellent IDE even if you're not building Qt programs.
Where is the review? :S 
And - much more importantly in my opinion - you're also communicating to the compiler what type you expect an expression to be. That let's it give you a nice helpful error message when you get it wrong, rather than wait till runtime to discover your value is not what you expected it to be.
Would you be so kind to report all the issues you have here: https://bugreports.qt-project.org/browse/QTCREATORBUG ? This way the Qt Creator guys will know what the users are missing :)
Those issues were already reported years ago.. https://bugreports.qt-project.org/browse/QTCREATORBUG-8967 https://bugreports.qt-project.org/browse/QTCREATORBUG-6438 I can get away with the lack of support of C++11 literals for now (eclipse doesn't support that neither) but the lack of code assist for STL is a deal breaker to me. I really hope that this improves soon so I can jump ship from eclipse.
Still no proper code completion after you go through one layer of STL? Ugh. (How is their attempt to incorporate Clang for code completion going?)
Could be worse. Most Fortran compilers still don't support all of F2003.
I've tried to compile your example but the compiler throws a bunch of errors. Here's the code: #include &lt;array&gt; template&lt;unsigned int dim&gt; class Foo { std::array&lt;float, dim&gt; data; public: Foo( const std::array&lt;float,dim&gt; &amp; a ) : data(a) {} }; int main() { Foo &lt;3&gt; f( {0.0f, 1.0f, 2.0f } ); return 0; } Here's the compiler output: $ g++ --version g++ (Debian 4.7.2-5) 4.7.2 Copyright (C) 2012 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. $ g++ -Wall -std=c++11 main.c++ main.c++: In function â€˜int main()â€™: main.c++:14:33: error: no matching function for call to â€˜Foo&lt;3u&gt;::Foo(&lt;brace-enclosed initializer list&gt;)â€™ main.c++:14:33: note: candidates are: main.c++:9:2: note: Foo&lt;dim&gt;::Foo(const std::array&lt;float, dim&gt;&amp;) [with unsigned int dim = 3u] main.c++:9:2: note: no known conversion for argument 1 from â€˜&lt;brace-enclosed initializer list&gt;â€™ to â€˜const std::array&lt;float, 3ul&gt;&amp;â€™ main.c++:5:7: note: constexpr Foo&lt;3u&gt;::Foo(const Foo&lt;3u&gt;&amp;) main.c++:5:7: note: no known conversion for argument 1 from â€˜&lt;brace-enclosed initializer list&gt;â€™ to â€˜const Foo&lt;3u&gt;&amp;â€™ main.c++:5:7: note: constexpr Foo&lt;3u&gt;::Foo(Foo&lt;3u&gt;&amp;&amp;) main.c++:5:7: note: no known conversion for argument 1 from â€˜&lt;brace-enclosed initializer list&gt;â€™ to â€˜Foo&lt;3u&gt;&amp;&amp;â€™ make: *** [main] Error 1 
Before reading your comment here I purchased Programming: Principles and Practice Using C++ (2nd Edition) by Stroustrup. Will be here on Wednesday. Looks like it starts at the very beginning and ends in discussions of GUI building and embedded programming. I'm hoping that this will be a good aide in getting to terms with C++11. Though I've now been told that the professor for the class will likely not use the --std=C++11 compiler flag for grading (which frustrates me because the code in the book doesn't compile without it... which makes it seem like there's no point to having the book.) I plan to learn the 11/14 syntax anyhow, even if I'm not allowed to use it. After watching the keynote for go native I feel like its probably going to be what people in the industry will want anyhow.
How can we apply pressure here? I can think of these: 1. Add more votes and people to the "Watch" list for these bugs. 2. Open duplicate bugs 3. Get paying enterprise license owners to use their support hours on these bugs 
Just compile it conditionally.
They really do indeed. When I first started using C++11 and then ended up having to go back to C++03 I said to myself, "How the fuck did I ever live like this??" Since C++14 has been available in clang I've said the same thing about C++11. Just the auto lambdas alone improve things by leaps and bounds.
So long as you're not relying on a compiler vendor that has still to release a complete C++11 compiler...like a great number of people are.
At least you actually moved to the 2010 standard library I assume. I mean, why would you assume otherwise right? We moved to 2010 but have been using STLPort for years and so are stuck not only with a C++03 std library, but one that didn't even implement it correctly. I've taken to writing a lot of the fundamental functions that are needed to write C++11 code, such as move and forward. It's kinda sad...and more than a little frustrating. I agree with the decision though unfortunately. Based on where we are and how we do things, switching to a modern implementation that doesn't implement all the extra crap that stlport did would not be in the company's best financial interests.
std::for_each(someContainer.cbegin(), someContainer.cend(), std::bind(&amp;Element::something, std::placeholders::_1)); c++ &lt;3
2 would more annoy the developers than bring the issue into the spotlight.
C++ has allowed implicit conversion via non-explicit constructors for a long time, though it is generally frowned upon without a very well thought out argument for a particular type. (Implicit constructors by default is one of my biggest peeves about C++.) For your example, it seems odd that a holiday is constructable from any random string, and I don't think the trouble the implicit conversion gives you is worth saving a few characters. A better solution might be leveraging C++11 [user defined literals](http://en.cppreference.com/w/cpp/language/user_literal) to continue to require explicit construction, but streamline examples like yours. It looks like C++14 adds predefined user literals for [std::chrono::duration](http://en.cppreference.com/w/cpp/chrono/duration), though I couldn't find anything for time_point, so you'd have to build it. Since your example looks like C# or Java, it might be worth pointing out that the C++ declaration would already be fairly compact, so that's another consideration if the goal is to save on typing: // Java or C# Holiday h = new Holiday(new Date("2014-12-25")); // C# only var h = new Holiday(new Date("2014-12-25")); // C++98 Holiday h(Date("2014-12-25")); 
Microsoft hasn't sent representatives to WG14 in years (happened soon after I joined VC in Jan 2007; I think it's been at least 5 years).
&gt; Please note, it's not an error You're absolutely right. I should've paid more attention to the output. On a side note, I've just tried to compile your example with g++ 4.9 and no compiler is thrown. Thanks for the help!
&gt; Microsoft hasn't sent representatives to WG14 in years I don't know what you tried to say. Meanwhile, I can point out [this 2 year old discussion in /r/programming regarding a public statement made by Herb Sutter, one of Microsoft's handymen on the C standardization committee, regarding Microsoft's stance on the C standard](http://www.reddit.com/r/programming/comments/t6m71/herb_sutter_no_c99_support_is_planned_use_c/). You may notice the part where Microsoft's chief developer and platform evangelist states that Microsoft has no intention to support any C standard beyond C90.
It's weird that that page refers to the standard as an international treaty and a 'legal' document. ISO is a [private, voluntary organization](http://www.iso.org/iso/home/about.htm) (and the US representative, ANSI, is also a [private, non-profit organization](http://www.ansi.org/about_ansi/overview/overview.aspx?menuid=1)) and the standard is not a treaty (e.g., it doesn't get ratified by congress in the US).
Still no support for make projects? à² _à² 
Can you use it as a library or does it require your to use it as a standalone server?
I tried to keep the review short. I am still working on improving my writing though. I also included a look at the Table of Contents for the book in the review, because I couldn't find the ToC listed anywhere else.
I usually use it with Qt, but whenever I try to use something not-bundled, like the Windows clang version, stuff breaks. Like creating compiler settings and assigning them, but creator just ignored whatever i did and kept using gcc. I eventually just gave up...
https://github.com/Valloric/ycmd#backwards-compatibility That seems to indicate that the internal/non-server API will change and is not recommended for use.
It's designed to be a separate server. The author did testing showing negligible performance impact. Having it isolated also provides stability and concurrence benefits. It can work while the UI updates and it can't bring the editor down.
Since we talk about vim completion plugins built on top of clang I'd also suggest looking at the implementation of [clang-complete](https://github.com/Rip-Rip/clang_complete/tree/master/plugin). It showcases how to drive completion via the libclang Python bindings.
WG14 is the C Standardization Committee (WG21 is C++, convened by Herb).
 if dim is a variable of type unsigned it,why declaring it through the template? why not declaring data as simply "std::array&lt;float,unsigned int&gt; data" ?
I would like to know how to get completion to work when creating a project using the "Import Existing Project" option. Currently I can enable partial completion for STL when adding these lines to the project.config file: #define _GLIBCXX_BEGIN_NAMESPACE(name) namespace name { #define _GLIBCXX_END_NAMESPACE } #define _GLIBCXX_BEGIN_NAMESPACE_CONTAINER #define _GLIBCXX_END_NAMESPACE_CONTAINER #define _GLIBCXX_END_NAMESPACE_VERSION #define _GLIBCXX_BEGIN_NAMESPACE_VERSION #define __glibcxx_function_requires(...) #define __try try #define __catch catch #define __cplusplus 999999L I also need to add the include path for the C++ headers to the project.includes file: /usr/include/c++/4.8 /usr/lib/gcc/x86_64-linux-gnu/4.8/include However, this is a hackish way of doing things. Does anyone know a cleaner way to do it? 
That book was not available yet when my class started and they recommended the other book meanwhile. Like you said, learn how to do it in both C++0x and c++11/14 and you'll be good.
What? It's had support for make projects for as long as I can remember.
I think it should be included in the 3.2 version as an optional switch. I thought that they're as far as shipping it, as a kind of beta / optional thing. Actually I thought it was already in 3.1 as an experimental feature, so I'm pretty sure it is included in 3.2. Check the options! :-)
And CMake as well. Works quite well.
I would agree, but just now I remembered that I got my introduction to C++ from Koenig's book *Accelerated C++*. That was back in 2004. I still remember being impressed by the elegance of examples from std algorithms library. I feel very thankful for that.
It's very very annoying that there is no code completion with std::unique_ptr. Weird, code completion works with my home-made smart pointers, but not STL... 
Great!! C++14 is officially finalized now? :D I'm really looking forward to switching over to using C++14 (can't yet, since we use g++4.7 at work), as it seems to be a polishing of the new features made in C++11. In particular, I'm super excited about the [[deprecated]] attribute. Our codebase has a fair amount of stuff that is deprecated but is not marked appropriately. I know there were such attributes that were compilers specific before, but that was precisely the issue: compiler specific. So, this feature will be a very welcome addition. :D Perhaps I'm not as excited as I should be with the extension of the "auto" keyword, but this is something which I don't really use much of when developing (I use it extensively with range based for loops but that's about it). The new templating features are pretty exciting though.
Thank you, that article will fit nicely in my bookmarks next to [this one](http://stackoverflow.com/questions/7194127/). My issue with allocators is that I find the documentation too noisy (for writing one,) and so I appreciate the code examples you've included. Lately I've been frequently using [intrusive containers](http://www.boost.org/doc/libs/1_56_0/doc/html/intrusive/intrusive_vs_nontrusive.html#intrusive.intrusive_vs_nontrusive.properties_of_intrusive), and since memory management is external to the container, I've found it to be more simple to get started with custom memory allocators.
4\. Fix the bug yourself. (It is free software after all) 5\. Pay an 3rd party company to do it
&gt; You should also be aware that iterators don't exist only in the STL. There are plenty of implementations out there, and even Boost provides a bunch of different iterator types. Yes. I know. &gt; Maybe you never used iterators beyond the default STL ones, but that doesn't mean obscuring code becomes a good practice. The iterator pattern is a well-known construct, but the point is that even if your particular iterator doesn't, you'll still get a compiler error telling you that you messed up. It's just not a big deal in practice. &gt; When you gain more experience, particularly in collaborative projects, I believe you will start to see the value in writing clear code. Give it a bit of time and you'll come to see it. Oh hey there Condescension Man. &gt; The thing is, if you insist in writing obscure code then sooner or later it will come around to bite you. `auto` does not obscure code unless you really make the effort to make it so. 
I find QtCreator works really well and even finds all compilers installed on my system.
I found clang on windows to be a tedious exercise in environment management anyways, so I am not entirely surprised that QtCreator had trouble with it. I was able to get it working using one of the more recent releases, so maybe have another go?
I'm hopeful that some form of polymorphic allocators will make it into C++17. It's currently a real hassle to intermix objects that differ only in the way they allocate memory, which is arguably an implementation detail. The option to type-erase the particular allocator used by an object would be a real win in a lot of code I have written. In particular, the 80/20 rule seems to apply to allocations: 80% of the allocation is done by 20% of the code. If you could drop in one or more custom allocators into that 20% without altering types, the performance benefit could be substantial with minimal work. Replacing a call to malloc() with a vtable lookup and a pointer increment is an orders-of-magnitude kind of improvement. The most current proposal I'm aware of is [N3726](http://isocpp.org/blog/2013/09/new-paper-n3726-polymorphic-memory-resources-a-revision-of-n3525-polymorphi). It's a little awkward in its current incarnation, proposing a wholesale replication of the current std types into versions in a new namespace supporting 'polymorphic memory resources'.
&gt;The most current proposal I'm aware of is N3726. It's a little awkward in its current incarnation, proposing a wholesale replication of the current std types into versions in a new namespace supporting 'polymorphic memory resources'. Aren't these just template aliases? The proposal defines the container types in the std::pmr::\* namespace as aliases of the usual std::\* containers, where e.g. std::pmr::vector&lt;T&gt; would be equivalent to std::vector&lt;T,std::polymorphic_allocator&lt;T&gt;&gt;.
Yeah, re-reading the proposal it's not so bad. I'm not sure that convenience is really necessary. I'd be happy to using my_vec&lt;T&gt; = std::vector&lt;T, std::polymorphic_allocator&lt;T&gt;&gt;; myself, though I can see the benefit in standard names. 
Indeed, It is perfect for arduino development too! (https://github.com/hrobeers/qtcreator-arduino) Way better than the official arduino IDE.
They are in the LFTS. I would expect polymorphic memory resources to land before c++17. I also have a implementation for libc++ that should be ready for review in a week or two. 
I agree, but for some people is too heavy or it adds too much compile time. Anyway my goal was also to make a library with the minimum dependencies possible.
&gt;auto x = uint64_t{10} ; &gt; &gt;auto y = int32_t{15} ; *What the fuck.* 
I've unfortunately been burned more than I thought I would be by the overuse of auto. The article mentions: &gt;Who cares what the types are? You should be coding to interfaces rather than exact types. Okay, I agree with this wholeheartedly, but what is auto's interface? auto is basically the void* of type inference, giving you no information about what you can do with the type. So if you're someone who wishes to read a snippet of code and then potentially modify it, you can't tell what operations you are able to legally perform on the variable, auto has erased all of that information. I've heard a great proposal that unifies Concepts and type inference that I hope gets accepted into the standard, which is being able to use Concepts to enforce that an expression produces a value that satisfies a certain interface. So if you have some "Iterator" Concept you can write code like this: Iterator i = SomeExpression(); That line basically says that it will infer the exact type of i, but what it infers must satisfy the Iterator concept. This conveys information to any potential reader or modifier of the code that i supports various iterator operations (++, --, ...) which I think is vastly superior to: auto i = SomeExpression(); Which conveys absolutely nothing about what i's interface is, what i is expected to be, or anything really. On a more minor, stylistic note, using auto often introduces some ugliness because it can't always be used to declare a variable. Consider a type X that has no copy or move constructor, you end up with some stylistic awkwardness such as: auto a = 5; auto b = string{"hello"}; X c(12); auto d = vector{{1, 2, 3}}; It would be nice to be able to do: auto c = X(12); But C++ treats that semantically as a move operation, and X has no move constructor.
&gt; Who cares what types are? You should be coding to interfaces rather than exact types. C++ cares, a lot. And in the case of a statically typed languages the type is just as much part of the interface as anything else. Things like auto and templates are hacked on top to (seemingly) simulate a dynamically typed language. I do use and enjoy those features, but they feel inconsistent. If you want a dynamic language then use one, and if you want a statically typed one then you should care for your types. C++ is the 800 pound language that seems like it can't decide quite what it wants to be. edit: I messed up the quote markup
It's not awesome. It's a slight improvement. There's no need to get over-excited.
`char x = 300;` compiles despite being nonsense, while `auto x = char{300}` is a compilation error.
 uint64_t x{10}; also prevents narrowing, without theâ€¦ unusual syntactic choices.
The idea behind auto is to eliminate redundant types. If the type isn't obvious then you should explicitly say it. The only exception is when the actual type isn't interesting, the most common example being iterators. You know it is an iterator of something from the syntax and often know the something, explicitly writing out the entire type is wasted space.
Um... Qt5 Font Anti-Aliasing is broken on Linux for long time. A lot of watchers and duplicated bugs, but still... As shows practice there is only one way to fix bug in Qt - send a patch.
&gt; Things like auto and templates are hacked on top to (seemingly) simulate a dynamically typed language Wrong. auto is a form of type deduction, which in turn is a subset of type inference. Type inference is in no way exclusive to dynamic typing. See Haskell for a language with static typing and tons of type inference. 
Ok, I got carried away there. I still think the article is wrong in saying there's no sense worrying about types, just code to the interface. Types are part of the interface.
But all this says is use better function/class/variable names. That is, write self-documenting code. Which is nothing new and something you *should* have been doing for years.
Type inference and auto sounds really neat. My initial thought re syntax was something like `auto&lt;Iterator&gt; it = c.begin()` etc. Though I am unclear how this could all tie into the language now. 
To clarify, it prevents accidental implicit narrowing conversions. Herb Sutter discusses this in [GOTW 94](http://herbsutter.com/2013/08/12/gotw-94-solution-aaa-style-almost-always-auto/): &gt; **Guideline:** Consider declaring local variables `auto x = type{ expr };` when you do want to explicitly commit to a type. It is self-documenting to show that the code is explicitly requesting a conversion, it guarantees the variable will be initialized, and it wonâ€™t allow an accidental implicit narrowing conversion. Only when you do want explicit narrowing, use `( )` instead of `{ }`.
`auto` also prevents you from forgetting to initialize the variable.
Sprinkling `auto` all over the place liberally can be reckless. It should be used inside a very narrow block scope, where the relationship between the `auto` variable declaration and the function that is used for type deduction is well established. I dare say that most STL functions and objects that return things should be assigned to `auto` local variables. A competent C++ programmer will know what `std::vector&lt;T&gt;::begin();` returns and what the underlying type could be, because STL is well documented in the public arena. If you roll your own poorly documented library, you might want to be more direct about declaring variables that accept values from your library functions. In other words, write self documenting code for obscure functionality, and it is okay to use abstract syntactic sugar for well known functionality, such as STL. 
IOSTREAMS MUST DIE.
If I understood correctly you have to buy it to get access to the draft. Would be nice if someone uploaded it and posted the link.
All I really want is to hide the implementation of a class so the header is only public stuff. Objective-C and C can do this. I have to use ugly PIMPL for C++.
No it wouldn't. His books are worth the money.
Just for the sake of curiosity, the need to be backwards compatible is what I'd change. I'm pretty curious to see what would happen in that case. 
What would be your recommended replacement?
Fantastic. I've been waiting for this. Can't wait to give it a read.
could a printf analog work with sockets, compressed files, memory mapped files, write to multiple sinks, etc?
Yes, why wouldn't it be able to? You just need a generic byte i/o protocol that it'd be implemented on top of.
Still waiting for #include to get tossed.
Also remove implicit conversions from larger integers to smaller.
Add positional params to the list It's pretty much annoying to provide localizated applications when the translator doesn't have the ability to reorder the arguments. "I can {2} the {1}", arguments, reorder
Just like you have to buy it to get access to the final version. If you buy now you get the final at no additional cost to you. If you want it, just buy it. You're almost guaranteed to find a coupon code to knock the price down. But really, it's worth the money.
I sort of expected 'header-only' to not mean having boost as well. Maybe that's just me expecting header-only libraries to be entirely self-containing.
Something like http://cppformat.github.io/
I love auto and use it a lot. However, sometimes I feel like using auto is equivalent to saying "Yes, I dare to write this piece of code without any help from the IDE in terms of auto-completion". Even when I know the type of the variable being deduced, I oftentimes forget what its member functions/variables and parameters were called and end up having to open up the corresponding header file (manually of course, because the IDE can't help you...). What's really missing is an IDE deducing the auto-ed types and showing them (maybe somehow floating above the auto declaration or something).
Seems like the interview has been poorly transcribed. I also suspect the editor has added some parenthetical remarks to what Bjarne was saying. Example of both: &gt; Java is an example it has more than trebled in size (the specification of the Java7 language definition is within 5% of that of C++11). I feel that if it were Bjarne who felt the need to bring that up, he would have been abundantly clear that this is only the case with the core language specification. The library specification is where the size difference pops up.
make it D without its current gc predicament
This is awesome. I've got bits and pieces of itertools littered all over my c++ projects, it's great to have them all available (and all from one place).
Maybe we can use the fact that you can't pass non-primitive value types to vararg functions. Make it so that when the compiler sees that you are passing a value type to a vararg function, it instead pass the result of a std::to_string() function to the vargarg function. Example: void my_function() { MyClass my_object(10); std::formatted_print( "The value for MyClass is {1}\n", my_object /* replaced at compile time with std::to_string(my_object).c_str() */ ); } 
Module and make the concept/model of dynamic library (dll/so/dso) a part of the language.
For me I pretty much want a variant of (GHC) Haskell with C++ semantics (strict by default, unboxed types by default, monomorphization of parametric types like with templates, optional GC) I'd be willing to sacrifice a few features just for that. 
QtCreator is nice but the fact that by default its navigator thingie shows only files that are added to projects is baffling. I can understand hiding the file tree in applications meant for end users but not for developers who deal with files all day long. Eclipse got this one right. I wish QtC would do as well.
I'd like all preconditions (like the one of std::vector::operator[]) to be officially enforced with an assert-like feature (STD_CONTRACT_ASSERT from [n4075](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4075.pdf) would have been nice, but it has been rejected). Checked STL are nice, but this is not standardized.
Ditch the preprocessor as much as possible, i.e. no macros&amp;includes. Only defines from the command line should stay for conditional compilation but nothing else. Any functionality that "goes missing" because of the lack of preprocessor should be added back as core language features. For example stringify-ing variable names should be made possible by static reflection. 
It would be a terrible idea. If you loop over a vector, you would pay twice for the bounds check: once for the `i &lt; N` or `it != end` and once in the `v[i]` or `*it` expression. Performance matters. Oh, and there is `std::vector::at()` if you insist on bounds checking.
Make â€˜const' the default. Use â€˜mutableâ€™ to override; not just for membersâ€¦
I recently added support for this to my [formatting library](http://adityaramesh.com/ccbase/format.html); perhaps this would be of interest to you.
In no particular order: * remove the file include model. Use import. * remove casts. If you need to use casts, you may need to redesign your program. At least, allow casts only with a compiler flag. * remove automatic conversions of any kind, unelss a compiler flag is specified. * remove primitive types. Make all types to be classes, and have a set of them match hardware types. * remove diamond inheritance. Make it an error. * Make the grammar context-free in order to allow better tools to be created. * add compile-time reflection. It's super useful for many abstractions. * fix the module initialization order. * make dangerous features like raw pointers and raw arrays not usable unless explicitly requested via compiler flag. * put safety first, performance second. I.e. have array index operators do bounds checking by default, unless a compiler flag is specified. * make every pointer a shared one by default. Have the compiler check for type shared pointer cycles at compile time and reject those types that introduce cycles. * remove all dangerous C features (printf, getfs, scanf, etc), unless a compiler flag is specified. * allow the programmer to override how messages are delivered to objects. It's not always vtables that we need. * remove the struct keyword. * remove the Turing completeness of the template type system; i.e. do not allow template specializations. Allow template overloads, like methods/functions can be statically overloaded. * provide proper string support for ascii and unicode strings. * remove the concept of a standard library and create an online repository of libraries that the programmers can choose from / submit to. Provide the standard library as a set of individually downloaded components from this repository. * allow classes to overload operator '.'. * allow references to types / functions defined later in a program. No need for forward references. * make operator delete/new type-aware. I.e. the type of the object to be allocated should be passed to those operators. * remove operator new[] and delete[]. Make arrays types. I.e. operator T::new[] doesn't allocate a bunch of Ts with an integer stuffed in front of it that contains the array's length, but an instance of array&lt;T, length&gt;. * make arrays value types and not reference types, in order to allow arrays to be passed at compile time as parameters to templates. * replace pointers and references with an intermediate type which acts both as a pointer or a reference. * add optional runtime introspection. * add optional garbage collection. Make the default be manual memory management via smart pointers. If garbage collection is specified, then implicitly convert all smart pointers to garbage collected pointers. * make a standard ABI, so as that binary code from different vendors can be combined together. * add delegates, remove method pointers unless the right compiler flag is used. * add nested comments. * allow floats as template parameters (since the template system would not be Turing complete, there would be no float matching problem). * allow default arguments to exist in any parameter index and not only in the right-side parameters. * make functions first class entities in order to eliminate std::function run-time overhead. * add pure functions/classes. * add optional non-aliasing reference/pointers. * remove iostreams. * remove the syntax '= 0' and '= delete' for functions. Use keywords. * allow unicode as source code text (I do not know if this one is already implemented). * do not do default packing of data structures. If packing is required, indicate that with an error to the programmer and let the programmer manually pack the data structures. Let the compiler do default packing only when a compiler flag is specified. * add data structure literals (syntax for specifying maps, lists, trees etc). * make bitwise operators (and, xor, or, left shift, right shift) have higher precedence over arithmetic operators. * add left- and right-insert operators. Instead of using the shift operators, use the insert operators for creating left- and right- associative expressions. * do not make assignment an expression; make it a statement, i.e. remove the ability of the programmer to make an assignment in the middle of an expression. * make statements like if, for, etc accept only block statements as bodies. I.e. enforce {} on these blocks. * make template parameters to have a type, i.e. instead of 'typename T' one could write 'Foo T' and have the template accept only Foo and its subtypes as arguments. * add multimethods, i.e. let the compiler select the appropriate function to invoke based on all of its arguments and not only the 'this' argument. ...the above is by no means exhaustive. If I sit and think about it, I am sure I will come up with a lot more. 
I would * completely redo the integers (usual arithmetic conversions, their names, â€¦) * add `std::string_view` and make string-literals have this type only * Replace the preprocessor with a module system and semantic, namespace-aware macros * Remove allocating new entirely * add a dedicated concatenation-operator and use that in stead of + for string-concatenation * make the parens around conditions in if-statements and loop-headers optional, but the braces mandatory * tiny: `for e: container {}` should be `for e in container {}` * completely redo the pointer-syntax. Basically `ptr&lt;int&gt;` should be the only way to write `int*`. * `val` and `var` instead of `const auto` and `auto` * first class tuples * the type of a variable should follow it's name if it is stated at all: `fn some_function(a: int, b: char) -&gt; int;` * replace iostreams, printf and scanf with something sane * Lot's of other stuff I just didn't think of
utf8 oriented strings and something designed around easily interating translation tables and expressing particular grammers. Demoting text file handling so it doesn't pollute binary files. Attaching locales to pure binary files like iostreams does is just silly.
make the grammer context free so it can be reasonably parsed. Someone already wrote a white paper with full suggestions for resyntaxing c++99 called SPECS. I would use this paper as a starting point (I disagree with a few of their suggestions).
Not a bad writeup, but just to point out, the term "functor" in this sense is actually outdated terminology. It's better to say "function object" or "callable". [Functor](http://en.wikipedia.org/wiki/Functor) has a distinct meaning specific to category theory, and the original use in this sense is a misnomer.
No, we won't pay for anything. I'm not proposing *Defensive Programming* that will always impact the performances as at() does. But a tool for *Contract Programming* (/*Design by Contract*). Assertions can be inhibited in production mode (with -DNDEBUG), they don't impact the performances in production. However, in test and development modes they help us greatly to find and fix programming bugs. I don't want bound checking (i.e. a tool that enables a buggy code to continue running), I want a tool that'll help me find my bugs. It seems, the fact this kind of feature introduces compilation modes into the standard was one of the reasons behind the refusal of n4075 proposal. [In an ideal world, static analysis tools could exploit assertions to detect contract violations. But AFAIK, they don't. Sorry, it's in French, but if you take the first code [here](http://luchermitte.github.io/blog/2014/05/28/programmation-par-contrat-les-assertions/#option-3--on-formalise-nos-suppositions--laide-das), static analysis tools should detect the contract violation (sqrt is called with a negative number) long before running into it.]
Re-engineer the syntax from the bottom up to use S-Expressions. Include generic multimethods. Basically turn it into a dialect of Common Lisp. What's the point of having two massively powerful multi-paradigm languages with standards denser than the avagage housebrick, when we can have one?
I just want an array class that is able to be sized at construction time, not compile time. Ie, I have a class that has some array of stuff in it. I don't know how big that array will be at compile time, but I do know it by the time I construct my class. Yes, I know I can use vector, but I don't need it to be dynamic after construction. I just need one fixed array. Yes, I know I can use new, but then boo memory cleanup. 
Just reminding the readers that formatting is only a small part of iostreams
There actually is a proposal to add a container called "dynarray" that I think implements the behavior you want. It was supposed to be included in C++14 but ultimately was voted out into a separate TS.
afaik, in C++ slang a class with overloaded () operator has always been called a functor, so it is not a something new, introduced in the article
I think lambdas are great if you want to quickly write a function without declaring it in a header. I guess it has many other purposes as well, but having a way to have function objects in the language makes things just easier in many situations. I still wonder what's the cost of affecting a lambda. auto f1 = []{/*some code*/}; auto f2 = []{/*some other, longer code*/}; auto f = f1; f=f2; f=f1;
It's definitely not something new â€” the term "functor" has been used in C++ for quite a while â€” but what I'm trying to say is that the original use is technically wrong, and very confusing to readers familiar with languages that actually use it in the correct sense (see: Haskell). It's much better to avoid the term "functor" in modern writings, unless you're actually talking about the functors from category theory. :)
&gt; Lambdas allow ad-hoc functions to be declared at block scope (something that was illegal before in C++). The lambda function (functor) is only available within the scope of func() in this example; unlike a function, which would have global scope (or file scope if declared as static). It can be done in pre-C++11 indirectly by creating a local scoped class definition with static function. [Like this for example](http://ideone.com/jlMqZE). It is not pretty, but I have seen this done here and there. The lambda did help clean this up (and allowed for less typing). What would be nice to have though are polymorphic lambdas.
I can't imagine why the cost of a lambda would be any different from the equivalent functor you would write yourself. If the code is stateless (no captures, just operates on its parameters), there should be nearly no cost. You mostly need to worry about the size of the captured data. If you copy an object by value, you also have to worry about the cost of the copy construction of the captured objects.
I would make everything EXPLICIT any conversion etc. It often causes the most tricky situation during every day life development. EXPLICIT HELL YEAH!
I don't see farmers telling mathematicians that field is the wrong term.
In the same manner you shouldn't use names like *function*, *integer*, *class*, *language*, or *vector*.
But Haskell/FP and C++ are overlapping fields (pun intended), contrary to farmers and mathematicians.
One of c++'s guiding principles is to pay as little as possible for something. Lambdas follow this as well. If a lambda captures nothing like in your examples, they will actually be reduced to pointers to "unnamed" functions. One really good use of lambdas is to initialize complex static objects. Another good one is to "hold state". This one is tricky, but generally if you're using callbacks and std::bind a lot, consider just replacing everything with a lambda.
without question I would first eliminate headers in favor of a smarter compilation system, like C#
Excellent, I've been looking forward to this book for some time!
I think it is often cheaper than functor or free function, because it is much easier for compiler to know from where given lambda will be called.
http://en.wikipedia.org/wiki/Functor: &gt; The word *functor* was borrowed by mathematicians from the philosopher Rudolf Carnap, who used the term in a linguistic context. Maybe mathematicians should stop using it as well...
Henceforth known as a functory.
Uhgg... as someone who has to deal with Hardware, many of these would kill the use of the language. &gt; remove casts. If you need to use casts, you may need to redesign your program. At least, allow casts only with a compiler flag. Everything at the hardware level is an array of bytes, then you have to cast it into the data type that you need. 90% of people don't have to deal with this, but we absolutely need reinterpret_cast. &gt; make dangerous features like raw pointers and raw arrays not usable unless explicitly requested via compiler flag. Also a killer for people writing hardware stuff. &gt; remove the struct keyword. Pointless because structs are already implemented as classes in C++, just default public instead of private. Only thing it changes is the mental mindset of the person implementing it, but struct X{ int a; int b; }; is the same as class X{ public: int a; int b; } Most people end up putting the public stuff first anyway, so they immediately turn a "class" into a "struct". Yes, structs can have private and protected stuff too!
I remember reading once that it would be nice if `switch` evaluated to a value. That's almost certainly the wrong term so here's an example of what I mean: At the moment, with `?:` we can say: std::string s = (x == 0 ? "zero" : "other"); // parentheses optional of course and it would be nice, especially when working with `enums`, if we could also write: std::string s = switch (x) { case 0: "zero"; case 1: "one"; default: "other"; }; With lambdas you can simulate this behaviour with std::string s = [&amp;]() { switch (x) { case 0: return "zero"; case 1: return "one"; default: return "other"; }}(); But does anyone know if there are hidden gotchas in doing this? [edit] You can also chain `?:` std::string s = x == 0 ? "zero" : x == 1 ? "one" : "other";
Native^1 imutable strings, so there won't be a different string type for every library. [1] By _native_ I mean that literals are of type `string`.
If programmers are smart enough to learn Haskell then they're smart enough to learn another meaning of the word "functor", especially when the author defines it at the very beginning. "Very confusing" my ass. Still, I agree that "function object" is a better term than "functor", but both are correct.
Absolutely no argument from me on that. I think `auto` is a mechanism to sort of get out of our own way when it comes to declaring variables, not a shortcut to lazy code writing.
Location, location, location. The body appearing before the actual loop makes this code harder to read. That's the advantage of the lambdas.
Maybe I'm confused, but it looks to me like both of the cppreference links have for months said: &gt; any other expression that may be accepted by the currently installed C locale That would be enough for me to realize that it is locale dependent, which makes sense since not all cultures write decimals and thousands separators in the same way (or they use ten-thousands separators, etc). It wouldn't hurt to more explicitly say that the results depend on the current locale, but those not familiar with what that means would still gloss over it. I'm not sure why you think this would make C++ less portable, and every language I've worked in uses locale information when converting values to and from strings. 
Why do you mean by "polymorphic"? We have polymorphic lambdas, unless you mean runtime polymorphism. 
Having to write separate .h and .cpp is a nusance, but it goes deeper than that. #include is why C++ compilation is so slow, especially the fact that you fiddle with #defines before you #include, and change the interpretation of the header. It is idiomatic, in fact, to do so to flip between marking code to export when building a module, and for import for those making use of the module (by module I mean .lib or .dll). So the compiler has no choice but to constantly reinterpret the header code. I also feel like with #include, the compiler can't make any guesses what it might really need from all that tree of code, but that a proper concept of "here is exactly what I'm presenting to the outside world" would help the compiler streamline to only what is being used. There is some project led by the clang team to replace #include, but I wonder how much it will really improve things, or just be a slightly more hygenic version of the old system.
What would this actually get you beyond vector though? Surely just because the functionality is there to resize doesn't mean you have to use it. What would this class do other than just not have a couple functions?
Your example of compiler generated code is incorrect in a subtle but important way. [](X&amp; elem) { elem.op(); } You say that turns into this: struct _something_ { void operator()(X&amp; elem) { elem.op(); } }; However, it actually creates something more like this: struct _something_ { void operator()(X&amp; elem) const { elem.op(); } }; Notice the difference? The difference becomes more important if there are value captures. Value captures end up as data members and therefor attempts to change them will cause compiler error. To create the example output you show what you actually need is: [](X&amp; elem) mutable { elem.op(); } http://stackoverflow.com/questions/2835626/c0x-lambda-capture-by-value-always-const/2835645#2835645 Note how high that answer is voted. It's a simple, basic question that gets asked a LOT. So this subtle error is not unimportant.
Should also note that there are dangers of using [=] beyond just overhead: http://crazycpp.wordpress.com/2011/04/06/lambda-capture-and-object-lifetime/
Well, streaming using `&lt;&lt;` is kinda awesome... but I do support stateless! Oh, and decoupling! You should have a `IStream` interface which is just concerned about streaming stuff: - not concerned about managing state (we said stateless) - not concerned about managing buffers - not concerned about anything else actually, just a plain dumb abstract class And then we can build *decorators* for when we want to change the formatting, and each implementation can manage the buffer on its own (or just call `puts`), ...
It's the principle of the Proxy pattern: if the class cannot be resized then you know it will never be. A comment at creation time `// Don't resize` is not as much of a guarantee.
C cannot, actually. It just uses Opaque Pointers, which is what C++ does under the name PIMPL (Pointer to IMPLementation).
Oh, static reflection. That sounds good for meta-programming capabilities.
Do you think so ? I would certainly hope an optimizing compiler would inline the `[]` call and realize it already checked `i &lt; N` so it can skip the check the second time.
I like for my things to have just enough utility to function, but no more. I'm wary of the possibility that it will be misused, that a future editor will look at my software and see a vector and think "ah, I'll just push_back() on it" when it's meant to be used as a statically-sized array elsewhere. (physicists are not always the best coders on the planet)
Ditch *every* single instance of: - undefined behavior - unspecified behavior - implementation-defined behavior (or at least seriously consider removing them). Today's compiler and programming language theory have greatly advanced: look at Rust *statically* proving that moved out objects are not used!
(Apologies for being so pedantic :) ) The terminology is wrong here I believe. It talks about 'template class', when it should say 'class template'. `vector` is a class template. `vector&lt;int&gt;` is a template class.
A module system can support separate compilation (seperate interface/implementation). Look at SML's module system which is like the Ferrari of module systems in the programming language world.
Hmm... I tend to try avoiding working directly in vector and other "primitive" types. If there's a concept I need to model that's constrained such that it can't be resized then there's sufficient reason I think to create a new class for that model. That new class then exposes only the functions I want it to and just happens to use a vector to store its stuff. I've found that interfaces which return things like vector, or map, or whatever fail to provide enough context. There's little reason other than laziness to not just wrap that vector or map into something clearer.
&gt; I also feel like with #include, the compiler can't make any guesses what it might really need from all that tree of code, but that a proper concept of "here is exactly what I'm presenting to the outside world" would help the compiler streamline to only what is being used. If you're talking about the resulting machine code, then you fell wrong - linker eliminates dead code since forever. Link-time code generation goes even further (e.g. inclining cross-translation units etc). If you're talking about compile times, perhaps, but I'd be surprised that would actually save all that much compile time.
Removing loss conversion is what Pascal does. It's been a while, but I don't remember issues with that at the time. C just got this horribly wrong.
What about systems where there's no such thing (think embedded)? It can only be an optional standard feature.
Looking at all the niceties of C++14, I would overhaul the world to make decades of C++ poor cruft disappear from world's codebase ðŸ˜‰.
I meant parametric polymorphism which we know as templates in C++. It seems that it is available in C++14.
What's with this site using images for code? Awful.
C++14 is just C++. 
We have `auto`, and `decltype`, and even `decltype(auto)`. They are related to each other, but do different things. Is there a comprehensive discussion of what they do? Does `auto` before a variable declaration do the same thing as `auto` in a generic lambda? Can we assume that the "base" type (i.e. ignoring ref-qualifers and cv-qualifiers) is the same in all cases? And therefore that the only possible differences are in how many `&amp;`s appear in the deduced type. Do ref- and cv-qualifiers always behave as you would expect when applied to `auto`? e.g. `volatile auto &amp; x = ...`. Does it simply apply any such references via the standard reference-collapsing rules, and add the cv-qualifiers as usual? (I guess my last paragraph doesn't apply to `decltype`) PS: Is `decltype(auto)` in C++14, or will we have to wait until C++17?
It may have been traditionally called "Functor", however, continuing use of the word could cause confusion over or even impede the adoption of [Functors](http://ldionne.github.io/hana/structboost_1_1hana_1_1_functor.html) in C++ in the future.
Break syntax compatibility with C
I am sorry. I don't follow. What I was trying to say is that template lambdas are available in C++ starting C++14. I didn't mean to say C++14 is a different C++. Forgive my wordings if they are misleading.
Come to the Qt side, we have cookies. And i18n. tr("I can %2 the %1").arg(arguments).arg(reorder)
"Generic" is the correct term. C++14 has Generic Lambdas. They allow you to use "auto" in parameter types, which creates a template operator() member function for the lambda closure type.
Old libraries that don't make use of modern smart pointers.
&gt; any other expression that may be accepted by the currently installed C locale I [just added that line](http://en.cppreference.com/mwiki/index.php?title=Template%3Acpp%2Fstring%2Fcvt_str2float&amp;diff=72421&amp;oldid=46921)
To be even more pedantic, `vector&lt;int&gt;` is a *template-id*, which names a class template specialization (and that makes it a *class-name*)
Nice article. The explanation of captures by showing the approximate generated class is very clear. I'm a huge fan of lambdas, `std::function`, and functional techniques in C++. But allow me to suggest some edits (if the author is reading): &gt; the type of the lambda is only known by the compiler (since it is compiler-generated), so you must use auto for declaration instances of the lambda. This is false; you can declare the lambda as the appropriate `std::function` and everything will work fine. Yes, it's converting from the lambda's "real" type, but "you must use `auto`" is not true. Second, your `SimpleCallback` is a weird example because it serves no purpose. It adds nothing to the `std::funtion&lt;void(void)&gt;`. I would demonstrate something slightly more complex, like duplicating C#-style events with a `std::vector&lt;std::function&lt;void()&gt;&gt;`, to illustrate the power of `std::function` solving a useful problem.
It's often referred to as polymorphic lambdas. The official proposal uses that term and the wording in the standard uses both generic and polymorphic lambda.
For instance, say I have some number of wickets. Now for the whole course of this program, that number will be fixed, but depending on the circumstances when it's run, that number may be different. I could, in principle, set wicketNumber each time in code, and recompile every time the system changes to some new number of wickets, changing that number. So I could, I guess, create a WicketContainer class that has, internally, some vector to hold wickets, if that's what you're suggesting... but it seems more straightforward that a container of fixed size is, in fact, an array. And that an array should not need to be known how big it is at compile time (though that makes it easier to pre-allocate memory). An array only needs to be a set size when it is constructed. It just seems to me an artificial limitation on what an array *is* to only allow compile-time size setting. It should be allowed construction-time size setting. And I shouldn't need to craft a new class to act like an array, I should just be able to use array.
I'm not partial to the syntax, I just need the improvements/features they offer. The syntax is much less awkward once you're used to it. Furthermore, with the type inference in D, it reduces the number of times you need to explicitly specify template parameters. See also: [Instantiator function pattern](http://wiki.dlang.org/Instantiator_Function_Pattern)
Without pulling out my standard here, f1 and f2 here have different types. Problem solved: the code isn't valid. If you intended to use std::function instead that has a different cost associated with it.
Actually, type inference in C++ can help a lot in repeating types as well. Also, the Instantiator function pattern is already used in C++(ie `make_pair`, `make_tuple`). However, since its kinda redundant to do this, I used this in C++11 to construct template classes(I call it a generic constructor): template&lt;template&lt;class...&gt; class Template, class... Ts&gt; constexpr auto make(Ts... xs) { return Template&lt;Ts...&gt;{xs...}; } Which you can use like this: auto t = make&lt;std::tuple&gt;(1, 1.0, std::string("hello")); 
You were a few seconds quicker than me in submitting it. But anyway I'd still like to take the opportunity to point out the GCC subreddit: /r/gcc to anyone interested in GCC related news and developments.
I intend to quote you on that. 
Personal preference, but I'm not crazy about auto. I prefer being more specific.
as long as both lambdas have the same argument list and return type, how could they be different types?
I am not sure I understand, but the file system tree can be displayed in the sidebar: http://qt-project.org/doc/qtcreator-3.2/creator-quick-tour.html#browsing-project-contents
How could it be killers when they would be enabled by a compiler flag? You embedded devices/microcontroller creators would not be affected at all. 
2014, and you still don't have the full 2011 features? What the fuck, Microsoft!
On your first point, he is correct, the type of the lambda is only known to the compiler. You are just storing it in an std::function, which is a completely separate type. Try it yourself: auto f = [](){return 0;}; auto g = [](){return 1;}; g = f; // error
I don't understand the graphic at the bottom. Do they plan to implement full generic lambdas, full constexpr, variable templates, expression sfinae, C++11 preprocessor, and two phase name lookup for the 2014 release?
hi, You could try [StackOverflow's tag info](http://stackoverflow.com/tags/c%2b%2b/info) for C++, it includes links to online compilers and a nice FAQ which should start to bring you up to speed. You could also try the [C++FAQ](http://www.parashift.com/c++-faq/) it's a good read. If you're going to do any significant brushing up you will need a local compiler and an IDE. The express versions of Visual Studio are free (though you have to make an account) or if you're on linux just use g++ directly with an editor you like.
Check out topcoder, I think they have exercises starting from simple to pretty tough. At least when I looked at it MANY MANY years ago.
Thinking in C++ is a free book online that is very good for reading up on any specific topic you may have missed or forgotten. Side question: how tough is it to get an interview at google? Curious what the qualifications are like since it feels like kind of the holy grail of tech jobs. Furthermore, good job, and good luck.
I bought the book, and it is a lot of good advice but I feel that sometimes bind makes an easier to read code , since you dont need a huge capture list(and i think [&amp;] is evil)
I hit a tricky bug with VC++'s implementation of speculative devirtualization. I'm glad I'd learned about the optimization previously since otherwise I'm not sure I could have figured out what was going on. Here's the bug report (now fixed): https://connect.microsoft.com/VisualStudio/feedbackdetail/view/812124/code-gen-bug-incorrect-devirtualization-and-inlining-when-building-with-ltcg
I put a few applications in on Monday and got the email about the coding assessment today. I applied for an entry level programming job so the requirements aren't too intensive. I just graduated with a computer engineering technology degree. I don't have the strangest coding skills but I have done a pretty good amount in c++.
The standard ([21.5] 'numeric conversions') says *explicitly* that stod(str) just calls strtod(str.c_str(), ...). , so the current C locale will be used (I mean the one set with setlocale(), not the "classic" locale called "C") regardless. Switching to the old C functions will therefore not help. Afaik nothing in C++ changes the C locale except calling std::locale::global() with a named locale object. Another interesting tidbit: &gt;[22.3.1]: &gt; Whether there is one global locale object for the entire program or one global locale object per thread is implementation-defined. Implementations should provide one global locale object per thread. If there is a single global locale object for the entire program, implementations are not required to avoid data races on it So, afaict, you can't rely on stod() *at all* in a multithreaded program, unless you can guarantee that all threads aren't switching locales, or only using the same locale you are. The following code seems to confirm this: #include &lt;iostream&gt; #include &lt;locale&gt; #include &lt;thread&gt; void foo () { std::locale::global(std::locale("en_US.UTF-8")); } int main() { std::cout &lt;&lt; std::locale().name() &lt;&lt; std::endl; std::thread t1(&amp;foo); t1.join(); std::cout &lt;&lt; std::locale().name() &lt;&lt; std::endl; } prints: C en_US.UTF-8 This isn't new to C++, it was inherited from C where setlocale() is also global. Your only real option, if you want to be sure, is to roll your own solution, like this: double my_stod (std::string const&amp; s) { std::istringstream iss (s); iss.imbue (std::locale("C")); double d; iss &gt;&gt; d; // insert error checking. return d; } Honestly though, I'm not sure why you're splitting your CSV in to std::strings, and not just using streams directly. Doing so would let you imbue() and get on with life. 
There is no 2014 release. As it says immediately above the graphic, VS 14 is scheduled for 2015. Given that the chart goes in implementation order, it seems pretty obvious that after "in CTP3" and "med probability" is "low probability" (where "low" might be "nearly zero").
Plorkyeran's interpretation is correct.
Binary literals, sure, that's tiny. But ask any C++ front-end compiler dev, and they'll tell you that constexpr is one of the most difficult features in the language to implement.
I see what was going on. I didn't realize that information was in a template and I was looking at the [history of the pages](http://en.cppreference.com/mwiki/index.php?title=cpp/string/byte/strtof&amp;action=history) /u/gablank linked. Apparently templates lead to a very confusing history page, since I wasn't seeing the actual history of the page I just read! Thanks for updating this! Cppreference is my favorite C++ reference site.
If you were writing a compiler from scratch with constexpr in mind it probably wouldn't be too difficult to find a design that makes it easy (at least by the standards of C++ compilation), but to jam it into an existing frontend is likely to require redesigning everything. The standard design for a compiler is a one-way pipeline of transforms, and constexpr requires either breaking that by having the back-end JIT-compile compile-time programs for the front-end to run, or to have an interpreter built into the front-end that can run a (increasingly large) subset of C++. 
Euh... I think that you misunderstood my point, it was about not compiling code that isn't used in a given compilation unit. As for #include processing times, you are correct, but * include guards prevent the compiler from actually parsing the file * precompiled headers are there since a *very* long time In other words, people who are affected by long build times are those who don't know how to use their tools or do a poor job of organizing their code (if a "central" header(s) on which everything depends are modifies frequently, there are issues way past build times).
Is the point of this just to avoid the duplication of writing something like: HashTable&lt;int, string, vector&lt;pair&lt;int, string&gt;&gt;&gt; instead of: HashTable&lt;int, string, vector&gt; Though actually I guess that's more valuable than I initially thought, as the vector may need to be parameterized by some HashTable-internal type.
The writing, I found, is **excellent**. Question: the very first code snippet does for_each(c.begin(), c.end(), f); Shouldn't that be for_each(c.begin(), c.end(), &amp;f); (at least in a standard-compliant world, hi MSVC ðŸ˜‰) ?
If we're completely redesigning things, I'm ditching the C-like syntax! Let's replace template &lt;typename I&gt; void quicksort(const I&amp; b, const I&amp; e) { if (b != e) { auto val = *b; auto less = partition(b, e, [&amp;](auto&amp;&amp; i) { return i &lt; val; }); auto greater = find_if(less, e, [&amp;](auto&amp;&amp; i) { return i != val; }); quicksort(b, less); quicksort(greater, e); } } with something like def quicksort&lt;typename I&gt;(const I&amp; b, const I&amp; e): if b != e: val := *b less := partition(b, e, [&amp;](i) { return i &lt; val }) greater := find_if(less, e, [&amp;](i) { return i != val }) quicksort(b, less) quicksort(greater, e) at the very least. Unions that play nicely with non-POD types. Come to think of it, this requires tagging, so basically just builtin sum types. Get rid of C-style casts. Remove the preprocessor, of course. And so forth. Basically I just want to program in `++`.
Which is C++03 and not C++. 
Ah, you're here just to troll? Go on, don't mind me then! ðŸ˜‰
so basically you just want python?
&gt; put safety first, performance second We don't need another Java/Python. C++ is so dominant today because of its speed. Removing that would kill the language. &gt; do not allow template specializations These are as useful as anything else in the language, I'd definitely keep them. I'd have to agree with the rest though, especially &gt; make template parameters to have a type, i.e. instead of 'typename T' one could write 'Foo T' and have the template accept only Foo and its subtypes as arguments.
I'm not here to troll, what gives you that impression? I'm saying that C++03 and C++11 are legacy. C++14==C++. Talking about "*C++14*" is just talking about C++, people shouldn't go on assuming C++03 is the default, because it's not, it's legacy.
You can't blame Microsoft for this. Despite their abject failure to produce a complaint compiler, people keep giving them money. If it's that upsetting, people should switch over to MinGW, otherwise you only have yourself/your boss/etc. to blame.
I like syntactic whitespaceâ€” I could get a lot weirder than this, but Python's pretty nice to look at. Otherwise the semantics are completely unchanged. The idea behind the absent types is implicit `auto&amp;&amp;`, like the proposed `for ( i : container)` syntax for C++17.
Nope, because then you're passing a `Functor*` and you can't call an object pointer. You don't even have to pass real functions by pointer like that either because the compiler transforms it into a function pointer for you.
That allows you to list files but a) it is not a treeview b) it does not limit you to projects' subdirectories What I want is "like project view but show full subdirectory contents instead of build targets".
The compiler shall have flags to remove all safety checks, so there would be no problem with speed if so wished. Regarding template specializations, i propose an alternative: template overloading. 
There is also clang for all of the three
Windows, and thanks! So MS Visual is pretty much run n' play? I tried Code::Blocks but I'm not cut out for all of that crazy shit. It's hard enough to try to learn a new language, much less use some crazy ass program too.
I can also recommend QtCreator (there is a standalone download link here: http://qt-project.org/downloads ). It should work out of the box on all operating systems. Note that QtCreator does not force you to actually write Qt code (even though it makes it easy to...).
Afaik codeblocks is run and play. If you use the installer that includes mingw.
There is that minGW + notepad++ combo which at least it serves to start toying with the language: https://code.google.com/p/pocketcpp/ Or you can also use a online compiler, for example: http://coliru.stacked-crooked.com/
Download from [here](http://sourceforge.net/projects/qtx64/) to get the IDE and QT + compiler for Windows. Linux, you're likely set already.
Dev-Cpp was the often recommended IDE for C++, but that hasn't been developed for very long time. Instead Code::Blocks seems to be the replacement for that and it works very well in my experience.
Its the lack of true RAII support that puts me off. Mote a library than language issue. GC seems largely baked in.
I really like the idea of an auto tutorial, does that involve learning without action?
I guess the biggest challenge is the code base it self, afaik they don't even have an AST on most parts available. Plus that the resources to work on a commercial, closed source compiler front end are much more limited then for the open source contenders.
There's a mingw gcc included on Windows. For Linux it just uses the installed gcc. Not sure what happens on Mac.
That was exactly my thought. Unfortunately they didn't keep the best bit of c++.
Yes, ut has promise. Its one of a number of languages I'm watching.
I wish it would hurry up.
While Visual C++ is still behind clang and gcc in compliance, I am very happy with the progress they have made. If you remember Visual C++ 2012 that came out with very little C++11 compliance advances over Visual C++ 2010, Microsoft has come a long way in a short time. I hope they do not rest on their laurels. I am hoping that when C++17 is finalized as an ISO standard, I hope that Visual C++ is completely compliant (as was clang with c++14).
Thanks for the thorough reply. Our program is not threaded, yet still the locale seems to be changed. Maybe there's some third party library at play here.
Deleting trigraphs would be nice. More so I'd like to C++ get away from ASCII and support a larger character set. It isn't the sixties anymore guys, I'd like to be able to write code with access to at least some of Unicode. 
Visual Studio Express is run n' play, yes. **But having gone through this myself, heed a warning:** I started in Matlab, then did some C#, then finally came to C++. *There are definitely "gotchas" in C++ that don't even cross your mind in some of those other languages.* Can definitely fall into some traps if your mindset is to jump in and play. The biggest IMO is resource / memory management. Definitely spend some time reading up on stack and heap allocation, RAII, how you can get memory leaks, avoiding new and free and raw pointers, etc.
Grab the bigger download under the Qt 5.3 section (or the equivalent online installer). If you look carefully at the top and bottom of that section, it mentions the presence of the MinGW toolchain. &gt; Select the file according to your operating system from the list below to get the latest Qt 5.3 for your computer. The binary packages include Qt 5.3.1 libraries and Qt Creator 3.1.2
Sorry for the confusion. I just checked myself as well. You are completely right. I guess when I tried it it simply worked because I had downloaded a Qt build with mingw before. I guess it's better to download the Qt build with MinGW then, which is available as 32 Bit Version on the page I linked and as 64 Bit version at the page that was linked by /u/wtfisthisidontevenkn below.
The lambdas themselves are always represented by a function object (which would result in a different type for every lambda, even if they have identical return types/parameter types). When the capture list is empty (and there are no auto parameters, i.e. "non-generic"), there is a conversion function (sometimes called a "cast operator") added to the class that returns a pointer to function type which has the same return type and parameter types as the lambda itself. The value returned by this conversion function is the address of a function that does exactly the same as the function object's operator() function (i.e. the lambda body itself). This conversion function means that you can assign the lambda directly to a function pointer and have it work as expected. However in the above example, assigning the lambda directly to "auto f1" means that f1 is the full lambda function object type, and then the subsequent "auto f= f1;" means that f is also the full lambda function object type of f1. Since f has taken on the lambda function object type of f1, it cannot possibly have f2 assigned to it. This is all from n3936 (the last public draft), so it could have changed: &gt;5.1.2.6 The closure type for a non-generic lambda-expression with no lambda-capture has a public non-virtual nonexplicit const conversion function to pointer to function with C++ language linkage (7.5) having the same parameter and return types as the closure typeâ€™s function call operator. The value returned by this conversion function shall be the address of a function that, when invoked, has the same effect as invoking the closure typeâ€™s function call operator.
Are you sure you installed codeblocks with mingw and not just the editor ?
Still, it is really pathetic when an expensive proprietary piece of software can't even keep up with the standard when free open source alternatives have already started implementing draft features of C++1z... Sorry but Microsoft fully deserves the blame here.
Please. Taking advantage of PCH requires restructuring the codebase, which isn't always a realistic option.
So... you'd turn it into Rust.
This + a way to specify the alignment of the array's backing memory. Alignas is useless for stuff like this because it can be ignored if the alignment requested is bigger than `alignof(std::maxalign_t)`
I hear this question often from undergraduate students who "just want to get going." I usually recommend CodeBlocks. It's available for Windows, mac and Linux. For Windows there is a bundle available which ships with a Version mingw. Nonetheless, after some motivational results you should start to get at least a big picture of the toolchain (which IDEs mostly hide from you).
Depends on what IDE are you using. For example Eclipse CDT does auto completion for auto types and shows the deducted type on hover.
We use unit test frameworks for such things... There are integration test frameworks out there for C++, but they don't seem as popular or well supported as the unit test frameworks. That said, we find the unit test framework Catch to work well for both our unit and integration testing, so you might find some luck there.
s/MinGW/other Operating Systems and platforms/ *trollface*
&gt; add a dedicated concatenation-operator and use that in stead of + for string-concatenation Why? 
String concatenation isn't associative, but '+' for other types is. There's also no sensible or useful way to implement a complimentary '-' operator. Using '+' personally doesn't bother me, but there are evidentally a lot of purists out there.
I see where you're coming from, but either way, in the context for strings, I personally think '+' makes sense for concatenation.
&gt; Remove allocating new entirely How would you allow for type specific default allocators? new/delete is currently an operator that can currently be overloaded on a per-class basis, and doing so makes std::allocator (the default for all containers) useful. &gt; completely redo the pointer-syntax. Basically ptr&lt;int&gt; should be the only way to write int*. Needless verbosity imo. &gt; val and var instead of const auto and auto You'd also need a 'ref', unless you're proposing vals be garbage collected &gt; the type of a variable should follow it's name if it is stated at all: fn some_function(a: int, b: char) -&gt; int; meh. I think this looks ugly in Rust. I wouldn't mind being able to use parameter names to *call* a function though, instead of having to ensure the order is correct. &gt; replace iostreams, printf and scanf with something sane iostreams are fine, they just need to scrap the polymorphic burden of implementing a streambuf, and allow for separate input and output stream buffers, etc. Boost.IOStream is closer to goodness
I tend to agree. If you added a concatenation operator you'd just have people otherloading it for other purposes. like '55 concat 42' to get 5542
In C, 'long int' can be the same size as 'char' and the range of any signed type with respect to its unsigned counterpart is unspecified. We're talking about a language that lets you implicitly cast a void* to a Widget* after all. Can't really blame C for choosing the current behavior in that setting.
GCCs -Wconversion and -Wsign-conversion, and the C++11 non-narrowing {} syntax help a greal deal.
&gt; look at Rust statically proving that moved out objects are not used! If you leave your moved-from objects in a usable state (preferrably the same state you get from an object with default construction), then reusing those objects can still have benefits.
* A sane module system * A dedicated concatenation operator * Pure functions * Support for contract-based programming and unit testing * Remove 'auto' altogether and implement a full Hindley-Milner type inference engine (Ã  la Haskell) i.e. variable types deducted at first use/initialization.
Except the other commercial vendors are even worse.
I use google test for basic unit tests and google mock for more in-depth integration style testing. Mocks also help keep test and production code separate.
That's cool, but that's not insert, that's push_back. Insert takes an additional argument corresponding to the position of the element to be inserted. Insert typically always, at least, moves all element past the new one, so its amortized cost is more likely something along the lines of O(n_elt_past_the_new_one)
Redhat?
Yes, true, I was just working from the wording in the standard that requires "insert" at the end to be amortized constant time. I'll clarify the wording nonetheless.
Why does the vendor who makes the OS have to also make the compiler? You can run GCC on Windows, it's called MinGW. GCC 4.9.0 is very compliant both with [C++11](https://gcc.gnu.org/projects/cxx0x.html) and [C++14](https://gcc.gnu.org/projects/cxx1y.html).
&gt; Why does the vendor who makes the OS have to also make the compiler? Because it has always been like that. Sucessful system programming languages are the ones that OS vendors have on their SDKs. All the others eventually fade away. Additionally, those compilers tend to outdated in terms of OS support. A problem that Borland, Zortech and others used to suffer from. &gt; You can run GCC on Windows, The issue is Microsoft vs other commercial vendors.... 
Which commercial C++ compiler does RedHat sell?
There is at least one problem: We want this to work: `"foo"s + 'c'`. Logically `c` + `d` should then result in `"cd"s`, but it is of course integer-addition here. It could be argued though, that char shouldn't be considered an integer, which is certainly something I can get behind with.
&gt; How would you allow for type specific default allocators? I fail to see how this is needed so often, that it would be a good idea to not be explicit with using something non-default here. &gt; I wouldn't mind being able to use parameter names to call a function though, instead of having to ensure the order is correct. Yes, but IMHO this should only be possible if the declaration explicitly allows this, otherwise argument-names become part of the signature which is something, that I don't consider a great idea.
Stick to STL containers as much as you can, and avoid dealing with raw pointers, if possible.
I don't really get why wouldn't MS do it up with the Clang team. I'm sure many customers buy C++ VS because of the good IDE and debugger anyway, so why won't MS just do the ABI work to adapt Clang to Windows? Some sort of corporate pride? I'm not good at this whole platform compatibility thing, maybe I'm missing something out?
Visual Studio, Code::Blocks, etc. are applications that try to to make it easier for you to write, compile and execute your program. It helps by setting the correct compiler flags, highlighting syntax errors, providing visual navigation of your project(s), etc. It still requires you to learn how it works, though it's hiding much from you. Another option is to use a simple text editor like notepad.exe, Sublime Text, etc. and compile your code on the command line using one of the many compilers available. This is how I got started. You still have to learn a crazy ass program (the compiler), but there's no getting around having to learn something besides the language.
&gt; so its amortized cost is more likely something along the lines of O(n_elt_past_the_new_one) Which is simply O(n).
You didn't mention anything about commercial C++ compilers. I'm talking about gcc, mostly. I really have no clue about what argument you're trying to make.
Most opensource compiler devs with clang and gcc are not volunteers. The work is their paid full time job. So I don't buy that "poor MS doesn't have enough resources" argument.
Well, having an open code base with more then one company working on it is a clear benefit. Ofc. Clang and GCC aren't written by hobbyists either. And having an open model which brings the option of implementing some feature as your prove of concept for the standard helps a lot too.
Why is that?!
That is not a random case, that is both the average and the worst case. Considering that std::vector has a broad use and offers a distinct method (push_back) for the best case, those are the only two complexities which are actually interesting. I guess what you mean is for a constant k, which results in O(1). That is obvious since the calculation would be almost the same as the one for push_back in the linked article.
It's not about that. It's about VS being the best available IDE and having the best debugging facilities, for C++ at least. I'd happily use GCC or Clang but no other IDE comes even close (I work regularly with QtCreator as well, and I've tried others. QtCreator is very decent as well, but it is still miles away from VS).
They are what the OS vendor sells, and you as consultant only have a say on the code to write, not what the compilers and OS the company that hired you has. In many companies, IT says what are the tools, not the devs. 
Who downvoted this? I bet money this is exactly what is happening.
Indeed; the term of art is "decay". In most contexts, functions decay into function pointers.
The latter.
Probably all the shit they put in their compiler that nobody asked for still needs to be supported: C++/CLI, C++/CX, all the COM stuff etc. Clang probably won't ever support it and now Microsoft is stuck supporting their various attempts at vendor lock in.
IIRC Rust's print!() macro does static type checking on it's arguments.
People fall on both sides of the syntactic whitespace vs. braces argument. I wouldn't care either way *so long as the compiler refuses to compile if you have inconsistent indentation*. Three or more different indenting styles **in the same function?!?!?** No longer possible.
Why is restructuring not always realistic? It takes time. Depending on your codebase, a lot of time. It also could break clients of your code if you're doing this to a library. Also your build system might not be amenable to it. I work in game development, and we compile the codebase I work on now uses a single-compilation-unit build (aka unity build). Basically we #include every cpp file into one that we pass to compiler to get a form of poor-mans LTO. Not realistic to restructure that to use PCH (not that modules would work here either).
Note the phrase some of Unicode! However why wouldn't you want the ability to use accepted mathematical symbols, Greek and other characters in your code? In many cases it can make supporting the code easier if the code represents the literature closely. Beyond all of that this isn't any worst than what we already have with case sensitive text or single characters like "l", "I" &amp; "1". Just those three have caused me grief over the years but you know we adapt. We choose fonts that reduce the possibility for mis interpretation and use other conventions to make sure we interpret characters correctly. As it is I've yet to see a good argument against that allows an expanded character set. 
No, I'm not sure.
help
With support for it added in GCC 4.9 I just changed over to -std=c++14, very exciting! I believe they added shared_mutex support which is what I plan on using in my project soon. EDIT: Just saw proposal for the any type, one more thing to convert over from Boost, awesome! Is there a complete list of what was approved for c++14?
Windows only -- VC Express. Free, download, and use. Cross platform -- Qt Creator. 
The first app I was made to write in school in C was a terminal based Battleship. It's pretty simple. 1. Randomly set AI's ships. 2. Allow user input to assign positions to ships. 3. Build in Battleship gameplay. Simple, but complex enough to keep a newbie involved and learning!
I implemented [Huffman](https://en.wikipedia.org/wiki/Huffman_coding) while learning C++. Advantages: * Comes with its own correctness test (compression followed by decompression must be byte-identical). * Performance is interesting to analyze and optimize for * Involves a real algorithm with an interesting data structure - you can get the STL to help somewhat but you do have to write most of it yourself * Doesn't involve any of the hard things - user I/O, graphics, networking, etc. The main disadvantage is that it is austere - it consumes and emits a file, instead of displaying something pretty on the screen.
What is your target testing interface?
write yourself a program to pirate haskell books, then read those instead
Generating HTML is something I believe you could do at this point (and it is also useful in practice). You could, for example, build some tool which lets users generate some fixed types of HTML reports/letters. For example, you could let the user choose to generate a table report from some csv input file. As another idea, you could have a simple general macro processor. It'd take 1 file as its command line parameter. This file would contain mappings from macro names to replacement content. Each mapping would be a line with __&lt;name&gt; &lt;value&gt;__. For example: body.background-color #ff123a footer.color black Assuming you call the program __mmac__ (my macro), invoking it like __mmac -p '::' params &lt; mycss.template.css &gt; mycss.css__ would read the mappings from __params__ and process standard input content by doing all the specified replacements. For example, if it read __::body.background-color__, then it'd output __#ff123a__. The __-p__ command line argument could be used to tell you which prefix parameter names would have in the input (so the macro __abc__ in the parameters file would be identified by a __::abc__ sequence in the input). All output would be sent to standard output. Since redirection is going on in there, standard input is actually mycss.templace.css and standard output will be mycss.css. As you saw in my example, you can use this as a simple CSS preprocessor. But it also serves as general pretty simple "templating" system. None of this is new. And, in practice, if you need stuff for these tasks, you'll be using something which already exists, but it should be an interesting exercise building these things. Having these two, you can write a simple shellscript which combines them to make something which generates simple styled reports. I think this all can be done in a day or 2, possibly less if you know what you're doing. To do this fast, you should try to make use of the standard library facilities otherwise it can take a lot longer than a day. Depending on your level, you could get stuck on an error and take a week or more to finish this. Of course, for the html reports generator, if you want it to deal with 1000 kinds of reports, it'll take a while to finish, but if all you want is for it to know how to deal with list reports and table reports, it shouldn't take long.
http://www.reddit.com/r/dailyprogrammer/ -- literally hundreds of challenges for you -- designed to be short and at 3 different skill levels. 
A simple and fun project I would suggest off the top of my head would be a virtual psychiatrist, advice giver or friend. Sounds complex? It's not, it will help you grasp strings and dive deeper into the STL. Just have it match certain keywords or phrases in a string that the user inputs with [`find()`](http://www.cplusplus.com/reference/string/string/find/) and then return random, funny or thoughtful replies. For added learning, you might store these replies in a text file and learn a bit of IO at the same time. For an example, you can have a look at the Psychotherapist in Emacs. ---- This isn't something to do in a few hours but is a great project that will improve your skills immensely. A simple application that you could find useful after is something that converts plain-text to another format. Say markdown to html. It would be a great exercise to learn the STL and possibly get a bit of regular expressions under your belt as well.
Well, if you want to go up and running fast, I recommend you Qt Creator or Eclipse, because both are multi-platform. But if you really want to learn how things work, I highly recommend you to download a text editor. I use emacs. It takes some time to get familiar with command-line tools, but once you do, you will know way more how things are working.
Have I missed a reference? What's haskell?
Whenever I want to learn a new language I start with a casino game. Blackjack. Poker. Craps. Roulette. Whatever. The reason casino games are attractive is because the rules are usually simple, the problem is well known, and in the end you get something fun you can play, so there is motivation throughout the process to keep moving forward.
Thanks for pointing that out. I find it is still a bit vague, but it does warrant changing my comment.
I actually like web servers as learning code. Initially you can write some single-threaded, blocking code that just serves up a file plus some headers straight off of disk to the browser. It scales well since the simplest case is very small, but requires disk and network IO. From there, you can make it handle concurrent connections in a variety of ways (fork, thread, polling, etc), embed interpreters or a templating language, and take it as far as you want.
Interesting. I really don't know what its end goal is. Have you got a good noob-friendly outline of what it is/does?
A functional programming language. If you're interested in learning about it, [Learn You a Haskell for Great Good](http://learnyouahaskell.com/) is a fun read. (Not that it makes C++ not worth learning.)
The lambdas taste like lambdas, the captures taste like captures, the conversions taste like conversions!
I'm not entirely sure what you mean.
it's a noob-WinZip
Gotcha, that actually sounds useful. I'll check it out :)
This doesn't work with `vector` unfortunately. When we see `vector&lt;int&gt;` we assume that `vector` is a template that takes one parameter, but really it takes multiple parameters (allocators, for example) which have defaults. This means the code in the blog won't work. error: expected a template of type â€˜template&lt;class&gt; class Contâ€™, got â€˜template&lt;class _Tp, class _Alloc&gt; class std::vectorâ€™ and the clang error message is template template argument has different template parameters than its corresponding template template parameter ***But***, we can save the situation with `using`. template&lt;typename T&gt; using vec = vector&lt;T&gt;; Now `vec` is *almost* identical to `vector` in almost every way. The difference is that it truly has just one parameter and therefore it will work as a template template parameter
My Hello, World program for new languages is [Petals Around the Rose](http://www.borrett.id.au/computing/petals-j.htm).
Is Clang on Windows any good yet? Last time I tried to get it working it was just a mess and I am far too lazy for that ;)
It is being downvoted because it is universally seen as an awful thing to do. Also codeblocks executes your program via a stub that will keep the prompt open so this should not be needed. If you *really* need to do something to keep the prompt open then cin.get() is a far better choice.
My favorite school projects were [raytracing engine]( http://en.wikipedia.org/wiki/Ray_tracing_%28graphics%29 ) and a [LR parser](http://en.wikipedia.org/wiki/LR_parser). The first one will give you pretty pictures to show off (e.g. on interviews) as a result and the second one will give you an invaluable mental tool to the future (you can even continue to extend it to some simple programming language). With both of them you'll exercise recursion, and I would describe them as pure solutions to a particular set of problems. EDIT: fixes wikipedia links EDIT2: Eh, I actually meant LR parser. Not LL.
http://www.haskell.org/haskellwiki/Haskell
Wow! These are excellent! I'm working through the roman numeral converter on code eval now. Fantastic, thanks a bunch!
Have you ever used PCH? You need to move from 'include what you use' to a 'include a global header that includes all other headers'. OTOH I'm not an expert on it. This is just how every codebase I've ever worked on that used PCH worked. It might be that this was done this way just to maximize their benefit.
A spell checker is a nice "Scalable" project. You can start with a simple list of words (like /usr/share/dist/words which is in a lot of linux installations). You can stop when you get bored but you can start with: * Read the file in and store it * Search it * Red some user input text * Split all the words out (punctuation too) * Check them against the dict * Make this all work faster/better/differently Extra features: * Read/Write the user's text from a file * Add suggestions.... This can be algorithmically very complicated in a real spell checker, but you can start small like checking for transposed characters or something and then investigate more interest techniques. 
Is it a gui, CLI or api?
I've had this suggested to me elsewhere. Is it easy to write? I've heard it can be quite complex.
CLI - run/compiled as a Visual Studio project, ideally. But I'm flexible.
I find it relatively easy. The rules are simple. 1. Any live cell with 2-3 live neighbors lives. 2. Any live cell with less than 2 or more than 3 neighbors dies. 3. Any dead cell with exactly 3 live neighbors becomes alive. All you really need to do is just loop through a 2D grid of booleans and apply those rules. 
&gt; it is universally seen as an awful thing to do We are talking about a "hello world" program here and the OP is confused that his output window disappears before he sees the result. Whether he uses system or cin or a command from code blocks to see the result is irrelevant at this point. 
Macros, seriously?
&gt; Have you ever used PCH? Yes, often. &gt;You need to move from 'include what you use' to a 'include a global header that includes all other headers'. That's a "no" for that "need" there. Yes, with PCH, you have a look at what is "external" to your module, and put all that together in a header that you include in all translation units. However, once that is done, you behave as if you didn't include the ""all" header, meaning that *you still include what any given translation unit needs*. This is so that you can still compile it correctly, even without precompiled headers. To verify that you're still proper, you then run the variant of the build without the PCH (or with an empty "all" header), which then breaks the build if you're not "clean" with your includes. That variant of the build can simply be your retail/release build, or it can be a dedicated build, it really depends on the context (e.g. you might want a retail CI build that takes advantage of the PCH, for speed). The debug build, however, is normally using the PCH, again, for build speed. Obviously, the above is a hassle. But the pay-off are shorter build times, and the bigger the module is, the bigger the pay-off. You said above that "Taking advantage of PCH requires restructuring the codebase". From what you're explaining, the restructuring is just a change in what you're including in your translation units. Quite frankly, to me, that isn't much of a restructuring. The more important point is this: point of the PCH are shorter build times. *No more, no less*. The "just include a global "all" header is therefore a bad idea, but to be frank, when people use the PCH and don't have a non-PCH build, they do get sloppy even if they don't intentionally go for "just include a global "all" header", you are not alone in that.
The blog post is not really about creating any macros. In the previous [post](http://pfultz2.com/blog/2014/08/17/type-requirements/), I discuss about defining the `REQUIRES` macro to help reduce the noise from `enable_if`. I do use that in this blog post as well, but you can replace them with easily with `enable_if`: template&lt;class Iterator, typename std::enable_if&lt;(models&lt;Advanceable(Iterator, int)&gt;())&gt;::type&gt; void advance(Iterator&amp; it, int n) { it += n; } template&lt;class Iterator, typename std::enable_if&lt;(models&lt;Incrementable(Iterator)&gt;())&gt;::type&gt; void advance(Iterator&amp; it, int n) { while (n--) ++it; } However, I find the macro version easier to read.
agreed. misuse of auto would be disastrous for readability and maintainability. That being said I find I would love to have auto available in lambas since it's not uncommon to declare a collection then immediately do something with it.
I was expecting a simpler solution - simply change the increment overload such that it `REQUIRES` that the other overload be *not* callable. I'm surprised it's necessary to make the more complex solution via `basic_conditional`. Is this necessary? Or maybe I'm missing some other advantage with this?
Well when you have just two overloads, that would work fairly simple, but it doesn't scale well with more overloads. At the end, I show how to write `advance` using three overloads; I didnt have to go back and change the previous overloads. Futhermore, it gets more complicated to write in the way you suggest, here's how it would look with three overloads: template&lt;class Iterator, REQUIRES(models&lt;Advanceable(Iterator, int)&gt;())&gt; void advance(Iterator&amp; it, int n) { it += n; } template&lt;class Iterator, REQUIRES( models&lt;Decrementable(Iterator)&gt;() &amp;&amp; !models&lt;Advanceable(Iterator, int)&gt;())&gt; void advance(Iterator&amp; it, int n) { if (n &gt; 0) while (n--) ++it; else { n *= -1; while (n--) --it; } } template&lt;class Iterator, REQUIRES( models&lt;Incrementable(Iterator)&gt;() &amp;&amp; !models&lt;Decrementable(Iterator)&gt;() &amp;&amp; !models&lt;Advanceable(Iterator, int)&gt;())&gt; void advance(Iterator&amp; it, int n) { while (n--) ++it; } This gets to be more complicated. With conditional overloading it easier to add more overloads, without figuring out what other overloads need to be negated. Plus, its easier see what function will be called based on its order in the `conditional` class. &gt; I'm surprised it's necessary to make the more complex solution via basic_conditional. The `conditional` class is an abstraction you write once to handle the complexity of overloading(and its only a few lines of code). Ideally, it would be nice if there were a language feature that could handle this in a much neater way. Does that make sense?
Yes, but you need to remeber to put parenthesis around the condition, or you will run into C++'s most vexing parse. 
How does Code Eval teach you code? It REALLY looks amazing, but how.
&gt;The blog post is not really about creating any macros. That the blog advises creating macros at all, in any capacity, whatsoever, makes it highly suspect.
Or just use `{}` instead of `()`..
1) i though if i should give him a function that does the same thing but is portable .. This would only have resulted in confusion. 2) While codeblocks has that feature, dont ask me why, but it does not work for me. I made sure that it is activated. PS: (portable pause version) void PAUSE(void) { std::cout &lt;&lt; "\nPress \"ENTER\" to continue." &lt;&lt; std::endl; std::cin.ignore(std::cin.rdbuf()-&gt;in_avail()); std::cin.clear(); std::cin.sync(); while (std::cin.get() != '\n') {} } 
It doesn't really teach you to code. It just has plenty of programming projects you can do to help you practice whatever language you're learning. On top of that you can get some job offers and networking opportunities through it. 
&gt; Except the other commercial vendors are even worse. Over $2k per seat and you get C++2003 support. Fun times! -_- (Not going to name and shame)
Obviously, you havent seen the other blog posts, where I define a macro to emulate reflection. So I guess that makes the entire blog "highly suspect". lol.
Maybe you should spend some time understanding how macros works. They are simple text replacement, there is no need to "fear" them. Also, you are more likely to get "bitten" by the non-macro version(due to many things including C++'s most vexing parse) than the macro version.
Kewl.
&gt;They are simple text replacement, there is no need to "fear" them. They are simply text replacement, which is **why you fear them**.
&gt;I guess that makes the entire blog "highly suspect". Yes that's my point.
Is this how people tend to use `enable_if`? In the template brackets? I always and heavily use template&lt;typename T&gt; std::enable_if&lt;condition, void&gt;::type f() {} Or am I mixing something up?
Yeah, unfortunately I'm getting downvoted to hell every time I ask for help because I don't know the proper conventions. I'd recommend checking out learncpp.com, that's the tutorial I'm doing, also [code eval](https://www.codeeval.com) which was recommended to me, excellent challenges for honing your skills.
Yeah I was on Code Eval and I may go there or to /r/dailyprogrammer/ I did start out by using the learncpp website but I was told not to by reddit for some reason.
Really? Did they give any reason at all?
Emacs or if you want to take the very hard road Vim ;) Using command line tools make it a lot more clearer what's happening, in contrast to a "magic" IDE. Once you become confident with the command line you can start using an IDE (but you'll probably prefer the command line by then).
Good to see more progress but I'd really like to see full constexpr and expression SFINAE support.
You can look at the feature set of existing servers, such as apache and nginx, to get some ideas of the sort of things you can put in there, and in some cases people roll in stuff like blogging style features. The truth is it's really open-ended. If you want to go more into performance tuning and networking, I'd start with just serving up files (say if the current working directory is /webroot and a file foo.html was in there, visiting it in your browser at http://mylocalserver/foo.html would serve up that file. Then you can spend almost an arbitrary amount of time chasing optimizations. You're done when you feel like any further performance improvement is not worth the effort, i.e., it's "good enough." On the more feature agglutination approach, it's just related to what itches you want to scratch. Maybe you want to let people upload files, for instance, or write the server as a library so you can easily embed it in existing projects, etc. The sky is the limit there.
There are more bad sources of learning C++ on the Internet than there are good ones. I am not familiar with LearnCpp.com but looking at just a handful of its chapters it is misleading, out of date, violates a number of C++ idioms, and focused on the wrong things wrt. learning C++ specifically. [C++ Primer 5th ed.](http://www.amazon.com/Primer-5th-Edition-Stanley-Lippman/dp/0321714113) is a very good book for getting started with modern C++.
Thank you. Your response is exactly the initial push I needed. 
I do not feel like registering to comment at that blog post, so I'll just do it here. This does not turn emacs into an IDE, it just adds a couple of features to an already powerful text editor. An IDE has a code model or it is not worth the effort to install. This means that an IDE understands your code, does proper highlighting based on the syntax tree (and not regular expressions). It means you can rename things easily and refractory your code semi-automatically. All that is totally out of scope of emacs, even pimped like that. Seriously, it is amazing how us open source guys are stuck to software development from the late 1980. I neared way too often that a real programmer uses him or emacs and a terminal (and maybe gdb, but only on the command line). We are in the 21th century, go out and try a real IDE for a week or two. 
CEDET provides a C/C++ parser that produces AST for intelligent completion. I explained CEDET in later section. Fyi, Emacs is **NOT** an editor. It's a **virtual machine optimized for text editing and comet with a text editor**. Yes, Emacs has a built-in parser that understands your C/C++ source code , CEDET is more than a parser; it's a complete compiler-compiler language framework that is written in pure ELisp, an C/C++ parser is an application written in it. As for indentation and highlighting based on AST, Steve Yegge did that with js2-mode: [js2-mode: a new JavaScript mode for Emacs ](http://steve-yegge.blogspot.com/2008/03/js2-mode-new-javascript-mode-for-emacs.html). js2-mode is basically a functional Javascript parser. Those things are **perfectly possible** to do in Emacs. It's just that not everyone has skill or dedication to do it. As you can see above, it requires quite a big effort. But the key point is, it is possible, because Emacs is a virtual machine for a general purpose language, Emacs Lisp. For the "real IDE", have you tried importing project as large as Linux kernel inside Eclipse or Visual Studio? For project that large, most of the features are not functional. Have you tried debugging a random executable in Eclipse? You have to create a whole project just for debugging a mere hundreds KB executable. OMG.
So does CEDET actually properly understand C++, or is it like Qt Creator's model, which just approximates and goes "good enough"? The problem with that approach is that in this day and age we have Clang. Also lol if you think that highilighting and indentation are the killer features of having working code model. 
Because the poster I replied only mentioned highlighting and indentation. I do not say it is the only feature. js2-mode is a parser that generates proper parse tree used for other things like intelligent completion, syntax check and outline tree etc... the so called code model. If you want an outline tree, here is a [more powerful version](http://tuhdo.github.io/static/part3/helm-semantic-or-imenu.gif). Read it fully [here](http://tuhdo.github.io/helm-intro.html#sec-7). As for CEDET, it understands C nicely. For C++, work well enough with library like Boost, but C++11 is not yet supported.
&gt; I've heard a great proposal that unifies Concepts and type inference That seems awesome. Reminds me of Go interfaces. It looks like the best approximation that we can get to this in C++14 is using [Boost's concept check library](http://www.boost.org/doc/libs/1_48_0/libs/concept_check/concept_check.htm).
Look into [YouCompleteMe](https://github.com/Valloric/YouCompleteMe). It provides auto-completion and goto definition through Clang, although looking at this I wish it also had search by function signature. It goes nicely with [Syntastic](https://github.com/scrooloose/syntastic). Both can be easily installed through the [Vundle](https://github.com/gmarik/Vundle.vim) package manager.
Ah yes. Thanks for that. By the way, I don't think you define the REQUIRES macro anywhere. I wonder if it might help to do so? I guess it's something like `#define REQUIRES(X) enable_if&lt;X,void&gt;:: type`
&gt;CEDET provides a C/C++ parser that produces AST for intelligent completion. I explained CEDET in later section. The homepage of CEDET lists "LL - Excellent &amp; crags" as backend for C/C++. Can't be much of an AST if it.needs crags:) If the LL part is what does a proper AST, then I stand corrected. &gt; Fyi, Emacs is **NOT** an editor. It's a **virtual machine optimized for text editing and comet with a text editor**. Yes, of course. &gt; Yes, Emacs has a built-in parser that understands your C/C++ source code , CEDET is more than a parser; it's a complete compiler-compiler language framework that is written in pure ELisp, an C/C++ parser is an application written in it. Great. So emacs has the begin of a real IDE framework. Is there a dedicated team on this? Can somebody expect this to become fully usefully at some point? &gt; As for indentation and highlighting based on AST, Steve Yegge did that with js2-mode: [js2-mode: a new JavaScript mode for Emacs ](http://steve-yegge.blogspot.com/2008/03/js2-mode-new-javascript-mode-for-emacs.html). js2-mode is basically a functional Javascript parser. So that does not work for C++? &gt;Those things are **perfectly possible** to do in Emacs. Of course it can be done. &gt; It's just that not everyone has skill or dedication to do it. As you can see above, it requires quite a big effort. But the key point is, it is possible, because Emacs is a virtual machine for a general purpose language, Emacs Lisp. Just use a real IDE instead then. &gt;For the "real IDE", have you tried importing project as large as Linux kernel inside Eclipse or Visual Studio? For project that large, most of the features are not functional. I know some kernel developers using Qt Creator. &gt;Have you tried debugging a random executable in Eclipse? You have to create a whole project just for debugging a mere hundreds KB executable. OMG. The problem is of course that an IDE does understand your code. To do that, it unfortunately needs a project to know which files belong to it. Yes, an IDE is not the ideal tool for a quick debug session, just as a text editor is the wrong tool for a big coding session. 
Clang produces a really useful code model. It still has two problems though: First it is rather slow. Qt Creators code model takes significant less time to parse a project than the clang parser does. Clang does of course produce the more complete code model by not taking the shortcuts Qt Creators code model does. The second is that the clang parser is not too good at recovering from errors in the code. An IDE will feed the current text buffer to the parser regularly, and this can happen when the buffer is not in a syntactically correct state. So it is really important that the parser does not just stop after the first syntax error, but tries to find a point soon after the error that it can continue from. Again that is not something the clang parser is optimized for.
Very cool and useful, but I would really, really like C++11 support in cc-mode more than any of these fancy features. I love using Emacs for C++ development, but not being able to indent eg. lambdas and class enums properly is really annoying. And yes, I know the code is open so I could fix it myself, but my knowledge of Emacs Lisp is limited to say the least and from what I can understand cc-mode is pretty much "black magic". Sorry for ranting.
&gt; The homepage of CEDET lists "LL - Excellent &amp; crags" as backend for C/C++. Can't be much of an AST if it.needs crags:) &gt; &gt; If the LL part is what does a proper AST, then I stand corrected. You misunderstood it. Read about Semantic [here](http://cedet.sourceforge.net/semantic.shtml): &gt; Language Parsers &gt; Parsers that have already been implemented: &gt; Emacs Lisp, Java, C/C++, C#, Python, Erlang, awk, Makefile, Scheme, HTML, Texinfo, Javascript, dot. &gt; Also: Semantic's own grammar format (.by or .wy) &gt; The text you read, it means you can use tagging tools such as ctags and GNU Global **as an addition** for browsing source code. Nowhere does it say "as backends". But for code completion, none of those tools are sufficient, and Semantic builds its own database for using its parser. In other words, CEDET works fine **WITHOUT** any of those tagging system. Here is an [overview of CEDET structure](https://www.gnu.org/software/emacs/manual/html_node/semantic/Introduction.html#Introduction). You can use any parser as backend (include the built-in from CEDET), as long as you produce appropriate format that can be used by Semantic. &gt; Great. So emacs has the begin of a real IDE framework. Is there a dedicated team on this? Can somebody expect this to become fully usefully at some point? Yes, CEDET exists long ago and people are still maintained it. It is **already useful**, as demonstrated in the my guide. If you have a project with under a million lines of code, then it is very usable. &gt; So that does not work for C++? Yes, it works. The equivalent is CEDET, which is much broader. The point is it's always possible. &gt; Just use a real IDE instead then. I use Emacs for tools like in my guide and other tools as well. None of the IDEs are as productive for writing code in multiple languages, and more efficient for text manipulation as well. If you have to work not only with C/C++, but multiple other languages, shell scripts, build files, other configurations files (i.e. crontab, DHCPD configuration...), you will understand the limitation of those IDEs. There are text editing tricks that even make you more productive than many "code aware" features. Of course, you can always pay hundreds dollar for Visual Studio, when you can get something for free. And it includes features that regular IDEs does not have, outside of regular IDE features. For example, [live grep](http://tuhdo.github.io/static/live_grep.gif). Or [open a 39MB C soure file](http://tuhdo.github.io/static/performance.gif). &gt; The problem is of course that an IDE does understand your code. To do that, it unfortunately needs a project to know which files belong to it. &gt; &gt; Yes, an IDE is not the ideal tool for a quick debug session, just as a text editor is the wrong tool for a big coding session. Linus Torvald uses MicroEmacs (basically barebone Emacs without any feature), offer no syntax highlighting and other things. Yet, it works. Btw, I think if a tool is able to browse a project with more than 14 million lines of code, it's sufficient for large project.
While I agree that you shouldn't be using `std::pair` as a lazy way of getting out of writing a struct, I disagree that this means it should be considered harmful, and I think the example with the student records thing is a bit of a straw man that goes out of its way to show poor judgement. By all means, yes, don't do that, but I don't know that this is a real problem that exists. As the article even explains, there are just certain cases where you need to have a container of items of arbitrary mixed types, and having one of those in the standard library is a good thing since it encourages a uniform way of doing that. For that reason you can't really go down the whole "considered harmful" route, because it's more like a judgement call. The fact that we have both `std::pair` and `std::tuple` is merely due to the fact that `std::pair` is the best that can reasonably be accomplished in C++98 without variadic templates and without resorting to soul-destroying preprocessor shenanigans. Maybe in an alternative history we would have gone straight to `std::tuple`, but we have what we have. And it's really not that much of a mystery as to why `std::map` doesn't have its own special `std::key_value_pair` type. If you're going to codify one of these things in the standard, you might as well make it as generic as possible, again going back to the idea that this will probably come up from time to time and the standard library should be there to provide a uniform means of doing it. Naming it `std::key_value_pair` and giving it `key` and `value` members would have locked in a specific use case, requiring either lots of duplication to have both `std::key_value_pair` and `std::pair`, or just going without the fully generic option and forcing people to choose to either awkwardly use `key` and `value` in non-map contexts, or to write their own buggy versions. None of these options are good, so it seems relatively straightforward to me why we have `std::pair`.
The whole std::map thing where the iterator key/value are referred to as first/second respectively drives me up the wall when working with them. 
Shortcuts is kind of an understatement. My experience with QT Creator is that once it hits your standard library it throws its hand in the air and gives up. Needless to say, this makes it useless once you try to do something ~fancy~, like use `unique_ptr&lt;&gt;` or `vector&lt;&gt;`... The speed can be an issue, but generally I prefer correctness. (As long as it is within reasonable time frame. :-)) I will bow to your expertise as far as its error recovery goes, I only have experience with Clang as full compiler in this regard. (Although I can't remember having this problem with it.)
Right, sorry, I missed that. I meant it more in the sense of a general pattern, though. 
I agree. I definitely like that .NET has a `KeyValuePair` class instead.
The argument brought up for std::maps using std::pair is either stupid or manipulative in my opinion. The issue is not "element.second" but rather the declrataion "auto&amp; element". That is a use of bad auto imo and also a bad variable descriptor. "keyval_pair", "keyValue" or whatever your prefer is more readable than just "element". for (std::pair&lt;int, string&gt;&amp; keyval_pair : myMap) { cout &lt;&lt; keyval_pair.second &lt;&lt; endl; } That should be understandable, even for someone who knows Maps in general but barely any C++. The proposed code is also not very good. "value" is a very generic identifier and could mean other things than "the value of a key-value pair of a map". It could mean that element is of type myMap::key_type and has a member named value. For this to be good code, you would have to at least call "element" something like "keyval_pair" too. Then the discussion is just "Is it worth to add a new type to the standard library to make auto more usable?" The answer to that should clearly be "no", I think. Good IDEs, which C++ sadly has very few but some, make auto complete and variable type assignment easy so you don't have to type out everything. On the other hand, keeping std::pair used by std::map lets you call some functions without converting, for example std::swap.
std::pair is meant to be used for very boring, simple and *localised* cases where multiple values needs shifting at once, and so forth. Don't over complicate things. If you start seeing a repeated usage of the same std::pair or std::tuple all over the place, and is becoming difficult to maintain and follow, by all means, consider using a struct. If the definition of a struct is not worth the one off scenario for passing multiple values, then use std::pair. I don't consider them detrimental. Right tool for the right job.
Yeah this is what I get a lot when I am looking for a place to learn. *C++ Primer*. I think their should be something a whole lot easier to learn from, but then again it is almost like learning Greek.
&gt; for (std::pair&lt;int, string&gt;&amp; keyval_pair : myMap) value_type in std::map is an alias of std::pair&lt;const key_type, mapped_type&gt;, so your loop should look like this: for (std::pair&lt;const int, std::string&gt;&amp; keyval_pair : myMap) Auto prevents such errors.
You can't rename members with a typedef or an alias declaration, so `std::pair` would still have members `key` and `value` or `std::key_value_pair` would have members `first` and `second`. 
&gt;Shortcuts is kind of an understatement. My experience with QT Creator is that once it hits your standard library it throws its hand in the air and gives up. Needless to say, this makes it useless once you try to do something ~fancy~, like use `unique_ptr&lt;&gt;` or `vector&lt;&gt;`... Qt Creator gives up at templates. That is incidentally the main reason why it is fast. &gt;The speed can be an issue, but generally I prefer correctness. (As long as it is within reasonable time frame. :-)) I agree. There is a certain annoyance noticeable when opening a project takes 10 times as long as it used to do, though. So just switching the code model globally is not an option. Note that Creator ships has a clang based codemodel that you can enable and use in favour of the traditional one. &gt; I will bow to your expertise as far as its error recovery goes, I only have experience with Clang as full compiler in this regard. (Although I can't remember having this problem with it.) You will not have that problem with it in this use case.
Thanks for the criticism, I will probably re-position the move slide to the beginning, I may even add another slide with move semantics. Yes I have watched Herb Sutter's talk, I watch almost all talks. I think in this one he also talked about prefetching and contiguous memory, I also had this in my slides but I decided to drop it. Edit: I also had T&amp;&amp; in my slides to explain reference collapsing but I also dropped it, I didn't want to scare them. I probably should also drop variadic templates.
I don't think that's significantly more readable. If you don't know that a pair has members named `first` and `second`, you're probably not going to know what either version does. ("What's this `second` thing doing here? This map doesn't contain anything having to do with times...?") Moreover, if you don't know that a map represents values as pairs, then it's also not going to make a lick of sense ("What has pair got to do with my map of names to phone numbers?"). Sometimes you just have to know C++ to use C++. BTW, you made the common mistake of forgetting that the key type of the pair is `const`, a perfect example of the sort of problem that using `auto` does away with, in an example by someone decrying `auto`. 
&gt;I don't understand why you make it sound like a bad thing people are using emacs or vim. I really like the movement I have in it. I do understand that, I used to code in editors like the rest of us till I gave Qt Creator a spin:-) &gt; Show me an IDE where I can do that same advanced movement and macros and I will be happy to switch. *All* IDEs have advanced navigation features, but *none* of them will have exactly the zoo of hand-rolled macros that you have for your current setup (if you are anything like me that is). Give them a try anyway, you lose so much of the boring work! All of a sudden you start to do things that were just too tedious before. When I tell someone how easy it is to rename a method, then I get "I hardly ever do that anyway" from the text editor front. That is exactly the point: You do not rename methods and prefer to stick with a slightly wrong name after changing it since it is just too much tedious work to change it. A IDE turns this into a couple of keystrokes. &gt; And I want to be able to use it on Mac/Windows/Linux. I use Qt Creator. Works everywhere and handles C/C++ rather well IMHO. 
&gt; I prefer rtags[1] over GNU Global or Cscope. A lot more accurate because it uses clang as a backend. rtags seems neat but I never get it working with plain Make project after going through all the videos. Maybe you send a PR for updating the documentation (because the documentation stated that the videos are outdated? &gt; If you work with CMake, then cmake-project[2] provides the ability to call M-x compile from the terminal as you might expect. Thanks for the advice. I will look try it when I use CMake. But EDE already supports CMake, so I will likely to use EDE. &gt; While I don't personally use it, some people like to enable the various electric editing minor modes, ie. electric-pair-mode[3] for automatically completing matching bracket delimiters, etc. (Perhaps a bad example but electric editing is a big thing in emacs these days) I used to use electric modes for simple things. But then, it needed more features. smartparens allows you to wrap an active region with a pair (instead of deleting it like electric-pair, and I would like to turn on delete-selection-mode). It works not only with delimiter pairs (like parentheses), but pairs of programing tokens too. &gt; I also like auto-highlight-symbol[4] . It highlights other occurrences of the symbol your cursor is over. For auto-highlighting, there's a better package that provides more features as well as auto-highlighting: [highlight-symbol](http://www.emacswiki.org/emacs/HighlightSymbol). Setup: (require 'highlight-symbol) (highlight-symbol-nav-mode) (add-hook 'prog-mode-hook 'highlight-symbol-mode) (setq highlight-symbol-on-navigation-p t) After setting `highlight-symbol-on-navigation-p` to t, it will automatically highlight symbol at point. &gt; I use iedit[5] instead of multiple-cursors[6] because of better integration with evil-mode, but I'd say some notion of multiple cursors is a fantastic thing. iedit with narrowing regions[7] and indirect buffers[8] works really well for me. Sure, iedit is cool. I also use it instead of multiple-cursors. &gt; To prevent from opening up additional random buffers in the current frame, and to use just one frame for the compile buffer, I use this trick[9] . Works like a charm, and great for people using multiple monitors. Nice trick to know. Thanks. &gt; Also, I should mention, I find gdb-mi to have some issues (like not being able to add breakpoints to some files sometimes or placing the file buffer in the wrong section when backtracing segfaults)... Some people use the older GUD interface, I think invoked via M-x gud-gdb, which doesn't support gdb-many-windows. Sure, I will add gud-gdb soon. I know that sometimes the gdb-many-windows doesn't work well, but it works most of the time. I intend to introduce the GUD interface, not only gud-gdb.
&gt; You do not rename methods and prefer to stick with a slightly wrong name after changing it since it is just too much tedious work to change it. A IDE turns this into a couple of keystrokes. What's wrong with using `sed` then?
&gt;Qt Creator gives up at templates. I see many problems with that design in its future, given how modern C++ is very template heavy...
Seal, that is why there is Clang based code model. The plan was to have that the default for a couple of releases now:-( It is not too bad for Qt programs. Those usually have way fewer templates than other C++ programs.
False positives:-)
Yeah I should probably replace the vector&lt;int&gt; with something more complex and use auto in the for loops, thanks. About the auto_ptr, was this really in C++98? I always thought it was introduced in C++0x? Edit: It seems you were right, it was C++98, I only know C++11 so I have to do some reading.
Java doesn't have a pair and that is infuriating whenever you want to create a map with a pair of values as key: std::map&lt;int, std::map&lt;int, std::string&gt;&gt; is a stupid idea in C++ and the same is true for Java. The rationale is funny too: Pair is not semantic. So, remind me, why does Java have int? Why does Java have arrays?
Thanks for that. I rarely use maps. &gt; Auto prevents such errors. No, it does not. It hides them. If I used auto there, the program would compile and do something else than what I had in mind, which is definitely a bad thing. If I would actually use that code I would get compile error and change my code accordingly.
&gt; Sometimes you just have to know C++ to use C++. The article stated otherwise, not me. I only responded to it.
auto_ptr is actually deprecated in C++11. unique_ptr is preferred.
auto_ptr was introduced in C++98, and is considered deprecated now, replaced by unique_ptr. The problem with it was that it did a "move" when it was copied, which became confusing. Since C++11 has std::move() now, it makes much more sense, and unique_ptr should be used in place of auto_ptr as a result.
Typedef solves some of the problems with std::pair. You still have to remember what's in .first and .second though.
Big thanks for this. I've been doing C++ dev in emacs for... 7 or 8 years now, but I've never really put in the time to really make use of anything but the most basic features.
There's already a permanent link to cppreference in the sidebar. No need to submit it here.
&gt; So maybe emacs can apparently indeed embed the beginnings of an IDE. I stand corrected. Lets hope at some point the code model will at some point actually be used for interesting things:-) Can you named me a few interesting things outside of refactoring? What is at the beginning of IDE? CEDET exists many years ago, and I already gave you a Boost screenshot. When I used Eclipse, it even doesn't have fuzzy matcher for narrowing completion candidates. What if your completion list get more than 100 candidates? The primitive completion popup Eclipse provides won't be useful anymore. The fancy code model you said is nothing more than parsing result gotten from a parser, with small applications written to make uses of the parsing results. Emacs can surely make use of Clang with project like [rtags](https://github.com/Andersbakken/rtags), or you can use the built-in CEDET. &gt; ... or spend that money on RAM and use Eclipse, Qt Creator or KDevelop. All of these are free software and have a code model. RAM never hurts when working with a code model and helps even more than usual with eclipse:-) None of them is equivalent to Visual Studio. &gt; Anyway, just because one guy uses something does not make that the one true solution for everybody else. Sure. &gt; Why would have a text editor problems with that? It does not do anything interesting with all that text and will just show it one screenful at a time. It can manage and make use all that text. For example, within Emacs, I can jump anywhere with a few keystrokes. Using Eclipse, you have to move your hands to the mouse, open a menu and click something. This prevents a smooth experience. If somewhere in the kernel failed to compile, with only few keystrokes I can jump to the error immediately. I can open hundreds to a thousand files in Emacs and manage all that text. Here is a [demo](https://github.com/emacs-helm/helm#advanced-usage) that I can narrow to a few files that contains some text, within a few keystrokes and interactively! The number of files opened are 252 (it is written just above the prompt where text is typed). You should noticed that's the same interface I used in the Boost completion demo. Whatever it is, this is just one use case. May I ask, what editor did you use before switching to the "IDEs"? If it is anything other than Emacs or Vim, sure it will be terrible compare with those IDEs. For Emacs and Vim, it's different. If you use either Emacs or Vim and don't miss at least anything from it, sure you misused it or does not bother learning advance features. Emacs is productive because it makes operate on little things much more productive. These little things are what IDEs are terrible at. I gave you a few demonstrations above: - live grep: you said this is not exclusive to Emacs. Show me an example. In Eclipse, you do not get feedback for every key or every few keys you type. - blazing fast search and open file: see how I [quickly search and opened desired file in Linux kernel source tree](http://tuhdo.github.io/static/helm_projectile.gif) with more than 40 thousands of files, **interactively**. The only thing equivalent is in Visual Studio, but it does not offer global interface for any other things. Eclipse only has Ctrl+h. Good luck. - [interactive outline tree](http://tuhdo.github.io/static/part3/helm-semantic-or-imenu.gif), that only opens when you need and will never take your screen estate. Tell me the equivalent in Eclipse. - [Diff between current revision and previous revision](http://tuhdo.github.io/static/vc-diff.jpg), with only a few keystrokes. In Eclipse, everytime you want to do this, you have to right click on a file and select diff through a few levels of menu. Slow. - [Quickly select files/directories in previous working session](http://tuhdo.github.io/static/helm-buffer-list.gif). You can narrow through thousands of files easily. Now, compare it to the "Recent Files" list in Eclipse, that can only keep track a tiny number of files. - [A cilpboard of all your cut/copied strings in the past](http://tuhdo.github.io/static/part3/helm-kill-ring.gif). - [Emacs can remember its window layout](http://tuhdo.github.io/static/register-windows.gif). So effectively, if you have 4 files you are viewing at the same times, and you use create other layouts for working with different things. Later, you can restore the exact old layout with 4 files effortlessly. The so called perspective in Eclipse is really rigid. - [Emacs can add multiple directories into the same view](http://tuhdo.github.io/static/dired-subdir.gif), making it easy for managing multiple directories easily. You can open multiple directories in a flat structure like that and save it for later use. That is, once you restore, you have all the inserted subdirectories ready to use. The file explorer using nested trees does not work so well for large project tree. These are the tip of the iceberg.
Google test and mock would be a good start.
rtags is definitely worth the effort to get working, I don't think I would do C++ in emacs without it.
The AI was simple; it just guessed randomly. You could make it more complex, like /u/kradem mentioned. This was my first real assignment, so I really didn't know how to implement an analyzer.
I will give it a try it again. Probably I will open an issue if something goes wrong to ask for advice.
&gt; Seriously, it is amazing how us open source guys are stuck to software development from the late 1980. I neared way too often that a real programmer uses him or emacs and a terminal (and maybe gdb, but only on the command line). We are in the 21th century, go out and try a real IDE for a week or two. It's interesting you say that. There are many people who hold this idea (including my boss who calls me "old fashioned" :P), but I think our differences root themselves in core principle or philosophy. Consider for instance, this case. You and I are both walking along looking to purchase houses. We come across two different homes... The first, fully furnished, but the furniture is fastened to the floorboards. The furniture is pretty nice, and conveniently arranged in a way where it suits most everyone comfortably, and impressed, you decide to purchase the house. The second is not furnished, but rather contains a bunch of tools and wood. We look at the previous owner oddly, and he exclaims, "I know it doesn't look complete, but you can make it into anything you want, that fits *you* most perfectly!" I say why not and buy the house. IDEs fit most developers very comfortably. It's the notion of sane defaults with a powerful collection of utilities to get the job done. If you don't want to have to build up such utilities yourself, then this is the way to go. Of course, they do allow for customization, but not to the extent that editors like Emacs allow. Emacs on the other hand takes a lot of time and effort to craft into something that is specifically designed for the way *you* work. Sure, it's a rough voyage to get it up to that point, but I'm very happy with my setup now that it is where it is. Of course, like most everyone, I've spent much time in an IDE (including QtCreator), but I just don't find I'm as productive or even as excited about my work in such an environment. It's a personal preference, and there are great developers on both sides of the table.
&gt; the program would compile and do something else than what I had in mind In a world without auto I'm guessing a vast majority of loops that looked like this would be a case of "I just want to iterate over this map", not "I specifically meant that I wanted non-const ints".
Every C++ programmer should know what tag dispatching is and when to use it.
&gt; std::map&lt;int, std::map&lt;int, std::string&gt;&gt; is a stupid idea in C++ The author's not suggesting `map&lt;int, map&lt;int, string&gt;&gt;`, but struct DescriptiveKeyName { int descriptiveName1; int descriptiveName2; }; map&lt;DescriptiveKeyName, string&gt;
&gt; You still have to remember what's in .first and .second though. That's the part that's more of an issue imo.
Which wouldn't work, since you would have in addition to define `operator&lt;()`, making this complete and utter overkill. Aside from that: What is the descriptive name?Often the two things are completely independent and their union is never needed elsewhere, because all we want is a map that takes more than one key.
On slide 10 - `std::make_unique&lt;T&gt;` is not in C++11. It is in C++14. 
I donâ€™t think that this is true at all though. Not in my experience at least (but it's been some time since I used it, so I could be wrong). I know for a fact that the code completer has unit tests for complicated template stuff, such as template base classes etc. which is pretty advanced. 
&gt;Can you named me a few interesting things outside of refactoring? All those refactoring operations are of course the most interesting things here. But basically I judge the quality of an IDE by how central the code model is, how much is connected to it. &gt; What is at the beginning of IDE? In the begining there is a code model:-) &gt; CEDET exists many years ago, and I already gave you a Boost screenshot. ... and still this looks (I never used it and you already corrected some misconceptions of mine) like something that is bolted on to the rest. Does e.g. the commit editor offer syntax highlighting based on the data in the code model? &gt;The fancy code model you said is nothing more than parsing result gotten from a parser, with small applications written to make uses of the parsing results. Exactly. The more central to the user experience the code model is, the more potential the IDE has. Unfortunately there are many ways to ruin that potential:-). First of: Eclipse has made some horrible UI choices, I fully agree with you there. I still would love to see open source developers to give it -- or other IDEs -- a serious try, just to see what they are missing out on. I run into so many people in the open source world that are actually proud of their ignorance of what an IDE can do for you. I do not want to count how often I have been told that all IDEs suck, because they have no vim bindings. Or that IDEs are for noobs like their co-workers, but not for hackers like them. &gt;It can manage and make use all that text. Sorry, but if that is not possible, then the editor is not worth its name, independent of wether that editor is part of an IDE or not. &gt;Whatever it is, this is just one use case. May I ask, what editor did you use before switching to the "IDEs"? If it is anything other than Emacs or Vim, sure it will be terrible compare with those IDEs. Mostly emacs, I could personally never understand the allure of vim. &gt; For Emacs and Vim, it's different. If you use either Emacs or Vim and don't miss at least anything from it, sure you misused it or does not bother learning advance features. So if I come to other results than you do, then that must be because I am stupid. Thanks, so far I really enjoyed our argument. I never said that I never missed anything from the good old days, but going back I miss my code navigation and especially the refactoring more. &gt; Emacs is productive because it makes operate on little things much more productive. These little things are what IDEs are terrible at. Yes. Emacs is nice, but it is -- like everything else -- not perfect. Neither is Qt Creator, but it still is my preferred environment at this time. &gt;I gave you a few demonstrations above: &gt;- live grep: you said this is not exclusive to Emacs. Show me an example. In Eclipse, you do not get feedback for every key or every few keys you type. QtC does when searching for filenames, class names, method names, etc. after hitting Ctrl-K. It does not for full text searches. &gt;- blazing fast search and open file: Does not look too impressive to me. Maybe I am missing something here or I am spoiled by QtC Ctrl-K again. &gt;- [interactive outline tree] Is that the outline of the current file or what is that? QtC has that too, but I never use it much... Jumping to stuff in the current file is again faster with Ctrl-K, the generic navigation shortcut. &gt;- [Diff between current revision and previous revision](http://tuhdo.github.io/static/vc-diff.jpg) All keystrokes here in QtC land. I doubt that you use this often enough that using the keyboard in stead of the mouse will make you faster overall. This is just micro optimization. &gt;- [Quickly select files/directories in previous working session] QtC has sessions, too. &gt;- [A cilpboard of all your cut/copied strings in the past] I always thought that is what the OS does? I am not aware of this in QtC, but then I have tons of snippets for the text I need regularly. I can't remember what I stuffed into the paste buffer anyway:-) &gt;- [Emacs can remember its window layout] QtC does as part of the session. &gt;- [Emacs can add multiple directories into the same view] I do not see why that is a feature. I start typing the filename and there is the file. Why would I even want to bother grouping folders? &gt;These are the tip of the iceberg. I personally fell in love with QtCs code navigation. Follow symbol (F2) is just great. So is Ctrl-K, which takes you around your project (jump to classes, methods in all kinds of Scopes, files in the project or filesystem, lines, help, you name it). And of course there are lots of small refactoring methods. Need to have a string marked as translatable? Hit the refactor key combo and QtC will do the right thing for that string. Need to rename a parameter to some method in some header? Hit refactor and QtC will make sure that the source file is also updated (incl. all usages of that parameter in the method). Need to implement all virtual methods of the base classes? Hit refractor. There are *tons* of these little gems. They help me being productive, and free my mind for more important things. PS: I do not need a mouse for QtC. You seem to think a mouse is a prerequisite for using an IDE. It is not.
QtCreator really is an excellent C++ IDE, IIRC Valve recommended it to developers moving to Linux for SteamOS development.
Using `auto` here disallows changing the key. Using your version lets you change it without anything actually happening. I see no advantage to the latter unless you explicitly want to change the key locally for some reason.
It's been working fine for me with libstdc++. The [version I have right now](http://llvm.org/builds/) has full C++14 support and recognizes that `for (x : cont)` is C++1z syntax, but doesn't actually support it yet (AFAIK, it is supported by Clang, though).
The proper way to do this is just to check the setting that says to keep the window open in C::B. Or you could run it from the console because it's a console application. Forcing it to pause outside of an IDE is abnormal behaviour.
Do the LLVM builds work independently of Visual Studio? Something similar to MinGW in that it is a full solution out of the box? I want an installer similar to what I can get from TDM-GCC. 
Clang has a working implementation of modules. Please get them sorted out by C++17!
That should be `Ts&amp;&amp;... xs` and `std::forward&lt;Ts&gt;(xs)...`.
And that TS is kind of dead for now.
It's sort of there. `auto noobPrint = [](auto t) {std::cout &lt;&lt; t;};`
"A vast majority" is not "all". For example, a beginner might want to increase the key of every map value by 1. Both using explicit type definition of std::pair&lt;int, T&gt; and using auto will cause a compile error. The difference is the place where the error happens. If you use the full type, the line of definition will cause the error. If you use auto, the first time you try to call a non-const member of pair.first is the problem. Obviously, the first option is better.
I really like Visual Studio as an IDE and the debugger but how would I go about using VS with a different compiler(clang/g++) ? Or should I switch to another IDE? Btw, I'm on Windows 
&gt; "A vast majority" is not "all" Okay, but so you agree that in not all but a vast majority of cases auto does fix the problem? Getting the error when trying to modify the element doesn't seem so bad either. for (auto&amp; p : m) ++p.first; You get an error on `++p.first` and think "oh, I guess I can't modify a map's keys while iterating over it". In fact, I'd argue that ++p.first is where the error _really_ is in that snippet. Even if I had written for (pair&lt;K, V&gt;&amp; p : m) ++p.first; The real issue here is that I'm trying to modify a map's keys while iterating over it, not that I got the type wrong. Fixing it to for (pair&lt;const K, V&gt;&amp; p : m) ++p.first; doesn't solve the fundamental problem. Also note that this problem exists in pre-11 land: for (map&lt;K, V&gt;::iterator it = m.begin(); it != m.end; ++it) ++it-&gt;first; I didn't even have a chance to declare what I thought the value type was.
I would definitely not buy a house with the furniture bolted down:-) I actually think we agree in that a good developer has a wide range of tools at his or her disposal. In this time and age IDEs should be part of any developers toolbox. Considering that you claim to have used an before IDE you seem to agree:-) So in your image: Buy whichever house you like better, but learn to use a power drill. Do keep your gimlet around for the "gimlet shaped" tasks that are bound to come up. An IDE is not "the tool to end all other tools". There are plenty of situations where a text editor and a stand-alone debugger are the better choice. I ran into surprisingly many people using one of the big-two text editors because that is what they have always done. They became trapped in their own muscle memory and can not even thing about trying anything new anymore.
&gt; I think their should be something a whole lot easier to learn from IMHO "C++ Primer" is the best C++ book for someone who has programmed before (just the basics, doesn't matter which programming language, although preferably a compiled one -- e.g., knows what a variable or a `for`-loop is, comfortable with using functions, good if also familiar with I/O fundamentals, perhaps also knows some basics about `class`es, etc.). If you have this background, you shouldn't find it hard, and the books with less prerequisites will simply waste your time (since they won't go into the C++-specific content soon enough to be productive and will instead spend more time on introducing &amp; encouraging you to practice the aforementioned prerequisites). OTOH, if you're looking for a book that introduces programming itself (and assumes no prior programming prerequisites), then PPP2 by Bjarne Stroustrup can be a good option: http://www.stroustrup.com/programming.html Give it a shot, perhaps it will help! :-) EDIT: what's important and shouldn't be discounted is that both "C++ Primer" and PPP2 target modern C++ (C++11, with PPP2 even updated for C++14, although the C++11&lt;-&gt;C++14 diffs are minor from the standardization point of view) -- the problem with most on-line tutorials is that they're often *extremely* out-of-date and using obsolete programming constructs which can be both harder to learn and less useful in general, thus only wasting your time with things you (should) never use (which also happen to be more error-prone, which in turn can only unnecessarily add to frustration when you're learning) and never getting to "proper" C++ than can actually make you productive -- a lose-lose proposition, really. This is probably what you were being warned about. 
As a followup, a template function can be written to provide the same functionality as make_unique, but, as correctly stated above, it is not part of the C++11 standard.
On slide 5: - Having the syntax be hard to parse isn't relevant. You're not the one writing the compiler, you're just writing the language. - Different compilers to behave differently but if you stick to standard C++ you should be fine. Unfortunately some support features while others don't but I don't see how this is a C++ specific con. - Not sure how 'Nullpointer' is a con. What does that even mean? The availability of `nullptr` makes sense and it's entirely up to the user if pointers are to be used. On slide 6: - The explicit type doesn't need `std::allocator&lt;int&gt;`, it's the default for `std::vector&lt;int&gt;` so it should be `std::vector&lt;int&gt;::iterator`. - C++98 doesn't have `begin(v)`. You should use `v.begin()` instead. On slide 7: - You can do the 'use case' without `std::function` in both C++98 and C++11. In fact, it's preferred because `std::function` uses type erasure which has minor overhead. It doesn't matter for most cases but if you do it everywhere it'll catch up. Example: template&lt;typename Function&gt; int call(Function f) { return f(1, 1); } On slide 9: - The explicit return type of the lambda isn't needed. The compiler will figure it out for the basic cases. - Again, it's better to use a template instead of `std::function` as a parameter in the general case. On slide 10: - `std::make_unique` is a C++14-ism. On slide 16: - In C++98 this wouldn't copy. It'd exhibit NRVO. - Your move constructor should probably use `std::move`. On slide 17: - You can use [`std::is_arithmetic&lt;T&gt;`](http://en.cppreference.com/w/cpp/types/is_arithmetic) instead. :p Those are all my two cents. Some are kind of minor but I figured they'd be worth mentioning anyway.
Maybe I can go back and finish ALL my Java before this, and hope that their comes a better way to learn it.
have to agree that that is a pretty poor design choice by the std people. I recently revisited some code I wrote that has been running happily for a year and the proliferation of first/second everywhere would be OK except I used a std::pair for something else in the same piece of code so it took a bit of time to unravel it. If i get a business case for it I think the whole thing will need chucked away and redone.
Good point. Tuples are a bit special that way. `std::tie` and `std::make_tuple` each have their purpose.
Is there an up to date guide on getting clang working on Windows with MinGW-W64? Looking around everything I find is a year or more out of date. 
Thanks for pointing out that begin(v) is C++11, I didn't know that. Also nice catch I completely forgot std::move in my constructor. For std::function, if templates are preferred what is the use case of std::function? For syntax is hard to parse: That might be editor specific but if I try to open a large code base like Unreal Engine 4 in Visual Studio it is basically unusable. I can't tell if that is the fault of VS or C++. Nullpointer is sort of strange because you have to check if a pointer is not null, but you can still mess up and access a nullpointer. In languages like Rust and Haskell you always have to check the result and it gives nice things like a maybe monad. For different compiler: I have some bad experience with c++ compilers for example MSVC seems to have a lot of extensions like non const references to temporary strings. I find non standard stuff like this somewhat strange. And for the allocator, we might use TBB which gives us a special allocator and I just wanted to show off the complete type of a vector iterator. I am pretty sure that no one has seen an allocator in a vector before. Thanks for the write up. Edit: I also didn't know about NRVO. I have to find another example. Edit2: Do you know of any cases where the C++11 compiler will move by default and the C++98 will make a copy? 
Just want to say that "Effective C++" was the pivotal book for me back in '93. I love the format of making an assertion (e.g. "prefer so-and-so"), and then going through all of the alternatives and explaining the pros and cons. I read through it once, then would occasionally browse through the TOC until I found some assertion that I couldn't remember the justification for, and would re-read that chapter. This book taught me what to do, why to do it, and the thinking involved in future design decisions. Through the years, I've recommended this book to anyone who'll listen. I'm looking forward to buying a copy of this when it's available.
&gt; You need to write an additional metafunction to map the type to its tag. Yeah, why bother writing a single function that does the selection logic when you can spread it out and repeat it several times in multiple different templates.
Yep good question. At work I have this exact setup; VS purely for code editing and it's sometimes useful intellisense, and Linux on a VM and I compile with gcc and debug with gdb/ddd. Our build system is currently Boost jam, so we have jamfiles everywhere. The VS solution/project files are there too so we can build on either platform. Currently those two systems are independent from each other; a developer has to maintain both sets even though they only use one. We are trialling CMake at the moment and I believe we'll gradually move to it, so we end up just supporting one system instead, while still letting devs use whichever OS+IDE they want. I should add that the easiest method of all is to just make VS use gcc/clang as compiler; VS and the MSVC compiler can be decoupled. Here is the [clang link](http://llvm.org/docs/GettingStartedVS.html), I can't find a decent link for gcc except this [stack overflow page](https://stackoverflow.com/questions/14768073/how-to-use-gcc-with-microsoft-visual-studio), and this plugin, [VisualGDB](http://visualgdb.com/), which I can make no claims for or against since I have never used it; use at your discretion.
That works for a one-liner example, like you did, but not for bigger code. The pair might be passed through several functions first and you would have to backtrace the error. An error should not occur in the line which you have to change but rather the line which tells you what is wrong. If you never worked with maps, that is clearly the point where the iterated variable is defined.
&gt; Works everywhere and handles C/C++ rather well IMHO. Terminal window?
&gt; That works for a one-liner example, like you did, but not for bigger code. The pair might be passed through several functions first and you would have to backtrace the error. In my (somewhat limited) experience, pairs you get from iterating a map tend not to be passed off to other functions in their entirety most of the time. But even ignoring that, having the pair passed through several functions isn't an issue; the first function you pass it to will either have the right signature or not, and this will be where the error occurs, in the body of the loop. &gt; An error should not occur in the line which you have to change but rather the line which tells you what is wrong. If you never worked with maps, that is clearly the point where the iterated variable is defined. I'd argue that the line trying to modify the key is precisely the line that tells you what is wrong: you're trying to modify a map's keys while iterating over it, which is not something you can do.
right, and i would feel uncomfortable getting the key out of a *key_value_pair* through it's member *first*
That's MS. Here's a solution in search of a problem. 
std::map&lt;int, std::pair&lt;int, int&gt;&gt; ran into this beast the other day.
The link points to a list of open source C++ libraries, not the front page of cppreference.com.
I honestly thought I clicked the link...which, obviously, wasn't the case. That said, said linked page is poorly described as a "C++ library reference". Why not just stick to the page's title, "A list of open source C++ libraries"?
I have to assume that there is some kind of miscommunication here. Pointers are faster at what exactly? Because it doesn't make sense as it's stated right now: following a pointer instead of directly accessing memory is basically always slower except maybe under special circumstances.
&gt;auto_ptr was introduced in C++98, I'm pretty sure auto_ptr was introduced with C++03, under the tr1. Unless I'm mistaken? 
&gt; Yeah, why bother writing a single function that does the selection logic when you can spread it out and repeat it several times in multiple different templates. You can see the type requirements for each overload, whereas with tag-dispacthing you have to reverse engineer the single metafunction. Also I don't know what you are talking about repeating it in multiple different templates? With tag-dispatching you have to repeat a lot and it gets a little ugly. Look at the tag-dispatch solution: // // Create the tag structs // struct incrementable_tag {}; struct decrementable_tag : incrementable_tag {}; struct advanceable_tag : decrementable_tag {}; // // Create the tag metafunction // template&lt;class T&gt; struct traversal_tag : std::conditional&lt;(models&lt;Advanceable(T)&gt;()), advanceable_tag, typename std::conditional&lt;(models&lt;Decrementable(T)&gt;()), decrementable_tag, incrementable_tag&gt;::type &gt; {}; // // Create the impl functions to dispatch on tha tags // template&lt;class Iterator&gt; void advance_impl(Iterator&amp; it, int n, const advanceable_tag&amp;) { it += n; } template&lt;class Iterator&gt; void advance_impl(Iterator&amp; it, int n, const decrementable_tag&amp;) { if (n &gt; 0) while (n--) ++it; else { n *= -1; while (n--) --it; } } template&lt;class Iterator&gt; void advance_impl(Iterator&amp; it, int n, const incrementable_tag&amp;) { while (n--) ++it; } // // Create another function to dispatch // template&lt;class Iterator, REQUIRES(models&lt;Advanceable(Iterator, int)&gt;() || models&lt;Decrementable(Iterator)&gt;() || models&lt;Incrementable(Iterator)&gt;())&gt; void advance(Iterator&amp; it, int n) { advance_impl(it, n, typename traversal_tag&lt;T&gt;::type()) } Now compare that with conditional overloading: // // Define the overloads with each of their requirements // struct advance_advanceable { template&lt;class Iterator, REQUIRES(models&lt;Advanceable(Iterator, int)&gt;())&gt; void operator()(Iterator&amp; it, int n) const { it += n; } }; struct advance_decrementable { template&lt;class Iterator, REQUIRES(models&lt;Decrementable(Iterator)&gt;())&gt; void operator()(Iterator&amp; it, int n) const { if (n &gt; 0) while (n--) ++it; else { n *= -1; while (n--) --it; } } }; struct advance_incrementable { template&lt;class Iterator, REQUIRES(models&lt;Incrementable(Iterator)&gt;())&gt; void operator()(Iterator&amp; it, int n) const { while (n--) ++it; } }; // // Combine them together into one function // static conditional&lt;advance_advanceable, advance_decrementable, advance_incrementable&gt; advance = {}; It looks much simpler(and is shorter), and its easier to tell the what the type requirements are for each function.
&gt;If I give you a std::pair&lt;string, int&gt;, thereâ€™s no way of knowing what that is ... but if you typedef it, or trivially derive from it, you know what it is. So that's not a problem. The problem are first and second.
I suggest that you convince them about nullptr, or they won't get why this feature was added: void f(char *); void f(int); f(NULL); //Calls f(int) f(nullptr); //Calls f(char *); This would a subtle bug if you use the old NULL macro. In the slide for constexpr, you say it is evaluated at compile-time. This is a mistake. To force evaluation at compile-time, you must use constexpr at the call site or the context must be a context where it is implicitly done. So you should do this in your slide: contexpr int res = fact(5); //Note the constexpr std::array&lt;int, fact(3)&gt; arr; //No need for constexpr in this context, since a template parameter must be constant and the compiler knows it. One important thing you are missing, performance-wise, is the use of noexcept. This generates better code, which is important for high performance contexts. Make sure they know about it at least. But don't abuse noexcept. 
It only looks simpler because you've not included the whole thing. While the tag dispatching code is it, that's all there is (in fact you overcomplicated it), your linear overload search is much more complicated but resides in the conditional library type. That's great and all that you abstracted that, but it's not even needed. I see this happen way too often. People go straight for TMP and SFINAE when the problem requires nothing more than the definition of a few empty classes. They rewrite overload resolution in templates rather than just using the compiler to do it. You've also forgotten a little bit of power and flexibility the tag version has, as you've written it in fact, that your conditional version certainly does not. I could override the resolution for any given type any way I see fit if I need to. All I need to is create a specialization of `traversal_tag` for the type. Because your conditional type insists on doing all that work itself using SFINAE there would be no way for me to customize it. Works OK given that all the calls and such that your concept constraint is assuming work, but as soon as someone wants something even the slightest bit different your advance function becomes useless. Tag version compiles faster, has more expressive and customization power, utilizes tools that exist rather than rewrite them (even if in library form), the dispatch code is easier to step through...it's better in almost every way.
 std::map&lt;string, pair&lt;int, bool&gt;&gt; studentToScore; // name -&gt; { score, honor code signed } Not that this is an universal solution, but arguably less code to maintan. I wouldn't use this for a domain entity, but for an implementation detail that's limited in scope, it's good enough. 
I'm learning C++ and I wrote a toy program which takes a coordinate (x and y). Coming from Python where tuples are widespread, I used a pair although I did feel readability was hindered (you can't do `x, y = point`). That's basically how I found this article which I felt covered the topic quite nicely.
&gt;No, currently Emacs highlights based on regular expressions, but it is a good thing. No, it is not. RegExp based highlighting is severely limited: It can not know "this is a local variable", "this is a member variable" and "this method here is a implementation of a virtual method". Having that information available in the highlighting makes a huge difference. &gt; But then, parsing takes time. What happens to QtC when you open large files and hundreds of them? Suddenly the performance degrades because all the parsing it performs. That is correct. Performance becomes a bit laggy when you open a project or reconfigure it. That takes a couple of seconds each time. &gt;CEDET was created for a long time, so certainly Emacs is not at the beginning of an IDE. It's just that most people use Emacs do not bother with it. In my definition an IDE is a set of tools sharing and working on one central code model. I admit that might be a bit different from other peoples definition, but this "programs lumped into one UI" approach that seems to be the normal definition is just so horrible:-/ You say Emacs has a code model and then go one to say what is *not* using that data. So it is in my definition only the beginnings of an IDE. &gt;When I compile with Makefile in IDE, all I get is non-interactive plain text. That is more a sign of a sucky IDE than on emacs supremancy. And yes, emacs can do a thousand things other systems can not. I annotated contesting that. But it falls short on code navigation (not text navigation) and on working with code (again, it is great for working with text) &gt;&gt; QtC does when searching for filenames, class names, method names, etc. after hitting Ctrl-K. It does not for full text searches. &gt;I've looked at it. The search is pretty limited; it's not the same as Helm or project finder in Visual Studio. You can only insert a single string for searching, and not regexp. The UI is quite complex compared with Helm or VS project finder. You should read [Why Helm is powerful](http://tuhdo.github.io/helm-intro.html#sec-28). Basically Helm allows you to incremental search with many patterns (each pattern is a regexp), and the result is narrowed according to the supplied patterns. Helm seems more like a clutch to me: What I want is to find a method named foo. An IDE knows which of the 1000 foos is a method, which is a class and which is a variable, macro and whatever. Helm(?) does nit know, so it needs to hop along on multi match clutches and RegExps. &gt;Does Ctrl+k support for other files aside from its "code model"? Why would it want to do that? Is a file is not part of the project you are working on then why do you care? &gt;Does it (Ctrl+k) offer fuzzy finder? IIRC it does case matching. Not 100% sure though. &gt;Again, read [Why Helm is powerful](http://tuhdo.github.io/helm-intro.html#sec-28). It has an example there. It is a totals generic text search thing. That is not what I want when working on code projects. It is really cool for other things. I will skip a rather generic list of nice text editor features. We agree that emacs has those and QtC does similar things anyway. &gt;&gt; I personally fell in love with QtCs code navigation. Follow symbol (F2) is just great. So is Ctrl-K, which takes you around your project (jump to classes, methods in all kinds of Scopes, files in the project or filesystem, lines, help, you name it). &gt;The way Emacs organizes key bindings make it easy to remember: Nobody is arguing this point. &gt;Finally, Emacs is a real IDE of its own language - Emacs Lisp. The whole Emacs is an interactive environment of Elisp. How does that help with anything but emacs? Your reply so far looks a lot like microbenchmarking to me (Look I am 5ms faster with the "insert the &amp; character" benchmark) without keeping te big picture in mind (How can I be more productive overall?). You are listing cool text editing and text navigation features. Any code navigation/editing features are notoriously absent so far. How do you implement all pure virtual methods in a derived class? Or something really simple classic: How do you rename a local variable 'i' in a huge file? Think about high level tools for a change:-) Getting people to think in terms of high level tools is all I want... and of course ranting that the author of that blog post did not follow *my* definition of what an IDE is:-).
&gt; No, it is not. RegExp based highlighting is severely limited: It can not know "this is a local variable", "this is a member variable" and "this method here is a implementation of a virtual method". Having that information available in the highlighting makes a huge difference. Fair enough. But I don't think that highlighting at this level matter much. Probably I work mostly with C so I don't care enough. This is a nice little feature to have, but not using the code model for highlighting or indentation does not make something primitive. &gt; That is correct. Performance becomes a bit laggy when you open a project or reconfigure it. That takes a couple of seconds each time. I mean, you open hundreds of files in your coding session, or 39 MB C file like I demonstrated. How is the performance then? &gt; In my definition an IDE is a set of tools sharing and working on one central code model. I admit that might be a bit different from other peoples definition, but this "programs lumped into one UI" approach that seems to be the normal definition is just so horrible:-/ CEDET makes use of the SemanticDB other things. For example, if you want traditional outline tree merged with file browser, you also have [speedbar](http://cedet.sourceforge.net/speedbar.shtml). Work in terminal as well. &gt; You say Emacs has a code model and then go one to say what is not using that data. So it is in my definition only the beginnings of an IDE. No, I said that other people don't bother learning it and complain for lack of features. But to be fair, these features are not activated by default. &gt; That is more a sign of a sucky IDE than on emacs supremancy. And yes, emacs can do a thousand things other systems can not. I annotated contesting that. But it falls short on code navigation (not text navigation) and on working with code (again, it is great for working with text) No, it has CEDET and I already demoed that in my guide. I already posted Boost demo. Here is [reference gathering demo](http://tuhdo.github.io/static/c-ide/semantic-symref.gif). In the screenshot, I gather all references of the struct *setting*, group in this tree format: - Top level node is the file that contains references of the struct *setting*. - At second level are functions/structs that use struct *setting*. - At the last level are occurrences of the struct settings that you can jump. You can jump to struct/class/function definition with other semantic commands. You can use external tagging tools for fast jumping. &gt; Helm seems more like a clutch to me: What I want is to find a method named foo. An IDE knows which of the 1000 foos is a method, which is a class and which is a variable, macro and whatever. Helm(?) does nit know, so it needs to hop along on multi match clutches and RegExps. What? How can [helm-semantic-or-imenu](http://tuhdo.github.io/static/part3/helm-semantic-or-imenu.gif) does not tell you what foo is a method, what is a variable definition? It lists full information there. The listing is, of course, make use of the SemanticDB as well. &gt; Why would it want to do that? Is a file is not part of the project you are working on then why do you care? Because some project contains other thing among your source files. For example, what about patch files? What about shell scripts? What about configuration scripts? Other tests written in other languages? Of you simply wanting to learn another language, and you have to learn a complete new IDE, like PyCharm. With Emacs, it supports for most languages out there, many are little known. &gt; It is a totals generic text search thing. That is not what I want when working on code projects. It is really cool for other things. &gt; I will skip a rather generic list of nice text editor features. We agree that emacs has those and QtC does similar things anyway. &gt; Your reply so far looks a lot like microbenchmarking to me (Look I am 5ms faster with the "insert the &amp; character" benchmark) without keeping te big picture in mind (How can I be more productive overall?). You are listing cool text editing and text navigation features. Any code navigation/editing features are notoriously absent so far. Sure, it is a total generic and **powerful** text searching. It's a framework that can be used for many things, not just text; for example, you can [browse files](http://tuhdo.github.io/static/part3/helm-find-files.gif) with it. As you can see how it can replace the typical outline trees in regular IDEs. But I want to make my point clear here: There are other ways to be productive. Having a built-in parser is great, but it is NOT the only way. I demonstrated those other features that do not fit the code model to reassure this point. Yes, QtC is cool with its support for its language, CPP. Outside of that language, it fails. You should be fair: you reply on IDE's code model to be productive; people in Vim and Emacs relies on generic text manipulations and optimized management utilities to make up for it. Emacs has its own language analyzer, of course, either built-in (Semantic) or external (tagging tools, language REPL). You really underestimate those micro-optimizations. With little optimizations, suddenly you become much more productive as a whole. &gt; How do you implement all pure virtual methods in a derived class? [function-args](https://github.com/abo-abo/function-args#moo-propose-virtual) package also makes use of SemanticDB (your code model) and allows insertion function body of virtual functions/functions for implementation. See [moo-propose-virtual](https://github.com/abo-abo/function-args#moo-propose-virtual) and [moo-propose-override](https://github.com/abo-abo/function-args#moo-propose-override). &gt; Or something really simple classic: How do you rename a local variable 'i' in a huge file? [Narrow](http://tuhdo.github.io/c-ide.html#sec-6-2) to the function and then regexp query and replace. It can be as fast or even faster, because the operation is really simple. There are more ways to get into the "21st century" than having a parser but good enough for everything else. **EDIT**: I realized that when you said this: &gt; It is a totals generic text search thing. That is not what I want when working on code projects. It is really cool for other things. I think you meant that Helm only searches for text in buffer. No, it's not. It gets info from Semantic and display it using Helm. Then you narrow down to what you want. It's like, instead of presenting you in a rigid tree using a GUI widges in regular IDEs for outline code structure, you get your code structure displayed in full text and select based on text searching. Much more productive, and in this case, keyboard &gt; mouse.
I thought this got optimized in C++98 with NRVO? 
For the first part, imagine something like this: http://ideone.com/SQloxe For your second paragraph, I guess that is just a matter of opinion.
auto_ptr was there in 1998, proposed in 1994 along with shared_ptr (which didn't make it that time) Also, TR1 came into existence a few years after C++03.
Except you're wrong. std::pair&lt;int, int&gt; get_pont() { return { 1, 3 }; } //elsewhere int x,y std::tie(x,y)=get_point(); http://ideone.com/XCzAwq
Ah okay, my bad.
what do you think about the code quality of the cl compiler?
what's so hard about char16_t? Cant you give us a typedef or something?
C++ is just that easy: download clang, start coding, compiler your code. there.
The manual thing that you go through is what most people do I think. Albeit, I think CMake clears up a lot of headaches... Anyway, just decide on a specific version for each library (unless you enjoy hitting a moving target), and make every developer responsible for getting the right versions of the libraries. Provide proper documentation! ;) I believe some people also do bundle the appropriate versions of the libraries with the source code so that it's better controlled. That might be more along the lines of what you want to be doing. That's still largely manual though.
&gt; I've been looking for a tool similar to Ruby's Bundler or Rust's Cargo to &gt; manage dependencies for my C++ projects for a while, without any luck. Take a look at [hunter](https://github.com/ruslo/hunter) or [cpm](https://github.com/iauns/cpm). The problem with these managers, however, is that there's only a few packages available. &gt; I have to manually maintain my CMakeLists.txt, and manually decide if i want &gt; to statically or dynamically link each library. I suffer constantly from &gt; dependency hell, version hell and platform hell. I actually somewhat like the flexibility. It seems you are struggling with the build process in general, which is understandable given how complicated things can be (and that's also the reason why I think it's very unlikely that there will ever be a C++ package manager which could handle all of the idiosyncrasies), but you will have to learn how to deal with it. &gt; How do you guys manage dependencies for large projects? Manually. If the dependency is small enough, I'd embed it right into the repository (deps/). For anything larger I would either download it via [ExternalProject](http://www.cmake.org/cmake/help/v3.0/module/ExternalProject.html) or state it as a prerequisite and rely on the system's package manager to provide the correct version. 
the other day? I would say around 2010, I would see this all the time! Except maybe worse, it wouldn't be just &lt;int, int&gt;, it would be something that was typedef'ed (like EmployeeId, EmployeeDeskNumber) so you had to trackdown what those types actually were, only to find that in the end, they were just damn ints. Mind numbing stuff. 
I have checked their site quickly, and I did not understand what this lib does. Help! 
Ah cool, I didn't know about this. I've been too busy falling in love with `auto`. I should mention that I did go ahead with std::pair because my program was very small and just did: auto x = point.first; auto y = point.second;
`dpkg` or `yum`. Package correctly and the dependencies will be handled correctly on install. Use [effing pkg mgmt](https://github.com/jordansissel/fpm/wiki) (fpm). 
I've looked at it, but I'm not a compiler dev, so I can't really judge it. One thing I do know is that it uses the STL extensively, which is a lot more sensible than, say, being written in garbage-collected C (as GCC was until quite recently when it switched to C++).
The whole point of char16_t is that it's a distinct type in the type system. On a scale of static_assert to variadic templates, it's not that hard, although I've heard the compiler devs grumbling that they've run out of bits to keep track of types. The STL is currently providing a fake typedef for char16_t which it really shouldn't be doing (I've had to remove it in Dev14 for various reasons).
"A blog about all things C/C++, with a focus on XL C/C++" Does XL C++ even support lambdas? Last I checked, it didn't.
Points should really have their own type. Pair is **great** as a small helper to pack to different things in one variable, but you really shouldn't use it to replace semantic types. Since you are coming from python, this may not be obvious for you, but static typing **really** helps finding bugs very early. But if you only use trivial types, the compiler will only find trivial errors: The compiler will (almost) always be able to catch you when you try to use a `std::string` as an integer. But if you encode both distances and durations as double, the compiler is unable to detect, when you try to use a distance as duration; OTOH if you create separate types for distances and durations the compiler will make sure that you use everything right. This is also not a hypothetical problem: [The Mars Climate Orbiter](https://en.wikipedia.org/wiki/Mars_Climate_Orbiter) went lost because of this kind of bug. Somewhat related: I wrote a [library](https://github.com/Florianjw/type-builder) a while ago that makes the creation of new types almost trivial, it's README contains further examples. Note though, that this code is more of an experiment of what can be done, than being intended for real-world-usage.
Graphics
From the first sentence on the about page: CINDER PROVIDES A POWERFUL, INTUITIVE TOOLBOX for programming graphics, audio, video, networking, image processing and computational geometry.
Anyone here using it? What's your take?
Take a look at their gallery, that's what they mean by creative projects.
Not sure either... But they seem to be working on better/full C++11/14 support. Maybe you'll need XXL C++ for that ;) *scnr*
Thank you! I am getting the impression that Cinder is more like a game engine, than a GUI toolkit (like QT for example). Am I right?
Wow that's cool, my library (anax) is linked on that site.
As a packager, that sucks bad if you *depend* on those specific versions. I would like to use the versions from my distro.
Why not just rely on your distro's package manager? Basically, let the packagers worry about the packaging and just do your thing.
I'm seeing a lot of people saying "just use yum/dpkg/your distro's package manager". Did you read the "platform hell" part? Not all platforms are Linux. This is a common problem with C++ development and it isn't solved by a long shot.
The shown translation of a generic lambda into a class is not quite correct. Generic lambdas produce a non-template class with a template function call operator: class lambda { public: template&lt;typename T&gt; T operator() (T t) const { return t; } } This means the same lambda object can be called with arguments of different types.
char, wchar_t, char16_t, and char32_t are distinct from each other and from signed/unsigned char/short/int/long/long long. If the compiler is missing any of them, they can't be (perfectly) simulated with typedefs. I don't know how to explain it in simpler terms, sorry.
I used an earlier version of cinder to write a 2d sidescroller game with pretty fancy destructible physics ( the level geometry was treated as 2d voxel space, which was dynamically editable, and would be marched and tessellated to convex geometry in real time ). Cinder provides great file IO, &amp; great access to OpenGL without proscribing what I could do. I had a great experience using Cinder. It is well thought-out, with the kind of API design that made me smile and made me rethink how I approach API design. Cinder made C++ fun. Now that being said, my game was halted in early 2013 because of paying work, and as such I haven't touched 0.8.5 or 0.8.6.
Thanks, I may have to look into it then.
sure, but why not define char32_t as int, for example? char16_t as word, etc. Why does that make a difference? (i have "solved" the problem in my project by doing exactly this)
The [Meson build system](https://github.com/jpakkane/meson) has a concept of [subprojects](https://github.com/jpakkane/meson/wiki/Subprojects), which aims to solve this better than current alternatives (full disclosure: I am the main developer). The main point is that you can take any Meson project and embed it inside a different Meson project so that it looks like it was a natural part of it. This allows you to do the Go thing of just grabbing a project from Github and using it but with the added bonus that you can easily use distro packaged version when it is available. The obvious downside being that not many projects build with Meson yet ...