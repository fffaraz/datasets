I confirm it was not yet. Also I believe the author is participating to the Unicode Study Group and he might be doing some modifications based on feedback. In any way there is a related proposal in work, you can find links to work in progress and impl in that discussion group.
if having to resort to this kind of trickery doesn't convince the commitee that this is a needed feature, nothign will
Personally, I think passing a struct and using named initialisers is a lot cleaner - the only downside is some curly braces: struct displayCoolNameArgs { std::string const&amp; firstName; std::string const&amp; lastName; }; void displayCoolName(displayCoolNameArgs args) { std::cout &lt;&lt; "My name is " &lt;&lt; args.lastName &lt;&lt; ", " &lt;&lt; args.firstName &lt;&lt; ' ' &lt;&lt; args.lastName &lt;&lt; '.'; } void displayCoolName({"James", "Bond"}); // works void displayCoolName({firstName = "James", lastName = "Bond"}); // works! You don't get the "in any order" thing but that doesn't seem like a good idea to me anyway.
When view::zip from ranges v3 comes into the standard, you'll be able to use the existing transform interface. After zipping some ranges, each of the elements in the "zip view range" will be a tuple of each of the corresponding elements in the underlying ranges. 
A multi-stage container works great for a CI system but last time I looked it didn't work well for day to day work. I had to maintain a second dev container to use for my normal code, build, test cycle as I still want to be in a shell where I can manually run cmake and ninja as I make changes. Main other downside of developing (C++) in docker, is that no editor has support for detecting header files from an editor running on the host but the code being compiled in the container. You can sometimes get it to work with SSH running in the container, but that is a bit of a pain to maintain. 
In C++20 I guess you will also be able to do this: struct named_arg { std::string first_name; std::string last_name; }; void foo (named_arg args); foo ({.first_name = "James", .last_name = "Bond"}); 
The first time I remember hearing about it was a month ago and I've seen it come up about 20 times since.
Shouldn't it be void displayCoolName({.firstName = "James", .lastName = "Bond"}); i.e. with dots?
That's _a lot_ of boilerplate required to get what should be a simple enough feature... And the fact that it's possible to make the "obvious" syntax mean something in current C++ probably means that any future standard that adds real named parameters would need to use a different syntax. Also, this method means you have to be really careful with naming. If you happen to have a local variable with the same name as an "argument variable" (hardly unlikely) then it will break things. You also can't have two functions/methods that take arguments with the same name but different types in the same scope (because you can't have two of those "argument variables" with the same name). Namespaces could help here, at the expense of making the syntax uglier.
can people from the street attend the meetup?
From what I've seen people are not arguing its usefulness but rather its semantics and extent. There are many issues with named parameters and it is hard to form a majority.
I think you're right.
Of course! It's public event. Everyone is welcome.
I don't understand this fascination with named arguments. My functions don't have enough parameters to make it worth it. If a function has many parameters, it's usually a sign that it's doing too much. For the rare cases where it _does_ need many parameters, it usually means that it requires a non-trivial configuration class that allows for fine-grained control over the function's behaviour. Named parameters just won't cut it. Anybody got cool examples of named parameters in C++ they could show me? I must be missing something.
That exactly is the problem with this solution.
You say that but the exact same thing is the canonical Python way of copying a list or string.
I don't write a lot of c++ so I might completely be missing something. But do you know the standard way of writing regression libraries? Like, what is the best way to write something like [scikits lasso implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) that has a ton of different parameters? I guess you could use a configuration struct, but you would need a unique struct for each regression method then which there is a lot of. In the few c++ regression libraries I've seen they simply just use a ton of function arguments. However, again I might just not have looked hard enough.
Yep, should have stopped after step 1.
The only place where I can see named parameters as useful is if your function has a few `bool` parameters and you decide to pass all of them as literals. Something like int foo(bool x, bool y, bool z); int a = foo(false, false, true); int b = foo(x = false, y = false, z = true); int c = foo(/* x */ false, /* y */ false, /* z */ true);
isn't it `.copy()` in Python?
No link description, no README, nothing: what is this?
Personally I'd like named parameters in the same way I like types: they're a way for me to state my expectations of what I'm putting into a function, so that the compiler will complain if my mental model is incorrect If I call do_something(y:variable) but do_something expects an x, I've gained something pretty neat. Its also clearer at the callsite precisely what your function is doing with a parameter conceptually which could alleviate function naming
It is super useful when you are doing refactoring. Examples: You want to put a default value to *y* so you move it last. There is zero help from the compiler to let you know that you forgot to swap the parameters at one of the calls to foo. You remove *z* and accidentally remove the wrong argument on one call to foo. Again no help from the compiler. Both those examples would let you do safer refactors with named arguments. 
C++ doesn't need this. No one looks at C++ and thinks "Gee, I would really like to use this language, but it doesn't have named parameters." Instead, they look at C++ and see things like lack of standard networking, then pass on it in favor of another language.
Ah very nice, a C++ Mystery Puzzle!
With booleans I never know what the arguments are for, so I ended up more and more doing: foo(false /*disable X*/). Now I tend to use enum instead, for example: enum class X { DISABLE, ENABLE }; foo(X::DISABLE); This gives compile-time errors when mixing arguments.
Yeah, but now you're adding a struct for every method you want like this, rather than just getting it for free, and you have to access the members of the struct instead of directly referring to the arguments, there's the cost of constructing the struct, etc. It works, but it looks awful, has poor ergonomics, and is just objectively worse than a language implementation.
In Python 3, certainly. But in Python 2, slicing has been the idiomatic way for ages.
If you need stanrdized networking library, you should really be active in the comittee. And I'll pretend Boost.ASIO doesn't exist.
Boost.Log and Boost.Process use this. I just hate that. Unfortunately I require Boost.Process so I have to use them :(
Did you see the [announcement](https://access.redhat.com/errata/RHBA-2018:3562) linking to the [release notes](https://access.redhat.com/documentation/en-us/red_hat_developer_toolset/8/html/user_guide/appe-changes_in_version_8.0) and [installation docs](https://access.redhat.com/documentation/en-us/red_hat_developer_toolset/8/html/user_guide/appe-changes_in_version_8.0)? For RHEL the the keys should presumably be added by the previous steps with the subscription manager. Or if you install the `rhel-server-rhscl-7-rpms` or `centos-release-scl` package, this should automatically add the required keys. I just double-checked this for myself. I create a CentOS 7 build container image using this [Dockerfile](https://gitlab.com/codelibre/containers/ome-files-build-centos-7/blob/master/Dockerfile) and you can see the build [here](https://gitlab.com/codelibre/containers/ome-files-build-centos-7/-/jobs/102931528). While you can see some warnings about missing keys, you'll see that the needed keys are fetched and checked immediately after.
This is the sort of suggestion I'd argue very hard against. Not only is this confusing, won't scale for larger APIs, it's not even future-proof, if say, in the future named arguments might be added to the standard they would definitely not look like that. I'm sorry, but no.
IMHO c++ doesn't need named args at all. When/if at a certain codebase abstraction levels are built properly, i.e on high abstraction levels the coder works with field-specific types (defined/provided by lower abstraction levels), then there is no need to use such a feature. For example: \`\`\` // instead of unspecific-typed arguments Pizza makePizza(int piperoni\_cnt, int jalapeno\_cnt); // use field-specific type Pizza makePizza(Piperoni piperoni, Jalapeno jalapeno); &amp;#x200B; int main() { auto p = makePizza(3, 1); // huh, what 3? what 1? auto p = makePizza(Piperoni{Parts{3}}, // 3 parts of piperoni Jalapeno{Parts{1}}); // 1 part of jalapeno (hot!) } \`\`\` Not the best example I could think of but I believe you can see the idea. 
This is how I usually "implement" named arguments: foo(/*firstName=*/"John", /*lastName=*/"Rambo");
I don't think anyone with little to medium C++ experience is going to hear the word 'container' and get confused and think it's a vector or something. Container's not even a keyword, c'mon. You said: "Those beginners are going to start **calling** pairs 'containers' and everyone will be confused and worse off for it." Calling? You mean function calling? Pairs aren't functions, silly. You can't use the word "call" if you want to talk about C++ unless you mean "invoking a function". You don't see how that ^ is a bit ridiculous, because you were just using the english definition of the word 'calling'? Regardless, I might have used the word container in a detrimental way. I don't think I did, but I'll review the video and check it out again some time this weekend to see. 
Maybe. I've made the video unlisted for now. Maybe I'll record another version, as you said.
I'm not going to argue that it isn't worse than a language implementation, but IMO it's better than making all param names be global variables as the linked article does...
This is already supported in both gcc and clang (I think).
It's useful any time you have two arguments in a row of the same type. OpenCV sometimes swaps x and y order for functions, and it would be super helpful there. It's definitely nice in it's existing form for struct initialization.
Too cool, but I see here just academic interest. By my mind, in practical programming this will be not usable. IDE support for showing argument names reduce chances to mistake of function parameter order
IMO the only time named parameters are nice is with booleans. How often do you see something like: ReadConfiguration(fileName, false) And wonder what the hell the false means? It happens to me enough that I build scaffolding to avoid it specifically.
Oh wow. I didn't read the article that is disgustingly gross, and definitely prevents compiler optimization.
&gt; Main other downside of developing (C++) in docker, is that no editor has support for detecting header files from an editor running on the host but the code being compiled in the container. You can sometimes get it to work with SSH running in the container, but that is a bit of a pain to maintain. What do you mean exactly? Some IDEs do support remote compilation/execution, though admittedly it wasn't enough when I needed it for WSL.
Alternative for C++11 if you just want the independent ordering: #define create(T, ...) ([&amp;]{ T ${}; __VA_ARGS__; return $; }()) struct S { int a; float b; }; auto myStruct = create(S, $.b = 3.1415f);
Refactoring is one, but i'd say improving self documenting code is probably the biggest benefit. Objective-c uses that convention, and while it may be verbose, it is also super informative when it comes to mentally parsing code. Overloaded functions could also benefit from named parameters as it ensures you're calling the right one.
Wt looks great, is there any Python bindings or some other high level languages? I know that there is kinda less supported JVM version, but I'm not the Java guy, sorry. Something like C# or Python bindings would be great.
LOL...if only you understand how redonkulous this sounds.
BOOOOOOO! I was expecting a *container* container, not a container. Like some new kind of vector, set, multi_map, et. al.
No, there was a PyWt a long time ago, but that went nowhere. My colleagues use JWt all the time for some key projects, though, so it's still definitely supported. There isn't really a JWt community though, and of course I personally do put Wt first :-).
I mean for auto-completion (e.g. Intellisense). If they detect any headers it will be those on your local machine so you may have a different version of the library installed locally to what you use in the container. Then you can get incorrect suggestions. For an example, something like [this](https://blogs.msdn.microsoft.com/vcblog/2018/04/09/intellisense-for-remote-linux-headers/) but able to detect system headers in the container without having to start an ssh server inside the container. 
Comments are not verifiable by the compiler.
Great minds think alike ;-)
I see, maybe it will be a good pet project to make Wt bindings to something like C# or Python, though it is hard to bind C++ code. Is the web server embedded in the framework (so called self-hosted framework) or do I need to use Apache or something with it?
There are several different "connector" libraries. Depending on whether you link with wthttp, wtfcgi, or wtisapi, you can use the embedded web server, FastCGI, or ISAPI respectively. I recommend wthttp, though. It's the most feature-rich version, and it's the easiest to debug. If a more feature rich web server is needed, then you can always use an HTTP reverse proxy.
Well, Python 3 has been out since 2008. Move on :-) (maybe if you can't move on in code yet because of some dependencies, then at least mentally). So It's not the canonical way _anymore_. I can feel the down-votes coming :)
The other solution is to just run your IDE inside a docker image that is based on your build image, but with dev tools (IDE, profiler, etc.) added.
This looks very heavy. For each function must be added structure.
Hm, what's the issue with enabling ssh inside the container (it could be part of the Dockerfile)? It needs a way to communicate with the remote machine somehow.
Something about our environment prevents the keys from being downloaded automatically. I don't work on the packaging part of our product here at work (we ship an appliance that runs CentOS under the covers), so I'm not sure why it worked for you but not for us. Edit: GCC 8 availability is cool and would be nice to use, though.
It looks like Wt is for building C++ web applications. Does a library exists where I can use HTML,CSS, and JS to create a UI frontend but use C++ for the application logic. The application would be a standalone application and not serving up web pages. I know there are several widget toolkits (GTK+,...) but I don't know of any that use this combo.
RHEL does, but CentOS doesn't, at least not out of the box. Yes, you can install Software Collections, but it's not an official CentOS project and isn't signed with the CentOS keys, so if anything in your process requires key validation, you're more or less stuck.
I don't think so, at least not in my \[our\] case. I think it's making sure that the packages are properly built, signed, and certified. If you're using full blown RHEL, you're probably fine as they do have official support for newer toolchains. If you're using CentOS, things get a bit dicier as Software Collections isn't an official CentOS project.
electron + node native modules, sadly, seem to fit your description
Verifiable by static analyzer, though. If you have a static analyzer that checks for this, this can be a good solution. Language level would still be better, of course.
For most functions, including this trivial one, named arguments are not needed.
I think strong typedefs are a better solution to this than named arguments, in addition to being more useful in general. For example, with a hypothetical `strong_typedef`: strong_typedef string first_name; strong_typedef string last_name; void foo(first_name f, last_name l); foo(first_name("James"), last_name("Bond")); And now you will get a type mismatch if you try to pass in plain strings or switch the arguments.
But unsigned boost libraries are ok?
Yes I omitted that from the quote because to me, it is an offense to the reader to find substr() being used to obtain what is not a proper (strict) substring of the original. I am less interested in the desire to not specify types. So before we had auto I used to write the clear if verbose copy that you suggested.
Of course this is true. It's also correct to note that *s* is a substring of itself, just like a set is a non-strict subset of itself. Even so, and even when I work in C++98, I avoid that formulation because casual readers of my code would likely be confused and would have to look up the default argument values to be sure of what it does.
Thats newer syntax is it not?
The main benefit of named arguments is the ability to override a default in the middle of a list of defaults without needing to care about the ones before it
I would rather write my own compiler extensions than write all that boilerplate and template abuse.
We use the Boost libraries that are packaged as part of the standard RHEL/CentOS distribution. Again, they're not the latest and greatest, but they are in the distro.
&gt; C++ doesn't need this. No one looks at C++ and thinks "Gee, I would really like to use this language, but it doesn't have named parameters." Instead, they look at C++ and see things like lack of standard networking, then pass on it in favor of another language. I really have a different perception. No one arounds me voiced strong opinions about networking being standard, because ASIO "just works" in all the relevant platforms and is just an additional include path away (and it's not like the "not-relevant platform" would ever implement it even if it was standard). But there's nothing that allows to easily "add" core language features, when compared to what languages such as LISP or Rust allow (e.g. stuff like this : https://github.com/mystor/rust-cpp). 
Hey all, Carbon Black is growing! Building an additional agile team here at Carbon Black focused on our [Predictive Security Cloud](https://www.carbonblack.com/products/cb-predictive-security-cloud/) product for macOS, to work with our existing teams. Looking for all levels of C++ developers. Here are the postings: **Company:**[Carbon Black](https://www.carbonblack.com) **Type:** Full Time **Description:** *Associate Software Engineer:* [https://carbonblack.wd1.myworkdayjobs.com/Life\_at\_Cb/job/Boston-Massachusetts/Associate-Software-Engineer\_3031-1](https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb/job/Boston-Massachusetts/Associate-Software-Engineer_3031-1) *Software Engineer:* [https://carbonblack.wd1.myworkdayjobs.com/Life\_at\_Cb/job/Boston-Massachusetts/Software-Engineer\_JR000067](https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb/job/Boston-Massachusetts/Software-Engineer_JR000067) *Senior Software Engineer:* [https://carbonblack.wd1.myworkdayjobs.com/Life\_at\_Cb/job/Boston-Massachusetts/Senior-Software-Engineer\_JR000068-1](https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb/job/Boston-Massachusetts/Senior-Software-Engineer_JR000068-1) *Principal Software Engineer:* [https://carbonblack.wd1.myworkdayjobs.com/Life\_at\_Cb/job/Boston-Massachusetts/Principal-Software-Engineer\_JR000069](https://carbonblack.wd1.myworkdayjobs.com/Life_at_Cb/job/Boston-Massachusetts/Principal-Software-Engineer_JR000069) **Location:** Boston and Waltham **Remote:** Yes **Technologies:** * C++11 * macOS * Python **Contact:** Apply via the job links above and we'll reach out! Thanks, Mark
&gt;I have never seen such a hardware, and I bet you never did either, but somehow C++ still needs to take this as a possibility and assume that it doesn't really now what will happen in this case Not anymore! C++20 now requires that integers use 2s complement :) - see also P1236R1. However, that does not mean that signed overflow is not undefined behavior anymore.
Yes. [And icc](https://godbolt.org/z/ifGCOQ), it seems.
&gt; You don't get the "in any order" thing but that doesn't seem like a good idea to me anyway. Most people use that as a selling point of named arguments in other languages. Why do you think it's not a good idea? Another downside is it makes the arguments optional. You could also do: void displayCoolName({.firstName = "James"}); // .lastName = "" by default Which is *sometimes* what you want, but not always.
I would love to get into the project.. I've been wanting to switch stack and do some low level stuff but it doesn't pay out in my country. Hopefully I can make up some time for it and contribute.
&gt; No one arounds me voiced strong opinions about networking being standard, because ASIO "just works" in all the relevant platforms and is just an additional include path away "Economics in One Lesson." You are paying attention only to the things that are visible (Boost.Asio is available) but ignoring the things that are invisible. What about all of the C++ libraries that have been written against other networking libraries (libuv, straight POSIX, etc)? Libraries written for different networking interfaces are not interoperable. For example I cannot take this HTTP server which uses libuv https://github.com/parachvte/libuv-httpserver and add the websocketpp websocket library which uses Boost.Asio. The consequence of the lack of standardised networking for so many years is an ecosystem which is immature with respect to the availability of good network component libraries. This is certainly true of C++, where the current state-of-the-art for fetching objects from HTTP servers is a program written in C (cUrl). Interoperable network libraries written in C++ are the exception rather than the rule. Compare and contrast this with other languages for which networking libraries are standardised. JavaScript is an easy target but so are many others. So I disagree very strongly that C++ has not been impeded by the lack of standardized networking. In fact, the very definition of what constitutes a good domain to standardize is "portable interfaces which require platform-specific implementations." Networking is the canonical case of what belongs in the standard.
Yes, I am aware of this, and I didn't bring it into the mix exactly because of your second phrase - overflow is still undefined, and my post is about undefined behavior.
&gt; not serving up web pages. I'm very confused about what you're trying to do. You want a hand-rolled website as a UI and you want its behavior implemented in C++ but those two parts not to talk to each other? Or you envision two separate servers - one serves up a (basically static) website that on the _client_ side talks to the C++ implemented server over... web sockets?
You could declare lastName as optional&lt;string&gt; if you want it to be optional, right?
Thanks. I appreciate the tip.
Inheriting from the object privately should avoid any of these pitfalls. Implicit conversions/slicing cannot happen outside of member functions and friends. Not only that but the inheriting class has control over what APIs are surfaced through `std::vector`.
&gt;instead of checking if value is allowed for an operation, C++ tells you that if you try to call operation X with value which is not allowed for it, behavior is undefined Also known as "narrow interface". A very important advantage of C++ IMO. (even if it's not limited to C++)
I'm not looking to make a website. I'm looking to make stand alone executable to run on a local machine. In my experience, HTML,CSS, and JS can be used to make elegant UIs in a fairly quick amount of time. There would have to be a mechanism that binds the UI to the C++ application logic. As mention by malex12345, I think electron would be the most appropriate solution for this. 
Thanks for the post! Waiting for the second part
`int` in the `main` with the unary `*`.
My old employer actually did this: C++ application backend + Chromium Html/javascript frontend. The C++ bindings were generated automatically for either C++/Cli or Javascript. But it was all developed in house. Just mentioning this here to say its possible.
That is a good point, I will add it to the text if you do not mind.
&gt;Hello Ladies. Look at your C++, now back to R, now back at your C++, now back to R. Sadly, your C++ isn't R, but if you stopped using the type you actually wanted to receive and started brave metaprogramming it could look like it is R. Look down, back up, where are you? You're in a text editor, with the single letter names your parameter names could spell like.
Please add the Visa field as listed in the template. (Also note that we’re nearing the end of 2018; when the Q1 2019 thread goes live, you can post there too.)
&gt; The larger issue is what is C++ supposed to be? Is it supposed to be a simple and transparent way to describe the work you want to accomplish, or and endless guessing game/research project figuring out what your code is supposed to doing. It's evolved into the latter and this article demonstrates that. As someone who likes templates, I barely use them. I cannot comprehend how people see a language as unusable just because it offers complex and advanced features. It is rare that I have to dabble in the arcane details and when that is the case it is for something other languages would make just as painful if not outright impossible^1 by withholding any form of built in support. ^1 I have to live with performance constraints if a solution has a high run-time cost it is unusable. 
Yes, you'd probably want `std::optional` for optional arguments, because otherwise you don't know if they were set. But I'm more worried about how you make arguments *required*. So if you add `std::string alias` the compiler will make sure callers don't forget to add that parameter. Maybe it's possible to write a `required&lt;std::string&gt;` class that could enforce this by not having a default constructor?
So, just to follow up... I'm well into the conversion over to the 'enum class' scheme for typesafe enums in this code base. I've caught a number of goobers so far. Most were benign but some not. The biggest one has been by reference collections, where there are constructor variations like these: MyCol(maxelements, adoptenum = adopt, threadsafeenum = unsafe) MyCol(adoptenum, threadsafeenum = unsafe) &amp;#x200B; I would accidentally pass the thread safety enum by itself: MyCol(tCIDLib::EMTState\_Safe); and that would get silently interpreted as max elements. So I ended up with a collection that only had a couple slots and was not thread safe. That happened in two places, and obviously was not good.
C++11 isn't new anymore. But the same applies to C++98 with `string(b)`
Yeah, and then you have to look up what a `Piperoni` is, and a `Jalapeno`, at which point you've forgotten what you were doing in the first place.
&gt; Calling? You mean function calling? Pairs aren't functions, silly. You are _awful_ at analogies. No offense.
&gt;default &amp;#x200B; Yes, default parameters are painful in C++. If you have a few important parameters and lots of small parameters that are usually default, you can't just have the function caller just choose a few to over-ride. You have to specify in your documentation the default values and they put all those in and then change the one they want to change. Or, go with some other pattern where half the parameters are inside a struct. In C#, it is just so easy to do. 
Named arguments are great, but they do not exist in C++, and they are unlikely to exist, because they present a lot of issues from standardization perspective, some of those might not even be universally solvable, And any aftermarket solution just stinks, including the one suggested in the article. Strong typedefs? Give me a break. They look great on paper, but I am yet to see a large scale application which will consistently use strong typedefs for every different entity they have. Just too much effort with uncertain benefit. (There is also no good way to create strong typedefs without macros - \`using LastName = NamedType&lt;std::string, struct LastNameTag&gt;;\` is prone to errors, especially with inevitable copy-pasting such verbosity will trigger). Do not even get me started on \`get\` in the example required to access the argument. It is also non-trivial to pass modifiable arguments this way! In the comments it was suggested that designed initializers from C++20 could do the trick. Those would also be prone to defects. First, one will have to define a companion struct for every function. I already see people balking at it. Second, it would allow omitting named initializers by mistake, thus giving an argument default value. Hardly a good thing. In other words, bite it - no named arguments, let's move on. In the famous quote attributed to G. Lucas he once opened a meeting with public with following statement: "Yes, sound waves could not travel in vacuum, so there should be no sound of explosion of space ships in Star Wars. Now let's proceed to the questions". &amp;#x200B; &amp;#x200B;
All set. Thanks! &amp;#x200B;
Committee is not a constant and not a single person. Opinions and members change over time. 
And this doesn't even fix the problem of default initializers, i.e. able to choose which default values to override. Also, doesn't really allow for out of order parameters. This is trivial in python and for implementations of algorithms with lots of minor configurations, this is a real pain. In fact, ask people to test, experiment and finalize their algorithm through the python bindings and then at the last part use the C++ library.
"Quickly develop highly interactive web UIs with widgets, without having to write a single line of JavaScript." An angel got it's wings when I read that.
Just even having standardized or at least universally accepted vocabulary types that can be used in library interfaces would be a big step forward to make for interoperable systems. Say, a std::socket_view , std::3dmatrix_view and a few others. 
C++11 is newer than when the substr function was designed, which is the point
Actually, the lack and impossibility of named arguments in C++ is one of the many reasons I gave up and “moved on” back to C#.
&gt; Its also clearer at the callsite precisely what your function is doing with a parameter conceptually which could alleviate function naming If named arguments were available, you'd use them not as a special case, but as a replacement of standard calls in most cases?
This ‘trivial’ one is the bare minimum justifying example for named arguments. foo(first, last); Or foo(last, first); Vs foo({.first=first, .last=last});
I would still recommend a separate struct, or at least a two-step process like: lasso() .alpha(0.5) .fit_intercept(false) .run(); This also allows you to validate parameters individually in their own setter and makes it easier to test them. Named arguments are _one_ way of doing this, but it's not the _only_ way, and C++ already has plenty of ways to make this work.
If you are happy with C#, you should certainly keep using it. 
What is the point of \`explicit operator bool()\`? If you do not want automatic conversion, wouldn't it be more intuitive to have a \`::valid()\`-type of function returning bool?
I look at C++ every day at work and think "I wish I could stop creating named global/local constants to make the function calls readable." Please don't try to deny the improvements in this area.
"first" goes first and "last" goes last. It literally doesn't get more trivial than this.
Consider `shared_ptr` and the desire to write `if (sp) { sp-&gt;stuff(); }`.
Oh wow. I knew that i * 1000000000 was undefined behaviour, but never considered that the compiler would make such logical steps to conclude that i &lt;= 3 in other expressions containing i. I guess this is why none of my embedded software works at -O3 :P 
The best example I've seen of compilers getting it ridiculously wrong when dealing with UB is when it ends up calling a function that the program itself never called. I'm trying to find it.
http://Cpp.chat/live
Just run a bunch of busy loop threads in the background and tell your customer that the application scales on as many cores as available!
My issue with C++ is that the “narrow interface” is frequently too narrow. There's several instances of situations that C++ classifies as UB that could (should, IMO) be implementation defined instead; classic examples are signed integer overflow and union-based bitcasting for standard layout data types.
You're actually wrong about that last example. If i was 4, then i*1000000000 would not be executed, so undefined behaviour is avoided. The real problem is that i\*1000000000 is undefined when i is 3.
It implies that 2's complement representation (or lack of it) is NOT the reason that signed integer overflow is undefined. 
It's not possible to "get it wrong" with UB, since all eventualities are correct
Probably not... it's just a move ctor.
&gt; C++ developers love to joke on how programs with undefined behavior can [...] format your hard drive. [It] doesn't happen as a result of undefined behavior with compilers and platforms I use Well, every vulnerability that is a result of UB and is exploited by some ransomware encrypts your hard drive. Ultimately being a case of UB leading to an unrecoverable HD. &gt; Most (if not all) software-related security exploits we heard of lately are due to undefined behavior creeped into even the most professional code, so one can see why it is super important to learn how to code without invoking it. Arguably no. Many security-bugs are not due to undefined behavior but because of logic errors like SQL-injections and alike. If you think about the big bugs of the past, the Debian-OpenSSL-debacle actually became exploitable from someone *removing* UB (which arguably should never have been there in the first place, but for good insults against the openssl-people I refer to the LibreSSL-guys) and Heartbleed in contrast to very popular opinion was not really so much of a UB-problem as a logic-bug (there was some rare cases of UB as well, but the really dangerous cases were the ones without it). That's also one of my major criticisms of Rust: They make such an elephant out of UB, that they seem to have lost sight of the just as dangerous logic-bugs without it, best exemplified by their more-or-less refusal of contracts.
There is such library for c++ https://sciter.com/ . As I know several anti-viruses used (or use?) it for their GUI.
Sample code from the document ``` TEST_CASE("Generators") { auto i = GENERATE( range(1, 11) ); SECTION( "Some section" ) { auto j = GENERATE( range( 11, 21 ) ); REQUIRE(i &lt; j); } } ``` 
catch is awesballs.
There are approximately 50 talks in the last 3 years about this... what do you cover that they don't?
&gt;we need to define an object firstName that has an operator= that takes a std::string (or something convertible to it) and that returns a FirstName Like a `std::string`, maybe? What's the point of all this NamedType stuff? static std::string firstName, lastName; std::string foo(const std::string&amp; firstName, const std::string&amp; lastName) { return firstName + " " + lastName; } int main() { std::string x = "John"; std::string y = "Smith"; std::cout &lt;&lt; foo(firstName = x, lastName = y) &lt;&lt; "\n"; }
Iv heard of it through cppcon. This video/talk is basically a good starting point: https://youtu.be/Ob5_XZrFQH0
Catch2 is great. Love it.
In my ideal world, co_await wouldn't be an built-in operator but a library function, written using compiler intrinsics for suspending the calling function and accessing the calling function's return value. Then monads could be implemented without the overhead of coroutines. Though this isn't possible because co_await modifies the function that calls it, splitting it on the suspend points. So to make co_await a library function would require some sort of new compiler annotation that forces the compiler to inline a function without regard for normal function call semantics. So probably not going to happen. But I can dream...
I really like catch2, but I find it compiled too slowly for my liking 
STD pair is used for building maps. That makes it pretty important to use sometimes. 
I was just about to write: if a function has so many arguments that they need names, define a struct.
Yes, it's the only problem
It can be slow if you use it in a header-only variant. You can, however, pre-compile it by making a cpp file that defines `CATCH_CONFIG_MAIN` and includes `catch.hpp` - you should not define `CATCH_CONFIG_MAIN` anywhere else; if you do this, empty test should not take more than a second to compile. This is basically what [first example](https://github.com/catchorg/Catch2/blob/master/examples/000-CatchMain.cpp) does.
No need for a custom type (though that would work). Just make it a reference of some kind - the compiler will insist it's provided because references have no default constructor.
I might be mistaken, but I think that only adds a default main function that registers and runs the tests. This is in no way precompiling the library. You also can't define it more than once or the linker will complain. googletest also has a default main (in libgtest_main), but is truly compilable into a library. In contrast, Catch2 seems to be truly header-only.
Some have to support Ubuntu 14.04 and thus only have C++0x available. It's limiting
Compiling the main part is the slow part. Compiling the unit tests themselves doesn't add a noticeable amount of time to our build times (we use catch at our company for several medium size projects) 
It's still way cheaper than the solution proposed in the article...
I think the reason it saves compile time is because every instantiation of any Catch2 template used by your various tests will only need to be compiled once total, and then the linker can recycle that compiled work across all the translation units since all the translation units are being compiled into the same target executable. But also linkers are a bit mystical to me, so I'm mostly speculating.
&gt; Arguably no. Many security-bugs are not due to undefined behavior but because of logic errors like SQL-injections and alike. Indeed. When deciding to back Rust, Mozilla studied their history of CVEs and identified that memory safety (a particular case of undefined behavior) was the cause of roughly 50% of them. On the one hand, 50% is nothing to sneeze at; on the other hand, it means that even completely eliminating them leaves 50% behind. It can be argued that with memory safety out of the way, more focus on the remaining code will further reduce the number of bugs... I am not so optimistic. &gt; That's also one of my major criticisms of Rust: They make such an elephant out of UB, that they seem to have lost sight of the just as dangerous logic-bugs without it, best exemplified by their more-or-less refusal of contracts. My experience seems vastly different than yours. On the contrary there's been much emphasis on correctness beyond UB in the Rust community, and many attempts at leveraging the type system to rule out logical errors. Session Types are a prime example: encoding a state machine transition in a way that the compiler can verify them.
I’ve used CppRest for that: https://github.com/Microsoft/cpprestsdk
There should have a law regarding people building stuff in a container and using it directly after as a service...
I didn't notice slow compiling time too though my test files are usually not too large.
It would require a [useless] dependency to another language. multiplatform maybe, but not available on windows by default, and on linux different versions is usually annoying. It is a lot of effort for simply doing that. 
Yes I did and I do, but nothing that can be achieved easily in c++. No need for installing other stuff already available. Much simpler and less troublesome.
You might want to add next time that you are interested in US located workers only. Otherwise you're wasting the time of 75% of applicants.
&gt; I am not so optimistic. Me neither. &gt; My experience seems vastly different than yours. I have to admit that I'm by no means an expert on rust and a lot of this is what it looks like from the outside. When I checked for contracts the last time, the impression that I got was that they more or less shot it down while pointing at their type-system. And yes, static type-systems are the thing that distinguish production-languages from toy-languages and they can catch many errors, but not all of them. It's impractical to encode every property of a value into the type-system. Just consider a binary search: It requires a sorted array, which you usually won't have marked in your type-system. With contracts it's now easy to state that this is a necessity and you can extensively test your code in the debug-builds. Returning the wrong result from that search can easily have terrible consequences later down the line, yet my impression with the Rust-community was that they pretty much didn't consider these kinds of issues. Again: I might be wrong here and the rust development-process on github isn't as easy to follow as one might think and the Rust-documentation at least had a habit of not being that much better than what you find on C++ (The excessive use of `.unwrap()` everywhere was what completely killed the language for me on one of my earlier looks into it, as that is unambiguously extremely inferior to exceptions. OTOH I considered the actual best-practice of using `?` to be very interesting, so why did the examples not use that?!)
Ah, I think I see better what you mean. I definitely agree that not all properties are practical to encode in types. Actually, when I first discovered "Rust" in 2011 it used to have typestate, a system by which a type could be annotated with various predicates, and by reasoning which functions required/established which predicates, the compiler would "prove" that the predicates held. Of course, this is pretty similar to just creating new types, and suffers from the same drawback: composability. The system was scratched. Going back to contracts: the community is very diverse on their use. Essentially it goes from "unenforced"^1 , via "enforced in Debug" to "enforced"; and each author has their own sensibilities as to which case should use which category. I personally write C++ and Rust code in the same mindset: enforce in Debug if the check is costly (relative to the usecase), always enforce if not. In C++, this means a combination of `assert` and `if + throw`; in Rust it means using `debug_assert!` and `assert!` respectively. As such, I do not see much difference between either language... and I'm definitely ~~proficient~~ dangerous enough in both to code bugs :) ^1 *I suppose that a 4th case exists: "undocumented" or "implicit".*
When I talk about contracts I mean specifically something like what we will (hopefully) get in C++20 or what D has. Classical asserts are IMHO a crutch. *If* the compilers start adding the preconditions even to built-in-operations I might even end up considering that to be superior to Rusts `safe`/`unsafe` distinction: Almost everything can be unsafe and just singling out memory-corruption might end up giving people wrong ideas. Also: A proper contract-system would allow far more aggressive compiler optimizations, which asserts don't really do. Funnily enough, rust added contracts in one place, but then half-assed it: As far as I understand it, rust checks for integer-overflows in debug-builds, but guarantees the behaviour in release-builds as wrapping. IMHO that is a really stupid decision: An overflow is apparently a bug, but instead of then using that information to optimize, they punish those who write bug-free code by not optimizing it. Personally I really assert that you should decide whether something is a bug or not and then follow that decision through!
What's the issue? This is C++, you're not going to get a good unit test framework without macros or miles of template metaprogramming.
I replied the wrong comment. I was referring to compilatoon speed (think about doctest for reference). 
Ah, all good then.
Yet with explicit bool operator it won't work. Thus the question.
That implication would be incorrect. It is well known that uncertainty about 2s complement is the reason why overflow is undefined. The question why defining signed encoding didn't definite overflow is a different one, I know it was mentioned in proposal but got pushback. My got feeling was that it was more of a caution - compilers have been treating it as UB forever, and it might be a lot of risky efforts to change compilers code to treat it properly. Again, just a guess on my side.
&gt; Funnily enough, rust added contracts in one place, but then half-assed it: As far as I understand it, rust checks for integer-overflows in debug-builds, but guarantees the behaviour in release-builds as wrapping. That's slightly inaccurate. Rust, the language, always considers overflow a bug: overflow is defined in resulting in an unspecified value. Ideally, the implementation would enforce this by panicking both in Debug and Release mode, however in practice there is a really performance penalty in using LLVM built-in overflow detection and therefore overflow detection is **opt-in** in Release while being the default in Debug. The hope, however, is to one day switch to an implementation of overflow detection tailored for performance rather than accuracy so that all Rust programs, whether compiled in Debug or Release, will check for overflow. There are much more pressing matters, though -- and it is probable that extensive changes to LLVM optimization passes would need to happen -- so for now the statu quo persists. &gt; When I talk about contracts I mean specifically something like what we will (hopefully) get in C++20 or what D has. Classical asserts are IMHO a crutch. I see. I do agree that it could be neat. I am afraid there are, once again, much more pressing matters. As a reminder, Rust still does not allow parameterizing a `struct` by an integer. It's something that I'm hopeful will come this year, as a lot of the groundwork has been covered. Still, I know there are (some) efforts for formal verification of Rust programs ([source](https://rust-lang-nursery.github.io/wg-verification/)); mostly led by the embedded community, and very much in its infancy. This is somewhat similar to contracts, though more shifted towards compile-time verification. &gt; Also: A proper contract-system would allow far more aggressive compiler optimizations, which asserts don't really do. Possibly, though not certain. Unlike C `asserts`, which disappear in Release mode (when `NDEBUG` is defined), Rust's `assert!` macro remain. Furthermore, the consequence of a failed check is a `panic!`, which essentially means that an exception is thrown. Rust, like C++, uses the Zero-Cost Exception model. This results in non-throwing being inexpensive, and throwing being very expensive. And the optimizer knows this. In turn, it means that the optimizer can aggressively optimize for the "common" execution path (the non-throwing one). So, while not a full-blown contract system... and notably lacking the compile-time warnings/errors... using `assert!` in Rust also results in optimizations. There's one caveat: `assert!` are an implementation detail, so while the body of the function containing the `assert!` can always be optimized, the code in the caller will not generally unless the function is inlined. So yes, contracts would allow optimizing more sites. 
I said it is always less than 4, so condition is short circuited. This is correct.
The loop thing in the last example is just f\*cked up. I've said this before, and I'll say it again: UB was always intended for situations where compilers could not reasonably be expected to issue a diagnostic. It's the standards' way of saying "sorry - if you do this, you are beyond our ability to help." It was never intended as a source of optimisations, and the fact that it works out that way is purely accidental, and increasingly undesirable. But here the compiler detects the UB! It has surpassed the expectations of the standard, and instead of eliminating code, it should issue a diagnostic. There's a contradiction in the source (on the one hand it sees the i&lt;4 test, and on the other it can 'prove' that i can never be &gt;= 4). That strongly indicates a logical flaw - so why, exactly, can't it share that information with the programmer? Something like "condition is always true" for the i&lt;4 would perhaps be puzzling, but at least give some starting point for further investigation...
You should recheck your assumptions.
Have a look at [doctest](https://github.com/onqtam/doctest) - it is basically a reimplementation of catch with a huge focus on compile speeds - [benchmarks](https://github.com/onqtam/doctest/blob/master/doc/markdown/benchmarks.md#compile-time-benchmarks)
Wait, rust checks asserts in Release-mode? That makes it even less useful, especially for contracts: Let's stay with the binary-search-example: With contracts I want to be able to require that the range is sorted, which of course means that the check takes way longer (O(n)) than the actual computation (O(log n)), which is perfectly fine in debug-builds but of course completely unacceptable in release builds as it completely negates the entire point of a binary search. That's specifically why C++20-contracts have something like the audit-mode: To allow for checks that are prohibitively expensive in release and potentially even debug-builds.
`memcpy` and type-punning via unions tends to generate the same assembly (https://godbolt.org/z/ZsTt53), so you can generally always prefer copying.
Rust has two asserts: `debug_assert!` is only checked in Debug mode and `assert!` is always checked. If you want to check that an entire range is sorted in `binary_search`, you use `debug_assert!`, so that the check is only performed in the Debug mode. The parallel with the contract levels is easy: - `off`: `assert!` (can never be turned off). - `audit`: no standard equivalent. - `debug`: `debug_assert!`.
this: mdr mon nouveau vase d'expansion est tellement blanc que ça fait con à côté de la saleté 😂
I've been using this heavily in the libraries that I've made recently. Makes adding tests to any project a breeze, really solid library.
I dislike booleans in interfaces specifically because of this issue. One of the worst interface I had to deal with was a function with **three** booleans, whose default values where `true`, `false`, `true` as far as I recall. Specifying them "naively" looked like: `MethodName(name, true, true, false);`. Instead, I heavily encourage creating one-use enums. `DoTheThing { Yes, No }` may look slightly overbearing, but at least it's clearer than `true` at the call site.
That is exporting templates. I've tried working with it a bit, but because of the way our template machinery works, it doesn't really help\*. The main cost is not in instantiating the templates for the same type, but instead for instantiating them with different types, and in the amount of code that is generated by assertion macros**. \* I say as I just thought about some things I didn't try \*\* Did you know that some versions of GCC have exponential runtime if they have to compile more than a certain number of `try {} catch` pairs in single function? No? Well, now you do :-D
Especially useful for boolean flags; because otherwise reading `true` at the call site doesn't help much...
Well, there's such a thing as [The Boost Parameter Library](https://www.boost.org/doc/libs/1_62_0/libs/parameter/doc/html/index.html) which is notably used in the [Boost Process Library](https://www.boost.org/doc/libs/1_64_0/doc/html/boost_process/design.html#boost_process.design.arg_cmd_style). However... I'd advise against it. It's a fun theoretical exercise, a nice kata, but it also pollutes namespaces at a rather alarming rate on top of making it hell to step through with a debugger.
What do you want to compare it to?
If you mean cross-*COMPILABLE*, there's imgui and Qt, Qt is bigger and bulkier with more features and platforms,, while imgui is extremely bare-bones and you would probably run ontop of something such as SDL2 for true-cross platform
Do you want a variant of vectors or a vector of variants? If you want a variant of vectors, then you must use `get` with the alternative that is actually contained in the variant, or otherwise you get an exception. This get does not return the first element of the vector but rather a reference to that vector. If you want a vector of variants or you just use the vector to hold at most one value, you can use `std::monostate` as the first variant alternative, so that the variant can be default constructible even when none of the other types are. Another option is to contain a pointer or `std::unique_ptr`, since in that case you don't really need to know the capacity or the size. Using get&lt;size_t&gt;, the same behavior would be implemented with: // \brief Helper function to retrieve type value as a string. static const std::string getTypeName(Type&amp; type) { auto vec = std::get&lt;1&gt;(type); return (!vec.empty()) ? vec.at(0).value : "NIL"; }
Having to rely on compiler intelligence and optimization based on knowledge about the abstract meaning of (even standard library) functions to produce good code is conceptually unsound. If anything, that's an argument in favor of making the behavior ID instead of UB (same for `reinterpret_cast`, or if you _reallly_ don't want that, at least the introduction of a specific cast operator, call it `type_pun` or whatever).
Something like Qt
Define "graphics". You could have a look at Qt, SFML, Cinder. Speaking of Cinder... the latest they seem to offer is VS 2013 packages. Is the project dead?
Like [`std::bit_cast`](https://en.cppreference.com/w/cpp/numeric/bit_cast)? ;-]
What /u/dodheim is alluding to is the fact that `explicit operator bool` was designed precisely for this scenario. There are three ways to convert to bool: explicitly (like `static_cast&lt;bool&gt;(sp)`), implicitly (like `void meow(bool); meow(sp);`), and contextually (like `if (sp)`). With `explicit operator bool`, explicit and contextual conversions are permitted, while implicit conversions are forbidden.
Interesting, I wasn't aware the proposal had been accepted for C++20. I would have preferred an actual “guaranteed no-cost” operator rather than a function that may or may not do a copy, but I guess this is the best we can get.
&gt;Define "graphics". I am planing on writing programs that have user interfaces. Also trying to write project templates that cover a rang of platforms.
You are probably looking for qt
gotem
Ok I will give Qt a look.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a6iff0/cross_platform_graphic_library/ebv9f7j/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
No, your explanation is absolutely wrong. If the undefined behaviour was only triggered by entering the loop with i &gt;= 4, then the condition would prevent that from happening. This would then mean that undefined behaviour is avoided, and eliminating the condition would be a compiler error. What happens is the compiler must have seen the undefined behaviour for i == 3, and worked out that this means the break statement must have been hit first. Therefore, the loop must always exit via the break statement and the condition is not necessary. This isn't the only way it could have tried to optimise the loop, so the exact sequence to get there is indeed a little puzzling.
That's not what it was doing. i * 1000000000 is UB for i &gt;= 3, so the compiler determined that the break statement is hit before i is 3. Therefore, the test for i &lt; 4 is not necessary. It's basically an extension of the following: *ptr; if (ptr != nullptr) // Always true
Ok sorry.
I do not think I understand what you are talking about.Compiler sees that i is always lesser than 4, and removes the check. I also sees other way of exiting the loop,.and assumes it will be taken (can't unroll collatz). The check for i is removed, exactly like I said in my original post.
It sounds like you're a beginner and should ask this question over at /r/cpp_questions.
Depends on where you use this. It might be a good idea if you're in a generic template function that takes a range as a *forwarding reference*, but it is a bad idea otherwise. Use the simplest tool that gets the job done. If you are iterating over a collection just to observe, then you should use `const auto&amp;`. Sure, `auto&amp;&amp;` would work: but this would hide information from the reader and make the intent of the code less clear. My advice: use `auto&amp;&amp;` when you need its flexibility/versatility.
&gt; Use this style of loop! Use `for (auto&amp;&amp; elt : range)`. It Always Works. Never use anything but the thing that Always Works, unless you are willing to deal with the possibility of the-thing-you-use Not Working. I don't know about this 100%-ism. Sometimes you want to take things by value - for the same reason sometimes you want to write functions that take their parameters by value. If I'm dealing with integers, `for (int elt : range)` is probably a better choice than `for (auto&amp;&amp; elt : range)`. Sure, it incurs an extra move construction - but maybe that move construction is on par with taking a reference and avoiding that additional indirection is better for performance anyway. 
Have Mozilla investigated a Facebook's BOLT tool to optimalize PGO binary builds even more? 
There’s no additional indirection; inspect the codegen.
Nothing in the example reads anything - it's hard to say anything in particular about it. 
You're right that the check for i is removed, but your reasoning is wrong. `i * 1000000000` is only defined when i is -2, -1, 0, 1, or 2. This means that the compiler can infer that i is one of those values in the body of the loop, but it will cannot infer that i is one of those values globally. int i = 4; if (i &lt; 4) { cout &lt;&lt; i * 1000000000 &lt;&lt; "\n"; } This program does not have undefined behaviour, and it would be illegal for the program to execute that cout. On the other hand, the following is undefined behaviour. int i = 3; i * 1000000000; ++i; if (i &lt; 4) { cout &lt;&lt; "Maybe?\n"; } The reason it removes the check in your example is that it knows that i is incremented from 0 to 4, but the loop will never be run when i is 3, therefore the loop is always terminated *before* i is 3 via the break statement, therefore the loop is *never* terminated via the check on i, therefore that check can be removed.
Doesn't the `const auto &amp;` example work against the argument? `auto &amp;&amp;` doesn't work for the very case you want to guard against accidentally modifying the element. The error message result from it ISN'T a bug. It's a compile error - the very opposite of a bug. Telling people to use `auto &amp;&amp;` 100% of the time because it always works is factually incorrect. The potential error of accidentally modifying the element is just as bad as the accidental CTAD error because in both cases you're left with the unexpected value.
It's nicer for the user, though. Currently, with existing C99 designated initializer support, GCC and Clang [do not give a great error](https://gcc.godbolt.org/z/Lezt5x) for missing a reference: &gt; note: candidate function not viable: cannot convert initializer list argument to 'args' Even if this improves, where I see it improving to is more along the lines of: &gt; no initializer provided for reference member 'y' Now the user has to wonder why a reference is relevant. I don't see a good way for the compiler to do much better because it doesn't know why the member is a reference. Should the errors improve to this level, a tag would reasonably look something more like: &gt; attempted to use deleted default constructor of 'required&lt;int&gt;' for member 'y' In fairness, with current error messages, the user has to look at the struct to figure out what's wrong anyway and then it becomes the difference between `required&lt;int&gt;` in code or a `// required` comment.
This is what part 1 of the article did.
This will be downvoted to hell, but it has always irked me how 'auto' claims to let the programmer not care about what's on the right hand side but, in reality, you very much do. Why does its type deduction rules follow those of templates? Such a missed opportunity IMO.
What else would it to? 
I don't agree with the idea that a narrow interface necessarily implies undefined behavior. The abstract machine calls out UB in a relatively small number of instances. Contracts often just guard against incorrect programs.
Deduce to the actual type, e.g. const std::string&amp; foo(); auto x = foo(); // x is const std::string&amp; instead of std::string.
Very legal &amp; very cool.
How would you differentiate between wanting a value and wanting a reference? The way it's specified makes that addition very natural: auto x = foo(); // x is a string auto const&amp; y = foo(); // y is a string const&amp;
Something like auto x = make_copy(foo()); All auto has done is save me typing a couple of characters, at the risk of introducing subtle bugs.
&gt;claims to let the programmer not care about what's on the right hand side but, in reality, you very much do. I'm not aware of such claims. Who made such claims?
What is cool about this?
Yeah, that doesn't work very well at all. You can't declare what your own value category is, it's up to the initializer? So if I have a generic lambda that wants a value... `[](auto x){ ... }` isn't enough, because maybe `x` is a reference and maybe it's not? I have to ensure that callers write `lambda(make_copy(foo()))` instead of `lambda(foo())`? It doesn't even work in this case because in the simple case where I just want a value, I need to know what `foo()` is up to. If `foo()` returns a value, I have to write `auto x = foo()`, but if `foo()` returns a reference, I have to write `make_copy(foo())`? If I just write the latter, I get bonus copies? C++ is a value semantic language, it's value by default. Having `auto` suddenly mean reference by default would be pretty jarring. Yes, you can get subtle bugs if you took a copy but you really meant a reference. But at least there's a syntactic difference between taking a copy and taking a reference. Otherwise, `auto` would just be insanely subtle. 
The name of the keyword gives that impression
You wouldn't have to ensure anything, the callers of your lambda would make sure they adhere to its expectations. You need to know what foo() does regardless. make_copy() could compile to a nop if passed an r-value. Use auto x = make_const(foo()); (admittedly pushing things a bit) I never said it should be reference by default. I'd like it to be what's given to it.
I do not understand why you keep saying I am wrong. I know everything you said above, as you might have noticed, I put this example there. I would not do this, if I wouldn't know very well what's happening there. You are just rephrasing what I have said (compiler removes check for i, because when i is 3 the behavior is undefined, so i is always lesser than 4. This is what I said in my post, and this is what you have said. Also, your first snippet does not have undefined behavior, simply because i is not less than 4. I do not understand what relation it is to example I gave. I suggest that if you want to tell me that I am incorrect, you tell me exactly which part in my original posting is incorrect. With quotes.
&gt; And it will do that because with 32 bit integers **i * 1000000000 exhibits undefined behavior unless i is smaller than 4. Which means i is ALWAYS smaller than 4**, and condition check in loop is redundant and can be removed - which compiler does, and the loop becomes endless. It is undefined behaviour unless i is smaller than **3**, not 4, which means that i must be less than 4 after the increment. The way you explained it is wrong, because you only said it was undefined behaviour when i is &gt;= 4, which can never happen unless undefined behaviour has already occurred. &gt;This is what I said in my post Maybe you meant to, but your post never said 3 was undefined behaviour.
No it doesn't. Maybe in another language. But C++ has always given the impression that type matters no matter what, so it never claims "you don't need to care". But a pragmatic reason is that if unqualified `auto` is not a value, then how can the programmer ever specify they want a value and not a reference? C++ is also about value semantics by default, so any other way would be at odds with the language.
Have you looked at pitchfork? [https://www.reddit.com/r/cpp/comments/996q8o/prepare\_thy\_pitchforks\_a\_de\_facto\_standard/](https://www.reddit.com/r/cpp/comments/996q8o/prepare_thy_pitchforks_a_de_facto_standard/) [https://github.com/vector-of-bool/pitchfork](https://github.com/vector-of-bool/pitchfork)
Yes, because it has to deal with the arbitrary probabilities, and apparently no specialization for 0.5.
My favourite conference! The first time I spoke there was just to not have to pay for admission. Now I'm hooked. But what should I talk about?
One should definitely go with the cliutils cmake and folder structure. I like moat the include/projectname as in big project we do not know anymore from here the header files come from and I fell like every project has a utils.h
this is exactly how I feel, if I see a customer project with a boost dependency, its pretty much guaranteed to by enterprisy bloat fest, where most of the cpu time is spent in string comparisons.
I for one am very happy typ are, when I make a reference ;)
In case you are not aware: IIRC, decltype(auto) does what you want. 
Is there anywhere where the details of these efforts are being discussed, or should I carefully browse through boost developers mailing list? I have seen a couple of PRs that seem related to this on Boosts's GitHub superproject, but unsure how it all works with all the submodule madness. I'd be happy to contribute! 
The first is initialization and the second one is the assignment. c0 is pointer in both cases.
Nothing in C++ "always works." There are always trade-offs.
Sssshhh!!! This is the cpp subreddit. Don't mention anything critical about anything that has to do with C++.
Your post has been automatically filtered because it appears to be spam (it was a link to imgur.com). If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a6ok47/when_someone_hijacks_your_custom_type_and_builds/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Answer has already been given. I feel so sorry for you. ROOT is not a pleasant framework to work with. Good luck with your degree in particle physics. 
These are not the same: the first declares a new variable c0 which is of type pointer-to-TCanvas, constructs a new TCanvas on the heap, and assigns the constructed canvas to c0. The second constructs a new TCanvas on the heap, and assigns it to an *already existing* variable c0, overriding whatever value was already there, and potentially creating a leak. 
This isn't the right sub for these kinds of questions, this is /r/cpp_questions 
First one declares and initialises a variable. Second one assigns to a variable that must have been declared previously. With raw pointers there's not much difference between assignment and initialisation, but with some objects assignment may mean the old object has to be torn down, or initialisation may need to allocate memory. So in general assignment and initialisation are different. It's also good practise to avoid having uninitialised or invalid variables, so code like: TCanvas *co; co = new TCanvas("c0","Canvas",200,10,700,500); or even: TCanvas *co = nullptr; co = new TCanvas("c0","Canvas",200,10,700,500); are considered bad style compared with: TCanvas *c0 = new TCanvas("c0","Canvas",200,10,700,500); even if there's no difference in the machine code generated.
I seem to remember they had something along the lines of BOLT to optimize start-up time by grouping all sections of code invoked at start-up together.
That's a meme.
The compiler error message is helpful. It correctly identfies that the parameter `c` in `opt_doesnt_work` isn't constexpr. It doesn't matter if a function is declared as constexpr and you feed it constexpr arguments. Inside the function, the parameter is non-constexpr, so providing `c.count` as a template argument can't work. In general, the only way to "preserve" constexprness through a function parameter is to provide the value as part of the type.
&gt; There's several instances of situations that C++ classifies as UB that could (should, IMO) be implementation defined instead; classic examples are signed integer overflow The implementers are the ones who fight to keep this undefined because of the performance benefit they obtain from it (something like 12 % speed improvements and 1 % size improvements in a geometric mean analysis of several common codebases, according to [this talk by lead C++ engineer at Apple](https://youtu.be/JhUxIVf1qok?t=2339)). When you translate that into say, a 10 % battery life reduction, it doesn't mean implementers will be keen to introduce wrapping or trapping on signed integers. The Committee's attention is now shifting to saying there should be more integer types; unsigned ones that have UB and therefore can be optimized better without caring about corner cases, and signed ones that implement modulo arithmetic. 
&gt; You wouldn't have to ensure anything, the callers of your lambda would make sure they adhere to its expectations. Rarely when I do a code review do I have to fire the writer of the code I'm reviewing. This might do it: "I won't enforce this with the type system, because I can just get every caller from now until eternity to enforce it on themselves." 
+1
The reason is two-fold: (i) [a large number of performance optimizations rest on knowing that signed integers do not wrap](https://kristerw.blogspot.com/2016/02/how-undefined-signed-overflow-enables.html); (ii) it fixes some security related bugs but in general if your integer wrapped and you were not intending to do modulo arithmetic, you have a bug whether or not the program is undefined.
Thanks. I mean I can see why `opt_doesnt_work` can't work in general as it would have to have two different signatures at the same time, but I guess my confusion boils down to understanding when something stops being a compile-time constant expression. I'll have to see if I can find some way of getting the information conveniently encoded as a type..
Removal of pointer indirection is a very useful performance benefit. I work on a large codebase from the 1990s which is spread into tens of thousands of translation units and is very heavy on nested pointer indirection. It's also run off network drives, so you get situations where you have to wait for a dll to be pulled off the network only to find you're jumping back into the original file you already had in memory. The more the compiler can do to eliminate this indirection for free, the better. If we hit some bugs along the way, we will fix them. Just like we do every day.
Basically, the answer is "when it becomes a function argument". It's really too bad we can't declare arguments as constexpr. As long as `count` is a member variable with a potentially runtime value, it can't be part of the type. Otherwise you'd just use `integral_constant` everywhere, or have it as a template parameter. Or in C++17, you can do something like this: [https://bitbucket.org/guan-jing-ren/gut/src/master/constant.hpp](https://bitbucket.org/guan-jing-ren/gut/src/master/constant.hpp)
Great explanation, thanks. And have a happy cake day!
Yeah, that'd make it a lot easier. I think I may be able to do something with some extra indirection though: template&lt;typename ConstructFunctionT&gt; constexpr auto optimized(ConstructFunctionT cf) { constexpr auto c = cf(); return counter&lt;c.count&gt;(c.count); } int main() { constexpr auto c = []() { return optimized([]()constexpr{return counter&lt;10&gt;{7}; }); }(); static_assert(c.count == 7); static_assert(c.max_count == 7); } Have to see if I can adapt to my real problem. Thanks again for the hints.
&gt; The implementers are the ones who fight to keep this undefined because of the performance benefit they obtain from it (something like 12 % speed improvements and 1 % size improvements in a geometric mean analysis of several common codebases, according to this talk by lead C++ engineer at Apple). When you translate that into say, a 10 % battery life reduction, it doesn't mean implementers will be keen to introduce wrapping or trapping on signed integers. Isn't that just a confirmation that it should be implementation-defined rather than undefined behavior, though? &gt; The Committee's attention is now shifting to saying there should be more integer types; unsigned ones that have UB and therefore can be optimized better without caring about corner cases, and signed ones that implement modulo arithmetic. I like the idea of having separate types for different kinds of behavior, but I don't particularly like the idea of having it restricted to unsigned vs signed. Why not have an attribute that orthogonal to the signedness of the type (to wit, something like `unsigned int [[overflow(saturate)]]`)?
Ops, I'm sorry my mistake
thank you :-) 
&gt; There's several instances of situations that C++ classifies as UB that could (should, IMO) be implementation defined instead; classic examples are signed integer overflow and union-based bitcasting for standard layout data types. I mean, in practice nothing stops compiler writers from giving you `-fwrapv`. 
Boost mailing lists (there are several) are where all the discussion happen. It shouldn't be hard to follow the recent ones, but it's still tons of messages.
Agreed, and just to quibble:, this one gets my vote: TCanvas * const c0 = new TCanvas("c0","Canvas",200,10,700,500); 
what isn't being enforced by the type system? All my suggestion does is make it explicit in the source code what the compiler will do anyway. What if i want to pass an actual reference to this lambda, for example a reference to something in TLS?
This isn't the right subreddit for asking c++ questions (see /r/cpp_questions). That said, you have a typo in `sendCofeOrder` (sic) and this is not at all a well-formed question. I also suspect it's a homework question which makes me even less inclined to read further.
I checked your post history... you're a repeat offender of this and have already acknowledged other comments saying not to post here. Please stop!
I'm working on my own coffee machine with a few friends. My understanding on uarts are not the best to be honest, which is why the questions asked a bit confusing. My problem that the uart will echo back whatever it recieves from other devices, sorry if this is not the quest subreddit, ill go look at cpp\_questions.
It's not a "waste of time" but you should pay attention to the feedback suggesting you make your language more precise. For example, stuff like: "Iterators are just special variables that point to a certain element in a container." Iterators aren't "variables." They are types with many variations (forward, random, bidirectional, etc). Earlier, you refer to pairs as "mini-containers" which suggests that there should be iterators for them. Sharp beginners *will* pick up on these incongruencies, so it is important to say what you mean, and mean what you say. Saying stuff like "you're now a C++ pro" is overly gratuitous and doesn't help anyone. As for the cheatsheet portion, my feedback is that it actually contains too much content to qualify as a "cheatsheet," which in my opinion, should be immediately readable and contained within a glance. For full examples and a description of the semantics, I would just use cppreference itself. Your cheatsheet should honestly at a minimum contain actual arguments and return types (note, it would currently be missing overloads) and a very terse description to be useful. 
I dont understand how \`NewMax\` is deduced in the \`opt\_ok\` function. \`Max\` makes sense from the function argument but how does the compiler know \`NewMax\` is 7?
I dont understand how \`NewMax\` is deduced in the \`opt\_ok\` function. \`Max\` makes sense from the function argument but how does the compiler know \`NewMax\` is 7?
&gt;But I can't What does that mean? `goto LOOP1;` really?
[removed]
I'm providing it explicitly in `return opt_ok&lt;c.count&gt;(c)`. `Max` is deduced from `c`. This works here because `c.count` is a compile-time constant expression in that context (but not inside `opt_doesnt_work` where `c` isn't a constant expression). At least that's my understanding.
I get how `Max` is working, but not how `NewMax` is being deduced. 
`NewMax` isn't being deduced, it is explicitly provided as `c.count`
yeah i just realized that, misread the function call, cheers!
convenience should never be a substitute for const-correctness. I would hate to maintain his code.
&gt; Why not have an attribute that is orthogonal to the signedness of the type I didn't explain myself clearly – but that seems to be what we are heading towards. Won't make the cut for C++20 though.
Hello. I just dropped by because I wanted to say: thanks for trying and even if the material is not there yet I am sure you can do a good job with the feedback given. Do not get discouraged, keep learning the material and teach it through good practices. I would recommend you books such as Effective Modern C++ and others. Stay positive under the criticism and good luck :)
Why would you want to take a vector by const reference, then move it? When the caller calls the constructor, the expectation is that the vector argument is unmodified, much less actually *moved from*. I would take the vector by value and use `std::move`. This way, someone can pass an lvalue vector and have the copy constructor called (so that the original vector is unmodified) or an rvalue vector and have the move constructor called (so that there is no unnecessary deep copy). See https://stackoverflow.com/q/10231349/8887578 for the rationale. Also, you need to do `this-&gt;vector`, not `this.vector`, because `this` is a pointer, not a reference. You should use [member initialization lists](https://en.cppreference.com/w/cpp/language/initializer_list) anyway. 
If your need to store the function/constructor parameter, you mostly want to take it by value and then move it: explicit Foo(vector&lt;int&gt; numbers) : _numbers{move(numbers)} {} Now, when you call constructor like this: Foo foo{vector{1,2,3}}; No copying will take place, as the vector is a temporary and will be moved into the constructor If you are passing an existing vector, you can pass by move: vector nums{1,2,3}; Foo foo{move(nums)}; Or if you want to copy the local variable its just: Foo foo{nums};
By-value-and-move saves a trivial amount of typing and makes the copy version slightly slower because instead of just a copy it's now copy + move. Too me, that doesn't seem worth the benefits of just writing the copy constructor and the move constructor.
Fully agreed. The only thing I'd add is that if ownership is very definitely being transferred he can do &amp;#x200B; Foo::Foo(std::vector&lt;T&gt;&amp;&amp; vector) : vec\_(std::move(vector)) {} &amp;#x200B; That at least forces the caller to std::move the vector in, making it obvious they're losing ownership. I guess it depends somewhat on what he means by "copying is rarely the answer because lifetimes are known by higher-level components" while still wanting to move things around; I'd interpret it as you have in your reply, and move in a copy, but it's an odd phrasing anyway since if you're going to move anything the higher-level components have lost track of ownership anyway...
Perhaps for one argument, but when you need to pass more than a single thing, the number of overloads needed grows exponentialy.
Please tell me why do you need single headers? Was it because of an easy way to exchange your library with others? I wrote it in python because C++ don't has a uniform dependcy/build manager like python. Targeting Windows, Mac and Linux (with all the distro) is not that easy. I think you know.
I feel it's a bit early to be blogging about how `&lt;=&gt;` will work in C++20. Given the concerns and proposals that have come up, I'd consider it likely to change before C++20 is done, which would make this material outdated. For example, equality might not be included in a defaulted `&lt;=&gt;` for reasons given in recent proposals and blog posts. 
I think it's fine since blog posts can easily be updated :) Better spread awareness early on what future things will come.
There are a couple things here to clear up: * Moving is a destructive operation. It cannot be done on a const object. * Confusingly, std::move() does not actually move anything! It casts a named object into an r-value reference. That is, it turns it into an expression that CAN be moved. * If you pass a movable expression into something \*by reference\* no move takes place. * On the other hand, passing a movable expression into something \*by value\* will invoke a move constructor (if one exists). So, if you are using a movable type, and you want to write a function that will accept moves, make it accept parameters \*by value\*: \`void myfunc(std::vector&lt;int&gt; vals);\` &amp;#x200B; Then, when you call \`myfunc\`, with EITHER a temporary value OR an std::move() expression, a move will be performed, and if you call it with anything else, a copy will be performed.
&gt;jea Done! Let me know if that suffices. I'm also planning a header only version with native support for all integer sizes "real soon now".
I really like this. Anything that removes the need for boilerplate code is ok by me!
Genuinely curious: when would you need such a type? And why would a shared_ptr/unique_ptr not work? 
&gt;For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
I've come to do a lot of event-driven programming in C++ and for most classes working with the event loop it is natural that the class shouldn't be copyable/movable as it basically would make no sense, and also enables usage of intrusive data structures. Sometimes I'd like to make a function that makes an instance of such a class; it's possible with C++17 but has limited usability because of this limitation of emplace. Yes, shared\_ptr/unique\_ptr is a workaround.
interesting article, learned couple tricks, which I'm afraid are too tricky for me to use in my projects. for me, building with static linking on windows works well enough, considering that I'm trying to keep the dependency list as short as possible.
It would be nice to avoid heap allocation if possible.
Note that you can already do it without modifying the container by using a custom type with conversion operator, as shown here: https://quuxplusone.github.io/blog/2018/05/17/super-elider-round-2/
From the future: did you try using cquery inside the container? Any luck? I'm expecting to have the same problems, and it seems like this could be the closest thing to a genuine solution.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a6tl6l/need_to_learn_mfc/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Another way (but quite constraining) is to delay load the binaries, and have some magic code at the beginning of the main to tell where your DLLs are. 
Ok thanks to both of your replies. I think I need to understand this more. I think there is no way to make this zero-copy with std::move ... and I might have to pass in a pointer to the vector. Basically what I mean by higher level components owning is that when they pass in any object to me, the way my code is called will always be in the lifetime of their stack frames and nothing escapes from my code so basically these large vectors need not be copied at all but as I convert all this C code to C++ ... it keeps getting slower and it is due to these extra copies that keep happening and I have no idea why! So I started looking at the Clang AST to find where all things are getting copied. And the answer is they're always copied unless I can prove otherwise. Of course then all the C++ gurus in my team say no that's not a copy that's a move .. and I'm frustrated .. I want an easy tool to tell me this is being copied or not. I'm surprised the C++ community doesn't have this. I want a tool that will tell me every callsite where an object &gt; pointersize is being copied. I now also understand copying is a vague term, what I need to know is every time a copy constructor or assignment operator is being called. I've also realized often times move constructors aren't that efficient so I now have to drop down to assembly a lot more often than when dealing with C.
The result of that will of course be that it will be delayed until C++23 and then be standardized without further changes... Sometimes I really hate the committee.
&gt;I seem to remember they had something along the lines of BOLT to optimize start-up time by grouping all sections of code invoked at start-up together. GCC does that automatically, too, even though it is not very smart (it splits code to hot&amp;cold and orders executed code according to the first execution). I plan to look into it for GCC 10.
All I want for Christmas is for Microsoft to fix exactly this. [Well ok, maybe there are a few other things as well. But mostly this.](https://nibblestew.blogspot.com/2018/10/things-microsoft-could-do-to-make-life.html)
&gt; This compiles. And is unreadable.
&gt; the new rules do not guarantee copy elision. Instead, the new value category rules are defined such that no copy exists in the first place. [Eh?](https://media.giphy.com/media/hEc4k5pN17GZq/giphy.gif)
`void f(struct { int a; int b; } args) { }` probably doesn't work, but it wpuld be nkce if it did.
Wasn't it decided that `operator&lt;=&gt;` won't generate `operator==` and `operator!=` due to performance concerns (i.e. `std::string::operator==` can be much faster than `std::string::operator&lt;`)?
std::unique being called with a non-equivalence relation is something I hope to never see again because 1) it makes std::unique no longer std::unique and 2) it's also undefined behavior. &gt;1) Elements are compared using operator==. The behavior is undefined if it is not an equivalence relation. Some of the output in the video would be different for different implementations of std::unique (based on whether it's comparing against the first element, or the previous element which in an equivalence relation will be the same)
The phrase "as part of a publically available C++ STL implementation." may be an issue for us (I am on vacation and I am not a lawyer so this is speculation) since it raises the question of whether MSVC's STL counts as "publicly available". (It also prevents your code from being used in other languages' libraries; e.g. Swift, Rust, whatever). I think it would be better to simply say "This software may alternatively be used under the following Boost Software License." Would that be okay?
Do you need to set the spaceship operator to default or will the compiler Rule of Zero generate one for you? 
RPath, esp. default absolute one was very unpleasant surprise to have when porting a library from Windows to *nix. Relative RPaths would be nice to have though. Mostly for aesthetic reasons.
Very good example being a rectangle class. I'd take having `Point` `Size` and `Point` `Point` constructors over a list of 4 integers that I have no ideas how to use.
Well in the example, because it's a template you can SFINAE all of it to force some arguments. For structs you could probably do something by using a class with no default constructor.
That sounds concerning. My heart still hasn't recovered since `= default` for equality operators was dropped from C++11. Do you have a link to those proposals/blog posts, so I could learn more?
I don't see any source code.
Papers: - [`&lt;=&gt; != ==`](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1185r0.html) - [When do you actually use `&lt;=&gt;`?](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1186r0.html) - [I did not order this! Why is it on my bill?](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1190r0.html) - [Spaceship library update](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1295r0.html) - [weak_equality considered harmful](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1307r0.pdf) Blogs: - [Improvements to &lt;=&gt;](https://brevzin.github.io/c++/2018/11/12/improve-spaceship/) - [Trip Report: C++ Standards Meeting in San Diego, November 2018](https://botondballo.wordpress.com/2018/11/30/trip-report-c-standards-meeting-in-san-diego-november-2018/#comparisons) - [Mathematics behind Comparison #4: Three-Way Comparison](https://foonathan.net/blog/2018/09/07/three-way-comparison.html)
&gt; You have to patch executables after they’re built and this really confuses your build system. Not a problem if you *always* write to a`.exe.tmp` file first, then only write the result of patching to the actual `.exe` filename.
So you registered a reddit account 20 days ago, just to post a video every day of your engine? There isn't much detail to any of these videos, no source code, no accompanying blog posts explaining some subreddit specific challenges (ie, cpp). Not sure what you want to achieve here.
Can you elaborate why making the event class movable would make no sense to you? 
Could you elaborate a bit more on why you need a shared/unique\_ptr? (I did not vote down or up, that was someone else).
&gt; And so, you'll find OS's like CentOS7 with GCC 4.8, with almost-complete C++14 support, and CMake 2.8, which came out before C++11. centos also has a cmake3 package with 3.12 AFAIK
&gt; OTOH I considered the actual best-practice of using ? to be very interesting, so why did the examples not use that?! Being able to use the `?` operator in main is a reletively new addition, which I think has something to do with it.
Oooh, saving.
&gt; Use `for (auto&amp;&amp; elt : range)`. It Always Works. "Saying that Java is nice because it works on all OS's..." 
It isn't really a `std::function` alternative, it's more similar to the `function_view` type that has been floating around, for example here: https://foonathan.net/blog/2017/01/20/function-ref-implementation.html
This must be an error. Today was supposed to be available, but there is no info on it. Nothing shows up in [Amazon.com](https://Amazon.com), and in my country, its not available: [https://www.amazon.es/Accelerated-C-Andrew-Koenig/dp/0135166675/](https://www.amazon.es/Accelerated-C-Andrew-Koenig/dp/0135166675/) Does anybody know if the author has commented something about a new edition being developed? &amp;#x200B;
`function_view` is undergoing standardization under the name of `function_ref`: see https://wg21.link/p0792 It does handle capturing lambdas. 
It all started here in 2005: [https://www.codeproject.com/Articles/7150/Member-Function-Pointers-and-the-Fastest-Possible](https://www.codeproject.com/Articles/7150/Member-Function-Pointers-and-the-Fastest-Possible) As the years have passed more modern versions have appeared, but all following the same principle. This version is just another one written in C++14
Another similar thread here: [https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/J62lsMB6Egc](https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/J62lsMB6Egc)
You can do this using Qt, with a QWebEngineView. Something very similar and with more functionality is to use Qt/QML which gives you C++ for the program logic and a javascript+declarative UI.
&gt; "C:\mydll.dll" I'm not a unix expert so maybe I misunderstood something, but this whole concept sounds alarming - why would you embed an *absolute* path into the binary? What if the user don't even have a C: drive?
\*\*Company:\*\* \[Mediapro\] \*\*Type:\*\* \[Full time\] \*\*Description:\*\* \[Mediapro is a leading group in the European audiovisual sector, unique in content integration, production and distribution. In our Barcelona headquarters we develop a novel system for automatic sports production named AutomaticTV (www.automatic.tv) which is currently being sold and used around the globe. AutomaticTV uses cutting-edge AI and video processing to leverage the limitations of traditional / human operated sports production enabling new business opportunities as human operators are no longer needed for recording and producing sports. Currently, we have an open job position for a **Senior C++/CUDA Engineer** with a strong background on advanced C++ concepts, and provable industry experience as a **C++** developer. Knowledge in **CUDA** is desired.\] \*\*Location:\*\* \[Barcelona, Spain. We speak English, Spanish, Catalan and a bit of French\] \*\*Remote:\*\* \[Only on very special situations. We highly prioritize candidates which can relocate.\] \*\*Visa Sponsorship:\*\* \[We prioritize European citizens, since no Visa is needed. For other continents we might consider special cases.\] \*\*Technologies:\*\* \[We use C++17, CUDA 9.1/10, Qt 5.9 LTS, OpenCV 3.4.x, ffmpeg, npp, Thrust, on Windows. Nice to have experience on OpenGL, OpenCL, HSA, Boost\] \*\*Contact:\*\* \[Pleas apply and we'll contat you with more details: [https://www.linkedin.com/jobs/view/1023009928/](https://www.linkedin.com/jobs/view/1023009928/) [https://trabajaconnosotros.imagina.tv/index.php/es/ofertas/ver\_detalles/478/senior-ccuda-engineer-barcelona](https://trabajaconnosotros.imagina.tv/index.php/es/ofertas/ver_detalles/478/senior-ccuda-engineer-barcelona)\]
You are right, instead of casting the lambda to a function pointer, it stores a pointer to the lambda itself and another "invoker" function to cast it back when invoking.
Code once, debug everywhere.
Code once, debug everywhere.
Certainly a good suggestion. I recently reworked a project structure to this and didn't regret it. Besides that: DO use modern CMake (`target_*` functions, no "plain" ones like `include_directories`, `add_definitions`,...)
`std::mutex`?
Came here for that argument. If you don't intent to modify the element in the body, you gotta declare it `const` or it wouldn't pass code review here (for good reasons). Why is there nor `const auto&amp;&amp;`?
I am coming a bit late with a reply; did take a look at it and benchmarked and tested it. I used the same 2.2 GB data I used for my own timings before. First of all, to keep testing simpler, i first tarred everything into one file for easier feeding to the blosc. The compressed takes 1.4 seconds with nthreads=12 (without writing the result out into a file). Snitch does the same trick in 2.8 seconds while writing the results out and in 0.9 seconds when NOT writing results. This was from the original data folder with 4000+ unique files. If I compress the tar, the it takes 0.8 seconds soo 100 ms is "lost" in opening and closing the files and other overhead like that. So in summary: blosc1.4 seconds, snitch 0.8 seconds. The resulting file sizes with these times were blosc 2100 KB and snitch 1965 KB. The example data in this test was hard-to-compress image files mostly. There was one property in blosc which was quite handy: the shuffling of data before compression. For example, if I know I have buffers of float values I can shuffle the data so that all LSB bytes are sequential first, then 2nd bytes and so on. This does improve compression ratio and it's nice that it's built-in into the compressor, I do that sort of stuff separately from the bitstream-compression. 
I tried it. I forget the issues I had, but there were plural. There were issues both on the cquery side and the vim side, unfortunately. I wish I could give you more information, but the key point is that I didn't end up getting it working.
That is very interesting. It's also a very mature library, so some of the ideas might be useful to incorporate in your own tool. Great information, I guess Snitch is actually a lot more mature than I may have imagined.
Sure, a program that calls vector::operator\[\] with an out-of-range index is incorrect. But zero- (or negative, given optimizations) overhead implies that such situation is "impossible", which appears to be represented as UB.
That's useful only for development. Imagine you have several different versions of a library on you system (quite common for dev machines). You wouldn't release a program like this, of course. Do note that rpath can be relative. This is can be used for releases as it makes the directory structure of an application easier to manage.
Bummer. So is running it the full editor from inside the container the only solution still? (Aside: why does nobody talk about this?! It seems like a huge asterisk in the whole 'docker makes everything rainbows and sunshine' narrative.)
We are compiling from linux to windows (32+64bit) via mingw, to linux 32bit (+64bit native), and apple universal(ppc,32,64) via custom gcc 4.2
There are some limitations there, like exported globals, and some others. For example this won't work with Qt5Core.dll (or ate least the version we are using - Qt5.10)
Patching executables may create issues with post-mortem analysis of your crashdumps (or you might take care of it specifically knowing it'll be done).
Couldn't that be solved by an override-like mechanism? I.e. operator&lt;=&gt; generates everything it can, but not any of the six operators that are user-specified. So you can have the convenience of &lt;=&gt;, combined with the potential for speedup in the cases where it matters. 
`&lt;=&gt;` is never implicitly generated. If you want it, you have to opt-in.
&gt; So is running the full editor from inside the container the only solution still? Yeah, that's the solution I've found. &gt; It seems like a huge asterisk in the whole 'docker makes everything rainbows and sunshine' narrative I think Docker is a way overvalued technology, personally, but this just isn't really an extremely common use case I don't think. The bigger issue here anyways is really that C++/most languages don't really offer great options for remote protocols for editing. cquery is not industry-wide, and the vim integration for LSPs in my experience is really hard to work right. Basically, if you can get your editor to use a compiler on a VM or another machine on your network, it will be even easier to integrate it with Docker. But if you can't (which I could get working for C++ and vim), you can't really.
There are lots of limitations, but it can work pretty well. I have no trouble with Qt 5.9, but I have to avoid creating some types (e.g. QList) but in my case it works well since my executable is just a shell that loads some plugins
I don't know about the apple one, but aren't the others available for free?
&gt; Support GCC's destructor extension in plain C Or, you know, just admit that you're no longer using _standard_ C, admit defeat and switch to C++
Huh. That still confuses me - the docker website is plastered with banners saying that it should make the development story far simpler by making it easy to setup a dev environment. Isn't this exactly the use case they're alluding to there? The only thing I can think is that a lot of people are using languages that don't rely particularly strongly on system libraries, making it a non-issue to get code-completion working on the host side. Anyway, thanks for the info!
So, a delegate, not a std::function alternative? 
&gt; Isn't this exactly the use case they're alluding to there? I think having the whole editor is what they're alluding to there, but even still, Docker would make what we want easier if the languages themselves supported these remote protocols.
Thanks
[This Sand Diego trip report](https://botondballo.wordpress.com/2018/11/30/trip-report-c-standards-meeting-in-san-diego-november-2018/#comparisons) says the following: &gt; (Approved) I did not order this! Why is it on my bill?, which probably deserves a medal of some sort for most creative paper title. (Explanation: the paper concerns scenarios where you don’t care about ordering your type, only equality-comparing it, you implement a defaulted operator&lt;=&gt; (because that’s “the C++20 way” for all comparison use cases), and you pay a performance penalty that wouldn’t be there with hand-written code to deal with equality comparison only.) A related paper offers a solution, which is along the lines of making == be its own thing and not fall back to using &lt;=&gt;, since that’s where the inefficiency stems from (for types like string, if the lengths are different you can answer “not equal” much faster than if you’d have to answer “less” or “greater than”). A second part of the proposal, where a defaulted &lt;=&gt; would also generate a defaulted ==, so that users can be largely oblivious to this problem and just default one operator (&lt;=&gt;), was more controversial, but was still approved over some objections. That might be what you're talking about. I really don't know how to read that paragraph.
I'm looking forward to your articles covering the subject, this seems like a hairy topic!
Huh, that's a cool hack. I guess I might put that in my code base as a quick fix.
1) It involves writing more code just to support this. Like correcting pointers to this class from other classes / data structures. 2) Such support would inevitably be less (un-?) tested in many cases and thus likely to have bugs.
Need? Putting the class into shared/unique\_ptr was suggested as a workaround in the top level comment.
I been working on the library underneath it for 6 years now, and the library it replaced is from 1998. I started from scratch with a complete rewrite in 2012. The older library was mainly single-threaded and using well established practices like opening a file handle, reading stuff into buffers and parsing from there. If I want to load an image, I parse-allocate-decode in one API call: Bitmap foo("hello.bmp"); You know, the usual.. quite common way to get things done, at least on the exposed interfaces which wrap libjpeg, libpng and others. I had other plans at the time.. it was getting pretty obvious at that time, quite hindsight already, that CPU core counts will just keep increasing and frequencies won't drive the performance anymore so much. GPUs been on that track for 15+ years at that point to show where we're headed, so I figured I want to work around memory latency and bandwidth bottleneck while also taking advantage of more CPU cores so I worked around that writing some prototype code. The prototype worked quite OK, so figured I might want to facelift the library and so I did. Some of the code has been tuned a bit excessively, some has been written more lazily.. but the paths the data take from file-to-screen can be really tight with the latest design. Optimum case is iOS / macOS with hardware compressed texture; the GPU can directly consume the texture data from the memory mapped file with this API on those platforms. That's pretty sick: there is no "loading" at all. I simply provide a framework which allows to make the connection between the "file" and the "texture", managed by the graphics driver (OpenGL / Metal). Although, Apple doesn't give much about OpenGL these days so the more interesting use cases in the future might be found on the DirectX 12 and Vulkan. The graphics landscape is fragmenting a bit lately so the future is a bit shrouded in mystery.. most likely Middleware will just entrench it's grasp on the developers with their GPU API abstractions (I am not saying that's good or bad thing, just saying how I see this played out most likely). It's not really about "loading images", it was just one example that popped into mind first as it's quite handy for that. There are some abstractions that make writing portable code more fun. The filesystem stuff is pretty cool, the C++ standard is bringing some fun back to that in C++17 std::filesystem but it's still missing the container / compressing / encryption support. They are just bringing unified API for the basic stuff, but that's still cool and might use that to clean up my code base for those parts. I used to use the SIMD abstraction we have these a lot in certain projects-that-shall-not-be-named and tuned it to be pretty fun thing to work with overall. The multi-threading support through ConcurrentQueue / SerialQueue is pretty easy to use and tuned to be reasonably low-overhead. My biggest "regret" is using std::function to pass the tasks as it is quite expensive, but it makes the code so much cleaner than having a job class which you must work with. Writing code like that is just not something for me. I get 10-20 millions tasks per second through the pool currently opposed to 200K-400K task you can do with std::queue and mutexes so it's still a big net win there. Plus the API is super fun to use :) ConcurrentQueue q; q.enqueue([] { /* my task */ }); That's it... your code is executed in the pool! The pool's job is more or less just remove some thread management/creation overhead but the API brings also some convenience into play. Stuff that doesn't really "do" much are still better off with simple std::thread, stuff like waiting for I/O and such. The pool is better when you want to break something heavy into smaller tasks. The reason why you would want to do that is because it scales better. If you got some job that takes 3 ms, you could just split it into 4 parts and call it a day. That works.. on a 4-core machine you run in 1/4 th the time, cool but when you get that 32, or 64 core machine it suddenly won't. Now you want the overhead to be manageable so that you can afford to split work like that. You can also split work based on your hardware concurrency but you can't do that until it is possible to split the work to begin with so making that as much fun and easy as possible is the cornerstone of going forward with how the hardware is evolving. Anyways, some thoughts like that have been the drivers on the evolution and design of the API is 2012. It's been a while again since then so my thinking has progressed a bit and trying to catch up and keep up. :) 
There is `const auto&amp;&amp;`. But that would only bind to an rvalue, so you probably dont want it. If the goal is `const`, you really do just want `const auto&amp;`.
There is a ton of C code taking care of core infrastructure and the people running those will _not_ switch to C++. That's just the way it is. Adding the destructor syntax would make it possible for those projects to improve and we _all_ would be better off.
I assure you that it is very possible to write and run a program that calls vector's [] out of contract, even though such a program would necessarily invokes undefined behavior. Depending on the program, compiler options, and execution environment, that program may even appear to execute correctly. Whether a compiler (optimizer) can *prove* that program invokes UB and what it does with that information is an entirely different question. There's a separate question as to whether a contract can inform the optimizer about logical conditions that lead to UB. The only thing "zero-overhead" about operator [] is that it has a narrow contract: its condition is not required to be checked.
[removed]
If you talk about on-line tools, I'm willing to assist you (remotely) with a demo of my code generator.
State of things so far: - `operator&lt;=&gt;() = default` (I might not have syntax exact) will generate `&lt;=&gt;` and `==` (and all the rest). - if you implement your own `operator&lt;=&gt;()` will NOT generate `==` (nor `!=`), it will only generate the ordering operators. - thus you need to also write `==` (you get `!=` generated for free) And there may be more small tweaks yet.
That sounds cool, but not my area really.
Wouldn't it be even better if this was standardized in C first?
I would look for a C++ REST API lib and connect to it with your web interface. I have a project that works like that except with Python instead of C++. The web interface is just some static html/css/js files that connect to the REST API of the server.
Yes, I provided this link, because as far as I know these kinds of "Delegates" all started with this article. It's for "historical reasons". I'm aware there exists more modern and much more compact versions like the one you have linked.
Thanks for the clarification, that actually sounds good. I wanted to ask what happens if you default `operator&lt;=&gt;`, but have a custom `operator&lt;`, but that's really not a reasonable scenario.
Yes it would be. But it is easier to standardise an existing, widely implemented extension to the core than going the other direction. I think at least, don't have first hand experience with that...
What? `const auto &amp;&amp;` follows the same template deduction rules, so it's a forwarding reference and would bind to a `const auto &amp;`.
That member function pointer syntax is insane. 
`const auto&amp;&amp;` is not a forwarding reference.
Yeah, I was wrong. I should have checked first.
&gt;Do note that rpath can be relative. This is can be used for releases as it makes the directory structure of an application easier to manage. I'm in the same boat (*nix newbie). If Apps A and B want to use the same shared library, how do two applications know which rpath was chosen by the other.. ? 
That's not a very enlightened approach to code review. That's why it's there: to review. If people make a mistake in thinking, design or implementation, the review is there to correct it. Only if people refuse to correct an obvious mistake should that shine a light on them.
For posterity sake, here's a good list of various implementations evolving in kind of chronological order https://www.codeproject.com/Articles/7150/Member-Function-Pointers-and-the-Fastest-Possible https://www.codeproject.com/Articles/11015/The-Impossibly-Fast-C-Delegates https://www.codeproject.com/Articles/13287/Fast-C-Delegate https://www.codeproject.com/Articles/136799/Lightweight-Generic-C-Callbacks-or-Yet-Another-Del https://www.codeproject.com/Articles/995916/A-Smart-Function-Pointer https://www.codeproject.com/Articles/1170503/The-Impossibly-Fast-Cplusplus-Delegates-Fixed https://github.com/codeplea/pluscallback https://github.com/marcmo/delegates https://github.com/reiver-dev/cppcallback 
I don't know about the TS, but Clang's experimental support of the working draft concepts seems to allow what you're trying to do: [https://godbolt.org/z/J\_Dl0J](https://godbolt.org/z/J_Dl0J)
Yup, sorry that's what I meant: standardizing destructors in C.
So storing a `void*` is cute, but why not store bytes and put anything trivially copyable in there? You can even keep track at compile time if there is enough room. Compile time 0 state objects that invoke member functions can be split off from this; then the memfun case is: delege&lt;Sig&gt;(memfun&lt;&amp;T::foo&gt;, &amp;t) where we stack the stateless memfun and `T*` into a buffer and unpack/execute it. We now have the ability to up the buffer size; say size of 3 pointers or whatever. In many compilers, trivial to copy lambdas are trivialky copyable; on those, delegate&lt;void()&gt;{ [foo]{ return foo.do(); } } can work, where we actually store the lambda in the buffer. Basically I have a concern that `function_view` and `light_function` **should not be the same type**, and that is what this delegate is. It is a light function for memfuns and object ptrs, and a view for stateful lambdas. The result is often toxic and unsafe; "can I pass a stateful lambda to a delegate" is "do I fully understand the lifecycle of this delegate and all of its copies". A function view should never outlast its initialization scope. It is a type erasing adapter for callback with limited lifetime. A light function should not be initialized by-value from something it requires to persist to be valid. Mixing the two is code smell. 
1) Sometimes I feel so. For example, I don't use the STL that much. Others don't use template metaprogramming. Even within C++ beyond the features, there are different subdomains and specializations that people choose instead of using all of it. Some people have their criticism of the language that because of the lot of added on features it feels like some "stitched together Frankenstein-monster". But I'm fine with C++ because the "you don't pay what you don't use" principle applies. 2) I still rather write desktop applications in C++ with Qt than in Java with Swing. Or for example, most finance companies I know also write their core software in C++ to maximize speed. 3) I wouldn't go back to C++98 if I don't have to. Smart pointers, move semantics, lambdas, paralellism and multithreading, variadic templates... These just reduce my workload. C++98 wasn't horrible and didn't had problems to work with, but modern C++ feels like version 2.0, and it's even easier for beginners to get into C++ with that. 4) I actually wrote about this. https://balintkiss501.github.io/faq
1. Not at all 2. Yes and no. In the niche, some people would argue that you should consider Go or Rust for new projects, but even new projects could still tied tightly with old C++ codebase/libraries/toolchain that are not yet replaceable so they would still choose C++. But outside of the niche, people value familiarity with more programmers, faster development time, and high level abstractions more over performance and minimal footprint. 3. In my opinion newer C++ is better but not significantly and it's okay to ignore the way of doing stuff 4. I don't know the answer to this yet, but I generally look for books and talks by the creators or maintainers of the language itself, or notable C++ libraries, or game engines.
Easy and trivial recommendation: copy what works from others. https://github.com/nlohmann/json Well set up CI, tests, build system, documentation, contribution guidelines, release notes and history of major API changes etc. 
1. Without question. Just begin by looking at the [initialization rules on cppreference](https://en.cppreference.com/w/cpp/language/initialization). It's a lot. We're fortunate so many smart people work on it and manage to introduce features which let people sometimes forget about some other parts of the language. If modules can at some point in the future offer a path toward more aggressive deprecation, then that will be a good thing. 2. Depends on the job market region, probably? Recruiters that reach out to me about C++ are hiring for very C++y things. My friends working on consumer applications--even for desktop--are writing JavaScript, C#, or whatever mobile language is appropriate. Friends who use C++ work on things like games, finance, aerospace, or embedded systems. 3. C++11 is clearly a net improvement. It's possible to be both bloated and better. C++98 compatibility is not worth pursuing. If you want to be conservative, then C++14 is a good cutoff point right now--though there are still many teams that can only use C++11. It is a sadness. 4. Hard for me to answer because I learned C++98/03 a while ago, then worked in other languages, then came back. What helped me catch up was CppCon videos, Scott Meyers' Effective Modern C++, arguing with people here, and a lot of experimentation. What level of C++ skill and knowledge are you talking about starting from here? Narrowing that down will help people give better answers to this.
An important use for Sparse Matrices is Cholesky (LDL or LU) decomposition. This is the way to invert large sparse matrices. My suggestion would be to implement this in your library. [https://en.wikipedia.org/wiki/Cholesky\_decomposition](https://en.wikipedia.org/wiki/Cholesky_decomposition)
(1) everybody has an opinion, why should you care? just look at it and make up your mind. if i was trying to be as fair as possible, i would say that anyone who says it is bloated just is not compatible with the language. every feature is there for a reason, in some places it surely is awkward and more complicated than it need be if you started from scratch. But where it most matters, c++ gives you the tools you need to write good software, even if you have to run around the block a few times to arrive there. this is a question of taste. Many people don't want to spend a year learning a language to only then find out that they like it. A newbie who looks at c++ will think it is bloated. All modern CPUs are incredibly bloated for the sole purpose of increasing efficiency. superscalar, speculation, cache. the bloat is enormous compared to the core purpose of a CPU. Yet, complexity will in the end give you a better performing CPU. Mastery of C++ will give you a faster program. Bloat is in the mind of the observer, not the language. (2) sure whenever speed matters, it is a good choice. Oftentimes another language could be used and c++ will be used because it is well-known. The difference between java and c++ is not that enormous. People use Java, because it is easier to learn, not because it is easier to use. When you have to learn c++, you can then just not learn Java. Many people like C++, because it has some tangible benefits and they will continue to use it. Whether it survives is mostly a question of marketing, not so much of language features. (3) pre C++11 is just an inferior language, the improvement is substantial. 
 * yes, but who cares you don't have to use everything * Java is nice but slow, i really don't like big java applications... everytime i open up eclipse i am reminded of that (and that's not even a performance hungry application). So i'd say for small apps or just simple guis java is the king - if you need performance not so much. And i will probably never understand how you can use javascript instead of C++? Did i miss something, how do you do that? When thinking about C++ replacements or alternatives the last thing that comes to mind is javascript. * i don't really care i use what i need and can and having more is always better * i think it doesn't really matter and is pretty much just over hyped. Just read a book get down the basics, no need to worry about being "modern" right away. The "modern" C++ will come on its own if you get more experience (googling answers on stack exchange) and you get deeper into the community and start to question how to do things right. But to be completely honest i think C++ has always changed a lot and it will keep changing so in my opinion it's just a waste of time trying to learn "modern" C++. Just learn C++ and try to keep up with new styles, programming patterns and new C++ features. If you wait for somebody to teach it to you you will always be behind. Imo the only way to do the "modern" thing is watching C++ talks and reading the reference. But first learn what a pointer is and how to write a simple function, "old" C++ is still very important and it helps you understand things. 
1) Yes, but so are all major programming languages. Python is always shown as an example of simplicity, yet I doubt many are aware how many pages Language Report + Standard library are there, plus the amount of changes between each major version. Languages either grow features to help developers, or let developers manually tackle them thus increasing the boilerplate they need to write. 2) C++ has become a niche language for high performance computing scenarios. Across mobile OSes and mainstream desktops OSes, Microsoft is the only vendor still shipping C++ GUI frameworks, everyone else uses C++ on the graphics engine, but exposes other languages on top. 3) C++ after C++11 became much more approachable to newbies, safer, rejuvenated to the point of being possible to write Python like code in straight C++. Note that many after C++11 features, are also kind of possible in pre 11, but most had tunnel vision for writing C with C++ compiler instead. 4) Bjarne's books, Tour of C++.
That's a strange requirement. An application/executable should want to load shared libraries it's linked against and ones it's tested against, not ones which some other, unrelated executable is loading. Still it's not impossible. You can load the file of the other executable with some library which can read the ELF header, search for the rpaths in there and deduce which shared libraries it would load when started.
This. I want to emphasize the tests as well. Tests not only ensure that the library works as intended, but also breaking changes are much easier to detect, if the tests are the first and most intensive consumer of the library. And from my point of view it's much easier to reach 100% test coverage for a library, because there's much less mocking and workarounds needed than testing an actual application.
1. Of course. It's just getting more bloated slower, which is a good thing. 2. Everything is in its respective niche field. Isn't "3D-printing preprocessing desktop product" a niche? C++ is doing fine in its plentiful niches. 3. The new bells and whistles are definitely more thought through than the old bells and whistles. Yet for me, the whole evolution of C++ is a showcase of how little the language itself matters for the programming. We did good, bad, and ugly code in old C++, and we do the whole range in the new one. Not that the whole evolution is completely futile, the language got better obviously, it's just the language as a tool is too insignificant to make a difference. 4. [https://godbolt.org/](https://godbolt.org/) is the best that happened to C++ education ever. 
Magnifique 
1) The functionality is massive indeed and I suppose there are only a few developers who have in depth knowledge and experience of all areas of the language. But I don't think it's a bad thing. I think most grown languages have the problem of being massive or bloated, if backwards compatibility is a concern. 2) I don't think C++ is only used for niche fields. It may be not so common for end user systems (like websites) or human interfaces, but that doesn't mean there aren't many fields of SW engineering, where C++ is in use and a top choice. my point of view is always take the right tool for the job. If C++ is the right tool for my problem, I don't care, how many people are using it. 3) C++11 provided a couple of tools and techniques to avoid or reduce common errors, especially in memory management. And in C++11 and later a lot of syntactic sugar was added to avoid writing lots of boilerplate code, which is boring and clutters the source code. If you have the possibility to start with or migrate to C++11 or later, do it! 4) I found CppCon talks very useful, the CppCoreGuidelines and lots of questions on stackoverflow.com
There is a member, length, but it is a function, not a field. [string](http://www.cplusplus.com/reference/string/basic_string/).
Here are a few suggestions: - Allow the user to supply an expected number of entries per column/row and use that to preallocate space in your storage vector - Remove the requirement of ordered input (it kills usability in [almost] all real world applications I can think of) (e.g. by sorting on every insert, inserting in correct order or ensuring ordering only prior to operations), implement `bool operator&lt;(const Element&amp;, const Element&amp;)` to help with this
1. Yes. I mean no. The standard library is woefully bare compared to other languages. I am delighted that it is expanding. As far as the language goes, you can still write fundamentally good code using only the basics. You don't \_need\_ all the extra topping in order to do good with the language. What has been added are ways to express those constructs concisely, at a higher level. You could write \`x0.destructive\_copy\_to(x1)\` if you wanted to eke out some extra performance ... or you could write yourself some language-specific move operations and get the same thing in more circumstances. 2. I believe so. There are a set of applications that are either a) large scale or b) small scale, and these are the ones for which power consumption is a key consideration. IMO, C++ offers an attractive abstraction:bare-metal programming ratio that is unparalleled. 3. If I were to go back, it would come with a significant price tag. 4. Youtube+Muse. There are an immense amount of conference talks, podcasts and that sort of thing that can help gain knowledge and ideas in bite-sized chunks, but this must all be tempered in the fire of actually coding. Keeping a muse project around to incrementally develop your best practices and ideas is key to the process, IMO.
Thank you @chillhelm! I will do some of them tonight. 
1) yes 2) yes but C++ never was for OS or drivers. C is. 3) stable vs experimental 4) don't. "modern" will be "old" in 3 years. I'll get downvoted hard.... 
Well that was a whole heap of nothing. While we wait for the real article, here is an actual implementation of that. https://www.reddit.com/r/cpp/comments/9ih7ze/eastltuple_vector_an_stlcompatible_data_container/
Usually sparse matrices are constructed from an array of triplets (i,j,v) where A[i,j] = v. You can use counting sort tricks to sort the indices when compressing to sparse csc or csr. That is the most user friendly way to construct a sparse matrix, and usually constructing the matrix takes less time then the stuff you are going to do with it afterwards.
Honestly, if you can make something as easy to use as Eigen that compiles quickly, even if it was much slower, I'd probably use it.
I'd also like the ability to add a row segment, or column segment, or even a block, at once.
Switch to [Julia](https://julialang.org/) ;)
People are so going to rely on this :(
I am not introducing the two language problem into any project I'm a part of. 
You probably already know this but take a look at Tim Davis’s book for worse matrix algebra. 
How does it compare to Eigen's implementation?
this would be great, though we should also an option to get a warning when this happens so that we can fix it (initialize the variable in the code)
1) Bloated: somehow. I measure that by the time it takes for beginners (including me) to learn stuff that is now considered obsolete, but that they still need to know. 2) You mean outside of: * Real time industrial process controls * Real time video processing * Embedded applications * Finance * A lot of deployed AI stuff (AI research is different) * Web browsers * Compilers ... Yeah sure, C++ is not used anywhere for new projects. /s For me it's the opposite: it feels like C#/Java/JavaScript are the languages for "niche" fields. Most of the new projects I interact with are written in modern C++, though more and more back-end stuff are written in Python. Also, keep in mind that a lot of "new projects" don't start from scratch either. 3) Pre-C++11: Established. Which can be both a quality and a defect. Post-C++11: I'd code only with that if I could. I would gladly throw away years of crusty old code. 4) Scott Meyers' Effective Modern C++ does an okay job for someone who already has a decent understanding of the subject. But for me the best way is still by reading/modifying other people's code, and understanding how it can be improved with modern techniques.
I would get rid of all guidelines that can be covered by warnings or linters like clang-tidy. Use CI to check those :)
COO is not the best choice of storage for some applications. You might want to consider using CSR or CSC as well.
Linters/CI can be used to enforce guidelines/coding style, but they are not substitute for guidelines. You can't just include clang-tidy into your master build and make it block development, not on large codebases anyway. You need to first define those guidelines to set those up correctly (clang-format, clang-tidy, CI, ...).
&gt;We could instead use -Wuninitialized! Indeed we could, but then we're forcing the programmer to provide semantics for something which doesn't actually have any (it's uninitialized!). It's then unclear whether \`int derp = 0;\` lends meaning to \`0\`, or whether it's just there to shut that warning up. So now the compiler will "provide semantics for something which doesn't actually have any". It's then unclear whether \`int derp;\` is ok and will be initialised later, or they just relied on clang and the code will blow up in your face when you compile it with something else. Awesome. The solution is actually simple: stop writing C and declare your variables exactly where you can initialise them with something sensible. &amp;#x200B;
Yes! Also get rid of all the guidelines about styling and use clang-format instead. It gets rid of all the formatting discussions (after the big discussion on how to configure clang-format;-). This also avoids bad blood when a co-worker rejected a patch that was a lot of work to write -- just because of some space missing here or there. Such nitpicks are much easier to accept from a robot than a human -- especially when that robot offers to clean up the mess for you, too:-)
Good idea: it should have been the default case since the beginning in C++. It would have solved many many bugs. Bad idea: it's not portable since the behavior rely on a compiler option which isn't standardized nor available on all compilers.
\^this
It's really time that this gets fix in the C++ standard, initialisation should be the default, uninitialized should be explicit, not the other way around.
Hey, I am currently trying out [https://github.com/uestla/Sparse-Matrix](https://github.com/uestla/Sparse-Matrix) with some openmp directives in my implementation of various solvers. I will try to integrate yours and see which one is faster for which cases. I have somewhat naive implementations of jacobi,GS, Conjugate Gradient and cholesky decomp. Its always nice to see alternative implementations to benchmark! Cheers.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a78cza/do_you_think_c_is_bloated_now/ec1ewis/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'd say that it's better to have "great principles" than strict guidelines. For me, these are mostly : - don't check at run-time what you can enforce in the type system (or more generally at compile time) - use RAII for anything more precise, I'm pretty convinced that you can find 100 examples where it helps, and 100 examples where it causes problems.
I suppose "worse" is a typo and supposed to be "sparse" :) Do you mean this series? https://www.youtube.com/watch?v=1dGRTOwBkQs
Yes to both. He is a great teacher. 
&gt; Bad idea: it's not portable since the behavior rely on a compiler option which isn't standardized nor available on all compilers. what goes in the standard should be things that are implemented by the compilers first
Except that gcc isn't the only C compiler on the planet, specially when we look beyond desktop computers.
The code (in essence) was reviewed, and they insist there is no problem because "every caller can be forced to do the right thing". 
I've written [these](https://florianjw.de/en/cpp_coding_standard.html) a while ago. A lot of it is still highly applicable, so maybe take a look to see what might be useful to you. One rule that I can wholeheartedly recommend that isn't there would be the use of [lizard](https://github.com/terryyin/lizard) to measure the complexity of your code and ban the use of anything with a [cyclomatic complexity](https://en.wikipedia.org/wiki/Cyclomatic_complexity) above 15¹. Usually it should be easy to stay below 10. This enforces simple functions that are much more easy to reason about, without telling you how to get there. Another one would be a restriction on the number of loops per functions. Try to use no more than one. (This is impractical as hard rule, but if you view it as more of a goal, it again leads to better code.) [1] Potentially with an exception for large (and simple!) switch-blocks.
Hmmm, looks like you check for something, but your throw message says something else. For example: if(this-&gt;cols() != mat.rows()) throw "For multiplication, rows and cols of first matrix must match cols and rows of second matrix, respectively!"; You say that both rows and cols should match, but is not the case. Also, this check looks wrong: if(this-&gt;m_rows != mat.cols() || this-&gt;m_cols != mat.rows()) throw "For addition, rows and cols must match for two matrices!"; Shouldn't you be checking `rows != rows` and `cols != cols`? Am I missing something?
What people have said already is great. If it we're up to me I would immediately say no inheritance, no virtual functions. No raw pointers or even raw smart pointers. No non trivial data transformations in classes. Keep the json virtualization or drawing separate. 
Are there specific considerations? I'm currently using CSR matrices where the main operation is summing the rows of the matrix (marginalizaiton). Would I be better off using another storage option?
I didn't check this too carefully, but it seems that you append data elements to your matrix and you don't keep it sorted so that the row, col indexes are in increasing order? I think this is essential for efficiency. Also, your equality requires that the data has been added to two matrices in the same order for them to be equal. Should this matter? I two matrices should be equal if all the elements in the data vector are the same regardless of the order.
I don't follow, you mean you cannot just clang-tidy in your master build and they you say you can?
There is one quick and easy way. You just gather everyone who has a say in one room, give them knifes, some amphetamines, and then turn off the lights for some 5-7 minutes. All the other ways are much more time consuming and ineffective. I've tried some before. The thing is, building guidelines is not a matter of engineering, but more of politics. Programming wise, all the rules or recommendations are either obvious or irrelevant. The former are more about an education. They propagate well by coding reviews and learning events. You don't really have to enforce them. They are good, they are helpful, you are already using them in your company. But the latter are about setting a convention. It's more about standardization than solving any specific problem. And the standardization always requires legitimacy. People don't follow the rules if they don't consider them legitimate. This means that the rule set should come from the team, all the team members should be involved in standardization at least technically, and all the efforts should be transparent all the way from "hey, why don't we make a guideline" to "here it is, now follow it". Yes, it goes for ages, and it collects clutter as it grows, and yes, there will be people who will still ignore some of the guidelines in the end. But it'll work. If you just enforce the guideline by authority, you'll have to enforce its usage every day after and no good ever came from that. Of course, the knife fight solves the legitimization problem much more elegantly. You either accept rules you don't like or die bleeding. Either way you wouldn't complain about it. It's a win-win!
Absolutely, and even simpler is to just pick one of the predefined clang-format styles. As you say, it doesn't matter too much as long as it's idiomatic and consistent.
Agree. Though these things is essentially a condensed version of the Effectice C++ books. So why do you need company specific guidelines anyway then? Why not just say, "Strongly consider doing as Scott Meyers says"?
Why is the underlying memory stored as to a pointer that points to a vector? Why not just a plain vector?
Hey I like you post. Especially about sticking to C++ naming conventions instead of creating your own dialect. But I don't understand why you prefer a blacklist approach rather than a whitelist approach (-Weverything) when it comes to warnings? Surely it's simpler and less error prone to disable warning categories you don't care about instead of constantly trying to maintain a comprehensive and ever growing list of warnings?
&gt; So why do you need company specific guidelines anyway then? I'd say that a lot of time, it's because managers have to provide a reason for them being employed :-)
In our coding guidelines there are only a few not covered by linters. I personally quite like the ones that specify when you should use which kind of argument type for functions/constructors. Can save some discussions at times: \- use by value for (integral) types that fit into the CPU registers (copying might be faster than dereferencing) \- for sink arguments use either unique\_ptr or by value and move \- non const references are by definition inout parameters and should be avoided if possible \- pointers are by definition optional/ could be null unless using gsl::not\_null or the like \- avoid shared\_ptr (especially non const), unless you have a good reason to use it \- avoid const unique\_ptr&amp;, rather use a pointer &amp;#x200B; I know I might get some hate for this, but we actually forbid generic lambdas (with auto arguments) in non generic contexts. The reason is simply that you don't get any IDE intellisense (or whatever you want to call it). So while it makes it easier/faster to write code it makes it harder to maintain / understand it for others and the typical read write ratio of code is \~ 90%read, 10% write.
I would say, why do you even need a company/project specific set of guidelines? Isn't it enough to pick a `clang-format` style, preferably as close as possible to one of the predefined ones, and then just point to the CppCoreGuidelines + The Effective C++ books?
I can't tell if you're trolling or serious. I wouldn't attempt to build anything substantial using C++ with these restrictions.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
CSR is of course the best if you access the matrix by rows, so you're fine. The most important reason I can think of to favor CSR over CSC is that it's quite easy to parallellize a CSR matrix-vector multiplication (y = A * x), while it's hard with CSC. With CSR you're basically doing independent inner products of each row of A. With CSC you are accumulating multiples of each column of A in y, and that runs into data races / requires atomic updates.
I disagree with this. Not all things can be checked automatically. Examples are naming conversations or an understandable use of auto
Most widely applicable warnings are covered by at least `-Wextra` whereas most that are not there are quite useless for general development. So instead of having a very long list disabling warnings that needs to be updated all the time I have a full list of useful stuff that I can still update should there ever be a useful new warning not already covered (which is very rare).
Sometimes there's a need for COO, in particular when dealing with hyper-sparse matrices. For a square matrix of size `n x n` CSC requires to store `n + 2 * nnz` (the column markers are `n` and the row indices + nonzeros are `nnz`). Whenever the matrix is hyper-sparse in the sense that `nnz &lt;&lt; n`, then it does not make sense to store the column markers as a dense vector, and storing triplets makes more sense. But almost always (in graphs, PDEs, etc) you have `nnz = O(n)`, so you want to use CSR or CSC to compress your data. 
Tnx for all the comments. Didn't expect this. The actual code can be found at: [https://github.com/rosbacke/delegate](https://github.com/rosbacke/delegate). There have been some updates to the readme file and added runtime support for free functions since the talk was given. As mentioned in the talk, this is not original but draws inspiration from include\_OS delegates and the article mentioned above. The main focus has been to allow one class (or file static) to construct a delegate with just the type knowledge to create a call signature. Later the one setting the actual callable entity (function, object etc) have the freedom to choose the means. A hard constraint have been to not do heap allocation to suit microcontroller work. This allows the delegate to handle low level callbacks such as interrupt handlers while the users have freedom to choose how to receive the call. It is an interesting idea to separate out zero state logic (member function/free function encapsulations) to one part and the state refering part (object to call member function on, functor/lambda referencing). I might investigate this in the future. For now the documentation clearly states that objects to call members on and lamdas needs to be maintained separately. I do not see a way around this without separate memory allocation. The code forbids reference to temporaries to reduce the risk of passing an on the fly lambda expression that goes out of scope. We have the same issue with objects to call member functions on. You could use the storage as a raw byte storage and store 'small enough' lambdas. This feels like an arbitrary limit so the choice was made to support full storage of stateless lambdas only (via function pointer conversion.). I am not familiar with the function\_view and light\_function so will check them out. I did see some light\_function in boost so I'm assuming that is the one. As the code is written today it should be platform independent and should work on systems where e.g. sizeof fknptr != sizeof void\*. &amp;#x200B;
good question, I am not sure. Maybe I should try with plain vectors and see how it performs. I am not an expert for sure.
What I'm saying is that doesn't scale on medium-big codebases (few millions LoC+) comprising multitude of subprojects. I'm not even sure that it scales in small projects.
True, though it’s a relatively non-trivial algorithm, sparse Cholesky. Tim Davis’s book is a classical reference, in particular chapter 4.
Naming conversations? Do you mean naming conventions? The naming style can absolutely be checked, and good variable names is something that code review needs to catch.
Other comment uses sarcasm to explain what I am getting at: &gt; ... (after the big discussion on how to configure clang-format;-).
I disagree, for the code I maintain the list of warnings we enable for GCC (which doesn't have -Weverything) is far longer than the list of warnings we disable for Clang (which has -Weverything). There are tons of useful warnings not enabled by -Wextra
Sure, but these sound like generic (and good) rules that are in the Effective C++ books. There isn't anything company specific that I can see. Why go through the process of duplicating work when you can just point to Scott Meyers and/or the CppCoreGuidelines?
&gt; (after the big discussion on how to configure clang-format;-). Damn humans, I can never tell when they are being sarcastic and when they are being serious on reddit. &gt; This also avoids bad blood when a co-worker rejected a patch that was a lot of work to write -- just because of some space missing here or there. Such nitpicks are much easier to accept from a robot than a human -- especially when that robot offers to clean up the mess for you, too:-) If the implication here is that there are no guidelines, nobody can blame me for commiting crap which happens to disable whole CI thing via annotation, right? [;-)](https://en.wikipedia.org/wiki/Poe%27s_law)
I've heard about something called 'Styx' or 'Sphynx' or something along those lines. I think this is what CMake uses, so it might be worth checking out. There's also readthedocs.io but I don't think I've ever seen it used for C++ projects. 
Sure but as far as clang-tidy goes it's easy. Start by enabling the no-brainers and then on a case by case basis you can start enabling more rules. Formatting is trickier as you need to agree on everything up front. That's why I think it makes sense to just pick one of the predefined styles and maybe tweak a few things (indent size for example).
&gt; If the implication here is that there are no guidelines, nobody can blame me for commiting crap which happens to disable whole CI thing via annotation, right? ;-) There is no such implication. People are really easy to hurt by criticizing something they invested a lot of work into. I have seen more than one co-worker that was convinced some other co-worker hated him, just because she had asked for styling issues to be fixed in a patch. People will jump to conclusions like: "It is very obvious that she is only pointing out these nits so that her patch can land first. Now I have to adapt everything to her changes!". Surprisingly enough many people do not mind a robot to point out the same issues: That is just a pretty stupid piece of software after all.
Hmm. Back in the bad ol' days of C, I probably wrote half a dozen doubly linked list libraries, nearly as many simple (usually not rebalancing) B tree libraries and one hash table library in various positions. The last job I worked that require plain old C to be used ended in 2005 and I've only had to do that sort of thing for interviews since then. Lately, I seem to be dealing with object serialization a good bit. I usually end up using boost's ptree library for that, with object constructors that just take a ptree and some way of converting the object back into a ptree. Then I can use Boost's code to read and write the ptrees to XML or JSON. Usually json. That has the added advantage that they're easy to squirt over the network if you ever need a rest service. I also find myself writing a cppunit custom test listener often enough that I've just put one [out on github](https://github.com/FlyingRhenquest/cppunit_contrib). I'd been writing my cppunit tests as one big monolithic test per library, so the listener times the individual tests and collects the test names. That way it can report the test status for each test at the end of the run, along with how long it took each test to run. Lately I've taken to writing one test executable per class and run them all with cmake, so it's not as useful. But I usually try to have several tests per class, so I still like it. The individual test timings are still pretty nice, too. My test runner seems to be reporting some failed tests as passed to Cmake, though, so I need to doublecheck my exit values in various cases.
Look at: * http://www.doxygen.org * http://www.sphinx-doc.org I've only used Doxygen so can't say how well suited Sphinx are for the documentation of a C++ codebase.
So you just argue your point once, and if they disagree with you one more time, fire them?
I'm absolutely serious, this is how I work after many years of experience. We can go through any or all of them if you have any questions.
I mean we spell this guidelines out, so the information is summarized and more easily available. Of course we also provide links to Scott Meyers and the CppCoreGuidelines so you can read upon the details. I simply mentioned this ones, because they are very easy to apply and not all of them can be covered by static analysis. 
Doxygen (is basically JavaDoc but for other languages, very common in C++) Sphinx (written in python, and common to use in that language and others. ) Standardese is another new one (work in progress) written by Jonathan Müller (foonathan) Has great promise. 
Doxygen is fine for most purposes, but you should also consider [standardese](https://github.com/foonathan/standardese)
Absolutely! We have indeed been looking into clang-format and clang-tidy. Integrated in the IDE, it's a great addition. However, we also have a use-whatever-IDE-you-prefer policy, so we need integrations to all IDE's. Our most used IDE's are Eclipse, Emacs, Qt Creator. But this, I think, is solvable. However, in general, people are good at complying to the format. &amp;#x200B;
- Given that you can't have a container of references in C++, how do you create a graph? - What do you mean by **raw** smart pointers? - How do you write an open set of polymorphic action without virtual functions? `std::variant` and `std::visit` are perfect to create a close set of polymorphic action, but you need inheritance for an open set. If you write applicative code, it's not an issue, but if you write a library, I think it's blocking.
You can always run them from the command line and, well, via CI ;)
You're right, that's why I meant *only* the things that can be checked automatically.
And you may use initially invoked lambda if needed ``` const auto myVar = [&amp;] { if (...) return 1; else return 0; }() ```
This I like. Principles that apply more general could be a better fit. Our main focus is perhaps not in the technical details (although this is also imporant), but making programmers write more modular and testable code. Most of our code is highly coupled, untestable, and singleton-based.. So this is a focus-area.
&gt; There is no such implication. Sarcasm. &gt; People are really easy to hurt by criticizing something they invested a lot of work into. Objective criticism should never hurt anyone and I have recently went trough two dozen commits to get a feature PR trough in one project, so I would know. If anything, it makes people write better code. &gt; People will jump to conclusions like: People are way too sensitive to this crap nowadays, assuming intent when there is none. Having rules helps to mitigate this. &gt; Surprisingly enough many people do not mind a robot to point out the same issues: That is just a pretty stupid piece of software after all. Sarcasm aside, I'm perfectly happy to see robots are enforcing the rules, but the original assertion here was replacing rules with robots. 
Thanks for sharing! These are all good guidelines. 
Oh sorry, I did misread your post
Haha! But what you say is true: the rules require legitimacy and should be anchored in the team. I think we will do something similar, but without the knives.
u/Stabbles already explained that - a sparse matrix multiplication with a dense vector is a very common operation since it's a basic block for iterative solvers. A prime example are Finite Elements models for solving PDEs since they tend to be quite sparse. You can perform this operation efficiently, parallelize across rows or vectorize it.
Sure, I never said that COO is not useful at all but it's not the best choice for many algorithms and domains. A good sparse matrix library should support multiple formats. For example, Eigen does support various storage formats.
We had some kind of style, which was more or less implicitly defined and used over the years. So we wrote a .clang-format file for that style, tweaked two or three things and agreed on that. Discussion was pretty short after everyone realized that it's pretty pointless to argue whether there should be a space between if and the parenthesis or not. Afterwards the .clang-format file was integrated in our tool chain and now it just works 
It's an alternative, yes. We would then need to focus on motivating people to looking into the references. This applies of course more generally to learning modern C++ as well. As we have moved to C++11/14 I've been doing sessions to teach about the new features. There's a big difference between those who actually start using the new features, and those who continue along the familiar C++98 path. I think continued sessions , workshops, and learning is key. I guess there's always a challenge to "cross the chasm" between early adopters and the rest.
We use clang-tidy and clang-format in our tool chain and then have a pretty short coding standard, which was loosely inspired by Qt's coding standard. Most important rule in the standard is "we write modern C++" and "don't write C".
doxygen. It just works and everybody knows how to use it. Recently we added some custom tags for requirements, so we get a matrix which classes/methods implement a requirement and which tests test it.
We have a support library, which adds syntactic sugar to string operations, file I/O, binary operations, time functions and a modern C++ wrapper over the super ugly WINAPI (mostly for device manager tasks). Something like that I'd like to see.
And you can use breathe to use autogenerated doxygen Sphinx. It works quite well together and the output looks nice.
I like the core guidelines (and we refer to them in our company's guidelines). As others have suggested, getting tool-enforced rules is best (especially for style, but for content too). Our company guidelines came out just before the core guidelines did and they pretty much were 20-30 of what the core guidelines were. The way we came up with that was a combination of looking at other guidelines (and yes, that means reviewing the whole thing) and knowing which ones are most necessary to your company's process/style/needs. At the time, we had a focus on how to use C++11 since we had just upgraded our compilers at that time and wanted to guide everyone on how to be 'modern'. And we picked a limited set because we knew that no one would read 100+ rules (but again, if those are tool enforced with clear messages/fixes, 100+ rules is great).
&gt; you can use breathe to use autogenerated doxygen Sphinx I know some of those words!
github.com/foonathan/standardese was already mentioned, and while I haven't done anything there in some time, I plan on "finishing" it during the holidays. For now check out the develop branch and file any issues/feature requests.
I was considering writing a C++ documentation system myself, but my question is: what do the current tools lack?
I tried proposing an attribute to mark things as uninitialized (https://wg21.link/p0632r0) but the committee wanted a more general solution that allows uninitialized resize of vector as well.
Care to paste both sets somewhere?
Is the main work on this parsing all the complexities of C++?
Have Windows developers forgotten about this old override mechanism for fighting against DLL hell? \`\`\` &lt;AppName&gt;.exe.local \`\`\` Just create a zero length file having the same name as the main \`.exe\` executable application and then add a \`.local\` file extent. When that file exist then the application will look first in the local folder (where the \`.exe\` resides) when searching for DLLs to load. [https://stackoverflow.com/questions/3809172/dot-local-file-to-deal-with-dll-hell-issues](https://stackoverflow.com/questions/3809172/dot-local-file-to-deal-with-dll-hell-issues) [https://filext.com/file-extension/LOCAL](https://filext.com/file-extension/LOCAL) &amp;#x200B;
Problem with that is that if you use a header which has that in, it would interfere with the whole project. You'd need modules at the least to contain that, or only have it in a implementation files only. Things like that would be able to be controlled by compiler flags, and it wouldn't surprise me If some compilers have that functionality. 
I'm curious: what are these limitations due to, exactly? I.e. why can't `QList` be used in this case?
"Pragma" by definition are non-standard, so that's out of the way xD But I'm sure it's been discussed in the past, but it's not really a priority. There are linters like cpplint and clang-tidy that let you do this as a separate process, so I don't think there's a great demand for it.
&gt; trough two dozen commits through Please fix and resubmit.
Yes this was my experience as well. Changing the discussion to be about how to configure a tool makes it simpler as well compared to writing a document on how to format. But what did you decide on the space between the `if` and the parenthesis though? I agree it's pointless to argue but you still need to make a decision
That's outsourced into https://github.com/foonathan/cppast Which itself outsourced most of it to libclang.
Most of the things the dev team agreed together, sometimes only on "most of the codebase is already formatted that way". Very few issues were decided by the architect / project manager, because no consensus could be reached.
&gt;Problem with that is that if you use a header which has that in, it would interfere with the whole project. That's why I suggested for this to be some kind of a pragma, because pragmas can sometimes respect specifically file scope (i.e. #pragma once).
Letting unit-tests work out of the box (We are using catch2 + ctest) is definetively very important. I've yet to see a student that writes unit tests if they aren't fully integrated into the workflow. &amp;#x200B;
Nice work!
We just adhere to clang-tidy and clang-format. And anything that's not covered by that, and is not obviously defined by some other guideline can be discussed when it's encountered.
In fact, you can already do this with GCC and Clang: #pragma GCC diagnostic error “-Wold-style-cast” You’d likely want to save and restore the diagnostics settings using push and pop (see [docs](https://gcc.gnu.org/onlinedocs/gcc/Diagnostic-Pragmas.html) for more). That said, you’d be better served doing this for your whole project using the command line: -Werror=old-style-cast
I don't know it well enough to explain clearly, so I'll direct you to qtbug 8552 where someone complais about not being able to delay load Qt. This is where I learned most of what I know
Of the top of my head GCC has stuff like `-Wctor-dtor-privacy`, `-Wstrict-null-sentinel`, `-Wold-style-cast`, `-Woverloaded-virtual`, `-Wswitch-enum`, `-Wunused-parameter`, `-Wunknown-pragmas`, `-Wsuggest-override`, `-Wduplicated-branches`, `-Wduplicated-cond`, `-Wfloat-equal`, `-Wshadow`, `-Wcast-align`, `-Wconversion`, `-Wzero-as-null-pointer-constant`, `-Wmissing-prototypes`, `-Wmissing-declarations`. 
Yes, but this is gcc specific. I was wondering why not standardize some of this. There are clearly C++ features that most people want to avoid.
How do you create a graph without raw pointers for ownership? You could still use pointers, but I wouldn't. I would use indices into an array of elements so that I can control the memory layout of the elements. I would do the same thing for a linked list. Not only should this be faster because it can avoid pointer chasing and possibly lots of small heap allocations, but it could be simpler and more transparent as well. In addition, you could make the graph (or linked list) exist in a single span of memory so that it is always serialized. Thus you have elegance and speed combined. &gt; How do you write an open set of polymorphic action without virtual functions? std::variant and std::visit are perfect to create a close set of polymorphic action, but you need inheritance for an open set. If you write applicative code, it's not an issue, but if you write a library, I think it's blocking. I would use a switch case and avoid any mess unless I was trying to bridge with an existing library. 
\#pragma once works because it's only affecting the preprocessor's behaviour - after the preprocessor has run the cpp file and all the headers it includes are collapsed into a single logical file with no preprocessor directives (like pragma) left... you'd need to use something else with explicit scoping that would survive to *after* the preprocessor. Sounds a bit like `extern "C" { ... }` honestly.
Watch [this presentation] to learn about why your API should be deep and small. Follow the principle of separation of concerns. Don't add in stuff that does not necessarily belong in there. I like to write libraries in KISS (Keep It Simple and Stupid) way. Also, the phrase "perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away" applies to library APIs as well. Also read [this about how non-member functions increase encapsulation](http://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197). And [here](https://stackoverflow.com/questions/1692084/how-non-member-functions-improve-encapsulation) is a StackOverflow posting about that article.
Doxygen gets confused by what I call "link-time polymorphism": Many files containing alternative implementations of classes named the same, in the same namespace, but never being included into the same translation unit or library at the same time (controlled by the build system). The pattern is not uncommon in embedded or some legacy settings. 
Sorry brain fart ! Should have been more explicit. I was thinking more about the lib being in a system-wide /lib or /usr/lib or /opt/lib or a random location that an app chose. App A - Installed via package manager or a manual install - installs the lib somewhere in the system App B - The app we're developing, wants to use the lib that App A uses. 
This is a good idea. But we already have a workaround for that. We can disables things with compiler flags per each translation unit. It can even be done in a more or less cross-platform manner with CMake if you keep your old code distinctly apart from the new one. For instance, we have special categories for some of our DLLs (SOs) that relax their set of warning turned errors. 
normal random() function
I have a similar task at my current job. I do share the philosophy of encouraging quality code while still allowing everyone their own freedom. But I am not necessarily trying to teach or train with this specific coding standard document, just be a reference to which practices we require, encourage, forbid etc. My main motivation is wanting consistency in terms of which code passes and which code doesn't. Not necessarily teaching/demonstrating good code, but to have a reference for reviewers to consult if they wonder "should I hold up a pull request for X?" and for developers to know "is using X acceptable?" in both cases basic knowledge of X is assumed. I also wanted the document to be short and tailored to our company context. In the end what I ended up with was basically a list of which cpp core guidelines we enforce and to what extent. One disclaimer: this was a brand new codebase so there was a lot of stuff I didn't have to worry about (e.g. dealing with legacy code/tools) and therefore adopting the core guidelines entirely was easier for me than it may be for others. That said, my first piece of advice is be on the same page about what the guide is for. How do you see it being used? Which questions do you expect it to answer? In my process I tried not to leave out any guidelines, but condense and summarize. For example what is several pages in the core guidelines i can just say "RAII everything" "pointers must point to a single object". Here are some things I used to my advantage while summarizing: the core guidelines can be read one section at a time without necessarily having read any other sections, so some information is repeated to make sections complete on their own while my document is meant to be read all at once. The core guidelines also entertain a much wider range of domains and scenarios than I needed to in a document for just one company. Also in some cases I also felt that following one core guideline rule strictly means you don't have to worry about a different rule. Besides summarizing, some core guidelines may require extra emphasis or you may even need extra rules. Maybe some of the core guidelines that are "prefer X" can be made required if that makes sense for your situation. As an easy example: the core guidelines say prefer Ensures/Expects but I made it required. Or maybe some guidelines you can't follow because of whatever external factors. I didn't really consult any other company/codebase standard. I did look at probably 5 or so but in the end I decided what works somewhere else may not be optimal for us since every company has it's own context. That's a big reason why I was so thankful for the core guidelines. The core guidelines do not rely on any specific company context just guidelines to help all c++ coders code better. Summary of my advice: ensure you have a clear specific goal for your standard, as that will likely heavily influence your decisions and maybe even simplify them. Think of each core guideline in the context of your own codebase. Can you adopt this guideline? Can this guideline be simplified? Are there exceptions to this guideline in your codebase? Consider summarizing the core guidelines rather than subsetting, but in come cases you may have to modify rules based on your company situation. It helped me to remember that the core guidelines are ideals, to me that means follow them all unless there is a real hard reason you can't. To answer some of your questions directly &gt; Should one select the 20-30 top rules from cpp core guidelines? Then how, does one select a decent subset..? Ideally I would try to summarize the entirety of the guidelines. Only subset if there is a hard reason like in some places of your code youre forced to violate rules. &gt;Should one ditch rules altogether, and focus on continuous training? Personally I think only you and your group/others at your company know the answer to that. In my case I felt that trying to establish a consistent bar for code quality was worth it, but I'm not going to pretend that's the best/only way. In fact for anyone that has tried the "no standard" approach I would love to hear your thoughts. Hopefully this was helpful. If possible I would be happy to hear how this experience plays out for you (:
I recently learned about an experiment someone did to implement `pragma jumbo` in LLVM: [https://lists.llvm.org/pipermail/cfe-dev/2018-April/057579.html](https://lists.llvm.org/pipermail/cfe-dev/2018-April/057579.html) ...and I think it was particularly interesting that they were able to implement as an LLVM plugin. That said, getting new pragmas actually accepted to the mainline compiler is probably pretty difficult.
No one ever even talked about them when I was in school, back in the late '80's. I don't think they'd been invented then heh heh. Designing testable libraries with coupling loose enough to test individual components is something else that has to be learned.
Doxygen is quite dated and not suited to modern c++. In our codebase, it commonly thinks decltype is a function that must be documented, or insists that deleted functions be documented. 
For clang-tidy it is particularly useful to use something like codechecker on the CI. This allows you to mark existing issues when you turn it on, and to mark false positives on the server.
It reminds me of all the subtleties around defaulted constructors and assignment operators. It is even a bit funny that Herb Sutter is the lead on the spaceship operator and on meta-classes, which are meant to offer a more general solution to default behavior for classes.
At syntax level you can restrict the usage with clang-query: https://gist.github.com/24b8d6ec78236b17674b548595984315
Have you tried the one with alligators, people tell me it solves this in about 4 minutes, also you can post it online for monetization.
It's self documenting 
That sounds like a great strategy. I have a messy code that landed on my desk that I will subject your product to. See if it can make more sense of it than Doxygen.
&gt;sparse matrices are constructed from an array of triplets No. They are generated from code that generates a stream of triplets. I really have a hard time imagining an application that spits out a random stream of (i,j,v) triplets. It is much more common that the appication has a loop over i, and an inner loop that generates (j,v). Which is code that maps closely to compressed row storage.
I just recently had to do the same for a globally distributed team newly pulled together. First i started by picking a base template from style guides that are automatically supported by clang-format - LLVM , Google ,Chromium Mozilla WebKit and then built on from there, with our own overrides and adjustments. Then made CI check at least clang-format consistency on every build, PRs don't get merged without it. Also, having other easily available code scanner tools like https://lgtm.com/ and codacy which are auto-checked for PRs. This already goes a long way. Further details can be sort of resolved by development lead and code reviews as you go along. 
Entirely correct. Sparse structures are hell on your caches as is, no need to increase the bandwidth requirements, and probably decrease cacheline usage, by using COO.
Makes a lot more sense to just use a static analyzer imo. Seems strange to standardize ways to remove standardized language features.
This leads to dialects and splits the language. We'd rather not do that.
The role of the committee is to add new features and deprecate old ones, not mandate minor compiled features. It’s a long process to standardize anything, and I think most would agree this feature is too minor to be worth the effort. An appropriate proposal would be one that removes old style casts entirely, but I wouldn’t suggest that, since it would break lots of code for little benefit as well as making interoperability with C headers practically impossible. The fact that this is GCC (and Clang) specific is not a big issue. I believe MSVC has a similar warning, and I know they have similar pragma operations. Any decently sized open source project is likely running a CI pipeline that uses GCC as one of their compilers, so they can just add these flags in, which will fail any pull request that doesn’t adhere to that standard. Private code bases can also turn on whatever flags they want. I agree that I avoid some features in my code, but I have never wanted to use a pragma to enforce it. The idiomatic C++ way to disable features is with compiler flags (that are managed by the build system).
Awesome, thanks. It's hard for someone new to writing libraries how to identify a _good_ one.
Finite elements assembly comes to mind where the loop is over the mesh elements (e.g. triangles or tetrahedrons). The loop is usually not over the nodes/unknowns, which would be the scenario you describe.
Definitely going to watch this after my exam! Thanks
what do you mean by "normal"
You can add clang-format as a git hook. And it's supported by pretty much all major IDEs.
Something conceptually similar to nullptr? `uninitialized&lt;t&gt;`?
But there already dialects in C++, each company makes their own coding-style, the committee tries to steer people away from some features (i.e. typedef -&gt; using). Won't a few standardized dialects still be better than a case where everybody rolls his own?
u/jtooker mentioned the [core guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md), a community effort led by Bjarne and Herb. Also check out Herb and Andrei's book [C++ coding standards](http://www.gotw.ca/publications/c++cs.htm). The above are examples of How To Do It Right. They're not perfect either of them but reasonably good. For an example of How To Do It Near As Wrong As Possible, check out the [Google style guide](https://google.github.io/styleguide/cppguide.html). 
r/cpp is for higher-level language discussion (standards etc). For practical programming help in C++, you're probably better suited asking at r/cpp_questions (especially considering this post is likely to be closed as off-topic). In aid of addressing your question though, I have to say that your question doesn't really include enough detail. What is \`Boid::BoidData\`? What is \`Vec3\`, a standard 3-dimensional vector? If so, did you roll it yourself, or is it from a library? Does it have math operators overloaded? etc...
Yes, they're after something like that.
Static analysis tools can help with this. We're using reshaper with clang tidy and core guideline checks. Pretty sure they have the c-style casts covered. 
Pro-tip: 1. Add a step to the CI which runs clang-format and MUST produce an empty patch (or fail). 2. Add clang-format as a pre-commit hook. The latter makes things easy, the former ensures that even if somebody bypassed the hook, it's not going to mess up the format.
In many case you would process boundary conditions separately.
Separate your rules into Advisory and Mandatory. Add rationales for both of them explaining why they are necessary. Advisory rules should be followed whenever is possible. Mandatory rules must be followed all the time, unless an agreement of all senior developers allow a one time exception for an specific portion of code.
[https://google.github.io/styleguide/cppguide.html](https://google.github.io/styleguide/cppguide.html) &amp;#x200B; I've always liked the Google C++ style guide. It's fairly complete and pragmatic. Not perfect, but none is.
In my experience code review is very useful for this, it lets the early adopters teach the rest organically
&gt; I would use indices into an array of elements So basically a pointer ;) &gt; I can control the memory layout of the elements However this part is really good. &gt; I mean treating smart pointers as values. Interesting point I view. I think I fully agree. &gt; I would use an enum and a switch case and avoid any mess unless I was trying to bridge with an existing library. However, I strongly disagree with this point. `switch` introduce a lot of coupling. And this is still a closed set of behavior.
+1 it's the way to go
If you have a custom `operator&lt;` the compiler will choose your overload (assuming it is a viable candidate). The compiler rewritten expression is only chosen if there is no other better match during overload resolution.
&gt; So basically a non-owning pointer ;) There isn't much difference fundamentally, and I'm sure there are many instances where non owning pointers work fine, however if you store pointers you have to recalculate them for any relocation of that memory. &gt; However, I strongly disagree with this point. switch introduce a lot of coupling. And this is still a closed set of behavior. I guess it depends on what the goal is, but instead of polymorphism I tend to use some combination of switch, lambdas and/or templates. Polymorphism allows operation on data structures that are made of different types for every element, which I essentially never find to be necessary. 
 &gt;\- non const references are by definition inout parameters and should be avoided if possible What do you use for multiple return arguments?
It's worthy to note that in the paper [`&lt;=&gt; != ==`](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1185r0.html) you _do_ get the `operator==` generated for you if you default the `operator&lt;=&gt;`.
Example of Sphinx with Doxygen and Breathe here: http://fmtlib.net/. Looks pretty damn good.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Isn't that my first bullet?
&gt; (You’ll need to enable concepts on most compilers. On gcc you must use the compiler flag ‘-fconcepts’) How would someone enable this from the IDE's point of view? Is it possible to use Concepts in Xcode or Visual Studio? I don't know anything about compiler options.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; There isn't much difference fundamentally, and I'm sure there are many instances where non owning pointers work fine, however if you store pointers you have to recalculate them for any relocation of that memory. That's totally right. I forgot that you can relocates the base array and not invalidate indices. &gt; but instead of polymorphism I tend to use some combination of switch, lambdas and/or templates That's static polymorphism ;) I agree that dynamic polymorphism is totally over-used, but sometime you still need to use it.
The fix for people like that, that are overly sensitive, is to take them out to the back of the building and beat the living hell out of them. Their emotional problems will disappear after that. 
Not OP but structs or tuples are the suggested pattern.
pragma once isn't even standard C++. This is something that we might get post-modules since the scoping will be easier to reason about,
I'd Gruss something like `get_random_number&lt;int&gt;(-10,5)` that doesn't require me to first get (and maybe initialize) a random number engine and then to instantiate and apply a distribution just to get a random number.
With guidelines if they are not strict then what is the point? Seriously guidelines are useless if not enforced. The trick is to keep the number of guidelines rational so you don’t trump creativity or productivity. Those that do get adopted should be well enforced. 
Verilog does it, people “just” have to tenable the flag at the end of the file
Interesting point! When it comes to guidelines there really needs to be a process for documenting and approving any deviations from the guidelines. This especially for things that are there to address bugs, firmware or hardware issues, that can change with new versions. It comes down to the fact that sooner or later you will need to do something the guidelines do not approve of to get a project to move forward. Such deviations should be minimalist and few in quantity though. 
Honestly a set of guidelines would not keep a manager employed. 
Isn't that just adding more permutations into the mix? 
Might also consider calling it Snapshot model, or something like that. Is the Flip part an implementation detail? Is the pattern the implementation technique or the use, or both? See also `std::snapshot_ptr` (coming soon to a C++ near you). The atomic_uint version has a bug, I think. Even though `current` is atomic, the read of `measures[]` is not protected. So a reader who is doing (via `GetLastMeasure()`) return measures[current]; Let's say they have read `current` as `0`, but haven't read `measures` yet Meanwhile the writer is writing to `measures[1]`. ... Another timer fires... Now the writer is writing to `measures[0]`. ... Now the reader finishes reading `measures[0]` - at the same time as writer is writing to it. :-(
I was told about old cmake commands on the don't list and to respond to warnings the same as I would with errors. 
If you mean a beginner in the since that I never written programs with graphics before then yes. I am doing research and looking for a good library. 
&gt; Problem with that is that if you use a header which has that in, it would interfere with the whole project. There's a reason that `-Wsystem-headers` isn't enabled by default.
So it is! My apologies.
For my product I ended up just creating my own, and I'll likely use the same for the code itself ultimately. It's written in XML and I have a little utility that reads the XML and spots out HTML. I have a little typescript that the spit out HTML invokes. It works pretty nicely and it allows for display format changes across the board, and it works exactly how I want it to work. XML allows for a strongly structured format and the parser does a lot of the work for you. It's not the most natural way to write, but you get used to it pretty quickly. I have macros in my editor to spit out the common tags and end tags. I don't think it's a good thing to put the docs in the code itself. I think it usually either ends up being trivial and hence mostly useless, or the code will be lost in a forest of documentation if you have as much as you probably should. &amp;#x200B;
&gt;Given that you can't have a container of references in C++, how do you create a graph? I might be a bit confused, but you can certainly have a container of references by use of `std::reference_wrapper&lt;T&gt;`. For example, at first glance I would implement such a structure with a pool (e.g., `std::vector&lt;T&gt;`) of owning pointers, `std::unique_ptr&lt;T&gt;` for my allocated nodes and as long as lifetime is guaranteed, I can have collections of `std::reference_wrapper&lt;T&gt;` no problem. Perhaps my approach is too naive though. &amp;#x200B;
Some things I've come to believe over decades of creating general purpose object frameworks... 1. It's easy, when your world revolves around the creation of a library, to elaborate it ad infinitum. You may feel pressure to keep it moving forward and can loose sight of the purpose of it, which is to be used, not to be written. This can also sometimes (IMO) lead to "abstraction for abstraction's sake", which I sometimes think the standard C++ libraries may suffer from a bit. 2. Eat your own dogfood by using it to create something realistic in its own right. This is both good testing and provides you with a good overview of how well its working as a practical tool. 3. Assume you will not get it right up front, and hence will have to continue to mutate it fairly rapidly for some time, and plan for that. That's a hard one. That's like saying, plan on not dying today, but it's important. If it's for public use, this is like remodelling an apartment building while people are living in it. If you aren't careful, you will end up drowning in 'evolutionary baggage' that you can't get rid of without breaking people. 4. One way to deal with #4 is to have internal implementation classes and public classes that work in terms of those internal implementations. You can create new public classes that work differently, while keeping the old ones alive, and not have lots of duplicate effort. It also has the benefit of significantly reducing compile times in some languages, because no data members are in the public interfaces, or very few. 5. Don't get launch fever. It's easy to start hacking stuff when you are close to a release and you just want to get it out, and doing those last few things really correctly are standing in your way. You'll almost always regret it. Get it right to start with. 6. If it's for public use, then documentation will be just as big a job as coding, or dang close to it. So plan for that up front and how you are going to do it. And, remember that, once you've written up all those docs, some changes that may seem reasonable in the code may have significant ramifications for the docs, requiring time consuming swizzling that can introduce inaccuracies. 7. If there are videos, they can be VERY time consuming to make and fairly small code changes can make them out of date easily and require re-doing them. 8. Strictly work out the issues of version up front. How you are going to do versions and how are uses of the library going to use those version numbers to appropriately accessing functionality. And how are these going to fit into your build process. Anyhoo, there are many more but these are some important ones.
One reason why this would be a bad idea is the additional burden it would place on compiler vendors. Most of the major compilers already have options like this, but for smaller compiler vendors, implementing standard C++ is a huge job already, without making it even more complicated by mandating support for a whole bunch of language variants.
The committee as a whole has shown fairly broad resistance against anything that reeks of standardizing subsets (“dialects”) of the language. There is one old exception to that which is “freestanding” vs. “hosted”, but that distinction is also being reconsidered. In any case, I don’t see anything like this feature gaining traction in the committee in the foreseeable future. 
It didn't really feel clear when I was writing it. No matter which way you explain it, there is a special case - either = default is special, or write-your-own-&lt;=&gt; is special. Which is sometimes enough for people to vote against a feature - C++ has too many special cases.
I think that implementing this is negligible in comparison with most other features that are constantly proposed and added to the standard. Maybe I'm wrong though, while I do have some experience with writing compilers, I never implemented a C++ compiler.
Every IDE has compiler and linker flags options burried somewhere in its tons and tons of menu.
It still doesn't output an "array of triples" as the original statement was. Also, it doesn't even output a random stream of triplets. Presumably you know the global structure of your problem, so each element integration would either create a new row element or additively update an existing one. I'm greatly in favour of the approach advocated in teh PETSc library that requires (or at encourages) you to first count how many nonzeros per row there are, use that to allocate enough storage, then actually create the matrix.
Not entirely sure if I understand why you are so concerned about it being a stream. If you're worried about memory, note that the grid itself has a huge footprint already. If speed is a concern, what I'm suggesting is a linear time method to construct the matrix; (How do you do know in constant time what entries to modify in the matrix? How would you apply boundary conditions and constraints easily?). Also note that deal.II implements FEM like I sketched above and PETSc is in fact one of its dependencies.
&gt;Yes! Also get rid of all the guidelines about styling and use clang-format instead. It gets rid of all the formatting discussions (after the big discussion on how to configure clang-format;-). &gt; &gt;This also avoids bad blood when a co-worker rejected a patch that was a lot of work to write -- just because of some space missing here or there. Such nitpicks are much easier to accept from a robot than a human -- especially when that robot offers to clean up the mess for you, too:-) Yep. Auto formatting code also teaches people proper coding style for your organization because people will instinctively match code styles. Way less annoying than rejecting people over a formatting issue. 
Maybe I am missing something, but I find this argument very silly. Instead of standardizing 200 fine-tuning knobs, we could do something similar to Rust epochs. Every major release of the language, standardize a safe subset. Allow usage of "unsafe" functionality in clearly marked scopes. Do this on a per-module basis. E.g. module foo; version "c++2a"; int main() { float f = true; // ERROR: Implicit conversion from `bool` to `float` is // forbidden in C++2a mode. Use `unsafe` to override. unsafe float f = true; // OK, but clearly marked. } There would be no dialects. It's a linear progression. If we don't do this, we'll end up with more and more ways of doing the same thing and more and more pitfalls every release of the language. We are creating more dialects by **not** doing this! 
`int i;` should not compile. `int i = void;` or whatever other keyword we choose to mean "uninitialized" should. We cannot change this until the committee understands that having something like Rust epochs won't fragment the language and would actually allow us to change language rules.
well it depends on what you want to build... commonly types are: 1. A library that is implemented in various language that has a C interface. 2. A library this is C++ with C++ interface 3. A library this is a header only C++ library whatever you do you will want to have a build system that can run unit tests, and output the headers and compiled library. specifics are hard with libraries, because they are different for different arch's and if you are doing a dynamic or static library...
This is going in the notepad! Thanks.
Have you experimented with Concepts?
In an organization I am working with, two different indentation styles have arisen. For a while, I flirted with the idea of automatically applying formatting rules to all of the code to achieve consistency. I even started working on this (reformatting a source file whenever I made changes in it), but I was dismayed by how this destroyed the line-by-line version control history. When dealing with an old code base, I find the line-by-line history of "git blame" or "svn blame" invaluable. At this point, I've just decided to let my editor auto-detect the indentation settings and leave them the way they are in each file. It's not great, but I value the file history more than I value stylistic consistency.
Not really and if I did, I wouldn't know anything about IDEs, because I'm a vim user.
I think the point is that this is exponential. Every c++ feature targeted must now be supported with or without all the others enabled. That’s O(n^n) !
Not even C - C89. Every version afterwards allows for definition of variables where used.
Such a verbose construct, though. I prefer the GCC-extension way - `const auto myVar = ({ if (...) 1; else 0; })`°
The tooling can tell you when you do this, clang-tidy. A c-sytle cast can be ok as long as it is the equivalent of a static_cast.... but how do you know by just looking quickly. So clang-tidy that code 
If you're lucky enough to be using C++17, you can also use structured bindings to extract data from tuples via: Auto&amp;&amp;[varA, varB, varC, etc] = getMultipleReturnValues();
I personally abhor boolean parameters in function signatures unless they are alone and they match the function adjective. SetVisible(true); ✔️ Render(false); 😕🤔😠
Do you allow generic lambdas that are just used for scoping? If a function would get long and has many unrelated operations but making functions for all those operations would be not useful because they'd be only called once, it's convenient to make a nameless lambda invoked right away. Prevents mistakes and shows what variables you need for this part of the processing clearly.
I am so glad you found the man made out of straw you where seeking.
Just use the normal person way const auto myVar = ... ? 1 : 0; 
Congratulations on entirely missing the point.
Don't these dialects already essentially exist, through code that requires different compiler flags to compile though? Surely it would be easier to actually specify the required functionality in the source file alongside the actual code, rather than in external documentation ("use these flags to compile file.cpp")?
Does it really count as outsourcing if both are your own babies?
You're the one who turned it into a fireable offence, not me. And you're the one who hinged it on "it was reviewed, but they insisted". How is that a strawman when it comes from your own words?
&gt;I'm teaching c++ at a university to electrical engineers &gt;I try to stay up to date with the latest standards **Thank you** Honestly, this will put your students way ahead of other engineers and even computer science folks just by having experience with the more recent language features. --- I'm assuming you already have some kind of UART wrapper to abstract out the various devices they are using? While not a library feature, per se, having a `std::vector` that uses a stack-based allocator will help folks stay away from raw arrays and allow a bit more flexibility than `std::array`.
clang-format has a python script clang-format-diff.py that is just for the diff's. So reformatting only the new stuff when it is touched.
&gt; Microsoft Crypto API ?
https://en.wikipedia.org/wiki/Microsoft_CryptoAPI never heard of it 
I think C++ has long passed this point.
hear hear!!!!
Does the body of the post refer to any part of the Microsoft Crypto API? 
Well technically it's the New Generation variant of it.
I like some of the rest but bassinet your coding standard on intellisense is lame
This is a really nice introduction, thanks. The power of concepts is not just a string of \`requires foo &amp;&amp; bar &amp;&amp; baz\`, but the definition of a new concept. I'd love to see a blog post on that as well.
I see two options for that: * Reformat the whole code base in one go and then live with one huge reformatting patch in the history. * Use a script that will apply clang-format on changed lines only. There are some out there. I personally am fine with the latter: That adds a bit more inconsistemcy (a third style while the other two tested out of the code base), but I do not mind that part... I want that bot mainly to avoid having to discuss details of coding styles in each and every patch. Visual consistency is just an added benefit.
There are other similar generators as well that look increndible beautiful, [m.css](https://github.com/mosra/m.css) for instance which converts the Doxygen xml output to html. See [https://naios.github.io/continuable/ ](https://naios.github.io/continuable/) for an example
I believe C++ requires that true is 1, but I've used languages where true is -1.
We don't need the standards committee to embrace epochs for something like this. We just need `= void` to be legal syntax (or a standard attribute or whatever), and then you'd opt in to requiring that with `-Werror=undefined`.
That's very similar to the issue where some people put `using namespace xyz;` in header files. Compilers can emit warnings for this kind of code (-Wheader-hygiene).
C++ requires that true _convert_ to 1. It doesn't require that the raw memory representation of true is 1, which is what is required here. It's like 0 and nullptr: literal 0 converts to nullptr, but there can and have been platforms where the raw representation of a null pointer was not 0.
The coding standards by Herb and Andrei looks quite good! Thanks!
Thanks for sharing your experience! Like you mention, it will be important to set a clear goal for the guidelines, as every company lives in different contexts with different history and future plans. We have many older programmers, highly skilled in their domain, but used to the old ways, and not the quickest to adopt new methods. For us, I think we need an iterative approach, starting with the most pressing issues. I would say our main issue is that coders are used to coding the same way the legacy code is built, which is a highly coupled, singleton-based pattern. Then, the second issue is to use modern C++. After all the comments so far, I'm am therefore leaning towards adding two sections in our standard: 1. A set of principles, to create modular, testable code. This should be the main focus of enforcement. 2. Reference to a set of guidelines, such as cpp core guidelines, with a recommendation to follow the guidelines. No direct enforcement, but with focus on training staff on modern C++. When we reach a decent level of modern C++ skill, we can consider enforcing the most important guidelines. I will work over some alternatives to present to the team. I'll update the thread when we've found our approach!
cppast is a generic library, so the "main work on [standardese]" IS outsourced and libclang is not his own ;)
Thanks for sharing! I agree that using tool-enforced rules is probably the better way to go. That 100+ rules is something no one would read was our concern also. It might be a solution for us to summarize the guidelines in a short format, focusing on the main parts, but still referencing the cpp core guidelines.
Agreed. Simple, but effective
I don't see why they couldn't wrap the whole file with a `language something something {... Contents of the file ...}` if they see the #language pragma directive or whatever. It doesn't sound like something hard given what the poor compiler makers have to do already for C++. Maybe I'm missing something though and I agree that given what there is in the language you would add that with modules. I've been trying other languages lately and man... Doesn't make me wanna come back to C++
This is just going overboard. 1. You can use compiler flags (e.g. disabling exceptions and RTTI). 2. Your example of steering people away from using C-style casts can also be done with linters and Static Analysis Tools like clang-tidy, where instead of littering header files, you just have a .clang-tidy configuration file in the project root to enable/disable checkers. You can even set it to exit with error on warnings (good for CI). You can suppress warnings in code with "// NOLINT" comments. 3. Have competent people in the company or competent people who review code well. 
We'll probably implement a CI check using clang-format. We found that the WebKit style is 95% similar to our existing style, so it should be easy to adopt. Thanks for the tool tips also! 
It's a great idea. Having advisory guidelines is a good resource for programmers to learn and improve.
Good point. The challenge is to select the correct set of guidelines to be enforced. Maybe iterative is a way to go, starting simple and basic with a few rules, then adding more as people adapt.
Bjarne gave a [great talk](https://youtu.be/HddFGPTAmtU) on concepts
Are you hiring interns?
Just out of curiosity, do you have some specific reasons about what you do not like about the Google Style Guide? 
Why though? Developers expect auto complete, and if a particular pattern prevents it, then disallowing that pattern seems reasonable. Plus it has a clear reason for being in place, which means that if tools improve, it is easy to justify removing it.
That's fluentcpp for you
Thanks, and sorry for the inconvenience.
Well, how specific can one get? `std::getline` would not pass a review enforcing those guidelines. Unless they've fixed that in recent years.
Bjarne commened on such things as unwated. They only fracture the language creating more imcompatibilities. If something should be slitable/modularized, I would vote for the freestading proposal which allows to split/disable certain language features (floating-point, threads, global data, RTTI) for hardware/performance reasons.
What I find odd is that your first example is accepted even though it doesn't involve \*any\* templates. After changing \`concept bool\` to \`concept\`, clang \*also\* accepts it. Is this really a thing and guaranteed? Or is it an additional feature of GCC &amp; Clang to allow \`requires\` clauses outside of templates?
That's exactly what the Standard committee fears - many dialects of the language controlled by fine-grained flags like the one you suggested. How many flags are we going to have? With something like epochs, we can solve most of the stupidity carried over from C and deprecate some features in favour of others (e.g. `using` vs `typedef`).
&gt; standardized language features That doesn't imply they're good. `std::initializer_list` is an example, as you cannot move from it and as it messes up uniform initialization. A module-level switch could fix all of that. Static analyzers can't.
Just dropping a link to [P0561](https://wg21.link/p0561) for those who want to read more about `std::snapshot_ptr`.
The part of C++ that's hard to implement is the part that comes from C.
Er, a C compiler is relatively easy to write. You don't have to handle templates, name mangling, overload resolution, ADL, name lookup, etc. Not sure how the hard part is C, which is a relatively barebones language.
Trying to parse it. A B(C); Depending on your A, B and C, any macros, overloads etc. this can parse any of a hundred different ways.
Macros get expanded before the compiler, by the preprocessor, and are basically just textual substitution. As for overloads, those don't exist in C.
Macros means that you cannot parse code without executing the macros, which mean you cannot meaningfully load and parse code and then write it out again for human use - say, clang-format.
It's Sphinx and it has nothing to do with CMake. Also readthedocs is used by quite a number of C++ projects. They use a Sphinx theme too https://github.com/rtfd/sphinx_rtd_theme.
upcoming std::atomic_shared_ptr can be used to push data from a producer thread to a consumer thread that pulls the data periodically. And this is lock-free.
We wrote a simple C Compiler at university. C is REALLY not that hard. There is a list of rules you have to work up and thats it (Im no talking about optimizing, that stuff is a lot harder)
Yeah pretty much this. We actually have C++17 support so structured bindings are mentioned as an alternative.
Talking about moving the goalposts -- weren't you talking about compilers?
That works in Rust because Rust doesn't have `#include` headers.
This is technically true, but... useless for anything other than toy projects. My car is "self-documenting" in the sense that I can work out how it works by dismantling it, but that's somewhat arduous if I want to change a spark plug. Which is why actual documentation exists.
I think it might have to do something with the size of our C++ Codebase - it's &gt; 15 million LOC. It's rather sooner than later that you will look at code/ classes that you have never seen or heard before even with &gt; 10 years of experience on the codebase. &amp;#x200B; I can tell you - even with the best naming in the world, it's often not clear what the given type in a generic lambda could be. And what do you gain? Being able to write the code faster? The cons are that you are loosing IDE tooling like going to the declaration/definition and autocomplete, which are incredibly helpful in navigating foreign code. For us we decided the cons outweigh the pros, so we don't allow them anymore. 
So.. what have you tried so far on your own?
Initializing with a pattern will be amazing for debug builds !
/r/cpp_questions is the place to ask questions, not /r/cpp Also, please format things like enumerated lists in markdown so they are actually displayed correctly.
/r/cpp_questions
Do you expect us to do your homework? It doesn't look very difficult, even for a complete beginner. Just give it a try, you'll learn far more than from a ready made solution that somebody else writes for you. Just start with simplest program, the function to check for a leap year and put it into a main program and continue from there. A small hint: you can check for divisibility with the modulo operator, e.g. if(year % 4 == 0) // year is divisible by four.
Managed to create only BISESTILE
[Probably just this.](http://i.imgur.com/RFzxg92.jpg)
Didn't know, i will in future
Edited post with what i did so far
What if your variable needs to be initialized in an inner scope? 
Newbie here, some questions: &gt; avoid const unique_ptr&amp;, rather use a pointer what is the use of `const unique_ptr&amp;` (why would one use a reference to a const unique_ptr?) and why would you avoid it? &gt; - for sink arguments use either unique_ptr or by value and move what are sink arguments? Arguments you 'move from' ? &gt; avoid shared_ptr (especially non const), unless you have a good reason to use it how come? memory management is refcounted, so why avoiding them?
Thanks for the feedback. The Location was specified as Boston or Waltham, but do you think I should make that more explicit?
Consider checking out the Boost Library Incubator at www.blincubator.com
Discussions about documentation for C++ programs always seems to focus on tools for creating documentation. This is probably to be expected given that we're C++ programmer and tools is what we do. But the problem with most documentation is that: a) It contains a lot of stuff which is not relevant. b) It misses a lot of stuff which is truly necessary. c) It's very tedious to write. d) It's incomprehensible because it is written after the code has been written so it tries to explain all the design mistakes in the code. The remedy is to develop the code and documentation in parallel as described in my CPPCon 2017 presentation on the subject which you can find here: [https://www.youtube.com/watch?v=YxmdCxX9dMk&amp;t=2s](https://www.youtube.com/watch?v=YxmdCxX9dMk&amp;t=2s) &amp;#x200B;
Because we already have `enable_if`, we didn't need another one. We just needed a better way to write the condition. enable_if_t&lt; is_detected_v&lt;Op, Args...&gt;, R&gt; The `R` here isn't necessarily related to `Op&lt;Args...&gt;`, so this keeps the separation nice.
What would the benefit be of your proposed implementation?
It seems nobody has mentioned it yet: Adobe recently open sourced their Hyde tool for documenting C++ out-of-line without cluttering the actual source. It uses LibClang, I believe, and basically acts as a front-end to Jekyll. The particular conciet is that you can check-in documentation in your source tree, that the tool can then verify as up-to-date after the fact. That makes it possible to use as a checker: PR changes the public interface, but no update to the doc? Then no merge for you! It also generates some pretty gorgeous documentarion, to my eye :) https://github.com/adobe/hyde
I think that ``is_detected_v`` is in some sense more ergonomic (and somewhat more teachable) than relying on ``detected_t`` to SFINAE out. You are right that having ``detected_t`` SFINAE out could eliminate some verbosity, but it seems that it would kind of defeat the whole purpose of the detection idiom, which seems to be to make SFINAE more usable and to some extent more hidden.
If you have a large code base here are some guidelines to make easier to manage. How to name variables. Writing applications with 10 000 lines are not the same as when you have 1 000 000 lines of code http://goorep.se:1010/changelog/report/rselect/page_result.htm?alias=guest&amp;query=Book+pages&amp;$TArticleBook1.ArticleBookK=2042 
&gt;what is the use of const unique\_ptr&amp; (why would one use a reference to a const unique\_ptr?) and why would you avoid it? So what can you do with const unique\_ptr&amp;? You and pretty much only call .get() on it to get the raw pointer... so you can as well just use a raw pointer. &gt;what are sink arguments? Arguments you 'move from' ? Sink arguments are arguments where the ownership is transfered to the called site. &gt;how come? memory management is refcounted, so why avoiding them? Basically unique\_ptr should be the default and is actually what can be used in 95% of all cases. For the rest of the cases, you should try to use shared\_ptr&lt;const T&gt; to make it easier to reason about the pointed to content and then the last resort would be shared\_ptr&lt;T&gt;.
Over the years i've developed a bunch of best practices for writing code, but honestly? My suggestion would be to focus on *documentation* guidelines. Stuff like (and I'm just spitballing here, the context of the type of environment you're working with is paramount in determining these): * All functions longer than 8 lines should include in-function documentation. * All none stack memory allocations must be accounted for in the function documentation * You must justify why a function isn't const if it isn't obvious. * Any internal usage of external static / global data (IE data that isn't accessed by some sort of dependency injection) * Which exceptions can be generated? * Which are In / Out params if they exist (also why aren't params const) * Which none standard Libraries are used? * What knowledge prerequisites are needed to understand this code? * Is this part of a recursion? If the cost of documenting a lazy shortcut that'll bite you in the butt later is greater than simply not taking that shortcut, it's my experience people will tend to do the better thing. Also it leads to actually documenting the freaking code. It's a skill, and if you only ever do it as it's own thing instead of while you're working on your code, you never learn to do it fast enough to do during crunch. If committing / passing a code review / doing whatever religious ritual you're agile methodology gods demand of you requires including a standardized documentation, it's gonna start happening more, and people will get better at it.
Hmm, I feel my proposal is just another side of the same coin. I suppose one can claim that it follows "convention" more (since it follows the precedence set by `enable_if`) although I'm not sure if this counts for much. To be clear, I'm not saying that `nonesuch` is a bad idea - I'm just curious why it was introduced instead of re-using the `enable_if` idiom, which seems like less work (e.g. there would not have been a need for defect #2960 "`nonesuch` is insufficiently useless").
That's... very handwavy, I don't really know what any of that means. Can you give me a specific example demonstrating what you are trying to benefit from, that would be an improvement over the current implementation?
How interesting. I wonder how widely used C++ web frameworks are used for production sites? Wish I could've used something like this at my last job where I had to use Javascript/NodeJS (shudder). Nodejs was ok for backend but frontend tasks made me want to cry
My guess is that `nonesuch` is needed to implement `is_detected_exact` and `is_detected_convertible`. Otherwise you'd have nothing to compare with (resulting in a compiler error).
As I said: &gt; Do this on a per-module basis. This relies on modules, and could be used in any module that doesn't `#include` non-module dependencies. 
&gt;Type checking still happens at compile time for both those cases. The problem which I think the OP was mentioning is that 'auto' satisfies all types. And so the *intention* of the programmer can get lost. auto s = "blah" and std::string s = "blah" don't mean the same thing, unfortunately.
&gt; I cannot comprehend how people see a language as unusable just because it offers complex and advanced features. I do think you're exaggerating their position. They didn't claim that the language was unusable.
Visual Studio does not support inline assembly in 64-bit mode. Are you sure you're building your program in 32-bit mode?
Ok, how do I build in 32-bit in vs? I am using visual studio for the first time, sry for stupid a question.
Write a paper carefully explaining how epochs won't fragment the language and how we can benefit from them. I'm not suggesting this to be a dick or tell you to go away... quite the contrary. The committee isn't going to magically come to understandings without someone actively providing a source for understanding. 
I can't really help with visual studio questions - I haven't used it for many years. You might have better luck in r/VisualStudio or /r/cpp_questions 
You would need an x86 solution configuration. [https://docs.microsoft.com/en-us/visualstudio/ide/how-to-configure-projects-to-target-platforms?view=vs-2017](https://docs.microsoft.com/en-us/visualstudio/ide/how-to-configure-projects-to-target-platforms?view=vs-2017)
Do you have a source for the way the reasoning goes? Integrating the `break` statement seems unnecessarily complicated. It also implies the compiler would not optimize like this if the statement was missing, to me it seems more logical that the compiler would have no problem generating an endless loop for this case.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I think you're making this more complicated than it needs to be. There is no reason to bring the `break` into this. 1. `i * 1000'000'000` is defined for [-2, -1, 0, 1, 2]. 2. Therefore `i` cannot take another value 3. Therefore `i &lt; 4` is always true
I know, I'm the first to say "write a paper" when someone complains about the committee. I got a lot on my plate at the moment but I might research this in the future. I'm bitter about this because I tried to float the idea around in JAX and it got shut down immediately, without much chance for discussion. A paper is definitely needed.
Yeah. It's just hard to even discuss since most people (myself included) don't actually know in meaningful detail what Rust epochs are.
An endless loop is undefined behaviour, unless it has side effects. The compiler generally tries not to create one.
Sphinx is great and LLVM docs are a good example: [http://llvm.org/docs/index.html](http://llvm.org/docs/index.html) . Making it work with Doxygen is a bit tricky, but can be done with Breathe: [https://github.com/michaeljones/breathe](https://github.com/michaeljones/breathe) . Doxygen is a weak part in all of this setup because of its poor support for modern C++.
I didn't know that endless loops are UB. Still seems logical that `break` is not used when reasoning about `i`, it still can be used later to reason about the loop as a whole.
I didn't know that endless loops are UB. Still seems logical that `break` is not used when reasoning about `i`, it still can be used later to reason about the loop as a whole.
But my point is subsequent operations on the object can't act on all types. I can't call "substr" on a const char *, for instance. Like I was saying, it's no different from a typename in that regard. He may as well argue we should avoid writing generic code at all because the same confusion about a typename.
In C++20 you can do ```c++ constexpr auto to_u32 = bit_cast&lt;uint32_t, array&lt;Byte, 4&gt;&gt;; const auto result = bit_cast&lt;array&lt;Byte, 4&gt;&gt;(to_u32(a) ^ to_u32(b) ^ to_u32(c)); ```
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/functionalprogramming] [Functional Programming in C++](https://www.reddit.com/r/functionalprogramming/comments/a7qeje/functional_programming_in_c/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
The book Functional Programming in C++ by Ivan Čukić is really really good, check it out! https://www.manning.com/books/functional-programming-in-c-plus-plus
This is exactly what i was looking for!
Well, I have it already. I was talking with Ivan about the book and hope to talk more at C++ Siberia 2019. *(I also was a reviewer of the book proposal for Manning and suggested to rework the table of contents in order to make it more consistent. Not sure how many of my suggestions have been taken by Ivan, by I like to think there is my little contribution to it. But of course, Ivan made a great work, so we can now enjoy his book)*
 [This](https://www.reddit.com/r/cpp/comments/6l79jl/functional_programming_using_c_introducing/?utm_source=reddit-android) was a very good course on introducing FP via c++. Not sure if it has exactly what you are looking for, though ^^"
Check out this talk by Simon Brand and Phil Nash: https://youtu.be/GC4cp4U2f2E They talks about monadic error handling.
Very roughly, they're a feature that the language designers use to make breaking changes to the language while retaining backwards compatibility. Every module can be compiled with a specific epoch that might change how the language works (e.g. `const` by default, `[[nodiscard]]` by default). The compiled modules can depend on modules that were built with an older epoch and vice versa. This is a good read: https://github.com/rust-lang/rfcs/blob/master/text/2052-epochs.md 
You know what also would have solved the issue with memory pressure in the main process? 64bit VS. Hopefully when we finally get this version in production at my job, I won’t have to kill VS so regularly due to said memory pressure. 
The author of the article, here. First of all, thank you so much for taking the time to read my work: both your observations are very good and subtle. I'll try to answer in the following. I choose the name "Flip Model" because this pattern is all about its implementation (i.e., using a couple of shared\_ptr or whatever, publishing one of them when the content is ready). That's why I used "Flip Model" as the "main name"; however, in the "Also known as" section I reported a couple of names that are metaphors of the use (e.g., newsagent -- after a newspaper is printed, the newsagent sells multiple identical copies while the next edition is printed, and those copies are thrown away after the readers don't need them anymore). I suspect "Snapshot model" wouldn't capture enough the essence of the mechanism. Let's briefly analyze a typical sequence of the atomic\_uint implementation (I'm using a pseudo notation for the events, hope it's clear): current = 0 ... // OnTimerExpired() auto sa = make_shared&lt;SensorAcquisition&gt;() sa-&gt;Scan(...); // start async operation... measures[1] = sa; ... current = 1 // OnScanCompleted() (end of the async op) (1) ... // OnTimerExpired() auto sa = make_shared&lt;SensorAcquisition&gt;() sa-&gt;Scan(...); // start async operation... measures[0] = sa; (2) ... current = 0 // OnScanCompleted() (end of the async op) ... The issue could arise only if the method `GetLastMeasure()` reads `current` before (1) and uses it exactly in (2) to return `measures[0]`. Between (1) and (2) however, a proper amount of time is ensured, because the periodic timer must have a period much larger than the async `Scan` operation (as underlined in the article). Unless there are serious problems in the OS scheduler, this ensures that no race conditions will arise. &amp;#x200B;
Right. I wrote about it in the issue #8 of the”Implementation” section.
What shit is this. Always compiles does not mean always works. Forwarding references are for preserving the value category, not for convenience. They were specifically called forwarding references by the committee (as opposed to the original proposed name, universal references) to avoid giving the impression you should just go around putting forwarding references everywhere.
Which isn't in the style guide and hasn't been for years (at least since I reviewed it for the first time). It feels like every time someone mentions how awful the Google style guide is, it's because of it's based on information that hasn't been true for nearly a decade. This knee-jerk reaction is getting old.
Thanks for that feedback. I checked, it's still there. I.e. you're basing your opinion of my assessment (and it's my impression that it's the general community's assessment) on ignorance, sorry.
Same. My team has its own style guide that's based on the google style guide. People treat style guides like it's either all or nothing. If there's a specific part of the guide you don't like (like no exceptions in my case), take it out and augment it. In many cases, tweaks to a style guide don't change the élan of the guide.
You know what costs a fucking fuckton and breaks all add-ins? 64 bit VS. 
Either I didn't understand your point about std::getline or we're looking at two different guides. Could you elaborate?
The variant of the Google style guide I referred is the one I linked to, (https://google.github.io/styleguide/cppguide.html). It says "output and input/output parameters will be pointers to non-const".
You can go with the following cmake enabler: # Add concepts support for gcc &gt; 7.2 with -fconcepts if (CMAKE_COMPILER_IS_GNUCC AND CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 7.2) target_compile_options(MyLib INTERFACE -fconcepts) find_package(cmcstl2 REQUIRED) # not mandatory but recommended, see https://github.com/CaseyCarter/cmcstl2/ target_link_libraries(MyLib INTERFACE stl2) target_compile_definitions(MyLib INTERFACE MYLIB_CONCEPT_TS_ENABLED) target_compile_definitions(MyLib INTERFACE concept="concept bool") endif()
Probably obsolete by now, but I used to blog about writing Haskell in c++ over at http://yapb-soc.blogspot.com/?m=1
Now I understand your point. But you see my confusion about that point; surely the style guide doesn't extend to functions that are already in std. There are many more functions in std that don't fit that criteria and I doubt Google (as evident in the abseil library) would restrict programmers from using such functions. So while I understand your point, I don't see how that's a specific reason to not like the Google style guide. Though I'm sure you probably have other unvoiced and valid reasons, my comment on outdated knowledge on the Google style guide was made in general based on what I've seen occasionally in this subreddit.
Yes, good point!
Pretty sure they’d have gotten over the cost in the the 7 years since someone requested it on user voice. [first result on google for 64 bit Visual Studio](https://m.slashdot.org/story/312059) True, it would have broken all addins but I’d rather have stability in my IDE then old addins that are not being maintained. That is where my cost benefit analysis of the utility of this change differs from yours.
One of the major use cases for the detection idiom is "`T::foo_t` if it exists, `bar_t` otherwise".
Boost.Hana is a library with concepts borrowed from category theory as you see in Haskell: http://boostorg.github.io/hana/group__group-concepts.html Also here is a video demonstrating making a promise monad with it for full duplex messaging: https://youtu.be/UalTAQmP3iE?t=1348
Not really into functional programming myself, but I've heard good things about this: [https://github.com/beark/ftl](https://github.com/beark/ftl)
While the latter is C++03, Boost.Hana and Boost.Phoenix are both highly relevant here.
Thanks, your reply made a lot of sense! Yes, I was thinking along the lines of allowing SFINAE on `detected_t`, but I agree that SFINAE is unergonomic
I have updated my original post with a (contrived?) defect. Basically, if application code contains an alias to `nonesuch`, `detected_t` will yield a false negative.
For my case, `detected_or` will require using an additional struct that specializes on `DETECTOR&lt;/* args... */::value_t` and provides a member typedef to `Default` if `value_t` aliases to `false_type`.
That's why it introduces a brand-new tag type that no existing code could have used and no future code should be using. We should not design around such nonsense.
More importantly, there's already a way to spell `detected_t&lt;Op, Args...&gt;`with your semantics. It's called `Op&lt;Args...&gt;`.
Lol yes, I didn't know why I didn't see that. I guess I was more worried about application code mis-using `nonesuch`, but i didn't realize that when i made my original post.
You might be interested in my attempts to (ab)use coroutines to approximate do-notation here: [https://github.com/toby-allsopp/coroutine\_monad](https://github.com/toby-allsopp/coroutine_monad)
No one cares about VS addins, I can’t think of a single one that I couldn’t live without 
Half the point of detected is being able to invert it, and/or do boolean algebra with it. `nonesuch` extends this; you could do a conditional on some clauses, and use detected for one branch. Even if the application is invalid a type is produced, instead of unwanted SFINAE. So long as you don't use it, the fact it is nonesuch is irrelevant. 
https://clang.llvm.org/extra/clang-doc.html
C++/WinRT? LLDB? NuGet?
Exactly, fuck those.
First of all why is C++/WinRT an add on? Shouldn't that be something the compiler handles? Second of all the NuGet integration in VS blows, it's laggy as hell and honestly would be faster to just use the command line. Lastly, do you really think Microsoft, one of the most valuable companies in the world, doesn't have the resources to rewrite three fucking addons in x64? 
I wouldn't be able to stand ditching Resharper C++. Though I would guess that JetBrains would probably patch it pretty quickly anyway.
I think another argument of theirs was that memory usages would increase a lot with 64 bit due to their datastructures
While debugging in VS2019 really got better for the most part. Resharper C++ for example still can easily run out of memory on huge projects, so I have to hope that it will be moved out of process too. Then something else will be running out of memory probably someday and so on. Going 64-bit seems to be much more reliable and logical solution in a long term.
Can we expect a better edit and continue experience in c++? I can never use it because: - half the time applying code changes run far more longer than just rebuilding the project - almost never work with lambdas (because it says that the type changes) - sometimes crashes or leave the compilation in an undefined state which require to close and reopen the solution - sometimes code changes aren't detected at all, likr commenting macro calls. So my point is that it works great on a Hello World example but not so good on a real case scenario.
Yep. It's sad that C++ mixed forwarding reference syntax with rvalue syntax. But yes `const auto&amp;` is reasonable and an argument against "always auto&amp;&amp;". Could the advice be amended to use `auto&amp;&amp;` for modifieable and `auto const&amp;` for constant range-based loops? It seems to work in call cases.
Cool, didn't know about Hyde. Just waiting for a Windows version
Possibly. I'm not sure about MinGW but at least it required rebuilding all dependencies due to ABI change in GCC 5/C++11. The apple cross-compiler is the main issue: Custom build as there are no available working versions (linux-&gt;OSX) and again: All dependencies need to be recompiled.
Thank you. I probably need to add one more section for courses into the document.
That's cool that so famous people are arguing about FP. Thank you!
In some sense, Boost.Spirit is functional too, but you know, it's *ugly*.
&gt;http://yapb-soc.blogspot.com/?m=1 Hi, that's a great work done. I'll add references to your posts into the document. May I ask is there a chance you'll write more posts about the upcoming FP fetures?
Indeed, thanks. I've included this library into the document already. Also, it was a source of inspiration for my own research of FP in C++.
Thank you, I'm definitely interested in the approach you're researching. I was wondering if coroutines have something to do with monads, and it seems they have. Unfortunately, without a real do-notation, we'll be dealing with limited half-decisions.
[This is what happens without the break](https://godbolt.org/z/UMseOu). It reasons that UB occurs when i is 3, and that i must be 3. It will only assume that i isn't 3 if there could be a valid program flow that avoids UB. In theory it's an optimisation that the compiler *could* make. But creating an endless loop is a really bad optimisation; the compiler is going to consider how the loop operates before it does anything with it. And really, most optimisations work that way - it involves context.
Hello. I did a talk about functional-style pogramming some time back in the Ho Chi Minh City C++ users group. It is not a pure functional programming talk purely speaking but related, so just in case you want to take a look: https://www.slideshare.net/GermnDiagoGmez/functional-style-programming?qid=bb32347f-bb9e-4eb4-b0fd-de5d8f9a0b11&amp;v=&amp;b=&amp;from_search=2
Hi, that's cool, thanks, I'll check it out. I think we need one more section for slides without videos in the document.
move-only classes seem like a good candidate for both functional and performant programming, since state is always confined to a single point of contact, and the fact that no copies are made. move by default is one of my favorite feature of rust to be honest.
https://www.fluentcpp.com/ is blog with strong functional influences, although it's not organized as a complete, comprehensive set of best-practices.
got any link to that?
I think that a library is not important. I would to have a tool that checks for style failures &amp;#x200B; Consistent use of field initializers, consistent use of size\_t, use of a standard indentation style, always check with valgrind, make sure that operator&lt;&lt; never prints into std::cout, moving operators should really move, assignment must be self-assignment proof. Students are incredibly good at creating bad code. If there is a loophole, they will find it.
This page is generated with doxygen: https://www.boost.org/doc/libs/1_69_0/libs/beast/doc/html/beast/ref/boost__beast__http__async_read/overload1.html
This just can not be implemented reliably when it comes to native code. Changing simple thing like constant value may be fine because it basically does not change layout of generated machine code. Adding/removing a section of code inside a function might also work. However if you start shuffling things around things get messy very fast. Add something before your breakpoint, add something after, state after recompilation can no longer be predicted. Adding/removing virtual methods would change virtual method tables thus invalidating any code that touches virtual methods from said class. The only sane way to achieve something like this is stopping execution at a safe point that will not change, serializing entire application state, recompiling and restarting application and unserializing state. This is of course not very practical thing to do.
Who the hell cares about memory usage - it will increase by 2x at most and that is less than 3GB. In reality it will be even less - 1.5-2 GB at most. If you're short of 1-2 GB of memory on a developer machine just close your chrome or something.
While making IDE in electron is fine. ¯\\\_(ツ)\_/¯
Tried it, looks good! Now I need a project that needs this \^.\^. &amp;#x200B; Goodbye and thanks for all the fish.
I did search it, but i can't find it. I remember one of the microsoft people stating it on reddit, can't find any official source :(
Great. Can I recommend you create a recording of your command line with something like this [https://asciinema.org/](https://asciinema.org/) and post it on your blog/github; it's always great to see what a UI feature will look like before trying it.
Is there any example of clang-doc output anywhere or is it only IR that comes out? From the very sparse documentation I'm not sure what to expect...
clang-format seems like a great opportunity for a useful tool that's in need of improvement.
I would advise you to use Meson instead of CMake, as it is far more modern (i.e. no legacy nonsense - even 'modern' CMake is a lot of legacy bloat and confusion) https://mesonbuild.com
Could you use `shared_ptr&lt;const SensorAcquisition&gt;` to enforce immutability?
Awesome! I've been looking for something like this. Can't wait to test it!
&gt; I can’t think of a single one that I couldn’t live without That's a very self-centric position. FWIW, I *could* live without beer. 
My conjecture why this might be prohibitively expensive: the code base is old and likely a conglomerate of many once-separate projects. I wouldn't be surprised to find VB6 IDE remains in there somewhere, or some remains from VC5. I'd expect some 3rd party components with less-than-favorable licence requirements that are bitch or impossible to update or migrate. It went through the hands of multiple teams, not all up to par. High risk of destabilizing a product that went through long pains getting stable. Parallel deployment and maintenance of x64 and x86 versions is probably required for quite some time. These ressources can be used better indeed. Yes, I'd welcome a 64 bit version. No, it's not ideal. Yes, the pressure will increase. But there's a good chance the 64 bit IDE will not be Visual Studio as we know it. 
Yeah, but it's a terrible argument. On Linux, BSD and also MacOS, we have had pure 64-bit systems where every last little bit of the system is 64-bit only. For over 16 years now in the case of Linux and BSD for x64, and even longer for other architectures. The world didn't end for lack of micro-optimisation of pointers sizes in individual programs. In fact, the consistency and standardisation made the situation vastly better. Why on Windows does this stuff get decided by the individual groups maintaining specific programs? Why did it not get mandated from on high 15 years back, that every program would be 64-bit from a certain date. A 32-bit Visual Studio hasn't made sense for years now, and yet it still persists. The fact that they are even arguing about this stuff baffles me. Not being 64-bit has caused me so much pain and so many repeated crashes of Visual Studio that I no longer dare use it for editing lest it bomb out and lose all my changes yet again. That got old really rapidly. I wasn't even using any extra plugins.
You know, it's not that hard to build a 64-bit plugin. I'm sure that the developers of these add-ins could take 20 minutes out of their day to add a 64-bit build. When thousands of us have had the CI infrastructure in place for many years to create 32- and 64-bit builds of our libraries, tools and applications, I don't think this is somehow an insurmountable hurdle. If Visual Studio becomes 64-bit, I think we might be able to manage.
Though you are right; there have been a few rare times when I need to know when a variable gets accessed. So I needed to add a breakpoint when a data member changes or is accessed. &amp;#x200B; Only recently I got data breakpoint in VS: [https://blogs.msdn.microsoft.com/vcblog/2018/07/25/data-breakpoints-15-8-update/](https://blogs.msdn.microsoft.com/vcblog/2018/07/25/data-breakpoints-15-8-update/) (I think I was doing a hack before?) And I have used \_\_property before: [https://docs.microsoft.com/en-us/cpp/cpp/property-cpp?view=vs-2017](https://docs.microsoft.com/en-us/cpp/cpp/property-cpp?view=vs-2017) such that I could feel like a public member variable but it would call a member function that I could add a breakpoint to. &amp;#x200B; Hope that helps! :)
Yep, exactly. The "bug" is one of those that will "never" happen, until it does and no one can figure out why, nor reproduce it. It probably won't be seen until someone uses the technique in a system where it turns out that writing is faster than reading or becomes that way due to changes made over time, etc. Or scheduling gets messed up because someone decides to mess with thread priorities, etc etc etc. Basically, it works for typical use, but I wouldn't put it inside a generic library, or offer it as a generic solution, because you don't know how people will use it. I might categorize your article about it under the category of "offer it as a generic solution". Unless you make the subtlety very clear, someone will implement it in a situation where the problem happens.
Was it [this 2009 blog post](https://blogs.msdn.microsoft.com/ricom/2009/06/10/visual-studio-why-is-there-no-64-bit-version-yet/) or the [2015 followup](https://blogs.msdn.microsoft.com/ricom/2015/12/29/revisiting-64-bit-ness-in-visual-studio-and-elsewhere/)? An older discussion on reddit was [here](https://blogs.msdn.microsoft.com/ricom/2015/12/29/revisiting-64-bit-ness-in-visual-studio-and-elsewhere/) and on stackoverflow [here](https://stackoverflow.com/questions/2516436/visual-studio-64-bit)
&gt; I'm sure that the developers of these add-ins could take 20 minutes out of their day to add a 64-bit build. That assumes the plugin was built with 64-bit support in mind, and the devs did already test that (how?), or just made no mistakes. Insurmountabe? No. Worth it? I honestly don't know. But at least people asking for it always make it sound like it's just a compiler switch. 
This is honestly a bad idea... the source code should have all variables initialized, don't rely on some stupid compiler option to do what you were too lazy to do, and will probably forget you did in your makefile that you never read.
It usually *is* nothing more complex than a compiler switch. I maintain many different cross-platform projects all of which compile for any CPU architecture. 32-bit-specific code is a strict rarity, and usually an unintentional bug at that. Making a plugin 64-bit-clean should be a triviality for the vast majority of cases; 64-bit support is not, and never has been, particularly onerous or challenging.
Data breakpoints existed already in VS 2008.
I've never heard of `__property`before and it took me some time to grasp the syntax. It looks quite usable, thanks for the hint!
If you develop on a word-size-agnostic platform, and don't serialize raw data, sure. &gt; 64-bit support is not, and never has been, particularly onerous or challenging. I have a few projects I'd love to see you get your hands on :) 
So I created **spartan-launcher** (also on github) as an alternative program launcher for Java programs that are intended to run as services and I too wanted super easy command line access to these services to be possible and for it to be trivial for the developer to add sub-commands that can be invoked from the command line. **spartan-launcher** is written in C++11 and can be compiled under g++ 4.8.x. But I departed from you philosophy in one respect - I absolutely didn't want to embed any manner of socket listener into spartan or the Java program. I chose to go this way for security reasons and to keep the launcher and its related Java classes as minimal as possible. Should be up to developers as to whether they want to enter into the fray of socket listeners and requiring ports to be open, i.e., should be part of the specific application and not the library or framework (or program launcher, in this case). Basically in this day and age, ssh connectivity is ubiquitous. And the Java-written services that have been devised using **spartan-launcher** are all being deployed in containers. It's required that first one get access to the VM or container in some secure manner and this is almost always over a secure ssh connection being provided by the wonderful sshd daemon on Linux (or the last leg is *docker exec -it containerid bash*, or Portainer web access into the container. But once there one need simply su - *service_user* to become the same user that the service is running as and then can issue command interaction with the service. This is especially useful to write bash scripts that interact with the service - say to batch process thousands of files in some backlog that has built up, etc. I notice that many other programs deliberately piggy back on ssh - such as the wonderful rsync or git. One gets secure access and defers that responsibility to some other program that is being well supported by a community at large. And can then avoid building in port access directly in one's on programs and thereby dodge the whole matter of security and authentication. Keep the program as minimal and purpose focused as possible.
Actually, I do serialise a lot of raw (image) data. It's not difficult to do this correctly, safely and portably without making assumptions about the CPU bitness or endianness.
I hear this reasoning often when I am trying to preach the same style as OP is proposing. TBH it really does not fly: the scenario you are describing is, arguably, pretty rare, at least in my experience, and easy to solve with a debugger. The cost of polluting the entire code of what will amount to thousands of useless lines of code is way bigger than the convenience of being able to break on a setter. But I understand these kinds of discussions often end up in "religion wars".
This is an over-simplification. Includes are not literally copy paste; this is the best first order approximation so we tell beginners that. But the compiler (at least some compilers) is still aware when processing a file what content comes from the translation unit, and what comes from headers, and could easily push and pop the pragma appropriately. If what you're saying was literally true, then the way that `-isystem` works in gcc would not be possible. Yet the *compiler* is capable of understanding that when it compiles a cpp file, it should apply warnings to the contents of the cpp file, and headers found via `-I`, but not headers found via `-isystem`. This shows that it hasn't been literally collapsed to a single logical file and the compiler has at least some of the information it would need to implement what's being suggested already.
But it's hard to retrofit correctness
Get out of the "header only" mindset and also target a package manager, like conan. I recently dumped catch2 and went back to gtest because it re-compiled my unit tests at least twice as fast. Whatever extra features it offered wasn't worth the permanent increase in build time.
This is true, but also most compilers are able to run *just* the preprocessor on a file - and then the compiler can be run on the result. This is a supported workflow, and one that is actually used...
this talk impressed me a lot considering I wasn't expecting it to be so functional (maybe why it's not on your list). They build a regex parser that is completely constexpr (no runtime) using lambdas [https://www.youtube.com/watch?v=PJwd4JLYJJY](https://www.youtube.com/watch?v=PJwd4JLYJJY)
I'm curious, in this kind of workflow, does `-isystem` not operate properly? Or does the preprocessor itself add special pragmas at the start and end when including files, which are sufficient for the compiler? That seems like a pretty logical way for this to work, given that it would keep the preprocessor and compiler separate. If the preprocessor adds something like this, then again that's enough information to implement file level pragmas that respect file scope even in a header.
The main argument was cache locality. Linux has x32 for that, but like nobody really uses it. And they probably will throw it out of the kernel now.
AFAIK it does - but none of that is mandated behaviour under the C++ spec. Actually standardising something as "file scope" would also involve also standardising what "file scope" was - #include's behaviour is actually remarkably vague in the standard.
No, that is definitely C++17
resharperC++ on a large codebase is exactly my situation. I am saddened that the debugger changes likely won’t relieve my frustrations. Oh well.
Interesting stuff, thanks! I'll be building a monadic parsers library for myself soon (resembling the Parsec library from Haskell), so that talk is pretty much in-time.
Yes, true, thanks. Jonathan Boccara does a great job popularising the ideas from the functional world (but not only). I'll add his materials into the list.
I doubt your conjecture about there being a ton of legacy components is factual. I cannot speak directly to this because I have not seen the IDE source code but having used VC6 through to today, I would find it hard to believe they’d still have UI components that are difficult to migrate to 64bit. I believe it was for 2010 when they changed to WPF for the UI so I would expect that in the following 8 years, we’d have seen all legacy UI removed. I’d also expect that their static analyzers should be screaming loudly if they have a bunch of code that is not 64bit safe. I know it was all the vogue back in the day to just cram your pointers into ints but we(the industry) have seen the harm these kinds of things have done and have been writing tools to find them for years.
Indeed. Most performance-critical applications avoid having lots of pointers around anyway.
You're making a mountain out of a molehill. The vast majority of bitness bugs are fixed trivially. You might possibly have to add some ifdefs if you need alternative serialisation logic if there's some entrenched misdesign in your code. But to be frank, this is a non-problem for the vast, vast majority of code out there. Anyone relying on fragile and non-portable binary serialisation in 2018 is doing it wrong. I've spent many years porting and building code for many different architectures, including Windows x64, and non-portable code has been the exception, not the rule. And when problems were encountered, the vast majority were usually fixable with a few one-line changes. I've yet to encounter an insurmountable problem. On the PC, we now have nearly 15 years of experience with this stuff. All the 64-bit infrastructure is well matured and understood at this point, on every single platform. There is little to fear here.
And it interleaves nicely with functional programming style. Sometimes it seems like people feel like they are being judged by the number of lines they produce instead of the number of well designed modules they create.
Ok, wait, what is that formatting on your github, https://github.com/daniele77/cli/blob/master/cli/winkeyboard.h#L74 please, that's disgusting.
I've got a source base with some 50+ executables and there is the occasional overlap in names (which isn't a problem since they are never linked together). Unfortunately it causes a lot of confusion in Doxygen, and I really wish there was a solution for that... (and I don't mean in the sense of "just run Doxygen 50+ times, once for each executable")
Steve Balmer was on the panel: "C++20 requires requires requires...". They couldn't stop him once he got started. &amp;#x200B;
I've done some work porting Arduino to C++17, and replacing many of the poorly implemented Arduino functions with better-optimized ones. One big limitation still is that g++ does not support `__flash` in the frontend, so you cannot mark pointers as pointing to the program memory address spaces. I have a rough constexpr/template solution for that, but it isn't perfect.
You mainly avoid pointer chasing like linked lists.
Agree 100%. I also feel like creating a style guide is like reinventing the wheel for the 1 millionth time. When a big company like Google publish a guide that they use internally, just use it. Accept the flaws and focus on producing code instead of guidelines.
I find this interesting, because I find success when maintaining mature software can often be defined by the number of lines you remove.
Ooof, some of those standard Arduino functions are problematic to say the least. I was more thinking about taking one of the STL implementations that already exist for arduino, and bringing it up to date with the standard library of C++17. When trying to use C++17 features in arduino code, I kept stumbling into issue where I'd find examples that'd rely extensively on STD helper functions, traits, and or structs, I keep having to re-implement basic features that I think most people could use. The argument I've seen most often for not including a version of the STL with arduino is that types like vectors and maps don't make much sense in an embedded environment, but that's a pretty outdated view of the standard library, that doesn't take into account its role in template meta-programming which is suited to an embedded environment.
Haven't tried it myself, but you could convert the Markdown document to epub: https://pandoc.org/epub.html
As i said above, i agree. Any line that can be removed, should be.
Thanks for this comment /u/bandzaw :) /u/graninas was one of the book proposal reviewers. Sadly, I didn't know that for a long time - all reviewers in Manning are anonymous - the manuscript reviewers have been automatically added by Manning to the acknowledgements section. Unfortunately, it seems they didn't include the people who gave suggestions to improving the book ToC. :/
Sounds great, I have exactly the same problem with Arduino programming. It would be nice to have at least the [freestanding](https://en.cppreference.com/w/cpp/freestanding) part.
The latter of "Boost.Hana and Boost.Phoenix". ;-]
Why do these features that use templates and values need to be ported at all?
Amplifying this thought... From [CppCoreGuidlines Contributing page](https://github.com/isocpp/CppCoreGuidelines/blob/master/CONTRIBUTING.md) &gt;Document style decisions &gt; &gt;We've discussed and made decisions on a number of document style. Please do not open PRs that revisit these stylistic points: &gt; &gt;\- The CppCoreGuidelines.md file is a single GH-flavored Markdown file. It is not split into separate chapters. &gt; &gt;\- We do not use syntax highlighting in the Core Guidelines. See PRs #33, #96, #328, and #779. If you want syntax highlighting you can either view the "pretty" version at [http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines) or do your own post-processing. &gt; &gt;\- We're sticking with the ASCII character set. We do not use Unicode em-dashes, Unicode spaces, or pretty quotes. Lots of people edit this file with their various text editors. ASCII is simple and universally understood. &gt; &gt;Miscellaneous &gt; &gt;\- To avoid line-ending issues, please set autocrlf = input and whitespace = cr-at-eol in your git configuration. Shouldn't be hard to convert this to epub. Only catch is to update epub when changes to the underlying document is updated.
Look for stuff from Juan Pedro Bolivar Puente, such as https://www.youtube.com/watch?v=sPhpelUfu8Q
Thanks, that seems to have worked well. Instructions for anyone in the future looking to do this: * Download the Markdown file. (either clone the project in Git or download the zip from Github) * [Install PanDoc](https://pandoc.org/installing.html) * pandoc CppCoreGuidelines.md -f markdown -t epub3 -s -o CppCoreGuidelines.epub 
Talks by David Sankel. ie https://www.google.com/search?client=firefox-b-1-ab&amp;q=david+sankel+function+programming
Hi Ivan, That's OK. :) The book is wonderful anyway. &amp;#x200B;
His API is [stupid](http://jamie-wong.com/2012/02/01/stop-returning-void/).
Look at Kvasir lib by Odin Holmes for some ideas. You can check out his talks also.
While I might not die without it, I'd lose a ton of productivity without Visual Assist. 
LOL I was just started watching these videos and both of you saved my ass, Thank you very much /u/Optimaton &amp; /u/EducationalHound (sorry for commenting in an old post) /u/Optimaton is Tony Gaddis' book `Starting Out with C++: Early Objects` good book to learn c++ it's kinda not boring or Reference Style book, I tried both Stroustroup's book and C++ Primer and kinda bored because they feel like Reference books for Intermediate to Advanced programmers not as Introductory for new n00b programmers. 
I was really confused, because I'm using C++14 features in Arduino... but I'm actually using Teensy, which uses arm-none-eabi-gcc. So you'd specifically be implementing a better STL for *ATMega*-based Arduinos?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/a81m4m/is_there_a_fast_equivalent_to_icu_u_snprintf_u/ec7k0x4/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That's a whole other blog...?
Arne Mertz's mutators return `void`. When they return `*this` they become much more useful.
It's almost as if C gets reinvented
Except that everything is mutable.
Unless it's const. 
I think the term "data structures" is reserved for special data structures like trees, graphs, lists, hash maps. What the article is about is POD objects. And the conclusion is that you should not over-engineer POD objects. News at 11.
This brings me back to that day I spent adding setters &amp; getters to my all my POD structs at my team lead's insistence.
Say for example you want to develop a library to read data outputted in a standard format over a serial connection. Now you COULD implement all of the messages in that standard using basic C++ semantics, but you'd just end up with a bunch of boilerplate code, compiled code that doesn't actually get used, and a whole lot of virtual functions. Or you could use template metaprogramming to build a more generic version of that library, that boils down a whole lot of that during compile time, rather than during runtime. Say you're repeating a request for message type 4242 over a serial connection, except woops, that serial device you're hooked up to expects that request ID to be in hex not decimal. You could: 1. Figure out ahead of time what the Hex value is, and write that down in your code. Which is the simplest, but will require more work when you've got to look for other values in the future. 2. You could figure out at runtime what the Hex value is, which is neat, but if you don't want to repeat that process for every request you're going to have to save that value somewhere. 3. You could write some template magic that figures out that hex value at compile time, and saves it as a static string, leaving you with little to no runtime overhead. String literals are a pain to re-write for every project, writing them in a concise manner is much easier if you can lean on some STL idioms for some of the metaprogramming syntax.
Do you mean C++14 language features or C++14 standard library functions? Because feature wise it's pretty easy to get GCC to compile even C++17 code for arduino boards, but I haven't seen that there was library support. Does it exist and I'm just missing it?
I'll be honest first time I've heard that term, welp more reading material for me!
That looks AMAZING! Exactly the sort of thing I needed a couple of months ago... Honestly the biggest thing for me would be conformance to the STL so that more code and knowledge could be shared between the domains, but honestly if the functionality exists in other forms (or at least most of it) maybe all the really needs to be done is some glueing and some gap filling and somethings like that could power the implementation.
&gt; We’ve also tested the runtime performance and ensured there is no noticeable overhead due to calls between components that are now going over a process boundary Curious how they achieved that.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/a83vkk/book_to_learn_c_as_a_total_beginner/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Actually this belongs to the famous OOP vs FP debate. Each has its appropriate use case. "Simple data structures" aka. FP style, considers objects as a bag of data, while OO style considers objects as a bag of functions. FP is good at adding operations but bad at adding things, vice versa.
These are data structures and the term is not reserved for things like trees, graphs, lists, hash maps... 
Except they are really really slow. Something like if( value &gt;= SOMEVALUE ) { noop( ); // breakpoint here } and a data breakpoint looking for the same condition is orders of magnitude different in performance 
Lots of this, really. Now, I'm far from the representative sample but I am of the opinion that unless C++03 is declared Illegal (as it comes to the committee that governs C++), one should expect that a C++ compiler should be able to compile C++03 code and a library that aims to serve C++ globally should work on C++03. If I wanted a whole different language I'd progressively move over to D, E, F, G, H, and their ++ versions, whatever. I develop with C++03 and C++11 because as a digital archivist I like things to last: the software I develop I try to make sure it compiles in my i5 laptop, but also in my old olidata laptop from like 1999.5 that is frozen on Ubuntu 14 LTS because nothing later than that will *install* successfully. I don't assume that everyone around me will always have access to the new shiny things - after all, *I* don't; and since I see everyone else just packing and leaving and those like me behind, I feel for me and I feel for them, and at least I can do something useful for us. In that sense, I started developing my own set of backports for C++11,14,17 features because while at the beginning I looked at Boost highly, it didn't take me long to realize that they had become a hindrance as they had become the jQuery of C++ (or jQuery became the Boost of JS, I'm no longer sure); a monolothic entity that has taken over not only the code but also the culture and the learning (I still remember the times when the default StackOverflow answer for any problem was "use Boost.Foo"), becoming not unlike the evils we bemoan in the forms of Oracle, Microsoft, Google, etc; not to mention increase compile times for simple programs twelvefold. While I no longer remember exactly I think the last version of Boost I bothered checking was 1.52. I'm not sure any later version would offer anything that I wouldn't find better by just heading over to the adequate domain-specific framework (SDL, Qt, etc), and the components of Boost I used to use have slowly given way to better tools for the job (Boost.Format I replaced with tinyformat for example). 
I'd severely upvote this, since it beats just removing all or some implicit conversions.
But it wasn't the good example anyway.
I don't think that there is anything particularly wrong with one or two getters, but I do consider setters to be really suspicious. The rationale behind this is quite simple: Your data-members will usually contain useful information that may well be of interest to users of your class (say the number of elements in a container), but once you add a (trivial) setter you imply that the contained data are not involved in invariants with the other members of the class and as such there is no semantic connection to them. This also means that the story is different for non-trivial setters: If you setter performs checks before assigning values, it again means that your classes enforces some invariants on the contained data and thus has a greater semantic meaning that just a named tuple. Also: You really don't need trivial setters in C++: Just overload the getters to return a non-const reference for mutable instances: class point { public: int x() const {return m_x;} int&amp; x() {return m_x;} // ... private: int m_x = 0; // ... }; auto p0 = point{...}; std::cout &lt;&lt; p0.x() &lt;&lt; '\n'; // 0 p0.x() = 23; std::cout &lt;&lt; p0.x() &lt;&lt; '\n'; // 23 const auto p1 = point{...}; std::cout &lt;&lt; p1.x() &lt;&lt; '\n'; // 0 p1.x() = 23; // Error!
Also check out https://modm.io/ , also CRECT. Reference: https://embeddedartistry.com/newsletter-archive/2018/5/7/may-2018-c-embedded-frameworks
vector&lt;bool&gt; as a data structure is pretty awesome. vector&lt;bool&gt; as a name is terrible.
not all strings are std::string, there are like 5 or so now for each of the character types(char, wchar_t, char16, char32, and now char8), and two back then
Also, on getters: A shocking number of people seems to be unaware that you can overload methods for rvalues, allowing much more efficient by-value-getters: #include &lt;iostream&gt; #include &lt;string&gt; class foo { public: const std::string&amp; get() const&amp; { return m_str; } std::string get() &amp;&amp; { return std::move(m_str); } private: std::string m_str = "foobar"; }; int main() { auto bar = foo{}; auto s0 = bar.get(); // copy m_str std::cout &lt;&lt; s0 &lt;&lt; '\n'; //"foobar"; std::cout &lt;&lt; bar.get() &lt;&lt; '\n'; //"foobar"; auto s1 = std::move(bar).get(); // move m_str! std::cout &lt;&lt; s1 &lt;&lt; '\n'; // "foobar" std::cout &lt;&lt; bar.get() &lt;&lt; '\n'; //""; } 
You can look at [https://wg21.link/P0829](https://wg21.link/P0829) to see what I think should be in such a standard library.
I think an iterative approach sounds great in your case. Especially when most of the issues are design oriented, I think training is the right approach to communicate such a deep subject. Also I like starting with exposure to the core guidelines rather than enforcement. In your case maybe just teaching the core guidelines will be enough to keep the code satisfactory. I am looking forward to seeing your final approach! I still have a lot to learn myself, and your discussion and this thread have been very helpful to me.
That's not what I meant. I meant why don't these parts of the STL compile for the arduino?
I was curious, does STL in Arduino cause code bloat, or does the 'pay for only what you use' principle carry over well?
I would assume the following: - It uses the AVR assembler / compiler instead of MSVC - An arudino has limited ram and speed. The STL is not efficient enough. (imagine copying an entire class of function pointers + variables to ram... on a device with 4kb of ram)
depends on which STL member. A std::vector will never be as efficent on space as an array. int num[10] puts all the memory nicely in line. a vector has the memory nicely in line... plus a bunch of function pointers (methods), and various variables.
My condolences. I think every programmer goes through a phase of over-complicating our code. Fortunately, most of us grow out of it, and learn the wisdom of YAGNI. 
Never heard of that book. Those books are boring probably because of the way you are reading them. Don't try to read the book in its entirety and then use the language, this will just exhaust you. Best way to learn is to use it. Get the basics right, take up a project and use c++. Definitely at some point you will need additional constructs to do the task, that's when you must look through these books/online resources to see if there are tools in the language to accomplish what you want and learn that concept completely. Here, You may find this interesting: https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list
I'd take a look at the work /u/vector-of-bool has done in [putting together something of a consensus about best practices for setting up a library]( https://api.csswg.org/bikeshed/?force=1&amp;url=https://raw.githubusercontent.com/vector-of-bool/pitchfork/develop/data/spec.bs), at least in terms of directory structure. 
Not OP but also not following. Most of the stuff in the STL for template metaprogramming shouldn't even compile to machine code. The "template magic" here would be on the code generation side of the compiler, it shouldn't matter what the target is. 
Movable is pretty annoying because then you need a moved-from state and then the type is essentially nullable, which causes pain.
Neither of those make sense. The AVR compiler is either gcc or clang. They already have c++17 front ends and AVR backends. This has nothing to do with STL 'efficiency'. This is about parts that are templates and values.
The vote about ASCII is telling. Not that I see a particular need for special unicode characters. 
Changes? 
they increased the version number
You are technically correct. What kind of correct is that?
THE BEST KIND!
Well, I guess one question that should be asked is: Do typical arduino projects even need/profit from the stl?
&gt;so I can't just use a smart pointer for them Yes you can. Use unique_ptr with custom deleter. There is example for that on [cppreference](https://en.cppreference.com/w/cpp/memory/unique_ptr).
Well, technically, yes. 
Thanks, looks like this is what I'm looking for.
Ugh, PGP key given by short-id. [They haven't been safe to use in _years_.](https://evil32.com/)
There isn't a single function pointer in std::vector. It has however a pointer to the start of the allocated memory region and a size and a capacity member. Vector solves a different problem than a plain array.
Data breakpoint is not the same as condition breakpoint. Data breakpoints are hardware supported mechanism for stopping on changes done to no more than 8 bytes of data. Should not have much effect on performance. However as far as I know VS does not support stopping on read, so breakpoint on getter may still be of use.
a) as already said you can use smartpointers with custom deleters b) your constructor could delegate to another constructor, which just ensures that a complete object is created (because then the destructor gets called). you can see this in action here: https://stackoverflow.com/a/38780597/3783662 
You can also use delegating constructors: class A { T* member1 = nullptr; T* member2 = nullptr; // initialize one member only A(T* mem1) : member1(mem1) {} public: A() : A(create_mem1()) { // at this point A is already fully constructed // so if this throws the destructor is called member2 = create_mem2(); } ~A() { // we know that member1 always needs to be destroyed destroy_mem1(member1); // but member2 might not if (member2) destroy_mem2(member2); } };
Seems you misunderstand how classes are implemented in c++. Unless you have virtual functions (which are very rare in the standard library), there are no function pointers at all and even then, there is a single pointer per function in the entire program + one pointer per object that has a virtual member function (and it stays at one pointer overhead per object, even if it has dozens of virtual functions). Doesn't mean all parts of the standard library are suited for such small, embedded systems of course, but not for the reasons you seem to assume.
meh, PGP has always been a joke. Remember when GnuPG decrypted messages with a broken MAC and claimed that this is ok because it prints a warning? They broke rule #1 of cryptography. 
Least elegant way, but it has to be mentioned: you can use `try/catch`. But that should really be a measure of last resort. Usually I still would recommend smart pointers and other raii wrappers, so you don't even have to write a destructor at all.
I feel like I survived a mass psychosis with that one. OOP is great and the encapsulation works wonders when your objects are really self-sufficient entities that only communicate with each other through some interface. Like gen\_server in Erlang/OTP. Sure, if your data provider is in Munich and the analyser is in Berlin, they both have their own bulks of encapsulated data they don't share with each other. But if you they share the same address space, it just doesn't make any sense to make it look like they don't. Maybe it was some variation of cargo cult, I just don't know. I'm just happy to see that not doing things that you don't need is generally accepted these days. I wonder if I eat right and exercise, will I survive the "custom types", too?
what is a POD struct? I know what POD is (plain old data, so variables and arrays) but a POD struct?
`-ftrivial-auto-var-init=zero -enable-trivial-auto-var-init-zero-knowing-it-will-be-removed-from-clang` *Looks up the patch author* Yep.
Sound like CommandLineIO...
mmm... How do you actually calculate if code is similar? Do you consider renames or something? Any secret sauce you can share? (Or a paper to point us to)
A struct consisting of only POD
Shouldn't this be a link instead of text post?
Actually Semantic parses the code to find where the functions (and includes, etc) are. This is very important to avoid most of the conflicts that are simply related to position changes. If you move a function down, then a text based algorithm simply tries to match whatever was in the original location (the original function) with what is now there (the next function in the file, that has nothing to do with the original). But, once positions are calculated and the tree of components is handled and diffed, the bodies of the functions are treated as text. It means we don't calculate if two functions are the same based on the number of if/elses it has, or in the AST itself (which is not a bad idea, by the way) but in how similar the actual text is. We do some tricks for that like ignoring spaces and tabs and all that (it's code) but at the end of the day we use levenshtein distance to check how similar two fragments of code are. In fact, semanticmerge comes with a language-agnostic 3-way-merge tool, that we call Xdiff/Xmerge that is also able to track moved code just based on this levenshtein calculation: http://semanticmerge.com/features/#xdiff-xmerge
Well he did say arm, whereas you were probably thinking of avr when mentioning arduino. So it doesn't quite matter if he means feature or std lib. With things such as enable_if etc. the difference is hardly important anyway 
Yes, a couple of TAB were left after importing some code. Already fixed in the repo. Thanks.
Yes, some kind of demo/gif or something of the command line created by the example code would be extremely nice to have.
The only kind, technically. 
At least OP should have a decency of including a changelog.
As far as I know, you can have member functions, but you can't have constructors.
I thought the rule #1 of crypto was "you dont roll out your own crypto"... which technically every crypto lib out there is breaking... and I dont want to use libs that are breaking the rules :D
Good catch. If you want to enforce immutability on the client-side you can just modify the signature of the method that returns the last snapshot: shared_ptr&lt;const SensorAcquisition&gt; GetLastMeasure() const { // same as before }
I do not understand how methods are implemented. It must have a pointer to instructions somewhere in ROM, otherwise how fo methods get called?
I have an ongoing effort to make libcxx usable on avr controllers (not Arduino specifically, but I suppose it could be used there). Most of the stuff work right now, such as type traits, `&lt;algorithm&gt;`, `std::array`, `std::tuple`, `std::vector`, `std::map`, `std::optional`, `std::variant` etc. The major problem I'm running into is avr-libc. For instance, `&lt;cmath&gt;` in libcxx just does `using ::llrintl;`, however, avr-libc does not provide almost any of the floating point functions. However, it prevents the `&lt;cmath&gt;` header from compiling. I could remove those lines conditionally, or just place the declarations of those functions to work around them. Perhaps another libc implementation could be used instead of `avr-libc`, however I haven't looked into it yet. Another problem is with the locale stuff of `&lt;iostream&gt;`, which avr-libc lacks, however, I'm not planning to use `&lt;iostream&gt;` ever, so it has a lower priority. As expected, standard library stuff emits the same code as my hand written versions of stuff I've written before I ported the standard library. Other than these problems, I just can't live with the absence of the standard library, so I absolutely think it's a worthwhile effort.
The changelog is secret. Use the source, Luke!
They forgot to link (or build?) binaries. They also forgot to link to the documentation. They also forgot that they didn't want to use the 7.x.y scheme anymore, but wanted to change to a two-number scheme, 7.x. So this would be 7.1.
I mostly agree with article: having a bunch of trivial getters and setters instead of a struct is really just boilerplate that doesn’t help either the readability or improve the design. But - when you have a bunch of code that uses this struct, and then you have to add some setter logic (such as limit the range of a variable, trigger a callback, etc), you suddenly have to change a whole bunch of client code... So, many times I’d go for the boilerplate of the getters/setters as soon as I realize that the ‘clients’ of this class might not want to be exposed to breaking changes I might introduce.
In the section "What if some of the data belongs together?" he says "Those two variables belong together, so they deserve their own structure or class." That's weird. They are in the struct/class that they are because they belong together. Now he's advocating just pushing the problem further down, not solving it. class PointOnTheUnitCircle { private: double x,y; public: void setx( double xx ) { if ( abs(x)&gt;1. ) throw(something); x = xx ; y = sqrt( 1 - y*y ); }; void sety(/* similar */ ) ; } An object in a program stands for a conceptual object, which is (partly) defined by a predicate. Setters are there to enforce the predicate.
There's the header-only library [randutils](https://www.reddit.com/r/cpp/comments/34yqxa/announcing_randutils_a_single_portable/) that abstracts &lt;random&gt; into a much simpler API.
&gt; They also forgot that they didn't want to use the 7.x.y scheme anymore, but wanted to change to a two-number scheme, 7.x. So this would be 7.1. They also had an GCC ABI compatibility issue which they want to fix in a true 7.1.0 right after this release, so it didn't really work out as they planned.
That is correct for functions at runtime (if you exclude inlining etc.), however the topic concerns compile time constructs, which do not appear in the final binary. The STL however also contains a lot of constructs that can be used at compile-time. For example `&lt;type_traits&gt;` contains a lot of useful things for template metaprogramming, that will never end up being present in the final binary (as the compiler evaluates those constructs directly). Those things however are not available on Arduino right now. 
Wow that's awesome! Would / could you ever consider publishing some of that work under a permissive license? Whatever lib I end up putting together, it's probably going to be a mish mash of different sources under an umbrella of some sort of MIT or BSD or Boost license. ATM my thought was to take an [existing port of STLPort](https://github.com/vancegroup/stlport-avr) to avr (which as far as I can tell was last updated for the C++11 standard) and use as many existing implementations of the newer functionality as I can to fill in the gaps, implementing myself (at least initially) only what I absolutely had to. My intention was to try and lean on as many "feature backporting" libs to source these library features. Probably wouldn't be the most performant STL implementation initially, but I think completeness (which would include benchmarking and tests) would be a good stepping stone towards optimization.
There is no difference between how normal function calls and calls to (non-virtual) member functions (I guess that is what you mean by methods) work. You write `foo()` and the compiler/ linker essentially translates this to a jump to the address of foo (in case of an arduino it knows that address at compile/link time). Further more the template meta programming facilities people are talking about are more or less compiletime only constructs that never get emitted into the binary at all (just their result).
&gt;Well, I guess one question that should be asked is: Do typical arduino projects even need/profit from the stl? Typical ones less so, especially since the platform is so accessible there's a good bet that a none-ignorable percentage of users don't even know how to use C++ templates. However I do think that it could be a very useful tool for Arduino library implementers, as well as some more complex projects.
&gt;That's not what I meant. I meant why don't these parts of the STL compile for the arduino? Honestly it's not that they necessarily don't compile, it's that a package of those features ready for deployment in arduino in a manner that would be compatible with other code that depends on the STL doesn't exist ATM.
That's starting to make some sense
I'll definitely look into it. Thanks!
&gt;Generally though, whatever you do, you are always going to be at odds with STL's default assumption that heap nd exceptions are available, and poor adaptability for anything else. Yes, you can have custom allocators that don't touch the heap, but handling out-of-memory conditions from say a pooled allocator is still tricky, because it would require exceptions. As a starting point I'd probably call anything that would be an exception but can't be in Arduino due to the platform limitations undefined behaviour. At least in the initial version of the library. It's far from a good solution but I think it's half decent as a step 1. I'd also probably stay away from anything that uses the heap in the STL at least initially. What I'm missing here mainly is the templates and algorithms in the stl, as well as the safer fixed sized structs like std::array (which can also be built on the heap... so maybe not exactly that one).
Not a single reference to smart pointers :(
&gt; ProductManagementTool program for Qt 5 language Qt 5 is not a language.
I intend to keep improving this reference and covering more topics including smart pointers. And I'm open to any helpful idea, suggestion and contribution.
Oh, i fixed that. Ty. :)
You should at least expand your Memory Management section with smart pointers. Adding a section on Algorithms would also be nice. Currently, it reads more like a C with classes reference.
Thanks for posting this link.
I'll be working on it, thank you for the feedback.
Agreed, memory management section should start from smart pointers and then add raw pointers with a huge warning note. Also, I suppose that "new replaces malloc and delete replaces free" isn't quite correct because they not simply allocate and release memory, but also call constructor and destructor. And a huge note that new and new[] must match delete and delete[], otherwise it is UB.
\&gt; They forgot to link (or build?) binaries. &amp;#x200B; IIRC binaries are done on somewhat volunteer basis. So officially release is out as soon as signed sources are out
 // throws an exception of type "string" throw "ERROR: Cannot divide by zero.\n"; guess again
Promoting my 2 cents... * Folding Monadic Functions http://cpptruths.blogspot.com/2017/01/folding-monadic-functions.html?m=1 * Dependently Typed Curried Printf http://cpptruths.blogspot.com/2016/11/dependently-typed-curried-printf.html?m=1 * Compile/Run-time Property-based Testing http://cpptruths.blogspot.com/2017/12/ground-up-functional-api-design-in-c.html?m=1 
Ouch, all text is in Turkish and you don't even use Qt's i18n features. 
I've not used UML for many years, but how good are they now at generating UML from C++/Qt code ? Or can they generate C++/Qt from UML?
Any note for new clang feature for cpp20?
That's what I thought, looks even better then. I really like the approach with the `shared_ptr` to give access to readers, simple, elegant and fool proof.
Thank you for pointing that out. I'll fix it right away.
Thank you for this helpful feedback.
is there something very wrong with. setters and getters in POD structs?
Another way is you can print http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines to pdf
Things is, there are not that many parts in the standard library that are useful on an arduino to begin with and because the standard library types are extremely generic, a conforming implementation is much more complicated than usually necessary. If you really do need meta-programming facilities (constexpr and auto got rid of many usecases), then maybe you should just concentrate on those.
A lot of people will read Remote as "anywhere in the world", because half of US companies mean that when they say remote, but the other half actually mean "remote anywhere in the US for US citizens only". Not being specific wastes your time and our time.
I have been using [StarUML](http://staruml.io) I'm not sure if Qt5 is supporting to export the **UML**. You can check [QtModelling](https://wiki.qt.io/QtModeling)
:D You are right. I did not have time to complete project. The project was must to be in Turkish language, and I transtaled it into English when I was pushing it to **GitHub**. :)
all right, next thing I clicked was the [SimpleVector.h](https://github.com/utkuufuk/cpp-quick-reference/blob/master/examples/SimpleVector.h) example using namespace std; That's a header file! [SF.7: Don’t write using namespace at global scope in a header file](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rs-using-directive) // default constructor SimpleVector() { arrPtr = 0; arraySize = 0; } [C.49: Prefer initialization to assignment in constructors](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-initialize) (applies to all your constructors) and [http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-in-class-initializer](C.48: Prefer in-class initializers to member initializers in constructors for constant initializers) (applies to this one in particular) I see a copy constructor and a destructor, but where is `operator=` ??? [C.21: If you define or =delete any default operation, define or =delete them all](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rc-five) and [Rule of Three (cppreference)](https://en.cppreference.com/w/cpp/language/rule_of_three) T getElementAt(int position); so I if I have a `const SimpleVector` (typically seen as a `const SimpleVector&lt;T&gt;&amp;` in some function argument), I can't access any of its elements. SimpleVector&lt;T&gt;::SimpleVector(int s) { arraySize = s; arrPtr = new T[s]; [...] SimpleVector&lt;T&gt;::~SimpleVector() { if (arraySize &gt; 0) { delete [] arrPtr; So if I create `SimpleVector&lt;int&gt; v(0);`, I get a guaranteed memory leak ==28378== 0 bytes in 1 blocks are definitely lost in loss record 1 of 1 
std::visit is often discussed in here and slack etc. https://www.reddit.com/r/cpp/comments/9khij8/stdvariant_code_bloat_looks_like_its_stdvisit/ https://www.reddit.com/r/cpp/comments/7pya5s/stdvisit_overhead/ https://www.reddit.com/r/cpp/comments/703k9k/stdvisit_is_everything_wrong_with_modern_c/ and from what I know, there are no (published) papers for std::visit 
Is the Boost Library Incubator still active? I submitted a library years ago and never got any feedback...
What about moving the common stuff out of the variant? struct Common { Position position; View view; }; template&lt;class Data&gt; struct Specific { Common common; Data specific; }; struct Variant { Common common; std::variant&lt;SpecificData1, SpecificData2, ...&gt; specific; template&lt;class Data&gt; Variant(Specific&lt;Data&gt; const&amp; s) : common(s.common), specific(s.specific) {} template&lt;class Data&gt; Variant(Specific&lt;Data&gt; &amp;&amp; s) : common(std::move(s.common)), specific(std::move(s.specific)) {} }; ?
Right. A Pattern is not a library, but an "idea", and the 'Implementation' section is there just to better understand the pattern, but eventually is the reader job to understand the pros and cons and the trade-off of each implementation, and choose the best fit for its needs. The method `GetLastMeasure()` results in very few assembly instructions, and the timer is sized with a large amount of time so -- unless you mess up very badly with thread priorities -- you are safe. That being said, if I had the chance to write again the article, I'd point up this aspect of the lock-free implementation example and warn the reader. I thank you very much for giving me the opportunity to explain better this subtle aspect.
You need Qt.
Anyone knows the name of the libraries suggested at the QA time? I didn't understand the names.
It's a good idea. I tried asciinema and shot a recording, but I wasn't able to play it in a github markdown file. Any help is welcome. Eg. it would be great if someone could provide me the [README.md](https://README.md) of the project modified with the recording inside :-)
In a patch-version release? :) For 7.x itself, see https://clang.llvm.org/cxx_status.html. Anything in green was already in 7.0, and anything else may come in 8.x but all bets are off (even if it says its in SVN already; it may not make it into the next release window). The release notes at https://clang.llvm.org/docs/ReleaseNotes.html are for the upcoming release and has _some_ stuff filled in but nothing about C++ language changes. On a side note, I really dislike how the version-unadorned release notes page goes to the incomplete _upcoming_ release notes instead of going to the complete _last official version_ release notes.
I wouldn't say very, other than you're adding more code to a potentially pretty huge project. Also performance matching direct member access is often imperfect and dependent on optimizations which in turn depend on you not writing anything in the getters/setters that might cause the compiler to skip on that optimization.
Besides moving the common stuff into a position where it can be accessed without having to go through visit, you can also try a visitor that uses if-else chains but unrolls multiple at a time. So instead of splitting a type list in head and tail, you split it in A, B, C, ..., H, Tail and use an if/else or switch to determine those types, otherwise handle tail. I found a performance increase when doing that.
That is really cool. I didn't know about those.
Well you don't *need* Qt but it sure as shit will make life easier that is for sure. 
Sounds quite complicated for someone who is new to C++. You are asking about client server, GUI, installers, update ability. Which is a LOT of things to develop. The fact that you are asking if C++ is right for the job - tells that you might not be ready for it right now. It seems that you are still learning the language and programming in general, consider to start with some simpler things.
A) There are no-throw accessors to variant, namely `get_if`. You can also query `index` or `holds_alternative` before actually accessing. B) This has been beaten to death already. It's very, very rare to have a variant with invalid index; you'd need to get an exception and ignore it. It's not ideal but neither are objects with throwing move constructors. If you're confident that you don't have any objects with throwing moves, then I think the way most implementations are written, the invalid state isn't possible. C) That's not true; you can write whatever code you want utilizing techniques described in A. D) That is a weird requirement, I agree. I'm currently helping out with trying to improve the implementation of variant and we're trying to see how much of a hard requirement this is. I think implementations will basically end up ignoring this, but we'll see. On top of all that, your basic type design just doesn't make sense. There's no reason I can think of to have data common to all types in the variant, or to use that weird inheritance based approach. ``` struct Token { Position position; std::variant&lt;WhiteSpaceToken, OtherToken, YetAnotherToken&gt; token_variant; }; ``` Where the classes `WhiteSpaceToken` and co do not inherit from anything or contain a `Position` member.
Which of the standard algorithms do you actually need though? You are not going to sort huge arrays of data on an arduino, so the difference between a std::sort and your own naive insertion/bubble sort is probably not all that big. Not saying a stl on arduino wouldn't be nice, but a couple of specialized libraries (with a better Interface than c++17 stl) would imho be more useful.
If I am not mistaken this looks like my first code example. But when I use these tokens in a parser, it gets really cumbersome to send both a reference to the common part and a reference to one of the specifics down through the call stack. This started my journey down the \`std::visit\` rabbit hole.
I'm really not a fan of PDFs on Kindles. Usually the text is way too small and I've had a really hard time zooming which is why I wanted a real epub/mobi file. I've also found that PDFs don't convert well to epub/mobi as well (I used Calibre)
Thank you for digging up all these links. I know I am not the first one to recognize this. I guess \`std::variant\` was adopted too early and now is somewhat doomed. Maybe we lack the necessary abstractions in C++ to implement an optimal \`std::variant\` that also works in all edge cases. \`std::visit\` and overloaded visitors in practice feel a bit awkward. For example it's quite hard to break a surrounding loop. Also Coroutines suffer from the extra function layer. Unfortunately, I cannot offer a good solution right now. - Let's go back to the drawing board!
It's posted now - https://www.youtube.com/watch?v=UnuAXlTL2pM
&gt; They also forgot that they didn't want to use the 7.x.y scheme anymore, but wanted to change to a two-number scheme, 7.x. So this would be 7.1. Lattner explicitly said the opposite: http://blog.llvm.org/2016/12/llvms-new-versioning-scheme.html
With my proposal of a fold of the ternary operator ?: (see https://github.com/zingsheim/ProposalTernaryFold/blob/master/ProposalTernaryFold.md or https://wg21.link/p1012) your fold implementation could be implemented shorter and without the hack of using an optional which prevents RVO. The implementation would then be simplified to: // fold based visit template&lt;class F, size_t... Is&gt; auto visit_fold_impl(F&amp;&amp; f, std::index_sequence&lt;Is...&gt;) const { return (Is == index ? f(raw_get&lt;T&gt;()) : ... : f(raw_get(FT{})}); // fallback / error } 
`variant` is meant for those places in code where you might have had a struct containing a type and a union of values. It does that pretty well. It also let's you separate behavior from the types, store and pass only loosely related types around, etc. It wins over switching on a discriminator value from a code writing and maintenance perspective. Also, can be better for performance than stuffing everything into containers of pointers to a common base. You seem to be mixing the common base OO style with variant. For your code, I'd probably have a single token class containing the common data and a variant for the specific behaviors. I don't think variant is broken, but it is one of those things that's easy to use poorly.
Thank you for your reply and your work on this topic! A) \`get\_if\` solves the enforced exception issue. But it is not enough here, because it still enforces a check. Basically we need something like, reinterpret the content of the \`std::variant\` as if it was initialized with a given type. See [godbolt.org/z/WJavVr](https://godbolt.org/z/WJavVr) \- I added a \`fast\_visit\` with \`std::get\_if\` at the bottom. \+ Much better than \`std::visit\` \- clang produces a stupid jump tables \- msvc is unable to resolve the condition chain \- All compilers add conditions. B) I think I did not get my point through. The index is an integer. An exhaustive variant would be usable with every value. Right now we have -1 and zero up to \`sizeof...(T)-1\` used. \`std::visit\` will have to error for all other states. So either we are allowed to assume they never occur, we have to always live with the check or we make the variant valid with all values. We might add a check from outside if the index is in the valid range, but prefer not to check on every usage. C) Agreed, if you dare to write your custom \`visit\` implementation. &amp;#x200B; &gt; On top of all that, your basic type design just doesn't make sense. This was my old \`Token\` [github.com/rebuild-lang/REC/scanner/Token.h#L86](https://github.com/rebuild-lang/REC/blob/4d56d495c8bc52bb5187e26ff04126e610fda8ec/scanner/Token.h#L86) Which leads to awkward implementations: * [github.com/rebuild-lang/REC/parser/filter/Parser.h#L159](https://github.com/rebuild-lang/REC/blob/4d56d495c8bc52bb5187e26ff04126e610fda8ec/parser/filter/Parser.h#L159) * [github.com/rebuild-lang/REC/parser/expression/Parser.h#L114](https://github.com/rebuild-lang/REC/blob/4d56d495c8bc52bb5187e26ff04126e610fda8ec/parser/expression/Parser.h#L114) \- \`it.current()\` is repeated, to prevent double capturing as \`++it\` is also used. Therefore I switched to a new \`Token\` design. [github.com/arBmind/REC/lexer/scanner.data/Token.h#L49](https://github.com/arBmind/rebuild-experimental-compiler/blob/develop/src/lexer/scanner.data/scanner/Token.h#L49) This allows for a cleaner implementation: * [github.com/arBmind/REC/lexer/filter.lib/filterTokens.h#L79](https://github.com/arBmind/rebuild-experimental-compiler/blob/develop/src/lexer/filter.lib/filter/filterTokens.h#L79) \- no captures required * [github.com/arBmind/REC/parser.lib/Parser.h#L212](https://github.com/arBmind/rebuild-experimental-compiler/blob/develop/src/parser.lib/parser/Parser.h#L212) \- \`it.current()\` is only used once. It feels much better. Most places use \`std::visit\` anyways, but they still suffer. Only one or two functions use the pattern I used for testing. I hope we can somehow fix \`std::variant\` or come up with an implementation that allows full optimizations and readable code.
I like the semantics of \`variant\`. They help me to write better, cleaner and faster code. I agree. When you have a closed system - like tokens types in a parser - the Variant wins any day over OOD. The inheritance was just used to shorten the code examples above - not to build object hierarchies. If you look into the [godbolt.org/z/aXef8w](https://godbolt.org/z/aXef8w) you see that it does not matter here. The idea of a \`variant\` is not broken. But it could and should generate faster assembly.
\+1 This would enhance many other code generating functions as well. I hope it will make it into C++20. Fixing \`std::visit\` one step at a time.
&gt; as well as the safer fixed sized structs like std::array (which can also be built on the heap... so maybe not exactly that one) What does this mean..? If you're excluding every type that works with `new` then you're excluding literally _every_ type. Even `int`. What makes `std::array` special?
I just had a quick look, but it looks like you are using JSON as the language to describe projects. The unfortunate part about this is JSON does not have native means of including comments. I cannot imagine maintaining even a slightly complex package build without comments in the definition file. 
See the second half of my comment about the design - [https://www.reddit.com/r/cpp/comments/a8bmpn/stdvisit\_unable\_to\_generate\_optimal\_assembly/ec9sofk](https://www.reddit.com/r/cpp/comments/a8bmpn/stdvisit_unable_to_generate_optimal_assembly/ec9sofk) I saw the \`switch\_visit\` implementations. My guess is, that they enhance the compile time and reduce the nesting for the optimizer. I fear my examples are too small to see a real benefit.
I like the #pragma push/#pragma pop solution
[Just going to leave this here](https://xkcd.com/927/)
One of the things to keep in mind is that `variant` is a library feature rather than a language feature. The implementation is to basically unpack the object based on the discriminator and call the visitor on the wrapped type. That basically guarantees that it's going to instantiate the template for each type in the variant. In theory, the compiler could inline everything and then do some sort of duplicate code elimination, and maybe with more uses in the wild, compilers will start to do that. It's a fairly new library type, though. I do know some of the pre-standard versions that people wrote jumped through extra hoops to try and squeeze more optimal code out of the compiler.
Thank you very much for your time and feedback. The truth is I began working on this reference when I started learning myself last year. I can't possibly claim to have mastered any language in a year, especially when it comes to C++. I didn't know the rule of three, so I looked around a bit and tried to fix the problem that you mentioned. I'm not 100% sure if I got it right so I'd appreciate it if you could take a look at it when you have time: [https://github.com/utkuufuk/cpp-quick-reference/blob/master/examples/SimpleVector.h](https://github.com/utkuufuk/cpp-quick-reference/blob/master/examples/SimpleVector.h)
Given that you're proficient with C++, why do you use the Arduino software part at all? It's pretty clearly aimed at people who are small time hobbyist programmers at best and are not comfortable writing native embedded code.
Well, there can be "comment" objects members, but still your point stands.
I was trying to port some standard c++ library parts to the platforms where the implementation is not available (ie. Arduino). But I was mostly focused on type\_traits and other things which does not require allocations (so I didn't even try to port containers). [https://github.com/lukaszgemborowski/cpptoolbox/tree/master/include/toolbox/std](https://github.com/lukaszgemborowski/cpptoolbox/tree/master/include/toolbox/std) This part consist of snippets found on SO, cppreference etc (so I'm not 100% sure about the licensing ...) or occasionally written by me. I've tried to mimic tuples, arrays and couple of other "static" containers: [https://github.com/lukaszgemborowski/cpptoolbox/tree/master/include/toolbox/container](https://github.com/lukaszgemborowski/cpptoolbox/tree/master/include/toolbox/container) &amp;#x200B; Maybe this will somehow be helpful to you.
I'm so very tired of that comic. It is constantly used to promote the idea that no one should try to do anything resembling anything that has been done before and that new users should do whatever is popular solely because it is popular in a feedback loop forever.
Not all of my clients share my level of proficiency with C++, and I'd still love to be able to produce libraries for them that can leverage template metaprogramming internally.
I use parson as the parser for the JSON files, which has support for \`/\* \*/\` and \`//\` style comments.
I said "heap" not "new". What makes array special is that its fixed size is known at compile time, and can be allocated on the stack. Now there are all sorts of none traditional heap allocators you could get to work well on arduino (pretty sure there's even a half decent implementation of new / delete in some versions) for other containers. However, most of those containers already existed in c++11 and earlier, and already exist in some form in the existing implementations of STL for arduino, what's lacking is the updates to the standard library from C++17, where I've felt that most is in the realm of template metaprogramming.
&gt;It wins over switching on a discriminator value from a code writing and maintenance perspective That's what I used it for, it made things a little more robust and helped cut out some edge cases. Maintenance was definitely easier... until I tried to compile the code on Mac, and discovered AppleClang doesn't really support it. Then sometimes on Linux the library implementation spits out really weird compiler errors, which was fixable (but I forgot the fix for). Ultimately I'm trying to move to some third-party single header implementation of `variant` lol, and the whole thing has kinda backfired. But the initial premise was good!
Why JSON? In my experience, anything beyond simple data structure quickly becomes a pain to express in JSON. Build systems often need to specify conditions, actions and other type of logic. JSON is not ideal for expressing logic. Look at GYP which was used to build Chromium, for example. They quickly realized how unwieldy JSON can become and switched to GN which allows to include logical statements as part of the build description. Your examples are very simple, but you should try to port any real world project to your bake and see how easy (or rather difficult) it is.
I think you may have misunderstood the intent of the project. Bake is not trying to replace or abstract existing build tools. When I started the project, I didn't even intend for it to be a standalone tool. You'll find it is a different approach to building code. Bake imposes a fixed structure on C/C++ projects, and uses well-defined conventions for things like naming and referring to projects. It's not a one size fits all. If you want total control over your build, bake is not for you. If you're ok giving up a bit of control, bake could save you a lot of time.
Boost.Variant is never empty and therefore there is no exception during visitation. And implements visitation as an if-else chain, which seems to be easier to optimise. In some cases the compiler can remove the whole visitation code, for example when the variant stores several classes with the same base class, and you do a static cast to the base in the visitation. I tried that on godbolt a while ago. It worked with gcc but not clang. You could try one of the many other variant implementations out there, see https://cbeck88.github.io/strict-variant/strict_variant/remarks/benchmarks.html
This is a good point, and is indeed an issue I ran into. I've used `rake` before, because I thought having the full expressiveness of a scripting language (ruby) would give me more flexibility. In reality though, I found that not using a declarative language for configuration makes it difficult to port to other platforms. With bake I switched back to a fully declarative design. To deal with the complexity, bake has a few mechanisms that should keep it manageable. Time will tell if they are sufficient. First of all, you can add conditions in your configuration, like so: ``` { "id": "my_app" "type": "application", "lang.c": { "${os linux}": { "lib": ["pthread"] } } } ``` The `${os ...}` expression is a bake function. Right now there is a limited set of functions available that lets you filter on operating system, platform and language, but I expect more in the future. As you pointed out however, for complex configurations with lots of conditional logic, JSON quickly becomes unwieldy. To address this, I added a feature to bake that allows you to encapsulate settings in configuration-only packages, like this: ``` { "id": "threading" "type": "package", "value": { "language": "none" }, "dependee": { "lang.c": { "${os linux}": { "lib": ["pthread"] } } } } ``` The settings in the `dependee` object are applied to all projects that specify `threading` as a dependency. Thus, I could now change my previous project configuration to this: ``` { "id": "my_app" "type": "application", "value": { "use": ["threading"] } } ``` The `use` field being how you specify dependencies in bake. That doesn't solve the whole issue though. In some cases you'll want to execute custom logic at the beginning, end or during the build. To address this, bake has a modular design, where projects can load multiple drivers that each take responsibility for a certain part of the build. These drivers can (and will) contain platform specific logic, which keeps the project configuration clean. 
This is even worse. 
Sadly if you actually mark the data members const, then you lose performance during moves.
How about YAML? It's kind of like json but with comments. The only unfortunate thing is that there is no header-only, modern YAML parser library for C++... There's "only" yaml-cpp. (Which is great, but we do need a more lightweight, header-only, modern YAML parser.
&gt; I said "heap" not "new". Surely you realize that C++ itself has no concept of "heap" – it has static, automatic, and dynamic storage. Dynamic storage is commonly referred to as the heap, but `new`'s the only legal way to get it.
Yay structured bindings support!
I'll just leave this here... [https://bakefile.org/](https://bakefile.org/)
The source code is available at the following address: https://github.com/PardDev
Structured binding makes the API really nice! It's funny to think that the convenient syntax that PHP had since 1999 is only possible since C++17. For instance, in PHP ``` $entries = json_decode($str) foreach ($entries as $key =&gt; $value) { // do something with $key and $value } ``` Of course in PHP it's baked into the language and in C++ it is more flexible, but still. And also it's funny that Javascript does not have this convenient way of iterating (not even in ES6). It's either `for (value of entries)`; or `for (key in entries)`; or -- `for (let [key, value] of Object.entries(entries))` in ES6.
Tradeoffs abound. For small structs and collections with bounded size I'd prob prefer value semantics and stack allocation and moves wouldn't matter. If I did need vector I'd write it correctly first then benchmark it. Then I'd start loosening up to suit my needs. 
It's ridiculous how good this lib is.
Listened to the podcast, and Pablo sounds very nice, and I wish him all the best; but this episode had almost nothing to do with C++, and just felt like a big advertisement. Maybe it's just me. 
Can you sell it to me why I should use it instead of Conan + CMake?
I mean, JSON5 exists as a formal standard. Maybe worth a full switch? 
How about a lib which you might find useful or you might use in the future. The lib should have a documentation and examples, just add another example. You will automatically find issues with the documentation and maybe with the interface.
Also https://en.m.wikipedia.org/wiki/BitBake
Why don't you try it out, and see which approach you like better ;-)
Why does it need to be header-only?
C++ doesn't know what a heap is but the std lib does via the allocator type passed to the container. Even if the vector object or map object or set object or list object you use is allocated on the stack, **the contained objects are allocated on the heap** (unless we're dealing with a short string optimization type scheme which is its own can of worms). Not to mention new is not the only legal way to get dynamic memory, you can use malloc or calloc or whatever the zeroed memory one is, not to mention all sorts of allocation schemes such as pools that take that dynamic memory or a pre allocated roll of static memory, or that troll one that uses rand to create fake pointers, and distribute it. Std array **does not** use heap allocation to store it's contained objects. At the very least a naive implementation of it doesn't. Its contained values are allocated as part of the container's allocation. If it is put on the heap they will be. If on the stack they will be on the stack. It is ambivelent to whether it and its members are on the stack, heap, static memory, etc. It's more or less a safer way to access a c style array, which uses std container semantics.
Every major compiler has a way to mark code as unreachable. if(index==-1) unreachable; where `unreachable` is defined to be whatever your compiler wants. 
Honestly? Not having to rewrite, maintain and debug my naive implementation every time is more important to me then the performance boost. 
See also this [stackoverflow question](https://stackoverflow.com/q/47383563/149138) about the same issue, and especially the first answer which shows hope with a custom visitor.
&gt; D) The standard requires a that std::visit for on std::variant has a complexity of O(1). It's true that the standard says that but it isn't true that this forces a jump table implementation. O(1) just means that it's a compile time constant, since any constant under big Oh analysis falls out. A search over the type space is allowable so long as it is bounded by a finite number of steps, which the compilers already "helpfully" provide by having limits on the number of template parameters that can participate in a pack. In VS 2019, Casey Carter taught our variant implementation to use switches instead of function pointer tables for N &lt;= 128 (if I recall correctly), so the output is much nicer now. #include &lt;variant&gt; #include &lt;math.h&gt; struct functor { double operator()(int x) { return sin(x) + cos(x); } double operator()(double x) { return sin(x) + cos(x); } }; double test(std::variant&lt;int, double&gt;&amp; v) { return std::visit(functor{}, v); } Now generates cmp instead of a jump table: ; Function compile flags: /Ogtpy ; COMDAT ?test@@YANAEAV?$variant@HN@std@@@Z _TEXT SEGMENT $T1 = 80 v$ = 80 ?test@@YANAEAV?$variant@HN@std@@@Z PROC ; test, COMDAT ; File C:\Users\bion\Desktop\test.cpp ; Line 9 $LN70: 00000 48 83 ec 48 sub rsp, 72 ; 00000048H ; File C:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\VC\Tools\MSVC\14.20.27215\include\variant ; Line 888 00004 48 0f be 41 08 movsx rax, BYTE PTR [rcx+8] ; Line 1486 00009 48 83 c0 01 add rax, 1 ; Line 1603 0000d 74 47 je SHORT $LN14@test 0000f 0f 29 74 24 30 movaps XMMWORD PTR [rsp+48], xmm6 00014 0f 29 7c 24 20 movaps XMMWORD PTR [rsp+32], xmm7 00019 48 83 f8 01 cmp rax, 1 0001d 74 06 je SHORT $LN15@test ; File C:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\VC\Tools\MSVC\14.20.27215\include\type_traits ; Line 1418 0001f f2 0f 10 31 movsd xmm6, QWORD PTR [rcx] ; File C:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\VC\Tools\MSVC\14.20.27215\include\variant ; Line 1603 00023 eb 08 jmp SHORT $LN67@test $LN15@test: 00025 66 0f 6e 31 movd xmm6, DWORD PTR [rcx] ; File C:\Users\bion\Desktop\test.cpp ; Line 5 00029 f3 0f e6 f6 cvtdq2pd xmm6, xmm6 $LN67@test: ; Line 10 0002d 0f 28 c6 movaps xmm0, xmm6 00030 e8 00 00 00 00 call sin 00035 0f 28 f8 movaps xmm7, xmm0 00038 0f 28 c6 movaps xmm0, xmm6 0003b e8 00 00 00 00 call cos 00040 0f 28 74 24 30 movaps xmm6, XMMWORD PTR [rsp+48] 00045 f2 0f 58 f8 addsd xmm7, xmm0 00049 0f 28 c7 movaps xmm0, xmm7 0004c 0f 28 7c 24 20 movaps xmm7, XMMWORD PTR [rsp+32] ; Line 11 00051 48 83 c4 48 add rsp, 72 ; 00000048H 00055 c3 ret 0 $LN14@test: ; File C:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\VC\Tools\MSVC\14.20.27215\include\variant ; Line 1603 00056 48 8b d1 mov rdx, rcx 00059 48 8d 4c 24 50 lea rcx, QWORD PTR $T1[rsp] 0005e e8 00 00 00 00 call ??$_Dispatch@Ufunctor@@AEAV?$variant@HN@std@@$00@?$_Variant_dispatcher@U?$integer_sequence@_K$0A@@std@@@std@@SAN$$QEAUfunctor@@AEAV?$variant@HN@1@@Z ; std::_Variant_dispatcher&lt;std::integer_sequence&lt;unsigned __int64,0&gt; &gt;::_Dispatch&lt;functor,std::variant&lt;int,double&gt; &amp;,1&gt; 00063 cc int 3 $LN66@test: ?test@@YANAEAV?$variant@HN@std@@@Z ENDP ; test _TEXT ENDS
It's also not even remotely applicable here. This isn't an attempt at a meta-thing that makes all the existing things obsolete.
There should be a rule for those videos that you have to add a 5 minute disclaimer "doing this is a bad idea and you should not do it unless you are a professional who knows what you are doing". if you actually want to make a game pick a game engine and you won't have to bother with all that little stuff that nobody likes to do. ( https://github.com/collections/game-engines ). if you are intersted in making a game engine for windows, go for it. Even though as somebody who loves linux and games i'd say there's no place for this project in 2019, DX11 and the WINAPI? That won't get my seal of approval. 
...or [this](https://docs.freebsd.org/cgi/getmsg.cgi?fetch=506636+0+archive/1999/freebsd-hackers/19991003.freebsd-hackers+raw)
You cannot just claim that O(n) is O(1) when N is finite. All values for n are ultimately finite in every practical sense, but nobody in their right mind will claim you can do a bubble sort in O(1) because there is a finite number of elements in the array. If there is some activity going on that takes a different number of steps depending on the number of types in the variant, that counts as O(n), even if there is a low upper limit for n. &amp;#x200B; &amp;#x200B;
I agree completely. Header-only is a scourge. It trades one-time convenience of installation for an eternity of increased compile times - a shitty tradeoff, if you ask me. 