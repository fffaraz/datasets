I hope I never have to work with whoever wrote that article :/
If you are making your own memory manager you must overload ALL of these or else you get some fun bugs: void * operator new(size_t size) throw (std::bad_alloc); void * operator new(size_t size, const std::nothrow_t&amp;) throw (); void * operator new[](size_t size) throw (std::bad_alloc); void * operator new[](size_t size, const std::nothrow_t&amp;); void operator delete(void * ptr) throw (); void operator delete(void * ptr, const std::nothrow_t&amp;) throw (); void operator delete[](void * ptr) throw (); void operator delete[](void * ptr, const std::nothrow_t&amp;) throw ();
You shouldn't use f after calling its destructor, anyway. It's not in a valid state any more.
YES. I remember it like a binary tree: new &amp; delete, array &amp; non-array, throw &amp; no-throw. I've found that the set that most people don't replace - in fact the set that a lot of people aren't even aware of - are the nothrow versions. I work in embedded systems, and I'd say at least half of them are compiled with exceptions disabled (hopefully this doesn't turn into a war over the merits of using exceptions...)
**Edit:** So it seems I got a few things wrong. Look at [grayfade's post](http://www.reddit.com/r/cpp/comments/fo6gj/reddit_could_you_explain_the_difference_between/c1hdt68) for more and better information. ~~x86 means the processor is in the family with the 286, 386, 486, Pentium, Core, and Xeon processors. i686 typically refers to Pentium or higher processors from that family. If you're talking about 64-bit programs, then the term you are probably looking for is either amd64, x86-64, or x64.~~
Good answer. Thanks!
Not quite. i686 is x86. x86 is used to denote processors which evolved from Intel's 8086. In the context of 32-bit vs. 64-bit instruction sets, the term x86 is often abused to imply 32-bit, even though corresponding 64-bit architecture is also technically x86. As a term it's pretty heavily overloaded. edit: [Here](http://gcc.gnu.org/onlinedocs/gcc/i386-and-x86_002d64-Options.html) is a list of architectural options for gcc. The command line option -m64 will force 64-bit code generation. But under normal circumstances I don't expect that you will need it, as it should be enabled by default in a 64-bit environment.
Intel's chip line was named with an 80 prefix (representing Intel) and an 86 suffix, for its 8086 8-bit CPU. The successors to that chip were the 80186 (used now as a microcontroller), 80286, 80386, and 80486. Since the 80286, Intel began marketing the chips without the 80 prefix (although it was still part of the chip's designation), but with an i prefix. i286, i386, and i486 were the names used in marketing materials, though they were commonly referred to as simply 286, 386, 486, etc. Because that one digit was the only one to change in this family of processors, it was dubbed "x86." The moniker remained even after Intel renamed the 80586 to "Pentium," and in technical documentation or CPU class specifiers, you might see "586" or "i586" referring to Pentium-class chips. The term "i686" or simply "686" refers to any 32-bit CPU that is compatible with the instruction set introduced by the Pentium Pro. (I know, it's a little confusing.) Compilers like GCC have a "386" or "x86" option to produce code compatible with all 32-bit x86-compatible CPUs, including the 386. Likewise, "486" means any chip compatible with the 486 or later, "586" for all Pentium models or later, and "686" for all designed since Pentium Pro. (The ISA has changed very little since then.) More specific settings might include code generation for MMX, SSE, or 3D Now! extensions, depending on the target. AMD's introduction of 64-bit extensions to the x86 was called "x86_64." (No, that's not a typo.) Many people called it "AMD64" for its origins, but the official designation was "x86_64." Intel calls their version of the extensions "EM64T," and Microsoft branded it "x64."
x86 is a set of instructions that a CPU can implement. i686 is a line of processors from Intel which implement the x86 instruction set.
Doug Schmidt's ACE books.
&gt; but its gcc that I am interested in... ... which is a C compiler. 
You probably already know this, but this works: #include &lt;stdio.h&gt; template&lt;int t&gt; class testt { public: virtual void do_it() = 0; }; class test1: private testt&lt;1&gt; { public: void do_it(){ printf("done it1\n"); }; }; class test2: private testt&lt;2&gt; { public: void do_it(){ printf("done it2\n"); }; }; class derived : private test1, private test2 { public: derived() {}; virtual ~derived() {}; }; int main(int argc, char *argv[]) { int data = 0; derived testd; ((testt&lt;1&gt;*)&amp;testd)-&gt;do_it(); ((testt&lt;2&gt;*)&amp;testd)-&gt;do_it(); } 
i686 refers to the "pentium pro (or P6)" and later x86_32 compatible processors. The original pentium, amd k5 and cyrix processors were the last i586 processors. I believe the amd geode was also i586 class.
You can't - you can only have one final override in your 'derived'. The template argument is not used in the signature of doit(), so it does not apply as a disambiguator. Consider instead that the template arg was used: #include &lt;stdio.h&gt; #include &lt;string&gt; using std::string; template&lt;typename T&gt; class testt { public: virtual void do_it(T arg) = 0; }; class derived : private testt&lt;int&gt;, private testt&lt;string&gt; { public: derived() {}; virtual ~derived() {}; void do_it(int){ printf("done it int\n"); }; void do_it(string){ printf("done it string\n"); }; }; int main(int argc, char *argv[]) { int data = 0; derived testd; ((testt&lt;int&gt;*)&amp;testd)-&gt;do_it(123); ((testt&lt;string&gt;*)&amp;testd)-&gt;do_it("123"); } Also, your casting to a private base class is wrong and evil.
IIRC the Geode is about one instruction short of being i686.
From the man page itself.. *gcc - GNU project C and C++ compiler* 
i686 refers to the pentium pro, not the plain old pentium which is i586.
&gt; In the context of 32-bit vs. 64-bit instruction sets, the term x86 is often abused to imply 32-bit, even though corresponding 64-bit architecture is also technically x86. Not to mention that the 8086, 80186, and 80286 processors aren't 32-bit either.
Gnu Compiler Collection actually. https://secure.wikimedia.org/wikipedia/en/wiki/GNU_Compiler_Collection#Languages
I love short, to-the-point explanations without all the unnecessary side discussions I find in so many articles written on the web. You should start a blog and just dump stuff like this to it.
What is the exact error that you are getting?
&gt; V-tables, man. When you call a method on an object, you don't just call that function, you have to look it up first.* &gt; * This isn't actually true. As long as you don't use virtual, you never have do deal with v-tables, but their mere existence offends some people Actually it's funny that Linus and the Linux community in general get mentioned regarding this. They are (justifiably) very proud of their object-oriented (yes, really) file system interfaces called VFS. VFS's implementation is basically virtual functions coded manually in C instead of in C++ though... I'm sure gcc is able to do well with those to almost (if not completely) get them as fast as in C++, but it makes you wonder sometimes. :)
There are plenty of standardized C++ ABIs. The current g++ ABI hasn't changed since gcc 3.4 or so for instance (and for most apps, hadn't changed since 3.3), and the ABI that is implemented now by gcc was standardized by an external standards body. Obviously it is *easier* to get a standardized C ABI since like you said, there is simply not as much going on in C. But I very clearly remember doing Win32 programming in C and having to be careful not to try and use functions in the MSVCRT from the Borland 5.5 compiler I had, since even the C language implementation were not fully compatible (at least, by default). &gt; Further, there's nothing standardized to force binary compatibility between the structures of the standard template library. For instance, passing a reference to an STL container (like vector) from one library to another at run time isn't guaranteed to work because the underlying structs involved are dependent on a particular STL implementation. An *STL vector*? That's very much like saying that Qt 3 is not compatible with Qt 4, or that the FILE* type provided by dietlibc is not compatible with the same one provided by glibc -- i.e., this is hardly unique to C++. As yet another example, I've badly broken a system before because I had two different libpng libraries (a C library, as best I can tell) installed. I'm talking two different versions of *the same library*. I'm not trying to detract from what seems to be your main point (C++ is too high level for a coherent application-runtime interface) but I do want to point out that it's not that much of a disadvantage compared even to C since C suffers just the same in a lot of cases.
Indeed it is, however this was just a quick and dirty example to demonstrate the concept. Thanks for the example though, I had done something like that previously which is what inspired me to try a version based on the value.
 testmain.cpp:16: error: cannot define member function testt&lt;1&gt;::do_it within testsuper testmain.cpp:17: error: cannot define member function testt&lt;2&gt;::do_it within testsuper Which is a little generic...
What is happening to MS? for real, check the headlines: Win32++: A Simple Alternative to MFC [codeproject], What’s so cool about Boost.MPI?, W00t W00t Nix Nix! « [C++Next] I don't remember when was the last time that MS tried to be part of the community (they always tried to rule the community), so now we will "fall in love" with MS and 5 years later they will be evil again? 
Yes, this is exactly the kind of stuff that creates freakishly slow and buggy software.
--&gt; stackoverflow.com
MS is alright. They got a good C++ team there now. Lets hope that team gains more and more influence on the rest of the company.
You're right. C has most of the same problems. It's just that C's are less severe by virtue of being simpler, making it easier to for C compilers to interoperate by targeting multiple ABI's and C easier to modularize. There's a deeper problem with template libraries. A template library cannot be upgraded without rebuilding everything that uses it, since the resulting code is being inlined into each compilation unit per template specialization. So if some kind of templated container appears in a system interface (such as an STL vector again), that template library cannot be upgraded without rebuilding the affected system components. Of course, you can make this seem more natural by moving these definitions into the kernel headers. A lot of the perceived complexity here depends on where you draw system boundaries.
No, that's a great point about template libraries. It happens to be a C++ feature that really throws a wrench into e.g. a kernel/userspace interface, but then we wouldn't defined such an interface in terms of C macros either. ;) It's also not impossible to work around, Qt and KDE both use templates to fairly good effect and are able to at least maintain backward compatibility (assuming the ABI doesn't change in between!). It's surely a harder problem than just trying to design a C-compatible marshalling interface, and any successful type of interface would probably imply not throwing the entire kitchen sink of C++ features in there... but no one says you *have* to use it all in every piece of code. :)
If it were merely a performance issue, I wouldn't have said anything.
Static function: a function that is available even without an instantiation of the class. Since there's no instantiation, you can't access any non-static class members from within a static function. Static members are also shared between all instances of the class. class foo { static int bar; int baz; static int quux() { bar++; // can't access baz from here } int bah() { bar++; // bar is static, but accessible from here quux(); // same with quux baz--; // baz is also accessible since we're non-static } } Abstract classes: just a class that has one or more abstract (non-implemented) member. You can't instantiate one, but you can use them as 'interfaces' by subclassing them: class foo_1 { virtual int bar() = 0; } class foo_2 : public foo_1 { virtual int bar() { return 4; } } int main() { // foo_1 f1; // can't do this; foo_1 is abstract foo_2 f2; // ok, foo_2 is a concrete subclass of foo_1 foo_1* pf1 = new foo_2(); // pf1 is a pointer to a foo_1, and a pointer to a foo_2 is sufficient }
Ohkay, so with the Statics: * 1) you can only use other static objects(or variables) within a static function. No initiated variables allows. (pretty much the racist of the group.) * 2) both static and non-static can be used in a non-static function. (The cool friend that doesn't see people that way...) Abstract ideas: * 1) an abstract class can't create an object directly from main(). * 2) it can however be used through a non-abstract class or if there is a pointer. (right?) Edit: Thank you so much for you're help. It is much appreciated. 
You're an RIT student, aren't you? I can't imagine any other school would be crazy enough to hold finals in February.
Nah, I'm a DeVry student and we work off the 8-week system.
&gt;MS is alright. They got a good C++ team there now. Like you said **NOW**, I'm afraid of what will happen tomorrow. 
&gt; 2) it can however be used through a non-abstract class or if there is a pointer. (right?) I don't know what you mean by this, but you CANNOT instantiate an object of the abstract type. Ever. Think of abstract classes as interfaces -- they don't DO anything, they just describe what kinds of functions derived classes will offer. &gt; Thank you so much for you're help. Thank you so much for you are help?
Not sure how you represent your matrix internally, but it would seem to me that with some arithmetic, you can just keep it as it is, and access it in the way you want. The first row simply becomes the last elements of all columns, the last row becomes the first columns, and so on.
My objective is to turn change the elements of the massive. mas[3][3] 1 2 3 4 5 6 7 8 9 must end up like this 3 6 9 2 5 8 1 4 7
I wouldn't say it homework.
Well, I *am* help, so it makes sense. Lay off. :D
It might be helpful to consider what C++ is doing behind the scenes. Every non-static member has a compiler-supplied `this` pointer which points to an instance of an object. C++ code like this: class foo { int bar; int inc_bar() { return ++bar; } static int quux; static int inc_quux() { return ++quux; } } This code gets compiled into something like this: struct foo$ { int bar; } int foo$quux; int foo$inc_baz(foo$* this) { return ++(this-&gt;bar); } int foo$inc_quux() { return ++(foo$quux); } Notice the following: * The instance variable `foo::bar` is stored in the `foo$` struct (consider the dollar sign to be the name mangling performed by C++). * The instance function `foo::inc_bar()` has an extra parameter `this` which is a pointer to a `foo$` structure. This pointer is used to access the instance data. * The static variable `foo::quux` is stored outside the `foo$` struct, so you don't need an instance to access it. * The static function `foo::inc_quux()` doesn't have the extra `this` parameter, so it can't get access to the `foo::bar` variable (because where would it look for it?). This is pretty close to how the C++ compiler actually works. It gets slightly more complicated when dealing with virtual functions, which brings us to 'abstract' or 'pure virtual' functions. When compiling something like this: class foo1 { int bar; virtual int frobulate() = 0; } You get something like this: struct foo1$ { int bar; int (*frobulate)(foo1$*); } Because the `foo1::frobulate()` function was declared virtual, a pointer to that function is stored in the instance data. (The reality is a little more complicated than this, but it's good enough for now.) The thing is, because `foo1::frobulate()` was declared pure virtual, there's nothing for it to point to, and the `foo1$::frobulate` pointer will be `NULL`. In order for it to do anything, you have to subclass `foo1`: class foo2 : public foo1 { virtual int frobulate() { return bar * 42; } } This compiles to: struct foo2$ { foo1$ _foo1; // this is foo2 "inheriting" foo1 } int foo2$frobulate(foo1$* this) { return (this-&gt;bar) * 42; } So now we've got a method `foo2$frobulate` that we can shove into the `foo1$::frobulate` member. I may be confusing you with the abstract members, so let me tl;dr it for you: &gt; an abstract class can't create an object directly from main() An abstract class can never be instantiated directly, because one or more of its members would be pointing to `NULL`, and calling those members would crash the program. (Actually, these members typically point to a stub function that prints something like 'pure virtual function called' and then throw an exception, but the result is the same.) You can only use an abstract class through a non-abstract (concrete) subclass, which provides implementations for all of the abstract members in the base class. &gt; it can however be used through a non-abstract class or if there is a pointer Remember, a pointer isn't an instance of the class; it's just a reference to a location in memory. So when you have a pointer to something, you're really just saying "look over here for the instance of the class". Think of abstract classes as being general, and concrete classes as being specific: class food { virtual int calorieCount() = 0; }; class doubleQuarterPounderWithCheese : public food { virtual int calorieCount() { return 740; } }; (My C++ is rusty and I've forgotten to put `public:` on all my class definitions, and probably forgot semicolons, but you get the idea.)
I always thought it helpful to think of abstract classes just as you would objects in real life. For example, all animals are things with specific characteristics; like brains, eyes, legs etc... but an animal is an abstract concept that can never exist in the real world. Instead there are dogs and birds which are similar, but have their own implementations of the more abstract concept that makes up an animal. 
I'm not even going to reply to you... shit.. I already did... p.s. thanks for fixing my 2 am grammatical error ;-)
I guess one of the biggest issues I'm having is thinking of how I'm supposed to use these concepts within my final project of creating a virtual restaurant, as well as understanding enough for me to create an example on my final if I get asked for one. I think your example with food may have put me back on the right track though. Thanks again for all the assistance, I REALLY appreciate it. Now I'm going to re-read your comment another 20 times in hopes that I may comprehend a bit better. 
&gt; I don't know what you mean by this, but you CANNOT instantiate an object of the abstract type. Ever. Think of abstract classes as interfaces -- they don't DO anything, they just describe what kinds of functions derived classes will offer. In C++ you can very much define abstract classes that have partial implementations. In other words it's easier to think about individual class methods as being abstract or not. It is true that C++ will not allow you to create an new instance of an abstract class. However, you can provide an abstract class with fully-implemented methods, and even use those methods. Consider: #include &lt;iostream&gt; // Abstract, cannot be directly instantiated. class Abstract { public: virtual ~Abstract() { } virtual void a() const { std::cout &lt;&lt; "Abstract::a\n"; } virtual void b() const = 0; }; class Derived : public Abstract { public: virtual ~Derived() { } virtual void a() const { std::cout &lt;&lt; "Derived::a\n"; } virtual void b() const { std::cout &lt;&lt; "Derived::b\n"; } }; int main() { Derived *derived = new Derived; Abstract *iface = derived; // Cast to the "interface" type. derived-&gt;a(); // "Derived::a" derived-&gt;b(); // "Derived::b" iface-&gt;a(); // "Derived::a" iface-&gt;b(); // "Derived::b" // The WTF moment: iface-&gt;Abstract::a(); // "Abstract::a!" return 0; } Due to the `virtual` declaration, calling `a()` and `b()`, even through an `Abstract` pointer results in calling the methods from `Derived`. But you can force C++ to choose a given `Abstract` method and it is happy to call it as well, even though the class it is part of is abstract.
I do have a blog, I just never think I have anything to say worth reading. :)
Not really aimed at you, but: It's not at all a WTF moment, it makes perfect sense, you are choosing to call the method from the base type.
Predictably, the first answer is totally wrong. (Seems like a lot of classes actually explain it badly, then CS students simplify the unclear explanation into something outright untrue). roxm's follow-up comment is better, because it mentions the implicit this pointer, but it still fails to explain that STATIC FUNCTIONS CAN ACCESS INSTANCE MEMBERS. What is a member function? It's part of the class implementation, and therefore can access all members of ANY instance of the class. Non-members can't access private members (unless they have been granted friend access). Now, how are static and instance member functions different, since both can access private members? An instance member function has an implicit variable, the `this` pointer, supplied at the call site. This `this` pointer is implicitly used when an instance member is named WITHOUT QUALIFICATION. Static member functions don't have any `this` pointer. They can be found from an instance, or from the class name, since no instance is needed for setting up the hidden `this` argument. The result is that naming an instance member without qualification won't work inside a static member function, because there's no `this` pointer to help find it. But instance members can be accessed perfectly well using the member access operators (`.`, `-&gt;`, `.*`, and `-&gt;*`). For example: class foo { static class foo foo1; int i; public: static int getIt(void) { return foo1.i; } }; class foo foo::foo1; This code compiles just fine, demonstrating that a static member function can indeed access instance members, even when they're private. I hope this helped. If you understand, you're doing better than 3/4 of C++ students.
Bringing the access modifier into the discussion muddies the issue, IMO. My post is correct - you must have an instantiation of a class in order to access the non-static members. In your example the instance being used happens to be static. If the OP had been asking about visibility of inherited members, I'd have touched on that. But he didn't.
This makes perfect sense, and now I've gotten an understanding of how static functions work, I'm now getting lost on the practical use of it and how I'll implement it within my project. Thank you for the insight.
Why doesn't the compiler check the access rights to the inferred variable?
&gt;Why doesn't the compiler check the access rights to the inferred variable? Because what is being inferred is a type, rather than a particular name of a type. Access restrictions apply to names, not types or values. A single type may have different names with different acess restrictions. Some expressions (like lambdas) have types that have no name at all, yet it must be possible to infer their type.
That sounds interesting. Could you give some example of one type with different names?
Any time you use `typedef` you are creating a new name for an already existing type. 
I thought typedef was more of a nickname/shortcut than a name in its own right. As in the following still outputs "int". &lt;code&gt; #include &lt;iostream&gt; int main() { typedef int MyInt; std::cout &lt;&lt; typeid(MyInt).name(); } &lt;/code&gt; I would be very interested in seeing a simple example that demonstrates: &gt; "A single type may have different names with different acess restrictions".
Artificial example: class A { protected: struct Hidden {}; }; class B : public A { public: using A::Hidden; }; //... A::Hidden a; // error: ... B::Hidden b; // OK
Thanks that is interesting.
&gt;I thought typedef was more of a nickname/shortcut than a name in its own right. I was talking about names in the sense of "identifiers introduced by declarations", rather than in the sense of "strings returned by type_info::name method". A typedef declaration introduces a new name, just like a variable declaration, function declaration, class declaration, or whatever other declarations there may be. These names follow, more or less, the same name-lookup rules, the same scope restrictions, the same inheritance/hiding semantics, and the same rules for access restrictions, regardless of the kind of declaration that created them. So I don't think it's useful to consider typedef names as something inferior to other names. In any case, each typedef name has its own access restrictions, even among names referring to the same type. &gt;I would be very interested in seeing a simple example that demonstrates: &gt;&gt;"A single type may have different names with different acess restrictions". What I was thinking of was the simple typedef: class Foo{ private: typedef int not_accessible; public: typedef int accessible; };
These are not podcast but i hope this videos will helpful to you. [This website](http://xoax.net/comp/cpp/console/index.php) have videos about cpp and other programming languages.
So why the compiler doesn't check the name of the inferred type against the access?
&gt;So why the compiler doesn't check the name of the inferred type against the access? Which name should it check against access when the inferred type has more than one name? And which name should it check when the type has no name? 
The name used in the type's declaration. If there is no name, then there is no need to check the type access. 
But then a type declared as private would remain inaccessible, even if there is a public typedef for it. This seems like it would lead to some surprising behaviour. class X{ private: class PrivateType{}; public: typedef PrivateType PublicAlias; }; X::PublicAlias a; X::PublicAlias b=a; //OK auto c=a; //ERROR: a has type X::PrivateType, which is inaccessible So your rule would forbid the declaration of c, even though its type can be accessed through an alias. I'm not saying that you couldn't do it like that, but it doesn't seem like an improvement over the existing rules. Besides, the code in the original article would remain broken, unless you also change the existing C++98 rules for the deduction of template arguments.
&gt; But then a type declared as private would remain inaccessible, even if there is a public typedef for it. Which is the correct thing to do. If a type is private, then it shall not be used publicly! &gt; So your rule would forbid the declaration of c How about deducing that C has the type PublicAlias, instead of PrivateType? 
&gt;&gt;But then a type declared as private would remain inaccessible, even if there is a public typedef for it. &gt;Which is the correct thing to do. If a type is private, then it shall not be used publicly! A type is never private. Only a name referring to that type may be private, which means you cannot reference the type through that particular name. Strictly speaking, it makes no sense to say that a type is private, just like it makes no sense to say that the integer 17 is private. Whenever someone speaks of a "private type", they mean a private name referring to a type. If a type can be accessed through both a private name and a public name, there is no reason why the compiler should prevent me from declaring a variable of that type through the use of auto. &gt;How about deducing that C has the type PublicAlias, instead of PrivateType? That would violate the rule that you proposed, namely that access restrictions for a type should be checked based on the name used in the type's declaration. Feel free to propose a different rule, though. 
This is plain wrong, Eigen does have blocked Householder routines. https://bitbucket.org/eigen/eigen/src/b311eb0b4c93/Eigen/src/Householder/BlockHouseholder.h
&gt; A type is never private. Ok...let's replace 'type' with 'primary name' of type, i.e. the name of the type used in the type's declaration. What I said is still valid. &gt; f a type can be accessed through both a private name and a public name, there is no reason why the compiler should prevent me from declaring a variable of that type through the use of auto. What's the point of the private name then? &gt; That would violate the rule that you proposed, namely that access restrictions for a type should be checked based on the name used in the type's declaration. I am ok with that. Still, there is a solution, as you can see. 
&gt;Ok...let's replace 'type' with 'primary name' of type, i.e. the name of the type used in the type's declaration. What I said is still valid. I understand what you mean. I just don't think it is a good idea. Suppose that type inference would only be allowed to work if the 'primary name' of the inferred type is accessible. Apart from the example I posted before, this piece of code would also not work: #include&lt;string&gt; using std::string; string foo="some string"; auto bar=foo; One would expect that the compiler can infer the type string for bar, but string is only a typedef for `basic_string&lt;char&gt;`, and the `basic_string` name is not accessible where bar is declared, because it's inside the std namespace. &gt;What's the point of the private name then? Normally, the private names should be reserved for types and values used in the class implementation, and the users of the class should not need to be concerned with them. In the original article, the 'privateness' is instead used as a trick to force that certain conversions are performed at the right time, so there is a public operator+ that returns values of the supposedly 'private' type. This makes the private implementation leak through the public interface. This design has some pitfalls even in C++98. Your suggestion to restrict type inference would be only a partial fix for that. I agree it can be done the way you suggest, it just seems to me the cure is worse than the disease.
&gt; One would expect that the compiler can infer the type string for bar, but string is only a typedef for basic_string&lt;char&gt;, and the basic_string name is not accessible where bar is declared, because it's inside the std namespace. The compiler could infer the type 'string'. &gt; Your suggestion to restrict type inference would be only a partial fix for that. I agree it can be done the way you suggest, it just seems to me the cure is worse than the disease. I don't see any problem. The compiler can easily infer the name of the type from an expression, and replace auto with that. In your example, the compiler should replace auto with string. 
How many legs does a cat have? A static member function would always return 4. An instance method might return a smaller value.
&gt;In your example, the compiler should replace auto with string. So now you suggest the compiler should also take typedef-aliases into account, rather than just look at the primary names. Than can be quite difficult in the general case. Suppose you have a type with primary name like `vector&lt;pair&lt;foo*,bar[10]&gt;&gt;`. To find out if there is an accessible alias for such a type, the compiler may have to look for an accessible alias for `foo`, `bar`, `foo*`, `bar[10]`, `pair&lt;foo*,bar[10]&gt;`, and `vector&lt;pair&lt;foo*,bar[10]&gt;&gt;`, and since C++0x allows aliases for templates, this may actually not be enough. And suppose that `foo`has an alias with a compound name, like `SomeTemplate&lt;SomeType&gt;::SomeAlias`. To find out if such an alias is accessible, we now need to check if SomeType and SomeTemplate have accessible aliases, triggering an arbitrarily long cascade of checks. It seems quite hard to figure out in the general case if there is an accessible name referring to a given type. The cost of implementing such checks seems to outweigh the benefit. 
Do you understand what those algorithms are? Understand the algorithms first, and the rest is then a simple matter of programming.
http://math.hws.edu/eck/cs225/s03/binary_trees/ Everything you need (and more) to get started.
Thoroughly understand the algorithms first. Then try to understand how you would implement them in software. Then it's just a matter of translating it into C++ code.
I'm a tutor, and I challenge my tutees to write out their program in English. If they can get it specific enough, turning it into code is a no-brainer.
First of all, the compiler already does this job of tracking the aliases to their primary name. This is evident in error reporting: when the aliased name is used in ways not supported by the type, then the compiler tells you that the given type does not have the specified operation or member. Secondly, in 99.99% of cases, there are going to be 2 or 3 levels of indirection. Thirdly, the alias computations always terminate. So, again, I don't see any problem. 
&gt;when the aliased name is used in ways not supported by the type, then the compiler tells you that the given type does not have the specified operation or member. Sure, but that just means that the compiler is able to deduce the type from a given alias, which is easy, because the type is uniquely determined by the alias. For your scheme to work, the compiler would have to do it the other way round: for a given type, check if there exists a suitable alias. This is hard, because there may be lots of aliases. &gt;Thirdly, the alias computations always terminate. That would depend on how exactly the computations are defined. If the compiler has to look for aliases inside class templates, it may easily end up with an infinite chain of instantiations.
&gt; For your scheme to work, the compiler would have to do it the other way round: for a given type, check if there exists a suitable alias. No, it does have to work like that. The compiler should know the type alias from the type inference: when the compiler tries to infer the type of expression 'a + b -&gt; x', then it locates the alias of type 'x' at the return type of the expression. For example: string s = a; auto t = s; From the above, it's easy to deduce that 's' is a string, and that 't' should have the type string. In case there is no type alias in the expression, then the primary name of the type should be used. 
&gt;when the compiler tries to infer the type of expression 'a + b -&gt; x', then it locates the alias of type 'x' at the return type of the expression. I am afraid I don't understand what you mean here.
Suppose you have an expression of the form a + b -&gt; x I.e. the expression returns a type with the name 'x'. The compiler can use this type for inference. 
I don't understand your `a+b-&gt;x` notation. Anyway, most expressions do not contain the name of their type conveniently attached to them. Type inference can deduce the type, but if you want to check access restrictions, you need some kind of 'name inference' rule to find the name for the deduced type. Using always the primary name does not work very well. Trying all possible aliases does not work very well. It seems you are now advocating some kind of ad-hoc rule where the compiler finds the 'most likely' alias name if there is one, or else uses the primary name. I don't know what your rule is, and it probably doesn't matter. The overall point is that performing this kind of access check is non-trivial, and does not really bring any benefit. Therefore, the compiler just infers the type and does not worry about naming it.
Using WMI in C++ to find out if it's a laptop or PC... Abstraction inversion much? &amp;#3232;\_&amp;#3232; 
&gt; I don't understand your a+b-&gt;x a, b and x are types. + is the operator applied to a and b. -&gt; is the result. &gt; I don't know what your rule is I already explained it to you: the name of the type should be inferred just like the type is inferred: if the name cannot be inferred, then the primary name is used. &gt; The overall point is that performing this kind of access check is non-trivial, and does not really bring any benefit. It brings the benefit of access checking on inferred types. &gt; Therefore, the compiler just infers the type and does not worry about naming it. And violates encapsulation in the process. &gt; Type inference can deduce the type But during the process of type inference, the type inference algorithm uses the names of types, so it already handles the names. If the type names were not used, then type inference would not be possible. 
Amazing how C++ keeps surprising me after having used it for several years.
I'm starting to wonder if you take this thread as some kind of an absurd joke. On the off chance you really mean what you say, let me respond one last time. A 'type' is not the same thing as a 'name of a type'. &gt;the name of the type should be inferred just like the type is inferred That makes no sense to me. Type inference does not operate on names, only on types, including anonymous types and types that have no name in scope. A 'type' is not the same thing as a 'name of a type'. &gt;It brings the benefit of access checking on inferred types. There is no such thing as 'access checking on types'. Access checking is always performed on names, regardless of what the names represent. Did I mention that a 'type' is not the same thing as a 'name of a type'? What you propose is to perform access checking on some particular name for the inferred type chosen by some unclear rules, and there is little benefit to do that. &gt;&gt;Therefore, the compiler just infers the type and does not worry about naming it. &gt;And violates encapsulation in the process. If your class has a public method that returns values of a certain type, then users of your class can use this method to obtain values of this type, even if you give the type a private name. It has been like that since C++98. If this surprises you, then your understanding of encapsulation needs to be adjusted to fit the actual language rules. &gt;But during the process of type inference, the type inference algorithm uses the names of types, so it already handles the names. No it does not, as demonstrated by the fact that type inference handles anonymous types just fine. If you still believe that checking access to names of inferred types, we'll just have to agree to disagree. 
Good one, even though its an old one.
Isn't it that static_cast is a template function? More on templates here: [function templates](http://www.cplusplus.com/doc/tutorial/templates/) In case you don't know what they are.
It's a built-in C++ operator that is invoked like a template, yes.
What's the difference between the derived class' destructor being called directly and via virtual dispatch? How can it call the appropriate destructor without virtual dispatch?
The compiler casts const Base&amp; to const Derived&amp;, and calls the destructor directly, as opposed to using Base's vtable to call the destructor (whcih would require that the destructor be virtual). This is possible because the type is known statically at compile time - although you assign a Derived temporary to a const Base&amp;, the compiler knows that the reference actually points to a Derived rather than a Base.
Read it as static_cast to int.
In case anyone else read the ScopeGuard article in DDJ linked from this one, and was wondering where the code was, it's here: ftp://ftp.drdobbs.com/sourcecode/cuj/2000/cujdec2000.zip
Having used CUDA 3.0 for some research work, this unified memory addressing looks to be a very useful tool. Having shared memory space looks like a great change, as it will increase memory coherency (if I understand it correctly) and, to a lesser extent, data transfer speeds.
I never thought about this case, but it makes sense. Here would be my argument: const T* Factory() { return new T; } void SomewhereElse() { const T* foo = Factory(); delete foo; } It doesn't really make sense to enforce const-ness on something that is being destroyed, otherwise this use case would result in an indestructible instance of T.
Oh, now I get it, thanks!
I'm not sure I would start new projects in CUDA nowadays. OpenCL may be less advanced, but it's more likely to be well-supported in the future.
With an AMD card it is really frustrating that companies continue to use CUDA instead of OpenCL. Looks like macs are going with AMD, companies like Mathworks will have no choice but to go OpenCL instead of CUDA.
One more reason not to depend on closed stuff like Matlab :)
Octave has a GPU accelerated parallel computing toolbox that supports both AMD and NVidia? Matlab's only supports NVidia.
You are saying that type inference works on anonymous types, but I say you are wrong: type inference never works on anonymous types; in fact, during the type inference algorithm, all types are named. Even in C++0x lambdas, the lambda types get internal names which are valid in the lambdas' scope. Without type names, it's impossible to do type inference. The c++ compiler cannot do the appropriate type conversions or invoke the appropriate code without names of the types. How is the compiler supposed to compare types, find the appropriate type conversions, and the appropriate functions to invoke without names? it is impossible. There has to be an attribute of a type which is used by the compiler to address that type internally during compilation; and this attribute can only be the type's name. Please show me a complete type inference algorithm example where names of types are not used at all. 
What it does not make sense is to use constness to return a value that is deletable. The correct approach is not to make Foo's return value constant, but to make T immutable, except for its destructor. 
Anyone know what the overhead is like?
We should just all start using NVIDIA then. 
Picking a final winner in the GPU field is sensibly equivalent to giving up on the current performance increase we're seeing over time. OpenCL doesn't lock you in either camp, so the sooner it becomes more widely used, the faster NVIDIA will start to commit their resources on improving their OpenCL implemetations rather than their CUDA ones. 
Recently implemented the same algorithm sequential &amp; parallel, plus others in Java for a school project. All work was done using the Parallel Java library. Code: https://github.com/bgianfo/pc-project/tree/master/src Slides: https://github.com/downloads/bgianfo/pc-project/pc-presentation.pdf 
I wish they could add runtime checking if CUDA GPU is available, and if not it would fall back automatically to a software implementation. We use CUDA otherwise, and the unified address space looks sweet. 
You can use cudaGetDeviceCount and cudaGetDeviceProperties to query devices and their properties. If you want, you can run all CUDA kernels in device emulation mode (software) when there is no real GPUs present. 
Cuz ATI's support of OpenCL is pretty abysmal. It's pretty much impossible to get an efficient OpenCL implementation for an ATi card.
As a general rule of thumb, if you're using multiple inheritance, something is wrong. 
I thought emulation mode was deprecated. And single-threaded (AMD's OpenCL implementation makes use of multicore CPUs even if you don't have a GPU). Of course, the bigger problem is that libcuda.so is installed with the NVIDIA drivers, which you can't install if you don't have an NVIDIA card (and you certainly can't expect all you users to have). With OpenCL, you link against libOpenCL.so, which finds and loads the appropriate vendor's implementation at runtime (although it might not find any implementation, so you either have a non-accelerated path for those users, or tell them to get OpenCL).
I can't seem to figure it out- does CUDA 4.0 have Visual Studio 2010 support without jumping through hoops?
OpenCL has almost no development behind it. AMD is not and never have been a software company, and they're not getting anywhere with OpenCL. Apple definitely hasn't pushed OpenCL either. So, NVIDIA's OpenCL driver (which just calls to their CUDA driver) is the best OpenCL implementation around. CUDA is also light-years ahead of OpenCL. So, in the long long term, neither of these will survive, and for the moment CUDA is really the only way to go if you're serious about GPU programming, which I am.
&gt; The algorithm needs to pad matrices with zeroes if they’re either non-square and/or have dimensions which are not a power of two. For this reason, if your input matrices have a square dimension something like N = (2n + 1), the algorithm works with a matrix almost twice that size. For that reason it will perform badly on matrices with this characteristic. Nitpicking, but I'd shy away from that use of the word "size" - it could be interpreted as though it's padded to have almost twice as many elements, not twice the number of rows and columns (and so ~4x the number of elements.) (All assuming I understood the paragraph correctly myself, of course.)
True and true (although you can always check if library is present before loading it). I'm eagerly waiting maturing of OpenCL (hardware and driver support). CUDA is already mature, but for reasons we are discussing in this thread, it's only suitable for situations where you can choose your hardware.
"... and that's how I lost my left pinky." Ah, kids, with their C# and their Dan Fogelberg records...
&gt; What it does not make sense is to use constness to return a value that is deletable. I would personally generalize that to say it does not make sense to return newly-allocated pointers at all, but I have seen enough static factory class methods to know that if it compiles, folks will do it. But frankly, this is naïve of me to say. In other code bases, I have seen very clever uses of auto_ptr (and variations), proxy objects, strict return by reference, and so on that obviate the need ever to return deletable pointers. And yet, that pattern has its place. One simple example is only ever returning immutable objects to users of a library. During construction, the objects can remain mutable without const_cast, mutable members, friend class gymnastics, etc., but once the object is returned it remains const. So I think that if you accept returning pointers and relinquishing ownership when doing so, then the const case follows necessarily.
An abstract class is a class with unimplemented methods (in some languages, "or members or etc"). Because there are unimplemented methods, they cannot be instantiated - the classes aren't complete. Their purpose is to have child classes derived from them, so that the abstractions may be filled in. The abstract members tell the compiler what to look for, what signature to enforce, help the language know whether the children are complete, and make it so that the thing the child has to fill in is a valid point for inheritance. Think of them like mad libs for classes. A static function is a member of the class, *not* a member of instances of the class. That means you don't need an instance to call it, and it can't rely on anything in an instance (ie, non-static members, because there might not be an instance.) If you make a class for converting from feet to meters, make the conversion static, because there's no call to need an instance or instance data there. Uses for static members tend to be esoteric, because for the most part things you could do without an instance you could just do outside a class. Therefore, giving examples is hard, because they're sort of random and scattered; there isn't a "flavor" for what you tend to need them for. You tend to need philips head screws for high tension screws, so that you can apply more torque to placing them, but which ones have hex screws are pretty random, because it just means someone didn't want user-servicable goods. One example of the purpose of a static member is a common method of implementing singletons - classes who manage their own creation and enforce that only one of themselves may exist. The common mechanism for that in C++ and Java style languages tends to be one static member - a private pointer to the class' own type, initially empty - a protected constructor (meaning the class itself can call it but outsiders cannot) - and one static public member function, often called Instance(), which checks the static member pointer for emptiness; if it's empty it calls the constructor, fills the pointer with the construction and returns the construction; if it's not empty, it just returns the pointer, which is the existing construction apparently. Static shows up where you want things to be part of a class but don't need (or want) there to need to be an instance of the class.
The criticism you're replying to is not correct. The person he's criticising is. It's easy to test who's right. class b { public: static void out() = 0; } class d : public b { public: static void out() { std::cout &lt;&lt; "in child\n"; } } int main() { b* I = new d(); I.out(); } Exactly like great grandparent said.
In what way is the post you're replying to wrong? &gt; &gt; Since there's no instantiation, you can't access any non-static class members from within a static function. &gt; but it still fails to explain that STATIC FUNCTIONS CAN ACCESS INSTANCE MEMBERS. You're not accessing an instance member in your example. An instance member is internal. You're accessing a member through an external call against an instance member as a resource. Strictly, grandparent is correct. You did not access an instance member. You accessed a member *of* a static member externally. Completely different.
In what way is the post you're replying to wrong? &gt; &gt; Since there's no instantiation, you can't access any non-static class members from within a static function. &gt; but it still fails to explain that STATIC FUNCTIONS CAN ACCESS INSTANCE MEMBERS. You're not accessing an instance member in your example. An instance member is internal. You're accessing a normal member through an external call against a non-instance static member as a resource. Strictly, grandparent is correct. You did not access an instance member. You accessed a member *of* a static member externally. Completely different.
He's just wrong. He's got a static method touching a static resource and is claiming that things done to said static resource qualify the external call.
Yes, I can. But I can not link both the emulation mode and GPU mode to the same binary in a transparent way to the application. And also device emulation mode is deprecated. 
&gt;For example, I have a situation where I have a callback interface, but one of the parameters to my callback is something that a lot of clients don’t need. For convenience, I want to let them register a callback that doesn’t take the final parameter. But to be ANSI C, I can’t cast between the two callback types, I need to store the two possible callback types in a union. Don't use two callback types. Use one and give it a default parameter. This was posted to /r/cpp, right? &gt;...But to be ANSI C Well, what do you expect? You are trying to give the language a feature, default function parameters, which it does not support. In that case, you might as well do it dirty and forcibly cast everything. If you don't you are just going to end up doing at runtime what should have been done with language features at compile time. 
&gt; Well, what do you expect? What I hope for is that the compiler will perform any optimization that it has enough information to perform, and for which a reasonably generic optimization algorithm can be written. The optimization I described certainly fits the first criterion, and I think probably fits the second also, though the need to support multiple calling conventions may make it more difficult. &gt; You are trying to give the language a feature, default function parameters You have misunderstood my use case. Default function parameters are just syntactic sugar at the call site for passing extra parameters that you don't have to write out. My use case, which would not be solved even if I had default parameters, is sort of the opposite: I want the *callee* to be able to ignore a parameter that was passed to it. &gt; In that case, you might as well do it dirty and forcibly cast everything. I would no longer be ANSI C, and would therefore be much less portable. &gt; If you don't you are just going to end up doing at runtime what should have been done with language features at compile time. The compiler has enough runtime information to eliminate the runtime check. That was the entire point of my post.
have to ask, what version of GCC was the test run with?
And at which optimization levels - and how does one know the compiler doesn't know more about the processors branch prediction than we do ? 
in all fairness, branching is always evil, which the GCC guys are hopefully aware of
Interestingly, MSVC10 correctly optimises both cases: void foo(funcs f, int which) { int a = 5, b = 10; if (which) { f.f1(a); } else { f.f2(a, b); } } push ebp mov ebp, esp push 10 ; 0000000aH push 5 call DWORD PTR _f$[ebp] add esp, 8 pop ebp ret 0 And the second case: void foo(funcs f, int which) { int a = 5; if (which) { f.f1(a); } else { f.f2(a); } } push ebp mov ebp, esp push 5 call DWORD PTR _f$[ebp] add esp, 4 pop ebp ret 0
I can't recommend [Accelerated C++](http://www.acceleratedcpp.com/) highly enough. I used it when I was learning C++ and it's perfect for someone who already has experience programming (little though it may be). I'm not a Mac developer, but you probably want to use Xcode for your development. It's an IDE and uses the GCC compiler. Good luck. :)
If you're just learning C++, use your text editor of choice and commandline gcc. Trying to figure out Xcode or equivalent at this stage in the game is a recipe for frustration.
Yes, don't learn C first (Like how most books about C++ are set up). Learn C++ first, and maybe not C at all. C is ugly, modern C++ is beautiful. Mmkay? Stroustrups new book is set up like that. C++ first, C last. http://www.amazon.com/Programming-Principles-Practice-Using-C/dp/0321543726 
&gt; An IDE will let him double-click on syntax errors to jump to them, something hugely important for a beginner. This is not really an important feature. It saves time but doesn't aid in understanding. &gt; OP, use XCode. XCode, in fact any decent IDE, has a huge learning curve that (in many cases) is as big or bigger than learning the language itself. You don't want to be fighting against your tool chain when you're still struggling to understand pointers or whatever. Removing that IDE element from the equation may make you slightly less efficient, but it will allow you to focus all of your mental energy on actually learning what you're there to learn.
[Lambda is also your friend](http://blogs.msdn.com/b/vcblog/archive/2008/10/28/lambdas-auto-and-static-assert-c-0x-features-in-vc10-part-1.aspx)
I've worked before with people who took the road of learning C++ at university and never even looked at C. Things worked fine until we linked against some third party C library -- and then these people were completely fucking useless and doing insane things like the following: // void someExternalCFunctionThatModifiesAnInteger(int*); void Class::foo() { int* x = new int; someExternalCFunctionThatModifiesAnInteger(x); // uh why don't you just do &amp;memberVar, you dumbass??? memberVar = *x; delete x; } Most of these people have now been fired over the past 4 or 5 years, and yet I still spend about 90% of my time cleaning up their bullshit instead of focusing on new features. * Edited to come off as being less of a douche.
I would say I am tired of cleaning up after programmers like you seem to be (sorry). Programmers who think C++ is just C with classes. Modern C++ is about avoiding type unsafe C programming style. -Use RAII style to avoid resource leaks. Use owned smart pointers instead of unowned naked pointers (which are just waiting to leak on exceptions). -Use STL collection instead of raw arrays (which are just waiting for buffer overruns). -Use iterators instead of unsafe pointer arithmetic (which are just waiting for overruns). -Use templated functions and pure virtual functions instead of casting void pointers to get polymorphism (which is just waiting for being cast to wrong type). And use templates instead of hacking C style macros (teaching a beginner about casts and macros is just asking for trouble.). -Use and extend STL and boost algorithms instead of reinventing the wheel (which is going to be buggy and inefficient). Pretty much all university courses, and books, teach C first, C++ core language second, and then not STL at all, or put it in a appendix nobody reads. This is completely backwards. This is what Stroustrup found, and thats why he wrote the book. There was no introductory book that got the priorities straight. Obviously if you are going to work with C APIs you need to understand naked pointers. But the priority is to learn the STL style first. And then to learn whatever C you must. 
&gt; No. Just stop making recommendations. Please. This is not the way to get people to respect your opinions. Learning C before C++ means the learner is likely to use C idioms in C++, which is not a good thing. If you need to interact with C libraries then you can learn how to use C later.
&gt; I would say I am tired of cleaning up after programmers like you seem to be. Programmers who think C++ is just C with classes. Actually, you couldn't be more wrong. The people I was describing were exactly the ones I fought an uphill battle against for most of my career just to get permission to install libraries like Boost or even something as rudimentary as being allowed to use namespaces. I've probably written more of the "beautiful" code you describe than you will in the rest of your life -- and I did most of it on 90s compilers that didn't have all the fabulous template support and type deduction that people take for granted now. You don't have to tell me how cool the STL or Boost are -- I was a firm believer in them even when half of the templates were causing the compiler to crash or run out of memory. I've patched early Boost classes (e.g. weak_ptr used to have an issue in VC98 where the compiler optimized out atomic refcounting) before it was cool to use Boost. I have a whole library full of compiler workarounds for std::mem_fun and its ilk that I'm glad I'll never have to look at or #include again. I've spent half an hour converting simple, 10 line algorithms into their equivalent 40-line std::transform/boost::bind expressions *because that's my idea of fun*. I've argued over and over (and often failed to convince) that using dynamic_cast'ing is cleaner than using one big global list of enums. Don't talk to me about why modern C++ is better than C. I was one of the people fighting the battles to make this fact known, even when C++ compiler vendors were trying their hardest to prove us wrong with their own terrible standards support and poorly-designed proprietary libraries. Here's the big BUT you were no doubt waiting for: C++ is, like it or not, an extension of the C language. Refusing to learn C, therefore, is refusing to become an expert in your own chosen language. It's inexcusable and lazy, and readily admitting to it should be grounds for termination. It hinders you from fully understanding or predicting potential problems you may have with thousands of open source libraries that are written only for C. Refusing to use those libraries *because* they're written in pure C is also an example of the exact same reinvention of the wheel that you complain about. Claiming to know C++ without learning C is like learning to play a musical instrument without learning how to read sheet music. Of course it's possible, but how far are you going to go without it? **TL;DR** - Learning C may seem "ugly" to you, but if you refuse to you're only doing yourself and your team a disservice.
Okay. Lets start over and pretend we didn't start insulting each other. The fact remains there are priorities. A beginner needs to start some where. He should learn the most useful and most important parts first. A big part of becoming a good modern C++ programmer involves unlearning lots of bad C style habits. There is a saying, "the worst person to learn C++ is a C programmer". But thats pretty much where we all came from. We leaned C first, then learned about classes, and many never bothered to keep going and learning STL or even RAII after that. Looking at the code in the wild is a bit depressing. Code you have to maintain full of bad programming practices and full of avoidable bugs. All these programmers who stop learning once they get the C with classes syntax down. They never bother to learn better and safer ways of coding. They consider themselves experts and dont want to change. Its that ignorance of their own limitations that is so depressing. I have met a lot of programmers like this, programmers who have been working for decades. I have learned that the number of years someone has been programming with a C++ compiler, says very little about their skill as a C++ programmer. It does not have to be like this though. New C++ programmers can learn STL from page one.. and RAII from chapter two. These are the most important parts of the language. If all c++ programmers used STL and RAII instead of the C alternatives ans style the world would be a less buggy place, of that i am convinced. The current layout of beginner C++ books and university courses are responsible for a lot of this. It sets programmers on the wrong path. I would much rather work with a relatively new programmer who had read a C++ and STL book and internalized it, than working with a long time C programmer who never bothered to read a modern c++ book. 
You make a fair point. I've amended my original post.
Is there a limit to the depth of nested templates auto can resolve or is that system dependent?
&gt; Okay. Lets start over and pretend we didn't start insulting each other. As mentioned at the bottom of my original post, I've now taken my old man pills and am again capable of speaking to people as human beings. &gt; The fact remains there are priorities. A beginner needs to start some where. He should learn the most useful and most important parts first. I have to admit I haven't even set foot in a university in over a decade, but in the Stone Age the way the curriculum was handled was such: Teach C++ for safe(r) I/O - teach C for everything else. That is, you used iostream and string, and then made one big class for your application that essentially acted like a container for global variables. On one hand, I completely agree with you that this is a terrible way to design a program, and it's doubtful that any of these textbook are explaining how much time a student could save by reading the STL documentation before attempting to tackle one of the assignments. On the other hand, we're talking about students who have no prior experience with real-world software design. Knowing how to properly plan the simplest class hierarchy let alone an entire library is an acquired skill. It's not something you can teach 30 teenagers in a couple semesters. Getting them to the point where they can actually solve a problem is, in the short-term, far more important than how they solved it. And memorizing a handful of C keywords is, again, in the short-term a much smaller barrier to overcome in order to be productive as a programmer. If by STL you mean cout and string, then we're in agreement. In fact, I'm pretty sure that if universities are even still teaching C++ (my understanding is most introductory courses that focus purely on data structures and algorithms have switched to using Java and C# in the past 10 years--arguments about indoctrinating them with an OS-specific language aside, I'm not so sure this switch is a bad thing, to be honest), these are the two concepts they think the entire STL consists of. Fine. They save a lot of time and there's no reason to use FILE or char* if you don't have to. But we should also realize that often these students are forced to learn things the hard way on purpose. You learn how to write quicksort before somebody bothers to tell you there's a standard C function for it already. You learn how to write red-black trees before someone lets you in on the secret that the STL is already using them. That's sort of the whole point. You're there to learn how to do the mind-numbing hard stuff that gives you a better understanding of general problem solving later. You also aren't blindly confused when switching from a set to a vector alters the runtime performance of your code, because that evil professor of yours made you code your own set and vector classes in Data Structures 101 and you vaguely remember him or her telling you something about linear search times. The fact that these classes exist and are templatised is only fully appreciated because there was a magical time in the past when they weren't. Would I enjoy my job a little more if I could rest easy knowing my colleagues were not reinventing std::set_difference or boost::object_pool, or forcing me to pass in references to specific containers that I may or may not want to use in their accessors rather than writing a member template that takes an arbitrary output iterator as an argument? Of course. But that's something I expect of a senior developer, not someone just starting out. That's what code reviews and mentoring are for. For every 5 "ruined" C++ developers that I wouldn't hire to clean my bathroom, there's also 1 or 2 kids fresh out of school (or sometimes more telling of their potential, eschewed university and taught himself) who, when properly exposed to alternative ideas, flourishes into someone you really respect, and what's more, writes something you can actually maintain.
Thanks for taking the time to write that. I think we will have to just agree to disagree. By STL I mean the collections, iterators, and algorithms that make up the "Standard Template Library" so the most important concepts to learn from the start would be the concepts of collections, iterators and algorithms. Learning how to use a few for each. And then the importance of RAII when defining your own types. I don't think its important for a beginner to understand how the STL algorithms are implemented before using them. That what I consider getting your priorities backwards. You dont have to know how to build a car to be a good driver. Its better to teach the high level first and treat the implementation details as black boxes to begin with. All you need to know to begin with is the interface of the types (and maybe some basic understanding of time complexity guarantees) . Abstraction and encapsulation is a good thing for programming as well as learning. Later you can uncover more about the low level implementation details.. If you start with the low details and work upwards.. then most people will only have time to get half way up, and then we are stuck with these C with classes programmers who are ignorant of how to use STL.
This is awesome, just in time. I'm trying to get some develops at work to switch from their own link list to an STL list or vector. But they've never heard of STL (old C programmers), so I'll pass these video's along to them. 
Don't forget the first 10 videos, but be careful he uses some c++0x functionality in few of the movies. 
I'm looking forward to this series. Learning c++, just watched the basic series. Like the presenter. He is a ball of enthusiasm which really helps keep you engaged.
No there should not be any limit. If you could explicitly spell out the types on the left hand side, then you can always ask the compiler to do it for you. Its just syntactic sugar. You are probably thinking of the limit of recursive template instantiation (to stop the compiler from running out of memory, much the same a recursive function can cause a program to run out of stack memory at runtime). Thats has nothing to do with auto though.. it has has more to do with recursion gotchas in general.
There is a lot of folks like that out there. Cant teach an old dog a new trick, and all that. Good luck though. C is so 80s, STL and boost is where its at.
That seems mostly useful as part of a decompiler, although that's the easy part compared to mapping binary code back to the relatively high-level constructs of an AST. Also, this doesn't seem to have anything to do with c++.
Discussion threads on HN and Slashdot: http://news.ycombinator.com/item?id=2296612 http://tech.slashdot.org/story/11/03/07/1337211/Nokia-Sells-Qt#comments Announcements from the Qt team and Digia (the purchaser): http://blog.qt.nokia.com/2011/03/07/nokia-and-digia-working-together/ http://www.digia.com/C2256FEF0043E9C1/0/405002251 
I remember Meyers bringing up the issue in "Effective C++" a while ago, I think it's interesting C and C++ explicitly prohibit this kind of behavior, since it can produce undefined results
If used over excessively, I'm afraid that auto will be our worst friend. Granted, it is easy to use, but as I see it, it hides (strict type) information (from programmer) which makes maintainability more difficult.
Yay. Know people from Digia, and they're decent, take this shit seriously. Nokia was just abusing Qt for whatever they could get out of them, then treating them like crap whenever they made the smallest mistake (ex-nokia guy, went crazy downhill). With luck, Nokia will end up selling the rest of Qt to Digia for $1 or something, and Digia can create a decent platform out of it (Qt has amazing tech, but no business capability, digia has a little). Either way, best possible outcome given the circumstances. Oh, Fuck You Microsoft, and now Fuck You too NokiaSoft.
From [slashdot](http://tech.slashdot.org/comments.pl?sid=2026132&amp;cid=35405640) &gt;Hi all Here are a few points that might add clarity. &gt;Nokia did not 'sell Qt'. It selected a partner to sell commercial licenses and support services, a task that is currently done by Nokia. Qt is offered under two licenses - commercial and LGPL - and the large (majority in fact) base of non commercial users are not impacted by this change. &gt;The agreement lets Nokia focus on Qt for its core businesses, and ensures Qt commercial customers - mainly in the desktop and embedded space - are given top service by a company that has commercial Qt licensing at the core of its interests. &gt;The development of Qt has not been sold or outsourced and is not impacted by this change. Nokia's commitment to advancing and developing Qt for all Qt users has not changed - it remains commited. &gt;You can read some more details at http://blog.qt.nokia.com/2011/03/07/nokia-and-digia-working-together &gt;Regards &gt;David Stone &gt;Communications Manager, Qt
Another article about decltype by Scott Meyers: http://drdobbs.com/article/print?articleId=229300511
Order dependencies of global variables and static variables is a pain. I wonder if it would make sense to add to the language some kind of constructors and destructor functions for every compilation unit. Then again I'm not sure that would make a difference as its the link order between compiler units that is unpredictable (I think).
yes, I feel like it would be nice if the language had better facilities for dealing with these kinds of issues, but at least it still keeps developers employed
&lt;pee-wee&gt;ahhhhh!&lt;/pee-wee&gt;
It's sad to think that in a few years (if not already) most of Reddit will be too young to get that.
Is that a Pee-Wee Herman [catchphrase](http://www.youtube.com/watch?v=rYyD55elKJA&amp;feature=player_detailpage#t=196s)?
I made this, and while it certainly is not a panacea I'd like to show it to the world in case somebody can find it useful :) At the time I wrote this, I couldn't find any C++-library for streaming JSON. The source is [on bitbucket](https://bitbucket.org/maghoff/jsonxx/src). (Crossposted here and on [proggit](http://www.reddit.com/r/programming/comments/g0cdr/jsonxx_a_c_library_for_streamgenerating_json/))
FTA: "The less code you write, the better." This statement is wrong!
Why?
Obviously you've never had to write in VHDL. You are correct that after a certain point writing less code will start to make the code less understandable (crazy regular expressions come to mind). That said, its nice to not to have to express the same idea over and over again with only slight variation. Templates in C++ (within reason) handle this problem nicely. That alone is reason enough to use C++ over C when you have the option.
Ok, this is probably best time to ask. Is there a subreddit for C? Or do most links/discussions for C end up here? Can't find any relevant subreddits searching for "C."
"secret word of the day" was one of the skits on pee-wee's playhouse, back when saturday mornings were funny
I think divide is a bad example. You really don't need all those checks to make sure it was successful. 
Verbose Code can be easier to understand, especially when one line of code does exactly one thing and not 100 things at once.
I'm not sure why somebody wouldn't want to do more with less. I'll admit there are rare occasions where embedding some assembly is the easier thing to do. However, 9 times out of 10 there's already a decent library call you can use to accomplish the same goal.
I think "less code" in this context means sparse code not cryptically short code (plus avoided duplication).
A community for 2 years, about C, with only 97 posts? That is sad.
Please forgive my ignorance. Does C++ have any overhead when it comes to code size? I usually use C for my hobby micro-controller projects as I thought C++ would have a larger image size. I had assumed that some of the C++ feature set required more runtime support.
Skimmed the article. I like C++, but to be fair, this doesn't have to be a poly-function as the author suggests. You can achieve something similar with callback functions no? WorkOnPixel(Garaud) WorkOnPixel(Phong) etc. etc.
In your compiler you can optimize for code size instead of speed. Using metaprogramming libraries (which you probably are not) can cause a bit of code bloat though. You can ask the compiler to dump out assembler output if you are worried about the amount of code its actually generating. You can turn off RTTI and exceptions if you don't want those features in the runtime. All in all you should be able to use C++ instead of C and pay nothing whether you are interested in speed or size. The biggest advantage of C++ compared to C though is correctness (more bugs caught by the type system).
I agree with that all of that.. one small thng though. I saw you used a bit of a bad programming practice though.. in that your inherited from CommonPixelData to reuse implementation, instead its better to use aggregation to reuse implementation. Inheritance is for reusing interface not implementation. In this case though it was a POD, so the data members are the interface.. so it might be Okay.. but its a bad habit to get into.
Yes. If you care about performance (if you don't, you are probably using the wrong tool if you use C or C++) you should sort your data to avoid branching inside heavy loops.
Thanks for explaining that to me.
C programmers are busy reinventing the wheel. ;-)
She has great communication skill. I definitely feel smarter after listening to her.
I think you're right that aggregation is better than inheritance when one wants implementation and I know basically nothing in graphics programming. That said my initial thought were the same but maybe this is simply because the name of the structures were selected to represent what they hold instead of what they are. Again, I'm probably wrong here but I would have called the base class SpanningPixel and the other classes something like SpanningAmbientPixel. From the code, the 'x' seems to represent the same thing here.
Is it any good?
all i heard was blah blah blah MVP blah blah
You must have selective hearing. I heard them talk about the evolution of C++ and some reasons why it could never be buried. When C++ is the right tool for the job, some other stuff and also how you too can become an MVP.
&gt;The Standard allows casting a method pointer to an unrelated method pointer via reinterpret_cast (5.2.10.6/9) and states that *invoking this cast method however is to be considered __undefined__*. In practice however the invocation actually does exactly what you would expect on leading compilers. Q: What is the output of this program? int main(int argc, char **argv) { int c = 1; c = ++c + ++c; printf("c = %d\n", c); return 0; } A: Undefined. If you think it's defined, try changing compilers, or even compiler settings. gcc outputs 5 or 6 depending on optimization settings. That's the problem with undefined behavior. &gt;However, the practicality of the result is questionable. Thankfully, the author does point out that it's more of a hack than something you should use. 
Anyone know what 'agents' are like in the MSVC library? For the rest there are std:: or free (boost, Intel TBB) equivalents it looks like. 
We use boost::function and boost::bind for this. Pretty reasonable... 
Another happy face in the C++ community. Thats good. Stephan Lavavej being another. We have enough grumpy old men with beards to spare (you can visit them in their natural habitat at comp.lang.c++.moderated).
stupid question, is there still a point for delegates when we're going to have lambdas in C++0x ?
I tend to use boost::signals2::signal (Signals2 is better than Signals because it doesn't require a runtime library). // Define the event typedef boost::signals2::signal&lt;void ()&gt; BasicEvent; BasicEvent MyEvent; // Connect the event MyEvent.connect(boost::bind(&amp;MyClass::MyFunction, this)); // Then just call the event MyEvent();
&gt; stupid question There is no such thing. To answer your question: yes, there is still a point. In C++, if you want to pass around a function as a variable you can do that easily with function pointers (some might argue that the syntax is weird, though I think it can be learned). The problem comes in when you want to do this to class member functions. Since in reality they all have a first `this` parameter that need to be valid. Delegates are a way of encapsulating the object and the function you want to pass around. With function pointers you would need to pass both an instance and the function pointer to be able to invoke the function. Lambdas are a different story. On one hand they allow you to define functions in a strictly limited scope (e.g. inside the body of a loop or just any block), on the other hand they can be used as closures. That means that the lambda you define will have access to the scope it is defined in (all variables and other lambdas, too). C++ gives a very complete way of specifying how these things are passed to the lambda function (references/pointers or copies). This gives the ability to use some functional stuff much more elegantly in C++ (e.g. STL's `&lt;functional&gt;` things that required a function pointer now can be used with a nice lambda).
It'd be cool if you could define methods as lambdas and use those as closures. Is there such a possibility? Or do you have to define lambdas within a method? 
How would that work? I mean how could you tell from a method that which scope is it being called from?
[C++ for Java Developers by Timothy Budd](http://www.amazon.com/C-Java-Programmers-Timothy-Budd/dp/0201612461/ref=sr_1_6?ie=UTF8&amp;qid=1300068444&amp;sr=8-6) is an excellent book. It's not free but the used price isn't bad.
thanks for the great answer, I still don't get it though :) Can't I encapsulate the object and the member function I want to call in the lambda itself ? like in: class A { int f(int); } a; auto delegate = [&amp;a](int x){ return a.f(x); }; and then I can pass call_f_in_a around (provided a doesn't get destructed but that's a different story) isn't this equivalent to ? Delegate delegate = createDelegate(&amp;a, &amp;a::f); thanks again
Seconded. It's a quick and painless book that I went over in a few toilet-sittings. I then switched to a C++ project from java and had no problem. **edit**: I was confused and actually read a book with a slightly different title. Please see my grandchild post.
You are right, I didn't think of that. 
Thanks for the tip! I looked it up and it seems the first and only edition is from 1999, 12 years ago. I imagine C++ hasn't changed all that much in that time, but what about the STL, compilers and development environments? Thanks again for the recommendeation.
what kind of project? just out of curiosity
A game engine for pre-rendered backgrounds with 3d elements a la resident evil and final fantasy 7. I'm hoping i'll be able to use ogre.
Cheers! What do you think of the issues I posted to your parent comment?
Oops! I was looking at the wrong book. I read "C++ for Java Programmers", 2004. That is a great book and it was even recommended to me by a professor. I cannot vouch for dmooney1's recommendation. 
By Imperial Order: Those with the Java taint hiding in C++ ranks will be sniffed out and eliminated.
There have been a number of changes in that time but the fundamentals remain the same. This book will get you jump started. The biggest development since '99 is the progress towards an update to the C++ language and standard library known as C++0x. Many compilers, including Microsoft and Gnu, have already implemented many of the planned features. Wikipedia has a good article. Also Boost, an open source collection of high-quality C++ libraries, has come a long way since '99. To be a good C++ programmer requires more study and practice. Books by Scott Meyers and Herb Sutter will help you advance more quickly. Read the top C++ questions on Stack Overflow. My language learning track was Pascal -&gt; C -&gt; C++ -&gt; Java but my C++ teacher basically just taught us a tiny bit of C++ needed to express basic OO theory. So it was just C w/ classes and inheritance and some basic iostreams stuff. It took me some time to realize how big C++ was and how little I knew. Try to avoid falling into this trap.
Its scope would be that of the object as it would be created at that time. The problem I see is that C++ closures are objects. So doing what I want is possible, but it would have to be a member reference to a closure. Unfortunately, you can't define an object member within a class. Only during construction. That's what I THINK will happen since only integral types can be defined within the class. I hope they allow an exception (pardon the pun) for closures. 
Please correct me if I'm wrong but I can't see why this should work. The cache map is local to the memoize function, it is therefore destructed when returning from it, there's no way to keep a reference to it out of the scope of memoize. On the other hand The lambda only captures a copy of the map (copy by value). Why would the map object be the same (by reference) each time the lambda is called? For me the map would be a new object each time the lambda is called, so the cache would be always empty. [EDIT] I haven't tested the code, just looked at it.
&gt; Why would the map object be the same (by reference) each time the lambda is called? The lambda captures the cache by value, which means that the lambda creates an object that contains a copy of the cache as a member. The lifetime of the cache will then correspond to the lifetime of the lambda object. So if you call the lambda object repeatedly, it will use the same cache. (But if you call memoize repeatedly, it will create new objects, each of them with its own initially empty copy of the cache.)
Thank you. I had no idea the cache-capture worked this way but it all makes sense now.
neat use of variadic templates
Visual Studio is nothing but hoops. No offense, but try an IDE that actually supports technologies beyond the vendor's own.
Interesting to see how for small arrays the parallel version(not the hybrid versions on the 2nd page) is less efficient. Guessing this has to do with the overhead of creating a parallel task. For smaller arrays its just not worth it.
He needs to unit test his flow chart.
There's always overhead in making an algorithm parallel. Recursive algorithms are easier to parallelize (think [Map Reduce](http://en.wikipedia.org/wiki/Map_reduce)), but infinitely harder to design correctly. At some level, you need to coordinate all the subtasks. He doesn't show the merge code, but I'm guessing that's where the coordination is since this is merge sort.
Given that they can't tell the difference between 0x and Ox, I have my doubts...
Then there's the whole fact that it's *still* not a standard yet. And the book is 2 years out of date. A lot has changed since then...
&gt; 2009 will bring us the second [ISO C++ standard] &gt; * Easier C++: An Introduction to Concepts I don't think so.
is it just me or does anybody always read C++0x as cocks?
It's only you, but thanks from now on I won't be able to take it out of my head...
Example B is better in my opinion. But the great thing about C++ is that it doesn't force you to use a style that some guy a long time ago decided was the best. So use what ever you want. Hell, you could even do class Foo{ private: int whatever; public: int foo; }; if you wanted to. (PS, I don't think you can initialize variables like you did)
I agree, that is a nice feature of the language... No you can't, they were just visual
Generally from code I've seen, people tend not to indent labels (such as for switch and goto statements, and for class sections), but you're free to do it if you want. Just try to be consistent within each source file, if not with a project.
Your lines might get long if you have verbose identifiers, nested classes, or functions defined in the class declaration. You might not want your lines to get too long for the sake of readability or a coding standard. If these considerations are important enough, you might choose to sacrifice a level of indentation for the access specifiers.
It's just to save some space. Once you start nesting more complicated things inside the class definition, you can find yourself way in right-field. So here's a complicated example: class KotrObj { private: int foo; public: typedef uint32_t KotrObjID; struct EVENT_DELAYED : KotrObj::EVENT { struct { struct { int max, min, avg; } points; PLAYER_ID triggered_by; // the player who triggered this event PLAYER_ID playback_for; // the player who should be the recipient of this event. KotrPlayerState players_inside; KotrFreqState freqs_inside; } old_state; EVENT_DELAYED(KotrObj::EVENT const&amp; copy) : KotrObj::EVENT(copy) { this-&gt;old_state.triggered_by = PID_NONE; this-&gt;old_state.playback_for = PID_NONE; this-&gt;triggered_for_obj = 0; this-&gt;delayed_for_ms = 0; } }; ... KotrObj(); KotrObj(KotrObj const&amp; copy); ~KotrObj(); };
Nesting to that stage just gets ugly also inline functions in the class structure just adds more confusion.
the nesting sure is ugly at definition time. But when it's being used, the organization it gives pays off by being self documenting. Unfortunately, inline functions are something I commonly see.
Although if it were a `static const`, you could initialise it, and with [in-class member initializers in C++0x](http://www2.research.att.com/~bs/C++0xFAQ.html#member-init), that will become valid.
Seeing them commonly doesnt make them good
It makes no difference and no one will think you are a “better” C++ programmer for using one style over the other. What matters is: * If you are in a corporate situation, you already have a style guide. Follow it. * If you are writing code for an existing project, be consistent with the existing code for cryin’ out loud. * If you are starting a project from scratch, pick the one you like and stick with it. 
Good advice here. One thing to keep in mind when you look at code examples, especially in books or in blogs, is that the author often compresses things horizontally to save space. Better to look at other people's C++ code and see what style they've settled on. Never underestimate the power of sitting down and just reading code. 
That's not standard C/C++ code formatting. The latter is, other than the requirement. K&amp;R style is same line braces, four space indents. It's just a tutorial with different preferences than yours. C/C++ doesn't care what your formatting is. Just do what you think is right. Incidentally, real programmers won't care what you choose either, as long as it's consistent, and doesn't clash with the rest of a larger project.
&gt; (PS, I don't think you can initialize variables like you did) You can if they're static. 
My personal preference is to half-indent the labels: class Foo { private: int whatever; ... public: int and_so_on = -1; ... }; This really is half-indenting, as I use a four-space indent for normal blocks. But use whatever you like best, unless you're obeying external some coding style. Just throwing my suggestion out there.
[Netbeans](http://netbeans.org/features/index.html) 
Vi
emacs, of course You might try Ultimate++
Since style is not mandatory of C++, you should pick a style you like and stick with it. [Indent style](https://secure.wikimedia.org/wikipedia/en/wiki/Indent_style) Allman style is what Microsoft uses. Most Linux code will be in K&amp;R style. 
qtcreator works really well
I have tried them all. The only real competition comes from Kdevelop 4
I recommend doing whatever the automatic indentation in your IDE wants to do. And for the love of god, please put the first curly brace on the next line ;)
Kdevelop is the only alternative IMHO. Eclipse bugs the heck out of me for C++/C development for lots of reasons. I love eclipse for Java development, but it's always seemed like the C++ stuff was just uncleanly glommed onto the side. That said, there's lots about Kdevelop that bugs me also. I hate to admit it, but Visual Studio is my hands down favorite. Unfortunately I very rarely ever use it because I'm usually not developing for a Win platform...
"The committee shall make no rule that prevents C++ programmers from shooting themselves in the foot." Made my day :) 
Indeed, one can go a long way with Vi (well, Vim in my case) and ctags. I'd imagine emacs can do just as well, though I'd have to use viper-mode or some other crutch to survive it for long. :D
I generally use the first form, though I like to keep the `private` label at the bottom of the class, since people aren't supposed to be mucking about with the private portions in the first place. My reason? Habit, mostly, but also screen real-estate. I'm a Pythonista as well, you see, and have been coding to PEP-8 long enough that I try to keep my code from getting *too* much over 80 lines. :D
I like code::blocks ok. Better than eclipse anyway. I'd like eclipse much better if it weren't for their "one folder/one project" philosophy.
I tried Code Blocks on OS X for the first time today. I was attracted by claims that it was sleek and lightweight as compared to Eclipse. Unfortunately, it beachballed for about 30 seconds as it started up. When it finally loaded the interface, it was in a 400x400px window, with each of its almost 10 default panes unusably small. I got a helpful on-load popup box, whose initial tip was—no joke—that I could stop the on-load popup box from popping up if I clicked the "never show this box on startup" box before clicking close. I quit and re-launched to the same 30s beachball, and then trashed it. My life is too short for bullshit software like this.
I know this may not be the best, and it's not even at version 1 yet, but I've been playing around in [Redcar](http://www.redcareditor.com). I love it so far and I'm hoping more people gather interest in it so they come out with version 1 quicker. 
I recommend **poppler** (http://en.wikipedia.org/wiki/Poppler_(software)). You can also try **MuPDF** or **Xpdf** (http://en.wikipedia.org/wiki/Xpdf). When it is developed, I presume that the best free library will be **GNUpdf** (http://www.gnupdf.org/Main_Page). For now you can contribute and, hopefully, it will be available soon.
I looked into some PDF parsing libs back in 2007. At the time xpdf was the king, but GPL2 prevented me from doing what I needed to do (add to a commercial product). PoDoFo was immature, but the guys working on it were putting a ton of effort into it. It was LGPL as well which worked for me. 
Don't get me started on curly braces on the next line :P. That's another thing that seem to be the standard, but I don't do out of habit (Java).
What OS are you on? If Unix/Linux (maybe there are windows versions): **pdfinfo** will give you basic information about a PDF, such as number of pages, page size and file size. **pdftk** has some useful commands such as spliting, or merging PDFs. It can also uncompresse and rotate them. **Ghostscript** Can also split, or turn individual pages into images (I think you have to have image magic installed). Ghostscript can do a lot of stuff, but I find it hard to get the exact parameters set up. **xpdf** I haven't really used this, but it's out there and it's free. 
If you're on Windows, use Visual C++ Express Edition. If you're on OSX, use XCode. Otherwise, try Code::Blocks, Qt Creator, or KDevelop.
Emacs + CEDET + vc-git/svn is great for simple C/C++ projects. Would be nice to see some unit test integration, better handling for complex dependencies in the generated Makefiles, and, of course, a lot better syntax completion. I use it for projects with fewer than 20 files. Anything more than that and you'll start to see where its flaws lie.
Win32 using VC2008. I'm trying to get xpdf to work with limited success... Well, make that no success... Having trouble with the last statement and LIBCMT issues with the linker... Grrr... I suck at command line compiling...
http://poppler.freedesktop.org/
I'll second that, actually beats out Visual Studio imo
We use Understand (getunderstand.com) 'cause it also supports Fortran.
vim + clang_complete script works like a charm, far better than ctags!
I'd given clang_complete a shot a month or two ago, but had given up since it didn't play nicely with my precompiled headers at the time. But seeing as I have a slightly more sane build system (ala premake) in place now, I'm going to give it another go. Thanks for reminding me! :D
Seconded. I use gvim for most of my tasks at work, even though we have VS and Eclipse support.
QtCreator has Vi-mode.
Be careful with OGRE, being a framework they use some designs that are bad design practices for you and me but good for them. Try this books for c++: http://www.linuxtopia.org/online_books/programming_books/thinking_in_c++/index.html http://www.linuxtopia.org/online_books/programming_books/c++_practical_programming/index.html
Thanks for the heads up and the reading tips! What and where are those bad practises in OGRE?
Mostly I don't like the boilerplate code (some tedious recoding - code::blocks tries to solve it). Many operations have a specific order of calls that you have to comply (Which is understood because it's a vast graphical framework). But it's still great and really fun to work with. Have you tried Unity? (I don't even know if you can bind to C++) I hear some chatter about it.
You forgot to link the link! You can either make a text post (Title, text) or a link post (Title, link). You don't get to do (Title, text, link).
I love how it highlights errors in red as you edit. Is there any way to check the error message though?
I personally combine them and use Linux style naming with Allman brackets.
http://herbsutter.com/2011/03/24/book-on-ppl-is-now-available/
The FDIS has not been published yet, but here is the last version of the draft they were voting on (there may be slight changes in the FDIS which will be published soon). http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2011/n3242.pdf
FDIS? Thats short for "*Fuck dis I'm going home*"? Good news though. I would hope they don't wait as long to start working on the next standard. We still need concepts badly. It would be better with smaller incremental standards. Maybe one every five years. Edit: A bit more info on what was discussed in the meeting is found [here](https://www.ibm.com/developerworks/mydeveloperworks/blogs/5894415f-be62-4bc0-81c5-3956e82276f3/entry/the_c_0x_standard_has_been_approved_to_ship23?lang=en)
*This time, virtually all features have actually been implemented in at least some shipping compilers, and design churn and overall design risk are significantly lower.* I like that. Hopefully it won't take too long for the major compilers to provided complete C++-2011 support. I wonder who will be first to claim this.
Hi - looks interesting but whenever I see powerpoint style slides I really want the video of the presentation too. Making notes during the presentation always harvests far more information as presenters inevitably embellish points with anecdotes.
Complete support? I'd be surprised if it'll be before 2013/14. probably gcc would be the first, MS won't add the complete implementation in the future service packs (they didn't add any in vs2011 sp1) so they would probably wait to a major release. I never used Clang but I think that they have other important work before.
So.... we're gonna call it C++0B?
wtf pay? get lost
It will be called C++ 2011.
GCC 4.6 is [very close](http://gcc.gnu.org/gcc-4.6/cxx0x_status.html). VC++ 2010 is behind GCC but not too far. I hope by 2012 both compilers can fill the gaps and we have full C++ 2011 support.
For a list of current GCC support of C++0x features, see the following link: http://gcc.gnu.org/projects/cxx0x.html
I haven't gotten into the rest of it, but nullptr is a nice addition. I've been using it in VS 2010, and I'm glad to hear that it's in GCC now.
Who said that?
C++ 0X was a name used in the community to denote a future standard with and an unknown date of publication (0X meant eveybody hoped it would be some year before end of 2009). Standards are usually named with a document ID and year (i.e. version). For example we have C++ ISO/IEC 14882:1998 which is the first C++ standard. The next version was ISO/IEC 14882:2003 and the next version will be ISO/IEC 14882:2011. As why 2011 and not 2012, I guess Herb made it clear in his weblog how the process goes: technical committee has finished its work and only some editorial job remain which is projected to be finished by summer. Notice that all the delays these years was due to problem they found in the standard in the technical committee.
hmm, could have spent his time on more practical things...
Why not C++0B, C++11, ...? Any official statement on the naming?
As far as I understand standards' versions as convention are always stated in full, 4 digit decimal years. Now in common use people my simplify it and say e.g. C++ 98 where they really meant to say was C++ ISO/IEC 14882:1998. So what will the community decide to use for the new C++ version? Hard to predict. I think if you say C++ 2011, everybody will understand what you are talking about.
Writing compiler unit tests is very practical.
I got all excited by the title and upvoted before clicking, expecting to see some funky template wizardry. Was disappoint.
If you are wondering why I didn't link to the article directly.. its because this is a reposts from 9 months ago, but it got downvoted then and went unnoticed. This article is by far the best explanation of rvalue references I have found. If you don't know what rvalue references are or how they affect overloading. Its time you read it.
The accepted convention for reposts is to append a query string such as "?repost..." to the URL. avoids blogspam, and gets through reddit's repost filter. No harm, however, since you were posting a link to a link for good, not evil, but just trying to help.
Interesting, I did not know that. So I could have done this: http://thbecker.net/articles/rvalue_references/section_01.html?repost 
There is a link to the source on the page
Yessir.
added the link. did not know that - haven't posted an article in a long time. my apologies.
u dont use rem2
ignore rem2, i need it to tell if the second input value is also either even or odd.
 void EvenOrOdd(int value) { static const std::string str[2] = { "Even", "Odd" }; std::cout &lt;&lt; "Value is : " &lt;&lt; str[value &amp; 1] &lt;&lt; std::endl; } 
It's no use: In the end you're still using a conditional to *make use of* rem3. There's no escape, give up :)
To be honest I would question the value of learning how to program without if statements. But here is one way: &gt; std::cout &lt;&lt; "is value odd: " &lt;&lt; std::boolalpha &lt;&lt; bool(value%2) &lt;&lt; std::endl; Here is another &gt; std::cout &lt;&lt; "value is " &lt;&lt; ((value%2 == 0)? "even" : "odd") &lt;&lt; std::endl; 
The level of amateur in this thread is frankly overwhelming. There are good reasons to learn to program without if-statements (branches are a pain, and learning tricks to avoid them can be invaluable), and to claim, as some have, that one would eventually be required to use an if-statement to handle this is incorrect and shortsighted. Just because you aren't smart enough to do this guy's homework doesn't mean it can't be done. It just means that you would fail this class. The higher level concept you are looking for here is to determine the remainder mod 2 (x%2 or x&amp;1, though an optimising compiler will turn the former into the latter for you, so readability is key here), and then later, when you have a 0 or 1, where 1 will suggest odd parity, you want to, perhaps, key all actions or output out of a length-2 array, as [lkz](http://www.reddit.com/user/lkz) has shown. No muss, no fuss, no pesky branches. Using the ternary operator (?:) or switch statements are not in the spirit of what is being asked here anyways. ?: is shorthand for if-then-else, so it is out, and switch statements are really meant to clean up long if-else-if chains that have integral keys. Both of these aren't exactly "if-free" (though, you could argue that the switch statement is actually a different sort of branch. Not your typical if-branch, but a branch nonetheless).
Branches are sometimes costly, especially in the midst of a massive loop. Incorrect branch prediction can slow down the instruction pipeline.
~~Programming~~ Code without if's is LOADS faster. Every time there is an if, the instructions past that if can't be pre-processed because processor does not have enough info to figure out which path the code could take. There is HUGE part in modern processors called "branch prediction" to combat this issue. So if you can figure out to do the same thing without if's, your code will run faster, sometimes even despite the additional instructions, because the processor does not need to sit there and WAIT until your if condition resolves into actual code path. So there is your value.
That sounds awfully close to premature optimization though. Surely a good compiler will be able to optimize this better than the programmer.
Using "?" or switches are just if statements in disguise though. Surely they are no better. I think this is premature optimization. The compiler most often does a better job at producing efficient low level code than does the programmer. The programmer (especially a new one) should worry about correctness, maintainability and high level algorithmic time complexity instead.
EDIT: Whoops, I didn't see [lkz's comment](http://www.reddit.com/r/cpp/comments/gcosb/even_or_odd_without_an_if_statement/c1mlmkh) posted earlier which is essentially the same as mine. Here's what I came up with: #include &lt;iostream&gt; #include &lt;string&gt; int isEven(int n) { // test for even-ness // returns 0 for odd, 1 for even return (n ^ 1) &amp; 1; } int main () { int n = 3485; std::string txt[2] = {"odd","even"}; std::cout &lt;&lt; n &lt;&lt; " is " &lt;&lt; txt[isEven(n)] &lt;&lt; std::endl; } Output looks like this: 3485 is odd 
In some cases jump tables lead to prettier code (*imho*) than long if-else-chains, and dynamic jump tables can be lots of fun :) (i know lkz's (correct) answer is not a jump table, but imho it's conceptually similar)
Every time there even slightly obfuscated code in the place of a natural "if" statement, your developer must puzzle out its meaning in order to debug or maintain the codebase. The time spent doing that, multiplied by the number of such occurrences in the project, raised to the power of the number of bugs introduced by confused developers, is almost guaranteed to be higher than the sum total of clock cycles saved by that kind of (almost always premature) optimization. In general, unless you have hard (ie. profiling) data to demonstrate that a given optimization is dramatically (ie. orders of magnitude) better for a piece of code, you shouldn't make it. Dropping "if" statements is a really fucking tough sell in the 21st century world of optimizing compilers.
I did not think that any programmer would be confused about ? : being just a special if. Premature optimization is just a weird mantra for people who think it's ok to write horribly stupid code. There is a difference between optimizing the shit out of something and writing sane code.
There is no point to take it to extreme. I'm sure that before replacing every if and obfuscating code there are sane examples of not using pointless amounts of if. I was just explaining the possible purpose of the exercise. And almost always when I have seen someone using the "premature optimization" excuse, it has been to explain away laughably bad coding. I mean just not even considering half of the requirements bad. It is not hard to write something that works, but it takes special genius to write something so "optimization friendly", that nobody even remembers why it should be there, has taken half hours to crunch trough for years and can be replaced with something that is done in 2 seconds as a warm-up task. Also thing that helps avoiding puzzles and is taught from the very first programming classes: commenting your code. 
Only if you assume that compilers are now able to read minds. Branch prediction is not easy, and if you can just save the compiler the trouble, why not? Premature optimisation is only wrong when its hard. Something this easy surely is a win for the programmer. **EDIT:** Branch prediction is hard enough, in fact, that many programmers don't rely on it when it counts. The Linux kernel is filled with references to the `likely()`/`unlikely()` macros, and GCC offers `__builtin_expect()` to try to give save the compiler the trouble. Hell, GCC has had `-fprofile-generate` and `-fprofile-use` for some time now to let it profile your code for you to give it better statistics on common paths.
 return !!(num &amp; 0x1); // returns true on odd (given usual disclaimers about the universe.)
I wouldn't measure the readability of code by counting if-statements.
The first thing I think of when I see an introductory programming class asking to do a conditional without `if` is the ternary operator. The two-element array is interesting and elegant. Thanks for helping me think in a new way!
cin &gt;&gt; simplehomeworkproblem; if ( post == cppreddit ) cout &lt;&lt; "Silly argument" &lt;&lt; endl;
You are *seriously* missing the point here. Any idiot can write if-this-do-this, if-this-do-this, if-this-do-this. Conceptually, there is a lot to be gained by seeing the structure of some pretty formulaic problems and identifying new ways to solve them. They aren't always better, but you learn something. Once you get a few cool tricks up your sleeve, you learn to start seeing the pattern in bigger problems, which makes you a better programmer in the long-run.
Unless I'm missing something... boolean isEven(int n) { return (n &gt; 0); } Edit: Oh, for console printing use this function with an array: sign["is odd", "is even"]. The boolean function is actually returning a 1 for true and a zero for false, so you would do the following cout &lt;&lt; n &lt;&lt; sign[isEven(n)] &lt;&lt; endl; Or, more simply: cout &lt;&lt; n &lt;&lt; sign[n&gt;0] &lt;&lt; endl;
If you strip the last bit of a integer type, you can get even/odd parity 1=odd, 0=even e.g. 00000001 = 1 odd 00000010 = 2 even 00000011 = 3 odd 1000 1011 = 139 odd So basically to get the value, you created a boolean called "IsOdd" and then drop the last bit in it. You could then have a array with two string [0] = "Even" and [1] = "Odd" to do the displaying, and you would require not a single if statement, or ternary. 
&gt;boolean isEven(int n) &gt; &gt;{ return (n &gt; 0); } TIL every positive number is even.
So basically: function isOdd(int num){ return (1==num &amp; 1); }
Now I'm not sure if you were trying to imply that, in this case, an if branch is worse than using the array method shown in lkz's comment, but I was quickly trying to make up the assembly in my head to try to understand what benefit one would have over the other. I'm assuming the code up to and including the 'AND var, 1' would be identical. Then you either have the JZ or JNZ jump for the if version or the ADD instruction for the array version (ADD is used to add the result of 'AND var, 1' to the address of the array in order to use the proper index). Granted you'll have another JMP with the if version, but in the array version won't you have to call cout twice (the first time to print "Value is:" and then a second time to print the contents of array[0] or array[1]). So is there any benefit in this case to use one over the other? Obviously I understand the original purpose of this assignment was to think outside the box but from your comment I'm wondering if there is truly any decrease in the number of instructions from one version to the other.
If we are measuring superiority by number of instructions, firstly, we have left sanity for the sake of strange metrics. To humor your question however, the array version performs AND, ADD (for the offset into the array), and then LOAD. The if-statement version would reserve two labels, with a few jumps (JNZ/JZ) and a few unconditional branches. The problem is not with the number of instructions, in cases like these, but with the way an instruction pipeline works: while one instruction might be working in the ALU, for instance, the CPU is loading values into registers and prefetching future instructions to save time. The problem with branch prediction is that, since it isn't until the end of the pipeline that we have enough information to determine which branch we are taking, so all of our prefetching might be wrong, meaning that we have to empty the entire pipeline and start from scratch after the jump.
None of these posts are actually explaining it to you, unfortunately. Knowing the answer is not as valuable as knowing why it's the answer. By bitwise ANDing the integer in question with 1 (value &amp; 1), you're masking out all of the bits in the number except for the [least significant bit](http://en.wikipedia.org/wiki/Least_significant_bit). I'm sure by now you're familiar with binary math, and you should know or be able to reason that all odd numbers have an LSB of 1 and all even numbers have an LSB of 0. This will have the exact same effect as your modulus method, which is another good solution. Once you have the LSB which will either be 0 or 1, you can use it as an array index. In lkz's case, an array with two elements of std::string objects (or unsigned char* if you're not familiar with std::string yet). Once you've plucked the right string out of the array using your LSB index then you can display it as output. And no conditionals!
:facepalm: I guess I was missing something. Here I am doing differential equations homework and forgetting what even numbers are.
Of course, `f(x) = n` is an [*even function*](http://en.wikipedia.org/wiki/Even_and_odd_functions#Even_functions) for `n &gt; 0`. ...and `n &lt;= 0`, come to think of it.
I agree, but this has nothing to do with the post I replied to.
&gt; when I have seen someone using the "premature optimization" excuse, it has been to explain away laughably bad coding Your experience and mine are dramatically different.
Neither would I, but I'm not sure what this has to do with my post.
Just "return x&amp;1" would be good enough, as true is 1 and the !! trick is only needed for non- zero to true conversion.
I suspect you are referring too my comment that there is little value in learning to program without if (or other branches). I stand by it. The length-2 array solution is frankly a hack that has downsides when it comes to thread safety (static is as bad as global), and performance because the array is an lvalue so it cant be moved but has to be copied into the destination. Of all the techniques and idioms to learn as a C++ programmer this has to be one of the bottom of the list. Its premature optimization. Even Knuth considered premature optimization the root of all evil. Its a case of getting your priorities all mixed up. This kind of thing is the compilers job not the programmers. None of the advanced best practice C++ books even mention it. There is nothing about it in any book by Scott Meyers, Herb Sutter, Alexansrescu etc.. I challenage you to find one well respected C++ authot who thinks this is important to learn (especially for someone new). What is much more important is learning RAII, STL, exception safety, encapsulation, time complexity analysis etc. 
It is this enterprise-level "let me read you the literature" approach that hurts programming in an academic sense. I am not suggesting that removing branching control statements is pivotal to being a good programmer. I am trying to make it clear that there is a lesson to be learned here, and it is that there is more than one way to solve a problem. Anyone can write blocks of if-then-else, if-then-else, but there are other ways to solve problems than to just worry about RAII, encapsulation, proper data hiding, multiple inheritance... If every problem were solved with the STL, would we have ever discovered Fibonacci heaps, spectral clustering, cartesian trees, etc. The point is to learn to think for yourself. To think about a problem with a set of constraints that forces you to find a new way to approach the issue. Let me know what Scott Meyers, Herb Sutter, and Alexansrescu have to say about the contributions of Dijkstra, Knuth, Turing, and our other forefathers. Or fuck those old guys, and lets just use the STL to solve all our problems. std::vector&lt;&gt; is pretty cool, right?
Even Knuth considered premature optimization the root of all evil. I guess that means you must consider his code stupid. The bottom line is that you as a programmer are a worse compiler than the compiler. Concentrate on getting the high level algorithmic complexity right.
 const char* f(int n) { static const short e[sizeof(int)] = {'e'-'o', 'v'-'d', 'e'-'d', 'n'}; static const short o[sizeof(int)] = {'e'+'o', 'v'+'d', 'e'+'d', 'n'}; static char r[sizeof(int)+1]; // not thread-safe! const int m = 1-2*(n&amp;1); for(unsigned i=0; i&lt;sizeof(int); i++) // compiler unrolls this // loop, no branches r[i] = (o[i]+m*e[i])&gt;&gt;1; r[sizeof(int)]=0; return r; } 
Fair play.
Oh come on guys, we can do uglier hacks than what I've seen so far! vector&lt;string&gt; formats(2); void do_it(const long val) { try { std::cout &lt;&lt; formats.at(val) &lt;&lt; std::endl; } catch (std::out_of_range&amp; e) { do_it(abs(val)-2); } } int main(int argc, char** argv) { long input = atoi(argv[1]); formats[0] = std::string("Even"); formats[1] = std::string("Odd"); do_it(input); } 
&gt; Premature optimization is just a weird mantra for people who think it's ok to write horribly stupid code. No, it really, really isn't.
 bool isEven(int num) { return num % 2 == 0; } bool isOdd(int num) { return !isEven(num); }
Other reason for my experience may be, that in most projects the "mature optimization" phase never really arrives until it's years later and program that has kind of always worked has grown to sluggish monster that everybody is afraid of. Probably that's the point where they have called me.
Suitably ugly, verbose and unnecessary. Go to the top of the class.
You are suggesting here there is some conflict between todays leading computer scientists and those of yesterday. There isnt. Dont forget the STL was born in academia and has its underpinnings in mathematics. Its almost a wonder this academic marvel made it into the wild. We should be thankful for that. Back to the point, Knuth said it himself. Premature optimization is the root of all evil. I meet a lot of programmers who dismiss modern C++ in favor of C. They seem to think working at a low level detail is good and that any abtractrion is bad. This if anything is anti-intellectual. If abstraction is a good idea in mathematics its a good idea in programming. Branch prediction is a CPU optimization. You are making a lot of assumtions about the specific omptimizing compiler and the specific CPU if you start writing code trying to tell the CPU how to branch optimize. When you start trying to do the compiler and even CPUs job, you are bound to get things wrong. Good programming is about stating your intent and letting the compiler and libraries choose how most efficiently to execute it. Anyone who has studied algorithmic time complexity knows it does not matter much how many cycles are spent on individual operations. What matters is how the algorithm scales.
Could have yes. But why should he? If he had fun, I think it was a good investment of time for him. Do you never go out just to do something inpractical? Karting? Bungee-Jumping? Skating? Jogging? Drinking a beer with your friends? Something like that? For all of them one can say "could have spent time on something more practical". Apart from that, what practical thing have *you* done? Also, it is not really inpractical, see jugglists comment.
!! makes a bool out of an int. It's generally not required, but I prefer to use it semantically as it makes the code more readable (by implying the return type).
I look forward to using nullptr as soon as our dev team moves to the new version. I think some of the best enhancements to come out of C++0x have been the simpler ones (simple as in in terms of concept, not execution), like 'nullptr', 'auto', and fully typed enums.
Thank you! I was worried people didn't understand the point of the exercise.
I believe that **form** do matter and unfortunately many companies do not have a C++ code layout style. And many do not enforce it. I believe the C++ community really needs a good/flexible C++ code layout style checker (application like Java's CheckStyle). The tool should complement the more important static code analysis, like testing for and enforcing quality, performance, security etc. A good code layout style should in my book favor readability/maintainability. I don't think these are as subjective as we might think, but there are very few research papers and statistics available from studies about which styles increases readability/maintainability. Surely I have never seen any for curly programming languages. More: * [Indent Style (wikipedia)](http://en.wikipedia.org/wiki/Indent_style) * [Programming Style (wikipedia)](http://en.wikipedia.org/wiki/Programming_style) * [C++ CheckStyle - the hunt for a good C++ code layout style checker program](http://www.suodenjoki.dk/us/archive/2010/cpp-checkstyle.htm)
You're getting *super* hung up on the specific problem and not on the spirit of this assignment. This problem is not made to teach students that if-statements are evil. The point is that there are several ways to solve any problem, and that if you always solve problems in the easiest, quickest way, you may not see interesting patterns. If I were going to write some code about whether or not a number were even or odd, honestly, I'd probably use the bit-tricks, because I know them, but there is nothing wrong with writing some if-statements. My initial point was that there is good reason to learn HOW to avoid them, and HOW to do without them, not that they must always be avoided. This was my point about academia. Not everything that is being done is for optimisation. Just because a student is told not to use if-statements, a teacher is not telling a student "you are better than an optimising compiler". In fact, at this point in a student's eduction, an optimising compiler will write better code in 10 out of 10 cases. The most important thing to teach a student now is "be creative" and for them to not to get trapped in the easiest, quickest, two line solution to every problem. You can write a for-loop to walk through a binary search tree, but isn't it really cool to think about tree traversal as recursion? Once you realize that recursion is perfect for that job, it makes everything look so clean and cool. Now, the STL uses red-black trees for almost everything (lets just talk about std::set&lt;&gt; right now, which uses red-black trees in GCC's implementation). To the user, it looks like list traversal. It isn't. It's tree traversal. If you don't show that to the student, they don't get to see how cool recursion can be. Should we stop having students implement their own linked lists? I mean, the STL offers std::list&lt;&gt; and std::slist&lt;&gt;. How about self-balancing binary search trees? Students should never need to learn how to implement one of those, since std::set&lt;&gt; and std::map&lt;&gt; uses those for you. Hell, let's get rid of arrays entirely, since std::vector&lt;&gt; handles resizing for you. Students will never need to know how to manage their own memory with the STL around. Thank god for the STL!
Ahhh....I didn't realize that thanks for the response
The C++ Primer Plus already weighs five pounds, I wonder how much weight this new standard is going to add to it.
Maybe the use of auto in code samples will counteract the length of describing new language features.
Sorry, but both this blog post and the blog post it linked too where unmotivated opinions. Where is the meat? C++0x if anything is proof that C++ has not stopped evolving. Its a huge change (in the right direction) even without concepts. We will get a clean concepts feature eventually, because everyone wants it. I would hope though it does not take another decade. But even if it did, there is no alternative language that can take its place.
Here's a tip: buy Visual Assist X :)
You say that as if it is news. If you're stupid enough to make unconfirmed assumptions about the ordering of side-effects, you deserve unexpected results.
[Here](http://www.cppreference.com/wiki//language/operator_precedence#order_of_evaluation_and_of_side_effects) is an explanation. [Here\(PDF\)](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1124.pdf) is the ISO C standard. Sequence points are described on page 438.
Lets not start the name calling again. Its not self evident that "=" does not make a sequence point. Please note that it's well defined for user defined types though (with copy constructor or assignment operator) because entering a function is a sequence point.
I agree, but I suppose it doesn't hurt to remind people. There may be some newbies reading who haven't stumbled upon undefined behaviour before. Especially as other languages aren't quite as brutal when it comes to things like this.
A car has 50 times more lines of code than an airliner??!?
That reminds me.. here is a leak of the c++ coding standards for the [Joint Strike Fighter](http://www.scribd.com/doc/3969122/Joint-Strike-Fighter-C-Coding-Standards). They could probably have avoided writing that thing if they just gone with [this book](http://www.amazon.com/Coding-Standards-Rules-Guidelines-Practices/dp/0321113586) instead.
As far as "name calling" is concerned, I'm sorry if I was unclear. The "you" in my statement was the general "you". I don't take you to be stupid, but I was merely trying to call to attention that making invalid assumptions invalidates expectations. And good call on the clarification, and I can see how this might be confusing, but I would hope that anyone that didn't know those details would avoid writing ambiguous statements like `x = x++;`
No worries.
Not only is it not self-evident, but I think it's a natural assumption that the expression on the right side of "=" is treated as a temporary with move semantics (even if the programmer doesn't think of it in those terms).
 main.cpp: In function ‘int main()’: main.cpp:10: warning: operation on ‘x’ may be undefined 
Simon Sheng? Is that you? From Motorola, many years ago? Remember when you submitted a defect report to Microtec Research saying that their C++ compiler was defective when you wrote i = i++; and i never incremented? And you were so stupid, arrogant and headstrong that you instantly assumed the compiler vendor, who's probably spent more time with its nose in the C &amp; C++ standards than you have with your nose in girly magazines, yes clearly *they're* the ones with the defect. Really? Are people still making this mistake??? There are 100 ways to increment i correctly, all I ask is that you pick one of them. ++i; i++; i = i+ 1; i += 1; etc.... 
Wow. These are the kinds of mistakes absolute beginners make. No C++ programmer worth his salt would write code this bad. Example 1 is something a new programmer might do if C++ is his first language and he's been at it barely a year. Example 2 is something a programmer might do if he can't track logic. Again, a programmer with any reasonable experience is unlikely to make this kind of mistake. Letting it happen is just sloppy. Example 3 is is just damn sloppy. If the destructor is doing anything that might throw an exception, it's probably doing too much at the wrong time. It's just bad design and bad work. Very. Bad. Examples.
It's approved for public release. Here it is on Stroustrup's page if you don't like scribd: http://www.research.att.com/~bs/JSF-AV-rules.pdf When it seems like the lunch order is classified, it's nice that they made this available.
That's only 4 ways. This is Reddit, darn it. I expected to see 96 more! 
UDB, no intervening sequence points
It was in binary
Not sure if your question is rhetorical or not. But no, neither me nor the author of that blog post has that name (seems a bit harsh though to name and shame some random programmer you once worked with). I posted this because I find sequence points an interesting gotcha. I agree the other examples in that post are not very interesting. 
I posted this because I find sequence points make for interesting gotchas. The other examples in that post where not very interesting. The second example: When it comes to using null pointers.. bugs like that are common but are best dealt with by using asserts. High quality code is usually littered with asserts. Asserts are for testing programmer assumptions (they catch logic bugs). I could if I had too work without unit tests, but not without asserts. aserts also document intention more directly than any comment ever could. The third example: The compiler should be able to produce a warning on the throwing destructor (at least in c++0x destructors are defined as nothrow). Also as someone pointed out it should be able to warn about the first example.
\*facepalm\*
[Undefined behavior. The variable is modified while being used twice between sequence points.](http://www.viva64.com/en/d/0162/)
That does seem counter-intuitive but a car is in permanent contact with the ground where there are orders of magnitude more variables than at 30k up. Take off, landing and taxiing are already inherently controlled and simpler to compute than say traction control on various road surfaces.
Here is my summary of the results: * In all the tests GCC is either faster, the same, or marginally slower than Clang. On the other hand, there are tests where Clang is significantly slower than GCC. * In one of the tests GCC with LLVM backend is significantly faster than GCC/Native backend or Clang/LLVM. * There are still programs that Clang cannot compile. * GCC 4.6 doesn't seem to be any faster than GCC 4.5.2 * Clang is significantly faster at compiling the code than GCC.
If only I had a half-tab button...
This is how to configure that aspect of the indendation style in Emacs: (setq c-basic-offset 4) (c-set-offset 'case-label '/) (c-set-offset 'label '/) (c-set-offset 'access-label '/) The `/` symbol represents `c-basic-offset` times minus one half. If your editor can't do this, get a better editor.
It is about time! 
The huge maybe even massive mistake you are making here is to suggest this has anything at all to do with optimization. Clearly it doesn't and is being used as an educational opportunity. There is a difference between optimization and being a code monkey that knows only what he has been taught about his coding environment. I actually have to applaud this guys professor for making his students expend a little effort beyond regurgitating boiler plate code. The reality is there are far to many schools graduating Visual BASIC programmers that can't think on their own. If this little effort causes just half of his students to come away with a deeper insight into what programming is the professor will have done the industry a great service. What you seem to imply is that schools should be graduating students with a superficial understanding of the science to that I have to object totally. Getting young minds to come up with new solutions to existing problems is part of what education is all about and is what moves science forward. 
A better tip is to make VC++ IntelliSense not slow especially when I pay hundreds of dollars for it.
Many programmers (especially c folk) make the mistake of thinking low detail = deep understanding. What is much more important is understanding the high level mathematical concepts that makes writing software a science. Think time complexity analysis, think generic programming, think STL. Pretty much all introductory C++ programming courses and books get the priority completely backwards. C is taught first and modern C++ like STL and RAII not at all, or mentioned briefly at the end or in an appendix. There is no reason you have to learn about pointers before iterators, or c arrays before std::vector, function pointers before lamdas, or even loops before for_each, or about inheritance before templated functions. In the mathematical sense the latter alternatives are the more general and basic. Seriously, the quality of programmer would be so much better if that was done the other way. Stroustrup realized this and thats why he wrote his latest book for beginners. So when I hear about professor giving new students assignments like do a branch without using the syntax of an if statement, its frankly a sad wasted opportunity to teach something both very important and very useful like modern c++ concepts.
A more precise title would be "Microsoft STL implementation details".
eww silverlight no thanks
Yeah, but you're missing out on some pretty nifty code.
You have the choice of downloading the video in several different formats and qualities. Just click one of them.
&gt; The problem is usually PCHs Hmmm... I don't use pre-compiled headers with Eclipse, but it seems much more responsive for its version of Intellisense. &gt; However, there are still differences, and occasionally, a file that compiles without error using our build compiler will not compile properly with our IntelliSense compiler. **Often, this is because the IntelliSense compiler has a more strict interpretation of the C++ standard than the build compiler.** Why? That seems just silly to me. If anything, I'd like the IntelliSense compiler to parse code with errors in it. For example, there may be an error inside a function someone else wrote, but for the module I am writing I care only about the declaration of that function with an error. 
Odd, it gave me the option of watching it using mp4.
Oh, that's cruel, posting an article like this on April 1st. Given the level of surreal complexity in the language, people might assume it's a joke.
Huh, it's almost April 3 here in Thailand.
Sorry, I meant the cpp-next blog. His entry is dated 4/1. &gt; Apr 1st, 2011 @ 09:32 am › Scott Meyers
i bet linus'd really love this mess...
People in glass houses shouldn't throw stones. C is as ugly and unsafe as they come. If you want a famous quote try this one by Robert Cailliau (the guy who developed the world wide web): &gt; *"I know only one programming language worse than C and that is Javascript"*. Personally I think he is being too hard on Javascript. After all functions in javascript are first class objects just like in proper functional programming languages. But thats another story. 
This is the only correct answer. I am amazed you are the only one to come up with it.
Probably it is necessary to draw again pictures. And that all think that it is banners. And -1, without reading. :-( Pictures aren't ads. They're the software whose source code reviewing: • Newton Game Dynamics • Chromium • IPP Samples • Return to Castle Wolfenstein • DOSBox
What kind of error are you getting?
Can you perchance indent the whole thing by 4 spaces? That should format all code as code, instead of just pieces of it. Aside from that, I can see that the average() function is declared as returning float, but the return statement doesn't have any value. You might want to do this: float average(float t1, float t2, float t3, float &amp;avg); { avg=(t1+t2+t3)/3; return avg; //&lt;------------------ added "avg" } 
In function "int main()" lettergrade undeclared(first use this function) (each undeclared identifier is reported only once for each function it appears in) I removed the "char grade;" from that function too and it still gives it to me. 
yeah i did that a few minutes ago, didn't help, i mean it did, but not for the current problem im having.
Looks like you need to forward declare your functions. by the time the compiler see the main function, it doesn't yet know about the ones below it. You can fix this by either 1) moving the functions before main, or 2) forward declare the prototype of the function and leave the bodies where they are.
That message lets you know that the compiler doesn't know of anything called "lettergrade" by the time you use it. That probably means that you either forgot to declare it, or mistyped something. Looking at your declaration of "lettergrade" function, I can see that it's in fact called "letter**G**rade", note the capilatlized G. C++ is case sensitive, so if you change "lettergrade" to "letterGrade", the problem should go away. Also, in the future I would advise to not only specify the error compiler is giving you, but also which compiler you're using (MS Visual Studio? gcc? etc?) and which OS you're using/targeting (Windows? Mac? Linux?).
lettergrade -&gt; letterGrade? You also probably want a forward declaration for it (or just put main below). 
Above the main function, but after the includes you need to declare the functions you're using. So put: char letterGrade(float avg, char &amp;grade); void input(float &amp;t1, float &amp;t2, float &amp;t3); float average(float t1, float t2, float t3, float &amp;avg); Also, after float average() function definition you have a semi-colon you need to remove.
what I came here to say :)
Is this seriously comparing a benchmark run on Linux / MySQL with a benchmark run on Windows / SQL Server / unknown hardware‽
As mentioned in [Sam's blog post](http://samsaffron.com/archive/2011/03/30/How+I+learned+to+stop+worrying+and+write+my+own+ORM) and also confirmed by my own tests, in this particular benchmark the database returns the data instantly. So as long as the DBs are of the same kind (i.e., client-server vs embedded), I would say the difference can be ignored. Regarding OS/Hardware, I agree, this is not very accurate. Dapper's results don't mention hardware, my results are from a Xeon E5520 2.27GHz box. I don't think Sam's hardware is much slower (most likely faster) than mine. In case of C#, what this benchmark tests is the ORM layer overhead. Once we are comparing C# ORMs to C++ ORMs, we are also throwing in the language and platform (native code vs CLI) differences. So overall, I agree with the criticism. But I think the results can still be useful as an indication rather than a precise measure, especially since we hear all the time how VM languages like C# and Java are now faster than native C/C++. 
Bleh...the guy is so wrong I can't be bothered to write a rebuttal; at every single line of his blog, there is a logical fallacy waiting to be debunked. 
The only thing I don't like about C is that on every platform int, long, double, etc. means something different. Why not use something like int_M16 for a 16 Bit integer with most significant bit first. 
I wrote a small [rebuttal](http://whyoopdoesnotsuck.blogspot.com/2011/04/why-oop-does-not-suck.html) to "oop sucks"... 
[`stdint.h`](http://en.wikipedia.org/wiki/Stdint.h) gives you fixed-width integer types in C99. As for floating point types, as far as you're likely to care they'll stick to IEEE 754.
I am extremely interested to hear what people have to say about this, especially the criticisms of OOP. I'm currently attempting to switch to an object-oriented paradigm (from C to C++), and praying it's not a waste of my time.
The critisisms of OOP are just plain...sorry to say this...stupid. They don't know what they are talking about. They mix irrelevant concepts together, using flaws in one language to blame OOP in general. 
Even when you see it criticized by Dijkstra, Stallman, Torvalds, etc? I'm not arguing it one way or the other, but it makes you wonder...
I don't see why the name of the person that is doing the criticism plays any role. Please show me the criticism of Dijkstra. I truly can't find a relevant paper from him showing OOP is bad. Stallman said that he tried adding OOP to Emacs and ended up thinking that it's not good. Well, in the Emacs LISP environment, perhaps it's not. Torvalds blasted out against OOP in the context of Git, where someone told him why Git is not developed in C++. Well, Git does not require OOP. The Linux kernel though has many object-oriented modules, implemented in the standard C way, i.e. via function pointers and vtables. What I see out there is thousands of object-oriented languages and frameworks, millions of oop code, and this can only mean one thing: OOP is a success. 
[Here](http://www-cs-students.stanford.edu/~blynn/c/ch02.html) quotes Dijkstra as saying: &gt;Object-oriented programming is an exceptionally bad idea which could only have originated in California. Anyway, I think you are right. Perhaps I will go back to learning OGRE now =)
A good resource for *why* things are done a given way is the effective stl series.
Start with the Meyers trio - Effective C++, More Effective C++ and Effective STL. Then do the Sutter trio - Exceptional C++, More Exceptional C++ and Exceptional C++ Style. Then do Dewhurst's C++ Gotchas. Once you've done those, you'll be ready for MC++D, which is an excellent book. However, if you're new to templates - which are most of what matters in C++ - then you aren't yet ready for that book. Vandevoorde last. It's more of a reference than a learning book.
I've done the Meyers duo (no Effective STL) and I've done the first two of Sutter's book. I didn't find MC++D to be particularly difficult to follow. I have a fairly strong background in multiple languages but your advice is certainly sound :). I hadn't heard of C++ Gotchas. I'll track down the books I'm missing from that list, thanks.
Well if you read four of the six prerequisites, it's not surprising that it was straightforward to follow. In my opinion, Effective STL is the best of the three by a wide margin. Don't skip it, even if you're afraid of Scott Meyers' Darth Haircut.
Buying it now actually :). I lost my copy of More Effective C++ some time ago as well so I'm tracking down another copy of that. I foresee much C++ in my future and given that C++0x has made the language more palatable I am interested in exploring it further despite my inner voice telling me "BAAAAAAAAD BAD BAD BAD".
Alendrescu's book should not be the first book you read on templates. It really explores the power of templates, and how far that power can be taken, but as a result it is a pretty scary pool of code to dip your toes in. Some people have a tendency to become worse coders after reading it: not his fault, but some people are prone to "Everything is an object heirarchy", "Everything needs a singleton, factory, visitor pattern", or in this case "Every problem deserves template meta programming". Josuttis is an excellent reference to the STL libraries, I highly recommend it. Though one could maybe find approximately the same information just googling each STL class. I don't remember it being helpful in learning about writing your own templates, but I regretfully don't have it sitting on my desk anymore. I've never looked at the Vandervoorde book.
A coworker of mine likes some of the IBM C++ documentation for templates: http://publib.boulder.ibm.com/infocenter/lnxpcomp/v8v101/index.jsp?topic=%2Fcom.ibm.xlcpp8l.doc%2Flanguage%2Fref%2Ftemplates.htm
I like [Stephan T. Lavavej's video series](http://channel9.msdn.com/shows/Going+Deep/C9-Lectures-Introduction-to-STL-with-Stephan-T-Lavavej/). He maintains Microsoft's STL implementation, and has a good walkthrough of the STL. I think he does a good job of explaining the design decisions as he goes along. You can probably get away with only watching the first few videos, but you'll learn more if you watch more. Don't be afraid to pause it and check it out yourself.
Good stuff. No lambdas though :(
Since you've done a lot of COM stuff in C++, you're probably familiar with the ATL templates like CComCoClass, CComPtr and CStringT. A lot can be learned just by reading and understanding the ATL source code for these templates and others. 
That is actually where I spent some time first picking up templates and learning about them. 
Ah, I have the video series bookmarked but forgot about it. Definitely will watch those, thanks!
Did you have any particular book you recommend for learning templates or is the suggestion of StoneCypher an effective approach in your opinion as well?
That's why game developers all use C. /s
C++ is an excellent language, and the Reddit reaction to it is hilariously clueless. C++ is a far more modern language than Ruby or Python, in ways the average Proggitor will never, ever understand. It's the good old fashioned test, after all: can you write one in the other without falling all the way back to turing completeness? It's a damned shame they axed *concepts* from C++11, though. They would have made C++ much more accessible to the masses.
I would fault his advice in not being very specific to learning templates, however they are well regarded books.
I don't mind so much about axed features, if they didn't axe them, C++11 would probably be more like C++20
Most of the axes I'm good with. Concepts in particular were very important.
i don't really understand the desire for language meshing :(
&gt; as far as you're likely to care they'll stick to IEEE 754. Nope. [The power-PC chips are not fully IEEE 754 compliant](http://www.qnx.com/developers/docs/6.4.1/neutrino/technotes/freescale_e500_spe_support.html). (And of course, [many older systems](http://www.quadibloc.com/comp/cp0201.htm) don't even use IEEE 754 formats.)
I'm disappointed by Clang. Ok the generated code is not nearly as good as GCC. But the major concern is that they don't work with libstdc++ if you want to use C++0x. libc++ is OS X only. Apple should really drop its GPL3 fears or else they are going to ruin Clang (and LLVM?).
For me, the bible of STL is STL Tutorial and Reference Guide by Musser, Derge, and Saini. Its one of the only books I regularly reference aside from Unix Shells by example. It walks you through pretty much all of STL. That is more of the "what" the why is probably better covered by effective stl. For boost... the docs are good, but the best book I have seen that walks you through stuff is Beyond the C++ Standard Library: An Introduction to Boost. The only thing is, its a little old now, there are more libraries that have been added or changed. There was a site that some guy was writing that was kind of like this, but covered different libraries, I can't find it right now though. As for the "why" in boost, you should just look through the list archives if you are curious about stuff, or just email the library maintainers! Now for general template stuff, I think C++ Templates, the Complete Guide, is the best bet. Modern C++ design is in my opinion pretty far advanced. I feel as if I have a pretty good handle on templates, and there is a lot of Modern C++ design that makes me scratch my head. You will also want to look at C++ Template Metaprogramming: Concepts, Tools, and Techniques from Boost and Beyond by Dave Abrahams. 
Utility. Nothing is perfect, but if you learn and take the good parts from every language you either have a great language or a cluster fuck. C++ users seem to be split on which it has become. I must inject my opinion though that is I believe those who think it's a cluster fuck either don't want to spend the time to learn it, or they want it to simply be another language instead of writing C++ in C++.
&gt; Apple should really drop its GPL3 fears or else they are going to ruin Apple ftfms
&gt;I don't see why the name of the person that is doing the criticism plays any role. Not the name in itself, but those people are generally known for having well considered opinions, and for being vocal about it. I think most of the criticism of OOP is really criticism of OOP as an end in and of itself. OOP can be very useful, and maps very well to certain problem domains. Using it uncritically leads to ravioli code, and is a source of leaky abstractions. &gt;thousands of object-oriented languages and frameworks, millions of oop code, and this can only mean one thing: OOP is a success. Popularity is generally a worthless metric when it comes to evaluating engineering merit. 
Yes, since how a language maps to a specific problem domain is clearly the metric languages should be measured by. /s
Are you really asking Reddit to do your homework for you?
ah well, c++0x will then be to your taste :) while i can do c++ in c++, when reading my old code (or others) in it i get the feeling that in this particular language it becomes "bad" in my eyes rather fast, partially because of the utility/ variety. and another point i find confusing when reading code is the ability to do several things in several ways several times (i wonder if this sentence makes sense :)...
I do think he is, good chap. And I don't even think he specified the language. Let us have some fun at his expense by giving him a solution in a interesting language like Shakespeare, Mondrian, or lisp.
Thats still not guaranteed to be safe.. as the compiler is free to reorder code assuming all code will be sequential. You really need c++0x atomics to guard against that. Edit: [volatile in different languages](http://drdobbs.com/article/print?articleId=212701484&amp;siteSectionName=)
I can't look at InterlockedCompareExchangeRelease's source code, but depending on what exactly they are doing in there, not only the compiler but also the CPU might be free to effectively reorder the code. This is called [out-of-order execution](http://en.wikipedia.org/wiki/Out-of-order_execution) and provides great performance benefits, but means that without [memory barriers](http://en.wikipedia.org/wiki/Memory_barrier) (which are relatively slow CPU operations) you can't really rely on any sequential ordering like that. It might be that InterlockedCompareExchangeRelease and friends do use the barriers, but I suspect they instead make use of the LOCK prefix available for certain instructions in the Intel instruction set, which ensures exclusive memory access for a thread for this one instruction, but makes no guarantees as to the order of execution.
You already have the algorithm in English. Just translate it.
The implementation is free to provide guarantees above and beyond what the standard requires. In this instance Microsoft provides InterlockedCompareExchangeRelease and also the compiler and the compiler does not reorder around synchronization operations. The C++ 2003 standard does not touch multithreading in any way, but that's not the same as a blanket assumption that "all code will be sequential", it's simply silent on the subject and reasoning about multithreaded code requires you to refer to other documents.
How does this &gt; Popularity is generally a worthless metric when it comes to evaluating engineering merit. go with this &gt; those people are generally known for having well considered opinions ??? either popularity counts or it does not count. Despite all the above, these people fail to use OOP as they should. They don't understand it, period. Most, if not all, computing problems map very nicely to OOP. 
I get what you're saying and I too used to be in the cluster fuck camp, though not outspokenly so, but I never would bash it. I can't pick a favourite, to me that seems like saying a hammer is my favourite tool, but I do *really* enjoy working with python. I love how structured and clean the code is, the notion that there should be one right way, and only one right way to do things, and due to the language's structure it's generally easy to pickup others code and know what's happening.
I found the Vandervoorde/Josuttis book and Alexandrescu's Modern C++ Design to be useful, with some overlap, and some complementary explanations. The V-J book read a little bit more like a textbook or a standards document - which is fine - and the Alexandrescu book read (to me) a little bit more like a "real world, here are tools &amp; techniques to put in your toolbox" book. I think the 2 books were written around the same time (2001?) but they're still relevant today. The TMP book (Abrahams et al) was a little bit more of a deep-dive, even more than MC++D. I found the Dimensional Analysis section to be incredibly relevant to some physics programming I was doing. The Boost documentation covers a lot of the material, but the book is still worthwhile.
The InterlockedXYZ family of functions do provide memory barriers. If the name has the suffix *Release*, then it provides (at least) a Release memory barrier. The suffix *Acquire* likewise includes an Acquire barrier. InterlockedXYZ functions with no *Acquire* or *Release* suffix perform a full-fence. [The x86 memory model is very forgiving.](http://bartoszmilewski.wordpress.com/2008/11/05/who-ordered-memory-fences-on-an-x86/) The LOCK prefix offers useful guarantees wrt reordering of loads and stores.
Although we have plenty of [materials](http://www.viva64.com/en/developers-resources/) on programming on our site www.viva64.com, programmers do not visit us often. The reason for this is that too few people know of our site and its resources. For instance, almost nobody visits the "[reviews of third-party articles](http://www.viva64.com/en/reviews/)" section. But one can find there many interesting articles on 64 bits or OpenMP. To tell people about us, we have started to use such technologies as Twitter or social bookmarking services. We have decided to come to Reddit recently.
Uh what do you mean? I works wonderfully with libstdc++ since that one hack went in that stops this error: &gt; /usr/include/c++/4.5/iomanip:63:12: error: expected expression { return { __mask }; } I suppose that is what you meant.
&gt;How does this &gt;&gt;Popularity is generally a worthless metric when it comes to evaluating engineering merit. &gt;go with this &gt;&gt;those people are generally known for having well considered opinions &gt;either popularity counts or it does not count. General popularity is not the same as the opinion of some well known and extremely accomplished individuals. &gt;Despite all the above, these people fail to use OOP as they should. They don't understand it, period. Are you arguing that Emacs lisp should add support for OOP? I'm sure there are macros for that, but it doesn't seem necessary or appropriate for the core language. Or maybe you think the linux kernel or git should be written in a more object oriented fashion? &gt;Most, if not all, computing problems map very nicely to OOP. If all you have is a hammer... OOP generally promotes stateful programming, thus making it harder to reason about rigorously. But if you have an overview of most, if not all computing problems, I won't argue with you. Clearly you must possess far greater understanding of computing than Linus or Djikstra 
Just what are you talking about here? Seriously CLang/LLVM generate some serious good code considering the maturity level of the projects. The libstdc++ issue seems to have been addressed and they are making reasonable progress to building Linux. That is pretty damn good considering all the extensions in GCC. As to GPL 3 Apple is on the right track here. GPL 3 has become unbearable and frankly is a step backwards from GPL 2. Right now the Free Software people are at odds with the larger open source communities, thus the gaining interest in projects developed under alternative open source licenses. Now adage it appears that GPL advocates are more interested in making public arguments about open source rather than the distribution of said code. A perfect example being VLC for iPad! It is pretty disgusting that one idiot can keep a whole team of programmers from expanding distribution of their code. That isn't open source at all, but rather somebody trying to dictate to a corporation how they should do business. Unfortunately the FSF needs to sit back a bit and reflect upon what they have created, they took a good idea and twisted it into a mess. To get back on track you need to realize that GCC was developed in a way to prevent some of the technologies we see in CLang &amp; LLVM. Cute of them isnt it? The success of CLang &amp; LLVMis actually causing some thinking to happen in the GCC camp which will hopefully lead to a much more open GCC. If not GCC will quickly become an afterthought with respect to software history. People should be applauding the fact that Apple has encouraged the LLVM team to produce a far more open set of tools than the FSF did. 
Did you try it in C++0x mode? I got several error messages and other people confirmed similar behaviour. I tried the libstdc++ of gcc 4.4, 4.5, 4.6 and 4.7. But I used the trunk version of clang. 
&gt; Seriously CLang/LLVM generate some serious good code considering the maturity level of the projects. Well then either I just have a bunch of "bad with clang" projects or you have a bunch of "good with clang" projects. I had a significant performance drop when using clang. &gt; The libstdc++ issue seems to have been addressed With which version of libstdc++ and clang does the c++0x mode work for you? I'd really like to try clang's c++0x mode. I don't want to say that Clang is a bad project. It's young and they already did a lot of great stuff and it found some standard compliance issues in my code. But what pisses me of are the politics. Developing libc++ only for OSX and then using libc++ as the major library for clang just is a really bad move. It could even kill clang for non-OSX development. 
I will say this... Object-oriented programming doesn't feel as free and fun as compared to when I was using a procedural style. This may be because I am not entirely skilled and fluent in it yet. I didn't know what I was doing before is called a "procedural style" until later - I was just having fun and programming the way it came naturally. With object-orientation, I have to worry much more about infrastructure and design issues, but I suppose this might be a good thing, especially in designing larger and more complex systems. Sometimes it just seems like so much overhead though.
What is your motivation for doing this?
Mh, what exactly did you try? Not all C++0x features have been implemented yet but using libstdc++ in general should work.
You need to adjust your expectations - new/delete aren't available because dynamic object creation/deletion is almost always a bad idea on an embedded platform with a tiny amount of ram. Try redesigning your application so that your objects are statically allocated. 
including &lt;vector&gt; in c++0x mode was enough to result in error messages. Some of them could be fixed by adding namespace std { class type_info; } prior to any std includes. But it didn't fix all problems and it failed to build the code. 
I want, that people knew that on our site it is possible to learn not only about PVS-Studio, but about many other things. At us the interesting articles, the interesting reviews, an interesting blog. 
I realize the memory limitation. But as malloc and free is allowed you would loose nothing and gain much by new/delete support. As it is now we have the worst of both worlds. Malloc and free means we are throwing away type information by casting to/fro void* and manually copying raw bytes. I could imagine using a std::vector and resize it to maximum memory usage at beginning, or better yet use a boost::array. But because of the new/delete unsupport I cant. Also even if I only limited myself to stack memory would not mean I I would be using any less memory than if I was using using heap memory. They are just different kind of memory. One is no worse than another. You can exhaust memory with deep call stack just as well (even without recursion). Runtime stack memory usage, just like heap memory usage, is not something that the compiler knows at compile time. It depends on the runtime program flow. 
Not really. They're not claiming to have full c++0x support (there are still some parts missing) and libc++ is not released yet. Besides there is nothing to stop libc++ working fully on linux and folks are already running it just fine on Linux.
The articles are indeed interesting and great. And true also, have never heard of your site, nor PVS Studio, so it made me confused when you wrote "not only to users of our product". What product? I think the connection to PVS-Studio and viva64 could be made more explicit on the description of the subreddit. Something like: "This sub reddit is about programming in 64-bit systems. It was started by company that makes PVS-Studio (viva64.com), but other general interest 64 bit programming articles are also welcome". But thanks for sharing. +1. 
Well the GPL3 hasn't really had that effect on the free software movement. The newer releases of gcc for example are very good, and all indications are that clang still has a lot of work to do to catch them. What technologies are you referring to that GCC was developed to prevent? Besides, the developers are surely allowed to choose their own licenses for code they write- no? VLC was pulled from the app store because of a license violation. Try taking an apple application, or apple code and distribute it against the terms of its license and see how long before apple legal are in touch. The GPL3 restrictions which cause apple problems are really quite reasonable. It would in fact be quite simple for apple to comply with the terms of the GPL3 for distributing apps in their app store- they choose not to do this though. However, to build the facilities for the restrictions they want to impose into their iOS they likely need to avoid GPL3 code altogether. I would think this is reasonable for a company like apple to do (or to choose to do)- and so they have gone and built their own compiler with a license they like (not a trivial task). Hopefully the whole open source movement benefits. In general, this should be considered the right approach- apple haven't been complaining about the GPL3- they just got on and build clang/llvm instead. There is no use complaining that you don't like the license on someone else's code- this is like complaining about the price of an iphone- apple made it, they decide the price and if you don't like it don't buy it. 
&gt; The 0.9 release will be the version that gets submitted for review to the Boost C++ Library project. Weird. Sounds like it really intersects with `boost::asio`. Would they synthesize the two, or make both available?
Code Composer Studio works fine for C++ work on TI's micros. avr-g++ works well for C++ on AVR. Likewise, so does GCC on ARM. The various runtime libraries might not support DWARF EH, though.
In what way does avr-gcc not support new/delete? This code compiles just fine: class foo { int i; public: foo(int i): i(i) {} }; foo *allocate(int i) { return new foo(i); } Did you invoke the compiler as avr-g++?
My point is that GPL 3 restricts distribution of code rather than encourages it. As you point out above. GPL 3 isn't about open source at all nut an attack on freedom. In otherwords if you want people to use your code freely GPL 3 is a very poor choice. 
Hi. If new works on avr-g++ it would be very happy. I have not tried compiling with it and i don't have a micro controller. I read that its the linker that will fail if you try and use new. Did you try linking it and calling new foo in your main line, and if so did you try running it on a microcontroller? [Sauce](http://www.pragprog.com/magazines/2011-04/advanced-arduino-hacking) 
 Is that proper C++ though or is it "Embedded C++". What I have read is that avr-g++ does not support new/delete, exceptions, or any of the c++ standard libraries. The only compiler for microcontrollers with those features that I know about so far is IAR. A'm I mistaken? And If so do you have some helpful links. [Sauce](http://www.pragprog.com/magazines/2011-04/advanced-arduino-hacking) Edit: I did some reading up on Code Composer.. and it seems to only supports "Embedded C++" not C++ proper. No exception handling, no template parameters, no STL, no streams. I think it supports new/delete though. [sauce](http://focus.ti.com/lit/ug/spru281f/spru281f.pdf)
The Vandevoorde book is an excellent primer on all things templates. Alexandrescu's book is more about pushing templates beyond their original design intent - it's a fascinating read but is above and beyond typical STL-style usage I'd say. 
Pretty much the opposite there. The restrictions in the gpl(3) are designed to come into force when someone tries to restrict your freedom (eg to redistribute). Apple could easily play nice with the gpl by not seeking to impose further restrictions not allowed by the license- they choose not to do that.
I read somwhere that the excellent Comeau C++ compiler generates C code (kindof how Cfront workd all those years ago). That then could be compiled with any of the many C compiler for a specific microcontroller. Unfortunately that doesnt work... as someone actually asked Greg Comeau about it.. and he said it would not, as the C code that is generated is platform specific. Damn.. that would have been the perfect solution. You can pay Greg to port the compiler to any platform though. The price is right there on his [webpage](http://www.comeaucomputing.com/custom.html). 25K. Anyone got some spare change?
I'm using gnu C++ with an ARM processor. 
I said static allocation, not stack allocation - which is something the compiler *does* know at compile time. Of course, you can't do that for everything. *cough* void* operator new(size_t size) { return malloc(size); } void operator delete(void* ptr) { free(ptr); } *cough* 
cpp-netlib is built on boost::asio AFAIK
Don't confuse the arduino environment with avr-g++. Arduino *does* use avr-g++ as it's compiler, however the library environment is different and it does some preprocessing of sketch files. That said, you *can* compile and link in normal .cpp files in a sketch, and you can just ditch the environment entirely, use avr-g++ directly, and upload it to an arduino (the hardware doesn't care.)
WRT TI's CCS, that might be processor-specific. I know for a fact that the C28x code generation tools do support the STL and template parameters, because I use portions of both of those features at work. I can't speak for iostreams or new/delete. Considering that iostreams tends to incur an enormous .text section space cost, I tend to avoid it in embedded projects, anyway.
Yes I miss-read you there. Sorry about that. Defining all objects with static memory duration.. Hmm. Is that the common practice in embedded programming? Its seems kind of drastic to me .. as it runs counter to PC C++ best practices. They are considered bad programming style as static memory objects and or global objects from different translation units have undefined initialization order (it depends on what order the linker links the units). I guess one could make the initialization order well defined.. if one limited one self to one single static object for the whole program and then constructed and initialized all the other non static objects in its constructor. Static and or global object are a pain though when it comes to concurrency. So I would like to avoid this style even for embedded programming if possible. Your definition of new/delete that redirects to malloc/free. Hmm. Is that all it takes to get avr-g++ working? If thats all that is neccessary then it would be good news indeed. Are you sure the compiler will do the right thing though and call constructor/destructor also? Does it call the correct virtual destructor. It makes me a bit uneasy patching avr-g++ standard libraries to make new/delete work.. as the compiler also has do the right thing. But if it does.. then that would be very good news. My goal is to be able to be to use some boost::array or stlport::vector like container on the microcontroller. Edit: I found some more info on patching [avr-g++](http://www.avrfreaks.net/index.php?name=PNphpBB2&amp;file=viewtopic&amp;t=59453) similar to your suggestion. So maybe that is all it takes. It seems a bit uncharted territory, patching like this though.
Nice. To be honest that is what I would prefer to use. A fully capable 32 bit processor. Am I correct in understanding that you can somehow use the full standard g++ compiler to compile for ARM? Or is it some crippled version similar to the g++ avr compiler? Are arm chips much more expensive than say avr chips? The Arduino platform seems to be simple to learn. Is there any similar platform or start-kit type product for ARM processors for complete beginners? What do you use? Edit: [guarm](http://www.gnuarm.com) looks promising. 
We need to go deeper. I suggest we write a python VM called Clippy using this C++ VM.
That would be very good. The way I understood the above link is that this was a limitation in the avr-g++ toolchain (somewhere between the compiler and the linker). Do you have any link to how this is done? Edit: I found [this](http://www.avrfreaks.net/index.php?name=PNphpBB2&amp;file=viewtopic&amp;t=59453) that tells you how to patch avr-g++. It seems a bit uncharted territory, patching like this though.
"PC C++ best practices" are all well and good, but they come about in an environment where you have an OS and a nice UI (a command prompt counts!) and gigabytes of RAM and lots of swap and a human who can readily come in and restart your application (locally or remotely) if it falls over. All luxuries that are rare in an embedded device! If you run out of RAM your application will crash, which can cause all sorts of trouble - especially if it's critical infrastructure or difficult to access. If you're using dynamic memory allocation it's hard to prove that there is *no* chance of running out of memory; when your allocations are all static this is much simpler. For the same reasons recursive algorithms are also trouble and should be avoided if possible. The static initialisation order issue is one I hadn't considered - it's probably a key reason C++ isn't more prevalent in the embedded space. These are all 'rules' in the usual sense though - they help keep you out of trouble but can be broken if you understand what you are doing and can put in the extra work needed to make them robust. Hell, on my last commercial project I broke them all, and it took a hell of a lot of work (and a few instances of discarding an approach and coding up a new one) to get it to work well.
I just realised this is all written with my 'professional' hat on - obviously it's not such a big deal when you're mucking about on a hobby project! 
&gt; The static initialization order issue is one I hadn't considered - it's probably a key reason C++ isn't more prevalent in the embedded space. Just a nitpick. C has the same issue. It's a linker thing. The way I see it, C++ is a better safer C. While I can see your point about dynamic memory being a bit dangerous.. its not really something that makes C++ worse than C for embedded programming. C after all also supports dynamic memory. Hell, Nasa programmed the Mars rover in C++, not C. If C++ is good enough for them, its good enough for me. Having an application that allocates all the heap/stack memory you will need at startup and never asks for any more.. that would be a cleaner way to control your memory usage compared to having lots of global or static objects. Even if you just moved those objects from global namespace space into main.. you would have gained deterministic initialization order.. I'm however not familiar with micro controllers.. and maybe there is some static memory address range that you can only use for static memory and cant reuse for heap memory instead. In that case your hand is forced.
I don't see how it can be a big issue in C. There aren't any constructors. No code gets executed. There's just a bunch of variables which are loaded with predetermined values by the startup code before main is called. The dynamic/static thing is independent of the C/C++ debate. But I'm of the opinion that the abstractions that can make C++ easier to work with can also hide allocations that can cause you grief. At least C is brain-dead enough that you're stuck having to be aware of what it's doing most of the time :) 
Making a 2D vector is really not hard to do...what've you got so far? What have you tried so far? EDIT: I'm actually almost 100% sure that part of the assignment is for you to figure out how to make a 2D vector, given what they've told you about 1D vectors. There's a reason the teacher has only talked about 1D vectors.
By 2D vector, do you mean a point in 2D space, or an std::vector of std::vectors?
someone's helping me, I will update. Thanks
Vague. Could be a vector of vectors, or a function to index into a single vector as if it were a vector of vectors. Go the extra mile and do both. ;)
A 1d vector? You mean a scalar?
In this context, I'm pretty sure vector implies std::vector and not euclidean vectors. 
Sounded like fun, so my take on this [std::vector inside of a std::vector, constructed from std::istream](http://codepad.org/0xfv7dz0)
&gt; General popularity is not the same as the opinion of some well known and extremely accomplished individuals. True, but all those people included in 'general popularity' can't be that wrong. Common sense is common sense. &gt; Are you arguing that Emacs lisp should add support for OOP? Nope. I never said that. &gt; Or maybe you think the linux kernel or git should be written in a more object oriented fashion? I don't know about git, but the linux kernel is object-oriented. All those vtables aren't there for nothing. &gt; OOP generally promotes stateful programming, thus making it harder to reason about rigorously. That's a very big lie. Stateless programming can make it equally hard to reason about. &gt; Clearly you must possess far greater understanding of computing than Linus or Djikstra You've run out of arguments, and so you pull the "you can't know better from these people, because these people are famous, you are not." Ok, if only famous people can speak, I rest my case. If not, and if you are willing to hear my arguments, then we can discuss. 
&gt;&gt;General popularity is not the same as the opinion of some well known and extremely accomplished individuals. &gt;True, but all those people included in 'general popularity' can't be that wrong. Common sense is common sense. I'm afraid we're going to have to disagree on that point. The reasons for a programming paradigm or programming language popularity rarely has anything to do with technical merit, and more to do with the overall ecosystem. &gt;&gt;Are you arguing that Emacs lisp should add support for OOP? &gt;Nope. I never said that. No, but you said: &gt;Despite all the above, these people fail to use OOP as they should. They don't understand it, period. Most, if not all, computing problems map very nicely to OOP. Concerning Stallman, Torvalds and Djikstra. So you're claiming to understand OOP and, presumably, their problem domains better than they do. &gt;I don't know about git, but the linux kernel is object-oriented. All those vtables aren't there for nothing. True. And Linus has not really argued against OO, but against C++ and against the excessive use and hyping of OOP. &gt;&gt;Clearly you must possess far greater understanding of computing than Linus or Djikstra &gt;You've run out of arguments, and so you pull the "you can't know better from these people, because these people are famous, you are not." I haven't run out of arguments, I'm paraphrasing your statement above. &gt;&gt;OOP generally promotes stateful programming, thus making it harder to reason about rigorously. &gt;That's a very big lie. Stateless programming can make it equally hard to reason about. I think you missed a word. The word was rigorously. One of the goals of declarative programming is to make it easier to verify programs using tools from mathematics. I'll grant that OO can make large modular systems easier to reason about, but not in the sense of provably correct code. &gt;Ok, if only famous people can speak, I rest my case. If not, and if you are willing to hear my arguments, then we can discuss. I'm all ears. I'm just pointing out that it is unlikely that these particular famous people have failed to grasp OOP, and that there is some validity to their arguments. 
What the fuck is this shit? I am sorry, but I originated as a c++ turned C#, and really really really miss the raw power and cleanliness of C++! I make games, so that's probably most of it, so every time is see those "wonderful" keywords var and foreach I think I'm gonna shit my pants. And the simple beuty of pointers in c++, it was so easy to tie objects together, and share resources. And Oh god do I miss the easy way of doing a deep copy. I either gotta inherit from somthing, or conduct some fuckery to get the same in C#. Call c++ a hunk of junk, and I'll just call you a soft-cock weiner. Last time I said something like this, people thought I was being sarcastic, and I was upvoted. No sarcasm. C++ is awesome.
Not only is your argument immaculate, it is so eloquently stated as well. Soft-cock weiner indeed, sir
In case you missed it, the title is a reference to Star Wars, wherein Harrison Ford's character describes his ship ([the Millenium Falcon](http://3.bp.blogspot.com/_fmx-RDYU9TQ/TTmx8TEr03I/AAAAAAAAAdo/s5ciiOhAEnM/s1600/millenium-falcon.jpg)) as being "the fastest hunk of junk in the galaxy".
&gt; I'm afraid we're going to have to disagree on that point. The reasons for a programming paradigm or programming language popularity rarely has anything to do with technical merit, and more to do with the overall ecosystem. So you think that the average programmer is dumb enough to follow what's popular, only because it is popular? I disagree with this view. Generally, programmers tend to recognize what's good and what's not, despite its popularity or non-popularity, which is independent of what language they choose to use, which is affected by many more other factors. &gt; No, but you said But I don't necessarily mean that their programs should be developed with an object-oriented methodology. Their problems can be solved by the way they have chosen to **or** by OOP. &gt; Concerning Stallman, Torvalds and Djikstra. So you're claiming to understand OOP and, presumably, their problem domains better than they do. Emacs is a text editor. Linux is a Unix-based operating system. If I had to program those, certain tasks in them easily map to OOP, as you may understand. As for Djikstra, his comment about OOP is extremely vague, and non worthy to analyze. &gt; True. And Linus has not really argued against OO, but against C++ and against the excessive use and hyping of OOP. But when most people read Linus' comments, they think that Linus is against OOP, not against excessive OOP. This is evident in many online forums, when people present Linus' comments as evidence that OOP is bad. It's one thing to speak about something being excessively used and another thing to speak about something as in being bad. &gt; I haven't run out of arguments, I'm paraphrasing your statement above. You're paraphrasing something I never said. &gt; I think you missed a word. The word was rigorously. One of the goals of declarative programming is to make it easier to verify programs using tools from mathematics. No, I didn't miss that word. It just happens that I don't see that stateless programming allows for "more" verification than stateful programming: the kind of logic bugs that affect the stateful programming can also pop up in stateless programming, in different positions. &gt; I'll grant that OO can make large modular systems easier to reason about, but not in the sense of provably correct code. Why not? has it been proven that OOP programs can not be proven correct? &gt; . I'm just pointing out that it is unlikely that these particular famous people have failed to grasp OOP Why? just because they are famous, that doesn't make them infallible, you know. EDIT: Linus' comments against C++ are biased, because C++ a) is not an OOP-only language and b) templates could automate many mundane C tasks, like memory management, which is especially important in the context of an application like Git. 
&gt;I make games, so that's probably most of it, so every time is see those "wonderful" keywords var and foreach I think I'm gonna shit my pants. What you call var in C# is auto in C++. foreach in C# is std::for_each in C++. &gt;And Oh god do I miss the easy way of doing a deep copy. It's no different to do a deep copy in C++ than it is in C#. If you want a value type (stack allocated), then use one. &gt;And the simple beuty of pointers in c++, it was so easy to tie objects together, and share resources. Ah... you're post was meant to be sarcastic. Now I get it.
She may not look like much, but she's got it where it counts, kid. I've made a lot of special ~~modifications~~ operator overloads myself. 
&gt;So you think that the average programmer is dumb enough to follow what's popular, only because it is popular? I disagree with this view. I never said they were dumb. There are other considerations than purely technical merit, however. I have written a nontrivial amount of PHP code, but that choice was not based on technical merit. &gt;But when most people read Linus' comments, they think that Linus is against OOP, not against excessive OOP. True, but in among the typical Linus acerbity, there are some valid technical arguments. &gt;Why not? has it been proven that OOP programs can not be proven correct? Certainly not, but mutable state does not map as easily to mathematical reasoning as declarative programming does. &gt;Emacs is a text editor. Linux is a Unix-based operating system. In this context we were talking about Emacs Lisp, a programming language, and if you wish to be pedantic Linux is not Unix based(though Posix compliant and unix inspired). &gt;If I had to program those, certain tasks in them easily map to OOP, as you may understand. In the kernel, there already is some OOP in the sense of objects having data and functions that act on that data. If you mean OOP in the sense of inheritance models and encapsulation, I'm sure you could find a use for that too. In the case of Emacs Lisp, adding OO to Elisp seems like a lot of work and complexity, for only a dubious gain.
That's awesome. You are awesome. I need more C++/Star Wars crossover references.
So much for C++0x!
If you count hexadecimaly then it's C++0B :3, so it's still within the 0x limit.
How about we always represent it in base the year when the standard is published, so it's always C++10. D'uh.
Dude, you mean C++10. Dude.
\*facepalm\* Haha, yeah, thanks for the correction. Aww man, it can't be written in 0x format anymore.
Smartass. &gt; What you call var in C# is auto in C++. foreach in C# is std::for_each in C++. Woah, do not want. Declaring shit as char or int makes it all so clear. Kinda odd that c++ does have these features... Cheers for letting me know tho. &gt; If you want a value type (stack allocated), then use one. There are times where you should use a class, and times you should use a struct. Classes also give your references, which are incredibly handy and a decentish sub for pointers. &gt; Ah... you're post was meant to be sarcastic. Now I get it. I never said I was a good c++ programmer. I doubt my skills today in C++ could get me any job, but I'd love to go back and re-learn this fine language.
Still no properties Bjarne! Still no properties! The 80's are laughing at you. 
What do you mean by "properties"? The C# kind? If so those are ridiculously easy to make on your own. Here's a [simple example](https://github.com/sempuki/scaffold/blob/master/component.hpp#L24). It includes publish/subscription model, but could probably be expanded along any sort of complexity dimension as required. Ultimately I wouldn't have spent any time on something so distinctly not more than syntactic sugar either.
No, not get and set. Properties where it looks and acts like a member to the user, but to the class, it can invoke custom methods for getters and setters. It's impossible to have them work properly with how C++ is currently built. Once you use them, you can't live without them. Calling it syntactic sugar is as insulting as saying your comment was nothing more than a waste of time. 
You can get the exact same thing either by using getter/setter methods, or if you want to give them more value-like syntax, with a custom property struct as above. If you don't like oberserver semantics, or declaring a struct for each class, you can use lambdas for specifying arbitrary logic. There's so many options available to you. Any way you slice it it's nothing more than syntactic sugar that saves you typing a few characters. Sadly writing C# is half my job these days, and "Properties" is probably one of the *first* things I could live without (lambdas probably the last -- until maybe the async keyword arrives in 5.0). To end it off by claiming the 80's are laughing at C++ is completely ridiculous. If it really bothers you so much, use Qt's property system.
Nope, you're still way off target. You really have to use them to appreciate it. Otherwise, you don't know what you're missing and you're better off until they actually decide to implement it. What's funny is that MSVC++ and Borland (or Embarcadelero or whatever it is) both have extensions for properties. But they're non-standard. The thing is that they work correctly. edit: I'll add again that it's not syntactic sugar. That's an insulting thing to say. 
Yes and Qt has properties as well. I don't really care how insulted you are, I use C# all day at work, and Properties are a constant source of dodgy code because when one assumes one is setting a data member (within an epsilon of book keeping which is the purpose), one is actually calling functions with serious side effects. Basically properties make data stop acting like data, and confuse the semantics of the language. If your intent is to make reactive computations in response to changing data, use the observer pattern. Properties, properly used, are easily replaceable syntactic sugar.
Ah sempuki, I should have know it was you. Leave the programmers to those who actually know what they're doing, eh? 
Only if you promise to do the same. By the way, when our game comes out, do you want me to get you an autographed copy?
Thanks the link sempuki, that's the simplest example of C++ properties I've seen. 
&gt; Calling it syntactic sugar is as insulting as saying your comment was nothing more than a waste of time Just wanted to say ditto. Most of C++ is "just syntactic sugar" on top of C, but that doesn't mean it's superficial or trivial.
This is totally backwards. Rather than have methods act like members, access members through methods. You have your consistency, your API isolation, and no bullshit pretending or magic.
Syntactic sugar means the idea is expressible with a high degree of fidelity without the syntax, but having the syntax means you're able to express the same idea in less characters. You're telling me encapsulation, inheritance, interfaces/programming-by-contract, templates/generic programming, RAII, namespaces, exceptions, lambdas, etc. are *all* syntactic sugar? * encapsulation is possible in C only by convention. * data inheritance requires preprocessing magic or pointer tricks, and behavior inheritance requires vtable tricks. although basic OO is possibly in C, there are many polymorphic ideas that simply cannot transfer over: see [GObject](http://developer.gnome.org/gobject/stable/) for the best outcome you can possibly hope for. * programming by contract is entirely by external convention; there is no way to express a compiler-enforced guarantee that an object fulfils an interface. * "generic programming" just doesn't exist. void pointers are the closest you can get, but you've given up all type safety right from the get-go. * the key to RAII is automatic compiler-enforced calling of functions on entry and exit of scope that allow guaranteed initialization and release without room for user error. there is no such concept in C, leaving the user the error-prone task of manually accounting for each scope change. * namespaces make naming a first-class operation: you can be as specific or as general as you want, depending on the scope of your operations. in C all function names are in the global space, which_occasionally_leads_to_needlessly_long_symbols. * exceptions might be largely over-used in the opinions of some, but there is simply no way in C to decouple error handling from functionality by systematically unwinding the stack. you either pass Error** to every function like GLib does, or revert to dangerous long jumps that may send you off to never-never land. * C function pointers may be "first class objects" in the loosest sense of the term, but are not truly type safe, cannot as closures, cannot be curried/bound, cannot capture variables from the defining scope, etc. I could go on, but I don't want to spend much more time making the point. Some of C++ may be syntactic sugar, but to say it's all sugar means to either not know languages or not know C++, and is about as informative as saying C# is syntactic sugar for assembly.
&gt; It's no different to do a deep copy in C++ than it is in C#. If you want a value type (stack allocated), then use one. As I understand it C# don't have copy constructors. So their objects dont' have value semantics, they have reference semantics. Everything is shared and a shallow copy under the covers. Getting actual deep copy value semantics requires hacks like "Cloned as Serializable". Much the same is the case in Java. I think reference semantics will come to burn the Java and #Net languages badly, in the massively concurrent world of tomorrow. Reference semantics simply don't scale well, value semantics do. 
I find this debate about the *sugarship* of properties quite ... pointless. The more I understand OO philosophy, the less I use properties (in the broad sense). Internal data are ... internal! My classes don't offer data, but services. I know there are frameworks that don't care about [Demeter's Law](http://en.wikipedia.org/wiki/Law_of_Demeter) and that are data/properties oriented. In my everyday job, neither do I use these frameworks, nor properties. So this is definitively not something I'm expecting (waiting?) of the next standard. lambda? thread related futures? rvalue-references? That's another story. That's features that I know I'll definitively use.
PVS-Studio also can find [some Undefined Behaviors](http://www.viva64.com/en/d/0162/). 
&gt; True, but in among the typical Linus acerbity, there are some valid technical arguments. Read again his comments. There are no valid technical arguments. [**Let's see:**](http://thread.gmane.org/gmane.comp.version-control.git/57643/focus=57918) &gt; *infinite amounts of pain when they don't work (and anybody who tells me that STL and especially Boost are stable and portable is just so full of BS that it's not even funny)* Not true, obviously. STL and Boost work perfectly, they are stable and portable. &gt; *inefficient abstracted programming models where two years down the road you notice that some abstraction wasn't very efficient, but now all your code depends on all the nice object models around it, and you cannot fix it without rewriting your app.* Not true, for the simple reason that abstractions can also fail in C code. &gt; *In other words, the only way to do good, efficient, and system-level and portable C++ ends up to limit yourself to all the things that are basically available in C* Wrong again. Manual memory management in C does not scale well. C++ smart pointers allow a single person to write many hundreds of thousands of lines of code without a single memory issue in a reasonable amount of time. &gt; *And limiting your project to C means that people don't screw that up, and also means that you get a lot of programmers that do actually understand low-level issues and don't screw things up with any idiotic "object model" crap.* Wrong again. C++ does not have an object model, and you don't need to have an object model to write efficient code. &gt; *So I'm sorry, but for something like git, where efficiency was a primary objective, the "advantages" of C++ is just a huge mistake.* Wrong again. STL sort is faster than qsort due to the lack of an indirect function call. C++ code performs faster in many cases. &gt; *and quite frankly, as a result of all these design decisions that sound so appealing to some CS people* CS people do not advocate C++. But Linus doesn't even know that!!! &gt; *the end result is a horrible and unmaintainable mess.* No. I've seen extremely large C++ code bases (millions of lines of code) are are extremely maintainable. **Please show me a SINGLE THING LINUS SAID that is valid!!!**. &gt; certainly not, but mutable state does not map as easily to mathematical reasoning as declarative programming does. I apologize for saying this but ...it's bullshit. Not only statically checked mutable languages are as correct as the immutable ones, but the mathematical reasoning you speak about does not guard the code against logical bugs. And let's also not forget FP languages use object-oriented mechanisms to achieve functions as first class entities, function composition and currying. Please show me how to have these without encapsulation and virtual methods. 
&gt;&gt;infinite amounts of pain when they don't work (and anybody who tells me that STL and especially Boost are stable and portable is just so full of BS that it's not even funny) &gt;Not true, obviously. STL and Boost work perfectly, they are stable and portable Perfectly is a strong claim. There are several platforms where they're dodgy(TI's C6000 compiler is the one place I've come across problems. Apparently it can be made to work, with the right combination of versions). For Git, I'd say Boost is plenty mature enough. For the kernel, not so much. &gt;&gt;inefficient abstracted programming models where two years down the road you notice that some abstraction wasn't very efficient, but now all your code depends on all the nice object models around it, and you cannot fix it without rewriting your app. &gt;Not true, for the simple reason that abstractions can also fail in C code. He didn't say they couldn't. He was arguing that C++ can lead to inefficient abstraction models, because you start abstracting before you start doing anything worthwile. The difference is between top down and bottom up programming. &gt;&gt;In other words, the only way to do good, efficient, and system-level and portable C++ ends up to limit yourself to all the things that are basically available in C &gt;Wrong again. Manual memory management in C does not scale well. C++ smart pointers allow a single person to write many hundreds of thousands of lines of code without a single memory issue in a reasonable amount of time. True, smart pointers are quite nice. However, having rejected STL and Boost for lacking support for some microcontrollers(a bit harsh, I'll grant), you'll have to implement your own, in a portable and efficient manner. And in what way doesn't manual memory management scale well? &gt;&gt;So I'm sorry, but for something like git, where efficiency was a primary objective, the "advantages" of C++ is just a huge mistake &gt;Wrong again. STL sort is faster than qsort due to the lack of an indirect function call. C++ code performs faster in many cases. A bit of strawman. He's not saying that C++ can't be fast, he's saying that for a tool such as git, which runs short and fast operations on files, the advantages C++ offer are not worth it. I'm not sure I agree, but it is an argument. &gt;&gt;and quite frankly, as a result of all these design decisions that sound so appealing to some CS people &gt;CS people do not advocate C++. But Linus doesn't even know that!!! At that point he was talking about monotone, and the use of a relational DB as well as object oriented libraries, both of which appeal to some CS types, as he said. &gt;the end result is a horrible and unmaintainable mess. He's still talking about Monotone. I've seen both maintainable C++ code, as well as C++ code that was like looking into the more macabre sections of the Necronomicon. I don't really blame the language in either case though. &gt;**Please show me a SINGLE THING LINUS SAID that is valid!!!.** I think I was thinking of another mail in the thread: &gt;*IOW, C++ is in that inconvenient spot where it doesn't help make things simple enough to be truly usable for prototyping or simple GUI programming, and yet isn't the lean system programming language that is that actively encourags you to use simple and direct constructs.*
Any details on the game you're making?
It's a commercial game (if you were expecting a an indie or open source one): * http://www.youtube.com/watch?v=M_FsHWhp-h0 * http://www.1up.com/previews/resident-evil-operation-raccoon-city-online-combat?pager.offset=1 It's funny because Vorlath thinks I'm making up where I work (his "leave this to the pros" comment).
Do you use C# for tools then?
Yeah I work on tools, so about half the time in C# and the other half in C++. I appreciate what C# gives me, but I'd rather work with C++.
Check out SafeInt. http://channel9.msdn.com/Shows/Going+Deep/David-LeBlanc-Inside-SafeInt It's a very boost like library for catching integer overflows.
&gt;Getting actual deep copy value semantics requires hacks like "Cloned as Serializable". This isn't true, anyone is free to write a constructor that performs the copying if they wish, C#, Java, or C++. C# doesn't have a copy constructor simply because it makes no sense given the context of the language. What would a copy constructor do? Clone/Serializable are not for creating deep copies, but rather for doing polymorphic copying. That is so you can do something like this: Animal* a = new Dog(); Animal* b = a-&gt;Clone(); // Ensures that a Dog is actually copied. Since the following won't work: Animal* b = new Animal(*a); // Animal is abstract, can't be instantiated. I'd appreciate being shown some case of C++ making a deep copy of an object using the copy constructor or some unique mechanism that isn't available in C# or Java. The issue of copying isn't intrinsic to any of these languages.
I use recursion regularly. The correct algorithmic approach occurs to me in recursive terms when dealing with data structures which themselves are recursive. It is natural to think of manipulating something like a binary tree, for instance, in recursive terms. I will implement whatever recursive function/method I need to write in whatever language I am currently using. There's nothing that magical about recursion. You can convert any recursive function to a non-recursive function if you iterate until the termination condition is meant and keep a local stack around for the state that would normally be kept in the stack frame. If you are someone that tends to think of things recursively, the recursive solutions are the easy ones to see. I took a class in college that used O'Caml and we weren't allowed to use any looping constructs, etc, and had to do all of that recursively. It just takes some getting used to. 
I used it a lot more until my datasets got bigger and I'd get stack overflows. It's easier to think about solving problems recursively for sure and the code is much more elegant but to be honest it doesn't come up very often in my day to day coding (or at least I don't recognize when recursion could be used very often).
See [here.](http://www.reddit.com/r/cpp/comments/goqk1/rcpp_what_are_your_thoughts_on_recursion/)
Damn... beat by two minutes... I was typing the same thing when I saw your post out of the corner of my eye...
Besides being confusing at times, the problem I have with recursion, and I think I had from day one, is the fact that the downsides of memory usage were glossed over (and kept hidden in my introductory CS classes). I remember when I was first introduced to the concept of recursion, I was very confused about what the hell happened to the function's local variables when it calls itself. The professor kept trying to explain it, without understanding what my hang up was. Then I learned about the function call stack, and was just annoyed about how recursion was presented as a "free" option. The obvious downside, when you ask what happens to local variables, is that space for those variables is allocated, and it doesn't get freed until you hit the terminating condition and wind back out. What I don't like is that if you use recursion, even for a function without local variables, it will still waste space, limiting the amount of iterations. At best, it will only use slightly more memory than if you had allocated space for the local variables yourself. It's over-rated and over-used in opinion, except when dealing with languages or problem domains where performance isn't a concern.
The vast, vast majority of my day to day tasks (both professionally and personally) are grunt work, and wouldn't make sense to have any recursive code - similar, I think, for the vast majority of programmers. That's going to depend on what you work on though. I think the last time I used a recursive function was in a breadth-first search implement, as part of pathfinding for a small game. That was in C++, of course. As for when it's most appropriate, there's not really a hard answer this. There's a lot of algorithms that are far cleaner when written recursively, but it's hard to say what exactly to look for. I know searching and parsing (specifically when you can have a node that contains any number of nodes, which in turn may have nodes...) are the two biggest categories that come to mind. While I don't use it that often, I do think recursive is an important concept to understand. In my opinion, it's a solid indicator of how well someone can visualize code in their head, not to mention extremely useful tool when it does come up.
Recursion as a concept is separate from the implementation detail of the stack. From an educational point of view, this is usually glossed over because a lot of students' eyes will glaze over if you throw everything at them simultaneously. I suppose it might be helpful to some students (particularly the engineering-types) to allude to the limited memory available for the stack.
 I always use recursion for tree structures.
&gt; Syntactic sugar means the idea is expressible with a high degree of fidelity without the syntax, but having the syntax means you're able to express the same idea in less characters That's not exactly what I mean by "syntactic sugar", but it's not far off. I take a wider definition to be that which a decent programmer could express informally as a straightforward (a) validation and (b) translation to a subset of the original language. I recognize our definitions differ, but that should clarify my intent. &gt; You're telling me encapsulation, inheritance, interfaces/programming-by-contract, templates/generic programming, RAII, namespaces, exceptions, lambdas, etc. are all syntactic sugar? Under this alternative definition, yes. I wouldn't generally include exceptions though, as a straight forward translation to using setjmp/longjmp would not be nearly as fast as the code generated by any decent C++ compiler. Another such exception would be linker handling of duplicate instances of inline and template functions, as C linkers would generally error or misbehave on such duplicates. I believe the original such "desurgaring" implementation was called [CFront](http://en.wikipedia.org/wiki/Cfront). I do appreciate your definition though; far less of C++ meets it -- perhaps namespaces, function overloads, and such, which one could avoid manually if they really set out to it. The best example being "while" and "do/while" as a special cases of "for", or "if" as a special case of "switch". &gt; Some of C++ may be syntactic sugar, but to say it's all sugar means to either not know languages or not know C++, You're now blatently misconstruing my words. I said _most_, you exagerated to _all_. Gross analogy for comparison, compare "the human body is composed mostly of water" vs. "the human body is composed entirely of water". The distinction _is_ an important, and hopeful the exception example demonstrates it. The veiled insult is also rather unnecessary, and perhaps backfired. &gt; and is about as informative as saying C# is syntactic sugar for assembly. If you fail to distinguish the difference, I suspect the failure is intentional.
&gt; C# doesn't have a copy constructor simply because it makes no sense given the context of the language. And thats my point. C# is a language with reference semantics. You don't have value, you have references. Doing a deep copy only given a reference to the object is going to be hard in any language. C++ is better here simply because it gives you the option of using reference semantics or value semantics. C# and Java force you to use reference semantics, so if you want value semantics you cant. In C++ value semantics is the default. The STL really shows the power of value semantics. The reference semantics made popular in OOP has fallen from grace. Edit: Base* base1 = new Derived(); Base* base2 = new Derived(); *base1 = *base2; // bad as '=' and '*' operators are not virtual base1-&gt;clone(base2); // bad as you also want virtual dispatch on the argument. One would need [double dispatch](http://en.wikipedia.org/wiki/Double_dispatch), [multi-methods](http://en.wikipedia.org/wiki/Multiple_dispatch) more generally, to solve this problem. I think there would be a good case to add them to the C++language just to solve these half working clone hacks. That said Java and Net would need them more urgently as they have no value semantics. There are patterns to simulate multimethods but they are a bit ugly. 
It's the new C++, C++ 2011 that has 'auto', and a new range 'for', and .. see [wikipedia for C++0x](http://en.wikipedia.org/wiki/C%2B%2B0x). 
&gt; The vast, vast majority of my day to day tasks (both professionally and personally) are grunt work, and wouldn't make sense to have any recursive code As a fellow grunt I disagree, I have a lot of recursion in my day to day work, But I work with files and directories which are trees. I would generally avoid recursion because... I just don't like it and it's not scalable. Edit: repercussion =&gt; recursion 
If you want to write safe/stable code then you can not use recursion in C++! There is no way to gracefully recover when you run out of stack space. Which is a sad thing because recursion can be quite elegant and I use it regularly in other programming languages that have safe ways of dealing with those situations. **edit:** if you are going to downvote me then at least explain to me why.
I told my teach during a class that reccursion not that perfect because the stack is limited. He didn't believe me and told me java as a modern language would optimize the recursion into iteration whenever he can do it, and that anyway the stacks grows dynamically. At the end I managed to get him giving a test on his laptop. I don't remember exactly when java rose an exception, but it occured sooner to both he and me expected it to be. Still, nowadays I tend to use reccursion without hesitation when it feels natural and if you are programming on PC you shouldn't really care about the stack.
There's recursive code and recursive algorithms. If you're going to do a tree traversal, you're going to need to keep track of a list of nodes to visit. You can (and I typically do) get rid of the recursive call in favor of a loop and a manually managed stack which solves some problems with naive recursion, but I still think of this as being recursive. Maybe that's just me though. 
Avoiding recursion can lead to unwanted repercussions.
&gt; Perfectly is a strong claim. There are several platforms where they're dodgy(TI's C6000 compiler is the one place I've come across problems. Apparently it can be made to work, with the right combination of versions). A faulty compiler does not make a faulty library, or a faulty language, or a faulty design methodology. &gt; For the kernel, not so much. Evidence, please. &gt; He didn't say they couldn't. He was arguing that C++ can lead to inefficient abstraction models, because you start abstracting before you start doing anything worthwile. The difference is between top down and bottom up programming. So it's not that C++ can lead to inefficient abstraction models, it's that programmers can abuse C++ with inefficient abstraction models. Blame the craftsman, not the tools. &gt; However, having rejected STL and Boost for lacking support for some microcontrollers(a bit harsh, I'll grant), you'll have to implement your own, in a portable and efficient manner. That's not a fault of the language or OOP. Blame the microcontroller compiler's developers. &gt; And in what way doesn't manual memory management scale well? In complexity. &gt; A bit of strawman. He's not saying that C++ can't be fast, he's saying that for a tool such as git, which runs short and fast operations on files, the advantages C++ offer are not worth it. I'm not sure I agree, but it is an argument. It's not an argument, since the advantages C++ offers are certainly worth it. Any version control system will need to manipulate strings, right? well, smart pointers can easily solve the memory management problem of strings. I would truly hate to do something like Git without smart pointers. &gt; At that point he was talking about monotone, and the use of a relational DB as well as object oriented libraries, both of which appeal to some CS types, as he said. His comment includes C++, because he says "They use "nice C++ abstractions". &gt; I think I was thinking of another mail in the thread: Oh, ok. Now you change the context. Fine. Let's see how it holds. &gt; C++ is in that inconvenient spot where it doesn't help make things simple enough to be truly usable for prototyping He does not explain why C++ is not usable for prototyping. There is nothing wrong in C++ to prevent prototyping. &gt; or simple GUI programming I can write useful Qt apps in less than half a working day. I call BS on this as well. &gt; and yet isn't the lean system programming language that is that actively encourags you to use simple and direct constructs Bullshit again. Nothing stops you from not having virtual methods, for example. You can do simple and direct programming in C++ by using only encapsulation, without using inheritance or message passing or anything else. Again, he doesn't actually have any arguments against C++ or OOP. 
Such as? EDIT: Oh... 10x.
I write computer programs to simulate materials, and I use recursion for certain types of cluster moves in Monte Carlo simulations, as well as in routines that measure the "difference" between two clusters. 
[Well...](http://www.reddit.com/r/cpp/comments/goqk1/rcpp_what_are_your_thoughts_on_recursion/)
(I'm really, really sorry about this.)
Tree processing and recursion often work well together... as long as you don't accidentally have a graph :)
If you are concerned about stack size and using recursion you should not be using recursion and use iterative algorithms instead. For well defined, finite, and none circular data structures, recursion can be an elegant solution.
&gt;&gt;Perfectly is a strong claim. There are several platforms where they're dodgy(TI's C6000 compiler is the one place I've come across problems. Apparently it can be made to work, with the right combination of versions). &gt;A faulty compiler does not make a faulty library, or a faulty language, or a faulty design methodology. How do you know the compiler is faulty? The compiler writers claims that it is conforming with the C++ spec. and that the libraries are relying on undefined behaviour. So either they're wrong/lying, or there is a fault with the library/language. &gt;&gt;For the kernel, not so much. &gt;Evidence, please. In case you weren't aware, the linux kernel is used as a base for several real-time and embedded operating systems. Some don't have a C++ compiler at all, and others don't work well with STL/Boost. If you want portability today, C is your best bet. &gt;It's not an argument, since the advantages C++ offers are certainly worth it. To you, perhaps. &gt;Any version control system will need to manipulate strings, right? well, smart pointers can easily solve the memory management problem of strings. I would truly hate to do something like Git without smart pointers. I wasn't aware there was a problem with managing memory with strings. &gt;&gt;He didn't say they couldn't. He was arguing that C++ can lead to inefficient abstraction models, because you start abstracting before you start doing anything worthwile. The difference is between top down and bottom up programming. &gt;So it's not that C++ can lead to inefficient abstraction models, it's that programmers can abuse C++ with inefficient abstraction models. Blame the craftsman, not the tools. It doesn't matter who you blame. It matters how you try to counteract the effects. Your whole argument seems to be "C++ can do more, why would you limit yourself?" Well, this is why. More portable code, and being forced to always consider the low level effects of your actions. Is this the optimal way to program? For most problems, no. But for some, it seems to be. &gt;&gt;I think I was thinking of another mail in the thread: &gt;Oh, ok. Now you change the context. Fine. Let's see how it holds. Same email thread we were discussing. Without reading at least part of that thread, the comment is meaningless. &gt;&gt;C++ is in that inconvenient spot where it doesn't help make things simple enough to be truly usable for prototyping &gt;He does not explain why C++ is not usable for prototyping. There is nothing wrong in C++ to prevent prototyping. I think C++ is usable for prototyping, but there are more convenient languages for that. C++ doesn't have a REPL, which I find invaluable for prototyping tasks. &gt;&gt;or simple GUI programming &gt;I can write useful Qt apps in less than half a working day. I call BS on this as well. You probably could have written it faster with PyQt. &gt;&gt;and yet isn't the lean system programming language that is that actively encourags you to use simple and direct constructs &gt;Bullshit again. Nothing stops you from not having virtual methods, for example. You can do simple and direct programming in C++ by using only encapsulation, without using inheritance or message passing or anything else. You can. But C++ is not actively encouraging you to use simple and direct constructs, you have to judiciously choose the subset applicable to your program. Not is it a lean systems language. It can produce lean binaries, but the language is too large and complex, and in large parts dependent on unspecified behaviour from compilers. 
I use it all the time as I work with graph traversal all day long. Without adjusting any defaults VC++ 2008 will give you sufficient stack space for about 4600 (best case) calls. If you're traversing through some worst case data structure where every node has only two branches, that stack space gives you room to handle about 10^1400 items. For comparison, the Earth apparently contains around 10^50 atoms. In my experience, recursion and stack overflow problems are either the result of: * working on resource limited machines (with embedded systems etc, fair enough) * a *very* dodgy algorithm (ie, a bug) * unnecessarily dumping temporary data on the stack instead of the heap. I am quite sceptical about reasons for avoiding recursion in C++ on standard PCs.
In order to understand recursion, one must first understand recursion.
&gt;C# and Java force you to use reference semantics, so if you want value semantics you cant. C# allows the use of value semantics. .NET intrinsically supports both.
Recursion is a means, not an end. Certain algorithms are suited to recursive implementations, and when you need one of those algorithms recursion is appropriate. Personally, in my day-to-day life, it's rare that I end up using a recursive algo or data structure. Which is fine; recursion (indeed any programming tool) isn't something you should be shoehorning into situations it's not appropriate for.
Recursion is a "tool", not a philosophy. I use it when it makes sense.
&gt; How do you know the compiler is faulty? The compiler writers claims that it is conforming with the C++ spec. and that the libraries are relying on undefined behaviour. So either they're wrong/lying, or there is a fault with the library/language. I know it because STL and boost do not rely on undefined behavior. They follow the C++ specs 100% in order to have maximum compatibility. It is always the compilers that are at fault. &gt; In case you weren't aware, the linux kernel is used as a base for several real-time and embedded operating systems. Some don't have a C++ compiler at all, and others don't work well with STL/Boost. This is not evidence of C++ or OOP being inappropriate for kernels generally. It's only evidence that C++ does not exist or is problematic for those environments. Please provide me with some evidence that C++ cannot exist in the kernels of those environments. &gt; If you want portability today, C is your best bet. That doesn't say anything of the suitability of C++ as a kernel language though. &gt; I wasn't aware there was a problem with managing memory with strings. I didn't say there is a problem with managing memory of strings. I said that there is complexity in managing memory of strings, and that complexity is managed better via smart pointers instead of manual management. &gt; It doesn't matter who you blame. It matters how you try to counteract the effects. Your whole argument seems to be "C++ can do more, why would you limit yourself?" Your whole argument (or Linus' argument) is that C++ is inefficient, which is terribly wrong as a position. C++ is as inefficient as you wanted to be. It's no different than C. &gt; Well, this is why. More portable code, "More portable code" is a matter of compiler availability, which is hardly an argument against any language; it's only an argument against a language compiler. &gt; and being forced to always consider the low level effects of your actions. Nothing stops one to do that in C++. The low level effects are always documented. &gt; I think C++ is usable for prototyping, but there are more convenient languages for that. C++ doesn't have a REPL, which I find invaluable for prototyping tasks. It could have. Again, this has nothing to do with the language. It's a matter of implementation. &gt; You probably could have written it faster with PyQt. Proof? &gt; But C++ is not actively encouraging you to use simple and direct constructs C++ is not a person, you know :-). C++ does nothing, it's an inanimate concept. You can use simple and direct constructs, if you wish. &gt; you have to judiciously choose the subset applicable to your program. Nonsense. You choose what you need, and that goes for any language. &gt; Not is it a lean systems language. Why? proof please. &gt; but the language is too large and complex Please quantify 'too large' / 'too complex'. Compared to what? every language feature in C++ is carefully chosen to serve a specific purpose. &gt; and in large parts dependent on unspecified behaviour from compilers. I don't see what that has to do with the language; if you don't like a compiler, use another one which is better / more conformant to the standard. 
Ask Douglas Hofstadter.
Trees are graphs. 
I only wished C++ had tail call optimization...I would use recursion more often. 
Java tends to use more memory than languages like C++ when allocating the function stack. Interpreted languages like perl are even worse (they tend to use a LOT of space for single variable allocation). I have yet to see a garbage collecting language that swaps data out of memory before it goes out of scope. The trigger for garbage collection is scope. With recursion, you are keeping all of those variables within scope with destroy the garbage collectors ability to clear it out. I don't know why your prof would think it works some other way, other than ignorance. I care about the stack because some of the data sets I work with are over a terabyte in size. At my last job, one of the files was 100 GB's, and the datasets were multiple TB's. I have to think about things like memory usage or I will quickly run out.
I think I'm very detail oriented, and notice it right away when something is glossed over. This made classroom learning a real chore, as they are always leaving stuff out for the sake of simplicity, which actually makes things harder for me, as I would find the missing information so distracting that I would tune out for the rest of the lecture. The upside is I tended to know what they were talking about before the lecture, so tuning out didn't seem to have much of an effect.
I bet you are a lot of fun at parties.
C++ can do whatever optimization it wants. Including tail calls. It isn't the sort of thing that needs to be a language feature. http://stackoverflow.com/questions/34125/which-if-any-c-compilers-do-tail-recursion-optimization If you write a simple recursive function, don't be surprised to find assembly for an inline loop.
I did a bit of reading. In C# structs have value semantics, classes have reference semantics. No type supports both. I find it rather ugly that this is something that is hard wired into the definition of the type rather than something the user is free to decide like in C++. C# is basically a language with two incompatible type systems. They support different sets of features. Value semantics in C# seems like a badly fitting afterthought. Seeing this makes you appreciate the uniformity and generality of C++. Thankfully Stroustrup got it right from the beginning. sauce: http://msdn.microsoft.com/en-us/library/saxz13w4.aspx 
&gt;&gt;If you want portability today, C is your best bet. &gt;That doesn't say anything of the suitability of C++ as a kernel language though. Ah, but it does. Unless you know there exists a compiler for your target machine, compiler availability and stability is part of the things you have to consider when choosing a language. A large part of the reason for the Linux kernel's success is that it is written in pure C. Because C is such a simple language and ubiquitous language, it's frequently the first language to have compiler support on a new platform is C. This is one of the reasons Linux was so early in supporting Arm, AMD64, and various microprocessors. &gt;&gt; you have to judiciously choose the subset applicable to your program. &gt;Nonsense. You choose what you need, and that goes for any language. Ah, and once again you simply ignore what I wrote. It's ok, I'll write it again. C++ has more features and more expressiveness than C. Generally speaking, more expressiveness means more productivity. So why limit yourself to just C? Well, that is what Mr. Torvalds is trying to get to. One is the lack of abstractions. If you want to enforce a consideration of low-level resource handling, it makes sense to use a language where you have to consider the low level implications of your decisions. Another might be portability. Most platforms have a C compiler, because implementing one is easy enough to do that it is frequently done in scope of a compilers class. A C++ compiler? Not so much. &gt;&gt;but the language is too large and complex &gt;Please quantify 'too large' / 'too complex'. Try implementing a standards compliant C++ compiler. Take your time. I'll wait. 
&gt;No type supports both. You can use a value type as if it were a reference, but you can not use a reference type as if it were a value type. This is just as it is in C++ but it's made an explicit part of the language to statically verify common errors made when people accidentally mix the semantics.
No, graphs are trees that do not have circular references.
This guy is an inspiration. Check out his vimeo: http://vimeo.com/flight404
[In graph theory, a tree is a connected acyclic graph.](http://en.wikipedia.org/wiki/Tree_\(graph_theory\))
&gt; as I would find the missing information so distracting that I would tune out for the rest of the lecture That sounds like a non-sequitur to me. I bet other students don't do that. When this happens, you should make a note in the margins to ask a question after the lecture instead of stewing and losing track of your lesson. (and then blaming the prof!)
Thanks! I had never heard of cinder until reading this article.. Looks like an interesting and new 'openFrameworks'
See "Tail Recursion"
This was over a decade ago. At this point it's less of an issue as I have no intention to get a graduate degree, and even if I did, the open-ended exploratory nature of such programs is much better tuned to my learning style.
C = C++; 
Java appears to give you a default stack with space for a little over 10000 best-case calls. 
&gt; Do you use recursion in every day coding? If so, why? If not, why? Yes, for algorithms working on relatively small data sets. If I have no information on the dataset size, I prefer an iterative solution, to avoid stack overflows. &gt; What language or languages are you using to implement your recursive methods/functions/sub-routines in? Uhh ... C++? (We are in the C++ subreddit) &gt; What situations do you find it most appropriate or most useful? Tree traversal, backtracking; Usually algorithms that can be reduced from working on a dataset to working on an element in the dataset. 
&gt; Ah, but it does. Unless you know there exists a compiler for your target machine, compiler availability and stability is part of the things you have to consider when choosing a language. No, it does not say anything about the language itself. It says something about the language implementations. &gt; A large part of the reason for the Linux kernel's success is that it is written in pure C. Because C is such a simple language and ubiquitous language, it's frequently the first language to have compiler support on a new platform is C. C has less capabilities than C++, and therefore it's easier to port. That's a fact. That doesn't say anything about the language itself being inappropriate for kernels. &gt; One is the lack of abstractions. If you want to enforce a consideration of low-level resource handling, it makes sense to use a language where you have to consider the low level implications of your decisions. I've read carefully what you wrote. C++ allows you to consider the low level implications of your decisions. It does not hide anything from you. &gt; Another might be portability. Most platforms have a C compiler, because implementing one is easy enough to do that it is frequently done in scope of a compilers class. A C++ compiler? Not so much. Again, portability has nothing to do with the actual language being appropriate for kernels. To put it in another way: if C was available for only one platform, and only one compiler existed, it would still be appropriate for kernels. &gt; Try implementing a standards compliant C++ compiler. Take your time. I'll wait. This is not an argument, since standard compliant C++ compilers already exist. Conclusion: you failed to produce any evidence that C++, as a language (not as a platform) is not appropriate for kernels. Furthermore, you failed to provide a persuasive argument on Linus' comments about C++. If you have any true arguments about the language itself (and not its availability), I will be glad to hear it. 
Indeed. The problem is that a tail call optimization is not in the language features, and therefore you cannot rely on such optimization to work consistently on all platforms. 
&gt;This is not an argument, since standard compliant C++ compilers already exist. Not for all target machines. If you know the target machine and compiler toolchain, C++ is an appropriate kernel language. IIRC Microsoft writes their kernel in C++. But portability is a concern, and it was one of the points Linus brought up. I still feel like that is an argument worth noting. &gt;Conclusion: you failed to produce any evidence that C++, as a language (not as a platform) is not appropriate for kernels True. Because I wasn't really arguing that. Though I can see a host of potential problems in using C++ for a kernel, all those problems can be mitigated using good programming practices. Also, in most cases, you don't choose the language independently from the platform &gt;I've read carefully what you wrote. C++ allows you to consider the low level implications of your decisions. It does not hide anything from you. It's the difference between allows and forces. For the most part, you want the former. You write the code nice and abstract, and when you need the efficiency, you write low level code. Some times though, you want to always consider the low level implications of your code. You're willing to trade productivity for robustness and efficiency, and you want to make sure all other programmers on a project does the same. In these cases, C might be a better choice.
You have to separate, in your mind, C++/the language, from C++/the language implementation. In this discussion, we are talking about C++/ the language, not its implementations. In other words, the discussion is the suitability of C++ on kernels on a theoretical level. It does not matter if there are compilers for a specific architecture or not. Do you have a comment on the language? on the language's capabilities? constructs? syntax? etc. If you don't, please let's stop this discussion. 
I think it is shame that I probably won't be approved to use it professionally for another 3-5 years. Though it makes the language a bit more complicated, it also solves a bunch of my nit-picks about the language. Shame they couldn't do something that would speed up compiles, like something to fix the problems with #include (namely that #including the same file from different source files can alter its definition)
I've been using it in a home project for about a year now and I like it quite a bit. Lambas and auto make using stl much more convenient. It would've been nice if they could've worked something out for concepts.
If you are using Visual Studio 2010 at work then you can sneakily start using some C++0x features without asking for permission. Thats what happened at my work. I got the go ahead to upgrade compiler as preparation for migration to 64 bit. I would probably never have been given permission to upgrade if they understood it was basically a new language. Nothing much can be done about multiple different definitions from the same header though.. other than to outlaw the preprocessor. It's outside of the compilers and the languages control . Thats said.. the linker is also outside the language.. but it would be nice if the C++ ABI could be standardized at least a little beyond the C ABI.
I'm only on 2008, and my code has to compile on it, an older GCC, Intel, and fuckin' Sun Forte.
Sun Forte C++, wow I never even heard of that one before. Portability is a pain sometimes.. least common denominator and all.
auto is very nice indeed. I've also started using std:unique_ptr instead of boost::scoped_ptr.
And it's a pain when you have a VERY nice feature on your hands and you can't use it because a dumb compiler wouldn't understand.
I was afraid it would make C++ even more complex, but in the end it made it a lot easier to use. Auto-typed variables, smart pointers, lambdas, range for, initializer lists, new classes in STL -- so much win!
&gt;Shame they couldn't do something that would speed up compiles, like something to fix the problems with #include The committee has been working on a proposal for modules ([pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2316.pdf)). It did not make it into the new standard, but apparently they plan to release it as a technical report when it's ready. The proposed solution would allow to replace header files with compiler-generated module files, which may be "included" without the interference of the preprocessor. It seems to work similarly to precompiled headers, but with proper language support and standardized semantics. The aim of the proposal is not only to speed up compiles, but also to deal with the "static initialization order fiasco" by making the initialization order correspond to the module-dependency order.
&gt; It would've been nice if they could've worked something out for concepts. Yeah, that's a shame. But at least we have static_assert now to check preconditions on template parameters.
I hope they hurry up with this. 
I would not suggest using a compiler designed for C++0x without some kind of approval. Think about how long it took for vendors to implement the previous standard even semi-correctly, and to this day it still isn't fully compliant. It's going to take a loooong time before the features introduced by C++ 0x have even semi-decent support suitable for production.
Very good slides, recommended reading.
I did not know about this. This would be on the top of my post C++0x wish-list, up there with concepts. You say the plan is to release it as technical report. Do you have a source? The proposal is from 2007, so it makes me a bit worried that it has been shot down.
How about a short TLDR?
**tl;dr**: The cats are breeding uncontrollably and we need to do something about it, or humanity as we know it, will no longer exist in 5 years.
&gt; Do you have a source? [Here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2009/n2869.html) is a committe document where they list modules as not ready for C++0x but heading for a separate TR. There is also this recent [forum thread](http://www.rhinocerus.net/forum/language-c-moderated/669619-question-about-module-proposal.html) where Francis Glassborow confirms that modules are planned for the next TR. 
No. This is what Tail Call Optimization is for.
I tend to implement recursion using std::stack and while (! stack.empty()). I originally did code more recursion but got into too much trouble with blowing out the stack and just found it more straightforward to manage my own stack. A weakness of function recursion is that it implies independent behavior (fire and forget). Operations like graph searching requires bookkeeping of already visited nodes be maintained (to not revisit them again). The more bookkeeping added the less clear the functional implementation (is to me). Oof...the spatial indices I have are function recursive...the splay tree implementation uses std::stack.
We all know about lambdas and the new meaning `auto`. `std::initializer_list` is underrated, I think. Gone are they days of initializing a vector using several `push_back`s!
- Hierarchical relationships. [OOP style virtual functions] - **Parametric** relationships. [Generic style template functions] "Parametric", thats the word that has been missing from my vocabulary. Sometimes the stylistic word "generic" is too vague, and the keyword "template" is too specific. The conceptual word "parametric" is just right. Very good slides. I would love to see the video presentation that goes with this.
&gt; I would love to see the video presentation that goes with this. For that you may need to add **Where** to your username LOL.
 template &lt; typename Type &gt; struct vinit { std::vector&lt;Type&gt; vec; vinit(Type const &amp; val) : vec(1, val) {} vinit&lt;Type&gt; &amp; operator() ( Type const &amp; val ) { vec.push_back(val); } operator vector&lt;Type&gt; const &amp; () const { return vec; } }; vector&lt;int&gt; const vecint (vinit&lt;int&gt;(1)(2)(3)(4)(5)); Add another size_t Dim template parameter so the constructor can call "reserve" on vec. I'm not sure this initializer_list isn't really *that* groundbreaking.
I've had to implement that before for a quiz question, so I know all about it. But if you think this is better than or equivalent to having a syntactically consistent form of initialization, then I guess we'll have to agree to disagree. i.e. compare with std::set&lt;int&gt; favourites = {20, 352, 24, -125};
There are (at least) two kinds of polymorphism. Subtype polymorphism is the one that everyone learns about - the pointer of a subtype may appear as the pointer of the type it is derived from. Parametric polymorphism allows you to use different values identically.
2 points here: it's arguable that non built-in types shouldn't be masquerading as a builtin type. The bigger argument is that the above syntax is definitely not worth the break in compatibility.
The above syntax was never valid, so it's not a break in compatibility. And if you read the slides, you'll see Bjarne believes (and I strongly agree), that user-built/library-built types should be as first class as fundamental types. Consistency ueber alles.
10/10. Would read again. On page 65 there is [this juicy quote](http://i.imgur.com/ZtJW4.jpg). 
The solution is to use [The book](http://www.amazon.com/Programming-Principles-Practice-Using-C/dp/0321543726) pictured instead. So instead of teaching stuff chronologically with C and low level stuff first and the moving on to the pre-C++98 parts, and then not have time to teach modern C++ like the STL. You do it the other way. The most useful and high level concepts first. Like the STL.. and then you move back to the less useful prehistoric features and the low implementation details later. There is this a saying: *"The worst programmer to learn C++ is a C programmer"*. So lets not make C programmers out of students before teaching them C++. Edit: Links where Stroustrup talks about the poost state of C++ Eduction: [1](http://drdobbs.com/article/print?articleId=207000124&amp;siteSectionName=) [2](http://itmanagement.earthweb.com/features/article.php/12297_3789981_2/Bjarne-Stroustrup-on-Educating-Software-Developers.htm) 
Nearest comparable I found is MISRA-C++:2008. Anyone have experience on them, how do they compare in reality?
I disagree. See here: http://www.reddit.com/r/programming/comments/g6k0p/parallelism_is_not_concurrency/c1laxbt
You have to realize that you are prioritising learning about low level implementation details over abstract conceptual models. Something has to give when time and attention is limited. Learning about basics of STL, RAII, and time complexity analysis first, instead of registers, cycle counting, and void pointers, should be the way. I am not saying the low level implementation details is not important, I am saying that at the end of a C++ course you will have a relatively productive modern C++ programmer who can write safe and efficient programs using the STL, or you will have a low level C programmer who does not have the tools or models for data-structures and algorithms needed to program. He will probably be stuck reinvent the wheel inefficiently and unsafely. The low quality legacy C++ code in this world wont disappear if new C++ programmers keep writing low quality legacy code. Dont get me wrong. A historical low level C++ course would be a good follow up to a high level modern one. But most people only take one course in C++. This means there is no time to waste and the priorities must be right. Please dont think I'm talking about OOP and inheritance when i say high level. I dont, think STL, parametric polymorphism and time complexity theory. Think of the mathematical foundations of programming. 
No, I don't program Jet Strike Fighters or anything near that!
C *is* the pefect language, just so long as you're not in too much of a hurry. Seriously, though. Anybody who looks down their nose at C or C++ immediately loses respect in my eyes. C because it is a language that has somehow managed to find a near magical balance between power, flexibility, and verbosity. Other languages are leaps and bounds ahead of C in one or two of those three categories. But C has an almost zen like balance between the three that grows on you the more you use it. It's also low-level enough that programming in it, actually actively improves the way you think about programming, by honing your mental model of what's happening in your code. C++ because it's one of the most widely used languages in the world. It's faults, annoyances, and problems are, essentially, completely irrelevant. If you're an application or systems developer, and you're ignoring/bad mouthing C++, then you're either stupid or extremely naive. Or you're an enterprise Java programmer.
You are stuck in the 70's mindset, the mindset when UNIX and C was all there was. I have found this mindset lives on in the opensource community (take Linus infamous rant as a representation) There is no abstraction penalty for using C++ compared to C. The abstraction penalty is an old misrepresentation that wont die even though its been [debunked](http://www.stepanovpapers.com/AbstractionPenaltyBenchmark.cpp) many times. STL is as efficient as any hand coded version in C. Algorithms after all are specialize according to type. Or take sorting for instance.. in C this involves function pointers which is slower than it has too, in C++ it only involves inline functors which is fast. What I think it comes down to is this anti-intellectual idea that thinking and coding directly in abstractions is somehow bad and that thinking and coding directly in implementation details are somehow good. In C++ there is a straight forward and efficient mapping from abstractions to low level implementation details, so nothing is lost. If abstractions are a good idea in mathematics then then they must be a good idea in software development. Abstractions are details with all the irrelevant bits cut out. Its better to think with those than to clutter your thinking with noise. 
Wow I loved your last sentence!
Doesn't to "bad mouth" something mean to say negative things about it? Didn't you just say that C++ has "faults, annoyances, and problems" I agree with you about C, but not that C++ is somehow above criticism.
Heh, Java is the perfect introductory programming language nowadays, and it's all OOP and no fun.
I see what you mean. I'll go back to my favorite quote here on the subject: Computer science is no more about computers than astronomy is about telescopes I think RAII and complexity analysis certainly belong in the same group of ideas. The STL? Well, maybe. I just think that in C++ it's too easy to shoot yourself in the foot, unless you know what it's doing for you. And there's any number of ways to do that in the language. If we want students to learn more about design patterns and how to write good code first, I'd hesitate to bring up C++. Java or C# make more sense for that. EDIT: I said design patterns, but probably I should have said something else. "Design patterns" brings up one book in particular and a whole set of other baggage in general. What I meant there when I said "design patterns" is "How to express ideas in code" more than anything else.
A common miss-conception is that C++, is just C with classes. Modern C++ is not about OOP though, but about generic programming. Patterns are something of a OOP thing. The OOP style has fallen from grace with modern C++. Deep inheritance hierarchies are often ugly because the types are so tightly coupled and inflexible. Many patterns are about how to loosen this coupling and make the relationships more flexible. Seen this way patterns are band-aids to fix the broken OOP style. Generic programming represents the modern alternative to OOP. With the generic programming style, patterns are not needed as much, as parametric functions are incredibly flexible and loosely coupled already. (Small reoccurring designs still happen but are called idioms, as they are not heavyweight enough to considered patterns. RAII, pImpl, swap, traits are examples of such) . The STL was the first library designed in a generic programming style. If you ask me it was the most important library ever invented. C++ would not be half the language it is without it. It showed the way for the boost libraries that came to follow. Java and C# went the wrong way. They continued down the OOP trail, while C++ changed direction and went down the revolutionary generic programming trail. I am very happy it did. I don't think Java and C# represent good programming style. You cant do RAII in those as they lack proper destructor. Also their types lack value semantics. 
-1 Save it for stack overflow, this isn't C++-specific. 
What do you think about OCaml and the like?
When no-one on Reddit will care except you, please resist the urge to post. It just lowers the quality of the comments. 
You seem well-informed; do you know whether Stroustrup's multiple-dispatch is headed for a TR? edit: p'raps not, it doesn't appear in the link you gave, [state of C++ post-SF 2008](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2009/n2869.html).
To be honest I dont know much about it. But any language with functional style is good in my book. Functional languages are very hot now with the computer going many-core as the functional programs scale very well. But they are often impractical as its hard to program without state. I think the big old big languages will borrow and integrate some of this functional style as best they can. In C++0x for instance we got lambdas, so its easy to make functions that are first class objects and can be passed around and copied etc. Thats a big win. Then we got c++0x auto which also looks rather functional. And then we got the metaprogramming black magic, which is all functional (as there are no compile time state or loops. Its all recursion)
It wasn't that bad. The gist of it was C is better than C++, because C is low level and therefore its faster and you have more control. 
 I disagree here. Learning registers, cycle counting, void pointers, and the basics of how a computer works at the most fundamental levels of programming has been instrumental in my understanding how everything else is layered upon it. You can safely skip Pascal, C, C++ and jump straight to something like Java, but you end up having little understanding of what is actually going on inside the machine. The one thing they all have in common is that they all boil down to assembly language at some point, and it is something I think every programmer should learn, even if they never use it. As a mathematician, you may never need to perform long division in your day to day duties, but you should still know how it works. 
&gt;C because it is a language that has somehow managed to find a near magical balance between power, flexibility, and verbosity. Interesting how readability isn't even on your list of things that are important. A little secret...it has managed to find that "magical balance" by completely ignoring that 4th ideal. Other languages embrace code readability, so they have to give a little on verbosity. 
Yes, it is important. But again its a question of priorities. How should C++ programming courses be layed out. The low level stuff first, and then the high level later (like virtually all of them are now). Or the high level stuff first, and then the low level stuff later (like Stroustrups new book and course). It matters a great deal as to the type of programmers that steps out of those doors into the real world. The student will have some gaps in his knowledge either way. Its easiier to pick up implementation details afterwards (like that an iterator is just a pointer in disguise). Its worse if those gaps in knowledge are in the high level conceptual models. Say if the student does not know about STL at all. Chances are he will never use STL and keep his mind in the gutter doing malloc, cast and pointer arithmetic all the way to undefined behavior land. Or if he does not know about RAII, well that a fate too sad to think about..
Maybe I should have worded that better. It is in no way above criticism, and many of the criticisms are well deserved. I only meant that if you are ignoring *the use of* or bad mouthing *the use of* C++. A better wording might be, "If you look down at those who use C++ as being old fashioned, or you see the use of C++ to be somehow, above you, then you are..." TLDR; C++ is not going away anytime soon.
how dare you complain against the status quo! you must be a baby!
That's the one thing I hate most about C++ books, they assume you're coming from a C background, even if written within the last few years. But 1272 pages? Isn't that a little excessive? I really want to see a C++ from Java/C#/Python/Ruby book. For the novelty, if nothing else. While I'm at it, I only ever seem to see C++ hate from C users, or other language users who once upon a time used c exclusively.
Maybe I don't understand what "code readability" means but how does C completely ignore it?
Java is a terrible introductory programming language
This is where coding standards come into play.
I thought I'd run that abstraction penalty benchmark myself, out of curiosity, so I tried it with g++ with -O2 and without, for people who are lazy: O2: test absolute additions ratio with number time per second test0 0 0.04sec 1250.00M 1.00 1 0.05sec 1000.00M 1.25 2 0.05sec 1000.00M 1.25 3 0.05sec 1000.00M 1.25 4 0.05sec 1000.00M 1.25 5 0.05sec 1000.00M 1.25 6 0.05sec 1000.00M 1.25 7 0.05sec 1000.00M 1.25 8 0.05sec 1000.00M 1.25 9 0.05sec 1000.00M 1.25 10 0.05sec 1000.00M 1.25 11 0.05sec 1000.00M 1.25 12 0.05sec 1000.00M 1.25 mean: 0.05sec 1017.31M 1.23 Total absolute time: 0.64 sec Abstraction Penalty: 1.23 without: test absolute additions ratio with number time per second test0 0 0.16sec 312.50M 1.00 1 0.20sec 250.00M 1.25 2 0.58sec 86.21M 3.62 3 0.85sec 58.82M 5.31 4 1.47sec 34.01M 9.19 5 0.97sec 51.55M 6.06 6 1.51sec 33.11M 9.44 7 1.72sec 29.07M 10.75 8 2.18sec 22.94M 13.62 9 1.67sec 29.94M 10.44 10 2.17sec 23.04M 13.56 11 2.69sec 18.59M 16.81 12 3.20sec 15.62M 20.00 mean: 1.11sec 44.97M 6.95 Total absolute time: 19.37 sec Abstraction Penalty: 6.95 
Full version: http://www2.research.att.com/~bs/JSF-AV-rules.pdf
Using any programming language effectively comes down to a lot of different and sometimes orthogonal skill sets. One of them is knowing "bits and void pointers and stuff", when you need to reduce constant, non-algorithmic costs of your implementation. Another is using language features at the appropriate level of abstraction to your problem, when you're mapping algorithms you want to use to solve your problem to the language/framework at hand. Another is picking algorithms that will work well. Another skill is "process" - version control, automated testing, etc. It probably doesn't matter too much what order someone learns all this stuff in. I learned details first, RAII second, so that's my preferred teaching order. Maybe you learned it the other way, so that's yours. Just curious, is there evidence about programmer effectiveness as a function of learning order somewhere? I bet CS departments think about this stuff on occasion...
What kind of projects do you work on? Thinking on whether I want to focus on c/c++ type development or more RIA Flex stuff
MISRA-C++ recognizes JSF++ as one of its sources. In fact, I think it is a superset of JSF++. The main advantage of JSF++ is that you can download it for free. The main advantage of MISRA-C++ is that it is already integrated in some static code analyss tools
Stroustrup has been in a lot of interviews about what he thinks of the state of C++ education (some links at the top). Thats where I first heard of this idea that the priorities are all backwards, and I think he is right. He got to redesign a introductory C++ course and write a new course-book (because they all followed the same format of C first and and then STL not at all), at his current job at Texas A&amp;M University. He considers his new approach a success and that the students who finished it could actually program.
Most people who write for either language can't explain what's wrong with the statement "c = c++;".
&gt;The STL was the first library designed in a generic programming style. [Ada has had generics since it was first designed in 1977–1980. The standard library uses generics to provide many services.](http://en.wikipedia.org/wiki/Generic_programming#Generics_in_Ada)
&gt; Learning ... cycle counting On modern CPUs? Cycle counting is near impossible on many modern CPUs (including x86 and PPCs). Caches, reading memory, pipelines, predictive branching, etc... all make this nearly impossible.
 I was restating the OP's comment. It's still valid in some situations, e.g. embedded, and it's also possible to give best and worst case, which are required to know if you are dealing with hard realtime development constraints. 
There's nothing "wrong" with that statement. It's syntactically correct, will compile, and the redundant assignment will most likely be optimized away by the compiler. It's just semantically redundant. There are many better examples of things that inexperienced programmers will get wrong, if that's what your looking for.
[Effective C++ in the C++0x Age](http://scottmeyers.blogspot.com/2011/03/effective-c-in-c0x-c11-age.html) was interesting and worth the read. Basically, the book stays valid. :-)
&gt;it's not scalable. Don't say that to a functional programmer :)
Or you can add this to your software sources: ppa:ubuntu-toolchain-r/ppa
Any reason for using new-delete instead of declaring a local object?
My guess is that he wanted to use the auto keyword. I think you would need the typename where the auto keyword is if it was a local object.
Nope, `auto` can work out the type for values as well as pointers.
I stand corrected. Just a few moments thought makes me realize how utterly ridiculous my previous statement was. It has been a long day. I've *used* the auto keyword with local variables.
It's just not idiomatic to write auto th = Thread(...); instead of Thread th(....);
Sure, but it's not idiomatic to use `new`/`delete` in this way either.
c = c++ is not a defined behavior. operator= is not consider a sequence point in C++ so the order of evaluating the equal and increment are undefined. reg = c; c += 1; c = reg; and c += 1 and c = c; c += 1; would all be valid for the compiler to interpret c = c++ as. well actually the compiler could do whatever it wants since it's undefined.
I'm guessing because it ignores whitespace completely as opposed to something like python where if you don't follow some minimum of coding standards it's not a correct program.
what would that look like?
That is a good option. The reason why i have been pulling the sources all the time has been to get the latest C++0x support. I do not know how often the ppa is updated?
`auto job = std::thread([](x) { return x; });`
Nice to see benchmarks even if none of the axes are labelled or described (I would assume lower on the y-axis is better) Been doing pre-increment for more than 10 years now. This is a no brainer considering worst case post increment makes an extra copy.
I don't know either. But I'm lazy, so it's good enough for me :-)
The most annoying thing in the world is a plot without axis labels.
thanx
I've read that with primitive types, like int and pointers, the opposite is true, because of the pipelining that a CPU does. With pre-increment, a CPU has to first increment it before it can use it. With post-increment the CPU can already start using it before it is incremented (and due to optimizations there is no copy to be returned for these simple types).
Pretty nice introduction for beginners. One thing I was disappointed is missing is a nod to member templates for constructors. Extremely useful in some cases.
Could you elaborate on that?
A programmer that uses post increment is usually just professing their ignorance. I have not met a programmer that used post increment and understood the assembly level differences between the two. Most that use post don't even remember what the difference is between pre and post at a higher level (that post will return the current value before the increment is performed).
Genocide, apathy, ignorance, prejudice, and greed. (joke)
An example of what you're suggesting: int original_val = i++; if( original_val == 0 ) { do_something(); } this is equivalent to: int original_val = i; ++i; if( original_val == 0 ) { do_something(); } I am skeptical that this would result in different code. If the increment was moved after the branch (for instance, because someone is using the ternary operator for brevity) you may get some performance difference when not optimizing the code, but after optimizations I would expect equivalent code.
In that case it will not make any difference. If the returned value is used, like in the next examples, it should make a bigger difference: int i = 0; while (i&lt;10) sum += ++i; versus int i = 1; while (i&lt;11) sum += i++; because in the second example the CPU can simultaneously add the the original value to sum and increment the value. I must add that I did not test something like this. And it's possible that the compiler unrolls the loops in these examples, so the performance difference might become smaller.
Plus behavior is likely to differ on other hardware architectures. In any event what I got from the article is that the greatest impact was seen in debug code to which I have to say who cares?! In fact it looks like the bench marks support your position. This whole thing is just a bit bogus in my mind as the programmers number one goal should be clean and easy to read code. That would mean selecting the increment type that makes the most sense and is idiomatic in the context. 
"Patterns" is a bit exaggeration
Sticking with the idea that this only makes a difference in debug (once the compiler starts optimizing it's too difficult to reason about). I think that the extra branch in the second block would balance out the stall in the first. But yeah.. hard to say...
Now what we need is a open source tool set that implements the ideas expressed in these documents. I'm think new school here in the form of LLVM &amp; CLang. Not that GCC is bad just that GPL 3 sucks and frankly the CLang has much better diagnostics. 
No one has mentioned LLVM &amp; CLang. Admittedly this is a compiler suite that is barely out of diapers for ARM but it is getting there. The whole LLVM tool chain is generating a lot of interest in the community, plus Apple is involved so I believe it has staying power. As to your micro controller decision, I would tend to agree ARM is the way to go. There are many development boards to choose from. However make sure the ARM controller you go with actually has a freely available C++ compiler for it along with the required support packages. Actually you need to make a board/processor decision in parallel with the compiler search. Even with ARM you may find yourself having a hard time finding C++ support as it depends upon the instruction set memory implemented and stuff. The thing is if you truly expect to be able to program in C++ you need some place for the runtime/libraries. Some controllers just don't have a lot of spare room. 
It doesn't matter if one is more efficient than the other, or if they are the same when one takes compiler optimizations into account. That isn't the point at all. The point is that they represent 2 completely different operations. Preincrement says, "advance one, and ignore the old value--I'm moving on to bigger and better things." Postincrement says, "advance one, but give me whatever the old value was because I'm interested in using it afterwards." Failing to understand the semantic difference isn't justified by modern optimization techniques. I don't need a graph to tell me someone doesn't know what they're doing. Maybe someone could instead design a graph to illustrate to me why forcing the compiler to pick up the slack for someone's lack of understanding of basic programming concepts is a good idea.
I came here to suggest using packages of Debian. But your suggestion does the job well.
Oh, the irony. 
I'd agree. But then I had Modula-2. :( 
std::array wrapper from c++0x. This can easily be "borrowed" for use with current c++ as well. I find his to be a nice way to express n dimensional geometry (locations, boxes) and use iterators and std::algorithm and keep operations on the stack (this is at times critical for multithread performance). Otherwise for general use, std::vector with a "reserve" call followed by push_backs is the way to go.
You can find some slides [here](http://accu.org/index.php/conferences/accu_conference_2011/accu2011_sessions). Unfortunately there is not video or slides for all talks. But at least there is something. If you dont know what ACCU is, it's the biggest C++ conference around. It always gets lots of big name speakers.
Very interesting. Sadly, I can not figure out how to view the videos and when I follow the link to vimeo, it says the videos are marked private.
So if you go into [this page](http://skillsmatter.com/podcast/home/move-semanticsperfect-forwarding-and-rvalue-references) for instance. You cant just click and play the video on the right? I can watch it in IE, firefox and chrome. 
Okay, apparently flashblock was the problem. Works now.
&gt; C and C++ go even further: They require that the size of an array be known during compilation; C (and even some C++ compilers) doesn't require that as far as I know. You can allocate an array on the stack with its size known at run time: void Foo(int n) { int a[n]; }
"Syntax patterns" is the best definition I could find - any suggestions for improvements are welcome :-) !
I would call it "introduction to templates", I understand why you used the word patterns but usually when people see the word patterns in a programming related post the expect something else. Great post about “Modern C++” it scared the shit out of me too.
This is pretty cool, I like it. C++ is so exciting these days! :) Can't wait for proper compiler support though. BTW some usage examples would made it easier to understand the idea.
You can take a look at this simple test: http://goo.gl/Y3RCO. It compiles with g++-4.5, and probably even with g++-4.4 enabling -std=c++0x. You have also to get my Yats (yet-another-test-suite) library header http://goo.gl/R5Jdq. Ciao
You're really putting me on the spot here to spontaneously come up with an example that is trivial enough to understand, but at the same time might serve some purpose in the real world, but let me give it a go: https://gist.github.com/942738
identifier starting with _M = :-( But otherwise really nice showcase of new language features. 
Interesting, thanks. "Syntax-pattern"-wise, it's not really different from any other member template, or am I missing something?
Yeah, people should move on, that book is *old* ;-) Seriously though, I agree, but still I have no alternative for "patterns" here, linguistically speaking.
Have you considered an exciting career in enterprise Java programming?
The #stuff will be the easy part, the C preprocessor is not a part of the language itself. And if you're writing just a parser, the templates and all the related semantics may not be such a hard thing either. IMHO the biggest pain in the ass will be types. (Ie. Is { Queue o(); ...} a function declaration or are you creating a static object using a non-parametric constructor?)
In addition to CLANG there is GCC-XML which probably does exactly what you want which is give you an easy to work with representation of the GCC C++ front-end output (although I don't think it does function bodies). There is no such thing as parsing C++ "[without] worrying about compilation". Lexical, syntactic, and semantic analysis are all tangled together in C++. Even a simple expression like: foo(bar); is governed by so many rules it will make your head spin. What kind of analysis are you looking to do? Honestly, even a fairly naive C++ parser is probably far beyond the scope of a student project. &gt; The hard part about writing a C++ parser? All of it.
As others are saying, there's really nothing you can do here that's within an order of magnitude of being a student project's worth of work. My advice? 1. Google "most vexing parse". 2. Reread it a few time until you're on the verge of tears. 3. Realize that the entire language is full of things like this (Partial specialization, Koenig lookup, dependent name lookup, etc., etc., etc...). 4. Come up with a new project idea.
Check out [antlr](http://www.antlr.org/), and then check out the [antlr c++ grammar](http://www.antlr.org/grammar/1295920686207/antlr3.2_cpp_parser4.1.0.zip) to see what you are up against. Head asplode. 
Run the preprocessor stuff through the preprocessor.
The hard part is that it's a context sensitive language.
I don't disagree with the other comments, but to answer you especially directly: in C++, distinguishing function declarations from function definitions is LALR(infinity), unlike in C, and traditionally was solved by having a special lookahead parser to disambiguate just that particular case, looking ahead an indefinite number of tokens to do so, and feeding a disambiguation to the primary parser. This was typical a decade ago. I got disgusted with C++ and stopped paying attention. The problem won't have gone away, but there may be a new favorite solution, like using an Earley parser. I agree with the conclusion others suggest, that it is probably the least suitable language you could possibly choose for a university project. C++ is a compiler-writer's nightmare.
Figure on 10 man-years to do a correct C++ parser, and that's if you're an experienced compiler guy. Note that in order to parse C++, you'll need to write a scanner, preprocessor, lexer, parser and semantic analyzer. What's hard about it? Refactoring your code many times as you discover things about C++ that you hadn't known before.
Flex and Bison cannot even begin to parse C++.
10 Man-years? That makes it sound like as if writing a working c++ parser is akin to finding a golden needle on a haystack for which there's a few million dollars bounty. I get the feeling from the other comments that it's the case though, hmm.
rofl ofcourse not. http://code.google.com/p/lbcplp/ http://doxygen.svn.sourceforge.net/viewvc/doxygen/trunk/src/code.l?revision=762&amp;view=markup
Echoing the rest of the comments here, I agree that actually writing the C++ parser would be way beyond the scope of your project. I'd leverage work that's already out there - focus on the core of your project. It doesn't sound like the core of your project is a parser - but the analysis of the code that gets fed into it. Depending on your specific needs, you may want to take a look at leveraging the GCC suite. Specifically, look at these two options: -fdump-translation-unit -fdump-tree-switch Many years ago in undergrad and grad school, I was friends with some folks in the systems group who were doing static code analysis, and had been leveraging the Abstract Syntax Tree in the GNU tools for use in their analysis. You may find it useful to look around for stuff about this. Also, don't mess with the preprocessor. It's actually not part of C++. You can obviate the need for having to process the preprocessor syntax by leveraging the GCC again. The -E directive allows you to dump what the preprocessor creates to a file. You may find it easier to work with this so that you can ignore all the preprocessor stuff. 
Of all the people in this thread to listen to, you should listen to [Walter Bright.](http://www.walterbright.com/)
Whoa, I think I'll stop assuming that full names as reddit usernames are always from movies or games.
Parsing C++ grammar is a fairly hard job. There are many syntatic ambiguities in C++ grammar, converting them to proper LALR grammar extremely tedious, though GLR parser can be helpful if you don't bother with efficiency. Moreover, its grammar structure can't be described in context free way. So just trying to parse C++ eventually requires a nearly complete compiler front-end implementation. 
So I guess someone seriously thinking of making a parser for it must be off the charts!
More or less.
Another good example: x * y; Pointer declaration or multiplication? (Or call to operator*()?) Argument-dependent name lookup is another potentially tricky thing that comes to mind.
If you want to focus on actual analysis instead of the nitty-gritty details of C++ parsing, have a look at [Dehydra](https://developer.mozilla.org/en/Dehydra). It has successfully been used on the Mozilla code base, so it groks some real-world code. Parsing C++ to the degree that you can perform reliable static analysis on it needs a nearly complete implementation of C++. All the really hard parts have to be there.
Any typed programming language is context-sensitive. It's just that C++ is quite a large language. It would still be hard to implement proper semantic analysis if there were fewer ambiguities in the surface syntax.
Or you could use an existing C++ source code analysis framework, and implement new analyses on top of it, perhaps a static API use checker for a popular, but somewhat difficult to use library.
&gt; Any typed programming language is context-sensitive. Yes, but proper typing is (almost?) never encoded as a *syntactic* property, and so *parsing* need not be context-sensitive.
But if you want to do reliable static analysis, you still have to implement semantic analysis. Of course, if the language is quite regular, it is tempting to fake it, and that's what's not really possible with C++.
I've dabbled in processing, but Cinder seems light years beyond it. Nice work!
I've heard that some C++ compilers support this, but I've never seen it and I use quite a few different ones. So even if a certain compiler does support it, it's not very useful if you have to support different compilers. 
Clang has this extension: http://clang.llvm.org/compatibility.html#vla
Nifty
I'm scared of people cleverly misusing this. OTOH you could say that about any language feature, even good old std::vector.
Thanks, but I think it's not a real misuse. The move semantic is indeed related to a whole object and it's not limited to its internals. By passing an xvalue (std::move(instance)) you are really meaning that such an object is to be logically moved. That's the reason why the entangled_ptr should be formally correct. 
I am having a hard time coming up with a real situation where something like this would be useful. The main utility of r-value references and move semantics is to make passing/returning objects by value as efficient as passing pointers to such objects. But if you already use pointers to pass things around, then why would you also use r-value/move semantics? Your code is already as efficient as it can be.
Heh, I'm not saying entangled_ptr is an example of misuse. It makes total sense and it's a good idea. My opinions are probably colored by my work. It's C++ on game consoles, with coworkers from a wide range of skill - from prodigious to suspect. Subtle bugs are hard to find, and this is another way to add them. What I am saying though is that like the rest of C++ (which is a great language, and the STL is great, and I'm excited about 0x and everything, don't get me wrong!), this feature gives you enough rope to shoot your whole team in the foot. 
Yes berium, I agree with you. If you pass things around by pointers you don't need move semantic for them, all the more so you don't need the entangled_ptr. But if it comes to pass objects by move semantic then it may have some usefulness.
Fortunately, the designers of C++ took that problem into account and made a much simpler, cleaner grammar.
o_0 You have a strange sense of humor. 
I am wondering if entangled_ptr&lt;&gt; can play havoc with refactoring of code. I mean what if somebody changes the strategy of moving the object around and decides to make a copy instead (perception being that move semantics are only an optimization, or having to use an older API during refactoring). Suddenly one has to wonder if there is an entangled_ptr&lt;&gt; pointing to the object and how to update that code now.
Perhaps it will be interesting. We develop the static code analyzer on the basis of library [VivaCore](http://www.viva64.com/en/vivacore-library/). VivaCore - library of code parsing, analysis and transformation developed by OOO "Program Verification Systems". VivaCore is an open library and supports C/C++/C++0x. The library is written in C++ and implemented as a project for Visual Studio 2010. VivaCore is built on the basis of OpenC++ (OpenCxx) which is currently not developed. P.S. The problem of creation of the analyzer is very difficult. It is better to take another's workings out.
No. In many cases, a constructor behaves the same as any other void-returning function (e.g. few people even realize you can use a "return" expression inside of it to exit early). It just has an air of mystery around it because it has an initialization list and is rarely invoked explicitly.
* Scribd: http://www.scribd.com/doc/31244302/C-GUI-Programming-With-Qt-4-1st-Ed * PDF in ZIP: http://qtrac.eu/C++-GUI-Programming-with-Qt-4-1st-ed.zip Author's homepage: http://qtrac.eu/marksummerfield.html
 Good stuff. With a timer interrupt and interrupt handler, this could easily be made preemptive. Normally your multitasking OS takes over the timer, but there [is another timer](http://free-books-online.org/computers/system-programming/time-updation-through-int8/) which can be used if you are careful about it. 
The [second edition is also available for free](http://www.informit.com/store/product.aspx?isbn=0132354160) from InformIT (not as a PDF though).
A video interview with Herb Sutter. What a rare treat. As far as I'm concerned he is the best programmer alive.
About time, over the last few years they've made C++ developers feel like second class citizens. I'm glad they're making "aggressive investments in C++". Let's leave the managed code for the folks doing CRUD apps. Oh and if XAML + Native doesn't happen I might cry. I've had enough of that dialog editor...
Qt has shown that it is possible to create a sane and usable C++ API. It doesn't have to be a nightmare like MFC. I'm looking forward to a native C++ framework for Windows.
Except for the fact that Qt pretty much hijacks the language with its own preprocessor/extensions.
No, it doesn't. A third-party signals/slots implementation can be used with Qt, if for some reason the moc is not desirable. The only thing that would be missing is the superior meta-information. And we are talking about the API, not the "extensions". Sensibly and consistently named classes and methods don't require a preprocessor.
While I don't like the MOC, the "extensions" are nothing more than macro definitions which are used by the MOC. 
What about the APIs? Microsoft has put all its effort to .NET. Are they going to recode their feature-rich APIs for C++? and then maintain two codebases, one for .NET and one for C++?
Is this somehow better? BEGIN_MESSAGE_MAP(CMainFrame, CMDIFrameWndEx) ON_WM_CREATE() ON_COMMAND(ID_WINDOW_MANAGER, &amp;CMainFrame::OnWindowManager) ON_COMMAND(ID_VIEW_CUSTOMIZE, &amp;CMainFrame::OnViewCustomize) ON_REGISTERED_MESSAGE(AFX_WM_CREATETOOLBAR, &amp;CMainFrame::OnToolbarCreateNew) ON_COMMAND_RANGE(ID_VIEW_APPLOOK_WIN_2000, ID_VIEW_APPLOOK_WINDOWS_7, &amp;CMainFrame::OnApplicationLook) ON_UPDATE_COMMAND_UI_RANGE(ID_VIEW_APPLOOK_WIN_2000, ID_VIEW_APPLOOK_WINDOWS_7, &amp;CMainFrame::OnUpdateApplicationLook) ON_WM_SETTINGCHANGE() END_MESSAGE_MAP() 
I have a really hard time believing that MS would be this stupid. I actually do enjoy working with C++, but MS has put so much effort into .NET and its languages, that I don't understand how they can justify such an about-face. C# really is a better language for writing little one-off client apps, and logically replaces VB in that role. Web application servers fill that role for one-off business apps today. Again, MS has aggressively placed C# in that role to compete with Java, and I think they've been fairly successful. C++ is much more demanding on the engineers, so it really is only suitable for highly demanding applications that justify the extra development cost. But it's the market need for all those little one-off apps that drives the bulk of the user base for tools vendors. I just don't see how they can double the size of their tooling revenue by selling C++. 
| if XAML + Native doesn't happen I might cry. I've had enough of that dialog editor... Who knows? Maybe they'll make a swanky new super-wham-o-dyne native API based on C++0x features. I'll believe it when I see it. Until then, its all speculation and dreamware.
There are a lot of sane, usable C++ APIs, but I assume you actually meant for windowing libraries.
 After dealing with straight Win32, MFC, and ATL, I simply won't make another C++ GUI for windows. Ever. What I will continue to do, is create C++ COM applications which expose their API and events as a cohesive, headless application, and then slap the UI on top of it using a more capable system, such as C#. Best of both worlds. The MVC concept is [not new](http://en.wikipedia.org/wiki/Smalltalk), and there is no reason the view has to be C++.
WinC++? Oi Vei! I can already imagine my next recruiter: "Do you know C++? and WinC++?" MS, please! before you do any of those things! FIX the vc2010 executable bloat!
There is actually an interesting comment to the original article that talks about this. Apparently, the "Windows Development folks" at Microsoft never really bought into this whole .Net thing. And now, that they have the success of Windows 7, they are trying to get it their way.
Three reasons - performance, performance, performance. Large desktop apps, games etc can't use .NET because it's just not fast enough. 
I understand the reasons why you might pick C++ for a particular project. I just don't think that the market for those performance-intensive projects is big enough to double their tools revenue in a few years.
Why should it be scary to anyone? I think it is a fair question from a person who has no C/C++ experience. Remember that Compile/Link model is ancient artifacts of old compilers. It is not like you are working with this guy now. 
Yeah, good point, I guess they will be looking to the next generation of phones and tablets as growth points?
It scares me that people can go head long into thinking "I'm going to use C++ for this project" without even a basic grasp of the language. Added to that is when people suggest he reads a book on the subject first, he replies with: &gt; I don't have time to read up in c++ before I want to get this done (I &gt; also hate pointers with a passion). I know that in c# I can include files &gt; so I could attempt to mix them together correct?
Hey look! That's right outside building 41.
That's MFC, and everyone knows it's awful. C++ has a strong future because it's so close to the hardware, and at the same time allows very high abstraction when used correctly. I'll agree that MFC isn't better than anything.
more likely he is the only one who can program in the office and has to work on some C++ code base. 
I fail to see what this has to do with C++ instead of their plans to expand usage of their IDE. C++ is definitely not a "microsoft centric" language. The standards body is platform agnostic, and microsoft "backs" it only in the sense that they have an IDE that supports it, and some old libraries that you can use to make applications. In other news, I can't believe they're still trying to push the paid IDE market. I fear that Apple is moving towards this direction with the paid subscriptions to the Developer program, though.
Funny how things are coming full circle. First the hardware was not powerful enough so we needed languages like C and C++. Then the hardware became so powerful that it didn't matter if we wasted some of the resources on the VM layer. Now, we are back to the point where every CPU cycle counts (battery life, size, cost per unit, etc).
That might be the case, but it's still asking for massive trouble.
Microsoft reinvents APIs all the time. GDI/GDI+/Direct2D; Win32/WinForms/WPF; a zillion different database APIs; and so on. I’m sure it’s great fun for their employees who get to abandon the old boring stuff and work on the new cool stuff, but it can be some work for us programmers to keep up. That’s our job though…
Qt source won't compile on a vanilla C++ compiler without running the MOC first (which *does* generate vanilla C++), but the "hijacking" is extremely limited and basically amounts to features C++ couldn't have without it (basically reflection: http://doc.qt.nokia.com/latest/metaobjects.html#meta-object-system). It's possible to have Properties without the MOC, but it's uglier and less flexible; it's also possible to have signals+slots without the MOC but auto-generating bindings would be harder, amongst other reasons: http://doc.qt.nokia.com/latest/templates.html
&gt; After dealing with straight Win32, MFC, and ATL I see your problem there; and it's not C++...
Cell phones and other embedded devices. That said, a Dalvik-style solution appears to be working for Google...
&gt; I can't believe they're still trying to push the paid IDE market. The latest Visual C++ is a f'n dream.
Seriously, I haven't found anything that works anywhere near as nice for managing code projects, even for money, and if you throw in visual assist there's a whole extra level of how the hell did I survive without this.
Yeah, I too use Visual Assist and find it very useful.
 Sure, C++ is fine. The problem is Windows, and the native Windows API. If you don't use the native Windows API, your apps look like crap. You can tell when an app is written in Qt, or Delphi, or Java, or any other system that roles their own API. Under Windows no matter what you do you can't get away from while(GetMessage(&amp;msg, NULL, 0, 0) &gt; 0) { TranslateMessage(&amp;msg); DispatchMessage(&amp;msg); } It's always there, crufting up whatever elegance you aspire to. My problem is I'm writing apps for Windows.
it might work for them but not for me. android is clearly less responsive than ios...and i have a tegra2 tablet running gingerbread.
[Herb Sutter said it best.](http://www.gotw.ca/publications/concurrency-ddj.htm)
You already have a dual core phones (if not quad), I really think that it's not JUST the performance of C++ that keeps it alive. 
Yep good point. Use the right tool for the job. I had this argument (and lost it) in the pre-.NET days, arguing that a C++ project should use VB6 for the GUI. There are occasions of course where a user interface needs the performance and finessed control that you get from a C/C++ API, but in the vast majority of cases you just need buttons and textboxes so for crying out loud use the tools that make this easiest. 
Embedded devices are much more common now than 15 years ago. Also the CPU's stopped getting faster (the free lunch is over). So performance matters again. The world has changed and the managed languages are starting to look like dinosaurs, stuck in a dead end evolutionary path. They made a gamble on moores law meaning free performance gains forever, and lost.
Silverlight, damn.
UR DOIN IT RONG; it's: Base* original = new Derived(); // time passes Base* copy = original-&gt;clone(); But you mention that double-dispatch wants in to the language; well Bjarne had something ready, but not in time for the standards process. 
Yes, that is polymorphic copy construction. I know you can use the clone idiom to do that in Java and C++. What I was trying to show there is that there is no (practical) way to do polymorphic copy assignment. We really need a core language feature for that. 
Qt has far more than mere windowing libraries.
I confess I don't see the need if you can do the canonical, version above but, there are other reasons to want double dispatch, sure. 
Copy assignment is a fundamental part of value semantics. Take an int. Built in types have value semantics and it means you can do: int i = 0; //1 int j = i; //2 i = j; //3 Currently working with OOP polymorphic objects is a pain because they don't support value semantics. We have default construction (1) and slightly cumbersome copy construction (2, with the clone idiom). But we don't have copy assignment constructions (3). It really is a fundamental gap in the type system. Enabling polymorphic copy assignment would be the the biggest selling point of multimethods. 
I finally get what you're saying. I guess the current C++ style is such that it steers us away from even noticing the gap. 
That and Amdahl's Law, which means parallelism (usually) doesn't give you as much as you'd hoped for. 
Very succintly said. .. so it's bonanza time for C++ programmers! Or, soon, hopefully. 
i think we should begin to accept that more and more people now want to write code just to get things done, and that source code is just a means to an end and not the end itself for most people. 
That was an awful lot of text. I didn't read any of it, but I'm sure the important bits can be summed up as: traverse rows, read full cache lines, bang bitches.
You should watch the [video](http://skillsmatter.com/podcast/home/cpu-caches-and-why-you-care). The presentation materials wont make much sense without it. Its mostly about false sharing. 
Hey jaybof - you'll probably have better luck asking a question rather then (apparently) just asking someone to do your homework. We're more then happy to offer advice, but you'll learn nothing if we do this for you.
bitches love cache EDIT: Downvotes? That's GOLD, Jerry, GOLD!
I don't always write memory-bound code, but when I do, I don't go against the cache grain. Yawn. Most developers don't know this because they don't need to know. The ones who do need to know already know.
That provides an extremely easy way to blow the stack accidentally.
Man I understood about 10% of that... the parts in ENGLISH
Here is a TL;DW: You care, if you care about performance. In the near future the only way to get performance is by caring about parallel scalability onto multiple cores. And this is where details like caches and false sharing will ruin your day unless you know about it.
&gt; `Vector(void)` ಠ_ಠ
Useful stuff, presented very well.
I am a little annoyed by the microsoft guys talking about c++ and the fact that c++ is cross platform, but at the same time they keep talking about task-based parallelization in the Parallel Patterns Library (PPL), which is windows only.
I understand the frustration and I apologize if it makes the talk(s) less interesting. When we were working on VS2010, a lot of the work in the standards committee for task-based parallelism wasn't baked yet so we opted to build our own libraries on top of lambdas as you point out. With a little more patience, I think it will be possible to write fully standards-compliant parallel task/future code but it would be hard to do so with what's out there right this moment. Would love to hear the specific libraries/features you want to know more about!
Well, I don't mind hearing about libraries or features in VS2010. But with most of the material from MSDN the listener/reader is not told which part is VS2010 and which is the standard library. That would be simple to fix by just saying "the following is a VS feature: ...". That way the (often great) information about c++ in general could reach more people. I expect this to be important for VS customers, too (cross platform and all).
I know you're trying to promote the PPL, but you never mentioned anything about what is getting standardized in C++11 in terms of concurrency/parallelism. You mentioned that the C++11 standard acknowledges behaviour in the presence of threads which is true but you never mentioned what was added to the language/standard library and talk about PPL which maybe misleading people into thinking those things don't exist for writing portable code. I would have mentioned both PPL and what it is in C++11 (in brief of-course) and just say that PPL is a more high-level API for writing code that utilities multicores efficiently. Nothing wrong with that. On an unrelated note the syntax for writing user-defined initializer lists is not by using operator overloading, just a constructor using the special single-linked list std::initializer_list, actually you can use std::initializer_list with any function. 
i find the videos from pluralsight.com and appdev.com a good way to learn c# in a short period of time. http://www.blackwasp.co.uk/Tutorials.aspx has some good tutorials. I wish you luck! btw the syntax for c# and java are very similar
I'd argue that they haven't put all their efforts into .Net. It's been said before, [Windows is not a .NET Framework delivery channel ](http://blogs.msdn.com/b/oldnewthing/archive/2011/04/04/10149346.aspx). The framework isn't even guaranteed to be on a given machine. A lot has been invested in the framework, that isn't in dispute, but isn't it interesting that none of their major flagship applications or system components are from-the-ground-up .Net? Incidentally, I thought I heard a rumor that the VS2010 ide leverages some WPF (which would explain why the fucking thing is shiny as hell but slow as fuck) but that seems to be about it. How long as .Net been out? Ten years? The two maintenance codebases you refer to already exist: Win32 and Everything Else (COM, .Net, etc). 
99% of their client APIs effort has gone to .NET. MFC has very small upgrades. I have expected something with the quality and easiness of Qt to come out of Microsoft, but they do not do that on purpose: if C++ suddenly becomes easy to use on Win32, then there is no much reason for .NET, is it? it's called vendor lockin. The reason their flagship applications aren't .NET 100%, is performance. Word, for example, must be able to handle ginormous engineering documents, something that .NET is not up for. Visual Studio needs to compile things as quickly as possible for intellisense to work (although I am not sure intellisense is not .NET). 
99% of their client APIs effort has gone to .NET. MFC has very small upgrades. I have expected something with the quality and easiness of Qt to come out of Microsoft, but they do not do that on purpose: if C++ suddenly becomes easy to use on Win32, then there is no much reason for .NET, is it? it's called vendor lockin. The reason their flagship applications aren't .NET 100%, is performance. Word, for example, must be able to handle ginormous engineering documents, something that .NET is not up for. Visual Studio needs to compile things as quickly as possible for intellisense to work (although I am not sure intellisense is not .NET). 
Anyone know if videos of the lectures will be made available? If so, which page/website should I be F5-spamming? :P
Previous lectures were available via http://blip.tv http://groups.google.com/group/boost-list/browse_thread/thread/f4365e144457911d?pli=1
You're absolutely right. I'll definitely try to ensure we do a better job in our talks and as for MSDN, I think it's a great goal as well (I have to look into how we can embed this kind of info). As for promoting PPL, the primary reason isn't that it's cross-platform but because we think it brings C++ developers the right higher-level abstractions to write safe and scalable parallel code. The standard has focused on the low-level building blocks (threads/locks) and we firmly believe that things like the actor pattern and light-weight tasks are more scalable, thus the PPL (plus the timing issue like I said).
Marshall Clow is recording both tracks so the videos will most likely be online at some point.
I've used this pattern, particularly with mixins.
Yes. It's pretty much always a mistake to put "advanced" anything on a resume unless you have the goods to back it up. Lying on a resume is a big mistake and always comes back to bite you in the ass.
It's hard to tell without knowing how much C++ you have programmed, and at what level. EDIT: What I would expect from someone with advanced C knowledge is probably very good knowledge of system and API design in a imperative/procedural fashion. Design whole systems including memory allocation and resource management, while keeping good control over how that system executes on the hardware it was designed for. Is it an embedded system? Then good conservative memory management is a must. What is the performance requirements? Does that affect my data layout? Etc.
Can you explain the differences (or lack thereof) between these function definitions? void foo(char c[]); void foo(char c[1]); void foo(char *c); Do you know why this is defined this way? #define FOO(X) do {\ something_else(X);\ } while(0) Can you explain the purpose of 'x' in this example? typedef struct foo { uint32_t header; uint32_t types; char x[1]; } foo_t; Do you know what alloca() is? Or more importantly, why it sucks? If I ask you to explain what happens when you call malloc(), how far down the stack do you get? What about free()? An "advanced" C guy should probably handle all these questions without difficulty. edit: fixed semicolon problem
Se my edit above of what I would expect (I program in high performance systems with somewhat constrained memory). It's still hard to tell at what level you are on (and what they think "advanced" is). Pray for the best.
Internship, as in, you are still a college student? Take this with a grain of salt because I'm an engineer and not a CS person, but when I was college, I was afraid every summer of being underqualified for my internships. Things always turned out fine. That's not because I was super competent. It's because when a (big chemical) company hires an intern, they are much more interested in your "soft" skills, like getting along with others, communication, docility, and the like, than they are in your specific engineering knowledge. They are test-driving you before they offer you a full-time position. If they decide to hire you after you graduate, that's when you'll learn everything you need to know to actually do something at the company. OTOH, if it's a small company who hires interns because they are a source of cheap and energetic labor, maybe you should start studying C. :)
If you're not lying about the "I know about X" answers, and could talk coherently about them for a few minutes each, I'd say that's "advanced" in some contexts... but probably not a global one. "Proficient" is probably a better designator. &gt; I don't know why you would declare array of size 1 instead of just a character pointer. Research that. It's a common C idiom.
Well, how far in school did you go? "Advanced" is really a subjective term. The company will have needs that they're looking to fulfill and that'll play a lot into how they define "advanced." As far as programming for wireless devices, you're more advanced than I. I know how to use C++ pointers and OOP like nobody else's business. Which skill is more "advanced?" If they're looking to make apps for cell phones, then I'm the wrong man. If they need someone that can create objects to hold arrays of pointers to handle lists of an unknown size then I can whip that up in a snap.
Look at how your experience racks up against other people in the job. If they have more than you, you're a novice. If you have more than them, you're advanced.
[link](http://channel9.msdn.com/Shows/Going+Deep/C9-Lectures-Stephan-T-Lavavej-Advanced-STL-5-of-n)
 #define FOO(X) do {\ something_else(X);\ } while(0); should not have the semicolon at the end, if I understand correctly. Probably doesn't matter, but you're using the do while idiom anyway, might as well use it right.
Ah, you're right, I missed that. Thanks.
[Link for the lazy.](http://stackoverflow.com/questions/4231953/trailing-array-idiom/4232016#4232016) Clever.
Gonna take a shot at the first question. Do you mind? I don't think there is a difference in the machine code. The difference is meaningful to the programmer, though. The first assumes a particular size (which I would expect to be passed in another variable), the second tells you that it expects an array of size 1, and the third takes a null-terminated string.
[this](http://blog.llvm.org/2010/05/clang-builds-boost.html) guy claims he was able to compile most all of boost with clang. Is your boost or clang version old? Edit: Some [other guy]( http://lists.cs.uiuc.edu/pipermail/cfe-dev/2011-April/014492.html) on the internet: &gt; Only very recently has boost and clang started working well together. I would advise upgrading to the latest version of boost. 
Maybe you need to say more about what goes wrong? I just used the latest version of clang to compile, link, and run the source code from here: http://onlamp.com/pub/a/onlamp/2006/05/04/smart-pointers.html?page=5
...
Apple clang version 2.0 (tags/Apple/clang-139) (based on LLVM 2.9svn) Boost 1.46.1
I've updated the text of this post with the specifics.
Maybe you need newer version of clang then. If I understand it correctly the one they tested boost 1_46_1 with was clang 2.8 but the one you got is 2.0. http://www.boost.org/users/history/version_1_46_1.html 
Yikes! Didn't realize Apple was so far behind! *Edit: It appears that Apple has their own versioning for Clang. The LLVM version is 2.9, which appears to be the latest. So, still stuck.*
I have an unrelated question. Are you building Boost or using the header only parts? If you do happen to be building it, are you using BJAM or is there some kind of Xcode project that I am not aware of?
It's installed via Macports (I've hand-built it in the past, but it's such a pain). However, intrusive_ptr is a header-only part of boost and doesn't require any compiled libraries to work. (Only threads and one or two other subsystems *(edit: a small handfull)* require compiled files, I think.) [I'm not the first person to run into this](http://lists.apple.com/archives/objc-language/2011/Mar/msg00048.html), but I've yet to find anything that details a solution (as is, as far as I've been able to find, an actual compiler bug).
I don't have 2.0 to test but stupid questiong: are you declaring intrusive_ptr_release before or after using intrusive_ptr?
Before, of course. :) The code compiles and runs just fine under GCC.
Ten tips, certainly. Not sure about "top".
Could you try this implementation https://gist.github.com/987870 ? At least it works on 2.8.
Interesting. That looks a bit different than my code. I'll give it a shot after work today and see how it goes.
Some of these are subjective, or even horrible suggestions. "do use using statement"? Seriously, as a blanket suggestion? You should *never* do a using namespace in a header. In a header, only pull in the specific names you want. using namespace should be restricted to implementation files at best, and even then, should be used sparingly to avoid collisions. I agree with the eliminate magic numbers, but wholly disagree with using "#define VARIABLE_NAME 10", use "const int VARIABLE_NAME=10;", instead.
Tip 0: Read Effective C++ Tip ∞: Apply Effective C++ in ways it makes sense.
Wow, that was a HORRIBLE article.
Pretty stupid. E.g. the first tip and this code: if (Sample *pSample = pFactory-&gt;GetSample()) 1. Get 2. Test for NULL 3. Local visibility But still equal '=' sign and it's very useful
&gt; Don’t Use Global Variables Except to Communicate Between Functions Never ever use global variables. Especially in threaded programs. 
nice to see google throwing clang some love
Those are pretty basic and not C++ specific. For instance advocating #define when c++ has "static const" variables is plain wrong. And a list of tips for C++ that don't mention RAII is incredible.
And instead of fixing C++ by making a new language, they create workarounds for its flaws, perpetuating the sorry state of programming that is today. 
Non-blogspam link: http://robert.hodgin.usesthis.com/
Go? 
&gt; Response ProcessRequest(Widget foo, Whatsit bar, bool *charge_acct) Who the hell wrote this horror? Never heard of references?
Google coding guidelines do not allow non-const reference parameters. If you have a function parameter used for output you pass an explicit pointer.
Did you try declaring your intrusive_ptr_add_ref/release functiona inside namespace boost? 
I tried your code and I'm getting a slew of different errors. I'm successfully using the line '#include &lt;boost/intrusive_ptr.hpp&gt;' and I put my derived class directly below your RefCounted class code in the same file: class MyClass : RefCounted&lt;MyClass&gt; { public: int myvar1; int myvar2; }; ... and instantiating is thusly: boost::intrusive_ptr&lt;MyClass&gt; ptr_myclass = new MyClass; *Edit: altered to derive RefCounted to be a public base class and the sucker compiled. Argh. I still have no idea what went wrong in my original code.* *Edit #2: I've posted my malfunctioning-in-CLANG-but-compiles-in-GCC [over to gist](https://gist.github.com/990218) if you'd care to take a look. I used the same structure as the Boost documentation examples, and it compiles and runs fine in GCC.*
Yep. [I've uploaded the object to gist](https://gist.github.com/990218), if that helps.
How do you allow a type to be written to a std::ostream then?
It's even worse for std::istream, where both the stream and the object should be non-const reference. But such guidelines usually have exceptions for this kind of thing, because you can't change the standard library, and most programmers will know that 'cin &gt;&gt; n' will change n.
Thats a very misguided guideline. The assigning bool to pointer bug would never happen with references. Also they get bugs when they don't check the pointer for null. It makes you wonder who is in charge at google? Most companies should just use [this book](http://www.amazon.com/Coding-Standards-Rules-Guidelines-Practices/dp/0321113586) as coding standard and save themselves the trouble of getting it wrong. Edit: If [this](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml#Reference_Arguments) is googles coding standard its a pretty sad one. You can tell they have the priorities wrong when half the coding standard is about naming and formatting and the important stuff is in a short section called other. They even forbid function and operator overloading! This not only makes function names confusing but but makes it hard to work with STL. But worst of all they suggest doing initialization outside the constructor! That makes RAII and exception safety impossible! Note to self.. never work for google.
Not good enough. Fixes some things, introduces some other problems.
&gt; The assigning bool to pointer bug would never happen with references. I'm not going to defend Google's coding guidelines (well, maybe I will, a bit, at least those parts I agree with): I don't work for them. I was just responding to aveceasar's question, "Never heard of references?" With that said, one reason I personally do not like using non-const references as output parameters is that it is not immediately obvious when reading code you don't necessarily know that the argument in question is indeed being used for output. You either need naming conventions (which you seem to disapprove of, "half the coding standard is about naming and formatting") or some other mechanism to unify form and function. &gt; Also they get bugs when they don't check the pointer for null. I do know that Google's C++ code uses lots of assertions to define pre- and post-conditions. Presumably there would be an assertion for this. My reading of their standards leads me to believe they are very pragmatic, and targeted towards an engineering environment where people jump between projects and groups regularly (they strive to hire generalists, not people with specific skills that pigeon-hole them into a single task) and have a huge code base to deal with. By specifying naming and formatting conventions it makes it much easier to come up to speed with new code because you have a common "world view". They are also very conservative. Many large companies I've worked for, with significant C++ code bases that predate the stabilization of some C++ language features, are similarly conservative in the use of language features to ensure compatibility. Anyway, just my $0.02.
&gt; If you have a function parameter used for output you pass an explicit pointer. Yep, another unfortunate Google guidline. The only good aspect of it is that it is visible from the caller that the value of the passed parameter could be changed.
Right, I would posit that this is a very good thing, since when reading new code you're more likely to see callers of the function than the function itself. 
More details here: http://www.h-online.com/open/news/item/FreeBSD-and-NetBSD-s-new-C-library-1250294.html
Hence this. Those are pretty stupid guidlines.
I'm honestly interested in your justification for claiming them to be stupid. I actually *hate* the use of references for output parameters because they make reading code in a non-trivial C++ code base very confusing. const references for input parameters, explicit pointers for output parameters: well defined usage pattern that avoids confusion. Seems like a win. 
Why do you think it's confusing? const reference for in arguments, non-const for out. Precisely because of the (hard to spot) bug in the article, pointers as parameters shoud be verboten...
&gt; Why do you think it's confusing? If I'm reading a piece of code, // ... blah blah bool foo = false; // 20 lines later... int frob = bindlewurdle(bar, baz, foo); if (foo) { // whatever } I have no idea that foo's value is going to be changed by `bindlewurdle` unless I look go and look at the declaration for that function. However, if there is a convention that output parameters are passed explicitly and I instead read int frob = bindlewurdle(bar, baz, &amp;foo); Then that is an immediate cue that foo is probably being mutated inside the function. A simple convention that lowers the cognitive load on the programmer who may not be familiar with the code-base. 
I can see your point... still it's not a good state of mind to assume immutability of variables. In your particular example, mere presence of "if(foo)" should trigger you curiosity. :)
Yes, the conditional is definitely a red flag that `foo` probably got modified. &gt; [...] still it's not a good state of mind to assume immutability of variables. Ah hah! In C if you don't pass a pointer to a function then you *could* assume immutability on the arguments. In C++ with the addition of references you always have that nagging feeling that the world could be changing out from underneath you without you knowing it. And that's the real point of this particular suggestion in their guidelines.
&gt; In C if you don't pass a pointer to a function then you could assume immutability on the arguments. Arguments? Yes. Variables? Not without **very carefully** examining the code... int foo = 123; ... int *bar = &amp;foo; ... sneaky(bar); ... whatnow(foo); Point being, better not to make assumptions. :)
Touché. :-)
This, like double-buffering, was one of those things I thought I had invented and then later stumbled across the fact that it had been originally discovered/used years and years prior. :) *Edit: Spleling*
You have yet to post even one error message. What are we, psychic?
The error message is listed in Edit #2: "Use of undeclared identifier 'intrusive_ptr_release'". Also happens with intrusive_ptr_add.
I apologize. My mistake. Thank you for the correction. From the earlier text, I had thought there were tons.
I was a little sleep-deprived during my initial posting, so any omissions and lack of clarity probably stem from that. :)
Just in case, I want to remind you that the article describes only some of the suspicious places in code. The analysis of the full PVS-Studio report is a huge task and it's better to be performed by the developers themselves. I will now cite some additional suspicious fragments from Chromium and it's libraries: V564 The '&amp;' operator is applied to bool type value. You've probably forgotten to include parentheses or intended to use the '&amp;&amp;' operator. base platform_file_win.cc 216 #define FILE_ATTRIBUTE_DIRECTORY 0x00000010 bool GetPlatformFileInfo(PlatformFile file, PlatformFileInfo* info) { ... info-&gt;is_directory = file_info.dwFileAttributes &amp; FILE_ATTRIBUTE_DIRECTORY != 0; ... } ----- V503 This is a nonsensical comparison: pointer &lt; 0. browser profile_impl.cc 169 void GetCacheParameters(ContextType type, FilePath* cache_path, int* max_size) { ... *max_size = 0; if (!base::StringToInt(value, max_size)) { *max_size = 0; } else if (max_size &lt; 0) { *max_size = 0; } ... } ----- V511 The sizeof() operator returns size of the pointer, and not of the array, in 'sizeof (salt)' expression. browser visitedlink_master.cc 968 V512 A call of the 'memcpy' function will lead to underflow of the buffer 'salt_'. browser visitedlink_master.cc 968 uint8 salt_[LINK_SALT_LENGTH]; VisitedLinkMaster::TableBuilder::TableBuilder( VisitedLinkMaster* master, const uint8 salt[LINK_SALT_LENGTH]) : master_(master), success_(true) { fingerprints_.reserve(4096); memcpy(salt_, salt, sizeof(salt)); } ----- V530 The return value of function 'empty' is required to be utilized. chrome_frame_ie protocol_sink_wrap.cc 399 std::wstring url_; HRESULT ProtData::ReportProgress(IInternetProtocolSink* delegate, ULONG status_code, LPCWSTR status_text) { ... case BINDSTATUS_REDIRECTING: url_.empty(); if (status_text) url_ = status_text; break; ... } ----- V554 Incorrect use of auto_ptr. The memory allocated with 'new []' will be cleaned using 'delete'. interactive_ui_tests accessibility_win_browsertest.cc 171 void AccessibleContainsAccessible(...) { ... auto_ptr&lt;VARIANT&gt; child_array(new VARIANT[child_count]); ... } ----- V540 Member 'lpstrFilter' should point to string terminated by two 0 characters. test_shell_common test_shell_win.cc 643 bool TestShell::PromptForSaveFile(const wchar_t* prompt_title, FilePath* result) { ... OPENFILENAME info = {0}; ... info.lpstrFilter = L"*.txt"; ... } ----- V517 The use of 'if (A) {...} else if (A) {...}' pattern was detected. There is a probability of logical error presence. Check lines: 800, 808. icui18n msgfmt.cpp 800 UnicodeString&amp; MessageFormat::toPattern(UnicodeString&amp; appendTo) const { ... else if (formatAlias == *defaultTimeTemplate) { appendTo += ID_TIME; } ... else if (formatAlias == *defaultTimeTemplate) { appendTo += ID_TIME; appendTo += COMMA; appendTo += ID_MEDIUM; } ... } And here: V517 The use of 'if (A) {...} else if (A) {...}' pattern was detected. There is a probability of logical error presence. Check lines: 777, 785. icui18n msgfmt.cpp 777 ----- V501 There are identical sub-expressions to the left and to the right of the '&amp;&amp;' operator: !has_audio &amp;&amp;!has_audio libjingle_p2p sessionmessages.cc 308 bool ParseGingleTransportInfos(...) { ... bool has_audio = FindContentInfoByName(contents, CN_AUDIO) != NULL; bool has_video = FindContentInfoByName(contents, CN_VIDEO) != NULL; if (!has_audio &amp;&amp; !has_audio) { ... } ----- V517 The use of 'if (A) {...} else if (A) {...}' pattern was detected. There is a probability of logical error presence. Check lines: 353, 355. libwebp frame.c 353 void VP8ReconstructBlock(VP8Decoder* const dec) { ... if (dec-&gt;non_zero_ &amp; (1 &lt;&lt; n)) { VP8Transform(coeffs + n * 16, dst); } else if (dec-&gt;non_zero_ &amp; (1 &lt;&lt; n)) { VP8TransformDC(coeffs + n * 16, dst); } ... } ----- V501 There are identical sub-expressions 'sub-&gt;negNsSet-&gt;value' to the left and to the right of the '==' operator. libxml xmlschemas.c 13949 static int xmlSchemaCheckCOSNSSubset(...) { ... if ((sub-&gt;negNsSet != NULL) &amp;&amp; (super-&gt;negNsSet != NULL) &amp;&amp; (sub-&gt;negNsSet-&gt;value == sub-&gt;negNsSet-&gt;value)) return 0; ... } ----- V501 There are identical sub-expressions 'ir1-&gt;operands [0]-&gt;type-&gt;is_matrix ()' to the left and to the right of the '||' operator. mesa ir_algebraic.cpp 189 bool ir_algebraic_visitor::reassociate_constant(...) { ... if (ir1-&gt;operands[0]-&gt;type-&gt;is_matrix() || ir1-&gt;operands[0]-&gt;type-&gt;is_matrix() || ir2-&gt;operands[1]-&gt;type-&gt;is_matrix() || ir2-&gt;operands[1]-&gt;type-&gt;is_matrix()) return false; ... } ----- V501 There are identical sub-expressions to the left and to the right of the '&amp;&amp;' operator: width &gt; 0 &amp;&amp; height &gt; 0 &amp;&amp; height &gt; 0 mesa teximage.c 2801 void GLAPIENTRY _mesa_TexSubImage3D(...) { ... else if (width &gt; 0 &amp;&amp; height &gt; 0 &amp;&amp; height &gt; 0) { ... } ----- V547 Expression 'input.len &lt; 0' is always false. Unsigned type value is never &lt; 0. nss pk11merge.c 491 struct SECItemStr { ... unsigned int len; }; static SECStatus pk11_mergeSecretKey(...) { ... if (input.len &lt; 0) { rv = SECFailure; goto done; } ... } ----- V564 The '&amp;' operator is applied to bool type value. You've probably forgotten to include parentheses or intended to use the '&amp;&amp;' operator. nss secasn1u.c 121 PRBool SEC_ASN1IsTemplateSimple(const SEC_ASN1Template *theTemplate) { ... if (!theTemplate-&gt;kind &amp; SEC_ASN1_CHOICE) { return PR_FALSE; /* no choice means not simple */ } ... } ----- V502 Perhaps the '?:' operator works in a different way than it was expected. The '?:' operator has a lower priority than the '+' operator. ots gdef.cc 278 bool version_2; bool ots_gdef_parse(...) { ... const unsigned gdef_header_end = static_cast&lt;unsigned&gt;(8) + gdef-&gt;version_2 ? static_cast&lt;unsigned&gt;(2) : static_cast&lt;unsigned&gt;(0); ... } ----- V501 There are identical sub-expressions 'kKeep_StencilOp == fFrontFailOp' to the left and to the right of the '&amp;&amp;' operator. skia grstencil.h 159 bool isDisabled() const { return kKeep_StencilOp == fFrontPassOp &amp;&amp; kKeep_StencilOp == fBackPassOp &amp;&amp; kKeep_StencilOp == fFrontFailOp &amp;&amp; kKeep_StencilOp == fFrontFailOp &amp;&amp; kAlways_StencilFunc == fFrontFunc &amp;&amp; kAlways_StencilFunc == fBackFunc; } ----- V501 There are identical sub-expressions 'x &gt;= 0' to the left and to the right of the '&amp;&amp;' operator. webcore_platform feconvolvematrix.cpp 289 ALWAYS_INLINE int FEConvolveMatrix::getPixelValue(PaintingData&amp; paintingData, int x, int y) { if (x &gt;= 0 &amp;&amp; x &lt; paintingData.width &amp;&amp; x &gt;= 0 &amp;&amp; y &lt; paintingData.height) return (y * paintingData.width + x) &lt;&lt; 2; ... } ----- V501 There are identical sub-expressions '(bStart &gt;= aStart &amp;&amp; bStart &lt;= aEnd)' to the left and to the right of the '||' operator. webcore_remaining spatialnavigation.cpp 236 // This method checks if |start| and |dest| have a partial intersection, either // horizontally or vertically. // * a = Current focused node's rect. // * b = Focus candidate node's rect. static bool areRectsPartiallyAligned(FocusDirection direction, const IntRect&amp; a, const IntRect&amp; b) { int aStart = start(direction, a); int bStart = start(direction, b); int bMiddle = middle(direction, b); int aEnd = end(direction, a); int bEnd = end(direction, b); // Picture of the partially aligned logic: // // Horizontal Vertical // ******************************** // * _ * _ _ _ * // * |_| * |_|_|_| * // * |_|.... _ * . . * // * |_| |_| * . . * // * |_|....|_| * ._._ _ * // * |_| * |_|_|_| * // * |_| * * // * * * // ******************************** // // ... and variants of the above cases. return ((bStart &gt;= aStart &amp;&amp; bStart &lt;= aEnd) || (bStart &gt;= aStart &amp;&amp; bStart &lt;= aEnd) || (bEnd &gt;= aStart &amp;&amp; bEnd &lt;= aEnd) || (bMiddle &gt;= aStart &amp;&amp; bMiddle &lt;= aEnd) || (bEnd &gt;= aStart &amp;&amp; bEnd &lt;= aEnd)); } ----- V501 There are identical sub-expressions 'cy ().isRelative ()' to the left and to the right of the '||' operator. webcore_svg svgradialgradientelement.cpp 253 bool SVGRadialGradientElement::selfHasRelativeLengths() const { return cy().isRelative() || cy().isRelative() || r().isRelative() || fx().isRelative() || fy().isRelative(); } 
&gt; I am also researching using lambda in signal/slots connections, but that would be for Qt5. It's the middle of 2011, and I can't still write a lambda function as a callback to a GUI object in a mainstream native programming language. If that isn't a shame for the developer community, I don't know what it is. 
Thread with comments: http://www.reddit.com/r/programming/comments/hkm59/c0x_in_qt/
[same but different](http://channel9.msdn.com/Events/PDC/PDC10/FT13)
&gt;That makes RAII and exception safety impossible! Which is probably why they forbid exceptions ...
4 months isn't really what I'd call advanced. 4 years maybe. But give it a shot. What's the worst that could happen? You look like an idiot and never hear from them again. It's not the end of the world.
Much is lost and nothing is gained by forbidding exceptions. Its much like turning the warnings off on your compiler and thinking you have solved something. Forbidding exceptions just means you are stuck with the worst of error handling schemes. Manual checking of return values (bugs when user forgets to check for error), and it also means sprinkling user code with manual teardown and cleanup code (copy pasta bugs). 
Yeah, unfortunately this 'exceptions are slow' thing still appears to scare lots of people. This is not the case here (for google) but their rationale is, to my mind, even worse. 
We don't need another EC++. &gt; *To the best of my knowledge EC++ is dead (2004), and if it isn't it ought to be.* [/Stroustrup](http://en.wikipedia.org/wiki/Embedded_C%2B%2B)
That was pretty useless. Also: &gt;cout &lt;&lt; results / (n / static_cast&lt;double&gt;(10)); Would anyone really write something like this instead of cout &lt;&lt; results / (n / 10.0);
Embedded C++ was crap because it was designed to make compilers easy to write, not to help the programmer... if you dont believe me, then explain how removing namespaces and the mutable keyword helps the programmer? These are features that have exactly zero size or speed penalties. Creating another EC++ is not helpful.
I agree that we don't need another EC++ ! However, many people would like an easier to use C++ with faster compilation, better intellisense and less complexity. EC++ would enable this. New programming languages like D and Go are interesting, but not quite ready for primetime. Scripting languages like Python are too high-level for many tasks. Everybody customize C++ to fit their needs (and to reduce complexity) - here are Google's guidelines as an example: - http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml It would be very interesting to see what Microsoft use for Windows and Office development (or Adobe) - pure C, or C++ with *some* features like Google ? What are *their* good parts ?
Yeah, I am all for a new cpp-style programming language. However, it has got to have a mechanism like templates, if the goal is performance. There is no point in a value-based language without static code reuse. 
easy one bool * const somearg that won't allow for this type of bug. Use const lots, even work your design around constness. It helps tons with bugs and frankly IMHO helps with readability and utility.
Link seems broken.
They deleted it because it wasn't a question (just a list of links). I reproduced the list [here](http://www.reddit.com/r/programming/comments/hnklo/videos_and_podcasts_by_c_celebrities_stack/c1x0ifg)
Ugh ... std::vector&lt;&gt;::reserve? Also, i like how 'Future ideas' sketch out implementation of std::deque. RTFM god damn it.
I think reallocate did not make it into C++ because its behavior is not deterministic.. you may get a realloc or you may get an alloc. Seems like a bugtrap to me as you would be tempted to use pointers into the collections and continue using them even after you insert new elements.. which would work most of the time until the day the fat man boards the airplane and causes a alloc instead of a realloc and the airplane falls out of the sky. Programs are hard enough to reason about without needless non-determinism. Better just take control of memory management in a deterministic way by using std::vector::reserve, inplace new, std::move, etc
Once memory becomes fragmented realloc() will do a copy anyway. Obviously the guy has put a bit of work into this but is it really worth the trouble?
realloc can not be used with C++ objects. The purpose of this work is to provide a realloc that works with idiomatic C++, so absolutely yes it is worth the trouble.
&gt;Seems like a bugtrap to me as you would be tempted to use pointers into the collections and continue using them even after you insert new elements.. This isn't possible to begin with. Pointers into a vector are invalidated when you add or remove from it, so having a realloc won't change this.
Right, this isn't an argument for realloc, it's an argument against using vector like that.
Is that true even when you've reserved or resized prior? I know I've written code that depends on this in pet projects, and it worked fine. Is it more a case of "don't depend on this, but it should work most of the time"?
Terrible article. The author didn't even bother to measure. 
Most of the cost isn't copying memory around, it's invoking copy constrictors and destructors. The C++11 spec takes care of that with move semantics and r-value references. So the penalty for a vector grow from push_back past capacity wont be quite as bad anymore.
Using a compiler's ability to construct in place (declare return value as first statement in function, have single return at function bottom) seems to also take care of most of these penalties. As does liberal use of const.
Yes, thats the point. Collections using realloc would invalidate iterators rarely and nondeterministically when memory is fragmented, instead of often and deterministically like now when size goes over capacity. It would be a bugtrap.
If its not in the standard it should practically always work. There was a time though when popular std::string implementations where copy-on-write, and the standard was written loosely enough to allow for this. Maybe std::vector was was written loosely enough to allow for it as well. If std::vector was to be implemented as copy-on-write then iterators could be invalidated after a push_back even if there was still capacity left.
Read the comments om the blog. He answers your points there.
&gt;provide a realloc that works with idiomatic C++ What are his objectives in providing a realloc that works with OO C++ memory management? Does he want the speed or does he want the memory efficiency? Both of those advantages can easily be lost when memory becomes fragmented. I seem to remember reading (I could be wrong) somewhere like D&amp;E that a deliberate decision was made not to include a realloc()-like form of memory management for the OO C++ memory management. If you are doing embedded work (as mentioned in the article) there are so many other things that suck down memory in C++ (such as exception handling) if you have to worry about reallocs() then you probably should be using C.
Optimizing away the copying of return values doesn't fix the case where you have an std::vector of some type that has nontrivial constructors and destructors and copy constructors, and you keep pushing back and eventually the size needs to grow past the capacity. In that case, the older C++ vector implementation is forced to copy construct to the newly allocated buffer, then call destructors on the old one. Move semantics let each object just relocate itself.
The author should have clearly stated the problem that he wanted to solve. The lack of `realloc()` is not a problem by itself. In the section titled **Comparing std::vector To realloc()** the author describes several problems with `std::vector`. 1. `vector` growth requires excess memory. When a `vector` grows, it first allocates new memory, typically 150-200% of its old size, so it temporarily requires memory totaling 250-300% of its old size. * Corollary: `vector` works with contiguous chunks of memory. 2. `vector` growth performs data copies, which requires reading and writing all elements. 3. `vector` growth invalidates pointers (and also `iterator`s). 4. `vector` growth may contribute to memory fragmentation (and may be unable to expand when memory is fragmented). (The author also mixes examples freely in this section. In one example, he talks about an embedded system with 4MB, in another a system with virtual memory and a `vector` in the with 100s of MB. There is no reason to believe that a single solution should be appropriate for both.) I don't see how `realloc()` materially improves these factors. If you implement a `vector`-like container with `realloc()` it *may* (nondeterministically) avoid these downsides in some cases but you'll eventually encounter every single one of them -- whenever `realloc()` cannot expand in place, it still must allocate a new contiguous buffer and copy all the data. It's even possible that most of the improvement from `realloc()` would occur at the wrong end of the size scale -- it seems more likely that you could expand-in-place from 1k to 2k then from 100M to 200M.
You're in the clear. Quoting from the 2003 standard, **`23.2.4.2 [lib.vector.capacity], para 5`** &gt; Notes: Reallocation invalidates all the references, pointers, and iterators referring to the elements in the sequence. *It is guaranteed that no reallocation takes place during insertions that happen after a call to reserve() until the time when an insertion would make the size of the vector greater than the size specified in the most recent call to reserve().*
Actually he does not. He just argues that these are not the same as realloc, which is truism. Also, 300% memory size against vector is retarded. realloc _will_ fail, and what happens then? You just end up with exact the same thing but overly complicated for no reason. That guy is solving the wrong problem, most probably. That or just wrote this for fun (which isnt a bad thing mind you).
Why is it better then boost?
boost is not standard compliant, is not evolving fast enough, lack of features, among many other reasons. just::thread author is the same guy who wrote boost::thread, and I have used the former. It is pretty standard compliant and has good support. 
&gt;boost is not standard compliant What do you mean?
I hate this idiom with passion.
I means it tries to be compatible with std::thread requirement but it is not. For example, it doesnt have std::asyn. In other word, it is not tracking c++0x standard very closely. 
Of course its not, C++0x isn't even technically out, and practically you would want to wait a bit for compilers to stabilize. I'm pretty sure boost will follow C++0x path pretty quickly, but there really is no point in racing to use new cool features that wont work everywhere just for the sake of it.
most of the std::thread implementation does not depends on c++0x language features and can be implemented with c++98 + compiler extensions. And your second claim is not valid, since boost.thread hasn't been updated since 1.40. Most of all, this library is not intended for end user but for compiler vendors. 
If you want a "cheaper" solution (cheaper than 60 pounds I mean), you can simply install a Linux in a virtual machine and play with the new C++0x syntax. I would recommend reading the book from the above website.
I don't understand the do-while macro that only loops once, what is the point? (I'm not in any way an advanced C programmer....)
While there might be special reasons to do everything by hand, I usually prefer installing MacPorts and then doing a "port install gcc46"... 
This is an interesting exercise and all that, but in production code I can't see any scenario where such low-level hackery could be deemed preferable to just using std::deque (+ as pointed out by one of the article commenters). 
Very true. This could be improved further if there was some sort of interface to the underlying memory allocator which gives `std::vector` access to the actually allocated chunk size, or tell it when the chunk can be enlarged in place. The standard `malloc`/`realloc`/`free` API is a bit of a poor match here.
Such a thing is indeed possible, especially if your application manages its own virtual memory allocations (&lt;http://msdn.microsoft.com/en-us/library/aa366887(v=vs.85).aspx&gt;), or equivalents on other platforms. The performance savings might not be worth it. In truly performance-sensitive situations, it's better to write everything so you can allocate up-front. In performance-insensitive situations, an extra alloc-and-copy isn't the end of the world. std::vector lets you pass in an allocator type, but I'm not sure if the stl's allocator interface supports realloc requests, or if clever users would have to write their own vector implementation to use that. There's really no replacement for knowing how much memory you need from the start, tho :) 
Just curious here.... Why do it at all after you install Xcode? Advantages?
Xcode 4 (the last release from Apple) is based on gcc 4.2. Compiling gcc-4.6 allows you to test some of the syntax of C++0x. Currently gcc is the most complete C++0x compiler. I have to note that clang++ which is included in Xcode also implements some of the C++0x syntax, but it does not look as complete as gcc-4.6. 
Thank you. 
tl;dr - type-safety w/o gc by giving up something else; e.g. sharing pointers. At the end, the author has limited pointers to something similar to `std::unique_ptr`. You can't have globals, `delete` maps to `.reset()`, and you statically verify no null-dereference operations occur. 
Other discussions of this paper: http://news.ycombinator.com/item?id=2615096 http://www.reddit.com/r/programming/comments/hqkwk/google_paper_comparing_performance_of_c_java/
&gt; just::thread author is the same guy who wrote boost::thread Re-wrote it. The original author of Boost thread library is Bill Kempf.
I found general findings of the report pretty 'meh'. What strikes me though is: there is a language out there that compiles slower then C++. WTF? Also, why would they include debug build of C++ version is beyond me. 
I found it surprising that the author needed the help of colleagues to come up with trivial optimizations such as using hashmap instead of map, or empty() instead of size() for lists. &amp;#3232;\_&amp;#3232; 
What strikes me most is how big Go builds are, more than twice as big as a debug C++ build. Measuring the debug build of C++ is useful because they consider compile time. During development you usually compile in debug mode, so you want to know how fast that is.
&gt;What strikes me most is how big Go builds are, more than twice as big as a debug C++ build. They probably linked go runtime statically. 
What about defining self recursive or mutually recursive functions? Would be nice to see that aspect compared as well. (I know it's a royal pain in C++, but how about Obj-C?) 
Recursive anonymous functions are a pain in the ass in ObjC as well. One technique is to declare a __block variable to hold the block, and then capture that variable in the block as well, like: __block void (^recurse)(void); recurse = ^{ /* blah blah blah */ recurse(); }; This can cause difficulties with memory management, though. Another way, which I think is slightly nicer, is to create a helper function which passes the block to itself as an extra parameter. Still not great, though.
&gt; create a helper function which passes the block to itself as an extra parameter Ah, the pleasure of fixed point combinators. 
Indeed. Actually, it seems like you should be able to do the same thing in C++ as well.
[You can](http://stackoverflow.com/questions/152084/fixed-point-combinators-in-c).
Its pretty strange that you cant do self recursion with C++ lambdas easily. After all these are supposed to be sugar over function objects, so technically 'operator()();' would kinda work. Then again, perhaps the usecase wasn't deemed common enough to allow this or introduce special syntax.