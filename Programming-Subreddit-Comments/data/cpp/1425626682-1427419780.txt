The people who hate C++ are wrong (the most insidious kind, with a grain of truth inside). I wasted a year and a half of my life learning C before C++, all because I believed Eric S. Raymond when he said C++ was too complicated. C++ is far from a perfect language, but it has unsurpassed strength in many areas. I'm glad I learned it, and it's set the course of my whole life.
&gt; and it's set the course of my whole life. :(
Because of how close to assembly C and C++ tend to be, they allow for very unsafe things. They are not bad inherently, but they tend to get blasted every time an exploit pops up that involves a simple buffer overflow or other undefined behavior because that is their nature (to pretty much try to do exactly what you tell it to). That said, most other languages' interpreters and compilers were written in C or C++ (some have gotten to the point where they can be bootstrapped, or compiled with a compiler written in its own language), including languages that feature protections against such common C/C++ bugs. They're pretty much the baseline for everything on modern computers, even if you don't see it with much higher-level languages like python or javascript.
Advocating the use of C where C++ can be used because "C++ is too complicated" is like saying you should walk to work instead of using your car, because using a car is more complicated. Now, when I meet these C people, I just speed right past them in my Lamborghini.
It's got a steep learning curve and gives you a power saw instead of safety scissors like some other languages. If you work with it enough, you learn its quirks and avoid weird situations just like with any other language. It's just that when you mess up, you *can* mess up spectacularly, and that turns a lot of people away. As for structure, the simple solution is to not write a program with poor structure. It's not a language-specific thing.
This isn't exactly an unbiased place to look for responses from :P
&gt; Have I done a huge mistake picking up c++ and continuing with it for almost 4 years? No. Apart from Java, it's the only truly cross-platform language viable for large projects. I find C too "manual"; I'm fed up of having to jump through hoops to get things like ~~generics~~ templates or ~~modules~~ classes. C++'s most huge problem is that it's not the latest hype. 
I've been going through some C++ books and they called C++ high level. Then what the fuck are Python and Javascript?
The upper management
I read something recently about the many pitfalls of using `char data[sizeof(T)];` as storage for T, but I can't seem to find it. What I can remember clearly is that it's... very bad. Would be nice if someone could find it.
ESR can really be a douche sometimes.
I just realized, doesn't static linking and including the DLLs in the application's folder make the DLLs reside in a different virtual memory space, causing cache misses? If that's the case, I suppose it makes sense for every application to point to the same file so that the OS doesn't have to keep multiple copies of the same files as well as clutter the CPU cache with the same data.
I don't see how that makes him a douche. He just has a different opinion on the two languages. An subjectively shitty opinion, yes, but that doesn't make him a douche. 
This is a historical view - the abstractions in C _are_ on a higher level than assembly. When people called C a "high level" language, they said that because it was the highest level yet attained. Then languages like C++ came along and "high level" came to mean languages with those new abstractions, like object orientation and the heap. More modern languages like C# and Python do all the memory management for you. These days, these are the high level languages, so everything else has slid down further, pushing C++ down to mid-level and C closer to the low-level with assembly. People can argue about what level C is, or whether C++ is mid or high level, but these disagreements are just semantics. 
I use C++ often as my preferred language. For personal projects I've mainly use it to add functionality to other programs that aren't open source. Code injection and API hooking is incredibly useful. For most projects you will want to use another language. The time cost of developing small apps in C++ is by far longer. However I will still write them in C++ because I don't feel limited by anything. It's just my code running natively. I feel "free" in a sense. But my point of view really is a terrible one for any serious programmer. Don't fall in love with a single language. Learn as many as you can. Use them like you'd use a specific tool to get a job done. 
It depends: what are your everyday tasks?! I honestly don't think that coding/scripting is needed for "everyday tasks". A spreadsheet and a terminal should be enough... But I'd say, life of a coder goes like this: * android? use java. * iOS/apple? my religion forbids me to answer this one. * desktop application, databases and stuff? use C# * games? use C++ * physics, simulations, scientific calculus, trading (ie "anything that requires performance")? C++ * anything else: doesn't matter, use your default language. (that means C++, right?) I learnt c++ a long ago. Back then there were basically two roads when you wanted to write an (any type) application: visual basic, or the real thing: c++. Today, I feel the same: you either use those toy languages or create the real, proper, fast thing. inspiration video: http://channel9.msdn.com/Events/GoingNative/2013/My-Favorite-Cpp-10-Liner from 8:30 suggestion: try to play a little bit with sfml (any other gfx lib will do) and create little games. I had tons of fun doing that
It's like the C++ garbage collector does nothing...
I'd say C++ most huge problems are toolchains from the stone age: * Java used Ant then it moved to Maven and Gradle. What do they do besides building targets and generating Eclipse and IntelliJ projects? They fetch dependencies: libraries, IDE plugins, sometimes even specific compiler for another JVM language. What C++ has? Well, it depends on the platform - on Windows you're fucked because Chocolatey is not used by everyone, besides it got its issues, on Linux every distro has different package management system and the same dependency might have 10 different names depending on repository, can't say anything about OS X and BSD but AFAIK neither of them uses something that can share config with either Windows or Linux, * debugging - from what I heard it got better lately, but still with inlining and optimizations on I cannot use much of conditional breakpoints and expressions (aka Immediate Window in VS) - simply because functions and variables I want to call are either inlined/optimized out and debugger cannot find them or they all are assumed to have side effects (even fucking non-copy-constructing getters...). Once I learnt in Java that modifying code by adding `if (condition) System.out.print("anus");` just to have a place to put a breakpoint on is what peasants not knowing conditional breakpoints do, it was hard to find out that in C++ it is often encouraged style of debugging... * build times and testing - change 1 line. Start build. 10000 target to rebuild. I'll learn what I didn't consider in a 20 minutes. Wait 20 minutes. So... what was I doing before I started build? Same for building tests so no one that I know in the company writes with TDD, * while IDEs got better I still feel that I'm less productive developing C++ project with Visual Studio than developing Java project with Eclipse. When I just began Java. Kind of understand why some people would use Vim to develop C++ project - whole IDE often freezes when during 1500 headers reparsing, intellisense is not that helpful, searching is usually just slightly improved grep. My whole C++ experience is that's pretty decent language with nightmare of a toolchain.
STL, you're a pretty cool guy. Keep on keeping on. Really appreciate the work you do.
There are some excellent tools and then there are no tools at all; depending on the platform. VS versions after 2010 are relatively decent to develop C++; but I will switch to clang-cl in a heartbeat if it is finished. Valgrind solves most of the leak issues one might have (but not on Windows..) and recently there is ubsan, asan and tsan in GCC/Clang. Clang's compiler diagnostics and standard compliance is top notch. Performance measure tools on *nix are pretty decent.
Wait, you've been picking up C++ for 4 years and you're wondering if there are any successful projects backed by C++ or whether it's useful? Shouldn't you be able to decide this for yourself by now?
C++ is complicated, but it's by no means unmanagable. Especially everyday use of modern C++ is not that much more complicated than C. The C++ critics are generally wrong. They tend to often be C programmers who either argues C++ is bad because they don't understand it themselves, or argues C++ is bad, but their argument is flawed because they're misinformed.
Are there any large Projects in C++? There is plenty. What kind of stuff are you looking for? Microsoft reportedly writes 90% of their code in C++. That includes the dominant office suite, large parts of the dominant desktop OS and all the other stuff coming out of Redmont (such as Internet Explorer, hate it or love it, it's still the most widely spread browser out there). Epic Games' Unreal Engine (the latest iteration of which just went open source) is also purely C++ and a damn good example of excellent design. So yeah, the (arguably) most wide spread game engine is C++. Ever heard of a browser called Firefox? Also C++. There is many more. Go to source forge and filter the project list by programing language for a starting point. 
C is more like a motorcycle -- stripped down, no safety features, but fast, nimble, and responds to your touch. In all other ways, your analogy is more apt than you know; you just forgot to consider that the city you work in might be full of narrow, cramped streets, criss-crossing back alleys, and lots of traffic, all of which your car can't navigate around. A car has a lot of material conveniences over a motorbike, but there are situations where you need something *smaller* than a car. And bikers tend to like to bash cars for not having the lightness, portability, and maneuverability that bikes have, while drivers tend to like to bash bikes for needlessly eschewing safety and sophistication on modern highways that will comfortably accommodate even the most unwieldy of vehicles. Both sides are correct, in their way.
Low level code (machine code) is programmed against a target piece of hardware; you, the programmer, have to be aware of all of the quirks, all of the conventions, and how everything is done at the most basic level, because you are literally penning the instructions in the processor's own native tongue. Mid level code (assembly) is written against an abstract virtual machine; you don't need to know every opcode, or how arguments are passed, or even what instructions are actually implemented. The assembler makes a pass through before you deploy and decodes all of your abstract operations into instructions for the specific target you want. High level code (C et al.) adds to the nonspecific target a compiler with the ability to rearrange abstract mathematical concepts in code -- the sort of patterns humans are good at seeing and solving -- into a set of instructions in assembly. Such abstractions include object classes, data structures, arrays, functions, loops, stacks, queues, pipes, threads, lists, pointers, datatypes, and every other convenience that modern programmers can't live without that doesn't actually exist in code. I've seen other descriptions and definitions, but what you described is the set of definitions I personally subscribe to. I have also seen schemes that broke languages down into a number of tiers or generations based on which specific abstractions they offered. Man, we humans love to categorize things.
ESR is, in fact, right. As someone who's been deep in the C++ trenches since the late 20th century, I should say that he is in fact *damn* right. Language complexity shapes the design of your solutions. It's almost universal. 
Your build takes 20 seconds?! What are you doing, trying to solve the travelling salesman problem with template meta programming? I'm running a centrino cpu and my builds barely scratch a couple of seconds.
Scott Meyers - Why C++ Sails When the Vasa Sank http://youtu.be/ltCgzYcpFUI
I always have to point out that what most people refer to as "Modern C++" is more or less "C++ from the last millennium".
Most people who claim that language X is the best just do not know other languages (well). If you have been programming for years in one language of course it feels good as it is your comfort zone and you just do not recognize, how complicated some stuff might be as you do not know alternatives. When I was younger I bashed Java all the time and claimed C++ was just much faster, better and so on. Meanwhile I am older but also wiser ;-) Even if I still do not like Java that much, the JVM ecosystem is such a good thing and enables languages like Scala and Clojure. I must admit that I **dislike** C++ overall nowadays - yes also modern C++ (&gt;= C++11 )! But I would not offend other people using it. But mentally I am often amused about the boileplate and complexity of C++ solutions where I could do that in other languages so much easier... I think you should strive for really learning different languages, especially with **different** paradigms. Then you can judge the overall quality of a language (including tooling and infrastucture) much better. And you get the feeling which language brings you more joy and fun programming with. When I discovered Python in the early 2000 years after C++ and a bit of Java (1.3! *urgs*) I was so impressed about the ease of just writing working software! As I still love Python for its clear and predictable semantics, but I discovered other languages then like C# (which I like much more than Java), Scala and as "newest" one Clojure. And with all those knowledge gained I do not believe that one day I will like C++ again... ;-) But of course the personal "taste" remains and there is no absoulte truth :-)
Do you want irony? Guess which language they are using in C runtime.
No, but [being a homophobic HIV-denier among other ridiculous positions](http://rationalwiki.org/wiki/Eric_S._Raymond) does. RationalWiki is obviously biased, but they link to ESR's controversial blog posts. You be the judge.
"High level" and "low level" are relative terms, not absolute ones. They change over time. For that matter, there's far more than one dimension in the concept of language complexity. Is Haskell higher-level than Ruby? How would you rank Prolog and Python? Prolog is declarative, which seems super-high level. But to do anything substantial in Prolog, you probably need to intimately understand the execution model of the WAM, red cuts and green cuts, etc. This is akin to having to write Java code with explicit L1 cache management stuff mixed in with your code, and that's not high-level at all. For the purpose of a textbook, it's quite common that you have "high level language" as a term for anything that doesn't require you to write loops with gotos. Don't sweat the definition too much when comparing reasonably modern languages.
Sorry for answering a bit late.. here is my example: I had two classes: template&lt;int a&gt; class X; and template&lt;int b, int c, int d&gt; class Y; Both had the []-operator implemented, which worked in a different way. Also the code was performance-critical. I also needed the operator +, so I needed X+X X+Y Y+X Y+Y With regular inheritance I could have just created a common superclass and declared the []-operator virtual, but that would have had an impact on the runtime performance (virtual table lookups and preventing some optimizations). Is there any way I was missing, that would have allowed me to declare the +-operator just once? I also needed the other mathematical operators. I ended up letting a student implement all these operators and allowed him to #include the function bodies. Doesn't feel right though... Edit: formatting
C++ is too complicated for simple minds. When listening to these negative comments you need to consider the sources. 
The project I'm working on currently is millions of lines of code. It takes over 40 minutes to do a clean build, and with full program optimisation on (which it is), add another 10-20 just to link the damn thing
I've had interviews where they would perform a "coding task" with me. This involved some C-style raw memory butchering with new and delete. Of course there were some nasty bugs (on purpose) in there. After I found them, they asked me how to fix the issues. I replied with "use value semantics", you shouldn't use new and delete in modern C++. They looked at me confused and said that they are using raw memory here. Yeah, right, "professional" software developers with 20 years of experience. Sure. I bet they've never heard of RAII as well. If you use C++ like C you're gonna have a bad time shooting yourself in the foot.
Just to boost your confidece with C++. [link](http://www.go-hero.net/jam/14/languages) These are statistics from Google CodeJam 2014. It's annual Google programming problem solving competition for everyone. In last round (with only the best left) C++ is most widely used language. I know competitive programming is not like the programming in production, but hey, if C++ was that bad, it wouldn't have been by about 80% of best competitors in the world.
As for destructors, gcc offers a non-standard CLEANUP keyword which is basically a hidden action on scope leave - exactly like a destructor. Of course, if you use it, you're better off programming in C++ anyway. 
My friend works in a company where some neckbeards are agains extracting code into functions in anonymous namespaces... because they don't believe compiler would inline them and code on embedded devices has to be very fast. Even presented with assembly for each used compiler on each supported platform is not convincing for them. Basically C-style C++ with serious penalties if you'd try to put something modern there. Unfortunately management is on their side. Since they worked here so long they have to be the experts and not some young hipster brats...
Me too - android + ios + windows phone: use C++, so you only have to code most of the stuff once Now if only Google could show a bit more of NDK love...
I'm not sure, but think there is much a stronger influence from Simula than from Smalltalk. Simula introduced virtual functions, classes, in much the same model as C++ has them. Smalltalk is a much more dynamic beast.
&gt; because it was the highest level yet attained Absolutely not. C was a relative late-comer. By the time it was created, much, *much* higher-level languages already existed. C is and always has been called “high-level” only in relation to assembly, not in relation to other languages.
It took you a year and a half to learn C? It's a tiny language.
And god forbid you have to work in a team -- the chances that everyone on it will write good, clean, idiomatic code? Often close to 0%.
Their names do sound kind of similar. Probably I had read about Simula then. I remember that the OOP features in C++ were inspired by some earlier language. **Edit:** Found that in Wikipedia &gt; The creator of C++, Bjarne Stroustrup, has acknowledged that Simula 67 was the greatest influence on him to develop C++, to bring the kind of productivity enhancements offered by Simula to the raw computational speed offered by lower level languages like BCPL
&gt; That being said; non-optimally written C++ code can still be faster than code written in another language. http://benchmarksgame.alioth.debian.org/u64q/cpp.html http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=gpp&amp;lang2=rust http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=gpp&amp;lang2=ifc http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=gpp&amp;lang2=gnat C++ loses in at least some (and in most cases half) of the benchmarks against those respective languages. The idea that C++ should be selected on a pure performance basis is a myth.
C++11/14/17 have been hyped as hard as any compiler development in the past few years. And there are dozens of viable languages being used in production on large projects that are not Java or C++. 
The take away here is - use the right tool for the job. You can pretty much write any program in any language. It doesn't mean you should. C++ isn't always appropriate. 
My experience with such people is limited (which is good I guess) and with pointers is quiet good. I stumble into errors once in a while but they're mostly related to referencing and de-referencing issues , rather than dead pointer ones. Probably because I pay much attention to scope based code and comment a LOT. You might even see a todo list inside my blocks of code haha 
&gt;Today I worked from home, wearing my pajamas all day. That's why we haven't got new videos for a while? We will forgive you if record them in your pajamas.... 
&gt;Is C++ really that bad? No. 
The people who talk trash on c++ typically have some agenda they are trying to push. They feel that by putting down c++ it makes their alternative look better. Some people treat languages like religion and take their choices way too seriously.
C++, much like C, is meant for expert programmers. The problem is, and my self included, most people simply are not truly expert programmers. Without really good programmers, C++ code can get in a big mess in a big hurry. It is not an easy language. It is easy to blow your foot off in it. It is easy to have poor design in it. Does this make it a poor language? No. C++ is a great language that has many pros compared to other languages when used for it's intended purpose. C++ was my first language. I am an applications deverloper. I spent the first 10 years of my career writing C++ and am very happy about that because C++ taught me so much that I just would not have learn from a language like C# or Java. After learning C++, the learning curve for all other languages are nil. Be proud that you are a talented enough programmer to be able to stick with C++ and not give up. Many young programmers will come to the conclusion that it is too hard and they will give up and move to an easier to learn language that holds their hand (C++ will not hold your hand). You will, and I am sure you have already, learn a lot from C++ that will make you an above average developer.
"more so than many other viable alternatives" I wish there were viable alternatives. Sadly, there seems to be a lack of languages targetting the same space. D and Rust look promising, but D's GC puts me off, and Rust is just not ready yet IMHO. (I know D can be used without a GC, but unless intimately familiar with the language and, particularly, knowing which library abstractions requires GC, that doesn't cut it for me).
Psssst.... auto_ptr is deprecated.... 
*Never* use `std::auto_ptr`. Use `std::unique_ptr` if it is available to you. If not, use something else.
Those opinions are just full of rubbish. C++ is an incredible language for a variety of reasons as listed by others here and more from a simple Google search. I've been doing C++ for nearly 6 years (3 in University) and I can't imagine going to another language and somehow getting a better life with it. I'm in a career I really enjoy, I get paid well, and I know it won't end any time soon. I've seen a lot of hate articles myself on the net and to be honest I found almost all of them had no substance, poor knowledge of the subject or some hidden agenda. EG: "C++ is dead, Haskell is the new way forward for the best tech etc..." *Written by a manager in a finance firm 
I use C++ all the time, you need the right language for the job. Some stuff only requires scripting, others like C# then for speed or pointers use C++
C++11 is much better. C++ and C are very fast. Any library you want it out there. Destructors and basic type templates are vital. But... Go on irc and you will realize people don't know C or C++. They don't understand the core concepts of how memory is handled. Programming in C++ while not understanding it is no way to go through life.
This, most of the negative comments are from people who aren't real programmers. A programmer should know the tool for the job and not get sunk into "bad or not bad". Programming is knowledge to pick up any language and go, not to say Python is the best, C++ is the worst. Take out Python and C++ as tools and what you have left is "is the best, and is the worst" which doesn't make sense. 
All libraries are still not out there. You will easily find a library for quickly creating sockets and tcp stuff , but that is rather unpractical when compared to a cpp web/http framework , which is not yet available.
I thought the difference between assembly and a compiled language is that assembly exposes architecture-specific stuff, which would make it architecture-dependent. Otherwise you can just call it a compiled language - after all what is the difference, you have a text file as input and binary as an output.
Backwards compatibility 
Modernize or death! :-D (Hey, at least it isn't VS6)
I said in my workplace. As in: I don't get to decide this.
Doesn't unique_ptr only allow for one thing to use the pointer? I would think that shared_ptr is preferred. I'm legitimately asking, I use raw pointers everywhere because I don't know better.
There is no difference! The distinction is arbitrary! The only difference between assembly languages and high-level languages is the form of abstraction; assembly languages are at most a step or two up from machine code in the sense that they use abstract instructions, are human-readable (this is the critical one), and in some cases offer limited portability. Some assembly languages are only a half-step up, mapping a specific processor's specific instructions on a one-for-one basis to a set of words ("add", "shift", etc.), while others are designed to be assembled for a variety of architectures and processors and offer a rich set of instructions and pseudo-instructions. YASM Assembly includes a macro feature that allows you to write structured code in a similar style to a procedural language. At the end of the day, everything is just a step in the toolchain from high-level code to low-level code; assemblers, compilers, and interpreters are all no different. Heck, code goes lower still: even machine code isn't executed directly; most complex instructions aren't implemented in hardware but in microcode. Your processor has its own firmware, and it is running an interpreter on your assembled binary!
Could you share how (i.e. tools, libraries etc.) you generate your website?
I read once that "if you write delete you almost have a memory leak somewhere"
Convince the people who run your workplace to avoid `auto_ptr` like the plague.
http://californiatokorea.com/wp-content/uploads/2014/09/aragorn.jpg
You really wanna go ahead and call Linus' comment had "no substance &amp; poor knowledge"?
&gt; http://llvm.org/ Which in turn enables other languages to compete with C++ :)
I wonder if you could design the code so that even 'new' need not be used explicitly.
Yes, it tells you how to do alignment properly, but it doesn't tell you the many things that can go wrong if you don't use it.
I'm OK with this. :) Honestly, C++ needs a reboot. I want it to remain a low level language with useful higher level constructs, but it needs to drop all of its legacy nonsense: excess reliance on pre-processor, text insertion (#include), noisy grammar (dot versus arrow versus double colon), etc. As for other languages, I welcome our LLVM overlords. Too few languages currently compile to native code. It's all about VMs and bytecodes. T_T
I think gcc is still competitive with clang for C++, if not in the lead. My point wasn't that C++ is slow or anything -- it was that it simply can't claim to be the only fast language at this point in time, and thus has to stand on it's own merits. That language has spent far too long depending on compilers that generate "faster" code to keep them in favor. It's really heading for a sink or swim situation for them over the next few years given new languages like Rust, D and Nim. I've mixed feelings towards Go as I don't think it performs as well as it should given its nature.
It's not true. Modern developers are scared of the responsibility that is required as a programmer when you use c++ and c including memory and other non trivial resources. For the benefits that c++ provides including performance, OOP and some functional idioms and its x-platform potential it is usually the right choice. For developers and companies, they like to take the easy approach (c#, java, etc) instead of the right approach.
Not a whole lot, since this was over the summer and the start of college, and I was completely self-taught. Figuring out separate compilation was the hardest part. I didn't have trouble with the concept of pointers, although actually managing memory proved to be too difficult as a novice.
Thanks!
It's actually because I've been working on features and fixes for 2015. My next VCBlog post will be quite lengthy, even though I already wrote up [all the stuff](http://blogs.msdn.com/b/vcblog/archive/2014/06/06/c-14-stl-features-fixes-and-breaking-changes-in-visual-studio-14-ctp1.aspx) we did between 2013 and 2015 CTP1.
Containers, make_shared, and make_unique make this possible.
Yes, that's a concern. (I forget whether the OS detects DLLs that are physically separate but binary-identical.)
2015 RTM will support targeting XP (which causes me tons of headaches as a library developer).
For refactoring not a bad idea in general if you inherited the OPs codebase. I introduced RAII to my co-workers at a previous workplace. They were shocked that I used new/delete and then tried to rid myself of them in the examples. One of them asked why I didn't fix it by using malloc and free instead... It was a long presentation after that.
It's a few source files, a Makefile, and one text file per page. I use the program to generate repetitive/obnoxious things, like headers/footers and especially tables. For example, my [MinGW distro page](http://nuwen.net/mingw.html) (the only actively maintained one) lists its components in a table. But HTML insists on writing tables left-to-right, whereas I *really* want to list them top-to-bottom (so I can add/remove components in sorted order). So my C++ program allows me to generate that table. It also used to take care of the fancy multicoloring, before CSS3 gained that ability. Another part of the program handles determining the file sizes of linked files, so I don't have to calculate them separately. The most recent part determines the dimensions of PNGs and JPEGs (using libpng and libjpeg-turbo), so I can encode their widths and heights in the HTML. I haven't made my source public, unfortunately. Perhaps someday.
You're welcome! We'll be publishing updated Core/Library feature tables as we get closer to RTM.
That hellish problem is everywhere. We had a sales rep from a commercial embedded compiler vendor come to us with the latest and greatest of their (hellishly expensive) package. He was there to present their C++ and it looked like it would produce awesomely fast binaries. But the compiler was being changed as we were moving to a C++11 application on top of a low level C based OS and driver layer neatly abstracted away and given a C++11 interface by another in-house project. So we asked what their level of support for C++11, namespaces and so on was, asking for their level of compliance with the C++ standard stuff that is available by vendors such as Intel, Gnu, LLVM and Microsoft. He froze and tried to deflect by saying it was top notch. But we dug in and found out they had: no C++ support beyond 98 and no namespaces or exceptions and some other limits. While we didn't need exceptions (but are considering making our own libunwind version because our HAL layer in C++11 is exception safe) the limits on lambdas, auto, constexpr and so on was just too much given the galling level of their price. We waited patiently for the presentation to end at that point and then the moment he had left looked at each other and decided they were not qualified to provide our compiler for the next long while (even if they got the features they were in dire needed of testing that the other bigger compilers already had).
Well, obviously on /r/cpp you'll get a lot of one side of the conversation. In my experience, when someone says they've used C++ I ask them "did you use anything from C++11?" and maybe they'll have used one new library, but rarely any of the new features. It's usually just C++98 programs that look like they were written half in C half in C++.
Apparently, you really are not aware of what is in C++1x. That's fine. But since you are "deep in the C++ trenches," I would highly suggest you pick up the new developments in C++. It makes a world of difference. Rather or not it is simpler, I'll leave that to you to decide.
Well... yeah. Take this: void foo() { T* t = new T(); t-&gt;bar(); delete t; } If `T::bar` throws, then `sizeof(T)` is leaked. Instead, we need this - assuming `T::bar` only throws something derived from `std::exception`: void foo() { T* t = new T(); try { t-&gt;bar(); } catch(std::exception&amp;) { delete t; throw; } delete t; } Now when we have two raw pointers to heap allocated memory that we're responsible for, the interactions get much worse. Luckily `std::unique_ptr` solves all this, as if `t-&gt;bar()` throws then `std::unique_ptr`'s destructor is called which calls `delete t` for us, hence both `delete t` lines are not needed and because we only catch an exception to throw it back, the try/catch block is not needed either thus reducing it to `void foo() { std::unique_ptr&lt;T&gt; t(new T()); t-&gt;bar(); }` and now we're protected against memory leaks. There is still the issue of what happens if `new T()` throws, though... if it's a `std::bad_alloc` then no memory was actually allocated, but we're also effectively out of memory so that's not good. But if `T::T()` throws then the constructor is aborted and the destructor is *not* invoked, however the memory for the `T` itself is released and the destructor of each *fully-constructed* member is executed. Hence any `T` that calls `new` in the constructor and stores the result in a *raw* pointer will cause a memory leak for those dynamically allocated members. Which really means that classes should not have any raw pointers and should only have `std::unique_ptr` members if it needs some sort of dynamically allocated (possibly polymorphic) or optional member. The alternative is much much worse: T::T() try : u(nullptr) { U* u = new U(/* args */); /* stuff */ } catch(/* something */) { delete /* raw ptr */; } // implicitly rethrows
Sorry, I just don't buy the "C is more nimble than C++". It takes much, much more code to do even simple things in C. There aren't even dynamic collection classes, variable length strings, destructors... You have to either write it all, or start off by bringing in some sort of lame-ass C "strings", "vectors" and "maps". For me, writing in C is like crawling across the ground when I could walk.
Because C++1x makes the language simpler _to use._
You misunderstand. C is not "nimble" in the sense that it makes it easier to write code. I think I covered that distinction in the bit about the comforts and conveniences of higher-level languages. C is nimble in the sense that it can go places other languages -- even C++ -- can't, due to its very minimal runtime environment and the fact that it has compilers *everywhere*. Tl;dr: If you don't understand the virtue of C, it is because you have never needed C. Do not assert that just because you can get on better with an alternative means anybody who uses C is a masochist or deluded.
I'm in favour of GC but, in a systems language it should be strictly opt-in. With respect to Rust I don't think the proposed v1 is good enough to tempt people away just yet. One ruster failed to get a LISP working well and abandoned the project. That does not bode well for the space it aims at.
C++ itself is fine, excluding few _absolutely ridiculous_ issues, like lack of modules in 2015. There is also pretty much no other choice in few areas. The problem is, there is a lot of it (C++). Its not really a problem when you collaborate with people that know wtf are they doing or people that know they don't know everything and their designs werent given to them by gods. The pain and misery happens when there is a developer high enough (lets call him an architect) that is kind of knowledgeable, but isnt really aware of what he doesnt know - you can _easily_ end up with designs that are so shit, its not even funny. Multitude of features in C++ make it very easy to fall in false sense of 'im an expert' feeling which promotes silly shit from such people. C, being so simplistic isnt as prone to that. Yeah, its cumbersome, and i hate it with passion, but you cant do as much stupid shit, without actively wanting to torpedo the project. It you read between the lines of Linus post, you will see that he really doesnt mind C++ itself, just C++ programmers. &gt;which makes me feel like I'm an total idiot who knows nothing. Do keep this attitude. Being humble and wrong is so much better then being douchebag who is wrong anyways. Its likely there are things you dont know.
The reference is a good replacement idea. 
His arguments against C++ has merit only in his domain, such as his kernel; he's just another programmer bitching about a language he doesn't use. While few things he says about C++ is true, such as C is usually better for performance; it definitely doesn't mean C is the best choice for everything, and it's pretty obvious where C++ excels. There is some incredible software out there that has been built on C++, such as portions of Facebook, Chrome, Firefox, MySQL, MongoDB, MS Office, Amazon services etc. The OPs question is if C++ is bad; No it is not. And he didn't make a mistake by picking C++ as a career. Don't let the shit that Linus spouts dictate your career or personal choices.
Unfortunately C++ is so large that very very few people truly understand it entirelywhich leads to a _lot_ of bad code being written. What's more, people often get thrown into it as one of their first languages without having learned when it's reasonable to have eg: an inheritance hierarchy (almost fucking never) and language pitfalls, which ends up compounding the problem. What's more, the people that really do understand the language are often pretty far out there in terms of CS knowledge, and so you almost have the problem of people being "too smart" for their own good. Have a look at the Boost Geometry [design rationale](http://www.boost.org/doc/libs/1_57_0/libs/geometry/doc/html/geometry/design.html) for a good example of this. They take logical steps until they end up with an inscrutable mess. At the end of the day, it takes a _lot_ of discipline both in yourself and with your team to not generate a pile of crap with C++, which I think is where a lot of the hate comes from.
Man, I've worked with C++ (not necessarily regularly over the last two years) for years and I still learn new shit about the language. 
I would be a good question to have posted in /r/programming Though they may have the same bias than folks at HN
http://geekz.co.uk/lovesraymond/archive/show-them-the-code
There is Silicon too , and I know about CppCMS and a ton others. Try searching http with c++ tag on github , you'll find a lot. But each one of them tries to be as low level as possible , providing no abstraction on top of them. Take a look at nodejs server example , you'll get what I'm trying to tell.
Modules as what? It is quiet generic term.
I like programming for the tinkering aspects, and for setting up stuff that works. I don't like having a billion premade routines and garbage collection, it kills the fun. But I'd guess it's better to go higher level if you want to make stuff quickly or easily.
I would say that Go is a bit immature yet, but it could be a decent contender in this field.
As something like [this](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2073.pdf), or couple other proposals since then.
I guess. I don't really know the guy, so I just went with what was on topic. I'm starting to think I'd rather not know this guy.
I like C++ a lot! It's an extremely useful tool and a very rich language. I think a lot of people much underestimate the "good parts" of it. Nobody claims it's perfect or the prettiest language ever, but nevertheless it's entirely possible to write very elegant code with it and the programmer gets an extremely impressive amount of control, flexibility, and options for solving problems. I recommend browsing the FAQ here: https://isocpp.org/faq And you may find this helpful: http://www.stroustrup.com/Myths-final.pdf There are *many* applications written with C++. You're probably using several right now. :-) 
Yes. I developed C++ for many many years and loved the language at one time. However, I've walked away. There are some very good reasons why (most of these are well known but good to summarize): * Incredibly complex grammar * no standardized ABI (making interop with other languages problematic) * too much 'action at a distance' (what does + mean, etc). A lot of other languages suffer from this, but c++ is the worst * too much paradigm drift over the years 
You're description of assembly and assemblers drastically oversells the abstraction. If you were talking about LLVM or CIL it would make more sense, but the class of assemblers and assembly languages is much broader and usually architecture specific. Part of the usefulness of assembly is the explicit ability to access hardware specific instructions and resources. To write 'C++' you don't need to know about RAII or the STL...
True, but then you might also argue that the best C++ almost never uses raw pointers.
The C++ comment doesn't make him a douche, I was basically strawmanning him. There was some thread I found on HN last year linking to an old lkml post where ESR rants against the Linux kernel management structure, I won't be able to find it again I don't think but his ire was just so indefensible and trollish that nobody even bothered to reply. Plus the stuff those other commenters mentioned. He is sometimes a douche, and I don't like his views on C++ either. 
You're absolutely right; C++ has always been designed with portability and minimal runtime in mind, and in recent years it has achieved both to a surprising (even unprecedented) degree. But historically, for embedded systems, C has been the way to go, and even now, there are microprocessors where your only options are assembly and a tiny subset of C89. As more and more of these legacy systems are obsolesced going into the future, we'll see that change, but for now C is still an absolute necessity for some things. And even where it isn't, oftentimes C is all you need; C++ has introduced some nice language features, but most of those eventually get written into C. If all you're doing is structured procedural programming with a few minimal data structures, there's no reason to break into the C++ toolbox; C will do just fine.
Please recommend me a book which teaches proper use of modern c++. I've got the basics covered. 
I agree with you but back it up even more. Most of my paid work is in C# and when I get someone who has done php/python their whole life and make a comment like c# is too complex I know I am not speaking to a programmer. Python has a habit of having a library that does what you want. My xperience with python people is that they assemble libraries all day. I am starting to rant now but most of the younger crowd see everything from a web point of view as well. I saw a question on reddit about a guy who wanted to install a light weight webserver on someone else's machine as a prank so he could call a web service to change the wall paper. It never occurred to him to have a an executable listening on tcp. In my 15 years of professional work vey little has been web. I feel like they miss out on the really cool stuff.
Microsoft is rewriting their C runtime in C++ from scratch, leading to many performance improvements :)
This is language independent.
I think you've almost answered your own question there without realising it: C++ is a language that is good for working in some areas, but not in others. C++ has a lot of legacy baggage and in many ways it's not a very nice language by modern standards. Its syntax is clumsy for historical reasons and because of the emphasis on backward compatibility. Its semantics are full of edge cases, particularly where language features interact. Its type system isn't particularly expressive. It has more ways to shoot yourself in the foot than a Wild West sheriff with a nervous trigger finger. And IMHO C++11 and C++14 haven't really changed any of this qualitatively, because while they make useful incremental improvements in some previous weak spots, C++ is still C++ and the basic pros and cons of choosing it for any given project are still much the same. On the other hand, for code where you need low-level control and very high performance, there aren't many languages in the picture other than C and C++. If you're writing, say, web apps or enterprise software back-ends, you probably don't need that fine control and all the downsides that come with it. (See also: Most projects discussed on HN, among others.) But if you're writing an operating system or a device driver or a networking stack or a number-crunching library or a rendering engine for games, your priorities will probably be different, and you don't have the luxury of using all those other nice, safe, expressive, (restricted), (dependent on heavy run-time environment), (slow) languages. While there is certainly the potential to have much nicer languages that can do the same jobs and in a few years we might have more options, the reality is that right now there are basically only two viable choices for a lot of projects. So the only useful question if you need to build a project like that today is whether you prefer the simpler, more transparent, but less powerful and expressive C, or the more complicated, potentially surprising, but more powerful and expressive C++.
I think everyone is desperately waiting for a C++ module system; that would help so much. More LLVM based languages help everyone; C++ will also profit from the ongoing LLVM work.
&gt;Look at how much indirection and dynamic dispatch is there with indirection and dynamic dispatch.
No, it isn't. It really, really isn't. It comes from two places. 1. C programmers who don't see the value in things like templates and the STL, and are trying to find a reason to stick to the C subset of the language. 2. High level programmers who aren't satisfied with C++ abstractions and miss how they were done in the other languages that weren't targeting efficiency. The remedy? Read *C++ Primer*.
oh, yes! let me add this one! same codebase: class HugeDatabase { // about 1Gb in memory. A cartography db with the road graph of a whole EU nation HugeDatabase(const HugeDatabase&amp;); HugeDatabase(char* filename); }; and a class to navigate the roads class Navigator { HugeDatabase graph; public: Navigator(char* filename) : graph(*new HugeDatabase(filename)) { ... } // THIS LINE! }; *new something()! I still have nightmares of it...
&gt;Heck someone could make a 40-50MB runtime in cpp which might do OS specific translations to satisfy them. It's worth pointing out that Nodejs and the V8 JS runtime it uses, as well as Firefox's Spidermonkey JS runtime, all use C++.
&gt; I'm in favour of GC but, in a systems language it should be strictly opt-in. I disagree, deterministic GC is perfectly acceptible for a wide variety of systems level tasks. Look at Erlang for an example of a high-level, GCd language designed for systems-level use. That being said, I don't know what collector D uses, but I do know that it's only used for heap allocated objects, and many of those situations can be manually avoided in critical situations. Given that a good C++ programmer will use the heap judicisouly anyways, coding in a similar style in D (and manually avoiding the GC in critical sections) should make the GC quite bearable, even for systems uses. That being said, Im not fond of it being tied to a special runtime library, and I've never really paid attention to executable size in that language. As for Rust, I think you're wrong. It's already quite usable. Some of the more esoteric OO stuff is still being nailed down, and the IO has been identified as needing work (which it's getting), but overall the language is solid. That guy failing on his lisp project is anecdotal at best -- you should give it a try before you discount it. 
It's possible but then I have to reintroduce coroutine_traits and ADL for await_xxx as they're currently ignored. FWIW, in the lib there're task &amp; shared_task, which are the coroutine-based counterpart of future &amp; shared_future.
im very happy with c++
I think I have a better idea of what you're getting at. Just seems really overstated to me.
 &gt;I agree with you but back it up even more. Most of my paid work is in C# and when I get someone who has done php/python their whole life and make a comment like c# is too complex I know I am not speaking to a programmer. Python has a habit of having a library that does what you want. My xperience with python people is that they assemble libraries all day. Interesting perspective and frankly I think you are at least partially right! A good portion of the Python community seems to be wedded to the virtualenv world where each product is built out of a custom Python configuration. Do realize though that the entire Python world isn't that way. &gt;I am starting to rant now but most of the younger crowd see everything from a web point of view as well. I saw a question on reddit about a guy who wanted to install a light weight webserver on someone else's machine as a prank so he could call a web service to change the wall paper. It never occurred to him to have a an executable listening on tcp. In my 15 years of professional work vey little has been web. I feel like they miss out on the really cool stuff. I don't disagree with this either. However renewed interest in micro controllers via boards like the Arduinos are at least getting people interested in programming outside the web. Then again you have people trying to use these controllers for web access or support. 
Raw pointers are used -all- the time, even in modern code where every pointer is owned by a unique_ptr. The issue is with RAII and pointer ownership, not with using raw pointers.
Agreed. Claiming that C++ is not a massively complex language is very ignorant.
&gt; Sometimes I think that whole C++ toolchain development aims for better, faster, more optimized output and only improvements in the area of comfortable debugging are better error messages. That assumption is not completely wrong. A lot of functionality, including refactoring, practically requires half a compiler. For a long time the best available open source C++ compiler was g++, which to this day is maintained as a monolithic blob as required by RMS. RMS is also known to personally step in and kill any plug-in that could "leak" useful information. With clang I have high hopes for the future.
&gt; I hear that sometimes, but usually only in C++ settings. I can never quite quantify what they feel is missing I think sometimes they can't either. Maybe it was just a vocal minority. I really liked Rust in the time I played with; especially that it allows you to do low-level stuff if you really want to. Biggest problems I had was the unstable documentation and that you find example code which isn't relevant anymore because the syntax and semantics changed. But a 1.0 release will fix that :)
HN people aren't smart enough to use C++ so they bash it to make themselves feel better.
He might have some controversial opinions, but he's not just spewing hate out, he's meticulously defining and explaining himself. Doesn't make him a douche or a homophobe to have an opinion and calmly standby it.
Most of thoses people would tell you that Java is the best programming language ever and why you do those complicated stuff omg inherit inherit inherit everywheeeeeeeeere simple as shit.
Hahaha, who is bad mouthing C++? It is THE standard for embedded systems, game development, and almost any speed intensive software. If you understand C++, you can understand just about any other programming language. It is fundamental and foundational.
If you desperately need to debug optimized builds, there [are flags](https://randomascii.wordpress.com/2013/09/11/debugging-optimized-codenew-in-visual-studio-2012/) you can pass to the Visual Studio compiler to make the experience a bit nicer. While developing you really should try to use debug builds though, or at least turn off optimizations. Also, you can actually print from breakpoints in Visual Studio by right-clicking them and clicking "When hit...".
You can find text attacking anything. 
I heard about RMS ideology. Whether or not his right a source of countless discussions over the internet. However I cannot help but notice that his approach slows down growth of OS programs in some regards (such as everything that would make use of exposed GCC's AST). I to have high hopes for Clang. Currently there where some good code formaters that were able to distinguish macros from functions and so on.Still, we need IDEs to make use of it and I have some hopes for CLion.
Yup. When I read shit like this: http://harmful.cat-v.org/software/c++/linus I lose a major amount of respect for a person. The close minded, over-generalized, fuckwittery that Linus shows here is pretty shocking. It makes me think he has absolutely no idea what makes a "good language." We can bitch about PHP, but when half the web is written in it because half the web is small little quick-and-dirty apps and that's what PHP is good for, then who fucking cares. If half the executables in the world are written in C++, then what does that say? It's more productive. The measure of a language isn't just the syntax, grammar, features, and efficiency... it's also the productivity. C is a fucking terrible language for productivity. It's just a scosh better than COBOL, Fortran, and BASIC. We're not all building operating systems. We're not all building source control. We're not all building 8-bit microcontrollers. If we were, maybe he'd have a point. And with regard to the request in that post, sure, he's right. C is by far the better choice **for that project**... but to shit on C++ as a language and even make blanket statements about those who code using it is ignorant as hell. &gt; C++ is a horrible language. It's made more horrible by the fact that a lot of substandard programmers use it, to the point where it's much much easier to generate total and utter crap with it. Quite frankly, even if the choice of C were to do *nothing* but keep the C++ programmers out, that in itself would be a huge reason to use C. Makes me want to kick Linus in the dick. That is some really ignorant bullshit. 
`c++` is quite wonderful. However, it's worth understanding that it's a sledge hammer. It's large, it's difficult to use, and you're gonna lose a toe if you don't know what you're doing. That said, when you need `c++`, basically nothing else will do. (Except sometimes `c`.) One thing you'll learn with time is that the more common a language, the more haters it gets. That's not a sign of problems; that's a sign of familiarity. A lot more people hate pepperoni than anchovies; a lot more people hate vanilla than cinnamon-cardamom.
nah, that's Java
The flip side of this is being bitten on something that has no visibility. When something _must_ be a particular way (inlined, not copied etc) because testing has shown it needs to be, then not relying on the compiler becomes useful. Now, if I could make inline_error_if_not, or guarantee_move_semantics then it becomes less of an issue. Having been bitten by all this multiple times makes people wary. Even when simple tests show its supposedly working. Since you cant necessarily look through every use case of something every time, building a safer API is a useful alternative. Granted you shouldnt cargo cult this either. Test everything, keep updated on modern techniques etc. 
`auto_ptr` can be used for pointers which are not copied, e.g. pImpl idiom in a non-copyable class, or impromptu RAII inside a function body. It is effectively the same as `unique_ptr` except it breaks at runtime when you try and copy it, whereas unique_ptr gives a compiler error. 
*new* returns a pointer, and \**new* dereferences it. 
Move semantics are completely deterministic and not at the whim of the compiler.
We'll AFAIK this could be easily somehow. Since they aren't using recursion (low memory, short stack) one could try simply use one of those smart techniques when you calulate how deep the stack is and prepare special build and tests which would check whether some function call increased stack's depth. I guess there would a way to do it in a way that wouldn't change which optimizations are used. They heavily rely on intrinsic though. Some maybe some compiler only feature that would ensure inlining heppened would be permitted. But I'm not into embedded programming and I never really investigated such things so maybe it cannot be checked that way.
Automated profiling should be able to collect enough evidence in your favor. Even more, the simpler the code and the more assumptions the compiler can make about it, the more optimizations it can apply. However touching code that just work is not wise at all. It is going to be necessary a lot of comprehensive unit testing to make sure any refactory will not break functionality. That takes a lot of time and I am quite sure they will not invest time/money fixing something that it is not broken. You should try to apply this only to code with severe bugs. Nobody will miss buggy code. 
Sorry, I disagree completely with the idea that knowing C++ makes you a better programmer somehow than those who program in other languages. Maybe I could agree that knowing C++ makes you a better OO programmer, but I would not expect the average, or even a good, C++ programmer to write very good assembly, or Lisp, or Haskell. Saying "Knowing C++ will make learning curves nil" is entirely untrue; just because you know how its implemented doesn't mean you can learn a language without work.
Let me guess... Java guy who doesn't know RAII even exists. 
Lisp. Lisp is incredibly high level, and was invented in the 60s. There's a reason C was called "portable assembly", and its not because C was high level. (Although it is. Automatic memory management is great)
C++ isn't bad, not at all! It gives you almost total control down to the bitlevel. The thing is: Most people are terrible at handling "total control". After coding 5 year i felt like a guru in C++ i knew stuff most people didn't hear about. I never had problems writing safe code. I embraced the boost library, was looking forward to C++11. Yet many people i worked with just did not care. "I can handle my pointers", "I don't need smart pointer". The same people never heard of exception safety. The Problem is that you have to embrace things like the boost library to make C++ safe, that is something a C# or Java developer will simply not understand. For them its like looking at a caveman crafting a hand axe from stone. C++ is old and you can tell it by just looking at the monumental clusterfuck that string handling is. Sure many people here will disagree. Many people will not feel the pain. They never question why every 3rd party library comes with its own string class, every major library... Today I don't want to know any more, i have seen other languages, more elegant languages. I don't care about move constructors. I never had the issues those constructs were supposed to fix. For gods sake what is so diffcult about using smartpointers? The industry i'm working on switched to C#. We won't touch C++ for new projects as if it were toxic. It is toxic. That is the problem of C++: It is too complex. You can have two C++ programmers meet and they have virtually nothing in common: One guy using template meta programming to optimize the backend of a successfull web company and the other guy writing rich clients with QT/QTQuick. Technically both are C++ coders, both may be excellent at their job yet one could not do the work of the other effectively. Not without 2-3 more years of experience in the field. Maybe not even then. People come straight from the uni learning 2-3 years of C++ and then they write production code. Terrible code, dangerous code. Code that is terrible because C++ lets them do things and more problematic omit things... A terrible coder will be a terrible coder regardless of the language but with C++ he can deconstruct your project. So yes C++ is also a terrible language, especially if you have to work with C++ newbies. Learning anything is never a waste of time. A Mandelbrot implemented in template meta programming is a thing of utmost beauty (is that even possible?). So are most contributions to the IOCCC (International obfuscated c-code contest). Did you ever wonder why there is no IOCPPCC? Too easy... Writing obfuscated C++ code is way too easy most people do it anyway. I like C++ yet I hate C++. If i had to write a platform independant application tomorrow i would choose the QT lib. And i wish someone had told me on thing earlier: Don't fight your coding environment! If you write STL code, write stl code but don't put stl strings into your windows or qt application. It will haunt you! So don't worry you'll be fine. There is plenty of C++ code out there and if you know C++ mastering other languages is a cakewalk. 
Oh okay. It seemed redundant to use a * with new, that makes sense. Thanks a lot! 
I agree. He has no idea what he talks about. Btw. this talk might interest you. Scott Meyers investigates why C++ is so successful despite apparently being horrible. https://www.youtube.com/watch?v=ltCgzYcpFUI
I don't know a single person that does. Anywhere. Also, I don't think that word means what you think it means.
I can't find a source right now. But i think i read somewhere that a standard complient compiler is not required to actually delete anything when calling delete. Does anyone have a source or can refute this claim? I believe the reason was to allow garbage collection in C++. 
um, nice blog post, could you add an RSS feed to your blog?
Good idea. I'll do it soon. Maybe a newsletter or a google group could be nice too.
Then you are wrong. Assembly is not abstracted, you do need to know the instructions for the machine and there is no concept of a virtual machine (except VMware). Some assemblers (e.g. nasm) support multiple architectures but the code you write would be quite different on each one
New returns a pointer. The asterisk, dereferences the pointer to obtain a reference to the object it points to. The issue here is that 'HugeDatabase' has two constructors. It's using both in the initialization list, but thats a giant waste. You could just have "graph(filename)", which would not only fix the memory leak introduced by this new, but also save yoruself the extra heap allocation. It makes it worse that its a 1Gb object, since now we've got two of them around, but, at least its not my code base. Sorry yCloser 
I find it odd that people have trouble with pointers. They seem so simple and obvious to me, but I guess everyone has their thing. I still get confused when I occasionally use a "managed" language and have to keep telling myself that the "assignment operator" is just a reference rebind!
C++ is basically in its own tier of languages. I feel that the problem with C++ is also its strength. It allows such an enormous amount of flexibility that anyone that doesn't know how to control/use it turn up impossible to read/inefficient code. I'm suspecting this is also why many C++ developers are also a little bit more stuck to it than any other language (you can see Python/Java toying around with other languages), but if you're a C++ developer, you're pretty invested in it. Of course, this is a lot from my observations.
Thanks for linking that. Very interesting. At 49:20 he mentions that there would be an alternative to std::bind in c++14. Does anyone know which feature he is talking about? 
&gt; Aren't there any successful projects backed by c++? Just a few obscure programs like Adobe Photoshop and Illustrator, Google Chrome and MapReduce, Microsoft Windows and Office, MySQL, Oracle, SQL Server, Maya, Autodesk, Firefox, and Winamp. Also a few small, indie games like Call of Duty, Halo, and World of Warcraft.
I think I must have chosen the wrong career path. Except, concepts.
I also wasted a lot of time learning C instead of C++, but partly because of another reason: Visual C++ 6.0 Boy that compiler sucked. For instance I remember having a big performance impact just by compiling C code as C++ ... That put me off for a long time.
I think it's worth pointing out that the feature was never proposed as "enhanced auto". It evolved as part of the Concepts TS. It's far more interesting when you start replacing "auto" with the name of a concept.
I'm not sure that has to do with inlining as much as it has to do with limitations/restrictions of the Visual Studio debugger. In my experience you seem to be able to invoke any static function from a breakpoint condition that won't affect the state of the program, like strcmp and such, but never anything like a member function which potentially could.
Bloody hell I had no idea. 
I find python programmers to more often be the ones that think their language is the best for everything. People who are good at java tend to be very pragmatic, much like people are good at c++. ( The others are just awful, without knowledge of programming, and just use java by default. They don't say java is best because they don't have opinions about programming. They just want to be promoted to manager.)
Two things: C++11's lamdbas don't support capturing move-only types (e.g. you can't move a `std::unique_ptr` into a lambda), and the arguments of a lamdba are fixed (i.e. you can't call the same lamdba with two incompatible types like `f(3)`, `f("hello")` even if the implementation of `f` would be valid with both types). C++14 adds in support for lambdas for both of these situations. The answers on this [this](http://stackoverflow.com/q/15598607/567864) StackOverflow post explain a bit more (and better).
I've tried using `boost::optional&lt;T&amp;&gt;` before in place of nullable pointers; there is a measurable performance penalty over raw pointers, so I'm not sure I'd recommend it over a simple `observer_ptr`-type class if you really need nullability.
&gt; *new something() I've seen this twice from fellow students when they were new to C++. More specifically both of the times it looked like this: type local_var = *(new type(args...)); I of course explained to both of them that I literally cannot think of any situation at all under any circumstances were this would make any sense. (This is probably unique to that pattern!) I remember that I told the second one that in Java he wouldn't create integers like that either but would just use `int foo = 3;` and let the scope manage it. He reply was “But `int` is a primitive type.”, which really struck me as odd.
Actually, it is not obvious that emitting an exception from Meow's constructor won't invoke ~Meow(). Almost everyone has to be told about this rule and the rationale for it. (It's a good rule, it's just not obvious.)
C++ is a better C. Not a fanboi statement, you can compile any C program as C++, with a minimum amount of changes. To say that one is better than another is really silly, because you don't pay for the parts of C++ that you don't use. At risk of destroying the analogy, you can program C++ like a car stripped down to two wheels and an engine if you desire, which is basically the same thing as a bike.
Then you are wrong. See also JVM, LLVM, etc.
Most people aren't capable of immediately thinking things through to see the need for the rule. Especially if they start off imagining a class that tries to be safe (by initializing the pointers to null), since they don't realize that the language cannot assume anything about the class's behavior.
Yes, but Java and C# are already OOP languages, similar to C++. If you get outside that realm, you will have a lot more difficulty. And I think that a solid background in C or C++ does make you a better programmer, but I also think you need a good background in a functional language, like Haskell or Lisp, because it really does change the way you think.
Yes, but Java and C# are already OOP languages, similar to C++. If you get outside that realm, you will have a lot more difficulty. And I think that a solid background in C or C++ does make you a better programmer, but I also think you need a good background in a functional language, like Haskell or Lisp, because it really does change the way you think.
That depends on what "actually delete" means. It *is* required to call the appropriate destructor. It is not required to release the memory back to the OS (and most implementations don't; they maintain internal lists of free memory). It's not required to that same memory again if you immediately make an allocation of the same size. This has nothing to do with garbage collection; the standard has no concept of an OS or RAM so it can't require these things to happen. You can read section 3.7.4.2 [Deallocation Functions] of the standard for all the details. However, there is something called "pointer safety" which was added for garbage collection. It's a list of rules that determine whether a pointer is safely derived, and the strict version of these rules requires a pointer to be safely derived if it is valid. The relaxed version does not place restrictions on how pointer values may be derived. For example: int *p=new int(), *q=new int(); auto pi=reinterpret_cast&lt;intptr_t&gt;(p); auto qi=reinterpret_cast&lt;intptr_t&gt;(q); auto p_xor_q=pi ^ qi; pi=p_xor_q ^ qi; p=reinterpret_cast&lt;int*&gt;(pi); On the last line, p is a valid pointer if and only if the implementation has relaxed pointer safety. If it has strict pointer safety p is not valid, and dereferencing it would be undefined behavior. This lets garbage collectors collect memory they think is not being pointed to, even if it's possible to somehow derive a pointer to it. This is obviously a constructed example, but there are [actual data structures](https://en.wikipedia.org/wiki/XOR_linked_list) that do things similar to this.
&gt; In fact, it is even advised to used raw pointers (or references) then to make clear that owership/resource-management is not involved But a raw pointer *doesn't* make that clear. A raw pointer carries no semantic information at all and enforces no constraints. That's why we adopt smart pointers, no? &gt; (and it is also faster) Are you sure? There are several plausible implementations of some of the now-standard smart pointer types. Historically, different compilers have had different results in terms of performance. Indeed, there was some interesting discussion within the Boost community a few years ago about the trade-offs, and various benchmarks were produced. It's quite conceivable that for some or all relevant operations a smart pointer would be optimised by today's compilers to the same degree that an underlying raw pointer would. Even back when the benchmarks I mentioned were done there was already typically no overhead for things like a simple dereference, and the concern was more about things like construction and copying, and that was an eternity ago in compiler technology terms. It's even possible that smart pointers will wind up a little faster in cases where potential aliasing issues would arise but can't because of the interface to the smart pointer, though I don't know whether the escape analysis in modern compilers has reached that level yet.
I admit, I have never touched a language that is not OO. I think I may give Haskell or Lisp a go and see how I like it
It's on his [website](http://www.stroustrup.com/bs_faq.html#really-say-that).
Its a function that emits a static string out , lets make a class for it :D
Take a look here , and go on completing at least 1 book from each level :)
You gave me mixed feelings.
As long as your career models the Pajamas concept, you're good to go.
Why would you do this: s.*(condition ? &amp;S::a : &amp;S::b) = 2; instead of this: (condition ? s.a : s.b) = 2;
It is certainly manageable on the user-side, but the implementation becomes ridiculous. Multiple dimensions and parametric type of the values is certainly a nice thing, but after that just overload it should you ever need it. Define one class-template and program for that: template&lt;typename T = double, std::size_t Dimensions = 2&gt; class point { public: static constexpr std::size_t dimensions() {return Dimensions;} const T&amp; operator[](std::size_t i) const {return m_data[i];} private: std::array&lt;T, Dimensions&gt; m_data; }; template&lt;typename T = double, std::size_t Dimensions = 2&gt; auto distance(const point&lt;T, Dimensions&gt;&amp; lhs, const point&lt;T, Dimensions&gt;&amp; rhs) { auto square_sum = T{0}; for (std::size_t i = 0; i &lt; Dimensions; ++i) { const auto dist = rhs[i] - lhs[i]; square_sum += dist*dist; } return std::sqrt(square_sum); } And then just let the optimizer do it's work.
The same reason why you would do char c[] = "test"; for (int i = 0; i &lt; 4; ++i) { i[c] = 'a'; }
...and why would you do this?
Thanks for nice feedback =). Credit for the stateless write API goes to [Doug Turnbull](https://github.com/softwaredoug) who had this great idea and a [prototype](https://github.com/softwaredoug/Sprint), as initially I only planned the formatting API. Nice thing about the write API in C++ Format is that it only needs to check and handle the state that is actually used which permits faster implementation compared to IOStreams.
It had never occurred to me you can use ternary for an l-value.
How did they come up with that name for the site, kukuruku.co? Because I remember kukuruku as a wafer that was heavily advertised when I was a child.
C++ is the much more complex version of C. Software can be done in C with better and simpler abstraction than C++, if the code is not biased by OO design, bgfx(C style using C++ syntax sugar), nanovg or Handmade Hero are good examples off the top of my head. C++ became very complex, I can't even read the news anymore eor understand why it makes sense to think about very complex stuff when I'm programming. Many optimizations C++ advocates talk about matter less when missing the cache and having bad performance because of that. Manual memory management is just simpler than automatic memory management. C++ at this point only needs to die as the complex bubble, far from elegance and simplicity, where C can still live on, coupled with other languages. But C++ will grow and we'll have this crap for oh how many years to come. Whatever it is the next version of C needs to be simpler than C to create abstractions.
Learn You a Haskell is a great tutorial for Haskell, and I would suggest Haskell ( because I like it more :) ) Edit: Oh and if you've never done assembly, its awesome. People who think that C has manual memory management have never done assembly :P
if you dont know the "feature", `a[i]` is the same as `i[a]`.
I worked that out from the working example, I was just curious as to why this was done. I'm glad it is not something I'd see in a serious application though I understand if it's just something like a "look what can be done" type deal.
I thought so for years. But the current project I'm has both a unity and "classic" build, and I _only_ use the unity build, because it compiles almost an order of magnitude faster. The maintenance really isn't that bad - the key concept isn't having everything in _one_ .cpp file but "a few" .cpp files, so you can solve any problem that comes up with a new compilation unit. Yes, you lose a little in purity. Yes, your anonymous namespaces lose some force. But as a tradeoff for making compilations many times faster, it's a very reasonable price to pay.
C++ was starting to become quite dated, but C++11/14 (and soon 17) have completely turned it around. Sure, you can code horrible nightmares with it if you want, but that's because this is a language that lets you do whatever the hell you want to with it. I find it a beautiful language.
Interestingly, C forbids this (ternary operator only returns rvalues), while C++ allows it.
Thanks for sharing! I imagine this will be useful to cpp geeks, such as myself.
Some of the examples are representative of good usages of the conditional operator, particularly initializing references and const variables. However, some of it's forced - like this: constexpr bool check_if_prime(unsigned int num) { return (num &lt;= 1) ? false : check_if_prime_impl(num, 2); } Which can be rewritten: constexpr bool check_if_prime(unsigned int num) { return (num &gt; 1) &amp;&amp; check_if_prime_impl(num, 2); } Quite simply, we can see that when you have `condition ? a : b`, where `a` or `b` is either `true` or `false` (literals), you can replace this with `||` or `&amp;&amp;` as appropriate and possibly invert the `condition` part depending on which literal boolean value was used. With the other example it's simply more chaining that's needed, but it's still possible to reparse it as a single boolean expression using nothing more than `&amp;&amp;`, `||`, and parentheses. Exploiting short-circuit behavior should never be a bad thing as, I think, it's much more understood than the more complicated nested conditional expressions.
Assuming that `a` is an array (or pointer), both are the same. int main(int, char**) { int* t = new int[5]; 0[t] = 42; std::cout &lt;&lt; t[0] &lt;&lt; "\n"; std::cout &lt;&lt; 0[t] &lt;&lt; "\n"; delete[] t; } This results in 42 42 as it should be.
Numbers 1 and 2 do this: int i; int j; (false ? i: j) = 45; which he claims will compile. He should be a lot clearer that this is not valid C but is valid C++.
What on earth kind of indentation scheme is that. 
Indeed, the first 2 answers aren't completely right. The article starts off talking about the unicorn of "C/C++", so I assume it is supposed to apply to both C and C++. In C, the result of the conditional operator is never an lvalue so neither compiles. Also the grammar is different , I don't recall exact details but when it is `a = b ? c :d = e;`, the assignments bind differently in C than C++. Or something.
[Whitesmiths.](http://en.wikipedia.org/wiki/Indent_style#Whitesmiths_style)
Which is, not coincidentally, used in VC's STL implementation.
Ah , I get it. Every modern programming language has them. But have you checked [biicode](https://www.biicode.com/)? 
Offtopic - but are you really a sysadmin from jail? ఠ_ఠ
Only time I've ever used delete for real in c++ is when dealing with c libs. 
No, I'm just in jail for now, but I could setup a domain controller for you if you'd like ;). Jail is better than being in prison, or so I've been told. I never wore orange jumpsuits before, but I'm starting to like it. Once I get out, I'm going to try marketing them with custom options, similar to vanity license-plates, but with stenciled letters/numbers on the back. I was thinking kickstarter or indiegogo. In reality, every moment of every day I could go to jail if I released or revealed information I swore/was-contracted to protect. This is why I have an issue with Snowden...there is a code of conduct similar to a doctor or lawyer: you do NOT release private info. If you have damning evidence of an organization you release it anonymously and very carefully, but that is in the most extreme cases. Lots of people have skeletons under the bedsheets, and if you sign the contract that you will not release them you fucking take them to your grave. Because you took the bait getting a contract ($$$) doesn't mean you get to pop open the genie bottle when you realize there is a moral issue. The moral issue was you taking the contract with a shady organization, government or not. Wait, I'm ranting again. Put me back in Cell C7.
Technically returning an lvalue is undefined in C; I'd be willing to bet that many C compilers would allow you to do it, as it is perfectly valid C++ and has a certain expected behavior, but I haven't tried it myself; in any case, it is non-portable at best in C and should be avoided. Also, as you said, I believe the operator precedence is different, but I don't know what it is for either off the top of my head. The ternary operator is not the only case of conspicuous differences between the two languages, but given how tricky it can be semantically, it is definitely one of the ones to watch out for.
OK, I've implemented the customization points, and provided the adaption code under &lt;co2/adapted/boost_future.hpp&gt;. Example: template&lt;class Promise&gt; auto test_future(Promise&amp; p) CO2_RET(boost::future&lt;void&gt;, (p)) { std::cout &lt;&lt; "start----------------\n"; CO2_AWAIT_LET(auto&amp;&amp; val, p.get_future(), { std::cout &lt;&lt; "got: " &lt;&lt; val &lt;&lt; "\n"; }); std::cout &lt;&lt; "end----------------\n"; } CO2_END ... boost::promise&lt;int&gt; p; auto f = test_future(p); p.set_value(5); f.wait(); ```
Thx 
C99 6.5.15/4 says: &gt; the result is **the value** of the second or third operand This means it is not an lvalue (see 6.3.2.1/1 footnote for clarification that *value* in the C standard means what C++ calls rvalues). This is reinforced by footnote 95: &gt; A conditional expression does not yield an lvalue. A compiler must issue a diagnostic if the result is used as an lvalue (e.g. `&amp;(1 ? a : b)`)
There is only few inheritance because this is a TEMPLATE Library and not a normal Library. Inheritance is not popular currently in C++ and everybody tries to propose a Template solution. However most of the time a inheritance solution is very easy to read whereas templates are awfull to understand, and certainly to debug in few months/years... 
Well, for me a reference is the same as a raw pointer that just cannot be optional :) Concerning passing smart pointer as parameters, I found this nice video by Herb Sutter: https://www.youtube.com/watch?v=xnqTKD8uD64#t=14m48s He explains the problem with passing smart pointers around much better than I could do (He also mentions the facebook problem I was taking about earlier). 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Artificial intelligence (video games)**](https://en.wikipedia.org/wiki/Artificial%20intelligence%20%28video%20games%29): [](#sfw) --- &gt; &gt;In [video games](https://en.wikipedia.org/wiki/Video_game), __artificial intelligence__ is used to generate [intelligent](https://en.wikipedia.org/wiki/Intelligence_(trait\)) behaviors primarily in [non-player characters](https://en.wikipedia.org/wiki/Non-player_character) (NPCs), often [simulating](https://en.wikipedia.org/wiki/Simulating) human-like intelligence. The techniques used typically draw upon existing methods from the field of [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) (AI). However, the term game AI is often used to refer to a broad set of [algorithms](https://en.wikipedia.org/wiki/Algorithm) that also include techniques from [control theory](https://en.wikipedia.org/wiki/Control_theory), [robotics](https://en.wikipedia.org/wiki/Robotics), [computer graphics](https://en.wikipedia.org/wiki/Computer_graphics) and [computer science](https://en.wikipedia.org/wiki/Computer_science) in general. &gt;Since game AI for NPCs is centered on appearance of intelligence and good gameplay within environment restrictions, its approach is very different from that of traditional AI; [workarounds](https://en.wikipedia.org/wiki/Workaround) and cheats are acceptable and, in many cases, the computer abilities must be toned down to give human players a sense of fairness. This, for example, is true in [first-person shooter](https://en.wikipedia.org/wiki/First-person_shooter) games, where NPCs' otherwise perfect aiming would be beyond human skill. &gt;==== &gt;[**Image**](https://i.imgur.com/frzVg2i.png) [^(i)](https://commons.wikimedia.org/wiki/File:Freeciv-2.1.0-beta3-sdl_slack11.0.png) - *In strategy games like Freeciv, the game AI must deal with large amounts of information* --- ^Interesting: [^General ^game ^playing](https://en.wikipedia.org/wiki/General_game_playing) ^| [^Artificial ^intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cp86ejo) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cp86ejo)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
This is also true for C, but in addition to accessing a C-style array like this: array[4] This is also perfectly valid and legal: 4[array] The reason for this is that it simply evaluates to code like this behind the scenes: *(array + 4) Which is equivalent to: *(4 + array)
To me, one of the more surprising (though not necessarily bad) things is function try blocks. So: void function_with_try_block() try { // try block body } catch (...) { // catch block body } Is equivalent to void function_without_try_block() { try{ // try block body } catch (...) { // catch block body } } These examples are from [this dr dobbs article](http://www.drdobbs.com/cpp/understanding-c-function-try-blocks/240168262). This is intended to be used to catch exceptions in class initializer lists, so struct A : public B { A() try : B(), foo(1), bar(2) { // constructor body } catch (...) { // exceptions from the initializer list are caught here // but also rethrown after this block (unless the program is aborted) } private: Foo foo; Bar bar; }; Note that it is impossible to suppress exceptions caught this way, they are automatically rethrown. 
I like the concept of writing troll code with it: assert(map["Hello World!"] == 'e'); //what type is the type of map? assert(map == 1); 
that's evil, i love it
Trigraphs are apparently a non feature from c++17 on, however [digraphs](http://en.cppreference.com/w/cpp/language/operator_alternative) seem to outlive them. The following is perfectly legal C++11/14 and apparently 17. %:include&lt;iostream&gt; int main() &lt;% std::string val&lt;:1:&gt;; val&lt;:0:&gt; = "Hello World"; std::cout&lt;&lt;*val&lt;&lt;std::endl; %&gt; An unrelated WAT can be found with user defined operator &amp;&amp; and operator ||, they cannot short circuit as the build in operators do. enum Nothing{ None = 0 }; bool operator &amp;&amp; ( Nothing , int ){ return false; } None &amp;&amp; printf("This happens!\n"); More WAT, this one from the standard library: [vector&lt;bool&gt;](http://stackoverflow.com/questions/14603395/vectorbooloperator-misbehavior) is specialized and in many small ways does not behave like a vector should. std::vector&lt;bool&gt; v; v.push_back(true); std::cout &lt;&lt; " before: v[0] = " &lt;&lt; v[0] &lt;&lt; '\n'; // Should be a deep-copy (?) auto x = v[0]; x = false; std::cout &lt;&lt; " after: v[0] = " &lt;&lt; v[0] &lt;&lt; '\n'; 
The syntax for constructor arguments in a variable declaration. Specifically how the very same syntax with no arguments (but parentheses) suddenly constitutes a local function declaration. I haven't looked into it in a while but I believe it was roughly like this void foo() { // declare variable of type A calling the constructor // with "world" as a parameter A hello("world"); // declare local function bar with return type B // and no parameters B bar(); } There is of course also the elephant in the room, namely the whole name mangling WTF (why isn't it standardized) that causes C++ code to be extremely hard to use from other languages. The nested template parens parser fuckup comes to mind too, where you can't have closing angle brackets right next to each other or they will be parsed as a bit shift operator. The parser can also produce rather weird error messages if you miss the semicolon after a class definition, a semicolon that is not necessary for C-style functions. I believe the [C++ FQA](http://yosefk.com/c++fqa/) might of interest to you
 std::cout &lt;&lt; L"Hello, world"; prints the string address `0x...`.
 std::vector&lt;::std::string&gt; v; is not valid (thanks to digraphs).
If cppreference can be trusted they fixed that in c++11: &gt; When the parser meets the charater sequence &lt;:: and the subsequent character is neither : nor &gt;, the &lt; is treated as a preprocessor token by itself and not as the first character of the alternative token &lt;:. Thus std::vector&lt;::std::string&gt; won't be wrongly treated as std::vector[:std::string&gt;. 
I have a feeling this is a relic of a time when compilers weren't that smart, and would translate those statements directly to memory access instructions, using different modes. In MIPS for instance, lw $t1,4($t0) Loads the second word of the array at t0 to t1, in immediate addressing mode, which is slightly faster than relative addressing. Anybody knows more about where the syntax came from?
A nice WTF is void_t: http://stackoverflow.com/questions/27687389/how-does-void-t-work 
that's why :)
What is the reason for the user defined logic operators to not short-circuit like the built in ones?
Because it's effectively a function call. So both of the arguments are evaluated before the function is ran.
It pokes a hole in the spacetime continuum.
Nice.
This one is about using non-existent array elements. I've been able to reproduce this on a couple machines and OS's 100% of the time. I used Code::Blocks 10.05 and 13.12 #include &lt;iostream&gt; using namespace std; int main() { int a[100]; a[105]=1; a[106]=2; a[107]=3; cout &lt;&lt; a[105] &lt;&lt; a[106] &lt;&lt; a[107]; return 0; } The output is 123
FYI accessing elements outside the bounds of an array results in [undefined behavior](http://en.wikipedia.org/wiki/Undefined_behavior). It may output 123 on your machine for your particular configuration (debug/release, compiler version, planet alignment, etc.), but you can't rely on that to work correctly all the time.
I don't think you understand what "undefined behavior" means.
Related to the digraphs, there are also Alternative Tokens, which allow you to write things like "and" in place of &amp;&amp;. These are not really WTF. You can, however, use them in a context where you are not doing boolean or bit operations. For example, the following compiles (and I believe it should): void some_function(int and myVar) {} void some_other_function(int bitand myOtherVar) {} Where myVar has type "int&amp;&amp;" and myOtherVar is "int&amp;". 
`std::wcout` should work.
I would love to be able to write int function (...) return *expression*;
it gets funnier on some vector implementation { std::vector&lt;int&gt; v(10); v[-1] = 5; std::cout &lt;&lt; "value: " &lt;&lt; v[-1] &lt;&lt; std::endl; } std::cout &lt;&lt; "out of scope" &lt;&lt; std::endl; Let say that instead of -1 there is some weird calculation of index that is buggy. If You are noob in c++, and You are not familiar with destructors, then You can be preety shocked when You see that Your program crushes on closing brace LOL.
it creates a namespace in which you create another namepace in which you only declare 50 and init sa with it....wait.... no you are right no fucking clue could you solve it?
Sure. The program is equivalent to this: #include &lt;stdio.h&gt; int main() { try { int sa[50]; sa[0] = ~~2; //complement of complement, equivalent to original number printf("%d",sa[0]); } catch (int e) {} }
I know, that's precisely my point: using obscure language mechanics to implement missing language features (this, non-copyable classes, `finally` exception handling blocks...) yields a fair amount of WTF code.
Yes, but that messes up your syntax.
`std::ostream&amp; operator&lt;&lt;` has an overload for pointers of any type not specialized for, and an overload for `const char*`. However, that `L` in front makes it a `const wchar*`, so `operator&lt;&lt;` defaults to the case of any pointer for `std::cout`.
To clarify, it creates a label `http` and then comments out everything after it on the line. Which means from within a C++ program you can `goto http;//reddit.com`
not much of a WTF with syntax highlighting...
&gt; write(j/p+p,i---j,i/i); causes undefined behaviour :( 
One of the IOCCC entries is a program that's valid C, ~~Perl~~ shellscript, and GNU Makefile . 
 eat dinner(fish and chips) { return move(chips); } 
They fixed the nested templates thing in c++11
Usually what makes me go "WTF!?" is the error messages from the compiler. :) While they are not mandated by the standard, the language specification seems to make it very difficult to provide terse and understandable diagnostic messages.
l3l no
Definitely. I've seen this in the next version of C# and it reads really nicely.
Not valid C++. `(const char[]){...}` is a C feature.
I'll call that a success, then! :)
In C++ it would be nice for **constexpr**s or otherwise inline (g/s)etters.
So '`#define else`' makes the `else` statement fire no matter what. `ord('T') == 84`, `ord('*') == 42`, so `x - y == 42` which would fire the '`if`'. I don't know why `x---y` doesn't pre/post decrement anything. Can someone explain that part?
All of the simulations we use in the design of interplanetary spacecraft are written in C++. All of the successful missions we've launched to Mars, Jupiter, Saturn, Venus, Mercury, asteroids, various moons, etc. relied on high-fidelity simulations whose software is all written in C++. How many rovers has Linus Torvalds landed on Mars?
The historical term in the C and C++ standards is "sequence points." For example, `&amp;&amp;` is a sequence point, and so requires that its left hand operand be evaluated before the right hand side. C++11 uses the terms "sequenced-before" and "sequenced-after" to clarify some issues that caused.
First, there's the famous [Hidden Features of C++](http://stackoverflow.com/questions/75538/hidden-features-of-c) question on SO. It contains a lot of what's in the comments I've seen here. There's also http://cppquiz.org, which is very good for some corner cases. In fact, I [submitted one myself](http://cppquiz.org/quiz/question/122). The following code (spoiler) is not ambiguous. It actually prints 2, for reasons seen in that link. typedef long long ll; void foo(unsigned ll) { std::cout &lt;&lt; "1"; } void foo(unsigned long long) { std::cout &lt;&lt; "2"; } int main() { foo(2ull); //not ambiguous; the parameter of (1) is named ll } --- The following is undefined behaviour, not (necessarily) a vector containing two strings ([source](http://stackoverflow.com/questions/24112281/c11-initializer-list-fails-but-only-on-lists-of-length-2)): std::vector&lt;std::string&gt;{{"testing", "123"}}; --- I'm sure a lot of people know this one, but `typedef` can be moved around a bit: int typedef MyType; --- Along the same lines, the following is a valid member function declaration: virtual int inline long constexpr volatile unsigned const long foo() const noexcept final = delete; Not only does it have twelve optional additions to `int foo();`, you can actually move things around. For example, `unsigned long int` and `int long unsigned` are the same. --- Not C++ yet, but assuming this part doesn't change, Concepts will make the following a valid declaration: auto aut0(auto(auto::*aut0)(auto)) -&gt; auto; --- Again, probably more well-known, this is well-defined: int main() { using int_ = int; int_ i; i.~int_(); } 
Using C89 terminology, `i` is updated (by `i--`) and read separately `(i/i)` without an intervening sequence point. The de-facto K&amp;R rules didn't specify any order of evaluation for function arguments either, but as far as I know they were just silent on what expressions like this should do. 
In C++, it's illegal to redefine a keyword when the program uses the standard library.
There is a surprising number of cases where the same code will do different things between C++03 and C++11, see this stackoverflow question for a long long list of them: [Can C++ code be valid in both C++03 and C++11 but do different things?](http://stackoverflow.com/q/23047198/1708801) One of the examples that stood out the most to me was the following: #include &lt;iostream&gt; template&lt;int I&gt; struct X { static int const c = 2; }; template&lt;&gt; struct X&lt;0&gt; { typedef int c; }; template&lt;typename T&gt; struct Y { static int const c = 3; }; static int const c = 4; int main() { std::cout &lt;&lt; (Y&lt;X&lt;1&gt; &gt;::c &gt;::c&gt;::c) &lt;&lt; '\n'; std::cout &lt;&lt; (Y&lt;X&lt; 1&gt;&gt;::c &gt;::c&gt;::c) &lt;&lt; '\n'; } and the result in C++03 is: 0 3 and in C++11: 0 0 I had included this example in my answer to the question, I originally found the example [here](http://dev.krzaq.cc/right-angle-brackets-and-backwards-compatibility/).
&gt; and for confussion A confused confession?
Oh, I guess you know by now that I'm not great with C++. For some reason I was thinking `z` should be affected by that. I see now that `x` is decremented after the assignment. I wasn't sure how it would be parsed either, so thanks for that. So this isn't really a wtf for C++, but it would be for the developer.
You're on Reddit? Hi! I, too, had an answer on that question.
No, this is the very _definition_ of the bracket operator.
Could someone breakdown this code and explain how each part works?
std::wcout
Something I would call weird -- you can overload the comma operator, ie, `operator,`. It can be useful in constructing DSLs within C++ or (if you're stuck in a C++98 world) enabling things like [boost/assign](http://www.boost.org/doc/libs/1_57_0/libs/assign/doc/index.html), but one could imagine doing some truly heinous / strange things with an overloaded `operator,`... 
What is the rationale for that?
There's nothing to fix. It makes sense to me. You're really just defining a function using a symbol that's supported by the language. If you wanted to overload an operator for conditional statements, then you should be overloading `operator bool()`. As I said, it's really just a function call so you could even overload &amp;&amp; like this: void operator &amp;&amp;(int a, int b) { cout &lt;&lt; a + b; } (notice the void return type). And then just do: int main() { int a = 1, b = 2; a &amp;&amp; b; } As you can imagine, this program will print `3`. Short-circuiting this statement makes no sense. That being said, the compiler is free to perform the shortcircuit optimization (and it probably does) on simple boolean functions if evaluating the right-hand argument has no side-effects. The example from josefx cannot 'shortcircuit' because printf has a side-effect.
Tone really doesn't come across well on Reddit.
Whiskey. 
Where I come from we call garbage collector an operating system. 
This case was fixed but in the end it comes down to the maximal munch principle and each case has to have an exception carved out for it in the standard. Two other cases `&gt;=` and `&gt;&gt;=` have not been fixed and were actually noted in the proposal that fixed `&gt;&gt;`. You can see all the gory details in [my stackoverflow answer here](http://stackoverflow.com/a/28354898/1708801).
Those aren't assemblers. What are you on about?
If the member initialisers don't complete successfully, you don't have a usable object, so you cannot let its constructor complete successfully either.
Excellent, one step closer to having an actual C++11 compiler on Windows. The release states that copy constructors are not invoked within the runtime. Does that mean that clang invokes any copy constructors at the catch site?
Actually, even most compilers after C++ were mostly/partly written with it.
At some point it will just be easier for Microsoft to maintain its own fork of clang just like Apple does.
I have a feeling you're not one for jokes.
I'm totally using and for rvalue references from now on.
This will make me both very happy and very sad. Very happy because it means finally a real compiler that I don't have to shell out $$ for on Windows C++. Also it means the chances of actually being able to cross compile from Linux and succeding are much higher. Very sad due to things that have already been mentioned (and the reason why GCC never seperated the parser and optimizer).
Why do you have to shell out $$ for C++ on windows? I switched from mingw32 to msvc2012 x64 a few years ago, mostly because at the time ming64 was not production ready, and it was smooth sailing. I never paid a dime for Microsoft branded development tools. I only write cross-platform code with it using Qt's libraries. All code i wrote the last few years can be trivially ported to linux or OS X.
Intel compiler is expensive. MSVC is fundimentally broken, and has been for many years. Mingw has never been ready for primetime. Cygwin has too much overhead. Ask this: Why are people still building 32-bit applications?
In GCC 5 it is :)
Embarcadero has C++11 support
Embarcadero uses clang, so it has the same limitations on Windows that clang does.
Not exactly the same. For example, it implements SEH.
I think people would be very happy if Microsoft developed a competing compiler to that of clang and GCC. The problem is that MSVC isn't one bit competitive with either of them.
&gt; Ask this: Why are people still building 32-bit applications? 32-bit Win7 has still &gt;10% marketshare, and even Win10 is available as 32-bit. 
I expect something like that to happen quite soon. Maybe not the next release of VS probably the one after. VS2015 will already support LLVM/Clang for Android development so we are heading in the right direction :) Also with MS making VS Community free it makes more sense for them to work with a community compiler and just maintain their own SDKs and tools. People pay for Visual Studio not for the MSVC compiler. It makes sense, to me at least, to work on LLVM/Clang than to maintain their own compiler just for Windows. 
Exactly. Why? None of the processors that are running Win7 are 32-bit processors. I understand why Win10 has a 32-bit version as it's the same OS (nominally) that's running on windows phones and those are still using 32-bit processors for the moment. Even that's going to change with the next two generations of phones however. Why is Windows stuck in 32-bit land? All the other OS's have gone native 64-bit with all system libraries and the vast majority of user applicaitons all running in 64-bit. Only on Windoes, where Visual Studio defaults to 32-bit and just about all your middleware are still in 32-bit land, do you still see new software being written in 32-bit when it's being executed on a 64-bit processor. (note - yes, embedded and mobile are still &lt; 64-bit and that's a different conversation).
Unlikely. See .NET. More likely they'll replace NMake with Clang/LLVM and turn Visual Studio into a purely graphical IDE rather than an IDE with a dedicated embedded compiler.
Depends entirely on your use case. Last time I tried (about 6 months ago) I rammed headlong into the 64-bit vs. 32-bit issue. Also any windowing code is going to pretty drastically change unless whatever you're porting was intelligent about things (using SDL or Qt or something). Managing dependencies under Windows is a real pain. As is generating solutions. CMake is your best bet for that but even that is no where near as good under Windows as it is under Linux. Case sensitivity is a real issue. Fortunately you're going from Linux to Windows so that won't bite you but going the other way it's really annoying at best. Watch out for your paths. '\' vs '/'. Again Windows doesn't much care but Linux will if you need to backport any of your changes. 
Out of curiousity what's the delta on speed just from the 32-bit and 64-bit compiles? Also I assume this is Windows?
&gt; 5-10% doesn't seem like it's really worth it for what you're sacrificing though. What am I sacrificing? Aside from some vague sense of purity that everything should be 64-bit it costs nothing to me or my users. In fact I also get greater compatibility in addition to the perf gains. If I did expect to have large data sets I'd go 64-bit. My code is 64-bit clean so I'd just need a recompile. Linux is actually worse in this regard. They do not have a good compatibility story between 32 and 64-bit. So having 32-bit apps on a 64-bit distro while possible is usually an exercise in frustration. I don't want to read too much into it, but I suspect this is why you feel having everything be 64-bit is so important.
Simple. Backward compatibility. Most applications on Windows are distributed as 32-bit, and source code isn't available. If you are using a 32-bit library, it is a pain in the arse to access from 64-bit code. Many 3rd party devices, some in the thousands of pounds price range, still only have 32-bit drivers. There are a number of similar issues, all determined by the fact that there are millions of Windows PCs, and MS are quite good at moving the market along in incremental steps (technically at least, the UI debacle of Windows 8 is a different matter). Over time this will improve, but its a fundamentally different model than Linux, with fundamentally different constraints imposed by the market.
Is this VC12 or an earlier version? If 12 which specific features are you missing? Template aliases are the only one I really miss.
Oh wow, I would definitely need to see some kind of justification before believing that. Both POGO and LTO are areas that I found clang excels at.
I've never found it that hard to switch back and forth between the two, and everything from MS is available in either flavour. In VS it's just 2-3 mouse clicks to setup a 64-bit build. Are you relying on third party DLLs that are only available as 32-bit binaries?
In terms of generated code, gcc &amp; clang might be comparable for LTO. In terms of runtime (i.e. memory &amp; CPU time), gcc is drastically ahead in terms of generating LTO'ed code. I don't know where MSVC is, but I think it's ahead too. MSVC has been far ahead in terms of the quality of PGO optimized code (that's why Firefox on windows was so much faster for a long time). I don't have a good sense of what the state of the world is right now.
&gt; Are you relying on third party DLLs that are only available as 32-bit binaries? Some of this. Some of trying to compile them from source under Windows. What is trivial in a Linux environment is like pulling teeth in Windows.
I love jokes! But no one jokes about C++ ಠ_ಠ. Just kidding, I liked the presentation Scott Meyers gave at DConf (see the other top-level comment).
My experience with LTO and PGO in clang is that they *significantly* reduce the size of the executable, but have pretty minor performance benefits, while with MSVC they also improve performance. I don't think it really makes sense to compare individual features between compilers, though. I don't want to use the compiler with the better LTO; I want to use the compiler that produces better binaries.
this looks really interesting, after time with Rust where you do notice its' better type inference. (Vec&lt;_&gt; etc..)
Have you played with the sanitizers yet? They're quite nice, and a looot faster than Valgrind. The only downside is that you can't use them on compiled binaries.
&gt; In embedded space, for example, I doubt any commercial C++ compiler outside the gcc/clang forks already does C++11. What else is there, EDG?
MinGW-w64 has C++11 since it's basically just a GCC port.
lol, I saw the top level comment! :D I'll check out that DConf presentation now, thanks! 
&gt; I know there are smart people working on MSVC, but it's clearly not enough. The darn thing is quite lacking when it comes to standard compliance and it crashed on me several times on relatively trivial code. You make it sound really horrible. Were you using a beta of the compiler? Because that's the only time I've ever managed to crash the compiler. Also, the MSVC team is working far better and faster than it did in the past. Granted, it can still be improved, but I'm liking the changes.
vc12 does support alias templates.
Aren't alias templates in VC12 (vs2013)? According to [this](https://msdn.microsoft.com/en-us/library/hh567368.aspx) they are supported. (I am on 11 or 2012) which yeah I miss them also. 
a) They didn't used to be. b) Intel's compiler is quite expensive.
Since VS2010, they had a pretty big lead over GCC (but lagged behind Clang) in the implementation of the C++11 standard library. GCC seems to have caught up in version 5.0 though.
What makes ICC the only reasonably decent compiler for Windows? 
Personally I think that at least with Clang and GCC they are quite good these days most of the time. The important thing is to not get shocked by 100 lines of output before looking at them. Most of the time it turns out that there is just a short stack-trace (which can be super helpfull) followed by the actual error (usually one, often quite readable, line), followed by a list of functions that are part of the overload-set but couldn't be used and why. If somebody complains about error-messages while `g++ [...] 2&gt;&amp;1 | grep error` produces a short and to the point message, the problem is not with GCC or C++, it's with that persons reading-ability.
&gt; This second class does not override any function in the base class. That code-example is way to complicated, the same is true for this: struct base{ virtual void fun(); }; struct derived{ virtual void fun() const; }; The problem is that `const` is part of the signature and therefore you can overload based on it. Once you understand that, it becomes obvious that this is really the correct behavior in this case.
Ironically, supporting XP is holding us back from delivering conformance as fast as possible (especially in multithreading).
I guess you could delete the default constructor and make a const version. The result would be forced immutable classes. Barring escape mechanisms like const_cast. I'm a perf guy so I can't say I'm fond of this idea. Immutable classes lead to millions of pointless allocations more often than not.
When you encounter an Internal Compiler Error, you should file a bug report through Microsoft Connect, with a preprocessed repro attached. In general, only the compiler devs can investigate ICEs (because they can debug into the compiler). If you don't report what you're seeing, it's less likely to be fixed (it usually takes several subtle things to break the compiler's brain, and other people aren't very likely to be doing exactly what you're doing to trigger the problem).
Does Vista and greater offers better threading primitive at the kernel level ?
ICC is the best at it from my experience.
Feature request while we are at it: Could MSVC be released in a standalone manner ? We may not want to install C++ along every .NET languages and every tool Microsoft ever created. (VS 2013 comes in a several gigabytes installer, the VC++ package does not even exist anymore) The way the CTP is released is far more convenient, especially if you are trying to setup a build farm, were you don't need graphical tools and you like to keep the impact on the overall system minimal. 
Thanks, I had forgotten it's exact name and couldn't find it. I only remembered hearing about such a tool.
I doubt all of them use EDG. Does for example Green Hills use them? Most of the chip companies like e.g. TI, used to have their own in-house compilers. Are there already C++11 certified compilers for embedded use, according to the required safety regulations? This recent thread shows how the embedded vendors are like, http://www.reddit.com/r/cpp/comments/2y46yo/is_c_really_that_bad/cp6csgy 
Too bad Embarcadero doesn't have a free version of their C++11 compiler. A free version would gain more usage, more bugreports, and potentially new customers.
&gt; C is nimble in the sense that it can go places other languages -- even C++ -- can't, due to its very minimal runtime environment and the fact that it has compilers everywhere. well... not really, C is almost perfect subset of C++. for good or bad :)
well this is actaully C and will be interprested as C, not C++. here is the c++ alt: #include &lt;iostream&gt; int main () { std::cout &lt;&lt; std::endl; return 0; } 
MSVC is terrible at C !!! Reason being, MS don't need C. Windows, unlike Linux, is C++
right.... all those unproven are always better ! :P
Compute shaders are more directly integrated with the D3D pipeline, so if you just want to do something relatively simple that's probably easier. However yes C++ AMP is nicer and more powerful to code in, so if that factor outweighs the extra glue you'll need to read/write D3D resource buffers then that would be a better choice. Chapter 11 of the C++ AMP book covers graphics interop, although the API has been updated since that was written. Remember D3D12 is on it's way, so check that out also.
FWIW, OP is not the author. The link is to /u/stl's website.
That text is a bit older &gt; I will assume that your computer runs Windows XP. This is the most modern Windows operating system
Also, check out Vulkan
Why can't you drop support for XP? Is there a planned release for when you can? Will/could there be options for folks to get the conformance they want by hitting a checkbox to drop XP support?
When you cross C++11 support with Windows support you get only three options: ICC, GCC, LLVM GCC is only through Cygwin or MinGW - both options already noted as not optimal. LLVM isn't quite there yet since that was what this whole thread started with. That leaves ICC. 
Well I suppose that was my point, I know XP was dropped by Microsoft for support reasons back then, so why does VS still support it? It's not like the previous versions don't exist anymore. I don't even have a Vista install to test on.
why would that ever be useful I guess you can pass them into overloaded functions to get different results
&gt;Particularly since const-ness can be cast away later. Possibly immediately. This can be said of all `const` annotations, but I think they are still useful. &gt;I've never needed construction logic that's unique only because the object is going to be const. I've only run into it once or twice for unique construction logic. However, creating `const` only classes (deleted default constructors) could be very useful.
Immutable classes are one concept that C++ doesn't currently have an easy way to express, but has definite uses. I'm struggling with coming up with simple examples where the construction logic for a `const` class would differ from a non-`const` class. I'll have to think about it more.
Argh, this page is so old. I've been planning to nuke it (and a whole bunch of other stuff), but I haven't gotten around to it yet.
Having "target Vista+" or "target 7+" options would be Modes, with all of the problems that modes cause (my motto is "modes are evil"). For example, object files and static libraries compiled with such modes would not be able to be mixed with those targeting XP. And it wouldn't solve the maintenance burden (which exists as long as there is *any* mode targeting XP). We actually do have such modes, but only in a form that doesn't lead to mix-and-match nightmares. For example, when the CRT/STL is built for the ARM platform, we can assume we're targeting Win8+, so all of our runtime logic for dealing with XP/Vista/7 is preprocessed away.
It's because we worked with Dinkumware to implement and ship TR1 (the first and only time we've shipped new Standard Library features in a Service Pack). This was the first major thing I worked on after joining VC.
I'm not familiar with modes, where can I learn more about them? Is ABI breakage the issue?
A mode is anything that would cause compiled translation units to be incompatible - i.e. anything that affects ABI. Few people understand exactly what they're getting into when they create a mode, which is why they tend to proliferate. I'm not aware of any good articles on the issue.
Makes sense! Sorry for asking for something incredibly shortsighted then, and thanks for the heads-up. 
Don't all these problems already exist with the XP/non-XP CRT? Or is that going away with the CRT rework in 14?
I thought there was a separate CRT because I remembered having to ship a different one when I switched to vc110_xp... but after double-checking it turns out my memory was just completely wrong and there were no changes to what CRT was being shipped until the update to VS 2013, and there aren't two versions at all.
No commitments at this point but this an area we are actively looking at. Totally hear you that the VS installer is a less than ideal delivery system for people who just want the compiler toolset.
A code sample would go a long way. Hard to help with just a vague description, though maybe someone can still provide insight. Hope you are running a single threaded program?
I'm sorry, should i repost it in /r/cpp_questions or keep it here?
To be fair, their main problem is supporting newer C standards (which they are slowly getting better). Back in 1999 Visual C++ 6.0 seemed like a decent C compiler, at least to my younger self. It still is, if you are only interested in C89
No, it's C++. Where you're confused is that C++ has an alternate way to do I/O beyond `printf`, with advantages and disadvantages. What a lot of people forget is that one of the most beautiful aspects of C++ is that it retained C as a subset, with minor exceptions. And *there's nothing wrong* with using the C functions and features over the C++ equivalent, when you want, and it's still C++.
Move semantics do not solve this problem. You can not wrote a move constructor for an immutable object as a move operation is a form of mutation.
We need to do some refactoring before we can get this one. For our codebase, this is one is tough to implement. We'll get it, but it will likely be the last C++11 feature we knock off the list. Based on what I know now, you will see full NSDMI and constexpr11, then attributes, then expression sfinae (from c++11, but we are hitting off 14 and 1y stuff as we go as well). 
Repost it. This will get deleted.
I was speaking in the context of constructors (where the internal state is marked const instead of the instance of the object itself), but it sounds like you're talking about making copies of an immutable object... but since the object is immutable, *you don't need to make copies*. Just use const references/pointers. And if you need to alter values, you do that in the copy constructor -- you're not doing more work; you've just moved where that work is done.
The statement was in reference to immutable objects resulting in a great deal of unnecessary allocations to which you replied that move constructors provided a solution. Move constructors do not solve this problem since they can not be used on an immutable object. Furthermore when someone talks about making copies of an immutable object, it is due to the fact that performing various operations on such an object requires making a copy of many of that object's components. Consider an immutable linked list; inserting a node into it requires making a copy of the entire list. Finally a conforming copy constructor should not be modifying values or doing anything other than a strict copy. Deviating from that will result in issues related to the fact that the C++ standard allows for the copy constructor to be elided or ignored in many situations.
Watching this, I'm kind of amazed about how much I would do differently due to C++11/14.
&gt;Move semantics help with populating non-trivial const data members. You can not call a move constructor on const data, you can only call a copy constructor. This is enforced by the compiler and you can try it yourself, the object's copy constructor will get called rather than its move constructor. For objects with no copy constructor, a compiler error will be issued. &gt;And inserting something into a const list? The list is const, you don't insert anything into it because it's const. It is perfectly valid, and common, to insert into an immutable linked list. Such an operation constructs a new list, inserts the object as directed, and then returns that list. As the poster originally stated, operating on immutable data structures results in a great deal of allocations precisely because of all the copies involved when operating on such a data structure. Your suggestion that somehow a move constructor can be used instead of making copies is invalid, move constructors do not do anything to alleviate the issue.
Not at all. There's no information about where the exception originated from so you wouldn't know which members to "roll back", and their destructors are guaranteed to have been called anyway. There's a nice write up by Herb Sutter [here](http://www.gotw.ca/gotw/066.htm). &gt; Constructor function-try-block handlers have only one purpose -- to translate an exception. (And maybe to do logging or some other side effects.) They are not useful for any other purpose.
You have a good point - and honestly I'm at the edge of my personal knowledge here. I thought ICC had a lot better C++11 support but looking at it I find that it doesn't. I was tripped up by the marketing page (https://software.intel.com/en-us/articles/c0x-features-supported-by-intel-c-compiler) which is notably missing most of the things that ICC doesn't do and has a 'Linux/OSX' caveat on a bunch. The problem is that I work in Linux using GCC with come occational Clang use. ICC is only used rarely and only on select projects (due to expense) and it covers the subset of C++11 that we use. MSVC doesn't and cross compiling is a nightmare at best.
So far too many issues with the x64 build. I haven't looked all that recently however as my time tends to be spent on researching compilers only once a year or so.
[How about Clang](http://coliru.stacked-crooked.com/a/8149e57a9f36d6e7)?
Yep. If you know what machine learning task you want to accomplish, I found their documentation to be pretty dang thorough.
http://www.reddit.com/r/cpp/comments/2y46yo/is_c_really_that_bad/cp6uw4i
The way GCC does it means less registers have to be copied to the stack and back around function calls. Someone did tests pretty recently (a couple years ago) and it's still a significant performance gain. Of course, if you were creating your own compiler, you could create a "backwards" calling convention to get obvious semantics *and* less register swapping.
Given the code `f(g(), h())`, GCC will evaluate `h` before `g`, and clang will evaluate `g` before `h`. Remember that `x() &lt;&lt; y() &lt;&lt; z()` is really `operator&lt;&lt;(operator&lt;&lt;(x(), y()), z())`.
Until then... I'm sticking with OpenCL.
Last time I tried it the problem was the lack of bigobj support.
As this has been answered i will not repost it, any mods can safely delete this
Thanks everybody for pointing out the right direction, i will look more into this matter and fix my code.
Probably their agenda includes pushing for an API that maps well to their upcoming manycore architecture (MIC).
The question is, do you want to do c++ or are you interested in doing other languages. I did a phd in c++ parallel programming then went straight into Android programming and project management. If you wana stick with c++ there are plenty of non HPC jobs around. 
The "correct" answer is "it depends". Is it supported on your target platforms? Will you have to port it to something else in the coming years? Will you interact with the graphics pipeline? If so you might want to consider using compute. But keep a C++ implementation around. Also: you **will** need to think differently since good performant C++ code does not automatically translate to good performant compute code (even though AMP). C++AMP, OpenCL, Cuda, DirectCompute, OpenGL compute shaders are your probable choice, and there is no correct answer unless you give a lot more information about the project you want to do.
Ugh, this is code is of a rather bad style because it uses a lot of C idioms. A "proper" C++ program would use `std::string` and possibly `std::stringstream` for conversions, so the last 3 of your questions would be non-issues. I suggest that you get another book, e.g., Accelerated C++. EDIT: This page http://isocpp.org/get-started recommends C++ Primer.
I'm a c++ guy, but please tell me this is just (bad) humor; 'why not java' was my lol-climax, looks like a 5 y.o. argument: my toy is great, your toy is crap sample quote: "why c++: C++ ... is a multiparadigm language" "Why Not Java: Alex Stepanov can explain it better than I can: It keeps all the stuff that I never use in C++ - inheritance, virtuals - OO gook - and removes the stuff that I find useful" very coherent, indeed 
Really thank you for the time spent to reply. I am not getting the `const char * prompt();` thing though. We've already set our response as a static variable, so its value isn't lost when function exits. What's the point of calling a pointer to an immutable character ?
The point of returning (not calling) a pointer to const char is that it's saying that the thing being pointed to may only be read, not modified. That implies that this is a private buffer and that the only function allowed to write to it is the `prompt()` function. This code is just flat out terrible. There is virtually no C++ here, this is all C with the exception of `nullptr`^([1]) and the using-directive. You should not be using things like `fgets()` or arrays of char in C++. If a tutorial is purporting to teach you C++, it's doing you a huge disservice and you should stop using it immediately and get a good book on C++. [1] And `nullptr` isn't even used consistently — the code also uses `NULL`. Just dreadful. 
My personal impression is that the answer-quality on /r/cpp_questions is much higher though. It may take a little longer to get an answer there, but you rarely see things like unopposed recommendations of bad style and occasionally get further information on how you can improve your code. And it is not like you don't get an answer there. If we can comprehend what is wanted, there are rarely ever unanswered posts. &gt; plenty of C++ experts there. Considering the answers there I get the impression that there are quite a few people who know some C++, but that the other-beginners-to-experts-ratio is much less favorable.
No it doesn't. Calling a chain of operator&lt;&lt;'s is not like a function call with N args - it's still a binary function. The chaining depends on the associativity of op&lt;&lt; which is well-defined as left-to-right, ie: (((Log::nrm() &lt;&lt; "Whoa! You picked ") &lt;&lt; num) &lt;&lt; "!") &lt;&lt; Log::end(); Or put another way, what you have effectively is: auto L1 = operator&lt;&lt;(Log::nrm(), "Whoa! You picked "); auto L2 = operator&lt;&lt;(L1, num); auto L3 = operator&lt;&lt;(L2, "!"); auto L4 = operator&lt;&lt;(L3, Log::end()); Which is most likely just fine - we don't have two order-dependent function calls as args, and the args are (obviously) all evaluated before the operator fn() itself. You _could_ screw it up, but you'd have to try very hard, like having implicit user-defined conversions that affect global state in an order-dependent manner. So while the other commenters are correct that the order of evaluation of function arguments is unspecified, this probably isn't relevant here. 
That is the way most tutorials approach teaching C++ and it is a very bad way. What I basically does is: here are all the basics on how to do stuff. Now forget everything again and look how much better C++ is.
I wish I knew it before I paid. 
Just something to think about as an aside... once you're out "in the field" I'd have to think it's rare for a developer to know *only* one language, or one specialization in one language. I feel like that's the kind of thing that makes you valuable and desirable - having a nice set of complimentary skills, rather than being a really one trick pony.
Because he's god and god's word is divine. /s
Language debates have been the same since time immemorial. People plug the language they like and bash the language they don't; and nobody changes their mind. "Rei" owns the thread IMHO but I'm sure anti-C++ people will feel he got owned by the guy he was replying to, etc. 
Not sure what exactly would qualify as "skill", but something I oh so very often see lacking is knowledge in the used toolchain, i.e. how a compiler works, what the linker does, what difference between shared and static libraries are, how to link against different libraries, how to build different libraries, etc. In my opinion you can't call yourself a C++ programmer until you're able to easily build and link different libraries. Because even though it's not part of the "standard", in real life you can't avoid libraries.
If you don't trust him, then you should at least trust the inventor of C++, Bjarne Stroustrup. There was an article written by him somewhere, where he explained how C++ was intentionally designed to be a pain in the ass (those are my words, not his, but his were along the line). I couldn't find the article, though. Maybe someone else can. EDIT: I found this, but I don't think it's the same article I saw long time ago: http://harmful.cat-v.org/software/c++/I_did_it_for_you_all
Programmers: Use the language that will most easily get you to your goal. If you are proficient in C, use C. If you are proficient in C++, use that. If you want to use a combination of Lua, C, Haskell, Scala, and Python, do that. If it get's your product/project done, who cares how it was written? For christ's sake, these discussions on "which language is better" accomplish nothing more than irritating people.
You do realize that this is a joke right? It's been going around for years, this is not really an interview with Stroustrup, and was written as a joke. I've seen many people dig it up as a serious reference over the years despite how obviously fake it is.
He basically rants that cpp libraries are inefficient and introducing them to a system inflicts a disease. I don't think any language can be called horrible because it is suitable for misuse. Any C language can be implemented as structured Cpp with same efficiency if you know how to do it. Knowing how to do it though is not as straight forward as C is all, but this is a community issue which he referred as substandard programmers. I also really don't understand why he goes on to generalize the developers using the language. Seems egoistic.
Because the kernel is famous and, as a result, he is as well. People look at big successful software projects and say "I want my project to be big and successful, how do I do it?". As a result, they look towards owners/primary contributors/creators of those projects and devore everything the creator says as being an absolute truth. The problem? Just because software is successful, doesn't mean it is well written or that the opinions of the creators are correct. It just means that it is used by a lot of people. It is easier to appeal to authority than it is to actually think for yourself and come up with your own thoughts and ideas.
Linus is an application developer. Or do you think "git" wrote itself? 
Keep in mind that Linus' rant is from 2007. Personally, I consider c++11 to be an almost new language.
"git" is a set of utilities designed to do something very specific and limited in scope. I don't see linus writing things like user interfaces or implementing regression, working with image processing, intelligent robust statistics, etc. Physical modelling seems far out of his area of expertise.
The people that need to interface with it and maintain it care. So at the very least it should be commented and documented appropriately to explain how it works.
If you're saying that the *project* or *product* needs to be commented and documented, I agree with you. However, this is an operational issue, not a language issue. If you can write clean, maintainable C++/Haskell/Python/etc... and so can your coworkers, use the one that suits best. That is my point.
Honestly I think the only reason for that is for a lot of pieces of software (especially dealing with hardware or because of legacy/dependencies), C/C++ are your only options unless you want to program assembly. 
Honestly, the worst part about C++ is that it still requires header files (lets have a ton of code duplicated in a separate file -- what could possible go wrong?), and even more so how libraries are handled. I think I probably spend 10% of my time in C++ actually writing and debugging code, and the other 90% of the time just trying to freaking get things compiled and linked correctly.
Or maybe for the performance of not having to deal with a garbage collector and VM?
You could also read what [Carmack has to say about C++](http://www.phoronix.com/scan.php?page=news_item&amp;px=MTI3NDQ).
I know... I also believe Edward Snowden. I'll go put on my tin foil hat now.
Got to disagree there. His rants are one of the most personally biased and opinionated out there. Just look through wikiquote, he even says so himself on several occasions. Then again even though I often don't agree with his opinions I got to respect him for always saying exactly what he thinks. Many people can't just go ranting like Linus as it would reflect badly for their work. But Linus can and surely does say his opinion no matter what others think about it.
It's just so obvious that it's fake once you know 1 or 2 of his interviews or conference talks he gives. There was a great Panel about systems programming languages specifically and language design generally with him, guys from Go, Rust and D and it makes it just so obvious that he'd never talk like this.
This a thousand times. Having learned C++ as my first language I often can't understand why people make it out to be rocket science. Yes, it got it's quirks and certainly isn't one of the easiest languages but it is far from what people make it look like. Using libraries is always a pain though. So many different build systems, libraries using the build systems in different ways... You just always struggle anew. I hope that changes though with the upcoming Modules proposal and dependency manager, package repository even though we're still ways off.
That's not correct at all. &gt; So while the other commenters are correct that the order of evaluation of function arguments is unspecified, this probably isn't relevant here. Um... Yes it is. Your code is very different from the one-liner example. In OP's example, Log::end() gets called before Log::nrm(), _due_ to the order of the evaluation of the arguments. To put it in code: Log::nrm() &lt;&lt; "Test" &lt;&lt; Log::end(); This gets translated to: operator&lt;&lt;( operator&lt;&lt;(Log::nrm(), "Test"), Log::end()); Which, as you can see, will call either Log::nrm() or Log::end() first depending on the unspecified order of evaluation of function arguments. This is clearly _not_ the same as: auto L1 = operator&lt;&lt;(Log::nrm(), "Test"); operator&lt;&lt;(L1, Log::end()); As then Log::nrm() would be evaluated first.
That's completely application dependent. On more than a few benchmarks Java outperforms C/C++ due to things like just in time compilation. While early versions of Java did have some serious GC performance issues, it's not really the case so much anymore.
Do you use C++11 at work? We're always porting and updating old code that no one is willing to try changing their compiler settings to support C++11 (just in case they break something) let alone actually code in it.
I know of companies using machining tools costing hundreds of thousands who are stuck with xp due to driver incompatibilities, with no updates in sight from vendors. Its simply too much cost for them to change.
Here you have the reference from Bjarne himself: http://www.stroustrup.com/bs_faq.html#IEEE
When people say C++ is hard I imagine it is because they are still groveling about in gdb on the command line. When you work with Visual Studio all day it is easy to be baffled by the "too hard" comments (and form a suitably dim view of the complainants). On balance, this must be it. I'm sure I would have a much less positive view on C++ without access to the Visual Studio debugger.
Yup. Using C++11. It's really about how you manage change. Either you let lots of incremental changes occur all the time, thereby ensuring the real fragile pain points in your code become robust, or you let things ossify and encourage brittle code that falls apart when even the subtlest change occurs.
Sometimes gdb is the only debugger available, unless you want to pay thousands of dollars. See: ARM Cortex-M devices.
some RTOS' don't support anything else other than gdb too
Sure, I get that. I'm just saying this could actually be the reason for all the hostility to C++ in many cases.
RTOS integration is pretty cool, but in the worst case you can get 99% of the same information by just dumping the task control blocks. I never got the FreeRTOS integration working in IAR's debugger, so I just bring up the TCBs in the watch window.
After participating in C vs C++ flamewars for years, I'm pretty sure it's due to all the stupid crap that C++ lets you do. This means that people end up doing them. Or they don't understand how some feature works (especially when used in conjunction with other language features), and now there's a problem they can't debug. C++ is notorious for its dark corners, caveats, gotchas, and general inconsistencies. In many cases, the code looks right, it compiles, then does something completely different than what you thought it would do. Because some clause buried down 30 sections into chapter 20 of the standard says, "but when X is true and Y is false, this is the behaviour".
A convenient thing about the header file/implementation split is that it mentally help with the Interface vs Implementation separation. The interface and documentation of the interface belongs in this file here and the actual implementation belongs in this other file (or files if both inline and compiled).
i didn't know qt was written only in 'c'.
&gt; Personally, I consider c++11 to be an almost new language I don't think C++11 or C++17 improves on the sort of issues Linus' rant is about.
I forgot what I was using this once but `info threads` returned nothing. Shit. 
Flames aside (seriously), the times I have found this to be true have been few and the majority were in the earlier part of my career. These are the typical claims that leave me confused. Have I just been terribly lucky in avoiding horrible problems? I've certainly worked at places where the code base was a horror and I've also experienced working with people that know just enough to be dangerous, but when it comes to writing new code I just reach for the tools that look like they'll get the job done with the minimum of fuss. I guess I also apply a pretty harsh filter when it comes to third party libraries too.
Indeed. And I must ask myself why his [subsurface project](https://github.com/torvalds/subsurface) (started 4 years after his famous rant) uses so much C++. Makes you wonder.
Possibly true, but if your requirements didnt call for that extra performance, then every moment you spent on memory management, language complications, and ensuring portability was wasted. It's like saying you need to build all your chairs out of titanium because it's strong. It's just not an intelligent way to select a technology. You analyze your needs, develop requirements, select appropraite tools, and measure your progress. It's engineering 101. 
I never said every program ever needs to be written as high performance as possible. 
Iirc because of Qt.
C++ has that only if the programmer wrote them, which turns any argument against them into "it hurts if I poke myself with a stick". But dig this: from perspective of C++, C has invisible function calls, too: Struct1 = struct2; // look ma, operator= Rettype f(type param); // look ma, copy constructor! The thing is: these invisible function calls sure do come in handy. One can be an ignoramus or know how to use them.
(((((1(0/((((((((((10)))()()((((())))
Any language needs tooling. There's GUI frontends to gdb. VisualStudio is great, but it is far from only IDE that speaksC++, and people manage without it just fine.
Everything Linus complained about is still true. His point was that C++ drives you to use ever more clever software inventions to solve problems and that many developers dont have the maturity to use those features judiciously, and that the result makes the overall solution more brittle and harder to manage. I don't think anyone, including Linus, can suggest, let alone prove, that C++ itself is not capable of being used to express a nice, efficient, clean program. It certain can. It's just really easy to mess up or misuse.
Writing C++ isnt hard. Depending on other people to write good C++ for you is.
I'd do a MSc any day. I personally think it's absolutely worth it. If you find one with a major in something that interests you, even better. In my opinion, you'll have much better job chances, and also a much higher chance to get something that interests you and not "web dev".
&gt; Universities are very corrupt. Can you elaborate on that? Corrupt in what respect?
List one free, sane and feature rich cross platform UI framework for C. They tried GTK which at least at the time of subsurfaces Qt migration had both a hostile community and zero interest in actually maintaining their windows port.
The C++ committee is extremely averse to making breaking changes, almost to a fault. Good c++03 code should compile file in a c++11/14 compiler.
I can't. I guess that shows that C++ is good for some things.
I think the kernel has efficient implementations for kernel developers to use. The limitations of the C standard library do not apply.
Well, it was originally written using GTK+/C and then later ported to QT/C++ for the reasons mentioned here: [https://plus.google.com/+DirkHohndel/posts/MwiTc3cHKgi](https://plus.google.com/+DirkHohndel/posts/MwiTc3cHKgi) The issue was not with the language, but rather the UI library.
It's more a statement than a rant. Carmack was a pure C developer, and he began enjoying C++ while working on Doom3. [He's now definitely a believer that C++ is the way to go for big project](http://fabiensanglard.net/doom3/interviews.php). Linus' fear is understandable, it's easy to make shitty code, but I'd say it's also possible to do just that in C, it's not inherent to the language.
Too bad there wasn't a good C GUI library that could meet their needs.
&gt; Re:No (Score:5, Insightful) &gt; by boristhespider (1678416) on Tuesday March 10, 2015 @05:16PM (#49228333) &gt; &gt; A clickbait article about a flamebait rant, commented on by trolls. &gt; &gt; God bless Slashdot
But don't you see, with C you can craft your own, bespoke linked list implementation each time you need one. (I am only halfway serious, something rather similar was given to me as a pro once)
Wow. Yeah, I've seen some doozies on that site.
That was sarcasm. I enjoy C++. I really do find it funny that someone who ranted so much about C++ ended up deciding to use C++. There's obviously good reason for it; a C++-based library fit the need where no C library that existed could. The application is useful and Linus is certainly no dummy. I'm glad for his contribution in both Linux and subsurface. I just think he needs to be careful with rants.
He's loud. 
I'm sorry you feel this way. I've seen miracles happen both ways: I have convinced others to look into languages I favor, and others have convinced me to look into languages I had long since written off. Obviously, stubbornness and personal insults take away from the discussion (inevitable on the Internet), but I love reading debates. Everyone has to dig deep to defend their practices. (And then there is PHP... Everything about PHP is indefensible...)
I love C++, but I acknowledge there are many things wrong with it. I think a big part of the reason C++ persists so strongly today is the fact that no one really steps up to compete. Every language that starts life as a C++ killer makes an abrupt left turn at a critical junction and moves out of the problem domain. I love many features in Java, C#, Lua, etc. but those languages all live in a different world. Virtual machines? Garbage collection? Dynamic typing? These are for developing web backends, light desktop applications, or simple tools. Meanwhile, game developers, database developers, etc. are left standing out the cold with C/C++ as their only options. Why is no one fixing the problem? Why do so few languages strive to create comparable assembly? As far as I can tell, only Rust is attempting it. Jonathan Blow is taking a stab at it, though. -- https://www.youtube.com/user/jblow888/videos
Yeah, I saw it dripping off the page;) The irony wasn't lost on me. 
I know of one breaking change that I've seen in reality: std::make_pair&lt;int, int&gt;(3, 7); Of course, this code is incredibly stupid to begin with and the safe fix is super trivial: std::pair&lt;int, int&gt;(3, 7) I don't think there is even one situation where that could break something outside of code that would be specifically designed to change meaning. The best way is of course to do this: std::make_pair(3, 7); Which is what this feature is actually for…
Visual Studio sucks.
Linus first point is about bad programmers using c++ features badly &gt; It's made more horrible by the fact that a lot of substandard programmers use it, to the point where it's much much easier to generate total and utter crap with it. The only way to deal with this is removal of abused features from the language until its list of features can be represented by the empty set. Linus point about inefficient object model also can't be fixed by the language. It is based on the believe that C++ in any of its iterations is a purely object oriented programming language. Which is a) wrong and b) caused by the bad programmers from the first point. 
What ? In my experience my friend who went the HPC route earn MUCH more than the typical web dev (like 4/5k$ for *internships* in petroleum companies for instance)
&gt;&gt; C++ most obviously be doing something right It's one of the most popular languages used Here's the problem. For most programming, garbage collection is ok, so most new languages focus on that, and you get a lot of choice. For those of us for whom garbage collection is unacceptable, we basically have C, or C++. we're stuck without choice - and it seems there isn't enough demand for alternatives to be developped and adopted (I've been following Rust which is promising, but tooling isn't there and it sacrifices too much c++ inter-op for my liking) Basically we are a captive audience. Look how long it took for C++ to get lambdas.
The most recent version of binutils supports bigobj (currently only for x64). Any up to date Mingw-w64 distro will probably have the latest binutils. STL's [distro](http://nuwen.net/mingw.html) is one of them.
Yes it is, or they'd be using one of the alternatives or developing alternatives themselves.
Which is no more "herding you" into using object constructs than C's built-in support for `gets` herding you into buffer overflows...
The main reason is that I desperately want to use [range-v3](https://github.com/ericniebler/range-v3) ;-) Thank you for your excellent explanation in your other comment above!
&gt; Honestly, the worst part about C++ is that it still requires header files For me its the way headers and classes interact. C has headers, but if you use C++ as intended, the header problem is worse; it demands that you put more dependancies in one place. But there is a strong draw to class-methods, because they show up with "dot-autocomplete" in IDEs which is extremely useful for navigation &amp; discovery. I wish you could prototype class methods external to the class, as if they really are just functions with a parameter in a different place. UFCS would be another acceptable solution.
The main problem with C can be summed into two lines. Suppose you have the following: char *one = ... something ...; char *two = ... something else ...; The question now is, what should you use to deallocate the resources pointed to by *one and *two? Is it free, g_free, something_unref, some custom dealloc function, or maybe nothing at all (because it might point to a shared piece of data). Then answer is that you can't tell. You have to go through the code every single time to see where you got your pointer and then read the documentation of the function that give you the resource. This assumes that the code is documented which more often than not it isn't. This is C's biggest usability problem: the way to deallocate a resource is unrelated to the pointer to said resource, so the poor developer has to manually track everything. Combined with the fact that you can't run deallocation automatically like what C++'s destructors do (there is a GCC extension for this but it's not portable) means that most C coding reduces to refcount debugging. This is great if you have obsessive-compulsive disorder, but terrible if you just want to get stuff done. C++'s destructors + unique_ptr make all of this busywork go away with no (or very small) runtime overhead.
&gt; but C++'s inbuilt concept of vtables are not perfect it's not perfect, but nor is it even that bad. And when it *is* that bad, just do whatever you would have done in C anyways and call it a day!
In the most common sense: money is misappropriated and other people cover for it. The administrations will retaliate against anyone who brings up the issues. That might not make sense to you at first, but it's outside (government) money Universities get for various programs. The administration only cares about their reputation, which includes having these programs. Productivity and results aren't as important.
No; C++ is not "100% fine". They don't switch because they don't have better options. C++, as broken as it is, remains the best choice. Having said that, tons of gameplay logic is implemented in script langauges or C# these days.
C++ isn't broken. Go back to /r/Java. 
In my mind there's specialist of language and there's specialist of application. Personally I view myself as a specialist - specialist of application (vehicle dynamics simulation). Still need to have a few tools in the toolbox. For me it's C#, C++, Matlab.
&gt; would you really want to make it more complicated to find out which function an expression will call? Yes. the current restriction is the greater evil, I'm utterly sick to death of bouncing between free functions and methods. It gets seriously annoying after a couple of decades. I don't want to be stuck with that nonsense 20 years from now again. I want UFCS or extention methods, ASAFP. Its' only going to make 'figuring out whats called' harder if you were using the same name for a different free function and a method, which would be abusing overloading anyway IMO. You can end up just duplicating that anyway, e.g. foo(a,b), then A::foo(b) { foo(this,b);} or vica versa. we do have mature tooling with C++ - tools can do jump to definition, and if worst comes to worst you can put a breakpoint and step into it.
Remember that kernel patch the other month where Linus fixed a bug caused by 12+ levels of macros? His checkin comment was "shame on me for not following the macros all the way down." He hates C++ because he'd have to code in a certain way to avoid the bad parts. Yet he uses C and finds he has use use fucktons of macros to get anything done. That's sanity?
Stop whining and read the rest of my comment. I like C++, but it's a remarkably flawed language. You can be a fan without being a fanboy. Try it.
Mentally help, i suppose, but they don't help at all at compile time. the entire definition of the class's data members is in the header file, so all its dependencies are visible to the client code. PIMPL or interfaces + factory functions are a solution, but they force everything onto the heap which is unacceptable. Lack of a Module system is the most pressing flaw of C++ right now. Client code only needs to know the objects' sizes unless you want inlining. I really hope the standards committee puts everything else aside until they figure this one out. then, concepts and ranges. 
Now that C++ has lambdas and auto for type inference, its biggest issue is lack of mandatory garbage collection.
That's not really that great...
&gt; Its' only going to make 'figuring out whats called' harder if you were using the same name for a different free function and a method, which would be abusing overloading anyway IMO Seriously, ADL is complicated enough. I'm not saying the current situation is great, but having those features would just make problems worse. I'll explain. Right now, you have the following problem (vaguely contrived, but I tried to make it plausible, because the examples online were moreso): namespace my_namespace { struct quaternion { float x, y, z, w; }; template &lt;class T&gt; inline void lerp(T const &amp;a, T const &amp;b, float t) { /* linearly interpolate between a and b, which have x, y, z, w */ } } /* i'm only vaguely aware this one exists */ namespace their_namespace { struct quat { float x, y, z, w; }; inline void lerp(quat const &amp;a, quat const &amp;b, float t) { /* spherical interpolate between a and b (similar function is named slerp in my_namespace) */ } } template &lt;class T&gt; T Interpolator::tween(float t, T const &amp;a, T const &amp;b) { return lerp(a, b, evaluate(t)) } Now, at some point, someone calls `Interpolator::tween` on a `their_namespace::quat`. The result is that your camera doesn't go where you expect and people make fun of your camera code on the internet. Now, there's a good defence to this, and it's using my_namespace::lerp in Interpolator::tween. This would effectively be defeated by UFCS. It will just make the ADL problem worse. 
Lol. Lol. lol. looool. The entire issue with every other language is mandatory GC, which sucks for perf.
This. I have to work on a codebase that has a pure C implementation of a linked list of linked lists. The functions ended up being huge (over 500 loc) and the logic is very hard to follow. Naturally, there were memory leaks and segfault on extreme cases. If std::list had been used it'd be faster, easier to understand, cleaner and safer. The reasons for not using it were that "C++ is not portable enough and STL even less so". Of course, in 7 years this *never* ended up being a real problem, it was just C-programmer paranoia. Between a bad pure C implementation and a bad STL use, I'd take the latter any day.
(it(use(to(have(don't(I(is(Lisp(about(thing(nice(The))))))))))))*
ICPC contest problems are good for algorithmic challenges. One good source of them is [here](https://icpcarchive.ecs.baylor.edu/).
This is pretty much programming. When you work for a company, you rarely are going to start from scratch and will need to comb through what the previous group had done. It sounds like the previous coder had left a big mess and I hope that you learn from his mistake and always document your code and follow a good coding guideline. 
For starters, I'm tired of sprinkling "explicit" all over my code to stop the language from doing some wonky crazy shit that nobody in his right mind would ever imagine should be *default behaviour*
Well, without getting into minor language details (they write books on that), here are some of the bigger high level flaws. * C++ lacks an ABI * C++ has C compatability, with all the good and bad that's brought. * C++ is terrible for string manipulation * C++ has no localization support * C++ is a PITA for GUI work (even with Qt) * C++ isn't NUMA aware * C++ has real problems with cross binary memory allocation/deallocation (related to lack of ABI) * C++ has no support for "pure functional" like they have support for "const" * C++ support for const has too many easy ways to accidentally break out of const correctness without even noticing They're all understandable flaws, but at the same time I look forward to a better language coming along someday. And yes, we can work around the issues. Just like you can write Linux in C if you try hard enough. That doesn't make it ideal.
There is no C GUI library. It's just a myth. ;)
But do most people really think like that? A few people ranting at slashdot doesn't mean shit really. You can find people arguing about anything on the internet, be it from a statement Linus Torvalds said, or from Honey Boo Boo. I seriously doubt there are many C advocates that are pro-C just because Linus is. There are certainly _some_ though.
Well in my country you're happy when you make 600 $ as an intern (currency adapted :p)
I disagree heavily. Stroustrup was *clearly* joking, did you even read it? Whereas everyone's suspected for years that the NSA were reading our emails, and it came as no surprise when it was revealed that they were in fact doing that.
I can't think of any examples, unless you mean automatic conversions between types, which are extremely sensible. If you don't want them, write `explicit`. We're not talking about PHP or Javascript here, mate. 
Sure thing kid. Have you actually written any sort of performance-critical system before, or are you just repeating what you've read on the internet?
Nobody cares. 
&gt;Stroustrup was clearly joking I couldn't tell. :) 
Take that with a grain of salt. People say "similar performance" and then produce code that's twice as slow. But it's "similar performance" because in the past interpreted languages were 50x as slow. But it's not *actually* similar perf. 
Eh, that sort of stuff is all defined in the contract of the function. No worse than having to keep track of not passing in a NULL, or only passing in numbers between 1 and 1000 to a function taking `int`. These things can be solved, but you've got to keep in mind the added complexity of the language, the added mental complexity when learning the code, the more complex compiler that takes longer, etc.
Done.
The fact it was grafted onto C, the fact that you are allowed to mix C/C++. The list goes on
No, implicit conversions between types can be sensible (char* -&gt; std::string) but they can also be stupid (int -&gt; std::vector) and retarded to the point of causing UB out of thin air (rules for integer promotions). It really would have been much better to have explicit default and `implicit` keyword, so that conversions would be opt-in only. (Sadly, because of backward compatibility there is no way to change the current state, or the integer promotion semantics)
It was the addition of perfect forwarding to pair and make_pair(), in order to increase efficiency and work with movable-only types like unique_ptr. There have been surprisingly many breaking changes in the Library. vector&lt;vector&lt;int&gt;&gt; v(11, 22) no longer compiles. Immutable set elements was another big one. As usual, none of the breaking changes that people actually encounter are called out in the Compatibility annex of the Standard.
&gt; money is misappropriated misappropriated for what? You're not very specific.
Well.. Look at boost. Its cool and all. But look at boost code. It is certainly more complex than it should be.. That makes me think complaints arent totally unfounded..
It's corruption. Money pays for services that have kickbacks, or to companies owned by family. Typical methods of writing apparently legitimate checks for money that ends up in your own pocket.
12 levels of templates sounds bad too. The point is, even "disciplined" C coders use a ton of macros because they need it to make something decent. A better language wouldn't require macros to do what they need.
I'm sorry you don't know your language very well. Being a professional requires you to know your tools. That includes the good and the bad. On the whole, C++ developers are more honest about this than any other group of developers I know. That's a good thing, and I admire it. Even C++ developers can get caught up in vim versus emacs though :-(
GC is a perf win in some scenarios, and a loss in others. Even where overall performance is better with GC, the loss of control can be too awful. Only recently have GC languages gotten smarter about this, but I'm not sure if they're stutter-immune yet.
&gt; There's probably some other stuff we've been missing Being able to nest templates without adding a space between `&gt; &gt;` to workaround the parser taking a dump was a nice addition.
here is my take on C++, hope Linus roles and shiver somewhere: the only bad thing I find in C++ is C !!! The fact C is subset of C++ is the best and worst at the same time :( "Where you're confused is that C++ has an alternate way to do I/O beyond printf, with advantages and disadvantages." lol , not I'm not: C style - fast and insecure C++ style - slow but more secure
git is essentially his knowledge about filesystems, distilled into C. The original versions of git very very FS-like. It took several iterations to actually turn it into the application we know today.
Yea, probably not. But I certainly think that doesn't apply to the standard library. And also not to all parts of boost. In the end, it might also not matter that much to the "normal" programmer, as what counts for them is how easy and safe a library is to use, and several boost libraries score high on that ladder.
I found that they all came from the same people (person, mostly).
Now you've explained what corruption in general is, but you haven't yet said a single word about how that applies to Universities, why they are corrupt, where money goes instead of where it should go, who is involved, what is going wrong, etc. All you say is "Universities are corrupt", and there doesn't seem to be anything behind your statement.
I can only be so specific without naming names. Like I said above, don't believe me. Go work at a University and find out for yourself.
GUIs are indeed one of the few places where class-bases/academic OOP works like a charm, simply because GUI is ultimately hierarchical-composition 
&gt; Yes, evidently because of Qt. But why not use a C GUI library? Because Qt is a great (if not the best) cross-platform GUI toolkit. And competent people don't make technical decisions based on fundamentalist beliefs. 
&gt;The rule of 3 (err... it's the rule of 5 now since C++11) is essentially, "C++ will give you some default constructors that are probably NOT what you want" Thanks, Bjarne! No... no it isn't. 
Nothing but clickbait
Another alternative that is pretty cool would be to contribute to some open source projects. This gives you practice looking at production code and working in teams, and also adds to your portfolio. Here are the steps I would recommend: 1. Get a GitHub account 2. Find some random projects that interest you. Look at the bug tracker for open bugs. Try to find easy things at first. Once comfortable with a project, consider adding new features. 3. Submit a patch! 4. Rinse and repeat, and start some of your own projects too! There are a number of good advantages here... * Other people are looking at your code. You can learn a lot that way. * You're contributing to actual projects. The satisfaction of knowing that other people are using your tools is fantastic. * Again, you can build up your portfolio. If you are looking for a job, then putting your GitHub account on your resume is a great way! * You also get practice with team oriented programming, mainly practice with bug tracking and version control.
There are benchmarks for many of those languages [here](http://benchmarksgame.alioth.debian.org/) that in some/many cases beat their C++ equivilent. The Rust ones for example beat the C++ at least half the time and the ones they lose on are dependent on known issues they are working right now. Sooner than later I expect they will be beating the C++ roundly. The biggest mistake C++ programmers make is confusing a fast compiler for a strong language. All it takes is something like LLVM to even the playing field and all of the sudden C++ isn't fastest anymore and has to depend on the quality of it's actual syntax. Should be interesting. 
I've had the need for mutable `std::set` elements _a lot of times_. It is extremely annoying that set elements are immutable, since a "WeakTotalOrder"-preserving mutation is a very easy to achieve when using a `std::set` with a custom comparison (for `std::unordered_set` hash-preserving mutations are also possible given that one can use a custom hash). I agree that using the STL should be "safe", but forcing developers to reimplement parts of the STL to get basic functionality is unsafer than adding `unsafe_` methods. And yes, they are forcing developers to either not use the standard library, or invoke undefined behavior. For example, the "right-way" to mutate a set element without invoking undefined behavior is: copy the element, erase it in the container, mutate it, reinsert it. The expected way of mutating it in-place is much faster, and can be achieved by invoking undefined behavior (just`const_cast` an element reference). So with the current `std::set` interface, I can either have a crippled `std::set` (no mutations allowed, reimplement my own for allowing mutations), a very slow `std::set`, or a `std::set` that is fast but forces me to invoke UB. And this is not the first time that the committee decides to choose "black-board safety" vs pragmatism. If you want a `std::vector` of default initialized elements (e.g. to receive objects via network, IO, another process...), you have to use a custom allocator that doesn't default constructs its elements which invokes UB and changes the vector type. The 15 years old Boost.Container.Vector solution is to have an extra default constructor `vector(size, default_initialized_t)` and an extra resize function. When I started using and learnig the STL, I didn't saw these issues. However, with time, I just think that the containers need a rework (polymorphic allocators by default, better "cache"-oriented hash tables and sets, flat set/maps, dynamic bitset, and the ability to unsafely and temporarily break container invariants...). 
&gt; Another reason is the garbage collector in D. It makes things like RAII less straightforward to use (IIRC, you need to use the "scope" keyword, and it can degrade the GC performance). Funny, Andrei Alexandrescu, actually claims the opposite to be true. See this [article](http://www.drdobbs.com/lock-free-data-structures/184401865) he wrote. The TL;DR is that, yes the GC has pauses, but that those pauses are the only way to implement lock-free data structures, which strongly reduce thread contention. Basically he appears to be saying that GC can reduce thread contention and that this is more important to throughput than GC pauses that can eventually be optimized away (and that thread contention can't be optimized away). I have to say i kind of agree with him. When someone shows me some clever, fast C++ code it almost never involves mutlithreading. It's one area, even with the new API improvements, that really makes C++ look ancient. 
and how about the ones, like me, who couldn't care the least for both ?
nope!, I rather say that for you!
isn't GC optional in D? otherwise is useless for embedded and D is pitched to embedded too!
many things are cleaner in D, to start it adopts solid contract driven programming in contrast to C++ oceans of asserts() and static_assert()
Can not reiterate number 1 enough. So many people don't fully utilize their debuggers to full potential. Whatever platform you are on it is worth getting aware of everything it can do, also how to use a dump file for debugging, it is so trivial and saves so much time, but people don't even seem to know it exists. 
how do you even find these? i have a github account but only use it to publish stuff that i've been working on
I agree. And despite Linus' rant to the contrary, his actions shows that even he (at least in the last couple years) doesn't makes technical decisions based on fundamentalist beliefs.
Nobody is asking you to *look at* their code. It's documented so you can *use* it and build your application.
Preventing NULL arguments in C++ is trivial: instead of a pointer take a reference (or pass by value). In C this is impossible. In C++ when you return a std::unique_ptr&lt;Foo&gt; from a function, the ownership is unambiguous, automatic and guaranteed by the compiler to be correct. In C this is impossible. This is also the correct place to put complexity. A few dozen people need to do extra work with the compiler and in return every single user of said functionality has it easy. Dealing with refcounts and resource deallocation manually is a bit like inline assembly. There are valid use cases for it, but they are very rare and 99.99% of the time developers should not be doing it.
Yes; also anti-GC people sometimes don't have experience of how GC allows you to write code differently. You can also combine GC and deterministic resource management, which is what D encourages. There are GCs that are hard-realtime, but they're not common, and the GC requirements can impact language feature design.
structs use RAII by default. If you want you can stub out the GC so there is no loss of performance. C++14 doesn't have a memory-safe subset, thread-local storage by default, transitive const (important for thread-safety), `pure` (much more usable than gcc's pure attribute &amp; useful in allowing safe conversions, optimizations, etc). Then there's useful safety features like default initialization (can be overridden). *edit*: I can't believe I forgot template constraints &amp; modules.
Sometimes, throughput is unimportant. Realtime processing is one example. In such situations, the most important requirement is to finish tasks on time, not to finish them as fast as possible. A GC can seriously hurt then.
Sure, it's just that C++14 is "good enough" for many people and many occasions. Remember the saying, "good is the enemy of great". That's exactly what is going on with C++14 and D 2.0.
I didn't ask for names - you can answer all my above questions without calling out any names. As it stands now, your sentence is just a lot of air. Too bad, I was curious to know more, but you don't seem to be able to back your statement with _anything_ at all. And I do work at a University.
C++ is a lot more than syntax. It has a standard library designed to be able to be implemented efficiently and it carefully leaves certain behaviour undefined to allow the compiler to optimise more aggressively.
I'm not sure if I agree, I'd have to hear a specific example to decide. A large portion of the library is templates, and, if anything, their dynamic nature complicates compilation/optimization, not enhances it. I'm no C++ expert tho.
https://github.com/trending?l=cpp
Also don't forget that boost tries to support older compilers - some with questionable adherence to the ISO standard.
This talk was recorded during the Library Working Group Meeting in Cologne.
Sure and you could hand-write assembly as well. 
Man the sound on that is bad. Over compressed I think.
&gt; I'm sure I can find any number of "roll your own" structures people have that leak memory, crash randomly, &amp; perform more poorly. You're in /r/cpp. We know; you don't have to say it. &gt; Keep in mind that Linus is coming from the perspective of the kernel. You're in /r/cpp. We know; you don't have to say it. &gt; Him complaining about STL is like him complaining about glibc. No it's not. He actually knows something about glibc. He knows nothing of C++. 
It was hideously old, like 2004, written as I was just learning.
People who run the uni buying land. Then deciding the uni should build some new facilities, on land they just purchased, might as well just rent it back to themselves, hey that's what subsidies are for! Then have their friend's construction company build the facilities. What a coincidence eh? Oh you found a great deal for some equipment online? Would allow you to finally get that set-up you have needed for ages? I'm sorry but we only order from specially selected suppliers, because of... errm, hmm, ah yes, the need for the long-term support guarantees they provide, or something. Honestly the people in charge of purchasing are in no way related to the people we buy from. Honest. So aggravating. Try calling them out on it and nothing changes, then you get shunned.
How is a Haskell type class different from a protocol/interface/abstract class in an OO language? I think that's what he's referring to.
I think the point is that it's perfectly fair to say, "I am frustrated by the fact that I am doing embedded development, and the toolchain isn't as friendly or refined as I would like it to be," but it is less fair to say, "C++ is inherently a terrible language because the toolchain on my platform is frustrating." I don't actually like Visual Studio that much as a matter of personal taste. But I do concede that it has many features that can be quite handy, and make the language more pleasant than when dealing with really bare bones tools.
Insert requires an iterator. Use push_back to insert into a vector.
The link to the slides is broken. EDIT: had to guess but found it: https://meetingcpp.com/mcpp/slides/Threads%20are%20an%20illusion%20-%20Chris%20Kohlhoff.pdf
Use `std::find` or `std::find_if` with a custom predicate (depending on your needs). More info [here](http://en.cppreference.com/w/cpp/algorithm/find).
Well, that is because of audio filters. This talk is recorded with the cameras microphone, which also picked up the noise from the beamer. Got the noise almost 100% out, but that comes at this cost, that the voice is a bit "compressed" by the filters.
If i try to use this with a class I would need to use an operator overload right?
"Even now, clang cannot compile some of our C++ codebase." Would be nice to have some simple examples of conforming C++ code that cannot be compiled with say clang 3.4+ 
thanks for noticing!
Oops, thanks! Actually, I'm going through Accelerated C++ right now. My syntax is not ideal because this is a test file purely for myself to go through exercises. Yes, I understand that I have multiple errors. I'm trying to take on one error at a time. Gotcha, thanks!
my point is i can't envision being able to work at the high level necessary to help ensure maintainabilty and more importantly, robustness. operator overloading is critical for making anything that implements formulas, performs differentiation or integration, etc remotely readable.
Thank you for the talk, it was worth it to watch it!
well.. C++ is for real time app :) as real time goes on non real time OS! what c++ AMP gives you, for free, at least that's the theory haven't played with it myself, is e.g. for unfold and then parallelization. the only thing that might stop you from using it for real-time is some initial cost that end up prohibitive! keep in mind that if you have a serial data dependency it will not give you any benefits, that is it will run as normal C++ and not on accelerated hardware. this is a general problem and you should always draw your data dependency so that you don't try to parallelize something that is sequential!
ASIO supports coroutines, fibers, strands, threads... you can get as fine grained as you want. From the ASIO ISOC++ papers, there is one called something like ~"An extensible model for asynchronous execution" that explains how it achieves this (I think this paper evolved into the new Executors papers).
learn to write unit tests and simlutations to break most stuff. then fall back to debug and asserts to see where in the chain stuff breaks. when writing highly threaded stuff debuggers tend to be useless since compiling in debug mode and running inside a debugger likely won't recreate the problem. i've seen some windows programmers code and have been appalled at how much they use a debugger. I might have to use one to look at a core dump maybe a few times a month.
+1
&gt; conforming that's your problem! Very few (significant) codebases are actually fully conforming to the standard. I remember this being a problem when gcc4.8 came out as even the standard optimization benchmark (comparing the running time of a standardized test compiled with different compilers) didn't run correctly when fully optimized in gcc4.8, because some parts of it were technically non-conforming. Even big established libraries like zlib are actually non-conforming in their most basic design (not just "local bugs" that can be fixed, but the basic design decision uses mechanics that "work" but are against the standard, such as assignment between different kind of pointers) So you can blame the developers, but blaming people doesn't help anyone. At the end of the day there is a big code base that has been written over many years, compiles and works well in one compiler but can't compile in another. Fine, it's because of non-compliance. But knowing this doesn't solve the problem.
Sorry for the snark, wasn't in a good mood. Also since I am pretty sure Accelerated C++ should teach you about RAII, and that calling `new` is wrong, maybe you should reread the relevant chapters. ;-) 
did I say anything about inheritance,or Java style OOP ????!!!! I know inheritance is limited. extention methods are superior, which is why i want them, or UFCS. I'm complaining about the conflicting syntaxes. regardless, a.foo(b) is supported by IDEs and it also reads better for chaining: .. `a.foo(b).bar(c).baz(d)` vs `baz(bar(foo(a,b),c,d)` .. whats the order of operations?.. and when you typed the former in an IDE, you had on the fly autocomplete at every step. its the sutter version I want, and he explains the motivation very well http://isocpp.org/files/papers/N4165.pdf ; but i would also be happy with a mechanism to define non virtual member-functions outside the class. he says:- &gt; "3. Discoverability and tool support: “Start with the argument” puts intent up front &gt; This section may sound philosophical at first, but it isn’t about philosophy. It’s all about practicality. &gt; More importantly, I am becoming convinced that member function call syntax is actually preferable in any language, because it puts the argument first rather than the function first. When you start with the func- tion name, the list of “objects/expressions you can pass to that function” can be undecidable and possibly infinite. When you start with an object or expression to be manipulated up front, it’s easy to narrow down a useful list of “things you can do to that object.” This aids programmer productivity, discoverability of APIs (what can I do with this object), and tool support." IMO the practicality is hugely important. There is Rust now which does give you extention methods via traits, but being new, tool support isn't there.. no autocomplete, so C++ with a mature IDE remains more productive. we should be able to have both benefits simultaneously. The superior productivity of a.foo(b) combined with the superior decoupling and extensibility of foo(a,b). the syntax split dividing them is undesirable.
Actually it requires C++14 now...I wish I could change the title :s
&gt; because some parts of it were technically non-conforming. Well, that is a very nice way to put it. Actually the bugs were quite serious buffer-overruns that were also written in a quite ugly way: [GCC-bugtracker](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=53073) int SATD (int* diff, int use_hadamard) { int k, satd = 0, m[16], dd, d[16]; /*===== sum up =====*/ for (dd=d[k=0]; k&lt;16; dd=d[++k]) { satd += (dd &lt; 0 ? -dd : dd); } Appart from being really hard to read, this ~~writes to~~ reads `d[16]` which is clearly not allowed and considering that there ARE code-execution-exploits base on buffer-overruns of a single byte, this might even be a security vulnerability. Strictly better code: /*===== sum up =====*/ for (k=0; k &lt; 16; k++) { dd = d[k]; satd += (dd &lt; 0 ? -dd : dd); } Or, with C++: for(int val: dd) { satd += std::abs(val); } I wouldn't be surprised if GCC generated faster code for this than for the original code with `-fno-aggressive-loop-optimizations'.
I think the reason why this happens is that ultimately the compiler tranlates: a[i] to *(a+i) and i[a] to *(i+a) since *(a+i) == *(i+a) it's basically the same
I think to answer this question, we need to compare the same concept, expressed in Haskell and C++ using concepts. Consider the Monoid: You could basically summarize a Monoid as "anything with an associative plus-like operation and an identity element, i, such that (x + y) + z = x + (y + z), and x + i = x". In Haskell, you can define a Monoid like this: class Monoid a where mempty :: a -- Identity of 'mappend' mappend :: a -&gt; a -&gt; a And define list, denoted "[]" to be an instance: instance Monoid [a] where mempty = [] -- The empty list mappend a b = a ++ b -- concatenation In old-style concepts, one could write a concept_map: concept Monoid&lt;typename T&gt; { T mempty(); T mappend(const T&amp; x, const T&amp; y); }; // The std::vector instance concept_map Monoid&lt;std::vector&lt;T&gt;&gt; { std::vector&lt;T&gt; mempty() { return std::vector&lt;T&gt;(); } std::vector&lt;T&gt; mappend(const std::vector&lt;T&gt;&amp; a, const std::vector&lt;T&gt;&amp; b) { std::vector&lt;T&gt; c = a; std::copy(b.begin(), b.end(), std::back_inserter(c)); return c; } }; See: http://www.stroustrup.com/oopsla06.pdf With '06-style concepts, one could think of a concept as similar to writing an "interface" in Java, or a type class in haskell because because it could at any moment be a check that a type meets an interface, or be the implementation of it. The concepts proposed more recently, using predicate-style functions, cannot be used quite the same way. template&lt;typename T&gt; concept bool Monoid() { // mempty&lt;T&gt;() must return a T return requires (T x) { {mempty&lt;T&gt;()} -&gt; T } // and mappend(x,y) must return a T &amp;&amp; requires(T x, T y) { {mappend(x,y)} -&gt; T }; } See http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4377.pdf n4377 does not make any mention of "concept_map" specialization that I can see, so they can't be used to implement the interface by themselves. However, we can do it differently: template&lt;Container C&gt; C mempty() { return C{}; } auto mappend(const Container&amp; a, const Container&amp; b) { auto c = a; std::copy(std::begin(b), std::end(b), std::back_inserter(c)); return c; } and overload these functions for other types of concepts as well. So, would we describe "concept_map" as object-oriented and predicate-based concepts as not? I don't like to get into abstract debates about philosophical (paradigm) matters, so I'll leave that unanswered, but we can see that C++-style concepts have gone from something almost resembling haskell type-classes to something actually stronger. The above monoid definition can be used for std::vector, list, queue, map--every standard container. But in Haskell, the monoid type class must be specialized for every single data type--even ones with identical interfaces. **edit:** it can't be used for *std::array* or containers without *push_back*... :(
Very basic, seems not to cover any part of the Standard library. And you can't declare an int final, like in the last example here: http://www.studytonight.com/cpp/variables-scope-details.php Thats const, not final.
Yeah but you can't currently allocate any reference type on the stack in Java. )The compiler does optimize to that in some instances I believe, but it's not default behavior.) So if you're not using primatives in Java, it's likely stored on the heap. In D you can make things like structs on the stack.
I see. Thanks for your in depth answer.
I was going to post some kind of response about how context switches between threads could be significantly cheaper than between processes, but on looking for a reference it looks like in the average case that might not actually be true: http://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html. Interesting discussion anyways, thanks.
The readability of the last example just beats everything. Btw, why not `for(int&amp;&amp; val : dd)`? Wouldn't it avoid an unnecessary copy?
Easy way to create immutable class: * make all members const * deal with absence of const-transitivity for pointers Done!
But when do you need an index? IMHO then its perfectly fine to use a raw loop, but mostly, the index is just used to access the members in the loop. So its mostly not needed actually.
It's best practice to have them separate, the header is the declaration and the class file is the implementation. See [this explanation](http://stackoverflow.com/a/333964) for a bit more detail.
If declaration is used only inside translation unit (.cpp file), keep it there. Less exposure, less recompilation, closer proximity. If it's used in multiple translation units, move to header file. Single declaration for all, only one place to change, can be used for linking already precompiled objects and for calling dynamic objects, no worries about ordering. Also read about forward declarations. For never changing short things, something that'll get inlined, it's ok to keep them in the header file. But it's really hard to tell which functions will be those, so better to keep everything clean as a habit. 
Its impossible to have predicates with templated "signatures" with additional constraints. As an example, a `Functor` could be conceivably defined like this using archetype-based concepts: template&lt;template&lt;class...&gt; class W&gt; concept Functor { template&lt;class F, class T, class U=decltype(std::declval&lt;F&gt;()(std::decval&lt;T&gt;()))&gt; W&lt;U&gt; fmap(F f, W&lt;T&gt; w); }; This is impossible to write using predicate-based concepts. First, the compiler would need to check every type, which is not feasible. Secondly, even if it was feasible, there would be edge cases that would not be clear to decided whether it fulfilled the predicate or not. Of course, with archetype-based concepts this is much simpler to solve since there is two phases of checking the types. 
&gt; but we can see that C++-style concepts have gone from something almost resembling haskell type-classes to something actually stronger. No, predicated-based concepts are weaker than archetype-based concepts, because there is only one phase of checking. &gt; The above monoid definition can be used for std::vector, list, queue, map--every standard container. I think you are convoluting archetype vs predicate based concepts with implicit vs explicit based concept maps. It is better to have an implicit concept maps and then the user explicitly overrides this for false positives(for when it quacks like a duck but isn't a duck). Both of this is possible with archetype-based concepts and predicate based concepts. Plus, archetype-based concepts allow explicit overriding(through concept maps) to call different functions as well, which matches closer to how customization points in generic programming is done currently. Note, however, the current design of concepts lite cannot allow for any explicit overriding even for false positives, which is a *HUGE* problem with the design of concepts lite in my opinion.
Noob question about this: I like python's way of looping, but a lot of implementations (eg bubble sort) need for me to do something with an element of an array and the neighbouring element/s. I can't really do this with for_each-like syntax, right? I've always wondered, as loops in python are really nice to handle until I need to do something with a neighbour and then it's for i in range(100): do_stuff(array[i], array[i-1]) or whatever, it just looks really clumsy.
You can do the same thing as in python (e.g. create a range of integers). If you don't want to create a range of integers but e.g. get a pair of values, you can do that too: for (auto &amp;&amp; p : zip(array, array | wrapped | slice(-1, array.size()-1))) { do_stuff(p.first, p.second); } I cannot recommend doing it tho.
This really doesn't matter for int at all in this context. `int` is about as cheap to copy as it gets. If anything, references might be more expensive on 64-bit machines.
Here's how `BOOST_FOREACH` expands: BOOST_FOREACH(int i,C){...} is a `define` that expands to: if (bool _foreach_is_rvalue6 = false) {} else if (boost::foreach_detail_::auto_any_t _foreach_col6 = boost::foreach_detail_::contain( (true ? boost::foreach_detail_::make_probe((C), _foreach_is_rvalue6) : (C)) , (boost::foreach_detail_::should_copy_impl( true ? 0 : boost::foreach_detail_::or_( boost::foreach_detail_::is_array_(C) , boost_foreach_is_noncopyable( boost::foreach_detail_::to_ptr(C) , boost_foreach_argument_dependent_lookup_hack_value) , boost::foreach_detail_::not_(boost::foreach_detail_::is_const_(C))) , true ? 0 : boost::foreach_detail_::and_( boost::foreach_detail_::not_(boost_foreach_is_noncopyable( boost::foreach_detail_::to_ptr(C) , boost_foreach_argument_dependent_lookup_hack_value)) , boost_foreach_is_lightweight_proxy( boost::foreach_detail_::to_ptr(C) , boost_foreach_argument_dependent_lookup_hack_value)) , &amp;_foreach_is_rvalue6)))) {} else if (boost::foreach_detail_::auto_any_t _foreach_cur6 = boost::foreach_detail_::begin( _foreach_col6 , (true ? 0 : boost::foreach_detail_::encode_type(C, boost::foreach_detail_::is_const_(C))) , (boost::foreach_detail_::should_copy_impl( true ? 0 : boost::foreach_detail_::or_( boost::foreach_detail_::is_array_(C) , boost_foreach_is_noncopyable( boost::foreach_detail_::to_ptr(C) , boost_foreach_argument_dependent_lookup_hack_value) , boost::foreach_detail_::not_(boost::foreach_detail_::is_const_(C))) , true ? 0 : boost::foreach_detail_::and_( boost::foreach_detail_::not_(boost_foreach_is_noncopyable( boost::foreach_detail_::to_ptr(C) , boost_foreach_argument_dependent_lookup_hack_value)) , boost_foreach_is_lightweight_proxy( boost::foreach_detail_::to_ptr(C) , boost_foreach_argument_dependent_lookup_hack_value)) , &amp;_foreach_is_rvalue6)))) {} else if (boost::foreach_detail_::auto_any_t _foreach_end6 = boost::foreach_detail_::end( _foreach_col6 , (true ? 0 : boost::foreach_detail_::encode_type(C, boost::foreach_detail_::is_const_(C))) , (boost::foreach_detail_::should_copy_impl( true ? 0 : boost::foreach_detail_::or_( boost::foreach_detail_::is_array_(C) , boost_foreach_is_noncopyable( boost::foreach_detail_::to_ptr(C) , boost_foreach_argument_dependent_lookup_hack_value) , boost::foreach_detail_::not_(boost::foreach_detail_::is_const_(C))) , true ? 0 : boost::foreach_detail_::and_( boost::foreach_detail_::not_(boost_foreach_is_noncopyable( boost::foreach_detail_::to_ptr(C) , boost_foreach_argument_dependent_lookup_hack_value)) , boost_foreach_is_lightweight_proxy( boost::foreach_detail_::to_ptr(C) , boost_foreach_argument_dependent_lookup_hack_value)) , &amp;_foreach_is_rvalue6)))) {} else for (bool _foreach_continue6 = true; _foreach_continue6 &amp;&amp; !boost::foreach_detail_::done( _foreach_cur6 , _foreach_end6 , (true ? 0 : boost::foreach_detail_::encode_type(C, boost::foreach_detail_::is_const_(C)))); _foreach_continue6 ? boost::foreach_detail_::next( _foreach_cur6 , (true ? 0 : boost::foreach_detail_::encode_type(C, boost::foreach_detail_::is_const_(C)))) : (void)0) if (boost::foreach_detail_::set_false(_foreach_continue6)) {} else for (int i = boost::foreach_detail_::deref( _foreach_cur6 , (true ? 0 : boost::foreach_detail_::encode_type(C, boost::foreach_detail_::is_const_(C)))); !_foreach_continue6; _foreach_continue6 = true) {...} Now, can you really look at this and then call for (dd=d[k=0]; k&lt;sizeof(d)/sizeof(d[0]); dd=d[++k]) (that does a similar thing in C) ugly? Non-conforming? yes. Ugly? No.
That... that looks horrible, syntactically. Is there any performance gain?
Is the performance the same as using an index in a range to iterate? Better? Is the syntax more readable?
The performance should be identical. The syntax is probably a bit more readable once you're familiar with a more functional style, but there would be a bit of boilerplate. The real benefit I tend to find from doing things in a more functional way is that bugs seem *way* less frequent. In general, if you can get it to compile, there won't be any bugs. I really like using the type checker to eliminate as many bugs as possible. If you're messing about with indices and pointers and stuff, it is much easier to get your arithmetic wrong in some small place and end up with a bug.
&gt; No, it doesn't on basically any platform where sizeof(int) &gt; sizeof(char) Now YOU'RE claiming that "I know what my CPU does" :) I don't care that it works - it's undefined behavior! A compiler can "optimize" it out, breaking your code. That's the whole point. Here you just committed the same "error" you chastise others for doing - basically saying "technically it may be wrong, but it works anyway so it doesn't matter". Also: &gt; and it has always been a retarded way to begin with. I wrote about it here. you completely ignored my whole point that using INT_MAX is very limiting: it depends strongly on knowing the type is `int`. What if you want code that works for all types? What if you change type later? That code in your example isn't portable in the least! (and don't give me "numeric_limits", although this is a C++ forum, this code is in C) Also your discussion is about a different case than what I did. See, your discussion is about assuming that INT_MAX+1 becomes INT_MIN. I never assumed that. All I assumed is that (max value + 1) &lt;= (max value) which will be correct under any and all implementations (except that it's undefined). Again, had the result been **undefined value** rather than **undefined behavior** , it would work. This is very different than your example from your link. I know things "have better meaning if done differently", but that's not the point. Being "captain hindsight" doesn't work. The whole point of "captain hindsight" is that he isn't helpful, yet that's all you seem to be doing here. Finally, you want people to write code like this `(c-'A') + 'a'`? No. That's not a good solution. You compare it to things like `++i=i++`. But that's not the same at all. `++i=i++` isn't even clear what you want it to do. But the desire that `c-'A'+'a'` being the same as `c+'a'-'A'` is very clear indeed. The assumption that the order of addition/substraction doesn't matter in "int-like types" is very important. People use it all the time to "open parenthesis" and change the order of stuff to optimize code for example, remove stuff that unneeded etc. Let's look at your example again: you claim that doing (c-'A')+'a' is the "correct" way. Well, readability-wize maybe, but actually the "correct" way code-wize is: c-('A'-'a') as that is a single "addition" (since `'A'-'a'` is a constant evaluated at compile time). And it happens to be that `'A'-'a'` is so well defined that we know it doesn't overflow/underflow, because we know what the numbers are. But in similar other cases it isn't true. Going back to my pointer example: int *q1 = B+(p1-A); is "readable" but does 2 additions (unless the compiler is smart enough). The "correct" (optimization-wize) way is int *q2 = p1+(B-A); which does a single addition, but this can result in undefined behavior. And DON'T tell me "the compiler will do that for you anyway". No. That isn't a solution as we know - because we know that reordering things manually, removing calculations that end up being unnecessary etc. is still important when optimizing code. We can't trust the compiler to optimize for us, as it still doesn't do it well enough. And we know that smaller platforms have "less good" compilers - but we still want to write efficient code for them. We can't just write "inefficient code" and tell the compiler to "sort it out". So changing order in addition like that is important - if it becomes unclear, document it, but you have to be able to do it. And to be able to change the order like this I must be able to trust the language to behave "well". My solution is to try and use "unsigned" when doing this. But that's annoying and unreadable as well. I still do all these "tricks", but I'm forced to be aware of what I'm doing. I'm not saying we should "fix" C. Not at all. I am saying that writing a compiler that is "correct" but breaks all the existing code out there makes it a bad compiler, in the sense that it's "unusable". So yea, maybe clang++ is compliant. But if it fails to compile a large number of important codebases - then that doesn't matter. It's still not useful enough. And if so many established codebases are non-compliant, then we have a big problem in our language and no amount of "they should have written it differently" would solve that. It only serves to ignore a big problem that exists. 
&gt;&gt; overkill use of boilerplate get/set accessors is long dead. oh another point: actually there is a strong usecase for get/set accessors for certain types of refactoring: see jonathan blows videos on a language for games: he's added inbuilt support for components hidden indirection, to allow the same code to use different data-layouts. cache-optimization is an empirical process. To get the same effect in C++, you'd just have to use getters/setters universally. So, more syntax sugar helping that (e.g. properties) would be welcome.
I wish there was a notion of filtered iterators, where you could specify a predicate on the iterator itself. Then you could easily use more of the std::algorithms. Example: There is no std::transform_if, but it's a pattern I find myself wanting to use. If I could supply a predicate to the iterator range, I could use transform as it stands to accomplish this. 
It exists for the same reason BOOST_FOREACH exists, and also the new C++11 for loop. They do the same thing (except for the "compliance" part). Why are you OK with one and not the other? Why do you claim writing C_FOREACH(dd,d) satd+=(dd&lt;0)?-dd:dd; isn't "better" than for (unsigned i=0u; i&lt;sizeof(d)/sizeof(d[0]); ++i){ int dd=d[i]; satd+=(dd&lt;0)?-dd:dd; } but still maintain that the new C++11 for loop for (auto i:v) ... is better / more readable than for (auto it=begin(v);it!=end(v);++it){ auto i=*it; ... } Why do you claim the first is better here (and you did that in a previous post) but not claim the C first one is better up there? Can you show me a good reason why you understand the need for the C++11 for loop but still fail to understand the appeal of the C_FOREACH loop?
The backwards compatibility break isn't an issue because he's only advocating doing it for new customization points. Users have to learn new ways of doing things, but no existing code is broken (unless they switch to the conceptified standard library, which may be breaking bc anyway).
I am not claiming that the BOOST\_FOREACH is in any way bad. (Apart from admitting that the implementation is ugly.) So, C_FOREACH(dd,d) satd+=(dd&lt;0)?-dd:dd; is of course better than the shit in h264-ref is.
Well, TIL If you can show me the paragraph from the standard I'll be very happy indeed. 
But C_FOREACH(dd,d) is implemented by doing this for (dd=d[k=0]; k&lt;sizeof(d)/sizeof(d[0]); dd=d[++k]) This is the implementation of the thing you admit "is better". Can you think of a different way to implement it (using only C syntax)? And even if you can - the point is that the code itself isn't ugly. It is "better" like you said and more readable. The "bug" was in the `#define` that uses undefined behavior (which makes it bad) BUT - it's bad ONLY because of the undefined behavior - not the "unreadability" as you claimed.
Can you expand a bit about the new "sequence-before/after" mechanics change of C++11?
Introduction to Section 5 (Expressions), paragraph 10. (5.0.10 if you like): Many binary operators that expect operands of arithmetic or enumeration type cause conversions and yield result types in a similar way. The purpose is to yield a common type, which is also the type of the result. This pattern is called the usual arithmetic conversions, which are defined as follows: * If either operand is of scoped enumeration type (7.2), no conversions are performed; if the other operand does not have the same type, the expression is ill-formed. * If either operand is of type long double, the other shall be converted to long double. * Otherwise, if either operand is double, the other shall be converted to double. * Otherwise, if either operand is float, the other shall be converted to float. * Otherwise, **the integral promotions (4.5) shall be performed on both operands.** ^61 Then the following rules shall be applied to the promoted operands: * If both operands have the same type, no further conversion is needed. * Otherwise, if both operands have signed integer types or both have unsigned integer types, the operand with the type of lesser integer conversion rank shall be converted to the type of the operand with greater rank. * Otherwise, if the operand that has unsigned integer type has rank greater than or equal to the rank of the type of the other operand, the operand with signed integer type shall be converted to the type of the operand with unsigned integer type. * Otherwise, if the type of the operand with signed integer type can represent all of the values of the type of the operand with unsigned integer type, the operand with unsigned integer type shall be converted to the type of the operand with signed integer type. * Otherwise, both operands shall be converted to the unsigned integer type orresponding to the type of the operand with signed integer type. ---- 4.5 (Integral promotions), Paragraph 1 (4.5.1): **A prvalue of an integer type other than bool, char16_t, char32_t, or wchar_t whose integer conversion rank (4.13) is less than the rank of int can be converted to a prvalue of type int if int can represent all the values of the source type;** otherwise, the source prvalue can be converted to a prvalue of type unsigned int. ---- 4.13 (Integer Conversion Rank) Every integer type has an integer conversion rank defined as follows: * No two signed integer types other than char and signed char (if char is signed) shall have the same rank, even if they have the same representation. * **The rank of a signed integer type shall be greater than the rank of any signed integer type with a smaller size.** * The rank of long long int shall be greater than the rank of long int, which shall be greater than the rank of int, which shall be greater than the rank of short int, which shall be greater than the rank of signed char. * **The rank of any unsigned integer type shall equal the rank of the corresponding signed integer type.** * The rank of any standard integer type shall be greater than the rank of any extended integer type with the same size. * The rank of char shall equal the rank of signed char and unsigned char. * The rank of bool shall be less than the rank of all other standard integer types. * The ranks of char16_t, char32_t, and wchar_t shall equal the ranks of their underlying types (3.9.1). * The rank of any extended signed integer type relative to another extended signed integer type with the same size is implementation-defined, but still subject to the other rules for determining the integer conversion rank. * For all integer types T1, T2, and T3, if T1 has greater rank than T2 and T2 has greater rank than T3, then T1 shall have greater rank than T3. [ Note: The integer conversion rank is used in the definition of the integral promotions (4.5) and the usual arithmetic conversions (Clause 5). — end note ] 
&gt; is implemented by doing this Oh, ok, I completely overlooked this. That is also why I said that I don't see how this is related. But in that case: Yes, I do criticize non standards-compliant code, even if it is in boost. 
&gt; will this be implemented in the future? I would be surprised if it wouldn't. For now it is sadly another case of “use boost or roll your own”, where the later is luckily not too bad. There are however things that are currently way to complicated to do. Even something simple as above mentioned filtered view is harder than it should be. You can find my implementation [here](https://github.com/Florianjw/libyoga/blob/v3/src/include/filter_range.hpp) but don't feel bad if you don't understand it. Then there are things that are close to hell if you want to do them right. The hardest that I have successfully tried so far is a carthesian product of ranges. It can be done, but it really is about the limit of complexity that I am feeling capable to write correctly. Considering that most people like to stop way before I do, this really is a problem. ([Implementation](https://github.com/Florianjw/libyoga/blob/v3/src/include/multi_range.hpp)) Maybe I will one day try to implement powerset, but I know already now that this will be more of a harsh challenge than it should be.
I knocked up a minimal version where `range` just has the member functions necessary to be used in your code: #include &lt;iostream&gt; template&lt;typename T, typename Step&gt; struct range_t { struct iterator { T operator*() const { return value; } void operator++() { value += step; } bool operator!=(iterator const &amp;other) const { return value != other.value; } bool operator&lt;(iterator const &amp;other) const { return value &lt; other.value; } iterator(T value, Step step): value(value), step(step) {} private: T value; Step step; }; iterator begin() const { return b; } iterator end() const { return e; } range_t(T first, T last, Step step = 1): b(first, step), e(last, step) { ++e; } private: iterator b, e; }; template&lt;typename T, typename Step&gt; range_t&lt;T, Step&gt; range(T first, T last, Step step) { return range_t&lt;T, Step&gt;(first, last, step); } template&lt;typename T&gt; range_t&lt;T, int&gt; range(T first, T last) { return range_t&lt;T, int&gt;(first, last, 1); } int main() { for (auto i : range('a', 'f')) std::cout &lt;&lt; i; std::cout &lt;&lt; "\n"; for (auto &amp;&amp;i : range(24, 31)) std::cout &lt;&lt; i &lt;&lt; " "; std::cout &lt;&lt; "\n"; for (auto i : range(100, 1, -3)) if ( i &lt; 90 ) break; else std::cout &lt;&lt; i &lt;&lt; " "; std::cout &lt;&lt; "\n"; } note: step version has to finish exactly on the end otherwise it causes UB; adding the ability to go past the end will lose some generality in what types can be used to form the range (since other types of ranges might not support less-than) and also need a bit of a code redesign. NB. Not sure what the single-argument range was supposed to mean
A lot of frequently quoted rules aren't really meant to be absolute. People tend to forget that what they really mean is "**prefer** this technique, **when appropriate**, but **don't turn your brain off**". An integer-range iterable pseudo-container might be nice, but not really because of range-base for. The gains for simple loops through integer ranges are marginal, plus range-based for is only simpler at all because it's also less flexible (e.g. you can't loop through the range backwards, or choose between an inclusive or exclusive end bound - well, not without becoming just as complex to use anyway). Where it might be more beneficial is when working with generic code that doesn't know what kind of iterable range it's dealing with, so you can call it for a range of integers without the expense of having to create a vector and fill it. Instead of having to remember the name of (I think) `iota`, you could use a copy algorithm to copy from an integer range pseudo-container. I found myself tempted recently to use a range-based for as an if. I have a library (probably duplicating something you can get from boost) which acts as an at-most-one-item container. It's a little bit like unique_ptr but it's not a pointer (the item is constructed inside the instance when needed using placement new and explicit destructor call tricks - there's no heap allocation for the element, which was a big part of the original point) and it provides most of the interface of a container. So you can do a range-based for to iterate the elements in the container, but there's at most one element in the container, so it's a kind of if-the-element-exists conditional that also provides access to the element via the loop variable. It's tempting, but I suspect the principle of least surprise is against using range-based for as an if. 
I don't rate myself as fully qualified to answer, so take what follows with a grain of salt. The big difference between the two concepts is in how they are defined in the standard. From 1998 §1.9 ¶11: &gt; At sequence points, volatile objects are stable in the sense that previous evaluations are complete and subsequent evaluations have not yet occurred. Note that this just means that at sequence points, the expressions on each side are executed in some order. It doesn't say anything about what happens in multithreaded environments or in more complex systems. So, from 2011 §1.9 ¶13: &gt; *Sequenced before* is an asymmetric, transitive, pair-wise relation between evaluations executed by a single thread (1.10), which induces a partial order among those evaluations. Given any two evaluations *A* and *B*, if *A* is sequenced before *B*, then the execution of *A* shall precede the execution of *B*. If *A* is not sequenced before *B* and *B* is not sequenced before *A*, then *A* and *B* are unsequenced. [ *Note:* The execution of unsequenced evaluations can overlap. — *end note* ] Evaluations *A* and *B* are indeterminately sequenced when either *A* is sequenced before *B* or *B* is sequenced before *A*, but it is unspecified which. [ *Note:* Indeterminately sequenced evaluations cannot overlap, but either could be executed first. — *end note* ] Note that now, the language has the ability to describe atomic operations in large, complex, multiprocessing environments. Now, if I say some expression is sequenced before another, then it is expected to be fully executed and its results stored before the other expression begins, even if it's in another thread on another CPU. The 2011 standard goes on in ¶15 to explain that expressions like `i++` are *unsequenced,* and clarifies why, exactly an expression like `i = i++;` is undefined. The 1998 standard doesn't have a clear definition of its execution model to explain that, and instead explains it in the much later section on expression evaluation, §5 ¶4. This was all necessary so that C++ could gain a consistent execution and memory model that would support the threading model they were adding.
Ok, i thought I knew C++, but...what does this double-noexcept syntax do? struct __begin_fn { template &lt;class R&gt; constexpr auto operator()(R &amp;&amp; rng) const noexcept(noexcept(begin(forward&lt;R&gt;(rng)))) -&gt; decltype(begin(forward&lt;R&gt;(rng))) { return begin(forward&lt;R&gt;(rng)); } };
Can't you write a macro that transforms a range for loop into an old style loop? I'm speaking about something like Qt's FOREACH loop.
&gt; I've never really been a C programmer. But I think that just a simple notion of destructors is so unbelievably powerful, that as a C programmer I would consider moving to C++ just so I could compile and get destructors. I've used this feature of the language (destructors) many times to get embedded programmers to warm up to the language a little bit. In embedded programming, opportunities to exploit destructors &amp; RAII are everywhere - obviously dynamically allocated resources, but also things like disabling/restoring interrupts (critical sections), mutex acquisition / release, timing on an oscilloscope (GPIO toggle), etc. There is a great Stroustrup quote floating around, something like, "The most powerful feature in C++ is the closing brace" or something like that (implying the running of destructors at a specific point, including a local scope). **Can anyone find that quote?** My Google-fu is defeating me.... EDIT: [Found it - PDF Warning](www.stroustrup.com/CVu263interview.pdf). &gt; Just that closing brace. Here is where all the ‘magic’ happens in C++. Variables get destroyed, memory gets released, locks get freed, files get closed, names from outside the closed scope regain their meaning, etc. This is where C++ most significantly differs from other languages. It is interesting to see how destructors -- an invention (together with constructors) from the first week or so of C++ -- have increased in importance over the years. So many of the modern and most effective C++ techniques critically depend on them 
There's a lot of misinformation here. The Predicate-based concepts *are not* weaker than "archetype-based concepts". You're just looking at the surface and seeing the true/false bit, so it's easy to miss the big picture. It is true that Concepts Lite does not mandate separate checking, but that doesn't mean it can't be done. To understand this, you have to understand what those predicates in Concepts Lite actually mean. Those predicates are transformed into sets of constraints that express roughly the same kind of information that shows up in a declaration in an 0x concept. You can think of those constraints as sets of required operations and type names. Checking a template against its constraints requires ensuring that every type and expression in the template can be found within the constraint sets. You could also think of this as asking if the set of dependent expressions and types in your template are subsumed by the constraints. It's actually a bit harder than that in practice, but that's the basic idea. I find what you state to be a HUGE problem as a wildly overstated concern that simply isn't based in reality. Stroustrup discusses them very briefly in a 2009 paper as "negative asserts", and I incorporated the idea into an early concept emulation library that I wrote in 2009-2010. I struggled to find reasonable motivating examples when I did that work 5 years ago, and in the years since I have *never*, *ever*, *ever* found a use case for them that wasn't utterly contrived (including the example in the paper I wrote about that work), and I have *never*, *ever*, *ever* found the need to use this in my own work. My feeling on this topic is that if you're using Concepts Lite and you find that you *really* need to explicitly negate a concept, then you can do one of two things: 1. step back and find where your design has fallen apart and led to this point, and then fix your design so it doesn't require that feature, or 2. use a tag class or member to artificially differentiate one concept from the other. I call #2 "syntactic differentiation" -- a means of syntactically differentiating concepts that appear to differ only in semantics. This happens with InputIterators and ForwardIterators (depending on the formulation of concepts). That's a slightly different form of the problem, but the principle is the same. Source: I'm responsible for Concepts Lite.
 &gt; This is impossible to write using predicate-based concepts. Wrong again. It is simply *not currently possible* because this requirement wasn't high on the list for the design of Concepts Lite. This is actually possible with a relatively small change to Concepts Lite and those "generic requirements" should be checkable without any significant changes to the existing language. I don't expect you to know that --- I just figured out the basic mechanism a month ago --- but please stop saying that things are "impossible" with Concepts Lite. You clearly do not understand the design of the language features, and your responses to these questions are misleading at best.
“Look, that's why there's rules, understand? So that you think before you break 'em.” ― Terry Pratchett, Thief of Time
It's a matter of coding standards. As long as you're consistent within your entire project, this formatting is nothing you will be murdered for. Preprocessor commands are usually not indented precisely to make them stand out from the code, to signal that they are something that will not be executed at runtime but at compile time. Personally, I would recommend (if you want to indent the preprocessor commands) to indent the actual code within the `ifdef`/`else`/`endif` block an additional level, i.e.: bool BasicApp::initOGRE() { #ifdef _DEBUG resources_cfg = "resources_d.cfg"; plugins_cfg = "plugins_d.cfg"; #else resources_cfg = "resources.cfg"; plugins_cfg = "plugins.cfg"; #endif root = new Ogre::Root(plugins_cfg); Just to make the seperation easier to see. Another compromise some people use is to put the `#` at the beginning of the line and just indent everything after that (which, in my opinion, makes for a much better reason to murder somebody than your choice does). E.g.: bool BasicApp::initOGRE() { # ifdef _DEBUG resources_cfg = "resources_d.cfg"; plugins_cfg = "plugins_d.cfg"; # else Anyway, in the end, it's your project and your choice. Consistency is what really matters.
I often find that I have two containers, eg two vectors of equal length, and I need to iterate through both of them at the same time. As far as I know, I can't use iterators for this, but people seem very against raw loops. Even when I can write iterator'd loops, half the time I have to swap back because I end up needing the index position. Am I being a complete idiot and missing something? Or are the c++11 loops just not that useful? 
What you want is a zip iterator. http://www.boost.org/doc/libs/1_57_0/libs/iterator/doc/zip_iterator.html
Dear Haskell, thanks.
It's just demonstrating the single-argument range, so that it can loop infinitely until you break.
Interesting, I originally had the extra indentation as well, but I found it caused some weird issues with nested preprocessor calls, where the indentation got a little wonky, but I do like your version better.
I agree with you that it would be best to try and write the code a little nicer to begin with. This was just an example taken from the Ogre3d setup framework they use. I also like the idea of taking the literals out of the function's scope entirely. The example from the same framework that really reminded me of this nuisance was the main function adjusted for different platforms: #if OGRE_PLATFORM == OGRE_PLATFORM_WIN32 INT WINAPI WinMain(HINSTANCE hInst, HINSTANCE, LPSTR strCmdLine, INT) #else int main(int argc, char *argv[]) #endif { BasicApp app; try { app.go(); } catch(Ogre::Exception&amp; e) { #if OGRE_PLATFORM == OGRE_PLATFORM_WIN32 MessageBox( NULL, e.getFullDescription().c_str(), "An exception has occured!", MB_OK | MB_ICONERROR | MB_TASKMODAL); #else std::cerr &lt;&lt; "An exception has occured: " &lt;&lt; e.getFullDescription().c_str() &lt;&lt; std::endl; #endif } return 0; } If you don't mind, how would you approach this example? This seems to be closer to your preferred usage examples of choosing OS. The examples I looked at from Boost seem to also indent the code inside the preprocessor block (even includes), except they began each line with a # to create a solid block. Like this: #if A == B # stuff.do(); #else # other_stuff.do(); #endif I don't mind that either. I think both are better than the traditional way. Thanks for your thoughts!
I'm a major detractor here in that I prefer to *always* have my preprocessor things defined as either `0` or `1` like so: #ifdef _DEBUG # define MYAPP_DEBUG 1 #else # define MYAPP_DEBUG 0 #endif For your example, my code would look like this: bool BasicApp::initOGRE() { if (MYAPP_DEBUG) { resources_cfg = "resources_d.cfg"; plugins_cfg = "plugins_d.cfg"; } else { resources_cfg = "resources.cfg"; plugins_cfg = "plugins.cfg"; } root = new Ogre::Root(plugins_cfg); I do this for a number of reasons: * I think it reads a lot better. * Using the symbol is totally valid, so it fits in ternary operators, too. * Forces code to keep compiling, even if nobody uses the configuration. * It fits nicely into [Boost.Preprocessor](http://www.boost.org/doc/libs/1_57_0/libs/preprocessor/doc/index.html) * The compiler optimizes out the `0` branch.
`range(0)` gives an infinite loop? wtf
What happens when the value exceeds the maximum int?
UPD.: This interview on YouTube. https://m.youtube.com/watch?feature=youtu.be&amp;v=PlEKa_haXCM
It's not my proposal. It's written on the github page. &gt; `range` with a single argument deviates from the Python semantic and creates an endless loop, unless it’s interrupted manually It makes sense to me, since you're only giving it a start value, but no end value. Not that I think it has many uses, but why not.
Maybe you didn't read his page. His code wasn't a proposal, it's a working library: https://github.com/klmr/cpp11-range
No, I thought someone was just making a proposal on this thread for a range syntax like Python.
What is your justification for this?
What's up with all the json libraries? I remember like five different json libraries coming out in the last couple of month.
Depending on the operation you want to do, you totally can. See std::inner_product and std::transform.
Unfortunately I'm dealing with gpus and I can't for performance reasons
I am of the opinion that Boost is de-facto in the C++ world. If you're doing serious C++ development and not using Boost, you're missing out. 
I've been using jsoncpp for my json stuff, and while I like jsoncpp I'll give this a shot later to see how good it is. 
Really well done, maybe not perfect, but it's one of best I saw recently.
The argument against indenting is that it's not /really/ part of the code once it's pre-processed. ie Imagine what it would look like post-pre-processing: the indentation would be wrong. But yeah, what everybody else said.
&gt; There are two ways to generate the capture files – with and without instrumentation. In non-instrumented mode, MTuner injects the process of profiled application and hooks low level system allocation functions. In instrumented mode, allocations are marked explicitly by the user and no hooking is required. what does that mean?
 &gt; &gt; It is simply not currently possible &gt; I wasn't discussing the current design of Concepts Lite. I was discussing the design of predicate-based concepts in general. I don't think you can separate those ideas in this thread. The only true "predicate-based" constraint systems in C++ are those written enable_if. Concepts Lite turns out to be very different under the hood. &gt; &gt; I don't expect you to know that --- I just figured out the basic mechanism a month ago &gt; Care to elaborate? I don't see how this is feasible without two-phase checking. Assuming you can declare template parameters within a concept definition (say, as part of a requires-expression), then determining if constraints involving those unbound template parameters essentially reduces to separate checking. But it has nothing to do with concept maps, if that's what you're thinking.
Sounds like the non-instrumented mode is non-intrusive, i.e. you don't need to recompile your program: It hooks itself into certain functions via DLL and system-level injection. Instrumented mode probably requires recompiling with a certain flag, and then MTuner can analyse your app directly (and probably more precisely).
But what does the user "mark explicitly"?
Neither of these seem to work for me (only two ranges?) To give a concrete example of what I'm trying to do, I have 3 vectors of x, y, and z coordinates. They're in separate vectors because at the end of all this, they're going to get written to the gpu, but there are legitimate performance reasons for doing this as well I need to process all these and do some sort of horribly expensive calculation, involving all 3 elements, then store the new elements back at the end. Iterators just don't seem to work for this without having to kludge the shit out of it
Yes, that's exactly the case. Non-instrumented mode is injecting a process and requires no recompilation. The instrumented mode is manual, requires minor code modifications but gives more flexibility like custom events, allocation grouping by tag, etc.
See this [blogpost](http://tsdgeos.blogspot.in/2014/08/kde-releases-in-future.html).
It sounds like you're doing SOA-style processing. I always fall back to normal loops for that kind of work. I wrote a machine learning application last month, and it was very heavy on std::transform and std::inner product. But I've found out the compiler was unable to vectorize my loops. I switched over to C style loops with explicit vectorization instead.
This is way, **way** out of date. It looks like it was written before C++98, never mind C++11/14. I mean, `&lt;iostream.h&gt;`, for heaven's sake?!
http://coverclock.blogspot.fr/2012/04/learning-by-doing.html And there was another blog post where a guy had an embedded software written in highly-optimized C where the end size was about 8kb. They rewrote it using templates heavily, and thanks to the better optimizations available, it went down to 2.5kb.
&gt; Json j; //notice it's simple JSON class, no values, arrays and stuff I'm not sure what your comment means here. A default-constructed `Json` seems like it should have a value of some kind (in JSON Voorhees, `value`'s default constructor gives you a `null`). &gt; j &lt;&lt; stringifiedJson; //generate json from given string In JSON Voorhees, instead of calling that `operator&lt;&lt;`, I call the operation `parse`. So, `j = parse(stringifiedJson)` is the equivalent. If your string happens to be a literal, the suffix `_json` gets you what you want (i.e.: `"[1, 2, 3]"_json`). &gt; j &gt;&gt; someString; //generate string from given json In JSON Voorhees, the equivalent operation is called `to_string` (like the Standard Library) -- `someString = to_string(j)`. If you want to output to an `std::ostream`, it is called `operator&lt;&lt;`. &gt; j["apple"] = 5; //give any value to this non-existent until now key in json object That behavior seems quite odd when coupled with your previous: &gt; j = stringifiedJson; //error, type mismatch Both a number and a string are valid JSON values -- why does number get an implicit cast to a `Json`, but a string doesn't? &gt; j[2] = "[\"arrays\", \"of\", \"the\", 7, \"different\", \"types\"]"; //ok, j[2] will be string Is `j` implicitly transformed from an object into an array here? JSON Voorhees would give you a `kind_error`, as you're not allowed to index an object with a number.
JSON is pretty popular on the web. Serializing objects for transfer and serializing responses for queries both typically use json. JSON is JavaScript object notation, so it's easy to use in web programming.
What did you not like about JsonCpp?
No, I'm doing opencl which means that the data needs to exist as a contiguous chunk
Why not be more simple? Assuming you are only loading .cfg files, this approach can be easily expanded. std::string operator"" _cfg ( const char* str, size_t) { #ifdef _DEBUG auto postfix = std::string("_d.cfg"); #else auto postfix = std::string(".cfg"); #endif return str + postfix; } Then the calls look like this: root = new Ogre::Root("plugins"_cfg); Its the same :o Well, almost.
Just a totally random comment: I would welcome a link from the documentations main page (http://tgockel.github.io/json-voorhees/) to the actual Github project, so I don't have to guess-type it. Or am I missing it?
Boost is _huge_. For a small or even medium-sized project, it's likely a hundred times larger than the rest of your project. At work I rely on Boost. For my smaller, open-source projects I do not.
There is a link, but it is pretty non-obvious ("It is hosted on [GitHub](https://github.com/tgockel/json-voorhees)"). I should make that better...
Another, related, form of analysis which is useful is static stack usage analysis: with a callgraph and the stack usage of each function (which is fairly easy to extract from most compilers), you can work out the stack trace which will result in maximal stack usage and what that usage will be. Most commercial IDEs focused on embedded systems have this but they can be annoyingly difficult to extend and I've not seen one which dealt with virtual functions nicely yet (they tend to be a bit C focused: one would output 'xml' but failed to escape C++ template functions). The kind of analysis you are already doing would be easy to generalise slightly for e.g. init-only functions (like heap allocation), interrupt-safe functions, and so on. What would be truly godly would be static worst-case execution time analysis, but that is pretty damn difficult (even assuming you're on an embedded system with no OS and a simple CPU).
Off the top of my head... * The default constructor requires an allocation, which makes it difficult to use in an array * No support for `move` * Use of the same iterator for both array and object types, despite the "element" of an array and object being different * No support for a range-based for loop on objects * Some of the queries don't make sense -- `Value::isObject()` returns `true` if the value is `null` * Impossible to use at static destruction time because of the memory management system * The safety of many operations relies on `JSON_ASSERT`, which is compiled out in release mode of the default configuration, meaning you can easily end up jumping into random bits of memory * Certain read operations can change the kind of a value type (for example, using a `null` as an array makes it an array) * No built-in convenience functions for construction (`jsonv::array({ 1, 2, 3 })`) Some of those complaints might be from 2012 when I first wrote JSON Voorhees, but I can't say I've looked back.
Right, but his point was that this subreddit has been saturated with new C++ JSON libraries lately. Is there something wrong with the multitude of options that are already out there?
I'm using the noise filters in my video editing software. The beamer noise is pretty dominant in the original.
I suppose people keep making more because there are things they don't like about the available ones. I have only used RapidJSON and Cereal both seemed adequate, so I am not the person to do a case study on the different APIs. I think it's great that people are exploring different syntaxes, and naturally they are going to do so in whatever they need at the moment. I guess a lot of people need to serialize things and see opportunities for exploring new ways of doing so.
I agree and am aware, my point was that there is a serious developer benefit to arranging data as an array of structs when that performance isn't necessary.
Well, that seems valid. It's not like you condemned the practice altogether, I'm not sure why you got downvoted so much.
Sorry about that, I guess I forgot to copy over the license from when I rewrote this. The GPLv3 is now specified in the repository.
Maybe that means you should just start making things and reference a tutorial?
Excluding the issues that variable sized stack arrays and recursive functions introduce, a stack based analysis would be pretty feasible with this framework. There certainly do seem to be tools out there which can accomplish a fair bit of analysis with C, but they simply do not extend to C++. It's not too surprising given the additional cases that C++ creates. Per finding a hard upper bound, I'd love to be able to do just that, but the scope of that problem is just too large for this tool to solve.
Yeah, there are obviously ways to make static stack analysis equivalent to the halting problem, but most embedded code carefully avoids even the tricky cases (except for virtual functions and function pointers).
/r/dailyprogrammer
I actually forgot to when I started writing this because the all that I use on my tablet doesn't immediately show it. I see that they are great tools though.
How do you use Args in your bind_value? You never use them in bindValue, just pass them along in the recursion it seems. void bind_value(QSqlQuery&amp;, int ); template&lt;class T, class ...Args&gt; void bind_value(QSqlQuery&amp; query, int index,T t, Args... args) { query.bindValue(index,t); bind_value(query,++index,args...); } 
How exactly does it give more knowledge about what I want to do? Specifically. A template gets expanded. Duplicate templates may get merged, and certain instantiations of templates may be inlined. You will have to be more specific about what information you think a template could provide to a compiler that hand coded c++ couldn't. I've generated assembler for a number of small template functions this morning and I can tell you that the implementations for the template/non-template versions are identical to the op. I also can't find a single article describing templates as a vehicle for optimizing anything but source-code size. All higher-level languages require you to choose between code duplication and runtime overhead, and templates duplicate code to avoid runtime overhead (polymorphic lookups) -- this is the only 100% certain optimization that templates provide. Template inlining may increase performance by reducing cache misses, but you can hand code inlined functions, and this isn't special to templates. Sorry, I'm not buying it, no offense.
I've done this sort of thing before by making the constructors private. Then some free functions that are friends can construct the object in some custom way and return a const-something (pointer, reference, shared_ptr&lt;const object&gt;). This way gets around complicated logic and lots of work being done in constructors (throwing in constructors is a no no).
&gt; $149 per year Also, it's $149 *per user*, *per project*, per year. That will explode to ridiculous amounts of money very easily. You have a friend working on it? Doubled. Two? Tripled. Make a sequel to you indie game? Doubled. And so on... ...And you'd still have no email support. 
It would seem like a good piece of software, if it weren't for the prohibitive price tag. Also, nice shill account. If your prices are so high, can't you afford legitimate advertisement?
I'm going to have to disagree. Ranged-for is so much safer when it's used safely. The fact that raw-for maps well to integer ranges doesn't imply the reverse, and this is something it took me a _really_ long time to appreciate. Explaining why ranged-for is so much safer is like trying to convince someone there is a different, better type of air they could breathe. You can't possibly understand the difference until you actually get out of the smog, and once you do, it hits you like a ton of bricks. You never want to go back.
Hi, I'm the author of pdqsort. If you have any questions about pdqsort leave a reply to the main post and I'll do my best to explain.
seems ok to me. But rather than formatting "by hand", why not just use clang-format? http://clang.llvm.org/docs/ClangFormat.html
The explanation sounds very similar to libc++'s sort. Compare the paragraph from the pdqsort github: &gt; To get linear time for the other patterns we check after every partition if any swaps were made. If no swaps were made and the partition was decently balanced we will optimistically attempt to use insertion sort. This insertion sort aborts if more than a constant amount of moves are required to sort. With this paragraph written by the author of libc++ explaining the sort algorithm: &gt; If after the partitioning is complete, the number of swaps is 0, then the algorithm takes note: I've been handed an already partitioned sequence. Might it also be already sorted? To check, the algorithm does a "partial insertion sort" separately for both the lower partition and the upper partition. "Partial" here refers to the number of inserts that are allowed to happen during the insertion sort. There is a low limit (like 7 or 8) allowed insertions, and if that limit is exceeded, the "partial insertion sort" gives up and returns the information that it gave up. Else it will complete the insertion sort and return that information. ([full description](http://www.reddit.com/r/cpp/comments/2fa7i1/libc_has_quadratic_stdsort/ck7roe8)) You compared pdqsort with libstdc++'s sort. A comparison of libc++'s sort with libstdc++'s shows similar [results](http://i.imgur.com/P8k6KxE.png) (originally from [this presentation](http://i.imgur.com/P8k6KxE.png http://llvm.org/devmtg/2010-11/Hinnant-libcxx.pdf)). How does this algorithm compare to libc++'s sort? I wonder if the two share a common source of inspiration. Are the ideas in pdqsort based on some prior work, perhaps a published paper or something?
A god header tends to create problems; Usually, when I need to centralize values I choose a very simple file format (like text or ini) and create a configuration file; Then, I can choose the configuration at runtime, based on reading said file at runtime.
mr_ewg posted this a while back: http://www.reddit.com/r/cpp/comments/2vj3o4/train_of_thoughts_on_c_the_auto_keyword_versus/coi90cq for(auto i : indices(v)) { std::cout &lt;&lt; v[i]; }
I work for a major cloud software provider and people with HPC skills are valued here. But the thing that makes me happy to be a HPC related field is that I see a lot more people over that age of 40 and 50 so I see my skills in software being in the long run
Great comments. They would be even more valuable (and visible) if they were directly on the blog post.
How about Open CL?
&gt; Some of the queries don't make sense -- Value::isObject() returns true if the value is null Maybe because `typeof null === "object"` in Javascript. 
did you compare with a radix sort?
No. pdqsort doesn't intend to compete with radix sort at all, pdqsort is a comparison sort.
Is this just a very small subset of GMP/MPFR functionality that solves a particular problem? Seems like GMP/MPFR has much better test coverage &amp; would perform better. Licensing would be about the only issue I could imagine, but it is LGPL. http://en.wikipedia.org/wiki/List_of_arbitrary-precision_arithmetic_software
I assume that is where a lot of these strange decisions come from, which is fine. However, I would argue that if the library makes a distinction between `nullValue` and `objectValue` (like JsonCpp), the helper functions should as well. As a more general statement, I don't believe a JSON library needs to perfectly follow the rules of JavaScript -- C++ has a different domain and different expectations.
In my opinion tail-recursion is one of those extremely hyped things that really doesn't deserve that amount of praise. Most of the time it requires an additional parameter that is basically used as local mutable variable, making it just a complicated way to basically modify local state. Let's see an example: // We want to accomplish something similar to the following // but don't want to use anything but push_back(): auto append(std::vector&lt;int&gt; lhs, const vector&lt;int&gt; rhs) { lhs.append(rhs.begin(), rhs.end()); return lhs; } auto append_tail_helper(std::vector&lt;int&gt; lhs, const std::vector&lt;int&gt;&amp; rhs, std::size_t index) { if (index == rhs.size()) {return lhs;} lhs.push_back(rhs.at(index)); return append_tail_helper(std::move(lhs), rhs, index+1); } auto append_tail(std::vector&lt;int&gt; lhs, const std::vector&lt;int&gt;&amp; rhs) { return append_tail_helper(std::move(lhs), rhs, 0); } auto append_normal(std::vector&lt;int&gt; lhs, const std::vector&lt;int&gt;&amp; rhs) { for(auto x: rhs) {lhs.push_back(x);} return lhs; } Does really anyone claim that the tail-version is better? I really don't think this is an unfair example either, from what I've seen so far most cases are somewhat like this.
Do you need them with atomics and mutexes? Are they even different.
&gt; What is the best way to do a multi-thread buffer read-write lock in Standard C++? Use a condition_variable.
Have you filed a bug report? No reason tail-recursion shouldn't work with a 64-bit value on a 32-bit platform. 
You can implement a semaphore in terms of a `mutex`, a `condition_variable` and an integer (potentially of the `atomic` variety, but it is not required). I prefer using this method instead of the POSIX `sem_t`, as `sem_timedwait` is based on `CLOCK_REALTIME`, while I can force my `mutex` to be based on `CLOCK_MONOTONIC`.
Direct link to the video: https://www.youtube.com/watch?v=QAmtgvwHInM
From the author of Hana, the almost-a-Boost library that unifies Boost.MPL and Boost.Fusion.
You are right! I started to write this code with a earlier preview version of VS2015, and the compiler could not always deduce the return type, so I had to specify it after the "-&gt;" in a function like: template&lt;typename...Args&gt; auto operator()(Args&amp;&amp;... args) const -&gt; decltype(make_pipeable(std::bind(_op, std::placeholders::_1, std::move(args)...))) { return make_pipeable(std::bind(_op, std::placeholders::_1, std::move(args)...)); } But now that you told me this, I checked again, and this does compile with VS2015 CTP6: template&lt;typename...Args&gt; auto operator()(Args&amp;&amp;... args) const { return make_pipeable(std::bind(_op, std::placeholders::_1, std::move(args)...)); } Thanks! This simplifies the code :-)
I tried with VS2013 using Full Optimization /Ox still resulting to have the same problem
Nice. But you should initialize the counter in CounterComponent with something ;)
Thanks! I think it would be nice if you add the comparison with libc++ to the github repo, the performance is awesome. Do you know of any collection of patterns for benchmarking sorting algorithms? I've had the need for them a couple of times. 
If you look at bench/bench.cpp in the pdqsort repo you can see the patterns I use for benchmarking. I'm not aware of a big testsuite however, but I suspect the guys at libc++ are working on one.
The article makes the interesting observation that his semaphore impementation is faster than a condition variable. I don't suppose that's proof of anything; but it certainly suggests that its a subject worth more consideration.
Unless I miss something, your examples, though, attempt to compare recursion with iteration (and we all know which one would be better). To see the benefit of a tail call recursion, it must be compared to one that isn't. As we can see from OP's sample, if a recursion is doing tail calls, then the compiler can optimize it to do jumps instead of a normal function calls.
I've looked through the article 3 times, is the compiler where this occurs mentioned somewhere I'm just not seeing?
Oh man, this is really fucking nice, if you pardon my french. I'd be happy to chip in, but as a student I don't really have much disposable income.
Well, we absolutely sure this is nice - we're doing it not because of money, but because we can't "don't do it". We're just asking community to help us - in any way you can (spreading news over, funding us or sending us patches - no matter what exactly). We're just feeling this is right thing to do - and we do it.
Sorry for being a noob, but why is the pound '#' sign being used? I am learning c++ and all we use in class is curly brackets. Can somebody through me a name for what this is called so I can better educate myself? Thanks!
&gt; I'm not sure why I'm getting downvoted here. You claim "On more than a few benchmarks Java outperforms C/C++" but you don't provide any way that we can check that claim.
 #include &lt;iostream&gt; int main() { int x = 5; int y = 7; cout "\n"; cout &lt;&lt; x + y &lt;&lt; " " &lt;&lt; x * y; cout "\n"; return 0; } There are a few problems here (assuming I've reformatted the code correctly). First, the compiler probably doesn't know what cout it. You need to either use `std::cout` or write `using namespace std`. Look up namespaces in C++ Secondly you need to use the stream operator to send "\n" into cout. Like this: `std::cout &lt;&lt; "\n"` These might work better for you. #include &lt;iostream&gt; using namespace std; // this can be a bad idea int main() { int x = 5; int y = 7; cout &lt;&lt; "\n"; cout &lt;&lt; x + y &lt;&lt; " " &lt;&lt; x * y; cout &lt;&lt; "\n"; return 0; } or #include &lt;iostream&gt; using std::cout; int main() { int x = 5; int y = 7; cout &lt;&lt; "\n"; cout &lt;&lt; x + y &lt;&lt; " " &lt;&lt; x * y; cout &lt;&lt; "\n"; return 0; } or #include &lt;iostream&gt; int main() { int x = 5; int y = 7; std::cout &lt;&lt; "\n"; std::cout &lt;&lt; x + y &lt;&lt; " " &lt;&lt; x * y; std::cout &lt;&lt; "\n"; return 0; } In the future please format the code properly (check out reddit's formatting help), and please tell us the error that you get instead of just saying it doesn't work.
You should post this to /r/learnprogramming or /r/cpp_questions. Also that code formatting is terrible, here's a readable version: #include &lt;iostream&gt; int main() { int x = 5; int y = 7; cout "\n"; cout &lt;&lt; x + y &lt;&lt; " " &lt;&lt; x * y; cout "\n"; return 0; } The answer is simple, your `cout`s with the `\n`s are incorrect, which is interesting, since you got it right in the other case. The correct way is: `cout &lt;&lt; "\n";` The other thing is, you're missing the namespaces before `cout`, either: 1. put a `using namespace std;` between the `#include` and `main()` (not recommended). 2. or use `cout` with the `std` namespace: `std::cout &lt;&lt; "\n";` (this is more verbose, but it's the recommended way).
There's a critical difference between semaphores and mutexes that people rarely acknowledge. Most mutex implementations prohibit you from calling unlock() unless the same thread previously called lock(). std::mutex for example. Semaphores don't have that limitation. As such, you can't implement the auto-reset event or the read-write lock described in the post if a mutex is the only native primitive that you use.
I will file a bug if you can give me a command line repro with 2013 Update 4. I need the full source file, exact command line, and resulting codegen (use /FAs to emit an .asm), plus the compiler version as printed by cl.exe.
Actual link [here](http://ldionne.com/2015/03/16/laziness-as-a-comonad/)
/u/changetip $10
The Bitcoin tip for 35,248 bits ($10.00) has been collected by *crystax*. [ChangeTip info](https://www.changetip.com/tip-online/reddit) | [ChangeTip video](https://www.youtube.com/watch?v=_AnfKpypMNw) | /r/Bitcoin
[Preprocessor directives](http://www.cplusplus.com/doc/tutorial/preprocessor/). They are logic that is applied to your code *before* it is fully compiled. So when the file is actually compiled they have been removed. The #include statements you use at the top of a file are also preprocessor directives. They tell the compiler to basically cut-and-paste the contents of the included header into the source code that used the include statement.
I updated the article. I inserted a link to a GitHub containing the solution I used. You can clone the repo and try locally if you want. 
I've written C++ on mobile platforms for 10 years and I can assure you it is by far the most dominant language in cross platform mobile development.
I'm immediately reminded of the [Boost Range adaptors](http://www.boost.org/doc/libs/1_57_0/libs/range/doc/html/range/reference/adaptors.html).
Yeah, Python did a great job making this composable. I miss the elegance and simplicity of code like: lookup = {} for elem, index in zip(container, range(len(container))): lookup[index] = elem Which can be made more concise with either a list comprehension: [lookup.__setitem__(index, element) for element, index in zip(container, range(len(container)))] ....or dictionary comprehension: lookup = {index : element for element, index in zip(container, range(len(container)))}
It's hard to evaluate such a claim. For a naiive implementation you may be right. GMP/MPFR is optimized quite heavily though &amp; it wouldn't be surprising to me that it performed much better than a naiive fp128 implementation.
This is nice! How come I've never heard of the CrystaX NDK? It was completely off my radar. Is the Android NDK really that bad though? I thought it supported most of C++11/14 of what's in gcc 4.8 and that it was always improving.
&gt; Concept are such a big change that, moving forward, we have the opportunity to adopt techniques that let us avoid these problems. It is the fact that we have to explicitly adopt techniques to avoid problems that worries me. &gt; Check out Eric's recent post on customization points. [...] I think people too often forget that Eric does the best he can with what the language provides him. He has a working solution to a hard problem. If you've read his latest proposal _you know_ that he thinks that his solution is complicated, even for standard library developers and standardization committee members. What is, in your opinion, the difficulty that defining a customization point should have? In my opinion it should be trivial: it is an essential building block when writing generic libraries. Eric's solution _is not that complicated_, but I don't think it passes this bar. For these reasons I have to agree with /u/pfultz2 here. Member functions (and ADL) do not make nice customization points. Can we do better for C++? I can't, and I can't discuss this with you at your same level, since you are way more knowledgeable on the topic than I am, and you have tried a lot of different alternatives while I haven't tried to implement any. I like that Concepts Lite is coming and that it works. What I can tell you is that I've had brief experiences with writing some generic Rust code, and while it being far from perfect, I felt in love with explicit refinement + concept maps. That made defining customization points extremely easy, and they are used in Rust all over the place. I can, however, understand that what works well in Rust might work badly in C++ (or not work at all) due to interaction with the rest of the language. 
How do you implement the `allocator` concept with your solution (and, in particular, `rebind`)? 
Your second code example is missing the prototype.
If the code compiles regardless of the #define, that suggests to me that you don't really need an if()... at all. resources_cfg = CFG_FILE_NAME("resources"); plugins_cfg = CFG_FILE_NAME("plugins"); 
The same technique to check template definitions can be used to check calls to other template functions or classes.
IBM Concurrent Building Block is another good resource: http://amino-cbbs.sourceforge.net/
Does that mean that you can check that for an allocator A its rebind can be called for _any_ U that models the "rebindable" concept (U is constrained), without providing a particular U? If rebind is constrained, then when you pass it a type U,that still checks that particular type. Is that also possible if U is unconstrained? I think that will make little sense because you don't know what to expect of U. But if U is constrained you can already check that whatever U models the concepts works with that rebind. IIUC this is one of the reasons of rust lacking unconstrained generics. 
WTF is the matter with people?! Read too much of " 50 shades of grey" or something? I really hope nobody in their right mind would actually use this. **ComVisible!!!** 
Is this available in pdf? Doesn't appear to include a download link on the page. 
First it's more C than cpp, then, maybe you should do you class assignment solo instead of asking the Internet the answer ... The answer is so easy I can not believe you are asking such things ...
I'm still learnhing CPP but can someone explain the reason something like this would have its own compiler. 
Power781, I think OP wants the node that is X nodes away from the end, not that has a value of X. NonaBona, in my experience questions like the one you are trying to solve are designed to teach you about recursion. I'd start by googling that.
It's building code for your GPU which has a very different processor on it than the main part of the computer. Different processor == different compiler.
I have to say C++11 and the ability to use Thrust on the card may be a game changer for my set of projects. We've been on OpenCL for years now but with no NVidia support to speak of and being forced to use NVidia hardware means we're stuck on OpenCL 1.1 My real hope is that NVidia will release a Vulkan driver that's actually compatible and we can jump to OpenCL 2.1 but even that is starting to lag without some of the library support that CUDA has.
Thanks more reading material!
&gt; Does that mean that you can check that for an allocator A its rebind can be called for any U that models the "rebindable" concept (U is constrained), without providing a particular U? Yes. &gt; Is that also possible if U is unconstrained? If U is unconstrained then the checking is "masked". It will appear that rebind can accept any "rebindable" U as well a U that is not "rebindable". So even though the check passes, it could possibly produce an error at a later stage. Of course, I am not a researcher, so perhaps Andrew has some ideas on how to deal with unconstrained templates. 
&gt; The author of this should please follow their won advice. CamelCase is not consistent with the snake_case of the standard-library. A few things: 1. Not everyone uses the standard library. 2. Just because the standard library chose an ugly formatting standard doesn't mean you should do the same. 
I think that allowing unconstrained templates to fail at a later stage is a big no-no. But it is already nice that this would certainly work if all the parameters of the nested templates are constrained It also looks to me that this can be added after concepts lite without breaking backwards compatibility. AFAIK in concepts lite you cannot define concepts to check nested template functions at all. Continuing the allocator example, you have to check that T models the allocator concept when you might want to rebind it to a specific U: `Allocator&lt;T, U&gt;{}` (which can be T itself: `Allocator&lt;T, T&gt;{}`), but not for any U right now (e.g. `Allocator&lt;T&gt;` wouldn't check rebind). /u/andrewsutton ?
I agree with that, but I think that it might have been an idea worthy of consideration to use Upper_snake_case or something like that for types. The main argument that I see against that is that with the existence of function-objects the lines between types and functions aren't semantically that clear, which became even more prevalent with the arrival of lambdas. So: I see why people would prefer to use `std::Vector` over `std::vector`, but I consider it childish and unprofessional to decide against long standing naming-conventions.
I prefer my own code look good and since snake case is ugly I ignore the standard. Also spaces are better than tabs. 
So why would anyone use the non-free version?
Agreed, but I'd prefer underscores/snake_case even if it were ugly, because it has consistency and predictability. Mixed-case is inherently inconsistent and unpredictable. As an example, suppose you needed a function that converted XML to JSON. Using mixed-case, what would you name it? Would you use camelCase? Or PascalCase? Do you preserve ALLCAPS in acronyms like XML? Do you have any expectations about how someone else would name that function using mixed-case? Well, let's check google! First page search results for "xml to json" [xmlToJson](http://davidwalsh.name/convert-xml-json) - camelCase [XmlToJson](http://www.javased.com/?source_dir=riftsaw/console/integration/src/main/java/org/jboss/soa/bpel/console/json/XmlToJson.java) - PascalCase [xmlToJSON](https://www.npmjs.com/package/xmltojson) - starts with camelCase, ends with ALLCAPS. Why is JSON all caps, but not XML? [XmlToJSON](http://doc.wakanda.org/XmlToJSON.301-655766.en.html) - starts with PascalCase, ends with ALLCAPS. Again, why? [XMLToJSON](https://www.temboo.com/library/Library/Utilities/DataConversions/XMLToJSON/) - ALLCAPS, with a cute little 'o' in the middle. D'aww [xml2json](http://www.thomasfrank.se/xml_to_json.html) - Congrats bro, you saved one character by using 2 instead of "to"! [Xml2Json](https://code.google.com/p/infoscoop/source/browse/branches/3.0/src/main/java/org/infoscoop/util/Xml2Json.java?r=629) - As above, this time with leading caps. This is the clusterfuck of inconsistency that you have to deal with when using code written in mixed-case. Every mixed-case library has it's own notion of what mixed-case is supposed to look like, based on the personal preference or background of that library's developers. When mixing mixed-case libraries that use different styles you end up wasting your focus and concentration on trying to keep track of which library uses which style. [(brain capacity)](http://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two) Using all lowercase snake_case, there is only one way that function could have been written: **xml_to_json** . There is no room for inconsistency. No wasted brain capacity. And it's arguably prettier and easier to read this way too. Edit: This is an example of the bullshit I have to deal with in one of the projects I'm working on. Some libs and their naming conventions for types and functions: lib | type | function -|-|- SDL2 | SDL_Window | SDL_CreateWindow Xlib | Window | XCreateWindow xcb | xcb_window_t | xcb_create_window gtk+ | GtkWidget | gtk_window_new OpenGL | GLboolean | glCreateShader EGL | EGLBoolean | eglCreateContext Complete inconsistency. xcb is the only one with a sensible naming convention.
You are not legally allowed to profit from anything you create with the free version. (Basically, i'm sure the actual licence is more nuanced). Sounds like if you are an individual you may be able to sell your creations for a profit, but I still wonder if there are some restrictions. If you are a 'corporation' then you absolutely have to buy a licence. 
I severely miss the C# refactoring tools when programming in C++ in VS. That said I've never really seen an IDE do C++ refactoring reliably, but I've really only used Eclipse (which is better at it) and VS any decent amount.
No, that's incorrect. The community licence has a mac number of licences per project or company, I'm Not sure which. Also can't be used if your revenue is &gt;1mil usd. 
Have a look at KDevelop - they did allready a great job based upon Clang, even there is much more to come. And KDevelop is not a project with so much manpower... I have no experience with CLion yet, but I would doubt, that JetBrains would ship an IDE with a complete lack of simplest refactoring support... Of course that is quite hard to supply good Refactoring in C++ - but VS is there for more than a decade *and* it is a commercial tool. So I can not understand why they call that an IDE for C++. Only Debugging works quite well - nothing more imho. Lots of people probably just know about the C# features - which are much more elaborated! (And in VS2012 the Bookmark function is imho completly broken as it relies *statically* to the *line* and not to the content!)
Try the JetBrains c++ editor, their stuff is generally amazing.
Yes, exactly my point :)
The intellisense in VS (even for C++ in latest versions) is excellent; it's very responsive out of the box, other than that, I generally agree about it not supporting it much. Older versions neglected it even more, to the point where intellisense barely did anything. I'm not doing any C++ at the moment, job or hobby. Using Vi to program C at my job currently. First time using it and I'm already loving it and missing it when using any other editor. I've heard good things about CLion and JetBrains, next time it's reasonable I'll definitely give them a look.
Could you use const CharT* c_str = "null"; const std::basic_string&lt;CharT&gt; null = c_str;
Yep. IIRC, the rule is &gt;5 devs or &gt;$1m in revenue and then you have to purchase licenses.
&gt; No, and I think your expectation that I should have done that is extremely unrealistic. I don't think it's unrealistic, but I do agree that it's not as easy. Hosting an online version is a good idea. I'll look into it. FWIW, it would never be as easy as using -concepts-lite-v0 on any compiler, since most maintainers would not include such an intrusive, experimental change in their release branches. You'd be building a compiler branch to use it.
I also think this can be added later without breaking backwards compatibility. If we had a `Rebindable` concept, then the compiler can check that: - `Allocator` has a `rebind` function constrained with `Rebindable`, and, independently, that - `rebind` requires `Rebindable` and nothing more. Independently of the `Allocator` concept being broken or not, if someone wants to e.g. implement Haskell type classes using concepts lite they are going to need this feature. I think this means that the feature is useful on its own. I'm all in for advancing step by step with concepts, but it is worth it to be sure that we can add the feature later without breaking backwards compatibility.
Quiet, you. It's dark out there. Neighbors are sleeping.
For a minute I thought you were talking about the old mainframe system. http://en.wikipedia.org/wiki/VAX
I didn't say the contrary. But until they do it 'right', you should definitely use VAX. That being said, it's not an easy thing to do and I don't think they currently have the manpower or time to do it, hence why it's much easier to just buy VAX. And no, I don't understand why you would feel that that makes it a bad IDE. It's got extension functionality to be used, so the extensions it has has to be taken into consideration, no? What other IDE would you recommend for C++ that has great debugging, great customization, and all of VAX's capabilities?
I know he is only using it as examples but for units I recently started using the boost::units library. It is pretty thorough and easy to set up new units if needed. In the cppcon video [Grill the commitee](https://www.youtube.com/watch?v=7P536lci5po) Walter Brown makes a comment about needing a language feature to do units properly, anyone know what feature he was talking about? 
someone just needs to link to the actual licence already, because i've heard so many contradicting statements. 
The right idea, but there really is no point in using inheritance at that point. Just create independent classes with implicit conversions between them if they represent the same thing (Celcius &lt;-&gt; Kelvin).
I think PascalCase and camelCase are ugly. Would it be okay for me to write a Java program with `snake_case` class names? Of course not.
I can see why Windows developers think C++ is awful and would prefer to use C#, if that is the sort of C++ they have to deal with.
Sure it would. The Java community is full of people I take extreme joy in annoying. If it upsets them go for it.
Of course it fucking wouldn't be okay. 
Great stuff, but I'd still prefer Qt's websockets module.
&gt; The Game module source code was released by 3D Realms on **April 1**, 2003. So was it actually released?
Makes sense, readability often hurts performance, and games, especially old ones, need every bit they can squeeze out of the hardware. I mean putting everything in one big function or using global variables liberally might allow for optimizations which would be impossible in a more modular code base. 
Thanks! Author here; happy to take requests/answer questions. Also - what do you prefer about Qt's approach? I've not looked at Qt all that much; I've been put off by its huge infrastructural overhead.
Great job, man. I have a naive question: the test result show that the Boost Asio libraty fails on apilevel-21-armeabi-v7a. Does it mean I cannot use Asio to build apps target on Android 5.0?
You can. If you look at http://www.boost.org/development/tests/master/developer/asio.html, you'll find that most ASIO fails are for x86/x86_64 ABI; arm targets are working better, and only couple of tests failed. This is results of testing Boost "master" branch, which is mostly the same what will be included to the upcoming Boost 1.58 release. From practical point of view, ASIO "mostly" works on Android, if you're using Boost release (not development branch), and we're going to fix rest fails soon. There are also many fails in Boost "develop" branch - http://www.boost.org/development/tests/develop/developer/asio.html, but most of that fails are compilation errors caused by bugs of development version of the ASIO. You shouldn't take into account fails of development versions - it's for Boost libraries developers, not for Boost users. Anyway, we're working on fixing all those bugs (together with Boost libraries maintainers) so situation will become better with time.
http://en.cppreference.com/w/cpp/language/lambda
Since this is /r/cpp, what C++ bindings do you all use with libcurl? I haven't looked into the situation in a long time so I don't know what's current, but once upon a time the C++ bindings were withering away as a third-party library that didn't receive much love and which wasn't all that great to use. I suppose it's possible everyone just uses the native C API, but surely there's got to be a nice modern C++11/C++14 libcurl wrapper, no? 
http://swtch.com/semaphore.pdf is a great read about semaphore implementation details. The algorithm described in this paper is today used in the Golang runtime for sleep/wake of Goroutines. Which means the mutex, condition, rwlock, channels, and other synchronization primitives provided by Go are all built on simple semaphores.
This is legitimately spot on. Stagnating because you're afraid of new challenges is something I get caught up on all the time.
Fantastic. I've been writing my own TMP library and have been keeping up with some of the others, and it's always interesting to see the differing philosophies of each. 
The fact that you're asking makes me think it won't be out as soon as I was hoping :( But thanks for asking, and since you are: I'd like it to have a switch for strict standards, like clang++/g++'s -std=c++11/1y/1z, etc. To apply to both core language and STL, and to TURN OFF features and extensions beyond the specified standard. As far as I know, there's no way to do this right now. The current system of just getting whatever you guys put into the language and library makes cross-platform development harder. It's not just that some C++11/14 features are missing, it's also that there are some extras in there which aren't standard, and it's easy to accidentally write code that MSVC accepts but that doesn't compile on other platforms. I like that you're making a big effort to come up to speed with C++14 and beyond, but even when MSVC is on par with clang++/g++, we'll always be in some kind of halfway house between standards, and it would make my life easier to be able to select a proper lowest-common-denominator standardswise, rather than dealing with some mix of lacking features and extensions. 
There are books for beginners and books for advanced. I'm not even sure you could write a book for that stage. Learning how to think through the problem, keep the codebase in your head and search for solutions is as much of the learning curve as anything a book could teach. That's why I always suggest working on an existing codebase that interests you. Add a feature, anything simple and work your way up. See how and why it breaks and fix it. That's the only way you'll get the kick in the pants to actually accomplish something and the kick in the gut of real world problems. 
I was looking at Summer of Code after finishing my Accelerated Intro to C++. Despair is exactly what I feel. 
I'm currently reading "programming principles and practice using c++", once I'm done I think I'll need to read other books because I'm pretty sure that after those 2300 pages I've only learned the bare basics.
Thanks, it's useful to hear that this is an issue. What you're asking for would be hard and problematic, but I see your rationale! In general, you are correct - VC has no mechanism to request specific Standard versions. (We do have fine-grained switches for a small number of compiler features, but they give us lots of headaches and we'd like to get rid of them.) The difficulty in providing 11/14/17 switches is that it would increase the amount of development and testing we'd need to do. 11 library features couldn't use 14 compiler features, for example, making development harder - and then we'd have more modes to test. The *real* problems happen when ODR violations are involved - e.g. linking 11 code with 14 code, when the guts of a library class are affected by the switch. Extensions, though, are a simpler matter. Since I began working on the STL, my policy has been to avoid extensions and non-Standard behavior, unless there is a very good reason and it is not especially harmful. For example, because calling conventions are a thing on Windows, the STL supports arbitrary calling conventions in &lt;functional&gt;. This works invisibly, at the cost of complicating our code a little, and makes working with Windows APIs easier. We have some legacy extensions (e.g. non-standard constructors on exceptions) that we've been getting rid of over time. The compiler has actually been acting the same way - new features generally enforce conformance, and they've been trying to gradually deal with legacy extensions. (My disinclination towards extensions is focused on otherwise-Standard stuff. Totally separate things, like the Filesystem TS, don't affect Standard code.) If there are specific extensions that are causing headaches, I'd like to know about them if they're in the STL, or I can report them if they're in the compiler. That said, I am going to ship one switch in RTM. My proposal to remove auto_ptr/etc. was accepted for C++17. (We're not revealing the full feature list yet, but since I proposed this thing, I think I can talk about it.) As much as I'd like to, I can't just rip out auto_ptr from the shipping product. So, I guarded every mention of the C++17-removed stuff with a macro. This way, the stuff is provided by default, but users can request conformance and have the nasty icky stuff preprocessed away. I've already asked Boost to begin migrating to the new world order, and this opt-in feature will allow them to validate their code and tests. Then we'll be able to crank it up to opt-out, and finally to unconditional. Although it is a mode, which I usually hiss at, this one is fairly safe because the code is either there or not, and it has been disentangled from the rest of the STL. (Also it is no longer evolving.) Providing modes for other 14/17 features would raise the issues I mentioned before. Oh, and on the topic of extensions - I am ripping out the stdext::hash_map extension VC has had for many years. It is deprecated with an impossible-to-ignore message in 2015, and I plan to remove it immediately after we ship. The mostly-but-not-completely similar interface and shared code with unordered_map has been a source of user and implementer headaches for a while.
Unfortunately that code just isn't legal, so this one isn't on Microsoft. It is legal, however, to do: `v.emplace_back(S{5.f, 1})`, and VS 2013 does support this. You can write it a bit more concisely as `v.push_back({5.f, 1})`. With optimization on these should all be just as efficient as constructing the object in place in the vector.
&gt; More C++14 support: variable templates, full constexp support, expression SFINAE I want all of that stuff too! (In fact, I proposed Variable Templates For Type Traits, like is_same_v, that were accepted into the Library Fundamentals TS and are a strong candidate for C++17.) &gt; One problem in VS2013's STL that bothers me... As /u/bames53 said, this is not permitted by the Standard, and both GCC and clang will reject it. Try the [Wandbox](http://melpon.org/wandbox/) online compiler. The reason is that emplacement uses parentheses, but your `S` is an aggregate, which cannot be constructed with parentheses. This is an issue in the Core Language, which the Evolution Working Group should fix.
I looked into Summer of Code, but all the projects are fairly intimidating. Bug trackers and learning a new language (or someone's giant C++ app). Actually, the biggest showstopper has been getting the dependencies together so the app will actually compile and run from source (What's Fresh, why does your program require a specific version of Ruby that hasn't received even security updates in over a year?). 
I kinda do, thanks.
How to structure your code decently. I am self-tought so I didn't have any guidance in this, so this might be less a problem in your case. Gameprogrammingpatterns.com helped me out a lot, it's free to read (online), is nicely written and won't take you too long to read. This appies to all programming languages btw.
I would love a way to exclude folders for warning/error checking (i.e. 'system includes'). I would like to work with /WAll /WX like I do on UNIX platforms, but cannot because many libraries, including the STL, do not pass higher than /W3.
It was noticed a while ago, but the idea of an "aggregate" is very old (it dates back to C) and is a tricky part of the language. It may be fixed, but I'm not sure if anyone's working on it right now.
&gt; Aggregate weirdness is one of C++'s not-so-fun things. That bit me yesterday... Trying to invoke copy-constructor, from a member function: MyClass x{*this}; failed to compile because `MyClass` was an aggregate, and so braced initialization tries to initialize the first member variable instead of invoking the copy constructor. To fix it I had to either use parentheses, or add a default constructor. This could be insidious if `*this` was actually a valid initializer for the first member as it would lead to no warnings and silent wrong behaviour. 
Yes for this one! "-isystem" like switch from gcc would be very useful. And make all the STL and Window SDK folders by default to use this new switch, not the regular /I.
Well, braces can't be used unconditionally, because types can care about the difference - notably vector itself. (A vector&lt;int&gt;(11, 22) contains 11 elements; a vector&lt;int&gt;{33, 44} contains 2 elements.) I am not actually sure if aggregates can be detected at the library level (there is certainly no Standard type trait for it). It might be possible to sense aggregates through TMP trickery, but the Library already does so much crazy stuff. It would be simpler and more uniform to permit parenthesis-construction of aggregates.
OK I'll try and reproduce and repost. This was g++ 4.9.2.
1) C99 style variable length arrays: int sz = 100; int arr[sz]; 2) GCC [statement expression](https://gcc.gnu.org/onlinedocs/gcc/Statement-Exprs.html) 3) ~~[__int128 type](https://gcc.gnu.org/onlinedocs/gcc/_005f_005fint128.html#_005f_005fint128), so I can use it for multi-precision integer math when doing 64-bit multiply and add with carry. Currently there is only __mul128 intrinsic for 64x64-&gt;128 multiply, but there is no way to add or sub numbers with carry.~~ My mistake. Apparently there is _addcarry_u64 instrinsic that does help here. 4) [static array indices in parameter declarations](http://hamberg.no/erlend/posts/2013-02-18-static-array-indices.html) 5) ability to ignore [any warning from link.exe](https://msdn.microsoft.com/en-us/library/dn782850.aspx) by number like warnings from cl.exe. Especialy LNK4203-LNK4209 ones.
While STL is fine with /W4, windows.h is not so good with /W4, not even talking about /WX.
Hmm, I thought windows.h was also supposed to be /W4 clean. If you report issues through Microsoft Connect, we can forward them to the Windows SDK maintainers.
I personally overhauled the &lt;chrono&gt; clocks in 2015 CTP1 (alpha 1). Read my [detailed VCBlog post](http://blogs.msdn.com/b/vcblog/archive/2014/06/06/c-14-stl-features-fixes-and-breaking-changes-in-visual-studio-14-ctp1.aspx) for more info. STL headers are indeed permitted to include each other in unspecified ways. I believe people have written tools to validate that you "include what you use" although I am not certain.
Note rewriting everything I did before, when I was less experienced.It's a real challenge, since you don't know in advance if the refactoring will be worth it, and the lack of novelty can be a real motivation-breaker.
I would like to see expresssion sfinae, full constexpr, value initialization, and properly generated copy and move constructors. In addition, I would like to see better testing of features. Many times I have to use Boost.MPL to work around problems with template specialization or type deduction. Ideally, what I really would like to see is microsoft embrace clang-cl instead of fixing their crusty old compiler. Clang is very close, I would rather see microsoft invest the effort towards clang fully working in VS 2015 instead of working on MSVC because then we would have a very nice C++14 compiler on windows in 2015 instead of waiting several more years. 
[Just this guy :P](https://connect.microsoft.com/VisualStudio/feedback/details/1189216) 
&gt; Currently there is only __mul128 intrinsic for 64x64-&gt;128 multiply, but there is no way to add or sub numbers with carry There actually is: [`_addcarry_uXX`](https://msdn.microsoft.com/en-us/library/hh977022.aspx)
I've looked for tools like that, but in practice only a full C++ parser combined with meta-information provided by the header files (some #pragma to declare which functionality is offered by a particular header?) can be accurate enough.
Well, my pipe-dream wish list: 1. Microsoft starts responding to their **paying** customers quickly. In my career I have reported errors like bugs in the crt, bad codegen or crashes in the VS extensibility and I either not received confirmations at all for my issues on connect or had to wait for up to two major VS releases for the fixes. 1. C++ compiler got sufficiently advanced to compile [cap'n'proto](https://capnproto.org) out of the box 1. node.js integrated out-of-the box - the current addon on codeplex is still quite rough 1. Work with cmake-based projects out of the box 1. stop installing SQL server and WP8 sdk by default. SQL server runs by default and is a huge security risk. WP8 bits take huge amount of disk space and may not even be usable on old processors (like mine). The WP8 is also quite insidious because it makes the computer slower (active hypervisor has non-zero runtime cost) and pro-actively and silently breaks third-party products like VirtualBox. Also, this happens when a monthly security update got pushed on the patch tuesday. 1. Ability to move PackageCache dir or remove it entirely. Part of my job is to develop VS extensions and thus have to have VS 2010, 2012, 2013 and 2015 installed. And with a mere 256 GB SSD the disk space is very limited. Even Office guys have MSOCache removal tool, and their files are minuscule to VS ones. I'd be delighted if 2015 fulfilled my points #1,3 and 5. 
Are you are C11 dropped VLAs into an optional feature?
I guess this is more for your boss and boss-like entities, but what I would like most -apart from full C++14 conformance asap, of course- is a more predictable and faster release cycle. Either the 12 month-ish gcc or the 6 month-ish clang one. And why not provide nightly binaries instead of the ctp series? I haven't counted them, but I have seen a lot of "the bug you reported is already fixed in the latest version" answers from you. This wastes time on both the submitter's and your side. If you ever want to catch up to clang, you'll need feedback as early as possible in the cycle. Long term, I guess only open source development of the compiler / library (not the IDE) will keep you competitive.
More work related to efficient code: - more intrinsics - more efficient executable - more flags about efficiency - improve virtual table connexions and possibility to avoid them - more work based on PGO and a better add-in than the one proposed by Microsoft. Library should also be usable in PGO via the IDE (there are from the command line and following an undocumented way)
Re-evaluate [Compiler Warnings That Are Off by Default](https://msdn.microsoft.com/en-us/library/23k5d385.aspx). Both for things that should be on by default: C4311 (level 1) pointer truncation from 'type' to 'type' and for things that should be off by default: C4100 (level 4) unreferenced formal parameter
To cut a long story short what I'd like to have: full C++14 constexpr support. As for my more expectations: More support for C++11 and 14 but not complete, possibly better optimizing codegen for native code.
While we are on the topic of Connect, it could use some UX enhancements. Not once I've given up on reporting something due to the unease of use. I seldom use my Microsoft account and don't remember the password so I always have to reset it. I have at least three accounts that provide SSO, let me sign in with them. Also, Github issue reporting is is a great example of a well designed bug tracking interface (at least from the bug reporter's perspective). 
Full C++11 support. FULL support, not a half-attempt like VS2012/2013. Not C++14 or C++17 features. FULL C++11 SUPPORT! Trying to write cross-platform software that complies to standards is impossible without full C++11 support in MSVC. The standard exists for a reason. Now that you've merged the normal compiler and the Intellisense compiler, and I presume that now you are getting the full AST in 'the' compiler, you have no more excuses to not support all of C++11.
[This bug](http://stackoverflow.com/questions/28553165/inconsistent-typeid-for-nested-template-function-in-visual-studio) is still in there, but I can't report it - I get a "You are not authorized to submit the feedback for this connection." message.
For starters, syntax highlighting, auto-indent, and keyword highlighting in CMakeLists.txt files. VS awareness of CMake would also help, in that it could auto-reload projects that were re-generated due to changes in CMakeLists.txt instead of prompting, and it could handle errors better than trying to build a solution with a basically empty project due to a CMake generation error. Since CMake is basically its own programming language, I could also see a full blown intellisense type of integration with command completion (CMake and custom macros,) argument completion, CMake variable lookup, path completion, error parsing and highlighting, etc.
This is also the most important feature for me. Especially full constexpr support. This would make cross platform/compiler development much easier.
Yes, I mean if they want to add relaxed constexpr a la C++14 by all means, but C++11 spec would be a great start (VS2015 has some support for it so I'm hoping full support will be in the final version)
I would love a warning when a `bool` is converted to any kind of integer. I was changing an internal API (the virtual function was named *read()* so I couldn't just grep for all uses of it) and clang, gcc, and MSVC all didn't warn me when I missed changing the args. I get why bool converts to an integral type, but since the compiler can warn about signed/unsigned conversions, it seems it could also warn about bool/integral conversions. To me, one of C++'s mistakes was preserving C's "all integral values can be bools"; I like the code clarity of explicit comparisons `==0` or `!= 0`, and I especially like the compiler to warn if I pass a wrong argument type. In a similar but opposite vein, the fact that math on integral types smaller than int promotes to int is annoying. uint16_t v = 0xf5; v &gt;&gt;= 4; // produces warning on signed/unsigned or truncation That just seems excessive. I understand why it gets flagged for a warning, but it seems to me to violate the principle of least astonishment. (Other `@=` operators also shouldn't warn IMO).
Well, I'd love experimental implementation of this: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3951.pdf
Considering my previous rant, I guess I have to answer :) . Thanks for asking. * An extensive description of what is not supported/non-standard. Sometimes the features listed as having "partial" support are not detailed enough * As mentioned earlier, switch-based version selection would be great. (Please do not include any non-voted C++17 features without a switch to enable them). I guess that will be even more important as c++17 can induce behavior changes ( n3922 ) * A better release cycle. I know VC 15 add a lot of things. But a lot of thinks will be missing. Concepts are around the corner and so are a lot of TS. It would be great to have these features sooner than later. The usual explanations is "merges are hard"... An issue clang does not seems to have. * Better, lighter installation process. I don't care for the IDE ( I use Qt creator ), and some people care about the IDE and not the compiler. A lot of people don't do C#, VB, etc... please don't force us to install them ( and I guess the C# people have little interest in having a c++ compiler). On the other hand some tools and libraries are hard to find, often hidden in the W8 SDK, which is huge. * Improved compile time ( easier said than done I guess :) ) to sum it all up, I guess what I'm saying is : more modularity ? 
VLA may be the worse C features. I'd rather not have them. std::vector or std::array with constexpr are much more suitable. having support for std::dynarray wouldn't hurt either :)
I've found CTP5 and CTP6 choke the C++ compiler and need a restart on several constructs. OK for a CTP but I hope you are now in a stabilisation period rather than adding new features. [Being able to compile boost lockfree would be nice :)] I'm banking on shipping product using 2015 features in June, and now I'm getting worried I may have guessed wrong about a RTM around 'Build' time in early May
How about support for something like rpath (including relative origin support).
Debug CRT and [/GS](https://msdn.microsoft.com/en-us/library/8dbf701c.aspx?f=255&amp;MSPPError=-2147217396) support some AddressSanitizer features
I'd expect to be able to compile code that uses std::index_sequence...
Avoiding complexity
You understand that array on stack is much different than array on heap? Also std:array can not be used with non-compile time size. If putting everything on heap is OK with you that is fine, but different people like to allocate objects or arrays on stack.
Yes. But knowing MSVC support for C99, we won't see C11 support for a very long time if at all. So having small C99 feature now would be more useful. I don't see how implementing VLA would be a big problem, because they have alloca already implemented. VLA is almost (not quite, but close) just a syntactic sugar for alloca. But typing VLA syntax is much nicer and more readable that using alloca.
_addcarry_uXX are Broadwell new ADCX/ADOX instructions. I'm asking for this: __int128 a, b; a += b; to generate this code (or similar): add rax, rbx adc rcx, rdx Which doesn't need any special CPU instruction, just regular x86_64. Afaik with current intrinsics this is not possible. 
I use (consume) cmake files, and I've got to be honest - I'd rather the VC team worked on almost any other problem. CMake is something I can deal with on the side. Non-standard compiler behaviour on the other hand...
Inheriting Constructors have been implemented and [are available in 2015 Preview](http://blogs.msdn.com/b/vcblog/archive/2014/11/17/c-11-14-17-features-in-vs-2015-preview.aspx).
Hah, I'll have to check out the preview. There's a bunch of places in Qt where these would be useful, maybe we can start using them some time around 2017-2018. :)
I'm sorry if I'm pointing out the obvious, but...: [CMake Tools for Visual Studio](https://visualstudiogallery.msdn.microsoft.com/6d1586a9-1c98-4ac7-b54f-7615d5f9fbc7). It doesn't do everything you're wishing for but it does do a few. 
The Usual Arithmetic Conversions and integral promotions inherited from C are definitely a headache. In general, I feel that value-modifying conversions are the ones to be worried about. Value-preserving conversions, like the integral promotions (i.e. widening tiny types to int) are much less worrisome.
This should work in 2015 RTM - the compiler has fixed many bugs involving the expansion of alias templates.
Have you reported the compiler bugs?
If you see suboptimal codegen with intrinsics, file a bug with clear examples of the source code, actual codegen, and expected codegen. The compiler back-end devs can investigate and improve things.
Thanks for taking the time to explain these tradeoffs in the MS development process!
To be blunt Connect is simply horrible and it's demoralizing having to use it to report bugs. I am often already frustrated by the existence of a bug in MSVC, and then I have to fight against Connect in order to report it and I basically just stop caring and give up. Getting bugs through Github and making it a much more open/transparent process would motivate a lot of people to use it and contribute.
I really try to stick to it but the constant false positives on syntax errors and freezes (even on a ssd) makes me go back to eclipse.
&gt; This channel has no videos. My problem? Or a problem with the channel?
yes, I bought the pre-release version and have gotten half a dozen updates since the official version was released.
You might be interested in Bloomberg's standard library implementation ([`bsl`](https://github.com/bloomberg/bde)) that allows for specifying allocation strategy independent of type and at more granular levels than program-wide. They provide an implementation of [polymorphic memory resources](http://en.cppreference.com/w/cpp/experimental/memory). So e.g. you can do: char buffer[0x100]; MyStackAllocator allocator(buffer); // implements 'bslma::Allocator' bsl::vector&lt;int&gt; data(&amp;allocator); // all allocations go through 'allocator' data.resize(20); // does not allocate from the heap In reality, you'd probably want to use `bdlma::BufferedSequentialAllocator` along with `bsls::AlignedBuffer` instead of `MyStackAllocator`, but the principle is the same - allocation strategy (from stack, heap, shmem...) is independent of the consumer of the allocations (vector, map...)
I think the only things missing from MNMLSTC Core not having MSVC support are constexpr member functions and `void_t`. I would violate intercontinental trade agreements to get `void_t` support.
I tried filing a bug report for the first ICE I hit with VC 2013, but I never succeeded in isolating the bug out of my large codebase. It was a university project and after adding some form of recursive initializer_list, I ended up with a C1001. However, that specific class compiled fine on its own and the rest of the code without that class compiled fine, just after adding the initializer_list constructor it died with an ICE. I found some similar bug reports to mine back then and because I really couldn't identify the cause I let the case rest (we were only required to build on Linux and GCC so it only impacted convenience for me somewhat). As for the valarray thing: The copy ctor is defined in the VC 2013 STL, it's just not implemented for some reason - hence throwing a linker error. I think gslice_array, indirect_array and masked_array were in the same situation in VC's STL. I should have reported this one on MS Connect earlier on, but it seemed intentional and I did not expect any answer other than "it's &lt;valarray&gt; - who cares?!". By the way, as others in this thread have made suggestions for warnings, I have one for that, too: If you've got a prvalue std::string (i.e. returned by a function), call .c_str() on it and thereafter make use of that pointer (which is undefined behavior, of course!), GCC will generate code that "works" - but Visual C++ will generate code that does not. Neither compiler will warn about this behavior however. I've seen this pattern breaking the Windows port of [InspIRCd](http://www.inspircd.org/) a few years back and thereafter a docent at my university (who only ever tested his code on GCC/Linux) making the exact same fault. If there's anything I'd wish for VC to warn about, that pattern would be it.
That it C++ library. But C99 VLA can be used in C code.
Seems they pulled the videos again. Probably released later on some official Qt Channel or so...
Minimal repros are best, but for ICEs, preprocessed files are acceptable. &gt; it seemed intentional Our implementation mirrors the Standard (declaration but no definition). It's unclear to me whether this is intentional in the Standard, or whether there's a spoken or unspoken rule that a definition should be provided. (In the containers, there are no paragraphs defining each copy ctor/etc., but there is a centralized bit of wording saying that they should all be defined and do blah.) &gt; and I did not expect any answer other than "it's &lt;valarray&gt; - who cares?!". That *is* my feeling, although I won't dismiss bugs just because I don't like the stuff. &gt; Neither compiler will warn about this behavior however. I've wondered whether .c_str() should be ref-qualified. In C++11 (and 2015), member functions can be marked with &amp; to require that they be invoked on lvalues. Some people would surely complain that oss.str().c_str() would be forbidden, but calling .c_str() on temporaries is just so dangerous. The problem is that local analysis (either in a warning, or with ref-qualifiers) cannot determine overall safety. People do hate warnings about valid code.
Full constexpr support!
Filed as DevDiv#1143450 in our internal database.
You've mentioned two substantial programming skills that are generally overlooked: 1. Ability to cope with an existing giant pile of code 2. Skill with build-systems and package-management The former is something programming classes don't generally teach very well. At best a programming assignment can have a student using Swing or Qt or something, and get them comfortable looking up how the API works, but it's not the same as *here is a giant codebase with virtually no documentation, off you go*. The latter is an annoying reality of programming. It's also somewhat specific to platform: getting dependencies working is different in C/C++-on-Linux, C/C++-on-Windows, or Java. A good command of CMake goes a long way toward being able to write a truly portable C/C++ program. *Edit: having read [this comment below](https://www.reddit.com/r/cpp/comments/2zry3c/what_is_the_hardest_challenge_an_amateur/cplrtzd), I'm reminded that a deep understanding of C's build model (and the slightly more complex one that C++ gives you with templates) is itself a non-trivial skill, never mind all the cleverness that build-systems and package-managers add on top.*
Thank you!
Wow, the errata list of the book is pretty long! I just bought it (print version), had I known, I would've waited for the corrected version.
I've had the same thought, but I'm not sure how to improve on what's out there. All I know for certain is that the existing build systems make me irrationally angry when I try to write build scripts for them.
I would like the forward and back mouse buttons to work for the peek definition pane.
It's got really good platform support (works great with IDEs and with Unix), and a wealth of package 'modules' built-in to automate finding libraries, but the scripting language and standard-library are just horrendous. I once thought I'd try porting the Find_ImageMagick CMake module to GraphicsMagick, a fork of ImageMagick. I didn't get far. Hundreds of indecipherable lines of CMake. Hurts just thinking about it.
Find_* modules I've written haven't been all that bad. I just can't decide what it is about the language and about the way it works that bother me.
The thing is that this was changed. I believe C++14 has the old behaviour, but maybe it made it in at the last minute. N3797 has: &gt; List-initialization of an object or reference of type T is defined as follows: &gt; — If T is an aggregate, aggregate initialization is performed
Ah, Standardese churn. That's why I always refer to the latest WP (I never look at earlier WPs when implementing stuff, only when I need to do programmer-archaeology for some reason). A resolution of a Core Issue was presumably responsible.
ICU. Maybe boost.
I'm not even sure wstring is an appropriate solution to this problem. Last time I checked, Visual studio's wstring was UTF-16. Maybe using an explicit basic_string&lt;uint32&gt; is better?
Right, I did the same with my Core library to support GCC (although I named mine `deduce_t`). This is good to know though! :D!
I am not an expert on this (and sorry if I misuse any technical terms), but as soon as you say “compare”, that tells me that you need normalization. And understanding the Unicode normalization forms is much more important than what API you use. You can’t know how to properly use the API without understanding the normalization forms. Once you know which normalization(s) you want to use and have found a function that implements it, the actual comparison can, I believe, be done with the regular std::string comparisons. Unless you have a good reason to use another encoding, use UTF-8 in std::string. Yes, length will give you the number of bytes rather than the number of characters, but you should generally not be doing operations in terms of characters. Where you might have used a character in the past, use substrings instead. That substring may be a single glyph represented by a single code point represented by a single byte, or it may be a single glyph represented by a single code point represented by multiple bytes, or it may be a single glyph represented by multiple code points, or it might be an actual substring. For the most part, your code should not care.
Sometimes &lt;atomic&gt; isn't an option. Doesn't &lt;atomic&gt; just use volatile for x86 and hope it works out? Wouldn't that mean that /volatile:iso is a no-op for x86?
&lt;atomic&gt; is always an option for native code. In 2015 we've enabled it for /clr too. &lt;atomic&gt; has no dependencies on /volatile:ms, for any architecture. On the strongly ordered architectures (x86/x64), it's implemented with Interlocked intrinsics for most operations (which grant full SC). A few operations can be implemented with plain reads/writes, as long as we use compiler barriers to inhibit reordering (the architecture then guarantees that the processor will not reorder stuff downstream; there is only a little bit of processor reordering to worry about). Getting this right required lots of review from back-end devs and you do not want to replicate the effort yourself. /volatile:ms's problem was that it was too weak and too strong simultaneously. Too weak, because it granted only acquire-release, not full SC, thus allowing the Independent Reads, Independent Writes problem. Too strong, because the acquire-release semantics are expensive on ARM. We know better now.
In what way does this fix the `length()` issue though? In Windows `wstring` is UTF-16 which is still a variable length encoding, it's also arguably harder to handle with its surrogate pairs. I generally see it as worst way to handle unicode. As for UTF-32 you can finally guarantee that 1 codeunit == 1 codepoint. That doesn't mean it's fixed width concerning grapheme clusters though which is probably what matters for users. So for handling length you either have to parse grapheme clusters using heavy libraries no matter which encoding or simply use it as an equivalent to the memory it takes which is usually more than enough. I usually recommend using utf-8 for its ease of use and low space usage and recommend to avoid utf-16. utf-32 is ok if you don't care about the space. If I look at utf-16 uses I mostly see that it's either used because the platform/library/language predates utf-8 itself. Or it depends on other stuff that predates it and heavily relies on utf-16. For new libraries utf-8 seems to overweight.
Fair enough - kernel mode is the one (and only) place where C is legitimately useful.
This post frustrates me to no end, because I'm *this* close to releasing a new version of my C library for UTF-8 text. ;) The library is called [utf8rewind](https://bitbucket.org/knight666/utf8rewind) and supports encoding to and from UTF-16 and UTF-32 and seeking in UTF-8 strings. The new version (due either today or tomorrow) adds case mapping and normalization. If you get the latest version from Mercurial, you will already have the new version, the only things left to do are the changelog and press release. utf8rewind is open source, portable, cross-platform, requires no initialization and does not use any heap allocations.
Use the override keyword. It's standard since C++11 and has been an extension in MSVC for a long time.
On systems with 16-bit `wchar_t` there are still all the problems you mention; plus extra problems. If you want to write code that doesn't rely on 32-bit `wchar_t` (i.e. portable code) then it doesn't seem a great option, all things considered.
Results will be discussed on next episode of http://cppcast.com
Uh... my point was that of course I'm already using it but I want to enforce that it's used everywhere possible, which is what that extension does.
Yeah, but then I cant use VS without it, so I have to keep it around.
In UTF-8 character might be single char or 2 chars. So you'd have to store chars in an array, and introduce some way of saying how log would that array be - wither by using hardcoded array length of 3 and terminating it with`\0` or introducing some even more complex solution. And then you'd have to use it somehow. Now, libraries usually use arrays underneath but I'd expect them to expose APIs in `std::string` or `std::wstring` (or [their own format](http://icu-project.org/apiref/icu4c/classicu_1_1UnicodeString.html)) - so without strings you'll end be packing and unpacking data to and from containers. Avoiding usage of strings seems like a good idea only on microoptimization level, it wouldn't hold in a bigger picture. Usually you don't want to iterat over characters, but if you do, check [ICU](http://site.icu-project.org/). It's thought to be the best cross platform UTF-8 library out there.
I would like a light version of VS with just the C++ toolchain and the Windows SDK (plus ATL/MFC). You could call it Visual C++ 2015, how about that? ;)
I like to use this library for it: http://utfcpp.sourceforge.net/ It is simple, integrates with the STL and has so far provided what I needed.
I've been tooling around a lot with futures and promises, and one of the things that C++ dearly lacks in the STL is continuation operations (or task chaining) for futures. Stuff like that is particularly useful for UI related interactions. So I ended up rolling my own custom class `foo_future&lt;T&gt;` that wrapped up a `std::shared_future`, and implemented the methods `.then(F handler)`, `.catch(F handler)` and `.finally(F handler)` in a similar vein as `PromiseKit` implements task chaining. The whole process seemed a lot easier than I anticipated. 
The correct approach is to use utf-8 in std::string, as already noted frequently by others in this post. A very good explanation of why using std::string is correct is provided at http://utf8everywhere.org/ - this is definitely worth a read and contains several hints through the widen and narrow functions to convert to wstring/CString/QString and back to utf-8.
You might want to take a look at [Meson](https://github.com/jpakkane/meson/wiki) then. (Caveat: written by me.)
And how using std::string allows me to iterate over _characters_ in given string?
I haven't seen that before, I'll definitely have to check it out.
What do you mean by characters? UTF encoded codepoints. Multiple codepoints (even when using utf-32) may be used to form a single glyph. So you need to explain what you are trying to accomplish... But it is easy to iterate through the UTF8 bytes and see where the codepoint boundaries are.
+1. You don't always want to install the IDE - sometimes you just need the compiler (on build farms, for example).
There's no such thing as "utf8 signs". You need to read a lot. Before getting a book, you might try [this](http://www.joelonsoftware.com/articles/Unicode.html).
Even uint32 doesn't cut it because of e.g. [combining characters](https://en.m.wikipedia.org/wiki/Combining_character) and grapheme clusters.
Why choose it over ICU?
No, you need moc only if you make use of the QMetaObject system, either by subclassing QObject or QGadget. QString is not based on either of these.
Just funny how exactly today I met with a bug that clang regex is broken with wchar_t in their latest stable library version, so the bugs could happen on every compiler's side. Of course VS2013 may have been too strongly filled with bugs in newest C++ features (esp. without updates) but VS2015 already looks more promising.
Is there not something like that proposed for C++17?
ICU is a pain to include in your project and requires customizing its dataset to avoid having 20MB+ increased binary size.
This is going to get buried but just in case you are still reading, here is one of my most sincere wishes. I wish that you would document all of the information you have put here about the compiler, etc, *in the product documentation*, and not on your personal blog/web page. Please? Hire some damn full time technical writers? *PRETTY PLEASE?????*
This makes one think that the world need to move to one language, English, and drop all of these complicated to support languages. OK so that is unrealistic. Has anyone considered the possibility of a truncated UTF 32 solution that simply doesn't support multiple code points? Why UTF even supports multiple code points is beyond me. While again maybe unrealistic looking backwards maybe looking forwards we need to consider that is we can't encode the worlds alphabets in a 32 bit integer then we have to consider forgetting about some of that old stuff. &gt;What do you mean by characters? UTF encoded codepoints. Multiple codepoints (even when using utf-32) may be used to form a single glyph. So you need to explain what you are trying to accomplish... But it is easy to iterate through the UTF8 bytes and see where the codepoint boundaries are. 
I consider this a valid reason for creating a similar alternative.
Not to be an ass but LLVM/CLang. One has to admit that developing with CLangs C++ compiler is very rewarding. This in the sense of rational debugging info, error messages and the like. As an aside it has been awhile since I've used Visual Studio. I do realize that you have made strides as far as compliance and developer support goes. Still the impression is that CLang C++ is really good. 
yes, the await proposal is here http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4134.pdf 
In the STL, I break back-compat all the time in the pursuit of conformance - for examples, see [my list](http://blogs.msdn.com/b/vcblog/archive/2014/06/06/c-14-stl-features-fixes-and-breaking-changes-in-visual-studio-14-ctp1.aspx) for the breaking changes between 2013 and 2015 CTP1.
Cmake isn't a build system. It spits out files for other build systems to use.
If you insist on being pedantic, yes, fine, it's a meta-build system, but it's the system with which the programmer interfaces to manage program build; it's not entirely inappropriate to just call it a build-system. Does it use 'make' behind the scenes? I don't care. *Edit: also, while you're right that CMake generates files, those generated files depend on CMake to function.*
I would suggest at the very least reading this: http://www.joelonsoftware.com/articles/Unicode.html It is a good (relatively short) intro to the wonderful world of character encodings and Unicode, etc. EDIT: I see somebody else has already posted this link in the comments below.
Others have already echoed it, but if you want to know the length, you should use the appropriate function from the ICU library.
It's important to remember the Visual Studio (or you mean MSVC? or perhaps Windows?) treads `std::wstring` as just `std::basic_string&lt;wchar_t&gt;`, where wchar_t is 16 bits wide. This **does not** mean the string contains UTF-16 encoded text, it just means it holds a (possibly) null-terminated sequence of `wchar_t`s.
I dont see the usefulness of void_t without support for expression sfinae.
It's still useful to query for nested typedefs, especially multiple nested typedefs. The STL does this extensively, e.g. in iterator_traits. The old way of doing this was much yuckier.
This is the typical pedantic response that does nothing to help. You know damn well what he meant, but took the time to show off how "smart" you are on the subject without offering a single solution. Properly supporting unicode strings is overly complicated and there is no universal solution that I'm aware of. As someone mentioned in another post, QT has some of the best all-around support.
boost.locale has iterators for character/word/sentence that could be used like that with a trivial wrapper function.
It's a 90s-style Java library that was ported to C++ and then had a partial C API tacked on. The end result is pretty much exactly what you'd expect that to look like. boost.locale wraps a decent chunk of ICU with a more reasonable API.
&gt; internally Off Topic Question: can I use Qt Network without depending on moc?
Where do we have multiple character? Even polish "dź, ch" aren't considered one _character_. Why are you overcomplicating topic? Character is character. Something that is bound to UNICODE positions.
That is a very valid question :-) Let's first look at this from a more generic perspective: There are characters that do not even fit into utf-16, and even worse, even multiple utf-32 characters may compose to a single glyph. So your question is not a concern only for utf-8 encoded strings in std::string, but is also valid for utf-16 etc. The solution is you need some smart iterator that handles this. Yes, at this point supporting unicode may seem to be complicated but that is now other languages simply work... You may want to look at http://utfcpp.sourceforge.net/ for doing this, it contains such iterators. (I have personally not tried this library, but read about it lots of times already).
indeed you can use QtSignal QtSlot to achieve similar non-blocking UI effect. http://doc-snapshots.qt.io/4.8/threads-qobject.html But to use those you need again explicitly control those two thread contexts! IMHO, best way is something around tasks. async task (non-block) and task (block).
Haha, turns out the most vexing parse is even more vexing.
I suppose the ease of use is in the eye of the beholder here. In this particular case, with QString the conversion from UTF-8 to UTF-32 with QString would be as follows: const QString s = QString::fromUtf8(data); QVector&lt;uint&gt; utf32_encoded = s.toUcs4(); Of course QString doesn't have member functions for every codec on earth, but it happens to have these.
But that can create problems if there is an explicit (whatever you call a constructor from {}). For example, the following code: int main(){ std::vector&lt;int&gt; v1(4),v2{4}; std::vector&lt;int&gt; u1(4,1),u2{4,1}; DEB // Shameless self promotion :) &lt;&lt;OUTPUT(v1,v2) &lt;&lt;OUTPUT(u1,u2) ; return 0; } will output =============== main.cc:6: in int main(): v1= [0, 0, 0, 0]; v2= [4]; u1= [1, 1, 1, 1]; u2= [4, 1]; =============== So if you really want B b(A(i)); and NOT B b{A{i}}; then you're out of luck. -------------------------------- On another note, I think it's problematic to just tell people to "use unified initialization syntax" all the time, as just replacing one with the other can be quite dangerous (as seen in the example above). And unlike the case discussed here where a programmer will soon find a compilation error when trying to use `b` as if it were `B`, the kind of errors created by changing to unified initialization will be runtime error which are harder to find.
double boss here :) hear you loud and clear on desire for faster release cycle and we are looking at options here post-RTM. What if we did conformance features in updates to RTM? For VS2013, we released updates every 3 months. If we made sure there were no breaking changes, would that work for you? followup on the point about bug resolution... we recently started updating the web compiler more frequently http://webcompiler.cloudapp.net/ . Would that help with checking resolutions? I can imagine people wanting to take nightly builds if we released a tools only package (a common feature request we are considering) but I'd be surprised if folks wanted to install the whole of VS more frequently than the CTPs. let me know. 
thanks. this is helpful feedback.
A hotkey for switching between open tab groups. The lack of a hotkey for this makes mouseless programming hard in VS.
Ah... yes... That one thing that can make debug builds super slow, and turning it off requires rebuilding all your libraries with it off as well.
The reason is because of exception safety: http://ptgmedia.pearsoncmg.com/images/020163371x/supplements/Exception_Handling_Article.html
If the goal is simply to describe a relatively simple self-balancing BST, I see no reason why AVL is not the go-to. The idea of height, balance, and rotations are much easier for, say, a sophomore CS student to grasp. 
I'm lost. C++ doesn't support nested functions, AFAIK. Obviously it's not a lambda (wrong syntax, no c++11 compiler flag), so if b is a function declaration this shouldn't even compile. Can someone please explain?
Assuming they've gotten past pointers and OOP principles, and have a decent grasp on complexity, multi-threading is the next big hurdle.
Git code in the C++ subreddit? Linus would not be happy.
Yes, you can use it to and from `std::wstring` like so: std::wstring towide(const std::string&amp; text) { std::wstring converted; int32_t errors; size_t size_in_bytes = utf8towide(text.c_str(), text.length(), nullptr, 0, &amp;errors); if (size_in_bytes == 0 || errors != UTF8_ERR_NONE) { return converted; } converted.resize(size_in_bytes); utf8towide(text.c_str(), text.length(), &amp;converted[0], size_in_bytes, nullptr); return converted; } std::string toansi(const std::wstring&amp; text) { std::string converted; int32_t errors; size_t size_in_bytes = widetoutf8(text.c_str(), text.length() * sizeof(wchar_t), nullptr, 0, &amp;errors); if (size_in_bytes == 0 || errors != UTF8_ERR_NONE) { return converted; } converted.resize(size_in_bytes); widetoutf8(text.c_str(), text.length() * sizeof(wchar_t), &amp;converted[0], size_in_bytes, nullptr); return converted; } I haven't measured its performance on millions of conversions, but it's not a very expensive function. EDIT: Input size is in bytes, not in codepoints.
I am really interested in openACC - https://developer.nvidia.com/openacc If this can work out!!
Isn't this exactly what bitfields are in C/C++? What you are describing sounds more like a bitset.
Looks nice in principle, but raw pointers, globals and macros in the hello-world demo, I'm sure there is loads more if you dig a bit deeper. I wonder if that's really necessary and if people couldn't start to adopt a more modern C++ style. For me, this means I wouldn't use this SDK.
Really? That's odd... In what way do the functions crash? Do they return an error, are you getting a heap corruption or does the library fail to compile? I have been getting reports that the conversion functions don't properly check the input size, but that's something I'm still looking into. I should also note that my original example was wrong; the input size is specified in bytes, not in codepoints.
You can also mix `{}` and `()` initialization to avoid the vexing parse: `B b{A(i)};` or `B b(A{i});`, so if either type can be constructed as you desire with `{}` then you can use that. --- When you design a type now it's important to design it such that an initializer_list constructor will never conflict with any other constructors. `vector` has conflicting constructors but only because backwards compatibility prevents this problem from being corrected. I think ideally a vector type would be constructed something like: vector v{capacity, 10}; // vector v(capacity, 10); // empty vector with capacity for 10 vector v{size, 10}; // vector v(size, 10); // vector with 10 elements vector v{size, 10, 1}; // vector v(size, 10, 1); // vector with 10 elements, {1, 1, ... vector v{10, 1}; // vector v({10, 1}); // vector with 2 elements, {10, 1} `size` and `capacity` are library constants of special types, not the names of local variables. This ensures that the correct overload is selected based on these 'tag' types. With a properly designed type you're never forced to use `()` construction. It's just another unfortunate 'gotcha' of C++ that type designers need to consider and avoid these possible conflicts. --- Item 7 in Effective Modern C++ provides the same advice: &gt; As a result, it’s best to design your constructors so that the overload called isn’t affected by whether clients use parentheses or braces. In other words, learn from what is now viewed as an error in the design of the `std::vector` interface, and design your classes to avoid it. I think it's unfortunate that this advice is not in the "Things to remember" summary, but it's good advice.
In your ideal vector type, how would it differentiate between vector v{size, 10}; // vector v(size, 10); and vector v{10, 1}; // vector v({10, 1}); ? I assume the first creates a vector with `size` elements, each element equal to `10`, while the second creates a vector with `2` elements, and the elements are `[10, 1]`. How will it know not to create `10` elements, each equal to `1`?
Oh, I guess that's wasn't clear. In `vector v(size, 10);` `size` is a library constant of a special type that indicates a particular overload: struct size_tag {} size; struct capacity_tag {} capacity; struct vector { vector(); // empty vector vector(capacity_tag, int n); // empty vector with n capacity vector(size_tag, int n); // vector of n default initialized elements vector(size_tag, int n, int v); // vector of n elements copy initialized from v vector(initializer_list&lt;int&gt; i); }; This overloading has been a pretty common suggestion in the wake of C++11, and the standard library even uses it in a couple places: http://stackoverflow.com/questions/28373911/how-to-design-classes-with-constructor-taking-a-stdinitializer-list
Ah! Now I get it. But if backwards compatibility is the issue, why didn't they just define the following: vector v{fill_tag,1,2,3,4}; or maybe more realistically: vector v{fill_tag,{1,2,3,4}}; would keep the convenience and backwards compatibility, while avoiding confusion, although it won't be as nice to use when doing a vector of vectors I guess.
Does anyone who has used HPX have experiences to share? It looks like an alternative to Microsoft's concurrency runtime and Intel TBB, albeit much larger in scope (e.g. distributed computing).
It's not a bug in MSVC, it's one of its [language extensions](https://msdn.microsoft.com/en-us/library/0yw5843c.aspx). `/Za` disables it. Edit: [C++ is strange](http://coliru.stacked-crooked.com/a/91252f8dea36fadf)
He's right. But only if you replace "most people" with "GuyWithPants".
&gt; status.philos[8] = 0; // assert: array index out of range Shouldn't it be possible to add a static_assert to this instead?
Yea, just tested it and this doesn't work: auto sp = std::make_shared&lt;std::vector&lt;int&gt;&gt;({1,2,3,4,5}); however, this does work auto x={1,2,3,4,5,6}; auto sp = std::make_shared&lt;std::vector&lt;int&gt;&gt;(x); so it's quite perplexing. ----------------------- Just another reason why I dislike initialization list. It's just... "squeaky", like it just doesn't work that well. And I'm really against it because it's the only part of STL that you HAVE to use, or lose functionality. Basically I used to think of all of STL as a "convenient library" that you can use if you want to, but you can also implement yourself if you want. You can make your own vector, algorithms, shared_ptr etc. - as if STL is an "addition" to the "core C++" language (it's part of the language definition, but not part of the "compiler" but rather a set of libraries you have to ship with the "compiler") In a way - the compiler doesn't have to know in advance that STL exists But initialization lists are hard-coded to use STL. If you don't include an STL header - you lose functionality. The compiler has to turn a C++ expression into an STL expression - it has to know about STL. The following code auto x={1,2,3,4,5}; cannot compile without `#include &lt;initializer_list&gt;`, even thought it doesn't have any STL explicitly in it - and it's the only such code in all of C++ as far as I know. I don't like it. It's badly implemented in many different ways.
Silly question - isn't it illegal to write to one union member and read from another? And if so - isn't it illegal to use in the first example `readers` and `writers`? As far as I remember (and it might have changed with c++11 maybe?) this goes against the standard...
Okay I tried out /Wall and a subtractive strategy with MSVC. Seems to work as well as -Weverything and I like it, but system headers ought to build cleanly rather than making clients deal with that. So that's the feature I'd like; platform headers should not produce any warnings that have nothing to do with client code. Doesn't really matter to me if it's through `#pragma warning(disable:...)` in the headers themselves or built-in suppression of all warnings in system header search paths. I also filed some bugs with a third party library so hopefully they'll update to suppress warnings too, or maybe they'll accept patches to fix this.
OK, but that means that in future versions they might change this to do some optimization or something, like the new things they added in gcc4.8 that broke a bunch of code. Also, what does "unspecified behavior" mean in this context? I know things like order of evaluation of parameters to functions is "unspecified", but I'm not sure what it means about unions.
Yep, undefined behavior is still something to be avoided which is why the technique in this article should be avoided unless there is overwhelming justification to use it. Unspecified behavior means that the behavior is well-formed and valid, but depends on the compiler/platform, the standard places no requirement on it. For unspecified behavior, the compiler is not even required to document it or even required to produce consistent behavior. For an example of unspecified behavior: int x; std::cout &lt;&lt; x &lt;&lt; std::endl; Since x is uninitialized, its value is unspecified so the output may be any int whatsoever, but this program will still output an int. If it were undefined behavior then the program would be free to do anything at all. In the case of writing to one member of a union and reading from another, similar situation applies with one additional caveat, the C99 standard says that if you write to a smaller member and read from a larger member, then the program may trap/abort. So writing to an int32_t and reading from an int64_t can result in your program terminating. Otherwise a value will be read, but there is no requirement on how that value will be produced, there is no requirement that it even correspond to a similar bit-representation. Those details depend on the compiler/platform.
He points this out along with the wording from the standard which /may/ make this legal for the special case of standard-layout structs with a common initial sequence. That wording is there for compatibility with C. He leaves it open as to whether that wording is sufficient to make it well-defined or not.
This is in the article: &gt;According to the C++ standard, when one union member is written and a different member is read, the resulting behavior is actually undefined. However, in the safe bitfield implementation shown here, every union member contains the same unsigned integer type, such as uint32_t. I believe this case is explicitly supported by the standard. In working draft N3337, §9.5.1 says: “If a standard-layout union contains several standard-layout structs that share a common initial sequence … it is permitted to inspect the common initial sequence of any of standard-layout struct members.”
&gt; Support "Press any key to continue..." at the end of execution Thanks for the great feedback, please vote for this feature suggestion on Visual Studio's UserVoice site (https://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/2440711-console-window-not-pausing-long-enough). The cost of doing this is somewhat high so it helps us to gauge overall interest in the community, where UserVoice is our primary tool for that 
So then, make it public and it's good to go? Or make them all private with getters/setters?
The async/await works pretty well for .Net.. Simplifies greatly GUI code..
`BitFieldArray` [doesn't have](https://github.com/preshing/cpp11-on-multicore/blob/95086533d420439a1a60259a1f8bad5de9f29790/common/bitfield.h#L68) a base class or subclass. Do you mean something else?
You probably know the article already, but Eric Niebler describes some problems with overconstrained templates in the Palo Alto TR in http://ericniebler.com/2015/01/28/to-be-or-not-to-be-an-iterator/ . If these kind of issues can appear in the STL, I can easily imagine them appearing in other libraries that probably received less critical attention as well.
It'd be really great if we could select the individual compiler revision, where right now you can select the major version (e.g. v120), it'd be nice to be able to select the compiler that ships with the specific updates. We've had several issues now where code compiles and runs fine on Update 4 or Update 5, but due to our release process we're stuck using the original release to do builds and QA testing. Developers like to run the updates because they improve the VS/UI experience, but this also means that we're using a different compiler than we should be. It'd be nice if the compiler changes could be decoupled from the UI updates. Please let me know if you need me to elaborate on this issue.
I tried it out and it seems the only way to do it in VsVim is Ctrl + W, H/J. I'd prefer it to have it as a single keystroke and I wasn't able to figure out how to change VsVim hotkeys (if it is even possible). I did find out that their implementation is based on [TabGroupJumper](https://github.com/mrdooz/TabGroupJumper). I built it and installed it, and then set the hotkey to what I preferred, and now everything is perfect. All thanks to you! :D
That's good, VsVim (like vim) can do arbitrary key binds but it'd be crazy to run all of that addon just for one keybind. I'm glad I inadvertently helped though :)
Any way to get an early look at the code behind "Ranges for the Standard Library"?
Sorry, I'm actually reading from [N4296](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf). Here's the relevant passage: &gt;3 In addition, some identifiers are reserved for use by C ++ implementations and shall not be used otherwise; no diagnostic is required. &gt;(3.1) Each identifier that contains a double underscore __ or begins with an underscore followed by an uppercase letter is reserved to the implementation for any use. &gt;(3.2) Each identifier that begins with an underscore is reserved to the implementation for use as a name in the global namespace. In N3337 the relevant chapter and verse seems to be 17.6.4.3.2.1.
Is this a bug with the VS2015 CTP? I'm here using VS2013's IDE and VS2010's compiler (legacy reasons) - using Mixed Mode debugging for C++/CLI code which mostly exists as a bridge between CLI and C code and I haven't had any issue with viewing floats.
Actually, the full sql sever is not used at all. Only the sql server compact is needed.
Done!
Yeah, the title reads: (Rob Pike's Distributed Search Engine Example) (in C++14 (with Nanomsg and Bond)); for a second I thought R.P. would write a C++14 code example, which made little sense. 
Ha, thanks. This seems really promising!
since I followed on your tip about problems disabling GC: http://forum.dlang.org/thread/kjo7id$22jk$1@digitalmars.com?page=4 and the speed improvements it makes, though speed is not my only concern about GC ! http://3d.benjamin-thaut.de/?p=20 
Do you have a citation for that in the standard?
[Bitfields are an obscure feature of the C language.](http://publications.gbdirect.co.uk/c_book/chapter6/bitfields.html) The term isn't referring to a technique or pattern, but to that specific language feature. It's a very rarely-used feature. It was only years after learning the basics that I even heard of bitfields.
I think GuyWithPants just hasn't heard of bitfields. No need for sarcasm.
AVL are really complex data structures. There are old. I am not sure there are used somewhere
Can't take a joke, can you?
Even then the permission granted to read and write from different union members only applies to the common initial sequence shared between structs; the `value` member isn't a struct, so it doesn't apply to that. However the author has updated the implementation to address both issues, so I think the behavior is well defined now.
I think it's telling that half of these talks appear to be about build systems, package managers, or project dependency management :v
:-)
Got my first internship-turned-job by calling on a want-ad in the local paper. The second job was a direct result of putting my resume on Dice, which resulted in a recruiter contacting me on behalf of the company that eventually hired me. If your budget allows, you might consider a recruiter or obtaining access to the resumes posted on sites like Dice.com.
Finding good C++ developers is very tricky. A lot of experienced (X years of experience!) developers still aren't very good. Best way to find them is via referrals. Look to get your company involved in C++ in the community. We've been hosing some users group meetings recently. Location plays a big part too -- depending on where you need them to be sometimes it's more difficult to find good people. I would suggest looking at StackOverflow answers. You can find smart and capable people there (though some attitudes leave something to be desired), and most probably wouldn't mind a reach out if they have a public profile. Good luck. 
on the first of every month, there's a "who's hiring" thread on hacker news, e.g. https://news.ycombinator.com/item?id=9127232 you might want to check it out.
&gt; One way to filter is to go straight to schools with good reputations That's counterproductive. In my experience, education and skill level are completely uncorrelated when it comes to programmers. They might even be *inversely* correlated. The best indicator I've found is quality and quantity of personal, non-work-related projects. That's how you find people who actually enjoy programming, and they tend to be very good at it. 
I regularly attend C++ meetups here (Austin) however the position is in a city I'm not located and there's no C++ meetup there (Boston). We're not too picky w/C++, we don't even use STL, just need smart proactive people. We don't hire enough to justify the ongoing commitment of giving back to the community. I'd still like to do it but corporate policy disagrees :( Would you recommend just posting the job on StackOverflow marketplace? Or should I find recent answers and just directly message those people?
Interest is more important to us than experience. We're not trailblazers, we don't even use STL not to mention c++11 (which is outdated now too?). I turned down a job once because the manager seemed too obsessed with the intricacies of c++ even. In any case, conferences are a good idea. I'll mention that to my manager.
PM sent. Hope to hear back!
Good idea for filtering the barrage of resumes we get from Dice.
That's where I went first. Got a couple resumes already, people look interesting. However, the threads are stale now and they don't seem to allow posts anymore. I guess I'll wait until 1st of the month.
Why no stl or C++11, are you writing embedded programs? I can't imagine experienced C++ programmers wanting to work in a codebase like that.
It's just a legacy codebase from the early 90s. We have our own STL equivalent. Our application domain is very time/memory intensive so we need all the wins we can get and STL doesn't fit the bill (I keep trying, hate maintaining that stuff). No particular reason we're not using c++11, just no one made the effort to use it. The parallel programming features are compelling so when we get the time then maybe.
It's true, not everyone good goes to meetups. Depends on cities too. I never attended in Boston cause it would just take so freaking long to get to them. I'm located in Austin but my group is in Boston. My industry is electronic design automation (EDA) and I work on a non-traditional compiler.
then you definitely need to target a more specialized crowd, I understand now why you struggle to find someone! good luck with your search!
Alternatively, (assuming its not against the rules).. you could post the requirements you are looking for (past c++ programmer obviously), I wouldn't be too surprised if you found some people on here looking for a job (college grad/soon to be grad/x years in industry).
Ask them.
If the STL takes too many resources for your application, you'll gain very little from a shift to C++11. Most of the new benefits/features are heavily designed around working with STL features/structures.
Got all excited when you said Austin.l as I'm looking to relocate, perhaps to TX. But... Boston is definitely out. 
Sure - other hobbies are important too (and exercise, etc). But if you really enjoy programming, those hobbies will include it in some capacity. And I've never met a shitty programmer who really loved doing it. I'm not saying it's a requirement, but it has moved people right to the top of my short list in the past. And thinly veiled horror in response to that question has done the opposite. 
No STL?! I &lt;3 STL.
Maybe, maybe not. It really depends on a whole lot of things. I'm more taken to doing personal projects lately than I have been for the last couple of years, simply because up until recently, I was spending on average 60 hours per week in the office. The little time I had off during that period was spent far away from most electronics (apart from the occasional game or dummy program for testing out a new language/feature). I could totally understand how someone who is constantly doing those hours would never want to program outside of work, even if they enjoyed programming and were good at it. Or I might just be a poor at programming. Hard to tell from the inside I guess.
&gt; It's just a legacy codebase from the early 90s. I'm not sure many decent C++ applicants would be very enthused hearing that.
I would assume most experienced, skilled engineers are employed, and so you're really trying to get lucky. That being said, they are interviewing you too, and you can't be helping yourself by coming on sites like this and referring to people's resumes as "spammy". You can't be helping their interpretation of you.
A lot of companies avoid using the STL including my own for embedded systems or cross platform development. For one, the quality of the STL varies too much from platform to platform. MSVC has a pretty poor implementation of many newer parts of the STL such as threading facilities or &lt;functional&gt;, also in far too many cases, MSVC's behavior is non-conforming to the standard or just plain wrong. libstd++, which is used with GCC, still uses copy-on-write for std::string, which is incorrect and will result in crashes/undefined behavior, it's also missing some aspects of the STL, and while libc++ (clang's standard library) has a complete implementation of the STL and is pretty high in terms of conformance, its performance isn't as good as libstd++. So on many embedded systems or for cross platform development, people write their own libraries to ensure consistency both in terms of behavior and performance.
No you are seriously exaggerating this if you think it's very common for people to crunch out 12 hour daily work sessions and then go home and contribute to FOSS projects. Furthermore it's unwise to use the comment section of reddit to validate or reinforce your perceptions about almost anything, be it programming, politics, almost everything. The people most likely and motivated to post on reddit are the ones who have some extreme and special circumstance that is likely to be noteworthy and gain attention. The people who do have modest, reasonable working hours and manage to live a balanced life aren't going to be the ones posting about it to reddit, a comment by such an individual would just be boring and not worth commenting about. As for comparisons to other professions, software engineering consistently ranks at the top of many studies in terms of "best jobs" which factor in compensation, working hours, stress, environment, you name it. The other professions you list with comparable compensation such as being an investment banker, or Doctor (!!!), or lawyer have incredibly long working hours and are high up in terms of stress. Apart from some crummy jobs like people working in mines or oil rigs, teachers are typically ranked as having to work the longest hours and software engineers actually rank very low in terms of hours of work. Check out some surveys that come straight from a simple Google search, they all have software engineer as being one of the best/top ranking jobs whether it's asking who gets the most sleep, which jobs have the best work-family balance, which jobs are the least stressful, you name it and it's funny because software engineering is almost always in the top 3. http://www.forbes.com/sites/jennagoudreau/2012/12/12/the-10-best-jobs-for-work-and-family-balance/ http://www.careercast.com/jobs-rated/2011-ranking-200-jobs-best-worst http://money.usnews.com/careers/best-jobs/rankings/the-100-best-jobs We programmers have no idea just how good we have it.
Where are you hiring?
VC 2013's &lt;functional&gt; was full of bugs, which I have *thoroughly* eradicated in 2015. (The only limitation is that I can't use Expression SFINAE in std::function's ctor and result_of.)