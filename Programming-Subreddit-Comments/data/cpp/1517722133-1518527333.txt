Story or many C++ warts right there!
That ship has sailed (or rather, that plane had flownüòÇüòÇüòÇ). That said, not really. You could say that the software should not attempt to allocate while flying the airplane. (Allocating stuff while initializing is fine).
**The EFL guy has no idea what he is talking about.** It's as simple as that. The default overcommit on Linux is the so-called heuristic (speculative) one, so malloc can return null. But dig this: even if they use the non-default "always overcommit", **malloc can still return null**. It happens due to memory fragmentation. (I even tried myself a long time ago just to see it with my own eyes). This is why the article is correct to speak of referencing null. The "malloc can't return null" is bullshit beyond belief.
[It is good that you didn't write it because you would have been **utterly** wrong](https://www.reddit.com/r/cpp/comments/7uj99c/why_it_is_important_to_check_what_the_malloc/dtpkj7d/?utm_content=permalink&amp;utm_medium=front&amp;utm_source=reddit&amp;utm_name=cpp) As for the minor twist of dying at a random place on Linux: forget Linux, compiler optimizations are a **bitch**. (What article says). As for Windows, as the other guy said, what you're describing doesn't happen with 32 bit processes.
I am not worrying about `bad_alloc`, not any more than any exception. There's no need! Just like any exception should, it causes my code to unwind the stack which normally frees lots of resources and the code can try something else (serve another request). As for reporting the error when memory is tight: I have resources prepared up-front to do that.
Linux definitely will not "kernel panic crash" in case of a random OOM.
Wow... a lot of downright dangerous people commenting here... amazingly all l33t linux haxorz... They should read the documentation and engage brain.
Yes, however, the other side of the coin that causes malloc confusion article speaks of is: one must not forget that on systems with OOM killer turned on, their program could get indiscriminately killed without seeing `bad_alloc`.
Yes, thank you! ... and programs who don't want check for malloc return should use something like "xalloc", typically made to call 'malloc()` and `abort()` in case of failure.
use_count() returns the number of things which share ownership with the shared_ptr. It doesn't care about whether you re-use addresses or whatever. expired is whether use_count is 0 or not. lock just depends on expired. It's pretty clear that there's no allowance for use_count to be wrong from re-using addresses, so the whole thing seems to fall into place nicely.
Oh okay, Thanks for the clarification!
Also would be nice to have something better than header guards :(
Easy enough to test. Just write an infinite loop that mallocs a megabyte or so and memset's it to all 0's. Admittedly the last time I ran into a problem and ran such a test was 6 or 7 years ago, but it definitely crashed the Linux system I ran it on.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
That's actually a very good question. The compile/link cycle is complex and has a number of trade-offs. You could write your code like this and compile library, shared or static. Shared libraries get found and linked in when you run the program. This has the advantages of making your executable file on-disk smaller and you can upgrade a shared library without recompiling executables that use it. Unless you introduce an incompatibility with your original API, anyway. If you compile a static library, the objects in that library will get stored with your executable file. While that means that you'll need to recompile anything that uses your library whenever you change your library, you don't have to go looking for those objects when you run your program, either. I've worked in companies where test environments were all slightly different versions of Linux, and the only choices for making sure my code would run on them all was to either statically compile all the libraries (C standard library et al) into one large executable. Either that or recompile the program on each target system when it was deployed (And a few of them didn't have compilers installed.) A lot of C++ libraries are header-only -- the classes are entirely defined in the header file. This makes programming with templates a bit easier, makes linking a bit easier since all the objects are already defined in the included file, but also has the disadvantage that you have to recompile everything that uses those headers whenever you update your library. Oh yes, and linking is fiddly and can be broken if you specify the files to be linked in the wrong order. You will learn to hate it.
modules will eventually remove those
Can you really (practically) end up with fragmentation of the virtual 64 bit address space? I‚Äôve never seen it happen, even with the churniest of applications. FWIW, the non-windows/non-Linux platforms that I‚Äôve worked on that limited memory have all had hard shutdowns in the case of OOM or a failed allocation, where the OS has caught and crashed my application before my allocation has even returned.
May be my personal setup, but when I indexed a project the whole computer was blocked. I don't mind indexing takes quite a while, but if I can't do other shit in the meantime, it's annoying. 
Yep, that's also very helpful!
More correctly, address space fragmentation. Which is really hard to get on today's systems with 48 bits of address space. 
Yes, of course. The world doesn't run on 64 bit though. Only desktops and servers do...
No you didn't. Or rather, what's meant by a "computer crash"? I rather think something else happened but you don't know what.
I work in games - we target 64 bit only now (thankfully). ‚ÄúExotic‚Äù targets are the current gen consoles, but I never worked with the older ones so I couldn‚Äôt say how bad they were. 
So... malloc from Orbis OS kills you if it can't return a non-null? Wow...
It is very unlikely, that modules will significantly improve compilation speed compared to precomputed headers and that isn't their primary goal.
CRTP Has nothing to do whatsoever with anything related to concepts. For example, you can't do that with CRTP: void foo(/* only integral types */ i) { // Do stuff with i } int main() { foo(3); // ok, int is integral foo(7ull); // ok, ull is integral foo(3.f); // error, float is not integral } I really don't know where CRTP fits in. If something can replace concepts today, it's SFINAE, and ordering SFINAEd overloads is a pain. Concept would simplify this so much, and with the adjective syntax, will remove the template declaration syntax from function template that uses simple (and maybe complex) concepts. That's one huge change to the language.
&gt;The `pmr` approach is the right one IMO, and container allocators will still be a little bit fucked in C++ for a long time because `pmr` is not the default. People will use `std::vector` instead of `std::pmr::vector` by default and write a bunch of code, and then when they go to customize allocators, now a bunch of declarations have to change. Or they have to convert a bunch of functions into function templates so they can take either flavor. &gt; &gt;What's a real-world use case for allocators as a template parameter? I do agree to some degree pmr skulls be the default. But I still agree that we could still change it via a template parameter. What if I don't want that polymorphism overhead? &gt;That's the biggest thing IMO. Way bigger than the metaprogramming with type_traits that C++ currently supports. Having this would make something like a hundred thousand lines of code redundant at work. Possibly more :'( I feel you. To remove that redundant code I used lambda EVERYWHERE, even in places that don't make quite sense, because it's possible to iterate on parameters. Still not as readable as having reflection. &gt;What do you use them primarily for? Naming types without mentioning their template parameters? When your classes names become long enough because of template parameters, making a shortcut for it make sense. And it's useful to give name to member type, without creating new one. Would you imagine a world were this is ill formed? int main() { std::vector&lt;int&gt; v; // error! int is not std::vector&lt;int&gt;::value_type! v.push_back(3); // Error! std::vector&lt;int&gt;::reference_type is not convertible to int! int e = v[0]; } Strong alias are great, but normal aliases still have their use. Also, look at the string class. It's an alias. And if generic code uses a basic string, you can still send a normal string there.
Stackoverflow thread: https://stackoverflow.com/questions/48610895/allow-calling-any-contructor-for-all-array-elements
`new int();` is actually a function declaration; this is known as 'the most vexing parse'.
Any syntax used for the initialization of C-arrays, has to be backwards compatible with the initialization allowed in C. Why don't you just use a `std::vector` and use the "fill" constructor? That will give you almost the same result as you are asking for.
What's with all this `new` stuff?
This is a non-breaking change, as T[N](Args...) syntax is not allowed nowadays. Vector solution is a workaround, it works but we should have some standard way to do this "cheap"
This isn't a problem in the proposal but in your code, you can still do that with vectors and fail the same way
And the gratuitous use of 'auto'
It's hardly gratuitous when it avoids repeating a type in the same line (aka redundancy).
What's non-"cheap" about the vector approach?
It adds nothing. In the case of int it's actually longer
You're actually arguing against DRY..? I don't know what to say to that. &gt;_&gt;
If you look at the documentation for Linux's overcommit behaviour it suggests using it when your machine is mainly doing things like scientific/mathematical computing. It doesn't seem that it was intended for everyday use, but maybe the performance benefits outweigh the carnage it can cause. I will likely turn it off on our AWS machines... if I ask for too much memory then I need to know, not have the OS lie to me and kill my program.
Upvoted
A crashing program is not robust by any means
It's consistent with how `int a[10](23)` is disallowed. I don't think this syntax is intuitive if allowed, and I wonder what's the use case.
Hypothetically, the developer could change the type of array, and they'd only have to update it on the right-hand side of the assignment expression, instead of updating it on both sides. That's what an advocate of auto would argue in defense of this.
No specific reason. I just used Google Benchmarks in another project and liked its output and the possibility to extend it a bit better.
The "fill syntax for arrays" OP is proposing could work in the same way.
If `10` is known at compile-time then there's no need to use `new int[10]`. And if it isn't known at compile-time then how can you write the initializer list of the right length? 
I think that was a reference to metaclasses, not concepts. 
Because making legacy-parts of the language nicer to use is the last thing on any todo-list and allocating `new` in user-code is nothing but legacy, and even more so for dynamic arrays. The work of writing a proposal to change this would be better spent on a proposal to deprecate allocating `new` (which we will sadly never see). (Placement-`new` has use-cases as an experts-feature, but together with explicitly called destructors, `std::malloc` and `std::free` everything one could ever reasonably ask for can be implemented.)
Hm... I'm thinking that if all of the elements were initialized to the same way, then what's the point of having an array? In your class itself, you can do things in the default constructor. auto* x = new Test[10](); Looks like it's implemented. 
That's not what DRY means.. You have to use either auto or the actual type.. So it's actually improved readability vs no benefits. In this case I would go with improved readability. 
Devils advocate, it adds a lot. It forces you to specify and initialize a type on the right side, avoiding a whole class of bugs. 
`#pragma once` is a slightly less obnoxious implementation of the idea, if you're using a sufficiently non-esoteric compiler.
Probably compiling in debug mode
% 3 returns 0, 1 or 2, that is probalitity 2/3, but if you negate it, then probability of executing the code is 1/3
There's use for having all elements start off the same way and then change independently. It's common for that starting point to be a value-initialized object, but other values can still make sense.
In C and C++, integers are automatically treated as boolean using the rule that 0 is false and anything else is true. A numerical expression in an if statement, like `if (X)` is a shortcut for `if (X != 0)` and negating it, `if (!X)` is a shortcut for `if (X == 0)`. Your code is, therefore, more verbosely written as `if ((rand() % 3) == 0)`. As the other commenter explained, there are three possible outcomes of `rand() % 3` and zero is one of them, so your final probability is one out of three.
I think std::fill should satisfy you. ;)
If it wasn't 10, but rather a number large enough to make stack allocation impossible, then you need to heap allocate. 
I failed a technical job interview because I didn't use "auto". I'm not saying which way is right, but some people are adamant about wildcards.
Boost Fusion helps with this a lot.
All the cool kids are doing cloud-native development these days :)
Since this is a build system post, I'm going to make a public service announcement: If you're targeting Linux only, look no further than Nix. It's alien technology compared to anything else.
It is very useful when you know that you need to scale something. Instead of having code that reads 'a[i] = b * c[i]' you can just write 'a[i] *= c[i]'. In such a simple case it might not be so important but it many cases you need to apply hundreds of equations on your data, which means that you need to initialize it anyways to some constant. Most of my work starts with having a for-loop filling some arrays with some constants, the syntax proposed here would help when writing those classes initializers.
And they didn't just present at Cppcon. They also published P0273 which I think does a good job of laying out some of the issues and why some solutions thus far laid out are insufficient. [Here][1] was my response to that "Common C++ Modules TS Misconceptions" when it was posted on reddit. [1]: https://www.reddit.com/r/cpp/comments/7a3t2w/common_c_modules_ts_misconceptions/dp78qg2/
That's pretty stupid. In the absence of a style guide for a particular project or workplace, the use of auto often comes down to personal preference.
&gt; It's mostly used in template classes so that you don't have to repeat the template parameter list every time example pls
Atom is an IDE? Not a text editor?
Not if the type has no default ctor
std::uninitialized_fill is the right algorithm, but its not the same as new[] because it must be called on plain memory and so delete[] wouldn't call the destructor. Better use std::vector or a wrapper around it. In both cases you can only use objects with an copy constructor. That is a bit bad.
I'd like to thank Charley for writing such a lengthy and detailed review report, in addition to performing duties in one of the hardest review managements I think I've seen this decade. I'd like to thank the reviewers for their feedback, and all those who have written me emails and sent me their notes and pull requests. I'd like to thank the dozens of people who made Outcome happen over the years since I started it in 2014, including my wife Megan for putting up with all my early nights so I could get in a few pre-work hours on Outcome each morning. I hope to get Outcome ready for the Boost 1.68 (August) or 1.69 releases (December). Lots of work remains to implement the peer review feedback, all of which has been logged to https://github.com/ned14/outcome/milestone/4 where people can track items as they get fixed. Thank you Boost! Niall 
Ha ha, you're better off
But how would you deprecate `new`? Isn't it basically what all the STL smart pointers are meant to call behind the scenes?
Congratulations on the acceptance, btw. Now the job starts for real. ;)
By default Sourcetrail uses the ideal thread count for indexing to make best use of your CPU. However, you can manually define the thread count in the Preferences at "Indexing". Decrease the value and you should experience less blocking.
How has it happened that the stream I/O operators were used in the opposite way?
I've not tested this stuff but seems that since c++17 you can write something like this (check ref for new op): #include &lt;iostream&gt; #include &lt;algorithm&gt; void* operator new[](std::size_t sz, char c) { void* p = operator new[](sz); std::fill_n(reinterpret_cast&lt;char*&gt;(p), sz, c); return p; } int main() { char* p = new('*') char[6]; p[5] = '\0'; std::cout &lt;&lt; p &lt;&lt; '\n'; delete[] p; }
No you don't. Extern C is for making your C++ symbols compatible for C-style callers, not for *using* C libraries.
WTF. vi gets its own option but not emacs? Fucking lame.
&gt; Using those, your error handling and your normal code are closely intertwined. If your program can continue normally after an error, error handling code is just as normal as any other code because in this case errors are not really errors but simply lower-probability branches, not unlike loop termination. There are superior mechanisms to exceptions like pattern matching on return value.
Personally I use it only for quick tests, but many use and consider Vim + plugins a proper IDE.
I'm sorry, I mean text editor
This page has janky scrolling. There is no reason for a blog's JavaScript to interfere with the browser's scroll mechanics.
If I get this error, and it isn't handled, are you ok with the process ending immediately? Do you have test coverage sufficient to ensure the stack unwinding at any point does not corrupt user data? Is this error edcrptional, and are you willing for the error branch to be 100x more expensive than the non-error branch? If yes to all 3, feel free to use exceptions. As an example, your allocator running out of address space; if you aren't prepared to handle that, process termination is reasonable. If not exceptions, then what? I would advise against error codes. Algebraic returj error types are all the rage now. 
Yes: struct evil { evil* operator&amp;() const { return nullptr; } }; a variable of type `evil`. In real code, some com smart pointers do something like this. 
Im just pinpointing you could use the same keyword to ensure compatibility between C and a new incompatible C++
http://en.cppreference.com/w/cpp/memory/addressof http://en.cppreference.com/w/cpp/language/operators particularly "any of the following 38 operators:+ - * / % ÀÜ **&amp;** | ~ ! = &lt; &gt; += -= *= /= %= ÀÜ= &amp;= |= &lt;&lt; &gt;&gt; &gt;&gt;= &lt;&lt;= == != &lt;= &gt;= &amp;&amp; || ++ -- , -&gt;* -&gt; ( ) [ ]" and afaik, you can always take the address
So you're suggesting adding a full second language to C++ to parse C files?
You can't get the address of main().
Read up about operator overloading, specifically overloading the &amp; operator. If we're talking about C++11 or later (which I assume we are), there's another way to get the address of a variable that avoids the issues with operator overloading, which you can read about on cppreference here: http://en.cppreference.com/w/cpp/memory. Other than that, depending on the depth that the question expects of you, you might want to think a bit about references. You can take the address of a reference variable, but what you get is the address of the referent (i.e. the address of the object it refers to), which is not the address of the reference itself. It is not possible in C++ get the address of a reference for the good reason that (technically) the reference itself does not actually have an address. There's a decent (and short) section on references in Chapter 1 of "The C++ Programming Language" (it's Ch. 1 in my *VERY* old edition, it might be elsewhere in later editions).
`main` isn't a variable, either.
Spacevim
Surprised that Atom isn't on the list, it seems to be pretty popular with developers - I use it for PHP and C/C++ (with plugins to make it closer to an IDE).
You can't take address of a bit field: https://godbolt.org/g/EUDhqG
Clion, it worths every cent
No?
More like anything that overloads &amp;-operator to prevent you from using it.
I don't use an IDE. I use text editors, mainly Sublime, VS Code, vim, and Geany.
In C (not C++), there's something called a "register variable", of which you cannot take the address, since the variable is not stored in memory. The following does not compile in a C compiler. int register x; int* y = &amp;x; C++ however ignores the keyword essentially, it doesn't attach meaning to it. 
VS Code is basically what Atom should have been. Much faster. Much more stable. Did I mention it's much faster? Oh yeah, it's a lot faster than Atom, too.
It would be the compiler job to parse it, like every other features discussed in this thread. Why does it matter particularly in this case?
QtCreator &gt; other C++ IDEs. Clang-based online fixits are a godsend and the locator takes 1/100th of the time CLion's locator takes to populate its index.
And the variable form of that is a function pointer.
`register` is a reserved keyword. Using it in current standard makes the program ill-formed and it's required not to compile
for types that overload unary operator &amp;, you need to use `std::addressof`. And you can not take address of temporaries or single bits.
This was my fault - I thought they had to be defined in a symmetric manner, so that for a json value `j` and a stream `s` all combinations (`j &lt;&lt; s; j &gt;&gt; s; s &lt;&lt; j; s &gt;&gt; j;`) would be possible...
Just tried it and it doesn't seem to re-open anything other than the first window if I close and restart. Is that a configurable option? Without it VSC is basically unusable for me.
&gt; I see no point in using an IDE over a text editor. autocomplete that works? Advanced IDEs check grammar and have sort of static analysis, I rarely encounter compile errors
Pretty good ideas about employing ranged loops and literal operators! Not sure why you have all those asap:: all over the code though, I assume it's just you own coding convention, but it really inflates the size of the overall code. I've tried to do my own time library too actually some time ago, combining the approach used in std::chrono with user-friendliness of Qt. Nothing too serious, but you may check it out if you want. https://github.com/Skoparov/helpers/tree/master/helpers/temporal Some usage examples: https://gist.github.com/Skoparov/a7c1d469d80a6207427deae4197730c5
Someone finally mentioning IDE with good autocomplete
Eclipse but might switch to KDE or Qt. Never VS.
compiler-assisted auto-complete and inline warnings/compile errors? integrated debugging? 
It reopens everything for me. Maybe a bug?
Turns out that the default is to remember one window. If anyone else comes across the same problem you can force all windows with the following configuration: "window.restoreWindows": "all"
This is only true from a computer perspective, but an error often has a great impact in the user experience even if your application is able to continue running. I advocate the use of exceptions whenever you need errors to "bubble up" until the point where you can inform the user of what has gone wrong. 
The best Microsoft sample of RicheEdit usage on Windows is WordPad. So If you think wordpad could handle your code it will be OK. 
I mostly use Visual Studio but have been considering QtCreator a while now. It looks pretty damn good. Any tips and tricks for a Windows guy switching from VS?
Doesn't it violate dependency inversion principle as in SOLID? You are essentially bubbling up implementation details in the form of exceptions from lower layers.
The biggest feature is Ctrl-K, the locator: http://doc.qt.io/qtcreator/creator-editor-locator.html in a few keystrokes you can go to any class (`c MyClass` or just `c MC`, fuzzy searching is supported), any method, do git commits, git diffs, show the online help of a class (`? QLineEdit`, or if you install the cppreference doc any standard C++ type... doxygen docs can also be integrated since doxygen supports the QtCreator help format). Then, there are a lot of niceties: integrated profiling and memory error detection with valgrind (http://doc.qt.io/qtcreator/creator-cache-profiler.html), static analysis with clang's analyzer, cppcheck (and clazy in the upcoming version). The debugger has some useful features: for instance it is scriptable with python which allows [to display images](http://blog.qt.io/blog/2010/04/22/peek-and-poke-vol-3/), etc... Finally, there are a lot of refactors available: http://doc.qt.io/qtcreator/creator-editor-refactoring.html
text editors have autocomplete. not as advanced as an IDE but it's decent depending on what you are doing. Static analysis and such are standalone tools that simply can be run via command line, and those editors he mentioned support assigning to a button to trigger static analysis, then have clickable errors via GUI to jump around between issues.
boost truly is irrelevant if they let this guy and his library in
Cheers! Will have a read of this tonight :)
Visual Studio. There are dozens of us! Dozens!
You're not forced to `catch` the concrete exception class, provide an abstraction you like (i.e. a base class for your exception ) and catch that instead. 
Why?
&gt; DISAGREEMENT: REQUIRES C++14 (versus C++11) I really don't understand this. It's not like people stuck on C++11 compilers will start using boost 1.67. New libraries should always use the latest version of the standard. G++ 4.9 which started supporting a correct part of C++14 was released 4 years ago already. If they haven't updated their compiler in 4 years, they aren't going to update boost either.
I think, recently, boundary between the editor and the IDE is becoming increasingly obscure. Editor with rich plugins(extensions) can simulate almost anything that IDE does, such as autocompletion, on-the-fly linting, etc.
I'm willing to have my view changed. However, last time I checked (~5 years ago, admittedly), autocomplete was completely unusable in heavily templatized code (that uses duck typing, expression templates, CRTP, ...) and therefore was just pointlessly draining my battery lifetime. Has that changed? Which FOSS IDE would you recommend?
Based on what justification? 
From [cppreference](http://en.cppreference.com/w/cpp/language/sizeof): &gt; Queries size of the object or type. &gt; Used when actual size of the object must be known.
There are plenty of developers who are limited in what compiler they use because of platform limitations. Cutting out large percentages of programmers undermines some of he goals of Boost C++ Libraries and creates a hostile appearance in the C++ community.
Emacs.
Eclipse with CDT plugin
`sizeof(char)` is always 1 on every machine. Querying `sizeof(char)` doesn't help you figure out the number of bits in `char`, `std::numeric_limits&lt;unsigned char&gt;::digits` does.
Is there any way to enforce exception types in C++ the same way as function return type can be enforced? In Java this is a big problem which leads to try-catch fortifications around third-party and system calls serving no other purpose than to stop propagation of undeclared exceptions.
IDEs that use libclang to parse your code do not have this problem
Firstly, Outcome v2 was a community effort by a number of well known C++ experts after v1 was rejected. I merely led out the project. I might add that Outcome as a vocabulary library is the very hardest kind of library to get into Boost (or WG21 for that matter). Literally anybody can design a vocabulary library, everybody has an opinion, everybody believes their opinion is the right one. Yet most - including the most expert of experts - are frequently deeply wrong when it comes to vocabulary types even slightly outside their domain of expertise. Now, you can decide that means Boost is irrelevant if you want. Up to you.
 template&lt;class T&gt; struct X { X&amp; operator=(const X&amp;); }; instead of template&lt;class T&gt; struct X { ::X&lt;T&gt;&amp; operator=(const ::X&lt;T&gt;&amp;); };
The C++ 14 requirement isn't really what it appears to mean. It's actually that Outcome requires very recent compilers, so a minimum of clang 4, GCC 6, VS2017, XCode 9. Lots of the userbase will be excluded as a result. Some of the reviewers felt this to be a showstopper, and recommended rejection as a result.
No I don't think it's possible. However you can nest and re-throw exception so that they can be handled in another place with more context. http://en.cppreference.com/w/cpp/error/nested_exception 
Nice example! I usually typed `X&lt;T&gt;` but never realized that just `X` was enough
I use it almost every day. It's just a shame they have hidden the download area so well on their website. It can honestly take me 5 freaking minutes to find the correct place if I don't have my bookmarks.
**Company:** [Skylla Technologies](http://skylla.tech) **Type:** Full time **Description:** We are a Boston area robotics startup looking to grow! If you're interested in robotics, 3D simulator development, or just looking for something new and exciting, please reach out! We are looking for a junior level developer who can grow with the company. We need someone who has experience working with graphics engines (like Ogre or similar) or OpenGL, is comfortable in a Linux environment, and loves modern C++. **Location:** Lexington, MA (just outside of Boston) **Remote:** No **Visa Sponsorship:** No **Technologies:** C++11/14/17, OpenGL, Linux. Optionally Python. **Contact:** Respond to our [Indeed posting](https://www.indeed.com/cmp/Empower-Robotics/jobs/Software-Engineer-21152deae64f0c5c?q=Central+Technology&amp;vjs=3) or PM me.
Sure, but better to tell users that they can't use a library with older toolchains rather than plague them with corner case internal compiler errors. I agree that that swaps hostile appearance with hostile experience, if that makes sense.
Pairing it with vsvim makes for a comfy environment.
This is one the most interesting comments. One can disagree with the positive reviews. One can disagree with the reviewers conclusion, as I'm sure many do. But it's hard to take the conditional acceptance of this library as a reason to conclude that boost is irrelevant. It's third iteration and review. It's been serious, extensive and exhaustive. And it's reached a real decision: accept the library subject to a list of doable conditions. What other system do we have for review certification of library quality? Well we don't actually have any. There are a very few libraries which have demonstrated that they are meet high quality and standards outside of Boost. But generally Boost is the only system we have of certifying that libraries meet even minimal standards for rational design, testing, and documentation. Really, has anyone seen a such a review on any other software as competently prepared as the one above? And in the space of a 10 days? Anyone. The fact that everyone will find libraries in Boost he doesn't want to use doesn't change any of this. I'd like to see Boost be even better, but given the low participation rate of people doing actual work, I'm not hold my breath. For Boost to continue on it's mission it needs more participation from the community. One easy way that persons such as this commenter could contribute is to participate in the formal review process when he has some experience in the subject matter. Note however that the custom in Boost is to post with one's real name which some people might find limiting. Robert Ramey 
The number of bits in a character is defined by the macro CHAR_BIT. I've never actually encountered a machine where CHAR_BIT wasn't 8, but my understanding is that it's possible and occasionally done.
Yes, you should. However, like pretty much every other language feature, you need to use it in an appropriate manner: - Only throw exceptions that are (directly or indirectly) derived from std::exception. - Give some thought to what information you want to be in the exception. std::exception contains a string, which is useful for error reporting, but if you also want to do error-specific error handling you may need additional information. - Do not create a new exception type for every possible error condition. Only create them if you need different handling. - In principle you should only be catching std::exception, unless you need exception-specific handling for another exception type. - Think carefully where exceptions need to be handled. This is probably the hardest part for a beginner, but a good start is around your event-dispatching code. Other relevant places will become apparent over time. - Don't be afraid to let exceptions bubble up to a higher level. Yes, it means you will have to write in a RAII-compliant manner, but you should be doing that anyway. Some numbers, to give you an idea of what is 'normal' exception usage... In my 300,000 line application I have 814 throws, 432 catches, and a grand total of 3 types of exception: std::runtime_error, and two internal types. And finally, why: - Because it is a normal C++ feature. Lots of existing code, including libraries you may want to use, relies on it. - The standard C++ library, including STL, relies on it. - `new` can throw. - Well-known parties (such as Google and Qt) that use a no-exception policy generally inherited this policy from the early days of C++ when exceptions were far less efficient. Google has indicated they would use exceptions if starting now, but have too large a code base to change. Qt is using exceptions in newer subsystems. - Because C-style exception handling is extremely error prone and tedious, in several ways: 1. Each function call becomes three lines: const auto ErrorCode = func(); if (ErrorCode) return ErrorCode; 2. Each return value is hijacked by error reporting, instead of actually conveying meaningful information. 3. It's easy to mix up error return codes from different subsystems, and lose track of actual error numbers. 4. Different functions tend to have different error values, with 0, -1, errno, or some other mechanism used to convey error information. It's easy to make a mistake. 5. It's easy to forget to handle error conditions, leading to undefined behaviour and random crashes. 6. There is a non-zero cost to checking error conditions as part of every function call. 
The only major breaking API change that I can think of will be the comparison operators. The current ones just don't work right (see https://github.com/ned14/outcome/issues/116). Other than that, it would be a simple find-replace-in-files of all `OUTCOME_XXX` with `BOOST_OUTCOME_XXX` and so on, if you follow the recommendation in the documentation to use `OUTCOME_V2_NAMESPACE` (you can see the standalone-to-Boost conversation script for yourself at https://github.com/ned14/outcome/blob/master/.boostify). Thanks to having to rewrite the entire thing from scratch last year, Outcome v2 was carefully designed to be virtually identical in the Boost and standalone editions. It makes migration especially easy, in both directions.
I have never used Qt. I have heard it did not handle modern C++ (C++11,14,17) well.
I'm wanting to give QtCreator a try to see if I switch over from VS, but I'm having a difficult time making it work properly. Apparently after creating a plain C++ project it can't initialize the vcvarsall.bat file. I've googled it and every post I've read says to check the Tools -&gt; Options -&gt; Build &amp; Run -&gt; Compilers and make sure that the compiler is there and it's definitely there. If I copy and paste the path into file explorer, the path and file exist. Has anyone else had this issue with QtCreator? I'm on 4.5 which I believe is the latest open source version.
If you use cmake and have a decent understanding of cmake generators on Windows, you can make Qt Creator just as capable for Windows development as Visual Studio.
It boggles my mind that people think auto complete is a desirable feature.
Xcode for macOS
I guess there isn't a repo to fetch the live code, right? 
Visual Studio, because it is an amazing tool for writing software. From within that one tool you can edit, do version control, change your build settings, build, run, and debug - it's an easily installed one-stop shop for all things programming. And once the code is running nicely on Windows I then check it out on a Linux machine, and do any necessary local editing using 'ed'. Because I'm not one of those sissies that need an "improved", "visual" editor... ;-) 
No it doesn't make sense. You can provide a non-hostile experience even while only supporting certain compiler by giving meaningful compile errors when you detect such unusable cases. But you can also provide a friendly experience by providing partial support based on the compiler features available. Plenty of people would prefer to have a limited usable version of a library if they can live with those limitations. And there are a variety of Boost libraries that already provide enhanced features the more capable your compiler is. From the review and other conversations it is my understanding that outcome2 only needs those really recent compilers for one or two specific aspects. So it might be beneficial to have a wider audience to test the rest of the outcome2 API by allowing such conditional use cases.
Indeed. YouCompleteMe alone gives tab complete, jump to symbol, show variable type. Only thing I'm missing is find usages. But rtags can handle that if necessary. Together with vim-fzf for all sorts of fuzzy search I'm much happier in vim than in Visual Studio. Even in reasonably large code bases (+500k lines)
Three cases unlikely to be relevant in 99% of uses: * Storage: 3 pointers vs one (start,end,capacity) - it could add up if you have many empty vectors. * Runtime: an if check / delete call in the destructor that cannot be avoided. * Program exit: again the destructor, potentially pointless cleanup. 
I find all the integrated stuff that worst aspect of VS. It's an ok environment with a pretty good debugger. But all the other stuff is mediocre and makes it bloated and slow. I chose the best tool for the job, not a single tool to do everything half arsed.
All error handling has this "issue". You are bubbling up implementation details in the form of an error - regardless of how you bubble up that error - return codes, etc. Return codes let (force?) you to translate the error into a different error at each function in the call stack, so that implementation details could be "contained" at a level, but who does that, and is that what you want? If the error info was something the user could do something about (ie "file not found") you probably want to propagate that "implementation detail" upward. Exceptions (and errors) are communication results from a function, not implementation details.
sarcasm or not?
Use of global variables =&gt; hard pass.
That's not possible I am afraid. If you drop C++ 14 `constexpr` entirely, the very latest point release of GCC 5 works reasonably well. Anything earlier ICEs. Any clang 3.x ICEs. Even early VS2017's ICE. The causes of the ICEs are myriad, but most stem from parser bugs, calculated noexcept, use of variable templates and use of calculated CRTP. The review mostly focused on C++ 14 `constexpr` as being the blocker for earlier compiler support, but that's only true in the C++ language sense. It's not true in the real world empirical sense where older compilers ICE frequently. Now, a totally different debate is whether C++ 11 ought to be supported but with these very recent compilers. Some felt it should be. I am of the opinion that C++ 14 and 17 are bug fix point releases of 11, and if your company is using GCC 7.3 but is refusing to switch on at least C++ 14, then your company is in the wrong and it needs to change. I appreciate that C++ users don't like being told they can't use shiny new toys for their own good. But, equally, by the time Outcome actually lands in Boost probably in 2019, the C++ 14 problem will mostly have gone away by then, and if not in 2019, then certainly by 2020.
I am a noob programmer still learning the language and I am pretty much forced to use visual studio since almost all of the tutorials are for that. If I knew how I would use code::blocks. I just find it easier to focus and more visually appealing, I don't know why
Note that the equivalent for C arrays in C++ is std::array. And it should have zero overhead.
I, too, hate efficiency
First: don't use `new`. Second, the C++ way is to use a `std::array` instead. If you really want the array to be allocated on the heap, go for `std::vector`. Third, for `std::array` there is no constructor that does what you need, but there are two options. a) use `fill` after construction (why not?) and b) write your own `array` class (if you really need this, take absolute control of what your software does). The language is needlessly complicated as it is now. I don't think it's fruitful to fix a broken case which should be considered by most coders obsolete. That's my 0.02‚Ç¨, if you need 'em.
**Company:** Sioux Consulting **Type:** Full time, Belgium **Description:** With over 600 engineers, Sioux supports or acts as the R &amp; D department of leading high-tech companies. Sioux is keen to take responsibility: from creating ideas in the conceptual phase up to the delivery of serial production. For long-term projects with our clients, we are looking for experienced C ++ software engineers. You work together with other team members on the development of technical software for complex high-tech products in the field of machine building, consumer electronics, telecommunication, automotive or agri. You are involved in every step of the software development and with your team co-responsible for the requirements, analysis, design, implementation, review, testing and documentation. We are looking for engineers with 3+ years of experience. **Location:** Ghent/Antwerp **Language:** Dutch **Remote:** no. **Visa Sponsorship:** no. **Technologies:** - C++11 en C++14, Boost, Python, Qt5 - Linux - UML, design patterns, agile/scrum,... - Multi-threaded applications - Git, SVN, Perforce **Contact:** Questions or interested ? Email me (Dean) directly recruitment.be@sioux.eu 
Two thirds of all C++ programmers are using C++11 only.
So what if the "code is terrible?" As a user you don't have to worry about it. The library authors and maintainers deal with it so that you the user get a polished product that works well across a wide variety of systems.
The difference is that IDEs know about the project with paths, compile options, etc. This can make parsing more reliable, and allow jumping to things you don't have open.
I don't know anything about what specific changes would be necessary to support older compilers, so take this with a grain of salt, but in general I'm strictly opposed to making compromises when developing new libraries/features in order to support old toolchains: All necessary conditional compilation and design compromises make the result much more difficult to maintain, more error prone and maybe even less elegant to use for people that have a modern compiler. Also consider this: When will those people having to use an outdated compiler (I'm one of them) be actually able to use a boost version that contains this library (what will be the first boost release including it, when is that library accepted into their toolchain? Will they still not have a usable compiler by then? 
If you want strong exception safety, you must change the interface of your code. For example, stack::pop returns void to be exception safe. If I can ensure my copy constructors are noexcept, my program and my interfaces become much simpler. If a copy constructor throws bad_alloc, how exactly am I supposed to deal with it? Most likely any recovery path I will take will require memory allocation. If instead you just let the bad_allocs pass through, they will just crash the program, so I would rather crash the program early and make my copy constructors noexcept.
Any feeling for how many of those developers can use the latest version of boost? Where I personally ran into this limitation is e.g. that you have to stay compatible to the default compiler of a certain linux distro, but then you also have to use the default boost library of that distribution.
I absolutely agree about the quality of the review report. Must have taken him many hours to write. Thanks Vinnie.
Qt Creator is completely independent from the Qt framework/libraries. You can use it for plain C++ projects with Cmake.
I generally love boost and use lots of the libraries all the time, but my god the parallel graph library is nowhere near up to the snuff of anything else in boost I've seen. I use your serialization library in conjunction with boost mpi all the time and it's fantastic, but when it came time I needed some parallel graph algorithms and data structures, I beat my head against a wall with PGL and gave up and wrote my own. 
&gt; As a user you don't have to worry about it. I certainly do every time my debugger steps into this mess. In addition, this makes fixing bugs and adding new features take much more time, which again, as a user, impact me much more than the support for Borland Turbo C++ or Visual Studio 2005.
I use VS Code for editing and VS for running and debugging, because VS is atrociously slow. Opening a file with the quick-open thing takes **seconds**. Also VS code has some really nice plugins that I would seriously miss.
Don't know why you were downvoted. I fire up msvc every couple of years and it is full of new things, but slower than last time. The compiler is also slower to get up to date, but I here you can use a real compiler now, but I don't really know how good clang integration is in the current version. It is also the only tool commonly mentioned in threads like these that costs real money.
I have seen this gif before! But could never found what a thing it is ... until know. Thanks.
OOM errors are very rare on modern PCs. I don't recall the last time my PC ran out or memory. So your program won't crash very often due to bad_allocs. Also, in places where you know you will allocate a large amount of memory (say a user pastes a lot data into your program), use a try_allocate function which can return null on failure. And you then pop up a message to the user (or log an error) saying his action cannot be completed. But the default allocation function should just crash on failure. I will further argue a program designed to crash and recover is more robust than a program which does not attempt to crash in the first place. Your program may crash for any number of reason, most of them out of your control - hardware error, power loss, OOM killer, etc. So instead of focusing on recovering from OOM situations, you should rather focus on recovering the work the user has done prior to crashing. That way your program is more robust in face of any crashes. There are other issues with recovering from OOM. How often do you test the OOM path? OOM can happen almost anywhere, will you be able to test for all those situations? If you haven't tested your OOM path, it probably doesn't work. 
If I was writing a library, or sub-component, I agree with you. Ideally in a library I should give the library user a choice on error handling strategy. But in my application, I decide the error handing strategy. And crashing on bad_allocs make my life much easier, from interface design to testing (You do test your program for OOM conditions, right?)
Same debugger, but not the same UI :) More features in Visual studio.
Definitely not, Qt 5 is the latest version (5.11 I think?)
Recently switched over to VSCode. It is what I always wanted out of emacs, but without all the hassle of emacs. Only a couple of downsides so far with Code 1. It is still relatively new and so many extensions and features are in their early days. 2. It is made in electron, don't care how good it is, a supposedly lightweight editor should't have the resource footprint of full blown Visual Studio. Before someone makes the "dev time is expensive" argument, it's Microsoft, a company that has wrote off more than $11 billion in the last 6 years. Before that I mainly used Visual Studio, which worked great. I just wanted a more portable environment and to be less reliant on a full blown IDE doing all my compiling for me.
It's pretty good functionally, but I've never found the right combination of options to make it *fast*... or maybe it's just that our CMakeLists are a mess :(
So nobody can use the newest version of Boost unless they have GCC 6+?
Heh, no. There are already libraries in Boost requiring minimum GCC 6 such as Hana. Those libraries simply are unavailable on older toolsets. There are likely more GCC 6 requiring libraries coming soon, Yap is currently being reviewed and it is built on top of Hana.
&gt; Visual Studio, because it is an amazing tool for writing software. From within that one tool you can edit, do version control, change your build settings, build, run, and debug - it's an easily installed one-stop shop for all things programming. This. The debugger is really great. Also, I can do a diff / merge from the IDE and get a window with full syntax coloring and intellisense and I can edit the code in the diff / merge window itself. The documentation for IDE features is a bit poor though. I had to experiment a lot to get semantic coloring working right.
If new releases of Boost require GCC 6+, which few people are using now, that‚Äôs pretty annoying.
Visual Studio is the least clunky C++ development experience that I've used.
&gt; Because it is a normal C++ feature. Lots of existing code, including libraries you may want to use, relies on it. The counterpoint to that item specifically is that a lot of companies and even industries typically avoid or ban exceptions and cannot use code that outright relies on them. Advice mostly only relevant to libraries is that it is worth avoiding mandatory dependencies on exceptions for error-handling in such code if you ever expect or would want the library to be used in embedded, real-time, gaming, or similar contexts. Note that this means using `error_code` or monadic errors or the like and not just `abort`/`terminate` - though of course exceptions can _also_ be offered so long as the code supports compiling with `-fno-exceptions` or its ilk.
I use Sublime for all typing, though not really an IDE
It's not a problem at all using the latest Boost on, say, 12.04, if you stick to the header-only libs.
QtCreator has everything I need: autocompletion, column edition, refactoring to rename vars but also implement virtual functions, move stuff from header to C, create properties. Powerful search using ctrl+k, switch between h and cpp. I mean what else do you need that is not in QtCreator? Just curious. 
I use a mixture of the following, depending on what projects I'm working on: - Vim + YouCompleteMe: Most of my personal projects. - CLion: Larger C/C++ projects I end up working on, especially CMake based ones. - Visual Studio: For projects that are already setup to build in VS. - QtCreator: I will occasionally use this for quick and dirty GUI projects. All of these options offer direct support or a plugin that provides support for Vim-style editor modes.
PDF: http://www.pvv.org/~oma/ModernCPPExplained_MoveSemantics_Feb2018.pdf
It's absolutely possible. Whether it's worth it is another story. For constexpr, specifically, you need just replace it with BOOST_CXX14_CONSTEXPR and that's mostly it.
Do you use in Linux out Windows? Atom for Windows is terrible. Nuclide for atom makes it an almost complete ide.
Slides at https://www.slideshare.net/PatriciaAas/secure-programming-practices-in-c-ndc-security-2018
I see. Thanks for the explanation :)
QtCreator. It's the only FOSS one that's good in my opinion.
Is the poll about preference or about about what your current professional environment "forces" you to use?
I was using it in Windows for a short amount of time before switching to VSCode.
Visual Studio. The debugger is just unmatched. I always feel sorry when I see colleagues using qtcreator for debugging.
It is just another customization point in std. Another example is std::begin, and std::end which are used for ranged for.
Very userfriendly and polished interface. Watches, STL visualizers, register view, everything works at a click of a button. One thing I use regularly, I can step through my code step by step, and then switch to the disassembly window, and the same step through key steps through instruction by instruction. Oh, and edit and continue. What have you tried with GDB what you cannot do with VS debugger? I find GDB and VS debugger equally capable, however VS has a far superior UI which actually makes debugging easy.
I use something very similar to this in a lot of my code. In my experience, it's often more useful to use enum's as the keys in the map, however, you can just make the key a template parameter of the registry. You can also extend the registry to classes that share a common constructor that is non-default by adding a variadic template parameter to the end of the registry's template parameter list.
I like how it randomly freezes and then carries on as if nothing weird happened. It's a bit like Homer Simpson having an internal monologue/dream without realising the real world is waiting for a response.
Of course it could be done. But the cost benefit just isn't there. If you're on a non-buggy recent compiler, just turn on C++ 14 and be done with it.
I don't use CMake but while I predominantly develop in Windows and with MSVC I do still have to swap to Linux and gcc fairly frequently. In Linux I tend to use Codeblocks out of long habit, and of course maintaining two solutions is a pain in the arse and ultimately pretty much non-maintainable. Do you have any good resources for picking up CMake on Windows and Linux?
right now it feels more like a half-assed plugin bolted onto IntelliJ. IntelliJ itself is far superior to all other IDEs in functionality, but it's also slow as hell. CLion especially seems to be very slow and doesn't work as well as IntelliJ with Java, so you might as well use visual studio. 
It sure does! But SOLID is a set of guidelines, not rules.
I haven't tried with 12.04 in some time, but it is e.g. also no problem at all to use a recent version of clang on ubuntu 14.04 although the default compiler ist g++4.8 (it is a bit more difficult to use a different standard library). The problem is usually that for some consistency, distribution, compatibility, whatever reasons, someone decided that everyone on your team / company has to use a certain toolchain and library versions (often those are the ones provided by the package manager). Or why exactly can't you use a recent compiler? Btw.: Using header-only libraries doesn't guarantee you, that two separately compiled llibraries which depend on different versions are abi or api compatible (at least I wasn't aware that boost gives any such guarantees) and if they are compiled on the same machine, then header-only or not isn't really important anyway.
Pleasantness of debugging code using Outcome was very high on my priority list. That's because you'll be seeing outcomes on every function you step through, so I tried my best to make the source code for the internals as pretty as possible. I am especially glad to say there are zero MSVC-specific workarounds in Outcome v2. It wasn't that Outcome didn't kill MSVC originally, it's that Microsoft went far out of their way to especially fix their compiler for me by bringing the live Outcome github repo into their compiler validation test suite. Thank you Microsoft.
Boost hana already requires gcc6 and doesn't even compile on MSVC (at least last I checked). That doesn't mean you can't download the latest boost release and use some pre c++11 library .
These were my arguments during the review. I've had a lot of feedback from inside corporations regarding use of Outcome, and most told me that they'll be onto GCC 6 or equivalent by 2019. Even in my current work contract, my next work item is upgrading a 25 year old 2M line codebase from VS2008 with pre-C++ 98 to VS2017 with C++ 17. And that jump is far from uncommon in big corporates, many went VC6 =&gt; VS2005/2008 =&gt; VS2015/2017 because of the 10 year EOL cycle for Visual Studio.
Every job in the games industry I've worked has used Visual Studio as the primary (only?) IDE
If the Boost library supports libstdc++-4.8, sure, you can use clang. That's possible in principle, but not very likely, as if it doesn't support c++11 at all, it's probably not being tested with libstdc++-4.8 (which is not even fully c++11 compliant if I'm not mistaken.)
Can Visual Studio set a breakpoint at library functions today? Last time I looked, I could only set breakpoints on things I have source code for (in my project) because I have to see it to set a breakpoint. Easy in anything that has a command language: "b printf". The best debugger I used so far was the one from Green Hills, closely followed by Lauterbach. Both combine a command language and a GUI, and a steep price. GDB falls back by not having a (default) GUI, Visual Studio by not having a command language. But then, if your programs are native Windows programs, VS' integration probably is unmatched.
I was using vs since 6.0 but at work a project required qt on linux environment so I had a chance to try QtCreator and after 3 years it‚Äôs hard to go back (still love vs, just a little less now).
I just only tried this briefly, but it seems very promising https://github.com/cppit/jucipp
This is also a great way to end up hating any language and the OSS community. I'd recommend being very picky about which OSS project you try to work on. Find something you are actually interested in that uses C++ in a way you would use it then make sure it isn't controlled by some insane group of people who argue over how many characters you put in a line / other forms of bike-shedding instead of what your MR actually does.
I think you'll see a big change in that next year if they're measuring Windows users accurately. Because of the 10 year EOL cycle for Visual Studio, the jump of VC6 =&gt; VS2005/2008 =&gt; VS2015/2017 is unusually common. At my current contract, we're going straight from 1994 era pre-STL C++ 98 into C++ 17 with VS2017. And I'm told that's not uncommon at all, most of the multinational corporation is doing the same across the board. You can blame VC6's unusual historical popularity for this. Back in the day it was utterly dominant. It's had long reaching effects :)
If Boost library X doesn't support C++11, it'll probably not support libstdc++-4.8 either, so using clang won't help. The question was if there's any point in new Boost libraries supporting C++11. Yes, there is, because you can use a newly downloaded Boost on a g++-4.8-based system. The distributed version of Boost has nothing to do with it. In the scenario of using a newer Boost on 14.04, you wouldn't even install the distributed Boost, as it's too easy to pick that up by mistake instead of the newer Boost.
I think that whether it's worth it depends on who uses the library. If nobody complains about this, all is good. That said, I do think that you should make Outcome a better Boost citizen, things like BOOST_CXX14_CONSTEXPR shouldn't be a problem. Same for using boost::throw_exception to throw.
Oh I was wondering how far I had to go down. I basically use VSCode on my Arch laptop for most code editing (c/c++, python, c#, haskell). It basically replaced emacs.
Visual Studio for Windows, Qt Creator for everything else
Thanks, that's really appreciated! What if we had two bool variables; one member variable called is_notifying_ that gets set to true whenever the notify is entered, and one local variable in the notify method called should_clean that only gets set to true if is_notifying_ is false when the method is entered... You think this could work? This should ensure that null pointers are only cleaned from the vector after non-recursive notify calls.
It is worth pointing out that all of the C++ experts listed in this article are in favor of using exceptions. The ones that are quoted as being lukewarm like Jon Klab and Andrei Alexandrescu are either misquoted quoted from old sources that are not representative of their current opinions on the matter. There is currently no real controversy in the c++ community on whether or not to use exceptions. There was in the past, but it has been settled in favor of using exceptions with exception safe code. The techniques for writing exception safe code are well understood and easily learned. Jon Klab (who is quoted as though he does not like exceptions) actually teaches how to use exceptions safely. The only real holdouts are the C with classes people. You can recognize these folks by the fact that they say nice things about C. They normally are writing in C++ because their work requires it rather than because they want too. Someone who's goal is to learn C++ should not listen to them anymore that someone who wants to learn how to code in Java should listen to me.
**Bolding** makes my **Dogmatic Opinions** sound **Authoritative**
So we did talk about different things. My line of thought was this VinnieFalco: &gt; Two thirds of all C++ programmers are using C++11 only. [So requiring a more recent standard excludes a large portion of c++ developers] Me: &gt; Any feeling for how many of those developers can use the latest version of boost? [There must be some reason, why those people can't use c++14 even though it is easy to get a newer compiler. Are you sure those people are allowed to use the latest version of boost? Otherwise those people are excluded from this library anyway] You: &gt; It's not a problem at all using the latest Boost on, say, 12.04, if you stick to the header-only libs. Me: &gt; [Neither using a new compiler, nor using the latest boost library (header only or otherwise) is a technical problem, but there might be extrinsic reasons preventing you from using either]
One of by biggest pet peeves is people waxing eloquent about how they only use a text editor and IDEs are a waste of time and resources, and then complain that they don't like auto because it makes it hard to figure out the type of the variable. A good IDE (for example Visual Studio) has no trouble showing you the exact type of the variable when you hover over it. Please feel free to use your text editor. But do not try to cripple C++ to conform it to what your tool can handle.
I use Visual Studio 2017 (exclusively with the new CMake facility) in Windows + Resharper for C++, and Clion in Linux. I wish though that Visual Studio just used Visual Studio Code as the editor. It is so sad that they still do not support natively multiple cursors, select next occurrence etc. 
This is completely false. There are many reasons why some places are locked into old compilers but still want to be able to update libraries for bug fixes, etc, or even use new libraries. This is especially true in embedded. My industry is only just now seeing support for C++11. 
&gt; by the time Outcome actually lands in Boost probably in 2019 Are you just erring on the side of caution or are you really expecting it will take so long?
UNIX as an IDE FTW.
Not very useful for templates as you can't really give a good autocomplete for dependent names. On the other hand, IDEs like Qt, Eclipse and KDE have great syntax-aware features (generate getters/seters, implement virtual functions, rename variable) + very deep coloring (Eclipse offers over 30 colors, including different colors for overloaded and non-overloaded operators)
&gt; Watches Don't all debuggers have that? &gt; STL visualizers GDB is capable of printing the contents of STL containers and such. Is this feature something more? &gt; What have you tried with GDB what you cannot do with VS debugger? The first things that comes to mind are conditional breakpoints and ignoring breakpoints for the first N times that they are hit. Most other stuff is more of a nuissance than a real limitation. For example, in GDB one can evaluate complex expressions like this: `print some-&gt;expression( someFunction(5) );` Or do something like this to insert a print statement in the code: break foo.cpp:44 command 1 print someVar continue end Both of those can be achieved with VS using "edit and continue", but then I have to remember to clean all the debugging crap out of my code later. 
Hmm - for the same effort you might have added your serialization implementation to the PGL and submitted it as a PR. You'd have gotten review of your work, extensive testing, nice addition to your resume, admiration from your peers and a portable solution which would might have been useful to a lot of other people. The way to make Boost better is to ... make Boost better. Hundreds of people have done this and that is why it is where it is. And that's what has to continue to happen in order for things to improve. 
It's about what you use. Multiple choices are allowed, so you can select what you use at work and what you use on your own.
**Company:** [The Monero Community](https://getmonero.org) **Type:** Full time, part time, contract **Description:** The Monero community is looking for experienced C++ engineers to work on the open-source [Kovri Project](https://getkovri.org). Kovri is a free, decentralized, anonymity technology developed by Monero. Currently based on I2P‚Äôs open specifications, Kovri is a security-focused C++ implementation of the I2P router (originally written in Java). There is funding available through Monero's Forum Funding System (FFS). In the FFS, a contributor that proves to the community that they can contribute positively puts a proposal to the community about what work they plan on doing and the price. The community evaluates the proposal, and, if they think it is worth it, they send donations to fill the requested amount of Monero. [Many](https://forum.getmonero.org/9/work-in-progress/86967/anonimal-s-kovri-full-time-development-funding-thread), [many](https://forum.getmonero.org/9/work-in-progress/89422/moneromooo-full-time-coding-january-march), [many](https://forum.getmonero.org/8/funding-required/89677/rehrar-s-2018-q1-kovri-proposal), [many](https://forum.getmonero.org/9/work-in-progress/89005/funding-for-sarang-at-mrl-for-q1-2018), [many](https://forum.getmonero.org/9/work-in-progress/86984/monero-video-series) proposals have been funded as the community has been shown to be very generous. All payments are paid out in Monero (XMR) which you can read more about at getmonero.org. **Location:** Remote **Remote:** Yes **Visa Sponsorship:** No **Technologies:** The following requisites should be considered: - C++14 and higher - Boost 1.58 or higher - Network programming with Boost - Cryptography - AES - Diffie-Hellman - ElGamal - SHA family - HMAC - RSA - Ed25519 (TweetNaCl) - Experience with [Crypto++](https://cryptopp.com/) - CMake + experience maintaining cross-platform compatibility ([all supported platforms](https://build.getmonero.org/waterfall)) - Anonymity systems and familiar with the various mix-network literature - Familiar with specifications that cover both the common overlay networks (I2P/Tor) as well as emerging systems (such as Kaztenpost/Panoramix) - Added bonuses would be experience with Bash/Python and Docker (all are used in our current testnet) **Contact:** Any interested parties can PM me here on Reddit, or drop by the #kovri IRC channel. Ask for rehrar or anonimal and mention this post.
It could look like Apple‚Äôs Swift language.
[CGold: The Hitchhiker‚Äôs Guide to the CMake](https://cgold.readthedocs.io/en/latest/index.html) is work-in-progress but well worth the read. It's written by the guy behind [Hunter](https://github.com/ruslo/hunter) - a package/dependency manager for CMake, somewhat reminiscent of conan and others.
Alternative suggestion...?
&gt; Similar discussions have been raised in other contexts regarding Boost distribution packaging, and the possibility of forking ‚Äúpre/post‚Äù C++11 (e.g., ‚Äúmodern C++‚Äù) libraries into separate Boost distributions. I'm actually quite interested in this topic. Is there any place, where information about those discussions can be obtained (like a wiki, forum, specific thread in the mailing list)? Or are those discussions mostly offline?
As far as I know, conditional breakpoints and a "hit counter" work just fine in Visual Studio. You can also evaluate expressions during debugging (though admittedly, the expression parser seems to have a few problems with operators).
Boost.Outcome already uses `BOOST_THROW_EXCEPTION()`. I don't know why everybody in the review thought C++ 14 constexpr was the only blocker for C++ 11 support. All the metaprogramming logic and SFINAE uses variable templates. We rely heavily on the added features in the C++ 14 STL. We even make use of aggregate member initialisation. Ripping out all that and replacing it is doable, but again, what is the cost benefit? What's the gain? You'd still be blocked onto GCC 6, clang 4, VS2017, XCode 9 or better because of the ICE problems. So again I ask what's the gain given the cost? I say virtually nothing. If you have those new toolchains available to you, then flipping on C++ 14 is not an issue. The toolchain bugs are the real blocker here, not the C++ version.
Don't use global variables. If the types available to a factory should logically change then that factory should be created externally and then injected.
Give it a try. May want to bump the memory you allocate for the IDE - but I do that for all of jetbrains' IDE:s. Per default, at least in the previous version, it defaults to only using 4 threads for compiling - but it's configurable.
Emacs when I can, visual studio when I must 
D
Visual Studio in Windows. Kdevelop at home.
All of that is possible in the VS debugger without using edit and continue, and has been possible since at least VS 2008 (which is the earliest documentation version available on MSDN).
&gt; FOSS Did you actually mean free or Free?
'Debug-&gt;New Breakpoint', type symbol name.
Yes, I don't know if it is worth it, but there definitely is something to be gained by being conservative about using new C++ features. I'd wager that even today (it was certainly the case a couple of years ago) your code is more portable if you use boost::shared_ptr/weak_ptr/function/bind compared to their std:: equivalents, and this isn't an accident but the result of a deliberate effort. "Is it worth it" can not be answered in the abstract, you need to be able to evaluate what is the likelyhood that your users will need this support on a given platform they're targeting. Note that in many cases they don't get to pick the compiler or its version.
really ? creating a project is, like, the first option in the "Files" menu: https://my.mixtape.moe/mwumoy.webm
Visual studio. I learnt to use C++ in an IDE and have stuck with it. Over the years I've looked at the text editors that some people are always raving about (vi, emacs etc.) but I have never been able to convince myself that it's worth devoting a significant amount of time to learning how to use something that has *fewer* features. And at the same time losing truckloads of convenience like good debugging, disassembly, intellisense, version control integration etc. 
I would need to be a counter, not a bool.
- too software bloated, installs soooo long - strongly tends to add non-standard features in code (precompiled headers - not as a compiler command but include in source), `_tmain`, `WinMain`, pragmans for libraries instead of project settings - [warnings on valid code](https://stackoverflow.com/questions/3317536/visual-studio-warning-c4996/3329714) - they warn about using standard low-level functions "just because they are unsafe" (too much C# point of view?), C4996 (unsafe) is one of them - some functionalities offered by (paid) Resharper are free in Eclipse and Qt - default `.gitignore` for VS has tens of patterns, for other IDEs it's just few or a specific directory - no ABI compability (check all different Visual Redistributables) - GCC can link against VS libs, but not vice versa - may compile code with mistyped file names (although it's a problem from NTFS case ignorance) - no good themes, searched multiple sites and plugins, max 10-15 different colors, Eclipse offers 30+, including 4 different colors for 1line/multiline/Doxygen comments and different color for overloaded operators (compared to non-overloaded ones) - works only on Windows, not very portable (might change due to VSC)
I use **nano** because I'm **too lazy** to learn **vim**. 
&gt;Algebraic return error types are all the rage now That's because they're infinitely better than error codes.
&gt; Always catch any possible exception that might be thrown by a library I‚Äôm using on the same line as it is thrown and deal with it immediately. Spolsky's writing is great ‚Äì I've never seen someone make clear just how much they're missing the point with a single sentence before. /s
Code:blocks is still my goto IDE. Auto completes, decent debugging interface, themes, etc. Not the most fully featured or sleek, but still competent for what it does imo.
Can you give a TL;DR of what it does?
Boost is a _collection_ of libraries; "using Boost" is certainly possible with much older toolsets, just not every library therein...
Whatever a kit is, there's no default installed kit on macOS. &gt; No valid kits found. Please add a kit in the options or via the maintenance tool of the SDK. You click "options" and it leads you to a page with 20 pages with 10 tabs each and each tab has about 15 drop down listings. You click add on what looks like the "Kit" page and are presented another 20 drop down menus. It all looks reasonable so you click "okay" and nothing happens. Still no kit. So you try again and play with some settings and modify a few things. Nope. Adding a kit clearly does not add a kit. 
I use emacs.
This doesn't seem to be on-topic for C++.
You can embed it into the function type in your internal map, so if you if your registry is templated on base class Base, your internal map uses that Base in it's function signature. I have a very old version of my code that does this [here](https://github.com/psalvaggio/cppregpattern/blob/master/registry.h#L128). That version hasn't been updated to use smart pointer and custom keys yet though. Also, most of those macros can be eliminated... I should really update that code.
It avoids one bug, a bug that would be ruled out by the most basic coding standard anyway.
I'd like to like Qt (I use it half the time at work), but I have to say it's still not 2018-ready. No relaxed line spacing in what is primarily a text editor? And the FakeVim support is very lacking to the point of being annoying (try Cmd+S...). VScode on the other hand is rapidly becoming my "IDE" of choice. The C++ plugin is improving at breakneck speed and the whole editor is screaming fast, built for productivity. 
Seriously! I faced this issue just today, and I've used QtCreator for a few years now. Had the iOS + Android builds available but could not for the life of me figure out how to add macOS. Had to look it up in the user manual, which for once had the info I needed. otherwise I usually have a google tab open.
Doesn't Nintendo still use CodeWarrior?
Here are some questions you might want to answer to be able to see what might appear "useless": 1. What problem are you trying to solve? 2. What is wrong with just storing the objects somewhere and accessing them when needed? Why hide the container? 3. What if I have a hierarchy but don't need/want to use shared_ptr? 4. Why would a user extending the base class want to modify it's type this way when normal inheritance or other simpler mechanisms would work too?
/u/14ned four questions: * how many hours of your time did this take? * was it worth it? * would you do it again? * what would you do differently?
I'm not in the gaming Industry but back in college when I along with 2 others built a video game (we won best game of the semester and apparently still haven't been out done) and we did it all in C++ with VS. No game engine though, just C++ code.
The one thing preventing me from using QtCreator is that it splits the .h and .cpp files into separate trees in the project instead of reflecting the files' actual location on disk. It sounds stupid, but this really bothers me. Hate it. I miss XCode, but I've left Apple as a dev platform.
Why is nobody talking about Jetbrains Clion ? Buy it crack it download it for free if you're a student whatever but jetbrains IDE are close to perfection
I've used Code:blocks as well, and I like it.
You absolutely can
Vi, and three other terminal tabs. 
Can we see the results? They're typically revealed to participants once they submit their selection...
Most of the time it's intellisense working hard.
I think something that's also great is you can get extensions for visualizers for other stuff, including for example images. You can also customize the view of your classes but it's a bit tricky to get it right.
I like it, but for my desktop not my laptop. It heats my laptop up too much. C++ IDEs are like that though.
Eh. Atom (and Sublime Text) are popular for web development, but for C++ it's not much more than a colored text editor.
Yeah, that was definitely *not* my experience. WiiU anyone?
I agree. Globals are in the language for a reason and are a code smell, but there are valid uses for them and performing static initialization tasks is one of them. These variables are never used or changed, so I don't really have an issue with them either.
Eh, C, not really C++. Though, C++ does have a few of these problems.
Erm... does Visual Studio run on linux these days? And last time I looked it was behind the new c++ standards to a pretty serious degree. Granted, that was quite some time ago...
Default ICE for platform
Did you ask them why they said that? If so, what were there arguments and why do you disagree with them? 
Sorry, I brought it up because to my knowledge source_group does it's thing for "IDE project generation", cmake by default in VS separates the h/hpp and c/cpp. So if cmake is the one doing that bit to you in Qt Creator, source_group might be the thing that fixes it.
Yeah as a non professional ive been using it for a while and it has a lot of great debugging tools. Its just that sometimes, maybe like 1/30 times i startup VS I get this fucking bullshit LNK error on compile (I think LNK2005) that GOES AWAY WHEN I RESTART VS SO THERES NOTHING WRONG WITH MY SOURCE CODE/LINKING AND I JUST SPEND HALF AN HOUR DEBUGGING FOR NOTHING. but other than that its good.
It looks like you wrote a lowercase I instead of an uppercase I. This has happened 4013 times on Reddit since the launch of this bot.
It is definitely my IDE of choice. Intellisense usually works pretty well (though in templated C++ code it is pretty useless), and the debugging experience is excellent.
But that's the whole point of using Visual Studio.
Not quite, the debugger and the IDE as a whole are also great. Intellisense is flaky and doesn't seem to scale well to large projects.
It crapped out on me a few times, but it got much better with newer versions of VS and lately it has been working well for me.
I will get ranted and down voted but I use Geany mainly for all my programming. Including C++.
Congrats, Niall!
Or it's the peek def window failing to load some COM shit.
Also supports vim mode out of the box which is great. Definitely my favorite IDE.
&gt;Can s_registered be eliminated? &gt;Fortunately, we‚Äôre also on the safe side: &gt;From the latest draft of C++: n4713.pdf [basic.stc.static], point 2: &gt;&gt;variable with static storage duration has initialization or a destructor with side effects; it shall not be eliminated even if it appears to be unused. &gt;So the compiler won‚Äôt optimize such variable. Yet unfortunately the linker will happily ignore it if linking from a static library. 
I'm using it to and from my experience it does not require a lot of resources. C++ extension does. It's not an electron issue.
I guess a counter also works, then you don't need the local variable bool either.
With the bool solution, is_notifying would only be set to false at the end of the function if should_clean had been set to true. So to me it just feels like a matter of preference (or maybe performance) if you do it with two bools or a counter.
If you use CMake and add your headers to `add_executable` / `add_library` they will be shown next to the cpp files, and there's also a hierarchical filesystem view nowadays: https://imgur.com/a/07HZt 
CLion is awful. It's also better than anything else I've found.
interesting, if you install Qt a default kit is generally added automatically so it must have fucked up somewhere during the install process. You have xcode installed right ?
Goddamn, that is literally what Jon Kalb says not to do and until now I though it was a strawman.
What are the practical applications of this?
Debugging? "prototyping" maybe having an slow to rebuild scriptingish c++?
The debugger is unmatched because the devs at Microsoft use it so much to try and fix Windows. *ducks*
I would imagine that this would also make it possible to have further optimisations done (like in the JVM). Also, maybe we will finally get a decent C++ REPL? :D
To force the library user to specify default parameters that are needed? Say you're doing dependency injection; not much use to have a defaulted nullptr now is there?
Have you tried Cling? It's horrible, C++ just isn't a scripting language.
I hear you. But in all fairness: Intellisense has a lot of trouble inside templates / generic code, which is one of the big use cases of auto.
So vim can do text insert and text deletion. Aren't those two things...?
- Improve C compatibility by redesigning the semantics of const. const int a = 0; int b = 0; Both should have the same linkage. - Improve internal consistency by unifying how in-class initializers are handled. class X { unsigned a = sizeof(X); static unsigned b = sizeof(X); }; Both `X::a` and `X::b` should be invalid (or both should be valid).
&gt; brew cask install qt-creator
What I find ridiculous are people who claim not to use an IDE, but add tons of plugins to their Texteditor to give it all the nice IDE features. Not saying that vim+ plugins can't be superior to a "normal" IDE - I haven't tried. But at that point, you are effectively using an IDE.
For writing code I use vim with the following plugins: * [YouCompleteMe](https://valloric.github.io/YouCompleteMe/) * NERDTree for viewing the file system in a tree view * Tagbar for viewing the functions and classes in a tree view for the curent file. * ctrlp.vim for fuzzy file search * vim-cpp-enhanced-highlight highlights things commonly found in C++ programs such as STL functions and classes * ag.vim for fuzzy content search, I usually still prefer using ag from the commandline though * vim-fugutive for common git operations such as blaming and logging * ultisnips for commonly used boilerplate For debugging code it depends on what platform I'm on and what compiler is used. When using GCC/clang I use Qt Creator as a visual debugger. With clang-cl/MSVC I tend to use the Visual Studio debugger for live debugging, and WinDBG for post mortem debugging. I'm not hardcore enough for commandline debugging, my colleagues are though.
YouCompleteMe main page
The SDK for Switch comes with VisualStudio integration now.
I don't like the "phone home' by default settings in VS Code and many of it's extensions. It means that I will never use it outside a virtual machine dedicated to a specific project.
Here is my review of the library. I only looked at the standalone version, as I feel the Boost version is already obsolete. First of all, it won't get the same API/ABI compatibility love as the standalone version, second of all, there's entirely no reason why I should use the boost version in the first place since it isn't remotely ready (considering that there is no documentation for the boost version and lots of open and unanswered questions about how to integrate everything into the Boost landscape have been left out of the review). Overall, I find the idea of a `result&lt;T, Error&gt;` type compelling. Unfortunately, I am disappointed with the presented implementation. Number one reason: It's overly complex and hard to follow. Most of the complexity seems to stem from the fact that the author tried to implement most of the presented classes as 'constexpr' and tried to amend painstakingly proper 'noexcept' specifications (which makes given the presented motivation). This becomes cumbersome due to the possibility to allow for user-defined policies which act as customization points. The result is that the library requires very recent compilers. I tried to compile the test suite with gcc 7.3.0 and got this output: https://gist.github.com/sithhell/27bfacb2bed3b537f3b3ee426473b6a6 I guess that if the implementation would get significantly simplified, those ICEs will go away (NB: It's completely irrelevant if a great simplification already happened when going from v1 to v2. Stressing this fact over and over again should tell you something). SFINAE, CRTP, advanced template metaprogramming and variable templates have been in use for quite some time now. Mitigation strategies for most ICEs surely exist. It's of course up to the verdict of the author to provide a pleasant user experience for users. Keep in mind, that updating a compiler is often not just a matter of doing a 'apt install clang-6.0' (or equivalent). Second, I feel that the presented solution falls short and is not able to deliver. At least to my expectations. To quote the docs: "Something which has long annoyed the purists in the C++ leadership is the problem of dual overloads in capable standard library APIs." As rightly observed, the decision on whether such functions throw or not, depends on the caller. The dual overloads fulfill this property. Outcome promises to coerce those dual overloads into a single one by using 'result&lt;T, E&gt;' as the return type, which is very appealing on first sight, but falls short when looking closer. What the presented solution does, in essence, is to shift the intent to throw or not to the caller with 'default' policies (depending on what the respective author of the library thought would be a sensible default regarding the value and error observers). So the situation gets worse. If the calling code needs to diverge from the originally intended policies of the library API, additional glue code is needed. I assume that this is where policies and the interoperation hooks come into play, adding complexity to the user code. Of course, this makes up a very versatile framework at the cost of code paths hidden in those policies. This makes me want to go back to the dual overload versions, which did exactly what I wanted in the first place at the cost of having a non-idiomatic "out" parameter in the function signatures. Now to the hooking events and interoperation functionality presented (or in general customization points). There is no doubt that those are very powerful beasts and I am pretty sure that they can be made to support the majority of use cases. Except for one: I miss the possibility to implement the semantics of 'value_or,' that is, even in the failure case, I want to provide some fallback value, that is, I just don't care about the error, all I want is some value which I can continue with. Second, I feel that, given the intention to customize and convert given result and outcome types coming from different libraries, makes the presented solution very susceptible to ODR violations. Unless all libraries can see all customization points, which kind of remedies the promised features and will lead to tight coupling once you try actually to incorporate and use different results and outcomes. Last but not least, the C layer is UB. At least the std::error_code part as it makes assumptions about the layout of std::error_code. A completely opaque C result would have been better, with a proper API to query for the different states of the result. I won't cast a vote. This is not an official Boost review, those are just my observations, which might hold or not.
How do you generate math formulas in documentation? LaTeX inside Doxygen comments?
What about user side? Need to install LLVM for everyone?
This should be on /r/cpp_questions
Maybe I'm creating some of that hostile experience you are talking about and I'm sorry, but ~7 years after those types have been standardized that is not a situation we as a community should find acceptable (of course set::shared_ptr can hardly become more portable than the boost one, but it should not lag behind). Sure, the will always be cases, where you can't use c++11 or later, but modern libraries should not have to implement workarounds which are eating up development time/adding dependencies/slowing down compilation, because people (either developers or more likely the management) insist on using outdated (or in case of msvc broken) tools. That will only increase the inertia (Of course there is little reason to upgrade if other people go out of their way, so that I can use their work with my current tools) and slow c++ development further down (and we are already moving at glacial speeds). I guess what I'm trying to say is that the problem is not the library requiring relatively new tools, but development environments that only offer outdated ones.
Yep.
Most compilers will warn you, and even the most basic static analyser will catch it.
&gt; how many hours of your time did this take? It's hard to disambiguate Outcome from the other code which uses it. But 1000-2000 hours by me alone is probably about right. The first peer review had more than 800 emails sent about it, assuming each person who sent at least one email spent twenty minutes reading every email sent (likely, they were long and detailed), that's about 1.5 man-years of effort by the Boost community just on that alone (my maths may be wrong here, I just woke up). Many hundred more hours were invested by other individuals on v2, not least on the tutorial. People forget this part about Boost code. A few hundred lines of code often consumes far more effort than tens of thousands of lines of code because it's more important to not screw it up. &gt; was it worth it? Yes. &gt; would you do it again? Probably no. It's become sufficiently hard that it's become once-in-a-career thing unless somebody like your employer is sponsoring you. Don't get me wrong, if I had a sponsor, I'd happily make Boost libraries all day long every day. But those don't exist in C++ since 2008/2009. All new library development is generally done by an individual with an itch to scratch. Consequence of a maturing ecosystem, plus the venture money has gone into other more fashionable languages. &gt; what would you do differently? Nothing. This was a textbook implementation of getting a vocabulary library into Boost, and it actually went much easier than I had originally expected. Niche libraries have a much different process, it's easier in a way because you can do much more of it on your own without the help of others. Much of vocabulary libraries require successfully managing a critical mass of other expert programmers. Fortunately, I have a degree in Management, so it was good use of that training. 
Thanks!
The applicability of some optimizations may depend on some conditions only known at runtime: the value of a variable used in a condition, the number of iterations a loop performs, the actual type of pointed object. This library gives the user a way to "inline" the values for some of the parameters, and obtain a new specialized version of the function. This, without dealing with low level compiler stuff, in contrast to using libjit or llvm. Currently, we're looking to apply it in the code generated by [pythran](https://github.com/serge-sans-paille/pythran).
Alright so I should learn VIM and *then learn to use a whole bunch of other tools*. You are doing the opposite of selling me. 
By the user you mean the programmer who uses the library or the user of the final application? For the first, Yes, as it relies on clang and a compiler plugin to embed the llvm bitcode (only for the functions that will be recompiled at runtime) in the generated binary. For the second, No, as llvm is linked statically with easy::jit's runtime library. However, as size is a concern in this case, we're looking for ways to reduce its size (may be using LTO?) as only a part of the entire LLVM is used.
Many C++ projects use Doxygen to generate their documentation. Having a good search for that documentation is also quite a common need. Maybe the title could be a bit more explicit (e.g. containing the words "CSS" or "template") but I found this relevant and interesting as a C++ dev.
I would've thought intellisense would be running on a background thread. Although maybe sync'ing with the GUI thread takes a long time?
Great summary and good to point these "mistakes" out from the blog. FYI the name is "Kalb", not "Klab" (it makes my eyes hurt :-O)
All IDEs and editors these days have at least a libclang backend for proper compiler supported code completion. This is hardly unique to VS and not really a selling point of Visual Studio.
Even why using an IDE I find it immensely frustrating reading code when I have to repeatedly inspect the types of variables. Code that you cannot understand if it was e.g. printed in a book or on a website is horrible.
&gt; Mitigation strategies for most ICEs surely exist. mitigation strategies for cars that don't behave correctly also exist: sue the car producer. ICEs are bugs. Compilers should fix these bugs. Users of the compilers should not complain to the libraries if their compilers are buggy. Else I will go out of my way to create a compiler that works *almost* correctly *almost* all the time, like a forked clang with a `rand()` added on the overload resolution mechanism, and you guys will have to support it in boost. &gt; The dual overloads fulfill this property. Outcome promises to coerce those dual overloads into a single one by using 'result&lt;T, E&gt;' as the return type, which is very appealing on first sight, but falls short when looking closer. What the presented solution does, in essence, is to shift the intent to throw or not to the caller with 'default' policies (depending on what the respective author of the library thought would be a sensible default regarding the value and error observers). So the situation gets worse. If the calling code needs to diverge from the originally intended policies of the library API, additional glue code is needed. In my experience, something like this is to the contrary very useful: for instance, sometimes whole codebases which use exceptions need to be switched to a no-exception mode, in order to be able to run them on specific environments -- it was the case recently if you wanted to compile for the web, emscripten used to not support exceptions. Having a single policy for your codebase that you can change by flipping a switch is an immense help in that regard.
Here is Vs Code, Visual Studio 2017 and Sublime 3. Each has the same .txt file open, so no C++ extension is loaded currently (but disabled it off just to be sure). Any global extensions turned off. Left is CPU, right is RAM: https://i.imgur.com/fXyrTdl.png Here is Code and VS2017 on the same C++ project (I don't have sublime set up so it wouldn't be a fair comparison): https://i.imgur.com/AMTHXtY.png Code uses more resources than a notoriously bloated IDE that contains far more features than it (by default). The advantage of editors is meant to be being light weight. That is a really small project as well. I'm not saying it makes code automatically bad, it is just a shame they went down the resource usage doesn't matter route. While it is nice to say users machines will keep growing in terms of resources so it does't matter, the truth is a little different. Average dev laptop has 8GB of RAM and has done for some time, you can get 16/32gb but most people aren't. Especially not when the cost of RAM has doubled in the last 2 years. With Code and a few chrome tabs open on win 10, that is around 40% of that RAM used. These apps don't exist in a vacuum and their resource usage quickly adds up. The more worthwhile ones appear the more they start competing with each other despite not being in the same market. If I started hitting 90-100% ram usage regularly, my first thought wouldn't be "I need a new machine" it would be "which of these apps that use way more resources than they should, can I do without or replace with something lightweight". My device is more than capable of its main task, I'm not upgrading because some devs want to turn a development problem into a user problem for whatever reasoning they subscribe to. I wouldn't be the only one either. Electron and the like are a short term "solution" (I struggle to call making a dev problem a user problem, a solution) to a long term problem. That isn't electron's fault, there was a gap in the market that they filled it. The problem isn't even electron itself. The problem is the pervasive "resources are infinite" attitude that has taken hold of software dev in the last few years (been coming for a while but it has skyrocketed in the last few years) for numerous reasons. Sorry ended up on a bit of a rant there.
An interesting application could be [hot swapping](https://en.wikipedia.org/wiki/Hot_swapping#Software) during development.
&gt; Mitigation strategies for most ICEs surely exist. &gt; &gt; mitigation strategies for cars that don't behave correctly also exist: sue the car producer. ICEs are bugs. Compilers should fix these bugs. Users of the compilers should not complain to the libraries if their compilers are buggy. Else I will go out of my way to create a compiler that works almost correctly almost all the time, like a forked clang with a rand() added on the overload resolution mechanism, and you guys will have to support it in boost. You miss the point. Yes, ICEs are compiler bugs. Those bugs can either be triggered by invalid input or because the compiler is just not compliant. Getting those ICEs fixed is, of course, desirable as well as upgrading to the latest and greatest version of your compiler, hoping there are no regressions. What you completely miss though, is that you leave users, who want to use your library completely in the rain. With the outcome that your library is completely unusable. Unless you upgrade to a future version of your compiler. Of course, this is desirable for a library. Every software has bugs. You either work around them, or twiddle your thumbs until those get fixed. Working around bugs/limitation probably makes up most of the time when maintaining code. One cool feature of a reusable library is that it hopefully did the heavy lifting for you already. YMMV.
&gt; Here is my review of the library. I only looked at the standalone version, as I feel the Boost version is already obsolete. First of all, it won't get the same API/ABI compatibility love as the standalone version, second of all, there's entirely no reason why I should use the boost version in the first place since it isn't remotely ready (considering that there is no documentation for the boost version and lots of open and unanswered questions about how to integrate everything into the Boost landscape have been left out of the review). That's because those integration questions were not answerable. Me and the boost-website maintainers need to go figure out some solution they'll be happy with regarding the documentation generation. Once we've decided, I'll go make that happen. The Boost documentation will look extremely similar to the standalone documentation. Main differences will be removal of all Javascript, accessibility support, custom fonts, search engine and obviously the section on installation will need to be rewritten to suit Boost. &gt; Overall, I find the idea of a result&lt;T, Error&gt; type compelling. Unfortunately, I am disappointed with the presented implementation. &gt; &gt; Number one reason: It's overly complex and hard to follow. Most of the complexity seems to stem from the fact that the author tried to implement most of the presented classes as 'constexpr' and tried to amend painstakingly proper 'noexcept' specifications (which makes given the presented motivation). This becomes cumbersome due to the possibility to allow for user-defined policies which act as customization points. The result is that the library requires very recent compilers. I tried to compile the test suite with gcc 7.3.0 and got this output: https://gist.github.com/sithhell/27bfacb2bed3b537f3b3ee426473b6a6 That's a long standing memory corruption bug in GCC's constexpr implementation. Any other compiler, including Visual Studio, works fine. You'll find GCC will work fine on some days, not on others. Depends on the memory layout on the day. GCC 6 is similarly afflicted. I have yet to try GCC 8. Too much focus has been placed on the constexpr support by most reviewers. It's not the blocker, nor feature, that people think it is. Without any constexpr at all, it still ICEs on older compilers for a long list of causes I listed earlier on this very Reddit page. &gt; I guess that if the implementation would get significantly simplified, those ICEs will go away (NB: It's completely irrelevant if a great simplification already happened when going from v1 to v2. Stressing this fact over and over again should tell you something). SFINAE, CRTP, advanced template metaprogramming and variable templates have been in use for quite some time now. Mitigation strategies for most ICEs surely exist. It's of course up to the verdict of the author to provide a pleasant user experience for users. Keep in mind, that updating a compiler is often not just a matter of doing a 'apt install clang-6.0' (or equivalent). The compiler version requirements are the compiler version requirements. As I've said before, I appreciate that C++ users don't like being told that they can't use shiny new toys without upgrading their toolchain. They think they'd prefer a hostile experience of dealing with weird corner case ICEs and poor optimised codegen rather than to be simply told "go upgrade your toolchain to one which works properly". But in truth, that attitude is a fallacy. Upgrading your toolchain to one which works properly will save you much more time and effort than sending your entire org down a rabbit hole with no end, and giving Outcome a bad name and soured reputation in the minds of the userbase. &gt; Second, I feel that the presented solution falls short and is not able to deliver. At least to my expectations. To quote the docs: "Something which has long annoyed the purists in the C++ leadership is the problem of dual overloads in capable standard library APIs." As rightly observed, the decision on whether such functions throw or not, depends on the caller. The dual overloads fulfill this property. Outcome promises to coerce those dual overloads into a single one by using 'result&lt;T, E&gt;' as the return type, which is very appealing on first sight, but falls short when looking closer. What the presented solution does, in essence, is to shift the intent to throw or not to the caller with 'default' policies (depending on what the respective author of the library thought would be a sensible default regarding the value and error observers). So the situation gets worse. If the calling code needs to diverge from the originally intended policies of the library API, additional glue code is needed. I assume that this is where policies and the interoperation hooks come into play, adding complexity to the user code. Of course, this makes up a very versatile framework at the cost of code paths hidden in those policies. This makes me want to go back to the dual overload versions, which did exactly what I wanted in the first place at the cost of having a non-idiomatic "out" parameter in the function signatures. It only appears complex right now through novelty. In practice it's really very simple and fire-and-forget to use. &gt; Now to the hooking events and interoperation functionality presented (or in general customization points). There is no doubt that those are very powerful beasts and I am pretty sure that they can be made to support the majority of use cases. Except for one: I miss the possibility to implement the semantics of 'value_or,' that is, even in the failure case, I want to provide some fallback value, that is, I just don't care about the error, all I want is some value which I can continue with. Thing is, you'll never actually use that operation unless you're using Outcome as an Expected (which I think unwise for most C++ code). And the most recent iteration of Expected before WG21 has also dropped `value_or`. For both Outcome and Expected, we expect those needing it to subclass with extended member functions. If you need a `value_or`, it's so trivially simple to add one yourself it's not worth worrying about. Unlike Expected, Outcome provides extensive interoperation support for individual namespaces severely customising their `ValueOrError` concept matching types. You in your library can write your own Monad implementation, and I can tell Outcome - without modifying your source code - how your custom Monad implementation should interoperate with my chosen Outcome formulation at a per-namespace granularity. &gt; Second, I feel that, given the intention to customize and convert given result and outcome types coming from different libraries, makes the presented solution very susceptible to ODR violations. Unless all libraries can see all customization points, which kind of remedies the promised features and will lead to tight coupling once you try actually to incorporate and use different results and outcomes. You may have noticed that Outcome permutes its namespace with the git commit SHA. Unless you're running the ABI compliance checker to enforce a stable API and ABI, it would be wise to do the same in your own code to avoid ODR problems. In the end this is on the user, and Outcome can't do much about user incompetence. We can merely show the way, and hope users will be sensible. &gt; Last but not least, the C layer is UB. At least the std::error_code part as it makes assumptions about the layout of std::error_code. A completely opaque C result would have been better, with a proper API to query for the different states of the result. No `error_code` implementation that I could find did not place the `int` at the front which is the only bit used by Outcome's C API. I did do a survey. You are however technically correct, and work is underway by SG14 on a `status_code` as part of a remedied `&lt;system_error2&gt;`. I would not be surprised if the Outcome C layer stops supporting `error_code` and starts supporting `status_code` by the time Outcome enters Boost, precisely because `status_code` would come with guaranteed C layout. &gt; I won't cast a vote. This is not an official Boost review, those are just my observations, which might hold or not. All constructive reviews are always welcome, from any source. Thank you for your review! Niall
OnlY once I'd like to see a talk that is concerned with a bit more high level things than out of bounds access or resource management. Imho the c++ community is far to concerned with those low level aspects. That being said, a language in which a simple Bug can have an unbounded impact on the program (UB) is by definition not well suited for security critical applications.
&gt; In my experience, something like this is to the contrary very useful: for instance, sometimes whole codebases which use exceptions need to be switched to a no-exception mode, in order to be able to run them on specific environments -- it was the case recently if you wanted to compile for the web, emscripten used to not support exceptions. Having a single policy for your codebase that you can change by flipping a switch is an immense help in that regard. Sounds like something to be immensely helpful indeed. What I miss is how outcome helps here though? You either handle possible failures or you don't. If you detect failures with exceptions, you need a different codepath for the case when you turn them off. This still holds when using outcome, no? Which magical switch do I miss?
&gt; That's a long standing memory corruption bug in GCC's constexpr implementation. Any other compiler, including Visual Studio, works fine. You'll find GCC will work fine on some days, not on others. Depends on the memory layout on the day. GCC 6 is similarly afflicted. I have yet to try GCC 8. You should update your prerequisites then: &gt; Outcome is a header only C++ 14 library known to work on these &gt; compiler-platform combinations or better: &gt; &gt; - clang 4.0.1 (LLVM) [FreeBSD, Linux, OS X] &gt; - GCC 6.3 [Linux] &gt; - Visual Studio 2017 [Windows] &gt; - XCode 9 [MacOS] There is no doubt that compiler bugs exist. What I am critizising is the attitude of pushing the responsibility of running a proper toolchain to the user. &gt; The compiler version requirements are the compiler version requirements. As I've said before, I appreciate that C++ users don't like being told that they can't use shiny new toys without upgrading their toolchain. They think they'd prefer a hostile experience of dealing with weird corner case ICEs and poor optimised codegen rather than to be simply told "go upgrade your toolchain to one which works properly". But in truth, that attitude is a fallacy. Upgrading your toolchain to one which works properly will save you much more time and effort than sending your entire org down a rabbit hole with no end, and giving Outcome a bad name and soured reputation in the minds of the userbase. Ultimately, it's your decision. I find it an unreasonable request. Upgrading to the latest toolchain might be a no-brainer for you and me, I'm sure. That's not generally true though, for whatever reason. There's also no doubt that newer compilers optimise their codegen. There will hopefully always be innovation in that field. And yes, sometimes I want to use shiny new toys without upgrading my toolchain. Especially if it is an experimental toy I just want to play around with. If I have to spend half a day to upgrade my toolchain just to play around with a library I am not sure fits my needs, I'll probably just leave it aside. Especially if I'm not interested in the non-functional features like super duper optimized codegen in toy examples. You should really reconsider that attitude once outcome has matured. The problem here is: where does "innovation" stop and "maintenance" begin? What do you do with regressions? Will there only ever be one specific point release of a given toolchain supporting the library? Furthermore, I am not trying to give outcome a bad name or soured reputation. If it's not working with an off-the-shelve compiler coming out of your distribution... well, that's upon you to judge. Noone said it's outcome fault per se. What I am arguing is that a high-quality library should be able to work around those bugs. YMMV. &gt; It only appears complex right now through novelty. In practice it's really very simple and fire-and-forget to use. Well, you can't argue that adding the customization points to your code is not adding complexity? Compared to the dual overloads, it does. Getting rid of those dual overloads is one of my reasons why I could find outcome to be interesting. My verdict for this specific usecase is that it's not worth it. &gt; You may have noticed that Outcome permutes its namespace with the git commit SHA. Unless you're running the ABI compliance checker to enforce a stable API and ABI, it would be wise to do the same in your own code to avoid ODR problems. That doesn't really help. Consider a code base, using the same version (as in git commit SHA) of outcome. What happens if a user specializes convert with the same types? This might happen if you want to have different behavior in some of your subsystems due to different needs and contexts you call the 'outcome'-ified API. This is not necessarily user incompentence, but a result of the advertised features. &gt; No error_code implementation that I could find did not place the int at the front which is the only bit used by Outcome's C API. I did do a survey. Observing what's the current status quo doesn't mean it's not UB. It's very similar to forward declaring std types, just a tiny bit worse. &gt; You are however technically correct, and work is underway by SG14 on a status_code as part of a remedied &lt;system_error2&gt;. I would not be surprised if the Outcome C layer stops supporting error_code and starts supporting status_code by the time Outcome enters Boost, precisely because status_code would come with guaranteed C layout. good luck with that! 
Thanks! I don't know if you have a blog, but I think I learned a lot from "seeing Outcome happen". I think it would be could if you could reflect about this again in 1-5 years time. There are many aspects of getting a library into Boost that might not be immediately obvious.
&gt; You should update your prerequisites then: &gt; There is no doubt that compiler bugs exist. What I am critizising is the attitude of pushing the responsibility of running a proper toolchain to the user. Outcome's test code pushes the compiler far harder than real world code does. I don't consider GCC's memory corruption bug in constexpr to be a problem outside of test suite code. I've never encountered it in years of writing code using Outcome. And besides, the GCC maintainers are on it, the fact it's not reliably reproducible is a real headache for them. So the listed compilers stand, though I may add a note to the docs about the fact that the test suite may, or may not pass, on GCC depending and to not read too much into that. &gt; You should really reconsider that attitude once outcome has matured. The problem here is: where does "innovation" stop and "maintenance" begin? What do you do with regressions? Will there only ever be one specific point release of a given toolchain supporting the library? That's up to the toolchain vendors, but I see no good reason for Outcome to not remain compatible with C++ 14 going into the future. If a toolchain vendor decides that a point release of their compiler must improve their C++ 14 implementation sufficiently that Outcome will run well on it without workarounds, then great. &gt; Furthermore, I am not trying to give outcome a bad name or soured reputation. If it's not working with an off-the-shelve compiler coming out of your distribution... well, that's upon you to judge. Noone said it's outcome fault per se. What I am arguing is that a high-quality library should be able to work around those bugs. YMMV. Outcome v1 went out of its way to support older compilers. There was significantly increased implementation complexity as a result. The first peer review wanted much of that complexity removed. I did as I was asked to do for v2. I did warn, at that time, that the consequence would be significantly increased toolchain version requirements. That was felt at the time to be worth it if implementation complexity was reduced. Now we have a number of people coming along and crying about spilled milk and saying better could have been done. And yes it could - but at what price? This library has already sucked down thousands of hours of my time, tens of thousands of hours of the Boost community's time. I'm sorry, but enough is enough. This is the library you're getting with the requirements it has. If you don't like it, please feel free to write your own Expected implementation and submit that to Boost where I am sure it will be widely welcomed by those who feel C++ 11 compatibility is very important. &gt; &gt; You may have noticed that Outcome permutes its namespace with the git commit SHA. Unless you're running the ABI compliance checker to enforce a stable API and ABI, it would be wise to do the same in your own code to avoid ODR problems. &gt; &gt; That doesn't really help. Consider a code base, using the same version (as in git commit SHA) of outcome. What happens if a user specializes convert with the same types? This might happen if you want to have different behavior in some of your subsystems due to different needs and contexts you call the 'outcome'-ified API. This is not necessarily user incompentence, but a result of the advertised features. It works fine. I do exactly this (specialising `result` into local custom implementation which is incompatible with any other) in my own code. All works swimmingly. &gt; &gt; You are however technically correct, and work is underway by SG14 on a status_code as part of a remedied &lt;system_error2&gt;. I would not be surprised if the Outcome C layer stops supporting error_code and starts supporting status_code by the time Outcome enters Boost, precisely because status_code would come with guaranteed C layout. &gt; &gt; good luck with that! I hope this was meant sincerely, and not sarcastically. 
I do have a blog - in fact, it has run since before the word "blog" was invented because I've been on the internet for so long now. But it does not cover technical matters due to the poor ROI (i.e. with the same time, I could do other things which earn me more money. Consequence of self employment!) I already have a reflective history of how Outcome got into Boost at https://ned14.github.io/outcome/history/. Expect that to get updated before it enters Boost.
you can use QtCreator for developing and deploying to [microcontrollers like the STM32](http://xpcc.io/guide/qtcreator/)
Slides and code examples: http://www.mshah.io/fosdem18.html
After 24 hours the poll collected almost 1,300 responses. Thanks everyone for voting and commenting. As promised I will post the results soon.
Not an answer but a question: I'm currently using CLion and i want to try QtCreator but i'm to fond of my keybinds, does anyone knows a way to export the keybinds from CLion to QtCreator? 
Qt Creator can import kms files. No idea what CLion uses, but you can check in the [default locations for user-defined keymaps](https://www.jetbrains.com/help/clion/configuring-keyboard-shortcuts.html) (see end of the page).
&gt; &gt; &gt; You may have noticed that Outcome permutes its namespace with the git commit SHA. Unless you're running the ABI compliance checker to enforce a stable API and ABI, it would be wise to do the same in your own code to avoid ODR problems. &gt; &gt; &gt; &gt; That doesn't really help. Consider a code base, using the same version (as in git commit SHA) of outcome. What happens if a user specializes convert with the same types? This might happen if you want to have different behavior in some of your subsystems due to different needs and contexts you call the 'outcome'-ified API. This is not necessarily user incompentence, but a result of the advertised features. &gt; &gt; &gt; It works fine. I do exactly this (specialising result into local custom implementation which is incompatible with any other) in my own code. All works swimmingly. I am not convinced. Consider this situation: https://wandbox.org/permlink/TNObsXXxCn9Hkaee This rightfully does not compile, of course. Which is more or less exactly my point: Either all `value_or_error` specializations are visible, which also implies that "context base" specializations aren't possible, or you get an ODR violation. Observe this: https://gist.github.com/sithhell/adef84a489688913198fde67ef4235a2 This is clearly an ODR violation, observable like this: ``` $ clang++-6.0 -std=c++17 -I../.. -I. A.cpp B.cpp C.cpp main.cpp $ ./a.out 5 5 $ clang++-6.0 -std=c++17 -I../.. -I. A.cpp C.cpp B.cpp main.cpp $ ./a.out 42 42 ``` What do I miss? Is this a use case that's not supported?
You're going off the assumption that these plugins require learning, with the exception of setting up YouCompleteMe, simply because it's big, it's all very straightforward.
I know it is only intended to be an introduction, but for me the template argument deduction rules for forwarding/universal references was a long time missing piece, which hindered me to understand std::forward and so overall the big picture. you just have to know the rule that: * with a lvalue argument, the template parameter T will be deduced as T&amp;. This leads in the end to the function parameter T&amp; (reference collapsing), but in the functionbody, std::forward&lt;T&gt;'s T is T&amp; * with a rvalue argument, the template parameter T will be deduced as T. This leads in the end to the function parameter T&amp;&amp;, but in the functionbody, std::forward&lt;T&gt;'s T is T i guess you could split the post in two posts, splitting where templates and universal references come into play. 
I'm quite a bit blown away by this presentation. Conan seems really great :-O It looks like they've taken a lot from `pip`, which is probably quite a good thing to do. I'm a bit curious how conan is working/integrating with CPack, but just found that [this](https://github.com/conan-io/conan/issues/102) [has been](https://github.com/conan-io/conan/issues/1061) [answered](https://github.com/conan-io/conan/issues/1061) quite well already. I think conan has a high potential of becoming a sort of de-facto package manager for C++.
I'm not sure whether `std::function&lt; void()noexcept &gt;` is technically valid in C++14. According to [N4140 \[except.spec\]/2](https://timsong-cpp.github.io/cppwp/n4140/except.spec#2) (emphasis mine): &gt; An _exception-specification_ shall appear only on a function declarator for a function type, pointer to function type, reference to function type, or pointer to member function type **that is the top-level type of a declaration or definition, or on such a type appearing as a parameter or return type in a function declarator**.
Out of the box, sure. There are plugins to make Atom more like an IDE though.
No, I hadn't heard of it before, but thanks, will check it out! :-)
So for every registered subclass of `Base`, you create (at static construction time) a shared pointer to it and register it somewhere. Then you can iterate over these subclass instances. A possible use could be a singleton system with delayed initialization or early destruction. Basically, where you have a family of singletons. 
Right
This is a strawman. There are very few people saying you should replace exceptions with C-style error handling. Compare exceptions to algebraic data types, like `expected` or `Outcome` or even `optional` or `variant`. And if you don't have experience with all of those, ‚Äúin times like the present, men should utter nothing for which they would not willingly be responsible through time and eternity.‚Äù 
&gt; B::result is identical to C::result, so obviously the value_or_error machinery will complain. Just let the explicit operators for converting between constructible implementations of result do their jobs. That's not what I want to show with that example. The scenario is the following: libB and libC use libA. A::foo returns some `result&lt;T, E, Policy&gt;` neither libB nor libC is happy with the choice. As such, the want to customize the behavior using the policy framework to return `B::result` or `C::result`, which happen to be the same type in the end. And it shouldn't matter if they are the same, since you want to avoid coupling in the first place, thus the splitting into two libraries. Since they are the same, behavior turns out to be undefined. Bad luck, I guess (as demonstrated in the example which actually split the implementations). Those scenarios are probably not uncommon and unavoidable in "multi-million line codebases" for which outcome was designed for. So the only choice left is to avoid the customization points in such codes altogether, rendering it obsolete. What the snippet showed is using the "`ValueOrError`machinery [...] for incommensurate inputs which have no locally defined conversions in order to handle stitching together third party libraries whose authors did not account for the interoperation being performed by the application writer tying them together." So injecting rules that are asked by the user of libA (libB or libC, both with different requirements) is just out of question, since we want to avoid coupling between libA, libB and libC. &gt; Library writers definitely should not specialise value_or_error. [...] Library writers would simply add constructibility between their result types and other library result types. Much easier. How do you imagine that to happen? Subclassing `result` and add the relevant constructors? That'd work for sure, but see above, and opens doors for other questionable side effects (virtual dtors not present, unwanted slicing, etc.) Again, assuming that the complexity of implementation stems from allowing those hooks and customization points, which only provide limited usage, doesn't justify why outcome requires such unreasonable high requirements to its users. (sorry for running in circles)
&gt; Since C++14/17, I don't use Boost anymore at all. Your loss ‚Äì Boost.Hana is the most compelling C++14 library in existence, and you can pry Boost.Spirit.X3 out of my cold, dead hands.
I don't know whether it is technically valid but, it is accepted by clang, gcc and msvc in C++14 mode, whereas in C++1z mode only msvc accepts: https://godbolt.org/g/MTyfXR
This look promising and interesting (I glance over it, I will take more time later). About the Unicode section however, I'm pretty confident saying that you don't support Unicode properly. One of the problem of Unicode and utf-8, is that their is multiples representation for complex symbols (more information on [wikipedia](https://en.wikipedia.org/wiki/Unicode#Ready-made_versus_composite_characters), I'm not an expert). So it will work most of the time, but not always.
+ Resharper C++ is amazing
Mike says in his talk that LLVM started out with the goal of having an intermediate representation to run optimizations on. Hasn't this always been the case with compilers in recent times? I seem to recall similar things being said about the GNU Compiler Collection at a presentation many years ago. If this is true, what is (was) the appeal of the LLVM project at the time of the project inception?
As long as you don't need to include boost... If you do, the only way CLion remains functional is by disabling all of the autocomplete features. Otherwise, if i type `var.` it starts searching the entire boost library for a possible completion, even if `var` is a string or even int. It takes 10 seconds to continue typing. This is on a 12 Core Xeon with 128 GB RAM, and 10 GB devoted to CLion.
There are a number of reasons why you might want runtime compilation of C++. The library author /u/jmmartinez is primarily interested in optimizations which need knowledge of the data known only at runtime. In the case of my own project [Runtime Compiled C++](http://runtimecompiledcplusplus.blogspot.com/) I wanted fast iterative development of C++ code beyond that which Edit and Continue could give. There's now a fairly substantial community of people using and developing approaches for this, and I keep a fairly [large list of runtime compiled C++ techniques on my wiki](https://github.com/RuntimeCompiledCPlusPlus/RuntimeCompiledCPlusPlus/wiki/Alternatives) - I've just added this project.
I've performance tested `optional` a few months ago, and found it to be painfully slow: the optimizer didn't do nearly as well as it did on a normal (business value) return + exception in case of error. Besides, most of the downsides of error return codes still apply: you still have to check after every function call (either explicitly, or by letting it trigger an exception (in which case, great job at avoiding exceptions), or through hideously convoluted syntax), it's still easy to mix error return codes, assuming of course they are supported in the first place (good luck figuring out what went wrong with optional), and there is still a non-zero cost of error checking and passing everywhere,. Moreover, this cost is much greater for the solutions you mentioned than it is for C-style error codes. So, no, it's not a straw man. expected, outcome, optional, and variant have all the downsides of error return codes, and they are (much) slower to boot, and it's a cost you cannot avoid, unlike with exceptions, where you only pay for the exception if it gets thrown. 
I think Hana is available as header-only, standalone version (https://github.com/boostorg/hana), and with any luck, free of any dependency to boost. Somewhat similar to ASIO I guess.
Yes I'm puzzled. Even on vim with YouCompleteMe, which is pretty barebone compared to VS, I got mostly the same autocomplete as Visual Studio.
If you're interested, you should also check out Angelscript: http://www.angelcode.com/angelscript/ It's a scripting language with a very strong resemblance to C++.
Also I was wondering, with what version of Qt is sourcetrail compiled? I tried to use my system's qt but it couldn't resolve some qt symbols.
As I remind there wasn't any possibility to distinguish function signatures given as `ReturnType(Args)` between `ReturnType(Args) noexcept` since a trait specialization of `template&lt;typename R, typename... A&gt; struct test&lt;R(A...)&gt; {}; template&lt;typename R, typename... A&gt; struct test&lt;R(A...) noexcept&gt; {};` would always prefer the the first one.
Qt Creator, for both C and C++ (without using Qt at all, even.) This allows me to use it on all platforms I need/want to support. Just copy the project over and I can build and debug right away, in the same IDE. No need to maintain separate VS, XCode, and Android Studio project files anymore. Not everything is rosy though. If you have Java code in your Android parts of your app, it's a bit of a hassle. But for Windows/macOS/Linux/Unix-likes, it's a huge time saver. I've heard somewhere that apparently there's even Linux kernel developers out there who have switched to Qt Creator for kernel code. I hope it's not an urban myth.
I sometimes get linking errors that can only be solved by a full restart. So frustrating. Not even deleting the library it claims can't be linked and re-downloading it fixes the issue.
(Off-topic) What is it with all these web pages that hijack my scroll wheel? Seriously, people. Stop it! It's obnoxious. I can't zoom the page and it does this annoying "high speed smooth scrolling" thing. /rant
IMHO, a redesigned C++ would be about getting rid of C compatibility, not about having more of it.
Can LTO help with this?
I have used Visual Studio extensively. The integrated debugger is an extremely well developed feature, and I have yet to find something that comes close. Every IDE leaves something to be desired. When you have one large monolithic program acting as your development environment, customizing and extending your environment can become hard and obtuse. IDEs consist of a bunch of components which act like black boxes, and hinder customization. For example, changing code syntax highlighting colour schemes in Visual Studio is unnecessarily complex. I find customizing options via a GUI to be slower and harder than changing config files. Using CMake to setup up your build toolchain is vastly superior to clicking through a bunch of menus. For me, the Unix philosophy is the saner option. The typical linux development environment consists of a bunch of smaller programs, where each one does one thing well. It allows you to customize your toolset to your hearts content. It can be frustrating at first. I have caught myself reinventing the wheel several times, but the end result is that you become extremely familiar with every component of a development environment. The learning curve is much steeper than using an IDE, but I think there is a point where your finely-tuned dev environment surpasses the features, responsiveness, and productivity of any IDE. Naturally, this becomes a consideration of whether the returns in increased productivity justify the enormous upfront investment in time. In the end, the most important thing is to be a productive developer, so master one development environment.
Apart from cling (part of the root project), you should also check out http://metashell.org/ if you are experimenting with template metaprogramming. In addition, for something a bit different there is this: https://github.com/graalvm/sulong which runs on GraalVM, a JIT compiler for the JVM. P.S.: ŒßŒ±ŒπœÅŒµœÑŒØœÉŒºŒ±œÑŒ± Œ±œÄœå Œ≠ŒΩŒ±ŒΩ œÉœÖŒºœÄŒ±œÑœÅŒπœéœÑŒ∑ œÄœÅŒøŒ≥œÅŒ±ŒºŒºŒ±œÑŒπœÉœÑŒÆ C++!
Personally, I don't find it that bad, considering it is C++ we are talking about and anyway, it makes more sense if you are going to use it as part of root and not a standalone interpreter. However, I found you had to jump through hoops to get it to execute properly without crashes on systems that are not supported by CERN (say Arch Linux, SUSE etc.). And don't get me started on trying to get it to compile on Windows. I know it is not the same thing, but I think that the edit and continue functionality of the Visual Studio debugger works just fine for testing your code in a fast, albeit rather "hacky" way.
This can be very useful if you have an very large (or even open ended) number of possible template permutations, but you know that you will only need a limited set of them for a given run of the program (based on user data).
it allows to do constant propagation at run-time, eg you pass it a function double foo(int N, double y) { for(int i = 0; i &lt; N; i++) { // do stuff with y } } if at some point at runtime you know that you are going to have a lot of time the case for N=10, then you can get an optimized version of this function for this case.
Outcome requires C++14, not C++11. At this time I would not let my team use C++14, because I require portability. &gt; either developers or more likely the management The case I was talking about is proprietary platforms that come with proprietary development tools. The developers and their bosses have no control over this, except to choose not to develop on such platforms.
My only nitpick with projects like these is that it is very probable that some of them will stop being maintained and thus for many developers it is not worthwhile to incorporate them into their toolchain. I believe the same can be said for most of the C++ build tools, in addition to the fact that there are so many of them but we cannot agree on a standard one. This for me is the number one problem of the C++ ecosystem. Scala for example has a standard repl and a standard build tool, sbt (although compilation in Scala is notoriously slow). Nevertheless, I have checked out your project in the past and it is quite interesting, well documented and it worked out of the of box, so all I can say is keep up the good work!
Well, what's *better*, and by what criteria? Probably not everyone has the same criteria as an "embedded" guy, and I found its command language, scriptability and easy configurability quite enjoyable.
Thanks! Maintainability is certainly a valid issue for any C++ library, and the lack of commonality in the toolchain increases the exposure to problems. I'd love to see the C++ spec evolve to include a standardized compilation toolchain spec which made tooling easier.
Xcode on macOS and Visual Studio on Windows
&gt; If you have to work on both platforms, cmake will make your life so much better. I'm already sold on this part, believe me. CMake could be almost unusable and it would still make my life much better than manually maintaining dual VS and CodeBlocks solutions... If CMake is even dimly usable otherwise that's a bonus.
CLion does it's own thing due to it's lineage, but I've never found it to be awful. That said, I personally find vim more productive. If CLion found a way to completely abstract the CMake file away from me I might consider moving back to it, but I figure if I'm going to be maintaining the CMake file manually then there's really not a lot that clion offers that I can't get in vim, and plenty that vim offers that I can't get in CLion. But CLion itself is a fine IDE.
What vim plugins do you use to make it more productive than CLion? I use the vim plugin for CLion and find that it's autocomplete and suggestions are far and away better than any other IDE. Clang-tidy integration is a complete game changer for me. I'll use vim for small projects but as soon as it's anything complicated I move to CLion. 
btw. are there any doxygen replacements atm, which has a nice visual style (or these kind of features) in the first place?
Haha good call. Made my eyes hurt too once you pointed it out. Fixed now.
 #include &lt;iostream&gt; template &lt; typename F &gt; struct fn; template &lt; typename R, typename ... A &gt; struct fn&lt; R(A...) &gt;{ fn(){ std::cout &lt;&lt; "noexcept(false)\n"; } }; template &lt; typename R, typename ... A &gt; struct fn&lt; R(A...)noexcept &gt;{ fn(){ std::cout &lt;&lt; "noexcept(true)\n"; } }; int main(){ fn&lt; void() &gt;{}; fn&lt; void()noexcept &gt;{}; } $ clang++-5 -std=c++1z main.cpp $ ./a.out noexcept(false) noexcept(true)
Hello, I've tried to integrate your remarks all the way through the article. They're very helpful. Thanks a lot for taking the time, and for this work you make for helping the C++ community.
So this would allow for decent REPL?
Sure, they just special-cased a file that contains exactly your string and generates the AST it should. Wait, nevermind, that was browser benchmarks.
You need to get your vendor to provide a consumer of LLVM IR or equilvalent. Then new language features that don't require backend changes are no longer their problem.
No, they actually git submoduled the public Outcome repo with nightly pulls. I know, because I broke their build with a weird git error the Microsoft engineer had never seen before!
&gt; but I think there is a point where your finely-tuned dev environment surpasses the features, responsiveness, and productivity of any IDE. My point was that at that point you are effectively using an IDE. It might be manually assembled, but in the end, all the components are integrated. So saying I don't use an IDE, just because I don't use a single Program (whatever the definition for that is - vs probably consists of a dozen or more different programs) is a bit strange.
Is a plugin for the Kde oriented IDE Kdevelop, in your future plans? 
Okay sorry, let me be more clear: What I mean is the Boost package from boost.org, the whole shabang. I don't mind using individual third-party libraries, if they're good, and I don't mind at all whether they're in Boost or not. But mostly Boost is an "all-or-nothing" thing, and libraries in Boost can't really be used standalone or separately, except for the very few exceptions like ASIO or Hana.
Seems like this changed with `-std=c++1z` because `-std=c++14` has still the behaviour as described above: https://godbolt.org/g/apa9kd
Ok, I am not sure what I should take away from your answer... First, just because there is a proposal to WG21 doesn't mean it is good, there are plenty of counter examples to that. The one in question, P0786R0, is probably in a too early stage to judge and will change lots. Unfortunately, the cited proposal has almost nothing to do with what you implemented, well except that you took over the name `ValueOrError`. Other than that, I can't spot any similarities. Second, you mention `excepted`. It's completely irrelevant to the flaws I described. Third, you assure that my example uses the wrong tools to solve problem of customizing the behavior of different `result&lt;T, E&gt;` coming out of different libraries and suggest that subclassing should be preferred in such situations (NB: what's the mental for such a type: 'is-a' result or 'has-a' result). Fair enough. It seems to be so obvious that the docs don't bother to mention that obviously superior technique for customization. And rather praise, those customization points which are problematic to use at scale, and which you yourself don't recommend to be used for the presented use case? So, right now, I am really confused about what to think of outcome. On the one hand, the customization points are praised as one of the outstanding features which makes it superior to any other presented solution. On the other hand, it is severely limited to application code. The boundaries between what is application code and what is library code is often quite blurry, especially for larger code bases. It's beyond me, why one should adhere to different rules and idioms for one or the others. So I conclude, despite my lack of experience, that the library is over-engineered. Trying to solve the right problem with the wrong tools. This leads to a overly complex implementation severely limiting it's usefulness due to overly restricting the usable toolchains.
YCM has a clang based engine and I use the 'vim-cpp-enhanced-highlight' plugin for a bit of extra oomph. On top of that I use ctrl-p for quickly opening/finding files and then ctags. I don't like integrated VCS plugins in IDE's, ever, so I don't use them. What I found with the CLion vim plugin is that it didn't really play all that well with the rest of CLion. Things like renaming can cause issues, so when using CLion I just turned it off. It's by no means a perfect experience, but between these plugins and using external tools such as grep, I don't ever really find myself missing IDE's. I've often thought about writing a 'vim IDE' that integrated the vim ethos into every bit of the IDE itself, including the GUI aspects of it, i'd call it 'vIDE'. The problem I've found with most plugins is that there's a clear delineation between the vim keybindings and the rest of the IDE.
Yes, in C++14 the ¬¥noexcept¬¥-specification wasn't part of the function signature. That's why the is_same in the original question in C++14 is true and in C++17 false. In C++14 it just didn't matter if you add an ¬¥noexcept¬¥ to the specialization or not. ;-)
Can that feature be used to lookup C++ and CMake reference docs?
You're welcome! Thanks for working on your articles, I think they're very accessible.
I don't think it's a defect that this isn't supported or see a compelling need for it. The template parameter for `std::function` describes the type of the function call operator of the `std::function` itself, which need not be `noexcept` simply because the `std::function` object's value references a function that is `noexcept`. It's similar to the following: std::function&lt;double(double)&gt; x = [] (int) { return 0; }; `x()` takes and returns a double even though the particular value doesn't actually match that. `std::function` 
I don't think it's a defect that this isn't supported or see a compelling need for it. The template parameter for `std::function` describes the type of the function call operator of the `std::function` itself, which need not be `noexcept` simply because the `std::function` object's value references a function that is `noexcept`. It's similar to the following: std::function&lt;double(double)&gt; x = [] (int) { return 0; }; `x()` takes and returns a double even though the particular value doesn't actually end up calling code that takes or returns a double. `T` in `std::function&lt;T&gt;` does not need to match signature of the code invoked by the `std::function` value, it just needs to be compatible. Instantiations of `std::function`are value types that currently always has a 'null' value such calling the function object throws. If you want to be able to specify an instantiation of `std::function` that guarantees calling it never throws then you have to do something about that null value. Eliminate it, make it call a no-op function, something. And what's the benefit of adding that irregularity? Without a good reason I think it's better to keep `std::function&lt;T&gt;` regular.
Their argument was, interestingly, not technical but rather close-minded: "why would we use anything we don't already know?"
I like this! That's what I wanted originally, but I'm pretty new to templates and template templates scare me. Still don't fully understand "value_type"-like types
Which Version are you using and what warning did you encounter? I hope you are not one of those people that activate /Wall and then complain about the warnings. I find all /W4 (rough equivalent to -Wall -Wextra on gcc/clang) pretty reasonable and the standard library headers should compile warning free. Only thing that can get annoying are the conversion warnings in codebases that where not developed with that in mind. Also, while I said that msvc became pretty good in recent times, I never claimed they reached parity with gcc or clang (I even pointed out the current main deficites). 
Your code isn't exactly complicated, so either your coworkers are very new to C++ or perhaps you didn't understand what they were saying.
[Basically programmable constraints for templates.](https://en.wikipedia.org/wiki/Concepts_%28C%2B%2B%29) It allows more expressive template APIs as well as greatly improved compiler error output for incorrect template parameters.
Hey this is great! Almost all CMake files I see though indent on newline, not align with opening bracket. Example set_target_properties(foo bar baz PROPERTIES COMPILE_FLAGS "-std=c++11 -Wall -Wextra" ) or set_target_properties(foo bar baz PROPERTIES COMPILE_FLAGS "-std=c++11 -Wall -Wextra" )
Don't. It is a waste of time.
Yes please! All of history points in this direction.
Thank you for trying! So far my lynda.com crash course is enough to tide me over and now just learn about missing pieces on actual things I need now. I think my understanding right now is too shallow to appreciate the things you listed. I appreciate it nonetheless. I hope to eventually get the aha moment and finally see what you meant. Sorry for the late reply, been busy with my new work and learning as much as possible. Also I hope this reply finds you even after my post got deleted.
Wow! That is amazing, its like c++ oozes out of you. Unfortunately I am not good at Java. I feel like it will take a lifetime before I could fully appreciate and experience every sentence you have said. ‚ÄúRefactoring is dangerous and hard‚Äù I imagine you doing it every breakfast and surviving at the end of the day with revered look from colleagues. One day I hope to be able to rattle off the same amount of advice at the drop of a hat. I appreciate it.
Sorry for the post. I was desperate when I made the post and failed to read the guidelines before posting.
I clicked the web site link, but can't find any way to fill my info. I am looking for remote opportunities and think my expertise and interest fit well with your company. I am new to reddi, not sure how to PM you. 
F12 might be as close as you're going to get.
the default keyboard shortcut is Ctrl+K, Ctrl+O for ToggleHeaderCodeFile. C++ intellisense always sucks, so it may not work as expected.
It's not a bug but I'm not sure it's accurate to say it's a deliberate choice either; it's really just a consequence of the way linkers work. Linkers pull in unresolved symbols until all symbols are resolved. Because the objects are never referenced externally the linker never considers them. There are some tricks you can do to expose the symbols (don't recall the specifics) but at that point you may as well just use explicit registration.
Resharper C++ gives you the option to select a name and include the appropriate header, as well as do that automatically when completing with a suggestion. I can't say firsthand how well it works.
Your primary complaint about VS is that it's bloated, but you use eclipse? It's been a while since I've used it, but it felt like the epitome of bloatware last time I tried (probably 3 years ago or so).
How do you do source control? Debugging? Crash dump analysis? ALM interaction?
Jeeze. I understand this isn't cppcon level of cloud and therefore that level of budgeting, but what's going on with the audio? Here at least it's somewhat understandable, but then [this](https://www.youtube.com/watch?v=SxSTAdRQNB8) monstrosity shows up, which is a bummer because it seemed so amazing. I mean, that video is downright unwatchable. What's the worst is that this is an issue for a huge amount of the talks, many seeming to be extremely interesting and very worthy of watching, but jeeze. That's just downright bad. Is it a funding issue? If so, where can I donate to help avoid this?
Clang-format for cmake?! You sir is a champ.
Well it is objectively useless if there isn't a use case for it.
The problem was that there was no "standard" intermediate representation, and certainly not one you can plug into other projects easily.
Git. gdb/lldb. Depends on the platform, no IDE could accomplish this for each platform I ship on. What the fuck is ALM interaction?
I'd call that a decent sequel, but not a remaster.
Thanks! 
I think they had that for STL headers as an experimental feature, not sure what happened to it.
VisualAssist has this feature, works 90% of the time.
Good point! Nevertheless, I would find it useful to be able to create an `std::function` only with a `noexcept` callable. Especially if I use it in a library interface. Specifically, I have the case that I want to call a callback that gets a `std::exception_ptr` as a parameter. Of course, the callback should not be allowed to throw an exception itself. p0045r1.pdf suggests deleting the construction without a callable in this case. I'm not sure that's the best solution. In my case, it should be possible not to pass a callback. Instead, I would suggest only adjusting the constructors. As long as I check if the `std::function` is not empty before every call-operator call, I would have the guarantee that the call never throws an exception.
Again, you don't even closely implement the mechanisms presented in P0786. The motivation, and focus of the proposal is to offer a unified way to access the different `ValueOrError` types. The classes in outcome, of course, would fall into that category. The customization points presented in that paper could have been implemented. What you implemented however, is the possibility to coerce and customize one `ValueOrError` into another, unrelated one. This is a completely different topic, which isn't even remotely covered by P0768. So yes, the value_or_error customization point you implemented caught my attention since it promises to be able to deal with different error signaling strategies returned by different APIs. I was obviously wrong in thinking it would solve the problem of the dual APIs with error_code, by allowing to ease the customization of different error handling strategies, on a calling context basis. As you and I pointed out, this is not possible with the solutions you propose and different techniques are needed. So yes, in essence, I am disappointed that outcome does not offer a solution for that, despite claiming otherwise. What it is able to offer, however, is to provide global and fixed error reporting/handling strategies. That is, once the `NoValuePolicy` is fixed, it is what it is.
**Company:** [Tenzir](http://tenzir.com) **Type:** Full-time C++ Software Engineer **Description:** Tenzir is an ambitious startup with the vision to substantially improve the security of computer networks. Our primary focus lies on network forensics: the systematic investigation of cyber attacks with big data analytics. We are seeking a very talented and collaborative person to help build the backend for disruptive cybersecurity products. We are creating a modern distributed system on top of a high-performance message passing architecture. Each of Tenzir's two co-founders have over ten years of in-depth experience with C++. We operate a modern code base and focus on quality-oriented reviews. (If you would like to get an impression of what our standards are: we are the creators and maintainers of [VAST](https://github.com/vast-io/vast) and [CAF](https://github.com/actor-framework/actor-framework).) As a key contributor to our technology, you will participate in the entire process from translating user needs into designs and then implement them as working code. In particular: - Design, prototype, develop, and evaluate abstractions in a cutting-edge C++17 code base - Create scalable and composable interfaces in a high-performance mesage passing environment - Tune and enhance data structures to accelerate search queries on massive amounts of data - Contribute to an open and constructive review culture in an agile development setting **Location:** Hamburg, Germany **Remote:** No **Visa Sponsorship:** No **Technologies:** C++ 11/14/17 on UNIX environments (Linux, FreeBSD, macOS) **Contact:** http://tenzir.com/careers/cpp-software-engineer/ or careers@tenzir.com
Sometimes it hides the full resource usage in the drop down of processes. Which can make it appear smaller. Electron basically runs an instance of chrome for each app so will have high resource usage. 
Correction: you can easily convert (without additional code) from, for example checked&lt;T&gt; and unchecked&lt;U&gt;, if T is convertible to U. So this at least solves part of the dual overload issues.
Which is OBVIOUSLY the right thing to do! Appending to a list an item should result in a one line change, not two! Makes merging easier too. This is the first of many attempts that seem to be doing any actual formatting. Should be easy to extend upon and add the customizing knobs later I guess!
It is for sure nice, but what I really want is a cmake-tidy :)
rvalue = unnamed temporary shortest description I can think of
(about `std::make_unique`) &gt; Here is its implementation: Not really. The actual make unique is more complicated as there are also unique pointers to arrays and standard requires unique pointer to an array of known bound to fail to compile
I do. It encourages a rather old fashioned form of programming and is perhaps not as advanced as you would like it to be. But that, I guess, is also the case for Qt. We chose wxWidgets due to the license, which is less restrictive than Qts. The fact that look and feel should be better due to the use of native widgets was also a factor. It has worked rather well for our old-fashioned mostly dialog- and text-based application. wxWidgets has nice support for an open source project and it does evolve: this release is not the only one for two years. That being said: if I were to write a graphics-based applicationI would probably use another framework. I just have no idea what framework I should use instead. Probably a framework originating in the game industry.
Today, it is complaining about a variable that is "unused" in two line comparison function, where it is clearly used. It is doing this on some version of 17. It is in a static string class that checks the length and receives that as a template parameter and then checks the contents of the other string if those are the same and non-zero. It does this as a single expression connected with &amp;&amp; and ||. Clang and gcc with -wall and -weverything (or something similar have warning flags enabled) has no warnings on Linux or OS X, and mingw has no warnings on windows. But literally today msvc had a warning. As for warnings in the std headers, yes that was with /w4. But the std headers aren't my code I shouldn't ever get warnings for them when using them correctly. I know I am using them correctly because my unit testsvall run in CI against 3 or 4 other compilers on like a dozen platforms with -wall a pile of other -w flags and -werror and have been that way for years on this project because we want to know our code is clean. We have 1 or 2 warning flags suppressed project wide for most compilers, but like 20 on msvc.
Just curious, which browser are you using?
Cool demo but not being able to select text with the mouse is really frustrating. 
Yeh, so can't I select text. Scrolling is working, but only if you are out of html5 canvas, where opengl is rendered. Browser not crashing (Chromium 63.0.3239.132)
Indeed (page is not mine). But keep in mind the select text problem has nothing to do with the webassembly demo.
seemed to work except the text was blurry how fast would quake3 ported to webasm be?
If you get warnings from the headers on W4 you can submit a bug (helped for me in the past). It's just /Wall where you can't reasonably expect warning free compilation (although I think they guard against Wall locally most of the time). I think the vs team is also working on an equivalent of `-i&lt;external_library_header&gt;,` but I'm not sure what the state is there. Regarding the unused warning: It's of course hard to say without the code, but that sounds like a bug to me too. If you feel like it, you can submit a Bug report to the msvc team. There is a very slight chance that due to short circuit behavior of(&amp;&amp;,||) the compiler determines that the expression is never actually evaluated, but I think this should produce a different warning. Sorry to hear your experience with recent msvc has been less than stellar. I'm only using it for small scale projects, so maybe that's the reason I didn't got any major problems/annoyances.
&gt; a lot of companies Weasel words, we have statements by one concrete company that this is a legacy issue. &gt; embedded, real-time, Other things not to use: malloc, threads, file io, any io, float values. Also use a 80286 emulator to make sure your lib is compatible with even the oldest embedded devices. &gt; gaming As shown by Minecraft and various Unity based games. 
I've integrated your remark to the article. Thanks!
Does not work on mobile chrome. I can get the ImGui help window rendering and selecting subsections highlights the respective bars, but I can't seem to get any of the menus to expand or drag around the window. 
[https://www.reddit.com/r/HomeworkHelp/](/r/homework_help)
Emacs
As long as you're using CMake, I wrote [a package](https://github.com/atilaneves/cmake-ide) for that.
&gt; doesn‚Äôt cover one case There are [3 overloads](http://en.cppreference.com/w/cpp/memory/unique_ptr/make_unique). I would just write "doesn't cover all cases"
Here is code that I send to my colleagues whenever we have a discussion about rvalue- and lvalue- references. It helps to have concrete examples. #include &lt;iostream&gt; class X{}; void foo(X&amp;) { std::cout &lt;&lt; "Call foo lvalue ref overload\n"; } void foo(X&amp;&amp;) { std::cout &lt;&lt; "Call foo rvalue ref overload\n"; } // "Trick" that Meyers attributes to STL // See Effective Modern C++ Item 4 // Uncomment (*) and (**) below to see deduced types // template&lt;typename T&gt; struct TD; /* (*) */ template&lt;typename T&gt; void bar(T&amp;&amp; t) { // TD&lt;T&gt; tt; /* (**) */ foo(std::forward&lt;T&gt;(t)); } X barf() { return X{}; } void goo(X&amp;&amp; x) { foo(x); } int main(int,char*[]) { X x; foo(x); // lvalue overload foo(std::move(x)); // rvalue overload bar(x); // bar&lt;X&amp;&gt; (lvalue overload) bar(std::move(x)); // bar&lt;X&gt; (rvalue overload) foo(X{}); // rvalue overload bar(X{}); // bar&lt;X&gt; (rvalue overload) foo(barf()); // rvalue std::cout &lt;&lt; "RVALUE or LVALUE? "; goo(X{}); // lvalue overload return 0; } Output is: Call foo lvalue ref overload Call foo rvalue ref overload Call foo lvalue ref overload Call foo rvalue ref overload Call foo rvalue ref overload Call foo rvalue ref overload Call foo rvalue ref overload RVALUE or LVALUE? Call foo lvalue ref overload 
Thank you for sharing! Alas, we are using bespoke 25-year old `make`-based build infrastructure. It's nicely organised and carefully maintained, but not at all modern.
What do you mean by without the file. What file? Are you supposed to analyze data you have no access to? 
*Beep boop* I am a bot that sniffs out spammers, and this smells like spam. At least 100.0% out of the 4 submissions from /u/Mercuraxx appear to be for Udemy affiliate links. Don't let spam take over Reddit! Throw it out! *Bee bop*
As I said in my post I will publish them soon, probably next Monday. I am just waiting to collect more data before aggregating and processing it.
&gt; We chose wxWidgets due to the license, which is less restrictive than Qts. Isn't it basically the same for open source project (LGPL)?
And the other end of the spectrum, distributed memory parallel. MPI is pretty dependent on all running processes taking the same code execution path.
Am I the only one who occasionally finds himself staring at the wrong file when using this? I have several identically named files, that are in different projects and different directories, but all in the same solution. Pressing ctrl-K ctrl-O sometimes opens a file with the correct name, but from another directory and from another project. The same happens when clicking on errors in the output window: most often it gets it right, but occasionally it shows another file that just happens to have the same name. And yes, I've reported this to Microsoft, but you know how they are: "can you please send in a reproducible example?" -&gt; no, I can't - it happens irregularly, it is not something I can make it do on command...
There is yet to be created a jit-ed language that outperforms statically compiled one. Even if some runtime knowledge may allow to make better optimization decisions (though so does PGO), the benefit almast always is dwarfed by the overhead of the JIT itself. Some languages are not made for static compilation and can only achieve acceptable speed in a JIT environment but I really doubt that something that was not made with JIT in mind and has many quirks that make JITing harder would somehow function better.
Hello, /r/cpp. I did this is my project. I'd be happy to answer questions and collect feedback. --hef 
I believe this has to do with "mouse capture" of the canvas element. As a demo: try opening a window in the demo region that requires scrolling and scroll with your mousewheel there. Try clicking outside the demo region, and try scrolling there. What I expect to happen is that scrolling in the demo region on a window causes a scroll to happen in imgui land. clicking outside the region causes the browser to handle scroll commands normally. In a IRL scenario, I wouldn't want to use the canvas element in a non-fullscreen type scenario, but I think you can forward captured mouse events back into the outer javascript layer and simulate normal scrolling
I'd also like to know your browser. I didn't bother making it work in browsers that didn't support wasm. It is possible to embed a wasm interpreter in your projects, but I figured that wasn't the point of the exercise, I wanted to see what framerates I could hit.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7vxi6c/basic_prng_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The generic "label" style text is not selectable, but a text widget does have selectable text. Check the "Keyboard, Mouse, and focus" section. After posting this article I started working and trying to hook up copy and paste behavior, and it got pretty hacky pretty fast. Firefox and chrome between windows, linux, and OS X handle it very differently. Some systems pass you the event for ctrl/command + c, some don't. In some registering callbacks for those disables native copy/paste, some don't. I didn't even look at mobile. It's probably possible to work through the matrix of copy/paste scenarios, but I got lazy.
What's annoying about the webpage? I can work on improving it.
That's my fault, I didn't wire up touch input. The events get passed from the canvas element into the c++ code, but I didn't pass them to the underlying imgui layer.
Yes, that's the builtin `@f$`, `@f[` etc. commands. Unlike in the standard Doxygen output I'm rendering it to inlined SVG to have faster client-side rendering: http://mcss.mosra.cz/admire/math/
The end result of this library, and other runtime compiled C++ approaches, is fully compiled code. The JITing is only done once (or as needed). The performance is thus the same as normal compiled code.
I don't have an explanation for blurry text, but I'd like to investigate: What browser/platform are you on, would you be willing to post a screenshot? I don't think I'd be willing to do an ioquake to wasm port myself, but my experience with emscripten is that it would not be too difficult to port something that already works on multiple platforms to wasm using emscripten. Icculus has already added a bunch of emscripten support to SDL2, which might further reduce the workload.
And... I just realized that you literally cannot copy any text on the page. Thank you for pointing that out. That is not intentional, I'll spend some time seeing if I can figure out how to correct that.
!removehelp
Gotta be a mod for this to work.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7vt4cl/visual_studio_auto_find_header_file_using_ctrl/dtvvrx7/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Application Lifecycle Management - features of an IDE meant to integrate with the rest of your software development process, such as pushing builds, unit test coverage / continuous testing feedback, integration with code review tools, so on.
[ahah](https://www.youtube.com/watch?v=GD6qtc2_AQA)
The JIT still needs to run at runtime to collect the statistics, decide what optimization to apply and what function to compile. Otherwise you could do it all AOT.
This is a nice summary of a few ways that C++17 benefits the author‚Äôs code. I appreciated it.
I don‚Äôt think it's your CMakeLists. It's way slow for me even with the simple projects my students are doing. I still like it better than anything else.
So... the question was "what do you use for *development*", and you said "an editor". So I asked how. So now you're saying something else. Because one can hardly reduce development to an editor.
Yes, but with the significant exception that binaries may be redistributed without source code. This allows for (I believe) static linking, and does not require one to disclose any changes made to wxWidgets included in one's code.
Wrong, the question said what *IDE* do you use. Note that none of the tools that I mentioned are integrated in the sense that an IDE is integrated.
&gt; may be redistributed without source code When it's not really an open source project though.
Haha, we're both wrong, because it's "what *IDE* for *development*". You're more wrong though.
&gt; there are valid uses for them and performing static initialization tasks is one of them. Your argument: *Static initialization is a valid use of globals.* Implicit assumption: *Static initialization is valid.* When you have crummy premises your argument is going to be crummy.
&gt; If I get this error, and it isn't handled, are you ok with the process ending immediately? An excellent default. It's usually better to fail fast and increase the odds that the bug will be caught before release than to silently ignore an error and keep running in an invalid state. &gt; Do you have test coverage sufficient to ensure the stack unwinding at any point does not corrupt user data? If stack unwinding at any point corrupts data, you have far bigger problems than exceptions. That means that `return` and `}` can corrupt your data. Exceptions or no, please don't write such fragile code! &gt; Is this error exceptional, and are you willing for the error branch to be 100x more expensive than the non-error branch? This is a very important consideration. Actually throwing is expensive, so it should only be used for actual errors and not for common or expected irregularities in normal program flow. 
%AppData% and %LocalAppData% is what things generally use, but this has nothing to do with C++.
I was paraphrasing and focusing on the more important part, idiot.
poll results?
I've been using a snapshot from a week or so ago. That snapshot seemed relatively stable, so hopefully the beta will be. The inline clang-tidy and clazy notifications are very, very nice.
I will publish them soon, probably next Monday. I am just waiting to collect more data before aggregating and processing it.
I use atom-ide-ui and ide-cpp, though the latter only works properly on Linux (on Windows it tries to find /usr/bin/clangd, which unsurprisingly doesn't exist). I still run commands like make from a terminal though. I have started using VS Code recently and been impressed at how slick it is. It's better than Atom for C/C++ and probably equivalent for things like PHP and Markdown (not sure if it has a Markdown preview which is a feature of Atom that I find really useful when working on documentation).
I've seen the same issue. Qt Creator is abysmally bad at working out of the box. I've found that that going into "Options -&gt; Build and Run -&gt; Compilers" and making a custom configuration that is identical to the default version often works. If that alone doesn't help, I do the same for "Kits" and "Qt versions" until Qt Creator decides to cooperate or I return to Visual Studio out of frustration. 
Congrats Niall!
This wouldn't be the first time I have stepped into bug in in the compiler territory, and generally whatever I have found is already found (but rarely fixed). I have to work around it anyway because I ship source and I cannot force people using it update or change compilers &gt; recent msvc All msvc, I have yet to find one anywhere near as good as the open source alternatives. I found exactly 1 bug in gcc and none in clang. The one I found in gcc was already fixed I justhad to get a newer version than was shipped in the OS package manager. The other compilers just have fewer defects, produce faster code and take less time to do it.
So, you are in an interactive application. The user does some operation. An exception is thrown deep in a library. It is not caught. Unless you (A) constantly store the application state in a way that outlives the current process, or (B) save the application state during stack unwiding, you just damaged user data. The user data in question is "the state of the application/document at the time I did the operation". This also means you should seek to treat application state and user document state more carefully. Your document edit history should be safe against application crashes, computer shutdowns, and possibly hardware failures. State should be constantly serialized and in a format resistant to memory corruption. Either that, or you need to have a draconian set of rules for exceptions (single base type and basically do nothing but report the error to the user). And you have to audit **every library you use** to follow those rules. And unless you agree with another code base's use of exceptions, you may not use each other's code safely. 
When you post here there's a huge big red box saying that this subreddit is not meant for help and you should try /r/cpp_questions
What were those projects? Do you know what they replaced wxWidgets with?
I don't doubt your experiences at all, but I use CLion with several boost libraries and don't have those issues. I do have some IDE freezes and indexing can be slow at times, but I don't think using boost necessarily cripples CLion in general. 
Page is completely broken on mobile safari.
The big one I know of is Unreal Engine - UE3 (aka UDK) used wxWidgets. UE4 uses their own UI system (known as Slate). Another I know of is [RPCS3](https://rpcs3.net/blog/2017/07/02/qt/) which is more recent.
Whatever comes with iOS - is that a Safari variant? was looking at it from my mobile..
How can I disable a specific warning in the clang inline showing?
ReSharper C++ (a VS extension) shows warnings inline, both from its own set of inspections, as well as from clang and clang-tidy.
Ah, I see. When I wrote this, safari still didn't support wasm, it looks like it was about 5 months later that safari ios supported wasm: https://caniuse.com/#search=wasm It might be fun to figure out a reliable way to crash safari on mobile. I'll have to try OS X safari too, that didn't have support for wasm at the time either.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7vyj4e/file_not_saving_when_the_user_isnt_admin/dtwei7q/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Does it crash for you as well, or is it broken in some other way?
The live demo displays as a black box, the text content on the rest of the page is cut off and then yes, the page eventually just crashes.
Interesting that RPCS3 just says "moved away from the outdated WxWidgets GUI to a Qt based GUI" (keeping wrong original capitalization), but without giving any details of what exactly they considered to be outdated. I may be blind, but I don't see a huge qualitative difference between their [outdated](https://rpcs3.net/blog/wp-content/uploads/2018/01/anniversary/gui_before.jpg) screenshot and the [new one](https://rpcs3.net/blog/wp-content/uploads/2018/01/anniversary/gui_after.jpg) (they do differ, of course, but AFAICS nothing would have prevented them from implementing the latter using wxWidgets neither). Personally I also find it a bit sad that we (that is, wxWidgets developers) only find that both of these apparently big projects used wxWidgets when they stop using it. Oh well.
flair checks out
Thanks! I'll take a look. ReSharper didn't appear in the first page of Google results for any of the following searches. Maybe your web team should invest in a little bit of SEO. üôÇ * visual studio inline c++ warnings * intellisense for warnings * visual studio warnings in editor * visual studio warnings next to code
Depending on what "impossible" means, debugging process will not improve unless self-contained reproducible test cases are submitted to the bug tracker. Especially because the CDB debugger is quite a black box.
This piques my curiosity. What makes visual studio better for debugging than other IDEs?
I'm looking forward to a cmake + conan world. I would love it if cmake moved to an alternate cmakelists.py file alongside the current language. Python scripting is working well with conan.
Same here. There‚Äôs supposed to be a fix in 4.6 codebase but haven‚Äôt had time to try the snapshots. I might try the beta. 
With about 10 seconds of Googling, I found [this](https://msdn.microsoft.com/en-us/library/windows/desktop/bb762159.aspx) You might want to use Schedule Tasks for the reminder, since it won't require your program to keep running until the notification.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7w1mkd/is_it_possible_to_interact_with_w10_notification/dtx0oe2/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
thank you! will do
Thank you! Wasn't quite sure what exactly to google, but this gives me a better direction. 
MSDN usually has a nice list of everything you need, if you know the right keywords you'll usually get what you need quite quickly.
If typing text was more important, then we'd be called typists not developers. It isn't more important, we are not and you're wrong.
And in case anyone else is wondering: https://download.qt.io/official_releases/qtcreator/
It's not the development or environment part I have a problem with. Unix philosophy. Google it.
Sorry, I was on mobile, so I didn't have access to my bookmarks. Your link seems even better than mine, here's the one I've been using lately: https://www1.qt.io/offline-installers/#section-11 They seem to be changing it constantly though, so yours is probably better!
Things that I like: * comfortable and fast inspection of every variable * thread display (what does each thread do right now) * parallel stacks view * ability to work with large, complex applications 
That's probably because it does way, WAY more than just that. R# is amazing, I refuse to use VS without it. 
windows 8.1, with dpi set to 149% which seems to be the issue; text is sharp when i set firefox zoom to 67%
Holy crap, why would you confuse every c++ programmer out there reading your code by using non-zero based indices?
Just a note that this is pre C++11 post and probably skipped memory management issues (as does GoF, for example).
&gt; I believe you hold outdated misconception that exceptions are slow, and that's wrong. No, no I don't hold any such misconceptions. Some folks seem to be confused about what I'm saying here: I am not debating the merits of exceptions and I am not going to, but I am asserting that a number of C++ developers shun exceptions and hence will not use any libraries that rely upon them, which is a potential concern for some library developers. As the other overly-angry poster mentioned, there are other facilities that can be similarly problematic in library code (missing custom allocator support, IO hardcoded to go through `cout`/`cerr`/etc., and so on) but those tend to be fairly well understood and are a boring discussion at this point. The reasons that any developer might have for banning exceptions are immaterial to my point. My point is that the ecosystem is bifurcated between "code that requires exceptions" and "code that works reliably without them" and that a library developer may wish to avoid contributing to further community division by ensuring their code is non-controversial in this context. This is a "you might lose a sale of your library because of a client's opinions of exceptions" situation, completely independent of whether said large client is being reasonable or not.
I believe you can use the `-whole-archive` linker flag (`/WHOLEARCHIVE[:library]` on MSVC) so that the linker doesn't discard your static initialisation.
Good startup time. How did you manage to reduce the code size? Our own experiments with Emscripten/Wasm led to 10-30 seconds loading time on slower machines and 10+ Mb JS/wasm files. But that was about 1.5 year ago, so maybe it's the progress of WASM compiler? Or maybe we just did use too much C++ with templates and everything...
The Qt GUI for RPCS3 features much more than the screenshots you shared: https://rpcs3.net/blog/2017/07/02/qt/ Likewise, Dolphin migrated from wx to Qt: https://dolphin-emu.org/blog/2017/06/03/dolphin-progress-report-may-2017/ having started GUI programming a long time ago with wx, Qt is just overall much easier to work with, and has the great advantage of also having solutions for most common programming problems you can encounter: XML / JSON support, serialization, networking, etc..
Link?
Do they use clang for the code navigation model yet, or still only for error checking and auto completion? Last time I tried qt creator (maybe about 2 years ago), code navigation was very fast to index, but totally unreliable on more sophisticated code. Especially if you want to e.g. find references reliably so you can make refactoring decisions; a process that involves for example correctly resolving ADL. The performance of error-checking/auto complete on large TU's was also really poor, and the vim emulation hadn't gotten TLC in ages. Hopefully these things have been improved? Still one of the better C++ IDEs.
Thanks Emil!
We had something like this, a factory unexpectedly being empty. I was never a fan of the self-registering anyway so I just threw it out and registered by hand.
If there is QtCreator devs reading this, please consider supporting `clangd`, that would let people use any clang version they want, including clang trunk. Also, would it be possible to create Kits from QBS profiles rather than the other way around ? Thanks !
Sorry, I should have paid more attention. Still, the missing delete troubles me - even in a "toy" example.
Nah, you're still wrong. The guy else-thread, who said "my development environment is UNIX" was right. You want to be l33t vi haxorz. Bwahahahaaaa... You're also just saying something, anything, because you think that having the last word wins you an argument. Sure dud. Knock yourself out, I am out now. 
An article from February 01, 1998?
Free as in freedom, which necessarily implies open-source.
&gt; As C++ developer I‚Äôm very confused. Should I use Them or not? Yes, unless you have a strong reason not to. &gt; There‚Äôs one common big issue invoked by all the C++ actors, it‚Äôs not trivial to write an exception safety code. This is a red herring. It is not trivial to write error handling code in gneral, and this is difficult for both error code returns and exceptions. &gt; We can classify C++ developers in four categories: &gt; &gt; Category 1: Use C++ exceptions without care of exception safety code. &gt; &gt; Category 2: Use C++ exceptions, and are aware of the safety code problematic. &gt; &gt; Category 3: Not Use them but not know exactly the pros and cons of exceptions. &gt; &gt; Category 4: Not Use them because they understand exactly the cons of using them. This categorization implies (in categories 3 and 4) that if you don't "know exactly the pros and cons of exceptions" you can afford to use them, and if you "understand exactly the cons of using them" then you will not use exceptions. This is poorly argued (OK, it is not argued at all). In my experience ( I know, that's very scientific ;o) ), the problem of safety in the presence of exceptions is best addressed through API design and correct responsibility assignment. When you design your API with preconditions, postconditions and invariants in mind, categories 1 and 2 merge into a "Category 1': use C++ exceptions and write exception-safe code" quite naturally. 
It's probably [this one](https://github.com/qicosmos/cinatra). Depends on Boost.Asio, and yes, the docs are in Chinese, so maybe not that useful... 
Pretty fast with Visual Assist actually
Visual Studio + Visual Assist and disabled IntelliSense on my desktop, becuase it does everything I need really well and it's just so insanely fast to work with (lot's of credits due to Visual Assist for that) and QtCreator on my Laptop since it runs Linux.
Both R++ and CLion can run clang-tidy as a background process, show its results in the editor and apply clang-tidy fix-its - that's the only clang usage at the moment. Using another process is really important here, since it protects from crashes (which happen very often) and allows safely interrupting clang-tidy. In R++ clang-tidy was built from trunk with minimal modifications (necessary for usage from the IDE) before the 2017.3 release, we'll update it to clang 6.0 in 2018.1. As an aside, R++'s own parser should not be a problem in terms of correctness. It works similar to a compiler frontend and understands most C++ features supported by the latest MSVC (bar evaluation of constexpr functions and language extensions like modules and coroutines). On the upside, it allows us to do some things which would be complicated with clang - see [this](https://www.youtube.com/watch?v=CZg2d3LoL84) 5-minute talk for some background.
From the summary above: Outcome is merely a mechanism to enable 3rd party module inter-operation. It does not make the decision for whether 'error' or 'exception' instances are provided by some subsystem, nor does it care. Rather, it is a unification mechanism that enables an algorithm to be authored with specific performance and behavioral guarantees when reliance is upon one-or-more modules that made that 'error' vs. 'exception' decision in a manner your specific use case finds unfortunate.
Name?
&gt; Who uses wxWidgets? The 3.1.0 release was downloaded [half a million times](http://www.somsubhra.com/github-release-stats/?username=wxWidgets&amp;repository=wxWidgets), so it looks quite a few people do. &gt; Couldn't some of those fixes have been released in the mean time? That seems like quite a slow release schedule. Yes, I plead guilty to this. I'm so used to just using the latest version from Git, that it's easy to forget that many people still expect to upgrade only once a new release is made available. We'll try making them more frequently, even if, historically, we're pretty bad at this.
That's pretty cool, never used C++17 , it's pretty wild what you can do with meta programming.
If ReSharper is so great, why use Visual Studio at all? Why not just use CLion, which seems to natively support all of ReSharper's functionality? (Rereading them, those questions sound sarcastic, but I'm asking them honestly and non-judgmentally.) It just strikes me as a bit unusual that a single extension would replace and/or modify so much of the host IDE's behaviour, especially when the maker of said extension has an IDE of their own. Obviously there's a business case for doing so, I just found out it existed yesterday, so I'm not criticising, just curious.
Qt supports this now: https://doc.qt.io/qt-5.10/qtspeech-hello-speak-example.html
Yeah it's a real pain. The one I found hasn't changed in at least a couple years thankfully!
Cool! Thanks for that info and the talk.
 clang -Os helps some. std::string and std::cout were clearly too large to use, so using c style printf() and char* helped a lot. Getting a fast filehost helps, these files are hosted out of AWS cloudfront. Really, it came down to establishing a base size of the .wasm file, and then when I would add a new include, track how much the resulting .wasm grew. It was sort of like trying to program for an arduino and watching the size of the .bin. You sometimes end up re-implementing stuff in the std library, and sometimes use void* and type casting instead of templates. 
Good work then. We tried compiling our existing code, which relies heavily on std::string, std::shared_ptr and other templated things from standard library, and it didn't end well enough. It was infeasible to rewrite the whole thing - even our 3D engine made heavy use of shared_ptrs, to say nothing of UI library.
That might make sense in some cases, but do you think it should apply in this case?
Well, what's the point of a redesigned C++ if you're not allowed to break compatibility in order to improve the language? Backwards compatibility is one of the big reasons why C++ can't offer a completely safe type system. It's also the reason why much legacy syntax and semantics can't be removed from the language. However, with that being said, compatibility with C is too useful to get rid of. Yes, we always b*** and moan about it, but at the end of the day, it's extremely useful to be able to use C libraries "just like that," without needing wrappers/bindings. So getting rid of C in C++ really seems to be something we want, but if it happened, we would wish it back :-) So in the end, my comment was rather hypocritical; I want to get rid of C in C++, but on the other hand, I rely on C in C++. Ah, well.
If [live at head!](https://www.youtube.com/watch?v=tISy7EJQPzI) is the new wxWidgets philosophy, that's fine (and pretty cool IMHO), but you should announce it publicly. I am one of these people who are waiting ages for a new release, because it's unclear if the latest GIT snapshot is production-ready or not.
Looks interesting, thanks.
Business case: ReSharper C++ and CLion have comparable feature set, but target somewhat different markets. CLion is a cross-platform IDE for projects that use CMake (and only CMake at the moment). While it does have experimental support for MSVC toolchain, it does not fully support all the MS language extensions and can't debug programs built with MSVC. ReSharper C++ has deep integration into Visual Studio with its project model and caters to people who are tied to the MSVC toolchain or simply prefer Visual Studio.
The warning shows the flag that controls the warning. When you have an unused variable, for example, hovering the mouse over the yellow warning sign says: "Unused entity issue -Wunused-variable" 68:9 warning: unused variable 'index' To disable warnings about unused variables, you need to add `-Wno-unused-variable` to the clang code model flags. You find them in the `C++` section of the options dialog (`Tools-&gt;Options...`), in the `Code Model` tab. Here, I use the "Warnings for questionable constructs [built-in]" setting, but I copied it to a new one so I can modify it. So select it, click `Copy`, give your new custom settings a name, and then add: -Wno-unused-variable in the box of clang flags.
Personally, I said many times in the past that I consider wxWidgets CVS HEAD (just to show since how long ago I was saying this)/svn trunk/Git master generally good for production use, but releases are still important for at least Linux distributions packagers, so we still need to continue making them.
There is a small type on the page: The emscripteen_set_main_loop call takes ~~~~~~~~^
They only asked if they could, not if they should.
There's been a lot of work put into it lately: https://hacks.mozilla.org/2018/01/shrinking-webassembly-and-javascript-code-sizes-in-emscripten/
Cool. I should try to compile out code once more, to see how much the size is reduced now. Actually, I checked the old files, and our code was just 3.5Mb, but it still took very long time to start in some browswer (well, I guess, parsing such big JS library isn't very fast).
Ultimately it's a good thing, because it lets the programmer decide where to pay the cost of checking. Compare [checked vs unchecked access](https://godbolt.org/g/6WbhwV) in `std::array`. If you know all your array indices are in range, then you shouldn't have to pay to check every time. But if you want to program super defensively then use `array::at()` and don't forget to catch the exception. 
&gt; Depends on Boost.Asio And it isn't very idiomatic in its use of Asio given that it's a library. People should consider [Boost.Beast](http://www.boost.org/doc/libs/develop/libs/beast/doc/html/index.html).
Huh.. for his constexpr_string, I wonder if string_view would work as a valid alternative.
Like [this](https://mcuoneclipse.com/2012/11/01/defining-variables-at-absolute-addresses-with-gcc/)?
What we need is a static printf.
https://www.sourceinsight.com. Loads in seconds, works with hundred of thousands files. 
Flashbacks to the compile-time compiler
From what I can tell, the template stuff isn't there to *replace* the `#define`s, it's there to add functions that access/modify `PERIPHERAL_TYPE::REGISTER` without modifying the SDK code (where `PERIPHERAL_TYPE` and `PERIPHERAL(N)` are defined). Although, after closer examination, the templated Driver class with only static functions is probably overkill.
Is there a resource that explains how to instrument your c++ code to use with Chromium's about:tracing feature? I.e. what format and kind of data does it read, and how do you feed that data to it?
It compiles for me without errors, after I fixed the typo? There were some extra &gt; using MyPeripheral0Driver = MyPeripheralNDriver&lt;reinterpret_cast&lt;uintptr_t&gt;(PERIPHERAL0)&gt;; using MyPeripheral1Driver = MyPeripheralNDriver&lt;reinterpret_cast&lt;uintptr_t&gt;(PERIPHERAL1)&gt;; gcc version = 5.4.0, compiled with -std=c++11 Which gcc version are you using? 
Last time I checked glibc on Linux implemented pthread cancellation by effectively throwing an uncatchable exception. And I am pretty sure `printf` is a cancellation point. So this could be one of the reasons.
Use the linker to set hardcoded addresses, and leave C++ alone. [Like this](https://godbolt.org/g/b1izbC). 
Here is a link to the [Chrome Tracing format](https://docs.google.com/document/d/1CvAClvFfyA5R-PhYUmn5OOQtYMH4h6I0nSsKchNAySU/edit) It's a simple json format - I mainly use the duration and complete events. And here is an example of an implementation (I wrote my own, but this may give you enough to build your own) [link](https://github.com/deplinenoise/tundra/pull/297/files) What I do is trigger a dump of the profiling info to a single json file (key press, time or some other trigger) and then I can load that up in chrome://tracing to inspect it.
One of the best things, i have seen for quite a while. A real treat I'd say. Naturally you would not use it in production, but still It's great to see people do such a crazy stuff with C++. The best part is that it's a great example to look at some "problems" from completely new perspective. I myself was thinking about learning some functional programming, but I never have enough time after work do start with haskel or scala because they are totally different than. However this implementation might be a good start to start thinking more functional programming way, and expend the way of seeing problems. 
The description above is utterly meaningess. It tells me exactly zero things. Which problems exist in interoperation between modules? 
I didn't want to use pure template meta-programming as has already been done by few other peoples: - https://blog.mattbierner.com/stupid-template-tricks-snake/ - https://github.com/phresnel/metatrace Then I went for hybrid meta-programming like Boost.Hana where you can mix type computations and value computations. And finally, I discover that most of the work will be value computation, so bare constexpr.
My best guess: Because they are c functions and c doesn't have noexcept.
I didn't understand it was about developers shunning exceptions, thanks for clarifying.
You are aware that the c++ code isn't a replacement for the defines right?
Are peripheral0 and 1 mutually exclusive?
When reading your message I was confused by the mention of a C++11 compiler, but instead it looks like it's a C++11 code generator. 
What does 'effectively' mean here? Unless it is literally throwing an exception, I don't see how this relates to the question?
Okay, cool! :-)
The range library is really something I'm looking forward too, especially after using C# and linq for some time. One thing I'm not so happy about is the overloaded '|' operator. Personally I would prefer chaining via '.', but I don't know if this is possible with C++
Whether extern "C" functions are considered to be `noexcept` or not is a quality of implementation question or not. In other words, neither the C nor C++ standards say anything about it currently, and it is up to the compiler vendor to choose what they think is best. MSVC, for example, provides a compiler option to tell it whether to assume C functions can throw or not. Most projects use `/EHsc`, which **does** tell MSVC that C functions will never throw. glibc definitely marks up many C functions with noexcept if being compiled in C++, but not all. I would assume they have good reasons.
It's not - the dot operator can _only_ be used for accessing member variables/functions of an object.
But wait - don't you then have to play with the linker file?? From the article: &gt; For gcc, placing a variable at an absolute address requires two steps: marking it with a section name in the source, and then placing it in the linker file at an absolute address. &gt; It would be good if there would be a way to avoid the linker file change, but I have not found another or better solution. I'd call that a total dealbreaker. Imagine what it would do to your toolchain!
At 2:05, the second equation is wrong. 11/2 + 3/2 = 7 Otherwise the point is well understood.
Does KDevelop support Java? Since it supports Cmake - a build tool for C/C++, can build tools for Java like Ant, Maven, Gradle be used in KDevelop? 
This is how thread cancellation is *implemented*, but absolutely not related to how it should be used. People who noticed this in practice were doing things with pthreads that they should not have been doing. They used C++ code that throws exceptions, with cancellation, and were expecting that to work in a context of a C codebase (like pthreads). These are broken assumptions, which means that they are also a bad reason not to mark C functions as noexcept (especially those exposed to the outside world).
Is `std::printf` a C function? (Does C have namespaces?) A more pedant question is whether ::printf should be declared `noexcept`and the answer is "yes, absolutely, it's a defect to report". This is because * C code is used from languages which has no idea what C++ exceptions are (think any foreign function interface of `ye olde lang`), so **glibc can't possibly throw a C++ exception**. * **(legally speaking)** There's no ABI for C++ exceptions, so whoever wants to call such functions (except code built with the buildchain who built them), has to recreate the ABI of that buildchain.
Actually, since C++11 the bottom-left field in the matrix is populated: `atomic&lt;Integral&gt;` is required to follow the rules of two's complement arithmetic for signed types, too. This means, there is no undefined behaviour anymore - just like regular unsigned integral types. Throw in a pinch of memory_order_relaxed to make arithmetic operations on signed atomic integrals as cheap as can be.
&gt; prinf can throw quite an ordinary exceptions I don't understand this part. How any C function is supposed to throw an exception?
if the documentation wasn't so woefully poor this would be the most widely used library in c++
all of the ``std::int*_t`` types are also guaranteed to use two's complement representation. There's a distinction between Two's complement (a format for representing numbers in bits) and modular arithmetic (a number line that wraps around). Just because a type must use Two's complement representation in memory does not mean overflow is defined behaviour.
Some APIs throw exceptions, and others return explicit 'error' objects. Outcome allows you to wrap those APIs into an '&lt;T|error|exception&gt;' instance so you can author an algorithm that performs consistent error handling (all with exceptions, or all with errors, or a mix if you prefer).
I don't personally find the documentation poor. Ranges v3 is pretty much exactly as you'd intuitively think it would be. For me the main impediment is the dire effect on compile times. I am seriously hoping this improves very significantly when Ranges ships in the standard, else unfortunately this is dead in the water for any serious use cases. I would assume the lack of proper Concepts is a part, that compilers are not yet optimised for Ranges yet is part, and possibly also that the reference implementation is less efficiently written as one written from scratch on C++ 20 might be. It's hard to say for sure, I just want it to go a lot faster.
&gt; I am seriously hoping this improves very significantly when Ranges ships in the standard, If there is any indication, I certainly did not notice std::variant being faster than non-std implementations on clang / msvc / gcc. 
Can a fresh undergrad in Shanghai apply for these jobs? Is there any position available for an undergrad at Shanghai office?
Quote from cppreference: For signed Integral types, arithmetic is defined to use two‚Äôs complement representation. *There are no undefined results.* (emphasis mine) Corollary: overflow **is** defined behaviour.
not only formatters. BSD (`funopen`) and GNU libc (`fopencookie`) let you create a `FILE *` with user-provided read, write, seek, and close functions.
I was not advocating passing throwing callbacks into C functions ;)
There is no `throw` statement in C so the glibc pthread implementation (and I am a bit fuzzy on the details; it's been a while since I messed with this) manually registers some exception-related handlers and then causes stack unwinding, as if an exception was thrown. Many years ago I've come up with a [patch](https://kolpackov.net/projects/glibc/cxx-unwind/) that makes glibc throw a real C++ exception (the advantage being able to detect that the thread is being canceled). If it were accepted, then I wouldn't have needed that *effectively*. But Ulrich Drepper (the author or glibc's then new pthread implementation aka NPTL) thought it was complete nonsense. And so here we are. 
What do you mean by cancellation point? I haven't heard this terminology
I feel like these presenters got owned.
&gt; Any syntax used for the initialization of C-arrays, has to be backwards compatible with the initialization allowed in C. Why? I am not "writing C in C++". 
&gt; At 2:05, the second equation is wrong. 11/2 + 3/2 = 7 Not for integers...
Stop. The web browser is not an OS and should not be used as one. Javascript was a mistake.
&gt; Ulrich Drepper Now that is a name generally seen when the user did something wrong. Issue resolved: PEBKAC . 
I see, you're saying that it's possible to have well defined two's-complement arithmetic in C++ by using fetch_add, fetch_sub etc. on atomic types. The types I referred to only have their representation defined, not any special arithmetic.
&gt; I don't personally find the documentation poor. Ranges v3 is pretty much exactly as you'd intuitively think it would be. Documenting stuff just for the sake of documenting it when it's obvious makes the documentation less valuable. Alright, Mr. r/iamverysmart. To you, it may be completely obvious and intuitive what each function and algorithm does and what a cursor is and what all the subtle implications of everything are. To the rest of us plebians, there isn't enough documented to be able to use the library without just guess and checking via compile errors.
This feels like an advertisement for Visual Studios. Is this sponsored by Microsoft?
It's no biggie thsrefore.
I have yet to watch it; your comment makes me unsure I should waste 30mins. What do you mean by that? Was the talk just wrong? 
Am I the only one that things you you are opening yourself to serious issues by doing that? I'm not talking specifically about qsort, but you can have serious issues with intermediate state. C doesn't offer any form of RAII so throwing inside a C API sounds as the worst idea ever.
As those addresses very often come from a header in the BSP (either a vendor or generated) copying the information into the buildsystems is imho just unnecessary maintenance work and makes it more difficult to understand the code.
I think some points are valid, but this talk is also from the track for new speakers, so presentation might not be perfect. Only thing I wonder is how you use less then 50% of the time for your talk with two speakers...
The talk was good. They were talking monotonic, but the contents was good. I don't see what's wrong.
I watched a bunch of UB talks. These days the compiler is too scary with it's optimizations. It makes me more paranoid about my code while debugging. Compilers need to tone back, or more things need to become defined. If this trend continues upgrading to a newer compiler version will become more scary.
Nothing is wrong, I think its just that some people point out obvious solutions in the questions after the talk. Also its normal that there is a wide range in how talks are received.
&gt; It‚Äôs almost as if CPP community doesn‚Äôt believe in responsive web design. They develop it in CPP and it scales right up.
Looks fine on my phone..
Yes, I have to do some more work on the CSS of the page, its not perfect yet...
I entirely agree, but that wouldn't work on godbolt :)
Sure, feel free to send me your suggestions.
Why not just treat it as throwing exception from `noexcept` function o.e. just std::terminate?
You don't have to be snarky. Eric has stated in the past that he didn't take Ranges v3 to Boost mainly due to the very considerable investment in documentation it would require to pass a peer review. Think http://www.boost.org/doc/libs/1_66_0/libs/range/doc/html, but far longer and more intricate. He could have ended up spending as much time writing the documentation as he did writing the library, same as it was for us with Outcome. And that's a huge ask of a single person's free time. Thing is, Ranges v3 is an open source library. Anyone can contribute. If you find that the documentation isn't good enough for you, instead of complaining and being snarky about the library on Reddit, go send in some pull requests with improvements to the documentation. That's how documentation gets better: it starts with *you* who has an itch to scratch. Even going to the Ranges TS spec document at WG21, and using it to write up better docs and/or check the reference implementation against the TS would be of great use to everybody, including yourself.
There is no concept of ABI in the C and C++ standard, and I think there is also no concept of ABI in Posix, but when you consider what actually are ABI there exist mainstream ones for which the interface to use for C++ exceptions is specified (SysV for various archs, for example)
I was really excited to see how he got keyboard input at compile time, slightly disappointed this wasn't the case :(
You can define a compile-time array of enums and use it as a input-feed source. After each render (compilation) add 1 more move.
still waiting for constexpr new
The second answer from SO sums up the problem prety much. Run static analysis untill you have no reports. It's the same as with compilation. You get 1 error, but only fixing it uncovers more errors: missing include =&gt; private member =&gt; unmatched template =&gt; ...
What about Boost Beast?
I'm obviously not complaining about Eric or Ranges or the documentation of it. I'm complaining about **you** and your post opening with a comment whose only feasible purpose is to demonstrate how smart you are. I get it, Principal Architect of Boost. You're super smart. Outcome was an enormous body of work. You've personally known everyone on the standards committee for decades. Enough already. You don't have to constantly talk about how smart you are. It's obnoxious. 
Ctrl + wheel. 
For that, the c function has to be compiled with a c++ compiler (i.e. calling terminate is something that has to happen from inside the callee.
Good point. Forgot that terminate happens in the function rather than outside of it.
gcc guys seem have no interest in coroutine?
Yes, but for FFI, that would mean that not only a C implementation **(not C++)**would need to "specify" exceptions" part of the ABI, but that **every FFI implementation** of whatever language would need to implement and adhere to it. IOW, if CRT functions aren't `nothrow`, all FFI implementations now are **broken**. But the reality is: CRT **is** `nothrow`, including POSIX thread cancellation.
I don't know where you got any of that from. I suspect mostly from within you. My original point was fair: the Ranges documentation is sufficient for most people. My Google summer of code student Tom last summer found little difficulty when he replicated the API design into his own project. Occasionally one will be unsure what some semantic is supposed to be, and you'll end up diving into the TS or the Ranges source code. But for the most part (apart from naming actually due to wanting to avoid conflict with existing STL names), Ranges works very intuitively and doesn't need much documentation once you get it. ASIO is another library like this, it is also pretty vanilla in design and doesn't require hand holding in the documentation. If you find it does, then that's really on you, not the library, not its authors, not me. Point your axes at yourself next time, try stepping up and investing in yourself instead of in bitterness towards others. 
So that's one step towards eliminating UB in the language. Would it be possible to extend this to non-atomic signed integers, do you think? 
With respect to videos and podcasts: of course video is a great format for sharing talks at conferences, but in general I prefer written text. Written text lets you read at your own speed, skip paragraphs, search for keywords, etc. Well-written text has been edited; it's not the first thing that came to the author's mind. I read all the articles on this site, but I only watch a small fraction of the videos, and I never listen to podcasts. Judging by the number of comments, I'm not the only one: there seems to be a clear ranking between article types, with reddit-hosted articles attracting most comments, external links attracting fewer, videos even fewer, and podcasts the least. 
https://cdn.cultofmac.com/wp-content/uploads/2015/05/mac_02.jpg ;-)
At least you should add viewport to the page. &lt;meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" /&gt;
Looks fine if I pretend I'm using 56k
&gt; its not perfect yet if this were a pok√®mon, I'd call it slowpoke
No it sucks. Period.
&gt; I don't know where you got any of that from. I suspect mostly from within you. No I think it too.
Is she the sister of Richard Smith?
Well, one reason could be programming videogames. I'm a C++/Unreal Engine 4 developer. Unreal Engine uses C++ as its primary programming language.
[Unreal Engine 4 Mastery: Create Multiplayer Games with C++ ](https://www.udemy.com/unrealengine-cpp/) [The Unreal Engine Developer Course - Learn C++ &amp; Make Games ](https://www.udemy.com/unrealcourse/?utm_source=dice&amp;utm_medium=web&amp;utm_campaign=dicepromo&amp;pmtag=dice040promo&amp;aff_code=Ewh3Y19bQHUGQRt3MkBPbG1RGXFfVFh8BV4bdk5QR3YAQxF1WD5XMRM%3D)
Intuition has nothing to do with it. We're working with a language that gives us UB at the drop of a hat in all sorts of unexpected situations. The only way to avoid it is by very carefully reading very well-written documentation. Don't tell us we don't need it because it's intuitive. 
&gt; Well-written text has been edited; it's not the first thing that came to the author's mind. Good talks (or even most talks) have often been in the author's mind and in the making for weeks and months, sometimes a year. They've been at least practiced, but in many cases given before (e.g. in front of friends, company, small user-group meetings), and then refined based on feedback. Of course most of these people are really good speakers and could also give a quite good "unprepared" performance, but what you're seeing most of the time is definitely not just the first things that came into author's minds. I agree with your other comments - videos are (not yet) searchable, sub-sections not skippable, and everybody learns best using a different media. For me, personally, the combination and the variety makes it. Some videos are better than any text I have ever read. Sometimes text is better than any video could ever be. Btw: Podcasts are great to listen to if you actually don't have access to a screen or are doing something where you can't or don't want to look at a screen. Commuting, cooking, or just relaxing on the sofa - most of the podcasts are quite entertaining too. It's a great alternative medium.
That would be unwise. Undefined overflow is too useful for optimization to just give it up. If you define the wrapping behavior, suddenly the compiler can't optimize stuff like x * 10 / 2 to just x * 5, or x / 4 to x &gt;&gt; 2. https://kristerw.blogspot.kr/2016/02/how-undefined-signed-overflow-enables.html?m=1
This page has a more recent version of dear imgui running in the browser: https://flyover.github.io/imgui-js/example/ And the author created Javascript binding: https://github.com/flyover/imgui-js 
Its a different medium, which reaches different audiences. Its not that the blogs are going to disappear.
That's a good idea. Thank you. 
It's a reasonable solution, but the addresses are supplied in the chip manufacturer's SDK header files. I don't want to copy them out into my own parallel SDK, I want to use what I'm given, so that when they supply new versions I have zero maintenance burden.
I tried with 7, from ARM's developer page: https://developer.arm.com/open-source/gnu-toolchain/gnu-rm
You misunderstood me. Just prepare an array of fixed moves and manually add more values after each compilation
Oh yeah, my mistake.
Most of my contracts are for modernising ancient code bases riddled with UB and race conditions. A lot of said problems stem from initial over reliance on documentation and misunderstanding the libraries being used as dependencies. Tldr if you need hand holding documentation for a library, then you shouldn't be using that library. Know your limitations, use one that you do understand, everybody will thank you twenty years down the line.
I'm really curious if there are any statistics on how far adoption of newer C++ standards have gotten in the industry. Often times I feel like the company I work with is the only one that's stubbornly refusing to acknowledge that things are progressing and that using C++98 in 2018 is hurting not only the product you sell to your customers but also the engineers that build said product.
I'm aware of this, but I also believe there is no _useful_ optimisation to be had here. Yes, you can construct artificial examples that run quicker, but I strongly suspect that if you find cases in real-world code that may be so optimized, it will in virtually all cases be a bug that needs correcting. Furthermore, I believe that after correction the performance advantage will be lost. 
I understand this point and think it is a valid one, however I still think it is a different one than: *"There's no ABI for C++ exceptions, so whoever wants to call such functions (except code built with the buildchain who built them), has to recreate the ABI of that buildchain."* Maybe what you tried to convey initially was: the C ABIs typically suppose that no C++ exceptions will be generated / don't consider them at all. It is pretty clear that the C functions won't generate exceptions by themselves, however maybe on some systems this would cause interop issues to mark their declaration in C++ as noexcept -- I don't know. If systems are designed to work with exceptions on some functions where cb are in use (so qsort comes to mind), those should not be marked noexcept, because this would be a mismatch between the declaration and the real type, and would result in undefined behavior from a formal POV. The C++ standard takes great care to not prevent conforming implementation from being implemented on real systems, so it is reasonable to expect that if interop problems could occur between e.g. thread cancellation and noexcept specifier on major implementations, they will prefer to not add the noexcept specifier for C functions in the standard. Same thing maybe for interrop between SEH and C++ exception, or similar things on other systems. To finish, note that there are some other functions of methods part of the C++ standard, and specific to it and not merely imported from the C standard, that have been voluntarily not marked as noexcept, despite the standard being very explicit in stating they will not throw. One rational was to ease the unit testing of the standard library. 
&gt;if you need hand holding documentation for a library, then you shouldn't be using that library. That's downright the most ridiculous shit you've ever spouted and that's saying something considering you're the one who shat out Outcome.
you're right!
[cquery](https://github.com/cquery-project/cquery) + VSCode/Emacs/Atom/Vim ...
According to [this issue](https://github.com/ericniebler/range-v3/issues/332), it sounds like pre-C++20 concept emulation is the culprit. I‚Äôd be interested to see how much of a compilation speed-up using a native implementation would provide as opposed to something like Tick in a set of benchmarks.
&gt; It's only a source of bugs, not a source of additional performance. Right - exactly my line of thinking.
Go there, make money -&gt; move to some other civilized place for the rest of your life.
Wow that's a really good comment, thank you very much! About the RemoveAt and InsertAt, yeah, probably it would be better to throw an exception, i was really stuck on that one and couldn't decide (it's just my character of exception avoidance), I'll change it, thanks again.
if not exception - assert
These illustrations are ridiculously good. Bravo.
As far as the address of member functions goes, it's not any more special than a regular function. Only difference is how you call it. 
`sizeof(pointer-to-member-function)` is also typically larger than `sizeof(void*)`, which makes it rather special IMO.
Very much agreed
Also don't return by `const` value: It inhibits move semantics.
If you don't care about autocompletion advanced highlighting, then any good text editor will do the job. If you want these features, then QtCreator, KDevelop, CLion and many other are really good. For compilers, you surely have gcc installed on your system. You can also install clang.
In terms of CPU address, indeed they are the same, in that both are opaque to C++ sources.
Give Qt a try. The SDK has everything you'll need.
There are several frameworks that have C++ bindings by default, such as [GTK](https://www.gtk.org/) and [Qt](https://www.qt.io/). I'd suggest learning one or the other, but you can do whatever you want! Good luck.
The C++ standard actually mandates that a conforming qsort that an implementation provides handle C++ exception nicely. If a C++ implementation can achieve that by linking to an existing C implementation of qsort, good for it. Otherwise, it has to provide its own, or be non-conforming.
I will use an HTML thing like Sciter, you will get all the power of the web and all the power of C++ combined, go and check Sciter or similar, the results you can get are very cool and more or less easy
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7wodsx/what_c_setup_should_i_use_on_ububtu/du1yn9b/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7wol7g/how_to_create_a_gui/du1ynua/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Loser 
I've been needing to look at vim, I'll check it out. Thank you
In combo with a terminal multiplexer it's great! I use it everyday all day ;)
Correct. If you want to materialize the view, append `| ranges::to_&lt;std::vector&lt;int&gt;&gt;()` (see [here](https://github.com/ericniebler/range-v3/blob/master/include/range/v3/to_container.hpp))
`Parser::FuckSpaces`? What a particular parser.
Quite the name right? This function just ignores the spaces.
Yeah, you might want to change that.
How does it work? Does it only do static analysis? If yes, does it print all possible paths or branches in a function?
Or shorthand `| ranges::to_vector`.
Yepp, https://stackoverflow.com/questions/12006854/why-the-size-of-a-pointer-to-a-function-is-different-from-the-size-of-a-pointer#12006882 &gt;&gt;So a member function pointer actually needs 1) possibly a function pointer, 2) possibly an adjustment of the thispointer, and 3) possibly a vtable index.&lt;&lt; I am sure this is also compiler dependent. Afaik this and the vtable setup is not (yet) covered by the standard. 
Hmm, do you believe optimizing x / 4 to x &gt;&gt; 2 is a useless optimization and not found in real-world applications? The former integer division generates 88 operations (not instructions) in the cpu, while the shift-right is only 1. And it's the exact same operation except very few corner cases. The performance advantage is significant.
Oh gosh, that's such a looooong article on such a simple topic. You can provide full picture for the technical people in like 3 short paragraphs, and that's being wordy, then fill in the details for those who barely know what a pointer is in another 6 paragraphs. So many pointless drawings, such low information density in the drawings... Sigh.
Wrong sub for that kind of content.
Again, wrong sub. But it looks like it is taking the size of the account class (or struct), interpreting the size as an signed integer then uses that size to go back (hence the -1 multiply) on the binary file that many bytes to print its contents.
No. I use C++, but I would never call it the best programming language xD
Troll
Are you sure? I found only this in the standard: &gt; Functions from the C standard library shall not throw exceptions193 except when such a function calls a program-supplied function that throws an exception. ... which is not what I am talking about. I used this copy of the standard: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3690.pdf Can you corroborate what you're saying?
I don't, but I don't see the relevance. There is nothing in specifying behaviour for signed integer overflow that would make this optimisation impossible.
Right. And you made a living refactoring broken code, you said? I'm not sure this forum is the right place for promoting practices that will lead to job security for you...
Seems juvenile, but on the other hand it's nice that's not so corporate
Why not lambdas?
I'm an atheist, can I still apply?
I'm happy with it. Thanks for your concerns!
Yes and yes. It traverses the AST with clang and prints any function call it sees.
But your users aren't. Will you ignore their feedback? 
Of course I appreciate your work. But just because something is free doesn't make it immune to criticism. 
Thanks for the kind words and politeness (finally!). Neither are you entitled that I change something (and even so on such a not functional level), just to accommodate your feelings :)
Nice! Looks handy! Side note: in the readme, "coma" should be "comma".
Fixed. Thanks!
Please read the subreddit rules.
Because he is using the g++ 2.95.
I am impressed by the work you put in. However, it seems to be that with all that work, you could have build an own doxygen replacement? I used a java script based approach to modify the style: http://www.rttr.org/doc/master/classes.html PS: i tried your python script, but it seems to have problems with non utf8 characters.
Lmao how pretentious you have to be to expect someone to change a name in a free piece of code because you personally can't handle it. I almost can't believe what I'm reading.
There's still a lot about C++ parsing that Doxygen handles reasonably well and redoing that from scratch would cost me *a lot of* time. OTOH there are many annoying bugs in Doxygen that need to be fixed. So far I am thinking that providing something on top of Doxygen would reach a broader user base than a completely new documentation system with alien syntax. Roughly 70% of the effort I put in so far could be reused when switching away from Doxygen to something else, as that's mainly about the output template, CSS style and testing. 30% of the effort was buried in workarounds for annoyances in the XML output format. &gt; I used a java script based approach to modify the style: http://www.rttr.org/doc/master/classes.html Looks great, I had to check twice that it's really Doxygen, haha :) But it's missing search ;) &gt; i tried your python script, but it seems to have problems with non utf8 characters. So far it assumes that the sources are UTF-8 encoded. If you can suggest an easy-to-implement solution how to fix that (maybe extracting some option from the Doxyfile and using that to handle the decodeing properly), that would be great. Thanks.
I agree, I think this is nit helpful information
I've used flite before, its certainly portable. I'm not sure about its support for non English languages though. http://www.festvox.org/flite/
That's why CMake has a combobox in the upper left corner and Boost a warning on top of the page to jump to latest versions. You should be directing your question to Google, not /r/cpp.
This is a general problem, not just with CMake and Boost, I think the op just used those as an example. 
This is an awesome idea!
I've been thinking of making a plugin (or at least Tampermonkey script) that lets you switch back and fourth for Qt doc versions. Annoys me too. Will let you know if I do.
This doesn't really belong on /r/cpp, it's more of a general issue with search engines that use a variation of [PageRank](https://en.wikipedia.org/wiki/PageRank). There's a shitload of links out there that point to outdated stuff and they apparently still rank higher than the new stuff. I think it's one of the problems [StackOverflow Documentation](https://stackoverflow.com/documentation) was trying to fix, but it [failed miserably](https://meta.stackoverflow.com/questions/354217/sunsetting-documentation). It's a relatively easy fix for version numbers (I append "5" to all my Qt searches), but it becomes very hard for things that are not clearly versioned, like OpenGL stuff. I've been working with V8 recently and the amount of dead links to the Google Code repo is rather annoying, sometimes even coming from within the official documentation on github. They also keep changing the API, so answers on SO from a few months back don't work anymore. For now, until something better comes along, spending time finding the right documentation is part of the job, I guess.
I think that it is precisely what you are talking about: for example your C++ program calls qsort with a C++ callback that throws; the exception shall be propagated, and, implicitly, this should not break random things in the process (and even merely leaking any kind of resources shall probably be considered as a breakage of random things) You can also look for example that references this paragraph, for ex. back to qsort; in N4660 28.8: void* bsearch(const void* key, const void* base, size_t nmemb, size_t size, c-compare-pred* compar); void* bsearch(const void* key, const void* base, size_t nmemb, size_t size, compare-pred* compar); void qsort(void* base, size_t nmemb, size_t size, c-compare-pred* compar); void qsort(void* base, size_t nmemb, size_t size, compare-pred* compar); Effects: These functions have the semantics specified in the C standard library. Remarks: The behavior is undefined unless the objects in the array pointed to by base are of trivial type. Throws: Any exception thrown by compar() (20.5.5.12). The letter of the C++ standard does not care whether it is possible for an implementer to use an existing binary written in pure C for a compliant qsort callable from C++: if it is, that's cool but merely a detail only the C++ implementer has to care about, else, the C++ implementation shall provide its own. (hm, thinking about it it could be an annoyance if there are different implementation but if a pointer to qsort coming from C shall be compared equal to a pointer to qsort coming from C++, but I'm also not even sure such a requirement exists from a formal interpretation of the standard). 
Yes!
It should be super easy to add, just changing the output format to dot, which would just be about adding few arrows here and there. Though it would be terribly unreadable and not interactive :) PRs are welcome if you find a nice way to do it though!
Despite me searching the internet, I can't find a def for "ippity", and can't understand what you mean
One possibility is to exclude old documentation from crawling, while making the newest version available at a stable address. But practicality of such approach depends a lot on particular library's or tool's development and deployment practices. It will also lead to another problem: broken links (as most people would link to the latest version instead of relevant one from SO threads etc.). You can see this a lot in Apple's documentation, where they take this approach (actually, I don't think they make old versions of documentation available at all?): often, a link from 2-3 years ago would lead to a page that no longer exists or has been renamed or moved. However, if you want to force usage of modern versions and practices (as Apple ruthlessly does), this is acceptable, and indeed desirable, as the advice that uses those old links might no longer be considered good practices. However, if we want to approach this from Google's side, I think some kind of meta-tag can be used to notify Google of obsolete versions so it can downrank them unless number of version in specified in the query. But I don't think this is practical: it's unlikely that Google would bother changing even minor properties of its algorithms for a relatively niche auditory (developers). Call me a pessimist here, but the first approach seems far more doable.
&gt; Similarly, Qt searches often bring up the 4.8 version of documentation, instead of 5.10 (latest at this time). 4.8 documentation is "archived", and there is no easy to find switch to go to the latest version. Just appending to "5.10" to the query is enough to give me the 5.10 documentation on anything Qt related. Somewhat peculiarly, while google also allows you to restrict the age of the results (e.g. only from the last year, month, week, etc), this doesn't seem to help in terms of finding more recent documentation.
It‚Äôs cool. Can it recognize the scope_guard and print the deferred function-call in right order? Another use case is that i want to find if one specified function, like my_open(), was called following a matched-pair-function, like my_close(). ‚ÄîWill this detecting be easy? 
I guess it does. Though I'm not sure how clang deals with them
The difference is in whether one engineers a whole system or individual components. I mainly engineer whole systems and optimise the whole, not the parts. The difference is a common one across many industries and sciences.
the article is very beautiful. my second biggest criticism is that it feels nothing like an STL container, it looks quite alien. but my biggest criticism is that it seems untested (doesn't compile, crashes on access) random notes: * the concept of iterators is nowhere to be found (not in the explanation, not in the code) * i couldn't see a way to get the number of items * GetAt() modifies the list, so doing `auto a = GetAt(2); auto b = GetAt(2)` will yield two different items. i'd rename this to `getAndMark(idx)` and add an `operator[] const` for pure access that doesn't modify the list. * templates appear out of nowhere. if you explain what a pointers and lists are, you might as well explain templates a bit. * `InsertAt` should check if the `new Node(item)` failed, else it wrecks the data structure. * the github code is missing `#include &lt;vector&gt;` here's how to make it crash: (no idea why, didn't debug) SelfOrganizingSortedList&lt;int&gt; list; list.InsertAt(11, 0); list.InsertAt(10, 0); list.InsertAt(12, 0); cout &lt;&lt; "item 0 = " &lt;&lt; list.GetAt(0) &lt;&lt; endl; cout &lt;&lt; "item 1 = " &lt;&lt; list.GetAt(1) &lt;&lt; endl; cout &lt;&lt; "item 2 = " &lt;&lt; list.GetAt(2) &lt;&lt; endl; cout &lt;&lt; "item 0 = " &lt;&lt; list.GetAt(0) &lt;&lt; endl; cout &lt;&lt; "item 1 = " &lt;&lt; list.GetAt(1) &lt;&lt; endl; // crashes with: pointer being freed was not allocated 
i think... the problem at hand is actually not so trivial. how would you implement a list that keeps multiple orderings (without using boost)? in this case, insertion order, element order and reverse element order. i think the author is trying to do a mix of doing teaching c++ basics, and coming up with a custom data structure (which is imho a bit much for a single article). 
&gt; This is a general problem, not just with CMake and Boost Well it sort of isn't a problem for Boost because Boost tells you very clearly at the top of the page that the documentation you're looking at is out of date and you can just click that to load the newest version of that page. If you're going to use something as an example, at least make sure it's a good one.
Thanks! I really need that kind of tools to quickly understand a codebase sometimes :)
&gt;there is no _useful_ optimisation to be had here. Define useful. [This does actually come up in real code.](https://www.youtube.com/watch?v=yG1OZ69H_-o&amp;feature=youtu.be&amp;t=2357) I'm curious to know what you think the author should have done in this case instead of using a signed integer which is subject to UB.
[duckduckgo](https://duckduckgo.com) has some bangs for [documentation](https://duckduckgo.com/bang?q=documentation) and [cpp](https://duckduckgo.com/bang?q=cpp). I find it works quite well.
Ya, my tip for you is... Don't waste your time. Every release i try (every once in a while) to setup qtcreator+cmake+msvc(compiler) is just 2-4 hour fighting with the piece of crap that qtcreator is on windows (with cmake+msvc) After all that shit, i just uninstall it (again, as always) You better off with notepad+cmake+msvc (or VS) than qtcreator
I really think calling out unique_ptr over shared_ptr would be better here. I appreciate that shared_ptr is easy to grok and there are some really sweet things you can do in conjunction with weak_ptr, but I see it way overused when people don't take the time to learn the concepts around ownership that it's trying to solve. People just replace their raw pointers everywhere with shared_ptr and say "Okay, I'm using smart pointers now!"
Smith is a pretty common name.
Nice artice but please, please stop overriding the browser's default scrolling behavior.
We're in the land of C++17 now, get with the times.
http://bilder.hifi-forum.de/max/5455/not-sure-if-troll_87222.png
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7wv8cr/new_program_idea_c_creative/du3eosl/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
\&gt; Not using C++17 in $CURENT_YEAR
For people coming from managed languages like Java or C# or even modern ObjectiveC, `shared_ptr` provides very familiar semantics. They're certainly not identical to a managed reference, but they're pretty close for most basic use cases. C++ veterans steer clear of `shared_ptr` often because of the perceived performance penalty, but again if you're coming from a managed language, you're getting so many efficiencies from C++ anyway that spending some cycles twiddling atomic counters is no problem. Likewise problems with shared ownership and fuzzy lifecycles exist in pretty much identical circumstances with both managed references and `shared_ptr`. If you can write for the garbage collector, you can use `shared_ptr`. I do a lot of architecture work in C++ for graphics and HPC. I also do a lot of similar work in Java. Our C++ codebase uses `shared_ptr` pretty liberally, for a variety of structures from GPU resources to cached image data to GUI elements. Pretty much any time a design requires that one object "hold" a pointer to another object that it doesn't directly manage, we use a `shared_ptr`. Most functions that use a pointer only temporarily take a raw pointer. As a result, we pay very little penalty for the reference counting. We've found that `unique_ptr` works best in situations where an API function is saying "here, I made this for you, now it's your problem". But even in those cases, client code may re-wrap with a `shared_ptr` when using the allocated data structure. I'd say `unique_ptr` is most often just used as a scoped pointer in our codebase.
I really don't get what's so great with strongly typed enums, apart from the implicit conversions. I still find the classical enums easier to use while writing software. What C++ really needs is enum-to-literal conversion, just like the `#` pre-processor macro but cleaner. Something to resolve this: https://stackoverflow.com/questions/5093460/how-to-convert-an-enum-type-variable-to-a-string
&gt; C++ veterans steer clear of shared_ptr often because of the perceived performance penalty OR because they know that having global state and reference semantics is bad. So I am fine with std::sharedPtr&lt;const T&gt;, but if you are using shared_ptr&lt;T&gt; you are just asking for complexity and bugs.
&gt; I still find the classical enums easier to use while writing software. It is not about being easier to use. It is about being harder to misuse. So yes in ideal world new feature would be easier to use and harder to misue, but if we can get harder to use, harder to misuse we will take it. :) 
Nice article. Though, a few comments: `auto` is easily abused. Too many times I've gone looking for a method signature because the `auto`'d variable's type was ambiguous. In fairness, the examples given in the article are good use-cases for it. `shared_ptr` is another one that can easily get abused as well. I try to use `unique_ptr` or `weak_ptr` before reaching for `shared_ptr`. Lambdas and range-based loops are my favorite features of Modern C++. I do wish the range support had initially been stronger, but hopefully the [ranges library](https://github.com/ericniebler/range-v3) will make it into the standard soon.
One I thing about the strongly-typed enums I like is that the enumerator names don't leak out of them into the surrounding scope. In general, they just behave more like proper C++ types, rather than a bag of int constants with names. Definitely agree on C++ needing an operator to turn the enumerator name into a string. That would be ace.
Yeah I agree with that, good point. I guess to each their own, codebases I work with tend to use the conventional enums safely, so I have tunnel vision when it comes to this feature.
I'd recommend you get out the Better Enums library. http://aantron.github.io/better-enums/
Couldn't said it clearer! I saw so much codebases just using shared pointers everywhere and they assumed they didn't leak, but in fact there was leaks in many places! I once asked about the lifetimes of some related objects in a module, and the writers has no idea! C++ memory management is all about lifetimes and ownership, not about manual management nor about automagic garbage collection.
This has been my experience at my current company. There‚Äôs a pretty serious overuse (misuse, I would say) of std::shared_ptr&lt;T&gt; that bleeds across module boundaries and is oftentimes unnecessary. The state space of interactions is totally intractable, and so things have devolved into ‚Äústick mutexes on every single object to save ourselves, because we don‚Äôt understand our own ownership, lifetime, and access graphs‚Äù. It‚Äôs frustrating because there‚Äôs no reason things have to be that way (just an unfortunate inversion of responsibility for ownership and synchronization). The other problem we have (not with shared_prt per say), is a huge number of functions taking a std::shared_ptr&lt;T&gt; const&amp; as parameter when they actually mean T&amp; or T const&amp;, and that‚Äôs a particularly pernicious failure of design. It‚Äôs infectious and forces callers to have a heap allocated object to interface with some portion of the codebase.
Obviously this is not best practice code at all! There is also a [readable version](https://github.com/bvanhauwaert/PlaneSize/blob/master/Script/readable.cc) but maybe you'd like the puzzle that is the condensed version. Just wanted to post this encourage everyone to start on that pet project they've been thinking about. Just a few hours is more than enough to get something limited but still meaningful. Even extremely complicated software was once a few lines of simple code. Good luck! If you have questions or remarks, more than happy to hear and answer them here!
Is this a copy pasta? I swear I've seen this comment multiple times before.
I'm on mobile, so how is it different from doxygen's call graph? 
It's textual. It's an interactive repl, and you have filtering. The goal is not to have a static callgraph of your project but rather have an interactive tool that will answer your questions about the structure of the code as they come and your understanding grows.
Fine I'll have a look at it Thanks 
So I guess this isn't so much an example of UB being beneficial for optimization, it's more a demonstration that non-pointer-sized unsigned integers can be a performance _hazard_.
I actually would love to use CLion, but as someone already said it only supports CMake and does not support the Qt build system. 
Watch Herb Sutter's talks on metaclasses. I'll wait for *that* instead of wanting enum -&gt; string conversion *now*. In the meantime Better Enums works well. 
Those C libraries allowing to register callbacks doesn't mean they are handling exceptions correctly. They expect C functions as callbacks, which means your callbacks are not allowed to do non-C things l like throwing exceptions. Unless specified otherwise, C functions will break if you give them callbacks that throw. 
This is really inspiring. It‚Äôs one of those Carmackian solutions that is shocking in its simplicity.
How do people in this sub feel about "auto everywhere". Is this good or bad?
Really cool idea! What kind of sandbox mechanism do you use to prevent exploitation and DOS?
`std::thread` instead of `std::async`?
I'm using individual docker containers with resource and filesystem limitations for each compilation and build. With a pre-built image, spawning and destroying containers is near instantaneous, so that doesn't add much overhead to the build time. There's also an independent timer to watch and kill the container in case of an unforseen error and the container doesn't stop. We have rate limiters on both the web backend as well as the webserver to prevent DOS. The build and execute queue for player code is limited as well, to handle an overload. We plan to open source the entire codebase after the event is over :)
The sad truth. Still for some really large legacy code base it just makes little sense, economically speaking, to completely rewrite in a newer standard.
I'm working on something similar and found this benchmark https://github.com/thekvs/cpp-serializers to be helpful. I posted some results here: http://webEbenezer.net under "Recent developments"
The 100 lines claim is dubious since it's not really formatted like a normal human would prefer. Is it really 100 lines if you're doing this kind of thing on each line: " add(0x3d); addInt(0); add(0x0f); add(0x84); addInt(0);"? Why not dump into one huge line and call it one line?
I hate it. I don't want to have to guess about things when reading new and unfamiliar code any more than I have to. Fortunately, it's completely banned in every code base I work on. But I do occasionally have to look at C# projects where var is allowed :(
I'd like to also add that it's pretty painful to look at screenshots of code. Syntax highlighting isn't too bad to setup in WordPress :)
What are your thoughts on for-loops on maps and storing the result of a find? I find implicit conversion often leads to people using the wrong types for both of those or incredibly verbose type signatures.
Are they leaking because of circular dependencies? I can't think of any other way to make `std::shared_ptr` leak, besides undefined behavior.
I strongly agree with your comment! I am coming from a game dev background and we are using a self made (partially faulty) in house implementation of shared ptr. We make strong use of bg threading, so i feel with you on the "stick mutexes on every object"... Best problems we face: some guys thought it would be clever giving out sptr, but making some systems depending on the release of all resources before we shut down and move on to the next level.. Happy resource tracking, so we can actually unload and not wait on a never-ending job... Furthermore, some other resources outlive some internal referenced objects/systems, and cause some splendid UB, which are the best hours figuring out what's actually happening... 
I agree the 100 line thing is dubious. Maybe I should have linked the title to the readable version since that equally well demonstrates the point I want to make. That it doesn‚Äôt take that much effort to get started with something to show for.
Use it when you know what's being returned or the operations you can perform over the returned object are clear. Otherwise write out the type.
I may be misinterpreting, but I don't believe the statement "we can also now inherit from an enum" is correct. In the example source code, if `category_type` is not an alias for an integer type, that's an error.
To be fair, that's a different issue, those people suffer from the insane disconnect between Indian school curriculum and real life.
Both circular dependencies (through lambda captures) and some raw pointers because of Qt and exceptions.
1. noexcept is useless outside libraries and very dangerous. The compiler won't provide the default exception handler and the program will crash. 2. Shared ptr is exaggerated. Shared is too expensive to be used in place of old pointers and unique pointer is not really friendly. If the object is passed to another function, the developer has to return it if the original caller needs to reuse it. 
Personally I use auto everywhere (just like I use var everywhere in C#) because my IDE shows the type when you highlight the variable with the mouse. This is mostly a habit though and I‚Äôm not sure it‚Äôs always the best thing for readability. For productivity it definitely saves a lot of time. Perhaps I should convert all pointless uses of auto with a libclang hack when I format my code to have the best of both worlds?
It's still an interesting exercise, no? But you there should probably be some sort of disclaimer in there somewhere.
To clarify: rr supports multithreaded applications too. The major differences, apart from Linux vs Windows, are that TTD supports recording multiple threads running concurrently while rr runs them on a single core ... but TTD recording is generally a lot slower than rr. Recording a simple Firefox session is about ten times slower in TTD than rr. There are also some feature differences. See http://robert.ocallahan.org/2017/10/thoughts-on-microsofts-time-travel.html for more.
Not just Indians. I am a CS student in Germany and the C++ course is pretty much C with classes: c-style casts, raw new/delete, etc But the we have to analyse precedence rules of a function pointer declaration... which couldn‚Äôt be any more useless.
&gt; I can't think of an example that wouldn't better be refactored to `unique_ptr` and `weak_ptr`. This isn't a thing; `weak_ptr`
Oops, you are correct of course. I meant non-owning pointers to unique_ptrs. Raw pointers or something like [this](http://open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3840.pdf).
With std::async a conforming implementation cannot use a thread pool (at least not very easily). The wording in the standard says that it must behave as if the function was called on a new thread of execution. That means reinitialising any thread_local state. I think the MSVC implementation uses a thread pool but I'm not sure on that. std::thread is the right tool for some jobs, std::async is right for others. Due to the issues with std::async and std::future (most of which seem to be addressed in the concurrency TS) I find myself using std::thread more often than not in my personal projects (though that may be more due to the kind of projects tend to enjoy).
&gt; With std::async a conforming implementation cannot use a thread pool (at least not very easily). The wording in the standard says that it must behave as if the function was called on a new thread of execution. That means reinitialising any thread_local state. I think the MSVC implementation uses a thread pool but I'm not sure on that. This is only with a launch policy of `launch::async`; with a launch policy of `launch::async | launch::deferred`, which is the default, a thread pool is permissible/ideal.
&gt; Pretty much any time a design requires that one object "hold" a pointer to another object that it doesn't directly manage, we use a shared_ptr. This seems like what you'd want to use weak_ptr for - especially if you don't care about he small performance penalty creating a shared_ptr when you lock it
&gt; Perhaps I should convert all pointless uses of auto with a libclang hack when I format my code to have the best of both worlds? Do that and open source it plz :) I like writing auto, but hate reading it unless the concrete type is mentioned in the initialization or for things like iterators.
My canonical example are `boost::asio` handlers. They should contain a shared pointer to whatever they manipulate upon being called, to prevent that when the handler is invoked e.g. after closing a connection it doesn't use freed memory.
&gt; I strongly agree with your comment! I am coming from a game dev background and we are using a self made (partially faulty) in house implementation of shared ptr. My favorite is when there are a shit ton of Lua callbacks interleaved with everything that can delete the pointees right out from under you by calling some DestroyEntity function that sets the refcount to zero.
The power of `const` is one of my favourite things in C++
 QButton* x = new QButton(); // calling throwing function otherWidget-&gt;addWidget(x); You'd be surprised how it's easy to have a throwing call when exceptions are used throughout a codebase and the separation between the `add` and the `new` is far.
How is that related to shared_ptr?
see edits ;)
quick-bench.com?
Thanks! It's exactly what I needed!
Love it. Makes me feel kind of like I'm writing ocaml, not C++. (Why oh why was variant done as a library thing and not part of the actual language, with pattern matching?)
I don't think, Metaclasses will realistically land before c++26 and God knows how long it will take until they can be used in production code. This is really not something I wait for - I don't even know if Still program in c++ by then.
Again, the leak has nothing to do with shared pointers - it happens before any shared pointer gets involved. All you are showing is that you can leak objects, when they are only owned by raw pointers.
No, the ranges library will not make it into the standard anytime soon. At most, the ranges TS will make it into c++20. Afaik there isn't even a proposal for the library yet. But I'd already be satisfied if MS wurd get their act together and shop a compiler that can use the ranges-v3 library.
Ah sorry for the confusion. I should have said that it leaked through misuses of shared pointers and exceptions. Creating shared pointers for owning raw one is dangerous and should be treated with care. Also the other leaks I was referring was indeed circular depencies, mostly hidden in `[=]` captures.
Ok, thanks for the explanation.
Some legacy systems can't even use a c++11 compiler..
I think it is very useful in a lot of situations. Btw, recently I had a Java classes at university and I was shocked that Java lacks of this feature. 
Yeah, they confused the ability to specify underlying types as inheritance (The use of ':' is pretty deceptive here).
&gt; Sadly, from an economical viewpoint it makes no sense to upgrade to a higher standard. That's the question isn't it? Upgrading to newer standards can increase developer productivity, reduce the number of bugs and increase the number of external libraries you can use (while reducing the number of libraries you need to use). This has to be compared to the cost of making existing code compatible to newer standards (you don't have to port everything to the new standard, just make it usable) depending on the age, this is certainly non-trivial work, but the question is whether you don't have to pay that cost anyway at some time down the road.
`unique_ptr` &gt; `shared_ptr`
noexcept is indeed dangerous if one lies about it, but what do you mean by "The compiler won't provide the default exception handler and the program will crash"? What do you mean by "exception handler" in this context?
`shared_ptr` is a boon for multithreading. Otherwise one is indeed hard-pressed to find good uses for it.
At least cppreference.com has overtaken cplusplus.com when searching for language documentation
Someone on the commitee once said that for large software systems which do not perform well the only way to repair them is to burn them down and rewrite them from the beginning - in most of them there are too many legacy and outdated technologies and workarounds
Using Lua is a dream i am having for a long time. I wish we had some issues like this =P Again, inhouse and faulty++ for me :=} Viva la reinvent the wheel 
https://www.jetbrains.com/research/devecosystem-2017/cpp/ has some statistics. 78% of the userbase are C++ 11 or later, if I read the statistics right (I think C++ 17 includes C++ 14 includes C++ 11, hence the percentages adding up to more than 100%) You've also got to bear in mind that anyone on Visual Studio 2012 or later is on a sort-of C++ 11, VS2015 is on a sort-of C++ 14 and so on. Many do not realise of course that they're on a newer C++ until they write `auto` and find GCC refuses to compile it. I've seen this happen quite a few times now.
The readability concern is legit, but I think the "auto almost everywhere" crowd has a good point in that it could _increase_ type safety. If you `auto` declare a variable and assign it to something returned from a function, you're going to get exactly the type that function returns. If you don't, and the function return type changes out from under you to something that may implicitly convert to the type you used, you could accidentally cause a problem. To contrive an example (where you'd have to be ignoring the warnings this generates): Consider: // declarations somewhere float GetDistance(Point from, Point To) const; void SetDistance(DistanceHaver thing, float distance); ... // your code const float distance = GetDistance(from, to); if (distance &gt; 0) SetDistance(myDistanceHaver, distance); Changing to: // declarations somewhere double GetDistance(Point from, Point To) const; void SetDistance(DistanceHaver thing, double distance); ... // your code const float distance = GetDistance(from, to); if (distance &gt; 0) SetDistance(myDistanceHaver, distance); Boom, you just lost precision. If you had used `const auto distance = GetDistance(from, to);` you'd at least have passed the buck on that problem. Myself, I'm still undecided on rules about `auto`. I use `auto` when the type is obvious, _or_ when it's non-obvious but convenient. I'd like to make up my mind about it someday though. 
One can modernise a legacy codebase and have it working well on the latest language and compilers. I'm currently upgrading a 1994 era C++ codebase of 2M lines or so to C++ 17. It's never going to be as good as a complete rewrite, of course. Most of the code will remain exactly as it was written, right down to the hand tuned assembler timed for the 486 :), use of `const char *` for strings, and use of macros instead of templates for generic class generation like you'd do in C because templates didn't work right back then on all compilers. But core classes can gain move semantics, use of Boost can be replaced with STL, and clang-tidy with the modernize fixits can purge and rewrite a surprising amount of cruft. clang UB, ASAN and TSAN sanitisers can be raised and run on 24 hour soak tests on CIs, and so on. Ultimately it comes down to cost benefit. Maintenance is boring and tedious, but can keep old codebases relevant and useful long into the future.
i always use auto for iterators and i find it much easier to read. in most other cases auto makes it easier to write, but harder to read. in java/eclipse i really enjoyed just writing `String x = methodcall();` for everything, then press ctrl+1,enter to fix the type of x. would be nice to have the same thing in VS/xcode -- write `auto x = something();` and press a shortcut to deduce+replace the actual type. 
but do they require you to use only Turbo C++ in Dosbox?
I feel good about it: - in most cases, auto does the right thing (and I don't care - for example that something is this or that type of iterator class, as much as I care that it came from a `begin()` call, to know what to do with it) - In the cases when it doesn't do what I want, I write: auto x = type_constructor{ value for init }; This allows for a very consistent initialization syntax, has all benefits of auto (no uninitialized variables) and keeps things consistent.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7wz1ht/how_to_benchmark_c_code_snippets/du4gdmj/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; If you can write for the garbage collector, you can use shared_ptr. What? First, shared ownership is hard; loops are hard to avoid as your code base grows. Once you have shared ownership as the default, and you "stop caring about lifetime", you will get loops. If you have gc ownership, breaking those loops isn't required to clean up the resources. Now, what happens in both cases is destructors and RAII becomes nearly useless: lifetimes become hard to predict for a mere mortal. So you lose one of the biggest advantages of C++ in exchange for not caring about lifetime. And if you have resources whose lifetime must be controlled you end up having to use unique ptr or manual lifetime management anyhow (which is how shared ptr codebases are *like* gc codebases). I suppose shared ptr might be easier to deal with than teaching C# programmers how to understand C++ lifetimes. Note that shared ptr's performance hit is atomic operation based; which means it makes *other* threads slower as you add/remove ref on it, at least on x86/x64. 
It's also easier to grep where variables are initialized.
because lvariant isn't implemented yet; there's a paper currently in flight at the committee.
Initially I switched to c++ 11 for the scoped enum alone, its amazing that it took this long to get it. 
&gt; There is currently no real controversy in the c++ community on whether or not to use exceptions. There was in the past, but it has been settled in favor of using exceptions with exception safe code. The techniques for writing exception safe code are well understood and easily learned. If you are going to lie you should do it less obviously. In case you are not intentionally lying you should not be saying stuff you do not know enough. 
explicit constructors should help some with identifying when something changes during refactor. Warning levels can also catch type demotion for simplle types. I will sometimes intentionally break things so the compiler forces me to visit all the declarations to check. With auto I find code to be almost unreadable if I haven't been working on it in a few months...
You could always fork it. Run s/FuckSpaces/FragSpaces/g over the code base?
I'm going to have to look in to this whole atomics are slow thing, I can't say I've ever seen that be the case. Then again, maybe they are talking about some sort of excessive usage like at atomic frame buffers where every float has to be compare and swapped.
Any description how it works? I see some direct hex hacks
&gt; lightweight &gt; scripting language That's not so easy possible. Any specific requirements? Some shells are lighweight but they offer practically nothing Wrong subreddit btw for this kind of question
The requirement is that it can be embedded in C++. Something I forgot to mention.
[ChaiScript](http://chaiscript.com/) is designed for C++, not sure about the footprint though. The aforementioned Lua is a possible choice as well, take look at [LuaJIT](http://luajit.org/index.html) or [Sol2](https://github.com/ThePhD/sol2) for efficient and C++ friendly implementations.
Lua is a very typical embedded scripting language, because of it's low footprint and flexibility. It's also quite common to write a custom LISP-like language. 
Maybe the ['PAWN scripting language'](https://www.compuphase.com/pawn/pawn.htm) would suit your needs, it's designed for embedded systems and it's very similar to C. It's the only one I know really.
I am very happy to say that if you're using boost, you can "Emulate" lots of modern C++ things using Acient compilers. 1. Auto =&gt; BOOST_AUTO 2. nullptr no :( 3. shared_ptr =&gt; boost::shared_ptr 4. enum class =&gt; BOOST_SCOPED_ENUM_DECLARE_BEGIN 5. static_assert =&gt; BOOST_STATIC_ASSERT or other SFINAE techniques 6. variafic template =&gt; BOOST_PP_REPEAT 7. for range =&gt; BOOST_FOREACH (which is not compatible with BOOST_AUTO) 8. Initializer list =&gt; boost::assign::list_of 9. noexcept =&gt; throw() with -fnothrow-opt in GCC 10. move =&gt; boost::movelib 11. lambda =&gt; no :( 12. delete, default =&gt; boost::noncopyable 13. override =&gt; GCC 5 C++98 mode supports it and -Wsuggest-override is working. 14. std::thread =&gt; boost::thread with move semantics 15. unordered containers =&gt; boost Of course, using latest standard is good if it is possible. (I code at home using GCC7 with C++17) But there are many reasons that you can't upgrade the compiler and standard.
Firefox redirector plugin is so good tool to deal with such use cases. https://www.reddit.com/r/cpp/comments/7j1v07/modern_cmake_talks/dr3kb8e
The Rubik's futuro cube uses PAWN, I guess the use case is very similar.
Ubuntu 14.04 ships with gcc 4.8 I think, and is EOLed in 2019. It's the first version that has full C++11 support, but incomplete C++14.
It's just frustrating when you are first learning some new thing, and you don't know when things changed, how new of information you actually need, etc. Official docs will usually say a specific version number, but all the peripheral blog posts and stuff may or may not. With Qt, if you want to learn how to do something with the QPainter API, old information from 4.x is probably still relevant because it hasn't really changed much in years. If you want information about Qt3D, you need to be careful because there was a Qt3D 1 that doesn't work like the Qt3D 2 that is in the current version of Qt, so information from the time of Qt5.5 would be useless now. Part of learning the new technology is learning the history of it, and how to google it most effectively and filter out old information. It's annoying.
You're right, but hell is other people :) In my (dumb) example code you wrote was broken later by somebody else without changing anything you did.
Same here. The other example when I use auto is when casting, since the cast operation declares the return type already. Makes it easier to read particularly when the type name being casted to is somewhat long.
Check out Tcl, there are some small implementations.
I don't understand this entire ecosystem. Every time I go to look for information about how to modernize my C++, I get an article like this and a reddit post that says basically "Well thats not really the best advice or usage of these new constructs..." What's it going to take?
The compiler should warn you about a loss of precision. I don't see this as a compelling reason to use auto for codebases that enable these warnings.
Reflex matches is always false in 4.8 AFAIK.
[MicroPython](https://micropython.org/) has decent support for ESP SoC's. In fact, [a recent commit](https://github.com/micropython/micropython/commit/bc08c884a2e7d1d3a4476c224f230b90ee2bf1e3) just added support for the Espressif ESP32. Interfacing with C or C++ can be done by [writing modules](https://micropython-dev-docs.readthedocs.io/en/latest/adding-module.html). Writing a module in C++ to talk to the LED panel, then driving it with MicroPython seems like a good way to go about what you're looking for.
Is the lua C API with something like FreeRTOS. I‚Äôve update my question. I am looking for a scripting language that can be embedded in C++. I don‚Äôt want to flash my chip with something like eLua or microPython.
Thanks. That sounds like a decent approach.
Among other things: different niches. Nobody would use Swift in a serious long lasting project, because it breaks your code every semi-major update. Certain places require the system to be built and supported for decades so backwards/forwards compatibility is a must (so languages like C++, Java, C# and others are used).
They have a branch with a few MSVC specific changes that make it compatible even with VS2015 AFAIK, and aiming for a proper support in one of the next updates to VS2017.
[Guile](https://www.gnu.org/software/guile/) is a Scheme implementation that's designed to be embedded in C (I believe). I'm not sure how lightweight it is, but I really enjoy using it. I don't know of any other good scripting languages, but I hope this helps, even a bit. Good luck!
&gt; maybe they are talking about some sort of excessive usage like at atomic frame buffers where every float has to be compare and swapped. I believe that it rather has more to do with the memory model, that is memory ordering itself. I.e. usage of std::memory_order_acq_rel where not absolutely necessary. [This paper](http://www.multithreadingandvfx.org/course_notes/2015/reinders_threading.pdf) I've stumbled upon right now makes me actually go and read that book :D
That version is an outdated fork and while I acknowledge the great progress the msvc compiler has made over the last couple of years, I believe any announcements about their compiler's capabilities when I see them in a preview and not earlier.
Constructor should take by value and move arguments. Correct me if I'm wrong, but I think the values are elided and only moved or copied into the members directly. Also, taking constructors arguments by value makes writing it much easier. If there's no performance impact, I wonder why I'd even bother writing that n^2 set or using forwarding references.
Agree with the last comment. Auto return types are imho useful in generic code, if the alternative would be to repeat the function body with a decltype around it. Otherwise I stay clear of it.
Not to be "that guy" but Google seems to have answers should one peruse it search results :) https://github.com/max1220/freertos-lua-component Lua is a tiny C library that can be embedded in basically any C or C++ project. Lua is also super minimal as in its a tiny library, can be compiled without any IO or even floating point support, etc. I'm consistently bewildered that it's still used at all in new desktop/server projects but it's a great fit for embedded contexts. :)
Use auto if otherwise you have to repeat the type. Still not a perfect guideline, but I try to avoid auto usually. If I have a cast, I usually use auto, because I already specified the type I wanted. I also tend to use auto if I'm using iterators (and the container declaration is reasonably close, e.g.: vector&lt;ID&gt; someIDs = SomeFunction(); for (auto id = begin(someIDs); id != end(someIDs); ++id); That is especially nice with iterators as changes to the iterator type usually don't need source code changes. I usually also use auto with range loops if the declaration of the container is close enough to be visible, although I wouldn't in the example above, as `for(ID&amp; id : someIDs);` is shorter and I don't gain anything by leaving out the type (contrary to iterators). Sometimes I use auto to shorten long template types, but I usually try to avoid such situations with type aliases. So auto is always a tradeoff. It can make your code easier to refactor and more readable by having less code to parse. It can also make your code harder to read if you have to look for the real type (by asking your IDE or looking through your declarations). Use it with care.
As I don't have experience with codebases I always wonder: Is the problem with upgrading to newer standard versions coming from breaking changes between e.g. 98 and 11 or is it that the code wasn't standard conformant to begin with and newer toolchains are less forgiving?
I actually can't remember doing that (not a lot of function pointers floating around our codebase, fortunately) but I will say that with pointers I usually try to be explicit and use `auto*`, which I started doing because I think the only way to get a `const thing*` is to say `const auto*` (`const auto` would be a `thing* const`).
If you‚Äôre disabling scripts that makes sense, my blog is a React SPA with no serverside rendering. Eventually I‚Äôll add serverside rendering :^)
Ah sorry, I didn't mean to imply there was something wrong in the page itself! I was just puzzled at first why it was coming up blank. uMatrix blocked Cloudflare JS CDN and ButterCMS, looks like, I guess that was the cause. But there are no nasty tracker scripts or ads so it's all good.
I wish auto worked inside lambdas. That's the most useful place for them. Iterators for nasty map/pair types as well, although now I try to use the new for() when I can.
It depends on the database, really. But normally you'd get a database driver/client library and include it into your project and use that. For instance, PostgreSQL has [libpqxx](http://pqxx.org/development/libpqxx), scroll down the page for an example. Most client libraries work in similar manner. Google for "&lt;database&gt; c++ library", you'll get yours with high probability, [like this](https://duckduckgo.com/?q=mariadb+c%2B%2B+library&amp;ia=web) for MariaDB. Happy hunting!
Makes sense, but what kind of changes to your toolchain and/or compiler flags do you allow then? And afaik, there are a few breaking changes between each standards revision (as far as I remember nothing major though)
look at sqlpp11 library on github
Most of us only take issue with the technicality of a few things. Mostly use of auto and perhaps some minor gotchas. Most of the list here is pretty good. IMHO the biggest real gain from c++11 was std::move and rvalue which has measureable performance gains. For typical general use other ones are nice to haves.
can you please elaborate on this? trying to learn how i can use it with multithreading :) thanks
We already build our code with c++11 flags. New libraries are written using c++11 std libraries (thread, memory mgmt). 
Qt has an easy to use and portable SQL module - http://doc.qt.io/qt-5/qtsql-index.html
You might want to have a look at [wren](http://wren.io/)
In multithreaded scenarios, dealing with object lifetime is not trivial at all. Say that you refer to the same object from two threads. Say, further, that one thread wants to remove the object from the program state. It can't just destroy it, that would cause UB in the other thread that might be using the object. That requires synchronization on destruction, always a tricky thing to do. This is where shared/weak fit like a glove. Say that the object's shared ptr is simply removed from some containers - that's deletion. Any other threads hold a weak ptr - when they try to obtain it, they get null and that's it. If they were holding a shared ptr when the "original" was being removed, they can still finish using it.
I Agree with the comment above me. It's very embedded friendly, very little dependencies, very easy to port. I'd like to add to what he said: - you can plug in your own memory allocator - you can plug in your own Reader, useful eg if you don't have a filesystem After a short while you get used to the way it does things (eg stack based approach) , or if you like you can use a c or c++ wrapper on top. 
ah, Thanks! i appreciate it. I'll look this up online more. if you have any good resources to learn shared ptrs with threads please do let me know :)
You can use them as tokens. using token = std::shared_ptr&lt;void&gt;; template&lt;class...Args&gt; struct broadcaster { void operator()(Args...args) { listeners.erase( std::remove_if( begin(listeners), end(listeners), [](auto ptr)-&gt;bool { return ptr.lock(); } ), end(listeners) ); auto tmp = listeners; for (auto weak : tmp) if (auto f = weak.lock()) (*f)(args...); } using listener = std::function&lt;void(Args...)&gt;; using listen_ptr = std::shared_ptr&lt;listener&gt;; token listen_ptr( listen_ptr pl ) { listeners.push_back( pl ); return pl; } token listen( listener l ) { return listen(std::make_shared&lt;listener&gt;(std::move(l))); } using listen_handle = std::weak_ptr&lt;listener&gt;; std::vector&lt; listen_handle &gt; listeners; }; here we have a basic broadcaster/listener implementation. You keep your listener registered by persisting the `token` returned from `listen`. When that token (or copies of it) goes out of scope, you are deregistered from the broadcaster automatically. The listener object has shared ownership -- the broadcaster and the thing subscribing both keep track of it. So shared ptr is appropriate. This is not an industrial quality variant of this technique, but it is a usable initial sketch. 
Worst case scenario, you always have EmbedVM. http://www.clifford.at/embedvm/ Will probably work on almost any MCU, but be prepared to modify it.
What makes you think auto don't work in lambdas?
I have uBlock Origin but the link seems to load and work fine for me?
Because you don't really want other people to look at your implementation. You have to implement templates in headers though.
Faster recompiles: If your implementation is split up into separate compilation units, you only need to recompile the ones that change when making edits.
&gt; Because you don't really want other people to look at your implementation. Ok, let's take that as a given. &gt; You have to implement templates in headers though. Ah, so when templates are involved (a language detail), then the above no longer matters? I don't think this explains OP's question.
This is not a relevant reason. When deploying, you wrap your code and supply a compiled shared object with a header that has nothing with your implementation. 
correct yet we are far from the time it took 30 minutes to compile. If your code is better maintained, without having to declare everything twice, and your compiler doesn't need to link, the extra millisecond worth the effort. Moreover, if your code is getting too big, you can just split it into another project, which makes everything more maintainable (and accessible to other team members)
[Modules](http://cppdepend.com/blog/?p=228)
Faster builds, smaller binaries.
There are many examples of 'header only' libraries that follow this path. But I think for code that only gets called once, or where you want to increase the separation between parts of your application, or where your functions are calling internal functions that you'd rather not give the users permission to mess with or depend on, putting the code into a separately linked object is the right approach. 
Today we are usually working in teams and separation to smaller blocks (projects) with predefined interfaces is mandatory. This gives you the ability to distribute the work load, preform unit tests, delegate tasks, and have a more organized structure. When working on a single project, there is no need for more than one source file. In addition - this make code sharing easier, since you just include your "source" and your'e done. 
Lua was built for this
[removed]
You clearly speak from experience. I think OP is suffering from a bit of Dunning-Kruger :)
&gt; People argue against reflection as one of the main culprits of code smell, I don't know who are these people but I'm pretty sure that most of the useful libraries in higher level languages are built around reflection.
That's what I do, small simple header libraries, and binaries that use them. There's pluses and minuses to both approaches, but so far (12+ years) it's worked well for me.
I'm curious about your workflow, how often do you recompile? I tend to go quite long between compilations. My editor will highlight any compilation issues while I type so when it comes to compile and test it pretty much always passes directly. So if it takes 1sec or 20sec doesn't have that large of an impact.
Still a favourite of games, and because of that there's lots of knowledge around it. I've heard embedding python, javascript or ruby to be comparatively much harder to embedding lua, and with boatloads of overhead.
I'm curious which editor you use that you trust that much? I use Visual Studio and it does a pretty decent job at highlighting errors but gets it wrong enough that I regularly still compile a file as I go to make sure it's working as expected. Every 5 mins or so I'll run the unit tests too as I progress, so incremental compilation speed is really important in my workflow.
Also a lot of Game Engines use forms of reflection and introspection to allow dev tools and Component Factories to function cleanly.
It's a pretty basic vim+YouCompleteMe setup. Used libclang and it seems to work pretty solid 99% of the time. Never really have any issues. It shows me exactly the same errors inline as when I manually compile. This is on a medium size code base of around 500k lines.
I think the idea that you would feel safe refactoring something like that and not also auditing the current use cases is crazy - with or without auto and with or without compiler warnings.
There is still separation of concerns: module interface unit and module implementation unit.
Good point, thanks! I‚Äôll fix it to discourage junky practices.
https://www.reddit.com/r/cpp/comments/7wuygc/the_15_c11_features_you_must_really_use_in_your_c/du4qkf8/
I agree completely, but reflection is touted as dangerous in a lot of communities. After all, it is one of the only constructs that can completely subvert user expectations depending on how the far the language goes to implement it.
&gt; There are ways around that such as using anonymous namespaces or the like, but that then would just trade ODR problems for code bloat in your final executable. Is there a reason, you don't mention the default solution to that, namely the `inline` keyword?
Could you please provide an example of this? I want to make sure I'm not doing something stupid with map for loops and results of find. Did you mean only when _not_ using `auto`? In that case I'm fine :D
[here](https://github.com/onqtam/rcrl) is a direct link to the repository - curious for any feedback!
&gt; Still a favourite of games, and because of that there's lots of knowledge around it. Yeah, that's were I experience it... and it still confuses me. It's used because it's used, not because it's in any way a good choice for the domain. :) &gt; I've heard embedding python, javascript or ruby to be comparatively much harder to embedding lua, and with boatloads of overhead. Lua is absolute very easy to embed for simple cases and pretty hard to beat in that regard. I'd agree that Lua is both easier to embed and less of a performance burden than Python or Ruby, though there's certainly advantages to both. JS is a far more complicated comparison to make, though. A key thing to remember about JS - unlike the other three - is that it's standardized and has multiple implementations. Where being small is a priority, there's also implementations like [duktape](http://duktape.org) or [mujs](http://mujs.com/) that are extremely comparable to embedding Lua but arguably a better language. And for cases where speed, tooling, a maximum ecosystem support matters, you can go to the modern "big" runtimes like V8, Chakra, or SpiderMonkey. V8 and Chakra are both fairly nice C++ APIs and at least the old versions of SpiderMonkey (haven't used recent ones) had a very simple C API of comparable quality and complexity to Lua's. Given the four scripting languages mentioned here, I'd personally quantify things as to say that one should use Lua where being "light" is the priority (like the OP's case, probably), use Python where being fully-featured out of the box is the priority, use JS where efficiency or tooling is the priority, and use Ruby where being needlessly different is a priority. :p (Just for the sake of disclosure, I've embedded all four of the languages you've just mentioned in game codebases - though my experience with embedding Ruby was over a decade ago, and for embedding JS only on personal projects - and I am a "core technology" engineer for a large C++ game project that embeds both Lua and Python... for Reasons(tm). So I've some experience with shoving scripting engines into C++ codebases :p)
The main reason that it is not common is that it is a tradition inherited from C to put the declarations in the headers, and implementations in the .cpp files. Most if not all C libraries and programs work this way. And it is generally better for build times in terms of memory consumption, parallelism, and incremental build time, if you do this. * The main time that it is NOT faster is if your code contains a lot of templates, or most if not all of your classes are templates. * Template instantiation can be a bottleneck in C++ code, and templates instantiations cannot be cached across compilation units. Look into C++ modules if you can use really recent versions of major compilers.
The main reason that it is not common is that it is a tradition inherited from C to put the declarations in the headers, and implementations in the .cpp files. Most if not all C libraries and programs work this way. And it is generally better for build times in terms of memory consumption, parallelism, and incremental build time, if you do this. * The main time that it is NOT faster is if your code contains a lot of templates, or most if not all of your classes are templates. * Template instantiation can be a bottleneck in C++ code, and templates instantiations cannot be cached across compilation units. Look into C++ modules if you can use really recent versions of major compilers.
why use both? isn't uMatrix just advanced mode of uBlock?
Mostly when not using auto: for (const std::pair&lt;KeyType, ValueType&gt;&amp; item: my_map) When the pair type of a std::amp is actually std::pair&lt;const KeyType, ValueType&gt; so it copies the key/value into the temporary pair every step.
Glad you stuck with it long enough to reproduce the problem!
That's a quality domain name.
If you were put in charge of a greenfield project to build new design tooling for a game engine, what would you do instead of the usual embedded Lua approach?
If you have 2 worker threads and a main thread, you can wait until they are both done and free your `unique_ptr`. There are cases where a shared pointer is better, but often it is because of bad design/lack of thinking about ownership. Usually, most `shared_ptr` are like "I have no idea when the fuck this object should be destroyed, so I'll let the reference count work it out". There are cases where lifetimes of objects are really complicated to evaluate, but this isn't as common as the actual use of reference-counted pointers.
&gt; precedence rules of a function pointer declaration Something Dante put in the last circle of Hell. Thankfully there are some websites that help you parse those declarations. I do think that even with C++17, it's good to learn about new/delete and what happens behind the scenes of `unique_ptr`. Forcing you to write some code without it the first time can be very helpful at proving the point that raw allocations are evil and dangerous and should only be used in some very specific cases. C-style casts are only tempting because they are shorter, I wish C++ had chosen shorter names for the casts.
That's some pretty low-effort implementation. bool parseComplexRegex(string){ return false;} Hey guys we can ship it, partial support for Regex!
Yes, when the object outlives threads, unique is better. And I agree that people tend to use shared like you describe, which is... pfffft I am talking about situations where objects come and go while threads are running. Say a dynamic collection of devices to exchange the data with. Data flows from and to and user decides to remove a device. So a background thread speaks to it on a periodic basis (and that takes time long enough to wait in th UI). Keeping a weak ptr to device and going to shared while communicating helps to avoid blocking the UI.
&gt; Also, taking constructors arguments by value makes writing it much easier. If there's no performance impact, I wonder why I'd even bother writing that n2 set or using forwarding references. Article is long but it mentions the difference... When you have value argument in case of a temporary this happens: 1) temporary is moved to argument 2) argument is moved into member Using universal references or n^2 overloads your temporary does not get moved into the argument(since argument is a a reference). Member is constructed from reference to the temporary. So less moves. 
You can optimize it to make it the same size or even smaller if you know whether it's always going to be a virtual member function or a regular one. In the virtual member function case, the offset you need to store should be small enough to fit on a single byte.
I haven't had to deal with this issue until now, but I guess it could happen. UI is probably the biggest pain of programming because it needs to deal with the user, and you knows what the user is going to do that you didn't consider.
[removed]
&gt; Thankfully there are some websites that help you parse those declarations. fuckingfunctionpointers.com
It's funny how I can feel their sentiment as they made this page.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
That also means the code cannot be optimized across TU boundaries, though.
You're gunna need some sources to say that a very large chunk of recently developed programming languages are all wrong.
What, copy-paste declarations around? You trade not having the source file for that "public" header and having possibility of it going stale (or plain wrong) and breaking clients.
There is a significant difference between anonymous namespaces and inline. The former will generate one copy of each function for each TU that will also remain in the final binary (for the linker they are completely unrelated symbols). Inline on the other hand has - in my experience - almost no influence on the final binary as the linker removed all duplicates and while the keyword influences the inlining decision of the compiler to some degree, that influence seems to be pretty small (at least with clang).
I rather think you will sing a different tune past a certain code size. Let me guess: your code didn't go over say, 100KB in source size? Having one big compilation unit when code is modular is strictly detrimental to the modify/build/test cycle. Say that you have 50 classes in your project and you work on 5 of them, and they are are used in 5 other. If these 10 have their own compilation units, you build one fifth of your codebase, including the benefits of precompiled headers and incremental linking. If you have one compilation unit - nah-hah. You can google the so-called unity builds though. Related to your idea and useful on a build server.
Howering mouse over `auto` in Eclipse shows actual type. You can click and copy it
good to know. hm.. i'm all setup in vs/xcode though. not gonna change over for that tiny feature :) 
Afaik that depends on the linker / type of lto you are using. It is of course less effective than "normal" pro, but I see no reason why the linker can't e.g. inline assembly code. But yes, I was assuming a situation, where the user can compile everything from scratch (working almost exclusively with internal or open source libraries).
I was explicitely referring to the seci d part. People need to accept that code generation is the best solution to a lot of problems: as mentioned: to generate UIs, webpages or serialization code. Templates are some form of codegeneration, reflection is another. Ranting because for my software I currently implemented codegen in cmake-lang -- I'd rather not have to do this even if it works relatively easily.
Not sure if that comment was specific to C++ or not, but I've definitely seen it abused in other languages as a really slow replacement for interior pointers, or worse, accessing private members. C++ generally has more ways to deal with this (although for the latter use case I would hesitate to call them "better"). Potential for abuse aside, I really want proper static reflection in C++. I don't want to deal with another unholy fusion of macros, templates, and generated headers. 
Isn't that exactly what I said?
I'm not sure you can really call this "compile time" reflection at all. Something like (taken from example code): for (const auto&amp; propertyName : propertyNames) { printf("Setting \"%s\" = %d\n", propertyName, ++value); LayoutMeta::Set(meta, propertyName, value); } Is heavily type erased, and in the general case will generate pretty bad assembly. In compile time reflection you should be keeping the types around, not doing sets and gets via heavy type erasure like std::function. This is basically runtime reflection.
&gt;On the contrary: If you only have one source file and implement everything in headers, it is IMPOSSIBLE to violate the one definition rule. If you have interdependent classes you'll have to be very careful with include order or you'll run into ODR issues. Good luck mantaining that. Also this breaks completely for libraries. &gt;Oh, and apparently all those smart people only did anything after Java, c#, python and whatnot where invented - all of which, don't have a separation of header and source files. Header files are a consequence of the primitive compilation model of c and c++ - not some great invention. And btw. you can have separation of implementation and interface in the same file. I was obviously talking in the context of C++. Other languages have different ways of dealing with this and sometimes it's a nightmare because of the lack of headers too. Ever tried programming against a closed source Java library? Or a closed source Fortran library? I have. It's not pretty.
I'm not sure what perspective you're looking at this from, but *all* introspection happens at compile time through templating. Calling the getters and setters isn't *really* the reflection part. The reflection part is iterating over the data members (happens at compile time) and generating the methods (happens at compile time), i.e., the actual introspective parts.
Never mentioned other languages. What I said is in the context of C++.
&gt; If you have interdependent classes you'll have to be very careful with include order or you'll run into ODR issues. Just don't make interdependent classes
I hope you are being sarcastic.
+1 for Lua in this use case. It's light-weight, reasonably natural for simple scripting and easily embeddable in C++. Lua's background in gaming has driven it to speed and responsiveness. See https://github.com/ThePhD/sol2 for a decent library for embedding C++ in Lua. 
&gt; to generate UIs, webpages or serialization code I do not see why you would need dynamic codegeneration here. Especially for serialization it should be enough to iterate over members and types. &gt; Templates are some form of codegeneration, reflection is another. The importend difference is that templates happen at compiletime, reflection at runtime. With dynamic codegen i mean stuff like it happens in the C# system.reflection.emit namespace 
I guess? From my perspective the compile time reflection aspect of it seems extremely complicated relative to what is achieved. All you really need is a tuple of references + string literals to do whatever you want. The main reason I can see that all this complexity ends up being required is because of the API that you chose. Do you really like that API that much more than: struct LayoutMeta { AUTOPROP( (int, x), (int, y), (int, z) ) }; If you choose this API, then you can just have AUTOPROP generate a member function that returns said tuple, and you're already done, 3-4 lines of code later and you can solve your setter/getter problem. Do you really have such a strong preference for the API that you showed, or was this implementation motivated by other factors?
&gt; software engineering best practices That is not specific to a single language.
RIP autocomplete tools with your code example.
isocpp.org cpplang.slack.com reddit.com/r/cpp I follow a few blogs more frequently, though most of them are promoted on isocpp
[hackernews](https://news.ycombinator.com/) &amp; [/g/](http://boards.4chan.org/g/) for the laughs.
Uhm, what? You mean that with my example, if I do `LayoutMeta m; m.` and hit tab, I won't get auto completion? I can tell you that's false because: a) I use a macro very similar to that, and b) I get perfect code completion.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7x8n37/your_goto_techprogramming_news_websites/du6bq1p/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You mentioned r/cpp, that's the correct answer.
I actually think header/source separation is great; it lets me control compilation in a way that's not possible in other languages. 
At close to 7 minutes into the video he brings up the project properties. Pretty much the first thing I do when bringing up these properties is set the configuration to All Configurations and platform to All Platforms. This is because he changes only Debug|Win32. He sets Level 4 warnings, permissive-, etc; but once he builds in Release or x64 it will not be Level 4 warnings, permissive-, etc. Probably not the biggest deal with warning level but say he were to set additional include directories or some other settings it can be real annoying figuring out why it compiled in Debug and not Release or x64.
sorry, I had misunderstood your message.
Great observation! IIRC they're finally changing the default to 'All/All' in the next VS update.
*Beep boop* I am a bot that sniffs out spammers, and this smells like spam. At least 100.0% out of the 7 submissions from /u/harperterp appear to be for Udemy affiliate links. Don't let spam take over Reddit! Throw it out! *Bee bop*
I just watched a bit of it. He says he likes to use "\n" instead of std::endl, but they do different things. std::endl prints a newline and *then* calls std::flush, which, if you've ever done C programming, know the issues of having unflushed data.