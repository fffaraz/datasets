What happens if I a call generateRandomBigNumber(nullptr, low, high) ? If you consider it my mistake to do so, why are you letting me make it so easily? Preventing is trivial and likely ends up in easier code for both of us, no?
Unfortunately `random_device` is uselessly underspecified if you want portable CS &amp;ndash; C++14 [rand.device]: &gt; ^1 A `random_device` uniform random number generator produces non-deterministic random numbers. &gt; ^2 If implementation limitations prevent generating non-deterministic random numbers, the implementation may employ a random number engine.
Have a good read. If you read the entire chapter and interprets that RAII have preceded exceptions, I just can't help you.
Okay, you take `std::mersenne_twister_engine`, and now you have to think about how to generate a non-power-of-two-bounded thing for the last chunk. And you also have to decide which engine to take in the first place.
RAII is inside the Exceptions section dude. Sorry.
I am aware of this, and I agree that we need something like a `std::crypto_random_device`. I know that microsoft claims that `std::random_device` is cryptographically secure and it is possibly the case for libstdc++ on linux. (If the CPU supports the RDRAND-instruction it will by default call that (thereby producing output that only a fool would trust), but will otherwise fall back to /dev/urandom (you can also request that explicitly) which is secure). I assume that libc++ is similar to libstdc++, but I haven't checked.
You're right, I'm wrong. It's clang-refactor. https://www.youtube.com/watch?v=cX_GhJ6BuWI&amp;feature=youtu.be&amp;t=3355
nana is looking very great! I should try it.
Owning raw pointer is a very common mistake along beginners. Using pointers too much is too. Using dynamic allocation for STL classes --&gt; just don't. Abusing oop is in my opinion what plagues most enterprise code base. Not sure if it helps fir an exam though.
Nitpick regarding the code example: ``` optional&lt;foo&gt; make(arg_t argument, std::error_code&amp; ec) { auto resource = make_resource(argument); if (resource) return foo(resource); return {}; } ``` Don't you want to set the error code in the case where the resource couldn't be acquired? You probably want to pass it as an output parameter to `make_resource`. Fun fact, the LLVM Programmer's Manual suggests a similar pattern for "fallible constructors", since the LLVM codebase disallows exceptions: http://llvm.org/docs/ProgrammersManual.html#fallible-constructors
What I meant is simply: that first parameter to thefunction should be a *reference*, not a pointer. References don't slow anything down, but help the caller understand the function better and prevent him from being silly.
Breathe in....... ...... ............ And breathe out....... .......... ..........................
Qt. It's huge, but you can start out small and grow your knowledge incrementally. See this series of YouTube videos: [C++ Qt Programming](http://www.youtube.com/playlist?list=PL2D1942A4688E9D63) . 
I'll be generous to you ok? I'll leave you this funny easter egg "from the mouth of the horse", as you said, I hope you're able to uncover it and enjoy :) http://imgur.com/a/NAVw9 Don't want to leave you with nothing besides downvoting, you know ;)
In case you're a simple (but still good) Padawan, you may have already uncovered [the easter egg](http://imgur.com/a/NAVw9), but possibly just have uncovered the shell, the more trivial to follow by reasoning. But [there's another](https://godbolt.org/g/rKnxYM) _inside_, which corresponds to the real truth. If you want to learn more about the sad state of reality on that, I invite you to check [this post of mine](https://www.reddit.com/r/cpp/comments/5noem9/a_personal_tale_on_a_special_value/), apprentice.
I think there's a plugin for vim as well, though last time I checked, it was a bit out of date.
You should avoid libraries that could teach you bad programming habits. Such as Qt - they teach you how to write exception unsafe code and they also bring security issues from conversions between standard and custom containers/strings, using int instead of size_t. nana ... nana looks good on the first look ... but looking deeper I can see "typedef unsigned long uint32_t" ... why not use standard headers and types (std::uint32_t)? I have spent a lot of time looking for perfect GUI library, but I never managed to find one. What I expect from a GUI library: * Exception safety * Support for both heap and stack allocated widgets * All strings in UTF-8 * Good support for key input support (some GUI libraries have issues, mainly under linux, with entering composite characters) * Using "correct" data types, such as using `size_t` for everything that represents size in memory. No pretending it can somehow load more than that into memory (such as Qt's read functions having qint64 as size argument, while returning QVector, which size is represented as an int!). * No custom container or string classes - only use standard ones * GUI library should only handle GUI. No other non-optional stuff for reading files, networking, or more. * It should be possible to integrate GUI event loop with some other event loops on target platforms - such as providing pollable file descriptor under linux, or allowing me to add other file descriptors into its event loop
Yuck! I get this when Java programmers on the team start to work with my C++ code; `new` and `delete` and C-style arrays all over the place, and clearly no understanding of how dangerous and outright buggy their work is. I banned their use entirely except for in special cases, requiring the use of `shared_ptr`. Last week we finally adopted C++11, so `std::array` and `unique_ptr` will also be permitted from now on, thankfully. For the original poster: think about the semantics surrounding ownership of objects, and the transfer and sharing of that ownership within your program. Making mistakes around this is the root cause of many bugs, such as deleting objects owned or shared with some other part, or using after deletion because some other part deleted the object you were working with. Consider the differences between value types, pointers, references, unique_ptr and shared_ptr, and the difference between each when used as function arguments, return types, or when stored in containers, and their effect upon ownership and lifetime. Also, get a copy of Meyers' "Effective C++" and later books from your library. It's a catalogue of all the things you shouldn't be doing with C++, and the best practices to avoid them.
Damn, I'd fail that exam.
Hi! I am trying to do some examples from your book. And I'm not able to compile this: http://coliru.stacked-crooked.com/a/2a6dc891455f877c. I think I am missing some basic thing but I don't know what exactly. Could you help me? Thanks.
&gt; It's not the same as the mathematical concept of a vector Actually it basically is. The definition of a vector is just an ordered, fixed-size list of components. It can be *interpreted* as the usual "length and direction" definition, but there's nothing that requires a linear algebra vector to correspond to any physical or geometric interpretation. After all, you can also interpret the elements of the vector as coefficients to an equation. I think the only place that `std::vector` fails the definition is in fixed vs. dynamic length. But that's more a generalization than a violation of the definition, since you can use `std::vector` with preallocated capacity. 
Well that's what I meant by a sound justification. I'm just not inclined to talk about the definition of a vector in merely discrete terms. I find the continuous definition more generic. Nevermind vectors while taking their name from mathematics, are typically meant to represent things other than vectors and have an implementation that is concerned with system details. Which is why I'm further inclined to not say they basically are, but yes they are basically related. Also I think the name for vectors also comes from them taking on a specific length at any given time, even though it grows and shrinks. Like a mathematical vector, a vector will be a specific length at any given time, though a variable vector could be described through some function over said variable. So maybe it's semantic fudgery on my behalf, but I don't think the dynamic length is a violation (even when ignoring a preallocated capacity.) I don't have a strong opinion for my semantics, but that's just how I end up talking about I suppose.
Yeah, I'm being a bit harsh for effect -- the typedef was actually there so they could swap in and out different array classes. That would have been targetted at C++03ish -- MSVC circa 2007 or 2008 -- but they were allowed boost in the code so I'm not going to forgive the, that much. (There were a lot of boost scoped and shared pointers still hanging around when I started too. And a few std::auto_ptrs. But I think those were from a year or so later) We've still not got the codebase fully modernised but the best of it is in C++14, and even the worst is now at least at C++0x. Some of my happiest times at work have been when I've been given carte blanche to improve the code. It's certainly the newing of the vector that really got me. To be fair to them, I ran a leak detector over that whole part of the codebase and it was all tight, which is pretty astonishing, not least given that those pointers made outside that class? They were first owned in a totally different library. Urgh.
&gt; GUI library should only handle GUI. No other non-optional stuff for reading files, networking, or more. So you prefer looking for : - A GUI library - A network library - A file reading library - An UTF-8 library - An image display library - An OpenGL abstraction library - An XML library - A Json library - An embedded scripting engine which will all have their own different APIs conventions, quirks, build systems, bugs trackers, maintainers, etc., instead of having a very similar interface on all the concepts needed to build a general-purpose application ?
applications can launch a URL into the users default browser. the user doesn't have "to go to"
Let's put it this way: webapps aren't the solution for pretty much *anything*. If being a webapp is part of of the problem specification (i.e. you are setting out to write Google Docs, or web skype) then write a web app. If not, pick a desktop GUI toolkit.
This is not the subreddit to complain about SO polices.
Are you really still pushing to get a WebUI for a desktop app. The fact that it's rendering to html at all is the problem. Not the fact that you have to click a link or have an automated way to go to the page. A webui is unnecessary. Period.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/stackoverflow] [SO dumping a valid question in seconds. Let's be a more friendly community? • \/r\/cpp](https://np.reddit.com/r/stackoverflow/comments/5o0lmo/so_dumping_a_valid_question_in_seconds_lets_be_a/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
If you want dereferencing a null pointer to mean something on your chosen platform then please contact your compiler vendor and let them know. UB=do whatever, and do whatever may include working the way you want it to.
This subject has been addressed in the question.
I think the voting indicates that your idea of "clear and straight to the point" is different to everybody else's. 
[put on hold as unclear what you're asking by juanchopanza, Christian Hackl, WhiZTiM, Bo Persson, Olaf 1 hour ago](http://puu.sh/tmzAj/b72ee73ad4.png) I mean it seems like the appropriate action was taken. It told you the way you wrote your question doesn't make clear what you are asking and tells you to reword it Regardless of if you had a valid question or not if the question can not be understood it can not be answered. The instructions for you to follow are clear and friendly. If you want question answered write it clearly so that people know what your asking.
If you consider closing a possibly valid question and dumping it in downvotes in matter of seconds appropriate action... I just have no words.
They told you they don't understand your question and you just need to word it properly and it will be reopened for discussion. There is literally nothing anyone can do if what you write makes no sense. It is the only course of action. They didn't force you to write the question that doesn't make sense. They told you to write it so that it does.
-1. I can't understand the question. You should tunnel your rage into to writing intelligible questions. So to have access for data lying at the null pointer through a C/C++ compiler one most probably will have to find means for fighting it.
If you use an IDE like Visual Studio etc., you need to find a checkbox saying something like "Keep the console window open after the program finishes". 
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/5o0hy6/so_dumping_a_valid_question_in_seconds_lets_be_a/dcft117/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[removed]
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/5npx3h/parameters_for_literal_operators_being_available/dcft5gz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
There is also a new project [RE/flex](https://sourceforge.net/projects/re-flex/) that you may want to check out. I've been working a lot with Flex for over 17 years, including teaching it to CS graduates. Flex is a maze of ugly code. Flex C++ code is not generated properly either. My disappointments with lack of real progress on Flex have led me to use RE/flex from now on, also because RE/flex is very compatible with Flex. RE/flex is currently beta, but I have not had any issues using it for many complex specs such as Java lexers.
Is it common to post a question on SO just so you can answer yourself?
[P0433](http://wg21.link/p0433)
This would be one of those things that C++17 could really use as a late adoption. It's too bad C++11 didn't have `_t` stuff and that C++14 didn't have `_v` stuff.
The STL does not have matrix multiplication AFAIK. Nor does it have a predefined dot product. Nor does it have a determinant function, nor matrix addition. You must build all those things yourself in the STL.
wow this is actually quite brilliant! I'd vote for it
[removed]
How is it fucking possible to ask these types of questions?
it didn't mention the web at all. i didn't mention a browser-only app either. "absurd to write a webserver and a webinterface" why? it's not rocket gardening.
That's good to hear. It would be great to get a c++17 complete Clang 4.0! Btw, on Linux, libc++ is not a first-class citizen compared to g++7 / libstdc++ (Ubuntu 17.04 pre-release has a ppa) or even Clang++ (the awesome apt.llvm.org nightly builds). Building libc++ from source works but is fragile (linking to g++ compiled Boost packages does not always work). It would be nice if there would be a regularly built libc++ package that works nicely with Boost. 
Hopefully /u/mtclow will see this. (Otherwise I'll ping in offline). PS. Always feel free to file a bug report :-D EDIT: [A Bug has been filed](https://llvm.org/bugs/show_bug.cgi?id=31645)
&gt;&gt; I want to add super simple graphics so that I can save it as an actual program All I could think about was the NEARLY BOTTOMLESS FUN he's going to have adding the super simple graphics. MSVC used to have this little app wizard that generated a horrendous amount of boilerplate for a GUI program. That was before you actually had anything working of course. 
STL actually [has a predefined dot product](http://en.cppreference.com/w/cpp/algorithm/inner_product), but the syntax is perhaps not the best for linear algebra. 
Comments on your template magic! --- You have two different ways of SFINAEing a specific implementation away - one of which works much better in your application. I feel that [this choice](https://github.com/mechacrash/simple-random/blob/master/simple_random.h#L44-L46), where you fail on the return type, is more obscure - because the template magic appears both in the `template` statement and in the trailing return type. [This](https://github.com/mechacrash/simple-random/blob/master/simple_random.h#L53) choice, where you have an unused template parameter, works very well. Particularly, this is easier for people who don't know templates well to read. They can just assume that you are doing that part right, and concentrate on the "classic" signature of the function. But honestly, I think it's easier for everyone to read. --- Since you're very much C++14, you should be using the `_v` versions of the type traits: not std::enable_if_t&lt;std::is_integral&lt;T&gt;::value, T&gt; but rather: std::enable_if_t&lt;std::is_integral_v&lt;T&gt;, T&gt; It's only a tiny change, but it makes things a little more readable. --- Also - I love `auto` and feel that people don't make enough use out of it. You have the reverse problem! - you use it too often in return types. The reason why that is sometimes bad is that the user has no idea what the actual type is without reading through your code - and if you have autogenerated documentation, that code is elsewhere and all they see is a worthless "auto" for the return type. I mean, look at this one: inline auto srand_(std::default_random_engine::result_type const seed = std::random_device{}()) { Surely that's much better as: inline void srand_(std::default_random_engine::result_type const seed = std::random_device{}()) { because it's completely clear what's going on from that one line...? The ones where you use `auto` instead of `T` are a tiny bit sillier even - because it's a little more complicated _and_ a little more typing! :-) --- So if you put together all my suggestions, you might move from this: template &lt;typename T = unsigned&gt; inline auto rand_(T const min, T const max) -&gt; std::enable_if_t&lt;std::is_integral&lt;T&gt;::value, T&gt; { to template &lt;typename T = unsigned, typename = std::enable_if_t&lt;std::is_integral_v&lt;T&gt;&gt;&gt; inline T rand_(T const min, T const max) { which I think is significantly better, not just because it's shorter, but because the signature of the function `rand_` is much easier to work out.
Minor nit: `_v` trait variables are C++17.
Hey people. Please check out the latest update. Now `sqlite_orm` has `WHERE` conditions with &gt;, &lt;, &gt;=, &lt;=, ==, !=, and, or, not and IN. Also parentheses can be used with conditions to specify the priority explicitly. Also there is transactions functionality.
MongoDB has an easy-to-use C++ driver. Check out the [quick-start guide](https://mongodb.github.io/mongo-cxx-driver/mongocxx-v3/tutorial/)
But this is a different discussion. The complaint is that modern compilers are silently removing code deemed to have undefined behaviour. Hence, decision at compile time.
&gt; Qt only wraps very few libraries If you use bundled 3rd party libraries, you risk them being outdated with security issues (and they are). Then you must wait for new Qt release and hope that they fixed those libraries. And if they statically link them (I have no idea how they link those bundled dependencies), you must rebuild whole Qt. It's is just better to build them yourself as dynamic libraries and update them individually when needed (or having a packaging system to do it for you). If you find a security issue in libpng, you can report it in Qt bugtracker, but I don't think they will actually go and fix it in libpng for you, when it really isn't their bug. It will likely be closed as WONTFIX or INVALID. You will have to go to libpng bug tracker and report it there, wait for them to fix it (or provide a patch), then perhaps report to Qt, that a new bug fix for libpng is available so that they release a new Qt version with fixed libpng and then rebuild the Qt - that is too much trouble. &gt; So for you all 3D engines such as Unity, Ogre3D, Unreal are flawed ? It depend's on a use case. If your code uses exceptions and they are exception unsafe, then it can be a problem. Or if you have multiple windows which all have own OpenGL context, it can be a problem, because the functions (including destructors) assume that owning context is set as a current. And quering for a current context and conditionaly setting it in each call could be expensive. I have no idea how those "big" engines solve this global state problem with working RAII without (too big) overhead and without leaking resources. I only know little about Ogre3D - that is exception unsafe and it leeks resources in case exception happens.
While we are at it: http://nosubstance.me/post/dereferencing-null-pointers/
I guess the OP was joking so instead of being butthurt that my precious topic of going offtopic I just joked about the fact that many people say that standard mandated requirements for unordered_map demand the implementation that some people dislike...
PSA: video is almost unwatchable.. it is not meetingcpp level bad ;) , but still...
mongodb and redis are somewhat standard, with redis being better in my opinion (more features, especially with replication), but having an inferior API which can give make utilizing more advanced features tedious. if it's something simple you want to implement, go with mongo.
&gt; If you use bundled 3rd party libraries, you risk them being outdated with security issues (and they are). Then you must wait for new Qt release and hope that they fixed those libraries. And if they statically link them (I have no idea how they link those bundled dependencies), you must rebuild whole Qt. They actually leave you the choice of using a static or dynamic version. 
&gt; Undefined behaviour should be a compiler error. Problem solved. I suspect you're correct, but /u/encyclopedist response does have a point over that quote. The UB you're referring to is not all UB, but just compilation-time detectable UB (you missed delimiting that). Of course, it follows logically that _compilers_ can only _detect_ and warn over _compilation_-time inferences (it could still try to output object code for runtime precautions), but that may have not been clear enough. Also, it may be interesting seeing the [ud2 instruction](http://x86.renejeschke.de/html/file_module_x86_id_318.html), [in action](https://www.reddit.com/r/cpp/comments/5noem9/), a platform specific runtime measure being used for a compile-time detected UB!
Yea, I was actually replying to /u/ivanstepin's comment and was wondering whether it was sarcasm, it probably is, I just wasn't 100% sure! I'm with you all the way :-)
For me premake5 is significantly more comfortable as cmake. Yes Lua is used as configuration language in premake.
I think they are considering introducing a policy of a "language freeze" about one year before the shipping date of the standard to allow some time to introduce corresponding changes to the library.
Postgres
Your post has been automatically removed because it appears to contain profanity or slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5o4z9j/c_why_are_you_doing_this_to_me/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Deleting both is just for exposition. Same with `noexcept` on the destructor. If I were to delete only one, it would be the move constructor, since non-movable types are seldom copyable.
See, I'd still prefer the language feature get in. We've had some nice features get in later on, and library changes aren't even always applicable.
Get rid of the [0x00] =, and [0x01] = ; those are not needed. What errors do you get? 
Just lose the "[0x00] =" part. C++ifying your code would look like: struct var_t { int type; int addr; }; var_t var[] = { {0x02, 0x002452CB}, {0x04, 0x00837C04} }; EDIT: Actually, it appears your code should be fine (though the typedef struct {} name; thing is very C-ish). http://cpp.sh/2zvs7 What are the errors you're seeing?
&gt; Get rid of the [0x00] =, and [0x01] those are the whole point, they are placeholders for defines.
I suggest not blaming the compiler or language when you have false expectations that C++ is a superset of C.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. 
&gt; C++ doesn't support designated initializers for arrays, unfortunately :( but there has got be a way to communicate what i want to the compiler, or not?
right, i could have used better words to describe my problem.
It's not possible to do: std::vector&lt;xxx&gt; v(10); v[N_FOO] = ...; v[N_BAR] = ...; ... or similar? 
possible but inefficent, i want the compiler to have a list of values that it uses at compile time, i dont want to access the list at run time.
Premake also recently released a new official binary, yay.
That's why warnings exist.
Or, if you insist on array.. just put them in any order you like and have a constexpr index by name into the array. I need a bit of more than that to give a satisfying answer.. what is the problem you are trying to solve, what is your end goal? 
Many thanks, I've updated the godbolt sample to use it. I'm reading the [proposal here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0137r1.html) and it seems the most relevant part is: &gt; [ Note: If these conditions are not met, a pointer to the new object can be obtained from a pointer that represents the address of its storage by calling std::launder (18.6 [support.dynamic]). — end note ] So, I'm understanding that I'm not conforming to the proposal [despite it working](https://godbolt.org/g/84l6rA), because I'm passing `nullptr` to `std::launder`, but the standard dictates no object to be there. I wonder whether implementations are going to chase this use for ruling it out at compilation time, a worthless effort in my opinion.
 var_t g_var_object0 { ... }; var_t g_var_super_object { ... }; var_t g_var_john_the_long { ... }; I'm not really sure what you are trying to achieve with this so a bit hard to give good suggestions. You are asking how to do X but I assume it is just means to actually do Y. 
It's the ide I'm comfortable with
This is why I love Reddit some people are super calm some people lose shit over nothing. I'm just trying to make a super simple GUI that looks like a notepad but asks you questions
I've also found the contrast in the recorded video somewhat too low -- what I ended up doing was displaying the slides (&lt;http://www.srl.inf.ethz.ch/workshop2016/Su.pdf&gt;) on another screen while watching; this made it easier to follow the talk, which by itself is quite interesting. There's been another version of the talk @ EPFL (recording quality looks good): https://slideshot.epfl.ch/play/icc_su (slides: &lt;http://web.cs.ucdavis.edu/%7Esu/emi-project/emi-testing.pdf&gt;).
i want to access a foreign process' memory though ptrace and read/write io. but forget all of that detail, what i want(ed) is **to use c++ gimicks to create a function that returns different types depending on (static) call values**. since that seems to not be possible i'll stop my venture into c++ at this point and do it in C with macros. thanks for all of your time.
When is that shipping? Also, abi breaking or not?
&gt; the standard dictates no object to be there New-expressions are defined to no-op rather than initialize an object at `nullptr`. But there are other means, such as using the linker to place a global there or `mmap` to alias the address onto other storage. Going into full-pedantic mode, [expr.new] N4618 §5.3.4/16 only goes as far as saying, "Otherwise, if the allocation function returns null, initialization shall not be done…" but initialization wouldn't be done anyway for `int` since it's trivially-constructible. And the note at ¶18.1 also acknowledges "If no initialization is performed, the object has an indeterminate value." According to a strict reading, `new (ptr) int` creates an uninitialized object equally well whether or not `ptr` is `nulltpr`.
:) Don't take the pedantry too seriously… you're right that it's a gray area. [Basic.compound] does also say that a pointer value can't be both null and referencing an object at the same time. The most likely resolution IMHO is that `launder` will be fixed to require a non-null argument. But, that could be different if the use case were presented convincingly when this is brought to the committee's attention.
&gt; New-expressions are defined to no-op rather than initialize an object at `nullptr`. Why a no-op and not UB? The aforementioned §5.3.4/16 says explicitly "*If the allocation function is a non-allocating form that returns null, the behavior is undefined*" and §18.6.2.3/1-2 make it clear that placement-new always returns exactly the address passed to it. I feel like I'm missing something.
Not ABI breaking. (We have ABI breaking changes we want to do but this was not that) The [first part](https://twitter.com/MalwareMinigun/status/808598636196048896) (made move construction 3x faster) ships with VS2017 (should be in RC.3)). [The](https://twitter.com/MalwareMinigun/status/814196564507799552) [remainder](https://twitter.com/MalwareMinigun/status/813311193255276545) should be in the first minor release after VS2017.
OK, I know, reading the standard is a mess to connect the dots and form a most probable strict judgement. I may have put the spotlight where I didn't want with this :( Thanks for the extra quotations padawan /u/dodheim
Interesting. But the standard placement-new isn't magic; you could just as well define your own (using an overload tag, or an object pointer type rather than `void*`) and then it wouldn't be a non-allocating form.
As dodheim says - _v syntax is C++17 and unsupported still on most stable compilers. I do have a C++17 branch on that repository which adds them, as well as redesigning to make use of constexpr if instead of SFINAE. I feel the argument about whether auto is used too little or too much is a difficult one to make. I'm a strong believer in the "almost always auto" idea, and firmly believe my code is suitable in that regards. An IDE will deduce the type for you if you need to know, but under almost all circumstances I would argue the type need not be known - it is implied through the use of the library and documentation (which doesn't exist here) can make it explicit if need be. ~~I actually prefer the template parameter enable_if, however in this case it causes a signature mismatch for the &lt;bool&gt; specialisation, so the only way to support that was with a trailing return type. Under normal circumstances I would have done it your way~~ just an update on this - I was typing this on my phone without the code on hand and I couldn't completely remember the reason for the trailing return type enable_if. The bool specialisation is something else (that's why I have a version of rand_ that takes no parameters, instead of making the main versions take default parameters in the C++17 build). The reason I use trailing return type is because the floating point and int specialisations would have contained the same signature - you can't overload a function based on template parameters alone. trailing return type resolved this issue - see: https://godbolt.org/g/bPTCtf You can see I've used template parameter enable_if where I can (rand with no parameters).
Hi Steve, do you usually have openings in VC++ team? Or this is rare stuff?
This works, too, and reads better IMO: https://godbolt.org/g/9VKnII Since both work, it's subjective obviously.
I didn't actually know this was a "thing". I quite like the simplicity of the trailing return type and as I already use trailing return type for more conventional code in my other projects, it fits into my current, personal, syntax "style". I'll definitely have a tinker with that format and see if it grows on me though. Thanks for that solution!
I second this, I found it to be the case that people even come to you to offer you a job if you know Qt with C++.
**full disclosure: I'm not of the mind that premake as a library is in any way The Right Thing Todo (tm) for All the Things. Also, much to my frustration, I haven't found a more succinct way to answer your question.** It is my hope that the premake community here in r/cpp is active and growing, though who can say. As a general rule, I have found that tools such as Conan, [Chocolatey](https://chocolatey.org), and - as I was recently pointed to by a coworker - [oneget](https://github.com/OneGet/oneget) have a higher barrier of entry than I would prefer in the sense of a "user story" when interacting with libraries I create. Usually, you are required to have access to an admin account prior to "go time" so that you (the admin) can have installed the necessary prerequisite tooling in order to conduct your business. The advantage of premake - aside from having a tool such as ZPM - is that in my opinion it is the smallest number of loc necessary to locally package a native runtime that can holistically describe your project build settings for (pretty much) any build tool you *already* might have locally installed without requiring access to an admin account. A premake pattern I've started using a lot recently is to build a path to having access to tools such as npm or Conan, so that I don't need to write and maintain a large amount of code in a particular Lua 5.1 dialect. Usually I describe my projects in lua and gtfo without doing too much fancy magic in the library blackbox. ZPM is interesting in that it represents a fairly complete (although in places I might say crude) implementation of a "fully" featured package manager in premake. I wouldn't say that I would necessarily use it, but so far I haven't found a case in my personal projects where I've successfully been able to convince my developer friends to install Conan so that they can acquire a version of Boost **before* they try to clone / build one of the projects I happen to be jazzed about.
code::blocks closes the window after it finishes by default, but you can keep the window after, find this checkbox. http://stackoverflow.com/questions/18040466/why-does-my-codeblock-only-display-output-for-less-than-second
EJDB it works fine, works as embedded db and easy to learn if you know what is mongo https://github.com/Softmotions/ejdb
Yep that's the wiki I was indeed looking at. Couldn't find a comparison with CMake there, any information whether Lua was the language used, nor a usefully "large" example. [This](https://github.com/premake/premake-core/wiki/Tutorial:-Premake-example-with-GLFW-and-OpenGL) is not too bad of an example but doesn't show how to use Boost unfortunately. Additionally it's quite hard to navigate through, and if you search for something, you basically have to click through each link.
Reading the feature matrix, that doesn't look too good for macOS / iOS development: https://github.com/premake/premake-core/wiki/Feature-Matrix CMake can generate good projects for those platforms, which is invaluable when it comes to debugging.
Side rant: teaching cmake and premake about new platforms is a giant pain in the ass. I wish it was much easier.
It's been a while since I was involved with it, but iirc [SimulationCraft](https://github.com/simulationcraft/simc) has a fair amount of virtual calls.
[Chromium](https://crbug.com/580389)? There still might be a room for improvement.
Yes, it does.
Qt, particularly the widgets, relies quite a lot on virtual calls as far as I remember.
I guess you've tried that... CMake toolchain files? Maybe not what you need - I'm lucky to only work on x64.
&gt; I am working on devirtualization in LLVM
I guess I don't understand what that means. Can you ELI5? 
"Devirtualization is an optimization turning polymorphic calls into direct calls." Example: Producing this int test(void) { return 42; } from this struct A { virtual int foo (void) {return 42;} }; int test(void) { struct A a; return a.foo(); } Here's an explanation: https://hubicka.blogspot.com/2014/01/devirtualization-in-c-part-1.html More: https://hubicka.blogspot.com/search/label/devirtualization Edit: These talks are also informative (similarly to the aforementioned blog series, some go into more details on how it's done, which may be helpful when trying to understand the state and limitations of the technique): - 2016 LLVM Developers’ Meeting: P. Padlewski “Devirtualization in LLVM”: https://www.youtube.com/watch?v=qMhV6d3B1Vk&amp;t=1447s - CppCon 2015: Piotr Padlewski "C++ devirtualization in clang": https://www.youtube.com/watch?v=lQAxldEGOys - GNU Tools Cauldron 2014 - Devirtualization in GCC: https://www.youtube.com/watch?v=oN15LjHX9xY / https://gcc.gnu.org/wiki/cauldron2014?action=AttachFile&amp;do=view&amp;target=Jan+Hubicka+-+devirtualization+in+GCC.pdf 
Virtual calls are slightly more expensive than normal method calls. So it'd be nice if compilers could automatically decide when it's unnecessary even when a method is declared virtual. They are working on adding this to LLVM. So they need test on programs with a lot of virtual functions to see if they can detect such cases often enough and provide good speedup.
I get that, i was just wondering if armadillo was generally accepted as a fast and efficient matrix math library. 
[removed]
That's a good solution, valid in C++11/14. In C++17, you may get rid of the recursive template machinery, by using a fold expression: struct accumulator { unsigned long long acc; constexpr accumulator(unsigned long long v) : acc(v) {} constexpr operator unsigned long long () { return acc; } friend constexpr accumulator operator+(accumulator a, char c) { // TODO: add static_assert to check overflow return accumulator((c - '0') + a.acc * 10); } }; template &lt;char... params&gt; unsigned long long operator ""_c() { return accumulator(0) + ... + params; } (not tested with an actual C++17 compiler)
I don't have a great example project, but I do have a devirtualization optimization that I think LLVM could apply. I think all calls to virtual functions on a type in that type's destructor can be devirtualized. GCC seems to do this under O3 based on some cursory testing, but there may be some edge cases I'm not considering. Regardless, good to hear someone is doing some work in this area.
Vtk
&gt; I can't think of any decently complete Qt application which performs as well as an MFC/OWL/VCL or Cocoa. ... [Maya](http://help.autodesk.com/view/MAYAUL/2017/ENU/?guid=__files_GUID_D6567F97_012D_4F45_B252_C3112EBAE859_htm) ? [Guitar Pro](http://blog.qt.io/blog/2010/06/17/how-qt-can-turn-you-into-a-guitar-maestro/) ? [Mendeley](https://en.wikipedia.org/wiki/Mendeley) ? [Parallels Desktop](https://en.wikipedia.org/wiki/Parallels_Desktop_for_Mac) ? [VirtualBox](https://en.wikipedia.org/wiki/VirtualBox) ? [Telegram](https://github.com/telegramdesktop/tdesktop) ? [Mathematica](https://en.wikipedia.org/wiki/Wolfram_Mathematica) ? [AMD Drivers](https://www.qt.io/case-amd/) ? [Adobe software](https://forums.adobe.com/thread/729128) (even if they hide it quite well) ? [CryEngine](https://en.wikipedia.org/wiki/CryEngine) ? [Google Earth](http://stackoverflow.com/questions/9740982/qt-and-google-earth-api) ?
I don't think this question is nonsense at all. Sometimes you have to choose between algorithmic convenience and computational performance. For example, let's recall the "array of structures" vs "structure of arrays" approach. Indeed, today I was fixing some code of mine that used the AoS approach, but failed because data inside the objects was not correctly aligned —my entities were stored into a `std::vector`. Storing the data into a big matrix instead would solve the alignment issue easily, but it would also make the code more difficult to read because of the index and offset calculations. 
&gt; &gt; &gt; &gt; &gt; Qt apps runs poorly when you put them on down-speced machines (i.e. machines similar to many that are out in the real world, that users have to run this software on). Listen, I develop apps with qt on ARM embedded boards with CPUs with a frequency given in megahertz and I still get 1080p at 60 fps. Your problem is elsewhere if you think that Qt causes slowness.
well, I don't agree, it's as counterproductive as to say "stop ascribing meaning to ASCII values" (after all, they collate as groups in some locales). But, TIL about Swift using EGCs as the basic units of a string. That's... intriguing.
&gt; Lastly, Qt Embedded isn't identical to the Qt people use for Application Development on desktop machines. Uh... yes it is... what would be the difference ? Writing to the framebuffer or EGL is just an implementation detail that is given in a platform plugin. Everything else is exactly the same. &gt; You likely are clueless as to how an equivalent app would perform on the same hardware, because you don't have access to the means to run it there I tried a desktop app I work on (funnily enough, an audio sequencer) on a raspberry and it performed correctly, so again, I don't see what you are talking about when you mention "performance problems". Of course X11 on the Pi is less fluid than writing to the framebuffer, but it is the same for any toolkit. &gt; A lot of consumer desktops have iGPUs and many of those iGPUs aren't really fantastic. Consumers also keep PCs for several years. There are still people using 2011-era MacBook Pros out there, as well as Windows Desktops and some Notebooks at that old. There are very few people using, for example, 2011-era smartphones. Do you really think than a 6 year old iGPU is slower than what's on an i.MX 6 (some PowerVR thing IIRC) ? Maybe it is but I really doubt it. &gt; the type of application the OP would be developing OP is developing a notepad. You could run Webkit through Emscripten through Electron and it would still be fast.
There is a premake module for cmake, cleverly named [premake-cmake](https://github.com/TurkeyMan/premake-cmake). I don't personally use cmake yet, though I have always wondered if it is sufficient to integrate the two. Looking through the code, it appears to generate all the appropriate things but still... grain of salt. Would a facility such as this be a viable option in this scenario?
[OpenSceneGraph](http://www.openscenegraph.org/), it has viewer and converter applications as well as some sample data. However most of its virtual calls will depend on runtime data. 
Yup. It's uses a COM-like framework called XPCOM. The entire architecture depends on virtual calls. 
 [ScummVM](https://www.scummvm.org) uses virtual calls for all platform-specific calls (i.e. all the critical ones), and also needs to run on very minimal platforms. It's a good target for your work.
Please tell me this actually works: Using deduction guides as metafunctions http://coliru.stacked-crooked.com/a/6f646667b8fbd701
Have you considered dogfooding it? Clang/LLVM have their fair share of virtual calls.
I'd really like to see this in too. 
&gt;Doing the correct thing is mass duplication of Platform APIs which require the program to load more code into memory, never mind bloating the size of the distributed binaries? Interesting... No, because the platform-specific APIs are either loaded dynamically so only the one you use is loaded, or linked statically and you chose on which platform you will run. &gt; Qt Embedded is designed that way. Again, you get the exact same OpenGL rendering pipeline on desktop or embedded (when you use QtQuick). There is no particular "design" apart from setting up an EGL context, no `#ifdef QT_EMBEDDED`. &gt; Weak Desktop PCs are still delivered applications based (often) on performance tested on much stronger PCs. This will be true whatever the framework, or toolkit and is much more an indicator of developer performance and practices than library performance. &gt; The UI is laggy. Draw performance isn't as good as MFC apps. Please substantiate these claims. This is not my experience. Is there a software that I could try on a low-end machine to see these artefacts ? &gt; The controls do not look fully native. This is a valid gripe, but certainly not a performance issue. &gt; If the application uses many parts of Qt, then it becomes quite heavy and performance suffers in other places. Do you realize how vague this sounds ? What does "many parts" mean ? Do you think that the application will become magically slower the more libraries you call into ? I also sometimes use audacity on windows, linux, and macOS and had more lag than any other apps (and honestly, macos by itself is already pretty laggy - on my laptop (macbook pro 2014) just resizing a Finder window exhibits visible lag; I dual boot linux on this machine and it is butter smooth in comparison) I did not understand the context of your last sentence.
`[text](URL)` to make clickable links (like on github).
I rarely have this many to fill at once but it's not that rare that I hire. Also, I handle a lot of the external hiring for VS overall and there is almost always something open somewhere in VS.
It compiles if you pass "Tag" to the templated constructor of Function, but the resulting types don't look correct. I tried it with decaying the type in the deduction guide but the static asserts still failed. https://godbolt.org/g/ZbTlbM Really cool idea, I like this syntax for metafunctions...
yeah, a static count would be really easy to get with a clang-tidy tool.
I also vote for Chandler Carruth. He is a great speaker 
Don't use pointers unless you are using them for abstraction or avoiding deep copies.
That's the sentiment I've been gathering. It doesn't make sense to use a pointer for a class method if your object can directly access it using dot notation....unfortunately all of the tutorials I've seen use a pointer to access methods, variables... the same way a simpler dot notation could. So that doesn't explain why they should be used. 
Your deduction guides weren't stripping `Type&lt;&gt;`; fixed: https://godbolt.org/g/1VecCL :-]
Big reasons to use pointers in C++: * Interfacing with legacy C libraries. * Creating objects of classes with virtual functions so that polymorphism works (Strongly consider actually using references when passing these objects to other functions). * Creating your own data structures (Use the ones in the standard library instead when suitable). In most cases, the object or function responsible for owning the allocated memory and disposing of it when done should be storing the raw pointer in a smart pointer like std::unique_ptr, which will handle deallocating it automatically, so that you don't have to remember to, and helping prevent memory leaks in the case of things like exceptions. If, as is often the case, you can do something without using a pointer, don't use one. Pointers and dynamic allocation open you up to all sorts of errors if you're not really careful.
Since the OP was talking about game engines, both of those use-cases are likely to show up, especially avoiding deep copies since game assets tend to be very large geometric data structures.
References work better for the latter.
Warning: strong opinion ahead, with bold text and shit. In C++, **references** should be used for polymorphism **wherever possible**. In C++, a pointer means: "this can be null and you need to check it for null". Using pointers nilly-willy is a C habit that needs to **die**.
&gt; why they're used over dot operators for access? If the code already has an object or a reference to it at its disposal, then using a pointer is just making the code more obscure and he who wrote the code is wrong. So your second example is more code to read, with no benefit whatsoever. None. It is also less efficient depending on the optimization level used (that's likely irrelevant in practice). A link to the code you're talking about would be beneficial, I suppose. IMNSHO, people who use more pointers than necessary are one of * inexperienced * old C farts who never learned C++ * lazy
Speaking as a one-time compiler writer, both versions will definitely have the same performance. The compiler absolutely will optimize it away.
Pointers are used because they solve a problem, that problem is usually having an object outlive the scope it was instantiated in. It can also be because the programmer is trying to reduce the amount of stack space by using the heap. It could also be because the programmer doesn't want to have data being copied multiple times. Lastly, lets take a string class. If you use a string and just allocate it on the stack, internally the string will store an array of chars that was allocated on the heap, managed as a pointer. Think of reasons why the string class uses pointers and heap allocation internally and you'll figure out why most people use pointers. The big one being that the string needs to grow and shrink throughout its lifetime.
I have never used it but quasardb is not new... I mean it may have problems, but afaik it has plenty of real paying customers for many many years...
char *foo() { char bar[2] = { 'h', 'i ' }; return bar; } This code is undefined behavior, and the solution to get it to work is: char *foo() { char *bar = new char[ 2 ]; bar[0] = 'h'; bar[1] = 'i '; return bar: } This is exactly why you'd use a pointer.
Small nitpick, passing `new SomeClass()` to `std::make_shared` completely defeats the purpose. Just simply pass no arguments, and you get the exception benefits and you save an allocation.
It is tracked by [LEWG 29](https://issues.isocpp.org/show_bug.cgi?id=29).
You keep focusing on the notation, which is the least interesting part of it. If you need to use a pointer, use a pointer. If you don't need to use a pointer, don't use a pointer. Whatever you use, you use the right notation for it. 
For class methods? What tutorials are these? They sound bizarre.
Actually the opposite is often true. Use of indirection can limit the ability of compilers to see optimization opportunities.
Good catch! I was accidentally using two different methods at the same time. Fixed :)
That's a horrible example. It'll break anything expecting a 0 terminated C style string, and you should be using std::string or std::vector&lt;char&gt; instead and letting them deal with memory management.
That's not a good reason to use a pointer beyond whatever object is responsible for owning the allocated resource. Anything that uses it can likely be passed a reference instead. Edit: I would also argue that game resources fall under my data structure point (it also wasn't meant to be an exhaustive list).
I think you're agreeing &amp;ndash; he's referring to the first code sample, which doesn't use pointers.
Right you are Jim! My mistake. 
True, I added the operation tag later and forgot to pass it as ctor arg too, but you got the idea ;)
Oh, more errors. Thanks! Maybe I should post this as a fist with proper versioning....
How much is "more than necessary"? What you said is true for almost everything in programming, not just pointers, so it's just like saying "hot water is hot". Judging the "right amount" always needs experience and the answer can be different from domain to domain. Using pointers is not bad per-se when the specific programming domain requires them. I can't speak for other domains, but in my 15+ years experience in game programming, I can truthfully say that you can't avoid using tons of pointers. 
Except you're me and you corrupted your Windows installation. Everything fine. But opening links from outside of a browser does nothing.
I kinda disagree with you create nicely and create badly. First, in C++17 your function create badly has no copying nor moving. I think game asset objects should not expose if it need to be held in a pointer or not. By the way, I expect them to hold triangles and vertices or texture pixel in vector or some sort of dynamically allocated array. So really, the size of an asset on the stack should not be *that* big, and moving object is great, so no reallocation. I may be too strict for a simple example however :)
&gt; By the way, I expect them to hold triangles and vertices or texture pixel in vector or some sort of dynamically allocated array. Assets tend to be shared because very often a game will need many copies of a single asset. This is usually handled through reference-counting pointers (nowadays this is ideally done through ``std::shared_ptr``, but I don't know how long it will take most game engines to catch up). Even a vertex array may need to be shared between multiple assets, so it will be passed around in a reference-counting pointer. You could argue that a reference-counting pointer is a container rather than a pointer, and I would agree with that. Still, I think it explains why the OP has witnessed so much pointer-handling in game engine code. &gt; in C++17 your function create badly has no copying nor moving. I assume you mean if I designed ``createObjectBadly()`` such that it returns ``myObject`` by value instead of just being void. In which case, you're right, and I think this would be the case in C++11 as well since that's when move semantics were introduced. Still, there's the whole asset sharing aspect which I didn't want to get into for the sake of brevity. Without using a some kind of reference-counting pointer, you'd have to make a copy of ``myObject`` for each asset that wants authority over its lifespan.
To all those people advocating against the use of pointers, I suggest the following exercise. It's in two step. Step one: write a json file parser without using pointers. Step two: replace the json file with a multi-megabyte file representing a network of thousands of polymorphic objects, instantiated at runtime from a hierarchy of hundreds of classes, where most of the objects hold references to other objects of the network and/or to shared resources that must not be copied in memory. Allow the possibility to have circular dependencies.
&gt;There are two ways of storing data in RAM: the stack and the heap. This is a bit archaic. In C++ there are four storage classes: *automatic*, *dynamic*, *thread-local* and *static*. Usually when people say "stack" and "heap" they mean the first two respectively, ignoring the other two. 
-fstrict-vtable-pointers fix your issue https://godbolt.org/g/TuIUm3 Upcomming clang-4.0 is able to devirtualize both calls also in the constructor. Is this case important to you?
"X out of Y virtual calls have been devirtualized in Firefox" sounds much better than "X out of Y virtual calls have been devirtualizaed from GCC testcases". Testcases from gcc might be a good idea for testing, but they probably can't be compared to "real application"
[removed]
I could, but I don't think it would give me the information that I want. It would probably be good measurement of how "virtual" codebase is, but I actually need data like "how many virtual calls got devirtualized by my optimization. It is true that I could count number of virtual calls with clang-tidy, but this would not count things like inlining etc, which can result in more virtual calls than just counting it from source code.
It sounds like you might nit really understand *the point* of pointers, actually. Your code is valid, but you need to know the difference in what each one does. MyClass myInstance; //creates an instance of the object **on the stack** MyClass* myInstsncePtr = new MyClass(); //creates an object in **the heap** MyClass myObj; MyClass* ptr = &amp;myObj; //this creates an object on the stack, then creates a pointer to it. The stack is where all of your local variables are stored. They stop existing once you exit the stack frame (which generally means the function scope). The stack is a relatively small part of memory where the currently running code and data reside. The heap is the rest of tmyiur available memory. Once you allocate something on the heap,it stays there until you delete it. So unless an object is strictly used as a temporary variable for the current function, it needs to be on the heap. That is, unless you're doing that trendy functional programming nonsense. ;) I recommend you read more about the heap and the stack. Also look into smart pointers. Smart pointers automatically keep up with heap allocated objects and delete them when nothing references them. 
Thank you very much for your review comments. This is the main reason I posted it here, to have some really useful reviews.
Most of those people don't hang out here. /r/programming, on the other hand...
Virtual methods get looked up and resolved when called through a reference just like when called through a pointer.
hehe, I was actually looking at direct calls and haven't noticed that 
I don't think there is as wide a gap in opinion as you might think between SG14 and the rest of the committee. There is a desire to see more of the STL being made available for use to C++ exceptions disabled code. There is a desire that a better alternative to globally disabling C++ exceptions exists. There is a bridge here to be built. Regarding exceptions making for more reliable and readable code, I think you're thinking of the top 1% of programmers and those who aren't constantly in an enormous rush to deliver product. Most need to bang out working code quick, and there is absolutely no doubt that the possibility of exception throw means you need to study a piece of code for longer to decide if it's correct because the potential execution paths aren't written in front of you. As a contractor, I've seen many if not most shops still using a mostly C with bits of C++ writing style. It's boring and an excess of typing effort at one level, but it does shine when you've got average programmers on staff and the code has a decade plus lifespan ahead of it and you are allocated a weekly quota of bug fixes you've got to deliver. Finally, on purely "what's best design", for a while I've been advocating a "sea of noexcept, islands of throw" design pattern for some code bases. In this, extern functions used by code outside a TU are all marked noexcept, but within a TU one throws and catches exceptions. Every extern noexcept function need a catch all try catch clause to prevent the std::terminate. This is a balance between throwing exceptions and error codes and can be very useful. It's not always right for all codebases, but some would say it combines the best of both worlds (and others would say it combines the worst of both worlds, but ce la vie)
See "sea of noexcept, islands of throw" design pattern described above.
&gt; _HASH_MAP_H__ 1&gt; http://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier 3&gt; http://stackoverflow.com/questions/3106110/what-are-move-semantics and http://en.cppreference.com/w/cpp/language/rule_of_three
That came from a conversation with a senior member of the core committee who said now the Expected paper has removed the monadic part, there are about four small things to fix to reconcile it with optional and variant. It's achievable in 2017.
yeah tell me about it :( of all the programming language fanbois, i'd have thought C++ would be slightly more open minded.
And algorithms over recursive deduction guide metafunctions, because I'm a terrible person: https://godbolt.org/g/syHaxu
Fair enough, I've never had to do any of that so that would probably explain why I've never really needed to use pointers. Thanks for the info!
1. It requires C++14. 2. It does not use dynamic storage. 3. It can be used in constant expressions. 4. It is trivially copyable if all its alternatives are trivially copyable, meaning that you can use `memcpy` with objects of this type. That's what I know.
Ability to typedef parameter packs would certainly be neat and also possibly would allow working with them without adding helper specializations.
gcc doesn't warn because it has an [established meaning.](https://gcc.gnu.org/ml/gcc/1999-06n/msg00806.html)
Anyone know if there has been any work on implementing the Range TS yet?
AFAIK, Eric's implementation is the one to use if you want to use Ranges. Eric is the original author and champion of Range proposal and use this implementation for testing it. [https://github.com/ericniebler/range-v3](https://github.com/ericniebler/range-v3) If you are using Visual Studio, there is a ~~fork~~ branch maintained by a Microsoft employee which add workarounds to make it work on Visual Studio 2015. [https://github.com/Microsoft/Range-V3-VS2015](https://github.com/Microsoft/Range-V3-VS2015) EDIT: Changed fork to branch as it better represent what Casey's branch is. See /u/caseycarter comment bellow for more information on it.
This is part of our effort to create a modern C++ build/test/package toolchain. Happy to answer any questions.
Of course the compiler will optimize the above example, but in some cases the compiler will need to emit an indirection (e.g. o.x.y vs. o-&gt;x-&gt;y).
Out of curiosity... how does Ranges depend on Concepts? Didn't c++ have soft concepts for a while? Is this something about Ranges that depends on the Concepts capabilities such as checking for required method implementations and the like?
 class base { virtual void f() { std::cout &lt;&lt; "base"; } } class derived : public base { virtual void f() { std::cout &lt;&lt; "derived"; } } void f(const base&amp; obj) { obj.f(); } f(base()); // prints "base" f(derived()); // prints "derived" However... void f(base obj) { obj.f(); } f(base()); // prints "base" f(derived()); // prints "base" **gasp!** Why not pointers: void f(base* obj) { obj-&gt;f(); } f(nullptr); // formats your hard drive
Oh cool! Any idea why this is not enabled by default under O2 or O3? It doesn't seem like it can cause any problem. Regardless, thanks for pointing it out. I wouldn't say it's particularly important to me, I was just surprised to see that clang wasn't doing it.
This is not horrible, it's an example show casing how you "could" use a pointer. Especially if you know the size of the array externally. I'm not advocating style, merely showing off a possible use case for a pointer to show why "some" people use a pointer. There isn't a "right" way for this problem, there is a "safer" solution or a "hacky and managed" solution, it's still not wrong, just a trade off.
Temporaries are not intrinsically const; they cannot bind to non-const lvalue references, true, but that's not because they're const &amp;ndash; it's because they're rvalues, which is why you _can_ bind them to non-const _rvalue_ references. Consequently, you can invoke non-const member functions on them, as long as they're not lvalue member functions (in terms of ref qualifiers).
Oh they're not too bad. A lot of big C++ codebases look very much like C with a few C++ whistles on top from the public header API level. There are good reasons for that, not least that it makes it easier to hire devs who can work competently on such a codebase.
Could you please explain how inling results in increase in number of virtual calls? 
TL;DR: I am working on it. There might be some misoptimizations caused by introducing extra barriers needed in devirtualization. Watch my talk to find out more, specially this fragment: https://youtu.be/qMhV6d3B1Vk?t=15m25s
I think it's mostly because while we can emulate Concepts with SFINAE, that's not user-friendly enough to be used widely in a Standard library.
Thanks for all of the input. I think the explanations in reference to the stack vs heap, and the need for certain high-memory objects/assets to exist in memory, explains why I see so much pointer use. I can definitely see why a you would need a static mesh of millions of polygons to exist on the heap. This is a very informative thread. BTW...the engine I'm using is Unreal 4. I've also seen this same convention on SFML. 
&gt; I've personally been very impressed with its relaxed constexpr implementation So that means it's non-standard? Does VC generate warnings for that? Just curious.
&gt; VS2017 apparently compiles Ranges v3 without workarounds. Did MS commit to this publicly or something? Because neither the 2017 RC nor the daily build compiles current master of ericniebler/range-v3 (as opposed to Microsoft/Range-V3-VS2015) without immediately puking in meta.hpp... :-/
Means what's non-standard? `constexpr` rules were changed ("relaxed") in C++14, but VC++ 2017 is the first version to implement the new rules; VC++ 2015 has to use C++11 constexpr rules, and even then it's half-broken.
This will work in any case. `Const` or non-`const` - does not matter. The operator does not change any of objects. It creates a completely new one.
I would say `STL = Containers + Iterators + Algorithms`, not just Containers and algorithms.
About a week ago, I started working on a new project. I had to choose a coding style, so I considered both the original and the new function-declaration syntax. After I compared their advantages and disadvantages, I personally came to a conclusion that the new, alternative syntax does not bring me that much. I don't know if I am just getting old, but the new syntax looks rather odd. So, in the end, I decided to stay with the "old", more familiar syntax.
I really like this "new" syntax even if there is cons. It may be longer ("fn" or "[]" instead of auto could reduce a bit that) but i would not be against the deletion of the old syntax (c++50?), the ambiguity that led to the MVP is something i still can't accept. The new syntax could be improved by removing the need of auto when declaring virtual functions: `virtual foo() -&gt; int;` This also give more sense to auto, as a virtual function may not have a virtual specifier.
How close is range-v3 likely to be to what eventually will be standardised? I know it's subject to change, but it's easier to convince co-workers to use range-v3 if the porting to stl2 later will be straightforward.
&gt; but VC++ 2017 is the first version to implement the new rule Really? I thought gcc got that with version 5 back in mid 2015. From what I remember, LLVM beat GCC to full compliance.
Not the first compiler overall; 2017 is the first version of VC++ to implement the new rules.
Well to start with, the very fact of being a range is a concept. Also, the library depends on concepts of iterators which are a central component in the ranges code, like InputIterator, ForwardIterator, Bidirectional and such. Other than that, concepts are quite intensively used throughout the codeline (which is a very good read btw) to document various components of the library.
While disappointed that we're dropping the monadic stuff, since chaining `expected`s gets you a ton of value, at least we can get it in and add more later. Two comments: A bikeshed. Please don't name it `bind()`!! It has nothing to do with `std::bind` and when I first implemented this for work use, everybody hated the name and had no idea what it meant. When I changed my implementation to match Rust's names (`and_then()`), everybody understood it and now everybody uses it. A goal. Rust's `try!` still has expression semantics, unlike the `BOOST_OUTCOME_TRY` macro. That's a language limitation. It'd be very helpful to be able to do something like `try!` or `?` or Haskells `guard` here as a substitute. Don't know how feasible it is.
You tend to see pointers used when the objects are created with dynamic allocation. I've noticed that in C++ I tend to allocate objects on the stack so I can take advantage of RAII, and let the objects handle any dynamic allocation that they need. My application program code in C++ rarely uses any pointers at all, but often the objects in the libraries I write do. In C, you'd also use them if you don't want to pass a copy of a structure -- let's say that you want to pass your data to a function, but you want that function to change the data for the rest of the program. If you pass by copy, the data will just be copied and discarded when the function returns. If you pass by pointer, you can change the data where it lives for the rest of the program. This is all included under the topic of "Pass-by," which warrants some consideration. C++ allows you to pass by copy, pointer or reference and you have to decide which to use for any given data. When doing so, you also have to consider who is responsible for deleting the memory that object uses when you're done with it. Older libraries that have a strong C heritage usually leave that up to the programmer, unless they don't. If you can isolate that responsibility to the objects you've written, the programmer only needs to worry about whether he's going to allocate those objects dynamically or on the stack. You could easily spend a couple of decades just thinking about object ownership in libraries, so don't worry if it seems confusing right now.
In a template-oriented style, it only makes sense for the return type to come after the arguments. It's very common that you want the return type to depend on the argument types. Plus, yeah, MVP sucks.
Well, yes, a legacy codebase is the "rare" reason not to drop pointers. But this is only a history-induced thing, not an expexient design in any way (quite the opposite, I would say). optional is specialized for a reference, it actually has no overhead.
&gt;auto hello = "Hello"s; Hmm. This seems like it only provides some small obscurity over std::string hello = "Hello" Is there any benefit (beyond potential styling) to using "Hello"s in this case?
Thanks, I understood there was a way to have polymorphism without pointers, which is not the case. 
The thisObject and thatImplementation examples don't use pointers at all and are still polymorphic. They're created on the stack and then passed by base class.
good post! i like this alternative style in theory, but i'm not keen on the 'auto' or the conceptually overloaded '-&gt;'. while i freely admit i'm new to these newfangled c++ doohickeys, i'm a bit leary of the ”auto all the things” attitude, and can see this becoming a nightmare similar to \#define and include hell. i'm also not a fan of conceptually overloading operators for new features, like '[]' for lambdas or '-&gt;' for this new style function declaration. this goes against everything i've learned about operator overloading and consistency.
&gt; Usually, you are required to have access to an admin account prior to "go time" That's not the case though with conan. This makes me question if you really checked it out? &gt; It is my hope that the premake community here in r/cpp is active and growing You can use conan with premake.
Nice FUD. For anyone wondering: premake is very much alive and well.
Well, the question is difficult, UIs are generally big complicated things, even if they ought to not be. C++ isn't a language with lots of library fragmentation. Libraries come with different features, issues, and priorities. Many of these libraries can be used together, but GUI libaries in particular are often closed ecosystems. Also, people are touchy about Qt because it has an extra compilation step where it processes certain macros. There are many programmers who find macro usage to be a code smell or otherwise bad for their ability to write a program and maintain it. What kind of questions do you intend for your notepad to ask? (I'm just curious)
`override` goes after the trailing return type because it is not part of the function's type (technically, `noexcept` isn't either until C++17 is done). To know whether you're overriding you need to know the function type; it doesn't make sense for it to be smacked into the middle of it.
Speaking as a developer who has been getting into the dirt with OpenGL and GLSL script files, I'd love to see a language extension like this, but I've yet to find any chatter about it from less than seven months ago.
I'm not sure, but I think I've never used `def` as an identifier in C++. So: #define def auto def foo(int i) -&gt; int { return 42 * int; } I'm done.
As with everything C++, "good judgement" required. I wouldn't exclusively use the new syntax just because it is new. If the return type is sufficiently simple, the good old syntax is just fine. And that is what I recommend. When you start writing "advanced" function declarations with dependent (return) type, the new syntax is necessary. So my personal style fits this grammar `simple-type name(parameter-list) [-&gt; simple-type]`. I don't recommend people trying to be fancier than that -- even when the standard grammar allows it. Writing professional C++ isn't about writing clever code or deploying code patterns that solve clever puzzles. You want your professional C++ to be simple, dull, and boring. Because you don't want to require the next maintainer to be as clever as you were when you wrote the code. That could be you in 6 months. :-)
Everything in the TS is present in range-v3, albeit with differing names in a few cases (TS: `iterator_t&lt;foo&gt;`, rv3: `range_iterator_t&lt;foo&gt;`) where the committee didn't like range-v3's bikeshed color. There are also many features in range-v3 that are not in the TS - most notably all of the view adaptors - that will certainly be proposed in the near future for standardization, likely as a TSv2. We obviously can't say how close the TS is to what will be standardized, let alone how close range-v3 is to what will be standardized, but I think it's likely the big pieces will end up in the standard. There will be algorithms and view adaptors. The syntax for using those things may differ between range-v3 and the eventual C++ standard that incorporates ranges. The names of the specific components will almost certainly differ between range-v3 and that C++ standard. I would say that it's very likely you will have to make automatable transformations to port range-v3 code, but not likely that you will have to redesign codebases completely.
Firefox *is* a GCC testcase.
"fork" has some negative connotations that don't really apply here as well. Range-V3-VS2015 isn't a fork in the "embrace and extend" sense, so much as it is a branch of range-v3 with some very intrusive bug workarounds for the VS2015U3 compiler. We are hopeful (read "a large part of my job is") that there is a smaller and less intrusive set of workarounds that will enable VS2017 to compile range-v3 that will be acceptable to upstream. 
I read the proposal, and I can see some areas where this may be useful, but it feels more like it's expanding the c preprocessor than C++ as a language (which is a matter of opinion). Also, for many of the uses, it feels like a #include would accomplish the same thing, meaning that this doesn't seem to add much. However some of the stuff with binary files looks interesting. The wording could use some work though, it feels difficult to extend and let users implement their own types.
That didn't answer my question. Like - at all. I work with Go where having a nil (null) pointer is valid state. But pointer itself is still invalid. 
Why?
Another pro for the new syntax: Using either leading `auto` or `void` makes it easier to parse the function names as they are generally aligned. e.g. Before: vector&lt;string&gt; get_prime_directives() const; void set_data_spike_extended(bool extended) const override; atomic&lt;bool&gt; const&amp; is_thigh_holster_open() override; After: auto get_prime_directives() const -&gt; vector&lt;string const&gt;; void set_data_spike_extended(bool extended) const override; auto is_thigh_holster_open() -&gt; std::atomic&lt;bool&gt; const&amp; override; 
I liked the article as soon as I read the title (pros and cons, exactly what I like). But I was surprised to find that the pros outweighed the cons except for the last con: &gt; this may cause that your co-workers will want to hit you with a stick :).
Probably because you were focusing on your usecase without being explicit, I thought you were talking about C for example, a low level unsafe language. I think I was also unable to parse your second line fully, sorry :-/ But I'm guessing it's more or less in the same reasoning as C/C++: you can set a pointer variable to null (valid), you can't derefence it (invalid). I dunno whether it's usual for the Go compiler to try having basic inference for when you're calling a method and check whether you're calling it on a null pointer or not, at translation, and hence 1: warn you, 2: do whatever, given it's undefined behavior, or, if no inference 3: runtime null pointer exception. Despite this, in Go language context, direct access to the address space and such kind of machine level matter is not usually related with the pointers you obtain from objects, but still, you could have a kind of alien hibrid high/low level programming language that worked like Go, defining a null pointer, and allocating objects for you in whatever address but promissing to never allocate them at the null pointer address, but that also allowed you to access any address value, if you cared to put data at the null address (or even recreate objects to [_without null checks_] call methods on), your call, because "my" alien objects won't be there anyway and "I" (on high level) will not touch what's in the address anyway. It's a promissed convention of the spec/implementation, but that doesn't interfere on your actions if you peer there in low level means of the language. If you get access violation, etc, it's your call. This would just be an unsafe version of what I described previously, unsafe because you still have nulls exposed on high level, and have to deal with them, can still dereference them, not hidden in the implementation of optionals, for example. The address space discussion is more targeted to system programming languages that aims to have an efficient mapping of the machine while not restricting its access.
Sums it up pretty well, and I use the new syntax in precisely the places that he listed as "pros" and use the old syntax otherwise (because most other cases appear in the "cons" section). I prefer the old style, but as soon as it'll save me from repeating the class name or gives me access to function arguments, i'll use the new style.
I was actually in the standard trying to prove you wrong... proved myself wrong. The virtual call is only elided for qualified ID member function lookups (e.g. `b-&gt;A::foo(4)`). Oops!
I like it, it reminds me of Ocaml or Haskell. Mostly Haskell.
Any keyword that is a keyword in C++ but not C already breaks compatibility.
I think math did it first. A simple function like `y = f(x)` is also talked about as `f: R -&gt; R` a function that maps elements from the set of reals to elements of the set of reals.
The problem is that you instantly break any code out in the wild that has used "def" as an identifier. It's why C++ is so stringent with new keywords.
They can clash with implementation code since implementers have free reign with leading underscore identifiers in the global namespace.
Not exactly. If I remember correctly, there was a paper proposing a system for soft keywords (existing in `std` rather than globally) that was shot down because adding a new keyword should not be taken lightly. C# has been making all new keywords contextual for quite a while now, so it's conceivable that C++ could do that for at least some, and there are alternatives like this proposal. If the committee wanted to add keywords without breaking code, they could have the means, but it seems there's an intrinsic aversion to adding keywords.
&gt; I'm curious what you are getting at with if (std::ref(predicate)(decltype(*it)(*it))) instead of predicate(*it) I found that `predicate(*it)` doesn't work if the passed in predicate is a pointer to member function, and it was quite important to me that I be able to use that. As far as I'm aware, `std::invoke` is the best way to handle that, but unfortunately that's C++14 and I still need to be C++11 compatible, so a kindly individual on stackoverflow mentioned that I could accomplish the same thing using `std::ref`. Frankly I don't quite understand why the best thing to do is `std::ref(predicate)(decltype(*it)(*it))` instead of `std::ref(predicate)(*it)`but it fixes some compiler errors. If you can enlighten me on that, please do! &gt; The using ItType = ... can largely be removed if you just use auto for the iterator types I did notice that, but haven't changed it yet. &gt; but most of this looks like it could be written using a for (auto&amp;&amp; e : list) instead Could you explain to me why it's better to use `auto &amp;&amp; e` instead of `auto &amp; e` / `auto const &amp; e`? Also I avoided using range based for loops because apparently they have a negative impact on performance when used with Qt's structures. I'm not 100% sure if that's true, or still true for the latest version of Qt, but I'm still using Qt 5.5.1 and wanted to play it safe. &gt; `std::begin` I was not aware of the existence of `std::begin`. Thanks for the tip! &gt; You should undef your macros when you're done, but be aware of the restrictions on names. any symbol containing two consecutive underscores is reserved for the implementation, as is any symbol beginning with an underscore followed by a capital letter. I was not aware of that either -- will fix it. I thought I was just being clever and picking a name even less likely to be used by anyone. &gt; Why not forward to std::all_of or std::any_of? You know, I thought about doing that but then didn't. I guess I wanted to reinvent the wheel? Probably better to use the standard library. &gt; Things like this const typename std::decay&lt;decltype(*list.begin())&gt;::type are best left to aliases. I was not aware that I could use aliases in this fashion. Thanks for all the tips! Also, CPPItertools looks cool. Eventually I'll be able to start using C++14, and since part of the point of my project was to give me C++ versions of some python functions, I may make use of CPPItertools as well.
[removed]
I would have been bitten by this if I hadn't read this article.
Thanks for the answer, I'd like to add that Haskell has a much nicer story of how much further concepts can be taken at run-time. Parametric polymorphism combined with type classes in Haskell are almost as expressive as the many dirty tricks you can pull-off with undisciplined C++ templates, but they can still be type-erased to be passed around at run-time.
It'll ask like what's your age? Then it'll return the value 
It isn't about the 1 letter. It's about keywords having clear and consistent meanings. It's pretty bizarre that the `auto` keyword is used for declaring functions even when there is no automatic stuff happening anywhere. `def` or `fn` or `func`or whatever else would have been better. (I assume the only reason `auto` was chosen for the standard was so that they didn't have to introduce a new keyword which could potentially break a lot of old code.)
Write your own language. Dunno why but most people think it's black magic. Auto increments your wizard level.
I've started using this syntax in my side projects, and have been liking it - though I use: \#define func auto e.g., func foo(int i) -&gt; int {...} The virtual auto foo() const noexcept -&gt; int override; part of the language is pretty unfortunate though. Maybe it would be better if override went at the start near virtual: virtual override func foo() const noexcept -&gt; int; or even: func foo() const -&gt; int [virtual override, noexcept] {...blah...}
How about: override func foo() const -&gt; int Since override must go with virtual anyway, why not replace it.
Anything really, what people usually look at is the quality of the code, not the function. Also (but I guess it depends on where you live), given the high demand for C++ programmers and the fairly little supply, I doubt you'll have serious difficulties in getting a job.
Do not avoid range-based for loop just because of Qt. Qt collection classes are copy-on-write and since the range-based for uses begin/end instead of cbegin/cend, calling them will copy the original collection as if it is going to be modified. It will happen whenever you get an iterator, and not a const iterator to a Qt collection that is shared. This happens only if the collection is not `const` (meaning you are safe if you got it as a const-ref function argument). Now, if somebody does not want that to happen, they should use `qAsConst` when passing the collection to the range-for as shown in the Qt docs [1] [1] http://doc.qt.io/qt-5/qtglobal.html#qAsConst
Concepts (and Modules) should reduce the issue significantly by the time the stl2 makes it to the standard. It is my understanding that the current range-v3 make use of some clever &amp; complex template / macro tricks to emulate concepts.
Correct, `std::optional` dropped the support for references that boost::optional had. I also found that odd when I discovered it, but the more I think about it, the more I agree. By the way, I would hate to see code like this: void f(optional&lt;MyType&amp;&gt; ref); // not std::optional! void g(std::shared_ptr&lt;MyType&gt; ptr) { // ptr may be null here, need to call f... if (ptr) f(*ptr); else f(nullopt); // or whatever } In this scenario, using `MyType*` is just as good, with `observer_ptr&lt;MyType&gt;` being slightly better.
The leading-underscore rule for `operator ""` is reversed. Since none of the literals in `std::literals` has a leading underscore, it can't clash with your stuff.
Some opensource contribution, a little OS driver, something with a DSL (domain specific language), using later c++ standards, something having GPGPU, deployment in a free microinstance in AWS.
Oh I see. I misread your post.
Hi, some-time hiring manager here (amongst other things). In my experience, the whole interview process takes between two to four hours, depending on company, the amount of scrutiny they wish to apply to their candidates, and the amount of scrutiny that candidates will subject themselves to. It's ridiculously difficult to assess talent, personality, and general "fit" in that time: that process frequently takes months. All we really do is use a set of evolving heuristics to make that assessment in the time we're given. So having a project -- any project -- available for scrutiny outside of that time eases the burden considerably. It doesn't necessarily make you a sure bet, but it makes you far less of a gamble that another similar candidate would be. It doesn't really matter what the project is to the recruiter, and it doesn't have to be a big project. But if you focus on making the project coherent, complete, and comprehensible (i.e. its purpose is easy to understand and not horribly waffly fluff, it fulfils the purpose to a reasonable level of quality, and it can be inspected and understood by someone who is not you), then the project will take you far.
Perhaps look at contributing to include os. It will marry your operating systems degree with c++ http://www.includeos.org
Cited from that same feature matrix: *Porting of Xcode and CodeLite have begun and are mostly working.* It's in the making, and currently works quite well on the projects that I have, running tests on Travis. Most of the problems I experienced (not a lot) are in the minor differences that the C++ standard has on OSX, I have not yet experienced any problems with premake on OSX. I mostly work on unix and windows, so platform specific things for OSX are sometimes hard to detect, but can be detected if you have automated tests on a build server like Travis. To be specific: I once had a problem that the definition of size_t matched with neither uint32_t nor uint64_t in a template specialization on OSX, but it did match on both unix and windows. But then again, the C++ documentation clearly states that size_t is implementation defined.
I found this video of a talk Howard gave at Bloomberg last year, which I haven't seen shared before on this sub, and I figured might be interesting. While a lot of the discussion about move semantics won't be new to readers of /r/cpp, one of the reasons for sharing it is that in the second half of the video, Howard comes out very strongly against the "copy-swap idiom", i.e. implementing a combined copy/move assignment operator as T&amp; operator=(T other) { swap(*this, other); return *this; } which is often advocated by (amongst others) Sean Parent. Howard also states that it's a "myth" (his words) that all you can safely do with a moved-from object is assign to it or destruct it, which again something that comes up in Sean's talks. Having two renowned and highly respected C++ experts giving completely conflicting information is rather unfortunate, it must be said.
This was added very recently, so yes :) So recently even, that it did not make it to the docs yet, but the feature is present. We will add it to the docs soon.
Right, I forgot this was for UDL identifiers. My mind saw the leading underscore bit and jumped straight to normal identifiers. 
We feel your pain. We've gotten most of our 11/14 feature work complete, though. Have you tried a recent compiler and the /permissive- option? More info here: https://blogs.msdn.microsoft.com/vcblog/2016/11/16/permissive-switch/
My solution where I need something like it is to generate an intermediate file for inclusion using a build rule in my build system, then #include that file.
Doesn't the operator await from the coroutine proposal take care of the monadic stuff? I seem to recollect that await can be used with any monad.
"override" implies "virtual", so "virtual is indeed redundrant here. Previous comments did not talk about "final" at all. 
does boost range library do the same thing or is something completely different? thanks.
New and delete are not compiler independent.
I disagree. A great many of the times I've used `first` or `last` with a container, I want a specific default value when the container is empty. Hence the reason I implemented `first` and `last` in this manner. It results in my code being much more compact and readable, and allows me to chain `first` or `last` with something else without having to resort to a ternary operator. It's not a source of subtle bugs if I use these functions purposefully. And if I want exceptions or to know that the element did indeed come from container, I can use any of the other available methods for doing so. Also note that I'm not using boost or C++17 so I don't have access to an optional type.
Thanks for clearing that up. A number of my functions could be simplified using ranged for.
&gt; (I assume the only reason auto was chosen for the standard was so that they didn't have to introduce a new keyword which could potentially break a lot of old code.) I believe so yeah. Lots of code has things like fn or func in it already, so using either of those would break lots, something the C++ committee are very adverse to because they want to avoid language fragmentation. I think it's the same reason we got the mildly ugly decltype, too, since it was not found in any code in the wild. 
That would be a good substitution to simplify my work in the short term. How would I do that in Visual Studio?
LOL nice pun. Thank you for the pointers. It is not for an assignment. I am doing it to help someone out with a project for work. I figured I could learn something in the process.
It's not guaranteed that you can use `delete` with code compiled with one compiler with code that has allocated using `new` compiled with another. In fact, none of the memory allocation functions, from malloc/free on up, can be used like this. And I have to say that this exercise seems futile - if you are using C++, you should be using smart pointers; end of story.
Why are you using VB for a C++ assignment?
I also use Eclipse Neon.2. But I couldn't see where to start a dynamic-link library in Eclipse. I am here to learn so if you have a suggestion I would like to hear it.
That doesn't mean it's advisable to make compatibility even worse. Removing the old style of declaring function return types would make it far less feasible to have shared C/C++ header files.
&gt; Due to dll boundary issues, using smart pointers, memory allocated in one dll cannot be deallocated in another dll unless they were compiled using the same compiler. As for new/deletes, they are compiler independent. Euh, no, that's not true, how did you figure that?
I noticed on one slide that `std::move(x.m_)` is used. I think that this is a mistake and `std::move(x).m_` should be used as a first choice unless you are absolutely sure the first is what you want. The compiler is smarter when you use the second one and it knows not to move if `m_` is a reference, for example.
I think that what he meant was that you can have new/delete pointers (i.e. raw pointers) exposed through a public API of a DLL, while you cannot have this for smart pointers.
&gt; I think that what he meant was that you can have new/delete pointers (i.e. raw pointers) exposed through a public API of a DLL Of course you can do this, but you cannot reliably delete those pointers vi different compilers, as I pointed out, any more than you can reliably use smart pointers or malloc and free with different compilers.
&gt; if the class owns a heap-allocated array ... This is subtly incorrect. A more correct clause might read something like: &gt; If the class directly owns a heap-allocated array, or indirectly owns the same by having members or bases such as std::vector or std::string, or has members or bases that may directly or indirectly own a heap-allocated array ... I.e. If you have vectors or strings _anywhere_ in your class layout, this issue is going to bite. While I'm here, you should not assert on self-move-assignment. Your self-move-assignment should leave a valid value, though it does not need to be a no-op like self-copy-assignment. A self-move-assignment that mutates the value still allows for a self-swap to be a (expensive) no-op. And a value-preserving self-swap is desired.
Huge congrats!! I love this podcast, keep it up!
The links (there are six) following "In case you don't know but is still curious for possible real situations" doesn't serve as example for you?
What Howard said. I think that the case against unified assignment should be made far stronger (it should not be referred to as "canonical" which has positive connotations). If it must be mentioned, it should be mentioned as "you may have seen this thing, but it's bad because blah, so don't do it".
[removed]
&gt; These are all things that I was told by my colleague. Your colleague is not an oracle. He can be wrong. In this case, he was. That's all. Back to square one on that, as the whole thing was based on a wrong assumption. Hopefully your workplace doesn't turn such things into big deals: anyone can be wrong, thus the way forward is to realize what was wrong, learn the truth, and move on.
Yes.
You paint a bleak picture that's fortunately wrong. All that copy-on-write does is lazy copies: they are deferred as long as possible. `begin` and `end` will only perform deep copy if the value is shared, so you're only paying the price of the deferred deep copy that was postponed thus far but now is inevitable. Had you used a non-Qt collection, you'd have already paid the cost of the copy: it wouldn't be deferred for you. So what you refer to isn't really an issue. You're supposed to write the code defensively, so if you don't intend to modify a collection, you should be iterating over a constant value or constant reference anyway. 
Thanks for the kick in the pants. I've just made it available here: http://howardhinnant.github.io/bloomberg_2016.pdf
https://msdn.microsoft.com/en-us/library/h7dhf0ty.aspx
 what about `register`.
It's a shame that disarming static_assert's in untaken branches didn't make it in. That would have been useful.
_Dynamic_ throw-specifications (`throw(typeid, typeid, ...)`) are removed; `noexcept` (which is what's being made part of the signature) is a separate thing.
&gt; Please share with me the valuable information that you have. Euh... that's the hard part, and I am not willing, because this is an internet forum where I come to engage my brain a bit, not do somebody's homework. It's not even valuable information, it's knowledge that you need, but you are likely not to know what you do not know (and so is your colleague if he told you above, which makes it harder)... I will tell you this: if you link to your C and C++ runtimes dynamically, then you can allocate stuff in one module and free it in another with either malloc/free or unique ptr. So from that perspective, your colleague is flat out wrong. tl;dr: you're asking for too much. Read stuff, **try** stuff, learn. When you have a specific problem, ask questions on dedicated sites.
I'm still learning C++. What the fuck does this mean?
That paper is irrelevant at this point; the changes have already been incorporated into the standard, the latest revision of which is [N4618](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4618.pdf). The latest relevant paper is probably [P0003R5](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0003r5.html).
Some [make demons fly out of your nose](https://en.wikipedia.org/wiki/Nasal_demons)!
They can always add it later if deemed necessary.
Featuring: links to a site with text so tiny I must zoom in to 200% to have a chance of reading it.
The example might be less distracting while still being correct if you remove "throw(int)" from the first declaration. 
The examples in section [init-statements for if and switch](http://www.bfilipek.com/2017/01/cpp17features.html#init-statements-for-if-and-switch) are kind of moot, in my opinion. In fact, already in C++11 you can write this: if (auto val = GetValue()) // on success else // on false... where `var` doesn't leak and is contextually converted to bool right after initialization. The innovation in C++17 is that you can now have arbitrary test expressions, so a better example of the new feature might have been this: if (auto val = GetValue(); val != 42) // on success else // on false... 
This is a list of new features being introduced in the next version of C++ standard, due to be released in 2017 (hence the name C++17). What you are learning now is (hopefully) C++11 or 14 (if not and you are using some old book and learning C++98/03, I strongly recommend to switch to at least 11), so this is an additional list of things for you to learn. 
"Later" in this case means 2020 at the earliest (next standard release), so not exactly "soon".
Thanks for taking the time to reply. This should hopefully be enough that I can start experimenting with range-v3 at work.
More likely they'll alias it to std1. So you could use either. They don't seem to like large breaking changes from version to version.
This page has a share sidebar that covers text, and a newsletter sign-up popup, that makes it EXTREMELY annoying to read on mobile. 
I'm learning from a c++ 14 book... is there a place where I could learn features of the new c++ versions? I'd really like to study them once I'm done
thanks for this suggestion, updated in https://github.com/fenbf/cpp17features/commit/68e19684d38882158bb532d00f02f34b7cc978c6 so tiny thing, but you're right that it could be confusing. 
Thats exactly the purpose of this post: to collect all the changes in a form that would be easier to learn incrementally provided you are already familiar with C++14. Note: C++14 is the current version (new versions are released every 3 years nowdays). The other sources are: - The official [isocpp.org](https://isocpp.org/) website. - [cppreference](http://en.cppreference.com/w/) already includes many C++17 features. - This exact subreddit - Blogs of various C++ committee members and C++ experts around the web (these are typically linked from this subreddit and isocpp.org).
you can always lobby your compiler vendors in the mean time, if it is implemented somewhere it will have more chance to make it in the standard
It does, but really rather inefficiently. Unless Gor listened to the feedback I gave him and has since fixed it.
&gt; A bikeshed. Please don't name it bind()!! It has nothing to do with std::bind and when I first implemented this for work use, everybody hated the name and had no idea what it meant. When I changed my implementation to match Rust's names (and_then()), everybody understood it and now everybody uses it. I hate to be that guy, but the monadic bind operation is not the "and then" operation. Outcome's monad provides both a bind() and a then() operation. They are quite similar, but not identical. Regarding your bikeshed, if you don't understand monadic programming, don't define the BOOST_OUTCOME_ENABLE_ADVANCED macro which turns that part on. &gt; A goal. Rust's try! still has expression semantics, unlike the BOOST_OUTCOME_TRY macro. That's a language limitation. It'd be very helpful to be able to do something like try! or ? or Haskells guard here as a substitute. Don't know how feasible it is. The lack of expression semantics on control flow permeates C++ in general. I agree it's unfortunate that you can't do if(try expr) {}, but it does at least match the rest of C++ e.g. you can't do if(for(...) {}) {}.
When one can expect to hear back? Is there any way to check the status of the application?
I had been told by a senior Microsoft employee that it was a soft goal for VS2017. That was at CppCon, so I guess given Casey's reply that's no longer a goal for this edition of VS2017. I will say though that VS2017 does compile all my C++ 14 constexpr without issue which is better than GCC 6 or 7 can manage. VS2017 still ICEs with my template variable usage, and yes that's on Microsoft Connect where it has seen no love yet :(
Just in case anyone that reads the link isn't aware, both GCC and Clang have compilers that will compile all of these attributes, GCC 7 being c++17 feature-complete. (I am not sure about the feature-complete status of Clang)
&gt; I am not sure about the feature-complete status of Clang http://clang.llvm.org/cxx_status.html
&gt; So my feeling is that in the general case, `std::move(s.m)` is probably what you want. I disagree &amp;ndash; `std::move(s.m)` is sometimes correct; `std::move(s).m` is always correct, and works correctly with member functions overloaded by ref-qualifier. If anything, the former rings alarm bells to me; why would I want to move only one member of an lvalue object? As a matter of clarity and possibly correctness, the entire object should be an rvalue, not just one single subobject; otherwise I'm asking for invariant violations (partially-moved objects). EDIT: See idiomatic usage of `std::get` for lvalue vs. rvalue tuples/arrays in a perfect-forwarding scenario; one gives the _outer_ object (tuple/array) the correct value category in order to access the subobject (element) with the correct value category. This is how it should be. EDIT 2: Typos
I thought it's in c++14 or c++17, but I can't find it. Maybe it's named differently.
Yea I had no idea he was telling me lies! Thanks h-jay. I will go talk to him about this. It won't end up being a big deal, but hey if I can engage my brain and learn something in the process it's a plus for me.
You've overestimated what I was asking for then. I just wanted any piece of valuable information you had, not everything. I am obviously reading through a textbook (thanks Amazon Prime). And using the internet to learn as much as I can. I didn't ask you to do homework either; is anyone in school here? I was looking for some direction, maybe a helpful article or forum, but if you're not willing that is fine. I will remember the small nugget of info you've given me. &gt;if you link to your C and C++ runtimes dynamically, then you can allocate stuff in one module and free it in another with either malloc/free or unique ptr. So thank you for that.
&gt; If you have vectors or strings anywhere in your class layout, this issue is going to bite that's a very good point! Updated [that page](http://en.cppreference.com/w/cpp/language/operators#Assignment_operator).
Awesome work!
Sigh. They've not published the attachment. I'll see if I can upload a copy to somewhere public and link to it.
&gt; See idiomatic usage of std::get for lvalue vs. rvalue tuples/arrays in a perfect-forwarding scenario; one gives the outer object (tuple/array) the correct value category in order to access the subobject (element) with the correct value category. This is how it should be. TIL, as they say on Reddit. Thanks :)
&gt; But the API is off by default, so if you are actively enabling it, you will know what monadic bind is. Is it _definitely_ going to remain in the library, even if disabled? Is it going to be as well-documented as the rest of the library? I'd hate to get attached to this stepchild functionality just to have it disappear because a handful of people on the Boost ML vocally "don't get it". I get it.
&gt; ... because we still support C++98. My condolences.
&gt; I just wanted any piece of valuable information you had, not everything A lot of what I (and kthers) know about this is likely to be valuable, but from your question it is pretty clear that you really don't know what you're doing, don't know what you need, and whoever tries to help you will be shooting in the dark. In other words, you made a low-effort fishing attempt. Not cool, and not appropriate for this sub either.
I'll quarrel with the "always". It's not correct with an rvalue reference member. Granted, these are almost certainly even rarer.
Sorry, yes, I meant alias std1 to std I was just thinking about them in reverse due to the whole "rename std" thing. Though I didn't realize the specialization issue. Thanks!
That "senior Microsoft employee" might have been me. It's part of my job to drive our dev team toward unreasonable goals :) But I'm still hoping that we will get Eric's version of Range-v3 compiling properly with MSVC in 2017. This will require bug fixes in MSVC, of course, but also some "smaller and less intrusive...workarounds...will be acceptable to upstream", to quote /u/CaseyCarter. Please email me the attachments to your connect issue or stick them on a DropBox/OneDrive somewhere where I can get them. My email is firstname.lastname@Microsoft.com. I can't guarantee a fix in any particular timeframe but I can guarantee you that I'll be loud about your ICEs to the right people. 
I would not consider Boost.Outcome's `bind` to be monadic bind. It does too many additional unrelated things. This makes for a very confusing interface. Also, `&gt;&gt;` in Haskell isn't even bind. `&gt;&gt;=` is (but associates the wrong way, so I understand where `&gt;&gt;` comes from) &gt; if you supply outcome&lt;A&gt; to a [](A a) { return outcome&lt;B&gt;(); } you'll get an outcome&lt;B&gt;() as per traditional bind. That is indeed `bind()`, or Rust's `and_then()`. &gt; If however you bind a [](error_code ec){} then if and only if the incoming monad is errored, then the function is called, else the monad is passed through This is not bind. Rust calls this [`or_else()`](https://doc.rust-lang.org/std/result/enum.Result.html#method.or_else) (if you're returning an outcome) or [`map_err()`](https://doc.rust-lang.org/std/result/enum.Result.html#method.map_err) (if you're not), which are both better names. &gt; There are additional overloads for [](A &amp;&amp;a){}, [](outcome&lt;A&gt;){} and so on letting you move, perfectly forward as well as copy from the input monad. This should result automatically from ref-qualifications. If I want to move from the underlying outcome, I should move the underlying outcome. &gt; I would agree if monadic programming were of any interest to 98% of C++ programmers. It also then depends on how you word the question. My users aren't interested in "monadic programming," but they really like using the `Result&lt;T,E&gt;` that I wrote, and use all the `and_then` and `map` functions regularly. Just make the interface friendlier. 
&gt; I'm still hoping that we will get Eric's version of Range-v3 compiling properly with MSVC in 2017. Just to make it perfectly clear to readers that we aren't making contradictory statements: I'm claiming that the compiler in VS2017 *at release* will likely not compile upstream range-v3, /u/AndrewPardoe - and myself as well, for that matter - is hopeful that an update released in the calendar year 2017 will compile upstream range-v3. 
I'd also note that the next minor release of Catch should be ~3 times faster in usual usage (no `-s` flag, tests are passing). The improvements are already in a branch, but we want to try releasing a 1.6.1 with minor bugfixes first.
&gt;from your question it is pretty clear that you really don't know what you're doing Which is why I came here in the first place. &gt;I am a novice C++ programming looking for some direction. It is clear to me that you are able to read. &gt;I need some ideas and maybe a starting point on how to create these two libraries in Visual Studio. I obviously know what I need. I have already created my two dlls I just wanted an idea for what type of functionality I should give them. I can ask for ideas and help if I want, it's not up to you what is appropriate and what isn't. You are not capable of helping, so don't try. 
What I meant was that it does not have to be C++, it can be C too (or other similar languages). At times I have worked with recruitment, and in my experience it is not as important to show proficiency in a specific languages/dialect/library/tool as it is to show skills in code quality and understanding the underlying differences between e.g. compiled vs interpreted languages and non-GC vs GC languages. Granted, Linux is a high profile project and I didn't imply that it's a minimum requirement (it was just an example of a high quality operating system project). Often contributions or personal patches to a well known project can be just as impressive as a complete personal project (it shows that you can familiarize yourself with a large/unknown code base, which is often a big plus if you are going to start working at a company with an existing code base).
/u/berium, I've fixed this for VS 2017 Update 1. Thanks again for the report.
Yes, I meant 2017 the year, not any particular product or update release. Thanks, Casey, for the clarification. 
Usually there are specific library features that someone implements before major compilers manage to release it, but I haven't seen anyone doing it in the std namespace. One example is "just threads" which was a drop-in replacement implementation of C++11 threads before it was available everywhere else. A quick look at their [website](http://www.stdthread.co.uk/) reveals that they are still active, and now implementing stuff from the Concurrency TS. There is also boost, which is unique to the C++ world in that it has a huge and direct influence on what ends up in the standard. At the same time, Boost libraries are expected to work on a large variety of compilers (even if in the implementation this requires lots of ugly workarounds). Consequently, many cool library features are available in Boost for old compilers. A good and well-known example is `boost::shared_ptr`.
If you aren't the toolchain vendor, you shouldn't be putting things in std. Those aren't your symbols, so you shouldn't define them. What happens when two different libraries use different shims for the same feature? You might get compilation errors, or you may get subtle ODR violations. Back ported features should go in an independent namespace, like boost, or your_org_here. You can then tear out your implementation and put in a "using std::thing;" declaration at a future time.
thanks for this description, I've updated the repo, https://github.com/fenbf/cpp17features/commit/43173a798b0a75fd54452f93ca2d1047ea9ab89a
Anyone know of a list like this, but sorted by compiler support? E.g. features with the (average) lowest compiler version numbers come first. Preferably with C++11/14 included. Would be super useful for people like me who have to weigh the use of each feature vs the amount of people I will piss off if I do :)
Isn't there a single Boost header that goes ahead and does all the defines for you?
Don't forget runtime polymorphism.
boost is the closest thing c++ has to that. 
 auto a = std::array&lt;std::string_view&gt;{"", "", ""}; Is something like this possible? (Perhaps partial class template deduction.)
I collected together C++11/14 implementations of `any`, `optional`, `string_view` and `variant` to make it easy to use them with older compilers. I guess this is the kind of thing you're looking for? The repository can be found [here](https://github.com/tcbrindle/cpp17_headers). Not that these use namespace `stx` ( for "standard extensions"), not `std`.
Yes that is indeed a possibility, you have a point there. But nevertheless, I think the workflow for testing your project is different. With ZPM, the main premake file in the repository is aimed at building and testing the project itself, while it has a separate premake file for publishing, defining how other projects should handle the package. With Conan, the main build file (with or without premake) is aimed at publishing the package, and it is indeed possible to have a sub-directory (you could call it a sub-project), that is intended for testing your project. In this setting, you have to package the project first before you test it. So to put it really crudely: * With ZPM, the aim is more: first test, then publish. * With Conan, the aim is more: first publish, then test. I know the difference is more subtle than this, but this is to highlight the difference a bit more. I wouldn't claim either approach is better or worse, that depends on your personal preference and what works best for you or your team.
&gt; These days, most new features are implemented in one or more major compilers before the next standard ships -- the opposite of the way it used to be. Really ? standardisation of C++98 came much later than compilers. And C++11 basically standardised a part of boost.
Partial deduction is forbidden, apparently. You'd need to change `std::array` to have a constructor that deduced the type, like this: https://godbolt.org/g/9EUIcf
&gt; With Conan, the aim is more: first publish, then test. No, you don't have to publish your package to test it.
I believe the approach for the specific example given is to do something like: using namespace std::literals; auto a = std::array{""sv, ""sv, ""sv}; Relying on http://en.cppreference.com/w/cpp/language/user_literal and the C++17 addition of `operator""sv` of course.
maybe its me or maybe its the compiler but visual studio 2015 says that std::move(s).x is a lvalue template&lt;typename T&gt; Type; struct S { int x = 0; }; S s; Type&lt;decltype(std::move(s.x))&gt; T1; // error -&gt; cannot create incomplete type Type&lt;int&amp;&amp;&gt; Type&lt;decltype(std::move(s).x)&gt; T2; // error -&gt; cannot create incomplete type Type&lt;int&gt; am i missing something?
You're absolutely correct, but I assumed the intention was to ensure that the array is of type `string_view` while using different types as input, like `{"", ""s, ""sv}`, but still correctly deduce the length of the array.
Before the reddit hate repeats the main criticism I got last time: yes I used the hipster reveal.js again, and yes you hate the navigation. That's fine, I like it and you don't. We can still hate on C++ together. Navigate using the ⬇️ arrow until you can't anymore, and then hit the ➡️ arrow once (and repeat). Now that we agree The Web is horrible, let's talk about C++! 😁
Which is why the Linux kernel won't compile with a C++ compiler
Thank you , it does make sense right now !
&gt; it's not up to you what is appropriate and what isn't Well, it's kinda up to all of us, see on this very page &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. You really are asking a question and seeking advice, it's not cool. But I do not mind that much. What I do mind, however, is the way you asked your question. It contains falsehoods, it is **way** too broad, no specifics, it doesn't really show what you have tried etc. That makes it really hard to help even for those who really want to. I think you should google "what have you tried" to learn something about asking questions. &gt; You are not capable of helping, so don't try. Oh, I am not particularly trying to help you, no worries.
&gt; One more chipping in with hate...what's next, WebGL and a captcha before each slide? WebAssembly hosting clang and GCC, along with the entire sysroot. Of course. &gt; Real question, though: when did structured bindings gain the ADL `get&lt;&gt;` access? Last time I checked it was necessary to specialize `std::tuple_{size, element}`, which was really annoying. According to http://wg21.link/p0144r2 it was pretty early on! &gt; R2: Applied feedback from Jacksonville: Switched from `auto {x,y,z}` syntax to `auto [x,y,z]`. The wording supports bitfields. Added `tuple_size` check. Expanded `get&lt;&gt;` to use `tuple_element&lt;&gt;`. &gt; &gt; R1: Applied feedback from Kona, including added support for `get&lt;&gt;` to let a type opt into binding. I wasn't in the room for that discussion, but from the notes it looks like it was suggested by Botond as something "straightforward".
Huh, I guess I must have misunderstood the rules, then; it wasn't that long ago. Thanks!
An open source alternative is [TinyThread++](http://tinythreadpp.bitsnbites.eu/) (unfortunately it hasn't gotten much love lately since most compilers that yours truly is using finally caught up).
Catch is for user-mode code and KmTest is for kernel-mode code. Kernel-mode is like a parallel universe: every C++ library you know doesn't work there (even STL).
I've also found https://github.com/PollardBanknote/cppbackport to be noteworthy.
As always msvc will be shit with standarts.
If it's only single-use, then other than the fact that the name `resists` adds an implicit comment about the intent of the code, i quite like the style std::copy_if(src.begin(), src.end(), std::back_inserter{dest}, [&amp;] (const auto&amp; element) { // Code to make decision return decision; }); Unless the "code to make decision" is huge, it's nice and compact and local.
&gt; So how is the above more complex than error-return, again? In fact, how is it even possible that error-return can possibly be easier to test? Read what I wrote again. You can have your expected&lt;T, E&gt; return flip itself into the errorred state randomly, and thus Monte Carlo all possible error execution flow paths.
&gt; Is it definitely going to remain in the library, even if disabled? Is it going to be as well-documented as the rest of the library? I'd hate to get attached to this stepchild functionality just to have it disappear because a handful of people on the Boost ML vocally "don't get it". I get it. If it's enabled by the unit test suite, it'll be staying :) Boost peer reviews have become exceptionally conservative in recent years, mostly because of how few people bother to participate in reviews any more so if you get one or two people who are vocally opposed to one small thing, it gets rejected. That means you need to strip back the default config of the library to the commonly agreed minimum. Only just last month I review managed Boost.Stacktrace and my condition of acceptance was to disable most of it by default because of lack of consensus on the non-mandatory parts. See below for an example of how contentious the monadic programming interface I chose is likely to be. Leaving it in the docs would mean rejection from Boost. Sorry.
I guess you should add /u/windshook's explanation to the article, or at least link to his comment ;)
Making the physical measurements private and then having public member functions for a few pre-selected derived quantities is a bad design. There's lots of things we might want to calculate about boxes, but unless they happen to only depend on the box volume and surface area we're stuck. I realise this post is about C++ style, and that boxes are intended as a toy example, but actually this point is pertinent to the lambdas vs functors question. The default approach for stateless mathematical problems is to adopt a functional style, i.e. use value types and free functions: struct Material { double density; double ultimate_tensile_strength; }; struct Liquid { double density; }; struct Box { double length; double width; double height; Material material; }; bool is_strong_enough(const Box&amp; box, const Liquid&amp; liquid) { // complicated calculation return true; // or false } Now, all of the calculation logic is held in a free function, and we can use a lambda in the idiomatic way: std::copy_if(boxes.begin(), boxes.end(), std::back_inserter(suitable_boxes), [&amp;](const Box&amp; box){return is_strong_enough(box, product);}); 
&gt; So in my experience BigInteger is better than boost multiprecision That's using Multiprecision's built-in backend; the nice thing about the library is you can switch it to use GMP (or libtommath or whatever else) as the backend without changing your code.
I was stumbling over "senior" and hoping that it meant one of my managers instead. Glad to hear that was so! Thanks for the repro and the mail.
https://github.com/AnthonyCalandra/modern-cpp-features https://en.wikipedia.org/wiki/C%2B%2B14 https://isocpp.org/wiki/faq/cpp14-language http://cpprocks.com/an-overview-of-c14-language-features/ https://www.quora.com/What-are-the-key-new-features-in-the-C++-14-standard http://en.cppreference.com/w/cpp/compiler_support https://software.intel.com/en-us/articles/c14-features-supported-by-intel-c-compiler 
They're pretty similar to the POSIX ones: https://www.google.com/#q=toctou+posix These issues were discussed before I joined the committee. My understanding is that for many users of &lt;filesystem&gt; this isn't a real issue because their application isn't prone to adversarial races (or that's what folks think). IIUC the people who raised these issues also volunteered to propose resolutions, but never followed-up. The committee elected to move forward with the proposal without addressing the issue. It could be resolved later with more APIs.
&gt; Yes it is terrible that the arrow keys don't do what you think. Seems like other mis-features are optional also, like every slide going into the browser history. Agreed. I simply don't optimize for this case: I optimize for when *I* present these slides. In that context, reveal.js is great. In the context of reddit folks trying to read it, it's not as great. Mobile slides are also pretty suboptimal. &gt; BTW why godbolt rather than Wandbox or Coliru, is the asm particularly relevant here (it's often blank)? I'll use WebAssembly with clang / GCC when that work acceptably. The asm is only relevant on some slides, and I live-edit the content making some of it useful as well. Agreed it's not particularly useful. I just like godbolt, and my fellow compiler engineers like it too. If anything, using it in front of people get them to want to use it too.
But the problem is in the implementation of `func`, not its caller. A function taking a non-owning reference shouldn't be stashing them anywhere and expecting them to persist. I see no point with requiring extra verbiage in the caller to "solve" a problem in the callee.
The example is not great, what about this one: auto callback = ...; return button(callback); It creates an object of a button class which stores a callback as function_ref. It is perfectly sensible for the constructor to store a non owning reference. In the above code, if callback is a lambda convertible to function pointer, everything is fine. But if it is not, the explicit constructor forces us to write `button(function_ref&lt;signature&gt;(fallback))`. That makes the lifetime issue obvious.
Isn't this mostly about *the* general problem with references in C++? Storing a whatever_view or whatever_ref for "later use" is basically like storing a bare const l-ref, which has the same caveats because rvalues bind to it. And I'd expect a reference wrapper to behave similarly, in particular I'd expect function_view to accept an rvalue capturing lambda. void foo(const std::string &amp;); // Implementation somewhere else void bar(); // ... { foo("abc"s); } bar(); // What if foo() stored a pointer to its argument somewhere and bar() uses it? How can you write, with a straight face, a function that takes an object that is clearly a lightweight reference wrapper as an argument and *stores* it somewhere for later use? It's like, class retarded_class { private: static std::vector&lt;std::unique_ptr&lt;std::lock_guard&lt;std::mutex&gt;&gt;&gt; my_guards_; std::mutex mutex_; public: void be_stupid() { my_guards_.push_back( std::make_unique&lt;std::lock_guard&lt;std::mutex&gt;&gt;(mutex_) ); } }; Unfortunately, C++ doesn't protect us from lifetime violations like that, but that's a foregone conclusion and (probably) can't be retrofitted onto the language in a backward-compatible way. The moral of the story is, &gt; If you want more safety, consider Rust. Edit: Error in example code
I have seen that. Not nearly enough. First, you need to have code where the E in your expected&lt;&gt; is uniform, which is suboptimal, because failure modes are many and varied. Second, in the same vein, you can throw randomly, too. You have tooling to do that e.g. with allocation failures. You speak of mangling throw statement, that's not how you'd do it. Rather, you'd act on any conditions who trigger a throw or inject exceptions through mocking. You have only ever seen one way to inject failures and think that's all there is to it. How old are you? The example I gave you is still relevant because when testing a function, you only ever care about the validity of the inputs and the desired failure modes. Those are **always** tested like in my example and exist in exactly the same way regardless of whether an exception is thrown or an error code is returned. That exceptions "hide" error code paths changes pretty much nothing.
&gt;- constant: `static int i = some_constexpr_function();` ~~This is missing either `const` or `constexpr`.~~ This was incorrect, thanks /u/tcanens, TIL! (token page of /u/TartanLlama to the thread)
This is an issue inherent to C++, and is the very reason why Rust has the borrow checker.
&gt; More seriously, you can make it an official sublibrary and it won't be (as) contentious; the main library gets reviewed, the sublibrary is an implementation detail, the user gets the best of both worlds (namely documentation). This is how Boost.Phoenix ultimately made it through the pipeline. All the documentation I've culled from the main view is still in the repo. I'm way ahead of you!
&gt; Isn't this mostly about the general problem with references in C++? Yes, it is. But that doesn't mean that we should keep the problem as is. &gt; How can you write, with a straight face, a function that takes an object that is clearly a lightweight reference wrapper as an argument and stores it somewhere for later use? I'll update the example, it is supposed to be a member function.
Too many words around the relevant bits. Still can't figure out what the `=default` in that weird place supposed to mean.
I don't really see any point in criticizing this toy example, on this particular point. Over-exposing internals is at least bad, if not worse, than under-exposing. Worse because fixing under-exposed interface is backwards compatible, and fixing over-exposed interface is not. Whether you are using lambdas a little more, or a little less idiomatically (allegedly), is far less important than the exact interface of your objects, one of the most important design decisions you make.
If you want to store it type-erased, just use `std::function`. Putting a `reference_wrapper` into one is guaranteed nonthrowing (and hence nonallocating).
I pm messaged you.
That is honestly one of the worst things I've ever seen. Yeah it's a cool page for a portfolio but as for actually reading it, I'd rather pour acid on my eyes. What's wrong with readable websites?
does anyone know why does make_unique does all that weird stuff with is_constructible?
Thanks for this. There's a lot going on in this code and it will require some serious refactoring to stop from ICEing, let alone work properly in `constexpr`. Our `constexpr` guru, Cody, mentioned that there's a weird non-standard MSVC extension (also supported by GCC/Clang) being used in the Boost code. The anonymous struct in this code should warn if you use pedantic, and you can see the code is explicitly disabling the warning on MSVC. // from the Boost source in the repro #pragma warning(push) #pragma warning(disable : 4624 4201) //#line 233 "g:\\boostish\\upd\\boost.outcome\\include\\boost\\outcome\\v1.0\\detail/value_storage.ipp" union { unsigned char _value_raw; struct { unsigned char value : 6; unsigned char type : 2; }; error_type error; exception_type exception; }; #pragma warning(pop) We will fix this bug, but it won't be fixed in the VS 2017 RTW release. Anonymous structs should work in most places in our compiler, just not when used to initialize a constexpr object. For my own reference, the internal bug number is 366138. Yes, we have places where we can improve our Connect system :( 
`T{}` may be either value-initialization or aggregate initialization or "plain" initialization calling an initializer-list constructor, depending on `T`. &gt; you can’t default-initialize a const-qualified object if it lacks a user-provided constructor, That's not the rule anymore, thankfully. See Core DR 253, resolved by [P0490R0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0490r0.html) (scroll to the bottom). &gt; The language mandates that the type without the user-provided constructor is value-initialized and the type with is default-initialized. That's not quite how it works. In your initial example, `a` is aggregate-initialized; `b` is value-initialized but its value-initialization doesn't do zero-initialization. "ordered"'s description is incorrect. That category also include all "plain" non-local static/thread-local variables. If "non-trivial" is referring to [basic.life], it's now called "non-vacuous" and covers all initialization except by a trivial default constructor.
The behavior is undefined so all three are conforming. There is an NAD'd LWG issue, closed because it's an extension rather than a defect.
I feel like Clang and GCC could at least raise a warning for undefined behaviour here. Even with -Weverything on Clang, I get nothing of the sort. Naturally, I guess MSVC's immediate error is just as questionable.
You need to have all three. `tuple_size` tells the compiler how many elements are there in the thing to bind to; `tuple_element` tells the compiler what their types are, and `get` actually gets said elements.
&gt; For callables that do need to be stored for later use, it unnecessarily forces the caller into using reference semantics, It doesn't force them, it's designed for cases where you *want* reference semantics. &gt; For transient type-erased callables that are not stored, it's unnecessarily verbose compared to the original function_view What's exactly is your problem? The explicit constructor? If so, you have to pick a trade-off between explicitness and convenience, I've made my choice and you've made yours.
You only have the choice thanks to something obscure, misleading, and risky. That's not the kind of choices I want that a language provide to me...
I did a little digging but couldn't find a real answer about why this is specifically excluded from the standard, other than the suggestion that it would be a terribly inefficient way to generate a stream of random bytes.
&gt; It doesn't force them, it's designed for cases where you want reference semantics. Always. So I can't use, say, captureful lambdas, ever, without extra gymnastics to ensure that it outlives whatever the reference's being stashed in. I wonder what use case requires that kind of design - storing a type-erased callable indefinitely, but only by reference. &gt; What's exactly is your problem? The explicit constructor? If so, you have to pick a trade-off between explicitness and convenience, I've made my choice and you've made yours. If you are not storing the reference for later use, then neither the explicit constructor nor the lvalue requirement provides any tangible safety benefit, only extra verbosity. That's not a benefit in my book, but maybe it's in yours.
if speed matters you do care if not use a different language ;-p
I don't care about how fast I crash. Therefore, given a different keyword could have trivially mitigated this risk, yet provided the necessary speed boost for that rare case where for example your optimizer is a piece of shit (in which case you should rather use an other compiler, but whatever) and you can outperformed it by being (too) smart, I persist in denouncing that specificity of the language as complete an utter CRAP (like a lot of other small hindrances, but *not* the whole language) 
Developing on that idea, I would like the lack of init to become widely explicit, so explicit that it is spelled something like [[fuck_me_hard]]. With some luck, a good proportion of shops are forbidding profanity in source code, so the end result will be a safer world.
Typo fixed, thanks! Other comments: those are straight from the latest revision of the paper: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0091r3.html Did things diverge since then?
Well, you're already getting zero-initialization with inline `=default` (as I understand it anyway). It seems reasonable to me that you also get it with out-of-line `=default` as well. 
That's not choice, that's a round of Monty Hall. 
So what's wrong with like, Powerpoint? Or something else that you can put on a stick and... present? Or literally anything that works on mobile?
What do you mean when you say about "over-exposing internals"? Do you understand when we have to use class + member functions instead of struct + free functions?
I don't think it's a good name though, in some languages _ is used with a "discard this variable" meaning 
I used the tool I felt like using. You don't like it. I do. Let's talk about C++.
I don't speak C++ very well since I'm a child of PHP, just reading a book about it, but sure. How about that... if constexpr? Yep, pretty nifty huh!
&gt; A function object or a Functor is an instance of a class that overrides function operator '()'. No! "Override" is a special word which is inappropriate here. You mean "overloads". &gt; Note that moving the elements within a collection (e.g sorting) invoke copy operations No, they'll get moved. As written, your Employee has compiler-generated moves, so it's efficient. &gt; std::copy_if(employess.begin(), employess.end(), This is a typo, and a clear indication that the code has never been compiled. &gt; IsDeptEmployee(const char* dept) This should probably be explicit. &gt; bool operator () (const Employee&amp; e) { You should get in the habit of marking this as const. It doesn't matter here, but it does matter for container comparators. This fails to mention the most important thing about sort comparators - they must behave like less-than (or greater-than), not like less-equal.
As far as I can tell that's not a guarantee even if constexpr is used for the variable. Or am I missing something?
&gt; The compiler should complain that you are trying to initialise constexpr variable with a non-constexpr value That part I'm familiar with, the right side of an assignment to a constexpr variable must be a constant expression, but (and this is where I'm fuzzy) the actual constexpr variable doesn't _have_ to be set as a constant expression. Though I'm not adept with standardese (or familiar with where I can easily read it). At the very least I've experienced compilers producing code allowing me to step into constexpr functions/constructors while setting constexpr varaibles. This I think typically goes away on release (or at least I don't remember if I experienced it on release or not) but I don't understand why it would be optional, as it's not really an optimization. 
&gt; gets(p-&gt;name); Hold! What you are doing is wrong! Why do you do this thing?
In a library I'm working on the usage of the new syntax changes the return type from `entity_manager&lt;meta::component_list&lt;Components...&gt;, meta::tag_list&lt;Tags...&gt;&gt;::entity_t` to just `auto -&gt; entity_t`.
Because then it couldn't return one of the input parameters, but instead would have to create a new value. Consider: min(5.0, 3). Given your min, it would have to return "3.0", which is neither of the parameters. That's OK for int and float, but not for arbitrary user-defined types, which may be expensive to construct and/or copy. So, min/max/clamp return by reference, and always return one of their parameters - no conversions, no copies.
Well, it looks to be based off of eclipse CDT, which is either an okay experience or an absolutely dreadful one depending on the release. The most recent one I tried a couple of months ago was very nearly unusable. Not to say that this might be just as bad, but I don't trust it at all any more.
Tried and failed: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2199.html However `detail::promote` from that paper eventually became `std::common_type`. :-)
*twitches internally*
It's not bonkers, it just gives you the power (and responsibility) not to initialize variables which allows for optimizations you can't do in some other languages.
does it support CMake? couldn't find it on their website.
 T global; //default-initialization This is surprising to me. I'd expect globals to be zero-initialized.
As best as I can tell, it's a [Firefly reference](http://firefly.wikia.com/wiki/Dictionary).
I know this ship has sailed, but I greatly prefer D's approach to this. If you want to avoid initializing an object, you do this explicitly, by pseudo-initializing it with `void`: int foo; // 0 int bar = void; // uninitialized
It will be zero-initialized first, then dynamically default-initialized after. (Guaranteed by [basic.start.init]/2 in C++14)
I can understand this point of view, but have you ever heard about anemic domain model?
TIL std::clamp is a thing. As someone who works with images a lot, that's going to make my code a lot cleaner.
Yeah, that behavior might be a bug now (thankfully). I looked at the assembly GCC and Clang generate at -O0 for that example and only GCC elides both cases.
&gt; giving us undefined behaviour if we attempt to read it Perhaps a nitpick; but I claim this is unspecified behavior vs undefined behavior. My program should not do anything undefined if I read an uninitialized int. I couldn't predict the value it'll read though. Is this accurate to say?
`unsigned char` gets some special treatment regarding indeterminate values ([dcl.init]/12), but for all other types it does in fact yield UB.
[removed]
They should be and often are. ADA is still used in some industries for example. Good policy though can have a huge impact on the reliability of C++ (a subset really) in many industries. The idea of course is that because you can doesnt mean you should. In the end safety critical software often fails not due to strange language behavior but rather due to human decision making. 
I doubt this will ever happen in C++ due to the code breakage. There's actually a discussion going on in std-proposals right now. The suggestions I've seen are: - `_` - `[]` (`auto [] = foo(); auto [a, [], b] = bar();`) - `?` (single) and `*` or `...` (multiple) (`auto [?, ?, c] = quux(); auto [a, b, * or ...] = baz();`) I believe some languages use `_` in the context of a single parameter lambda (like Kotlin's `it`): `foo(2*_)`. This fits in here.
You are talking out of your ass. As far as I know C is used in the automotive industry and even in the aerospace industry. When it comes to safety critical systems a lot of checking is involved. Those are parts where the word "engineering" really also applies to the way software is developed. A lot of people take a lot of time to write not much software (in terms of LoC). Also a lot of formal verification is used. There is a reason why formal verification is a research topic at least in Europe and why companies in the automotive sector employ researchers for formal verification. And as far as I know (though I am not sure) they even very the program i.e. the executed code, not the source code. The fact that millions of cars a driving every day whose motor only works if the ECU controls the injection parameters to an accuracy down to milliseconds and they still just works prove that this can be done. And the fact that airplanes do not fall out of the sky because of faulty software (faulty as in programming error not in questionable design decision) also proves that using C or C++ is not the issue. Engineering is about a methodical approach and also a lot of hard work. You should not worry so much about safety critical systems written in C or C++, because hopefully they were developed with strong standards but more about the fact that today everyone connects everything to a single network which has not much security or safety build in and can be brought down by a botnet of routers and (the irony) security cameras.
Hard choices. I'd probably vote for `?`, as it's the least used symbol.
Between being enthusiastic about C or C++ and your two previous comments is a wide margin. Yes, it would be nicer if safer languages like Ada would be used but considering the general attitude towards safety and security I would say the risk of doom just because of the use of C or C++ is right now low. If that was our biggest threat we would be much safer than now :) Regarding the aerospace industry: I heard that Airbus supposedly implemented their software twice, once in C and once in Ada by separate teams. Both implementations run in parallel and it is checked whether the results agrees. 
O(n) Iterate and count the spaces (allocate exact memory for a string without the spaces, do remember the \n ) iterate and put in the string leaving the spaces behind 
Practically, I'd likely just suck up the extra memory space and write an iterator-wrapper that would just skip spaces on-read. 
&gt; If you don't agree without ever having tried it, use another library. I tried it. A very common use-case for me is to have a Result where the error type is an enum, but that doesn't work at all: enum error_code { }; template &lt;class T&gt; struct policy { ... }; // with error_type = error_code template &lt;class T&gt; using Result = outcome::basic_monad&lt;policy&lt;T&gt;&gt;; Result&lt;int&gt; r(42); r.bind([](int i){ return i; }); // static assertion failed r.map([](int i){ return i; }); // static assertion failed Using standard `outcome::result&lt;T&gt;`, there are many operations that I can't do: outcome::result&lt;int&gt; r(42); r.bind([](int i) { return i; }); // ok r.bind([](auto&amp; i) { return i; }); // static assertion failed r.bind([](auto i) { return i; }); // ok, but ALWAYS the value r.bind([](outcome::error_code_extended e) { return e; }); // ok r.bind([](outcome::error_code_extended const&amp; e) { return e; }); // static assertion failed r.bind([](outcome::error_code_extended ) { return "42"; }); // static assertion failed struct Y { Y(outcome::error_code_extended ); }; r.bind([](Y ){ return 42; }); // static assertion failed struct X { template &lt;class T, enable_if_t&lt;!std::is_same&lt;T,int&gt;::value, int&gt; = 0&gt; std::string operator()(T ) const; }; r.bind(X{}); // static assertion failed That's pretty artificially restrictive. If you don't believe me that `bind()` for all four operations (`map`, `map_err`, `and_then`, `or_else` in Rust's naming) makes for confusing code, then at least believe me that `bind()` for all four operations limits what I can do as the user. 
it IS bonkers. Any time you have to consult a reference just to determine what code is actually doing, you've got a problem. The whole function of a programming language is to permit one to express his intent in clear unambiguous way. Many languages, C++ is one of the major offenders, fail to meet this requirement. This is not the only C++ "gotcha" of this nature, but it's probably one of the worst. The committee needs to spend more time on getting these things right.
\#CodeIDoNotWantToMaintain
I always hated the pointer / reference syntax, although that sort of applies to C as well. There are several ways to write equivalent code that look completely different. It trips up pretty much every newcomer to the language. int a[2] = {1, 2}; int b = 3; int* p = a; int* q = b; cout &lt;&lt; p[1] &lt;&lt; endl; // 2 cout &lt;&lt; *q &lt;&lt; endl; // 3 cout &lt;&lt; p &lt;&lt; endl; // address of a Shouldn't `p[1]` be the address of `a` with an offset of `sizeof(int)` and `*p[1]` be the value at `p[1]` for the sake of consistency? 
&gt; https://godbolt.org/g/rsFcVj my life is an endless pit of sadness
std::remove, let the library writers figure that out ;)
Doesn't have to be C++. It is just that the top bots are written in it.
Not very. I spotted some ARM assembly recently but it was for GPU drivers, beats me why intrinsics weren't used but whatever. The biggest value is when you start debugging, that is still done a lot, although most of the time you'll be just stepping the HLL language source line by line. I still run into it but not so much in source code written in last decade or so. Older code still has more of it, but mostly inline variety which is starting to be deprecated for a lot of toolchains. TL;DR answer: not so much.
That doesn't mean you won't benefit from knowing it. It depends what sort of programming you'll be doing, of course, but for the lower-level kind of work it's good to know the fundamentals and how the higher level constructs map into what the machine will be executing. It's sort of sad seeing people writing all kinds of pointer chasing indirectional nonsense w/o understanding the ramifications of the data layouts they choose and write code around to. Knowing how to place data in memory efficiently is helped by knowing what kind of facilities CPUs have to deal with the code you write. That sort of stuff is still cool and relevant even if you use higher level languages.
Oh awesome, security is the industry I am hoping to go into so that's good to know
This is a C++ subreddit, so let's see how the STL does^1. std::remove_if(str.begin(), str.end(), [](std::string::value_type c) { return std::isspace(c); }); The best time of 10 runs on my machine^2 was 3.38 nanoseconds per character which gives 1.35 cycles per character. All code was compiled with gcc/g++ using `-O3 -march=native`. test | cycles/char ---|---|----|---- memcpy(tmpbuffer,buffer,N) | 0.130859 avx2_countspaces(buffer, N) | 0.271484 sse4_despace_branchless(buffer, N) | 0.375000 sse42_despace_branchless(buffer, N) | 0.601562 sse42_despace_branchless_lookup(buffer, N) | 0.753906 sse4_despace(buffer, N) | 1.027344 **std::remove_if(std::string)** | **1.35** sse42_despace_to(buffer, N,tmpbuffer) | 1.500000 faster_despace(buffer, N) | 1.667969 sse4_despace_trail(buffer, N) | 1.681641 **erase(remove)** | **1.764** countspaces(buffer, N) | 3.539062 despace64(buffer, N) | 3.552734 avx2_despace(buffer, N) | 3.935547 despace(buffer, N) | 5.056641 despace_to(buffer, N, tmpbuffer) | 6.464844 I'll take it. *** [1] [code](https://gist.github.com/anonymous/488c560e8f05fbef041637e482dd62bf) [2] Intel(R) Core(TM) i7-6500U CPU @ 2.50GHz *** **EDIT**: To address /u/sakarri's concern, I reran the `remove_if` with the complete erase/remove idiom. Timings from the best of 10 runs have been added to the table.
"Near extinction" probably not but there is certainly the possibility for a lot more deaths that don't need to happen. However I have to agree with the majority of your comments, much of which is due to incompetent managers. Frankly we need to see laws written and enforced that place these idiots in jail when something bad happens.
But something something immutable data! 
Some people, when confronted with a problem, think "I know, I'll use regular expressions." Now they have two problems.
Don't forget that library writers have more concerns than just performance on your specific architecture. They need to conform to the language standard, they need code that others can also maintain, and they need it to work well on a variety of architectures. Also, don't forget that it has to work for a wide range of data types. Yes, there is certainly some template detection used for things like `std::copy`: unsigned char *start, *dest; size_t size; std::copy(start, size, dest); is the same as memcpy(dest, start, size); except `copy_n` can take a much wider variety of input types and, starting with C++17, can also easily be adapted to run in parallel. In contrast, this function only works with `char`s on 64-bit machines. The last version only works on Intel machines. In exchange for readability, maintainability, and generality, you get a speed improvement (maybe, we'd need to see some evidence). I agree, if there is a standard library solution, start out by using it. However, in a performance critical section, it could make sense to craft your own solution to replace the standard library one. That depends on profiling, etc, of course, and shouldn't be the default.
Hey Andrew, I just got this bug report that something's corrupting our foreign language UTF-8 stings. Do we have any ASCII-only code hiding somewhere?
1. I actually work in Kernel at my work, it isn't that hard assuming you're writing the code and not just trying to port code to be of the correct style. Essentially you just have a fake kernel with mocked functions and use that for usermode. Then, you use typedefs for all the kernel calls as well as ifdef if you're in kernel. It's a bit of work to setup, but then you get all the features of gtest. 2 &amp; 3. Agreed, it is very cool. I wondered why no one had done something like this before actually. :D 
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5pcwtb/looking_for_beginner_projects/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
There's a cast missing in `_mm_loadu_si128(despace_mask16 + mask16)`. It's fixed in the repo. Threw me for a loop. The `despace_mask16` table is huge, 1 MiB. It would probably be faster if split into two 256-entry tables, totaling 8 KiB which would fit into L1 cache. Also, it should be aligned. The benchmark puts one space character per 33 characters on average. That doesn't represent text very well.
VOD: https://www.youtube.com/watch?v=uJfc1a_PGss&amp;feature=youtu.be&amp;list=PLS6Qj916df6K9z3dOLQhCS0KatlvBqhbE 
note that gcc is somewhat safer, however that might be because of a temporary miracle and change in a next version :/ Note that even with Weverything clang does not even emit a warning while omitting to set eax because it was UB. This is not useful behavior. This compiler should probably be avoided for anything remotely safety-related. On a quite unrelated note, icc optimizations seem pretty poor?
Am I the only one wondering if having a different output buffer, and marking both as `__restrict`, would help the compiler optimizing the naive version? Because the problem of the first version is that you are reading and writing from the same buffer area, such that vectorizing it is complicated. Oh, and is `_mm_storeu_si128((__m128i *)(bytes + pos), x);` strictly legal? Seems to me it violates alignment requirements, which is undefined behavior. Would be interesting to sanity check the functions to make sure they all produce a correct output...
To be fair - code from OP's article only shifts character to the beginning too (no memory cleanup at the end) from what I can see in the article. So this should be fairly similar in both ways since you have to do same thing here and there. I agree that it's name (`std::remove*`) is very poorly chosen... I have no idea what its creators had in mind when they named it so. `¯\_(ツ)_/¯`
As /u/ripper37 noted, the code from the OP's post mimics the behavior of `std::remove` which is why I used only half of the erase-remove idiom.
Inlining is a wonderful thing. :)
I am a big fan of Asio and am quite excited that there is a TR to add it to the standard library (likely for C++20). However, personally, I prefer the [standalone version of Asio](http://think-async.com/). It is header-only (unlike the Boost version, which requires `boost::system::system_code`, while Asio uses `std::system_error`). Also, since any Boost library is allowed to use another Boost library, you are required to download the entire 500MB library. Asio is only about 20MB. A lot of people / companies are unwilling to adopt the entire Boost library, since some of the libraries are of better quality or more up-to-date than others. It's easier to vet and adopt one header-only library instead of the entire Boost collection. Finally, the standalone version is, in my option, easier to use with a C++11 compatible compiler, since it will use the standard library version of `array`, `system_timer`, etc. (I believe Boost defaults to these versions for `boost::array` if they exist, but I'm not sure). So if you don't need another Boost library and have a C++11 compatible compiler, I'd suggest using Asio without Boost. Just define `ASIO_STANDALONE` and `#include &lt;asio.hpp&gt;`.
The 'u' in [`_mm_storeu_si128`](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm_storeu_si128&amp;expand=5179) means unaligned, so the starting memory address doesn't need to fall on an alignment boundary for `__m128i`.
Genuine question: why? I have a hard time seeing C++ the most suitable for this; clearly some scripting language would fare better?
Thanks! Great content. I've watched 3 videos (not counting the intro) so far. My university has a HPC cluster and I've recently become interested in the topic.
There is a CPU limit per frame. So you would want to use a language that is fast, even if the bot might be more simple. This is especially true for terrain analysis, which can take quite some computation time.
But OP's article can get away with shifting characters to the beginning because C string's always end with a null character, and a null character always denotes the end of a string. In C++, a null character does not necessarily denote the end of a string although the end of a string does necessarily have to be a null character. This subtle change of semantics means that using `remove_if` is invalid for an `std::string` even though conceptually it is valid for a C string.
It is actually the case in practice according to the STL implementations in MSVC, libstd++ and libc++. `erase` in all of those implementations is not constant time but rather linear time.
So how does one program a bot to play the game without access to in game data files? I feel like you'd have to analyse a lot of things on screen on the fly and that wouldn't be a trivial task.
The people who made the BWAPI figured out the memory locations for things like the units in the game. You encode those into a DLL and inject that DLL into the game.
CoW could never have applied there, it applies to copies of `std::string` from another existing instance, not construction of an `std::string` from a random buffer, obviously it can't just hang on to a pointer to stack memory
Thrust interests me, but it doesn't mention much about non-Nvidia hardware
Good point on the remove if. I wonder if the would both boil down to the same optimized code though. But less lines of code is usually better for maintainability in my experience.
When you factor in the GPU, mmap makes more sense (and you'd be surprised how many unix utilities use mmap when they have the option). I agree with you though.... the performance seems surprisingly bad. I'm guessing it is some kind of challenge related to shuffling data to the GPU, though it isn't clear what exactly is causing the problem.
OP omitted the details about the kind of storage was used in the test, which is crucial IMO. I'm guessing it was probably a mechanical drive, with an average read throughput ranging anywhere from 80 to 200 MB/s, so the bottleneck could easily been the disk access itself. 7s read time is not unreasonable for mechanical drives, especially if the file is fragmented and not cached. Pure speculation though.
Did you see his CPU? Intel i3-4130
Based on this your numbers seem about right: https://github.com/tobbez/string-splitting
~~Unix `cut` takes 0.28s, which is quite reasonable.~~ OP has his/her own implementation: &gt; Parsing 11 fields using hand-written program with strtok : (no threads, no memory-mapped file) This is the slow one that is not shown. EDIT: whoops! my mistake. It is 28s, NOT 0.28s.
&gt; Unix `cut` takes 0.28s, which is quite reasonable. 28.764s; not _that_ reasonable. ;-] &gt; This is the slow one that is not shown. Quite right, my mistake! (Though half the time of `cut`, so not so slow in comparison to _that_.)
 let newStr = str.replace(' ', ''); Wait...this isn't r/javascript...
I work mostly in Javascript and you're one of first people I've found that hates Regex as much as I. This black magic must be purged from the land!
`strtok` mutates its input, so it's extremely likely the data has to be copied first.
Does it still retain that "writing objective-C in C++" taste or did they move the code to use RAII and modern C++?
I don't understand why both this article and the original one it refers to recommend against using std::function to store passed-in functions. I've found it convenient to pass lambdas to constructors to implement delegation, e.g. class C { public: C(std::function&lt;double()&gt; getAnswer) : m_getAnswer{getAnswer} {} private: const std::function&lt;double()&gt; m_getAnswer; }; C c { [](){return 42;} }; If we didn't store the function, we wouldn't be able to pass a lambda this way.
lmao
These articles are explicitly about passing functions to other functions; _persisting_ functions, as you are, is another matter.
In the event that `buf` contains no nil-characters the code yields UB as `string`'s constructor will read past the end of the array. It may _appear_ to work correctly, but that's just one possible manifestation of UB.
I wrote my own C++ csv library recently as I was disappointed with both the performance and usablility of existing libraries. https://github.com/cwzx/cwcsv It's single-threaded so there's no attempt to parallelise but I ran it on this data set out of curiosity. I took the lineitem_small.tbl in the repo and copy/pasted it until it was 6 million lines. The benchmark just counts the number of cells and rows (there's no casting or converting of the values), so it's purely a test of the iteration/splitting. Results: rows: 6080000 cells: 97280000 cells/row: 16 time: 0.938127 s rate: 103 cells/us 
Oleg already corrected you already, I just feel like adding that this is not a coincidence. The UTF-8 encoding was specifically crafted so that: 1. All ASCII characters (`[0,128)`)would have the exact same byte representation in UTF-8 2. No encoded codepoint could be a subset of another encoded codepoint, which allows "re-synchronization" when jumping in the middle of a UTF-8 stream (by moving at most 3 bytes) I find UTF-8 really clever ;)
Yes but... ... it doesn't matter, really. The problem of undefined behavior is that the compiler can see this code and transform it to: _mm_storeu_si128((bytes + pos) &amp; ~0x0F, x); since `__m128i*` has an alignment of 16 bytes, then any pointer to it *necessarily* has its 4 lower bits equal to 0.
I asked last time and they said that it did not
Too bad, it's the only blocker for me to use it.
It's a mix of majority c++11 and objective c reference tracking. However the only objective c style thing used are the auto-release objects, which are pretty much easier to use shared pointers. 
Yes, you're right, std::string made me forget about this kind of UB. 
[removed]
Thats not true. libc++ does it in constant time. See [here](https://github.com/llvm-mirror/libcxx/blob/master/include/string#L2744) which in turn calls [`erase(pos, size)`](https://github.com/llvm-mirror/libcxx/blob/master/include/string#L2703), which then [computes](https://github.com/llvm-mirror/libcxx/blob/master/include/string#L2712) how many chars to move, which in our case is always zero, so it does not call `move` at all. Edit. And libstdc++ does similar thing, /u/dscharrer [provided](https://www.reddit.com/r/cpp/comments/5pb5h3/how_quickly_can_you_remove_spaces_from_a_string/dcr4v6b/) a link 
Wow, cool blog! Added to my bookmarks. Thank you!
Still, some of the most performance intensive things can be done in C++ and decision making (which is usually a bunch of if-else statements, state machine or behaviour tree) can be implemented very efficiently in Lua or some other scripting language. So, for example, the terrain analysis will be computed in C++ and the scripting language will get the result of it as lists of possible paths or something like that. This, of course, depends on the engine structure, so maybe it's not really possible in Stacraft's case and maybe there's not much time left for AI computation per frame. 
Good to know, thanks!
You can generate eclipse projects in CMake and use that?
It basically is that. The refactoring support is better then standard eclipse. But I find eclipse in general to be slow and clunky
This is a pretty impressively large collection of algorithms, but I'm curious how you envisage them being used in an interview setting. I give quite a lot of interviews and I'd never dream of giving most of these as on-the-spot implementation problems. 
Suggestions for /u/moarthenfeeling : &gt; Entity* getEntity(int); bool entityExists(int); These should presumably be const. Also, EntityId should presumably be used consistently (instead of mixing it with int). The article's repeated mention of moving things around in memory is confusing. I have never seen "memory fragmentation" be an issue in real code, especially with bucket-based allocation (note that heaps often use this behind the scenes whether you're aware of it or not; Windows does). &gt; Entity* operator-&gt;() { [...] Entity* get() { Ditto constness (on the member functions). &gt; Entity(EntityId id) : name("John"), id(id) {} This should *really* be explicit. &gt; entities.emplace(id, std::make_unique&lt;Entity&gt;(id)); auto&amp; e = *entities[id]; You're paying two lookups here (this seems to be an incredibly common error when implementing caches; I catch everyone doing this, sometimes even three lookups). &gt; auto it = entities.find(id); lua["onEntityRemoved"](id); entities.erase(it); It is unclear to me why you don't just use erase(const key_type&amp;).
yay, [more undefined behaviour for the unsuspecting!](https://godbolt.org/g/G7H4ci)
I did. Want criticism for that as well? Okay. First; the Partition() function should return a value. Second; the swap() is doing even more work than the solution 1. You are swapping *everything* except the zeroes when you are *linearly* walking through the data. You skip the zeroes so that you swap them with any non-zero value that might occur after them. That's fine, I got it, trust me. I didn't want to comment on solution as as I thought the solutions were sorted best-to-worst. I guess not. I am not sure if having two indices advancing at different rate is equivalent to partition logic of quicksort but if you say so. Bonus points for not trying to check if the swap needs to be done or not that would potentially be a mis-predicted branch which would be much worse than a write, which would be write combined anyway. 
I'm a bit confused why `io_service` is introduced - it's not used later in the post and also I haven't ever used it. The post mentions that it's the main workhorse of asio but I'm not convinced why an internal detail of asio is explained? It seems to me like `io_service` is used to run things in parallel processes or threads. So why not just use `std::async` or std threads?
dude, these are interview questions not real software problems, you don't have to dig that deep... only Big-O analysis, logic and number of passes matters here.. and the second solution would be called more efficient than the first one as it takes only one pass.
There is a lot of cool stuff there, let's not focus on some minor thing too much. I'm just bitter because I never had to do a job interview, don't mind me. :) p.s. I am anally pedantic and always over-analyze shit. I might be autistic. :( 
Seriously, use some less distracting formatting (brace placement, spaces between operators, the occasional empty line). This doesn't invite to read. 
I've been programming in C++ a long time and I didn't immediately get the answer. I've been bit by this before, but because I'm very careful not to overload virtual functions in derived classes as a matter of good design, I forgot about this rule. Anyway, thanks for the reminder :)
Add "using Parent::print;" to Derived class declaration and everything will be fine.
OOC, why do you want a variadic implementation of a C++03 lib? Far easier to use a C++11 lib that was designed around variadic templates from the beginning, like [Brigand](https://github.com/edouarda/brigand).
It's not working
I wish basic http support as in beast library is merged and becomes part of networking TS. Doing http with raw asio is a pain. Beast follows asio philosophy very closely so it already feels as a bunch of additional asio routines anyway. Perhaps the author could consider proposing it? In the end more cooperation on networking TS would be of great benefit.
The author has an account here; paging /u/VinnieFalco
in fact, everything inside the hana documentation looks like runtime programming. I'm unclear why this is advertised as a compile-time-library.
yeah, kinda like "using ie to download chrome", sad.
&gt; p.s. I am anally pedantic and always over-analyze shit. I might be autistic. :( Or just, you know, a C++ user.
I have been thinking of implementing a tasking system (like libdispatch) using ASIO, but was quite discouraged to pursue it further after seeing the same video by Sean. It seems only natural to use ASIO as a tasking/scheduling system along with network IO rather than having to use another library for that (I don't like libdispatch that much, it's code base is unreadable). ASIO as of now does have _almost_ all the constructs so as to be used as a tasking system. Anybody has any idea from where the performance penalty is coming from ? OR is it just that ASIO task-queue handling is not as optimized as in libdispatch.
Hana uses run time syntax, but the results of the compile time computations are embodied in the return types of the functions. That's why everything is a template. 
If you provide two the constructors Person(std::string&amp; first_name, std::string&amp; last_name) Person(std::string&amp;&amp; first_name, std::string&amp;&amp; last_name) for performance reasons, you also have to provide Person(std::string&amp; first_name, std::string&amp;&amp; last_name) Person(std::string&amp;&amp; first_name, std::string&amp; last_name) That's four constructors doing almost the same thing. DRY! The idea of passing-by-value is that constructors are special. If you call auto p = Person("Peter", parsed_name); You expect `p` to hold a *copy* of both first and last name bound to the lifetime of the object. So copying is the right thing to do. Person(std::string first_name, std::string last_name) Pass-by-value will *copy* any lvalues passed in. So that is already intended behaviour. For rvalues (and maybe even xvalues?) the compiler can elide the copy and instead move the value into the parameter. From there it is moved into the member. This behaviour will even be guaranteed in C++17. So all the four constructors save you, is one move. And one move should not even be measurable.
Using the library type std::uintptr_t instead of uint64_t not only makes your code more portable, but also makes it clearer to the reader that the integer is actually supposed to hold an address. (The two types are probably aliases for the same base type on your platform, but using the "correct" name is always better)
 MyType ProduceTypeWithConst(int a) { const MyType t = ProduceType(a); return t; } Last time I checked (which, admittedly, was a while ago), making a local variable `const` prevented the compiler from (implicitly) moving out of it on return (which seemed like a really strange behavior, at least on the surface). I believe in your example output the move constructor was elided. Are you sure that if that were not possible, you wouldn't have gotten a copy instead of a move?
Yes, had exactly the same thought: most of the top ones are written in C++ but in no way related to C++ development. Exception being `protobuf`.
What do you want to do? Read and write actual .proto files or do you want to serialize binary data from/to a file? To read and write protocol buffers to a file I would use memory mapping. If you want portability then use [boost](http://www.boost.org/doc/libs/1_50_0/libs/iostreams/doc/classes/mapped_file.html) if you don't care go straight to the OS (mmap() on Linux, CreateFileMapping() on Windows). A memory mapped file will appear as an allocated block of memory from your point of view. The whole file isn't actually loaded into memory, it just looks like it is. 
I recently wrote a fast CSV parser using gsl::span&lt;&gt; and no malloc for a job application and I got about 20 nanoseconds/cell. It was custom adapted to the specified CSV and uses all the CPU cores on your system to divide and conquer the problem. So your results look about right for a single threaded implementation.
&gt; string val("Hello"); &gt; foo(std::move(val)); &gt; &gt; Therefore, a good practice in C++ is to avoid using move in the case like this, even if this means unnecessary deep copy of the value, to avoid the accidental usage of the moved value. No, good practice is making sure that no code paths access the moved-from value. Unfortunately C++ doesn't have a compile-time borrow checker like Rust, but that doesn't mean that people should avoid move semantics because of the chance of errors. Just be careful when using `std::move`, but do use it **when it makes sense**! --- &gt; If the copy of value is actually costly and should not be copied, it is worth wrapping it into unique_ptr (like Box) or shared_ptr (like Arc), which will keep a single instance of the value on the heap. Relying on move in such case is very fragile and incurs a maintenance cost to keep the program correct. I strongly disagree for the same reasons mentioned above. Move semantics are a tool that needs to be used properly, like everything else in C++. Resorting to *dynamic allocation* because of potential mistakes is not the way to go - it hinders performance and unnecessarily changes the semantics of the program. If you don't care about a particular value in a scope, `std::move` it and **be very careful** not to access it again.
But ternary operator for example already works that way. If you pass it two reference of the same type you get the reference of that type back. Two references of different types then it's simply common type without reference. I think since built-in operator works like that it could be considered more or less natural. OP example wouldn't work that way however since `std::common_type` also performs `std::decay` on ternary operator result type.
I see, quite a bunch of games seem to be using the same approach. I guess I just love Lua a bit too much. :D (Devs of Don't Starve and Natural Selection did this: most of their code is in Lua while base engine is in C++).
Oh wow, you work on Factorio? I've never played it, but heard a lot of positive things about it. Seeing how many entities you have on the screen at once, using C++ for logic is completely understandable. :D
Can I use Qt Lite with a Qt desktop application in Windows / MacOS? How do I enable / configure Qt Lite?
Thanks, will do. I'm sure Cody appreciates having interesting code to compile!
Does Awesomium provide anything substantial over just using the Chromium Embedded Framework directly?
Why on earth aren't you using gsl::span&lt;T&gt; to implement borrowed references? That's the probable way C++ will standardise that design pattern. Spans are very cheap to copy whilst the thing they borrow stays put, so you can pass them around freely without needing to think about std::move. Some static analysis tooling also understands span&lt;T&gt; and will tell you a lot of the same stuff Rust does if you do stupid things with it.
Was it a successful submission?
I dream about Qt 6 to be mostly devirtualized, concept driven, using value semantics, more functional, don't try to mimic stl and without MOC, but I think it's quite unlikely... Maybe Qt 7?
I never used Awesomium, but it seems like a stripped down web rendering framework? Not sure I'd want that over a natively compiled cross platform UI library.
&gt; and without MOC I'd assume that would need reflection support by the language itself?
Why not? There is already an implementation of static reflection in clang, and the proposal is headed for a TS. And even if we don't have reflection, compiler plugins can be made. MOC already was implemented as a clang plugin.
Qt 6 almost definitely would happen before all required features would get into C++ standard and spread across all major compilers. Qt 7 on the other hand... It's to distant to think about)
Since when is London abbreviated as LN?
Qt is way more than a web framework
&gt; I dream about Qt 6 to be mostly devirtualized, concept driven, using value semantics, more functional, don't try to mimic stl and without MOC, but I think it's quite unlikely... Maybe Qt 7? Dunno about this one, the dynamic features of Qt are pretty nice and useful. If everything was static and concept driven, software such as [GammaRay](https://www.kdab.com/development-resources/qt-tools/gammaray/) would not be possible I think. Even QML is mostly the result of the dynamic nature of the Qt object model.
probably a silly question, but at that point, why not just use a pointer?
boost.fusion
**Company:** [FlyInside Inc.](https://flyinside-fsx.com/) **Type:** Full time, permanent **Description:** We develop virtual reality flight simulation software. Our core software brings popular flight simulators into VR, and we also develop custom solutions for customers in military and aviation. We're looking for a C++ developer to enhance our core product and work on client projects. You'll be developing software for Oculus, Vive, and to interface with various pieces of VR hardware. **Location:** Troy, NY - Downtown **Remote:** No **Visa Sponsorship:** No, must be US citizen **Technologies:** We mainly use C++ 11. We use boost, OpenGL, DirectX. Most development is on Windows. We're open to anyone skilled and comfortable developing in C++, but experience with graphics programming or reverse engineering is a big plus. **Contact:** Either PM me, or e-mail dan@flyinside-fsx.com 
[removed]
Fair point, I agree. I took issue with the wording as it seemed/seems like a poor generalization, but it does appear technically correct. Thanks for clarifying.
Yeah I know that's the point of the article, I just don't know in which cases you're free to use std::uintptr_t, but not an actual pointer.
You can dispatch any work to it, but it isn't a thread pool. It's trivial to create a thread pool using `io_service`, but `io_service` itself doesn't have threads; _you_ supply the threads. See [The Proactor Design Pattern: Concurrency Without Threads](http://www.boost.org/doc/libs/1_62_0/doc/html/boost_asio/overview/core/async.html). EDIT: [These slides](https://dl.dropboxusercontent.com/u/10282384/asio_presentation_with_story.pdf) are good if you have a few minutes to read through them. EDIT 2: I forgot this one: [Threads and Boost.Asio](http://www.boost.org/doc/libs/1_62_0/doc/html/boost_asio/overview/core/threads.html). Rather relevant...
BWAPI, the API that they're using to write the bots, was written in C++. There are ports to other languages, but people tend to prefer the original.
:(
Thank you, not sure how I did that.
Concept driven will only hide virtualization into an implementation detail, and enable you to put runtime polymorphism *only* where need. Programming with concept (even emulated ones) does not forces you to not use runtime polymorphism, but forces you to put it only in the places you need. QML should be possible without any hurdle, GammaRay seem interesting. I don't think it would be impossible, but maybe somewhat harder to implement.
Ah! I was afraid that the intrinsics would be based on the SIMD types themselves. Good news on this front. It may still be a challenge for the next-level API (which type to pick then?), but I'd vote to punt on that.
[removed]
I have already done it, it really works well. Qt + some boost gives you a really nice framework to base your work on. 
Care to elaborate what (potentially non-UI) aspects of Qt were especially handy to you?
For example: * Qt will give you an event loop. You can use that in non-gui context to do asynchronous downloads, among other things * Qt makes it dead easy to spawn subprocesses and interact with them * Unicode handling, colation, etc * Support for xml, json * Great reflection-based variant type * Simple date/time management 
I see, thanks!
Aah cool, thanks! And thanks for the links!
Take a look here to see where my head is currently at: https://github.com/BurntSushi/stdsimd/blob/master/src/x86/sse2.rs --- You'll note that most of the intrinsics take newtype'd vector types, which can be created using [constructors](https://github.com/BurntSushi/stdsimd/blob/master/src/macros.rs#L15-L20), much like the current `simd` crate. However, those constructors aren't always optimal, for example, if you want to load a `&amp;[u8]` or even a `&amp;[u64]` into a vector directly, then you might want that to compile down to a simple vector load/store, but bounds checks might get in the way of that. So there is occasionally a need for [unaligned load/store into vectors](https://github.com/rust-lang/regex/blob/master/src/simd_accel/teddy128.rs#L770-L794), and while it's unsafe, it should all just work. &gt; It may still be a challenge for the next-level API (which type to pick then?), but I'd vote to punt on that. Yeah. I think our current proposal is basically "stabilize all vendor intrinsics in `std` as normal Rust functions and provide a very minimal cross platform vector API implemented using the llvm cross platform intrinsics."
In the definition of `load_unchecked`, I think you forgot to mention `offset`: it should be: &gt; `slice[offset..]` must have at least the number of elements required to fill a SIMD vector I think. --- And thanks for the detailed reply, and the work :)
Move is not destructive in C++ and as such you can re-use moved-from objects provided you reset them to a know good state. That's perfectly defined behavior. For example: std::string val("hello"); foo(std::move(val)); val = "goodbye"; foo(std::move(val));
Don't forget C++ All-In-One for Dummies! This is the book that taught me how to get started.
Also useful if you have to implement a bare-bones allocator like `malloc` or `new`. Without it you run into aliasing and bounding problems pretty quickly.
&gt; pragmatic Nailed it. Lots of people forget that software has to be pragmatic over perfect. Perfect does not even exist...
In our build we set an env var which enables or disables LTO. Dev machines as well as incremental quick builders have it disabled, the full build machines have it enabled. Best of both worlds.
yes. And I've yet to see an example on how to use it. Let's assume I've a boost::mpl::set&lt;boost::mpl::long_&lt;enum1&gt;, boost::mpl::long_&lt;enum3&gt; &gt; How would I create a boost::mpl::map&lt; boost::mpl::pair&lt;0, enum1&gt;, boost::mpl::pair&lt;1, enum3&gt; &gt; ? 
as far as I know boost::fusion does not provide any containers, does it?
strike this. There are containers but they have the same limitations as the containers in boost::mpl.
Any links to reflection in clang? Googling only turns up reflection generating tools that use libclang.
In non-GUI programs I use KDSoap (depends on Qt), QtWebSockets and QtJSON. Boost is for the features that are about to come into the C++ standard.
&gt; C++ Primer Plus Noooo... This book is just misinformation.
For those not in the know: /u/HowardHinnant's [date.h](https://github.com/HowardHinnant/date) and its corresponding [standard proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0355r1.html)
C++14's `constexpr` and `auto` allows runtime-style code that is actually compile-time. Read [the documentation](http://www.boost.org/libs/hana/) already; the second sentence: &gt; The functionality it provides is a superset of what is provided by the well established Boost.MPL and Boost.Fusion libraries.
I use Qt but don't use the MOC for anything. The gains that Qt's reflection gives you do not outweigh the downsides of using the MOC in my opinion.
I'll assume you mean the equivalent hana types, otherwise there'd be not much point using hana. Let's say we have a set: constexpr auto s = boost::hana::make_set(boost::hana::long_c&lt;enum1&gt;, boost::hana::long_c&lt;enum3&gt;); And we want to create a map where the keys are the values' index in the natural iteration order over the set. Hana doesn't provide an `enumerate` function to my knowledge, but `enumerate` is just `zip` with an appropriate range: constexpr auto m = boost::hana::to_map( boost::hana::zip_with( boost::hana::make_pair, boost::hana::to_tuple(boost::hana::range_c&lt;std::size_t, 0, s.size&gt;), boost::hana::to_tuple(s))); We can print the type of `m` using Boost.Typeindex: std::cout &lt;&lt; boost::typeindex::type_id&lt;decltype(m)&gt;().pretty_name() &lt;&lt; std::endl; Or just verify it has the desired type: constexpr auto expected = boost::hana::make_map( boost::hana::make_pair(boost::hana::size_c&lt;0&gt;, boost::hana::long_c&lt;enum1&gt;), boost::hana::make_pair(boost::hana::size_c&lt;1&gt;, boost::hana::long_c&lt;enum3&gt;)); static_assert(m == expected); 
Alternately: don't mess with inline until you understand the tradeoffs.
Here! ;-)
How to use Qt lite? Do we need to compile Qt itself specially or we only need to configure our project .pro file?
You can start here : https://groups.google.com/a/isocpp.org/forum/m/#!topic/reflection/Y44k5JTZ598
To be clear, you're talking about C++ Primer Plus, not Stroustrup's Principles and Practice, right? S's P&amp;P was written from scratch to use C++11, and is thus of quite recent vintage. If so, I think your comment would have better been a reply to dodheim.
Edited to clearly identify the book. 
&gt; The containers are quite different from the STL because thy are copy-on-write. Move semantics &gt; copy-on-write &gt; Some stuff like shared pointer and atomics are still there but are mostly written in term of STL Why not simply use STL then? Introducing another api for the same thing can only confuse users that already learnt the standard way. &gt; Most graphical operation are likely to dwarf the cost of any virtual call Qt make Yes, but may prevent inlining when you don't acutally need runtime polymorphism. Inlining boost performance a lot and can, in some cases, reduce binary size. &gt; There is also the matter of compilation time That issue is actually worsen by moc. Other than that, I mostly agree with you. The change required may be too big to be resonable, but hey, I can still dream about it ;)
The blog entry really should have included a link to the documentation on how to use Qt Lite and what features are disabled.
I've done something similar with a Qt/Wt mashup, but Wt uses more boost-like libraries. If you just want to open up a network port and feed data to a static HTML/JS page, that's possible with Qt as well. http://doc.qt.io/qt-5/qtwebsockets-echoserver-example.html
Just another example of someone who uses Qt for non-UI applications. In general, I don't *need* it but I do notice that the stl library is missing a few things that make life easier with lists/vectors/strings. Also, QFile/QDir is great. It just saves a lot of time knowing that what I expect to be there is already there.
Thanks.
`[citation-needed]` Ours was constant time even before I overhauled it. (It is `O(length-of-shifted-suffix)`, and when you're removing everything after that point, `length-of-shifted-suffix` is 0)
The number of characters to move backwards will be 0, so yes, constant time.
How will this be better than existing C++ tutorials?
Ahh, OK I see you meant the opposite, that it would be great if there was an edition of the book with C++11.
Is this not what you need? https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.message#Message.SerializeToFileDescriptor.details
You can, but you won't see big changes. Qt Lite is mostly focused on QML applications on embedded devices. For example, Qt now allows to avoid dependency on OpenGL and use software rendering backend for QML. For embedded devices this can be huge win in size savings, because GL dependency on Linux can pull in a lot of packages. On Windows / OSX this will not save you much. Few kilobytes, maybe up to megabyte max.
What have you actually tried? Protobuf comes with all the APIs you need. Construct a CodedOutputStream/CodedInputStream around a FileInputStream/FileOutputStream. Prefix each message with WriteVarint32 of the length when writing &amp; ReadLengthAndPushLimit to get the next message. WriteLittleEndian32 may be slightly faster than WriteVarint32 but then you have to read the length &amp; push the limit when reading yourself (not that much code). That being said, if you have flexibility, you may want to consider a 0-copy serialization format like Cap'n'proto (written by the guy that wrote Protobuf 2) or FlatBuffers (written by Google primarily for games) as both don't need any encoding/decoding step. In other words, you can "read" 1 million of these records instantly &amp; writing is bound by the speed of your disk assuming you mmap &amp; memcpy into the file destination. The downside is that these tend to be larger on the wire as they're not as compact so you need to layer gzip/lzma on top of that if you need it (i.e. if you want to process the compact form multiple times, protobuf may have a better trade-off of smaller size vs fast decode but I haven't benchmarked).
Absolute C++ book is a good way to begin if you have at least one programming language background.
If you see a book introducing new/delete in the first couple of chapters then it's an old C++03-style book. They used to be one of the core features of C++, but they are now shunned.
On the issue of IDEs, I'd add that Windows is also perfectly decent for C++ development on the command line. You can install Mingw or Cygwin to get GCC/Clang, or you can install Clang natively, or you can install the MSVC compilers and command-line tools without having to mess around with Visual Studio. Flame wars aside, the recent versions of each compiler are much of a muchness.
hm.. for that case i would have dumped inlining.. though im not that familiar with msvc to do that.
Interviewer here.. the answer we were looking for was: struct Node { foo::intptr ptr; // store prev ^ next, like Knuth foretold in holy scriptures }; struct Iterator { foo::intptr current; foo::intptr source; foo::intptr step() { auto temp = current; current ^= source; source = temp; } }; You failed because you had not read The Art of Computer Programming. We only hire d best f d rest. PeACE. 
Your last exemple with ranges is not isofunctional with the previous code as it will print all number smaller than 10, rather than all numbers encountered before a 10 or higher number. Not to say you shouldn't use range, because indeed you should, but with this particular exemple you'll have a hard time no using a state... 
With your approach, every computed property has to store the `this` pointer; other languages pass the pointer implicitly. What happens when your `Article` is copied or moved? I believe this approach: ComputedProperty&lt;&amp;Article::computePriceWithVat&gt; priceWithVat() { return {*this}; } would be safer. Then make `ComputedProperty` noncopyable/nonmovable (rely on guaranteed copy elision of C++17) and define the conversion operator only for temporaries (ie. `operator T() &amp;&amp;`). That should make it impossible to get a dangling `this` pointer, but you actually have to call the property with function syntax.
Yucky. Can I also adopt this as my largest pet peeve? Allowing temporaries to bind to a non-const reference is insane. I've personally written SFINAE checks that depend on non-const references not being able to bind to temporaries.
Not at all now that i think about it. You could however make the property writable with an assignment operator and some setter function. Its pretty pointless compared to a normal function, though.
apropos SFINAE, my biggest pet peeve is definitely its strange treatment of templates, where e.g. [this](https://godbolt.org/g/ea4YEk) triggers only exclusion from overload set and [this](https://godbolt.org/g/myS3Xx) is ok
With compile time reflection, you can generate the metadata you need and fill your runtime structure with that metadata. Then, you can use it at runtime. The contrary cannot be done. This is why compile time reflection is much more powerful.
Another great article, thank you! Do you mostly see this being useful for algorithms and other higher-order functions?
Ok, so curry is a type transformation. It takes a function and returns a function. I suppose now with constexpr lambdas we can actually do this in the compiler, but I haven't tried it yet. Partial application is different. It takes a function and an/some argument(s) and returns a function that takes more arguments. `std::bind` is an example of partial application. So, homework assignment: What do you get if you curry partial application? About 10 years ago I tried this using Boost, but made some idiotic mistakes. I'm pretty sure I never got around to doing a new write up. I guess now is the time. http://www.kirit.com/Blog:/2007-09-10/What%20do%20you%20get%20when%20you%20curry%20partial%20application%3F
A movable QObject/QWidget would be helpful, since internally they are pretty much fat smart pointers so they are "almost" there. Having more Qt containers and having all of them in both implicitly-shared and non-shared variants would be useful, since copy-on-write isn't free: e.g. every dereference via non-const `operator[]` has to detach.
Code generation is there to help you. You're somehow dead set against moc, but that's the least of your worries. If you literally use no tools other than a build tool and the compiler, you're already doing it very, very wrong and are making yourself uncompetitive.
&gt; What's the properties problem? For instance imagine that you have a "user settings" class : struct MyAppSettings { int foo(); void setFoo(int); std::string blah(); void setBlah(std::string); my_class duhh(); void setDuhh(my_class); }; And want to render them all to JSON / XML / whatever. With properties you can have a generic solution for this, by passing a "property" object with a single interface. You are able to associate metadata (for instance the json key). Current solutions for this are a macro hell.
You don't need the MOC to connect slots to signals in Qt5. There is an alternative API which is much more consistent with modern C++, works with lambdas, etc... For making new signals/slots in my own classes, I much prefer using boost's signals, the API is a lot cleaner, ownership is much more explicit, and there is a lot more functionality available to control how slots get called.
&gt; You don't need the MOC to connect slots to signals in Qt5 You never did. `SIGNAL()` and `SLOT()` are just macros and always were. However you need moc to **generate the implementation of your signals** in a `moc_myclass.cpp`. if the following code compiles : class Foo : public QObject { Q_OBJECT signals: void mySignal(); }; int main() { Foo f; f.mySignal(); } it means that moc is running (or that you are implementing the signals by hand which can be quite painful).
Oh, nevermind. I thought that the syntax you wanted was `object.computedProperty()`. Since it's not that, uniform call syntax won't work. Sorry.
I'd go to a library and read the chapter about graphs in any algorithms book.
I'll take using two different signal-slot systems in my software rather two different languages mixed together. I avoid frameworks and use them in a very lightweight manner. If all you use is Qt and have no problem writing your code assuming that Qt will forever be around and the best option then by all means use the MOC and use all of Qt's functionality. My experience is that it's unwise to depend on frameworks and tailor your codebase to a framework, so to the best of my ability I write my code using modern/standard C++. My codebase has been around for over a decade and will have to continue to be around for decades to come. If later on a new framework comes along that is an improvement over Qt, or even if Qt itself undergoes a major change like it did from Qt3 to Qt4, switching over to it is very straight forward and my codebase remains robust and adaptable.
Hey people. Check out pure select function that returns vector of a single column values like `storage.select(&amp;User::id, where(is_equal(&amp;User::firstName, "John")));` at the latest commit.
\*braces self for Slashdot comment section\*
which one of the committee's proposals was turned down?
Thanks for providing this hard fact in these times of *alternative facts*.
I think their statement is just BS. The committee doesn't want to get concepts wrong is all. C++11 was originally suppose to have concepts, but they realized it wasn't going to work so they had to go back to the drawing board.
The original concepts proposal which was to go into C++0x. It didn't involve predicates, involved more explicit concept maps, etc. I'm sure there are others that can provide more accurate details than me.
Multiplication is given higher priority over addition because multiplication is multiple addition so it wouldn't make sense. I'm asking a serious question here 
C++ does it that way because C did it that way. C did it that way because mathematicians did it that way. In boolean algebra, logical-and is treated like a product and logical-or like a sum, so it follows that logical-and has higher precedence, since multiplication is given higher precedence than addition. For example, AB + CD means (A and B) or (C and D). So it would have been surprising to people familiar with mathematics in the early 1970s for it to work otherwise. 
Already thought you dropped the blog...
This is a really useful article! I'm at the point in my first attempt at a game engine of implementing this sort of stuff. I had considered using shared and weak pointers, but hadn't thought of using the technique you mentioned. I'll have to give it a shot, and roll in some of the revisions /u/STL suggested 
...What? 5 + 3 * 2, why wouldn't it make sense to do the addition first? Multiplication is done first because thats the convention.
There are more mathematically founded reasons why multiplication is given a higher priority, but let's not digress. The fact is that AND **is** multiplication and OR **is** addition when you see those operations as forming a [semiring](https://en.wikipedia.org/wiki/Semiring).
Don't mean to jack OP's request, but any thoughts on a good resource for someone who started with python? I'm having a real hard time wrapping my head around templates in c++, I keep seeing tutorials say that a lot programmers don't understand templates well and I can understand why. I find everything about them confusing, from the seemingly overly complex syntax to why to use them over just creating classes with multiple constructors for different data types. 
Better is debatable. Qt slots are invokable through reflection (they are implicitly marked Q_INVOKABLE) and have automatic queueing across threads based on QEventLoop. Other than that boost and Qt signals are pretty similar.
&gt; As for why they didn't simply use '+' and '*' `&amp;&amp;` and `||` short-circuit. `+` and `*` don't. 
Thank you! :)
Not to sound inconsiderate but google and 'c++ tutorials' There is a ton of online tutorials, and most of them have you walk through what ide works better for beginners and chapter based tutorial work to progress with. They will have you build little programs at first learning why and how it is compiling and what the processor is doing, how everything is translated to machine. It might seem boring at first but once you get deep into it if you don't have the fundamentals down pack and can work them well the more advanced of the language won't make a lick of sense. You can get into reference pointer nightmares, loop problems, general logic on deep c++ gets nuts. But it is a very solid language. It might be boring as you stated without having a complete creation program in the end of a lesson, but there is a reason they are walking you through it. It is similar to saying; I am learning a new foreign language and it is moving slow and boring yet I want to write a book in the language now.
the only thing in boost::mpl which needs to be fixed is the emulation of variadic templates and the resulting size limit.
This example (including the entire hana documentation) does not make sense, as there is no template argument input. From what I finally understand (after a very long discussion at stackoverflow.com), at least hana::set is not useable, as it cannot be default constructed and thus any template class getting it passed as a template argument cannot have a default constructor.
I did read the documentation and since I did not see any template argument input, I decided that it is not a meta programming language as I can do all these examples with normal runtime programming.
Amazing that you got this far with C++ with such terrible reading comprehension!
I would recommend the thinnest one just to grasp very basic concepts. Actually the best way to learn for beginners is practicing a lot first and then read a book to consolidate knowledge. So just find any lightweight tutorial online ( youtube? ) to bootstrap and start programming. After a couple of months when your programs become at least 1000-line long you will need a book. Then return back with a new question ;)
I understood all the examples. I only did not see any replacement for what I was doing, as there never was any template argument input. And now it seems that this never was intended -- see my previous statement regarding boost::hana::set not default-constructable. 
The types of function template arguments can be deduced. This has always been the case. Why is it confounding that they're not explicitly needed here?
I meant template argument for a template struct/class.
Apologies, I meant [the code](https://www.reddit.com/r/cpp/comments/5pleus/how_to_make_this_variadic_implementation_of/dctepim/) /u/scatters showed in response to your request for a translation from MPL. (Not to mention 90% of the code in the Hana user's guide.)
They define simple requirements in 5.1.4.1 and 14.10.1.3, and it doesn't look like it needs a return statement. Instead it looks like the expression simply has to be valid.
Your `curry` is a bit wrong, it should be equivalent to: curry ∷ ((a, b) → c) → (a → b → c) curry f a b = f(a, b) Your version has type `((a, b) → c) → ((a, b) → c)`, which is just an identity function.
Thanks for the *(as always)* thorough and very valuable feedback. --- &gt; "callable" has a specific meaning. You are not accepting pointers to member, so you are just accepting function objects. You're right - changed "callable object" to "function object" in the article. I tried using `std::invoke` as part of `curry`'s implementation to make it more general, but got unfortunately blocked by ICEs... --- &gt; Isn't step2 supposed to be the result already, according to your previous examples? Yes - fixed. --- &gt; is_callable&lt;TF()&gt; is incorrect. You want TF&amp;&amp;. Fixed. --- &gt; The explicit constexpr is unnecessary. Lambdas are implicitly constexpr if they meet the requirements. Added a note mentioning this. --- &gt; I'm not particularly convinced about moving things, since that implies that anything returned from curry can safely be used only once. Currently looking into this issue... I'm again getting ICEs when using move-only types *(gcc version 7.0.0 20170113)*. --- &gt; apply_fwd_capture uses tuple_cat, which can get expensive in case you have things captured by value, especially if the move ctor isn't cheap. Good point - I'll write an alternative that expands the tuples in place without `tuple_cat`. --- &gt; In general, I'd like to see benchmarks with more complicated argument types than int and more complicated callable types than a stateless generic lambda. Assuming that the compiler will cooperate, I'll definitely work on these and add them to the article.
`-&gt; decltype(auto)` isn't SFINAE-friendly. Attempting to instantiate the call operator with an invalid argument sequence would be a hard error instead of SFINAE because the error would come from instantiating the body and not the signature, and that's not the immediate context. 
Are we browsing the same Reddit?
I added `&lt;TreatSpecificWarningsAsErrors&gt;4239&lt;/TreatSpecificWarningsAsErrors&gt;` to my project props (pre-VS2017). Which obviously isn't as comprehensive as `/permissive-` but at least catches this bugbear.
&gt; On the internet, everyone has a huge ego and pretends to be an expert about everything all the time. FTFY
Bats are not birds ._.
Honestly, I agree with those that say it shouldn't be in yet. I think the definition checking is a critical part, aka assuring that only things specified in the concept definition are used guaranteeing that anything fulfilling the concept can be used.
Here's an out-of-context Hacker News comment extract for your enjoyment: &gt; One useful rule of thumb that works 99% of the time in C++11 is: Never use "std::move" [...]
Beginner questions should be sent to /r/cpp_questions as the sidebar advises.
Is it fair to think of concepts as the "meta" equivalent of something like C\# interfaces? Interfaces (or I guess pure virtual classes) used as constraints on instances, concepts being constraints on types?
MSVC is trash
This is going **way** too deep down the rabbit hole for my taste. It rightly claims that what it does this is relying on the unspecified stuff. Then it say, "ah, but there's Itanium ABI spec which most compilers implement, so let's do that". Then it notes that, hmmm, that spec isn't exactly unambiguous and clang differs. So gcc it is. Finally, it says, OK, it's for 32 only. So there's almost no C++ left, only gcc for 32bit code. **There is no ABI** in C++ language. And... There isn't one in C either! (See how your C standard says diddly squat about calling conventions or padding? Well, there you are!) If you ask me, the world would be a better place if people, in lieu of inventing C++ ABI or reverting to the sad least common denominator that is C, worked with actual language-agnostic integration specs. But wait! Because we're so primitive in that regard, there's no such thing! (There is COM, and it is very competent as a language integration spec, but it's Windows-only).
Wait, wut? `/permissive/` *disables* non- conforming code by turning warnings into errors? Why does VC use the exact opposite convention of the IMO more intuitive `gcc -fpermissive` which, well, *permits* non-conforming extensions?
Well, my "up to megabyte max" was pure guess. No idea how much it will actually save. [Application](https://github.com/mmozeiko/CxxProfiler) I made has only 17.6 MB of Qt dependencies on Windows when linking dynamically. Well +0.7MB if you count also .exe size.
&gt; std::printf("%f\n", table.priceWithVat); How is this not UB? What you're passing in is not a `double`, and varargs functions are not going to cause any type conversion.
Discussed [here](https://www.reddit.com/r/cpp/comments/5dh7j5/visual_c_introduces_permissive_for_conformance/da4l4tv/).
7.1.7p5 &gt; A function concept has the following restrictions: &gt; &gt; [...] &gt; &gt; — (5.4) The declaration shall have a _function-body_ equivalent to `{ return E; }` where `E` is a _constraint-expression_ (14.10.1.3).
Hahahahaha!
&gt; Implement deserialization as a constructor, and ~~de~~serialization as a virtual function: How I do it is : * Always put the deserialization in the constructor in order to always have a "good-state" object when leaving the ctor. * Put the serialization in a virtual function only for polymorphic types. The actual serialization code is not "in the class", I use a template similar to : struct Serializer { template&lt;typename T&gt; void serialize(const T&amp;); }; struct Deserializer { template&lt;typename T&gt; void deserialize(const T&amp;); }; and next to the actual classes there are template&lt;&gt; void Serializer::serialize(const MyClass&amp; c) {...} // etc... For deserialization of polymorphic classes, I give them an UUID and [look in my registered factories](https://github.com/OSSIA/i-score/blob/master/base/lib/iscore/plugins/customfactory/SerializableInterface.hpp#L64), then I have some [tag dispatch](https://github.com/OSSIA/i-score/blob/master/base/lib/iscore/serialization/DataStreamVisitor.hpp#L173) for serialization to know if I am serializing a polymorphic type or a simpler, value type. But I limit myself to flat inheritance trees, else it would have to be more generic.
 Eh, why would you not have /w4 enabled, and warnings == errors.. 
s/meta/compile time/
Non-Mobile link: https://en.wikipedia.org/wiki/Common_Language_Infrastructure *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^22648
I think I understand the reason for the complexity better now. I just have this mental block of "why is this thing that's a non-issue in python so complex in C++?", but I understand that same complexity allows a lot more granularity and optimization. I think I get it now, just in the scope of the projects I'm working on I don't see that much benefit because usually I design functions and classes for a single purpose so I don't see the need to cover all types. I can certainly understand how when making larger more professional programs that functionality would be integral to keeping code manageable. Thanks for the explanation. 
In my defense I do mention that in the source code comment (it was intended to be kind of a joke)
sounds like material for https://github.com/cplusplus/concepts-ts/issues 
Good point
Thanks for the link, /u/dodheim. The short answer is that one day we'll flip the default compiler behavior to be conforming. At that time /permissive will enable the compiler-specific weirdnesses, just like GCC. 
Hi! :-)
&gt; for_each has the specificity of keeping the same instance of functor all along the traversal of the collection, but it is not the case of all algorithms. Other algorithms do not guarantee they will use the same instance of callable along the traversal of the collection. Instances of callables may then be copied, assigned or destructed within the execution of an algorithm, making the maintaining of a state impossible. To find out exactly which algorithm provides the guarantee, you can look it up in the standard but some very common ones (like std::transform) do not. What's the relevant difference between the specifications of `for_each` and `transform`? Both say they evaluate a call to the parameter variable for each iteration over the range.
I kind of prefer to have stuff like trace tables, brake points and step into/step over. I can monitor precisely the values of each variable but i guess that is also a weak point because you can get pretty lazy. 
&gt; An exception to this last rule is the use of C++17’s structured binding: If the name we pass to `decltype` is one of a variable defined in structured binding, then the result is the type of the bound-to element. Example: &gt; std::pair&lt;int volatile &amp;&amp;, double&amp;&gt; f(int); &gt; auto const&amp; [a, b] = f(22); &gt; While the type of `a` is `int const volatile&amp;`, `decltype(a)` will give `int volatile&amp;&amp;`, as that is the type of the first element of `f`‘s return value. Similarly, `decltype(b)` will result in `double&amp;`, not `double const&amp;`. Within expressions, `a` behaves like an lvalue of type `int volatile`: It is possible to initialize an lvalue reference of type `int volatile&amp;` with `a`. From that, we can deduce that the real type of `a` is either `int volatile` or reference to `int volatile`. Similarly, the real type of `b` is either `double` or reference to `double`. If I understand http://en.cppreference.com/w/cpp/language/declarations#Decomposition_declaration correctly, the declaration auto const&amp; [a, b] = f(22); is roughly equivalent to auto const&amp; e = f(22); int volatile&amp;&amp; a = get&lt;0&gt;(e); double&amp; b = get&lt;1&gt;(e); That is, `auto const&amp;` is the type of the hidden variable `e` and is not directly related to the type of `a` or `b`.
My guess is that the change is there to make it *more obvious* when you have trouble with your reading logic. Seeing nonzero numbers repeated from the last successful read in a loop is more likely to confuse than zeros. If zero is valid input you could still get confused but not as easily I guess.
&gt; I don't feel the need to respond to every trollish comment, but I do like to respond to everyone who takes a moment to reach out to us. Judging from the wording - I don't think that is a case. First of all - you would need to define "trash" =D &gt; If a developer cares enough to mention us they deserve a kind and informative response. For that, I and many others, are truly grateful. &gt; Unfortunately, it's a costly proposition to implement a feature that might change drastically, or may never be standardized. I thought that TS's were almost "good to go" with an exception that committee would like people to play with them before settings things in stone. So it's essentially not a matter of "if" but "when and how". I saw some last minutes changes, but that was mostly because some "last minute" bug in design. Is there any list of TS's that was revoked (not redo'ed, just revoked) (not talking about Concepts C++0x)?
The most significant diffrerence is that `transform` applies a function on the elements of the source range AND does an assignment to the destination range, while `for_each` barely applies a function on the elements of the source range.
which compiler are you using? I have used codeblocks
[removed]
FYI, you have been shadowbanned. You must contact a reddit admin to fix this (subreddit mods cannot lift shadowbans).
The first few results for C++ concepts seem relevant to the topic. I get both wikipedia and a cppreference page. 
&gt; principal You mean "principle". &gt; It doesn’t allow duplication of data. C:\Temp&gt;type meow.cpp #include &lt;iostream&gt; #include &lt;queue&gt; #include &lt;string&gt; using namespace std; int main() { queue&lt;string&gt; q; q.push("NO"); q.push("stop"); q.push("NO"); q.push("NO"); for (; !q.empty(); q.pop()) { cout &lt;&lt; q.front() &lt;&lt; " "; } cout &lt;&lt; endl; } C:\Temp&gt;cl /EHsc /nologo /W4 /MTd meow.cpp &amp;&amp; meow meow.cpp NO stop NO NO
Haha yea! I couldn't have expressed it in a better way :-D
Thanks for letting me know, do you know the reason for that?
No idea. Maybe you were a bad kitty, maybe some algorithm was overzealous.
Aside from a handful of built-in traits, don't traits in Rust need to be explicitly implemented for each type by the programmer? Concepts seems more like Go's interfaces.
Unrelated, but this makes me wonder if MSVC will ever get gcc/clang-like compiler switches.
I'm wondering about the reason you thought it wouldn't be possible.
Agreed - I really don't get why some people like 70's era editors design for TTYs :) On Windows I'd go for the free Visual Studio Community edition. The main advantage is you can trivially jump into debug mode and step through your code, watch variables (including pretty formatting strings and STL data structures), which is great for understanding what's going on. That's the real point of an IDE (kinda what the "I" stands for), rather than different key bindings or white vs black backgrounds. I mean I'm sure you can get to some approximation with Linux subsystem, cmake, vim, gdb, ctags, clang-format etc., but as a learner of C++ and not fiddly toolsets that are sometimes a struggle in themselves, that all seems an unnecessary distraction IMHO, at least as a first step. 
Bitbucket Pipelines can use any Docker image - you're not limited to the default one. Depending on your needs, it may be worthwhile to specify a C++-friendly container, or to build a custom container that has some of your other utilities already baked in.
I recently wrote a Property type that overloads all of the mutating operators (=, +=, *=, stream extraction, etc.). The type takes a mutator function (as a template parameter) to perform validation whenever the property is changed. This means I can write things like: health -= damage_taken; where health is a property, instead of set_health(get_health() - damage_taken); Obviously if you don't need special accessors/mutators, exposing the field directly is better. But when a field requires additional validation or side effects I think properties make the code more readable.
Before writing any data processing anything, go to this list: http://en.cppreference.com/w/cpp/algorithm and see if what you're about to write is on that list. Particularly common ones people do over and over again are `remove_if` and `rotate`.
for trivial changes it would be great to see gains as long as you guarantee deterministic builds.
Not really. Concepts are just compile-time predicates. Haskell's Typeclasses and Rust are a bit different.
I've been tinkering around with C++ and CI lately. I don't use bitbucket, I'm on Github using Travis. I've got it set up to compile on check-in with clang and g++. Then for deploying on linux I'm using systemd unit files. One thing i highly recommend for deployment and automation is Ansible. At work I've been using the latest Jenkins "pipeline" feature. I suppose pipelines in Jenkins have benefits of orchestration but a lot of plugins don't work easily with pipelines and simple things like disabling a pipeline isn't in available in the menu anymore. It's just been painful for me. I've heard a lot of good stuff about Team City. 
Better to respect the `stream.exceptions()` setting.
It can be perfectly lived with. You don't see anywhere near this much anguish about things like Flex/Bison or the custom bash/perl/awk script KHTML uses to generate some of its CSS handling code...
&gt; I'll take using two different signal-slot systems in my software rather two different languages mixed together. So would you avoid other C++-based DSLs like Boost Spirit just to avoid having "different languages" mixed together, even if they were right for the job?
Because boolean algebra is isomorphic to the semiring of integers modulo 2 under addition and multiplication. (The same thing everyone else is saying, but in technical terms.) 
That's why I got erase_if() added to the Library Fundamentals TS v2.
Ah, trying to integrate a fold now in CUDA has been interesting. Lots of different methods for doing it, going pretty low into individual GPU hardware. The complexity of it all has made me relish std::accumulate, to be honest (well, that and the fact that all my CUDA code seems to set EVERYTHING to zero...)
I wouldn't expect a transitive closure over changed functions, but just the changed ones, with relocation re-done to link to the new one.
Ah, nice, thank you. One less function template in my convenience header. Do you know why the committee decided on `std::accumulate` instead of the more common `foldl`? 
Man, gpu programming is so much more of a faff than coding anything for a CPU. CPU algorithms are super easy, doing anything whatsoever on a GPU is a giant pain in the arse
Or ``reduce`` 😉
`std::move` is not only a cast, but also exists as a three parameter version, moving objects from one container to another.
http://en.cppreference.com/w/cpp/algorithm/reduce
I've used `std::mismatch` on a couple of occasions.
Ada and VHDL mandate parentheses to make the meaning clear. I'd not be surprised if they where not the only one. There are also languages without precedence at all (APL being the probably the most major one in those with infix syntax). I'd be surprised if there was a language with inversed priority. 
Looks to me like you want a zip iterator. http://www.boost.org/doc/libs/1_63_0/libs/iterator/doc/zip_iterator.html
Even if in the Pen case you choose not to add a default-constructor, the partially-formed state is natural, and always there. You need it as the state moved-from Pen objects end up in, so having the default constructor establish the same state is only logical, and adds convenience to the user for almost no work on the side of the class author. 
I completely agree: http://foonathan.net/blog/2016/08/24/move-default-ctor.html If you're adding move semantics (explicitly or generated), embrace the empty/partially-formed state.
Yes, and the default-constructed state would be the same (partially-formed). However, not having any other ctors means you can't construct a Rect from, say, (Point, Point) or (Point, Size).
Interesting! Seems to me that the only difference is, that you can tell the compilere to execute ``reduce`` the different steps in any ordering or even parallel, right?
check out Effective STL by Scott Meyers.
Quick question: In the `Pen` example, wouldn't the compiler generate the same move constructor/assignment (and probably mark them as noexcept as well?)
That's a loaded question. You don't get to assume that something is right for the job as part of your question, you have to first justify why something is right for the job and the burden for justifying that rests on you. Besides that... my argument is not that I would never use any DSL period, my statement was that I would rather mix in a library written in standard/modern C++ to use signals and slots rather than mix in a separate language that requires its own pre compiler and build system to solve the same problem.
VS2017 hasn't been released yet, and even if it had been, it'll be a long time before our shop will be able to migrate to it. We're still rocking VS2013. Hence the "can't wait".
i found std::nth_element useful in some algorithms e.g. building tree structures. It partially sorts (in linear time) the sequence so that on the n-th position, there will be element as if it was fully sorted, everything before it is lesser and everything after that is greater. 
No. Move of built-in types (incl. pointers) is the same as copy. So the compiler-generated move ctor would not null out other.d.
"Ha ha ha ha!" Our large, legacy codebase of C-with-classes-style C++ laughs at your optimism.
Thanks! Will add.
Algorithms of the form of accumulate / fold / prefix sum / scan are tricky because not because of GPU per se but because they are hard to parallelise. The obvious implementation has an inherently serial dependency chain. You'd have the same issues with threading and/or vectorisation on CPU (and as Sean Parent points out, if you are writing scalar, single threaded code you are utilising ~1% of the compute power of a modern PC). However good solutions exist so shouldn't be hard to find a library or reference implementation...
Follow up question: Is it important to null out other.d? Doesn't the standard require that is in unspecified state and can be assigned to. So even if we haven't nulled it out, we can still assign to it.
Shouldn't RAII be one of those "C++ 98 design pattern"s that "ought to also be very familiar to readers"?
[Direct link to Patreon](https://www.patreon.com/mattgodbolt) goes into more detail.
You've pretty much just summed up Part B of the tutorial. But to defend Expected, Expected is a *primitive* like std::vector. Some of the time you'll use it directly, but most of the time you'll wrap it up into something else more powerful such that people using it from the outside don't need to think about the primitives used to implement whatever it is. For that reason I think Expected ought to be standardised but with the same flashing warning signs all over it as anything in the &lt;atomic&gt; header - if you're frequently using this directly outside of library implementation, you're doing something wrong.
&gt; I seriously dislike that any filesystem examples do not include the file name in the error information. This will cause people to add that bit of context themselves, therefore adding to the verbosity. I agree, and both AFIO v1 and v2 embed the path (if known) of the item failed to open. AFIO v2 is a very heavy user of outcome::result&lt;T&gt;. &gt; IOW, just error_code is nowhere near not good enough as error information, not in my book. The function that uses that file is likely to return expected&lt;t, enhanced\_e&gt;, and is also likely to use an error type on the heap (e.g. expected&lt;t, unique\_ptr&lt;e&gt; &gt;, so that it can report different failures, because failures modes are many... &gt; There are libraries who report errors better. That's a shame, I think. Outcome provides an outcome::error_code_extended with extends error_code with a custom string, two u32 custom values and an optional stack backtrace, all without using malloc and keeping the trivial destructor. As that's an Outcome only feature, it's not described in Part A but is in Part B during which I assail the naive use of Expected exactly along the lines you just described. &gt; But doing that else will make the code even more convoluted. &gt; Bleh, really. AFIO v1's file open implementation approached 1000 lines of C++. AFIO v2's file open implementation which makes heavy use of outcome::result&lt;T&gt; is only a bit over 100 lines. The tutorial, like all documentation which requires contrived examples fitting onto a single screen, isn't representative of the amazing simplification and clean up that these transports can make possible. &gt; BTW, did someone measure the perf. price of default-constructing that error_code for all those return expected&lt;t, e&gt; structures? &gt; Exceptions cost, but those babies don't come with 0 tag on them either. error code is an integer and a pointer. Constructing them is sufficiently trivial I wouldn't worry about it. Also, it would be very rare that you would default construct an expected&lt;T, E&gt;, they are almost always constructed with some specific value in them. Finally Outcome, unlike other Expected implementations, was very carefully trial and error tuned for the optimisers of GCC and clang to produce zero assembler overhead wherever possible under optimisation. Per commit a suite of canned code sequences is compiled and the assembler opcodes emitted counted to ensure no accidental blow up. tl;dr; quite a lot of the time using Outcome to return values is completely free of cost in terms of assembler generated. As in, zero extra assembler instructions generated in an execution path.
I use it all the time and wouldn't want to see it go away. I threw a couple bucks his way. If I can afford 3 bucks a day on coffee I can deal with 1 buck a month.
In LTCG functions are inlined all over the place -- changing an inlined function of course changes the inlinee, and changing any function that might have been inlined changes whether it is inlined or not across the whole binary. Any time a function changes, you need to consider that function as well as all of its potential inlinee candidates; of course if the decision was previously "don't inline" and the new decision is still "don't inline" then the candidate inlinee can be left alone. At least on our implementation, the backend is responsible for inlining decisions, so what's in the .objs doesn't know what's inlined or not.
[next_permutation](http://www.cplusplus.com/reference/algorithm/next_permutation/) is very handy 
[removed]
I was approving their comments manually. (Mods can approve shadowbanned comments in their subreddits, they just can't lift the user's shadowban itself.) However, the shadowban does appear to have been lifted. The way to check is to click on the username and see whether their profile page is visible. If it's "not found", that's a shadowbanned user.
I have overridden the AutoModerator and approved this post; although it is a request for help (which we usually send to /r/cpp_questions), this appears to have the potential to start interesting discussion about starting in the industry and what good C++ looks like. If I were reviewing such code, I would absolutely be looking for egregious mistakes, indicators of low quality (e.g. rampant use of global variables and new/delete; not minor deficiencies), and so forth. High quality code generally looks like it, with attention paid to both style and semantics. (In general, I feel that if someone is lazy about style, I can't trust them to think about the semantics of their code either.)
Maybe post some code? Doesn't have to be 3k lines, even a snippet might be enough to begin a fruitful discussion.
`lower_bound` is a traditional binary search. I think a lot of things in `&lt;algorithm&gt;` are poorly named. It's very hard to tell what an algorithm does just by its name. There's also the fact that working with iterators is very annoying. Ranges and Concepts can't come soon enough. I'm hoping for a nice third-party replacement for `&lt;algorithm&gt;` that's a lot more intuitive.
&gt; When I say function object, I’m referring to any type with a defined operator(). Actually, that isn't the Standard's formal definition, where a function object is anything that can be called with parentheses. This includes function pointers, classes with overloaded operator(), lambdas (special case of the previous one), *and* classes that are implicitly convertible to function pointers. Granted, the latter basically never comes up except in &lt;functional&gt; unit tests. &gt; Most C++ programmers can probably agree that C++11 lambda functions changed their lives. On the other hand, "lambda function" drives me nuts. Lambdas aren't functions (or std::functions), but such terminology encourages confusion. &gt; Formally, a functor is a mapping between categories that preserves identity morphisms and compositions of morphisms. No, that's math. Programming is different. Mathematicians consider a "vector" to be different from what we consider it to be.
When I review applicants code, I'm generally looking for a few things: 1.) Are there obvious errors that suggest a fundamental lack of understanding (for example functions returning pointers/references to local variables)? 2.) Does the general feel of the code suggest that the author understands the modern form of C++, or are they closer to C-style developer who has just been introduced to classes? I don't need to see every last new corner of the language, but a sprinkling of features like range-based for loops, the auto keyword or move constructors suggest that the author has been following the language as it evolves. 3.) Is the code style clean and internally consistent? As other posters have mentioned, neatness and care in formatting and naming things gives the impression you were paying attention when you wrote the code. When I ask for a code sample, I'm only asking for a small amount of code. You have the option of sending me your best work. If it's a mess, I'm going to assume you didn't care. 4.) Is the code either well commented, or expressive enough that it's self documenting? As a simple rule of thumb, can I scan your code and understand what it does without having to pick through it line by line? Hit those basic points, and you are probably already ahead of a decent chunk of applicants. 
A lambda expression is an expression (like `2 + 3`) that defines a class type and constructs an object of that class type. Lambdas aren't functions (`printf()` is a function), and they aren't `std::function`s (although they can be stored in them). Lambdas, being classes with function call operators, are function objects. "Lambda function", while appropriate in other fields, suggests incorrect connotations in C++, and I strongly discourage that terminology. (I hate "closure" for entirely different reasons.)
&gt; On the other hand, "lambda function" drives me nuts. Well... [cppreference may need some adjustments then](http://en.cppreference.com/w/cpp/language/lambda) (EDIT: fixed it myself - the header for the lambda page was **"Lambda functions"**)
I keep seeing the phrase "modern form of C++", do you know of good sources to dig into what that means and looks like?
&gt; my statement was that I would rather mix in a library written in standard/modern C++ to use signals and slots rather than mix in a separate language that requires its own pre compiler and build system to solve the same problem. Qt is written in modern and standard C++. You could do everything moc does by hand if you want, and it would work fine. The fact that users of Qt are not quite that masochistic should not be treated as a knock on moc. After all I never see this much whining about the user interface compiler either, or QML for that matter.
It looks like you can specify default function implementations for types in rust: https://doc.rust-lang.org/book/traits.html#default-methods Though I guess concepts is duck typed with respect to concepts.
And how many people actually do that? And what would you do for `std::cin &gt;&gt; i &gt;&gt; j &gt;&gt; k;`?
It's very risky to do that because you can't check the `istream` internal state between reads (and you should). Of course c++ allows you to shoot yourself in a foot :) 
it means C++11 onward. 
I thought you meant building the iterators and the implementation of func. Ya, you have a point, I would find a use for inplace_transform or similar. 
Windows: CMake, Qt, GDB, QtCreator, not boost (i got my own headers for the necessary stuff).
Framework: Windows API (we write unportable code so you don't have to!) Editor/IDE: Visual Studio Code, most of the time. If I need to debug something I get out Visual Studio, if I need to edit a file VS code can't handle I break out Sublime. (I would use full VS for everything, but I get to work in codebases with varying whitespace styles, which is painful to do in full VS... maybe one of these days we'll clang-format our STL and tests and I'll get to use VS :D)
I'm in the process of learning rust right now, but it's my understanding that those default function implementations would only be available if you've explicitly implemented the trait (the non-default functions). So to pick up the default `fn is_invalid()` you still must explicitly implement trait `Foo` (in this example, `fn is_valid()`) for your type.
At work, I'm generally working within the framework of MSVC's STL (we have internal machinery and conventions that make our code very different from user code). We have surprisingly limited use of the Windows API, CRT, and compiler intrinsics. Most of our code is just layers of pure C++. No Boost, that would create a paradox. I write code in Metapad (an ancient freeware Notepad clone-but-better) and occasionally browse with Source Insight (because I learned it when I worked in Outlook and I am stubborn about changing tools). When I need true power, I have grep. Imposed upon me are TFS for source control and MSBuild for building, although I do work with git when dealing with libcxx's test suite, which is a surprisingly large fraction of my time these days. At home, I use mingw-w64, Boost, and a bunch of other stuff in my distro (FreeType, libjpeg-turbo, etc.). I write my code purely in Metapad, no Source Insight there. Although I avoided source control when learning, I've been using git happily for several years now. My build system is a handwritten GNU Makefile, featuring perfectly parallel and incremental builds with automatic dependency generation.
That's pretty cool, thank you for the information! I think there are pros and cons to each approach. The duck-typed interfaces in Go are surely convenient and it's nice having the compiler check for you, but on the other hand the explicitness of rust's approach is also nice.
C with classes.
Usually working with raw stl C++ cross compiling a framework using clang on mac, gcc on linux, and msvc on windows. I usually use VSCode for all my code editing, and we have a gradle build system set up for everything. Building an embedded software library for students on High School Competition robotics teams. We have our own utility libraries, which mostly includes some custom JNI utilities, and copies of many of the LLVM stack based data structures.
Current project is built in both XCode and Visual Studio. It's a custom graphics engine that uses Vulkan so all of the graphics programming is on windows while most other stuff is done on my mac laptop. The projects are generated by cmake. Major libs: OpenVR, Qt, Vulkan, libpng, gdcm, PortAudio [Bonus Video](http://globalnews.ca/video/3176140/virtual-reality-brain-developed-at-u-of-s-will-help-medical-students-and-surgeons-study-the-brain)
Binary files (Sublime has a built in hex viewer) or files that are enormous (for example, 700MB msbuild diagnostic log).
I use it at work to develop portable text analysis software. The build system is based on CMake. No Qt, Boost or any other framework. The language is C++ 98 as we have to support some 10+ years old compilers for the core libraries, but in some of the products that use them, I work with C++11. As for the dev environment, it is vim+gdb+ctags on Linux and Visual Studio+VsVim on Windows. 
also the one to use for median searches as well.
A bit... typeclasses define function tables -- kind of like virtual function tables -- that get passed to functions that require them. You get errors when a function argument doesn't provide an implementation of a required table. Concepts define no tables and require no explicit declaration of implementations. Satisfaction is based on substitution and name lookup. Nothing more.
+1 very much agree it's important to support such projects.
I agree doesn't seem right overriding or changing in general the exception behavior of streams.
Being in high school, I mostly learn do C++ as a hobby but I do plan on getting a job that involves C++ programming. I use Eclipse CDT, with G++ 5 on Ubuntu 16.04. I am currently most interested in GPU related applications. For window creation I use GLFW, I use GLM for maths, and Vulkan for graphics.
Why: Because C++ needs a better [build toolchain](https://build2.org) Language: C++14 Compilers: All of them (GCC, Clang, VC, ICC) IDE: emacs &amp; build2 Testing: [Testscript] (https://build2.org/build2/doc/build2-testscript-manual.xhtml) 
&gt; featuring perfectly parallel and incremental builds with automatic dependency generation *(since I don't do any source code generation)* There, fixed it for you ;-) 
&gt; (we have internal machinery and conventions that make our code very different from user code) Understatement of the year.
&gt;Currently switching many of my projects over to scons, because there's only so much flexibility that I can add to make before it becomes painful. May I recommend Waf?
&gt; ROOT, working on data analysis. The less I say about the ROOT framework, the better. why whats wrong with ROOT? 
At work I use VS2015 on Win10 and KDevelop/GCC 4.8 for ARM and x86 on Linux. Mainly I work on a 2FA desktop and embedded applications with smartcards, most of the components are cross platform and as external libraries, I use boost, openssl and thrift. For GUI, Qt 4.8 is being used on ARM (due its graphic limitations, I cannot switch to 5.x) and MFC for Windows, because of the limited space given by Credential Providers on Logon process. I also develop drivers with the Windows driver framework, so there's a bit of specific ATL/COM code there, like for the custom credential provider as well. On Linux, the main part is in C, but the core utilities are in C++. Our code is full C++11 and we cannot upgrade everything to 14 because of the old GCC toolchain for ARM, but with ifdef guards, something is already using c++14. For testing, Google Test is the main framework and QTest to support GUI testing. On the driver development, I'm experimenting Doctest, which is pretty fast. Everything is being built with CMake and Jenkins and recently I'm trying to switch to Conan, but there are still limitations on cross compiling, while on desktop everything works well.
Everyone is quick to downvote without realizing that in some countries 1USD can feed a family while in others it's a pocket change you would kick when spotted on the pavement.
vim with a few plugins + gcc + gdb + make. we use c++11 and c++14 with STL and boost where applicable. job entails making servers, clients and gateways, and other stuff.
At work, as an infrastructure language when I need to step out of JVM and .NET stacks: - Binding to native libraries that aren't easily exposed via JNI, JNA, P/Invoke, RCW, UWP Controls; - Interacting with the native APIs from the JVM and CLR for low level control; - Optimizing functions where all options at JVM, CLR have been exhausted; - Before Microsoft bought Xamarin, to write portable code between Android and UWP. Which I must confess, happens very seldom, just a few times in a full year. As hobby, it is probably the language I mostly use. I learned it back when C++ARM was the only "standard" and I was searching for a language with more portability support in the industry, while allowing me for Turbo Pascal like safety and expressiveness. Actually I am happy to seldom use it at work, because most of the enterprise code I happen to look at, is just plain C with Classes, full with the typical safety issues. Majority of enterprise projects shy away from C++ best practices, unfortunately.
That's generally an improvement (global variables are pretty evil). However, algorithms aren't objects.
What plugins do you use?
Have you looked at your header files? You guys could at least get together on tabs vs. spaces. Every time I have to go look at an STL header and my VS plugin tells me they're inconsistent it makes it sound like the library was written in crayons by children^1 :) Also, and I'm just curious, why aren't implementation-specific helper template things organized at least into "details" namespaces or something? At least then I could use my IDE to collapse them if I'm there to look at the interface and not the nuts/bolts. ^1 That plugin is supposed to be for me to whine about _our_ libraries, written in crayon by actual children
What about algorithms used to parameterize other algorithms, like passing ordering lambda to sorting function or specializing `FileEncryptor` to use SHA1/RSA/AES ?
Qt Creator. Multiple compilers &amp; platforms. No reason not to be portable. I really enjoy QBS, the next-get build system for/by Qt - However, you may wanna stick with CMake who apparently won the race. I use cccache when I can. I use valgrind, vtune, etc. In my previous job, I had a jenkins instance doing the build. It's horrible to setup. Someone should come up with a c++ oriented/multi platforms/multi-compilers CI, easy to set up, compatible with qmake/cmake/etc and bonus point for distributed build and caching. I use Gerrit as a pre-commit build gateway to ensure the code was still functional under all platforms. No unit test because I'm an horrible person. I like using Qt, a lot. I use boost with bcp - a great tool to tame the monster. Mostly to get stuff like std::optional. I've used ranges-v3 a bit with great enjoyment. And git. Obviously. start there. On my time I went from svn to bazaar, to mercurial to git. Use git.
Its useful, but I'd love to have it a plug into to a text editor.
I really enjoyed this article, and I think the distinction is useful. "Function object" is (AFAIK) a term which grew up in the programming world and clearly communicates its meaning. "Functor" is a term which certain programming communities have borrowed from category theory and twisted into something related, but not the same. If you talk to someone who is unfamiliar with the terms about "function objects", they'll probably be able to intuit what you're talking about pretty easily. "Functor" is less obvious, and downright confusing if you come from a mathematics background. Why not use the clear, non-overloaded term? In addition to the clarity, it'd free up the other for discussing functional programming and category theory and how they can be applied to multi-paradigm languages like C++.
remove_if doesn't reorder an array, it leaves the space behind the new end in some garbage state. If you want to reorder an array (move all invalid elements to the end), use std::partition.
&gt; it makes the examples seem unnatural and contrived. There's a destructor releasing a resource, but where's the matching constructor doing acquire-or-throw? Why would sane C++98 code have catch(...)? Oh I see what you mean. I remember when I was writing that that I would normally have used a custom deleter on std::unique_ptr to delete the temporary open file descriptor, but we don't have that in C++ 98. I'll see if I can rework that example to be less contrived. Thanks for the spot.
TL;DR * **uniform**: `build2` looks &amp; feels exactly the same on Linux, Windows, MacOS, FreeBSD, etc., whether you are using GCC, Clang, VC++, ICC, etc. * **fast**: we are not only running the external tools (compilers, etc) in parallel, but the build-system itself is multi-threaded (so we can, for example, parse header dependency info and obtain timestamps in parallel). We also run tests in parallel (see [Testscript](https://build2.org/build2/doc/build2-testscript-manual.xhtml)). * **cross-compilation** is the norm, not an afterthought (we even support *cross-testing*, e.g., running cross-compiled Windows tests on Linux with Wine). * **sane syntax**: for example, here is the [`buildfile`](https://git.build2.org/cgit/build2/tree/build2/buildfile) for the build system driver. * **build model**: `build2` has a conceptual models of how things are build. In this sense it is more like GNU `make` rather than all the other build systems/project generators which are essentially back boxes. * **reliable builds**: `build2` goes quite far (like checksumming the C++ compiler) to make sure that when it says things are up to date they really are. * **source code generation**: `build2` supports complex projects with automatic header/source generation. For example, it can automatically extract header dependency information (`-M`, `/showIncludes`, etc), detect missing/out-of-date headers, (re)generate them, and then re-extract. This was my #1 issues with GNU `make`. * **extra operations**: `test`, `install`/`uninstall`, `dist`. * **package manager**, which, again, works exactly the same on all the platforms. All these points (and more) are covered in more detail in the [FAQ](https://build2.org/faq.xhtml). If you want to see what using `build2` would feel like, check the [Intro](https://build2.org/build2-toolchain/doc/build2-toolchain-intro.xhtml) (you don't even need to install anything -- it shows the output of all the commands). Or, if you prefer the audio-visual version, there is the CppCon [Presentation](https://www.youtube.com/watch?v=hHRaZy1LZPA) (there you can see me running `bpkg` first on Linux then on Windows and the only difference is how the slashes look ;-)). For more resources see the project's [Documentation](https://build2.org/doc.xhtml) page.
Often enough you really don't have to, because either the input is formated correctly or you it's an error one way or another anyways and the details are not so important.
&gt; That is probably good enough, but still considerably less rich than what can be achieved with exceptions. If you're doing rich things with exceptions, then you're likely working in a use case where you could just attach a std::string or other rich information into a custom error_code type. &gt; It also comes with a performance price, no? If you don't use the extended info, there is zero overhead, no extra code is touched. If you do, it's the cost of a single atomic increment and memcpy of the extended info. It's competitive with an exception throw which tends to drag a lot of cold cache lines in as the EH tables are spidered. &gt; I rather meant: one always default-constructs either T or E and that has a cost, error or success. But that could be avoided through a convenient usage of placement new, I suppose. Like that? If yes, then indeed, an optimizing compiler should be able to avoid all overhead. Well, not stack usage, yes? Outcome's outcome&lt;T&gt; and result&lt;T&gt; do NOT default construct to a T like expected&lt;T, E&gt;. They default construct to constexpr empty. If you are referring to move or copy construction, those use placement new into the union storage. Move and copy assignment uses the move and copy assignment operators when possible, but if storage needs to be switched it'll use move or copy construction instead. Optimising compilers do a great job with Outcome's code, for example: int main(void) { using namespace boost::outcome; result&lt;int&gt; f(5); auto g = (f &amp; 6) &gt;&gt; [](auto v) -&gt; int { return v==5 ? 2 : 8; } | 2; return g.value(); } Compiling this with GCC 6.2 with `-std=c++1z -S -O3` yields this assembler: .section .text.startup,"ax",@progbits .p2align 4,,15 .globl main .type main, @function main: .cfi_startproc movl $8, %eax ret .cfi_endproc So that is four `result&lt;int&gt;` instances constructed and destructed above, two copy operations and one move operation, all elided by the compiler.
I dunno man. GPUs suck. The whole pipelining thing makes it super difficult to get high performance out, because you need to ensure there's always sufficient work going to keep gpu utilisation up Its much easier to make a threaded/vectorised implementation though. CPU vectors are easy conceptually, and you can easily use them to get fast. Threads on a CPU are comparatively simple to understand, and high performance synchronisation objects are already widespread. There's stupidly simple tools like OpenMP, and there's no thick wedge of API between your code and the CPU GPUs though have 64-1024 threads going at once. But they don't really exist, you have fixed sized warps of threads which are similar to SIMD, at 32/64 (which can be abused for fast interthread communcation), although there's no way to query this at run or compile time in portable versions of OpenCL Then you have a step up from that (2 really, but the half warp/warp distinction is not relevant here) which is your local work group, which can be synchronised using slowish barriers, where you have a local cache/memory whatever that can be used to exchange information, although at the expense of performance depending on the size you allocate. The size of your local work group can vary dramatically, and dynamically depending on your settings There's nothing like that on the CPU. And then depending on your global work size, you have anywhere between a few and a bunch of local work groups operating 'in parallel'-ish (but not completely), with absolutely forbidden synchronisation between them So if you want to finish the last step of accumulation, you have to launch a bunch of kernels to do it. Which involves the pipelining issues, possibly having to fiddle about with asynchronous reads, and all through a hideously clunky API And that's just pretending that both vendors have the same performance profiles. If you go cross vendor/OS... RIP you. None of those issues (to the same degree) on cpu
Would it be worth applying with very little Windows but lots of Linux experience?
I think at this stage (RC3) those would be pretty obscure corner cases. In particular, I would not expect any missing/broken language/library features to be implemented/fixed. For that we will have to wait for Update 1. 
I agree, but I personally would be interested to see the corner cases anyway.
Real-time software, usually - things where I need the performance of C++. My two biggest projects are a commercial music practice application which loops recordings for you to play against, and an open-source Python extension that does fast color arithmetic. Using: C++14 (for the DSP)/C++11 (for the Python extension) - the JUCE toolkit, Google protocol buffers and the Rubber Band DSP library.
STL headers should be consistently tabby (I personally prefer spaces). Perhaps you're thinking of non-STL headers which get put into the same directory. The STL has access to the ultra-powerful _Ugly convention, which we gotta use anyways (to defend against macros). A details namespace would be redundant. (That said, we've talked about teaching the IDE to ignore _Ugly machinery; I forget whether that's happened yet.)
Aye, so am I.
Also some of us are poor lazy jobless ingrates (including myself)
That looks reasonable. I assume there's an ability to say "compile all of the cpp files in this directory according to this pattern". &gt; build2 has a conceptual models of how things are build. In this sense it is more like GNU make rather than all the other build systems/project generators which are essentially back boxes. Hmm, this is interesting - can you explain a bit more? What I like about make is that once you understand how it's based on a DAG, its behavior is straightforward. Any build system that relies on "passes" or "phases" is instantly rejected by my brain - there are no such things in a DAG.
e: ~~idk who's downvoting you (it isn't me) but you're negative atm and your response is actually informative~~ maybe it was vote fuzzing, I don't want to look too dumb tomorrow when you're at +982734 karma Does type_traits count? http://i.imgur.com/K42HNIM.png And yeah, heh, if one underscore isn't enough, use two or three! Whatever it takes! :)
How actually stable/usable is it currently? I'm currently looking for a cross platform build tool, and the fact that it has dependencies and package management is also what I want, but I'm suspicious of anything not 110% mainstream
Computer graphics - custom raytracer written in C++ and CUDA, and OpenGL applications Environment: Visual Studio + CMake Libraries: glm (math), SDL (window management), glew (OpenGL wrapper), Thrust (STL-like library for CUDA)
Yes, real world is what we are after. That's why it is taking a bit of time to lay the foundation.
Do you mean VPSes you happen to own? Or 3rd party providers?
It's very good at what it's built for but it is also... Let's just say a bit odd (although it's improving a lot compared to just a year ago)
Didn't know it was 1 USD. I can dontate that!
Your code and the resulting disassembly are not representative, compiler read through everything and evaluated it. Try this: int main(int argc, const char* argv[]) { using namespace boost::outcome; result&lt;int&gt; f(argc); // Eat this, nasty optimizer :-). auto g = (f &amp; 6) &gt;&gt; [](auto v) -&gt; int { return v==5 ? 2 : 8; } | 2; return g.value(); } Real software depends on the outside, you know :-). &gt;&gt; That is probably good enough, but still considerably less rich than what can be achieved with exceptions. &gt; If you're doing rich things with exceptions, then you're likely working in a use case where you could just attach a std::string or other rich information into a custom error_code type. I am rather thinking of this: void f(params) { if (!whatever1(params)) throw error_1(params etc); if (!whatever2(params)) throw error_2(params etc); } I think I can't do the above with outcome&lt;t, e&gt;? That's what I meant by "because failures modes are many" in my first comment. I need "e" that encompasses both failure modes, no? If so, my complaint is: at a scale, outcome&lt;t, e&gt; forces people to cram everything and anything into "e" (or live with a couple of numbers and a string, which is poor).
Make sure the code samples work/will run. I've seen so many people not check that. 
I just switched. There's no indication that scons will support python 3 any time soon
at work, in a linux teminal : vim make gdb same at home 
One of the first comments on TFA was about compile-button. I think that is a great cost-saving measure and will make editing the code also more user-friendly; win.win. Just make the compiler automatic when first load the page so that clicking shared link will display the results automatically. Had to repeat it here to make the comment more visible.
Ooh, boy. Let's go with a short list of a few of the problems. * Huge reliance on global state. For example, you cannot explicitly specify which file an object should be written to. Instead, it gets written to the currently active file. Or, you can specify that the file should write everything that it owns, which leads to the next point. * Incredibly weird ownership rules. For example, any histogram that is constructed belongs to the currently active file, unless there is no active file, in which case it belongs to the calling scope. This means that declaring histograms on the stack doesn't work, because the active file may have claimed ownership of the stack-allocated object. * Reliance on unique names. If you open two windows for displaying histograms, and they both have the same name, the first one will silently be closed. * Global state + unique names. Suppose you want to take the projection of a 2d histogram. The function signature shows that it returns a 1d histogram, which makes sense. However, that histogram may be (a) a newly generated histogram owned by the calling scope, (b) a newly generated histogram owned by the active file, or (c) an existing histogram that was overwritten and is owned by maybe the active file or maybe a different scope. You fall into case (c) if you accidentally name the projection something that already exists inside the active file. * Global state relating to drawing as well. Everything gets drawn to the currently active pad, no exceptions. * As a result of all the global state, multithreading is a royal pain. You need careful mutexing around completely unrelated actions. Calling `TThread::Init()` activates some of root's internal mutexes, but not enough to avoid segfaults. For example, calling `TObject::InheritsFrom` on one thread while `TTree::Branch` is called on another. * Reading user-level configuration files without letting the program ignore them. For example, if a user has the line `Root.ObjectStat: 1`, it will activate some tracking code that runs in the constructor and destructor of every single object provided by root. This tracking code is not at all threadsafe, causing segfaults at nearly any point in the program. * Really weird class hierarchy. It is impossible to specify "function that accepts a 1d histogram", because 2d histograms are a subclass of 1d histograms. * Really, really big amounts of scope creep. There are some things, like neural networks, that exist in root, but probably would be better to use from an external package. Then it goes off the deep end, and includes a [web browser](https://root.cern.ch/doc/v608/classTGHtmlBrowser.html). * Classes with far too much responsibility. For example, the main histogram class is responsible both for holding the histogram data, and for displaying it. As a result, you cannot display the same histogram with different ranges in two different windows. This is a small sampling of things. I'm keeping a list of issues with root, just to keep my sanity. There are currently 177 items in the list. Most of them are design issues, rather than outright bugs, so they cause pain without being justifiable cause for submitting a bug report. Some things have been fixed with root6, the latest major release, when they switched to an llvm-based C++ interpreter. Ooh, yes, I almost forgot about that. It has a C++ interpreter. All the flexibility of C++, and all the speed of an interpreted package, all wrapped up in one! Its existence is the best way I have to understanding the many design flaws in ROOT. In order to have a decent experience in the interpreter, you want to have as many shortcuts as possible. Since the interpreter is just a wrapper around the libraries that already exists, use of root as a compiled library has those same shortcuts there. The existence of the shortcuts, and all the global state they require, makes compiled programs be a royal pain. I'm trying to wean myself off of root, mostly switching to plain C++, numpy, and matplotlib, but it is a long time coming, since I have a large amount of code that depends on it. I had thought that once I learned the pitfalls of root, I would be able to avoid them. Instead, as I go deeper and deeper, I find more and more pitfalls.
I use c++ for graphics programming mostly. I use OpenGL, GLFW, GLM, easylogging++, and nlohmann::json. As far as build tools and editors go I use the CLion IDE, which entails using CMake
Well, scons's release notes say that the current version is the last that will support python versions before 2.7, as they "begin to move toward" supporting python 3. Granted, the last 7 releases have said that, so maybe that should be taken with a grain of salt.
&gt; Your code and the resulting disassembly are not representative, compiler read through everything and evaluated it. It took over a month of me trial and erroring internal implementation variants to make GCC and clang's optimisers correctly collapse code like I just demonstrated. It is **highly representative** of the value added by Outcome over alternative implementations. If you try one of the many C++ monad implementations on the internet, you'll find they are nothing like as lightweight. I went far out of my way to achieve that, and wrote a per-commit CI test to ensure it stays working. Regarding your second example, sure it generates lots of assembler to cover all the use cases with could occur from a different argc input. But if you follow execution with the debugger, assembler executed still remains ideal. And it will have pruned emitting branches not possible to execute. So my claim holds. For some given inputs, Outcome is tuned very carefully to make GCC and clang emit as optimal code given those inputs as C++ and current optimiser technology allows. &gt; I think I can't do the above with outcome&lt;t, e&gt;? That's what I meant by "because failures modes are many" in my first comment. I need "e" that encompasses both failure modes, no? If so, my complaint is: at a scale, outcome&lt;t, e&gt; forces people to cram everything and anything into "e" (or live with a couple of numbers and a string, which is poor). You are for some reason thinking it's all or nothing. outcome&lt;T&gt; lets you transport a T, an error code or an exception pointer. If some function is best written with C++ exception throws of very custom types, then rock on with that. If the function which calls that function is best written with a result&lt;T&gt;, then the outcome&lt;T&gt; lets you return, *without loss of information*, all possible error outcomes, *including throws of custom C++ exceptions*. That means you're pushing the complexity of dealing with lots of different error handling systems onto (effectively) the main() function. But that's a design choice regarding cost benefit for the programmer. Outcome provides stuff which eases implementation of some code patterns. It says nothing about wise nor sane usage of that stuff, though I try my best in the tutorial to dissuade people from certain practices. Finally, nowhere in Outcome am I suggesting your need to use outcome&lt;T&gt; everywhere. The Mk 3 tutorial no longer mentions this, but a mixed mash up of C++ exception throws with Outcome is a very powerful design too and very suited to some code bases. One of my embryo libraries uses result&lt;T&gt; to return expected errors and throws C++ exceptions for unexpected errors, thus implementing a "transaction undo" abort execution flow. Very elegant design, suits that problem domain perfectly. So tl;dr; use Outcomes where they make sense, don't use them where they don't make sense. Outcome is designed to make doing that as easy as possible on you. Mixed error handling strategies in a single code base is absolutely embraced and encouraged.
A VPS is basically just a fancy name for a VM or system container. It runs your choice of Linux distro, and has a public external IP. You're pretty rarely in the web interface, since it's basically just: * Power off * Reset * Reinstall * Emergency SSH (connects to a tty connected to your container) or access to the KVM.
For me the automatic compilation is the most useful part :) I don't know how much it'd save costs: most of the time the site is responsive enough with a single host, unless you've found it laggy sometime?
i use c++ for school, and use code::blocks and bitbucket to develop work! :) simple but it gets the job done 
As a counterpoint, the firewalls at work make every request high latency (talking seconds to minutes of latency). I've been tempted to spin up a local version, but even just having a switch for automatic compile + compile button would help a lot.
&gt; It took over a month of me trial and erroring internal implementation variants to make GCC and clang's optimisers correctly collapse code like I just demonstrated. It is **highly representative**... Dude, if you were always trying code that can fold into constexpr and cause the compiler to return a calculated value, you wasted a month. Real world code depends on external inputs that the optimizer can't fold into "ret 8". I **can't believe** that you showed a completely misleading disassembly and replied with this wall of text when shown how wrong you were. Care to show the dissasembly from my snippet? That would be honest, you know. &gt;But if you follow execution with the debugger, assembler executed still remains ideal. What do you mean by that. What is "ideal"?! I am not claiming that your implementation is inefficient, far from that - how can I, without trying for myself etc? But now I think that you are missing major bits of understanding how those things work.
Framework: DirectX / OpenGL / Vulkan Editor/IDE: Vim with visual studio or MinGW as compiler.
I found **Thinking in C++ by Bruce Eckel** useful. It wasn't my first language to learn though. I would also recommend using a free version of Visual Studio, learning command line compilation and tools like CMake later. Important - learn purpose of pointers an how they work in C++ early on
JBCoe has a compiler explorer docker container here: https://hub.docker.com/r/jbcoe/godbolt-compiler-explorer/. It works without any network connection.
do you have any gdb frontend you like? or are you just using plain old gdb? I'm using cgdb, but its clunky. Building the latest version from source, but its kind of buggy and locks up occasionally.
What do you ( still) use OpenCV for?
My work uses Makefiles + CMake + Apache Ivy for the build system. I don't know what other people use to edit with, but I use gvim with a bunch of extensions + valgrind + gdb.
Carefully. C++14 adopted parts of C11 but notably omitted parts that were unnecessary/incompatible with C++ such as C atomics or C99 VLAs.
no frontend. The idea is to be able to deal with the minimum set of tools. That way, on almost any server, I can work without needing something to install. 
Your points are good, and worth reaching for, but I wouldn't be so critical of entry-level, just out of school code. Unless they're a rockstar, who has been coding on their own for years and just went to school for a piece of paper, they're simply not going to know or understand much of what you just talked about. They'll know whatever C++ they were shown in school, if any (many don't anymore--it's Java or C#). Your first bullet is probably a wash. If I saw any amount of cleanliness I'd be quite impressed. I'd also expect it to be quite unintuitive and difficult to read. The Colleges and Universities just do not prepare you for real coding and 4 years is frankly not enough time to learn much in that environment. If I hired someone strait out of college I would expect to be mentoring them 99% of the time and having to pay extreme attention to anything they wanted to check in. Basically I'd be paying them to educate them, not to get anything really accomplished because I hired them. Of course there are those software companies that just hire out of college because it's cheap and they're small and/or penny pinchers. Code in those places is generally terrible and when I did interview people (I worked for one) I just crossed my fingers. Best one I found was a college dropout and he was actually good. Our interns were pretty much wastes. The things you really need to know were not taught when I went to school. We paid elementary attention to memorizing what "cohesion" meant, but beyond that--no techniques or anything like that. Data structures, OS theory, Language theory, and other generally useless fodder was thrown at us through a fire hose. Based on the garbage I see posted on SO regarding homework...I don't think anything's changed.
I just find it a bit annoying, with the editor constantly jiggling around with currently irrelevant error messages coming and going. But thanks for the tip that ctrl-enter works if you toggle auto-compile off, that's useful to know.
I see, thanks! When you get that pattern ability, let me know, and I might try converting my build system at home. Your phases are sane (they apply to how the build system figures out what to do, not how the execution of the rules work).
Probably so. I could swear I've seen mixed white space farther down a file, but I don't remember if it was in the STL.
Your example compiles down to `8` for the same reason. Any int input would be a positive result, and that value is immediately discarded. Yay compilers. A more interesting example would be result&lt;int&gt; bar(result&lt;int&gt; f) { return (f &amp; 6) &gt;&gt; [](auto v) { return v == 5 ? 2 : 8; } | 2; } That completely inscrutable compiles into a single branch, one of which still moves 8. It's optimal for at least the operation.
A simple example is this (from [SO](http://stackoverflow.com/questions/1887097/why-arent-variable-length-arrays-part-of-the-c-standard)): int x[n]; std::vector&lt;decltype(x)&gt; y; What is the type that the vector y holds? Well, if n is a compile-time constant, then it's an array of `int[n]` whereas if it's a runtime value it's an array of `int*`. Things like sizeof also become messy in that there are scenarios where it's not a runtime constant. There's other challenges like what does `A x[n]` do when n is a runtime-defined value due to needing to invoke constructors, destructors etc. Of course it's not that these aren't intractable problems but the C++ committee probably thought it wasn't valuable for C++ &amp; that Here's an alternative C++-centric mechanism Stroustrup proposed: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3810.pdf It has its own challenges but I would bet if C++ ever got a stack allocation mechanism it would look a lot more like that.
And on top of that, I'm not even sure the functional crowd is using the word quite right even in the mathematical sense. Granted this is based on a skim of the [Wikipedia description](http://i.imgur.com/u2DVmwe.png), but it sounds to me that a functor is the function that maps values, whereas the functional crowd says a functor is the *container* that *is mappable*. So in a std::transform example: // associates to each object X in C an object to_upper(X) in D transform(c.begin(), c.end(), back_inserter(d), to_upper); Based on the Wikipedia description, I'd think "to_upper" is the functor, the thing that maps values. But the functional crowd would say "c" is the functor, the container that is mappable. Thoughts?
Both for work, and personal projects (mainly in cosmology and scientific computing), and C++14 all the way. I use VS at work, and a mixture of VS and CodeBlocks at home (laptop is on Linux, desktop is on Windows) so CMake support in 2017 is something I'm very much looking forward to to stop having to maintain two different solutions/workspaces. Libraries: boost both at work and at home. At home also a few other libraries, primarily FFTW, the LLNL Silo libraries, a C++ port of QuadPack, and a small collection of other integration and interpolation libraries I've built up over the last couple of years. (And also a couple of cosmology integrators, one in a doggy mixture of F77, F90 and F08 that I put together over the last decade or so. It's... very ugly.) Edit: also, testing. CPPUNIT at work, Boost::Test at home. Git for source control at work, along with a couple of old TFS repositories. Mainly git at home, but some Mercurial repositories too.
Is it just be there for binary back compat and not exposed in the headers? gets() is just pure evil...
thanks ! 
I recall a talk Stroustrup gave once in which he said he didn't think "class" was a good name. He'd prefer a class be called a "type". But, he said, the Simula guys were mathematicians, and "class" is what made sense to them.
Now known as Windows Store apps or Windows 10 Universal App
Try thrust::reduce
The buildfile has too much magic special case syntax. It is yet another language for which I have to Google basic syntax every time I use it (like cmd.exe, sh, Make, etc). It also seems to be stringly typed which is awful for correctness and productivity. Why not use an existing programming language? You are repeating CMake's mistake: Coupling the useful features (portability, a sane build model, reliability) with an awful language. Why not build this as a library with different language bindings?
I'm working on a Win32 security middleware with OpenSSL and the PKCS#11 smartcard API. It's slowly being rewritten in C++11 using Visual Studio 2013. I also compile it with MinGW because that gives me some different warnings. Other useful tools I use are VIM, git, doxygen and plantuml. Edit: typos
MSVC's `system_category` already does this (after I fixed it to use FormatMessage).
 Really useful, especially like that it supports MSVC since most online compilers don't-
I'm pretty sure that a majority of programmers alive today were first introduced to the word "functor" through the "function object" meaning. This ship has sailed a loooong time ago. https://en.wikipedia.org/wiki/Functor_(disambiguation)
[removed]
Sure. Decent beginner problems.
Thanks. I've put together a pretty cool web portfolio and mentioned my work as part of teams in my cover letter. Are there any other major things you look for when hiring new programmers? I hugely appreciate you replying by the way! 
I wonder if the vector still wins out if you include the sort operation?
I'm not sure how dumping out an inlining report would have helped. When I started the investigation I had no idea that inlining was the problem. Once I knew it was the problem my work was done. What I knew was that an unwanted object file was being pulled in, but only in LTCG builds. Analyzing the verbose linker output told me what. It was a somewhat slow process, but it was methodical and almost guaranteed to give results. 
When building Chrome we have many build settings in order to let us tweak the tradeoffs between run-time performance and build times. - LTCG has the longest build times but produces the best run-time performance - Release builds have much faster build times and still have very good run-time performance - Release component builds break Chrome into many more DLLs and, when all goes well, allow incremental builds that take ~5-10 seconds, but DLL boundaries and incremental linking cause some harm to performance The multi-minute and hour long build times are reserved for special occasions such as investigating full-release-only bugs. There are also debug builds, optional server-farm compilation, and many other variations. 
You can almost treat inline qualifier to method almost meaningless to an optimizing compiler. It may tweak its heuristics to make the method more favorable as the inlinee, but is not a guarantee (at least most compilers out there?) that it will always get inlined. For such, use attribute((always_inline)) or macro method.
No, not at all laggy. The error messages just get in the way. Thanks for your cool website. It's the best.
We use OpenCV to quickly test viable research paths. It provides a lot of algorithms that we can play with, like canny edge detection or optical flow. We also use it for some internal tools, though those tend to be written in C# nowadays. We do embedded video analytics for threat prevention / business intelligence. 
&gt; Your example is wrong because it shows the power of the optimizer: it could read though your code, which can be evaluated at compile time, and gave the result. But that is largely irrelevant, because in real world, code is subject to inputs, and they break such compile time evaluations. People don't write convoluted crap to come up with a known number, they write the number down, for crying out loud! You appear to not understand how optimisation works. It's optimisation based on the *constraints* applying. If you feed code unconstrained inputs, you get code for all possible inputs, which is optimum. If you constrained your inputs to one of two possibilities, because I've gone that extra mile not to spook the optimisers, the compiler should only generate code for those two inputs and any other inputs for other code those generate. In other words, optimum. &gt; Your example is wrong because it largely does not show the ease of producing optimial code for your sources. It merely shows that the optimizer wasn't fooled by your long-winded constant. No, it demonstrates that I've gone the extra mile to not spook the optimisers in recent GCC and clang for various code patterns. They get spooked easily, they are very jittery beasts. If you'd spent any time doing this sort of micro optimisation yourself you would not be arguing with me and instead you'd be congratulating me on a job well done. &gt; tl;dr if you want to evaluate codegen quality for the real world, you need to have outside input in your code. &gt; Kindly show the generated assembly from my example. It's irrelevant as I've already said. Anybody can write C++ which forces the compiler to emit code for all possible inputs even when those inputs are clearly constrained and the code generated is provably never, ever executed. The more you can help the compiler to eliminate potential execution paths, the more it snowballs as you write more complex sequences to eliminate even more code. You also appear to not understand that this type of optimisation serves best inside lengthy bits of logic. The inputs to some large block may be unconstrained, but in a long sequence of logic the optimiser may be able to tease out consecutive runs of logic and collapse them into special "fast path" cases. I use "may" because to date I've not seen this happen with profile guided LTO on GCC and clang, but future optimiser technology could do this.
It is likely, yes. As mentioned by STL above, `vectors` are loved by CPU because their memory is contiguous, which make them very cache-friendly, and this kind of benchmark is essentially memory/cache bound. Unrestricted implementations of sorted/hashed sets based on arrays (B-Trees, open-addressed implementations) could perform much better than their standard counterparts; of course, they would have other trade-offs.
I still can not get around pointers and the purpose of them, Do you haven any good read for it? I mean, when someone should use pointers etc. ? 
Hash table/`unordered_map` can also be useful in the following cases. 1) frequent lookup. For a huge data set, a hash table lookup is often cheaper than a binary search on a sorted vector. 2) too many duplicated elements. For example, for counting the number of distinct words, hash table would be a better data structure than reading all words, sorting and then counting.
[I'd not waste time](https://www.reddit.com/r/cpp/comments/5msdf4/measuring_execution_performance_of_c_exceptions/dc8qc2b/?context=1) with /u/Gotebe if I were you.
TL;DR: no.
I didn't know about passing a QObject pointer as a "lifecycle context". That takes a lot of the potential risk out of connecting signals to lambdas. 
&gt; Ok, show me a commit of yours which was made to help the compiler improve the codegen and the resulting codegen difference? One is enough. How is it somehow on me to do the work to demonstrate that you are mistaken? That's on you matey. I'll do my best to tell you how to replicate my claims, but in the end, I'm providing a C++ library free of charge to you. I can claim anything I like on that library and I have zero obligation to you. Absolute zilch. &gt; I see your point, but do not buy it. tweaking the code to accommodate any given optimiser state is a fools errand. Optimisers move, you have no guarantee that a particular shape of the source code will stay "optimal", or that some other form will not become better. As I've mentioned several times now, there is a per-commit CI test ensuring various canned sequences do the right thing. That catches compiler optimiser bugs nicely, and to date the teams behind all of MSVC, GCC and clang have been more than happy to fix my optimiser bug reports. &gt; Euh, no this fails basic logic. It shows that one version of one compiler wasn't spooked by that one sample. You have some very weirdly harsh opinions. I wrote standards C++. It compiled to good code on various compilers I tested. Never at any stage is there any guarantee that some future version of any compiler won't produce segfaulting garbage on mine or anybody else's code because those compilers are supplied to you and me free of cost on a "best effort" basis. You are making exactly zero valid points here. &gt; Finally, if you are so confident in the quality of your work, show the disassembly for my example? I will repeat myself: I have zero obligation to you. I supplied to you a high quality C++ library free of cost representing hundreds of hours of work. It is 100% on YOU to prove or disprove any claims I made in my free of cost piece of work given to you for free, just the same way as it's on YOU to find and report bugs in that free of cost library to my issue tracker. If you come up with a failure to optimise to optimal code, please report it with reproduction on Outcome's issue tracker and I will look into it. Otherwise, I don't see any point in further discussing this.
I think you skipped the *"Let C and D be categories"* part. `c` from your example, an instance of a type (for example `std::vector` that you are passing to `std::transform`) is not a category. So, you can not apply the definition and get *"associates to each object X in C an object to_upper(X) in D"*. In your example, the type of `c` along with `std::transform` defined for it is the functor. 
I disagree in the strongest possible terms. Understanding that a lambda defines a class and constructs an object of that type (not an ordinary function, not a std::function) is crucial for reasoning about how they behave. It's important to understand how lambda objects interact with **lifetime** (e.g. reference captures don't prolong lifetime, so a long-lived lambda object must be careful), how they interact with dynamic memory allocation (e.g. lambdas don't inherently allocate memory, but value captures of objects can), etc. This is not something that can simply be ignored, unlike low-level backend details.
In the release notes (https://github.com/nlohmann/json/releases/tag/v2.1.0), there is the MD5 of the json.hpp header.
Ahahaaaa, excellent! Didn't realise what f &amp; 6 does. I wonder why the other redditor didn't set me straight then!?
It depends on the use case, and its not there to help with malicious action from a maintainer, but rather to protect from a MITM (man in the middle) attack, where an attacker could potentially intercept your internet communication and change its content on the fly. It could also potentially tell you that the download went randomly wrong I guess, but MD5 is good enough for that. For someone who just downloads the release from github page, it does not matter, because the download itself should go over https and thus is secure. If someone was to download things over http, it wouldn't matter because the attacker could just mess with the webpage itself to change the hash as well. Where it becomes relevant is if you have a released artifact from somewhere (a cache?) where you aren't sure of its origin, and would like to verify its origin, without redownloading the whole thing. All of this is probably irrelevant for your specific case, because the known attacks on MD5 mostly rely on being able to add "dead" bits and bytes to a binary, but making a sane looking + compilable code is a bit of a special case, but I'd like this to become general knowledge. 
Oh, I see. Yeah, boo to MD5.
Should also be useful for mingw or cygwin -- I don't believe GNU's STL has windows error support.
For testing the Big List of Naughty String: You might want to extend the test so that it checks for a round trip. What we did for our library is reading it as JSON, than converting it to a pretty-printed string again - you just have to remove all those trailing spaces in the original file. Question for the user-defined type support: Is it also possible to overwrite/extend the behavior of built-in types, e.g. `double`? We needed this for our library as we are using it to log values and obviously the log-system should not barf on `NaN` or non-finite values.
Good point with the Big List of Naughty Strings - I shall see into that. About the overriding - I am not sure right now. I'll have a look.
Maybe they assumed you read the documentation for the library you're critiquing? ;-]
We started recently to use your library in production, nice work! Just a suggestion, it would be nice to have better support for rvalue references, for instance in your `person` example it would be nice to support 2 additional overloads: void to_json(json&amp; j, person&amp;&amp; p) { j = json{{"name", std::move(p.name)} //etc } void from_json( json&amp;&amp; j, person&amp; p) { p.name = std::move(j["name"].get_ref&lt;std::string&amp;&gt;()); // or better: p.name = std::move(j)["name"].get&lt;std::string&gt;()); // move the string out } In general overloads of `get` for rvalue-reference `this`. It is very useful IMO, as most of the time when I convert from `json` to `person` I also throws away the `json` immediately after ( parse file to json, json to object, no need to keep the `json` around ).
Yes, but you don't want to replace all use of `double` or any other standard type in your code base or change all calls to the logging system to convert in-place. Also, if you forget one place, this would not be caught by the compiler. But it's not an actual problem for me, as we have our own JSON library. I was just checking if Niels provides this use-case in case others (who want to use his library) need something like this.
Do you really need a PDF? http://cppreference.com is very good, and there's a downloadable archive version.
So then you would think that something like [OpenCV's algorithm interface](http://docs.opencv.org/3.2.0/d3/d46/classcv_1_1Algorithm.html) is absolutely horrible, right? (and they're instantiated with `Ptr&lt;SomeAlgo&gt; algo = makePtr&lt;SomeAlgo&gt;(...);` or `Ptr&lt;SomeAlgo&gt; algo = SomeAlgo::create(...);`)
Thanks for the answers guys... I love that some of you are regularly on reddit!
Seems terrible, but perhaps they need to work with attached state, like JPEG decompression does.
Wikipedia is (sadly) not the best choice when trying to get into most mathematical concepts. I'd advise you to dive a bit into Bartosz's 'Category Theory for Programmers' [1] or the Category Theory section of the Haskell wikibooks book [2]. &gt; So a category is... a collection of objects plus functions...? Not strictly speaking, but yes, something like that. With objects commonly being the language types. In [2] you have a definition of a category that contains all Haskell types (section "Hask, the Haskell category"). Then, a functor F is a function on those types. It transforms one type `T` to another `F&lt;T&gt;`, and transforms functions that operate on `T` to functions that operate on `F&lt;T&gt;`. For example, `std::vector` is a function that transforms any type `T` into a `std::vector&lt;T&gt;`, and `std::transform` is conceptually* the function that lifts any function `f: T1 -&gt; T2` into a function `F(f) : std::vector&lt;T1&gt; -&gt; std::vector&lt;T2&gt;`. (*) Conceptually, because `std::transform` has a problematic API - receiving iterator pairs for a collection instead of the collection itself, and output arguments instead of returning transformed collection as the function result. But the concept is the same (transform from range-v3 is much closer to the concept API-wise). [1] https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/ [2] https://en.wikibooks.org/wiki/Haskell/Category_theory
Careful with QPointer, it does not have ownership semantics and is not thread-safe. But what you propose would work just fine with std::shared/weak_ptr or QShared/WeakPointer. However I'd assume that giving the context pointer to Qt instead would be more performant or at least use less memory. 
The PDF version supported searching the functions and searching the whole library and it was very helpful as I'm learning the language so that way I discovered many functions 
Also isn't there std::overload in C++17 ?
Any flat set or map will be slow if used incorrectly because insert is O(N), this makes building the set or map quadratic in time. The boost versions contain a special insert function (taking an ordered_unique_t) that allows you to insert a list of presorted data in O(N) time. 
You need to measure. It depends on many things, like access patterns, etc. I've seen it go both ways. Here's one analysis: Building a std::map of N items is O(N log N). Building a std::vector of N items and then sorting it is O(N log N). But constants matter. For the std::map case, this can be rewritten as O(log 0) + O(log 1) + O(log 2) + O(log 3) ... + O(log N) // For insert For the std::vector case we have N * (O(1)) // for push_back + O(N log N) // for sort The std::map has smaller constants because the log section is small in the beginning. But, it suffers from having to perform extra memory allocations, so allocate performance constants will make a difference.
Looks interesting!
Sorry, but that's not very convincing.
I dunno... When I told them to try the other (my) example, the reply was (among other words) &gt; Regarding your second example, **sure it generates lots of assembler** to cover all the use cases with could occur from a different argc input So either they didn't try, or they made a mistake trying, or were lying. All bad. Not havingtried myself, I tend to believe what you told me, that makes more sense than what they were saying. And that says something - they have the most knowledge and the data, but they fail to show me wrong. Weird. I do think the library will be good, mind. It's more that I **really** wouldn't like that it becomes the norm for day to day coding. Way too verbose, and I think constraining WRT error info. boost::exception is just better in my book. The use of this thing, I believe, should be **only** the most hot low-level code paths where it is shown, through profiling, that exceptions do hurt throughput and latency.
It's quite annoying to have a link that links to an isocpp.org post which contains no information whatsoever except for just linking to the actual blog post. Can we please just link the original blog post to this reddit directly?
I finally got around to completing the port to range-v3: https://github.com/tahonermann/text_view-range-v3
I'm going to leave this up, but I don't really think it's on topic.
[This post](https://www.reddit.com/r/rust/comments/5qq7ty/a_guide_to_porting_c_c_to_rust/dd1wrh1/) over on /r/rust has a good critique of this guide, and might save you some time if you're thinking about complaining about it here :)
This is all very interesting, but I think it would be less painful to start porting from C++98 (this is what this guide uses for comparison) to C++11/14, than any other language, for starters. But it's just my opinion. 
The example https://github.com/fpark12/PurifySampleProject is a 404
I was hoping for more insight than just binary size on two compilers.
First impressions: * **NO LICENSE**! Add one *now*. http://choosealicense.com may be helpful. * Use CMake or some other project generator tool (e.g. Autotools). I have no way of building the game right now. * Formatting seems consistent throughout the codebase. * [Rule of three/five/zero](http://en.cppreference.com/w/cpp/language/rule_of_three) * It took a while to find a comment anywhere in the code. Consider adding some while you still remember what the code does. * You seem to use the STL quite liberally. That is a good thing for a beginner. But just to inform you, the gamedev industry prefers to avoid it. * tinyxml.h and other third-party dependencies should probably be in their own folder (or use git submodules) * You don't need to specify `inline` on member functions defined inside a class as they're added implicitly by the compiler. (File Entities/Entity.h) Those are my thoughts after cherry-picking some files. I'd say it's pretty impressive for someone that has programmed for only a year.
Well apparently this was simple test with flat_map as drop in replacement for std::unordered_map and Co. with random insert and erases, this are the cases where flat_map should not be uses. Any way flat_hash_map and flat_hash_set do not have such problems and still have advantages of continuous memory. 
Sorting for integers, floats, double can be done in O(N) if radix-sort is used. This way std::vector would be O(N) of course with some significant constant factor.
[removed]
(As someone who doesn't know Rust,) I found this critique much more interesting than the original post.
Well he did say lazy
Yeah, at least performance comparison on a well formed zip file (if fucking around with malformed ones to exercise the error path is too much work).
Very nice! What resources have you been using? How have you found C++ as a first language?
Just looking through and adding on to what the others have already said: * Use `std::unique_ptr` instead of `new`/`delete` in constructor/destructor. Try to use smart pointers wherever possible (especially `std::unique_ptr`). * Code like: //Load XML file TiXmlDocument levelDocument; assert(levelDocument.LoadFile(levelName.c_str())); in `LevelParser.cpp` will break in Release builds. The expression passed to `assert` should not have side-effects. It's a macro which will expand to nothing in Release. There are quite a few places I found code like this. Good luck!
Just cherry picked: https://github.com/RyanSwann1/C-Developments/blob/master/include/Managers/TextureManager.h#L15 The assignment for the return is unnecessary. Then it should return std::unique_ptr (impossible to forget delete) or an optional type.
STL *was* slow, nowadays it's pretty great. Even std::vector was significantly slower than a hand-rolled counterpart, but now it's pretty much as fast as possible. std::unordered_map was awful when first introduced, but now it's only really beaten in speed by google::sparse_hash_map. To be clear, I'm referring to the versions of STL included in Visual Studio and Clang.
Why should they be using header guards instead of #pragma once?
&gt; The game industry has a big NIH problem. &gt; I may be caricaturing Yes, you are caricaturing. I don't think you fully understand why STL isn't used in many game engines. For game engines that were created several years ago, STL implementations provided by compiler vendors (if they provided one) did have some performance issues. Additionally, it was difficult to control memory allocations in STL containers. Therefore, it wasn't unusual for game developers to roll their own solutions. Over the years, custom implementations would become the ubiquitous in the engine and got the job done. Occasionally, there are times when you need to tweak the implementation for a specific platform. STL implementations have improved over the years, but it would be a lot of work to convert a game engine to use them. There would be little business value in it, too. However, if someone were creating a new game engine from scratch, I would say to go ahead and use the STL since it'll save you a lot of work. Of course, if your game becomes more sophisticated and profile captures shows that it under performs in some scenarios for a target platform, then an alternate solution should be considered. So it's really not accurate to say that the game industry has a "NIH" problem. We have problem with anything that's slow or inefficient. If we need to reinvent the wheel to get cycles or bytes back, then we will. 
I don't want compare strengths and weakness in any language, because there is not and will not be a winner. What I learned in more than 10 years of sw development in multiple languages was that most of issues are caused just because of inexperience. We like at first to write&amp;design the app and later studying when it went wrong. I don't think someone will rewrite the app (time&amp;money). It won't happen for either small nor large projects. But the question is - why choose language XXX. Does we want switch to other language because it's better like actual one or we will look for new language which meat more closelly our needs. Probably, the company will continue with new modules with completelly different language. Or we can still lead/teach our collegues :-)
I'm not a windows person, but I'm surprised this works: #include "XML\tinyxml.h" // vs. #include "XML/tinyxml.h" I would think the first form specifies a tab in the string and not a directory.
&gt; My reasoning are simple, you can't skip a check for them and wind up with a silent failure. Sure, instead you can skip a `catch` and your entire application terminates.
Which is exactly the point! If there were an exceptional error (that your program couldn't correct automatically) and your application continued it could be much worse. Imagine a finance app processing invalid transactions that ought to be inspected by a human. Imagine a music or video transcoder that cannot read or write a file and continues doing hours or work and none of it is meaningful. Imagine any kind of error in any application and now imagine that error happens and is never reported. These are silent failures and they should be horrifying to any programmer who wants reliable and fault tolerant software. Let it crash, look at the logs and the fix the bug, then the next version cannot fail that way. This isn't new concept either: http://wiki.c2.com/?FailFast and http://wiki.c2.com/?LetItCrash In order to get that with exceptions a coder must write a catch statement that actively does nothing. In order to get silent failure with return codes one must accidentally forget to check one. One of these is much harder to do, I will tend to use the coding style that makes writing bugs hard. This works even better with unit tests too. EDIT - added "way"
I remember reading somewhere about possible `std::overload` but quick googling didn't find any reference/proposals, so I'm not sure if it's a thing yet.
Hey I'm still kind of new to C++. Does pragma once buy me anything over ifndef define?
If we *assume* the constant is the same, the total time for std::map is (with stirling's approximation): c*(log1+log2+...+logN) = c*log(N!) ~ c*N*(logN-1) Note that log(100)=4.6. This constant 1 in the equation barely affects the total time when N goes large, so we almost always ignore that. When analyzing constant, we focus on `c`. The constant for sorting is several times smaller than that for std::map. That is why sorting is almost always the faster solution when you are not dynamically inserting new data. In addition, you are overlooking the fact that many sorting algorithms have a time complexity of log1+...+logN, too. Heapsort is an obvious example. We never write time complexity as log1+...+logN because few care about its difference from NlogN, as I explained above.
First things first, it's easier to make ideas look more attractive when others came first did mistakes and built knowledge but there's nothing Rust does that C++ cannot do, the opposite is not true. But let's face it, C++ (as C) has to carry the weight of its almost 40 years. Let's see how Rust looks in this much time (if it survives). Though the author is right in pointing out that the bad/old practice is never deprecated in C++ (this is also called backwards compatibility BTW). However, since the introduction of clang and its tools (i.e. modernize) things are **slowly** changing for better. The new 3-year cycle of the ISO standard committee also helps in keeping users of language more engaged. About that, there's also a community thing... Rust has new one, engaged, focused and energized in "changing the world". The C++ community is diverse -- amazingly diverse, people of all ages, backgrounds and mainly, different levels of engagement in improving the ecosystem around C++ (which is huge). This is both a good and a bad thing: while this allows the language to be used in many different industries and applications what pushes it to the limit on several directions, in the other hand that creates a decentralized mindset, what leads to some inertia regarding changes. A good example is how hard has been for the ISO standard committee to reach consensus (i.e. Concepts). As a closing note: competition is good thing, the future will tell.
Run the STL on a PS2, even PS3. Enjoy.
Not sure why you're getting downvoted, you're absolutely right. I work on a codebase with C++ roots back from 2003, and I don't doubt for a second that the original designers may have had good reasons for writing their own container classes: stuff that for better or for worse is now being used throughout the project. At this point it doesn't really matter whether the STL containers are faster/better, because replacing the current ones would mean spending time and effort without any immediate upside and plenty of downsides. Just think of QA/regression testing, compatibility for older/more exotic platforms/compilers that we need to support for legacy reasons, etc. For some people it's not about having beautiful, dogmatic, up-to-date and highly performing code. Sometimes it's about doing Good Enough™ and not breaking stuff.
It doesn't use a preprocessor define, which could cause conflicts if you have multiple headers with the same guard defined. It's also just cleaner, since it only requires a single line at the top and that line is unambiguous in what it does. Really, the best solution is to use [modules](https://blogs.msdn.microsoft.com/vcblog/2015/12/03/c-modules-in-vs-2015-update-1/), but they're not ready for production use yet. Headers are a poor solution to the problem, but we're stuck with them for now.
I mean that's just wrong. It's very easy to write a faster sort or do vector math quicker than STL. STL is a general solution that is fast enough for almost every situation but if I know that every number I'm sorting is 8 bit I can write a faster sorting algorithm (radix), faster vector operations (known indices sizes, optimal unrolling, knowing when to vectorize and when not to, etc). I spend a lot of time making code run faster - most of the time I'm converting to STL but sometimes I'm converting away from it.
&gt; Do not be afraid to make small commits that leave the project in a "broken state". Wouldn't this affect negatively things like git-bisect?
Thank you /u/nlohmann. We use your library in production, it works pretty well.
Yeah....that's windows for you. Another fun one, say you have your own implementation of string: #include "String.h" Have fun getting std::string instead... (Not that you generally need your own string class, but still, that was a trip when I did use one)
Nowadays it probably shouldn't but it used to be that various compilers would have optimizations for it over the ifndef. I think most compilers optimize them both now. Some folks like to do both. *shrug*
I really like your structured approach for small source files. It looks really clean and planned out. While clicking around I spotted this tidbit: sf::IntRect TileSheet::getTileLocationByID(const int ID) const You do not need a for loop. It looks like you have your grid aligned row-major, so you can get the column by division of the id by the number of rows, and the row by a modulo operation of the id and the number of rows. More importantly there is a comment indicating that you are not quite sure why you need to modify your row index. If you do not want to figur it out while you go along, I would suggest marking it with a keyword like // TODO or // BROKEN and maybe even emit a message in Debug mode. Then make it a habit coming back to those areas and figuring it out, even if it just means understanding and removing the comment, or explaining the rational in a comment. Otherwise such sections will be hardly maintainable later on, and the rest of your code looks really good in that regard, so you might wanna put in some more of that good planning. 
Yeah this assert thing is quite a nightmare to debug, I made the same mistake once, but then I learned the lesson U_U
~~You're calling a beginner that explicitly and nicely asks for review on his code dumb, for not using move constructors? I have no words for that except "Wow". I really hope I'm misunderstanding what you wrote.~~ I did misunderstand - sf::Texture is from SFML!
What are you using for the graphics?
I'm fairly sure he calls sf::Texture dumb for not having a move constructor, not OP.
This is an interesting topic but you are pretty much wrong on every count ;-) &amp;nbsp; &gt; It also seems to be stringly typed No, it is not. &amp;nbsp; &gt; Why not use an existing programming language? We do, it is called C++. You will be able to extend the build system/buildfiles with C++ code. &amp;nbsp; &gt; Coupling the useful features (portability, a sane build model, reliability) with an awful language. Why not build this as a library with different language bindings? So instead of writing this (which, I think, anyone who has at least basic knowledge of `make` will understand): lib{hello}: cxx{hello} hxx{hello} You want to manually populate hashtables using your favorite scripting language? Also, there is no such thing as a portable scripting language -- none of them are available *out-of-the-box*, say, on Windows. 
Hi everyone again :D Last time I posted my library [rang](https://github.com/agauniyal/rang/) in this sub which got lots of reviews (and stars on github :p) and one of them(/u/RogerLeigh) was to use a [terminfo parser](https://www.reddit.com/r/cpp/comments/5hpj4o/a_minimal_header_only_modern_c_library_for_colors/db3hqri/) (either by using ncurses or infocmp) instead of hard coding values for major terminals. I accepted that this was probably the best way to go and decided to update my lib on next version. Now since I'm learning c++, I decided to write my own implementation instead of parsing bash output or using C lib, which I'll soon integrate into the original library it was intended for. As there isn't anyone whom I could show this lib and ask for reviews, I'm posting it here among the experts :D. Here is the link to repo - https://github.com/agauniyal/termdb and have a good day everyone :) P.S. I haven't really wrote documentation before, even this time I managed to pull off with showing examples of api, but I'm curious about how do people write/generate documentation for their libs. Any examples would be appreciated!
&gt; How does your build system handle cyclic dependencies at link? We currently don't but will probably be able to support it if there is interest. We already do some pretty sick stuff during linking (like emulating rpath on Windows using manifests) so this shouldn't be anything out of the ordinary. &amp;nbsp; &gt; What about Solaris cc (&amp; spark)? I don't expect to see much demand (especially with recent announcements re Solaris future). But we could probably support this on the commercial basis. &amp;nbsp; &gt; How does your package manager compare with conan/premake? There are too many differences to list but the main one is that `bpkg` only works with `build2` as the underlying build system. This allows us to stay sane, provide uniform functionality across platforms, and some pretty cool features. See the Intro (link in the parent post) to get a feel. &amp;nbsp; &gt; How does your build system compare with fastbuild, when it comes to distribute parallel compilation on a build cluster? This is something we are planning to support in the very near future as part of our buildbot component. That is, you will be able to use `bbot` for CI while idling but when someone on the team needs help building things, that will take priority. &amp;nbsp; &gt; What about "custom target" (for instance, when you need to compile some cuda code)? `build2` is completely customizable and you can define your own target types, operation rules, etc. You can even define custom operations. &amp;nbsp; &gt; What about customizing compilation flags for specific files? Easy: obj{foo}: cxx.coptions += -O0 # Disable optimization because of compiler bugs. 
Ok having thought about it, here's the problem with your argument: &gt; This defeats the point of a custom E. You define a custom E because you want a strict, controlled, and type-safe set of possible errors. There is nothing precluding you *extending* std::error_code with any custom type you like in order to gain your type safety. In fact, that part B was saying to do just that, though now you've given such a great rebuttal I've realised that part B needs to say so much better than it currently does. So, in other words, subclass std::error_code with your type of choice. Gain the type safety, but stay in line with the C++ 11 STL way of doing error codes. &gt; using MathError = std::error_code; &gt; static constexpr MathError DivisionByZero = std::errc::result_out_of_range; &gt; static constexpr MathError NegativeLogarithm = std::errc::argument_out_of_domain; &gt; static constexpr MathError NegativeSquareRoot = std::errc::argument_out_of_domain; &gt; using MathResult = outcome::expected&lt;double, MathError&gt;; &gt; Again, I feel like this defeats the purpose of E and hinders type-safety... because I can now write: &gt; auto x = MathResult{std::errc::directory_not_empty}; &gt; And the compiler would be totally fine with it. I want type-safety! Great point. It's actually very straightforward to redo the example so the MathResult custom error type is type safe, yet still aliases std::errc. I will do this. Finally: &gt; This has a run-time cost. As an example, std::error_category uses run-time polymorphism in libstdc++. Can you clarify what you mean by this? I'm assuming you are not referring to error_category containing virtual functions?
My 5 cents: make useful git comments.
Sounds good, thanks!
&gt; Is there documentation on the language itself? Not yet, it is still a bit in flux. &amp;nbsp; &gt; Neither is build2. There is a big difference between building a native C++ program (`build2` can be bootstrapped on a clean 32-bit XP) and installing/maintaining a language like Python. 
What's the difference if OP is the direct and sole author of `sf::Texture` (and asked for feedback about it)?
That's because the preprocessor (which handles all lines beginning with a "#", doesn't have string escape sequences like "\\t", so it just gets interpreted as-is.
The issue is large, precompiled third party dependencies that are slow to support newer VS versions. As eager as we are to upgrade, we can't move ahead until they do.
&gt; resetData() is called when user reparses another term with an existing object, not sure if I understand what you're suggesting.. You have the same code both in `resetData()` and `TermDb::TermDb()`: // more repetition... std::fill(std::begin(numbers), std::end(numbers), cap::NP); // more repetition... What you could instead do is have a separate `TermDbData` `struct` that deals with initialization: namespace impl { struct TermDbData { // more stuff... uint16_t numbers[39]; // more stuff... TermDbData() { std::fill(std::begin(numbers), std::end(numbers), cap::NP); } }; } So that `resetData()` simply becomes this-&gt;data = TermDbData{} inside `TermDb`, and so that `TermDb`'s constructor can be compiler-generated. --- &gt; What benefit would I get by making it constexpr string It is repeated twice in the source code. --- &gt; I don't know much about reordering, little bits from here and there. Any resources that I should read to learn about what you're suggesting. The gist of it is that you should order your members from biggest to smallest (unless you rely on destruction order). This minimizes the padding that the compiler adds between member in order to respect memory alignment. Just google for "c++ padding" and you'll find many resources. 
Literally takes 10 seconds to look at the header files, and see that it is clearly not from OP. https://www.sfml-dev.org/documentation/2.0/classsf_1_1Texture.php Don't be condescending.
Apart from calling constructor on already existing object feels a little bit weird to me, rest all very good suggestions. Thank you again for your detailed explanations to my queries, I'll read more about it and make the suggested changes :D
Its more than 'just' windows. I would think he would want: #include "XML\\tinyxml.h" Which escapes the '\' properly. A single \ in a string has different meaning. Perhaps the preprocessor treats this differently. Broken! Point well taken on capitalization. However this can be minimized using the recommended practices to prefix (as this person has done) with a namespace &amp; dir prefix.
I mean I never tried it anything that wasn't Windows, even on Windows I try to use '/' because it works on all the platforms I care about. But it seems as though according to another poster the preprocessor simply doesn't care about escape sequences. I just assumed MSVC made a non-compliant preprocessor in that regard, as you did. I guess I'll have to read the standard on preprocessor stuff some time. And sure, it can be minimized, at the time I ended up making a sub folder, but nowadays I just avoid relative paths out from the current file and instead use the path from the project directory. 
Any programming pattern allows someone to be an idiot, which is exactly what that code snippet is. In a decent workflow that would make the Pull Request or Code Review fail, because it is so glaringly wrong. Compare to: functionThatMayOrMayNotReturnAnErrorCode1(); functionThatMayOrMayNotReturnAnErrorCode2(); functionThatMayOrMayNotReturnAnErrorCode3(); Which line if any has the error? You need to know the return type of each function to adequately review the code. And worse, if someone changes one of these function this snippet won't show up in the diff during Code Review or PR.
Thank you!
I wasn't sure how to interpret the "Dumb!" comment. Given the mostly-constructive tone of the comments, I decided he was either (1) calling himself dumb for almost suggesting return by value, or (2) the author of sf::Texture was dumb (and not the OP). 
People here just really don't like comments that suggest that exceptions aren't perfect I guess. &gt; For error cases you know how to handle of course you should write in some solution. Well, fine, but now we're back to square one. What should that "some solution" be? It can't be exceptions. &gt; the [programmer] can deploy the wrong solution for unknown errors or fail to be checked. I'm assuming you were missing that word so I stuck it in. Yeah, sure. But the programmer can also deploy the wrong solution for unknown exceptions or fail to catch them. This seems much more likely to happen as in order to know that you caught/didn't catch all the right exceptions you have to know all the exceptions that can be thrown - which is difficult to be able to do. 
If the error handling mechanism is visible in the signature of the function, then at least knowing the return type of each function would be sufficient to adequately review the code. If those signatures were: void one(); int two(); void three(); That at least would raise the question about what to do with `two()`. Moreover, in C++17, we can even have: [[nodiscard]] int two(); And now the compiler will tell us if we didn't handle the return. I am a big fan of compiler diagnostics. But with exceptions? You need to know the *body* of all those functions. And maybe even the body of all the functions that those functions call. And turtles all the way down... 
**Company:** [Euronext Technologies](https://www.euronext.com/) **Type:** Full time - all levels, Internship **Description:** Euronext Technologies delivers all core trading applications used to run Euronext markets, International Markets and MTFs. This includes member connectivity, order matching, market data broadcasting. The candidate will have the opportunity to work on challenging subjects to address new functional (Mifid 2, Business initiatives). These initiatives are managed using Agile methodology. We are currently looking for talented junior and senior IT profiles as well as tech-savvy graduates to join our team in Porto. Our Porto office is a fast-paced, dynamic hub within Euronext, focused on pioneering the evolution of financial technology. Key Accountabilities: * Being really interested in Trading Business * Implementing in C/C++ new functionalities in the most complex Trading components * Designing of performance critical subsystems * Producing clear and accurate documentation relative to implemented code * Actively contributing to continuous code improvement * Working with other teams on overall trading system design **Location:** Porto, Portugal (English mandatory, French is a plus) **Remote:** No, only on-site **Visa Sponsorship:** No **Technologies:** C, C++98/03, C++11, Boost, Qt, Linux, Git, Unit Testing **Contact:** reddit PM, [Careers page](https://www.euronext.com/en/careers), or reply below for questions 
You can achieve the same thing in C++ by running aggressive clang-tidy checks as part of your build and failing if you catch anything.