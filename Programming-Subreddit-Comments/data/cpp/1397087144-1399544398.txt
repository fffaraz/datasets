Yeah, it was IMO accepted into boost too soon, but it has improved steadily since then.
&gt; and can only read .txt files. 
 QString lib_loc = "/Users/austin/Documents/Courses/cs242/final/readmotiv/books/library.txt"; ಠ_ಠ
Sorry, that was an old version, it has been updated with a more general form.
I wanted the file to be as small as possible, the post explains why, I am using this for an experiment and it achieves the goals. It would be relatively easy to add a converter before displaying, but I just didn't get to it in the ~10 hours I spent programming. 
To be honest C and C++ have been around so long and is so wide spread you can assume that there is a library already out there. You then google - "&lt;desired functionality&gt; C++ library" and it should pop up. Also, if you are on Mac you can use repositories via port or brew. Also, in my opinion Visual Studio is hell, it breaks a large portion of what makes C++ so simple and cross platform.
C++, I assume? [] gives you the best performance for accessing a single character. string::at() includes bounds-checking, which has a performance penalty. If you're being careful, you shouldn't need the bounds checking. string::substr() is a very expensive way to do this because it constructs a whole new string object. If you just want to get a single character, and don't need a copy of it in an entirely new string, don't use substr().
Makes sense. So the guy was being kinda dumb using substr, I tend to be careful so I use [], and my friends use .at just to make sure they aren't breaking stuff during loops and the like. Thanks!
`substr(index, 1)` will return a string of length 1, containing the character at `index`. That is a different return type than `operator[]`, which returns a single `char`, and `at()`, which also returns a `char` but always checks that `index &lt; size`. So you use at(index) to access the char, operator[] if you already know the index is in bounds, and substr(index, 1) if you want a string instead of a char. See [this reference.](http://en.cppreference.com/w/cpp/string/basic_string) 
[MNMLSTC Core](https://github.com/mnmlstc/core) has an implementation of the `std::any` proposal. I haven't used it, but given who the author is I assume it's a good implementation.
I ended up rolling my own lightweight version. The boost implementation seems pretty good though, assuming you don't have any issues with using boost in your project in the first place. Any reason for wanting an alternative?
It's actually really straightforward to implement your own. Basic structure off the top of my head: class any { class internal { std::type_info _data_type; }; template &lt;typename T&gt; class internal_typed : public internal { T _data; } internal * _internal; }; template&lt;typename T&gt; T any_cast(any &amp; a) { if (typeid(T) == a.internal-&gt;_data_type) { return ((internal_typed&lt;T&gt;*)a._internal)-&gt;_data; } // throw type error }
The Adobe Source Libraries has an [adobe::any_regular_t](http://stlab.adobe.com/classadobe_1_1version__1_1_1any__regular__t.html) type that functions much like boost::any. Latest versions of the library can be found [on GitHub](https://github.com/stlab/adobe_source_libraries). From the documentation: &gt;any_regular_t differs from boost::any in several ways: &gt; &gt;* any_regular_t models EqualityComparable, fully modeling a Regular. &gt;* any_regular_t supports type promotion. See adobe::promote for more details. &gt;* cast&lt;&gt;() results are returned by reference, making any_regular_t generally more efficient. &gt;* small values (less than or equal to 64 bits) with a non-throwing copy constructor or which model Movable are stored without a free store allocation. Edit: formatting
Any reason why you can't/won't use boost?
The servers I'm running my code on don't have the boost libraries. 
Extract the library you want to use with `bcp`.
Exactly, if OP doesn't says what's wrong with the Boost version, then on what grounds can people suggested better alternatives?
well, are you going to write in and document the whole exception path? No? Right then [] and debug asserts are going to be better.
Just C&amp;P the headers that you need. Boost any is header only.
That's a pretty damn silly response.
This. Debug asserts result in crashes and other absurdities in the field. If I had one cent for every time a debug assert did not catch a problem during testing and let some horrible issue out into the field, I'd be rich as Bill Gates. Depend on asserts when other constructs are truly unavailable and not just considered unavailable because someone has decided they'll be slow.
Boggles my mind that C99 decls only made it into MSVC last year. It took them **14 years**. There are several OSS projects stuck on C89 just because of MSVC. I constantly have to commit twice to fix mid-block declarations. *Edit:* Speeling, and hey it's my cake day.
Interestingly, substr seems to be the standard way to do it in perl (i'm a perl noob, so i could be wrong). http://www.perlmonks.org/?node_id=4688 
"Dynamic C++" presentation list several alternatives (and covers much more than that, of course); it's been given in several versions: - (PDF) https://github.com/boostcon/cppnow_presentations_2013/blob/master/thu/DynamicCpp.pdf?raw=true - http://www.slideshare.net/aleks-f/dynamic-caccu2013 - http://www.slideshare.net/aleks-f/dynamic-c-silicon-valley-code-camp-2012 - http://pocoproject.org/blog/?p=659 Here's the YouTube video from the C++Now 2013 presentation: https://www.youtube.com/watch?v=QySTK4cSq7o
By at least one obvious implementation, it's a constructor call that includes allocating space for a new array from the heap, then copying over the substring (in this case just a character). By comparison, [] is a fetch of the address of the underlying array, a little pointer arithmetic, and a load. No allocation necessary, no constructor call necessary. If you do too much unnecessary object construction, it will cost you. I once worked on a project where carelessly tossing around objects by value (and therefore calling copy constructors all over the place) caused a huge performance hit--as demonstrated by certain copy constructors showing up as taking a scary chunk of the running time under a profiler.
Yeah I just figured most string implementations now a days would use some form of SSO. 
Yeah, that's actually probably true. So OK, it's still constructing an object on the stack that it's just going to index into to get the first (and only) character and then throw away. Maybe not crippling, but definitely wasteful.
at(index) can be interpret as: if (index &gt;= length) throw exception; return p[index]; (p is a pointer to the first char of the string) substr(index, 1) can be interpret as: char* newPtr = new char[2]; char* ptr = p + index; for (int i = 0; i &lt; 1; ++i) newPtr[i] = *ptr++; newPtr[1] = '\0'; return newPtr; [index] is just p[index]. It's faster than .at() (doesn't have to do 1 comparison), and a lot faster than substr() (have to allocate mem for 2 chars, copy 1 char over and assign '\0' to another. If p and newPtr are far apart (in term of memory address) this *1* copy can be slow). In fact the .at() is utterly slow enough compare to []
I watched thenewboston but I'm sure he didn't cover external libraries. Edit: Actualy found something that seemed informative- 
Use [StackOverflow](http://stackoverflow.com/search?q=Qt+Eclipse) for questions. Also you might want to check out [this course](https://www.youtube.com/watch?v=IkPyNpg4_x4&amp;list=PLZ9NgFYEMxp4ZsvD10uXmClGnukcu3Uff). 
Are you going to tell us what it is, or just leave us hanging?
Shouldn't be an issue. So long as you can get the boost libraries where you develop and build, you don't need them where you deploy given that boost::any is header only. Even if it wasn't you could still compile statically.
and unicode makes all of this fairly irrelevant. I like treating std::string mostly like std::vector. I believe std::string was written before the collections stuff which is why it has such a wierd interface in comparison.
Does anyone know of a well designed SAX XML parser written in C++?
bcp copies a total of 291 files (2.8 MB) for any.hpp.
I share similar views. at() is related to defensive programming. In my opinion, it shouldn't exist. As *Design by Contract* tells us : it's up to the client code to ensure the bounds are respected. It's not the responsibility of the called-code. Let's take another example. Let's say we have a program that loads a file made of distances, and that it applies sqrt() on them (for whatever reason). Having sqrt throw an exception when it receives negative numbers would result in "error: sqrt can't process negative numbers". Having the caller code check the distances at the source would result in "negative distance found at line 42 of file bar/distances.foo". Checking the positivity of the number is not sqrt responsibility. It's obviously the responsibility of caller/client-code. It's up to the client to respect sqrt contract, either by construction (-&gt; sqrt(abs(x))), or by checking the inputs: (if (x &lt;0) throw ... ; sqrt(x)). It's exactly the same regarding at() and []. The client has to ensure the bounds are respected. When out-of bound access is made, it means there is a programming error. And assertions are our best friend here. Unfortunately, according to the standard, [] is not expected to assert anything.
&gt; at() is related to defensive programming. In my opinion, it shouldn't exist. As Design by Contract tells us : it's up to the client code to ensure the bounds are respected. It's not the responsibility of the called-code. Precisely. If I call `at` with invalid args then my program is fundamentally bugged; the time spent coding the error path would be much better spent ensuring it didn't happen in the first place. &gt; Unfortunately, according to the standard, [] is not expected to assert anything. True, but the standard doesn't say much about debuggers and text editors either. Doing your development with stdlib assertions turned on (libstdc++, libc++ and MSVC's thing all support this) is just using the tools that are at your disposal. The library asserts aren't in the release build anyway.
So? Wang then into a directory and be done with it.
Well, you can't really say "he was dumb" without knowing the circumstances. I personally wouldn't have a problem with using an expensive operation for something that only happens once in a while (if using that operation increases code clarity/readability). In my books the mental optimization budget should be spent on things that happen often and regularly - where shaving off a few ms really matters.
&gt; 100 million values The time spend in program will be mostly waiting for memory to fetch, not real CPU time doing any processing.
 #(4 1 7) collect: [ :i | i squared ]. 
This seems to fit well here: [Windows is not a Microsoft Visual C/C++ Run-Time delivery channel](http://blogs.msdn.com/b/oldnewthing/archive/2014/04/11/10516280.aspx)
This is actually really telling. After watching Eric Brumer's talks at GN and \build you really understand how important memory is. So doing a `std::transform` on a `std::list` of integers would be much slower than on a `std::vector`, simply because contiguous memory on cache is just so good (also Herb talked about this in build as well, I'd link the talk but I'm on mobile right now). 
I am looking forward to Rust, though I really need to write non-trivial code in it to get a feel (hello world just gets you so far...)
 [x*x for x in [4, 1, 7]]
Part of contract programming is enforcing your domain.
http://semver.org/
The question: is this susceptible to XXE attacks ?
[Herb's](http://channel9.msdn.com/Events/Build/2014/2-661) [Eric's Builld 2013](http://channel9.msdn.com/Events/Build/2013/4-329) [Eric's Build 2014](http://channel9.msdn.com/Events/Build/2014/4-587) My favorite talks on Ch9 
&gt; but is this really necessary for something as trivial as squaring elements? No, of course not. It is just an example. With longer loop bodies the benefit is higher.
Or in Haskell: map (^2) [4, 1, 7] I also like this better, but that article was about C++. ;)
I personally would prefer [`map`](https://docs.python.org/3.4/library/functions.html#map) and [`filter`](https://docs.python.org/3.4/library/functions.html#filter) over the list comprehension; in Haskell also.
it was more of a rhetorical question, it's just that i'm seeing things like this pop up often for trivial problems in *actual* code, and i'm not a fan of it. of course the new features are highly useful, i just think they're overused.
[Herb Sutter's Build Talk](http://herbsutter.com/2014/04/04/yesterdays-build-talk-is-now-online/). The stuff about memory starts somewhere around halfway through.
Your third link is the same as the second link. Were you intending to link to [this](http://channel9.msdn.com/Events/Build/2014/4-587)?
Implementing the normal algorithms as in place transformations vs duplication makes them simpler, but also confuses some of the complexity in the std::transform code. For instance the author calls out you don't know the size of the resultant vector, except you would if you were making an output vector.
Wouldn't a for_each be even better? vector&lt;int&gt; squareVec(vector&lt;int&gt; v) { for_each(begin(v), end(v), [](int&amp; i){i = i*i}); return v; }
pugixml is great, the xpath support sold it for me. Unfortunately dealing with namespaces can be a pain.
Nah, but you could add it as a feature. 
No, ty!
Or Fortran, y =x*x
There's one thing I didn't see mentioned: You can't add a new virtual function to a leaf class, that's the same name as another virtual function (ie. an overloaded one that takes different args), as virtual functions with the same name (stupidly) get sorted together, so the new function will shift any other later functions further down the vftable. eg. given the class: class blah { public: virtual void func1(int arg); virtual void func2(int arg); virtual void func3(int arg); }; Users of the library might be passed an object of this type, and they call the various functions. The class might not ever be derived from (so you could argue there wasn't any reason for the functions to be virtual) so in many cases a later version of the library could add extra virtual functions at the end, eg. class blah { public: virtual void func1(int arg); virtual void func2(int arg); virtual void func3(int arg); virtual void func4(int arg); // New function }; Any library user that was calling func1(), func2() or func3() won't be affected. However, if the library added a new overload of an existing function, eg. class blah { public: virtual void func1(int arg); virtual void func2(int arg); virtual void func3(int arg); virtual void func2(char *arg); // New function }; the vftable will actually end up actually being: class blah { public: virtual void func1(int arg); virtual void func2(char *arg); // New function was moved here!? virtual void func2(int arg); virtual void func3(int arg); }; So existing code that used the library, that was calling func2(int) will now get func2(char *), and what was calling func3(int) will now call func2(int)! This behaviour might be Microsoft ABI specific. I've certainly come across this before. It makes sense, but it's not immediately obvious: &gt; reimplement virtual functions defined in the primary base class hierarchy (that is, virtuals defined in the first non-virtual base class, or in that class's first non-virtual base class, and so forth) if it is safe that programs linked with the prior version of the library call the implementation in the base class rather than the derived one. The library might expose two classes, 'base' and 'middle': class base { public: virtual void func1(int arg) { } virtual void func2(int arg) { } }; class middle : public base { public: virtual void func1(int arg) { base::func1(arg); } }; and then the user of the library creates a third class: class top : public middle { public: virtual void func1(int arg) { middle::func1(arg); } virtual void func2(int arg) { middle::func2(arg); } }; Later on, the library wants 'middle' to override and have an implementation of func2(). Unfortunately, the 'top' class isn't actually what it appears to be. The call back to the parent class implementation doesn't go through the virtual function table. It's a direct function reference. So since at the time it was compiled, middle::func2() didn't exist, what the binary code is actually doing is: class top : public middle { public: virtual void func1(int arg) { middle::func1(arg); } virtual void func2(int arg) { base::func2(arg); } // Directly calls base::func2() as middle::func2() doesn't exist }; So the newly added/implemented middle::func2() in the library gets completely skipped by top. Similarly, if the user of the library had implemented 'top' as: class top : public middle { public: virtual void func1(int arg) { middle::func1(arg); } }; its vftable would be generated at compile time as: top::func1(int arg) base::func2(int arg) Again, if the library then later decided to add an override and implementation of func2(), that won't affect the entry for func2() in that existing vftable. Any call to func2() off a 'top' object, will still call base::func2(), not middle::func2(). eg. top *ptr = new top; ptr-&gt;func2(0); // this will still call base::func2() even though middle::func2() now exists edit: grammar
This is where C++ "people" get really scary. I mean, how somebody can think that this: for (int&amp; i : v) { i = i * i; } is less readable and less explanatory than this: vector&lt;int&gt; result; result.reserve(v.size()); transform(begin(v), end(v), back_inserter(result), [](int i) { return i*i; }); really is beyond me... this is where languages as Go really have an edge: devs and users have their feet firmly on the ground. 
Those don't do the same thing. The in-place transform is transform(begin(v),end(v),begin(v),[](int i) { return i*i; }); which still isn't great. It would be nice if the standard provided it, but you can easily make an in-place transform map_container(v,[](int i) { return i*i; });
Still don't get why calling an obscure function "map_container" (the meaning might be obvious for somebody but not for everybody) that hides the operation being performed (in this case i*i) in a lambda would be better than calling a very simple for loop. The loop is something anybody that has got past the first chapter in any programming language book would be able to immediately understand. The other option.. well, you need to know what a lambda is, its syntax, what an iterator is and so on.. it's just complicating things for the sake of it.. it doesn't make sense at all. 
The point of using as little loop code as possible is to eliminate possible issues and bugs related to loop iteration. Bounds checking, iterator advancement, element range deduction is already taken care for you. The only thing you need to worry about is the implementation detail that belongs in the loop body (hence the lambda). Also, the implementation detail within the `&lt;algorithm&gt;` library is well known and more predictable for the compiler authors, and thus serves as a great advantage for generating optimal binary code. For example, parallelising `std::transform` is conceivably easier than a C-style `for` loop, where "anything goes".
Agreed. And major-version-bumping skill makes sense once we agree on the definition. =P
Thank you. You are absolutely right. I updated my article and code accordingly.
Glad I can help.. just not sure what happens when you pass something that is a constant container... you might have to remove the cons and or the ref, when you had vector you did that automatically. This then makes the template of the transform nasty. You may want to leave it as vector. STL had a great talk about problems with helping the compiler.. http://channel9.msdn.com/Events/GoingNative/2013/Don-t-Help-the-Compiler some of the earlier parts are a bit beginner you may want to watch starting halfway through.
Or in Julia: [4 1 7] .^ 2
TL/DR: "It is possible that an unordered map might have faster lookups than an ordered map in some situations."
functional =&gt; pure. Nothing functional about it, it's been a property that you could inform GCC about for years (__attribute__((pure)) ). It'll then optimize as a functional compiler would.
&gt; I am surprised how compiler can optimize that code so aggressively: "for loop" version is the most straightforward one, while wrapped transform version uses a std::function which (if I am not mistaken) is implemented using dynamic polymorphism. You're not mistaken in that `std::function` would indeed use run-time / dynamic polymorphism (type erasure, essentially). Note however that if you're referring to `template&lt;typename Container, typename Functor&gt; Container transformCont(Container xs, Functor op)` it does NOT rely on `std::function` anywhere -- nor should it. Each lambda has its own, distinct type: &lt;http://en.cppreference.com/w/cpp/language/lambda&gt;. There's no reason to always store the lambdas in `std::function` (nor to pass them as such) -- in fact, it's usually better to store lambdas as in `auto lambda = []() {/*...*/};` (if the storage is needed) and pass it as in the function template example: in both cases the types shall be preserved and no conversion to `std::function` will take place (all polymorphism/genericity is purely compile-time, and thus without imposing any run-time overheads). // BTW, I also wouldn't call any of the versions "the fastest" -- I don't think the differences that far after the decimal point are [statistically significant](http://en.wikipedia.org/wiki/Statistical_significance).
Looks like they're going all the way to `__attribute__((__const__))` with that one---`pure` can depend on global state but `const` depends only on the parameters.
Damn, I incorrectly read a std::function use in wrapped transform version. My fault. Also it's correct all versions have the same performance statistically.
True, I was mistaken.
What debuggers would you recommend that are actually better? And in what mays does it make them better than VS?
Would an array of function pointers be good for this? Four arrays total. One for the strings test through test4 and another for test5 through test7, then one for function pointers doTest() through doTest4() and another for doTest5() through doTest7(); Pseudocode: Step 1: Find input in firstArray. Step 2: If found, run doSomething() and use that index for an array of function pointers that correspond to the correct function. Step 3: If it wasn't found, check secondArray for input. Step 4: If found, run doSomething2() and use the inex for an array of function pointers that correspond to the correct function. Step 5: if not found, then not valid input. What do you guys think? This may sound like overkill and that it may be ugly, but the alternative is 22 if-elifs in a row each with 1-2 lines...
Could use switch-case setup. See near the end of this link http://www.cplusplus.com/doc/tutorial/control/
&gt; would you mind if we integrate that work into the Wiki page If you think it's important or relevant enough (given that it may be Microsoft ABI specific), go ahead. It's probably good if that titbit of information was more widely known (could help someone producing open-source software, that's available for multiple platforms). It's just an observation I'd made (probably over 10 years ago. I say 'observation', but what I really mean is, 'was bitten by it'). I don't have a monopoly on the information, or the authority to stop anyone from using it, or observing the same behaviour themselves and commenting on it. I don't know what the sorting method is. It could be based on the mangled/decorated name I suppose, but I don't know if that's actually the case. It's certainly more than just gathering functions of the same name together, but still keeping them in the same order that was originally declared. If that was the case, given my example, func2(int) would still be before func2(char *). But that's not the case. The (char *) version ends up before the (int) version. So some form of extra sorting is going on.
Mmm... if your doTest() functions have the same signature then I'd probably go with a map. Let's say for the sake of argument that the signature of these functions is: void doTest(); So you should be able to do this: typedef void (*testFunc)(); std::map&lt;std::string,testFunc&gt; testFuncs = { {"test",&amp;doTest}, {"test2",&amp;doTest2} ... etc }; std::string input; while(!testFuncs.count(input)) { std::cout &lt;&lt; "User must enter input for sacrifice" &lt;&lt; std::endl; std::cin &gt;&gt; input; } (*testFuncs[input])(); The initialization bit assumes a C++11 compiler. Otherwise it would have to be done manually: testFuncs["test"] = &amp;doTest; // etc. for 22 lines However you can easily just have that map be a static object in some helper function: testFunc GetTestFunction() { static std::map&lt;std::string,testFunc&gt; testFuncs; // If you put the initialization list here it is executed only once // otherwise do this: if(testFuncs.empty()) { testFuncs["test"] = &amp;doTest; // etc .... } // Rest of code from above, except the last line now reads return testFuncs[input]; } Just, please don't use a C style array. 
Interesting... Map makes sense. I am pretty new and so that's why I thought of using two arrays rather than just using that apparently much better map. Thanks! fyi: the functions are all basic math functions that return a double and take double as input. I want the user to be able to say sin:4 or tan:4 or cos:4 or floor:4.3 or one of 22 other methods that I have and get the result... right now I have ti so it goes: if(input == "sin") do sin(4); and so on for every single method, that's why I thought a map would be better since currently I just have tons of if statements that point to a different function with the same input and same return type. What do you think? 
Also, as an aside, is this a bad use of an array? int precedence(const std::string op) { //right side of array has higher index and thus higher precedence. std::string operators[22] = { "mod", "fmod", "-", "+", "/", "*", "%", "^", "!", "log_", "rt", "ceil", "floor", "round", "abs", "trunc", "cos", "sin", "tan", "acos", "asin", "atan"}; for (int index = 0; index &lt; 22; index++){ if (operators[index] == op) return index; } return 0; }
http://www.codeproject.com/Articles/11250/High-Performance-Dynamic-Typing-in-C-using-a-Repla
pls respond
GCC 4.9 has NOT been released. It will be released on the 22nd. http://gcc.gnu.org/ml/gcc/2014-04/msg00089.html
Ah, I knew it. Well, released really soon ;)
just do yourself a favor and delete the post until then, no need to thank me.
The article is a bit unclear, but I think his gripe is this: * If the destructor is not virtual, you get UB deleting a base pointer that points to a derived * If you declare a virtual destructor then it suppresses the default move constructor, so you have to write out all the verbiage to explicitly `=default` the 5 functions, which is annoying The following suggestion is interesting: * Don't have a virtual destructor That allows you to meet the Ro0 without explicitly defaulting everything. Then you use `std::shared_ptr` (or your own rolled equivalent) to manage the object. The `std::shared_ptr&lt;Base&gt;` does call the Derived destructor (it stores a function pointer to which destructor to call, basically). It has a bonus side-effect that you don't have to add a vtable to classes that had no v-table already. Of course the downside is that you could accidentally make one without using `shared_ptr` and cause undefined behaviour by deleting it. 
Overload resolution does exactly this. Note that overloading is totally different from overriding. Specifically, when overload resolution is given the signatures `func(Base *)` and `func(Derived *)`, and the argument's static type is `Derived *`, the `func(Derived *)` overload will be preferred, because it's an exact match. The compiler *can* convert `Derived *` to `Base *`, but it prefers not to. In fact, given an argument of type `MoreDerived *` (in a 3-level hierarchy), `func(Derived *)` will still be chosen, because the compiler can see that converting `MoreDerived *` up one level to `Derived *` is "better" than converting two levels up to `Base *`. The same thing happens for `meow(Base&amp;)` overloaded with `meow(Derived&amp;)`.
Could someone explain what's the reasoning behind not having a type-erased deleter for unique_ptr as it's done in shared_ptr? Is it for technical reasons? What are the advantages of this approach? 
You could perhaps use a macro to =default the 5 functions. That way it's also more apparent that it uses Rule of Zero.
There is something about nuget that makes me detest it without having even ever used it. I think it's the name, it just irritates me so much. I know this is irrational and it's probably a good tool. But I don't think I could ever bring myself to even look at it.
It's cool what `shared_ptr` can do, but I think forcing shared semantics onto a class because you're too lazy to `default` 5 functions is going too far. Personally I find the `unique_ptr` option quite clever and well written, but it's still side-stepping the point that if you're writing virtual functions in a class then you better have a good reason not to declare the dtor as virtual. &gt;It has a bonus side-effect that you don't have to add a vtable to classes that had no v-table already. `foo()` is virtual in his example so all classes will get a vptr regardless of a virtual dtor. One other thing that should be mentioned is Sean Parent's [templated adaptor pattern](http://channel9.msdn.com/Events/GoingNative/2013/Cpp-Seasoning) (covered in his third rule talk starting at 48:45) to use objects polymorphically without burdening a class with the virtual keyword at all. 
For `shared_ptr`, type-erasing the deleter is relatively cheap. It already has the heap-allocated control block for the reference count, so the type-erased deleter can just be stored there. OTOH, it'd make `unique_ptr` no longer have zero overhead. which is one of the main points of `unique_ptr`.
Just what I was thinking. I get that the author is trying to explain how to handle this corner case, but it's hardly a best practice. std::shared_ptr&lt;std::function&lt;int(int)&gt; &gt; fib = std::function&lt;int(int)&gt;(); *fib = std::function&lt;in(int)&gt;([=]() { return (n &gt; 1) ? (*fib)(n - 1) + (*fib)(n - 2) : 1; }); *Yikes.* An implementation that only a Perl programmer could love. Let's go back to the real function, and use a lambda to close over the scope, which is what lambdas + auto are really good at doing succinctly: int fib(int n) { return (n &gt; 1) ? fib(n - 1) + fib(n - 2) : 1; } int x; auto my_fib = [=]() { return fib(x); } There are some advantages to doing it this way: * More readable, which leads to fewer possible bugs being introduced during maintenance * More testable, since fib() has been lifted to a function and is independent of the rest of the program * More modular: fib() can be made available to other parts of the program
Yes, SSO sounds nice, but I read somewhere (not remember where) that if you have plenty of strings and `std::move` them over and over (think of `vector&lt;string&gt;`), SSO will reduce your performance.
That makes complete sense. You're trading less expensive allocation for more expensive moves when you store more data in-line with the class.
Or in c++: map(pow(_,2), list(4, 1, 7)); Unfortunately the above, while valid c++ from a language point of view, cannot be written because all the little functions that are required do not exist. 
I don't think you would lose performance, you just wouldn't gain any additional performance by moving a SSO string. Even the non-SSO small string would end up copying about 16 bytes in order to perform the move (pointer, size, capacity, allocator). I would strongly encourage measuring this before blindly trying to optimize a std::string for movablility.
The main problem I see with this implementation is that you end up with an object held by a shared_ptr that holds a copy of that shared_ptr. In other words, you have trusted shared_ptr to solve all memory leaks, and in doing so created a circular reference and thus a leak. The solution to this is to only store a weak_ptr to the std::function inside the lambda, then only create strong ownership when the function is run, by way of weak_ptr::lock(). Which of course is the paragraph at the bottom of the other article that was posted above. 
You might lose some performance because of more checks.
This is interesting, however it is slightly sad to augment the size of `std::string` just for this. So, instead, you can design your `std::string` class to be 24 bytes *with* SSO by re-using 16 bytes (instead of 8): struct RegularString { char* data; size_t size; }; struct ShortString { char data[15]; unsigned char size; }; struct string { union { RegularString regular, ShortString shortie } _; size_t capacity; }; char* data(string&amp; s) { return s.capacity ? s._.regular.data : s._.shortie.data; } size_t size(string&amp; s) { return s.capacity ? s._.regular.size : s._.shortie.size; } size_t capacity(string&amp; s) { return s.capacity ? s.capacity : 14; } // beware of the NUL character
You can do better than reusing 16 bytes in a (pointer, length, capacity) representation. Have a look at the string in libc++, they reuse 23 bytes for small strings with 1 byte as a length/discriminator.
What about the following, which is close to your succinctness, but should actually work: map(bind(pow, _1, 2), {4,1,7}); for sufficiently defined functions `map` and `pow`.
Implementing better syntax for multi-dimensional arrays can be done easily: http://coliru.stacked-crooked.com/a/b9e39f4fd5c48060 - raw arrays cannot be extended to include all the functionality of `std::array` while still remaining backwards compatible. For example the syntax that should rightly be used for passing a raw array by value is used instead for something else. `std::array` is able to use the correct syntax for passing by value. - If something can be done in a library rather than the core language then that should be preferred. I include that second point not simply to be snarky, but because it is true. One reason it is important is because making changes to the core language requires far more work in terms of updating all the tools and infrastructure around processing C++ source code than is needed for pure library additions. For example core language changes can require updates not just to compilers and preprocessors, but also to syntax highlighting software, code editors, auto-completion software, documentation comment parsers, debuggers, etc. Another reason is that core language changes are far more likely to cause unforeseen problems and are much harder to correct after the fact. Also, `i++` does not do the same thing as `i=i+1`.
Last I checked these weren't in MinGW though.
Code a good tetris game. Plain and simple, but it will cover a lot of ground.
&gt; The question is: how many times function allocate (on the allocator) will be invoked for the purpose of memory allocation during this program’s execution? 3, 2, 1, 0? He gives an initial argument for 3, and then for one with either NRVO, or when a move constructor is available, by why not 2? I always imagined the process would be once in the callee and once in the caller, with no third temporary inbetween. &gt; first, copy-initialize a temporary from s; next, copy-initialize t from the temporary. Is this how it's usually done? e.g. in the code &gt; string t = makeText(); the temporary is on the right side, and the copy-initialize on the left. Seems like something any compiler would optimize away, no?
If you are interested in working on game engines there are plenty of open source projects that need help.
Yeah for sure, I've worked with C a little bit but mostly C++, like I said I know most of the basics of it, classes, aggregation, inheritance, etc. My math background in all honesty needs some work, i'm learning trig (still in the very early parts of trig) and i'm about at a college algebra level, probably going to give calculus a try just for fun (if I fail horribly at least I tried :P) but like as far as stuff like openGL, Allegro, all those things I have no experience with, Pretty much I have medium algebra skills with basic c++ skills, hope that gives you an idea
Well that's something i'd totally be into! but what i'm asking is more how can I get to a point where I can actually work on one from just knowing c++ syntax, etc. like is there an api I should pick up, some sort of math or physics I should learn, etc.?
If you want to do graphics, you'll need to learn Linear Algebra and Trig like the back of your hand.
Well that's interesting, first i would strongly recommend to calculus class. For your C++ skills, try to pickup something that you are interested on, why not a simple tetris or a snake game with SMFL. try to do it as if it was i real project , take five minutes and think about your architecture , look at some design patterns you might need, try to write unit tests for the project, write clear comments as if someone is working with you on the project , try to use doxygen style for example. give a try to git or mercurial, you'll learn a lot. 
If you want to start writing simple 2D games, check out SFML: http://www.sfml-dev.org/
thanks a lot man, I appreciate all the feedback from everyone :) I think i'll give SFML a try
To get access to the bits of a float, use this: unsigned int* x = (unsigned int*)&amp;f; In a 32-bit IEEE float, the exponent field is 8 bits at offset 23, so you can then do *x += (val &lt;&lt; 23); But I bet that the integer operations will take about the same amount of time as the floating point operations anyways.
From your post, C++ seems to be your first programming language. Unfortunately, it's a very hard language to start with and you may get demotivated at first when trying to write your games. If you don't want to be be a professional software engineer and are mostly interested in games, you should choose something like Java or Python. You have a ton to learn and C++ difficulty will not help. Make sure you are using a book that teaches at least C++11 and not the outdated and even harder previous standards of the language. If I'm not mistaken, Stroustrup (the creator of the language) has a book for beginners that uses C++11, that would be probably a good book for you. You'd also do well to pick up a book for Algorithms/Data structures and another for Design Patterns. Learning a version control system would also be very useful to you. I find Mercurial(Hg) to be the easiest: http://hginit.com/ Someone recommend unit tests but IMO that would be overkill for someone learning C++ and doing personal projects. SFML was a good recommendation. It's object-oriented and much easier to use than SDL. 
I make mobile games for Kumobius, our latest game is called Duet: http://duetgame.com
Cool! That looks interesting and complicated! hahaha! 
You can't overload operators for primitives.
It sounds like you are suffering from a condition known as premature optimization. Don't be embarrassed; it happens to a lot of people. Just try not to worry so much about your performance. If your application really is running too slowly, and you're definitely not bottlenecking on I/O, and you're already running the CPU-intensive section in parallel to take advantage of multiple cores, that would be the time to *begin* considering sacrificing portability and maintainability by overriding your compiler's judgement about how to multiply numbers. If it gets to that point, you might want to consider specialized hardware, like crunching your numbers on a GPU.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Code refactoring**](https://en.wikipedia.org/wiki/Code%20refactoring): [](#sfw) --- &gt; &gt;__Code refactoring__ is the process of restructuring existing computer code – changing the *[factoring](https://en.wikipedia.org/wiki/Decomposition_(computer_science\))* – without changing its external behavior. Refactoring improves *[nonfunctional](https://en.wikipedia.org/wiki/Non-functional_requirement)* attributes of the [software](https://en.wikipedia.org/wiki/Software). Advantages include improved code [readability](https://en.wikipedia.org/wiki/Readability) and reduced [complexity](https://en.wikipedia.org/wiki/Cyclomatic_complexity) to improve [source code](https://en.wikipedia.org/wiki/Source_code) [maintainability](https://en.wikipedia.org/wiki/Maintainability), and create a more expressive internal [architecture](https://en.wikipedia.org/wiki/Software_architecture) or [object model](https://en.wikipedia.org/wiki/Object_model) to improve [extensibility](https://en.wikipedia.org/wiki/Extensibility). &gt;By continuously improving the design of code, we make it easier and easier to work with. This is in sharp contrast to what typically happens: little refactoring and a great deal of attention paid to expediently adding new features. If you get into the hygienic habit of refactoring continuously, you'll find that it is easier to extend and maintain code. &gt;Typically, refactoring applies a series of standardised basic *micro-refactorings*, each of which is (usually) a tiny change in a [computer program](https://en.wikipedia.org/wiki/Computer_program)'s source code that either preserves the behaviour of the software, or at least does not modify its conformance to [functional requirements](https://en.wikipedia.org/wiki/Functional_requirement). Many [development environments](https://en.wikipedia.org/wiki/Development_environment_(software_development_process\)) provide automated support for performing the mechanical aspects of these basic refactorings. &gt; --- ^Interesting: [^Source-to-source ^compiler](https://en.wikipedia.org/wiki/Source-to-source_compiler) ^| [^Test-driven ^development](https://en.wikipedia.org/wiki/Test-driven_development) ^| [^Agile ^software ^development](https://en.wikipedia.org/wiki/Agile_software_development) ^| [^IntelliJ ^IDEA](https://en.wikipedia.org/wiki/IntelliJ_IDEA) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cgslxj9) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cgslxj9)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
This works with version 11.6 of [my distro](http://nuwen.net/mingw.html), containing mingw-w64 3.1.0: C:\Temp&gt;type meow.cpp #include &lt;iostream&gt; #include &lt;string&gt; using namespace std; int main() { cout &lt;&lt; to_string(1729) + "meow" &lt;&lt; endl; cout &lt;&lt; stoi("512") * 10 &lt;&lt; endl; } C:\Temp&gt;g++ -std=c++11 -Wall -Wextra meow.cpp -o meow.exe &amp;&amp; meow 1729meow 5120 
RapidXML hasn't been updated since 2009. Not sure if there are any maintained forks, but I'd consider pugixml these days
I second using sfml. I've messed around with it a bit and everything is pretty straightforward. Not super-hard to get into.
Before SSE and AVX x86 had F0-&gt;F7 which are 80 bit (long double) registers. That's why double vs float didn't matter. What you're saying about AVX and the 2x speedup should be true but it really depends on the nature of the code. You'll only see performance increases in tight loops are similar. I would suggest looking to the SSE/AVX intrinsics headers. Theses will give the most control over how numbers are allocated to the vector registers without having to write any assembly. 
This is exactly the reason we can say there is no library which overloads that operator without actually having scoured any libraries. When you define a binary operator O, the signature R operatorO(T a, U b); must be such that either T or U or both are user defined types. 
Also, you have to be careful the book is teaching *idiomatic* C++. I’ve got a thorough C++11 book that still teaches those old crappy patterns Stroustrup sneered at in his 2012 Going Native talk.
Don't put &gt;&gt; and &lt;&lt; in code I have to read, thanks.
Plus: profile, profile, profile
Is there any way to control the formatting (e.g.precision) of these functions?
Given a naive and overly strict view of the world, it seems obvious that `s`'s destructor must be run before `makeText` returns, and `t`'s constructor must run after `makeText` returns. Since `s` is destroyed before `t` is constructed, you wouldn't be able to copy-construct directly from `s` to `t`, and there'd have to be a temporary in the middle.
FLOATING POINT UR DOIN IT RONG
en4bz is correct. Without vectored SSE/AVX code the two are pretty much equal. With SSE/AVX it's pretty clear you can do more per clock cycle with singles rather than doubles. If your situation is more memory bound than CPU (often the case, especially after the first round of vectoriziation with SSE) then you get an extra boost by using singles. To be fair I've not really done much hand rolling of SSE code myself. The memory argument on it's own is enough to think about when dealing with image data which is what I spend a lot of my time doing (churning over million element arrays as fast as possible.)
It's difficult to come up with even a highly artificial scenario where it's a net loss. Maybe with a very special-purpose allocator that manages to always get external buffer allocated very close in memory to the `std::string`? Avoiding a single memory load due to the SSO buffer would outweigh a very large number of branch mispredictions, and if you never hit the SSO buffer then the branch predictor will make the check nearly free.
That was my first real project, definitely a good one imo.
Sorry in advance T4s0thcmdr, but I strongly disagree with your statements. I think C++ is an excellent language to start with, it's easy to get around without touching the advanced features, and allows a lot of room to grow. C++ was my first language, and it set a very strong foundation for the rest of computer science.
Online tutorials are excellent places to start. I made many game clones a few years ago using directx calls I learned from simple tutorials. No need to be an expert in these libraries, just know enough to get around. Optimization can come later.
This will not gain you any performance. It will cost performance. Floating point registers and integer registers are different. Your code will have to save the floating point register to memory, load the memory into an integer register, add the exponent, save the integer register to memory, and then load the memory back into a floating point register.
Very nice to know, thanks. Sadly I can't use either in my current codebase without major work, despite my app's startup time being dominated by XML parsing. C'est la vie.
Yeah, that would work. 
If you're interested in OpenGL check out http://nehe.gamedev.net ; specifically the Legacy Tutorials section. Some of the stuff in there is slightly outdated (immediate mode geometry is specifically deprecated but you need to know how to deal with it anyways) but it will all still compile and run and the tutorials themselves are really well written.
I guess it depends on your SSO implementation. It should be possible to implement your string class in a way that a move constructor just `memcpy`s the internal representation and `memset`s the source to zero -- regarless of whether the string content was heap-allocated or not. So, in any case, you have to copy 24 bytes and zero 24 bytes (assuming a 24 byte string representation on a 64bit platform). You can't do much better than that, can you?
If your code is compute bound, with AVX you can do 4 double SIMD operations or 8 float SIMD operations. There is potentially a good improvement but it obviously depends on the ratio of compute to memory accesses. Which leads to another possibility, if you can change your application to use floats natively instead of doubles, you can half the memory bandwidth required. I have personally hand written AVX float code that gave me almost 2x speedup for a compute bound problem compared to the double version. YMMV.
Direct link: http://wildermuth.com/hwpod/20_Scott_Meyers
I teach my students (nearly) the opposite rule of thumb: *use floats if you think performance matters* — it'll improve cache performance and halve memory bandwidth consumption, and it'll double the speed of vectorized code. Then I teach them how to make sure they're using SSE or AVX. When not to use single precision: when stuff breaks because of round-off and when performance is not an issue. 
I disagree, arrays are such a common feature that they should not be lib feature(look at lambdas-core language although boost has them, even with prettier syntax), but ofc another reason is that C haters are glad to see c arrays die, so they would not want to add a functionality to make them useful. and im not a compiler dev, but implementing .begin .end and .size for arrays seems laughably easy- aka clang and g++ can do it now msvc in 2 y :P . and for pass by value... well in that case use std::array. your example is nice, multidimensional array syntax go from terrible to meh, but like i said it is such a used feature that it is idiotic not to augment c arrays with usability features. it is not like im requiring some kinky syntax or features, just to expose subset of functionality it can in STLish fashion. :) 
*scnr* You can submit papers to Meeting C++ till sunday: http://meetingcpp.com/index.php/mcpp2014.html Also if you get an early bird ticket till Sunday you'll be able to take part in the voting and have double the vote weight...
 &gt;For well optimized code where the algorithm has few enough dependency chains that you can execute a significant number of FP operations in parallel and your algorithm is vectorizable, I'd expect floats should be not-too-far-from twice as fast as doubles. This is the key, which the original poster provided little information on. When trying to take advantage of vector processors, you need code that can vectorize well. If the data and algorithms don't arrange themselves to leverage the hardware you can not realize the advantages if these execution units. &gt;By well optimized code I mean code which tries to use the processor resources efficiently. You use the SIMD units (SSE*/AVX), you've thought through your memory access patterns and have a clue on what the compiler is doing to your code. &gt;For something that's not part of an inner loop (run of the mill usages of double / float in C or C++), you're not very likely to care about or notice about any speed difference. Clarification on the original posters needs might help to determine if he even needs to worry about such things. In many cases it is far easier to just use double precision especially if you know your code won't take advantage of SIMD. 
 &gt;I teach my students (nearly) the opposite rule of thumb: *use floats if you think performance matters* — it'll improve cache performance and halve memory bandwidth consumption, and it'll double the speed of vectorized code. True if you know performance will be an issue and you are willing to take the time to verify that floats will not lead to round off errors or other problems. If not it makes far more sense to just use Doubles. In this case we aren't even sure if he has vectorizable code. &gt;Then I teach them how to make sure they're using SSE or AVX. &gt;When not to use single precision: when stuff breaks because of round-off and when performance is not an issue. I'd go one further and say prefer doubles until you know for sure performance will be an issue. Either that or you need a real strong understanding of the problem domain. Sometimes you really need to defer to the domain expert and follow his advice. Sometimes the right answer is to throw more hardware at the problem. 
Aaand it leaks fib to the outer namespace, something lambdas were intended to fix ;) 
You have gotten a lot of good responses here but it sounds like you are on the wrong track if I may say so. That is it appears that you want to hack at games without really learning computer science and your programming environment well. In this regard I'd suggest taking a step back, find a couple of good C++ tutorials, and really bone up on the basics. Once you have a though understanding of the various offerings in the standard library then start to craft real simple programs that you spec yourself. Build these programs without referencing the web first and then after you have something working look at as many examples as you can find on the web and study the differences at length. These don't have to be games and many shouldn't be games, the idea is to beef up your mind so that you can think about solving a bunch of different problems without wondering how in the hell that is or should be done. So build a tic tac toe game, a note taking app, a calculator, a logbook, a calendar app or whatever challenges you to solve the functionality in a different way. I hope you understand what I'm getting at here, the idea is to progressively expand your skills while doing a self code review of sorts against other solutions that can be found on the net. In the end the only real way to learn is to discover that your solution Might not have been the best and thus you expand your capabilities by understanding why other code might be better. In the programming world there are many ways to solve a problem, experience and the knowledge of others will help you learn why one is better than the other for a specific situation. You may notice that I've said little about games, OpenGL or other advanced concepts because honestly I don't think you are ready yet. You need to get to the point that if somebody said make me a program that does X, that you can get started immediately no matter what X is. Getting started here doesn't mean widely hacking out a solution, but rather reasoning about an approach (designing an app) that might work for the problem at hand. So for example if somebody handed you a file of numbers and said I need a count of numbers, and a list of the following (largest, smallest, average, the number of even and the number of odd) and finally they want an ASCII graph of the numbers could you do this? That is design the program to give the file owner that data. Sounds contrived, which it is, but it would verify or help you to develop some skills. These would be file reading, text to integer conversion, array handling, iteration and solving math problems. If you can't do a solution for this then you really need to think long and hard about trying to jump straight into advanced gaming. 
 &gt;From your post, C++ seems to be your first programming language. Unfortunately, it's a very hard language to start with and you may get demotivated at first when trying to write your games. If you don't want to be be a professional software engineer and are mostly interested in games, you should choose something like Java or Python. You have a ton to learn and C++ difficulty will not help. This is so much baloney that I just had to say I don't agree in the least. This from somebody that is primarily a Python programmer. C++ is not difficult to learn to use constructively. Yes there are dark holes you can get sucked into if you aren't careful but a disciplined programmer doesn't dive into those holes unless he needs too and has the experience to leverage the trinkets in those dark holes. The base language and the standard library are in fact relatively easy to learn. &gt;Make sure you are using a book that teaches at least C++11 and not the outdated and even harder previous standards of the language. If I'm not mistaken, Stroustrup (the creator of the language) has a book for beginners that uses C++11, that would be probably a good book for you. Well this I more or less agree with. However the rate at which good C++11 books have arrived is relatively slow. So there is a lot of value to be found in online tutorials, but you need to find a good one. &gt;You'd also do well to pick up a book for Algorithms/Data structures and another for Design Patterns. Again I have to agree with you as I have this feeling that this individual is trying to hack his way into game development. Frankly I don't see it working especially considering the way he stated his questions. If he has no idea about how to design an app, any app to solve any problem then he is a very very long ways from writing novel games. The basics come first in my mind. &gt;Learning a version control system would also be very useful to you. I find Mercurial(Hg) to be the easiest: http://hginit.com/ Maybe! I find that the way many version control systems work to be odd at the very least. So shopping around for a best fit is probably a wise move. &gt;Someone recommend unit tests but IMO that would be overkill for someone learning C++ and doing personal projects. Really but yet you recommend a version control system? That is very strange honestly. In some circles testing is considered to be as important as the base code itself. I just find it strange that you would recommend one and not another. In general I think you have the right idea in that he has the cart before the horse here. I take that opinion directly from the way he asked his questions in the initial post. If he can't reason about how to build a program he is way ahead of himself and needs a grounding in basic concepts. 
&gt; I disagree, arrays are such a common feature that they should not be lib feature Frequency of use doesn't necessarily have any relation to whether something should be a language vs. library feature. Anyway raw arrays should be a rarely used feature because of the various problems they have, problems which cannot be fixed without breaking backwards compatibility. &gt; look at lambdas-core language although boost has them, even with prettier syntax The original proposals for c++ lambdas discuss boost lambda among other things and the reasons that library is not sufficient. Nor is the boost lambda syntax always prettier (in particular it requires bind expressions for functions calls). &gt; but implementing .begin .end and .size for arrays seems laughably easy That does seem like a relatively easy feature, but other simple features like digit separators have turned out to be more complicated than they seemed at first glance. Also, as I said earlier, updating the compiler is only one part of what needs to be done. Besides, there's already a `begin()` and `end()` for raw arrays, but because of the previously mentioned problems with raw arrays they're not as useful as one might wish. That would be the same even if these were built into the language. For example, this: void foo(int arr[10]) { arr.size(); } would not work any better than: template&lt;typename T, int N&gt; constexpr int size(T (&amp;)[N]) { return N; } void foo(int arr[10]) { size(arr); // error }
There is no difference. operator() is just another member function: foo1(Functor1 f) { f.operator() ("Hello World"); } is doing exactly the same. So, in the end, the STL just says "call your function not compare, but operator()". The reason for doing so is to treat functors like functions, being able to write code using templates: template&lt;typename F&gt; void foo (F f) { f(); } void x(); struct y { void operator()(); }; void bar() { foo (&amp;x); foo (y()); } Thus, you can pass a plain function the same way as you can pass a functor into std::sort(). Else, you would need two overloads.
Oh I see, I didn't realize you could pass in a function like that.
Like wung said, sometimes your callback can be stateless, and you can pass a simple function pointer, other times you might want a stateful callback, in which case the functor becomes quite useful. It's very convenient for the *user* to be able to make that choice without the *interface* having to change. If it worked as you described, then every function that takes a callback would have to be specially designed to accommodate both cases, with the end result being unsatisfactory to either the person implementing the interface and having to do more work or the person using the interface and not being able to pass a stateful callback.
Ah! I had not thought about that. Definitely better indeed.
I see. Just to make sure that I understand you (because I've never seen the terms stateless and stateful before so I'm kind of inferring their meaning here), you're saying that the user might want to define additional data members for their functor to use? Like maybe a integer that counts how many comparisons have been made?
Ahhh… because of the segregation of registers, this hack couldn't gain performance. *Unless* the floating point hardware supported it, with special instructions to add/subtract some integer to the exponent field. So, do any FPU's have opcodes for that? It could be worth doing, for [shift and add](http://en.wikipedia.org/wiki/BKM_algorithm) algorithms. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**BKM algorithm**](https://en.wikipedia.org/wiki/BKM%20algorithm): [](#sfw) --- &gt; &gt;The __BKM algorithm__ is a shift-and-add algorithm for computing [elementary functions](https://en.wikipedia.org/wiki/Elementary_function_(differential_algebra\)), first published in 1994 by J.C. Bajard, S. Kla, and J.M. Muller. BKM is based on computing complex [logarithms](https://en.wikipedia.org/wiki/Logarithm) and [exponentials](https://en.wikipedia.org/wiki/Exponential_function) using a method similar to the algorithm [Henry Briggs](https://en.wikipedia.org/wiki/Henry_Briggs_(mathematician\)) used to compute logarithms. By using a precomputed table of logarithms of negative powers of two, the BKM algorithm computes elementary functions using only integer add, shift, and compare operations. &gt;BKM is similar to [CORDIC](https://en.wikipedia.org/wiki/CORDIC), but uses a table of logarithms rather than a table of arctangents. On each iteration, a choice of coefficient is made from a set of nine complex numbers, 1, 0, −1, i, −i, 1+i, 1−i, −1+i, −1−i, rather than only −1 or +1 as used by CORDIC. BKM provides a simpler method of computing some elementary functions, and unlike CORDIC, BKM needs no result scaling factor. The convergence rate of BKM is approximately one bit per iteration, like CORDIC, but BKM requires more precomputed table elements for the same precision because the table stores logarithms of complex operands. &gt;As with other algorithms in the shift-and-add class, BKM is particularly well-suited to hardware implementation. The relative performance of software BKM implementation in comparison to other methods such as [polynomial](https://en.wikipedia.org/wiki/Polynomial) or [rational](https://en.wikipedia.org/wiki/Rational_function) approximations will depend on the availability of fast multi-bit shifts (i.e. a [barrel shifter](https://en.wikipedia.org/wiki/Barrel_shifter)) or hardware [floating point](https://en.wikipedia.org/wiki/Floating_point) arithmetic. &gt; --- ^Interesting: [^CORDIC](https://en.wikipedia.org/wiki/CORDIC) ^| [^List ^of ^algorithms](https://en.wikipedia.org/wiki/List_of_algorithms) ^| [^List ^of ^numerical ^analysis ^topics](https://en.wikipedia.org/wiki/List_of_numerical_analysis_topics) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cgt5ax9) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cgt5ax9)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
TIL! Obviously, I'm no expert. 
But we could fake it, right? class shiftableFloat { float _theFloat; operator &lt;&lt;() (int n) {…} operator &gt;&gt;() (int n) {…} ... } 
Right. The callback can have access to member variables which can carry state. That's what makes C++11 lambdas so powerful: std::vector&lt;int&gt; vi; ... int cutoff = calculate_something(); std::partition(begin(vi), end(vi), [=](const int x) { return x &lt; cutoff; }) The lambda here is nothing more than an instance of a class that has an `operator()` and which has a member variable that captures a copy of `cutoff`.
Awesome! Makes perfect sense, thank you.
I like C++ but saying it is easy for complete beginners to start with is just being blind. Headers for example are an unnecessary PITA for beginners. What about those cryptic linker errors? "WTF is even a linker?". Unit testing is overkill if you can't even code anything right yet. These are personal learning projects. Unit testing should be learned later. Source control is always useful: "I messed up the code, I will just revert to the previous version". It's either using a VCS or manually copying your source code files every now and then. 
Recommending that a beginner learn the horribly OUTDATED OpenGL compatibility mode is just pure evil! Absolutely don't! And if you don't want to be a graphics programmer, don't even learn OpenGL. It's a low-level graphics library not a game engine. And there's so much more to graphics programming than learning OpenGL, OpenGL is just a way to use the hardware to run graphics algorithms. 
You may want to observe this [C++ String to Int](http://www.reddit.com/r/cpp/comments/1khevz/c_string_to_int/)
The only added benefits are syntactic. You could have native functions use function calls and user-defined functors use `.call()`, native types use `==` and user-defined types use `.equals()`, and so on, like Java does, or you could provide a uniform interface that puts user-defined types on the same level as built-in language features.
Nobody is going to download your source and unzip it, post the parts you want criticism for on pastebin or something
I'm dumb, I can't find the edit botton. Edit. [And here](http://i.imgur.com/gGgjvC0.png). It grew quit big, hehe.
In addition, why does C++11 allow assignment to rvalue? void f(int &amp;&amp;x) { x = 5; } int main() { f(7); return 0; } compiles perfectly fine.
Couple of things from looking at your secret_encoder.cpp. 1) Where you have all your flags up and the top, since those are globals (and have static storage duration), they'll be initialized to zero for you, so you don' t have to do that again in main(). Also having a bunch of similarly named variables is a big code smell telling you an array would probably be better. 2) Where you call system("pause"); to pause input, I would use getchar() since that will work anywhere rather than just windows. 3) When checking the user input, you compare against both the capital and lowercase version of the input, it's probably easier to use toupper/tolower to translate the user input and compare against that, also note that having a big series of if/then statements is often better represented with a switch statement: letter_input = toupper(letter_input); switch(letter_input) { case 'A': break; case 'B': break; ... } 4) All of out_progress can probably be re-written using an array for all the flags (or possibly just computing those values on the fly, I'm not sure what they do), and a for loop rather than enumerating all those possibilities in a big if/then. Those are the big ones I saw just with a quick glance. As a matter of personal opinion I think the C++ I/O streams (cout/cin) are a hot mess and just printf/getchar() are better options most of the time. A couple more small things: it's generally bad practice to include system headers using quotes (#include "iostream") since a lot of people use those to distinguish project headers (I don't since the quotes are actually compiler dependent). You don't _have_ to prototype all your function definitions up top. Only the ones that need to be visible before they're defined. Though sometimes I do that just to have a mini-api definition easily visible. It's also good to get in the habit of putting braces around all your if/thens in my opinion: if (letter_input == 'A' || letter_input == 'a') { encrypt_code(); } else if (letter_input == 'B' || letter_input == 'b') { crack_code(); } else if (letter_input == 'Q' || letter_input == 'q') { quit_jump(); } else { cout &lt;&lt; "\nInvalid option. Closing Program\n\n"; } because it's just _so_ easy to burn yourself without them by inserting another statement later that's unconditionally executed (doesn't really apply here, but good habits). In this case a switch is better anyhow. 
Being able to modify an rvalue opens up the possibility of moving instead of copying, which is the major motivating reason for the feature. In C++98, rvalues could bind only to const (lvalue) references, which means they couldn't be modified. At the time, it was thought that being able to modify a temporary whose lifetime was about to expire was too likely to cause confusion and bugs. C++11 relaxes that, but you still have to opt-in to it by using the new syntax. 
I updated it with a picture of the source code :)
For 5) you can do either: #include &lt;iostream&gt; or #include "iostream" the first if which is more common for system headers, don't know why your book does it the other way. 6) You'll feel different the first time you do: if (something) foo(); bar(); // meant be inside if statement, executes unconditionally instead When that day happens I want you to think of me ;) On #4 I think I see what you're doing with the print_progress. If it was me writing that, I'd probably do something along the lines of: void print_progress(double percentage) { // ensure it's called with 100 for num_char == 1 case static int printed=0; int segment = (int)round(percentage)/10; // convert percentage to 0/1/2/3/4 for (size_t ii=printed; ii &lt; segment; ii++) { cout &lt;&lt; "..." &lt;&lt; printed++; if (ii == 10) { cout &lt;&lt; endl; } } } That uses a static variable (value persists between function calls) to store what you've printed so far, and then just prints from that to the current value. 
5) The book uses &lt;iostream&gt;, but VS Express has "something" by default, I was lazy and just left the quotation marks. Is there a difference? 6) haha! It actually happened when I was writing the program last night! XD 4) Thanks! I don't think I've seen static variables yet, so its interesting to see how you made it. Seems many times more efficient! haha! Thanks for the comments man! greatly appreciate it!
A good question! I'm not sure about that myself :) My first thought: this may be undefined behavior so different compilers might handle this differently, but I don't know the standard well enough to justify that. It could just modify a register rather then memory. It could allocate memory on the stack unbeknownst to you and modify that. A look at the assembly it outputs might be able to answer that, but as I mentioned, may differ based on your compiler.
It's not undefined behavior. And if you want to talk about what actually happens, it's a dead store and the function call will be optimized away completely.
They invented these marvelous things called "*video cameras*" that you can use to record a presentation, and then people can actually view and hear the presenter giving the presentation at their leisure, rather than just reading the slides out of context.
&gt; Couldn't the STL guys say, "Create an object that implements a member function named compare." Even the other reason notwithstanding, *why would they do that*? What’s the benefit of having a class which defines only on (arbitrarily named) function? [None, it’s an Java-istic anti-pattern](http://bennuttall.com/stop-writing-classes/). A class which only implements one function is called a [closure](http://en.wikipedia.org/wiki/Closure_%28computer_programming%29). So why not use a closure directly? In C++03, the answer to that question is “overload `operator()` for a class`”. In C++11, the answer is (most of the time), “write an actual closure via a lambda”. Effectively, classes who overload `operator()` behave like functions. So then the question becomes: &gt; Why should I use a function instead of a class with a member function named `xyz`?
&gt; These functions are actually just wrappers over `sprintf` and `swprintf`. That’s a shame, because [`sprintf` is darn slow](http://tinodidriksen.com/2010/02/07/cpp-convert-int-to-string-speed/). Granted, most of the slowdown in the benchmark probably comes from its handling of localisation (I’m guessing here) but at the very least it has to parse the format string at runtime, which is an avoidable overhead.
Where does the lvalue live? Where can I find the value of 5 in this example?
When initialising a reference with a literal (which can only be done if it's a const lvalue reference or if it's an rvalue reference), a temporary object is created and initialised with that literal. See section §8.5.3/5 of the standard: "a temporary of type “*cv1* `T1`” is created and initialized from the initializer expression using the rules for a non-reference copy-initialization (8.5). The reference is then bound to the temporary."
Object oriented programming is a particular paradigm that is appropriate for a range of problems. Not surprisingly, author has a case where it is not appropriate. Existence of a case where it is not appropriate proves it is "not always appropriate" but does not well support the notion that it is "always not appropriate." Despite the (excellent) example, feel free to use the facilities he is denigrating when you are writing code where those facilities are appropriate. 
Most of my work is on this exact sort of thing (putting C++11 on a 16-bit 32kB RAM ASIC). Virtual methods are the one thing I've really noticed that compilers are still pretty bad at optimizing out, but I wonder why the author ever even used them? If he's okay with templating his classes, why don't we simply use template classes? RAII is quite useful as well, since a pin really is a resource. Here's a sample similar to what I usually use: enum class Polarity { ActiveHigh, ActiveLow, }; template &lt;size_t port_&gt; class OutputPin { public: Pin(const size_t pin, const Polarity polarity) : pin_(pin), polarity_(polarity) { GPIO_CONFIG_OUTPUT(port_, pin_); } ~Pin() { // natural state of a pin is typically as an input GPIO_CONFIG_INPUT(port_, pin_); } void MOCKABLE Set(bool value) { // MOCKABLE is defined as virtual when testing if (polarity_ == Polarity::ActiveHigh) GPIO_SET(pin_, value); else GPIO_SET(pin_, !value); } private: const size_t pin_; const Polarity polarity_; }; The output from a class like this is usually identical to that of calling C routines, while still maintaining some sense of OOP (and we use RAII which is cool, since pins really are a resource to be acquired.) The author went to static template classes, which I find hard to test. They also don't offer RAII, which is probably okay for a pin, but when you're dealing with other complex hardware systems (I2C, UART, SPI peripherals) RAII is invaluable, and this same methodology can be applied.
It's worse than that though. He's conflated OOP with *runtime* polymorphism. His "solution" is still OOP, just with static polymorphism.
Better title: "Runtime polymorphism? No, thanks!"
Nice! I'm considering integrating this with the [Wayward Web Framework](https://github.com/simonask/w). Any thoughts?
It's a great use case for it--I encourage you to and would love to help if you decide to do so. (Offhand, for instance, it looks like it wouldn't be too much work to specialize a Synth value adapter for your `PERSISTENCE` layer.)
I love the look of your web framework BTW... You even have an orm later that doesn't make me want to barf!
There are two mistakes related to C++ itself here: - one can use OO without `virtual` - the introduction of templates does not require that `pin` be types, they could be simple objects (with runtime arguments) just as well, which would certainly limit the code bloat Combining those two, we get: // template based blink-an-LED class lpc1114_pin { public: lpc1114_pin(int port, int pin): port(port), pin(pin) {} void set( bool x ) const { gpioreg( port, 0x04 &lt;&lt; pin ) = x ? -1 : 0; } private: int port; int pin; }; // class lpc1114_pin template&lt; class pin &gt; void blink(pin const&amp; p){ for(;;){ p.set( 1 ); delay(); p.set( 0 ); delay(); } } int main(){ lpc1114_pin led(1, 0); blink(led); } And it will likely give the same code. Or not. Depending on whether it decides to inline `blink` and `set`. But I would expect a good compiler to, because it's got all the tools. Regarding the issue of `virtual` methods, it essentially depends on how they are implemented and unfortunately an implementation by v-table (as is common) with a v-ptr as a first member of the object does not lend itself to optimizations easily because the C++ front-end does not do optimizations (or not much) and the optimizer/back-end have no knowledge that this weird setup is actually a representation of a virtual table obeying a hard set of rules (such as: the v-ptr cannot change during the call of a non-const method, except constructors and destructors).
The double situation is a lot more complex. For a start, the CPU time of the actual 'parse' stage is dwarfed by performing the decimal exponentiation with bonafide rounding, which the 'naive' version from that post simply ignores. strtod() is likely almost certainly the second largest function in libc, right after scanf/printf. The [GNU implementation](https://sourceware.org/git/?p=glibc.git;a=blob;f=stdlib/strtod_l.c) uses set of bignum operations (using the GMP library) in order to get it right, and even given that, [wasn't even correct until GCC 4.9](http://www.exploringbinary.com/real-c-rounding-is-perfect-gcc-now-converts-correctly/)
What I like about this version is that all the leverage in the class happens at compilation time. If the compiler is smart enough to inline your method calls, the resulting assembly should appear as though there was no class at all. The only part I'm not certain of is if polarity_ and pinNumber_ can be optimized out of memory entirely since they're declared const.
&gt; The only part I'm not certain of is if polarity_ and pinNumber_ can be optimized out of memory entirely since they're declared const. I can actually answer this after extensive profiling with Clang! If the calls are sufficiently small such that **everything** is inlined (which is frequently the case for simple hardware wrapper classes like these) the variables will not be emitted into memory, and further won't even appear to exist. This is also compiler specific (though these are pretty mundane optimizations). I compile with clang -O3, and run it through several passes using LLVM's optimizer `opt`, with flags `-std-link-opts` and `-O3` The compiler will only emit those values into memory if they are actually loaded from. By inlining and propogating constants, the values are no longer referenced by the code, and can be removed. Now, this is easy to break. The second you need to reference the object by address, these values will need to exist. For a couple examples, this could happen by passing the object to a non-inlined function that takes a reference/pointer or keeping an array of objects. 
That's exactly the idea of it, now that you mention it! ;) Thanks! Hopefully it'll be usable soon.
That was exactly my thought — I've laid the groundwork with the horribly named `StructuredData` interface, which is intended for exactly that type of binding. One challenge is that Wayward wants as few dependencies as possible, so I'm trying to keep Boost out of the core, but as far as I can see a hypothetical Synth binding could easily live in its own plugin module. I'm going to give it a shot and see what happens! :D
I am not super good with C++, so this might be a silly question. Why do you have Boost as a requirement and not C++11? It would seem that a lot of those functionalities Boost offer are now actually a part of the C++11 standard. So why pick a library over the actual language?
A very small part of boost is equivalent to c++11. There is no c++11 equivalent to xpressive, fusion, program options, property tree or python, which are all the boost libraries OP mentioned.
Can restrict be specified on references now? That is one reason I end up using pointers in performance critical code. Also, I love optional, but it has a size penalty versus null values of course. 
&gt;The iterators in C++ are so powerful that many people forget that raw pointers are what they replace. I don't see how you can say that iterators **replace** raw pointers when raw pointers **are** iterators.
Size on the stack? I wouldn't bother that much. It constructs everything in place making better use of cache.
Looks pretty reasonable but suffers from the fact that STL algorithms in general are pretty poor to begin with. Would be nice to see this same kind of approach used for boost.range, or heck just adding boost.range to the standard. Algorithms over iterators is far inferior to algorithms over ranges.
I'm a bit surprised that [rapidjson](http://code.google.com/p/rapidjson/) wasn't included. As the name implies, it is quite fast.
Good point, haha.
It's no longer supported/developed and actually makes quite a few questionable decisions, such as using setjmp when there's no really compelling reason to 
Nice. I would have liked to have libjson in this benchmark. The good thing with this library is that you can tune it according to your usage.
Enjoying my experience with the library so far. One question though: is anyone else getting an exception from ::CloseThreadpoolWork(static_cast&lt;PTP_WORK&gt;(_Work)); in scheduler.cpp?
I always love these things. I'd be curious to see the Qt5 Json stuff added, always makes like easier when you need only rely on one (although huge) library instead of 30 "puzzle pieces".
cereal?
Yeah, I would have liked some comparisons with C JSON libraries too. We recently ditched usage of the spirit JSON library for the C based YAJL library with wrappers due to the performance boost. 
C++11 does support strongly typed enums: enum class MyEnum { Value1, Value2 };
Look up what a "header file" is.
3) Be careful. toupper takes an int parameter and it's undefined behavior to call it with a value that is not representable in an unsigned char. The code as shown passes a "char" and if that is signed which it is on many platforms, then you may pass in a negative value for some characters you can type on a keyboard. 
Benchmarking time without memory usage is almost useless.
depends on your use-case. If you have a server with 64GB of ram, whether the library use X MB more or not does not really make any differences. If it does, then I would rather consider msgpack, protocol buffer, or capnproto as serialization mechanism.
Agreed. I use ptree from boost and parsing an 11mb json balloons memory up 1gb. EDIT: I decided to use gason and damn the results are awesome. No real memory footprint and very very fast. What took 4 seconds to parse now takes, well it's too fast for me to really determine unless I benchmark it.
Sounds good! Take a look at https://github.com/ajg/synth/tree/master/ajg/synth/adapters for an idea on ways you could do it.
Isn't really a json-library but a serialization-lib that supports json as one of four document-types. You really see that from the generated files and the terrible runtime-errors if the json-file is invalid. Note that I don't say that cereal isn't cool, just that this really isn't it's major application.
cereal uses rapidjson which is no longer supported. I personally think that rapidjson was over-engineered with the use of sse intrinsics instead of relying on the compiler to use the most appropriate instructions.
Agreed, rapidjson is one of the fastest JSON parsers out there. rapidjson, sajson, and vjson are in a different class of performance from most others out there: http://chadaustin.me/2013/01/json-parser-benchmarking/ 
No [jansson](http://www.digip.org/jansson/)?
yajl?
Why do you think a JSON parser needs to be supported? Unless there are bugs, a JSON parser is a tiny, simple piece of software, and it's quite conceivable it can be complete. 
Or you know, you could just use SFML, which is already nicely object-oriented and everything
If you had read the article you would find that the final solution is a general function that can be used to manage resources from most C based libraries, a common task many C++ developers run into at some point or another. SDL is used as a concrete example. Do you have any actual constructive comments about the article?
&lt;numeric&gt; gets my vote for silliest STL header (they should just live in &lt;algorithm&gt; like everybody else).
But then how would one know that they're meant to be used with numbers? Come on! 
Are you the author? Thank you so much for posting this! I found it highly informative as well as timely; I'm taking a course right now which requires the use of SDL2, and I will be glad to use these ideas to reduce cruft and increase memory safety! I would note that it would behoove you to proofread your articles before posting; I noticed a handful of typos, including at least one in a code listing. (Stray comma.) It didn't really detract from the readability, though; it's just a pet peeve of mine, I suppose.
have a look at http://isocpp.org/files/papers/N3949.pdf 
Well, you can abuse then for non-numeric stuff. /evil laugh
You could use a macro: #define REPEAT(n) for(int i = 0; i &lt; n; i++)
i know you can use a macro, but i'm really more interested as to *why* `repeat` isn't a language feature - it doesn't seem like it would be difficult to implement on a compiler level? and yes, i know i'm nitpicking, but i'm kinda bored.
`for (auto : boost::irange(0, 10)) { ... }` avoids having a pointless variable in scope. It's not really something that justifies syntatic sugar.
Your `repeat` is just syntactic sugar for the `for` loop you are using: the compiler would have to generate code identical to the loop, so there isn't a point in adding yet another loop construct to the language. 
It is probably just stylistic. Repeat would just be a less flexible for loop. You would just be hiding its inner working while removing any complex looping possibilities. Most people would say, "why implement a weak feature when you already have a strong feature that does the same thing?" And, like DarkEdge said, you have macros to implement that feature if you so choose.
You're probably wondering why you're getting downvoted so hard: As the sidebar says, "For C++ questions, answers, help &amp; advice see /r/cpp_questions" This sub is more for C++ news and articles.
Slides from a talk given by Howard Hinnant at ACCU 2014. Has some very good discussion about the semantics of the special member functions.
I like these posts from this website. Showing off the small subtleties of STL.
That's probably not the case. On x86, the loop construct is small enough to fit in the L1 cache, so there's no reason for one of those loops to be slower than the other. And even if there was, I guarantee there's a more important bottleneck in your code.
not wondering at all, i'm familiar with the community and its desire to be 'helpful'. i also moderate /r/cpp_questions and felt that this subreddit was better suited (in addition to having more members) for a question of this type. i.e. i was asking more of a philosophical question, seeing as i already know how to use a loop.
x86 is not the only platform (on ARM it's one instruction less) and just ignoring a possible optimization is wrong.
Ignoring an unimportant optimization like this one leaves you to spend more time worrying about performance concerns that *actually matter.* Executing one less instruction in a small loop in one small corner of your application is not going to make any difference. Executing one less O( N^3 ) algorithm *will* make a difference. There are far bigger fish to fry in your program.
If the compiler did this for you, you wouldn't have to care about it. My argument is simply: - repeat(x) can be faster - repeat(x) makes the code more readable You don't need to make the unimportant optimization YOURSELF. It's just that repeat(x) is better than for(int x = 0; x &lt; 10; x++) in every case when it's sufficient.
Ripple sure made the right choice in bringing Howard onboard. 
&gt; for(int i = 0; i &lt; 10; i++) is slower than for(int i = 10; i--;) This is **incorrect**. Just checked with GCC 4.8.2 -O3, which emits the exact same assembly for those loops.
My contention is the difference between the two for loops above (unimportant), not the `repeat()` construct (useful).
This code: #include &lt;stdio.h&gt; extern const int count; int main() { for(int i = 0; i &lt; count; i++) puts("hi"); for(int i = count; i--;) puts("hi"); } compiled it with arm-none-eabi-gcc -O3 -std=gnu1 -S test.c generated one instruction more for the top loop. Should I file a bug report? ASM: top loop: add r5, r5, #1 ldr r0, .L13+4 bl puts cmp r5, r4 bne top loop bottom loop: ldr r0, .L13+4 bl puts subs r4, r4, #1 bne bottom loop (Only the loop body, rest left out) Edit: GCC 4.8.2 as well Edit2: Same on x86_64 using my distro's GCC 4.8.1
Isn't that dependent on the optimization level though?
If you care about a single extra instruction in a loop and aren't using the maximum optimization level then something has gone wrong.
One thing I don't like about this approach is that the `unique_ptr` ends up with a rather complicated type, which makes it difficult to use in contexts besides local variables on the stack (such as function arguments or class members). Here is my approach to this problem, tailored for libedit but easily adaptable to SDL: struct libedit_deleter { void operator() (EditLine* p) const { if (p) el_end(p); } void operator() (History* p) const { if (p) history_end(p); } void operator() (Tokenizer* p) const { if (p) tok_end(p); } }; template&lt;class T&gt; using libedit_unique_ptr = std::unique_ptr&lt;T, libedit_deleter&gt;; Whenever you need to manage a resource from libedit, you just use the `libedit_unique_ptr&lt;T&gt;` type as follows: libedit_unique_ptr&lt;History&gt; hist(history_init());
Ranged based for loop is just syntactic sugar for the for loop you are using: the compiler would have to generate code identical to the loop, so there isn't a point in adding yet another loop construct to the language. Also could use the same line of reasoning against pretty much the entire STL. Loop abstractions are both useful and nice features of a language, they are here to stay and have good reason to. Being dismissive of people who ask about their existence is just rude. 
Any decent compiler will optimize a small fixed range for loop away. Literally the only difference that matters from any perspective is that repeat does not bind a new variable in the scope of the loop body.
The good question here is the, how would you implement the repeat loop structure as a library?
It doesn't take very advanced data flow analysis to identify that the value of `i` is never used inside the loop.
I agree, but I find it odd that loops are *ever* getting reversed. For all I know it might be trying to reverse loops all the time when the iterations are independent.
&gt; Also could use the same line of reasoning against pretty much the entire STL. This statement intrigues me. Are you implying that iterators are just syntactic sugar? &gt; Loop abstractions are both useful and nice features of a language, they are here to stay and have good reason to. Being dismissive of people who ask about their existence is just rude. I didn't say loop abstractions are not useful. I said that `repeat` is not useful in C++ because there is already at least two ways to achieve the same behavior within the language and adding that particular statement would not be useful. 
But is it actually faster? On my machine (x86_64 GCC 4.8.2) the first loop is also longer than the second, but executes 16% faster when `puts` is replaced with a non-inlined empty function.
In the solution unique_ptr never has to be typed by the user when making use of auto, I consider these overly verbose types to be the situation auto was intended to ease: auto window = sdl2::make_window(...); I had considered using a typedef of for the return types in the case of the SDL2 example it looks something like typedef std::unique_ptr&lt;SDL_Window, void(*)(SDL_Window*)&gt; sdl2_window_t; sdl2_window_t make_window(...); The primary goal of the article was to drive towards a general solution though and that guided many of the choices. Thank you for the feedback!
That's great, I hadn't seen this paper yet but it appears to solve the general problem in a more robust way that I've laid out here.
This looks very interesting and worth working into a solution to further reduce overhead, however, I'm having a hard time imagining how one might fit this into the general solution or if a custom deleter would need to be defined by hand for each type. Thanks again for the comment, it gives me a new goal to work on.
Just tried it with a count of 50000000, confirmed. But why? Branch prediction? I don't know x86_64 well.
If you are just looking to perform a loop an X number of times your standard for(;;) is very much designed for this. If you want to *create* a range on the other hand, you have several options. boost::irange(start, end) for a range iterator std::iota for filling a container with incrementing values only. std::generate for filling a container with control. int i(7); std::array&lt;int, 5&gt; range; std::generate(range.begin(), range.end(), [&amp;]{ return n--; }); for(auto&amp; x : range) {} Certainly more verbose than what it sounds like you wanted. :) for(auto: boost::irange(0,10)) {...} Is ok... but I don't know how efficiently it compiles compared to a standard for(;;).
Actually, it's even weirder. My original test program was: extern const int count; void foo(void); int main(int argc, char **argv) { if (argc==1) { for (int i=0; i&lt;count; ++i) foo(); } else { for (int i=count; i--;) foo(); } return 0; } With `foo` and `count` defined in a separate source file. But if I remove the if statement and only keep the else block, the loop speeds up to the speed of the other loop. The difference also disappears if I compile it in 32-bit mode instead of 64-bit mode. So I have no idea what's going on. 
Can confirm as well, the "i--" version is faster in 32bit mode. I'd imagine the "i&lt;count" version is faster in 32bit mode as the constant loaded is only 32bit wide instead of 64, but it got slower for me. So with -m32 both swapped the roles, hm, I have no idea at all what could be causing this.
Could do it as a lambda too. On my phone otherwise I'd put together a sample.
Well, no, but one would expect a valid reason to change the semantics of the code. It is a low-level construct after all.
Reversing a "repeat n"-equivalent loop *doesn't* change the semantics though; that's why the optimizer's allowed to do it.
I guess it depends on what you mean by "semantics". Sure, it will run the same, but such a reversal adds nothing that I can see, and it changes the low-level semantics of the code (so that if you were perusing the assembly, you would really have to scratch your head about why that was done).
Compiling to get easy to read assembly is very different from the usual case. You'd want to use -O0, which would disable such changes.
I have to disagree with his conclusions on the last few slides. He suggest picking the fast option over the safe option by default. So a simple, innocent-looking program will default to exception-unsafe. I'd rather my programs default to safe, and if I'm having performance issues I track down the culprit and use an explicit fast-but-unsafe assignment. I'm also unable to replicate his performance results, benchmarking default-assignment vs copy-and-swap-assignment gives me equal performance.
Will videos be available? Will slides of the other talks be available?
For anyone else interested, this post does a better work: http://ivan.fomentgroup.org/blog/2014/04/18/using-clangs-static-analyzer-to-analyze-your-project/
Why do you recommend template&lt;typename... Arguments&gt; auto make_window(Arguments&amp;&amp;... args) { return detail::make_resource(SDL_CreateWindow, SDL_DestroyWindow, std::forward&lt;Arguments&gt;(args)...); } to specialize the management for a window? Wouldn't explicitly naming the arguments to be passed give much more readable error messages? Something like auto make_window(char* name, int w, int h,...) { ...}
&gt; and it changes the low-level semantics of the code (so that if you were perusing the assembly, you would really have to scratch your head about why that was done). C++ does not specify the "low level semantics", neither do many other languages. Depending on the contents of the loop the compiler may omit it completely and just store a precomputed result or even omit that if it isn't used. It may transform, move, replace, omit, etc. as much as it likes as long as the behavior meets the requirements for "observable behavior" outlined by the standard and assembly no matter which platform is not covered by it (nor are debuggers - resulting in wildly jumping code execution). &gt; but such a reversal adds nothing that I can see Nothing you can see, for the compiler it could be part of a normalization process that prepares the input for the optimizer or just a transformation done by default since it is better on some platforms without impacting others. 
Watch this talk http://channel9.msdn.com/Events/Build/2014/4-587 Was posted earlier this month.
I did. Good talk. That's what brought me to post this. I don't recall Eric speaking to floats vs doubles.
The basic guarantee isn't "unsafe". It's the ordinary guarantee provided by the STL. Instead of thinking as the strong guarantee as "safe", you should think of it as "special and unusual, and I hardly ever need it". (The nofail guarantee is common and quite useful; e.g. swap being nofail is important.) The STL was designed to provide the strong guarantee only when it would be free. For example, vector multi-insertion provides the basic guarantee, because achieving the strong guarantee would be expensive.
Well, he talked about the performance difference when using 256bit vs 128bit opcodes being significantly less than 128 vs 64 due to memory stalls and cache misses. I assume the same should hold true for floats vs doubles, though perhaps not as drastically. I just use doubles nowaday for everything since I also compile 64 by default and this already causes pointers to double in size, why not double the floating point precision as well :)
I've been on the fence about this one myself, not only would the error messages be more readable but it would allow IDE's to provide code completion for make_window. Thank you for the comment, I may update the article with that suggestion.
I am still looking for people, its so difficult to find someone who will be interested on....
I was going to say this as well. Why use pthreads or C struct mutexes when you have `std::thread,std::mutex,std::lock_guard`, etc. 
I think he wants to still use constructs like break and return without adding more mutable state.
It seems interesting, do you have more details?
You can ask and I will try to answer your questions. Currently its a templates based neural network actually most of the implementation is about multilayer perceptron and backpropagation algorithm. I also have some example with simple ocr where the nn is used. I would like to implement much more things there, like support for different network configurations. There are u-tests missing which have to be written. Recently I integrated an integration build server (not completely it is still on going process). So I see that I don't have so much time to handle everything there therefore some help would be great :).
Are 'scan-build' and 'clang --analyze' functionally equivalent? I am confused as to what the difference is.
http://ideone.com/37rugY template &lt;class F&gt; void repeat(unsigned n, const F &amp;f) { for (auto i=0; i&lt;n; ++i) {f();} } repeat(10, [&amp;]{ std::cin &gt;&gt; x &gt;&gt; y; x_coords.push_back(x); y_coords.push_back(y); }); 
The blog quotes the documentation for steady_clock, but until 4.8.1 g++ didn't use a monotonic clock for steady_clock. http://gcc.gnu.org/gcc-4.8/changes.html#4.8.1
I don't know why you are getting downvoted. While there is a WG for ranges so that we should (hopefully) see ranges in the C++17 standard, the algorithms interface is definitely inferior to that of Boost.Range. The C++ iterator concept is itself broken, because the traversal category and value access policy are subsumed into the same tag. The two are in fact orthogonal concepts: see Boost.Iterator for details. Alexandrescu took note of ranges when designing D, and even wrote an article discussing the importance of ranges. I think that D's standard library uses some of the innovations that the people who wrote Boost.Iterator and Boost.Range came up with.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Argument-dependent name lookup**](https://en.wikipedia.org/wiki/Argument-dependent%20name%20lookup): [](#sfw) --- &gt; &gt;In the [C++](https://en.wikipedia.org/wiki/C%2B%2B) [programming language](https://en.wikipedia.org/wiki/Programming_language), __argument-dependent lookup__ (__ADL__), or __argument-dependent name lookup__, applies to the [lookup](https://en.wikipedia.org/wiki/Name_lookup) of an unqualified [function](https://en.wikipedia.org/wiki/Function_(computer_science\)) name depending on the [types](https://en.wikipedia.org/wiki/Data_type) of the [arguments](https://en.wikipedia.org/wiki/Argument_(computer_science\)) given to the [function call](https://en.wikipedia.org/wiki/Function_call). This behavior is also known as __Koenig lookup__, as it is often attributed to [Andrew Koenig](https://en.wikipedia.org/wiki/Andrew_Koenig_(programmer\)), though he is not its inventor. &gt;ADL occurs only if the normal lookup of an unqualified name fails to find a matching [class member function](https://en.wikipedia.org/wiki/Class_member_function). In this case, other [namespaces](https://en.wikipedia.org/wiki/Namespace_(programming\)) not considered during normal lookup may be searched where the set of namespaces to be searched depends on the types of the function arguments. Specifically, the set of [declarations](https://en.wikipedia.org/wiki/Declaration_(computer_science\)) discovered during the ADL lookup process, and considered for resolution of the function name, is the union of the declarations found by normal lookup with the declarations found by looking in the set of namespaces associated with the types of the function arguments. &gt; --- ^Interesting: [^Andrew ^Koenig ^\(programmer)](https://en.wikipedia.org/wiki/Andrew_Koenig_\(programmer\)) ^| [^Typename](https://en.wikipedia.org/wiki/Typename) ^| [^Outline ^of ^C++](https://en.wikipedia.org/wiki/Outline_of_C%2B%2B) ^| [^Barton–Nackman ^trick](https://en.wikipedia.org/wiki/Barton%E2%80%93Nackman_trick) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cgx7vzf) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cgx7vzf)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
The downvotes are mostly a bandwagon effect but that's fine. Among people who have used both ranges and algorithms, it's certainly not controversial that ranges are trivially superior, but I doubt many C++ developers have used boost.range. My concern is mostly that the Parallel STL will be applied to the existing set of &lt;algorithm&gt; and will not apply to the work being done to standardize ranges, meaning we'll end up with parallel algorithms but no parallel ranges. That would be a shame in my, I guess, highly unpopular opinion.
I haven't seen a more stretched strawman in a really long while. :-)
What you describe doesn't stop you from using a BLAS, just add a specialized template for floats (which would call SGEMM), one for doubles (DGEMM), the other types can use the generic matrix-matrix multiplication. However, from what you write it looks like your template hierarchy is too overengineered. I'd cut the `Neuron` class out of the equation....A neural network does not need a separate class to represent a single neuron, just pass the datatype and the Activation function as template arguments to the Layer-class. 
Thank you for your comment. I would disagree that a neuron class is useless here. I decided to create this class in a case if I would need to construct a network with a different topology than a multilayer perceptron What if I need to make a network which does not contain layers but only has neurons similar with this used in perceptron? It is also helpful in my tests so I can mock it if I need it.
Very nice post. However I think you need forward iterators for your mean function. Once you've "read" from the input iterators to compute `sum` you're not guaranteed to be able to access the same elements a second time to compute `std::distance`. For example, if I see `mean` takes input iterators as parameters, I assume that I can pass in `std::istream_iterator`'s, but it doesn't seem like that will work.
Gosh, you're right. I'll get that fixed as soon as I get home. Thanks for the read!
No problem, I enjoyed it! It's a message that I've been telling students at my university for a few years now (ex C++ TA.)
you're right, I was only thinking about MLPs... But out of curiosity, what will each Neuron store?
&gt; what will each Neuron store? Normally Neuron is an interface, see INeuron but in my case currently I have just one implementation of this interface, it stores only the inputs (pair of weight and input value + bias) it might be that you will need a neuron without bias or you will need to change the calculation of the dot product. You put me in some thoughts about refactoring neuron should be more general should not have setters and getters for weights. 
Note that the correct fix isn't to require forward iterators, it's to count while you're iterating.
As a fan of STL I really enjoyed the article. One side note, I think we should finally start phasing out this narrative: "lol, C bad, unsafe, here's how we do it in superior C++". It was good 20 years ago, but these days most people either jump straight to C++ or come from languages other than C (like Java). This narrative not only reinforces the harmful notion of C++ being "just a better C", but also makes us miss an opportunity to confront C++ with other modern languages often sold as better than C++ or even obsoleting it. Notice for example how you could easily use Go as a bad boy in the article, instead of C.
I'm currently a student and I see students writing C like in the example code. It may be more relevant than you think.
CMake is my build system of choice too but I found that's its more convenient that I don't need to integrate it. It should work around CMake
Thanks a lot for reading the article! The C code that I displayed was code that I see in C style C++; granted, things are miles ahead now of how it was in 1998, and I'm so glad to see the new standard embraced by newcomers to the language, but unfortunately the sample code I listed happens quite often.
C UR DOIN IT RONG &gt; double mean(double *data, size_t len)
Nice but incomplete. Shouldn't you actually implement some code using accumulate. Maybe I missed it as I started skimming after realizing that the article goes on forever. 
I must disagree, as someone who does this for a living. (Algorithm implementation, that is, not disagreeing with people on the Internet, although I do that too...) Calling `distance()` is doubly wrong. First, because when algorithms have weaker requirements, users are happier (even if implementers are sadder). Second, because even if you don't care about input iterators, performing a second pass for `distance()` is slower for forward and bidi iterators. Generic algorithms need to be optimal given their arguments, or close enough to it, in order to discourage handwritten code. When I'm working on a heavyweight algorithm like `is_permutation()`, I'm constantly thinking about the worst possible arguments that the user can give me, and how to avoid paying extra penalties like unnecessary passes and pointless work. This often requires extra logic both at compiletime and runtime, but it's worth it - a well-written algorithm pays for itself many times over. (The needs of the many users outweigh the needs of the few implementers, or the one.) The only reason to call `distance()` here is laziness. Sometimes even an implementer needs to save time, but you should acknowledge when you're doing that, and not try to rationalize it as the "correct" way to write the algorithm.
I do agree with what you're saying, but I don't think I'd call using distance() here laziness. It's not the most optimal way performing the computation, but it's pretty straightforward to see what's going on. I wouldn't expect a core algorithm in the STL to be implemented this way, but for the purpose of showing a clear way to compute means, I think it's fine.
&gt; Now that’s some really nice, concise, readable code Uh, not as displayed by my browser. Maybe you'd like to web-ize that code. It looks copy-pasted from your editor, and HTML eats whitespace for lunch. template&lt;typename ForwardIterator, typename T &gt; T mean(ForwardIterator first, ForwardIterator last, T start) { return sum(first, last, start) / std::distance(first, last); } Looks awful, doesn't it? Let's try a few purely stylistic changes. template&lt;typename ForwardIterator, typename T&gt; T mean(ForwardIterator first, ForwardIterator last, T start) { return sum(first, last, start) / std::distance(first, last); } Now that is readable code in my opinion.
As much as I love STL algorithms, I have to admit that I don't love typing `thing.begin(), thing.end()` all the damned time. I like adding a `, 0` even less. I've been known to write wrapper functions that just take a container and pass begin and end along to a standard algorithm. On the other hand, I do appreciate being able to specify the accumulate type, because there are times I'd like to add my floats using a double to get more precision.
Id say C++ is becoming more multi-paradigm, not converging on lisp style.
 &gt;I was a quite average CS major in college who studied C++. I've spent the last three years completely out of the field, so I'd like to go back and start from square one--building a solid knowledge foundation this time. That is actually a good thing because C++ has a new standard, as such you might as well learn the new techniques. The new standard I'd called C++11 by most with a minor tweak called C++14 due to be ratified soon. So any text you choose must be current and support C++11 It is imperative due to new techniques that should make your life easier. &gt;With that in mind, I've narrowed down my book choice to either Stroustrup's [The C++ Programming Language, 4e](http://www.amazon.com/C-Programming-Language-4th-ebook/dp/B00DUW4BMS) or Savitch's [Absolute C++](http://www.amazon.com/Absolute-C-5th-Walter-Savitch/dp/013283071X/). (I've looked at Savitch's [Problem Solving with C++](http://www.amazon.com/Problem-Solving-8th-Walter-Savitch/dp/0132162733/) too, but I'm not quite sure the difference--content-wise--between this and former). Never heard of Savitch so can't comment on his books. However Stroustrups book is a bit of a reference so I'm not sure either of these are right for your needs. Somebody else mentioned Lippmann above, that might be a good choice. Here is the big problem, not a lot of good texts exist right now. You will find yourself browsing the Internet often to make up for the lack of texts. &gt;What are your recommendations out of these two (or three)? Well for most people it would be neither. However you have indicated some C++ background! as such Stroustrop may be OK for your needs. Whatever text you choose to work from make sure it is C++11 complaint. The problem here is that texts have or will be revved, so what you really need is a list and unfortunately I don't have a URL handy. Try StackOverflow as some place on that site they have a good list. 
Don't get The C++ Programming Language, his other book, Programming: Principles and Practice Using C++, is closer to what you are looking for. The downside of that book is that it is based on pre-C++11 standard. You can wait for him to release a second edition based on C++11/C++14 (which could be years), or try antoher book. Stan Lippman's C++ Primer is well though of, as others have mentioned. 
A question in the related context -- are there any hopes for automatic kernel fusion for cases like this some day? I'm asking, since this looks to be a common case when talking about the composition of algorithms and its impact on performance -- not only in the Standard Library, but also in Thrust. Consider `saxpy_fast` and `saxpy_slow`. Here, kernel fusion has been applied manually, combining three algorithms invocations: // temp &lt;- A thrust::fill(temp.begin(), temp.end(), A); // temp &lt;- A * X thrust::transform(X.begin(), X.end(), temp.begin(), temp.begin(), thrust::multiplies&lt;float&gt;()); // Y &lt;- A * X + Y thrust::transform(temp.begin(), temp.end(), Y.begin(), Y.begin(), thrust::plus&lt;float&gt;()); } into one (with the appropriately defined functor) // Y &lt;- A * X + Y thrust::transform(X.begin(), X.end(), Y.begin(), Y.begin(), saxpy_functor(A)); . http://code.google.com/p/thrust/wiki/QuickStartGuide#Transformations Naturally, the difference is significant: "Both `saxpy_fast` and `saxpy_slow` are valid SAXPY implementations, however `saxpy_fast` will be significantly faster than `saxpy_slow`. Ignoring the cost of allocating the temp vector and the arithmetic operations we have the following costs: fast_saxpy: performs 2N reads and N writes slow_saxpy: performs 4N reads and 3N writes" Another example is [`thrust::transform_reduce`](http://docs.thrust.googlecode.com/hg/group__transformed__reductions.html#ga0d4232a9685675f488c3cc847111e48d) (on a side note, I wish we had this one in STL -- especially if it turns out that we cannot get automatic fusion on the implementation side), which fuses the `transform` and `reduce` operations. Now, in the GPGPU world there's been some R&amp;D done into the automatic kernel fusion/fission: - http://saahpc.ncsa.illinois.edu/09/sessions/day2/session2/Garland_presentation.pdf - http://www.fi.muni.cz/~xfilipov/s4-1.pdf On the programming (and reusability) side, this is a bit like the M*N problem for #containers * #algorithms (before it became M + N with templates / automatic code generation), where instead we now have combinations of possible fusions: "The number of possible fusions is high as each fusion is created according to sequence of kernel calls and data dependency between them. Thus, re-usability of fused kernels is limited. Because of this, it is impractical to produce libraries consisting of already-fused kernels. Instead, it is more practical to use the library of simple and re-usable kernels and automatically generate fusions when the sequence of kernel calls is given." // http://arxiv.org/abs/1305.1183 I'm wondering, would you see that as a possible development in the STL some time in the future?
I used problem solving with c++ for my community college classes. most here would not recommend it because it doesn't teach the language per their philosophy (jumping right into oop rather than beginning with essentially c and bringing in oop later). Technically you can if you go out of order, and I think it had some teaching guidelines that show what order you can go without dependency issues. personally I think either style has their benefits, especially if you're savvy enough to know better when it comes to not using the old if there's obviously new stuff that is better to use. the book is quite thorough/wordy but has good problems. programming is something you learn by doing, and that book gives you plenty of stuff to do(20-30 programming exercises at the end of each chapter that progressively get harder). I couldnt see myself 'reteach' myself programming by reading word by word this book (i would go insane). The problems are a good indicator of whether you know your shit
This might not be what you're after, but personally, I've learned more from writing small to mid-sized programs myself, reading code of others, cppreference.com. That aside, back in my college days I bought Stroustrup's book. I've looked a few times into it, and I think it helped me to get a fundamental understanding. But now, after I know general programming language paradigms, I'd probably tackle C++ like any other language. Get familiar with the basics (which shouldn't be to hard, when you have a programming background) and work your way to more advanced topics. I think the most rewarding things to learn about C++ are proper use of the STL (iterators, algorithms &amp; containers) and template meta programming. Template meta programming will change the way you think about data types. Combine that with learning a functional programming language (e.g. Haskell) and you'll see things from a completely different point of view.
I may get downvoted for this, but ever since I got to know Common Lisp, I always find it laughable when someone calls C++ multi-paradigm.
The second edition is due in June http://www.amazon.com/Programming-Principles-Practice-Using-Edition/dp/0321992784/ref=sr_1_2?ie=UTF8&amp;qid=1398086459&amp;sr=8-2&amp;keywords=programming+principles+and+practice+using+c%2B%2B
I don't get the joke. Nor do I get smug lisp weaniism in this day and age when lisp doesn't seem to offer very much over a half dozen other languages.
Really? Sorry, I tested it on Firefox and it looked fine. The second angled bracket on a line by itself before the `T` is my crappy personal style though, I should go back to doing it the more civilized way.
&gt; auto now = [val = system_clock::now()] { return now; }; I think there's a typo here. You capture `val`, but then never use it. Did you mean "`return val;`"?
Can't you use Boost.Range ? auto sum = boost::accumulate(vector, 0, plus&lt;&gt;);
I'd personally recommend C++ Primer to almost everyone, but here is a broader list: http://bert-hubert.blogspot.nl/2014/02/the-cprogramming-books-i-recommend.html (despite URL, this is about C++)
Stupid question. Can you mix autodeduced return type with new style function declaration syntax? Eg. ```foo() -&gt; auto { ... }```
Yes, though you need the leading `auto` as well. auto foo() -&gt; auto { ... }
The Stroustrup one will give you a more solid base. It's written by the creator of the language, and it goes in depth on *why* the screwy things in the language are that way. Also, the best reference I've found so far is [this](http://en.cppreference.com/w/) site. It's not very good tutorial-wise, but it's great for looking up how to use all the different part of the standard library.
Binary literals have been in Digital Mars C/C++ since, oh, 1983 or so. As far as I can tell, nobody found them interesting or used them.
I don't understand where this idea of `shift` comes from: - The STL that is cited was created before the first C++ Standard ('98) - Of all the things that C++11 introduced, only `auto` and `decltype` seem to be used C++ has always been multi-paradigm, and Boost has featured Preprocessor Programming, Template Meta-Programming and Concept Checking (among others) for years.
Binary literals exist in gcc. I mainly use them to encode enums into bit fields if the amount of values is small enough.
It's definitely a useful feature when working with bit masks.
Its a very big code can't write here!
This is probably the first hello world tutorial I read for which I can't just copy the code and compile it, since there is no compiler available... How should I (or anybody else) take the SYCL standard seriously when it has been developed without any implementation experience? My brain-embedded compiler can only go so far, or otherwise I would never get compilation errors when writing C++ code. The ISO C++ committee seems to have gotten this point right. Provide an implementation, let people try it and play with it, and only then, discuss about standardizing it. Even when you do it _right_ bugs make its way into the standard... AFAIK SYCL might be impossible to implement, since no one has proven otherwise yet...
Yes, I did mean to return `val`, thanks!
Also, is that variable captured at creation or execution of the lambda?
Well, since I've (rightly) been downvoted for being vague and wry, i'll link you to a ~50 minute discussion by Alex himself on why the STL, as is, has flaws. I won't tl;dr because it's worth watching, as are the next few on similar kinks in the STL. https://www.youtube.com/watch?v=dUEA8fHx0r0
I'm way ahead of you.
I can't find the exact wording right now, but I believe the initialization is done when the lambda expression is created. Think of it as creating an extra member in the lambda's functor class. 
I'm in a similar situation as OP and have decided to go this route, though I'm ending up reading both simultaneously and more as a reference than study material. I found it very useful to go through some rudimentary exercises (Exceptional C++: 47 Engineering Puzzles, Programming Problems, and Solutions or some such; /r/dailyprogrammer, and so on), refreshing data structures knowledge, and getting familiar design patters (this subject seems to be somewhat controversial but being familiar with design patterns helped me a lot when reading through someone else's work). Effective C++ and More Effective C++ have been very helpful as well. And don't forget to get very cozy with STL and Boost.
&gt; As far as I can tell, nobody found them interesting or used them. Understandable, if you want to write portable code. Personally I welcome this new feature. I did a a lot of bit manipulations in the past, and often wondered with C or C++ never had this part of the spec.
Some of this stuff is quite nice. I hoping that this trend of template simplification (and in some cases complete elimination) via the introduction of new language features will continue.
I was hoping I could find a book with exercises built in... Hmmm
Are you so gay that you can't handle hexadecimals?
Yes.
C'mon, you have internet access and a bit of imagination, don't you?
Excellent! Thanks.
I've written a lot of bit manipulation code, and I mean a lot. I thought binary literals would be helpful with this - but they aren't. You wind up spending time carefully counting digits on the screen with a pencil tip, and woe if you miscount. Hex, on the other hand, has much less of an issue with this, and over time the hex digits form the right bit patterns in your mind.
1. Yes, you can generate a pseudo-random number. It is common for people to use the C function `rand` to do this, but `rand` is pretty terrible. There are absolutely no guarantees about its quality. Also, it is typical for people to do something like `rand() % 100` to get you a random number within a range, but this doesn't give you a uniform distribution. Basically, don't do this. Instead, use the new random number generation features of C++11 in the `&lt;random&gt;` header (or if that's not available to you, use [Boost.Random](http://www.boost.org/doc/libs/1_55_0/doc/html/boost_random.html). If you want a uniform random integer between 1 and 100, you would first do the following to set up the distribution: std::random_device rd; std::mt19937 gen(rd()); std::uniform_int_distribution&lt;&gt; dis(1, 100); And then you just do `dis(gen)` to get a value according to this distribution. 2. You can do that. Again, C++11 provides the new `&lt;chrono&gt;` header for measuring time. You can get a "time point" representing the current time by doing `std::chrono::system_clock::now();`. If you want to make sure the player takes no longer than a specific number of seconds, you'll need to store the time at the start and then check that the difference between then and the current time is less than the limit. If it goes over the limit, they lose. 3. Of course you can. The IDE is just where you write the code. Whenever you run your program, the code is first being compiled into an executable before running it. This is known as building the program/project. You can build your program and then distribute it in a number of ways. How exactly you do this depends on your platform and the IDE you're using. If you're using MSVC, for example, you would typically change the "solution configuration" to "Release" (instead of "Debug") and build the program from the "Build" menu. This will output a `.exe` file in your build directory.
Rand should be considered harmful. http://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful
&gt; restructure code in order to make it more reusable That's where many problems start. If you're not writing a library you shouldn't think about re-usability until it really pokes you in the eye. (And then you probably should extract it into its own library anyways). I'm not really sold on this. But maybe I'm not academia enough to see the light in this case.
I think that that article needs better motivation to convince C++ users to learn FP. All of the examples in this article (mostly based on generating Pythagorean triples) can easily be implemented using Boost.Iterator and Boost.Range. (The latter library is closely related to some of the concepts mentioned in the article.) I did skim the text, so I may have missed something that makes one of the examples difficult to implement using existing tools. The machinery you need to simulate Haskell in C++ requires virtual calls (since std::function is used) as well as stacks. This renders this approach unusable for performance-sensitive code. I don't really understand what we gain from this over existing tools. Several of the author's past articles have been trying to gently seduce C++ programmers to buy into FP. In some ways, like with std::future, we have. But as far as the more esoteric FP concepts go, I have yet to buy it. Most concepts in FP still seem to be academic curiosities rather than tools that can be used to solve practical problems. (Hey Haskell, how's that implementation of bitmap coming along?)
&gt; Rand should be considered harmful. Only if you're using it for cryptographic or security purposes. For deciding what colour a cartoon elephant is, "harmful" is a little extreme.
No, you should just get in the habbit of using good API's over bad ones regardless of how important it's use is. It's the same as using new[] or malloc over a vector, why bother, just use a vector and be done with it. That way hopefully with time C++ will look less like some dinosaur and more like a useful language again. http://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful
I'd prefer understanding over blind obedience to rules of thumb like this. Knowing why `rand()` is bad let's you avoid those times when you might write your own badness into your application. If you just think "no `rand()`", then you don't know enough about programming to avoid making similar mistakes yourself. It reminds me an awful lot of "`goto` considered harmful", which was equally unsubtle, and is now widely accepted as such. I'm not saying `rand()` will ever be rehabilitated, but bad programmers don't need `rand()` to make insecure software.
&gt; I'd prefer understanding over blind obedience to rules of thumb like this. That's precisely why I linked the video. You can know something is bad and still not use it, it's the same reason I don't do skag. At the end of the day, using &lt;random&gt; is never going to be worse than `rand` and is often going to be better and always be cleaner. Rand is as good as deprecated.
Well, I gave you a link to the video which states that claim. STL will do a much better job arguing that case than I will.
Probably because the syntax for static functions is a bit easier to understand. Compare: return thunk_(this); vs. return (this-&gt;*thunk_)(); or T const &amp; (*thunk_)(Susp *); vs. T const&amp; (Susp::*thunk_)();
&gt; The machinery you need to simulate Haskell in C++ requires virtual calls (since std::function is used) The `std::function` is really not needed, it would just require him to use more complex types(which is how laziness is generally implemented in C++). 
rapidjson was written with c++03 and custom sse4 instructions. when sse moves on to the next generration, or new c++ language features become available for more aggressive optimization opportunities, you want the project to be updated, it's as simple as that.
scan-build is basically just a wrapper around "clang --analyze" that allows it to run on multiple files and generate a summary report at the end.
Then your comment "Returns current time" is incorrect. It returns the time the lambda was created, not the time it is executed. Maybe something more useful would be auto timer = [val = system_clock::now()] { return system_clock::now() - val; };
I can't, for the life of me, understand why: const int engineOn=1; const int doorOpen=2; const int lightOn=4; ... turnOn(engineOn|lightOn); Or similar...
and here I am still using gcc from 2010. God I hate large collaborations who don't want to update software.
Call your headhunter (free after Andrei Alexandrescu).
Doesn't implementing the Pythogorean triples example using Boost.Iterator incur precisely the same benefits? In a few lines of code, we can subclass `boost::iterator_facade` and maintain the loop counters as mutable member variables. When `dereference()` is called, we advance the loop counters until we reach the next triple. Using Boost.Range, we can elegantly compose the iterator with other filters to operate on the output. And nowhere in any of the headers are virtual function calls or heap allocation used. I agree that the benefits gained by using FP are often worthwhile having, but in this case I don't think simulating the Haskell gobbledegook using C++ is the best way to go about it.
Ah ok, thanks. I guess I don't have to change my make system then.
C++ is a BIG language, and it's capable of a wide range of horrors and wonders. I recommend you learn a modern subset of the language. I think you should start with the book: "Accelerated C++". It's about learning C++ without letting too much cruft from the past complicate things (though I wish there was a C++11 version)... When you're finished with that, read Effective C++ and by that time Scott Meyers NEW C++11 based "effective" book should be out and you'll be able to get fully up to speed.
pasting stepanovs lecture as a link evidence to your argument should be a crime... cuz nobody is gonna listen to him talk 50 min to say 3 sentences worth of content. 
You are lucky. I am using gcc 4.3.4 from 2009 :) The funniest part is that it feels pretty decent and recent compared to the Sun/Oracle compiler I also have to support.
&gt; I strongly dislike raw arrays, and not because they're from C. I dislike them simply because raw arrays behave in bizarre and inconsistent ways which make them prone to serious errors. Time and again I find myself fixing bugs in our old code that result from the usage of raw arrays. do you mind explaining what those problems are and why they would not be fixed with .begin, .size . end but are solved with std:: array? 
My workplace is still using 4.1.2... 
&gt; You might be concerned about the performance of lazy data structures, and rightly so. They use the heap heavily, so memory allocation and deallocation is a serious performance bottleneck. There are many situation, though, where code structure, reusability, maintenance, and correctness (especially in multithreaded code) are more important than performance. While this is true in many circumstances, I don't think it rings nearly as truly for the traditional use case of C++. People come to C++ when they _need_ performance. I'm all for better abstraction, but in C++, they must exist at little to no cost.
Stuck with VS2010 here, at least it has lambdas though :P.
Interesting. Also part of a large collaboration that by default uses gcc 4.3 or 4.4, depending. Although if you bypass the "official" environment and use the "standalone" one you can use gcc 4.7 or 4.8.
Impossible.
Policy-based design and templates in general still have their place.
Hm, I am happily using Clang for a while now. The Mac OS X Mavericks upgrade replaced GCC silently, gcc became a symlink - I only noticed because of some C++11 library issues 
Bad troll is bad
oh man i'm such a noob at installing IDE's/compilers. i think it's the biggest bar to entry 
Let me know when you prove me wrong and have learned C++.
It's not a joke. Look at CLOS: far more general than C++ OO support. Look at macros: far superior to C++ templates. Look at reflection: oh, C++ doesn't have that at all. Look at functional programming or OO: having garbage collection makes it a lot more flexible. And so on... I know that Common Lisp is often not practical to use (e.g. lack of good libraries), but that doesn't make calling C++ multi-paradigm less ridiculous.
&gt; it's about beauty. I agree the Haskell version of this program is a beauty. But I fail to see how the C++ lazy version is beautiful. I wrote my own crappy version of the Pythagorean generator and I do find it beautiful: &gt; https://gist.github.com/alejolp/11171006 
&gt; But as far as the more esoteric FP concepts go, I have yet to buy it. I'd love to read an article about the use of [Foreign-Ptr](http://hackage.haskell.org/package/base-4.7.0.0/docs/Foreign-Ptr.html) to simulate C++ object polymorphism and vtables on Haskell. 
that entails a whole other hassle in of itself that would probably only raise the bar higher
I had 4.8 installed on my personal computer (now upgraded!), and am very used to the C++11 syntax. I created a toy assembler and virtual machine for my Operating Systems class. When it comes due, I find out that my code is supposed to compile on the lab computers... which have 4.4 on them. Goodbye, range-based for loops.
For some reason when i visited this link it took me to /install.php ...
 auto p = make_unique&lt;int&gt;(10); auto lmb = [p = move(p)] { return *p; } This seems fishy.. i guess you need to rename one of the variables or else you will run into problems as this should just move the uninitialised p to initsialize p .. 
No, it takes about 10mins to get used to your package manager then you realise then life is easier when you don't have to build everything from scratch and that your includes just live in /usr/inc and your libs in /usr/lib. Both default paths for your compiler.
Me too. I just download Qt SDK and it installs everything for me. Someday they will include minGW with GCC 4.9, until then you can use the 4.8
I wanted a literal answer, its not "impossible"
I know constexpr is basically just replacing the result into the code at compile time. But being able to do so in a safe (no preprocessor code) way still blows my mind! EDIT: Compiled with VC++ CTP 2013. 
This appears to be magic.
This looks nice and simple but the macros are not good. They should be uppercase and namespaced to avoid clashes with other macros and functions. Utimately, it could use [ZLang](https://github.com/pfultz2/ZLang) to make them neater(a ZLang dedendency is not required to make it work with ZLang). Also, `throws` does not need to be a macro either, and should really be called `throw`. Here is how the examples would look with ZLang: $(tests that run before main() ) { $(test 1 &lt; 2); // test shall pass } $(tests that run after main() ) { int a = 1, b = 2; $(test a &lt; b) &lt;&lt; "this shall pass; comment built on " &lt;&lt; __TIME__ &lt;&lt; " " &lt;&lt; __DATE__; $(test a &gt; b) &lt;&lt; "this shall fail; phone Aristotle (+30 " &lt;&lt; 23760 &lt;&lt; ") if this test fails"; } int main() { $(test 1 + 1); $(test throw std::string hello = "world"; hello.at(10) = 'c'; ) &lt;&lt; "test shall pass, exception thrown"; $(test throw std::string hello = "world"; hello += hello; ) &lt;&lt; "test shall fail, no exception thrown"; } I could try to submit a pull request, if the author would be interested in this. EDIT: Actually, I think it would make sense that throw was an expression instead of statements, just for consistency sake: std::string hello = "world"; $(test throw hello.at(10) = 'c') &lt;&lt; "test shall pass, exception thrown"; $(test throw hello += hello) &lt;&lt; "test shall fail, no exception thrown"; 
What optimization level are you using? What does the disassembly look like? I'm surprised that constant propagation and dead code elimination don't make both cases exactly the same. Constant propagation should let the compiler compute ``degrees_to_radians(180.0f)`` at compile time, so that you get the same effect as ``constexpr``. Dead code elimination should see that ``degrees_to_radians()`` is a pure function, and its result is unused, so the entire loop that calls it can be removed! On my version of clang, "Apple LLVM version 5.1 (clang-503.0.40)", using ``O2``, I see that both runs take 0 ms, and looking at the disassembly, I can see that both loops have been entirely deleted. Neat! One way to coerce the compiler to not delete the code is to store the value into a volatile pointer. You can see an example of that [here](http://pastebin.com/4P0xtXEk). It's good to double-check the disassembly to make sure that the compiler didn't outsmart you. Sure enough, both loops are optimized into repeatedly storing a constant. The code is almost the same. No constepxr: 0000000100000834 movl $0x989680, %ebx 0000000100000839 callq 0x100000cf0 ## symbol stub for: __ZNSt3__16chrono12steady_clock3nowEv 000000010000083e movq %rax, %r14 0000000100000841 nopw %cs:(%rax,%rax) 0000000100000850 movl $0x40490e56, -0x2c(%rbp) 0000000100000857 decl %ebx 0000000100000859 jne 0x100000850 With constexpr: 000000010000090b movl $0x989680, %ebx 0000000100000910 callq 0x100000cf0 ## symbol stub for: __ZNSt3__16chrono12steady_clock3nowEv 0000000100000915 movq %rax, %r14 0000000100000918 nopl (%rax,%rax) 0000000100000920 movl $0x40490e56, -0x2c(%rbp) 0000000100000927 decl %ebx 0000000100000929 jne 0x100000920 What's pretty cool is that the compiler has figured out that ``degrees_to_radians(180.0f)`` and ``DEGREES_TO_RADIANS(180.0f)`` return the same value, and has baked that value in only once at ``0x40490e56``, reusing it for both loops. You'll notice that both loops differ at the fourth line, the nop instruction. I'm pretty sure that nop is inserted to align the back-edge of the loop, the part that gets jumped back to. I think this is just a consequence of where each loop begins in the binary. For me, the "no constexpr" loop takes 8 ms, and the "with constexpr" loop takes 6 ms. I'm curious if this could be a consequence of the loop size, a detail which ended up having nothing to do with constexpr at all! Indeed, if I swap the order of the two loops, I now see that the "with constexpr" loop is padded more than the "no constexpr" one, and now the runtimes are swapped. Anyway, this is a neat example! It'd be interesting to see if MSVC's optimizer is really that bad, or to double-check if you're accidentally building a debug build or something like that.
Why what? Why that works? Why not use that over binary litterals? Why someone would use that?
For this simple case though, the optimizer should be doing that anyway.
Thanks for the suggestions :D Good point indeed, even if $() can collide with other macros as well! Like: - https://github.com/orangeduck/libCello - https://github.com/r-lyeh/wire/blob/master/sample.dollar.cc - and so on There is no sane point with macros afaik. Anyways, I guess the library is so small that anyone can tweak the #define if desired : ) 
Ooops! Yes I did indeed build with debug on! (stupid me!) The results are both 0ms now! Praise compiler optimizations! Very informative comment btw! I'm still learning C++ in uni. (1st year) and I love to know more about what happens behind the scenes. I have already had a course on assembly so I know more or less what is happening on the compiler generated code. Next year I have a compiler &amp; interpreter course (fun!). Thanks a bunch for the informative comment!
It seems documentation is somewhat lacking. Will you improve it? Anyway I really like the "just headers" feature and the ease of integrating scripting and C++ stuff :)
Indeed it is! I compiled with debug on :(. Both results are now 0ms!
Well the dollar sign can be disabled, and `ZLANG` can be used instead, since there are a few platforms that don't support the dollar sign in the first place.
Visual Studio 2008 here. Company refuses to upgrade until MS fully supports c++11. So i might be stuck with it for another decade or so.
It would probably be better to use good known linear congruential rng instead of rand() as a performance baseline. Also: mt19937_64 needs an unsigned long to contain the full range. Did you mean uint64_t?
Numerical stuff is what has seen the biggest boost in performance, in the ~20x faster than it was. The goal right now is for ChaiScript to be fast enough to not get in your way. This means that for anything that's performance critical you can use ChaiScript to prototype it, then move the performance critical code into C++. Compiled C++ will be able to give you performance well beyond what any scripting language can give you, and with ChaiScript that move into C++ is nearly trivial.
Since this is on Linux, it would be nice to include the performance of /dev/urandom as well. The libstdc++ implementation of `std::random_device` uses RDRAND if available, and it would be nice to show some numbers related to that.
Sorry to see that all of the new generators are slower than rand(). I'd like to see Well512 implemented as a uniform generator, I wrote an implementation of it for 32 bits and it was ~2x faster than rand() IIRC. 
You've allocated the memory but haven't actually instantiated the streams, so you're calling open() on nothing and getting the segfault. Replace: files[i].open(line.c_str()); with: files[i] = new ifstream( line.c_str() ); EDIT: I'm retarded. The c-style malloc threw me. You'd have to change the malloc line as well to: ifstream** files = new ifstream*[numcats]; Probably better to just use a vector and then use your open() and avoid the explicit memory allocation altogether. vector&lt;ifstream&gt; files( numcats ); for( int i = 0; i &lt; numcats; ++i ) { getline( cats, line ); files[i].open( line.c_str() ); } 
I made some edits while you were responding :P.
Aha! That worked. Thanks for the STL tip. I'm less familiar with it than I'd like to be.
I digged out my StackOverflow post when I had these "library issues" after the upgrade to MacOS X Mavericks if someone wants more details: [http://stackoverflow.com/questions/19649421/something-odd-happened-to-c-11-in-mavericks](http://stackoverflow.com/questions/19649421/something-odd-happened-to-c-11-in-mavericks)
It looks like you may know C and just be learning C++, in which case you need to forget most of what you know about C because it is a very different animal; the use of malloc in a modern C++ app is a mistake in 99.99999% of circumstances. If you aren't coming from C and learned to create vectors this way the C++ material you're learning from is very old, and you should learn from somewhere else I'd possible.
It is probably worth mentioning storing an ifstream in a STL container is only possible since C++11. ifstream is not copyable, but is now movable. 
&gt; The inclusion of rand() is just for comparison, keep in mind that it is not thread safe, usually has horrible numeric characteristics, and commonly (at least under mingw) only has a 15bit range.
No, that's fine. See the explanation in Wikipedia: http://en.wikipedia.org/wiki/C++14#Lambda_captures_expressions
These testp changes seem quite interesting... I am always excited to see new stuff from agner fog 
POST your flags, also it would be interesting to see a comparison vs boost random as well
But I'll Never™ need more than 15 bits because it's Plenty™, the quality of the randomness Doesn't Matter™ because this will Never™ be used for anything Important™, and I'm Not Using Threads™.
When doing a benchmark like "generating 10000000 numbers and writing them into a `std::vector`", you should include a line for "writing 10,000,000 non-random numbers into a std::vector" so that you have some idea how much overhead is in your benchmarks. Also, please use digit separators when writing 10 digit numbers. Had to highlight digits to see if you did one million or ten million.
We could special-case powers of two, although it wouldn't be completely free (we'd have to pay at least one branch per invocation). This is on my todo list, but implementing new features and fixing bugs is higher priority than nice-to-have optimizations.
&gt; If the range is something like 2^31 -2 like the default_random_engine in my test I would like to point out that VC's default_random_engine is mt19937, which emits the full range of [0, 2^32 ). I consider non-power-of-two URNGs to be abominations.
Are you trying to print a superscript 'st' is the terminal? I don't think that is possible.
I found out the hard way that the movability of streams is not consistent across all compilers. We ended up using shared pointers.
No way, stick with the new C++ standard. Lambdas are awesome, auto is actually handy, and the standard library now includes threading. Variadic template arguments are interesting. I was able to create a [simple wrapper mechanism](http://www.reddit.com/r/cpp/comments/21pxx2/what_is_your_favorite_little_c_snippet_of_code/cgksyc9?context=3) for a custom intrinsic refcount smart pointer system so I could easily add support to existing standard library classes. *Edit: I'm also a big fan of the new strongly-typed enums.*
&gt; all the other often recommended books like "Accelerated C++", "Exceptional C++", "Effective C++" are outdated. There is Stroustrup's The C++ Programming Language, 4th Edition. Scott Meyers' C++11/14 version in the Effective C++ series should be finished this year, if not released as well. If it doesn't make it to release this year, early 2015 I figure. Scott decided that instead of revamping Effective C++ and More Effective C++, the C++11/14 edition would gets its own focus, as the advice in the old books still stands. So in that sense, they're not out of date. Also, I think both of "C++ Primer" and "C++ Primer Plus" got updated for C++11, but I actually don't know which of those is the one usually recommended. If you're a beginner, Stroustrup's Programming: Principles and Practice Using C++ (2nd Edition) is coming out in June (target date), and is updated for C++11/14. &gt; Why is the adoption rate so slow for something that's 3(?) years old? The standard is three years old. Even that is a bit misleading, as it was ratified fairly late (August) in 2011. If I understand correctly, we've only recently got compilers with full language **and standard library** compatibility this year. This has been the case with most language standard releases in the past, but looking forward to C++14 we're likely to see full implementation much quicker. At least with gcc and clang. VC++ is still a bit of an unknown, as they are promising to finally fully implement C++11 and have a near-full implementation of C++14, but I have been disappointed by them in the past. I expect stuff to slip to their alpha CTP releases again, and VC++ to not really have a full implementation until 2015 or later. I would love to be surprised about this not being the case, of course! &gt; Is this Python 2.7 vs 3.x all over again? No. C++ has strong backwards comparability, some would argue to a fault. &gt; Should I abandon C++11 and focus on C++98 + Boost instead? Absolutely not. But you should still pay attention to Boost.
Old projects will mostly use old standards and adapt new standards slowly. As far as I have seen new projects, most of them use some parts of C++11 as it really makes programming faster and simpler (if you keep it simple). The C++ Programming language 4th edition is a good book if you want to learn C++ with its C++11 standard. You say that the standard is 3 years old, but that is only the standard, as far as I know, Visual Studio is yet to fully implement it and gcc and clang fully support it for less then a year. So it is still fresh and new. And C++14 is coming as a mostly bugfix for C++11. 
&gt; we've only recently got compilers with full language and standard library compatibility this year Ah, that explains a lot. I was confused by the name, thought it meant the year it was fully released &amp; ready for use. &gt; Scott Meyers' C++11/14 version in the Effective C++ series should be finished this year Saw that. The problem is that I'm learning now, not next year. I guess it's not an issue if the other books are still relevant as you say. Then I have plenty of material to read!
Thanks alot buddy will test it out, it seems weird to see that st is a subscript at first. Gonna try your method but I think I will just end up with the normal 1st!
Added both, thanks!
added the boost mt's to the integer section. The source is linked, but it was compiled with g++ -lboost_random -O3 -march=native -std=c++11 perf_cpp-random.cpp -o perf_cpp-random
Personally I love C++11. However, I can't really use the standard library parts of it because one of our targets is older versions of OS X, and there is only standard library support for newer versions on that platform. It's really annoying, but an example of why someone might want to use boost instead. Still, we're using a bunch of new language features, just not the standard lib. 
That's really useful, thanks!
good spot :D yep, a single unsigned will be enough! to be fixed on next rev :)
&gt; that VC's default_random_engine is mt19937 Why not std::mt19937_64? In my own tests it produced entropy with about double speed than std::mt19937.
Added /dev/urandom and rdrand via the std::random_device. Surprisingly slow!
I think C++11 (and C++14) will get adopted, it's just a matter of time. Things just move fairly slow in the C++ world. There are positive signs when you compare C++98 -&gt; C++03 transition to C++03 -&gt; C++11. The compiler support has been added a lot quicker. There is more activity around the standardisation process as well. Clang actually implements all of C++14 in addition to C++11, and GCC isn't far behind. Here are some projects which use C++11: - Component library: https://github.com/facebook/folly - Rest API: http://casablanca.codeplex.com/ - Test framework: http://banditcpp.org/ - Qt5: http://woboq.com/blog/cpp11-in-qt5.html While I'm at it, I'm also going to mention my books because they are specifically focused on C++11 in GCC, VS2013 and VS2012: http://cpprocks.com C++ Primer 5th Edition and The C++ Standard Library 2nd Edition also cover C++11.
Great, useful.
If you don't know the standard library features then learn. Writing code with malloc and similar constructs is just creating more shitty code. And there is enough of that in the world as-is.
Should this be in the standard? 
&gt; Is this Python 2.7 vs 3.x all over again? Absolutely, the C++ inner circle seem to have lost the picture. There are great things like the new for loops for iterating through things, auto, and handful of other bits. But take a look at how these template happy types want you to break up a string with a delimiter. Or the template way to convert a string to a float. C++ has gone far away from reality and solidly into academia. And before you vote me down. Remember if C++ becomes too hard for new people to learn it then they won't; and if there isn't a solid stream of fresh new blood then a language will die and die quicker than you might think. 
&gt; Also, I think both of "C++ Primer" and "C++ Primer Plus" got updated for C++11, but I actually don't know which of those is the one usually recommended. Recommend C++ Primer. C++ Primer Plus is a really bad book.
No whaaa? Do you understand the Python 2.7 vs 3.x debacle? It has very little to do with additional functionality and everything to do with a lack of backwards compatibility (with little gain in the eyes of many users). When has the C++ standards committee *ever* done that in recent history. I think you're crazy if you think C++ is purely academic right now. Most of the changes to move semantics for example were motivated primarily to make std::vector faster which was something developers have clamored for for a while. To your point about C++ becoming too hard to learn and dying, your C++03 stuff still works with a C++11 compiler. Heck, you can write C++98 code and be fine for the most part. And the language isn't dying at all. I would say C++11 revitalized it, with things like a threading library, a WAY better random library, a chrono library, better smart pointers, and tons of other things.
What advantage does it offer with respect to e.g. clang/gcc -finstrument-functions ? I use this option a lot since it automatically insert at the entry and all exit points of your functions (including compiler generated functions) calls to an entry/exit function pair. The argument given allow you to get the function name, and to do whatever you want: stack traces, logging, profiling... You can easily tell the compiler to do this only for some files/TUs, and to skip some files (e.g. standard library files), as well as on a per function basis using [[attributes]]. So IMO writing a macro manually on every code section seems like a step back.
&gt; The standard is three years old. Even that is a bit misleading, as it was ratified fairly late (August) in 2011. If I understand correctly, we've only recently got compilers with full language and standard library compatibility this year. In the Fortran world, [full support for the 2003 standard](http://fortranwiki.org/fortran/show/Fortran+2003+status) still isn't available, and only a couple non-free compilers (IBM and Intel) are very close.
It is, but something being in the standard doesn't mean that all implementations will have actually implemented it.
There's no reason to use `shared_ptr` over `unique_ptr` if moving the streams would have fit your needs.
If you think that the most interesting parts of c++11 is range for loops and auto, you should have another look.
&gt; the language isn't dying at all. I would say C++11 revitalized it Yep, I think C++ is taking back the throne. I can see that all the way from PHP world, hence my interest. :) Also, I don't think it's hard to learn at all. Syntax could be ~~better~~ more modern, but I understand that's due to BC
We're in exactly the same boat. We're writing lots of C++11, but still finding plenty of uses for Boost. Boost fills some useful gaps where a compiler is lagging behind the others, and provides lots of great functionality that goes beyond the base language (filesystem is particularly nice). That said, we're only able to use the common subset of C++11 features that are supported by all the compilers, with MSVC typically being the lagging slouch.
C++11 did not "revitalize" C++ at all. If you look at C++ popularity stats it continues its long steady slow decline. I wouldn't say that C++ is dying in that it is still the absolute #1 way to program many products. I argue for Python but many of the core bits of Python are programmed in C++. If I were running a huge mega project for some company what I would be thinking would be to program it in Python and then as certain core bits become solid to reprogram them in C++. But if I saw some programmer on that project going mad with templates (not just using vectors and other clean bit) I would fire his ass so fast that people would be nervous about using less than and greater than just in case I thought they were using templates. If a company like Adobe hired me tomorrow to rebuild Photoshop from scratch, I would only start with C++, but probably with some sort of Python API for plugins and macros. If I were making Angry birds I would use python, if I were making a FPS I would use C++. So C++ is not dying but the trend is heading in the wrong direction. C++ is getting less popular and in my opinion worse, while other languages are getting more popular and are getting better. Then you have LLVM type technologies which potentially allow for something like Python to become solidly compiled into rock hard executables which would then gut the potential pool of new C++ programmers. If you want to see a great example right in the history of C++ look at the story of how Visual C++ was born. In summary the guy ignored what the C++ hardcore types wanted (templates oddly enough) and asked what most people wanted, which was making it way easier to make Windows executables. So he delivered and within a year Borland C++ was dead. BTW I also remember when Borland C++ had all kinds of new "Templates" features. So if you go to a C++ conference and ask around as to what people want you will get an entirely different set of answers than from some guy who learned C++ so that he could make games. And keep in mind that the future of any language is that guy who learns the language to solve some problem that he has. Objective-C didn't become as popular as it did because people fell in love with Objective-C but because it was what (at the time) you had to use to make iOS apps. So right now if you want to make Adobe Photoshop you must use C++ but if you suddenly had a choice then will find itself in the dustbin of history pretty much overnight. 
C++ isn't hard to learn, there is just a vast volume of knowledge that takes time. A lot of pain is caused by legacy features.
You should still learn C++98; there's more C++98 code than C++11 code. That being said, you should not ignore C++11: it has added a great deal to C++ (being the first major 'update' to C++ in more than 10 years), that is both good for you and for your code.
Python is not implemented in C++. CPython (the primary implementation) is implemented in pure C, as the name implies. While there are several other implementations, I know of none written in C++, although I suppose one could argue about Shed Skin.
scott meyers explained `noexcept` quite well at last years [going native](http://channel9.msdn.com/Events/GoingNative/2013/An-Effective-Cpp11-14-Sampler). forward to ~26:20 for the relevant part.
&gt; But if I saw some programmer on that project going mad with templates (not just using vectors and other clean bit) I would fire his ass so fast Send him my way. If I have an opening (unlikely, sadly), I'd hire him.
I should have said C/C++
You can currently get Scott Meyers' presentation materials for [Overview of the New C++ (C++11/14)](http://www.artima.com/shop/overview_of_the_new_cpp), which discusses the new features of C++11/14. Comes with free updates, as well.
I tried to keep it on a minimum, while still providing multithreading support etc. I've tested some reallife-projects and there wasn't overhead noticeable. Of course this could always be improved, I'm open for ideas.
The biggest advantage is the visualization, profilers like CxxProf, Telemetry or the Chromium Timeline show how your code executes in detail. CxxProf also allows to track over threading and application limits, as well as define the context of your data via Marks and Plots. All in all it's quite good at working and analyzing a lot of data, but focuses on the important things. Regarding your point between sampling/instrumentation profilers: With the -finstrument-functions you generally have some control over which TUs are recorded, but you do not have the control an instrumentation profiler would give you. Take for example a TU where you have a lot of nested functions. With an instrumented profiler you could just profile those methods and that scope that is important to you. It helps keeping the mass of data to the minimum. Also: What if you want to profile something compiled with Microsofts VC? CxxProf is written portable and even allows to profile gcc and MSVC compiled applications at the same time (perhaps you're analyzing your network layer, ...). Wiki has some basic information about the different types of profilers and their dis/advantages: http://en.wikipedia.org/wiki/Profiling_(computer_programming)#Instrumentation
That was really good. I went ahead and watched that whole talk, and I’m wondering if there are any good really in-depth primers for threads in modern C++. It seems like there are enough caveats that just trying to implement them ‘for fun’, I’ll shoot myself in the foot.
C++ Concurrency in Action by Anthony Williams talks about threads in detail (as well as mutexes, lock guards, and the C++ memory model). Here's an [amazon](http://www.amazon.ca/C-Concurrency-Action-Practical-Multithreading/dp/1933988770) link. Here's a pdf version : (note that you have to click the link under e-book to get the file) [here](http://it-ebooks.info/book/673/).
for me the rvalue ref stuff was the one killer feature that drove c++11. Most of our code already used default copy, assign and destructors, so just turning on c++11 gave a noticeable speed bump. Other classes, including some very critical matrix and image processing code had specific rvalue ref code added. More huge gains. Most other problems that c++11 addressed we already had worked around. Single statement lambdas are very covenient and add to readability.
"I'm so hungry! I'd like to order an extra large pizza, stuffed crust, with pepperoni, extra bacon, chicken, pineapple, and crushed red pepper." "Sure, but we're out of pineapple, and we're running low on bacon." "Fine! I'll just have a glass of water!"
I wildly disagree with many of your points and reasoning but only have a little time to tackle a few of them. &gt; But if I saw some programmer on that project going mad with templates (not just using vectors and other clean bit) I would fire his ass so fast that people would be nervous about using less than and greater than just in case I thought they were using templates. You're delusional if you think this. Templates are an integral part of the language. Vectors are built on templates. Are you suggesting that you'll never need to operate at a low level such that you'd want templates? If all you want is the standard library, then you really don't have a use case for the language at all, and are probably better off just not using it. &gt; Then you have LLVM type technologies which potentially allow for something like Python to become solidly compiled into rock hard executables which would then gut the potential pool of new C++ programmers. No. Just because something emits LLVM code does not mean it is efficient as something else that emits LLVM code. Python doesn't allow you to lay things out in memory and have fine grained control of the heap and the stack. The optimizer will do its best, but you are not going to get the same executable that a C++ program will. &gt; So if you go to a C++ conference and ask around as to what people want you will get an entirely different set of answers than from some guy who learned C++ so that he could make games. This is simply not how the language progresses today. C++ is the sum of many interest groups operating in tandem and lobbying for *standards*. **The** standard is something that delineates C++ from all other standards which are more monopoly or anarchy driven. C++ needs to solve the broadest needs of pretty much any language you can think of.
`noexcept` is used to evaluate expressions - it returns `true` if the expression does not throw an exception, and `false` if it does or may do. so yeah, you can pretty much put it anywhere you want. #include &lt;iostream&gt; void foo() { throw std::exception(); } //throws exception void bar() {} //may throw exception void poo() noexcept {} //guaranteed to not throw an exception int main() { std::cout &lt;&lt; std::boolalpha &lt;&lt; noexcept(foo()) &lt;&lt; std::endl; std::cout &lt;&lt; std::boolalpha &lt;&lt; noexcept(bar()) &lt;&lt; std::endl; std::cout &lt;&lt; std::boolalpha &lt;&lt; noexcept(poo()) &lt;&lt; std::endl; std::cout &lt;&lt; std::boolalpha &lt;&lt; noexcept(2 + 2) &lt;&lt; std::endl; } output: false false true true
Thanks for the detailed answer! I'll have to try it out in a mini project to be able to compare both approaches in detail. For me the biggest difference in measurement quality comes from callbacks vs CPU counters. E.g. callbacks are expensive and alter the result but give you information that is more related to the code you actually wrote. OTOH sampling profilers using CPU counters like Intel's VTune or Apple's Instrument give you more realistic results for your program but they are sometimes hard to interpret since at high optimization levels without debug information it can be hard to know where things come from. What I generally do with the call backs is just time the functions with &lt;chrono&gt; and then update the results in a global thread safe hash map (see &lt;folly&gt;). At the end of the program these gets written to a log file that is easy to postprocess. Then I use a sampling profiler (disabling the callbacks) and compare the results provided by both.
Well, at this point in the article it is referring to the state of affairs before UTF-8 existed, so it is actually accurate. UTF-8 and GB18030 came later and had to be squeezed into what was originally meant to be the non-Unicode model in the C standard library.
I can't offer much good advice here but I'm very much in the same boat. Fairly new to C++ ... bit awkward to jump into with standards and literature all over the place.
Vectors are good templates but I see people who will use templates in a class as a way to allow future use of the class with different data types; yet the class will never be used with future data types. Then there is the fact that templates are rarely used in wonderful simplistic ways such as vectors. Often templates are used to create huge piles of code that look like lisp instead of nice clean self documenting code. 
You're going to want to use dispatch queues on OSX or make sure to use thread-local for the recording hotpath &amp; then read those thread-local structures when you need to combine your data. Dispatch queues are orders of magnitude more efficient than mutexes even with no contention.
&gt; I think C++11 (and C++14) will get adopted, it's just a matter of time. Things just move fairly slow in the C++ world. The slow adoption rate isn't a C++ world thing. It's just a natural consequence of requiring that a business is founded on a stable infrastructure. Before jumping to the latest and greatest, things need to trickle down from the standardization committee to the implementations. After the implementations are available, tools need to be updated and refined. Only then can a shop migrate their business to the then latest and greatest. [Thiis thread](http://www.reddit.com/r/cpp/comments/23om1r/gcc_490_released/) illustrates this issue. Things don't happen overnight. Only (relatively) recently has he C++11 standard been set in stone.
tl;dr: Windows is PITA. wchars (and other w*) are worse than useless. 
bro, do you even TCHAR
I'll have a look at that, thanks for the tip!
when?
Ermm I am not sure if it's what you were asking but, I was recently looking for C++ jobs, and in interviews the libraries I was asked about were the stdlib, boost then Qt (and POSIX or the WIN API if company was platform dependant). So yes, definitely worth getting a little Qt experience. That said, I have little Qt experience and got offers from most places when I demonstrated a willingness to learn and was able to show that I've picked up APIs in the past. Just don't do the programmery thing to do and be like "yeah Qt is junk" or whatever have you.
A company I worked for used Qt exclusively for many linux and windows commercial products. BTW, in their forums in the past they've been quick to correct people that it's Qt, since it's not an acronym and QT is for QuickTime.
You would have gotten bonus points for *discussing* a possible extension in C++17 that lets you drop the "auto" in for(auto x : etc). IIRC, "auto&amp;&amp;" is supposed to be used as default in that case.
For clarification: QT != Qt QT = QuickTime I use Qt at my job. I picked it up after having zero training. Now I've ported our #1 product from Cocoa to it. It's not hard to learn, just you need to know C++ well before you start. Helps to have written GUIs in other frameworks and understand the underlying layer of what Qt is wrapping.
So that was the bonus point for discussing the auto&amp; as well? 
Ah, I do indeed remember reading about that. Slipped my mind. [Relevant /r/cpp thread](http://www.reddit.com/r/cpp/comments/1vxgeo/rangebased_forloops_the_next_generation/).
I am unfamiliar with this! I will go look it up. Thank you. *Edit: Looks like as long as my SmartObject class never takes any parameters in its constructor, this will indeed save me some boilerplate. However, if I ever have to modify it to take parameters, I'll have to go back to the templated constructor method I originally used.*
Looks like basic, albeit horrible, use of enable_if to me.
Qt is used throughout the industry. I use it often, write most of my software with it, as it offers good UI Support. You also can easily use it together with boost. One drawback is that Qt is a bit old in its roots, though that its not really using modern C++. Qt on Android is not for mobile phones mainly, its more for the embedded areas where more and more machines get enhanced with touchscreens etc.
&gt; its not really using modern C++ I think that has been what has limited my interest in the past. I think it pre-dates the first C++ standard and so you have QStrings and Q-This and Q-That rather than STL classes. I have never been a GUI person so just on the strength of a stand-alone library I found POCO more modern and less Quirky. I'm not sure what you mean by the distinction between embedded areas and mobile phones. Can you expand on that?
Arguable. Consider this alternate sentence: utf32 seems like the perfect general solution despite occupying more space for the Latin character set. Time and again, it's been demonstrated that programmer efficiency trumps space. I'd argue utf32 makes Unicode-programming so much simpler it's worth the extra space.
Hmm, I'm currently writing GUIs in Cocoa (rest is C++) and would be interested in switching completely to C++ with Qt for the GUI. How hard is it to make a Qt app play nicely with OS X? (So it's not directly obvious that the application isn't using Cocoa but Qt).
It's about the most complex solution to one of the simplest problems I've ever seen. DRY taken to its absurd extreme and in fact it gets it worse by not actually applying DRY completely. Further, what's going to stop anyone from doing this: Point&lt;int, 2&gt;().setZ&lt;4&gt;(666); That's probably going to do some pretty weird stuff. Might get lucky if you're doing something silly like keep all 4 dimensions even for a two dimensional point. It's fragile, verbose as all getout, and only makes a mountain out of a pebble.
Thank you. The GUI portion is both the challenge and allure of Qt for me since I have no experience in that area. I am looking for a relatively painless way to cover multiple platforms, including mobile, with one framework. Do you have any insight into Qt's adoption in the mobile space?
The `N == P` is to keep people from using it wrong and doing nonsensical things. /u/Crazy__Eddie mentioned this code in his post as a possible misusage (not realizing I had thought of that already...): Point&lt;int, 2&gt;().setZ&lt;4&gt;(666); 
I know the road won't be fast, but definitely looking into this for the long haul. Have just been so lost on where to go. I know some very basic C++ as i took a class on it in Highschool. 
I prefer [bandit](http://banditcpp.org/) as a modern C++11 solution.
This is pared down example code. It's a Point/Vector class with lots of convenience functions that I removed to illustrate the actual point.
Very nice. Thanks!
If we'd been using utf-32 since the 70s and everything expected it, then using utf-32 would indeed be easier than using utf-8 is in the real world. However, here in the real world using utf-32 is more work than utf-8 for simple things due to the need to convert back and forth constantly, and helps much less than most people expect for complex things.
Come on, this is funny. Why the downvotes? (The same people who don't get the _tchar joke are probably going to downvote me as well... /braces for impact)
The side of this subreddit links to books. Read that whole stackoverflow link; they explain very well why a book is necessary. If it still isn't clear, you'll notice that most of the books that are highly recommended by the community sit at over 1000 pages. That is just way too much to cover in any online tutorial. It just can't happen. C++ has too much complexity and history, and way too many changes over the years. Honestly, if you ever start to enjoy C++ and its complexities, you'll end up like me, wanting to read through 2 or 3 more books on the language. So just dive in to a good book now. If you want a very specific recommendation, I had a quick flick through C++ Primer (5th Edition), and it looked good. Go for it. Just keep in mind though, depending on how much time you dedicate, it'll take you months before you finish this book and are able to use all the ideas in it comfortably. You won't be any closer to making games by this point. Don't expect to be making anything for a while, if you choose to go this way. People are giving sage advice when they say that you could make games quicker by choosing another language. But this path can be rewarding in other ways.
Yes and no. UTF-8 was invented in 1992. There's some details of the email exchange here: https://www.cl.cam.ac.uk/~mgk25/ucs/utf-8-history.txt. Here is a quote from the email (September 1992): | Below are sample implementations of the C standard wctomb() and mbtowc() functions which demonstrate the algorithms for converting from UCS to the transformation format and converting from the transformation format to UCS. The wide char stuff might not have become an ISO standard until 1995, but it was in the language before (the same as a lot of the C++11 standard libraries already existed as boost libraries way before the standard was adopted).
Not to detract, but if you really want to excel in C++, you'll need to read far more than 3 books. There are probably at least 8 must read books - the side bar is a good start there. You'll also want to become familiar with the standard itself (daunting at over 1200 pages of dense standardsese, and not saying you need to read it cover to cover, but it is useful to learn the structure and what and where things are defined so you can quickly use it as a reference for the inevitable "why doesn't this work or why doesnt it do what I think it should"). Also, at the risk of being cliche, there is no substitute to actually writing code (and rewriting once you've learned more). 
Unfortunatly UTF-32 doesn't really solve anything, because all the same problems that come with a variable width encoding also occur in UTF-32 due to combining and various control characters. Even if you use a composed normalization there are still characters that use multiple codepoints. So UTF-32 doesn't _really_ make handling text any simpler, it just means that programers will take longer to notice that they've done it incorrectly. If it really did fix things I'd be all for it despite the extra memory usage. As it is I think UTF-8 is the best option since it eliminates that false sense of security and also has compatibility benefits.
I think it's more important to learn the underlying language (c++) and how to program GUIs well. Once you learn how to use one GUI library, other GUI libraries will come more naturally and quickly. The most important thing I've learned in the last couple years is to have the user interface be a thin wrapper over standard c++ (and boost if available) code. Make your ' just under the wrapper ' UI classes testable (and if need be mockable). Oh what I would give to have more of this on the project I'm currently working on. Manual tests are slow and don't get run often enough to detect regressions quickly. 
I guess this is a phase that programmers go through.
embedded and mobile phones: there is the consumer grade electronics like phones and tablets running android. But then there is also the industry needing devices and panels to integrate in certain machines and processes. Qt is very good at being integrated in an embedded environment and also supports a modern UI. Android brings a lot more hardware support, so there is the option to use Android as a linux base, and Qt as the software stack.
Build GCC 4.8 with 4.4. Compile on lab computers with custom toolchain.
If your code doesn't need to compile with Sun Studio, just use `#pragma once`.
This looks like clang to me, not g++.
Yeah, i just made a quick test here, it's definitely clang.
Is that true of preprocessor macros as well?
Thanks a lot! 
This. Additionally, it leads to faster compiling. Wikipedia.
wc/mb functions were standardized in C89. Anyway, my point is that UCS4/UTF-8 is just another locale, nothing alien to C.
Yes. It’s true for all identifiers in code; see [global.names], which applies to all *identifier* tokens, and [lex.pptoken] defines that a preprocessor name is an *identifier*.
Can I do this without sudo privileges? Is there a way to "install for user" on Linux? 
My employer uses Qt fairly significantly. As mentioned by /u/meetingcpp the company makes embedded touchscreen devices running linux under the hood. We also use Qt to make some desktop support applications for the device.
You can do this without sudo. You will also want to get the latest libstdc++. To install, add the appropriate directories to the environment variables that GCC uses for search paths: PATH for the binary, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, OBJC_INCLUDE_PATH for headrs, LIBRARY_PATH and LD_LIBRARY_PATH for the linker.
Digia offers QML as the way to write native look'n feel apps in every platform, which as you say currently outside of 3 desktop environments (windows, linux and mac os x) is not native at all. Those native controls will arrive in Qt 5.3 or so :)
I'll try it! Thanks! 
I really love Channel9. They have A LOT of good videos. And you can download them without any hazzle.
The value added comes from the fact that content and talks are properly organized and tagged . this site doesnt show only cpp talks.
Adoption rate is actually kind of good (at least in the academic level), I'm studying 1st year Computer Engineering in Sweden and our first course in programming is modern C++ (C++11 &amp; C++14). Our university recommends C++ Primer by Lippman (its really great!). "Why is the adoption rate so slow for something that's 3(?) years old?": I think its because compilers have just started to support the entire C++11 standard (not partially), some are still even working on it (looking at you VC++...). Hopefully companies will be willing to make the switch (or at least prefer it) in the coming years.
No, it really isn't very funny, and the implication that using tchar is a good thing is completely wrong.
Why would I use a hidden instance of gdb rather than using a debugger directly?
If it's something you repeat often enough it's useful to automate it. There's probably a way to do it purely with gdb commands (repeating backtrace + continue, combined with file logging), but it's still going to save you keystrokes in the long run.
Looks like you are returning a local variable there. It's not clear what the 'Mat' object is, but if it's an aggregate type... you're going to have a bad time.
That's fine. Returning pointers or references to local variables is what's bad.
Well, no, it's not fine. It's not disastrous (it will work), but it's unnecessarily very inefficient (the object will be copied several times), and is considered bad practice. Particularly so as the correct way is so easy (have an 'out' reference, or return a smart pointer). Unexpected copies can have unpleasant side effects also. For instance, each time the object is returned, the destructor will be called on the original object. If that deletes memory for the object he could have problems. It all depends on the implementation of the 'Mat' object, obviously. TL;DR: Don't return non-primitive local variables. EDIT: Turns out I'm wrong! You learn something new everyday. Thanks for the replies everyone. [Hides face in shame]
It's actually fine. The compiler will optimize this out. It's called [Return Value Optimization](http://en.wikipedia.org/wiki/Return_value_optimization). Also, if the destructor frees memory used by a copy, the copy-constructor or destructor is badly designed. **TL;DR:** it's usually fine to return locals, especially when the object returned is always declared in the same place. The object won't be copied because it's allocated on the stack in the calling function.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Return value optimization**](https://en.wikipedia.org/wiki/Return%20value%20optimization): [](#sfw) --- &gt; &gt;__Return value optimization__, or simply __RVO__, is a [compiler optimization](https://en.wikipedia.org/wiki/Compiler_optimization) technique that involves eliminating the [temporary object](https://en.wikipedia.org/wiki/Temporary_variable) created to hold a [function](https://en.wikipedia.org/wiki/Subroutine)'s return value. In [C++](https://en.wikipedia.org/wiki/C%2B%2B), it is particularly notable for being allowed to change the observable behaviour of the resulting [program](https://en.wikipedia.org/wiki/Computer_program). &gt; --- ^Interesting: [^Copy ^constructor](https://en.wikipedia.org/wiki/Copy_constructor) ^| [^Copy ^elision](https://en.wikipedia.org/wiki/Copy_elision) ^| [^Expression ^templates](https://en.wikipedia.org/wiki/Expression_templates) ^| [^C++11](https://en.wikipedia.org/wiki/C%2B%2B11) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ch389fi) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ch389fi)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Not necessarily inefficient, see: * http://en.cppreference.com/w/cpp/language/copy_elision * http://en.wikipedia.org/wiki/Copy_elision * http://en.wikipedia.org/wiki/Return_value_optimization OTOH, references (or pointers) can be potentially costly, too -- they may cause inefficiencies due to aliasing (in general, indirections are not uncommonly harder to see through from an optimizer's point of view). See: http://stackoverflow.com/questions/9709261/what-is-aliasing-and-how-does-it-affect-performance TL;DR: don't guess, profile. 
&gt; Particularly so as the correct way is so easy (have an 'out' reference, or return a smart pointer). People have already pointed out RVO, but even more relevant these days are move semantics. With C++11, return-by-value is the *correct way*.
No, it is fine. This will trigger moves, not copies.
For those looking for something more complex and reusable there's a pie chart implementation in the Qt samples. It's implemented as a View so it can be integrated with MVC for any ui. 
Yes, its a nice example if you use the Qt Model/Views: http://qt-project.org/doc/qt-5/qtwidgets-itemviews-chart-example.html In my use case I don't have that, and using just a vector&lt;int&gt; for the display plus vector&lt;QString&gt; for the labels makes it very reusable for me too. In fact I already use it in 2 different places with 2 different modes.
~30LOC seems excessive: #!/usr/bin/env gdb -x catch throw commands bt end run 
Interesting. I've chosen to have this separated, as in sometimes I might not have a label or want the data to be the label. I've seen that you've got a memleak, you must also delete the QFile pointer returned by openFile in your code. Actually there is no good reason to allocate this on the heap... This is how I do it: QFile file(path); if(!file.open(QFile::WriteOnly)) return; QTextStream out(&amp;file); 
LOC = lines of code
Thanks for pointing out the memory leak. I haven't taken the time to get valgrind on my mac (OSX 10.9) which apparently has issues. It's really a "by preference" type of things, just thought you might the pair idea interesting.
Yeah, but i mean it's not as if it is important how many LOC a program has. EDIT: For the record, i didn't downvoted OP's comment
It's very rare that operating on code points is correct. For example trimming whitespace technically should not be done in terms of code points (consider what happens if that whitespace has combining characters on it, you can mangle non-whitespace characters or even produce an invalid sequence). Of course if you're defining a formal grammar for a file format you can just rule out the problematic cases and say those things cause undefined behavior. As a couple of examples of where operating on code-points is the correct thing: copying a code point sequence or producing a debug display where each codepoint is shown like `&lt;U+NNNN&gt;`. Usually operations that work on a codepoint basis can also work on a code unit basis, or by using a simple in-place adapter that works over code units to provide a code point view.
yes, I'm thinking how to only bind this to a data provider object, which has a int operator()(size_t index) interface. An Adapter for Qt models would then be easy.
Any particular reason?
Do 'you' ?
'yes' 
C++ Primer is good, I have it and it's been frequently recommended here. It's up to date with (good) modern coding practices and accurate. FYI don't get C++ Primer Plus, it's unrelated and considered inferior. 
I recently put up a list of recommended books on Meeting C++: http://meetingcpp.com/index.php/books.html API Design for C++ is a book I would recommend for getting a general overview, for C++11 I think its either Bjarne or C++Primer. Also Scott Meyers works on a new book, most likely to be released this summer.
The C++ Programming Language by Stroustrup
Standards-wise this is indeed undefined, although mscrt + glibc specify that printf type formats are coerced, so it's well-defined with those libraries. 
I prefer `begin(thing)` and `end(thing)`, they're more general. 
You might like to read through the JSF code standards document. 
You can use `%d` to print anything that's smaller than int, but which promotes to int under the default argument promotions. It's undefined to use `%u` with something that promoted to `signed int`; however, positive values of a signed int are required to have identical representations as the equivalent unsigned value, so unless the compiler "does magic" (which it is entitled to, but there's no reason to believe any compiler would do magic here), the library implementation of `printf` will receive identical input to as if the person had cast to `unsigned int` first, so the code ought to work on a sane implementation. 
&gt; I would like to point out that VC's default_random_engine is mt19937, which emits the full range of [0, 232 ). I consider non-power-of-two URNGs to be abominations. IIRC I already commented on this on C9, but my point is that maybe one day there will be really fast/cheap/good/unicorn hw urng-s that produce weird ranges, so standard did not want to limit those... 
I think a better practice is simply to know your errors and mitigate for it. This usually involves checking against some tolerance. (Or use some numerical method to keep errors down.) int a = 1; float b = 1.0f; const float eps = /*some error tolerance*/; if (std::abs(b - float(a)) &lt; eps) {...} 
We should chat. I've been thinking about this a lot lately as well (although for a different compiler). The consensus over here was that as written your transformation isn't legal because your assumption is incorrect: opaque could in-place new a different derived object into b, legally changing the vtable.
The entire concept of sorting a list which contains numbers of different precisions is sort of nonsense.
This is not guaranteed by the standard &gt;§7.21.6.1 9 [...] If any argument is not the correct type for the corresponding conversion speciﬁcation, the behavior is undeﬁned. although both glibc and the MS crt guarantee that types are coerced to the format flag.
&gt;You can use %d to print anything that's smaller than int This isn't [guaranteed](http://www.reddit.com/r/cpp/comments/244wfv/the_perfect_int_float_comparison/ch3t2zu).
All integer types smaller than int passed to any C vararg function are promoted to int (and floats are promoted to double). This is done by the caller, not `printf`.
C++11 5.2.2.7: &gt; When there is no parameter for a given argument, the argument is passed in such a way that the receiving function can obtain the value of the argument by invoking va_arg (18.10). [...] If the argument has integral or enumeration type that is subject to the integral promotions (4.5), or a floating point type that is subject to the floating point promotion (4.6), the value of the argument is converted to the promoted type before the call. These promotions are referred to as the default argument promotions. Same rules have applied since the primordial days of C before function prototypes when promotion occurred for all arguments. [e] [The relevant paragraph in the current draft](https://github.com/cplusplus/draft/blob/master/source/expressions.tex#L1392).
Agreed, %i or %d would be a better choice here :)
I agree. I wanted to access it using unsigned char (which is defined and allowed), but I see that I did change the pointer type instead of actually accessing it using the unsigned char type. Yep, memcpy would be better here. One more thing: &gt; the compiler is smart enough to see what you're trying to do. Actually it's the other way around - the compiler is stupid enough to not do anything about it and let the underlying platform handle it, which does (one might argue that "by accident") what I expected to happen.
&gt; It's guaranteed not to be undefined behavior [According to this standardization-paper it is not](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3751.pdf).
Yep, until the Accelerated C++ book is updated this is definitely the book to go for.
Scott Meyers effective series is great : you're missing out on a lot of nitty gritty details of C++ if you don't read them. With that said, when the books that adhere to the new standard come out, you should get those as well. In the meantime, watch talks like going native and build, and also get Herb Sutter's Exceptional C++. Learn about things like reference collapsing, struct padding, vectorization of loops, move semantics, universal references, and perfect forwarding.
I would like a more in-depth review of the capabilities of the OpenCL libraries for interfacing with C++ functions and function objects. This is not possible for OpenCL libraries but most of them allow some level of code reuse via macros that e.g. stringify functions. I would like to see examples of these macros along with a discussion about what they do/don't allow. In the previous and present article these macros are mentioned, and it is mentioned that they allow the user to pass custom functions (but AFAIK you cannot pass e.g. lambdas, function objects, function pointers, template functions...). I think that without a more detailed analysis the discussion will be a bit dead when it comes to comparing these libraries with the approaches based on language extensions (CUDA/Thrust, C++AMP, OpenACC, OpenMP4.0, Sycl, Parallel STL) whose main advantage is that they allow kernels to be written in C++, that is, using generic functions, function objects, lambdas... instead of just stringified kernels.
Original author of the articles here. You raise a good point gnzlbg. The reviews are not very in depth. I agree that what you mention is an important point, especially to C++ folks. If I find time I will put more emphasis on this point and maybe I will even write a separate article discussing the limitations of OpenCL with regards to C++ and template code. In the meantime, if you have a look at Kyle's article here [0] you can see that for function objects, the exact type must be specified. But for lambdas this is not necessary. What is more, Denis explains in a stackoverflow post how he implements the OpenCL version of templated algorithms here [1]. In addition, there is an AMD OpenCL extension called OpenCL Static C++ Kernel Language Extension [2] that solves some of the problems you mention. Unfortunately it is AMD only for now. [0] http://kylelutz.blogspot.de/2014/03/custom-opencl-functions-in-c-with.html [1] http://stackoverflow.com/a/22475483/244786 [2] http://amd-dev.wpengine.netdna-cdn.com/wordpress/media/2012/10/CPP_kernel_language.pdf
I have used Qt professionally at my last and and current jobs, and have spoken with plenty of coworkers who have used it at prior places, too. It's an incredibly useful library to know, if you're going to pick one for its utility and widespread use.
IEEE floating points are ranges, while integers are points. Is the range [0, 3) bigger or smaller than the number 1? Adding additional context about what the numbers represent can make this answerable, but in the abstract it's a meaningless question. If the goal is to sort a list of numbers by their string representations, then I'd be inclined to just do that, and view the stuff discussed in the article as a fairly extreme potential optimization.
Thanks, guys. The traffic is giving my new server a nice little stress test. :-)
Thanks for the links, I'll take a look at them! I sincerely hope that it doesn't feel like I'm bashing on OpenCL. The approach taken by OpenCL has its advantages/disadvantages: no special compiler required and easy to cross-compile vs lack of static typing/static checks and lacks of reuse of kernels for non-OpenCL backends. Since it is a tradeoff intrinsic to OpenCL, trying to solve this drawbacks with a library only approach is very hard. Some libraries doesn't try to solve it at all, others provide macros that partially address the issue, and finally some libraries like PPL or Parallel STL TS rely on compiler support to solve the problem (C++AMP, execution policies). For example from Kyle's article it looks like Boost.Compute does a pretty good job with its macros to solve the issue. But for me it is not clear from reading his article how would he define a member function to also be a kernel (and how would the _this_ pointer be passed). These issues are important since, for example if you have a class that right now does some computation inside a kernel-like member function, the amount of work required to rewrite the kernel into a string, and add logic at each call site in order to target an OpenCL back-end is much larger than if you can just call the member function from within a lambda in a `std::for_each` (Parallel STL TS). 
Jacking up the inlining threshold significantly reduces the speed penalty with clang (and results in a smaller binaries): $ clang++ -I/src/range-v3/include -std=c++11 -Wno-unused-function -O3 comprehensions.cpp -o comprehensions &amp;&amp; ./comprehensions &amp;&amp; wc -c comprehensions [9s] 20667ms 10650478 3233ms 10650478 67136 comprehensions $ clang++ -I/src/range-v3/include -std=c++11 -Wno-unused-function -O3 -mllvm -inline-threshold=50000 comprehensions.cpp -o comprehensions &amp;&amp; ./comprehensions &amp;&amp; wc -c comprehensions 5926ms 10650478 3284ms 10650478 42192 comprehensions May or may not be a viable option for real programs. Clang's inlining heuristics seem to be pretty flawed (or at least the default values are wrong), since I consistently see smaller binaries with -O3 than -Os.
This is awesome. I really like the `yield_if` function. Seeing that just made it click why monads are great.(it never really clicked reading Bartosz Milewski's article for some reason). I wonder if its possible to add a `yield_do` function to do even more imperative type generation. So say you want to iterate over a binary tree, perhaps it could be done like this: auto yield_node(node* n) { return yield_do( yield_if(n-&gt;left, yield_node(n-&gt;left)), yield_if(n-&gt;right, yield_node(n-&gt;right)) ); } Now, `yield_do` could be implemented something like this: template&lt;class Range&gt; auto yield_do(Range&amp;&amp; r1, Range&amp;&amp; r2) { return view::for_each(make_range(r1, r2), [](auto&amp;&amp; x) { return yield(x); }); } But this requires that the ranges be the same type, perhaps there is a better way, I'll have to think about it more. 
That is just not true. Quoting the IEEE 754-2008 (the very first sentence in the overview section - 3.1.1): &gt; This clause defines floating-point formats, which are used to represent a finite subset of real numbers A **finite subset** of real **numbers**, not ranges, especially not continues ranges as you imply. Please note that the fact that there is a rounding error on conversion does not mean that the final floating value represents a range - according to the IEEE 754-2008 it means that the original value has been modified and that the "inexact result" should be reported (see section 5.4.1 Arithmetic operations - "formatOf-convertFromInt(int)" description for details). Therefore, again, it is perfectly logical to compare two values that are supposed to represent a number, even if they are of different type - since from a certain point of view, they are just numbers anyway.
Interesting suggestion. When Bartosz first saw my suggestion, he said something along the same lines; namely, that folks would want "imperative" constructs to use in addition to `yield_if`. Definitely worth looking in to.
Huh. Because the function call section says that the default promotions (char/short-&gt;int, float-&gt;double) are performed on all trailing arguments, or if the prototype doesn't specify arguments. It makes sense to declare things like passing in a `long` and using `%d` as undefined, but it seems strange to exclude things that have undergone the default promotions.
Some general feedback: You have a **a lot** of grammatical mistakes and associated spelling errors. It is worth proof-reading things like this as it makes people take you more seriously and sets the tone for your work. The a* channel in LAB is not generally referred to as the "alpha" channel, that makes most people think of some kind of transparency channel. If you want some ideas of where to take your algorithm, take a look at the ["gist of a scene"](http://cvcl.mit.edu/papers/OlivaPBR2006.pdf), which is concerned with computing a high level summary of a scene very rapidly.
Does the "always inline" attribute help in this regard? I would hope that specifying this attribute in the appropriate places produces results that are on par with those of GCC. Modern idioms in C++ are relying more and more on the compiler to be able to inline extraordinarily well. This comparison serves as a warning for programmers to test before making assumptions about how/what the compiler is inlining. It would also be interesting to see what the call stack for the range-based approach boils down to, and in what ways it is deficient compared to the imperative approach.
&gt; Modern idioms in C++ are relying more and more on the compiler to be able to inline extraordinarily well. This isn't really a recent thing. Stepanov's abstraction penalty benchmark was published in '97 and required what was then considered extraordinarily good inlining.
&gt; -mllvm -inline-threshold=50000 Nice, I'm able to reproduce this.
&gt; Does the "always inline" attribute help in this regard? Clang doesn't appear to support it for lambdas, and slathering it on everything else that appears relevant didn't have any effect. Would need to look at the bytecode to see what exactly isn't being inlined.
Important to note that this is (sadly) only open to European students. Otherwise I'd be applying right now. 
&gt; I hazard to guess that the code to advance the induction variables and evaluate the expression templates will be easier for the compiler to inline than the nested lambdas. I'm not sure why you believe that. Expression templates are evaluated recursively and also require good inlining. But it doesn't matter to me. GCC generates good code. Clang will too eventually. And as much as I like expression templates (I wrote Boost.Proto after all), a solution with acceptable syntax that doesn't use ETs is better than ETs any day, so long as the code generation is good enough.
At least there is no heap-fest as with Bartosz's `std::function` approach. I wonder what the timings for his implementation would be compared to yours?
Well, there is no travel funding. So if you can get the travel funding, you should apply. And the focus is on the European C++ scene at Meeting C++, international guests are very welcome though.
Does the funding include stay in the hotel? Or is there a hostel or something like that close by? Because the prices really look extremely high for my eyes (as if they were not intended for private persons but for business-people who get everything from their company). Also: Do you have some tips for the application? I guess github is de facto required but what other things should be mentioned? Reddit-accounts with &gt;90% C++-posts?
Too bad infix and user defined operators aren't permitted. Would be nice if you could say: auto triples = intsFrom(1) &gt;&gt;= [](int z) { ints(1, z), &gt;&gt;= [=](int x) { ints(x, z), &gt;&gt;= [=](int y) { return yield_if(x*x + y*y == z*z, std::make_tuple(x, y, z)); });});}); Then the syntax mirrors the clean Haskell code ... almost. If you're squinting. Remember that the Haskell `[ (x, y, z) | x &lt;- 1..n ... ]` syntax is really short for `1..n &gt;&gt;= \x -&gt; ... (x, y, z)`, the difference being that Haskell lambdas are nowhere near as ~~ugly~~*creative* as C++ lambdas. 
&gt; in C# you can [...] `yield return i;` [...] With range comprehensions, equivalent code looks like [...] `return yield_if` [...] Where's the equivalent of: IEnumerable&lt;T&gt; HelloWorld(IEnumerable&lt;T&gt; seq) { foreach (var value in seq) { yield return value; yield return valuel } } I was having some trouble in this article figuring out how yield_if handled normal yield-return cases.
Sure, you can have that if you want it. Just hacked it: // Define an infinite range containing all the Pythagorean triples: auto triples = intsFrom(1) &gt;&gt;= [=](int z) { return ints(1, z) &gt;&gt;= [=](int x) { return ints(x, z) &gt;&gt;= [=](int y) { return yield_if(x*x + y*y == z*z, std::make_tuple(x, y, z)); };};}; All it took is the addition of this function: template&lt;typename Rng, typename Fun, CONCEPT_REQUIRES_(Iterable&lt;Rng&gt;() &amp;&amp; Function&lt;Fun, range_value_t&lt;Rng&gt;&gt;())&gt; auto operator &gt;&gt;= (Rng rng, Fun fun) -&gt; decltype(view::for_each(std::move(rng), std::move(fun))) { return view::for_each(std::move(rng), std::move(fun)); } 
Sweet. Looks much better :-) (concepts ftw!)
That, and sequencing isn't the only control operator. There's if-then-else, loops, and (for the brave) passing `yield` as a first class value to recursive functions (in C#, using Rx): IEnumerable&lt;T&gt; Fringe(ITree&lt;T&gt; tree) { return EnumerableEx.Create(yielder =&gt; { await Fringe(tree, yielder); }); } async Task Fringe(ITree&lt;T&gt; tree, IYielder&lt;T&gt; yielder) { if (tree.IsLeaf) { await yielder.Yield(tree.Value); } else { await Fringe(tree.Left, yielder); await Fringe(tree.Right, yielder); } } I'd be curious how you were thinking of handling this case for C++? It's a particularly challenging one to do efficiently (O(N)) without revering to coroutines. References: - Rx library function for EnumerableEx.Create [\[source code\]](https://rx.codeplex.com/SourceControl/latest#Ix.NET/Source/System.Interactive/EnumerableEx.Creation.cs) - SameFringe example in Scheme [\[pdf, page 8\]](http://repository.readscheme.org/ftp/papers/ai-lab-pubs/AIM-349.pdf)
And so it begins ... attack of incomprehensible complex lambdas. Bjarne: Every powerful new feature will be overused until programmers settle on a set of effective techniques and find which uses impede maintenance and performance. I don’t think I ever described lambda expressions as “best avoided,” but – as with all new features – I do encourage a bit of caution. I have already seen multi-page lambdas, but I prefer all non-trivial operations to be named. **If you need a lambda of more than an expression or two, name it.** A good name indicates intent, and separating definition and use gives the opportunity for a well-chosen comment. Complicated expressions (with or without lambdas) can be a source of errors and a maintenance hazard. 
Point to the lambda in that article that contains anything other than a single return statement.
While it's interesting to ponder what this might look like, I don't plan to get too hung up on it. It doesn't have to be Turing complete to be useful. I don't think Haskell or Python list comprehensions handle those cases, either. I'm sure someone will correct me if I'm wrong.
&gt; I don't think Haskell or Python list comprehensions handle those cases True, though imperative programming in Haskell is a pain, and Python generators [*do* handle those cases](https://docs.python.org/3/whatsnew/3.3.html#pep-380). Nonetheless, its really nice to see this happening in C++. I look forward to trying it out at some point.
&gt; Is not there a lambda defined inside another lambda? There is. But is there a lambda in the article that contains anything other than a singe return statement? There isn't. &gt; compare "range comprehension" code and tripple loop one at the end. Dunno about that triple loop. I mean, is there not a for loop in a for loop? Mercy! ;-)
and this is in /r/cpp because?
&gt; But is there a lambda in the article that contains anything other than a singe return statement? There isn't. Lambda that starts on line 13 and ends on line 23 contains 3 return keywords.
&lt;shrug&gt; You don't like it. That's fine, I get it. C++ programmers in general aren't used to a style where larger functions are built by composing smaller ones. But that style is used to amazing affect in other languages by programmers who are mortal. I reject the argument that this is too complicated for your average brogrammer. It's not. It's just unfamiliar.
&gt; (concepts ftw!) No kidding! I couldn't write this lib without concepts. My range lib was about a day old when I realized I had to shelve it and write a concepts lib first.
As I said there is not travel funding sadly. Like for every other attendee you also as a student will need to find your way to Berlin and a place to stay. Berlin is full of Hotels and Hostels and other traveling opportunities. Ticket price, well the conference and Meeting C++ is funded over the ticket sales. There is very little sponsoring, so every attendee has to pay its share. And yes, that's often companies sending their employees. Tips for the application: think-cell should be able to see from it what you do with C++, how your connection is to it etc. If you have a github, stackoverflow or reddit account you should mention it.
&gt; Footnotes are non-normative BTW. Well exactly, the point is that ... arguments do not necessarily need to be handled by va_args, would an implementation be free to handle the variation args in a different way? Sorry I didn't express myself clearly about va_args, my misunderstanding. And yes I missed the last line, thanks for pointing it out, although I'm still confused as to why the fprintf section specifically says it is undefined to pass different types.
As oldwolf2 pointed out the aegs are promoted, my bad. I still don't understand why the standard makes it clear that calling the printf functions with unmatched types is undefined.
Yes, indeed. I realized this after an answer on Clang showing off aliasing issues, and in the process of demonstrating how the demonstration could be made safe in the presence of aliasing I hit that v-table switch issue. It's quite crippled, the transformation is safe on method calls: struct A { virtual void foo(); virtual void bar(); } void func(A&amp; a) { a.foo(); a.bar(); } In this case, we can legally transform this into: void func(A&amp; a) { void const* const vptr = a.vptr; a.foo(); assert(a.vptr == vptr); void const* const vptr = a.vptr; a.bar(); assert(a.vptr == vptr); } Unfortunately, this is very restrictive: - it does not cover free-functions - it does not cover other arguments than `this` in methods Because any of those two could, potentially, replace the object pointed to by something else. Still, on the other hand, it's also applicable to `const` attributes not being changed or `const` methods not changing anything else than `mutable` fields. 
\+ it is pretty iritating to explain average joe with kids wife and a dog that beside he needs about this newfag :P stuff he also need to learn about stuff that is not implemented, aka dear joe you cant just go to cpp wiki reference and see how to to X, you need to see if X is implemented in VS, better still dear joe is that error will say blah blah blah, not uniform initalization not implemented... you dont know what uniform initialization is? ah poor joe :D
I must say that I am a convert to policy-based design! I am open to all criticism and improvements as I know there are various possibilities to not repeat templates everywhere (though I haven't exactly found how). Also I am a bit embarrassed that it crashes Clang so effectively! (bug report here: https://github.com/beniz/libcmaes/issues/19 )
Lisp is much older then C++, Haskell is 24 years old. Functional programming is as old as programming itself. Why is not it widespread? I am a fan of Clojure and Hickey is very convincing but then I ask myself this question. I don't think C++ was designed for this type of functional programming so considering questionable practicality of functional approach why bring this kind of style into C++ program?
Sorry what? You link to a blog page which contains only a link to an Amazon search for "C++"? Seriously? Since when is the Amazon rank a mesaure of quality? The third entry is "C++ Primer Plus" which is a bad quality rip off of "C++ Primer". Talk about blog spamming ...
Yeah, parts of C++ are ugly, and Haskell and Lisp are elegant. But the same syntactic uniformity and terseness that makes them powerful and elegant can also make them inscrutable. It's a double-edged sword until you learn to see the red dress in the Matrix.
&gt; [1] http://kylelutz.blogspot.de/2014/04/using-amds-static-c-kernel-language-in.html Thanks for this post! It really shows how to use AMD's template extension. &gt; VexCL has examples that show how a kernel can be constructed from an existing function object [0]. ~ Not really. Those function objects just wrap the DSL that VexCL is using, that is, you cannot use any function object that might represent a valid kernel in C++ code, but only function objects whose kernels have been specified using the _Boost.Phoenix-like_ lambdas that VexCL offers. I find this is still really really neat! And for the _real_ thing VexCL offers some stringify macros [1]. What I mean with function object is the ability to use any _pure C++_ function object without annotations to write a kernel. This is supported by the Parallel STL TS, OpenMP4.0, OpenACC, TBB, Thrust (for some backends), and in the future, Sycl. OTOH, even tho C++AMP and CUDA both require annotations, these are similar enough to be easily added generically using macros. Then, at the far end is OpenCL which basically requires you to stringify everything. A bit before OpenCL you can find the OpenCL libraries that allow some of this C++ style using lots of _black magic_ (expression templates). They are still extremely limited by what OpenCL allows. IMO OpenCL's drawbacks are so important in the C++ world that I cannot imagine a future in which any of the OpenCL based library solutions gets standardized. Whatever (if any) solution gets standardized, it would need to easily target heterogeneous systems of any kind using the best of C++14 without sacrificing performance. There is a Parallel STL TS that looks a lot like nVidia's Thrust, and then there is C++AMP with a single context-sensitive usage of an already existing keyword (restrict), and that is already able to target DirectCompute, OpenCL, and SPIR backends. These things look pretty good already but I hope that whatever gets standardized is even better. [1] http://ddemidov.github.io/vexcl/#custom-kernels
Some points I noticed by simply browsing: - Try to avoid writing empty destructors: there's (generally) no reason to do so. - Don't if-else through an `enum` if you can use a `switch`: that allows the compiler to check your code better. - Avoid starting variable names with underscores, as these names can be reserved (see [here](http://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier)). Common alternatives are `var_` or `d_var` for data members. - Avoid `NULL` (e.g. in [`parameters.h#L69`](https://github.com/beniz/libcmaes/blob/master/src/parameters.h#L69)). Use `0` or `nullptr` instead. - Don't use C header files like `time.h`: use the C++ versions `ctime`, `cmath` etc. - If at all possible, try to write constructors with less parameters. For example [`parameters.h#L86`](https://github.com/beniz/libcmaes/blob/master/src/parameters.h#L86)... Wow. - Don't specify `enum` values unless you really need to. E.g. [`esoptimizer.h#L31`](https://github.com/beniz/libcmaes/blob/master/src/esoptimizer.h#L31) is useless, as that is the default behaviour. - Constructs like [`genopheno.h#L136`](https://github.com/beniz/libcmaes/blob/master/src/genopheno.h#L136) are useless, instead of `else return gen;` just write `return gen;`. Again at `genopheno.h#L150`. - Avoid commenting out source code (e.g. [`esostrategy.cc#L54`](https://github.com/beniz/libcmaes/blob/master/src/esostrategy.cc#L54)). - Double-check your headers: do you need `&lt;iostream&gt;` in [`esostrategy.cc`](https://github.com/beniz/libcmaes/blob/master/src/esostrategy.cc)? - You compile with `-Wall`: good. Maybe `-Wextra` and `-pedantic` will help you catch more issues (didn't test this though). - (Style) I don't like your indenting. See for example [`genopheno.h#L163`](https://github.com/beniz/libcmaes/blob/master/src/genopheno.h#L163): in this function the `if`-code is on a different level of indent from the `else`-code (and the `else` is superfluous anyway). I wouldn't indent on `{` already. Not a proper code review, but I hope it helps.
&gt; INRIA Saclay I guess we'll be hearing about Saclay more and more in the coming years; glad to see it popping up here.
A couple *style* remarks: - Prefer `T const&amp;` over `const T&amp;`: the latter is inspired by English but does not compose well (`const` can only ever sit on the left of the outermost type) and behaves differently with macros and `typedef` (nobody should be using macros but...) - Always use `{}` even for single line statement blocks, it's too easy to add an indented statement afterward and forget that alignment does not block make; `{}` make those mistakes stand out more clearly 
Personally, the only takeaway I have from this is: &gt; Why are truncating conversions silent in C (and C++) ? The fact that `int` can be silently converted to `float` and lose some precision, or vice et versa, is not really different than the fact that `int` can be silently converted to `char` and be truncated. And there is no reason for this behavior. Or actually, it probably stems from the fact that any instance of a small integral type (`char` or `short` and their (un)signed variants) are first promoted to `int` before most arithmetic operations, thus yielding an `int` as a result, and it would have been awkward not to be able to write: `short add(short a, short b) { return a + b; }`; but really C threw the baby with the bath water on that one :x
I was just thinking the other day how I could really use a "blackbox stochastic optimization using the CMA-ES algorithm for Covariance Matrix Evolution Strategy".
Well, if you wouldn't have adblock on you'd see an amazon widget first with my recommondations for books. The search is just there to give people a general overview on C++ related books.
Not sure if I get the Matrix reference: the Red Dress represented the very elegance one should not get distracted by in order not to miss the gun that could get into your face the following scene :-) 
&gt; Prefer T const&amp; over const T&amp;: the latter is inspired by English but does not compose well This really is a personal decision. Personally I clearly prefer `const T&amp;` and my impression is that I am with the majority here, but both choices are fine, if used throughout the project. Concerning the typedefs: `using foo = …;` is better anyways, so no problem there. 
&gt; instead of `else return gen;` just write `return gen;`. IMHO this is a question of personal preference, not something that can be applied so general. In fact there is a very good reason to do so: Consider this code: if(a) { return 1; } else if (b) { //return 2; // oops! } else if (c) { return 3; } else return 4; This code will issue a warning that the control-flow reaches the end of a non-void-function, whereas the return-without-else version would return a wrong value. 
With the specification you give implementations along the lines of int method1() { return 0; } string method2() { return ""; } double method3() { return 0; } // ... should be sufficient.
The reason I changed style is that the following reads better/more consistently right to left. char const * const p; A const pointer to a const character.
I am aware that it is somewhat different with pointers, but since I rarely ever use them outside of the implementation of very high-level stuff, this really isn't a problem. Btw: I believe the following is more readable and cleaner: template&lt;typename T&gt; using ptr = T*; const ptr&lt;const char&gt; p = …; If I had to redesign C++, the syntax for plain pointers would always be something like the above (maybe with a much longer name to dis-encourage usage (like with reinterpret_cast)). 
Ah, I've heard of boost::format but forgot about it. Sounds like it works similarly. Thanks, I'll check it out.
I had indepent and identically distributed tears running down my face!
When you are creating a constructor for a class, think of this as initializing a function. You give the function certain parameters, and from those parameters it can determine its public/private variables. So if I wanted to make a bicycle class, class bicycle{ public: bicycle(int numTires, int price, string brand){ tires=numTires; cost = price; company=brand; } int getTires(){return tires;} private: int tires; int cost; string company; } To create a bicycle and check how many tires it has from main, I would do: bicycle newBike(2,150,"trek"); int howmanytires = newBike.getTires(); 
To match style with Win32/MFC, basically. I've worked on projects where DWORD is defined cross-platform, making it effectively uint32_t. There's definitely reasons to use a specifically-sized type (like uint32_t, int16_t, etc) for portability.
It predates even MFC. Masm had a 16-bit WORD which led to the 32-bit DWORD. This went into the windows SDK to have standard types. There is BOOL, which is just an int, for similar reasons: there was no bool type. Note also that DWORD is defined as long, not int.
I had no idea this was a thing. Thank you!
A tour of c++ by stroustrup
The #1 problem with heavily refactoring a large old code base is organizational. You have to get everyone involved bought-in on a plan. This is harder than you probably think. Does someone with seniority to you agree the code needs fixing? As far as actually doing a code modernization effort I don't think there are any tricks to discuss. Adding unit and integration tests before making any changes would help. Other than that, it's just a matter of cleaning/fixing one problem at a time and testing.
I personally use VIM for everything. Lots of plugins to choose from and it's easy to write your own. Great on Linux, decent on windows. http://www.vim.org/download.php http://vim.wikia.com/wiki/Omni_completion -- C++ code completion A lot of people I work with use Eclipse which is also fully featured. Completely cross platform. https://www.eclipse.org/downloads/ Keep in mind you can't actually have editors do C++ code refactor. Might do some neat cross file tricks with naming and declarations, but no editor can do real C++ refactoring, its not worth it to look for it. 
In C++ we usually prefer bicycle(int numTires, int price, string brand) : tires(numTires) , cost(price) , company(brand) {} since it avoids useless default-initializations and copies (not so much an issue in Java). 
You could add it to your path by typing this into your terminal: &gt;export CPLUS_INCLUDE_PATH="$CPLUS_INCLUDE_PATH;&lt;Your directory here&gt;" And if you want this to be ran every time your terminal starts, put it in your .bashrc file(you typically add this at the bottom of the file), or if you're not using bash, the equivalent for your shell. Of course if you're using an IDE you would configure your IDE to see the correct directory(which is IDE specific, google it).
&gt;&gt; If at all possible, try to write constructors with less parameters. &gt; In the case you linked, it would have been perfectly fine to have a default constructor that initializes the fields to sensible values, then have clients overwrite the fields they need through direct member access (they are all public anyway). Kind of screams for C++11 style brace initialization... But OMG, this code could use some refactoring. Still, hard to look a gift horse in the mouth.
yeah, and all it takes is one semicolon accidentally inserted on that last line and you lose all the value of that.... If at all possible, formulate that kind of scenario with a switch statement, an unordered lookup, template specialization, or (wait for it...) the much maligned ternary operator (this is actually a case where it is applicable).
&gt; try to write constructors with less parameters As long as we're being pedantic... make that _*fewer* parameters_.
not a book, but every video i saw of him was very good. http://boqian.weebly.com/c-programming.html 
Thank you so much! Did commit a couple of fixes already based on some of your points. 
OK, point taken. This parameter object is the one being exposed, so I might take your advice and add a default constructor, and maybe get rid of the long ones. Thanks for this.
Only in case of stochastic emergency yes!
If I remove the explicit template instanciations at the bottom of cmastrategy.cc clang does successfully compile the library (though this is kind of useless I believe). Any ideas ?
The problem with `typedef` is not in defining them but in using them: #define MACRO_TYPE int* using AliasType = int*; const MACRO_TYPE &lt;=&gt; int const* MACRO_TYPE const &lt;=&gt; int* const const AliasType &lt;=&gt; int* const AliasType const &lt;=&gt; int* const This is an unfortunate difference because most people that I know (myself included) will at first glance treat the alias as a textual replacement (like it were a macro) and only a few will realize it's not the case if the `const` is placed on the left. Style is about clarity, and allowing the `const` on the left has disadvantages thus it's objectively better not to allow it. Of course, I realize a lot of people have taken the habit of doing it nonetheless.
Don't! Eliminate the redundant constructors, definitely -- but don't jump to doing this via the default constructor just yet. At least don't do this as the first choice, not in C++11. First, instead of using default constructor, you should always (automatically) delegate the member initialization responsibility to the so-called "in-class member initializers" (using a brace-or-equal initializer for each data member): * http://isocpp.org/wiki/faq/cpp11-language-classes#member-init * http://en.cppreference.com/w/cpp/language/data_members#Member_initialization * http://www.informit.com/guides/content.aspx?g=cplusplus&amp;seqNum=427 * http://www.informit.com/articles/article.aspx?p=1852519 The advantage is that this delegation happens automatically (and it is prioritized) -- you don't have to call these manually in any way (nor ensure that they get called). Overall [this was introduced to](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2756.htm) "increase maintainability, reduce the risk of subtle errors in complex program code, and to make the use of initializers more consistent." In other words: It just works :-) If you really *do* have to rely on constructors, then "delegating constructors" will help a lot: http://isocpp.org/wiki/faq/cpp11-language-classes#delegating-ctor
very very useful, thanks for taking the time to write such comment!
I use it to control overloading.
Well yes, but why is `setZ` templated at all? You wouldn't have this issue at all if you just had std::enable_if_t&lt;N &gt;= 3&gt; setZ(T const&amp; t); instead of template&lt;size_t P=N&gt; std::enable_if_t&lt;P &gt;= 3 &amp;&amp; P == N&gt; setZ(T const&amp; t);
Expand the diff for self-immolation.
You need the inner template otherwise the entire class fails substitution.
Direct link to the list widget: http://ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;MarketPlace=US&amp;ID=V20070822%2FUS%2Fmeetingcpp-20%2F8003%2Fb23ca1ce-f4ed-4abc-a218-b560bf76a25e&amp;Operation=NoScript Personally, I like the list on the official website, https://isocpp.org/get-started, as it also says a few words about each book -- this may be helpful for those trying to decide / narrow down their first choice(s) :-) Of course, there's also an even broader list (also with a mini-blurb for each book -- and a suggested reading order, which I think really adds value) linked from the sidebar: http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list Perhaps it would be more helpful to replace the (admittedly somewhat unfiltered) search with these links, what do you think? :-)
Well, the book page is work in progress. Currently I don't have the time to improve it further, as I'm focused on the conference and my C++Now talk.
It won't let me move anything into that path? How do I make those folders edittable? 
TIL. Thanks.
OTOH... &gt; fmt % "John" % "Kelly" % 10 % "fish"; ... is an absolutely horrid syntax :(
I'm waiting for Boost 1.56.0 so I can update them simultaneously (instead of using 1.55.0 with a too-new compiler).
Check out [ccbase.format](https://github.com/adityaramesh/ccbase), which allows you to do things like this: &gt; throw parse_error(cc::format("Error parsing header: expected $ at line $, column $, but got $ instead.", a, line, col, b)); There's also println, errln, etc. I tried hard to keep the syntax as clean and intuitive as possible. (Suggestions welcome.) I feel that this is the most natural syntax for formatting arguments in C++ right now. 
It's closer to the hardware than that, I believe you also need a press and release otherwise the key is stuck down: keybd_event(0x41, 0x41, 0, 0); // Press A keybd_event(0x41, 0x41, KEYEVENTF_KEYUP, 0); // Release A 
advanced TMP by Di Gennaro is a crappy book, idk why ppl love it so much...
I don't think it's horrid. It's not great, perhaps, but not horrid. It would be very natural to some with a python background.
Is there any benchmark somewhere? Which is faster Facebook/folly json &amp; dynamic or this one? https://github.com/facebook/folly/blob/master/folly/json.h https://github.com/facebook/folly/blob/master/folly/dynamic.h
Don't forget Boost::property_tree
First let me say great talk! Regarding this line, I note the lack of the ubiquitous `auto`. Am I right in assuming that in this case you would have to write `Matrix` rather than `auto` otherwise `m4` will be an unspecified helper object with dangling references to temporary objects? A few years ago we discussed an `operator auto` is this still in the works? 
Tried the benchmark from http://www.reddit.com/r/cpp/comments/2380pg/benchmarked_performance_of_c_json_libraries/. Folly's `parseJson()` failed to parse any of the files (throws std::range_error). Using the same benchmark, with a different test file (https://github.com/mloskot/json_benchmark/blob/master/data/canada.json): impl | Average Time (us), 1000 iterations ---|--- `QJsonDocument`|56913 `folly::parseJson()`|78523 jsoncpp|62920 Results were consistent +/- 100us over a few runs. Edited to add jsoncpp.
Thats not a JSON Library, its a common misconception to think that.
This would be a perfect time to use `static_assert`: const T&amp; x() const { static_assert(N &gt;= 2, "Point must be at least 2D"); return ...; } demo: http://ideone.com/i8pv1K
Thanks for doing this review series! &gt; Depending on the quality of implementation and specialization of the provided parallel primitives, close to peak performance should be possible with Boost.Compute. Developing and maintaining high quality, high performance implementations of parallel algorithms across the wide range of constantly shifting parallel processor architectures is non-trivial, so a claim like this must be justified. In addition to reviewing the design and API of these libraries, a series of reviews on libraries for acceleration really must consider achieved performance.
I have run this in VS 2008 and 2012, they spew the same errors. But running it at http://codepad.org/ , https://ideone.com/ , and http://www.compileonline.com/ works *fine*. installing MinGW to try it now as well. edit: yes this works **fine** using MinGW's cc.exe. edit2: derp i meant **enum** not **enumerator** in the title.
&gt; VS 2008 and 2012, they spew the same errors &gt; works fine using MinGW's cc.exe. I think you have your answer here.
AFAIK boost::property_tree has no full JSON support. So its useless in such a benchmark.
I see. I always thought it was more like stackoverflow
&gt;slides Seriously, were video cameras uninvented? 
Have you tried using a const int? 
I would switch man, I rewrote an app I had spent ages on in Cocoa in a couple of days with Qt. Granted I am an iOS person rather than desktop Cocoa but you will be hard pressed to find a nicer designed toolkit and API for c++. Another plus is that obvs you can use objective-c wherever you want and if you don't your app can be easily ported to different platforms without rewriting anything sometimes. 
I have a C++ library for JSON called [JsonVoorhees](https://bitbucket.org/tgockel/json-voorhees) that might be along the lines of what you're looking for...it is very small (only dependency is compile-time for `boost::lexical_cast`). I'm still working on documentation, polish and probably some other important things, too. Just don't look at the parsing code, it is ugly as sin (especially the UTF-8 encoding bits).
I was impressed by entityx on github. https://github.com/alecthomas/entityx
Fair point, boost property tree is lacking support in Json arrays.
I have the same question but for wxWidgets :)
I have a library called [gears](https://github.com/Rapptz/Gears/tree/doxygen) that showcases my attempt at using C++11. I also have [sol](https://github.com/Rapptz/sol) though that one is ugly due to Visual Studio's poor C++11 support. My friends in Lounge&lt;C++&gt; also have projects that might interest you, such as [annex](https://bitbucket.org/mickk), [ogonek](https://github.com/rmartinho/ogonek) and possibly even [nonius](https://github.com/rmartinho/nonius). 
I wonder how cache friendly this decoupling is. While I was reading through it I kept thinking of [Herb's talk](http://channel9.msdn.com/Events/Build/2014/2-661) and the importance of [data locality](http://gameprogrammingpatterns.com/data-locality.html).
I find auto and lambda as the most useful additions in C++11. These are the only two additions i have used so far. Examples of how i used them can be found in these source file[1][2][3]. [1] https://raw.githubusercontent.com/mhogomchungu/qCheckGMail/master/src/task.cpp [2] https://raw.githubusercontent.com/mhogomchungu/zuluCrypt/master/zuluMount-gui/auto_mount.cpp [3] https://raw.githubusercontent.com/mhogomchungu/zuluCrypt/master/plugins/luks/main.cpp
Thanks for the link.I,too was experiencing the nasty crashes she is talking about and i could not figured out what was going in. I read the link and it looked like i came up with more or less the same thing she got but in a different way.Her "this" is equivalent to my "m_babu",her "worker" is equivalent to my "m_baba" and her "thread" is equivalent to my "m_mtoto". She seem to do things more clearly and will change my code do as she does them.Again, thanks for the link.
It seems to be a game engine of sorts. Though it might be cache unfriendly this kind of design is easy to work with and you're usually bottlenecked by the GPU anyway. Even if your game isn't very graphically intensive as long as you hit 60fps there's not much point in optimising (unless you're deploying on oculus). Data locality is super important and code like this gives you few advantages over java. Still deterministic memory management is great so there's that.
Or to be clear: as usual, VS is buggy.
A couple remarks: 1. Thanks for NOT using an `errno` scheme; global variables are hellish, and even thread-local variable do not play well when integrating in coroutines or green-threads. It's really crucial for libraries to avoid those or it makes them just plain unsuitable for languages that use either coroutines or green-threads. 2. You could guard the destructor body of `ThrowOnError` with `if (!std::uncaught_exception()) { ... }` to avoid double-throws; it only returns `true` during unwinding (and not during a `catch` clause!). 3. While `void*` is indeed a prevalent style in C (for some reason), it is not at all type-safe because `typedef` are perfect aliases. Instead you can use `struct foo; typedef foo* foo_t;` and regain type-safety whilst still hiding the exact implementation details of `foo`.
As it is right now it's not cache friendly in and of itself, but I am working on a similar engine which basically does the same thing and is also cache friendly and uses an object pool, which this lacks. The pattern in itself is very easy to write in a cache friendly manner which is (one of the reasons) why it's so popular for game design. This has nothing to do with C++14 in particular though.
Other than auto and lambdas that you mention, I also find really useful: * ranged for - removes a ton of boilerplate * constexpr - nicer than #define or "regular" const as the processing is done "up front" rather than at module/program load time * std::unique_ptr - used liberally most places that need a pimpl/compilation firewall * std::shared_ptr - in some places we had trouble using it in place of boost::shared_ptr - if memory serves correctly there was some bugs with shared_from_this that made it tricky. * std::move - starting to (ab)use this to avoid unnecessary copies from const refs is very handy indeed
It is not all roses, but https://github.com/ahupowerdns/metronome and https://github.com/beaumontlab/antonie are reasonably small C++2011 projects.
Decoupling into components like this can be incredibly cache friendly, far more so than a typical object-oriented design. This is something the link you used for data locality goes into: if you split your entities into components, then you can iterate over an array of those components to update the individual components, which is much better for caching than having entities which contain everything about the entity in one object. A great free read on this topic is [Data-Oriented Design](http://www.dataorienteddesign.com/dodmain/dodmain.html) by Richard Fabian. It even has a [section on component systems and why they're great for the cache](http://www.dataorienteddesign.com/dodmain/node5.html).
Thanks for your feedback. What my review is saying (maybe I should have clarified this): I could find nothing in the *interface* of the library that could impact performance in a negative way. Of course it is not trivial to provide good performance across a wide range of architectures. And it is a lot of work. But it can be done from an interface and architecture point of view. Achieved performance is important but also unfair to compare. If I run Boost.Compute on Intel, AMD, and Nvidia and see significant performance problems on Intel what does it say about the library? That one implementation does not fit all architectures. But we already know that. It also says that Boost.Compute is not *yet* optimized for the Intel platform. Or that Intel has some performance problems in their OpenCL implementation. These are important findings and interesting questions. But we already know how to solve these problems. What we don't know: what should the interface look like to program accelerators. How can we define it to not shoot ourselves it he foot (i.e. prevent maximum performance at the interface level).
The imminent [1.0.0 release branch](https://github.com/alecthomas/entityx/tree/1.0.0) is extremely cache friendly. Components are allocated via placement new in semi-contiguous chunks. Here are the benchmark differences between the old and new versions: Old: creating 10000000 entities 0.992084 seconds elapsed destroying 10000000 entities 1.60206 seconds elapsed creating 10000000 entities while notifying a single EntityCreatedEvent listener 1.64891 seconds elapsed destroying 10000000 entities 1.58506 seconds elapsed iterating over 10000000 entities with a component 10 times 5.59065 seconds elapsed New: creating 10000000 entities 0.458225 seconds elapsed destroying 10000000 entities 0.799043 seconds elapsed creating 10000000 entities while notifying a single EntityCreatedEvent listener 0.675956 seconds elapsed destroying 10000000 entities while notifying a single EntityDestroyedEvent listener 0.838062 seconds elapsed iterating over 10000000 entities with a component 10 times 1.23081 seconds elapsed
I have my BSON library [jbson](https://github.com/chrismanning/jbson) which uses C++11/1y throughout. Currently only works with clang &amp; libc++ as gcc's libstdc++ is lacking. Some highlights of C++11 features: * Uses unicode facilities in `&lt;codecvt&gt;` (which gcc doesn't have) in JSON parser and for validation. * Uses `boost::string_ref` quite a bit which could easily change to `std::string_view` when it's standardised. * Uses `&lt;type_traits&gt;`, template aliases, enable_if, decltype, et al. extensively. * Move conversion operators, using "rvalue this", i.e. jbson::document doc = jbson::builder("key1", "value1")("key2", "value2"); Propagates rvalue-ness, avoiding copies. May be some others I'm forgetting right now.
Sometimes it can be a bit tricky to go too new as I just discovered when the android ndk would not use the std::to_string function even though it generally supports C++11. Not a huge deal as I dealt with it through an #ifdef. Except that I generally think that platform related ifdefs are bad form. 
&gt;gcc's libstdc++ is lacking. Just curious as to what you're missing. I know `&lt;regex&gt;` didn't work until gcc 4.9.
I'm curious what issues you had with [std::enable_shared_from_this](http://en.cppreference.com/w/cpp/memory/enable_shared_from_this/shared_from_this). It may have been a specific implementation was poor as I've had no issues swapping from boost - well as long as I remember to swap both the enable and the shared pointers.
How does a terrorist programmer get to heaven? With a fork bomb. 
I would like to mention universal brace initialization as a pretty nice C++11 feature, plus more liberal use of algorithms (such as generate_n and for_each etc.). 
I was also caught out by a similar issue using strings. I had a few C style functions that accepted `const char*` as an argument. By design, the function also accepted `nullptr` to denote that the parameter(s) were not used. void Foo(const char* S, const char* K); Foo("Bar", nullptr); //Ignore second parameter Sometime later, I changed the parameter types to `std::string`, but I forgot to update calls with `nullptr` as the argument: void Foo(const std::string&amp; S, const std::string&amp; K); Foo("Bar", nullptr); //Oops Compiled fine. Didn't run fine. Took me a while to figure out what was going wrong.
`&lt;codecvt&gt;` is missing. Admittedly, some of the things I've used can be approximated with the older `std::codecvt` in `&lt;locale&gt;`, but still, would be nice to have it all :)
For sure it was an implementation bug, not a bug in the standard. I have vague memories of some assignment issues deep in the bowels of shared_from_this. Was a while ago on OSX clang, so I've gone to the code in question and find/replace to use std:: and it compiles and the tests pass now. I'm too scared to check that change in though :-) 
What the standard really still lacks is a char-range to integer conversion-template. I participate in project where we have to read a lot of lines from a file, where every line contains some integers (ascii-encoded). By replacing the stdlib-string parsers with a simple hand-written function, we were able to gain big amounts of performance. Im currently experimenting with writing a better, more general form, which can be found [here](https://gist.github.com/Florianjw/a5a6b5b064f3a8efb924), and it still gives much performance, in this case even without compromises on error-checking. (Just in case someone now tells me to write a proposal: I would probably do that if someone would be willing to champion it, since participating in standardization personally is definitely of limits for me.)
&gt; Thanks for NOT using an errno scheme Agreed! `errno` is just unfortunate. I'm surprised [ZeroMQ](http://zeromq.org) uses it for error reporting... &gt; `if (!std::uncaught_exception()) { ... }` Huh, I knew about `std::current_exception` but not `std::uncaught_exception`! &gt; Instead you can use `struct foo; typedef foo* foo_t;` I used to do something similar but stopped when I realized that I was violating aliasing rules (by internally casting it to an unrelated `class`); using a forward declared `struct` and then having the internals match that name makes a lot of sense. I can think of some practical issues with MSVC's ever-so-special mangling of `struct` vs `class`, but I think there's an easy way around this...more on this to come!
I don't even understand why `std::string(nullptr);` is not just treated as `std::string("");`. If you accept a pointer argument, **expect it might be `null`!**
Also, can you point me to the wording that states that forward declarations must match in terms of `class` vs `struct`? I've wondered about this for some time but never found a clear cut answer in the draft.
VS's C++ support is... spotty. :(
How does it compare with the boost.spirit parsers?
or they think people get what they deserve when writing code like this.
That's what I thought, thanks!
I have found 2 libraries by the same author to be interesting: * C++11 multiplatform utility library: https://github.com/mosra/corrade * C++11 and OpenGL 2D/3D graphics engine: https://github.com/mosra/magnum I would like to give it a try, the code seems well documented, supporting multiple platforms, using modern C++ for enhanced type safety, to fail on misuses of the libraries and all that kind of stuff.
After fighting with the boost documentation for quite a while now: * It is way easier to use * It doesn't increase the compile-times by huge factors * but boost:spirit is in fact still clearly faster It should however be noted that the project tries to avoid depending on other libraries, so using it probably isn't going to happen. (The maintainer is already now weeping over the compilation-times.)
I don't think I am alone when I say that std::string is poorly designed. They tell you to write your own string class, throw it away and then use std::string. But I don't know, I'm tempted to keep mine.
std::string certainly isn't perfect, but it is pretty close to the best compromise we can get. The problem is that everyone has different opinions about what the main-problems are and the solutions are mutually exclusive: std::string should be fast for small strings, but if you use the small-string-optimization to achieve this, they will complain about wasting space. They want unicode-support, but are unwilling to pay for the resulting HUGE performance-cost of a few hundred percent. … The real problems of std::string are few in number and often cannot be overcome at all (like string-literals being of type char[N]). Stuff like the often cited “to many methods” may be valid, but is certainly something that can be ignored quite easily. 
I wouldn't say that `std::string` is the "best" compromise simply because I'm not sure that ranking the compromises is really possible. There's quite a few radically different approaches to strings that are each sometimes the correct choice, and picking one as the best default would require far more information about how C++ is used than exists. I think the only thing it really makes sense to judge is whether or not a string implementation is at a local maximum for the approach it takes. By that measure, `std::string` is pretty good, as the problems that could be solved without doing something totally different are fairly minor, but they do exist.
Eh, ease of use is in the habit -- I find it pretty simple, especially if you need to stuff the results into a vector or some structure. But even for a basic string to int conversion, it's a one-liner: #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;boost/spirit/include/qi.hpp&gt; namespace qi = boost::spirit::qi; namespace ascii = boost::spirit::ascii; int main() { std::string s = "1234"; int result; bool r = qi::phrase_parse(s.begin(), s.end(), qi::int_, ascii::space, result); if(r) std::cout &lt;&lt; result &lt;&lt; '\n'; else std::cout &lt;&lt; "failed parse\n"; } demo: http://coliru.stacked-crooked.com/a/ed21d7033b300396 I do agree on compilation time.
I think [banditcpp](http://banditcpp.org/index.html) is very neat. I use it as my new favorite testing framework.
That was nice 😉. Is there a reason to use get: libfoo_error_details_t* get() const { return &amp;_details; } In lieu of libfoo_error_details_t* operator&amp;() { return &amp;_details; } (same thing for ThrowOnError, who has operator\* for the similar thing) ? That IMO gives somewhat more "natural" (*for calls to C*) look&amp;feel when calling the function: ErrorDetails error; if (libfoo_create_widgets(12, &amp;container, &amp;error) != libfoo_success)... And libfoo_create_widgets(12, &amp;container, &amp;ThrowOnError()); And a slight complaint: there are two ways of checking whether an error occurred there: return value and the presence/absence of libfoo\_error\_details\_t. It's just a "don't make me think" thing, but I wonder whether that could go away.
&gt; even thread-local variable do not play well when integrating in coroutines Why co-routines? It look to me that, as long as that thread-local error value is "consumed" *right after* the failed call (which is the *only* correct way to do it), there is no problem? Or...?
Without seeing (at least a sample of) the file, I'm not sure I can completely track down the problem. However, here are a few things that stood out: //the selling cost of the item void readSellingFile(ifstream &amp;fp, double &amp;selling,int &amp;number) { int i; double total=0; for(int i=0;i&lt;number;i++) { fp&gt;&gt;selling; total+=selling; } } a) number is never modified, so it should be passed by value or constant reference, not regular reference. b) Total is accumulated but never used or returned. Is this important? In your main function: while(!fp.eof()) { getDataFile(fp,item,number,cost); for(int i=0;i&lt;number;i++) { readSellingFile(fp,selling,number); gross=grossprofit(total,cost); net=netprofit(gross,total); getDataFile(fp,item,number,cost); } display(item,total,cost,gross,net); } you read the number in from the file, start looping, and on the first loop you read the number in again. This is almost certainly wrong. Depending on how that then works, your last loop (where the file has failed, and thus isn't reading anything in) may be setting your number to an invalid or very large amount, where it stays every time the loop is executed, and therefore likely won't terminate for a long time.
`boost::lexical_cast` was just the easiest way to do what I wanted -- I intend to use straight C++ before I call the system 1.0.
`while(!fp.eof())` is a mistake. As a rule of thumb, using `eof` in a loop condition is usually a mistake. What you want to do is to read until your read operation fails. What you are actually doing is processing some garbage after your read operation fails; and then if the failure reason was `eof` you will stop, but on other failures you will go into an infinite loop. After `getDataFile` and `readSellingFile` do `if ( !fp ) { /* maybe display something */ break; }` . Also you should modify `readSellingFile` so that if the read fails then you do not add a garbage value onto the total. As cjhutt says, your loop is fail: you re-read `number` after each iteration, so you actually never do a particular number of iterations. What were you trying to do here?
If you haven't read *Effective C++*, *More effective C++* and *Effective STL* by Scott Meyers, you probably should, even though it's pre-11. The same thing goes for *Exceptional C++* and *More Exceptional C++* by Herb Sutter and *C++ Coding Standards* by Herb Sutter and Andrei Alexandrescu.
* 'const' in all its forms and why it is useful. Depite the extra code you have to write sometimes, const makes your programs much safer as well as easier to reason about. * RAII. Don't only use it, design your classes to be able to be used as RAII objects (when appropriate). * std::unique_ptr, std::make_unique * std::vector and std::array (avoid C-like arrays as much as possible) 
I'm currently working on a reactive programming library for C++, which makes use of many C++11 features: https://github.com/schlangster/cpp.react
Looking at your code... Points you should fix: * Global variables like in BasicBookReader.cpp are not a good style. Make those member variables. * You are overusing new, Qt already uses Copy-on-Write and shares often between objects the same data safely through reference counting. Only use new in Qt if you create a child in a QObject or for a QWidget/Layout. * the over usage of new brings you a bunch of memoryleaks * IMHO you shouldn't keep QFile objects around, use them locally to read/write files, then close the file resource (destructor does this for you).
I am more so looking for small things that enhance the language, but I *do* need to sit down and read these.
&gt; I am more so looking for small things that enhance the language Then these books are perfect for you. They contain a lot of small things like that, generally covering 1 to at most 5 pages. Edit: Ah, I see you mean additions to the language. Those you won't find, no.
I'd like to add std::map to your final list, it's one of the most useful containers imo.
I understand, but I wish we had less instances of *the type system will accept this, but it'll blow up in your face*.
*STL* from end to end. Don't duplicate code. *RAII*. Do not use new and delete. If you do, it's a good sign that something's wrong. *Template meta-programming*. Scrap your boilerplate. *Common idioms*. Write code that everybody can read &amp; understand. (Wikibooks has a nice list of idioms) *Design Patterns*. Same as with idioms. The GoF book is a good starting point. 
Why avoid C-like arrays?
OK, i found out what my problem was all the time: I did not include qi.hpp but qi_numbers.hpp and qi_parse.hpp. But I still fail to see why this would result in failing static assers…
You might find the open book "More C++ Idioms" useful. It has some obvious parts, but accompanied with a few gems as well. http://en.wikibooks.org/wiki/More_C%2B%2B_Idioms
Because they decay to pointers, losing length information, and thus easily allowing out-of-bounds reads and writes (ie, undefined behavior).
On that note I'll add boost:: container:: flat_map and it's ilk. I find myself using this by default nowadays in lieu of map. 
Inexperienced student here: I tried understanding the cpp vector a while ago, but I just got lost and confused. Do you perhaps know if there's a simple explanation anywhere on how and when to use them? 
Even when I'm using a C-based library, I still use std::vector. If you need to call a C-based library function that requies an array, you just need to pass a pointer to the first element of your std::vector: somefunction( &amp;somevec[0] ); Here, your specifying that you want to pass a pointer (&amp;) to the first element ([0]) of the vector. And since vectors arrange their data so that it is contiguous in memory, the C-based library sees it as a normal array.
But when you use delete[], the compiler suddenly comes to know of it's length, oh the irony.. :P
Even though I need to understand it better and use it more in my own work, how about Boost?
You're right. I need to look more into Boost myself.
Why? How much of an advantage is it?
Your book should cover it. [If it doesn't...](http://www.reddit.com/r/learnprogramming/wiki/faq_cpp)
Does the speed for lookup hold true for massive data sets? I'm thinking a container like this would have to be searched linearly since it's a flat vector. Or, does it employ some kind of binary search? 
I always find myself using std::unordered_map over map. std::map has to be implicitly slower to satisfy order constraints. If I need ordered keys, I'll use the classic map.
It's a sorted flat vector. That turns insertions into O(n) as opposed to O(1) for unsorted vectors, but lets you do O(log n) lookups.
It's an array that automatically resizes itself when you add stuff to it.
The previous post said it was a sorted vector, so I'd guess the latter. 
This article is *terrible* about links. First there are several pieces of blue underlined text that aren't links (BIG no-no!) and then there is a list of proposals with no links, then some with links, then without, then more faux-links... Is a little bit of consistency too much to ask for? Also, the article seems to be half summary, half poorly formatted list, half random notes. Although you can get a good idea of the C++14 changes by picking through the article, it doesn't make a good summary in and of itself. Actually, looking at it, I'm wondering if this was a pile of notes from the meeting that was copy/pasted into IBM's CMS and the formatting got really confused along the way. **Edit:** And it actually has proposal numbers wrong and occasionally links to an apparently private wiki for them. Terrible. * "N2462: improves result_of in SFINAE" -&gt; N3462 * "N2471: constexpr util lib" -&gt; N3471 * "These were in N3921" -&gt; ??? (The list of things "in N3921" includes N3921) If someone who already has an IBM DW account could post this as a comment on the actual article, that would probably be more useful than me ranting on reddit. I don't want to bother setting up an account just to complain about one poorly written article.
This is not C++-specific but you *must* be familiar with this if you don't want to make enemies out of people you work with and people you haven't even met yet: * Composition and reuse. Design for composability and reuse, and look for something you've written before to reuse before you start coding something new. Examples of composition: * add a member to your class, rather than inheriting from another class. * in your function return a value as output and accept a parameter as input, as opposed to modifying an argument. * keep your function simple, responsible for one thing. * consider a free function before you consider a member function. * consider narrowing what your program does * consider following an idiomatic input/output protocol for your program so it composes with other programs. UNIX programs have a protocol for that to follow, so they compose nicely in a pipeline. These are all examples of guidelines you can (should) follow for the end means of composition and reuse: composing function calls, composing class instances, composing programs, and so on. The idea is to make the best out of anything you create and others before you have created, so that you don't need to write as much code, so you make less mistakes, so you make less pain and suffering in the world. Compose and reuse, compose and reuse, compose and reuse.
You do not state at all what gears actually does.
Nice, I didn't know that - thanks!
I wonder if that has something to do with the low-fragmentation heap on Windows. On Windows, small allocations will be routed to a special pool allocator - so even if you make a huge number of tiny allocations (as std::map probably does), they'll all end up contiguous in memory anyway.
Explosions, horrible horrible explosions. That is why. With a vector if you go past its boundaries it will cry scream and generally lose its mind. But if you go past the end of your allocated memory in an array it may very well work just fine.... most of the time. It really depends on how critical a thing you have next in memory. Plus the bug won't be in your array (usually) so lets say you have an array[10] with your next allocation being a decryption key. If you put something into array position 11+ then it will probably overwrite your decryption key. So now you will be hunting for a bug in your decryption code. 
This is not universally useful, but I like the use of header files for storing data. In particular the combination of [X-Macros](http://en.wikipedia.org/wiki/X_Macro), [Named Parameters](http://www.parashift.com/c++-faq/named-parameter-idiom.html), and [aggregate initialization](http://en.cppreference.com/w/cpp/language/aggregate_initialization). It's much faster and less error-prone than writing file parsing code, and if the time comes when you *need* to switch to file parsing then it's trivial to translate the header into a custom file format.
Yea I know, I just meant in this era, we should be able to get size of it. Compilers of others languages have advanced to an extent compiler can be used as a service while writing code.
Linear search can outperform your traditional tree. It can even outperform binary search within a contiguous chunk of memory. The prefetcher will have your next few elements in the cache before you ever even look at them and it doesn't have to figure out any access pattern to do so. Herb Sutter likens it to an extra level of cache of infinite size.
I think it is important for c++ programmers to understand what pointers are and how the heck they actually work. I'm fairly surprised to find how something that fundamental is confusing as heck to a lot of even intermediate level programmers. I'm no expert, but pointers and their relationship to many aspects of oop are incredibly important.
Not if it was stack allocated. Then your heap manager is going to get really fucking stupid.
With C++11, I find myself using boost a lot less.
I found *Head First Design Patterns* to be more approachable than the GoF book.
Did put it through callgrind with a simulated cache and compare the cache miss rate?
Use deque over vector unless you need contiguous memory, but for the reasons you are advocating here deque should be fine.
Move semantics, easier? I'm not so sure about that...... But I agree on the latter two ;)
Hm. I thought I state what it does in the overview. Well, it's basically just a bunch of utilities, similar to boost I guess.
I've heard that a lot, but honestly I didn't read it. The same with the GoF book, I look up some patterns to get a general idea, but I do not read the whole thing. I prefer the Internet for reading about these kind of things. Anyhow, personally, I'm a bit skeptical about the cookbook style presentation of most patterns. Patterns are nice, but one has to be flexible enough to adapt them to their own needs. If I have a problem at hand, I think about how I could solve it with various patterns. But I always think about non-pattern solutions too. With the common design patterns one has to be very careful not to fall into the Hammer-Nail-trap. tl;dr; Design patterns solve problems that do not exists in other languages.
After going boost-crazy for awhile, I decided to completely drop it with the introduction of C++11.
There are likely some introductory examples that show you how to make the STL vector class. Effectively, imagine you wanted to build a vector class for integers only. You may start with this: class MyVector { public: /* some constructors */ int&amp; operator[](int position) { return arr[position]; } private: int* arr; int lastUsedElement; int numberAllocatedElements; }; When you try to add something to it, it needs to check if there are free elements available. If there are then it increments lastUsedElement and assigns into arr. If it isn't then it does something like this: int* newArr = new int[numberAllocatedElements*2]; for(int i=0; i &lt; lastElementUsed; ++i) { newArr[i] = arr[i]; } delete [] arr; arr = newArr; numberAllocatedElements *= 2; And then does a normal "push_back". One thing to consider: you do need your constructors to do something for arr. By default you may say arr = new int[8]; So that no reallocation happens until you enter a 9th element, figuring the memory cost vs typical usage is a pretty good compromise. And your destructor: MyVector::~MyVector() { delete [] arr; } Now the STL vector takes something like this and templatizes it so everything is really template functions: template&lt;typename T&gt; vector::~vector() { delete [] arr; } The key to all this is to use the copy constructor. In the integer case, we could use memcpy instead and it would work. But converting it to a template class you can't use memcpy on arbitrary objects. Especially if it's a pointer that the vector is supposed to own, ie, you have been using vector&lt;T&gt;::push_back(new T()).
The code invokes undefined behavior. It might happen to work by accident, but that can change by the phase of the moon. There's no sense in trying to predict or analyze undefined behavior. You might use a different compiler or different version of the same compiler or different compilation options and find the behavior completely different. 
If you simply compare what would replace a c style array sure. If you are using the container in a manner where you don't know the full data set size ahead of time and you may be inserting data at random points a deque will be more performant than a vector and without knowing this you might opt for using list in its place. So perhaps I might alter my suggestion on just take the time to fully understand the containers available and when their use is appropriate.
In modern cpp : use auto's, use vectors, use contiguous memory, use unique pointers, use move semantics
Boost
3\. Make pure functions when convenient.
You can get the size of it... as long as you use std::array or std::vector :P
I'll give you that, though arguably it's arguably always been possible to write code that returned by value. It just usually* wasn't efficient ;D. \* Due to return value optimization as implemented in most C++ compilers, this wasn't always strictly the case. The caveat of course is that one can never rely on the compiler performing an optional optimization, especially when it could change the semantics of the program.
Only if the type has a nontrivial destructor. For something like int[], it just needs to know the size of allocations, which is often bigger (e.g. smaller allocations will be rounded up to a power-of-two by most allocators).
So just C++ and some of the C++ derivaties?
There is nothing more useful than learning how to use the symbolic debugger for your code. Now matter what you write - you WILL eventually have to figure out why it is doing something you didn't intend or isn't doing something you did. 
I kinda feel like... If you aren't willing to EVER spend the time to do things that are more prone to error but more efficient, why are you even bothering with a language like C++? Use a higher level language that is optimized for safer programming.
[stacked-crooked.com](http://coliru.stacked-crooked.com/).
What's a free function?
You can try out [Visual Studio Online](http://www.visualstudio.com). For programs with just a single translation unit you can use online compilers such as [Coliru](http://coliru.stacked-crooked.com) or [rextester](http://rextester.com/runcode).
I see requests for this sort of thing every couple of months but I never asked... why would you want such a thing?
Just a function that's not part of a class (it would then be called a method).
You should learn with naked pointers, but you should probably only use them in real life if you’re actually implementing a low-level library (one that *really actually* needs to be close to the metal). Thanks to operator overloading, you can use them pretty much the same way, you just don’t have to pinpoint every little place it *might* not get deleted.
C and C++ are designed to not do anything that is "extra" because it often happens that you *do not* need length information for every array. Storing lengths and checking lengths of arrays upon every access is not too difficult for language authors, it just is not desired all the time.
Point'ngui mglw'nafh Cthulhu R'lyeh wgah'nagl pointagn
http://ideone.com/
with covers part of RAII, but misses the most important part: not having to explicitly do anything at the point of use, and not having to even care if an object holds non-memory resources.
The idea is that free functions are not a commitment like methods. With methods, you need an object instance (well, unless it's a static function which essentially is a namespaced free function) and that implies lots of things. A free function actually promotes decoupling more than well-designed class ever could. C++ is not an OO language, it's a multi-paradigm language so don't use it as you think you should, use it as appropriate.
That's actually kind of what it looks like to de-reference a wild pointed :-P
I'm not sure what you mean by "game networking", but have you had a look at boost.asio?
maybe boost? I don't know if it has networking, but it has alot of things.
It's 'a lot' not '[alot](http://hyperboleandahalf.blogspot.com/2010/04/alot-is-better-than-you-at-everything.html),' ya dingus!
I know boost.asio and it's somewhat painful and low-level to use. To specify, I'd like something a bit more high level and perhaps with some domain specific things that enet does explicitly not provide such as authentication, lobbying, server discovery, encryption. Essentially raknet does all that but the license isn't quite as liberal as I'd like it to be.
The [POCO project](http://pocoproject.org/) has some fairly extensive networking libraries. I'm not sure they are directly appropriate to gaming thou.
Thanks for the criticism, I've fixed the global variables, a large number of the "new" issues, and the QFile. 
move semantics/rvalue ref: switching to c++11 gave us an immediate 20% speed boost...move semantics got that for us from having mostly default copy constructors and assignment operators. I went in and hand diddled about 4-5 low level classes adding in rvalue ref stuff and got another boost. Modified several sets of constructors to force pass in stuff to be moved. For multithread stuff this is especially a big deal and even bigger on windows with its very lame memory allocator.
really only use deque if you need to work both ends like a fifo. A deque actually can give you a little extra memory breathing room if you must collect a lot of elements of unknown size. The little extra chunks of allocation are a bit more friendly than a vector resize.
proper unit tests and print statements can easily preempt using a debugger. Nowadays I only debug post mortem and I tend to force the crashes with the unit tests or a simulation.
The answer is almost always. I can't find it off hand but Herb Sutter has a talk on modern c++ he takes a tangent on move semantics and shows that vector out performs list and maps in some of the most common uses for them, because the continuous memory lets the prefetcher do its thing.
Relying on optimizations isn't something you can _usually_ do, but rvo isn't like most other optimizations - both GCC and Clang apply it even at `-O0`. If you can't rely on your compiler performing rvo (for perf concerns, not correctness), you should get a better compiler.
&gt; it would then be called a method Not in C++ it wouldn't. The proper term is "member function".
&gt; Pointers, like chainsaws, are only dangerous for people who use them carelessly and inappropriately. But if you're writing high-performance software, you have no choice but to juggle them: ownership transfers are unavoidable (unless you want to use "out parameters", in which case you'll really like C). The only solution is to meticulously document when ownership transfer is expected to take place -- but if you do this in comments or separate API documentation, the code and the documentation are \*inevitably\* going to get out of sync in places, and then the best case scenario is memory leaks. That's the greatest thing smart pointers offer: self-enforcing documentation of ownership. Using smart pointers doesn't have to mean wrapping everything in a shared_ptr; unique_ptr has very little overhead (no extra space, a tuple access the compiler can optimize out), and if you use a convention of ownership following the unique_ptr with bare pointers where no transfer takes place, you can avoid even unique_ptr most of the time, while codifying ownership. It's not worth leaving ownership tracking up to faithful reading and writing of the documentation to avoid minimal overhead the compiler can usually eliminate.
Not to mention the compile time when *all the code* is in headers...
Are there any good online explanations of proper RAII?
SFML comes packaged with a networking lib, which is probably just a wrapper around some other library. Nothing fancy, but you could certainly propose adding more complex stuff to SFML's networking lib, I don't think they would turn down some solid game-centric networking code.
&gt; I wonder whether there's a new hip kid on the block that uses C++11 in fun ways. I have to ask, is that *really* what you want from a library?
I can't believe someone downvoted you for that comment. For shame, guys. Svenstaro is saying exactly what I'd expect a game developer to say, because those are exactly what game developers need out of networking libraries. They don't need a nice wrapper around raw sockets, they need quite a lot more.
Plus, unless you really are working *really* close to the metal on embedded hardware, there’s the principle of [premature optimization](http://en.wikipedia.org/wiki/Program_optimization#When_to_optimize). In all likelyhood, you’re going to invest your man-hours in the wrong place worrying about stuff like that.
[Wikibooks](https://en.wikibooks.org/wiki/More_C++_Idioms/Resource_Acquisition_Is_Initialization) and [Wikipedia](https://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization) both have good explanations and examples. But RAII isn't difficult. In C++ it simply means to allocate your resources in the constructor and to deallocate them in the destructor. That way, you can wrap a resource handle into an object and assiociate the resource's lifetime with the object's lifetime. I also suggest to take a closer look at `shared_ptr`, most of the time it is sufficient (and comes with built-in thread safety). ^(Edit: Messed up links) 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Resource Acquisition Is Initialization**](https://en.wikipedia.org/wiki/Resource%20Acquisition%20Is%20Initialization): [](#sfw) --- &gt; &gt;__Resource Acquisition Is Initialization__ (__RAII__) is a [programming idiom](https://en.wikipedia.org/wiki/Programming_idiom) used in several [object-oriented languages](https://en.wikipedia.org/wiki/Object-oriented_programming_language), most prominently [C++](https://en.wikipedia.org/wiki/C%2B%2B), where it originated, but also [D](https://en.wikipedia.org/wiki/D_(programming_language\)), [Ada](https://en.wikipedia.org/wiki/Ada_(programming_language\)), and [Vala](https://en.wikipedia.org/wiki/Vala_(programming_language\)). The technique was developed for [exception-safe](https://en.wikipedia.org/wiki/Exception-safe) [resource management](https://en.wikipedia.org/wiki/Resource_management_(computing\)) in C++ during 1984–89, primarily by [Bjarne Stroustrup](https://en.wikipedia.org/wiki/Bjarne_Stroustrup) and [Andrew Koenig](https://en.wikipedia.org/wiki/Andrew_Koenig_(programmer\)), and the term itself was coined by Stroustrup. &gt;In RAII, holding a resource is tied to [object lifetime](https://en.wikipedia.org/wiki/Object_lifetime): [resource allocation](https://en.wikipedia.org/wiki/Resource_allocation_(computer\)) (acquisition) is done during object creation (specifically initialization), by the [constructor](https://en.wikipedia.org/wiki/Constructor_(object-oriented_programming\)), while resource deallocation (release) is done during object destruction, by the [destructor](https://en.wikipedia.org/wiki/Destructor_(computer_programming\)). If objects are destructed properly, [resource leaks](https://en.wikipedia.org/wiki/Resource_leak) do not occur. &gt;Other names for this idiom include *Constructor Acquires, Destructor Releases* (CADRe) and *Scope-based Resource Management* (SBRM); this latter term is over-specific and inaccurate, since RAII ties resources to object *lifetime,* which may not coincide with entry and exit of a scope (notably variables allocated on the free store have lifetimes unrelated to any given scope). However, using RAII for automatic variables is the most common use case. &gt; --- ^Interesting: [^C++](https://en.wikipedia.org/wiki/C%2B%2B) ^| [^Exception ^handling](https://en.wikipedia.org/wiki/Exception_handling) ^| [^Resource ^management ^\(computing)](https://en.wikipedia.org/wiki/Resource_management_\(computing\)) ^| [^Object ^lifetime](https://en.wikipedia.org/wiki/Object_lifetime) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ch94w4c) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ch94w4c)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
We just use Steamworks for all of that these days.
&gt; STL from end to end. Is that even possible? 
You are making an assumption that `delete[]` knows what it's doing. Do not forget it's undefined behavior to call `delete[]` on a pointer which was not returned by `new[]`: delete[] ((new std::string[5]) + 1) this is, of course, because of this decay. If `new[]` returned a non-decaying `std::string[]` type that did not support pointer iteration, then we would not be in this mess :x
Will `push_back` then `std::sort` be generally shorter than `insert`?
The classic article by Scott Meyers is a good read: [How Non-Member Functions Improve Encapsulation](http://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197)
There is the assumption here that `Derived` in `poly_collection::insert` is the most derived type of the object being inserted, however this does not seem to be tested, potentially leading to *splicing* because: - `typeid(x)` gives the most derived type - but a `poly_collection_segment&lt;Derived,Base&gt;` is built, which stores `std::vector&lt;Derived&gt;` I would advise either ensuring that `Derived` [is `final`](http://en.cppreference.com/w/cpp/types/is_final) or, if not, resorting to a runtime check that `typeid(x) == typeid(Derived)`.
I read a lot of "We need help with this and we can't use C++11."
Is there any reason you had a for_each member function instead of having iterators, begin, and end, so the standard library algorithms could work on it?
This is my revised code which I got the file to read in and it is almost working. The problem I am running into now is for the selling price it is only taking in my last price for selling instead of collecting all of the prices. I know it must be an easy fix but for some reason I just cant figure out what I need to do to fix this. Thanks for the help. #include&lt;string&gt; #include &lt;iostream&gt; #include &lt;iomanip&gt; #include &lt;fstream&gt; using namespace std; //all functions needed for this project void readSellingFile(ifstream &amp;fp,double &amp;selling); double grossprofit(double total, double cost); double netprofit(double gross, double total); double totalPrice(double &amp;selling); void getDataFile(ifstream &amp;fp, string &amp;item, double &amp;cost, int &amp;number); void display(string item,double total, double cost,double gross,double net); //main funtion starts here int main() { int i; double gross,net,selling,total; ifstream fp; string item; int number; double cost; fp.open ("sales.dat"); if(!fp) { cout&lt;&lt;"Error Opening the file"&lt;&lt;endl; } while(!fp.eof()) { getDataFile(fp,item,cost,number); for(int i=0;i&lt;number;i++) { readSellingFile(fp,selling); total=totalPrice(selling); gross=grossprofit(total,cost); net=netprofit(gross,total); } display(item,total,cost,gross,net); cout&lt;&lt;"Bye!"&lt;&lt;endl; } } void getDataFile(ifstream &amp;fp, string &amp;item, double &amp;cost, int &amp;number) { cout&lt;&lt;"Reading from the file. "&lt;&lt;endl; fp&gt;&gt;item; fp&gt;&gt;cost; fp&gt;&gt;number; } //the selling cost of the item void readSellingFile(ifstream &amp;fp,double &amp;selling) { fp&gt;&gt;selling; } double totalPrice(double &amp;selling) { double total=0; total+=selling; return total; } //calculates the gross profit double grossprofit(double total,double cost) { double gross; gross=total-cost; return gross; } //calculates the net profit double netprofit(double gross,double total) { double net; net=gross-(.06*total)-(.10*total); return net; } //prints out the results void display(string item, double total, double cost ,double gross, double net) { cout&lt;&lt;"Item:\t\t"&lt;&lt;item&lt;&lt;endl; cout&lt;&lt;"cost:\t\t$"&lt;&lt;fixed&lt;&lt;setprecision(2)&lt;&lt;cost&lt;&lt;endl; cout&lt;&lt;"Selling price:\t$"&lt;&lt;setprecision(2)&lt;&lt;total&lt;&lt;endl; cout&lt;&lt;"Gross Profit: \t$"&lt;&lt;setprecision(2)&lt;&lt;gross&lt;&lt;endl; cout&lt;&lt;"Net Profit: \t$"&lt;&lt;setprecision(2)&lt;&lt;net&lt;&lt;endl; } 
It was simpler to write. Also, implementing an iterator is of course doable, but I suspect the performance of for_each(c.begin(),c.end(),f) won't match that of c.for_each(f). 
Note that poly_collection::insert accepts refs to *any* subtype of Base, so type erasure from const MoreDerived&amp; to const Derived&amp;, if it happens, must happen prior to insertion... That said, adding the runtime check is straightforward and doesn't hurt.
No, that would be exactly the overhead required, which is one more check per iteration than poly_collection::for_each has. Anyway, a full-fledged container based upon the sketch given here would definitely provide an iterator along the lines you describe.
That was Bjarne Stroustrup, here: http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Keynote-Bjarne-Stroustrup-Cpp11-Style Just start at 44 minutes in. The whole talk is well worth watching though.
That's another reason why people should limit using operator[] on vectors (unless they really need to). I'd think most uses of vectors would be for iterating over them to do something.
That's probably because a lot of the boost library features were pulled into the standard. Examples include some smart pointers, locks, algorithms, etc.
It's still a method in C++, member function is just another name. So if someone calls it a method, they aren't incorrect. 
Ada isn't a C++ derivative, but they have it as well.
I'd say use an insertion sort, but it would be interesting for someone to profile multiset vs vector with insertion sort. I'm too lazy right now.
&gt; which is one more check per iteration than poly_collection::for_each has Surely there would be only 1 check per iteration, that being an end-of-segment check? If you are at an end-of-segment then of course you need to do a 2nd check to see if there's another segment to switch too, but the same thing happens with the nested for loop you're using anyway.
There's pretty much an implied "except for Ada" after any statement about how no programming languages have some useful feature. It's really a shame that it hasn't been more influential on other languages.
&gt; Surely there would be only 1 check per iteration, that being an end-of-segment check? Only one check for operator++, but there's an additional check for the end of range passed to std::for_range, hence two checks per iteration step.
&gt; You do mention both those points, but they get lost in among the other details when they really are crucially important. Point b for example only pops up in conclusion. Well, poly_collection is not even a container, but a quick sketch showing the foundational ideas of the article --it does not even have iterators or erase, for instance. With some more work, it could be grown into a full-fledged container. &gt; Also I wonder how a vector sorted by type_index would compare? I'd expect it to be somewhere between the two, but where in-between could be interesting. This is easy to see by slightly modifying the test program: I've done this locally and these are my results: for_each: vector_ptr;poly_collection 1000;0.0270055;0.0264612 10000;0.0333247;0.0272696 100000;0.125241;0.0341785 1000000;0.158608;0.028614 10000000;0.212345;0.0277992 So for small values of n a sorted pointer vector performs more or less like poly_collection, and when n grows execution times are about 65% of those of an unsorted pointer vector (and much worse than those of poly_collection). 
Ah ok, my logic was to have `operator++` be unconditional and have `i != std::end(c)` contain the extra logic of handling the end of a segment. That that approach would only work if the `i` can be modified when you compare it to `std::end(c)`. I'm guessing now that's probably not allowed for a STL style iterator.
&gt; Well, poly_collection is not even a container, but a quick sketch showing the foundational ideas of the article --it does not even have iterators or erase, for instance. With some more work, it could be grown into a full-fledged container. Yeah I do understand that. I wasn't meaning to be overcritical.
Print statement require that you know what to look at. Following the execution path and inspecting variables as you go won't require a compilation cycle every time you want to look at something new.
Indeed, but that's not what the article is about.
What do you use for actual communication?
SFML has *sf::Packet* which is more than just a thin wrapper: http://sfml-dev.org/documentation/2.0/classsf_1_1Packet.php#details There is also *[Simple and Fast Network Utility Library](http://en.sfml-dev.org/forums/index.php?topic=13723.0)*, which actually doesn't even require SFML afaik.
&gt; I don't know what C++11 features you'd want in a networking library. Oh, I dunno, native threads/mutexes/atomics, native high-resolution timers, lambdas, initializer lists, constexpr, a well-defined memory model, and move semantics?
Woah guy, you've just outlined a *framework* not a library. I don't normally want my networking code to define the whole structure of my program.
My list above allows for a better/cleaner interface *to* the networking library, and the library itself can be made simpler and cleaner (code-wise) leading to fewer bugs and faster performance. And all those things I listed? They're not a "framework" anymore, they're all integrated into the C++ language and standard library. C++11 fixes so many issues with the language that the prior standards look primitive and clunky in comparison. The question isn't why are you using C++11, the question is *why aren't you?*
&gt; they're all integrated into the C++ language and standard library This is /r/cpp. We know that. &gt; My list above allows for a better/cleaner interface to the networking library I don't see how my networking library interface needs threads, mutexes, high resolution timers, initializer lists, or constexpr. I could see some value for the other items including memory model, move semantics, and perhaps lambdas in the interface. Including the whole kitchen sink leads me to believe your hypothetical networking library places a whole host of demands on the structure of my program, and is more a framework than a library. &gt; The question isn't why are you using C++11, the question is *why aren't you?* My, you are young. C++ has a huge number of features, some of which I like. Just because the feature exists doesn't make it the best choice. Just because the feature is new doesn't make it the best choice. As a programmer you have thousands of choices. Justify why putting those features in the interface of a networking library is the best choice.
&gt; My, you are young. Heh. Oh man, I wish. I'm an embittered C++ veteran, and a C++ networking library built specifically to interface via C++11 would be leaps and bounds better than the old standards. My, you *are* young. :P
&gt; a C++ networking library built specifically to interface via C++11 would be leaps and bounds better than the old standards. Okay, prove it.
Cute, but it doesn't hide the fact that you made an assertion and couldn't back it up. Also, for the record, being 26 probably doesn't make you old enough to be an embittered C++ veteran. It's great that you're hyper-excited about new things, but with time and wisdom you'll come to realize where they help and where they don't. Maybe you'll also outgrow using insults to cover the fact that you've overstepped the truth.
I might just do that but as the other dude pointed out, having all that modernization work already done for me would be quite a treat.
Reminds me of the design principles espoused [here](http://gamesfromwithin.com/data-oriented-design), where it's recommended that objects be stored contiguous with their fellows for efficient mass processing.
So RAII is geared more towards instance variables rather than global variables? Or does it work for global variables as well?
Strictly speaking, I don't know if it will actually work. I've made several stabs at it (starting with a C99 version waaay back), failing design-wise each time and learning from that failure. This latest push looks promising. The goal is to have 100%-autonomous free-willed NPCs that can make long term plans, have opinions and misconceptions, and talk to each other. That will have children, grow old, and die. It's the RPG I've always wanted to play. My test-case for a full run will be to hardwire one of the NPCs with a goal of "take over the world" and then watch to see how he tries to accomplish that. I'm designing it as a world-agnostic toolkit, so if it works I'll also package it up and try to sell it as a plug-in AI library. Minimum goal is to support around 1000 concurrent NPCs. I'm working on world-agnostic world representation at the moment. In working order (but not fine-tuned) is a template DNA/chromosome mixing system that supports mutation and the bog-standard crossover mixing styles. I'm almost done with the long-short-term-memory neural network (cloud-of-neurons model) I'll use as a sort of glue or high-level trigger/control system for immediate-response to the environment while the slower asynchronous brain modules work on whatever the current thinking task is.
ISteamNetworking. It's pretty basic but does all that is needed.
What about the opposite? Preventing the less-safe heap allocation?
One way to do this, is to overwrite the any new operators for the given type and either return nullptrs, if you want no use of new at all, or use a stack based memory pool within. (Stack based, as in, i have a static array of size x, i can at most allocate x instances of this object allocated through new) The user can still forget that he allocated an object from the pool and malloc would still allow an allocation on the heap, so no absolute safety here.
distance(end(), end()) == 0
You can use the `= delete` syntax to disable them
Some things are just better as free functions. Like an AccountTransfer method. It "could" sit on an Account class, but it kinda violates SRP. In languages like C#, it *has* to be in a utility class, because the language doesn't have free functions. They reference it in "Implementing Domain Driven Design" in the chapter on services. Quote: Since the domain model generally deals with finer-grained behaviors that are focused on some specific aspect of the business at hand, a Service in the domain would tend to adhere to similar tenets. Since it may be dealing with multiple domain objects in a single, atomic operation, it would have the latitude to scale up a bit in complexity. Under what conditions would an operation not belong on an existing Entity (5) or Value Object? It is difficult to give an exhaustive list of reasons, but I’ve listed a few here. You can use a Domain Service to • Perform a significant business process • Transform a domain object from one composition to another • Calculate a Value requiring input from more than one domain object The last one—a calculation—probably falls under the “significant process” category, but I call it out to be clear. It’s a very common one, and that kind of operation can require two, and possibly many, different Aggregates or their composed parts as input. And when it is just plain clumsy to place the method on any one Entity or Value, it works out best to define a Service. Make sure the Service is stateless and has an interface that clearly expresses the Ubiquitous Language (1) in its Bounded Context. End quote A free function works great for that.
Lol I was trying to understand this until I realized you meant to reply to /u/bnolsen.
i totally agree. i've unrolled three wrapper libs for that already: auth, encrypt and enet. im still missing the lobby, server discovery and putting all together in a newer lib. im trying to find a decent alternative for all of them as well; so if you find a decent replacement could you update the post/message me? :D thanks in advance!
 auto addf = [](auto x) { return [=](auto y) { return x+y; }; }; addf(5)(4); // 9 5 is x or y? Can anyone explain this a little more? 
You can simply test it: http://coliru.stacked-crooked.com/a/2ebdf06b3d790d42 x = 5 y = 4 result = 9 In other words, `add(5)` creates a closure (closing over the environment containing value `5` in place of argument `x`) that will add its argument (i.e., `y`) to `5` (which was originally taken through the argument of `add` itself, i.e., `x`). HTH! :-)
I hadn't, but it's a good idea (note, this is just for the iteration benchmark). Old: ==68008== ==68008== Events : Ir Dr Dw I1mr D1mr D1mw ILmr DLmr DLmw ==68008== Collected : 63052374661 20647268043 12818986948 7149 157472849 29769136 4804 156468024 29345945 ==68008== ==68008== I refs: 63,052,374,661 ==68008== I1 misses: 7,149 ==68008== LLi misses: 4,804 ==68008== I1 miss rate: 0.0% ==68008== LLi miss rate: 0.0% ==68008== ==68008== D refs: 33,466,254,991 (20,647,268,043 rd + 12,818,986,948 wr) ==68008== D1 misses: 187,241,985 ( 157,472,849 rd + 29,769,136 wr) ==68008== LLd misses: 185,813,969 ( 156,468,024 rd + 29,345,945 wr) ==68008== D1 miss rate: 0.5% ( 0.7% + 0.2% ) ==68008== LLd miss rate: 0.5% ( 0.7% + 0.2% ) ==68008== ==68008== LL refs: 187,249,134 ( 157,479,998 rd + 29,769,136 wr) ==68008== LL misses: 185,818,773 ( 156,472,828 rd + 29,345,945 wr) ==68008== LL miss rate: 0.1% ( 0.1% + 0.2% ) New: ==60732== ==60732== Events : Ir Dr Dw I1mr D1mr D1mw ILmr DLmr DLmw ==60732== Collected : 23897800697 9293361110 4772238231 6165 26131968 11733332 4572 25953004 11680605 ==60732== ==60732== I refs: 23,897,800,697 ==60732== I1 misses: 6,165 ==60732== LLi misses: 4,572 ==60732== I1 miss rate: 0.0% ==60732== LLi miss rate: 0.0% ==60732== ==60732== D refs: 14,065,599,341 (9,293,361,110 rd + 4,772,238,231 wr) ==60732== D1 misses: 37,865,300 ( 26,131,968 rd + 11,733,332 wr) ==60732== LLd misses: 37,633,609 ( 25,953,004 rd + 11,680,605 wr) ==60732== D1 miss rate: 0.2% ( 0.2% + 0.2% ) ==60732== LLd miss rate: 0.2% ( 0.2% + 0.2% ) ==60732== ==60732== LL refs: 37,871,465 ( 26,138,133 rd + 11,733,332 wr) ==60732== LL misses: 37,638,181 ( 25,957,576 rd + 11,680,605 wr) ==60732== LL miss rate: 0.0% ( 0.0% + 0.2% ) 
First tried in c++11 compiler, didn't work. Had to explicitly specify param type and std::function as return type to get it work :P
`auto` parameter types for lambdas is a C++14 feature.
What's changed to make overloaded lambdas work? Looks to me like it creates a class that just inherits from all the lambdas you pass it. This makes unrelated bases with the operator() overloaded, which is the same as having unrelated bases with fun() overloaded. This should fail: &gt; If the resulting set of declarations are not all from sub-objects of the same type, or the set has a nonstatic member and includes members from distinct sub-objects, there is an ambiguity and the program is ill-formed. Otherwise that set is the result of the lookup. http://crazycpp.wordpress.com/2011/03/28/name-resolution-and-overloading/ Name overloading doesn't work if the derived class isn't declaring all the overloads itself. This rule would have to change in C++11/14 for the proposed code to be OK.
If it works, it'll be commercial closed-source since the approach I'm using is a bit like a magic trick -- it's obvious once you know how it works. My window of opportunity will be rather brief.
Yea, he's missing a `using` statement. It actually needs to be something like this: template&lt;class...Fs&gt; struct overload_adaptor; template&lt;class F, class...Fs&gt; struct overload_adaptor&lt;F, Fs...&gt; : F, overload_adaptor&lt;Fs...&gt; { typedef overload_adaptor&lt;Fs...&gt; base; template&lt;class T, class... Ts&gt; overload_adaptor(T head, Ts... tail) : F(head), base(tail...) {} using F::operator(); using base::operator(); }; template&lt;class F&gt; struct overload_adaptor&lt;F&gt; : F { typedef F base; using F::operator(); template&lt;class T&gt; overload_adaptor(T f) : F(f) {} }; 
Very interesting talk. Just made me rethink how I'm doing things in a repository. I can still use a unique_ptr to imply the repository is a sink, and then unwrap it and push the object into a vector to get the benefits of contiguous memory. I didn't realize until now that the vector would handle the destruction of objects placed in it. I thought I *had* to use a unique_ptr to ensure proper cleanup. I need to take a closer look at the STL and my assumptions.
Check out answer to Q8 in Q &amp; A page at gamedev.net: http://www.gamedev.net/index.php?app=forums&amp;module=forums&amp;section=rules&amp;f=15
Fair enough, then.
Edit: Ignore this, left here just for posterity. Got access to a C++14 compiler over lunch and verified it does exactly what I expected. I don't have a C++14 compiler handy to test this out. Since this creates a closure, can we do the following: auto add5 = addf(5); add5(4); // 9 ? I feel like the answer is obviously yes, but want to check to be sure. I know I have done something similar in the past with std::bind.
Its a good video. Glad you liked it :)
It's going the other way that I'm using `lexical_cast`, because the C++ standard library does not have a zero-allocation `std::atol`/`std::atoul`/`std::atod` that works with strings that are not null-terminated. I would definitely appreciate help on getting that working, though...just fork and shoot a pull request if you'd like.
Bjarne's original design required you to pass in the size: int *ptr = new int[5]; delete [5] ptr; Personally I think that would have been better.
Can you elaborate in this? I'm decent at C++ but I cant wrap my head around that sentence.
I'm working on documentation ever so slowly which should solve that issue.
Do you have chapter and verse for that? You can't just throw a compiler at C++ to verify your interpretations of the standard. Comeau makes a decent check, but they all fall short on something. I'd expect that if the rule doesn't apply to operator() then the standard would specifically say so.
There is no such thing as a "race condition that does not matter". It is Undefined Behavior and anything can happen. E.g. an optimizing compiler can act under the assumption that your program is race-free, and transform it into something you didn't intend at all.
After getting a C++14 compiler I feel about the same about auto lambda as I do about lambda to begin with: can't stand life without it. 
The problem is not that the end result could be different because of timing. The problem is that the code has undefined behavior, and is therefore not a valid C++ program at all and the compiler may do all sorts of crazy things to it.
Why not? [cppreference.com](http://www.cppreference.com) is a good starting point. The most important thing about the STL is to know how algorithms &amp; container work together. Algorithms always work with iterators, which is a generic interface. Build your own data types (classes) with iterators and use STL algorithms. There's a lot to learn from the whole design and implementation of the STL.
I guess I must be going blind in my old age -- where is the race condition?
There are many sorting algorithms that meet the complexity requirements of `std::sort`, so your implementation might already be smart enough to perform fairly well when adding items one at a time to a sorted list. See: http://stackoverflow.com/a/14549428/365496 and slide 54 here: http://llvm.org/devmtg/2010-11/Hinnant-libcxx.pdf
Global variables still have their constructors and destructors called, so you can still tie a resource's lifetime to a global object using RAII. There are ways to skip the destructors for global variables, however, such as calling `exit()`. And of course global variables are still generally a bad idea.
Notifying a condition variable while the associated mutex is locked in the caller is just giving the scheduler unnecessary workout.
Yeah, he's describing what the removal of concepts was like. People insisted that the design of the feature was broken and the feature needed to be removed or it would impose a large burden on C++ users for a long time. He's saying that there was no dramatic debate at this meeting like the earlier one over concepts.
When you have multiple threads running, there is always a "race condition" as their execution might happen in any order. Jobs finishing in non-deterministic order does not automatically cause undefined behavior in the sence that it is defined in the standard.
It's more of a conceptual point: An empty string is a string that contains no characters, but is nothing special besides that. Null on the other hand has the semantic meaning of “there is no string at all (not even an empty one)”. It is somewhat like the empty set being not the same as the set containing exactly the empty word.
I would strongly recommend that anyone interested in lock-free algorithms watch Herb Sutter's video titled "Atomic Weapons". I think that it is crucial to have a strong understanding about how relaxed atomics work in C++11 to write portable and maintainable lock-free code. His effective concurrency series is also a great read, and one of the articles goes through the implementation details of a lock-free producer-consumer queue. The benchmarks he gives in this article do a great job of illustrating what to optimize for and how to do it. I am anticipating the release of his book with the same title. See also the articles regarding lock-free algorithms on 1024cores.net. The author has a lot of experience writing lock-free code, and he shares many interesting insights in his articles. I have not had the time to through many of these articles personally, but I would be interested in seeing what others have to say about them.
Race conditions aren't illegal according to the standard. *Data races* for non-atomic variables **are** illegal. His code does not have any data races.
No. It doesn't have undefined behavior. He does not have any *data races* on non-atomic variables.
Can anyone explain how, in the Type Switch example, "test(b)" calls the Derived version?
In particular, [an introduction to lock-free programming](http://preshing.com/20120612/an-introduction-to-lock-free-programming/) is a good overview. Ulrich Drepper's [what every programmer should know about memory](http://lwn.net/Articles/250967/) is also a good read regarding modern memory architecture.
Looking good!
short answer is dynamic_cast. Long answer is that a lot of template machinery is hidden the match(p)(...). It basically casts b to each parameter type of the lambda. The first successful branch is taken. This machinery kicks in only if the static type of b and the target type is polymorphic. See std::is_polymoprhic. Please see http://coliru.stacked-crooked.com/a/707d9bfd2d1c11f6
Preparing second part of this article.
What you are calling a "non-critical race" is called "non-determinism" in most of the literature on parallel C++ programming. I.e. in your example the meal tickets can be interleaved. I find it rather confusing to call this a race, even though Wikipedia uses this very broad term. But you're right, your program is data race-free in the sense of the C++ Standard.
c++ if for harcore I think nowadays Am moving stuff to golang cos its much simpler and does same capers for web services and alike And this will probably get seriously downvoted
Uh ... I just get: &gt; SQL Error: Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) at /www/kukuruku/engine/modules/database/Database.class.php line 72 &gt; Array ( [code] =&gt; 2002 [message] =&gt; Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) [query] =&gt; mysql_connect() [context] =&gt; /www/kukuruku/engine/modules/database/Database.class.php line 72 )
Sorry, reddit killed the server. 
&gt;but the program will actually allocate much less because the "1024\*1024\*1024\*5" expression is of the int type. It will result in an overflow, and the expression will evaluate to 1073741824 (1 GByte) Isn't [int overflow undefined behaviour](http://en.cppreference.com/w/cpp/language/operator_arithmetic#Overflows)?
I am actually going through the first edition right now. I am by no means a C++ expert, especially since I learned how to program with Python. The book can be a little wordy at times but Stroustrup has a very careful attention to detail that I don't see too often. There are loads of exercises and examples. Probably my major complaint about the book is sometimes I wish he would put a command in bold and as a header for easier reference but highlighters and sticky notes do that pretty well. Definately for the beginner but great for that purpose. 
I don't know - I'd expect a game networking library to be about a semi-reliable system built on udp, data replication/reflection, bit packing to minimize bandwidth, bandwidth tracking, extremely cross platform, etc. Once you get beyond that sort of those domain specific areas, you start hitting very general server communication often built on top of RESTful service interaction. That seems more typically enterprise than game domain.
Does a char* to an empty string point to a literal null terminator?
It is, formally speaking. Allocating only 1GB is one possible output, though in this precise case I would be hard-pressed to come up with other plausible ones.
If you want to get into modern C++, please stay away from Digital Mars C++. Is is ages old and doesn't even know something like C++11 exists. All normal compilers will produce code without any dependencies (except maybe C++ runtime) and will work on Windows 8.1. Personally, I would stay away from anything older than G++ 4.7 or Visual C++ 2013 since anything older will be pretty much useless for developing using features from C++11 (and C++11 is really a different language to C++03). For begginners I would recommend http://nuwen.net/mingw.html , which is a MinGW distro with Boost integrated, so you don't have to worry about compiling it. You just extract it and you are set to go develop stuff.
You realize this is a C++ reddit right?
Looking forward to this book. Bjarne is an incredible writer.
You might have better luck asking in one of their C++ forums at the [D Programming Language Discussion (beta)](http://forum.dlang.org/). The C++ forums are there, despite the name. Scroll down close to the bottom.
Good to see this being released, given that it uses C++11 and C++14. There is so much in C++11/14 that simplifies C++, especially for those new to the language.
Relying on undefined behaviour is dangerous. It's not safe to assume anything about the result of running the program. You could have [`-ftrapv`](http://gcc.gnu.org/onlinedocs/gcc-4.0.2/gcc/Code-Gen-Options.html) on your gcc command line and `SIGABRT` is generated on overflow. Maybe signed integers saturate on overflow and equal `std::numeric_limits&lt;int&gt;::max()` or maybe the whole thing is optimised out - who knows? I also don't like the assumption in an article on cross-compatibility that even if that expression was defined and `int` wrapped like `unsigned int`, that the system uses a 32-bit, unique representation for `int`s. I'm surprised that none of this was brought up when this article was published.
If you are using a string-literal: Yes: char* foo = ""; assert(foo[0] == '\0');
Thanks! That makes perfect sense.
Will do, thank you.
This seems needlessly overcomplicated just to avoid noncontiguous allocation of polymorphic objects. vector&lt;Rect&gt; rects; vector&lt;Circle&gt; circles; vector&lt;Square&gt; squares; // fill up rects, circles, and squares with your objects. vector&lt;Shape*&gt; shapes; for (auto&amp; x : rects) { shapes.push_back(&amp;x); } for (auto&amp; x : circles) { shapes.push_back(&amp;x); } for (auto&amp; x : squares) { shapes.push_back(&amp;x); } This also creates a separation of concerns. One set of vectors responsible for memory management and the polymorphic vector for providing a view to your objects. And now because we have separate vectors dedicated to memory management, our code will be cache friendly as we traverse the *shapes* vector since each other vector will fill its own cache line.
I don't know why you're assuming order doesn't matter.
You can still maintain order. It's perfectly possible to add the object to the appropriate non-polymorphic vector at the same time you put it in the polymorphic one. I was simplifying for the sake of the example. Regardless, I was responding to the OP's "real problem" (as stated in his blog post): &gt; As a side note, the normal way to do this is to create a std::vector&lt;Node*&gt;, or perhaps a smart pointer version of that. **I didn't want to do that because I didn't want separate memory allocations for each element of the vector.** P.S. Your comment would be much more constructive if the your criticism of the content of my post wasn't phrased as a personal attack. I.E: "The problem with your solution is that it ignores ordering."
Iterating over all items of each type individually is friendlier to the icache and branch predictor, since you end up calling a single virtual function a bunch of times in a row before moving on to the next one rather than switching between them.
Not to dismiss Digital Mars at all, but if &gt; I like that it still works even on Windows 8.1 an generates executables without any dependencies except the Windows-API is your main motivation then you should know the same applies to VC++ and MinGW.
When did VC++ lose the dependency on msvcrt? 
You've always been able to statically link the runtime.
You know, to the uninitiated this whole thread would be akin to reading /r/vxjunkies
It's almost like complaining that this is unreadable: void main(){const char* str="Hello World"; for(int i=0;i&lt;11;++i)printf(str[i]);} 
I can only hope the average reader of /r/cpp is initiated. C++ is a complex language that runs on complex machines where reasoning about performance is almost a black art. The uninitiated have their work cut out for them. As one example: http://www.altdevblogaday.com/2012/05/20/thats-not-normalthe-performance-of-odd-floats/ Another example of surprising behavior thanks to the hardware you're running on: https://www.youtube.com/watch?v=YQs6IC-vgmo Finally, a rant on the perils of ignoring how hardware works: http://queue.acm.org/detail.cfm?id=1814327 Many applications can ignore all this—it only really matters if performance is critical. If performance is critical, though, a lot of crazy things that used to be irrelevant suddenly matter. It may all look like moonspeak to some, but there's reason behind it.
Why do small executables really matter when you are targeting windows 8.1, the most bloated sloppy OS going.
I'm not targeting anything specific. But it is nice to see that a somewhat old compiler still produces executables for a modern OS (without commenting on the quality of the OS) without any issue, at least for simple examples. We target the Windows platform at work so I'm not really in a position to choose something else.
your code doesnt run &gt;[ink@mtz ~]$ gcc t.c -std=c99 &gt;t.c: In function ‘main’: &gt;t.c:4:1: warning: passing argument 1 of ‘printf’ makes pointer from integer without a cast [enabled by default] In file included from t.c:2:0: /usr/include/stdio.h:362:12: note: expected ‘const char * restrict’ but argument is of type ‘char’ &gt;[ink@mtz ~]$ ./a.out &gt;Segmentation fault &gt;[ink@mtz ~]$ 
If you are doing it for work, then I would strongly prioritise using well established tools than underdogs. If you want a really good code-gen for windows look at the Intel Compiler.
I never said it would. And it's pretty obvious why it wouldn't, especially with that warning the compiler gave you.
Just made a test file with iostream in VS2013 Premium and the executable is 11.5Kb. http://i.imgur.com/gkMRABh.png And with cstdio it is 6.5Kb http://i.imgur.com/nawNLOP.png You sure you are not compiling in debug?
Just put template&lt;typename T&gt; using ptr = T*; somewhere and after that write this: ptr&lt;int()&gt; function_returning_int; ptr&lt;void(int)&gt; function_taking_int; Even complex types stay relatively readable: ptr&lt;ptr&lt;int(char)&gt;(ptr&lt;float()&gt;, ptr&lt;void(int, char)&gt;&gt; var; But in general use std::function instead of above `ptr`. Anyways another case where C-criticism cannot really be applied to C++.
Which is a nice experiement in and off itself :)
Ah yeah if you **need** to static link the VC++ Runtime then it is never going to be less than 100Kb
I will admit I have no benchmarks to back this up, but it seems to me that the two areas where dynamic, JIT'd languages have the most pronounced potential performance advantage over C++ are heap management (available GC makes many allocations a simple pointer increment) and the ability to dynamically inline through polymorphic calls, with all the usual further optimizations that inlining allows. If heap allocation is a problem for you, C++ provides usable if somewhat awkward mechanisms (STL allocators, placement new) to ameliorate it in a general way. But AFAIK, there's no general solution to the limitations polymorphism places on inlining other than static de-virtualization and profile guided optimizations (Visual C++ can apparently profile for "hot virtual calls", not sure about gcc or clang). Of course, in the general case the compiler has to deal with a pointer to an instance of a polymorphic class that could have come from anywhere. But in my experience it's often the case that the class definitions for all actual instances are known at build time. I wonder if there's a practical limited form of "optimistic" inlining that could be supported by the language or a sufficiently smart compiler. Something less awkward than an RTTI-based conditional cast.
Nice :) But it would be even nicer without the need for iod_define_attribute()
&gt; not sure about gcc or clang gcc 4.9 has a lot of new devirtualization optimizations, including speculative devirtualization. That turns code like this: PolymorphicBase *ptr = ....; ptr-&gt;memfunc(); into PolymorphicBase *ptr = ....; if(ptr's vtable slot for memfunc points to &amp;CommonDerived::memfunc) { (&amp;CommonDerived::memfunc)(ptr); // direct call - can be inlined } else { ptr-&gt;memfunc(); } The choice of which derived class to choose (here `CommonDerived`) can be made based on analysis of the hierarchy, or through profile guidance.
Yeah, I'd use `typedef`s, but you're missing the point of the article. What declaration syntax do you find nicer? Are you going to decompose only `typedef`s? Why not decompose everything, like so: bool less_than(int lhs, int rhs) { if (lhs &lt; rhs) return true; else return false; } The above code is freaking awful, because we can compose expressions beautifully: bool less_than(int lhs, int rhs) { return lhs &lt; rhs; } Why cannot type declarations be composed so beautifully? Do you really think...? I give up on you. You just missed the point of the article.
iostream pulls in a lot of stuff. Minimal cstdio + vector is 60kb. Under 100 kb is possible depending on what the tool needs to do.
I don't like the assumption much either :)
Sorry yeah I should have specified I meant iostream statically linked to vc++rt. 
First, I want to mention that it's only copy construction and the like that is searching all of the subclasses. Regular method calls don't do that and should be O(1). I'm not sure I completely understand what's going on in that code. And it doesn't seem like you ever set _index to a value, so I suspect there's at least one bug. But it seems similar to how I was doing constructors a few revisions ago, see [this version](https://gist.github.com/tringenbach/10013369/fadfba5485f9d2bb301f6c02eecd043c7d8ccc96), in particular the variable named copier. But I didn't like wasting the extra pointer (or really, it would need to turn into at least 2 and maybe 4 extra pointers for copy, move, assignment and move assignment). Keep in mind, the only time emplacer searches the list of types is for copy/move construction and assignment. It only does this because constructions are not allowed to be virtual in C++, but it needs to run the copy construction of whatever it has stored. For regular method calls, emplacer does a reinterpret_cast to the abstract base class (which is always safe because it only allows itself to hold subclasses), and then lets C++ handle the dynamic dispatch exactly the same as if it hold a pointer to the base class. I had considered doing something like what I did in the linked commit, but storing it as a static class member. But I was worried about multithreading issues. Although maybe if I could make the initialization only happen once so that I only had concurrent readers, that wouldn't be an issue.
Fair point, but when someone comes along and needs to change the declaration they still need to be able to parse it. K&amp;R C had to spend a fairly long time on C declaration syntax. Go was an opportunity to simplify this. That being said, I'm not sure why this was posted here all of a sudden.
Regarding those new optimizations, the developer wrote a full serie of blog articles talking about them, which I posted [here](http://www.reddit.com/r/cpp/comments/23rjda/honza_hubi%C4%8Dkas_blog_devirtualization_in_c/) on reddit 2 weeks ago. Very interesting (I found).
type aliases make it possible to compose types using a similar left-to-right style in C++: template&lt;typename T&gt; using ptr= T*; template&lt;typename RetT, typename... Args&gt; using func = RetT(Args...); ptr&lt;func&lt;int,int,int&gt;&gt; fp; ptr&lt;func&lt;int, func &lt;int, int, int&gt;, int&gt;&gt; fp; ptr&lt;func&lt;func&lt;int,int,int&gt;, func&lt;int, int, int&gt;, int&gt;&gt; f; I think that compares well with Go's `f func(func(int,int) int, int) func(int, int) int`.
Looks cool. One minor point is that it looks to me that perfect-forwarding isn't being utilized. For example, iod should be: template &lt;typename ...T&gt; iod_object&lt;T...&gt; iod(T&amp;&amp;... args) { return iod_object&lt;T...&gt;(std::forward&lt;T&gt;(args)...); }; Note the use of std::forward as well as T&amp;&amp; to properly have things collapse to r-values/const lvalue&amp; as needed.
I don't find it any more or less unreadable than a function declaration. It's different from other declarations, sure, and if you don't see function pointer/pointer-to-member declarations that often, then I can see why they'd be confusing, but after you've seen enough of them they -- like other declarations -- are (in my opinion) perfectly understandable. It's when you start nesting them that they become problematic, but that's true of many things, I mean consider nested templates, or pretty much anything involving `std::enable_if`.
A type with a templated `operator()` as shown in the accepted answer behaves in the same way. The author of the linked answer seems to significantly misunderstand how templates work, as the paragraph explaining what is happening is almost entirely nonsense.
Do you know any resources on EXACTLY what the memory is doing during a move/foward? I feel this is a serious hole in my knowledge. All the descriptions I hear about move/fowarding are just airy-fairy like 'it rips the guts out of it'.
I'm going to go ahead and second this request. In the contexts I've heard it, "perfect forwarding" almost sounds like a buzzword- no definition has been given (or even a plain explanation as to why it's useful), so I'm just totally lost. As for a move, by default, it will simply assign the values of an object to a new object and overwrite the first object's values with default ones. This doesn't matter for objects that don't do memory management, but for those that do, it means avoiding an allocation of equal size and copying over the contents of a dynamic array or whatever is being managed- it simply assigns the pointer value to the new object and sets the old object's pointer to `nullptr` without using `delete` on it (usually). The best example is `std::vector`. If you've got a vector that has allocated 10,000 bytes for whatever reason (game vertices, colors, etc?) inside a function and you want to return it, you wouldn't dare copy that- it would take way too long. Instead, you simply move it, essentially taking any managed resources from the first `vector` (allocated in the function) and put it in the second `vector` (outside the function). Since it's simply a pointer to the data, probably just 8 bytes, it's *way* more efficient than copying.
Would something like that even be possible? 
You might be interested in google's `double-conversion` library which is very performant and used by facebook's folly library for JSON parsing as well as v8/chromium. Of course that adds some dependencies which are not fun to deal with 
that named parameter business is very very neat, thanks for posting that
I like double-conversion as a library, but the dependency issue is worse with it. `boost::lexical_cast` is header-only, so I'm not forcing any run-time dependencies on potential users. `double_conversion::StringToDoubleConverter::StringToDouble` has *exactly* the semantics I want (minus the use of `int`s to describe length instead of `std::size_t`), so it might all be worth it.
Perfect forwarding/moving refers to a number of related elements, mostly compile time. There's the behavior of rvalue references (and, by extension, the behavior of references in general) as well as the behavior of move construction and assignment. Now, granted, I don't know how references are implemented in general, as I haven't studied that much compiler design. I usually assume that they're just pointers under the hood, with some extra machinery compiled in to handle destructor calls when necessary. However, you could conceivably implement rvalue references as a pure stack variable, depending on the call sites. The "reference" "r/lvalue" parts are part of the type system, and therefore only manifest at compile time; in the case of references, it'll mean adding extra stack space for temporaries and adding destructor calls to remove them. So, the space overhead for using any kind of reference, BEFORE optimizations, is a pointer on the stack plus sometimes a temporary on the stack, and the runtime overhead is sometimes calling a destructor, though the decision about whether to call a destructor is made at compile time. The other part of rvalue reference- actually performing a "move," as opposed to a "copy," shows up when you define a separate move constructor, and is basically just a normal function overload. It isn't perfectly free, as it has all the normal overhead of a function call (along with all the opportunity for inlining and other optimizations.) Where the move becomes significant is that usually moves apply to objects for which "copying" implies copying a large amount of data, whereas "moving" implies only copying a few pointers, which is a blindingly fast operation on all CPUs. That's my layman's explanation; feel free to send additional questions, or point out if I'm totally wrong about anything.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2002/n1385.htm defines the forwarding problem and covers the (ugly) attempts at solving it in C++98. "Perfect" forwarding is simply a refinement where all of the "almost the same"s become "exactly the same",
Rules of Optimization: 1. Don't do it. 2. Don't do it yet. 3. Don't do it again. Amazing how many different ways you can apply those rules effectively. 
On a completely unrelated note, in the "Overview of the library" the line std::string json_string = R"json({"name":"John", "age": 12})json"; It was the first time I noticed you can enter text before and after the raw text ( i.e. : json), or as the standard calls them delimiters , can any one tell me why would I need them? the same line could be written as: std::string json_string = R"({"name":"John", "age": 12})"; And it will give the same results.
Hooray, now I can stop writing my own is_sorted&lt;&gt; every time I touch a new codebase.
Nah. &gt; In established engineering disciplines a 12% improvement, easily obtained, is never considered marginal and I believe the same viewpoint should prevail in software engineering -- Knuth Optimisations are often necessary and are often far too low hanging to ignore. Furthermore, the 'optimised' code is often the same as 'good code' (IE clean algorithms are generally more efficient than messy algorithms). And if something is suitably low down in the stack but a lot of time is spent there it absolutely makes sense to optimise (think OS functions, or BLAS). Silly one liners like "Don't do it" aren't helpful.
When does one ever need an is_sorted?
Well, it's a hell of a lot cheaper than just calling sort() if you strongly suspect the collection is already sorted. There are also cases where you can't justify the cost of a sort, but you can justify the cost of *checking* if it's sorted so that you can use a more efficient algorithm.
I've used it a couple of times in assertions for sanity checks. E.g. if you have a sorted vector which is acting as a map, and you insert elements into the right spots using binary search to find the positions, this can double-check that your insertions do result in a sorted vector.
&gt; Furthermore, the 'optimised' code is often the same as 'good code' If you think the old code is ugly and want to replace it without too much politics, making a clean fast version can also be done in a great way by saying “And besides, it's twice as fast”. 