Oh! That's clever. Would never have thought of taking advantage of short-circuit evaluation like that.
All they've done is to compact the EH tables, so less space is used, and thus less cache pressure, so it runs faster. Otherwise the mechanism is identical (indeed individual functions can be told to use the old table format), and remains non-deterministic.
Oh, you must be using it on Windows? When I was using it on windows it was unbearably slow
&gt; "these comments suck!"
Now that's some interesting topics!
Ok I just tested a bit and lldb does seem nicer, for one it's able to start the program much faster than gdb, and the defaults seem more sensible. I kinda want to migrate my tooling to lldb now...
IRC, it had better support for C++ constructs.
Thanks. I experimented a bit with ways to try to simplify the output when there are many messages (for the regular textual output), to try to reduce the "wall of text" effect, but I didn't come up with anything I was happy with. I hope to revisit this in GCC 10 though. Currently (as in GCC 9) the messages support just one level of nesting (parent+children); perhaps I need to extend it to support deeper nesting? (not sure, but your comment got my thinking)
If it was possible to start gcc in TUI mode (or piping the output to a TUI program), even the regular text output wouldn't be an issue.
To give you an idea of the issues I get on a regular basis: I've got deeply nested templates with return type expression SFINAE, and whenever I get a substitution failure, it gives me all the possible overloads that failed, and why they failed (think hundreds or thousands of lines of substitution failure errors for a single call in some of my tests). They often failed because of substitution failure in functions they tried to call, so I also get the list of overloads that were tried and failed for those functions, etc. But everything is flat and at some point it's extremely difficult to know whether the substitution failure happened when trying to call the top-level function or some function at any level for which overload resolution failed. That would be my main use case for foldable error messages, and would indeed need to support an arbitrary level of nesting in error messages.
I already noticed your work 1 month ago when I was playing with gcc9 (to have some nice C++20 features than were just release) and I really liked the new annotations.
Awesome! The JSON format and the improvements to optimization info are particularly exciting
&gt;There are now fix-it hints \[...\] for when the compiler needs a typename [It's amusing that the programmer knows that it's a type and the compiler knows that it's a type, but the ritual shall be followed nevertheless](https://i.imgflip.com/2vj8hh.jpg). &amp;#x200B; [Good news](https://gcc.godbolt.org/z/qWUOgt) though.
No worries, I think I know what you mean. We have a few bugs open for this kind of thing e.g. https://gcc.gnu.org/bugzilla/show_bug.cgi?id=88512 I think the consensus is that when template substitution fails, we do want to show all of the information about the failure - but maybe there are ways to format it and present it to that make the information easier to "grok" (if you will). Maybe some special-casing is applicable here, too? Ideas welcome. Sounds like I should implement arbitrary nesting (at least) for GCC 10.
When I tried rust for the first time and the errors didn't have highlighting (unlike the examples in the article) they looked like a ton of noise and I actually wished for C++ errors. However, with the highlighting as in the article, it's definitely more readable than what we have today.
Yes, that's one path of solving it. However, with module scanning, there may be optimizations you can take to avoid expanding *all* macros since, with some smarts, you can determined "this macro can't possibly create an `import` or `export`" and skip that expansion. For details on the general strategy, please see D1483R1 ([mirrored here](https://mathstuf.fedorapeople.org/fortran-modules/fortran-modules.html)).
Cygwin and use Linux software, darwin for Mac. It's fast to compile all in Linux.
C++ errors without highlighting also look like a bunch of noise to the uninitiated. I think one just becomes accustomed to knowing where to look, after a while. 
Do the json output support emmiting both type of output? Like the IDE would output the normal output in the console, but consume json error from the blob for a single build.
As a rule, I forbid copying objects involved in public hierarchy. This solves slicing, and save time that we don't spend in doing things that are never used/needed
I don't know how to make it any simpler than the fact that FoodFactory.cpp has to include Burrito.h. That's quite literally the first block of code in the article. This is not possible if FoodFactory.cpp is in the library and Burrito.h is with the user. You still haven't addressed this very simple point, and only keep discussing whether Burrito shows up in FoodFactory's public API. As I explained, that's not always good enough. &gt; Yet you continue to fail to even come up with a good motivating use case for it. Meaning, not only do you not understand the pattern, but unable to see that your "expert" programmers may not be as expert as you think and you've mislearned to accept bad design as good design. Nope, I have explained the use cases to you several times. You're just so used to solving the problems you're solving (my guess: you've only worked on codebases where base, derived, and factory, are all owned by the same person), you have trouble seeing every other one. Fundamentally, the fact that the modern factory allows you to invert dependency between the factory and the derived, is a pretty simple idea, it's been recognized as being sometimes necessary as early back as the 90's. That's why you have smart people in the C++ community (Andrei, Herb, Scott, etc) writing about it. It doesn't mean it's always the right solution. But the fact that you think it's never the right solution, just shows a lack of understanding on your part. Do you really think there's some key point that you understand here, that all these guys have missed, that invalidates ever using the factory pattern? Believe me, there isn't. 
They keep pumping up this whole safety thing with no evidence that it actually works in practice lol
The compiler doesn't always know it's a type. It's likely to be but in unusual cases may not be.
[removed]
An equivalent to g++'s "-fno-enforce-eh-specs" perhaps.
Right now it can only do one: if you choose -fdiagnostics-format=json it emits JSON to stderr instead of the regular textual output on stderr. Should it be to a file instead?
If both need to be done at once, it seems like a reasonable solution.
Here, you dropped this: /s
This looks very nice. It should helps a lot. The only thing I often miss on the errors is a number like error messages from databases or visualc. It's really easier to search for explanations on blog or stackoverflow with a code than using the text message. 
 YouTube
Clang is compatible with MSVC's ABI, no other compiler is close.
Pipe to a file and then open that file in your editor of choice.
Very valid point about static by default and no tests by default. Thank you. Will also modify example and add all namespaces in it and mention what headers to include.
&gt; AFAIK, there are no outstanding features that lldb has and gdb misses. lldb can execute whatever C++ code you throw at it at runtime, gdb is in my experience more limited in that regard (lldb) expression Enter expressions, then terminate with an empty line to evaluate: 1: class foo { 2: foo() { printf("whatever\n"); } 3: }; 4: foo f; whatever 
Who's they?
These helped when i was learning a bit of c++ https://www.learncpp.com/ https://www.youtube.com/playlist?list=PLAE85DE8440AA6B83 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ayrfrg/learning_c/ei2sh7p/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ays24s/c_semi_beginner_book/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Does LLDB support Python scripting too?
Think at a larger scale, windows update/Google chrome distributes binaries to millions of people. That's serious money going just to bandwidth. What if they could reduce their installer size with this? 
Thanks for the response. I don't implement any IDEs, but I thought this might be useful for them? Outputting the JSON in a file might be useful too. I imagine the normal output in the build console then annotations in the GUI to help me inside the text editor. Also, thanks for the hard work, the new errors look gorgeous!
You just untied it from Qt, but do you have any plans to add a convenience method to go from QObject* + signal to future, like [asyncfuture](https://github.com/benlau/asyncfuture)'s observe method?
So it is something like **Future&lt;T&gt; static fromQtSignal(QObject \*sender, Signal &amp;&amp;signal)**, where Signal is reference to signal in sender with one param T (or in case of many arguments in signal it should be tuple of them)? It should work like one-time connect, right? Seems like a useful and valid thing to add and shouldn't break Qt optionality, thanks for the idea.
For your use case, maybe.
I could effectively pipe the output in vim, and use folding, but I don't think it would be an optimal workflow. I was thinking more of something were you get only top-level errors, and you can navigate with `&lt;Up&gt;` and `&lt;Down&gt;`, and open/close each fold with `&lt;Right&gt;`/`&lt;Left&gt;`.
Yeah, exactly. I'm not sure what the best type for Signal should be, asyncfuture just uses a template parameter (see [here](https://github.com/benlau/asyncfuture/blob/master/asyncfuture.h#L1412)). An alternative might be to mirror the type signature of connect to ensure at compile that the types of sender and signal match.
I typically make my factories return a unique_ptr. If someone wants a shared_ptr they can specify it but when you return a shared there is no way to go back to unique.
Followup PSA: Use `gsl::not_null&lt;T&gt;` wherever you are taking a parameter that should not be null. 
There is one! `gsl::not_null&lt;std::shared_ptr&lt;T&gt;&gt;`. If that's too verbose, use a templated `using` declaration to give it a shorthand convenience name. 
One of UB's many possible manifestations is the _appearance_ of things working correctly, but UB == illegal code, period.
What is expansion statement? I didn't heard about it. 
Very nice work! Compiler messages are complex and underappreciated things.
I see. So what would a proper routine be for the rule ”keep the program alive until onClose is triggered”?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/aytk4l/how_to_enable_blur_behind_window/ei35mp6/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Refinitiv hiring in St. Louis, MO: [https://jobs.refinitiv.com/ShowJob/Id/216956/Senior-Real-Time-C-Developer/](https://jobs.refinitiv.com/ShowJob/Id/216956/Senior-Real-Time-C-Developer/) [https://jobs.refinitiv.com/ShowJob/Id/204721/Lead-Software-Engineer/](https://jobs.refinitiv.com/ShowJob/Id/204721/Lead-Software-Engineer/) [https://jobs.refinitiv.com/ShowJob/Id/199764/C-Senior-Software-Engineer/](https://jobs.refinitiv.com/ShowJob/Id/199764/C-Senior-Software-Engineer/) &amp;#x200B; &amp;#x200B;
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ayoij5/cross_compiler_from_windows_to_linux_and_mac_osx/ei36t5y/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You must follow the template. I have removed your post until you correct this.
Yes, I was trying to make that point :)
&gt; and Elm, which is where I believe Rust took theirs from They did.
Ah, I didn't know. :) Thanks!
 \*\*Company:\*\* Refinitiv \*\*Type:\*\* Full Time \*\*Description:\*\* Refinitiv was previously the Financial and Risk business of ThomsonReuters. Looking for experienced C++ developers to produce highly available, highly performant software for the financial services industry. \*\*Location:\*\* St. Louis, MO \*\*Remote:\*\* We offer the ability to work remotely part time, but jobs will be based in St. Louis. \*\*Visa Sponsorship:\*\* Yes \*\*Technologies:\*\* Different teams have different requirements, from C++11 all the way up to C++20. Development ir predominantly Linux based, so Linux familiarity is a plus, but not required. \*\*Contact:\*\* Interested parties should PM resumes to me
Right, that's why I'd like to see a comparison in binary size- that's what changed.
Looks good except the sections are showing up with \*\*double stars\*\* instead of **bold** (I checked both Old and New Reddit). Your comment should contain two asterisks on each side to activate bolding. In the template, I escape the asterisks with backslashes so people can see what they need to type (maybe you used Reddit Enhancement Suite or something to access my original markdown).
How could you even possibly say that unless you literally don't know anything about the language? Segfaults when in developing C++, are a matter of course. Segfaults in Rust are literally compiler bugs.
Slides (PDF): https://static.sched.com/hosted_files/devconfcz2019/c8/devconf-gccoptim.pdf Tools: - Discover optimization passes used during compilation: https://github.com/drepper/gcc-passes - Markup source code showing optimizations: https://github.com/drepper/optmark - Show optimizations enabled per optimization level: https://github.com/drepper/gcc-opt-enabled Description ([DevConf.cz 2019](https://devconfcz2019.sched.com/event/Jceh)): &gt; "To most developers compilers are opaque. They translate high-level code to machine code and flags tell the compiler to create better code. But how does this work? Why can it be done? Once a developer reaches basic understanding of optimizations the next question is: what did the compiler do to my code, why didn't it do more? &gt; This is where things get tricky. By default the compiler does not flood the user with explanations. There are ways to get to the information. This talk is an introduction into using the compiler's diagnostics to understand what the compiler does in detail and, more importantly, to learn how to possibly rewrite or restructure one's code to achieve better performance. This is especially necessary and useful when relying on auto-vectorization and -parallelization."
In C++20, you won't need typename as much as before. I've implemented [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0634r3.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0634r3.html) for GCC 9.
If there are fewer of them, there's less chance they will end up on the same pages as normal functions, in favor of other, normal functions, so less chance of page faults. The linker might already put them all together away from normal code, although I'm not sure to what extent it does or is capable of doing this under various build configurations.
I think Java's named loops are the best solution. 
The "modern" factory isn't modern. Forcing classes to inherit a class and then registering it via a singleton is literally one of the first patterns to get taught in Java. The "traditional" factory is actually the more modern form. I have addressed the point. Yes, the example has the derived header in the factory cpp. But the registering is done with the Register function, which, I keep repeating, is likely the public interface where you can use to register any old thing via a type-erased function wrapper. So while the EXAMPLE that's given has it all in the cpp file, in another code base where the factory is a library, it's OBVIOUS that you can still use the registration outside that library. You're the one who keeps ignoring this point.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ayw60s/partner_for_learning_c_pro_cons_or_pointless_your/ei3ri2c/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Do you mean like when you do :make in vim and then see the errors with :cw ?
You could mix run-time and compile-time computational quadrants if you were willing to work with an interface that returned a variant or passed the result to a continuation.
Nice work! If you’re interested in performance, I’d suggest looking at Blaze or Eigen for the Vector2D/Vector3D class; simple object oriented approaches like this create lots of temporaries that can slow things down (aside: your have a bug in you Divide by Scalar test case). I would also suggest rethinking the signature of compute_{accel,velocity,position}: 1) There are lots of large vector creation/copies going on... personally I prefer in-place updates to the state vector, even though it’s less “functional”; 2) some more accurate time integration schemes will not allow separating the velocity/position updates like this; 3) each sub-function must be called in order and leaves the solution vector is an inconsistent state, so I’d argue that conceptually it makes more sense just to consolidate them into a single function the returns a self-consistent n+1 state. Cheers! 
I wasn't speaking of that. It's a good idea, but would require the support of some plugin. What I was thinking about was `g++ foo.cpp | vim -` and then having the correct `foldmethod` and similar settings to fold the json output of gcc.
Any word on if we can finally get a flag to turn off printing 900 lines of candidates on a template substitution failure? 
It basically let's you do loop unrolling automatically
I tried using several versions of lldb on Linux a few years ago and it was crashing all the time. Literally running a program with some breakpoints and printing a value would crash. Did it get more stable recently or was I doing something wrong?
SmallVec has memory overflows in rust lmao.
&gt;**Important to note is that the equality operator==() is comparing the absolute subtraction of both vectors.** If they are equal, the result of the subtraction would be close to zero which is checked by comparing the result against std::numeric_limits&lt;double&gt;::min(). This utility template is representing the smallest possible finite value of a specific type and is part of the limits header. An alternative would be to check against relations of both values, but for the moment this would cause too many following issues, such as division by zero. **Bruce Dawson is suggesting a comparison against an absolute epsilon based value, in case of comparisons against zero, which we are doing with the std::numeric_limits&lt;double&gt;::min().** Uhh, not exactly? This is the relevant part of Bruce's post: &gt;* If you are comparing against zero, then relative epsilons and ULPs based comparisons are usually meaningless. You’ll need to use an absolute epsilon, whose value might be some small multiple of FLT_EPSILON and the inputs to your calculation. Maybe. * If you are comparing against a non-zero number then relative epsilons or ULPs based comparisons are probably what you want. You’ll probably want some small multiple of FLT_EPSILON for your relative epsilon, or some small number of ULPs. An absolute epsilon could be used if you knew exactly what number you were comparing against. * **If you are comparing two arbitrary numbers that could be zero or non-zero then you need the kitchen sink. Good luck and God speed.** You're taking the difference of two numbers and using Bruce's recommendation for comparing against zero when it's clearly the third case, comparing two arbitrary numbers.
Thanks for linking this, I hadn't seen it before. I've used a language with something very close to what Herb proposes, and I like it from a programmer perspective. You get the syntax sugar of try/catch without the unpredictability and bloat of exception handling. The downside is it's no longer zero cost in the case of a no-throw, since you have to check the return value to see if you should take the error path, but in that way it's still no worse than checking an error code.
Yes that’s true, but I didn’t want the kitchen sink;)
Thanks for your suggestions. I already had similar thoughts, but your thoughts helped. I thought also using external libraries for some parts but decided against because for my purpose it just makes more fun to implement it myself, even if it’s not as sophisticated as the library could do;)
Yes that’s true, but I didn’t want the kitchen sink;)
Thanks for your suggestions. I already had similar thoughts, but your thoughts helped. I thought also using external libraries for some parts but decided against because for my purpose it just makes more fun to implement it myself, even if it’s not as sophisticated as the library could do;)
Totally! I’ve written similar code as well just to learn how to write operators properly. Looking forward to the next articles in the series. 
this is really awesome!! thank you
Noticed the readme link is pointing to a wrong place.
I had a quick look at your readme and I must admit I found some stuff quite disconcerting, like "anti-STL, anti-piecemeal, anti-modernist", "flabbergasted at some of the modernist C++", "won't be turned into Javascript Jr. via use of 'auto' everywhere" and "we are manly enough not to be frightened by the existence of raw pointers" In any case, I'm mostly concerned about your homegrown "license", mostly this: &gt; Do not host or offer (for free or sale) any modified versions of this code base or any modified binary builds of this code base. Such things are to be used for your own private development purposes only. and this: &gt; You may also build and make available C++ libraries that are based on the official CIDLib code. If it is based on your own version of the CIDLib code, you cannot make it publically available, it must be for your own private use. Can you clarify this? Your title mentions that it is "open source", but that is probably one of the most twisted definitions of "open source" I've seen in a long time, although it's probably technically correct. In terms of CC, this would (I think) be akin to BY-NC-ND. That's basically "look, but don't touch".
That's not my link, that's an automatic one done by the forum. I'll try to make it go away. 
My understanding is that you can use it privately and commercially, but just can't publicly fork the project
It means, if you aren't using the official stuff, keep it for your own private use. The point is to avoid having multiple, incompatible and different versions out there. You can modify it however you want for use in your own application development, since only you will see that. If you want it publicly available, it needs to be based on the official build, so that it doesn't fragment into a thousand variations. &amp;#x200B;
Correct title would be: Simple implementation of explicit Euler method to solve n-body-problem. You are solving like x_i+1=x_i+f(x_i)*dt and not x_i+1=x_i+f(x_i,x_i+1)*dt. x_i is the state vector. Also you are not using a good abstraction for the solver which can be generalized.
Exactly. If you want to mangle it beyond belief, that's fine, but it has to be for your own use. That can be a commercial product. Obviously it can't be for an open source product, because it would be impossible to do that and not publicly expose your version. And that makes sense because this repository IS the open source version, and needs to remain the only one. &amp;#x200B;
You "request that any fixes or improvements at least be offered for inclusion back into the code base", but I can't fork the repo and do a pull request. Do you want patches by email?
I'm no GitHub maven by any means. But I would have thought you could keep yours private, right? &amp;#x200B;
Somehow the author gives me a bit of Terry Davis vibe. Anyway that's an impressive ammount of work and dedication to a single project.
Your license says: &gt; - Do not host in any public way your own versions of this code, in whole or in part. This repository should be the single source for the code base. &gt; - Do not host or offer (for free or sale) any modified versions of this code base or any modified binary builds of this code base. Such things are to be used for your own private development purposes only. I am confused by "This repository should be the single source for the code base", which would seem to forbid _any_ cloning. I am also uncertain what you mean by "host", since you seem to consider a public repo as "hosted", but not a private one. My reading of your terms is that I can only modify your code if it's on my machine, I'm the only user on it, and nobody's looking. I might have to buy new curtains. In any case, telling me I must keep my repos private is a non-starter for me. Good luck, though.
Thanks for your comment. I wanted to generalize it in the next posts when implementing other methods.
&gt; it has to be for your own use. That can be a commercial product I'm really confused. How does "your own use" mean "a commercial product"? Can my client have access to the source code? Or does it have to stay private? Can I allow my employees to look at it? &gt; Obviously it can't be for an open source project That's probably the first time I've seen a license that encourages commercial use and forbids the use in open source.
Usually likes are quite good in separating regular code from cold stuff. That is one of the reasons why table based exceptions are practically zero overhead when not thrown. My point is: Unless someone shows me hard evidence (I.e. a benchmark) that this change will speed up regular program execution. I'm very sceptical about performance claims.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/az149z/help_printing_a_class_array_defined_in_main/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It would be better if you would have chosen an appropriate well known license. Your fear about *fragmentation* is imho artificial: if you embrace community patches and development, nobody has a reason to fork your project and evolves its on his own. So if you would allow commercial easy use, choose the MIT license probably. If you want patches go back to you, LGPL. I think such a *self made* license is a no go for most companies, to choose using your lib. And you will get feedback and help primarily from professionals for such a project - so why riskt to loose those? Isn't getting help the most motivation for open sourcing a project? 
&gt; we are manly enough not to be frightened by the existence of raw pointers WE ARE MEN! BUGS DO NOT FRIGHTEN US!
https://wg21.link/P1306
No offense, but if you didn't want people to fork your repository, you probably shouldn't have put it on GitHub. It's inevitably going to happen, if your thing generates interest.
With modules we will be more free about this. Fewer accidental imports + no header propagation effect :)
This is **not** open source: &gt; **Usage/License** &gt; Though it is of course impossible to prevent people from abusing anything and everything for their own nefarious purposes, and though we realize that these issues are still a ways out pending documentation and such, clearly something like CIDLib will only achieve its ultimate capabilities if it remains a coherent entity. Therefore, we impose the following usage limitations: &gt; 1. Do not host in any public way your own versions of this code, in whole or in part. This repository should be the single source for the code base. 2. Do not host or offer (for free or sale) any modified versions of this code base or any modified binary builds of this code base. Such things are to be used for your own private development purposes only. 3. We would request that any fixes or improvements at least be offered for inclusion back into the code base, but we realize that's obviously not always practical if that code is commercial. 4. You may use the official builds or your own builds of this code for development of free or commercial applications of your own. You must note in the documentation that the product is built on the CIDLib code base and provide a link to this repository. 5. The previous point applies to applications. You may also build and make available C++ libraries that are based on the official CIDLib code. If it is based on your own version of the CIDLib code, you cannot make it publically available, it must be for your own private use. We would hope you do this in the context of the official code base of course. 6. You must NOT install any non-official builds in any system directories where they could be seen by other CIDLib based applications. Limit them to your own application's local use. 
Actually if you read the GitHub TOS, that's one of the only strong requirements that the website have : your code must be forkable
The license is a big NoGo for me. I won't bother looking.
&gt; 1. Do not host in any public way your own versions of this code, in whole or in part. This repository should be the single source for the code base. So if I clone this repo for my own use, but have an ssh server on my personal computer, I have violated the license? The ssh server can be accessed from any part of the world if one has the right credentials. In other words, this repo is basically read-only.
&gt; Add a cmake option to build a static lib Why would you make an option for that, if cmake has this build in? 
Ah yes, the for... I saw it in the metaclasses proposal. 
Judging by `Pushing that 'make public' button was one of the hardest things I've done in a long time` this might hurt your feelings, but... It seems you've just published a ton of 25yo not-crossplatform not-opensource not-standardized legacy. What's the purpose?
That's just not what open source means. You have us a peek at your stuff, but forking is part of the core ideas of open source.
Why not just take a reference?
Congrats on the first step of open sourcing your life's work. I think your fears of forking and competing codebases are overblown. First, nobody is going to maintain their own slightly modified 400+ kLOC codebase. It took you 25 years to write, it's gonna take someone at least 25 months to understand what it does. Second, the most likely contribution that you are going to get is a pull request. And guess what, the preferred way on GitHub is to a) to fork, b) to make your own changes and c) send a pull request to have it merged. If you don't like the merge, you can reject it or suggests changes. BTW, you should put up a formal license in your repo and cite that license in every source file.
This is not just not open source, it is basically unusable for anything with these licensing terms. On top of that it seems to be almost impossible to actually contribute code to it.
It is actually, by definition. The source code is viewable to the public, therefore it is open source. Free and open to modification has become synonymous with open source, but is not a requirement.
That isn't really true, if one speaks about open source they usually mean the OSI definition, which is very specific.
We do have two nice features in the next lldb release that gdb hasn't to my knowledge: - syntax highlighting for source code by default - IDE-like tab completion in the expression evaluator With some luck we have C++ modules support in the next release, which means you can do crazy stuff in the expression evaluator like reusing the templates from your code without problems (including `std::vector` and similar STL data structures working just fine).
&gt; remote for the right fit from Europe?
Hard to follow because of the bad audio unfortunately
I'll be definitely have a look at it, because I'm always curious how other people have solved issues, but your own custom license will be a big NO NO for using it at my job, because my company doesn't want to evaluate a proprietary license and probably still having the risk getting sued some day without any precedence.
Wondering if the attendees had seen anything on these little screens.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/az2xfc/help_getting_simple_coroutine_code_compile_on/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
What disturbs me most about the anti-STL sentiment is that none the things I've looked at that have a stdlib counterpart seem more desirable than the stdlib ones. And some of them are not just not-better but flat-out broken. E.g. the TVector default construction does `new TElem[8];` followed by memsetting that to zero. Guess what happens if you write, e.g `TVector&lt;TVector&lt;TInt4&gt;&gt;`
How long will you keep on bragging about this when it's been months it has been fixed and you got told countless times, even by Steve Klabnik? https://old.reddit.com/r/programming/comments/avuwl0/announcing_rust_1330/ehi69e3/
&gt; &gt; 1. Do not host in any public way your own versions of this code, in whole or in part. This repository should be the single source for the code base. &gt; 2. Do not host or offer (for free or sale) any modified versions of this code base or any modified binary builds of this code base. Such things are to be used for your own private development purposes only. &gt; 3. We would request that any fixes or improvements at least be offered for inclusion back into the code base, but we realize that's obviously not always practical if that code is commercial. (1) prohibits me from pressing the fork button on GitHub. (2) prohibits me from pushing a branch with any changes to my fork. (3) asks me to submit pull requests, but somehow without violating (1) or (2).
Because doing things in one function make them twice as cool: template &lt;class Tuple, class Pred, std::size_t... I&gt; constexpr size_t find_if_impl(Tuple&amp;&amp; t, Pred&amp;&amp; pred) { std::apply( [&amp;](auto&amp;&amp;...args){ ( pred(decltype(args)(args)) || ... ); , std::forward&lt;Tuple&gt;(t) ); } also one line. 
&gt; It is actually, by definition. The source code is viewable to the public, therefore it is open source. The "open" in open source has always referred to it being open for modification, not to be open to readability. I mean, if the source is available and not obfuscated, it's automatically readable. But it does not mean you can do much with it, legally. As a counterpoint, interpreted programs have never been considered "open source" just because you can (obviously) read the code.
&gt; It doesn't use the STL or standard library stuff at all. It is a complete world unto itself. Obviously for a lot of people that will mean it's of no interest. right you are
honest question: what do you mean with anti-STL? I can imagine when you started 25 years ago the STL was not in a good shape, so you implemented similar functionality yourself, and now you want to keep it consistent. &amp;#x200B; But it seems you are expressing a more profound dissatisfaction with STL itself: you don't think C++ projects nowadays should use it as generic, optional, indipendent building blocks?
Unwarranted hostility and condescension. The guy is asking a question, not trying to make a change to the standard.
I can't give you opensource test tools but I can point you at these videos [https://www.youtube.com/watch?v=nZNd5FjSquk](https://www.youtube.com/watch?v=nZNd5FjSquk) (part 1) and [https://www.youtube.com/watch?v=CFzuFNSpycI](https://www.youtube.com/watch?v=CFzuFNSpycI) (part 2). Here John Lakos from Bloomberg gives presentation how they have tested different memory allocator strategies. However, I don't recall if they've open-sourced their test setup or not. Hope that helps.
ok thanks, this might be interesting too for me!
Do you want to make a generic comparison (a variety of scenarios to see where each allocator shines/sinks), or do you have a particular application in mind?
in the end, i want to make both. but i would like to make a generic comparison in a first step.
You really don't know what an 'internal ticket' means?
While this isn't your question, I remember the advantages of each allocator combined with the licenses to mean that there actually wasn't much overlap between which one to choose. Hoard costs money, dlmalloc is simple, ptmalloc (I think) uses lots of memory and jemalloc ends up being a decent middle ground (although it is a little hefty for an allocator)
`lldb` still crashes on my Fedora Linux 29 from time to time. I cannot figure out why.
As a somewhat new C++ dev, what's the advantage of this feature in day to day programming workflow? &amp;#x200B; From the post: &gt; Contracts are a good replacement for the assert macro and compiler intrinsics &amp;#x200B; My understanding of the assert() macro is that you use it while developing to catch programming errors but then you define NDEBUG to remove them when compiling for release. &amp;#x200B; Can this be used the same way? For example, setting compiler build-level to off? &gt;A program may be translated with one of three *build levels*: &gt; &gt;*off*: no contract checking is performed. &gt; &gt;*default* (default if no build level is selected): checking is performed for contracts whose *contract-level* is **default** &gt; &gt;*audit*: checking is performed for contracts whose *contract-level* is **default** or **audit** &amp;#x200B; &amp;#x200B; &amp;#x200B;
I don't get the downvotes for an honest question. I'm not too familiar with them, but I'll try to answer as best I can. The idea behind contracts is that they're used with templates to restrict a class to a certain inheritance or implementation. So if you wanted a class that *only* works with the "container" classes, you'd specify the "container" contract, so your class' user would be aware that they could only use your class with classes that respect the "container" class, and you'd be free to write code *knowing* that methods x, y, and z had to be present and working. Right now, nothing is stopping you from writing a templated class that tries to call `T.size()`, but nothing guarantees that its valid until you try to compile, run, and get ugly-ass error logs. This should make those errors more readable. An advantage over assertions, is that assertions don't necessarily catch these bugs, but contracts make sure you can't get these bugs.
I think you're confusing contracts with concepts
I think you are talking about Concepts, not Contracts. &amp;#x200B; Contracts are replacement for asserts, but with a benefit, that contract can be a part of function declaration, instead of implementation. &amp;#x200B; Consider following code without contracts &amp;#x200B; `*.hpp` `float sqrt(float a);` &amp;#x200B; `*.cpp` `float sqrt(float a)` `{` `assert(a &gt;= 0);` `&lt;implementation&gt;` `}` &amp;#x200B; User of this function will see only what is inside a header and won't be able to know that function expects only positive numbers. &amp;#x200B; Now consider code with contracts `*.hpp` `float sqrt(float b) [[expects: b &gt; 0]] ;` &amp;#x200B; `*.cpp` `float sqrt(float b) [[expects: b &gt; 0]]` `{` `&lt;implementation&gt;` `}` &amp;#x200B; It behaves the same way as a version with assert, but now user can see that he should pass only positive numbers. &amp;#x200B; As u/108life correctly stated, you can build your code with different levels of contracts checking. For release build you might want to check off level and all the contracts check will be removed from your code, thus giving you faster and smaller binary. For development build you might want to use higher levels, to give you more possibilities to detect errors in your code. &amp;#x200B; So to sum everything up * in case of \[\[assert\]\] contract the benefit over assert() macro is that you can choose either default or audit levels, thus giving you a little bit more control compared to the defined or not defined NDEBUG. Also contracts don't rely on macros, so it is not possible for somebody just write something like `#defined NDEBUG` `sqrt(-1);` `#undef NDEBUG` * on top of that contracts give you a possibility to define pre and post conditions for your functions, which will be visible to the user and to the compiler, which gives potential for more optimizations
Taking a quick look at different places of the code: * Instead of using wrapping proper dependencies, everything is re-implemented by hand. Even stuff like `std::numeric_limits`. Even crypto... * Weird stuff like `tCIDLib::TVoid` instead of `void`, `kCIDLib::True` instead of `true`, `tCIDLib::TBoolean, instead of `bool`, etc. I don't see the point. * Modernization is not just about using `nullptr`, `= delete` and stuff like that. I see some move ctors/ops in a few places, though, but that is about it. Actually, if those are the only features that you are using, then it is best to avoid entirely C++11 and keep compatibility. * Commits with thousands of lines changed (impossible to review). Lacking commit messages. Lots of changes that do not even relate to what the commit claims... * Stuff that should be selected at compile-time (like thread-safety in the `TCollection`s) are instead selected and manipulated at run-time. Overall, it looks like you have written this in complete isolation of the rest of the world! :)
Thanks. That makes more sense in the context of using it in declarations to show the user the pre/post conditions.
By the way, `expects` and `ensures` are currently called `pre` and `post`, but we'll see what happens in future meetings.
Oh yeah, my bad.
I was looking at en.cppreference and axiom is never really touched on. Can someone provide info on how axiom affects expects, ensures, and assert?
contracts can be used to express things about your code at a higher level (things you'd consider in your design/spec) which leads to robustness, rather than ad hoc assert statements which tell you more about your implementation alone. if youre interested do some reading on design by contract, especially in the ada and eiffel programming languages.
Why do you check the same condition in the contract and in the code?
&gt; As a somewhat new C++ dev, what's the advantage of this feature in day to day programming workflow? Preconditions and postconditions are exposed to the compiler at the interface level and can be checked in ways that plain asserts can't. Example: // foo.h int foo(int x); // foo.cpp int foo(int x) { assert(x &gt; 0); return sqrt(x); } That function has a precondition that `x` is positive, but it is not stated anywhere in its public interface; the assert is an internal implementation detail. If `foo`'s body is hidden from the compiler (e.g. it's in a separate translation unit) then the compiler has no way to even _know_ about this precondition and will happily let you write code like `foo(-1)` without so much as a warning; so far as the compiler knows, any signed integer is a valid input to `foo`. With the new contracts features, you'd write: // foo.h int foo(int x) [[expects: i &gt; 0]]; // foo.cpp int foo(int x) { return sqrt(x); } The "assertion" is still present and will still be checked at run-time, but now also the compiler knows about this precondition. A compiler that chooses to do so can now warn you when you write code like `foo(-1)` but it knows statically at compile-time that the function's precondition will be violated. Beyond just checking and warnings, it also helps the compiler generate better code. If the compilers _know_ (via a contract) that a particular value is never negative, for example, then it can propagate that knowledge further. It could hypothetically remove conditions that check for negative values, or at least optimize those branches as "unlikely" automatically. Further, unlike the naive C `assert` macro, the new C++ contracts specification integrates better with the C++ language in some ways (e.g. exceptions... and not being a macro and all the problems that entails) and has failure-overrides builtin (which hopefully can do all the things that some of our custom "fancy" assert macros do). &gt; A program may be translated with one of three build levels:off: no contract checking is performed. You quoted the answer to your own question. :) Contracts' assert is a contract, so in the off-level, where no contract checking is performed, naturally no contract-based assert checking will be performed.
Maybe a contrived example to show compiler optimizations probably.
It's supposed to declare something that is always true and therefore no need to ever be checked.
Gotta love the internet, where you can do one of the most selfless things in your life and dread getting up the next day and reading the comments. Anyway, to address the over-reaction to the usage terms.... The point is to avoid lots of disjoint, not-compatible variations, to make it a project that might be competitive with commercial projects by being a single, well defined thing. Where using an application that is based on it doesn't require downloading ten different libraries and such. That's why open source never competes with commercial software. And not to discourage other open source development based on it, but to encourage that such development be PART of this project, not some completely different thing based on some completely different version of the code base. And I'm not trying to be a Nazi about it. If you are working on something open source that is ultimately intended to be based on the official version, but you need in the meantime to make fixes or small improvements that you intend to submit back, I don't care about that. Or, if you have built binaries that are just shipped with your application, I don't care. If you don't document the changes you made, then no one is going to be able to use them separately from your application. You are just creating some variation for your own application's usage. You just shouldn't create some documented version of your own, and put it out there for third parties to use as a library. And if you want to fork it to your own private repository, or onto your company LAN for use in commercial or person product development, then that's not publicly visible and it doesn't matter what you do as long as you provide attribution if you use it in something you release. If your company developers use a Github repository for sharing that variation, just keep it private. &amp;#x200B; Anyway, I can update the readme to make these things clearer if that makes any difference. Not that it probably makes any difference. 
Well, yeh, that's the whole point. That it's an alternative. I understand that most folks will use the standard no matter what. That's fine. I'm just providing an alternative. As to the commits thing, I was making some last minute large changes before pushing it up. This is the initial public version. What happened before that is not really of any concern to anyone but me.
Well, it's not 25 years old, it started a long time ago, but there may not be a single line of code that's anywhere near that old. And the purpose is not to be based on the standard libraries, which are not the language itself.
Thanks.
See my latest comment. People are blowing the whole thing way out of proportion, since that's what the internet was invented for.
Don't you love the internet. You got utterly down-voted for being appreciative. 
Okay, brain dump time then! ### Memory Overhead The speed of allocation matters, but this doesn't mean that the memory allocator itself should simply trample all over the cache each time you do allocate. =&gt; You may want to benchmark the impact on L1 cache for allocating with various allocations; ideally down to understanding how many cache lines it pulls in. ### Memory Footprint In a similar vein, different allocators have different footprints: - They may reserve or hold onto more or less "buffer" memory. - They may have a varying degree of granularity^1 . =&gt; You may want to benchmark the overall memory footprint for allocating various sizes. ^1 *An allocator rarely allocates exactly N bytes when asked for N, instead it's likely to have buckets. An allocator with buckets for power-of-two allocations (1, 2, 4, 8, 16, ...) will use more memory than an allocator with buckets for half-power-of-two allocations (1, 2, 3, 4, 6, 8, 12, 16, ...).* ### Memory Contention Opposite to low-footprint, an allocator may create False Sharing by allocating two different items, operated on by two different threads, into a single cache line. =&gt; It's unclear how easily this could be benchmark; inspecting the code would reveal whether this can happen or not, but judging the practical impact may be delicate. ### Number of Threads The performance of the allocators should be measured in a variety of threading scenarios: - 1 Thread. - N Threads. - A varying number of Threads. For example, some allocators have a fixed number of pools (based on the number of cores) whilst others may have strictly one thread-local per thread. In the latter case, applications using many more threads than cores (for example, having dedicated blocking I/O threads), may lead to a higher memory consumption... and possibly reduced contention. =&gt; You may want to benchmark if allocation throughput scales linearly with the number of threads, for example. =&gt; You may want to check the memory footprint when scaling to multiple threads. =&gt; You may want to check the memory footprint after shutting down N threads which released everything they allocated; to see if the footprint is proportional to the current number of threads, or the peak number of threads. *I seem to remember than tcmalloc and jemalloc had a different behavior on this point.* ### Speed: Local vs Global. Allocating and deallocating memory locally is different than allocating on one thread and deallocating on another. The latter is more likely to cause contention in the allocator; possibly leading to higher latency/lower throughput. Similarly, allocation spikes may cause an exhausted thread-local pool to be swapped with a fresh one from the global pool, and then later be grabbed by another thread, causing a similar pattern of having one thread allocating from the pool while another tries to deallocate. =&gt; You may want to try all variations of Single/Multi Producer Single/Multi Consumer. =&gt; You may want to allocate heavily from a thread, then start allocating heavily from others at the same time you start randomly freeing stuff from the first. ### Speed: Throughput vs Latency. Most allocators that I have seen are tuned for throughput, and can exhibit terrible latency under heavy contention... or simply at random moments (OS interactions). Working in low-latency applications, it's something I am very sensitive to. =&gt; Heavy contention is relatively easy to simulate, see above. =&gt; Large "deallocating periods" may lead to releasing memory to the OS. 
I don't much care for the direction that the STL has gone. I think perhaps I'm not the only one. Though of course their dislike will generally be enough to push them away from it even so. One problem I have with it is that they have spent endless effort creating a cathedral to container abstraction, but you can't write even a modest realistic application without having to use a bunch of third party bits and pieces. My concentration has been on providing a tightly integrated, and potentially very portable, system that provides that practically useful stuff.
No, everyone is over-reacting, see my latest comment.
Could you have it say, "The first error was..." and repeat it tersely at the end of the big wall of text? The first is usually the one you need to try to fix first, but it is the hardest to scroll back up to when some template weirdness generates a megabyte of error messages and overflows your terminal scrollback buffer.
I didn't know who he was. You might be closer than you think, though not quite that bad. At least not yet. I still have some time. I do suffer badly from anxiety issues, or have since the early 90s (which just happens to be when I started the earliest bits of this code so maybe there's a connect there.) Anyhoo, this code is not a toy. The CQC automation platform that sits on top of it is a very large and very complex system. It's network distributed, multi-user, highly multi-threaded, and constantly active, and it runs for months and years at a time on customer systems. I could not possibly support such a product if the underlying code was flakey. I'd drown in support issues. And of course I take the performance of CQC very personally, it reflects on me and my reputation. So I've worked very hard to make it all high qualty. I should say that this code doesn't reflect a currently shipped version. All of this recent modernization stuff has been happening in between CQC releases. So some of these recent changes are still being tested out and such, and may not be quite as clean yet. &amp;#x200B;
Good job dude , I am legitly impressed
Uh-oh. A positive comment, it's doomed.
Obviously trailing comma. std::tuple&lt;int,&gt; foo(1,2); 
You assert something that should not be checked. This is to express some assertions that cannot be checked efficiently and/or allow other tools (like static analysis) to eventually check them or maybe allow a compiler to just assume things and optimize accordingly. At least on theory.
I'd say that it is still better to add it as an **option()**, so it will be visible in different GUIs and users will know of its existence
I believe the aforementioned test setup is open-sourced (see BDE Allocator Benchmarking Tools below--including the links to BDE libraries for context); here's a couple of benchmarks: - malloc-survey: benchmark for different memory allocators - https://github.com/r-lyeh-archived/malloc-survey - Validation of Memory-Allocation Benchmarks - http://wg21.link/p0213 - https://github.com/gbleaney/Allocator-Benchmarks - BDE Allocator Benchmarking Tools - https://github.com/bloomberg/bde-allocator-benchmarks/tree/master/benchmarks/allocators - BDE Libraries - Basic Development Environment - a set of foundational C++ libraries used at Bloomberg - https://github.com/bloomberg/bde - https://github.com/bloomberg/bde/wiki - Basic Standard Library Memory Allocators (bslma) - http://bloomberg.github.io/bde/group__bslma.html - Basic Development Library Memory Allocators (bdlma) - http://bloomberg.github.io/bde/group__bdlma.html - BDE Allocator Model - https://github.com/bloomberg/bde/wiki/BDE-Allocator-model - BDE Allocator Benchmarks - https://github.com/bloomberg/bde-allocator-benchmarks - rpmalloc - Rampant Pixels Memory Allocator - cross-platform lock-free thread caching 16-byte aligned memory allocator implemented in C - MIT license / Public domain - https://github.com/rampantpixels/rpmalloc - https://github.com/rampantpixels/rpmalloc-benchmark 
With a few system libraries as dependency on Ubuntu. How can I use an up to date gcc? Do I have to compile those libraries myself?
Having types that are both owning and non owning is usually a bad plan. It is raw ptr vs unique ptr. Write non owning types, and owning types. Owning types must cheaply be convertible to non owning. Functions that don't need ownership operste on non owning types. Functions that do need ownership operate on owning types. Similarly, a thread safe foo and unsafe foo are different types. I like having said types be monadic template wrappers around the unsafe types. That permits the thread safety to be as granular or not as they want. template&lt;class T&gt; struct mutex_guarded { auto read(F&amp;&amp;) const; auto write(F&amp;&amp;); private: T t; std::mutex m; }; for basic pseudocode. Multi lock, rw locks, copy/move/consyruct, etc all take more details. 
That’s a pretty worthless title. 
Thanks.
There are a lot of compromises involved. My collections, for instance, are polymorphic and I get a lot of mileage out of that. If you make thread safe or adopting parts of the type, then suddenly you can't have a method that takes any by ref collection of strings, for instance, because it can only accept either thread safe or not thread safe collections. For the vast majority of such uses, the thread safety really is irrelevant and it would be pretty nasty to have to have different versions of all of those calls to accept the different types. &amp;#x200B;
Open source != source available
shouldn't it be \[\[expects: x &gt; 0\]\] ?
I'm not a lawyer, but It seems like LGPL+a [CLA](https://en.wikipedia.org/wiki/Contributor_License_Agreement) allowing the author to distribute the software under a proprietary license for his commercial purposes would have been a better approach to satisfy most of the author's desires without creating all of this ambiguity, and while staying true to [Open Source](https://opensource.org/licenses) as understood by most of the free software community. And the CLA might not even be necessary if the author's commercial builds are based on the publicly available source and there's no need for the author to re-license community contributions for commercial purposes. I think the [Qt](https://www.qt.io/licensing/) project is a good example of this. Most of the source is available under the LGPL so it allows users to create private forks for non-commercial use, and any public binary distributions must make the modified source available unless they pay Qt for a commercial license. It doesn't prevent anyone from publicly hosting a fork of the source and/or distributing binaries based on that fork, but at the same time there aren't really any long-lived forks of the code that compete with the official Qt releases. The only forks I know about, like [CopperSpice](https://www.copperspice.com/), don't claim to be Qt (just derived from it.)
Cool stuff. However you don't need to add \`-Wall\` et al to compiler flags manually, they are always used (unless you explicitly go and set your warning level setting to zero).
It's focused on iOS debugging, but [this book](https://store.raywenderlich.com/products/advanced-apple-debugging-and-reverse-engineering) is the most detailed resource for lldb that you can find. 
The link for Meson on in you Readme(s?) lead to meson.org, which AFAICT is unrelated to mesonbuild.com, which I think is the right link.
Runtime thread safety selection is a pretty bad smell.
There are always various compromises involved. My collections are polymorphic and I get good benefits from that. If the thread safety became part of the type, suddenly I can't have a method that takes any collection of whatevers, because the thread safety is now part of the type. I actually started down the path of making it part of the type, but it quickly became really ugly, so I backed those changes out. &amp;#x200B;
TArea&amp; operator= ( const tCIDLib::TRawArea&amp; areaToAssign ); &amp;#x200B; No thanks :p
Thanks for releasing all this work for others to look at. It's impressive to see a nice unified and clean code base, especially one that handles code generation, comms, and windowing. I believe I have seem some of your other comments mentioning things you can do with this system. It would be awesome to see some more examples of what this system is capable of. &gt;And that makes sense because this repository IS the open source version, and needs to remain the only one. You made this comment in another thread, but I think you are miss reading the situation. Right now you are the **only** expert in this system, the most likely outcome is nobody uses it all. This is given its monolithic nature and custom versions of existing system people are familiar with. It would actually be a huge success if your project hits the adoption level to merit someone wanting to fork it. Forks happen when the main project is used by lots of people and maintainer abandons it or does not work with community. 
A good number of folks have already done it, but a lot of those may just be looking to steal code, I dunno. If you look at some of the videos on my personal Youtube channel, I show some of the capabilities there. All the current samples in the code base are very simple, just to demonstrate this or that particular capability. I'll start creating some more complicated ones as well. I'm probably going to move all the stuff in \Samples to \Samples\Basic, and then create a \Samples\Advanced to keep them separate. 
I applied the fixes to all readme(s) now it should take you to the right place, [***Mesonbuild***](http://mesonbuild.com). If anything else seems to not be working then let me know so I may fix the issue. &amp;#x200B; &amp;#x200B; &amp;#x200B;
That's untrue; the standard library is part of C++. Its in the same specification.
But it's not the language itself, it's something in addition to the language. My code base obviously demonstrates that the STL is not a requirement to write a butt-load of C++ code.
They aren't seperable. Parts of the core language depend on definitions in the std library. 
In this post you're actually doing neither Explicit Euler nor Implicit Euler, but Leapfrog. std::vector&lt;Particle&gt; solution = calculateAcceleration(particles); solution = calculateVelocity(solution); solution = calculatePosition(solution); Notice how you've clobbered the velocity before calculating the next position. This is a better algorithm than Explicit Euler, though (Leapfrog has bounded error in the energy for long times, whereas the energy of Explicit Euler systems grows over time - the practical result of this is that bodies in orbit always escape if you integrate their trajectories with Explicit Euler). Anyway, if you're looking for ways to speed this up, the way to do it would be either a Particle-in-Cell method (where the potential is calculated on a grid via Poisson's equation and then interpolated to the particles), which is O(n) but tricky to get correct because of the boundary of your finite grid, or some kind of multipole method, where groups of particles are coalesced into single effective particles for the purposes of calculating their force on distant particles. In practice I think this is often done via Octree, i.e. you calculate some multipole moments for each octree cell, and then particles in the same or neighboring Octree cells calculate forces on one another the O(N^2) way, but particles further away than that just use the multipole moments of the distant cells to calculate forces on themselves.
Whatever. It's meaningless to me either way. I shouldn't have even responded to him. My original point had nothing to do with this. It's that you don't have to use the STL to write C++ and that I am providing an alternative. 
Thanks neutronicus that’s a good point. Yes I think there are several performance improvements possible. On a pure programming way the particles could be handled as std::vector of x,y (position, velocity, acceleration). This way the data would be more efficient to process because it would be better fit into cache. I planed also other implementations, e.g Barnes-Hut, which as far as i understood is an octree/quadtree algorithm. Btw are you a physicist? I didn’t study this, studied mechanical engineering, I’m just interested in the topic 😉
No, if you don't support the standardized STL you quite literally do not have a C++ compiler - it's some other language that shares C++ syntax.
&gt; Anyway, I can update the readme to make these things clearer if that makes any difference. If you want to make a difference, choose an [OSI](https://opensource.org/licenses)-approved license.
Nobody cares what you say because what actually matters is what a lawyer can argue based on the license provided. I have never in my decades of programming **EVER** had a problem with there being forks of a main repo. It's not confusing and you're absolutely freakin' delusional if you think that's why "OS fails against commercial". Really the only time the alternative forks are more popular are if you, the maintainer, refuse to provide bug fixes or neglect features that the users of the product want. AKA - if your product is worse and people *should* be using the better fork. Also you need to switch the hosting platform or change your license, because you're violating the Github TOS by having a public repository that does not have the required license grants for other Github users: &gt;[5. License Grant to Other Users](https://help.github.com/en/articles/github-terms-of-service#5-license-grant-to-other-users) &gt; &gt;Any User-Generated Content you post publicly, including issues, comments, and contributions to other Users' repositories, may be viewed by others. By setting your repositories to be viewed publicly, you agree to allow others to view and "fork" your repositories (this means that others may make their own copies of Content from your repositories in repositories they control). &gt; &gt;If you set your pages and repositories to be viewed publicly, you grant each User of GitHub a nonexclusive, worldwide license to use, display, and perform Your Content through the GitHub Service and to reproduce Your Content solely on GitHub as permitted through GitHub's functionality (for example, through forking). You may grant further rights if you [adopt a license](https://help.github.com/en/articles/adding-a-license-to-a-repository/#including-an-open-source-license-in-your-repository). If you are uploading Content you did not create or own, you are responsible for ensuring that the Content you upload is licensed under terms that grant these permissions to other GitHub Users.
That is what the product is?
\&gt; And we are manly enough not to be frightened by the existence of raw pointers &amp;#x200B; Clearly women use \`std::shared\_ptr\` and REAL MEN use \`void\*\`. Seriously what is this garbage?
It was my semi-facetious response to so many people these days lately acting like a pointer is some sort of toxic thing that will kill anyone who touches it. My code base covers a broad range from very low level to very high, and there are a lot of bootstrapping issues. At the low levels, it's reasonable to use raw pointers. At higher levels it will lean more in the other direction. &amp;#x200B;
Are you talking about these [forks](https://github.com/DeanRoddey/CIDLib/network/members)? They clearly show the history of the code. Having code that others cannot post publicly is just incompatible with how GitHub. There is nothing you can do to disable forks I believe, and others have mentioned they are needed for open source development. You should think about why you posted the code. If you truly want others to benefit from it you need to let go a little and use BSD or MIT, if you simply want to educate and inform something really restrictive like AGPL v3 is the way to go (ie they have to release all source code if any customer uses the code). It will be hard to capture the value this code has to you for others, because it’s too different, platform locked, big and undocumented. Nobody is going to make you look like a fool by steeling the code and managing to do that.
Yeah, I studied computational plasma physics in grad school, so this kind of thing (large numbers of Newtonian bodies interacting via action-at-a-distance) is near and dear to my heart.
I've made it clear anyone can fork it. I just asked that they keep them private to themselves if they are going to create incompatible stuff that they aren't going to offer back. 
&gt; where you can do one of the most selfless things in your life Open sourcing something isn't selfless. What is your goal? What are you trying to accomplish by open sourcing this software?
What can be done using this?
Not the GP but I used clion on Linux and it really didn't like our project: very good IDE when it works but it worked only ~30% of the time (probably an issue with generated files and/or ninja). VScode seems to work better.
So, giving away for free something that literally took 25 man years of your life to create isn't at least a bit selfless? I'm putting it out there to see if some other people who share my view of things might want to get involved and expand on it. And that some folks might find it a useful platform on which to build their applications. My hope is that it remain a single, coherent thing, since that's really the point of it, to not be like the usual thing of a bunch of bits and pieces coming from different places or a thousand different Unix variants. That's why I'm trying to push non-application work (i.e. extensions of the general purpose code) towards being done as part of the official code base, and not to have lots of variants out there. 
Because references created object lifetime hazards. They can dangle, and are ultimately not much an improvement over a naked `T*`.
Uhm... A reference as a regular function parameter can't, afaik, dangle, as long as you don't do something stupid somewhere else. And I'm pretty sure gsl::not_null&lt;T&gt; will not save you from being stupid either.
No, you're wrong. std::initializer_list. It's a type part of the standard library (no, it's not the STL) encoded into the language. Because the standard library is part of the language
I don't see this point of this section: ## # # Meson: Check projects required info # ## if meson.project_name() != 'cProgram' error('Incorrect master project name string:' + meson.project_name()) endif if meson.project_version() != '0.0.1' error('Incorrect master project version string:' + meson.project_version()) endif if meson.is_subproject() error('Claimed to be a subproject even though we are the master project.') endif Absent a bug in Meson, the project name and version should always be correctly set, right?
OK, in order to quiet the jackals, here is a new usage/license section that will be in the [readme.me](https://readme.me) file I upload later tonight with some sample updates. &amp;#x200B; The following usage/license terms are imposed: 1. Do whatever you want 2. If you use my stuff, be a mensch and give me appropriate credit 3. If you find bugs, please send them in, in digestable chunks. 4. If you want to contribute large stuff, i.e. new facilities, then be sure to follow the existing style and substance carefully, because I'm an OCD, paranoid, anal-retentive. It would obviously be best to coordinate with me first to make sure no time and effort are wasted. 5. Please don't install any non-official builds in any system directories of user's machines, where they could be seen by other CIDLib based applications. Limit them to your own application's local use. 
&amp;a[4] is getting the 4th item of the array 'a', then taking the address of it. It is getting the 'end' pointer of the array. [](int i, int j) is the capture and signature of the lambda with the body {return i &gt; j; }. 
 &amp;a\[4\] takes the address of the fifth element in the array a. a only has four elements, so this is pointing one past the end of the array. A more clear way of writing this would be: &amp;#x200B; std::sort(std::begin(a), std::end(a), ... &amp;#x200B; \[\](int i, int j) declares a lambda that takes two integers. std::sort uses this to determine the ordering of the elements it is currently comparing.
a[4] is the fourth member of the array a, which is one past the end (so normally illegal to use) &amp;a[4] is a pointer to that address The other thing is the syntax for a lambda (anonymous function) on c++. So they're defining a function that takes two ints and returns if the first is larger than the second, then passing this function to sort.
The first line &amp;a[4] is a reference to the element past the last element in the array a. The int i int j part is a comparator function you pass to the sort algorithm that overrides the default behavior of sort (ascending order in case of numbers and chars). In this case I think your array will be stored in descending manner. When dealing with stl vectors, V.begin() and v.end() are passed to sort. V.end() is the element past the last element (if you try to dereference it, you will get an error). 
I updated the terms in the [readme.md](https://readme.md). If those aren't gracious enough, I don't know what would be. &amp;#x200B;
&amp;a[4] means "take an address of the 5-th element of an array", or, more concise, given array of T, "return pointer to the beginning of the array + 4 * sizeof(T)". By convention, STL functions work on range of [a, b). Since we need to sort the whole array, we give pointer to the first element and to the one-after-the-last element. In the given snippet, "a" is pointer to the first element, and "&amp;a[4]" is pointer to the one-after-the-last. The third argument is an anonimous closure, so-called lambda function. [] — no variables from the outer scope will be captured. (int i, int j) — take i and j of type int as arguments { return i &gt; j; } — function body, returns true if i &gt; j and false otherwise. As for the first question, I suggest you to read more about arrays, iterators, especially end iterators, and STL design overall. The second one is quite simple, just google the syntax of lambdas. 
It's a fairly big lever, so presumably you could move the world.
Thanks. Given that we have a\[0\], a\[1\], a\[2\], a\[3\] initialized with values 3, 2, 4, 1 respectively, why a\[4\]? Also, for (int i, int j) where does it tell the program the value of i and j and where the initial value for i and j as well as the amount of increment (e.g. i = i +1) defined?
&gt; why a[4]? Because in C++ algorithms usually work on iterators defining some range using iterator to the first element and one-past-the-end (so one can use it to know when to stop). For simple arrays pointers act as such iterators and `&amp;a[4]` is the pointer to the `one-past-the-end` element of `a` array.
Some of your questions should be answered by looking at the [std::sort](http://www.cplusplus.com/reference/algorithm/sort/) documentation. Treating addresses as [Random access iterators](https://www.geeksforgeeks.org/random-access-iterators-in-cpp/) means that the next address is given by doing ++ on the addresses. So the compiler is using pointer arithmetic on the array values - and it knows that the values are integers and the length of the integer, so it goes to the next one. 
Who is the dumbfuck who down voted this? 
Your code, your rules but you will make it easier to use CIDLib if it’s under an existing license. My employer has a list of approved licenses similar to [Google’s](https://opensource.google.com/docs/thirdparty/licenses/). GPL, Apache, MIT, and such are all fine but any license that isn’t on the list must be evaluated by an attorney. The last time I went through this process it took about 7 months. I would need an extremely compelling reason to use a license that we haven’t approved.
The first line is there to keep me from mixing other example projects with the other ones. The second one is for keeping track of versions as examples and projects get updates. And the last line is just a sanity check.
That's like saying "You don't have to use pointers to write C++" or "You don't have to use classes to write C++". That doesn't mean those things aren't part of the standard.
Can you give some concrete examples? What exactly is a cathedral to containers?
Manliness has nothing to do with programming, though.
Use the Boost license.
&gt; Well, yeh, that's the whole point. That it's an alternative. I understand that most folks will use the standard no matter what. That's fine. I'm just providing an alternative. An alternative to what? AES, or AI, or crypto, or compression, or most of the things you have are not on the standard (today, and for years to come) and there are far better libraries written by experts of each field. And, surely, something like `void` and `true` needs no "alternative". They are even language keywords, dammit. &gt; As to the commits thing, I was making some last minute large changes before pushing it up. Surely you did it *after* pushing it up. Otherwise we wouldn't be able to see it. &gt; This is the initial public version. What happened before that is not really of any concern to anyone but me. Commit history is very important to understand a code base. In your case you may not be able to provide it due to several reasons, that is fine, but that does not mean it is not useful.
It's a freaking joke. Jeez.
I'll think about it later when I have time. It's not an immediate concern since no one can even build it. BTW, if your lawyer took 7 months to go through the above, then I'm in the wrong business.
&gt; Where using an application that is based on it doesn't require downloading ten different libraries and such. That's why open source never competes with commercial software. Virtually all big commercial *and* open source projects use "libraries". What are you even talking about? Really, if someone tried to sell me their own hand-rolled crypto implementation and argue it is to "avoid downloading 10 libraries", I would stay reaaaaally far away from it. &gt; And I'm not trying to be a Nazi about it. That is your word, not a contract. If you have been selling you software, surely you know legal issues grow everywhere around us.
This was a great cast. Kirk explained things so well. More like this! In fact could we have more of Kirk explaining things in even more detail?! 
&gt; It took you 25 years to write, it's gonna take someone at least 25 months to understand what it does. Not really. I understand what you are trying to say, but in this case the code is best described as a bunch of common libraries re-implemented by hand. So picking one and understanding it is quite straightforward.
&gt;Why do you check the same condition in the contract and in the code? He wanted to see if an optimizer could deduce the branch would be deleted if the contract was in
[Selling to the Fortune 500, Government, and Other Lovecraftian Horrors](https://training.kalzumeus.com/newsletters/archive/enterprise_sales) is a pretty accurate description of our procurement process. I think that’s where most of the time is spent. My most recent request was in July of last year and the ticket is still open.
Nah, I totally agree with this "a cathedral to container abstraction". C++ arguably has anything relating to containers overengineered. He's right -- they're *not* tightly integrated, and at times it's impractical. But IMO that's a good thing. It takes a while to learn for something that's absolutely elementary in most other languages, but once you do, they're just so damned flexible. It comes to the point that, except for historical reasons, there aren't very many good reasons to *not* use std's containers. You compose them to your needs. And then the magic is -- the composition melds together at compile time leaving highly efficient, low and no-cost abstraction.
&gt; Really the only time the alternative forks are more popular are if you, the maintainer, refuse to provide bug fixes or neglect features that the users of the product want. AKA - if your product is worse and people should be using the better fork. And this is the natural way things would go, anyway. If there are 5 forks, and 3 of those are actively generating pull requests back to the base repo, the base repo is progressing 3x as fast as any one of the other 5 forks. This naturally drives more interest to the main repo, and next thing you know is it has 10 contributing forks. There's maybe a handful of projects out there where I see forks actually get forks. Almost always people who find forks and want to fork themselves just end up forking the original and will patch in the parts of competing forks that they're interested in. And it makes since -- the original is where everything congregates so it's the one you want to follow.
There's this post from IT Hare where they describe their process to compare memory allocators: http://ithare.com/testing-memory-allocators-ptmalloc2-tcmalloc-hoard-jemalloc-while-trying-to-simulate-real-world-loads/ It comes with the code on GitHub: https://github.com/node-dot-cpp/alloc-test
Seems like you need a memory allocation library. A while ago, I started writing a memory allocator library called "nsmem" (for namespace mem). It works but it's missing some special allocators, unit tests, etc. It's been a while since I worked on it, like a few years; but I used it recently for a small personal C++ project and it worked quite well. One of the thing it provides are polymorphic allocators, if you need them. Using a policy-based approach, you can also choose or extend a method of logging output (cout, file, etc.), add fences, detect leaks, etc. I put the lib on github to find collaborators willing to improve nsmem with me, I would want to use it more in my programming so I could work on it too, unless it's completed superseded by std::pmr (?). https://github.com/binarez/nsmem DLHeapAllocator.cpp provides dlmalloc Allocator.hpp : the polymorphic allocator interface The debug policies : https://github.com/binarez/nsmem/tree/master/src/nsmem/debug Or look into using std::pmr::memory_resource, that's new C++ stuff I'm not too familiar with right now. 
Should be [[pre: x &gt; 0]] I am in pedantic mode 😆
That is a "joke" in very poor taste then.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Men, you guys are savage... You may disagree with his license and his engineering choices, but the fact remains that he made available a large body of code that could very well be of use to people. And for his trouble he gets some massive downvoting, including down votes for people who simply appreciate what he's done, a long discussion about the license, and a single "it looks good" comment from the one person who apparently had a look at the source itself. Let's say someone else is thinking about open sourcing some piece of code they spent a long time perfecting, and they see this discussion. What do you suppose they'll say? "Oh yes, I'll go ahead and publish that, people will appreciate it"? Or maybe "I can live without the scorn of the world, let's forget about the whole thing"? 
&gt; a lot of those may just be looking to steal code Who would want to steal such code? It's compatible only with itself, it can not be used as is. 
Because modules are, in a way, an abstraction over source files?
`#include` does not specify a path to a file. If you write `#include "xyz"`, how that `xyz` is mapped to a file is not defined by the standard.
And in fact, isn't required to be a file at all - it's legal for it to be internal to the compiler, for example.
I didn't know that. In this case I'll rephrase the question to: why isn't the same mechanism used for importing modules as well?
The module proposal should be ironed out by implementing all of Boost as modules. If that's practical, then maybe it's not dead on arrival. Otherwise, we have a problem. 
In CompilerExplorer you can use URL as include files. Which is super helpful when you want link to some single header library hosted on github.
Wow! r/til
Awesome, I was very close to study physics as well, but at that time I was more interested in engineering. Ironically I’m living just a few hundred kilometers away from CERN but until now never visited it, I really should do.
Other than the header name, the module name is defined in-source. As the standard doesn't talk about files, it can't mandate that the module name and the file name have any particular correlation. (That being said, I don't think, anything is preventing an implementation from requiring that the module interface unit be named exactly like the module.
It's dead.
That's well highly exaggerated, **owning** raw pointers are frowned upon, pointers **are** good, but have their uses.
The thing I don't like from this article is it create the *cyclic dependency* between component. You have `FoodObject.h` as a abstract type, and later the concrete types like `Apple.h`, `Orange.h` depend on `FoodObject.h` and `Factory.h`. And then `Factory.h` depend on `Apple.h` and `Orange.h`. This make program more tightly coupled. The other problem is that from `Factory` class, you can not know which component is registered with your factory class if you can not look at the *cpp* code of that class which can be provided by a binary format (dynamic/static library). And what would happen if the those derived class has constructors with different types and parameter instead of default parameter (I think you can find the solution with help from variadic template paramter) 
Several companies have policies limiting the use of "open-source" software that doesn't conform to a specific license, I think that's part of why he's suggesting you add one. Some of them are very brief if that's what you're concerned about. I think that [3-clause BSD](https://opensource.org/licenses/BSD-3-Clause) might be appropriate, It's short, requires anyone using your library provide a copyright notice (which satisfies your existing credit requirement), **isn't a copyleft license**, and (explicitly) prevents anyone from misrepresenting their use of you **your** library as an endorsement on your part. I'd also separate out the license from the usage, as the current way it is set up potentially allows you to sue someone if they send you a particularly long bug report.
Boost is not a good example. It has quite a few circular dependencies, which isn't allowed with modules.
I think you should `declare\_dependency` for each library instead of remember which directories need to be included, libraries need to be linked when linking to a library. This is something look like `PUBLIC, INTERFACE` in cmake
It's a good example because it shows there are serious issues with using modules for existing code.
If it is difficult to find the relevant files, then why don't we require a separate "module description"? We can require this is called *module_name.mod* which in turn specifies all the source files in the module, and possibly some other data that might be useful to know before parsing the source files. Like we have *include* paths and *library* paths, we could also have *module* paths that we pass to the compiler.
I'd argue that is shows that parts of boost are of questionable quality. You should never have cricular header dependencies, because it doesn't make a lot of sense, if any.
Why not just update the OP instead?
That's also true.
My impression here is that you felt like you are doing everyone a grand service but have received a few uncomfortable truths along the way. You seem to think that the biggest risk of 'open sourcing' your project is that you will lose control over it, so you're trying to lock it down. In reality, the biggest risk is that no one will use it or contribute. You're trying to have it both ways, in that everyone should be grateful for your benevolence but also adhere to your own personal interpretation of open source. The funny thing is that you have already been forked 6 times, presumably by people who are having a laugh at your license and responses here. If you hadn't have chosen your home-brew license, you'd be a year away from anyone even thinking about forking your project. You need to appreciate that if someone spends their time learning how your 25 years of undocumented code works, then decides it's worth using and in doing so contributes improvements back to your project, its not a case of you being generous to that person. It is in fact the reverse. So respect and courtesy and reasonable licensing terms should be extended to that person. Why not split the project into sub-projects? You seem to have adopted a pretty modular design, and most people aren't going to use all of the pieces here. You're much more likely to get a library incorporated into another team's project if it is not so bloated. I know that you can just build and use the bits you want, but just for maintainance, code contribution, and appearing in relevant google searches it would be nice to have separate repos for each library. Also, can you tell me why someone would want to use your build system over say CMake? I can see you have some level of tooling for linux and windows, but what about if I want to cross-compile armv8 targets? What about if I'm targeting a microcontroller with no OS? What about if I'm using a non-POSIX OS? What about if I want to incorporate a tool like ninja into my builds for faster incremental builds? What about if I want to link in a sub-project? And sometimes I want to link that in statically and other times dynamically? CMake and many other build systems are mature enough to allow me to do pretty much all of these things in a few lines of configuration. So I get that you might not have the features of CMake **now,** but do you have any design approach that would mean you will **one day possibly** have superior functionality to build systems that are already out there? Because I would need that spelled out to me before even thinking about contributing.
In that case we're on the same page. I also don't see Boost switching to modules any time soon even if they could do it effortlessly. Boost treasures C++98 compatibility too much for that to fly.
No, that's wrong. It would serve no purpose to use modules to implement code one was sure was easy to implement with modules. The more incompatible with modules, the better the example is. 
Why don't we fix the broken code instead of making modules even harder? Because, let's face it, code that has circular dependencies is broken.
Thank you a lot my friend, this are very very useful informations!
Very good explainations and useful thoughts, thank you a lot my friend!
Thats really great, thank you a lot!
Really interesting and useful for me, thanks a lot for your reply!
For "too costly to check" you have `[[assert audit: x &gt; 0]]`, the default level is `[[assert default: x &gt; 0]]` and then there's `[[assert axiom: x &gt; 0]]`. 
Good luck finding a C++ codebase of any size that isn't broken.
We don't need beautiful code, just code that doesn't have circular dependencies. Large boost libraries can be modularize, but not entire boost. Anyway, boost won't accept those patches, so it would be a wasted effort beyond a proof of concept and you can do that with just a single library.
Wow, I did not know that!
Terms 2–5 are conflictive with term 1: "Do whatever you want". Term 5 is particularly problematic. Again, choose a proper open source license. You can say you prefer users to use your libraries in certain ways, but you can't require this.
Couple of thoughts: - it would be probably helpful, if the code documentation would be moved to something like doxygen etc. So this massive library would have pretty and easy to navigate API docs. - I'm really interested, why you implemented everything by yourself even true and void? I'm sure when you started many things weren't even around, but migrating to basic boolean type seems like a no brainer. - as said using an widely adopted license would it make more likely for others to get involved.
This is clearly an ego-trip, based on your comments, and not a selfless act of humility. Maybe take the opportunity to reflect on why you’re getting this response. 
This is outside of the scope of the standard. An implementation could choose to do that, even if it's not practical. Clang did that with its custom modules. Likewise, am implementation could also choose to only allow a strong mapping with modules name to be equivalent to a path and a filename. Although this is stricter than recommended by the standard.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/azfok8/book_recommendations/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It is a fallacy to expect modules to solve all problems of the current compilation model, while easily adoptable by any existing project structure without at least some amount of refactoring. Either you want modules to improve upon the current system, which means you have to implement them in a way that does not offer a 1:1 mapping for every imaginable way that headers are used at the moment, or you want them - in effect - be headers with a different syntax but you loose most of the advantages modules can offer.
How could an implementation "*only allow a strong mapping*"? If I write a module it needs to work with all implementations. My question is, why don't the standard specify something like this? Assuming it would make things easier...
There are no circular header dependencies in boost. There are library level dependencies but I guess most of them could be solved by not requiring a strict one to one mapping between boost repositories and modules. Even if you follow the idea, where one library roughly maps to one (super-) module, many of the repositories effectively contain multiple libraries and could be split accordingly.
The standard don't even define a mapping for header files. It doesn't even specify it should be files. Implementations choose to agree on something that made sense. The same thing is happening to modules, I'll wait for the TR to get a more in depth explanation on what's recommended.. 
If they're polymorphic, couldn't you make the thread-safe versions just derive from the same base class?
I'm much more interested in what modules can do for future projects than how easy or difficult it is to migrate some humongous legacy code bases over. If we only care about existing code anymore, then c++ is effectively dead already.
How can an implementation require a *strong mapping* then? I know the standard doesn't require anything like this. The question is *why?* It clearly solves some problems. What problems does it introduce?
And who is going to do that work (which will effectively become obsolete as soon as it is finished)?
Well, for example, someone in it's makefile could choose to map `my.sprcial.module` to `my/special/module.cpp`. But as far as I know, this is not recommended by the TR, and does not solve all the problem. You still need to extract the dependencies between files, so you need to preprocess, read and parse it. At that point, you already know what file extract what module, so why not allow arbitrary mapping?
You must process 1 file then, instead of reading all files until you find the correct one. That is the issue we are trying to solve here.
&gt; I don't think, anything is preventing an implementation from requiring that the module interface unit be named exactly like the module How can ONE implementation require this if it is not required in the standard, while being *standard compliant*. If I write standard compliant code it works on all compilers.
The Boost contributors are working on some sub-goals, e.g. dependency reduction. Assuming that the work will be obsolete is to assume that the modules proposal won't make it even after being updated. That's pessimistic. Pessimists believe in the opposite of what they hope, optimists hope for what they believe in. ;-) 
&gt; Assuming that the work will be obsolete is to assume that the modules proposal won't make it even after being updated. How do you figure that? It will be obsolte, because it won't happen inside the actual boost repositories (certainly not before modules are accepted into the standard) and as it will require significant source code as well as build system changes, you can bet that the ongoing evolution in boost will make a merge almost impossible unless the fork is constantly kept up to date. Admittedly, a lot of the boost libraries are more or less abandoned, so mergin that won't be that difficult, but at the same time, most boost maintainers aren't willing to break backwards compatibility either. So for an indefinete period of time you'll have to either maintain a separate fork or clobber the boost source code with yet another set of `#ifdefs`. I believe that we'll see some module wrappers for boost at some point in time, but that is something completely different than a "modularized" boost.
gcc requires you to pass -std=c++17 on the command line in order to use c++17 features. Nowhere in the standard is that required. The standard doesn't say anything about the physical organization of source code or how building actually works, so implementations can require whatever they want in that regards.
Thank you for verbalising exactly what I was thinking. It's a real shame witnessing how the community has treated this guy
It died and libcxx replaced it. The one place I know that even uses it uses a version of libcxx instead now, and still has it as an option that really can't be used... mostly because libcxx was for a specific compiler and did its job well overall for replacing stlport.
I will definitely take a look. Thank you.
Are you already using LLVM and clang for your tooling?
&gt; The one place I know that even uses it Out of interest, can you say where that was? 
https://github.com/LADSoft/OrangeC used to use it/still technically has it in there, but doesn't really do anything there and we're trying to update to the latest version of libcxx and are finding a shit-ton of our own errors in doing so .-.
I suppose you could pretty much then customize it to your hearts content. I will try to familiarize myself more with the Python API. Thanks for pointing me in the right direction, and thank you for the example.
I mean, it's C++, nothing can save you from your own determined stupidity. But not_null&lt;shared&lt;T&gt;&gt; will save you from careless stupidity in a number of ways: 1. You can't default or null construct a `not_null`, so that's saved at compile time. 2. If for whatever runtime reason, you do get a null in there, you will get a nice clean assertion rather than a mysterious segfault from dereferencing an address near zero. 3. Lifetime guarantee, which ensures you don't get strange crashes from UAF. &gt; A reference as a regular function parameter Yes, if it's used within function scope and never copied. But then one day someone decides they need to keep it around, then months later you spend a day dealing with segfault :-P
Unfortunately I find this kind of behavior pretty common in the C++ community where anyone who isn't part of the "C++ is the best thing since sliced bread, and STL is awesome" hive mind gets harshly criticized and downvoted. This made me permanently leave the C++ community a few years back due to how toxic it can be at times. I understand that people might not agree with his choices, but it'd be nice if they just stopped before acting and thought how \*they\* would feel if someone would take a shit on the last 25 years of their life.
May have more success if someone not completely insane did your pricing 
This is a serious, non-aggressive, non-insulting question : are you autistic ? I am, and that's typically what I would be doing if I didn't have my family/friends getting me out of my cave constantly. First of all, congratulations and thanks. I feel like you've just spent the last 25 years working on something in your cave and you decided to share it with the rest of the world. It is definitely courageous to do so and I'm sure it was a terrifying choice. However, by spending so much time working on something so big without external input, you can easily find yourself completely lost. I know that for a fact, because I've been there many, many times, and I have the scars to prove it. I don't know your personal life but I'm really curious about it. What do you do for a living ? Do you live alone ? Is your product (http://www.charmedquark.com) successful ? Again, no offense. I might be completely wrong, I'm just curious, because the whole thing reminds me of myself.
Thanks
Not really, there are many Boost libraries not supporting C++98 and some not even C++11.
Yes, yes it should. :) Typo strikes again!
But then you couldn't have code that can take any collection, lock it, and do atomic operations on it. So you kind of lose either way. The way it works now, if you want to do something that's not a single operation (which is guaranteed atomic if the collection is thread safe) you can just do: TMtxLocker mtxl(colWhatever.pmtxLock()); If the collection is not thread safe, the lock is null and the locker does nothing. If it is, then this locks the collection So any code can do stuff that it knows will be thread safe is that is important to the caller providing the collection, and can still do that via the base collection class.
Well, I didn't *implement* true and void. They are just aliases. In order to have a portable system, I need to allow each platform to define my types, so that they are the same on each platform. It would have been really messy and asymmetric to have most done that way and some not. 
Wow...
It's a professionally oriented product, not DIY. In the pro world it's very reasonable. In the pro world, you put in a lot of work supporting fewer installation, unlike the DIY world, where the goal is to put in as little work as possible supporting lots of installations. So the price necessarily is higher. There's no point in us competing in the already over-crowded low end. That's where all of the big companies are going, who are willing to almost lose money in order to make a play for what they see as possibly the next big thing that will let them see and know everything you do (and a lot of it is really about data for them, not home automation per se, though I'm sure that a lot of the people doing the actual work do it for those reasons.) So it's pro or no really. &amp;#x200B;
This makes sense for things that you give to the compiler, like source file, but not for things the compiler is supposed to find automatically. The source file is a translation unit that I give to the compiler, so what name it has does not matter. But for things like include directives where the compiler is supposed to find something for you, the compiler can't just demand that if I do "*#include &lt;foo.h&gt;*" it should be looking for a file called *bar.h* I think the same thing would apply for modules. I assume the intention is not that every time I compile a c++ file I should have to point out all the other files where it should be scanning for modules. I assumed it would work more like include files in that I tell the compiler where there are include files and it also has a standard location it always looks. The compiler can't really scan the whole disk for module files, and I should not have to know the insides of a module to import it. This means there has to be a standard way for the compiler to find it, no? Or did I completely misunderstand the point of modules? I'm don't know that much about the details...
It absolutely can. Say you have a unique_ptr&lt;T&gt; and take a reference of its value into a background function/different thread (probably a very poor choice though!). The unique_ptr&lt;T&gt; could go out of scope on the original thread/function and now your reference is dangling. This is a good use for shared_ptr&lt;T&gt; obviously, but nothing in the language prevents a dangling reference, and yep I've done it before! This is probably what you meant by "don't do something stupid..."
No, not autistic. Like many software engineers I'm probably somewhere on the Asperger's spectrum. I'm definitely one of those folks who got kicked out of the lone wolf club because I never went to the meetings. I do suffer from anxiety, which back in the 90s used to leave me curled up in a ball on a regular basis. Eventually I figured out it was just the fear of fear itself (which Mr. Roosevelt clearly didn't have a good appreciation of) and now I don't let it send me off into heart attack land anymore. It does sometimes result in mild paranoia, but I know perfectly well that it is and just ignore it at as best I can. And, no, my company is not successful, at least not financially anyway. I'm currently living in a 40 year old single-wide trailer behind a convenience store, which sucks. And haven't been to a doctor in 20 years because I can't afford it, which doesn't suck in immediate terms but of course may end up sucking fatally at some point. I moved back to SC about 5 years ago (from my beloved Silicon Valley, which I missed tremendously every day) and all my family is around here. We have a once a month restaurant get together and some birthday/holiday things. So I get enough interaction in the human unit compartment from that to suit my needs. &amp;#x200B;
Your impression was wrong.
It's been covered up, but really the internet was invented to maximize negativity. It's clearly met its goals. Post a video of a puppy chasing a ball and people will start castigating you for exploiting puppies for your own sick gain.
Your example goes outside what I was talking about when I said "regular function". As soon as you move data between threads or share data between threads, the complexity goes up significantly (if you share data across threads, shared_ptr helps but is probably not enough to ensure correctness).
Not very funny to all the non-male programmers out there.
I'm guessing that they will survive, and probably (being clearly more mature than their male counterparts as evidenced by this thread) would probably actually get the joke. &amp;#x200B;
The mechanism by which the compiler finds the primary module interface file is implementation-defined — pretty much like header files, as explained above. That means the compiler has to tell you (i.e. documentation) what is accepted and what is not. Said differently, yes the compiler can impose further restrictions because the Standards give it that permission.
You asked how an implementation could require something like this even if it was not in the standard. And that is exactly the situation we are currently in: There is no standardized way how module names have to map to files, just like there doesn't exist any standardized way how includes are mapped to files. Just as with includes, an implementation is free to choose any mapping mechanism it wants and just as with includes, implementations will most likely pick one (or a few) same mechanism, but that is (unfortunately) outside of the scope of the standard.
Of course you would say that but I really want to hear what /u/STLport has to say.
&gt; If it is difficult to find the relevant files [...] It isn’t. The compiler tells you what to do. The concept isn’t new — it has been in practice for header files for over 40 years. Some people are however new to how and what we specify in the Standards, and are blowing things out of proportion. That being said, I’ve always said I wanted common notations and practice across implementations. That is part of the reasons why I called for the creation of SG15 — and not just for modules. We are making good progress and I am very much pleased by the work of Kitware folks in this space, in particular by /u/mathstuff. Nathan Sidwell has been doing an amazing job - check out his paper in the post-Kona mailing and also the GCC branch that contains his modules work.
It IS the language. The C++ language consists of the core language and of the standard library. Any definitions of what C++ is that try to represent this differently are plainly wrong. 
The Standard does not want to limit or impede on innovation in this space. The same goes for calling conventions, etc.
Agreed.
Why not make one way mandatory to support, but allow different ways also? It seems, either all major compilers agree and we have a de-facto standard anyway, or they don't and we have ourselves a really shitty situation. Why not have a proper standard instead of a de-facto standard then?
It just struck me why you probably saw a huge number of files. I used to have a single repository. Unfortunately, GIT doesn't deal with multiple repositories as thing, and since the CQC part of the code isn't public, I had to split it. I hate that because it's easy enough to screw up when you have just one. Anyway, a day or two before I uploaded it, I deleted the old repo and created two brand new ones and added all the files. When I pushed the CIDLib one up, presumably it included that history. So you would have seen every single file in the whole thing in a massive initial check in. Then followed by a couple final cleanup sweeps through the code with a bunch more files. &amp;#x200B;
Thank you so much. This will change everything
Thank you! I could never figure out the right incantation for installing header-only libraries!
Isn't this just a hybrid of a flat hash map and a hash trie? https://lwn.net/Articles/175432/
fair enough, within a function I agree a &amp; or const&amp; should suffice
Yeh, I'm going to sue someone for sending in a long bug report. You got me. That was the reason I posted this code, so that I could get rich suing someone who sent in a long bug report. Damn... Oh well, I guess another 25 years coming up with another plan.
Nope, I don't quite see the equivalence there.
Who is "we"?An implementation can mandate just that, for the standard this more difficult. 
I did something [similar](https://github.com/ttroy50/cmake-examples) when learning CMake a few years ago. It covers some of the same examples that you have and a few more.
Given their history of posts and comments, I doubt they have anything to do with STLport the library.
Are you planning to upstream the parallel hashmap to abseil?
Definitely. I have a pull request in: https://github.com/abseil/abseil-cpp/pulls
Sweet! I'm planning to use abseil in a project I'm working on. Perhaps I'll wait for your PR to get merged and do another set of benchmarking.
In the case where the collection isn't thread safe, isn't it hazardous for the container to act as if it is? What if I'm relying on the container being thread safe in the code I wrote?
I understand your comment was good natured in intent, but let's avoid calling out details of people's personal life or asking if they are autistic. Some could take it the wrong way.
My field has been using this trick for years to insert billions of keys. At least in my implementation, multi-threading is achieved slightly differently. We may use tens of thousands of sub-htables (e.g. with N=14) and attach a spin lock to each sub-table. We lock a sub-table on insertion. Because the number of sub-htables is much larger than the number of threads, the chance of two threads inserting to the same sub-htable is tiny. The spin lock rarely kicks in. This strategy allows you to simultaneously insert data produced from multiple threads. It is more flexible, without requiring you to prepare the data on parallel insertions. The downside: this won't work well for small hash tables.
Thanks man, I fixed the link in the PR. I hope the Abseil devs will merge it quickly, the new hashmap passes all their tests on windows and linux. Also let me know how your testing goes. BTW, if you feel like trying it right now, you can pull from my fork at https://github.com/greg7mdp/abseil-cpp.
Interesting, I was not able to find any reference to this technique myself. In the writeup I mention (and test) the same exact technique you mention above (see "Using the intrinsic parallelism of the parallel_hash_map with internal mutexes"), however even with a large number of submaps there will be lock contention, because when a submap resizes, it will take a very long time compared to an insertion, and the other threads will likely be blocked on the resizing submap's mutex.
From what I understand, your licence sates that you can sue your users for a few arbitrary reasons. This is a huge problem, no matter if you actually sue anyone or not. The license sates that you can do it, and that's probably enough to prevent a vast majority of people from using your code for anything serious. 
It's also &gt;3000 lines of added code. It will definitely take some time to review. &gt; if you feel like trying it right now, you can pull from my fork at https://github.com/greg7mdp/abseil-cpp. I could, but in my project abseil is pulled in as a git submodule, making it very annoying to replace the upstream url. That said, pulling in a PR for local testing wouldn't be a problem. If you're interested more in my use case, which admittedly is odd and can make a `std::unordered_map` way ahead of abseil counterparts, check [abseil/abseil-cpp#223](https://github.com/abseil/abseil-cpp/issues/223).
If you really must ask, it's best to do so with PMs, not in public.
The container's only responsibility is that the methods you call on it be atomic if it is marked as thread safe. You can't ask any more of a container than that. So it's not really acting as if it is thread safe per se. All of the methods you call on it are basic modifications, not extended operations. So in that sense it's not really different from any other thread safe objects you might create. It locks while inside its methods, and that's the only promise it makes. If you have methods that you want to be thread safe through the whole thing or in some part of it, where multiple operations are being done on the collection, then you have to either lock it from the outside across those operations, or the collection is protected along with everything else via some other sync mechanism, which is often the case of course. Mostly thread safe collections are used where you are almost always just doing single operations against it (one thread calls add, another thread calls move or get or something.) If you have other data that needs to be synchronized as well, you would likely sync the collection using the same mutex or whatever. Or you can make the collection safe and use its mutex as a general sync mechanism, if the bulk of the sync is just on the collection. But it's not often the case that any code called makes assumptions about the thread safety of the collection really. Not any general purpose code anyway. That's mostly the responsibility of the calling code that knows what is going on. If it wants to insure thread safety across anything other than calls directly to the collection, it has to lock the collection itself. Obviously, if you have some application specific code that you know should only receive a thread safe collection, because that's part of your design, you should add an assertion or a check for that. Once nice thing about the collections being able to be thread safe is that the ForEach() callback iterations will be inherently thread safe if the collection is marked thusly. So you can do iterations of the collection that will be safe if the collection is safe, else not. There's no need to lock from the outside for those. 
It didn't bother me, not a problem.
I think you have mis-stated your non-goal. Its not that you're **not** trying to be everything to everyone, its that you **are** trying to be everything for your CQC product, and everything not geared towards that is considered overly complex and unnecessary. Which is totally fine by the way, just be upfront about it. But one of the things you have clearly stated that you **are** trying to be is cross-platform and portable. So I think asking how your build system meets those goals when compared to an easy to use, well documented and well maintained tool such as CMake is a pretty reasonable question. An answer of "I'm not trying to be everything to everyone" is just a cop-out. If you really think about it, not trying to be everything to everyone is actually a really good argument for splitting up the repo into multiple projects. Then each one can have a very specific and targeted use case and user base. Keeping it all together and monolithic implies that you actually are trying to be everything, but only for applications with similar requirments to your CQC product. In fact you even say this in your readme: &gt;It's about a tightly integrated, one stop shopping solution for application development. You can't use bits and pieces of CIDLib, you go all in or not at all, because it's all a tightly integrated whole (though of course it is layered, so you can choose to jump in at whatever layer suits your requirement I know feedback like you have received in this thread can be hard to take, but how you respond now probably says a lot about you. You could shut down the conversation and say that everyone else are idiots who don't understand your creative genius. Or you could accept that maybe you're not the only smart person in the room and you can start to educate yourself more about open source practices and working collaboratively.
Many of the lines are for duplicated tests, but yes agreed it is a large PR. I don't think that the parallel_hash_map will help in your benchmarks, unless you use multiple threads and can benefit from less lock contention. Otherwise the main benefit will be lower peak memory usage when the map resizes.
For reference: [here](https://github.com/lh3/bfc/blob/69ab176e7aac4af482d7d8587e45bfe239d02c96/htab.c#L12) is the definition of hash table and [this function](https://github.com/lh3/bfc/blob/69ab176e7aac4af482d7d8587e45bfe239d02c96/htab.c#L60) implements parallel insertions. The implementation is slightly different from what I said. If not `forced`, the function refuses to insert the key. The caller buffers the key and retries at another time elsewhere in the code. &gt; when a submap resizes, it will take a very long time compared to an insertion, and the other threads will likely be blocked on the resizing submap's mutex. I tend to believe this is not a big issue if #tables/#threads is large because the multi-threading efficiency seems good. Nonetheless, I haven't carefully evaluated the effect. You could be right.
So my options are agree with you or I'm an arrogant a-hole? A major point of the whole thing is NOT to be a pieces and parts bin. I made that clear. I made it clear that I think C++ suffers badly because of this, and that it can't compete with languages like C# which have a monolithic, integrated set of libraries that are sufficient to do real world applications. That's got nothing to do with CQC or me being smart or not or arrogant or not. It's just my desired approach and one of the reasons why it's an alternative to the standard scheme of things and not YACL. Since I wrote it, it's written the way I think is best. That's just the way it is. I'm putting it out there for use of people who might appreciate this particular alternative. If there are none, then there are none. 
@attractivechaos, Thanks for the references. Have you ever seen this technique written up anywhere?
&gt;So my options are agree with you or I'm an arrogant a-hole? Come on dude, really?
I have to remember to use those damn smiley thingies. I was being darkly facetious. 
But anyway, the bottom line, it's not likely I'm going to get behind anything that is designed to turn it into exactly what I spent so long trying to make it not. Just accept that it is what it is. If that's useful to you, great, use it. If not, then it's just not.
I meant we as in "the standard". Too me it seems like it would be easier in practice if the standard mandated it. Then we wouldn't have a situation like with includes, where nobody knows what it *really* means, but in practice it works the same everywhere anyway.
I don't mind rewriting a larger piece of code to squeeze out more performance. Basically, what my benchmark comes down to is iterating over `Map&lt;std::string, Set&lt;Class&gt;&gt;` and it already happens under a mutex. Anyway, I'm going to test your hash map and report my results.
Sure, seems reasonable. However in that case you should update the readme to be less confusing, since not being "everything to everyone" is not compatible with "one stop shop for application development". It is important that developers know the type of project they're getting into when they contribute.
I'll make another pass at it before I push up the next changes.
I believe [this paper](https://www.biorxiv.org/content/10.1101/217372v1) uses a similar technique. However, it also adds bells and whistles on top of that. If you are not working in our field, the use of the idea may not seem obvious to you.
Hum, for iteration the parallel hashmap will be slightly slower than the underlying absl::flat_hash_map, so I don't think you will see an improvement there. However, I'm curious as to why iterating should be so critical for your use case. Maybe you can give me a high level view of what you are doing with these hash maps.
Sure. It's a completion engine and the part you're looking at does the following: - User opens a file in an editor - Ycmd scans for valid identifiers and populates the database. This isn't as critical, because it is done in the background, so the user doesn't notice any delay here. - Then, when user starts to type, the following needs to happen as soon as possible: - Given the current file's filetype and what the user has typed ("query" - `f` in `foo` or `up` in `unique_ptr` etc.) - Find the inner map that corresponds to the current filetype - For all inner map entries, figure out if the query can match the currently inspected candidate. - If it can, add it to the vector - When all matching candidates are gathered, sort them and present them to the user. The faster that code executes, the faster the user in vim, emacs or some other supported editor gets his completions.
C++ has pros and cons. One of the major cons actually doesn't have so much to do with the language (although the language isn't completely innocent in this), namely the fact that unlike many other languages there isn't really a coherent C++ community, and so we never really converged on a coherent set of tools. One consequence is that managing dependencies is a pain in the arse because there is no standard package manager that most people use, nor is there even a package format most people use that could be managed; `vcpkg` is probably the one with the largest support but that still has its issues (it can install a bunch of things but many of those still don't export `*Config.cmake` files that are needed to use the packages with `CMake` based builds for instance). This also translates to build systems, with `CMake` (which technically isn't even a build system) being mostly dominant right now but several others competing, each trying to solve different (perceived or real) shortcomings of other solutions in different ways. In short, it's a mess, to the point that many projects _still_ outlaw external dependencies entirely if they're not absolutely required. This has other consequences as well, with code styles being widely inconsistent - which is great if you hate cargo culting, but makes the aforementioned issue even worse because even if you set up external dependencies they'll all look out of place and will have very inconsistent ways to use them. So basically, it can be quite a bit of a headache. On the other hand, the language isn't nearly as difficult or weird as people are led to believe (not that there aren't many weird parts but the best way to deal with those is usually avoiding them entirely if you can help it). I personally still think working with C++ can be a great deal of fun, although if I were starting a project from scratch where I had full technical control and no non-technical constraints to force me otherwise I'd probably do it in Rust or Haskell instead lol. Anyway, don't worry about job opportunities. There are plenty of places that need C++ developers and this is unlikely to change in the near future. In any case, realistically learning new programming languages is _really_ not that hard so nothing is stopping you to be at least passingly familiar with most 'en vogue' languages of the day. Don't think of jobs so much as "C++ programming" or "Java programming" or "JS programming" - not that there aren't technical differences, but a competent developer will be able to do any of these given a little adjustment time. Finally, regarding your first point: While I don't want to discourage you or anything, but using a product isn't the same as developing for it. Just because you like _playing_ a football manager game doesn't mean you'd enjoy working on it. Also, don't get married to the idea of working for a particular company - that way you're just needlessly restricting the pool of available jobs. Heck, in this industry the company might not even be around anymore by the time you graduate.
I'm honestly curious what drove you to re-implement so much code on your own. Why not use other people's libraries and tools? Was the platform you were coding for so consistently bad it was just easier to roll your own everything? Do you think this approach is still justified today? Was this more due to necessity or preference? I guess what I'm really asking for is your perspective, now and what it was 10-20 years ago, and a bit of backstory. You put together a reasonably large system and developed it in a rather unique way, I'm always interested how such things came to be. &amp;#x200B;
Thanks for the explanation. I have a strong feeling that, for a given filetype, you should store all the possible candidates in a trie (or radix tree). Not only it will maintain the candidates sorted (eliminating the last step), it will make it very efficient to find all entries matching a given prefix.
&gt; it will make it very efficient to find all entries matching a given prefix. Notice the example where `up` matches **u**nique_**p**tr. It's not a prefix match. The [`operator&lt;`](https://github.com/Valloric/ycmd/blob/master/cpp/ycm/Result.cpp#L82-L151) is not really trivial. Apart from that, using a trie would make scanning more difficult. I also need to keep track of what candidates came from which files, so when a user edits that file, I know which set of candidates to update (actually drop and repopulate). An edit could introduce new identifiers, but also completely remove all traces of an older one.
To paraphrase a classic... A build system is like a joke: if you have to explain it too much, it's not that good.
Well, of course the devil is in the details. Some ideas which may or may not work out in practice: - when you see unique_ptr in a file, you could add both up and unique_ptr to the trie - for the scanning issue, you could keep one trie per file as you do today with the mao.
I'll have to trust you on that, cause from glancing at the paper it is certainly not obvious to me :-)
Echoing the first commenter somewhat, but I would say that C++ has depths to it that most languages don't. This a good and bad thing. Because of its age and popularity, you can do almost anything with it. But on the flip side, you'll work eventually with experienced developers that have done some brain-meltingly weird stuff with it. Good luck debugging that. If you're really hell-bent on learning c++ and have experience with other languages, I recommend the "effective c++" book series. Concise, industry-relevant tips that will get you through an interview and started writing decent code. I would not, however, latch onto one company. Especially a game company. They'll chew you up, exhaust your passion, underpay you, and kick you to the curb if you burn out. Or so I've been told. The product a company produces can have little or nothing to do with its internal work environment. Use your own judgment, of course. 
&gt; when you see unique_ptr in a file, you could add both up and unique_ptr to the trie That still doesn't work. The ranking algorithm ranks word boundaries highest (`up` in `unique_ptr`), then prefix (`un` in `unique_ptr`), but then, as long as all the letters in the query appear in that order in the candidate, the candidate is still matched (`uqut` would match **u**ni**qu**e_p**t**r`). The last is "level" is ranked the lowest, but *sometimes* it is what the user wants. Think of all the `str*` functions in `string.h`. The only word boundary is `s` and everything has `str` as the prefix. So why stop a user from typing `scmp` (or even `scm`) and get `strcmp` at the top? &gt; for the scanning issue, you could keep one trie per file as you do today with the map. I've tried that once and for some reason it didn't work very well. It's definitely worth considering again. I will give this another shot.
My personal software interests have always been in general purpose frameworks. I started that in the early 90s and worked for a decade in my off the clock hours (I was a mercenary back then) building up the core bits of CIDLib. So I did it because that's what I wanted to do, not because there needed to be any justification for it. I also worked at Taligent, which many here won't remember. It was an Apple/IBM effort to create a portable OS, which devolved into an IBM only portable library, which devolved into nothing and I went to their Java Tech Center and wrote the Xerces C++ XML parser (my other adventure in OS land.) Eventually I had so much code that I needed something practical to do with it. Being a geek, automation is something that I was interested in, and I worked in industrial automation for some years way back. So I decided to create an automation system that became CQC. Ultimately maybe that was a horrible choice. And of course I picked a horrible decade to go off on my own (walked out my ex-employer's door into the the Great Recession.) Anyhoo, modern high end automation systems like CQC are voracious functionality consumers, so that drove me to develop more and more underlying functionality to support it. I would very much try never to just implement something for CQC. If it had any general purpose utility, I'd try to implement it as such in the general purpose layer. Though there's still a good bit more than could be moved down if I had to the time to abstract it. And, though CIDLib is a lot of work, it's somewhat toy-like compared to CQC. So, ultimately it's been the 'easy' bits. I don't want to use other people's stuff, because I don't like that pieces and parts approach. I wanted something elegant and consistent and tightly integrated. You can't do that if you use other people's stuff. And of course if I used the STL then I am forced into a whole other world of compromises I didn't want to make, and I can't get 'under' the STL and create a fully integrated system from the ground up. It would have always been a big compromise. So I just have done my own. All that code now uses my logging system, my error system, my statistics system, my ORB, my UI framework, my streams, my collections, etc... There's no 'impedance mismatches' anywhere in the system. And nothing (other than the OS) is a black box to me. I can find and fix any bugs very quickly. I know everything intimately. I never have to wonder if I'm doing the right thing, or if this is the best approach for the tools. I seldom have to have look anything up. I can program in this system about as fast as I can think. Admittedly that's gotten slower in my waning years, but still. &amp;#x200B; I'm not against the mainstream thing. You do what you have to do. But unless you've lived in this sort of world, where you are in control of and totally understand everything, it's hard to appreciate how powerful that is. And a good demonstration of that is that I WAS able to write another 650K'ish lines of far more complex code by myself and keep it clean and tight over decades of enormous change. I don't think I could have remotely done that in the pieces and parts way. I guess it's like often happens at a smaller scale to all of us as programmers. You can jump in and do something quickly, or you can take more time and work out some infrastructure and flexibility and such. The latter takes more up front time, but usually is faster or at least more resilient in the long run. Maybe I've just taken that up 10 orders of magnitude beyond the norm. &amp;#x200B; One of the most painful, but probably most professionally beneficial aspects of it, is that I've had to jump repeatedly into one big new problem domain after another and figure them out. If you are looking for a way to keep your mental gears sharp, that's definitely one way to do it. OTOH, it means that I'm ultimately very much a broad generalist. And the open jobs for that types of are a lot fewer than for those are more of the narrow but deep type. &amp;#x200B; As to practical, no clearly it's not practical for almost anyone to do. It depends on psychopaths like me to do them in a completely impractical way. Even a large company would have a real problem doing something like this because their necessary time scale is so short, and they need to put it to immediate use, and it starts gathering evolutionary baggage quickly and in the end practical constraints maybe dictates that you just ride it till it dies then eat it. I was able to do it over a long period of time, with fairly minimal pressure, and the ability to cast off evolutionary baggage all along the way (though obviously there is still some amount.) &amp;#x200B; Anyway, this is like asking someone to show you their baby pictures. It's a dangerous question to ask.
Its dead. I was the primary maintainer of an internal fork of STLPort at my last job. PM me if you want contact information for the guy who took over maintaining it. This organization is in the telecommunications industry, but not an ISP or phone company, and I worked there for just under 5 years. 2 major product lines target their internal fork of STLPort exclusively, and migrating to the compiler supplied standard library (MSVC, Clang, GCC, all three) was constantly talked about but never actually done. Maybe they'll eventually do it ;) I did patch STLPort (the internal fork of it) to work properly with MSVC2015, MSVC2017 and MSVC2019. It was a real slog. Had to rewrite a bunch of stuff. If you really need it, I imagine they would be willing to give you a copy of the patched version of STLPort. Again, pm me if you want contact info. 
Being a software engineer specializing in C++ is great! I recommend this path. Of course, others are great as well, but I'm talking from my own experience. As you can see on Tiobe "hit chart" of programming languages [https://www.tiobe.com/tiobe-index/](https://www.tiobe.com/tiobe-index/) C++ is one of the main languages in use now. But the language depends on the application. There are different technologies in use when you develop w web service (also different at front-end, different at back-end), different when you make business software, embedded systems etc. C++ is mostly used wherever there is a need for high performance, but also highly complex code, like in game/media/graphics development or systems development, e.g. when you code a game like The Witcher 3, a web browser like Firefox or a word processor like MS Word.
I was talking only about the axiom case only for which "to costly to check" here really means "it might take hours just to check this and make the program impossible to use" (or sometime it's hiting NP hard problems etc) not "it will slow down the program a bit". If it was the last case yeah it would be audit.
Wow. How is Compiler Explorer still free. 
Unfortunately there is a huge amount of entitlement on Reddit about open source. Thanks for releasing this man.
Next time don't use a recording device with built-in compression. That brings out the noise in the original, necessitating the later "repair".
This looks extremely similar to java's ConcurrentHashMap design (see https://dzone.com/articles/how-concurrenthashmap-works-internally-in-java), which appeared in Java 1.5 (2004).
I would really appreciate a full example of using cuda, where cuda is not located by dpkg. (i.e. cuda was manually installed in say /usr/local/cuda/cuda90/...)
Inserting all subsequences of a word of length N into a trie would be an O(2^N) procedure. The search remains fast but the setup might be too hefty a price to pay.
Need to know what types U and T it's being instantiated with. It could be a bug or it could be a fix, i.e., a correct interpretation of the rules that was incorrectly being allowed before. But since the code presumably compiles on the latest GCC and Clang, the former is more likely. 
is there a way to generate a report of all the types it is trying to be instantiated with?
That could be a huge list. The ones being used in this particular case should be listed along with the error in the build output window. The "error list" window is only showing you a tiny portion of the actual output.
Your post has been automatically filtered because it appears to be spam (it was a link to imgur.com). If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Spam%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aznjnr/please_help_im_new_to_cpp_getting_weird_errors/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Letting people know what is off topic on r/cpp doesn't need to be a hidden affair.
&gt; I am a big fan of the football manager game and i would love to work in the company, sports interactive, that develops the game. I would think long and hard before getting married to game development. It's still a pretty volatile market and is notorious for dev abuse. Other software development tracks tend to offer a lot more stability and work/life balance at the price of being fairly boring end-products. &gt; How is it like to work with c++, as i know it is really powerful, but somehow languages like js, python, java are easier for me to learn It has its ups and downs, like every other language. It's very hands-off, which lets you do some really cool shit (TMP, for example) but also lets you gleefully shoot yourself in the foot (non-virtual destructors consuming memory, multiple inheritance, etc.) without so much as a peep. However, it's not nearly as daunting as developers like to meme about: it's still an OOP language so the basics you've learned in Java will transfer pretty well. &gt; what kind of projects should i do to be able to become a junior software engineer in c++. Basic C++ literacy (if I picked a random project you've done in another language, could you redo it fairly easily in C++?) and surface knowledge of common boost libraries (karma, qi, and smart pointers) should be enough to get your foot in the door. If you have the chance, taking a compiler course would be really helpful since it'll give you a lot of insight into what's probably going on under the hood.
I've never even heard of karma or qi (looking it up, is qi the same as spirit, or a sub-library?), much less used them, and smart pointers are in the standard library. Definitely not things I would recommend to someone who's just getting started with C++.
It looks like a similar concept, but not really the same thing (although to be able to tell for sure I'd have to look at the implementation).
I’m actually have a hard time thinking of reason why this isn’t a good idea. Well done, OP. So, in theory, we could have a “Project.h” which would include other “ProjectX.h” files, which in turn have source includes. Personally, if there was a “include source folder” type of source include as well, that’d work for me. The only possible reason I can think of why it “can’t” be done would be that as far as I know (and I’m likely wrong) the preprocessor is the same between C &amp; C++. Also, the committee wants to avoid the preprocessor as much as possible. 
Even if it became nonfree, it would be easy enough to spin your own instance, the code is freely available.
If the standard didn't allow this, it would be pretty much impossible to be standard compliant.
If you have circular header dependencies, you just put the 2 headers into one module. Easy to solve and less bad surprises about something getting included without knowing or linking errors.
/r/cpp isn't stack overflow. it isn't for tech support.
&gt; I've never even heard of karma or qi (looking it up, is qi the same as spirit, or a sub-library?) They're the main components of spirit. If you've used spirit recently, you've used either one or the other. &gt; smart pointers are in the standard library. Boost has more expressive pointers, specifically intrusive_ptr, that are absurdly useful when you start working on memory management. Which IMO is fair game if you're trying to label yourself a C++ dev. &gt; Definitely not things I would recommend to someone who's just getting started with C++ Neat, except that's not what OP's asking. They specifically asked what it would take to be considered a Jr. Dev with a focus on C++. That's a *very* different question from "How do I develop competence at C++?" or "Where is a good starting place for someone who knows zero C++?"
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/azom5u/good_book_or_tutorial_on_modern_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Intrusive pointer is nice but not necessary very often. Very optimized setups aren't using shared pointers to start very often, and make_shared gives you some of the main benefits of intrusive pointer. Right, this knowledge is still not necessary (or even close) to be considered a junior dev, or even a mid level dev, or even a senior dev. And I don't spirit (or intrusive pointer) is the most common boost library. These are just libraries you happen to like, or are particularly useful in work you've done. I really like Hana for example and I've found it very useful, but I'd never call it necessary, or the most common boost library. I think just knowing C++ itself well, and understanding the systems API (sockets, files, memory, etc) is enough to be considered a mid level C++ dev. And a pretty good one in fact; most mid level people I interview don't even understand those well even.
what if you dont have the source code to those libraries? even if you do, now oyu compile each library in your executable and that's why we have shared libraries. to share them. how do you do parallel compilation then? what if you have a 1 mil lines project and the resulting c/cpp file is gigabytes long and the compiler crashes because the AST is too big. 
Ah, yes, it is same as google::DenseMap and llvm::DenseMap. 
I'm on board that this is clever enough to be thought about. Having 'source' as the keyword is not a good idea though. #include unit, #unit, #compliation, #pragma unit, etc. etc. might be better ideas. 
What in the hell are you even talking about
Is this a question or a statement? Also my experience with kdenlive was that there was no need to fuzz it, unless you were trying to find some arcane combination of input that _didn't__ make it crash.
The documentation for Gnu make is actually quite a good starting point.
How does this work for symbols that are intended to exist in only one translation unit? It seems like anything defined anywhere (say, pnggamma has a gamma correct table) would then exist in every translation unit.
I don't think this is meant to include the source of the .cpp file, that could be done with #include. Maybe #pragma depend would be better.
OP is suggesting basically the ability to add a translation unit to a project/build within the language, which makes your points a non-issue.
You set CMAKE_PREFIX_PATH to tell cmake where your dependencies are installed when they are not installed in the standard locations. It’s a list and you can give it multiple paths. The path should be to the install root(ie the path you set with CMAKE_INSTALL_PREFIX).
&gt; Yeh, I'm going to sue someone for sending in a long bug report. You got me. And I'm sure you think your sarcasm/"dark facetiousness" will go really far in court, right? It doesn't matter if you can fulfill your end of the license; the point is that no one will touch it regardless. Because it would cost money to even deal with – wasted money – because your license isn't serious. &gt; I need some time to look through the options. Time you don't have, like you've said so many times...
If I understand you correctly, you are talking about including the object file of the "included" source in the final executable, i.e. giving it as an input to the linker, not the compiler. This is supported by MSVC with `#pragma comment(lib, "libname")` And it doesn't remove the need for a proper build system, as other commenters mentioned already, as we need to handle dependencies, know when to invoke the compiler on a specific source file and when the previous compilation output can be reused etc.
The idea looks fine on the surface: add building facilities/awareness to the language. The problem with that is, as usual, that as soon as you start talking about build systems in C/C++, there are a lot of things to take into account. For starters: * Several languages: in this case, the example talks about a C library, not a C++ one. This moves us into the second point. * Compilation flags support: many projects require flags that you may not be happy to share, even incompatible ones: language version, strict aliasing, different warning/error levels, optimizations, FP mode... * Now that we solved that, we need a way to compile in several compilers/platforms. That means different flags. That means conditionally defining those options. `#ifdef` to the rescue. * What about several configurations? Debugging, production, etc. More `#ifdef`s, I guess. * What about commands that need to be run during configuration? A `#build run` command that sets a preprocessor symbol? :) * ... So, in the end, either you need to support some of these things (ending up with a DSL intermixed with C++ code using `#build` preprocessor directives equivalent to your `Makefile`s and friends), or you can only use it for dependencies that can be included as-is as if it was code from your own project (same language, same flags, no non-trivial configuration). Eventually, you realize what you really want are 2 related things: * To be able to simply say, in your C++ code, something like `using System.Console;` in C# or `import zlib` in Python; leaving out all details on how to fetch that interface. C and C++ have support for that by using headers, but we are still lacking a proper way to represent the concept of a module, instead of simply doing text replacement. That is Modules. * A standardized/de facto build system, which in turn allows to have a proper standarized/de facto package management systems. This brings you the fancy stuff people love like auto-downloading from a Git repository and all those things. That is how you end up with dpkg, pip, cargo, etc. For C++ you have some contenders like vcpkg, CMake, build2, Meson, Boost's system... that try to fix this, but it is a mess. None is ubiquitous, libraries don't support all of them, etc. so you end up having to configure your dependencies manually, as usual. vcpkg tries to go the other way, supporting most libraries themselves instead of the other way around. Some people are hoping that the first point (Modules) end up helping to achieve the second point.
The preprocessor makes it very hard to do an IDE (and humans, too) since it changes the code in arbitrary ways before it is seen by the compiler. So the direction is to remove the preprocessor, not to extend it's functionality.
No one believes that someone other than you or a friend of yours would actually care. Blame the internet all you want; if you got better reception in person you wouldn't be spending so much time you "don't have" posting this on the internet.
In my experience the language doesn't make a huge difference. The actual type of work is all that matters to me. I'd probably like to use Swift or some other convenient modern language, but I have no interest in working in the fields that use Swift. You have to pick the job you want and the type of projects you want to work on and then you are stuck with the language those projects use. Sometimes you'll have a few options (e.g. a few teams at my work use Rust) but generally you're rather stuck. 
lol
Any chance these examples could include compilation invocations? I haven't been paying attention to modules at all and google searches are giving me wildly varying results.
Nice reply. Fully agree about the somewhat messy and hard to grasp permutation rich ecosystem. However, I believe it does have an upside. That is, it kind of forces a lot of people to actually understand what the differences are, why they are there, link and build specifics and so on. Sure it is a PITA but I feel it leads to a higher level of wholesome understanding in the C++ community. With other communities I have seen (and indeed been part of) like Java for example, there is a number of people that simply rely on some standard toolset or framework and never really understand what it does or why it's there in the first place. One uses it as everybody else does and you don't question it too much. Errors coming out of it are often ignored and replacements are not really considered. IMO this can lead to a lower overall quality and efficiency of what comes out of it. So I do feel like I see a high level of quality in many modern C++ based projects. Of course, like all generalizations, this is complete bullshit but my opinion nonetheless. As a side not to OP, C++ is a great language to get into at the moment as it is evolving better than it ever did. Games, VR, AI, networking, you name it... Except for one thing: UI. Everything that has a UI is generally painful, cumbersome and boring in C++. I'm looking at you, Qt! So, enough with that Monday morning blather. Off do do some C++.
people are actually doing this using unity build, except you must take care name pollution.
Partially, I'm already using ccls (which uses clang) as language server, I'm compiling with clang, but for debugging I'm using my own gdb plugin. It would likely take quite some effort to migrate that one.
Thank you for all the kind words, really glad people are finding it helpful!
It seems to me that people keep constantly assuming that adding some sourve files to your build script in language X is somehow difficult and hence needs to be further simplified. (E.g. via header only/ single file libraries or suggestions like this). Combining a bunch of c++ files into an application isn't difficult in any build system I'm aware of. Its not even difficult to do this with a blank compiler invocation (g++ a.c b.c d.c)
Do you know you can format your code in WordPress? &gt; Therefore, to match the new pointers in C ++, always write the delete pointers and always type the code between these new and delete operator the explained in the above example. How about RAII?
This isn't really the place to post about basic C++ concepts.
Sorry..I will keep in mind
Completely different story. What the OP suggests should still leave you with N individual translation units - just as if you involved the compiler with N source files. 
Quite often a macro based technique is much more readable (both for IDE as well as for humans) than the equivalent TMP code. Sometimes I wonder if improving the preprocessor wouldn't have been a bet solution for some problems than banning it and trying to come up with "clever" ways to achieve the same in language. In any case. I think that particular feature is useless and it wouldn't really be a preprocessor feature anyway.
I think he is actually talking about a preprocessor command that should trigger (independent) compilation of that source file and then link it into the final executable.
Oops, my bad, the "if you really must ask" was meant about the original comment.
I'm curious how the compiler finds the module to import
Ah. Yes, right. I would generally advise against asking people that in general. But PM &gt; public
&gt;Despite the potential speed-up from modules, an import boost; that imports the entirety of Boost could be deathly expensive to compile times! Isn't imported modules supposed to be already precompiled or at most compiled once? &amp;#x200B;
Term 1 is what a lawyer would call vague and thus open for interpretation. Thus it's not really conflictive, just open ended.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
&gt; or you can only use it for dependencies that can be included as-is as if it was code from your own project (same language, same flags, no non-trivial configuration). Considering that that is the most common case, I don't think that would be a problem. For everything else you can use a "real" build system. Personally I still don't think it is worth standardizing, but not due to limited functionality. 
Well, maybe, but I took the part that has a clear design and usage. The part of the compilation raises many questions. For example, how is the inclusion in more than a single file handled? The compiler should know somehow to compile it once? So the compiler becomes a build system? Of course this removes the need for a build system, if the compiler is one already.
That's added maintenance load on the programmers unnecessarily. Plenty of languages have solved the module question without doing this. We don't need more boilerplating in C++
Why I don't see other comments? 
I would say, defenately look at how other languages tackle problems C++ faces, and then research why c++ doesn't do that. This gets you into the interesting parts of the language. For example, the c++ &lt;type_traits&gt; header is incomplete if you look at d's 'module std.type_traits' how about coroutines in python or C#? How about memory management in Rust? The difference between the Boehm gc for C/C++ and java's gc.
Almost every large code base contain parts with questionable quality.
&gt; There are still good reasons to use PIMPL with C++ modules) That frightens me more than anything else. 
I think it is not about compilation, but you are importing a whole lot of symbols, which might showdown certain operations, but just the import shouldn't be a big concern compared to including a header.
Modern version is [here](https://hg.openjdk.java.net/jdk10/master/file/be620a591379/src/java.base/share/classes/java/util/concurrent/ConcurrentHashMap.java) (OpenJDK 10) old version (from OpenJDK 6) [here](https://hg.openjdk.java.net/jdk6/jdk6/jdk/file/8deef18bb749/src/share/classes/java/util/concurrent/ConcurrentHashMap.java) 
&gt; Another thing I'm looking for is a good introduction to using Makefiles.
&gt; Another thing I'm looking for is a good introduction to using Makefiles. I suggest skipping the Makefiles and diving into CMake instead. Why bother learning a single build tool if you can use a generator instead. For a learning material, the Stroustrup's `The C++ Programming Language` was the best thing for me personally
You would probably have been better off picking something akin to the LPPL rather than rolling you own license, if the primary goal is to "avoid having multiple, incompatible and different versions out there". The unknown legal consequences of a homebrew license will probably scare off most even slightly serious projects from using this library.
Yeah, I probably should have written CMake instead. Same thing applies: I've "used" it before, but never in any systematic manner.
It could be useful to test with different value sizes
ABI.
How well does this work in practice?
&gt;A build system is like a joke: if you have to explain it too much, it's not that good. And in almost every thread about CMake we see recommendation to buy book about CMake... ( I would say project files of a build system itself should be the only documentation a developer needs in 95% of cases. &gt;Then again, the market isn't exactly swelling with good (or even acceptable) build systems. Meson, QBS.
Module map files. GCC supports a file, socket, or program which it uses to ask "I need module `M`, where is its BMI?". It seems the other compilers will support similar mechanisms.
`sizeof(myclass)` is part of your API/ABI, so PIMPL is still useful.
Don't they usually solve it by requiring a specific file name?
Should not be relevant as long as my special member functions are not inlined and the size of the class doesn't change.
In particular, the [LPPL](https://opensource.org/licenses/LPPL-1.3c) would probably cover the main goal of distinguishing forks from the "original", since it requires derivatives to be "clearly and unambiguously" identified as such.
&gt; the size of the class doesn't Layout as well. Both is much easier to maintain with the pimpl idiom.
if it became nonfree, I’d buy it
Yes, it would be cool to get a dump, for example, queries to Google and play with various hash functions .. I have a theory that you can accelerate speed if you use a simpler hash function for text requests
So, to use symbols from the implementation (for PIMPL) we must create a partition to be able to import it (since a module can not import it self). And if we have a partitioned module `foo:sub`, and want to use the PIMPL idiom, we have to create another partition, say `foo:subpriv`, to be able to import it with `import :subpriv`? Or can a partitioned interface module `foo:sub` import its implementation with `import :sub`?
Amazing article. Looking forward to seeing the next one!
In theory, for what I see, an import boost will only show you (in a well-designed world) the API exported. So it should be faster than headers anyway, is that correct?
Does ccls provide similar functionality to clangd? Thanks for introducing me to kokoune. I will check it out. The server-client architecture is a feature that I'd really want to see in neovim. I've been frustrated by some of neovim's limitations. Maybe I just don't have a deep enough familiarity with vim script. I've been trying to build a LLDB plugin for neovim myself.
What happens here ? how do i know which module get\_phrase was imported from ? [`//speech.cpp`](//speech.cpp) `export module speech;` &amp;#x200B; `export const char* get_phrase() {` `return "Hello, world!";` `}` &amp;#x200B; [`//speech2.cpp`](//speech2.cpp) `export module speech2;` &amp;#x200B; `export const char* get_phrase() {` `return "Goodbye Cruel world";` `}` &amp;#x200B; `//main.cpp` `import speech;` `import speech2;` &amp;#x200B; `import &lt;iostream&gt;;` &amp;#x200B; `int main() {` `std::cout &lt;&lt; get_phrase() &lt;&lt; '\n';` `}`
Depends on the strength of the ownership model. (My understanding; what follows may well be incorrect.) In Itanium, module names are not mangled into symbol names, so this is actually an ODR violation. MSVC would probably error on an ambiguous call.
Assuming BMIs are better at allowing faster parsing, you'd get less I/O during compilation. You may also benefit from the filesystem cache in that instead of reading 100's of files for each TU, you read that set once, memoize into a module BMI and other compilations reuse that BMI.
&gt; Considering that that is the most common case Well, I would say it is the opposite. It is very rare that a library fits all the following conditions: 1. You have the source code. 2. It is not a header-only library. 3. It works (and, critically, does not trigger UB) when compiled with your flags. 4. It does not have complex pre-building generation/configuration. 5. Such usage is supported (be it upstream fixes or actual paid support). 6. Such usage is allowed by the license. Even if you satisfy all those, e.g. if you only talk about very portable MIT/LGPL C libraries or very popular Boost's non-header-only libraries, that does not mean it is proper: upstream will be more likely to ignore your bug reports, upgrades will be more difficult, etc. In the end, you are not using them as intended and you are overriding their build system. Any issues are on you and only you.
The more I see modules, the less excited I am. :-/ I mean, look at the very first example: import speech; import &lt;iostream&gt;; int main() { std::cout &lt;&lt; get_phrase() &lt;&lt; '\n'; } How does `get_phrase()` appear in the top namespace? What if I have thirty import statements - how do I guess which of these contained `get_phrase()`? Of course, I can write the code in the `speech` module in any namespace I choose, but again, that namespace appears magically in the importing file, and has no specific connection to the "import" statement. I know, I know - because of namespace resolution and a dozen other things, we can't have speech "imported into a namespace", resulting in `speech::get_phrase()` above. I just wish there were a more elegant solution for the reader. I spend much more time reading code than writing it...
Yes it should be much much faster. Not only don't you have to parse all the code c++ code again and again, but as you said, the compiler should only see the interface not all the implementation details that boost puts into the `namespace detail`, but (because most libraries being header only) which the compiler still needs to process and stored every time you use that header.
Modules are orthogonal to namespaces. It's only purpose is to share symbols to other translation unit. Whether they are in the global namespace or not. There is also ABI. If you had a function `potato(int)` inside the `garden` namespace, you may want to move that into a module without breaking ABI, and even ship a header that exposes functions from your modules. Name mangling must be the same for exported functions. If this is a possibility, then you must admit that you cannot have the same name in the same namespace exported by two different modules.
Yes? Specific file name, specific folder name or connected-to-path name or similar. This would IMO be a lot more of a sane approach than keeping an external listing.
Every single header only library must effectively staisfies your requirements (of course we don't really need such a feature for using them, but it might still improve compile-times). And most modern non-header only libraries I've seen also do little more than saying "compile all those sources" for most of their code base. Againm use a build system iif you have to deal with corner cases or have more complex requirements, but most of the complexity I've seen in build files is 1) Around tests and or installation 2) Only compile file X if condition Y is satisfied, whre condition Y can most of the time just as well be detected with the preprocesspr (and often you do just that - gain in code anyway). If nothing else, every single code base I've seen has one or more variables called `&lt;some_name&gt;_sources` that holds a set of cpp files, which could be replaced by that technique and generally speaking: If this ever were standardized even more libraries would make sure that they can be compiled in that manner. Again, I'm not saying it is a useful enough feature to go into the standard, but I think you are highly overdramatizing the situation.
Why should the layout be important?
Discussion from [three days ago](https://www.reddit.com/r/cpp/comments/ayeg0b/making_c_exception_handling_smaller_on_x64/).
ccls indeed provides similar functionality, I've never used clangd but it's also a language server for C++, so you can get references, definitions... I'm always happy to spread the good word of kakoune, if you're already using neovim it shouldn't be as much of a shift as if you used a traditional IDE. You can ask around on /r/kakoune, [https://discuss.kakoune.com](discuss.kakoune.com) or #kakoune at freenode. Luckily LLDB also speaks gdb's "machine interface" which my plugin uses so it might be possible to support both gdb and lldb, I need to ask around on their mailing list. 
it still doesn't solve the "proprietary lirbaries" issue.
Yes, but keeping that fixed is relatively easy. E.g. reserve a bit more space up front. I'f you compare to the overhead of dynamic allocation you can be quite conservative and if you really run out of space one day, you can still put some data on the heap. My main point is that if modules still don't allow me to completely hide my implementation details without pimple, then they don't offer the level of isolation I've hoped for.
Because (at least when talking about the Itanium ABI) changing the order of members would change their offset in the class, and thus is ABI incompatible. 
Why do you care about their offset in the class, if you only access them through member functions 
It can lead to changing the class size. If you had a series of `bool`s and you change it to interleave `int`s, you could end up with more padding then you did before, changing the `sizeof`. (and yes, I see the other thread about `sizeof` so I'm leaving that part along)
It seems you didn't understand OP's suggestion. If you don't have the source code, the feature simply does not apply, there is no issue here. And since you have independent TUs, you don't have "extremely large ASTs" and you still have parallel computation.
I assumed the root problem is that they don't want to do that.
 if ( CMAKE_CXX_COMPILER_ID MATCHES "Clang|AppleClang|GNU" ) The `Clang` part will already match `AppleClang`. You want either `STREQUAL` or `REGEX`. Please correct me if I'm wrong.
&gt; This makes sense for things that you give to the compiler, like source file, but not for things the compiler is supposed to find automatically. &gt; &gt; [...] the compiler can't just demand that if I do "#include &lt;foo.h&gt;" it should be looking for a file called bar.h This is where you are wrong. The "automatically" is defined by the standard as "in an implementation defined way". Applying this to include directives (where it is defined the same way) this means that the compiler CAN in fact demand that "#include &lt;foo.h&gt;" refers to a file called bar.h. Obviously compilers are not doing that because it would be surprising and people tend to hate surprises ;-) So for modules it will be similar: The compilers WILL specify how to find modules. This may (and I hope will) result in module "Foo" means look in a file called "Foo" located in some directories which have default values (like /usr/include) and can be changed by command line parameters. &gt; This means there has to be a standard way for the compiler to find it, no? No. As with includes and the `-I` flag a quasi-standard way will form though. &gt; I assume the intention is not that every time I compile a c++ file I should have to point out all the other files where it should be scanning for modules. I assumed it would work more like include files in that I tell the compiler where there are include files and it also has a standard location it always looks. The compiler can't really scan the whole disk for module files, and I should not have to know the insides of a module to import it. Yes. I expect what I described above: The compiler gives you a flag and defaults WHERE to search for module files and it MAY enforce a naming convention for the files belonging to a module. Otherwise it will be highly inefficient. Assume you don't have a naming convention. Then the compiler would need to scan EVERY file in EVERY search folder for the module. And there might even be conflicts (module Foo defined in a file "bar" and another file "baz"). A naming convention solves this.
If I were overdramatizing the situation, we would have had a de facto build system and package manager for C decades ago and nobody would be excited about Modules :^)
Feel free to contribute on GitHub!
You can use pimpl without heap allocations if you just use pimpl with placement new.
Great feedback, thanks. /s
Wouldn't that require some allocation wrapper like `std::make_shared`? That would then mean you can't compose your class' allocation optimization with `std::make_shared` either. It'd be nice if there were a way to compose that.
True, which just demonstrates that the there is no inherent reason why the private members of my type have to be known to the compiler at the user site, as long as size and alignment is known. I was just referring to one of the common reasons why people employ pimple: To be able to add members later without changing ABI.
Is there a reason why each module is not it's own namespace ? Is this documented anywhere ?
I don't know off hand. Reasons for not doing things are usually only in the minutes unfortunately. If I had to hazard a guess, it's probably to do with lookup rules and having to then opt-out of the namespace if you wanted to provide a specialization for `std::swap` and the like. There's no syntax for that currently.
What is the reasoning why?
The responses here are quite concerning - some combinations of inferiority/envy/entitlement - hard to say for sure. It's an excellent body of work, OP. Thanks for sharing and keep doing what you're doing.
&gt; Yes. I expect what I described above: The compiler gives you a flag and defaults WHERE to search for module files and it MAY enforce a naming convention for the files belonging to a module. Otherwise it will be highly inefficient. Assume you don't have a naming convention. Then the compiler would need to scan EVERY file in EVERY search folder for the module. And there might even be conflicts (module Foo defined in a file "bar" and another file "baz"). A naming convention solves this. So basically everybody agrees there will be a de-facto standard that all big compilers use, and that it is necessary, because otherwise modules will suck? But we don't want to turn this de-facto standard into a real standard. I just don't understand this... Are there compilers out there that are so different that they can not make basic assumptions about the environment, like the existence of a file system?
Not sure, but at least I assume you don't want to force a big module to be one single file.
You're limiting your options by starting with \`std::ifstream\`. How about making a [mapped\_file\_source](https://www.boost.org/doc/libs/1_69_0/libs/iostreams/doc/classes/mapped_file.html#mapped_file_source)?
Thanks, maybe it would be my next task :) I heard that mapping is faster but never try it out.
&gt;Future with C++20 &gt; &gt;For example with [P1091](https://wg21.link/P1091) you can capture a structured binding. I was quite surprised when I discovered that currently it's considered ill-formed. Interestingly, [among all the major compilers only Clang cares about that](https://godbolt.org/z/O-btku).
Thanks! 
Lookin at the code again. It is neither leapfrog nor semi-implicit Euler because of how he decided to do the calculations for the position update. His position update is furthermore missing a factor of 1/2.
To be honest, more often than not the answer why C++ doesn't do something a certain way is "because when it was introduced in C++ nobody had thought about the other way now seen elsewhere yet, and now we are stuck with it because of backwards-compatibility. "
Mostly ABI and re-exportation. [See my comment below](https://www.reddit.com/r/cpp/comments/aznum0/understanding_c_modules_part_1_hello_modules_and/ei9rykj).
&gt; So the compiler becomes a build system? Proposed "C++ modules" is de facto such a build system. Any good module usage/inclusion mechanism should have something like *#include source|unit "..."* under the hood anyway. Instead of hypothetical modules I would rather want that as pure mechanism: Issuing `g++ a.cpp` where a.cpp is // file a.cpp #include source "b.cpp" #include source "c.cpp" Should be a direct equivalent of current g++ a.cpp b.cpp c.cpp So that will cover most of modules use cases and, what is more valuable I think, tons of exiting libraries. 
Meson is quite simple to use.
&gt; but as you said, the compiler should only see the interface not all the implementation details that boost puts into the namespace detail I don't understand how this can can work. If you have e.g. namespace boost { namespace detail { template&lt;typename T&gt; struct whatever_trait : and&lt;is_foo&lt;T&gt;, is_bar&lt;T&gt;&gt; { }; } template&lt;typename T&gt; void do_stuff(int x) { if constexpr(detail::whatever_trait&lt;T&gt;) { ... } } and import boost; int main() { boost::do_stuff&lt;float&gt;(123); } the compiler still needs to make `detail` visible to the caller because it's the caller object file which is going to instantiate do_stuff. 
What is your problem with Qt? I have always found it to be pleasant to work with when developing UIs.
!removdgfko
So you still need the `#include` of the corresponding header file(s) to get the declarations of entities defined in `b.cpp` and `c.cpp` and used by `a.cpp` file?
It would be nice if cmake had set of supporting utilities to create a default project from templates like these. Example: cmake-init header-only myheaderonly-project Instead of searching the internet over and over again. (Sent from phone. Please excuse formatting)
Atm it's implementation defined (IIRC), the standards committee is drafting a technical report with guidelines on various aspects of the implementation of modules
Why though? You can have a cmake file just as small that will work across other platforms and compilers, with exported compile commands for various editors and ides, with reasonable defaults for debug vs release mode etc. 
So basically the mechanism specified in [P1184 - A Module Mapper](https://wg21.link/p1184)? When I posted that paper on [reddit](https://www.reddit.com/r/cpp/comments/amhmiw/a_module_mapper/), /u/vector-of-bool and /u/c0r3ntin informed us that SG15 considers it a non-starter? What changed?
Great article! How does module interface and implementation unit work with inlining and templates? Currently, templates and inlinable functions / types are required to be defined in headers. How does that work with modules? Can types and functions defined in implementation units be inlined? How about templates - can templates defined in implementation units be exported.
It's mostly because structured bindings are weird beasts themselves and actually far from regular variables. It's uncanny at times.
And there you have the endless source of frustration that is the two independent definitions of what the axiom contract level is. One definition, very much in line with how default and audit are defined, is that it is for checks that cannot be checked at runtime. (They have neccessary side effects, they take too long to ever execute, they simply cannot be implemented in the language, or in some cases you just haven't gotten a chance to implement them yet). The other definition is the mathematical one. But why the hell would you ever want to write a check that COULD be checked but remove the option to turn on that check in some build modes for debugging? The mathematical "this should always be true" meaning of axioms is a statement that is true for ALL contract checks - you expect them all to always be true. This meaning for the axiom contract level is pointless and distracting. Axiom was a bad an horribly misleading name for what it is actually useful for.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/azog3t/whats_a_good_exampleoriented_resource_for/eiaatas/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I just thought I'd add on to what the previous comment said. I found principles to be an incredibly thorough book and if you're still a beginner you should definitely check it out. However, I don't think it touches on makefiles or any kind of build system for that matter. 
&gt; One definition, very much in line with how default and audit are defined, is that it is for checks that cannot be checked at runtime. (They have neccessary side effects, they take too long to ever execute, they simply cannot be implemented in the language, or in some cases you just haven't gotten a chance to implement them yet). So if we are supposed to take this definition of `axiom` over the mathematical one, what would be the difference between `axiom` and `audit`? I thought `audit` was for terribly slow and impractical checks.
thanks
&gt; C++ modules are a huge change. To discuss every aspect of them will take more than a single post. We’ve covered the bare basics, but there is so much more to discuss. There's... more? I'll already need to study this post in detail to make sense of the various ways to seemingly do the same thing. Awesome post btw.
The big issue SG15 has with P1184 isn't the mapping, but that it is done by having the compiler talk with an external process over a pipe. It is very expensive and complex when compared to a module mapping file, which could satisfy any use cases we can think of. We had a general distaste for having external mappings because it would be inevitable that every platform and every build system would implement them in wildly different ways (and probably _incorrectly_). The C++ Ecosystem TR gives us a foothold on which we can prescribe a common behavior for how modules should be mapped, even if that is a module mapping file. The current design we are leaning towards is having the compiler provide a "module scan" mode, wherein it can report the module information in a way that is reliable, correct, and (importantly) fast. SG15 is discussing what the interface of such a "module scan" mode might look like (started by /u/mathstuf).
The reasons I had in mind aren't related to compile times or ABI at all. PIMPL is practically useful for a few very common purposes: - Creating cheap-to-move types, where the only data member is a `unique_ptr`. These can be moved by a simple pointer exchange. - Creating address-stable objects. If the object or related APIs require that the object data not move, storing the real details in an immobile implementation type is the best way to do it. - Creating copyable `shared_*` types, where the PIMPL is a `shared_ptr`.
&gt; The current design we are leaning towards is having the compiler provide a "module scan" mode, wherein it can report the module information in a way that is reliable, correct, and (importantly) fast. SG15 is discussing what the interface of such a "module scan" mode might look like (started by /u/mathstuf). Correct. I'm working on a new patch of GCC / CMake which uses the format discussed on the list this past week. This scan mode's output is then used to generate the information for the build executor and the compiler (module map file). Ideally there will be just one file format for the scan output. I can understand different module map formats, but since the build tool only has to write that, it's not as big of a deal as different scan output formats.
As far as I know auto [x, y] = make_pair(1, 2); is the same as std::pair&lt;int,int&gt; temp = make_pair(1,2); auto&amp; x = temp.first; auto&amp; y = temp.second; What's the pitfall that I don't see right now?
On Itanium, they are mangled into symbol names. 
I do not believe there is any use case that _requires_ separate partitions. You can define the private implementation within the same module unit and simply not export it. This example was just illustrative of what implementation partitions might look like.
The first surprise is that x and y are references and not copies.
These are good questions and will be the subject of a future post. (And are also the subject of some lively debate on modules.) I'm hesitant to talk definitively yet about `inline` because there is a paper in-flight that might change the meaning of `inline` within module units. As for templates in implementation units: I do not believe it is possible to export a template that is defined in an implementation unit. Its first declaration must be in an interface unit and have the `export` keyword.
axiom is for impossible checks that cannot be validly turned on. Checks with side effects (most common example is that of seeing if an input iterator has data available, though many systems might have preconditions that cannot be checked without altering state) are one common category - the predicate of any evaluated check having a side effect is considered UB. Checks that cannot be implemented but might be understood by a static analyzer are another canonical example - functions that a static analyzer may declare, understand, and provide useful warnings with might be things like "is_dereferencable" or "is_reachable". There's a certain subjectivity about "Too long to execute" with the axiom/audit boundary that is similar to the default/audit boundary. In practice though, if your check will take millennia to run on your smallest sample set then making it an audit just means you can't turn audit on and run anything. There's a difference between "impractical" and "impossible" - impractical you don't want to turn on in production but might want to turn on for local testing, impossible you couldn't even use in local testing in any useful way. One could envision "I haven't written this check yet but want to document that I will eventually" as another use case for axiom during system development. 
And I say this is what axiom is for based on what was said in P0380R0, which was where axiom seems to have first been introduced as a contract level, and the understanding of at least 2 of the authors of that paper regarding this being its intent. Also, again, the mathematical definition - that something is expected to always be true - is an attribute that EVERY contract check should have, it's not special to any of the levels. A lot of confusion seems to be coming from conflating "cannot check at runtime" with "don't bother checking at runtime and just assume this fact". One is an attribute of a predicate, one is a decision that you might make when building a system.
Why don't you go mow my lawn and finish the MQTT driver I'm trying to get done, while I look through some licenses.
No, it's basically using `std::aligned_storage_t&lt;X, Y&gt;` and then `new (&amp;storage) Impl(...)`. It can easily be wrapped, too, in a `inline_impl&lt;Impl, X, Y&gt;` class which does all the heavy lifting. You can (and should) have `static_assert` in the constructor, ensuring that the size and alignment of the storage are good enough for the `Impl` class that you're building there.
If the member function gets inlined, then you care very much. I am not sure how this'll work with modules, but nowadays a getter defined in a header file can get inlined even if the class is part of a DLL. Change the offset of the field it points to, *BOOM*.
Did you manually ignore the duplicate link submission detection? The URL is exactly the same. Removed.
&gt; What if I have thirty import statements - how do I guess which of these contained `get_phrase()`? At least within your own code, you can setup the rule that module should match namespace to keep your sanity.
In that case, not even pimple can help you. If you want to be able to change the implementation without recompiling the consumer (usual reason to employ pimpl in the first place) you have to deactivate link time optimization (although I haven't heard about any toolchain that would actually optimize across dll boundaries).
&gt; So you still need the #include of the corresponding header file(s) Yes, #include "header" works and required as it is, nothing changes in this respect. * a.hpp defines external API of "a" module. * a.cpp defines its implementation. Thus if your module consist of just these two files then its consumer will need both: #include "a.hpp" #include source "a.cpp" And that is conceptually the same thing as [import a;](https://clang.llvm.org/docs/Modules.html#semantic-import) The only major difference is that #include source is backward compatible - any existing C/C++ library can be modularized this way without touching existing sources. 
Ok, thanks for the clarification. TBH, I don+t see a reason to imbue those properties into the class itself. A simple value_pointer template (or whatever you want to call it) can provide that for any class, with the only disadvantage, that you have to write foo-&gt;member() instead of foo.member().
Indeed. I don't see the point of ever writing a Makefile when we've got CMake...
&gt; (although I haven't heard about any toolchain that would actually optimize across dll boundaries) That's actually the underlying question. Today, all you need to do to guarantee a stable ABI is avoiding defining the function in header files, and your DLL should be good to go. I wonder, with modules, how you'll obtain the same guarantee: how do you export the function (it needs to be called) without allowing the compiler to inline it at the call-site? 
I tried again to post the same link, it got accepted without issues. Maybe duplicate link submission detection not working.
What happens if I have 2 files in my project and both do `#include source` for the same `a.cpp`?
Pretty sure most physics engines will break themselves under these kinds of conditions.
I like the part where you didn't say if it needed to be real-time or not.
https://github.com/bulletphysics/bullet3/tree/master/examples/VoronoiFracture ?
Interesting, but there's not a mention of the mediocre performance: 2 execs/s (the line that mentions 60 execs/s has a comment: "not a single valid API call has been made.", suggesting really shallow stacks)
Well then, your personal liking differs from mine. I’m a boost kind of guy and only touch Qt when it comes to Ui. Never liked it to be honest. * own cryptic build system while cmake exists * the single most difficult dependency to build in my entire code base * messy licensing situation * denies existence of exceptions and tries to push that down your throat * denies the existence of threads as well and makes life hell when they come into the mix (signal chains and resulting deadlocks) * strongly favors built objects (linked lib) vs templates * favors inheritance over composition * tries to do way too much rather than just focus on the Ui and improve that * QString * Qt Designer And most importantly the three words from hell: abstract table model. This and everything around it it just so horribly over-engineered that every time I touch it I wish there would be another Ui framework. Yet in all that rant there is positive I can say about it: the documentation is excellent. Always a pleasure to have almost everything documented. Also, I quite like Qt Creator and use it on Linux. So, sorry ... this is all just my opinion. Qt might be perfect for you, so use it. 
Options are: * To react in the same way as currently with this: `g++ a.cpp a.cpp` ( same file appears in linker list twice) * or to treat content of `#include source` as having `#pragma once` now. Otherwise you can always define a.module file with this content: #pragma once #include "a.hpp" #include source "a.cpp" And use it as #include "a.module" 
I don’t disagree on most of the opinion parts (especially licensing), but like Qt myself and use boost much less (not for any particular reason, just how projects have worked out so far). One of my favorite QOL things is QString, methods like .split() etc I find to be incredibly useful even if the resulting QStringList isn’t particularly performant. Of course, I could always wrap my own more efficient version based on regexs, streams and use my own split method. What do you dislike about it? It was pretty much the only thing in your list that I was like.... wait, why? But hey, like you said gotta love Creator. 
I had to adjust the code to compile it with macOS using GCC (`std::exception` only has a default and a copy constructor. When changing all occurrences with `std::logic_error`, the code compiled). However, the binary fails to parse a lot of the test files from https://github.com/nlohmann/json/tree/develop/test/data. First, I thought it could be an encoding problem (do you support UTF-8?), but it seems I also get an error parsing https://raw.githubusercontent.com/nlohmann/json/develop/test/data/json_nlohmann_tests/all_unicode_ascii.json. However, the error message `An exception occurred: [3/3] - An illegal escape character` is not really helpful. Can you comment on this?
&gt;To react in the same way as currently with this: g++ a.cpp a.cpp ( same file appears in linker list twice) Linkage error. OK. But no one would write such a command manually (and no build system would generate such a command), but it's easy to to so now with the `#include source` addition. (And let's don't start with the nested dependencies.) So the chances are you upset the users. They'll have to keep track on which file they put the `#include source` to make sure it appears exactly once. &gt;or to treat content of #include source as having #pragma once now. `#pragam once` works because it affects only the current invocation of the compiler. Do you suggest an external "DB", where the compiler has to keep track of which source has been compiled already and going to the linker input and thus shouldn't be compiled and linked again? What this means about compiling more than one source file in parallel? Oh, and we haven't touch the point that most of the real projects never use `g++` to generate the executable directly from the source. Each source file is separately compiled into an object file and only then the object files are linked together to create the final executable. How this works with the suggested `#include source`, or this is intended only for single-file projects?
I had this discussion just ladt week with the team. I call it ‘heavyweight strings’ vs ‘lightweight strings’. Heavyweight as in ‘magic’. Knows about encoding, offers all those operations like split based upon that knowledge and is a jack of all trades string where you never need to worry. Myself I prefer a lightweight approach. Std::string with the contract (sadly, only enforced by documentation and implied knowledge) that everything in it is utf8. This way the string can be very lightweight and efficient, doesn’t pull in a Qt dependency and goes well with other libs and the STL. And when I need it, template algorithms work on it with or without the encoding overhead if need be. That’s C++ in my book: only pay for what you use. As opposed to always carrying that extra weight. I found that more to my liking but I guess that depends on how much of your application and string usage actually is end user exposed and encoding relevant. If you have much Ui and little underneath a QString appears a better choice after all. So yes, the QString was a bit of a long shot in that list. 
That's pretty specialized and probably doesn't exist in any easy form. I'd probably scour academic papers for reference implementations. What do you need it for?
clangd will use it if you ever want to use LSP instead of YCM.
Text transcoding in general is apparently basically a non-starter in C++ without some sort of add-on library. So I wouldn't be surprised if it couldn't handle anything other than ASCII really, as is. Or you'd have to maybe set some global code page setting for the C++ I/O streams to what you think the encoding of the file will be, before you do the parse. 
Nice. And LSP seemingly supports finding definitions and references outside the current translation unit as well. I will definitely give it a try. Thanks
So what's the general scheme for discussion and such for Github projects? Not that I expect a lot of traffic, but if someone wanted to discuss something with whoever is interested, where would that sort of thing generally occur for GitHub based projects? There's an issues section I see, but nothing like a discussion per repo/project disucssion forumy thing? I could do it on the CQC forums, but it's not really directly CQC related. 
These are technical details, not a show stopper, right? You don't need DB, file system is pretty adequate for that. MSVC supports this (ugly I shall admit) construct already: #pragma comment(lib, "some.lib") to include static libraries into final executable. And that `#pragma comment(lib, "some.lib")` may appear multiple times. So all that is doable in principle. 
YCM has merged clangd support. Also compilation databases work even with YCM's old libclang completer.
&gt;own cryptic build system while cmake exists QMake actually predates cmake by quite a while. They know it is bad though, and Qt6 is going to be built using cmake. QMake will continue to exist for legacy projects though. &gt; the single most difficult dependency to build in my entire code base No argument here, it is a bit unwieldy when you have to compile it yourself. &gt;messy licensing situation What is messy about it being LGPL, with the option of a commercial license. This isn't a particularly uncommon model. &gt; denies existence of exceptions and tries to push that down your throat Again, no complaints. Largely this is just the curse of legacy APIs. &gt; denies the existence of threads as well and makes life hell when they come into the mix (signal chains and resulting deadlocks) I'm not sure what you mean by it ignoring the existence of threads, threading is central to the design of the library (QThread, QEventLoop, QObject, etc.) &gt; favors inheritance over composition I'm not really sure where they use inheritance that it doesn't make sense. &gt; tries to do way too much rather than just focus on the Ui and improve that On the other hand, providing a well integrated environment makes it convenient for developers who don't have a problem using their stuff for other tasks. Their entire set of APIs is pretty nice. &gt; QString QString (as well as the containers) is needed to provide a stable ABI. It is also much more functional than std::string, in part due to being unicode aware. &gt; Qt Designer I'm not sure how having an optional graphical UI designer is a detriment? Do you just consider it to be a poor implementation of a UI designer? I will agree that the model/view stuff can be a bit tricky. I like it, but part of that is just that I have spent a bunch of time working with it to become comfortable with it. It isn't terribly simple to get started with, and for a long time I also disliked it, so I can't really argue with anyone who dislikes it for its complexity. 
"The program above is ill-formed, no diagnostic required! NDR is one of the most frightening terms in the C++ standard. If often means undefined behavior." I don't understand this. Why should this be undefined behaviour? Isn't this clearly a developer error (and a compilation error should be issued)? Why the standard defined it like this?
File https://raw.githubusercontent.com/nlohmann/json/develop/test/data/json_nlohmann_tests/all_unicode_ascii.json is ASCII, and I did not set any code page.
OK, yeh, that's a torture test file. I wouldn't be shocked if it managed to trip up that little example parser. It's doing lots of escaped characters and such, which it probably isn't handling. Also, this isn't probably the kind of file you'd want to parse with a program that is going to build up the whole contents in memory. There are 1.1M entries in that file. For these types of tests, you probably want to invoke just the core parser that doesn't store our output anything at all, it just does a parse and throws the data away as it goes. My own parser (which is not that code I posted, and which does have full transcoding support) handled it, but it took quite a while because my little test program also does build up all of the content in memory. I should do a tester that just parses and tosses the content and incorporate some of those gnarly test files. 
The size of the file should not be an issue - it just enumerates all valid UTF-8 code points as ASCII representation. Any JSON parser should be able to parse it. If your example parser does not contain the code that your "own" parser has, than I fear your little JSON parser is worthless, as it cannot parse JSON.
OK. I never claimed it was bug-free. I just threw it up there for some comments on the style. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The NDR is regarding the missing `import export :part`, not regarding the unresolved function call. Current compiler designs make determining if there is a missing `import export :part` virtually impossible. NDR is usually invoked when a program is ill-formed but actually determining that fact is unreasonably difficult for an implementation (ODR violations are the prime example). I'm not sure if the missing `import export` can cause UB. It _might_ be cause an ODR violation if overload selection changes between module units for a call to an inline function defined in another module. That would be a very pathological case, and I'm not sure if it's possible... I wouldn't worry about this being UB. You'll probably get a "no matching call" error, but it won't be obvious at first why it is happening when your module files _appear_ correct at first glance.
So, will capturing lambdas be passable to function pointer parameters now? &amp;#x200B;
Yeah, Clang is a real stickler for details, but that's getting the issues in the various standards fixed
1: Blatant spam, enjoy your ban OP. 2: You're a few centuries late, the Rothschilds are worth over a trillion dollars when it's all combined back together.
I had a brief look: - It is incomplete - the issue I described above is due to the fact that `\u` escapes are not implemented at all. - The empty array `[]` yields a parse error. The same for `{}`. - It is noncompliant - you serialize numbers with quotes. - It is inefficient - when reading large nested values like `[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[1]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]`, the parser takes forever. 
As I said, I just put it up to get comments on the style. 
In the first example, if I modify the `get_phrase` implementation, does `main.cpp` need to be recompiled?
That's actually a hard question to answer. As there are no \*complete\* implementations of modules available yet. And optimistically we could only expect something minimally complete in a year. Assuming nothing drastic happens between now and the Summer meeting when the next draft IS is finalized. Realistically don't expect a \*good\* implementation in less than three years. But there are some partial ongoing implementations available that you can try. For example the current gcc modules implementation is available in Compiler Explorer (built on a nightly basis). Here's the first example: [https://godbolt.org/z/sMWNIB](https://godbolt.org/z/sMWNIB) \-- But the examples that follow and need multiple files it's not going to work. But it currently does understand the partitions [https://godbolt.org/z/jQtJW-](https://godbolt.org/z/jQtJW-) Please go ahead and "play" with it yourself though to investigate what works. Or you could build the compiler yourself :-)
Easy: Put the declaration into the module interface unit but the definition into an implementation unit (or the private part of the module interface unit).
Depends on whether the compiler decides to export the definition of the function, which can depend on if `inline` is provided or not. Some early existing implementations will export the definition even in the absence of the `inline` keyword. A lot of SG15 doesn't like the idea that the definition is exported implicitly, and we hope to convince implementations (via the TR) to not export the definition of non-`inline` code.
Not sure what one thing has to do with the other, but: The reason why everyone is excited about modules has nothing to do with simpler build systems (quite the contrary) or package management. All that I'm saying is that the suggested feature would be applicable to many more libraries than you are implying. Now, depending on the company and sector you are working, in you might have to deal with a very different set of libraries in your day to day work, which might be the reason why our experiences are so different.
Thanks. My biggest hope for C++20 is that I don't have to split everything into headers and source files.
Assuming you use cmake, why not just have cmake export it for you?
Anyone else feel the language is fast approaching the point of just too much complexity?
Clang format?
Yes, it can reformat your code according to the `.cang-format` configuration and *I think* it users the compilation database.
Rtags
At no point have I gone looking to do something and found it missing and reacted with "good, it shouldn't be able to do that". It's always the opposite: if it can't do something it annoys me. So, no. I'll never think it's too complex. It's a tool to get a job done and if it can't get the job done then I need something that can.
I would have agreed with you not but a year ago until I was able to have some in depth discussions with highly skilled C++ programmers- the kinds that make meta template projects just to achieve compile-time magic. The kind of coders that often \_discover\_ bugs in the compiler along the way. Almost every new feature since C++11 up to C++20 I did not like. I felt that the C++ committee was just stuffing the language features without much thought. Turns out a lot of the features that make it in have already existed to some degree, but has been hidden away by implementation. For instance lambdas were already a thing. They were functors. the \`\[\](){}\` syntax is just a bunch of sugar hiding away the implementation. (I will take a moment to say I wish C++ used the lambda syntax PHP7 uses because it's readable and \`\[\](){}\` makes me feel like I'm just making silly shapes on my desk but I digress). Things like modules have been in discussion for years now. Every new feature has been vetted and deemed essential for modern programming and papers are written to prove they can be added into the language or a spec is drawn along side a working version on a custom compiler. So the language hasn't been approaching anything fast. The committee has made sure the language actually taken its time to mature. What we're seeing lately is a lot of in-demand features finally seeing resolution and integration into the language. Perhaps it's not that the language is getting complex but that our software demands are becoming complex. A good language will meet those needs and it won't feel so complex anymore. 
For what? I've never seen clang format ask for a compilation database.
I said "I think", because I was talking from memory and wasn't sure if it required a compilation database.
My understanding is that this is a compilation error (not link error) when compiling `main.cpp` which basically will state that the call to `get_phrases()` is ambiguous (we don't know which one to call). This is not really a new kind of error, it happens each time you end up with several possible candidate in an overload set and some have the same signature (though I suspect it is not /exactly/ the same issue. Note that the modules will be compiled without errors, only `main.cpp` will need a fix. This is a similar error than if you did : namespace A { const char* get_phrase(); } namespace B { const char* get_phrase(); } int main() { using namespace A; using namespace B; std::cout &lt;&lt; get_phrase() &lt;&lt; '\n'; // ERROR: which get_phrase() should be used here? Need disambiguation. } 
&gt; The primary Cats unit does not export-import :Behaviors! &gt; The program above is ill-formed, no diagnostic required! Any reason for not saying compilers should throw an error if you use a symbol that wasn't visible from the primary interface unit? Not requiring a diagnostic "your forgot to export `foo`", just saying "I don't know this symbol".
ccls is much better.
When you have templates it can't be helped obviously.
What's your opinion on `bool++` then? Agree that it deserved to be terminated?
Reflection wouldn't be necessary if the standard would just define some linkage standards. Or rather it would be possible to infer. But every fucking compiler has to do everything different. There's a bunch of projects out there based on LLVM. Who knows, we may get something (nonportable). *shrug* I know it's not as simple as linkage, it's issues like memory allocation, file handles, etc, thread local storage. Someday, maybe. 
The standards committee has way more important things to do than bother itself with useless things like how to _use_ C++ /s I'd really really love for them to have made a compiler like 
No.
Personally, I prefer rtags over the LSP servers. Both are clang based and both use compile db, so it is easy to try both. I just find that the C++ language-specific protocol and API work better. I use rtags for indexing + YCM for autocompletetion, and the combo works well together in vim.
ccls can't handle my very large codebase, it freezes: https://github.com/MaskRay/ccls/issues/316 . cquery can handle it. Last I tried clangd it had issues but that was last fall, maybe I should try again.
Many applications do not have the choice to crash when they encounter a failed contract check - your pacemaker, your car, your average weapon control system, etc. They need to handle any input gracefully and attempt to recover from bugs, even if they detect that there is a bug. They do, however, want to have preconditions and assertions checked immediately during testing to identify any flaws that can be identified as thoroughly and systematically as possible, hopefully to allow them to be fixed. No one deploying systems like that, however, can sanely say they can catch all bugs during testing. This is one of the primary reasons that the current default behavior of assuming all contracts that are "off" is ludicrously dangerous. It makes redundant checking pointless since it is implicitly elidable, a level of risk that many applications can never even consider deploying. 
&gt;the C IMHO the problem is CMake itself here, specifically [https://gitlab.kitware.com/cmake/cmake/issues/18977](https://gitlab.kitware.com/cmake/cmake/issues/18977). In [https://github.com/pr0g/cmake-examples/blob/master/examples/header-only/library/CMakeLists.txt#L25](https://github.com/pr0g/cmake-examples/blob/master/examples/header-only/library/CMakeLists.txt#L25) you are already telling CMake you want to install the "target". The headers \*are part of the target\*. You should not need to tell it "and also this directory" [https://github.com/pr0g/cmake-examples/blob/master/examples/header-only/library/CMakeLists.txt#L37](https://github.com/pr0g/cmake-examples/blob/master/examples/header-only/library/CMakeLists.txt#L37). When you are telling to CMake to install the headers CMake doesn't even know it's installing headers! It only knows it's copying a directory. This lack of knowledge by CMake, the lack of syntax to give the knowledge to CMake, is IMHO the single most urgent issue to fix. &amp;#x200B;
I think it's more of an unfortunate possibility due to composing of language features.
I use spacemacs with rtags and ycm. Spacemacs is emacs, with a configuration layer that provides a roughly comparable feature set to something like vscode; gives you consistent keybindings, project text search, git functionality (via magit), window/buffer management, and also pretty much perfect vim bindings (far better than vscode, eclipse, clion, etc) via evil. Rtags is like ycmd but project wide, so you can find references and goto definition between different files. I still use ycmd for auto completion and error checking as I find it's faster. I also know of people using ccls and cquery with similar setups that say it works well for them. Another good thing to do once you have a compile_commands.json for your project is run clang-tidy with whatever checks are appropriate, nightly.
What is the point of posting these? They don't seem to have any particular audience. They are just your stream of consciousness. If nothing else, at least give a more nuanced title so people can easily choose if they want to read it or not.
issues should be fine for that sort of stuff I assume. If you want to share some knowledge - use wiki pages at github.
Thanks for your post but this isn't really the place to post tutorials about C++.
The Art of Multiprocessor Programming has a few similar designs I believe. https://www.oreilly.com/library/view/the-art-of/9780123973375/#toc-start
Just an aspect of C++ I found interesting. I agree about the title. Sorry for trying to share knowledge?
I can understand your dislike for the \[\](){} but I find the PHP7 lambdas annoyingly verbose like older Java. Personally I quite like the succinctness of \[\](){} after using it for quite sometime, and usually the lambdas have enough captures/args that it makes it easy to spot them.
cool project, any love for [https://github.com/nlohmann/json](https://github.com/nlohmann/json) support? It would also be interesting to see benchmarks on how much your library adds in overhead to the underlying parsers/serializers.
That's good to know. Thank you!
Adding members can change your ABI in more than just size. There's also alignment and how the type gets passed.
&gt; What if more than one of them import that symbol? Then you get both. &gt; Is it by order? No. &gt; What if an update to one library hijacks a symbol that used to resolve to another? What if you do that with headers today? Use namespaces.
I've whipped up several little tools using `compile_commands.json` 1. A tool that builds just one file. I use this one rarely, but every now and then I'll run into a situation where I don't have a build target for a specific file and I don't want to build some larger target which contains it. This tool looks up the file I want and runs the compiler using the commands. 2. A tool that builds a file and dumps assembly for it. 3. I use it to get the flags to build the current file I'm editing with neomake. This give me compiler errors in warnings right in nvim. Aside from those I also use YCM and clang-tidy. &amp;#x200B; At work we have a pretty complicated build system, we're practically cross-compiling so maintaining all the flags is crucial to get anything useful out of these tools. The database is really useful for that.
It's important to differentiate between inlining the compiler optimization, and `inline` the keyword. Compilers can perform the inlining optimization on _anything_ they want. There are no restrictions. They can also choose to not inline anything they want, and the `inline` keyword has no relevance to this decision. What the `inline` keyword does do is provide a way to expose the definition of functions to other translation units for the inlining optimization to kick in without hitting multiple definition errors. With this in mind, all the things currently required to be defined in headers will need to be defined in module interface units, as only things that are in module interface units will be visible to importers.
Good point about the linker input, which may be encoded into the object file, but here the compiler has to check if the source was compiled already (part of trning the compiler to a build system), which is less efficient. It also less doable when the sources aren't in the same directory (or the compiler must know in compile time all the inputs that are going to be in the linker command, another part of being a (less efficient) build system). All in all, it seems like it covers a very narrow use case while the real world use cases are much more complicated, and the added value doesn't exists, as you need a build system anyway for separated compilation of multiple source files.
You would need a content aware build system to avoid downstream recompiles in this case. For timestamp based builds all they are going to see is that foo.cpp changed, and thus foo.pcm is out of date, and so is everything that depends on it. It's possible to get a good build experience out of this, but it will take some work.
As the person who patched `regex_iterator` in the Standard (at the same time as `regex_match/regex_search` taking a temporary `basic_string` with a `match_results`, the more important issue), I can say that of course deleting `const X&amp;&amp;` binding isn't a panacea - however, it prevents easily-preventable errors, and doesn't cause significant headaches in practice.
Does the content of foo.pcm change in this case? If not then the build system could recompile dependencies based on whether a hash has changed. I realized that there is another couple of features that I would need. Will this compile or does the `some_module` import also need to be exported? export module speech; import some_module; export const char* get_phrase() { return function_from_some_module(); } And will modules allow a circular dependency like this? // module1.cpp export module module1; import module2; export void function1() { function2(); } // module2.cpp export module module2; import module1; export void function2() { function1(); } 
I suppose what we want to do instead is to cast an arbitrary lambda that *does* capture state to a pair of a no-capture lambda that takes its state (via `void*`) as its first argument and a `void*` (its state)... Is there anything non-kosher going on here? [compiler explorer](https://godbolt.org/z/8NYGO6) / better ideas?
I don't think you'll find many such snippets. C++ Is mostly about understanding the semantics of the language and being able to copy/paste a particular piece of code is typically not too helpful.
I feel you. On one hand there's convenience and the other there's readability. 
Type-system-wise, your solution is 100% kosher. That's exactly how you should "split" a lambda into its code and data parts. Lifetime-wise, you've got a bad bug. The `s` in your `[l, s]` is a pointer with the value `&amp;t`, where `t` is the temporary object of lambda type. That temporary object is gone by the time you call `l` and dereference `s`. So you're dereferencing a dangling pointer. https://godbolt.org/z/kVAHgd If you want to split up a lambda into its code part and its data part, then you will need to manage the lifetime of its data part. That means RAII. That means maybe you wrap the data part in a `shared_ptr` or something. Trying to wrap it in a raw, non-owning `const void*` isn't going to work.
It isn't `std::pair&lt;int,int&gt; temp = make_pair(1,2);`; it's `auto&amp;&amp; temp = make_pair(1,2);`.
Interesting, thanks for pointing to Meson, I was unfamiliar with it. Looks relatively convenient.
Here's another case where value categories and lifetimes do the opposite of what you'd expect: std::string s = "hello, world"; std::string_view Function1() { return s; } std::string Function2() { return s; } void test() { auto value = Function1(); auto const&amp; reference = Function2(); s = "goodbye, cruel world!"; // 'reference' is safe to use, 'value' is not } string_view acts like a value, so it happily binds to auto. Meanwhile, lifetime extension means that assigning a value to a reference will work like a value. The end result is the exact opposite of what you'd expect. 
oops, I was contracting the code to make it shorter, previously I had the unspilt (capturing) lambda named and its lifetime would extend beyond the use of the split constituents... Looks like I screwed it up in formatting the code Thanks.
It's clear you've put a lot of work into SpecNet, but performance analysis is best done with humility and rigor. The below observations assume you're doing this out of a desire to learn and explore for curiosity's sake. 1. The convention when doing a complexity analysis, count the number of operations, not wall time. std::binary_search for example is described in terms of both the number of iterator increments and the number of comparisons. https://en.cppreference.com/w/cpp/algorithm/binary_search 2. Caches are designed to exploit temporal locality in various forms. The most important part of the analysis is how it performs under different access patterns, but only one access pattern is used, which is random, so it's informative only about cache misses and not hits. Try taking a trace of your application, and using that to design a way to generate synthetic data. 3. Benchmark should match the desired environment. Best I can tell, this is intended as ephemeral storage mapping from TKey (which appears to be a message header) to the body of the message. Given that the header is around 40 bytes, assuming around 100B body off of the old SMS limits, each entry in the cache is more than 180 bytes. That's a pretty different setup from the random data evaluated which is roughly 32B. 4. A sum is not a hash. Try std::hash. Distribution is as important as overhead. As far as fast cache algorithms go, Linux uses Clock-Pro for its page cache IIRC, which is an approximation of LIRS. Given the size of your keys and values, I'm not sure what to expect out of a flat map in terms of improving hash table speed. https://github.com/abseil/abseil-cpp/blob/master/absl/container/flat_hash_map.h RocksDB has a sharded clock cache implementation for mapping from keys (16B in the benchmark IIRC) to blocks (4KB IIRC).
That was one of the best episode's I've listened to. Probably because it happened to be in one of my main areas of coding. :) But also because it was really enlightening - less about what was going on in a committee or conference (though there was plenty of that) - but more about a different way of async programming and *why* it might be better, and why it's holding up ASIO, etc. I listened to the episode twice, just to grok it all.
&gt; string_view acts like a value ... What makes you say that [or, it like this], it doesn't [act like a value], as you point out. 
We have been using this library in our product for several months. I strongly recommend it for its small footprint (in terms of runtime, compile-time, and pressure to build system), efficiency, and more importantly, a solid feature set that continues to deliver what we need for building a high quality software.
I used it to extract include directories and compile definitions to pass into our stupid script used to generate QtCreator project files. Can't wait to get rid of all that stuff and move to a proper CMake in a few months.
Per the sidebar: For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow. 
Assuming
Erase remove idiom - in place remove items from vector while iterating on it. It even has its own wiki page: https://en.m.wikipedia.org/wiki/Erase–remove_idiom.
Alignment can be set directly (alignas) and an what exactly do you mean by how the type gets passed? Whether it is passed on the stack or in registers?
&gt; One of the major cons Compilation speed, or lack there of.
Thinly disguised Rust propaganda. Bleh. /s
Static defines lifetime of the object and runtime, constexpr compile time. They're congruent concepts
You are pretty close, actually! template&lt;bool v0, ..., bool v3&gt; void doTheThing() { if(v0) { /* Replaced at compile time with true/false and thus likely optimized away. */ } } doTheThing&lt;true, false, true, false&gt;();
You could make the bools template arguments. That way, the compiler can remove all the if statements from your code (and code which isn't needed for values of your bools). Downside is that you need to compile a different function for every combination of bools you're using. This can increase the compile time and size of your binaries.
Great article! But my first impression after reading it was "[why it is such complex and what logic was behind this approach for C++Modules?](https://eao197.blogspot.com/2019/03/progc-cmodules-there-is-no-place-for.html)". It will be very-very useful to have some explanations about C++Modules design written for ordinary C++ users like me.
&gt; Object lifetime in a constexpr function doesn't make much sense why ? why would you not want to be able to do constexpr int f(int x) { static constexpr std::array&lt;int&gt; large_table{...}; return large_table[x]; } int main(int argc, char** argv) { constexpr int a = f(0); int b = f(argc); } in this case it's actually more performant to make f non-constexpr and the array static, since the compiler won't initialize it every time especially in the MSVC debug case where constexpr is moot : https://gcc.godbolt.org/z/AdduDS
Where does that "Seatbelts can't prevent all injuries, so we shouldn't use them" attitude come from? Of course, for every api you usually have to balance convenience vs performance vs safety and the usual answer for c++ is: There is no solution that is optimal in all 3 dimensions. So e.g. trading some convenience for some safety is a perfectly normal and legit process. And btw.: &gt; See, here we’ve made a temporary String object out of "hello world", and we’re trying to pass that String to a function that takes a string_view parameter. There’s nothing intrinsically wrong with this code. Yes there is very much so: You should not have been creating in intermediate temporary `String` object in the first place. And yes, I'm aware that there are other constellations, where the situation is less clear. I'm just pointing out that many low level problems can actually be solved much better one level higher. 
Oh, I didn't intend to step on anyone's toes. Just stated my opinion as I was asked for it. In any case, about a few of your very valid points: &gt; QMake actually predates cmake by quite a while. They know it is bad though, and Qt6 is going to be built using cmake. QMake will continue to exist for legacy projects though. I am aware of this. Just didn't want to spoil a good rant with reality. &gt; What is messy about it being LGPL Nothing. If it were. But it isn't. When I use boost, I can use the whole thing and know for sure it's boost license. Simple. When I use Qt, I have to step into [this minefield here]( https://doc.qt.io/qt-5/licenses-used-in-qt.html) and figure out what this means to my project first. &gt; I'm not sure what you mean by it ignoring the existence of threads Every Qt Ui application I have maintained or developed in my time was quite workload intensive and used to spread this work over some kind of internal threading or multiplexing model. Say, asio, thread pools, mixtures of same, anything really. Normally those threads will operate on and influence some kind of in-memory data model. Again, grossly simplified. Now the UI will generally also need to access this data model in order to display values in it or influence it via controllers. And herein lies the problem. Most UI functions expect to be called from what Qt calles the "Main Thread" or the "Qt thread" without being clear what exactly this is. So, when I try to do this I will generally end up writing some mechanism to demux events and signals back into that very Qt thread. Then I end up having to lock things in the data model as the rest of the application doesn't care about the Ui too much. So I lock it, for example to retrieve some values in some abstract whatever model for Qt. Which in turn very often causes other signals to fire, unknown to me or some other Qt abstract data model internal function to be called from within Qt itself and so on. Which will inevitably cause deadlocks on the mutex that I need to access the data unless I use some kind of recursive mutex, which I will be damned if I ever do. It gets really messy and buggy real quick and I normally end up bypassing Qts table model stuff by just setting the widget's states manually and disabling the entire signal slot mechanism. Which in turn then makes me wonder why I chose it in the first place. All this wouldn't happen if Qt would either avoid those signal wildfires, strictly document them or acknowledge that there is such a thing as threads and that thing often involves mutexing data. This is what I mean by that. Having a QThread class, yeah, that's nice. We got that in the std by now. Being able to create a Ui that can deal with it, not so much. &gt; I'm not sure how having an optional graphical UI designer is a detriment? My problem with Qt Designer is not that it's there. In fact, I have it as a rule that everything that can be done in the designer should be done in the designer. My problem is that it's not very good, difficult to use and it falls woefully short to catch up with the actual widgets and capabilities that Qt offers. All the time I will end up using the designer and not being able to create even simple UIs because many (if not most) widgets are just not there and I have no idea how and if I can add them. And I'm not talking my widgets, I'm talking Qt's. So more often than not my Ui ends up a mixture of designer made things and then in code further stuff gets added. In my opinion, the designer should be waaaay better. Which is one of the many reasons why I keep saying they should focus on the Ui more and make that better rather than adding things that people will use boost or std for anyway. &lt;/rant&gt; Again, sorry if I stepped on your or anone's toes. I know Qt has a large and lively community but so has boost and it's like with cat and dog people... Very few will be both at the same time.
Could you please tell whether this library provides simple concept of logging facade? So that one can use it in SO and then configure implicitly through executable?
Yes I did mention this issue in the article and as far as I know it does not utilize something like slf4cxx
That feels almost more like a kernel bug - I wonder what it’s doing?
But this kind of questions usually get closed in minutes.
windows tho
Kudos to the author for such a great article! You did tremendous job explaining all this stuff to common programmers like myself. Though, I have few concerns regarding specifically modules. First, I'd expect such article from GDR or another module designer. ATM it feels more like "we designed cool thing and it's now up to you how to handle it". Second, this design looks one of the most complex, inflexible, error-prone and compiler-oriented of all module systems I've seen so far. Third, it seems `internal` visibility specifier for classes is off-limits. 
Yep nlhomann's is probably the next big one on the list, cpprest and Qt where only first as I had used them in other projects. &amp;#x200B; Haven't got around to bench marking, but hopefully not too much overhead, most of it should be generated at compile time (I can measure that as well I suppose). But yeah, nlhomann's and then some performance testings sounds like a plan.
A `constexpr` function doesn't mean compile-time. Using `static` for runtime-evaluated calls without affecting compile-time-evaluated calls could make sense.
Just to see how realy good a project file cold look check the *qbs* project files of [QBS itself](https://github.com/qbs/qbs/blob/master/qbs.qbs). It is super easy to read.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b048ba/my_friend_saul_has_a_problem_needs_to_solve_a/eic9xq6/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
$ ./a.out Only enter 0 to exit \---------------------------------------- Enter a Number to calculate factorial: 100 The Factorial of 100 is 0 Only enter 0 to exit &amp;#x200B;
OK I see. I took it as being THE way to do pimpl with modules. 
&gt; The reason why everyone is excited about modules has nothing to do with simpler build systems (quite the contrary) or package management. So why is people excited about modules in your opinion then? &gt; All that I'm saying is that the suggested feature would be applicable to many more libraries than you are implying. Now, depending on the company and sector you are working, in you might have to deal with a very different set of libraries in your day to day work, which might be the reason why our experiences are so different. It is clear that different fields have different libraries, but in the several fields I have worked on, which use pretty popular open source libraries, there has been no one that fit those requirements. If you know some examples from your field, please name them, it would be useful to know.
 // The factorial function int long Factorial (int long Number) { for (int i = 1; i &lt; Number;i++) { return Number*Factorial(Number-1); } return 1; } That's an interesting way to try and compute a factorial...
Hey i have just noticed about this. &amp;#x200B; How can i resolve it?
If the Seatbelt prevents you from driving... 
I would have suggested, but just laughing at the code is also fun: long fac(long n) { assert(n &gt; -1); if(n&gt;0) return n*fac(n-1); else return 1; }
As usual, avoid storing references (of any kind: actual references, pointers, iterators, indexes, etc.) and objects that keep references to other objects.
Hey i have just noticed about this. How can i resolve it? \- When i do the factorial of 10 the do while loop seems to work fine but for numbers like 100, 1000 it views them as 0. &amp;#x200B; Any clue how i can resolve that?
For me personally, C++ job openings are more interesting. There are fewer of them to be sure, but there are also fewer C++ devs. With more interesting I mean that they often relate to computer vision, machine learning, CAD, medical software, data analysis, ... and that's also the world I want to be working in.
Did you try stepping through the debugger?
[https://github.com/mesonbuild/meson/search?q=visual+studio&amp;state=open&amp;type=Issues](https://github.com/mesonbuild/meson/search?q=visual+studio&amp;state=open&amp;type=Issues) [https://github.com/mesonbuild/meson/search?q=windows&amp;state=open&amp;type=Issues](https://github.com/mesonbuild/meson/search?q=windows&amp;state=open&amp;type=Issues)
&gt;QBS [https://blog.qt.io/blog/2018/10/29/deprecation-of-qbs/](https://blog.qt.io/blog/2018/10/29/deprecation-of-qbs/)
Returning `string_view` is equivalent to returning a pointer, and you should never store the result anywhere, the same way you don't store the result of `std::string::c_str()`. They are meant to be consumed right away, nothing else. Same thing for iterators to collections. If it is intended to be stored, please return references to actual objects that manage resources. By the way, using `auto` makes the error even more subtle. That is one of the reasons I don't like `auto` for non-generic code, and I am against AAA. If I see `string_view foo = ...`, at least I can recognize the bad smell if it is not consumed immediately.
Thanks. &amp;#x200B; But the problem i am having is when getting a value like 100 from the user in the do while loop it considers it as 0.
Coming to package installation, I really love the way pacman handles the installation of libraries and it's dependencies in Arch Linux. In most cases, library installations in Arch is just a command away. 
As a frequent user of CMake, I can tell you that not all the systems I use have it installed. So I've had to rely on Makefiles. You mileage may vary depending on where you work and which systems you need to use/have access to.
It doesn't. It may prevent you from taking off your jacket while driving (depending on your agility) but as I said - it is a tradeoff
I've never gone looking for it but it existing has never caused a bug in our code so I don't care that it exists.
`use_it(String("hello world"))` not compiling, to stick with the analogy: *"of course you can still drive, but with the seat belt in, you can't fully release the hand brake."* It certainly does break (or require additional workarounds for) common patterns and constructs. 
finally we solved the age-long discussion about the best way to calculate the Factorial by taking the best from both for loops and recurisive programming. I am actually going use this solution if i'll ever have to answer how to do that in an interview again. 
you should probably check how big a number 100! is
Ok, but that's because 100 factorial is about the square of number of atoms in the universe. You cannot represent the square of the universe with standard C++ types. If the Gamma function works for you, use it instead. tgamma in cmath seems close enough to what you want.
 **Company:** [Optiver Europe](https://www.optiver.com/) **Type:** Full time, Summer Internships **Description:** At Optiver, a leading global electronic market maker, we trade and provide the most up-to-date and competitive prices on over 50 exchanges globally. We operate our business on in-house built technology. Our infrastructure is a combination of vastly distributed systems, with high-performance computing and low-latency trading algorithms on one hand and high-throughput dataflows, huge storage and data analysis on the other. To be successful, we constantly need the most advanced solutions – we evolve our systems on a daily basis. Working in tech at Optiver is: * Solving challenging business problems * Close collaboration across the teams * Daily releases and immediate results * Ownership of the full stack of applications * Working with simple, reliable and well-architected systems * Having a system-wide understanding * Taking a pragmatic approach * Writing clean code ***Jobs @ Optiver:*** We have opportunities at any level in your career! From graduate to years of experience. We are looking for exceptional engineers, who favour simple solutions for complex problems and have a passion for clean code and good architecture. Knowledge of financial systems is not required. * [Software Developer](https://www.optiver.com/eu/en/job-opportunities/eu-1243339) * [Application Engineer](https://www.optiver.com/eu/en/job-opportunities/eu-1207954) * [Graduate Software Developer](https://www.optiver.com/eu/en/job-opportunities/eu-510831?gh_jid=510831&amp;gh_src=6c0pe11) * [Graduate Application Engineer](https://www.optiver.com/eu/en/job-opportunities/eu-652166) * [And more](https://www.optiver.com/eu/en/job-opportunities/all/Technology/Amsterdam/) **Location:** Amsterdam, Netherlands **Visa Sponsorship:** Yes **Remote:** No **Technologies:** C++14 on Linux, next to that C#, Python and Lua and FPGAs also form part of our technology stack. Want to learn more? Although optimization is important, it's not the only thing to do and certainly not a must! **Contact:** Please e-mail Jinre van der Veen or Patrycja Ostrowska at [recruitment@optiver.com](mailto:recruitment@optiver.com) for any questions.
Yes, I know, but I am sure that QBS will not die.
`decltype(x)` is not a reference in the structured binding case, even though `x` behaves like an alias.
Parsing numbers in C++17 #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;vector&gt; #include &lt;tuple&gt; int main() { auto parse_double = [](const std::string&amp; str) { char* end; double val = std::strtod(str.data(), &amp;end); return std::make_tuple(val, std::isspace(*end) || end == str.data() + str.size()); }; auto str = "3.141519"; if (auto [val, success] = parse_double(str); success) { std::cout &lt;&lt; val &lt;&lt; "\n"; } else { std::cout &lt;&lt; "could not parse string " &lt;&lt; str &lt;&lt; "\n"; } }
This is a good point, that last line is a bit pants I agree, but I suppose at the moment there isn't a better alternative :( I hope better support is added for header-only libraries in CMake too, or if there is another approach please let me know! :)
I'd like to write simply this: constexpr int f(int x) { constexpr std::array&lt;int&gt; large_table{...}; return large_table[x]; } which should produce assembler code the same as the non constexpr version and static array with optimization turned on.
Though in C++20 there's [`std::erase`](https://en.cppreference.com/w/cpp/container/vector/erase2)
can we expect some shorter syntax for lambdas? writing 'return' and 'auto' is NOT OK.
This is a cool idea! I little templating library to auto-generate CMake scripts :P Might be nice as a bootstrapping type of thing... It'd be cool to have something similar to https://yeoman.io for CMake! :)
How to read a file into a string. Because C++ has no obvious way to do it. #include &lt;fstream&gt; #include &lt;iterator&gt; std::optional&lt;std::string&gt; load_file(const char* file_path) { std::ifstream file(file_path); if (!file.good()) return {}; return std::string(std::istreambuf_iterator&lt;char&gt;{file}, {}); }
This is the best explanation. Thank you so much, i will also check on the gamma function.
https://gcc.gnu.org/wiki/InstallingGCC
Honestly I was a bit disappointed that modules doesn't force you to use namespaces by default and I have not really seen a good reason not to do this. I'm told there are reasons but they are hidden away in the minutes of meetings. Maybe taking these reasons and making them public with good examples would stop people like me being disappointed once we know why this solution was taken.
&gt; Do not host in any public way your own versions of this code, in whole or in part. This repository should be the single source for the code base. This is against GitHub ToS. Any public repository is implicitly allowed to be forked, no matter what the license says.
Thanks /u/shipstain, I had a look at the book and I was not able to find the same concept as the parallel hashmap in this book. They do have an array of locks protecting an array of buckets inside a hash table implementation, but is is not quite the same thing.
In C++17 you would use `std::from_chars`.
The Standard **does** talk about files. I don't have a link as I just have one of the ~C++17 drafts on my pc, but here are some relevant quotes: &gt; **19.2 Source file inclusion [cpp.include]** &gt; &gt; 1. A `#include` directive shall identify a header or **source file** that can be processed by the implementation. &gt; &gt; 2. A preprocessing directive of the form `# include &lt;h-char-sequence&gt; new-line` searches a sequence of implementation-defined places for a header identified uniquely by the specified sequence between the `&lt;` and `&gt;` delimiters, and causes the replacement of that directive by the entire contents of the header. How the places are specified or the header identified is implementation-defined. &gt; &gt; 3. A preprocessing directive of the form `# include "q-char-sequence" new-line` causes the replacement of that directive by the entire contents of the **source file** identified by the specified sequence between the `"` delimiters. The **named source file** is searched for in an implementation-defined manner. If this search is not supported, or if the search fails, the directive is reprocessed as if it read `# include &lt;h-char-sequence&gt; new-line` with the identical contained sequence (including `&gt;` characters, if any) from the original directive. So if you put it between `&lt;&gt;` it is a "header", but if you put it between `""` it is a "named source file" - although doesn't strictly say **filename** anywhere.
ccls is the only application that has this issue. Git, cquery, Gcc and many other applications run by maybe 20 users on this build server all run fine.
&gt; I'd like to write simply this: ... Use Clang and you can. 
\_These are extremely idiomatic C++ classes.\_ - makes a dangling reference. Nope mate, that is not \_idiomatic\_ at all.
Personal pet peeve: An equivalent to apt.llvm.org with nightly builds would be great for both gcc users and developers. Just think of how much more early feedback you’d get if people start compiling their projects in Travis CI with gcc tip-of-trunk. Currently only toy examples will be tested on godbolt or wandbox.
Link's broken, leads to unknown server error.
Ridiculous, I was just reading it. Here is a mirror https://sohabr.net/habr/post/443400/
You are 100% correct, but at the moment std::from_chars is not implemented by gcc/clang.
[removed]
Integer parsers are already implemented.
 #define let const auto &amp;#x200B;
Would you just use use_it("hello world") in this case though? Easier and also safe. 
Exactly, that argument would work for `consteval`, but not `constexpr`.
A comparison with spdlog would be interesting!
Thanks I will have a look 
Is there some rule against: class String { std::string s_; public: explicit String(const char *s) : s_(s) {} operator std::string_view() const &amp; { return s_; } operator std::string_view() const &amp;&amp; = delete; }; It makes the interface less pretty to be sure, but it prevents exactly this sort of pitfall. Defensive programming is part of making interfaces "easy to use correctly, difficult to use incorrectly".
It's logical for `static` not to be available in constexpr function because that would mean shared state between execution, which is not allowed. However, I too don't understand why not `static constexpr` is not allowed. Maybe someone should write a paper?
In the example yes - but there are often scenarios where you'd want to make this CTor explicit. Or maybe `use_it` has overloads that require clarification, and the whole purpose of String() in this case is to tell `use_it` how to handle this string. These decisions should be completely independent of whether or not applying our "safety belt". Often, they happen in 3rd party components and are beyond our control. (Note that these are just trivial examples demonstrating the problem with commonly known classes.) The intent of the &amp;&amp;-delete-construct isn't apparent (unles that becomes a common pattern, which the optimist in me doubts). So it would be operator string_view() const &amp;&amp; = delete; // helps against *SOME* accidental dangling references, but also blocks some legit uses, unfortunately Which isn't really helpful for the person stumbling over a compiler error: do they have a dangling reference? Or does a hypothetical mistake prevent legit and intuitive use? --- Certainly, for a particular constellation of classes, if we can prevent just some incorrect uses, it may be a good idea. Yet it's not a good *pattern*, because we cannot give good advice on when to use and when to avoid, and slapping it on indiscriminately certainly will lead to curses, frustration and a general pondering of the simplicity of the olde times. 
The [godbolt link](https://gcc.godbolt.org/z/AdduDS) in [this post](https://www.reddit.com/r/cpp/comments/b04smy/static_variable_not_permitted_in_a_constexpr/eic7dwm/) shows that Clang actually generates code as if it was `static`.
Yeah, I don't think this is sufficient. Technically, `static` variables have different lifetimes and since we have `is_constant_evaluated()`, it can be quite handy for the lifetime of a variable to last longer than the function itself.
There's the Docker image I posted about last week which has GCC, CMake, and Ninja set up for modules. If you set up a repo with `CMakeLists.txt`, it can be cloned into that image and tested out. https://hub.docker.com/r/benboeckel/cxx-modules-sandbox
I don't know if the reasons were discussed or if they're public (minutes or no). But how would you define a `std::swap` or `std::operator&lt;&lt;` overload if a module is forced into a namespace?
In the process of studying the work of c++ compilers, implement an interesting tool - [https://github.com/Neargye/nameof](https://github.com/Neargye/nameof) also some of my little snippets - [https://github.com/Neargye/yacppl](https://github.com/Neargye/yacppl)
&gt; If not then the build system could recompile dependencies based on whether its hash has changed. The compiler could also say "hey, the content didn't change" and not touch the file at all.
Fair enough.
&gt; Most UI functions expect to be called from what Qt calles the "Main Thread" or the "Qt thread" without being clear what exactly this is. Just in case you're actually unclear on that: it's the one where you called `exec()` on your `QApplication` or `QCoreApplication`. &gt; end up writing some mechanism to demux events and signals back into that very Qt thread They already wrote that for you. It's the `QEventLoop` itself. Signal/slot connections are thread-aware (as long as you didn't override the signal/slot connection type yourself), and will post in a thread-safe way to the other thread's queue. 
It means evaluatable at compile time. I never said it was only compile time
lol if you ask close/above upper bound won’t honor it the expectation is that you’ll lowball yourself 
Hah, whaddya know... I stand corrected: https://doc.qt.io/qt-5.9/threads-qobject.html#signals-and-slots-across-threads I was not aware of this. Perhaps the last time I checked that was undocumented or simply not there yet. Granted, the last time I checked was probably more than a decade ago. During which I have written at least 3 different ways to do just that. The last one not two years ago. So OK, if this works, it solves the demuxing problem. It will however not solve the issue itself, the deadlocks in signal chains. Still, once again, nice docs. 
I dunno. Godbolt shows that Clang 'judges', *in that case* the thing to be the same, but obviously the `constexpr` function has wider `constexpr` use-cases. Is Clang wrong, or the others not clever enough?
It wouldn't take much to point such a utility at your favorite cmake git repo of template projects, ask it for a listing, and just fetch "directory X". The next level of usefulness would be taking said git repo and use templates to customize these exemplar projects with the name of the project, -std=c++XX, and bias it towards the native platform e.g. GNUInstallDirs on Linux (I dunno what the equiv is on windows). For whatever reason, the kitware and the cmake community has focused on generating overwhelming amounts of documentation over formalizing best practices via tooling. I've lost count on the number of blog posts and videos that claim "this is the right way to do it" while all being just a little different. And people wonder why newer developers are embracing meson...
Allowing and disallowing references to temporaries are actually not the only two choices, right? You can also make references to rvalues a different/distinct type from the corresponding references to non-rvalues. For example with the SaferCPlusPlus library (shameless plug), reference objects (pointers, iterators, views, spans, etc.) to rvalues are "inert" types that do not support being dereferenced (or copied, etc.). They can be converted to their corresponding (fully functional) reference types, but only when passed (as an rvalue) as a function argument. It does require the (reference) function parameter to be [annotated](https://github.com/duneroadrunner/SaferCPlusPlus#as_an_fparam) (with a template wrapper class), but it allows functions to safely accept references to temporaries, while at the same time preventing references to temporaries from being stored and dereferenced outside of the function scope. Although personally, I don't mind the policy of just avoiding references to temporaries whenever practical. 
Just making sure. Now taking an example, you can throw in a `constexpr` function despite exceptions being a runtime-only feature. `constexpr` handles it gracefully by giving a compiler error when the throw is hit during compile-time evaluation, but it doesn't prevent you from writing this construct that is useful when the function is called at runtime. It's possible that it could handle `static` gracefully as well in order to support the runtime side without hindering the compile-time side.
You can find a bunch of 'pattern' snippets here: [https://en.wikibooks.org/wiki/More\_C%2B%2B\_Idioms](https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms)
Sorry, my mistake. It talks about files: It aknowledges that source code is usually stored in something called files. However, as you saw yourself, it doesn't talk about filenames, filesystems, directories or in general, how files on your system are stored and identified. I'm not sure if anything about that changed with c++17 and the std::filesystem library though. The end-result is the same. So far, the standard is lacking the basic concepts that would allow it to define, how a mapping between a module name and the filenames of the module units should look like. However, I don't think that is the actual problem - If the committee really wanted to, I'm sure, it could specify something like that (probably not in the c++20 timeframe though) but a) it would not be in line with current policy on what gets standardized as part of c++ an what not and b) There is very little experience in the field that would allow them to make an informed decision (although I'm sure that some of the experience from other languages could be applied here). are identified on your system, nor how a string like "boost/config.h" mapps to a location on your filesystem (at least in the past) it didn't talk about how the stuff in the source (e.g.) `# include "q-char-sequence" ` mapps to file names and locations/folders on your computer. Not sure if this changed with c++17 and `std::filesystem`. So yes, it could say (and maybe does - haven't read the text in a while) that `import module &lt;module-name&gt;` identifies a file containing the primary module interface, but just as with includes, the actual mapping is completely undefined. 
Buggy microsoft code? Omg no way 
there's also [https://github.com/rizsotto/Bear](https://github.com/rizsotto/Bear) for any other build manager 
I was more suggesting that they repost in cpp_questions.
Old news, dude. 
Neat to read. &amp;#x200B; I wonder if naming and shaming source code like this will make organizations less likely to contribute source code like this in the long run.
I don't think Microsoft cares what an individual did in a project that looks stupid, unless it's a security issue.
I'm no C++ programmer, but shouldn't a lot of this get caught by the linter?
For me the issue is that, a function pointer parameter provides concise, obvious error messages because it's actually saying, THIS is what I want. A generic template parameter gets you into the standard illegible deluge of error messages thing. &amp;#x200B;
&gt;I honestly don't know the answer but i'm sure smarter people then me could come up with a possible answer. &gt; &gt;What i'm really after is was this ever seriously discussed and where could i read/watch that. &amp;#x200B;
Does `static const` work? I thought `constexpr` just says that it can be evaluated at compile time - not that it will not be modified.
It's pretty amazing how far this sub has fallen to hype.
It should. But the calculator app makes little money for Microsoft, so it might have low priority compared to other projects.
I'm not going to create Ubuntu packages but I just created https://copr.fedorainfracloud.org/coprs/jwakely/gcc-trunk/
Thank you everyone!
I was thinking in general if big company X seemingly has nothing to gain from the contribution but could look bad because of code defects, it might dissuade them.
I guess it's sort of shaming, but not really. The bugs aren't a big deal or breaking the calculator in any way. Perhaps part of the reason to release it as open source is to get low-cost labor to fix these little bugs instead of paying a dev full-time for something that already works as intended.
Which is probably why they open sourced it, so they can accept pull requests for free :D
There is no "_the_ linter" for C++. The tool they use is just one that checks things of that sort.
&gt; In the example yes - but there are often scenarios where you'd want to make this CTor explicit. Or maybe use_it has overloads that require clarification, and the whole purpose of String() in this case is to tell use_it how to handle this string. Then the function would not take a `string_view` but a `String`. As I said, it mgiht be less convenient, but you can almost always turn a temporary into a local variable, so you loose very little actual power. The real impact is much smaller than people arguing with "there could be a case where"... are usually implying. Now again, I'm not saying it doesn't have disadvantages, I'm saying it is a tradeoff that you may or may not think is worth it. Back to my original post: You can't have perfect usability, safety and performance together - you have to make trade-offs 
How does alignas help when you already shipped with 4 or even 8 byte alignment? How they are passed as arguments, correct.
Yes, it is less convenient - so are seatbelts. Other than seatbelts, no one is forcing you to use the pattern, but just because you don't like the tradeoff doesn't mean it is generally useless.
If you need any help, please let me know or open an issue at https://github.com/nlohmann/json/issues.
I just assumed it was made in visual studio
I you do want to provide a stable ABI type, most likely you'd specify it with alignas(X) and maybe add a static_assert to begin with. Regarding parameter passing: At least with the itanium abi, types with non-trivial copy constructor (which a type with a separately defined copy constructor always has regardless of the members) are always passed via address (i.e. the caller makes a copy and passes that by reference: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#calls). I thought, that was the same with other ABIs, but I might be mistaken.
Just finished, yours was one of the most straightforward to implement :) [https://github.com/CathalT/Cerializer/commit/16a7e0a95ca3026450ce402200645aeb1021c488](https://github.com/CathalT/Cerializer/commit/16a7e0a95ca3026450ce402200645aeb1021c488) &amp;#x200B; Next step is to benchmark this stuff, see what the overhead is like
Until recently the static code analysis feature of VS was very... rudimentary. It probably also doesn’t help since this is C++/CX and not straight C++.
Hopefully, it is more important for them, that the users get a less buggy product than that some developers holding their codebase in contempt.
Most of the issues here would not exist if the code used a more modern style. Also, these bugs dont matter. Calculator proves useful to millions of people on a daily basis and has for decades.
You could make overloading `::std::swap` escape/ignore the implied module-namespace and instead create an overload in std, no? 
I believe the primary reason is because modules are sealed. You can't add to the interface of a module from another file. If you tied namespaces to module names then you could only have a single module for an entire namespace, which doesn't match existing practice and would make it difficult to move code over.
Where is the german one? 
verbose is the opposite of readable in this case though.
You can write a standard compliant compiler that takes as input PNG images of code, does OCR, then compiles the result. No other compiler is going to accept those PNGs. It doesn't accept text. Both are standards compliant, because the standard does not specify what the actual format the input file is in. 
&gt; the compiler can't just demand that if I do " &gt; #include &lt;foo.h&gt; &gt; " it should be looking for a file called &gt; bar.h Yes, it can, and be standards compliant. The standard *does not describe* where the `#include &lt;foo.h&gt;` gets its content from. It could take the string, add the word chicken in front if it, ROT13 it, put it through a SHA-256 hash, and search for a webpage named after that on the internet. That wouldn't be a great QOI, but the standard is **completely silent** on where it finds that resource. There are conventions and most compilers follow them. We do not yet have conventions for modules. There is an incoming TR that hopes to establish some. 
Yeah, after reading the replies here the last couple of days, I realized this is in fact true. But this just feels like a bug, more than a feature. Like a common code smell, to make things more generic than necessary. It introduces extra layers of complexity, without the benefit that comes with generic code in other situations.
No; this freedom is only actually used when needed in actual practice. Godbolt, compiling on OS's with alien or no filesystems, interpreted C++, etc. 
Unfortunately, on linux, it only works with glibc. I have a 1 line PR and an open issue, but it gained no traction.
Thank you, this is much appreciated! I downloaded and installed the .rpm on Ubuntu using the `alien` tool. Using `update-alternatives` I managed to select the gcc-trunk as compiler and check the version. However, there are some errors about missing libraries (libmpfr.so.4), which are no longer installable on Ubuntu 18.04. Could it be that your gcc-trunk defaults to 32-bit address mode? Or is my Ubuntu system tricked by the /opt install directory? I'll try and set up a VM with Ubuntu 16.04 to see if it works there (which is the Travis CI distro). BTW, http://apt.llvm.org/bionic/dists/ has the dates: the unnumbered toolchain corresponds to tip-of-trunk and is updated almost daily (yesterday last time). The numbered toolchains are stable release (8 coming out any time).
Yes, but we can still have all those things, they would just have to advertise as "*C++11 compatible with the following exceptions*" instead of "*C++11 compatible*" Then it would be clear what the standard means for normal systems and the other systems specify how they differ. Instead of the current situation where nobody knows anything and we just do what we always do and hope it works. It is also possible to specify multiple behaviors, and things like "On a system with a posix compliant file system, it works like this. Otherwise it is implementation dependent."
Btw, here's a [link](http://coliru.stacked-crooked.com/a/55ea711872393b4b) to a (hasty) example of how one might implement the `String` class in the article's example so that you can still use temporary `String`s as arguments to your functions while disabling them everywhere else by default.
I hoped the Bjarne paper about never go after perfect design should at least get executors in, but well. And again, there is nothing perfect, especially the latest Chris paper stated that executor design is future proof and can integrate coroutine easily. But if it's because of time constraints then well smh.
It's a fedora package, I don't expect it to work on Ubuntu, at all.
If the system has a C++ compiler than you can compile CMake for it 
It comes from C culture. Dennis was actually aware of the unsafety issues of C, which is why Johnson created lint in 1979. &gt; Although the first edition of K&amp;R described most of the rules that brought C's type structure to its present form, many programs written in the older, more relaxed style persisted, and so did compilers that tolerated it. To encourage people to pay more attention to the official language rules, to detect legal but suspicious constructions, and to help find interface mismatches undetectable with simple mechanisms for separate compilation, Steve Johnson adapted his pcc compiler to produce lint [Johnson 79b], which scanned a set of files and remarked on dubious constructions. -- https://www.bell-labs.com/usr/dmr/www/chist.html To this day having static analysers as part of C or C++ development toolchain is still a discussion theme.
It's the new calculator, not the old one.
Found the pragmatist. Really though if MS was looking to outsource calc.exe for the lowest price possible how can they go wrong?
The software sold by and used by the blogger is a linter. So all of it did get caught by the linter.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b0e1ka/how_do_you_read_comma_separated_int_from_a_text/eidzcp6/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I really don't see anything wrong with that being a reason behind a corporation open sourcing a tool. If the tool is useful, the community will fix it and everyone benefits. If the tool is useless, well, the corporation still won't waste time and money on it.
`void App::OnAppLaunch(IActivatedEventArgs^ args, String^ argument) {` What language is this?
C++/CX
The thing is, static inside a function has different meaning than static outside a function, so the compiler translating one from the other is, in my opinion, not reasonable. Namespace scope static variables are guaranteed to be initialized before main -- inside a function, theyre initialized on first call. It's a subtle difference, and with the way the OP wrote his first example, its explicity saying "don't define this until this function is called", which now means a constexpr function now has a side effect -- something it's not allowed to have.
TIL. Thanks.
I would consider it legacy at this point. You can use C++/WinRT to achieve the same result but using only standard c++.
I wouldn't expect this to be how it works. My first thought was to leave runtime behaviour unchanged and make the compile-time version ignore the `static`. Constexpr contexts won't allow side effects in the initialization anyway, so as far as I can tell, this leaves the behaviour unchanged in the situations where the function can be called in the first place. Obviously a proposal would actually explore why that idea probably has a subtle breakdown somewhere.
At least a few of them don't look like bugs. 
Somebody is macroizing `min`, likely `&lt;windows.h&gt;`. Preprocess to see whether it's damaged. Compile with `/showIncludes` to see the header order, and compile with `/P /d1PP` to preserve `#define` directives to find the offender (if windows.h isn't obviously the culprit). If it is, define `NOMINMAX` project-wide to suppress the offending macro, or wrap your `min` in parentheses as the STL's implementation does to defend it from the evil macro.
no software is 100% perfect, so I don't know how this is supposed to "make them look bad". When they announced the open sourcing of it a few days ago, the soul intent was to get features and bug fixes from the community.
So C++/WinRT replaces C++/CX that replaced C++/CLI that replaced Managed C++.
Which is a good thing, for those who want to gain experience contributing to a project that millions of people will probably use.
Is there anything in C++ that allows for this nicely, like a logging facade in a library (static or shared/DLL), and then a user of the library can decide their own logging framework if they're already using one? This would be quite huge for library writers. How is this done in (modern) C++ usually?
I agree with you there. But the tops question was "why can't the compiler translate this into that" -- and the reason is because they two examples are fundamentally different when it comes to when they are initialized. Most of the time this doesn't actually matter to the user, but when it does, it matters a lot. You may have memory constraints that makes you prefer initialization before or after main, and the compiler can't force you to one way when it meant the other
That's fair. In a way, I was on about transforming it to a local by simply ignoring `static` while the OP gave the example of transforming it to a global. 
Use/implement your own `std::function` if you don't want to use template parameters.
Releasing something as open source usually involves a lot of additionnal internal work to make everything "pretty enough" to be published that wouldn't have been done otherwise.
Eh, not quite. There are two lineages there: 1. **C++/CLI** replaced **Managed C++**. It is a fully-fledged managed .NET language like C#, F#, or VB.NET and is meant to be compiled to CIL bytecode. It has .NET-ty features like finalizers (in addition to regular destructors). C++/CLI is still a supported language for .NET. 2. **C++/CX** is a wrapper around the new windows runtime (WinRT). It has special syntax which _looks like_ some of the C++/CLI syntax but is essentially syntactic sugar around ComPtr and HRESULT and RoGetActivationFactory and all the crap that you have to deal with if you use WRL (the underlying native C++ layer). It compiles to fully native code. It has been replaced by **C++/WinRT** (née [Modern C++](https://moderncpp.com/)) which is 100% standard C++ but is still built from the IDL files like any other language projection (unlike WRL which is much lower-level).
You mean "it was totally made by an unpaid intern". At least I hope that's the case, or when they git --blame some of those bugs, someone may get fired.
 std::string_view sv1 = s; // OK std::string_view sv2 = String("hi"); // BAD! Is it really the case that the first one is OK, or is that by fluke? What if this member function **itself** creates a temporary string object which is then converted to `string_view`: operator string_view() const { return s_; } The idea is that the first definition is OK is predicated on this not happening; that `s_` itself is passed to a suitable constructor of `string_view`. 
As /u/STL said, the evil `min` macro is ruining your day. You can either find what file put it in and use some other macro to disable it (in case it's from `windows.h`), `#undef` it, or rename it to avoid conflict. Also I would advise putting some SFINAE or `if constexpr` with a static assertion to avoid awful error messages if you try to use it with a type that doesn't support comparison.
The 'Suspicious comparison of real numbers' example certainly looks deliberate to me. The entire expression should be examined, not just the second clause in isolation. The 'Suspicious function sequence' appears to be complaining that logging of an error state doesn't also log success so the code is doing what seems correct to me.
Window.h was the culprit. I learned something today. Thanks for the lesson, friend!
....Man you just SAVED my life! I still find CMake to be kind of unnecessarily complicated, but at least now I understand enough of it that I can create some things that work, also delegate cmakefiles to someone else as a trap. Thanks! 
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;See [P1143, _Adding the `constant` keyword_](http://wg21.link/p1143), as I believe that covers this. 
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;A variant of something along these lines built with concept subsumption and type erasure instead of inheritance would be interesting to see…, but I imagine that producing it would likely spill over into requiring [metaclasses](http://wg21.link/p0707) to avoid the same amount of boilerplate that this version does. 
I'll look into that.
`type function(args) use (capture,list,here) { }` is much more readable than `[catpure list](args) -&gt; decltype type { }`
`constexpr` implies `const`, AFAIK.
By their respective std::libs.
Using this, you can do it cross-platform: https://github.com/mandreyel/mio
Last time I checked, this is order of magnitude slower than using [file_size](https://en.cppreference.com/w/cpp/filesystem/file_size) and [read](https://en.cppreference.com/w/cpp/io/basic_istream/read): std::string s; s.resize(std::filesystem::file_size(file_path)); file.read(s.data(), s.size());
&gt; unpaid intern I'm not sure why you'd say this? Microsoft interns make $7.2k/mo plus housing, transportation, and medical benefits.
In my experience, the direct posts from people looking at the code are respectful and not a problem. It's the people who read those posts who then overreact and do the shaming. /r/windows is having a debate on the meaning of the word "suspicious" in this post, not really understanding that this is selling a static analyzer and not bashing code. 
It's more about the cliché that all shitty job is done by an intern than a jab at Microsoft for what they pay their interns (which I didn't check anyway). Also I feel sad to see interns there get paid more than I can get with a fulltime job here.
Hi OP. I'm somewhat of a beginner in c++ (been using it at an internship for a few months), and I want to mess around with the language on my own time. I've been looking for build systems today and stumbled across this post. Could you explain what control I would be losing by using bake, as opposed to something like cmake?
Author here - actually, I thought I did not blame anyone. Regardless, allow me to clarify the points you mention - debug builds are a compiler issue -&gt; this is false, the STL at least in all the implementations I've ever seen, relies terribly on compiler optimizations. It will pretty much go into 10-deep call stacks for even the most trivial operation, for no good reason at all. And it's not hyperbole, try anything at all. Dereference a smart pointer. Access a vector element etc. Debug builds can't inline these calls and everything dies. SIMD - "libraries exist", yes and threading libraries existed and smart pointers and whatnot, even lambdas... So we shall stop and never add features to C++, even most of the ones that were added because "libraries exist". Even if SIMD is obviously something that would benefit from standardization more than even, say, lambdas. If you want to call me "whiny" - please make good arguments - Alignment. Yes, that was one reason why you could not use STL even for simple containers that should be good enough for it to handle. See EASTL rationale.
Good question! There are a three areas where bake takes control. The first one is project layout. Bake expects source files to be in `src`, and include files to be in `include` ([more details here](https://github.com/SanderMertens/bake#project-layout)). Binaries will be stored in a `bin/platform-config` directory. The second one is, bake by default adds "common sense" compiler options, like `-O3 -DNDEBUG` if you build in release mode, and `-Wall` which ensures you get all warnings from your compiler. In addition, bake also specifies the C/C++ standard you're compiling for (`c99` for C, `c++0x` for C++) by default. You can override these in your project file. The third and last one is that bake has builtin rules for building C/C++ files (how to go from `.cpp` to `.o` to `.so`). If you want to add rules (for, for example for code generation) you have to create a bake driver. An example of a bake driver that does exactly this is the [bake test framework](https://github.com/SanderMertens/bake/tree/master/drivers/test). So this is not really a limitation (in fact, it's quite a bit more powerful), but it is *different*. Other than that, you're free to do whatever. You can add your own custom compiler flags with the `cflags` or `cxxflags` attributes, and a host of other attributes which let you add libraries, library paths and include paths in a platform independent way. [This is a list of available C/C++ options](https://github.com/SanderMertens/bake/tree/master/drivers/lang/c). Make sure to check out the [Bake FAQ](https://github.com/SanderMertens/bake#faq) and [Getting Started](https://github.com/SanderMertens/bake#getting-started) to get a feel for how it works.
Authore here - Partially, yes. But also because it fails at even the most basic containers. A deque without the ability of specifying the block size? And let's look at say, MSVC block size. Ouch! Most structures are also too slow to compile, way to slow in debug for no good reasons. For a long time alignment was not understood. Error messages were cryptic (and still are in many cases). Often implementation atrocities, but equally often, design/standard ones too. A good read is the EASTL rationale
No I meant what loup said. Sorry if I wasn't clear. Bottom line, C++ is already in a complexity crisis, there are a few proposals that would ameliorate that (like concepts... but also deprecating stuff would help a lot), but adding new features and complexity always seems to take priority.
Aren't there ruminations floating around on how to not rely on ADL for these customization points in the future?
Why? Why it's a tooling issue and not an STL issue? I mean, making a vector&lt;&gt; that is fast to compile &amp; in debug &amp; easy to debug is not hard...
Not at all. Because there is no reason why a smartpointer dereference or a vector access should take you to 10-deep callstacks. It's a STL failure
I got the first part of the next step done tonight, which was a big re-swizzling of the build environment setup stuff. It was all up above the two CID\_Dev/CQC\_Dev source directories, as was a number of dependent files. I've got that stuff worked out now so that the stuff CIDLib needs is down in its directory, updated the environment setup files and got those down there, and did some useful setup simplification in the process. That also affected my CQC installer image builder as well. But that's done, so now I can get the build docs done next. &amp;#x200B;
Author here - I'm sorry if I made you feel that way. I actually thought I was being quite "nice" - I admitted it's "us" that have some particular view of the problem/language and that C++ is going in the same direction it always did. Actually I said that other languages should learn from its attention to the ecosystem. Yes, C++ is "dead" to me, but that's not a bad thing. Lots of great tech reaches the phase in which it's pretty much gigantic and ugly and a mess but an useful mess that someone has to keep pushing. OpenGL is probably the closest example. Huge. Ugly. Made by a committee. But it's useful at what it does.
Author here - yes you are right. Lots of smart people are busy shipping and won't touch the committee.
Eigen is gigantic and not optimized for the platforms we ship. In fact, I'd say a linear algebra library, even if only limited to 3x3, 4x4 etc would be quite useless in general. A SIMD standard could be somewhat interesting, mostly for tools and other things where we don't wanna go to the specific CPU intrinsics. That's a different thing than vector math
If you read the comments (of the blog post), I actually tried also to explain why languages don't matter for videogame companies. And actually why they matter a lot at the same time and we innovate on them all the time! Have a look
Because the library authors need to maintain the software, support weird systems, and word weird compilers. Why isn't EASTL shipped with compilers or used outside of games? Do to honestly think the libc++ is written like that to about annoy you personally? Or no one else is smart as you? As much as the committee doesn't understand about writing games, game devs don't understand about backwards compatibility.
It's hard to make a cross platform data type that doesn't hard bind the implemention to the state of the art the day it was specified. STL isn't meant to be all things to all people. EASTL was the motivation for creating SG14 (games study group) iirc.
I fully assume that STL implementations are written by people that know the language a million times more than I do. I am not saying they are dumb, in general, I assume people who are pros doing a given thing are competent until proven otherwise. But in practice, it still takes 10-deep callstacks for trivial things. Which is a STL failure, at least, when it comes to what I care about. Is it because of legacy and compilers and tiny but extremely complex speculations in the standard? Most likely. But I can write my smart pointer in 20 lines that doesn't have all these problems. Would it be standard compliant etc? No. But it's much better for what I need... Maybe, if doing a vector&lt;&gt; is so hard in the STL, then it should have been in the language, or the STL should have been less strict. I don't know nor do I care. The end result is something I can't use.
It sounds like the only true limitation are the assumed directories, and the other two limitations are more like default configurations than anything. If that’s the case, then I’m very interested and will be checking out the github link. Thank you for your explanation and contribution to the community. :) 
If you write the paper, I will present and champion at committee.
You are not answering to my very basic and specific critiques. A deque that does not allow you to specify the block size, and defaults to way too small blocks in extremely widely used implementations, while they are waayyy to big in others - is that a good design? Who is that serving? https://bugs.chromium.org/p/chromium/issues/detail?id=674287
The only paper I would write is one that calls to stop adding complexity before having ways to remove some. Can we do that?
We use unreal 4 at my current non game job. I'm still very aware how and why games implement their own array types. There have been alternative libraries for vectors and smart pointers for a long time. The fact the committee cannot serve every use case to full satisfaction is both understood and not considered a failure.
So we are in agreement. My entire post was about the fact that C++ is going in directions it can -legitimately- want to go. And I legitimately can say these directions are useless to me and at least in my industry, that's not an uncommon sentiment. What's the problem? Do I -have- to love the STL, or r-value references or something?
There is slf4cxx, which seems to be a slf4j port. And slf4j is exactly what you’re asking for. A facade against you can code. How then the problem of linking is solved I don’t know at the moment. I’m thinking about to research a bit and write something about slf4cxx as well.
No -- backwards compatibility. Pick the feature you want to remove and then calculate what that would cost to all parties who depend on the old behavior, and the amortized cost to everyone who now realize c++ is no longer backwards compatible, and get back to me. Given how many game devs come from Windows ecosystem you'd think they'd understand the power of backward compatibility better... And if your refuse to participate in the avenue available to you to affect change, then to lose any ground left for complaining as well.
No. But your post came in a moment of zeitgeist that was seen as incredibly self indulgent and arrogant, even among people who sympathize. There problem is not new and response is not new either. You need to talk to your seniors that think *all* of C++ is overly complex and slow to get some perspective.
My seniors? Anyways, I can only answer for what I think, not for the entire industry. I won't tell you to answer to nonsense said by other C++ enthusiasts do I? Like that infamous thread, which U might have seen, where some people said that you don't need debuggers/debugging...
STL was designed in mid 90s. Which part should have anticipated CPU performance in 2010s?
You're a conservative progressive :) So you are progressive, but only in the direction in which things are going already? Think a little about it and you would see I think that it makes no sense to hang everything to "backwards compatibility". For example. Deprecating stuff does not mean you kill backwards. You can support that even forever. You can say for example in C++30 we will kill X. But that doesn't kill all the code using X, it simply means people who need X won't be able to upgrade. Compilers can still support X till the end of times. It's perfectly doable. In fact, lots of other huge languages do deprecation. See Java. It's a big one! There are even additive features that do reduce complexity. Modules -could- if done well. Concepts could, if done well. Metaclassess... Refusing to add complexity would be a huge change...to the committee goals. I support change! 
Windows is a great example. You can still write games that use DX9. But DX12 does not care at all about the legacy of DX9, does it?
Lol. I know Sean. Sean is principle scientist at Adobe. I guarantee you still use things he wrote a decade ago. He is right in so far as to have access to your own source, and you're not teetering on the edge of burn out at 2am with an impossible publisher imposed deadline -- most bugs are solved through code inspection. If someone put a gun to your head you could manage that too. And "don't use c++ at all" wasn't some crank idea, it was defacto industry consensus. Computers got faster, she developers got younger. The same thing will happen again. And C++ will still be relevant after N games have come and gone because of backward compatibility 
I don't know how that's an answer to that basic deque design fail. Also, even if that was one, and it is not, you could still add an extra parameter to the templates to specify that very very important block size. And it would be backward compatible too via defaults. So it's pure nonsense what you're saying. Please think things through a bit more.
And look how long it took to get people from 9 to 11 or 12. Look at python 3. Round up all the people who have a stomach for that and how much it will hurt them, and let's talk.
You *never* go full progressive conservative. And it's not "me", it's in the DNA of the language going back to C. Yes we can deprecate anything you want. Write your deprecation paper and I will present it.
And as ugly as C++ had always been, it's always been "don't pay for what you don't use". The only real cost is cognitive in learners, and those poor compiler writers.
Python didn't deprecate, it made breaking changes all of a sudden. DirectX is incredibly successful. And OpenGL, the thing that is designed by committee and compatible all the way back, is useful in some contexts, yes. But it also became ugly and abandoned for state of the art stuff because of its own weight and all the issues that a design-by-commitee thing always faces. And btw, the same will happen to Vulkan, but we are digressing. The bottom line is that just saying "it can't be done because legacy" is - false. Java does it. Lots of other huge things do it. So. FALSE. Then it might be hard, not worth it all the times etc, but simply rolling with the fact that C++ never did it and parroting the position as it's factual, the word of god, is not very productive... 
And tooling etc. Yes I agree. These are not small costs. It's NOT a coincidence that you will find way, way more advanced static checking and metaprogramming and experimental wonderful tools for C, rather than C++. Even just parsing C++ is a herculean task. The fact that tooling is not considered a thing, while it is simply the most important thing in any language ever, is its own fail
Write the paper how you'd like deques to be modified and I will present it. Most people when they don't like the vanilla default download a library they think works better.
I'm not sure what part of "write a paper and I'll do the annoying leg work" you don't understand? No one is going to come take your order and get back to you with a hamburger. This is a participatory process. Participate -- not on Reddit.
I thought I made my point on why I will not join the committee process - in the post. I fundamentally disagree with that kind of governance. But there it is, if you think the committee works, that's a very simple, very obvious example of a huge deficiency that is trivial to fix in a fundamental data structure. You don't need me to write the paper, anyone can. The chrominum post was the first thing I found on google btw, tons of people are aware of the issue, it's not a secret (obviously, as it's a quite glaring and fundamental one)
I was replying to what you said, as I thought it was a false excuse - nothing more and nothing less. I wrote and entire blog post on why I do not care about the committee nor changing the language at this point. How's -that- not clear?
How is it not considered a thing? How many SG15 meetings have you attended?
None, of course, but I do still follow C++ itself and I have never seen anything done to help tooling. If I'm wrong, tell me what. I do have no doubt though that compiler writers complain a lot and put vetoes in the meetings. That is -not- what I mean by being tooling-friendly. That's being vendor-friendly, at best.
And that anyone is you. The fact you decline to offer your own time outside of complaining is telling. There is no C++ outside of community governance. Perhaps you can fork whatever you think it is that C++ is less community and see how that project runs. Or just use C or C# or whatever you feel is better governed.
I pushed up those changes, which includes a new readme, based on feedback. I haven't had time to select a license yet, but the legalisms are removed from the readme, replaced by a few explicitly non-legal 'would be nice-isms'. &amp;#x200B;
It's not clear on so far as you're on Reddit showing you seem to very much care. Usually people leave their blog opinions on their blogs.
I'm cool with that. "C++, it's not you. It's me" - that's my title again I don't know how to tell you that. I do not care. I do think C++ is evolving in directions that are -wrong- for -my- use, and I do not care, I'm fine with it going towards python-esque thing I won't use. Why? Because what I do does not hinge on language innovation anymore (see what I wrote in the comments if you care) and thus I'm ok with staying mostly around C-ish C++ and eventually wait for something else if that ever comes. I hope I was clear and we can all agree and live happily now?
I appreciate your interest in how I make your sausage, but I think it's clear you think your problem should be my problem, and you can't be bothered to help yourself. We work hard and mostly in our spare time. If you every decide you want to be a part of the solution feel free to contact me again.
I actually have no problem. 
Why do you care about me wasting some time?
I love these PVS Studio ~~advertisements~~articles! &gt; Memory leak in native code Hereby I posit Gotebe Law of C: as the codebase changes, the probability of a possible leak like the one in the example (and many more kinds) is asymptotic to 1. 😁😁😁 &gt; Elusive exception It's **not normal** that this * is part of a Calc code (there must be a library doing it) * wasn't discovered earlier &gt; Suspicious function sequence This one is a job for whatever ScopeGuard one's using. Would **not** have expected any linter to look and detect this situation, kudos to PVS team!
If I get fired over bugs like these, I don't want to work for the company that fired me anyhow so all is good. Heck, if I see that being fired over such stuff is even possible, I am already out.
The suspicious sequence pretty much looks like a ctor/dtor pair. The analysis does say it's suspicious, not a definitive error. So while you could be right, wouldn't you want to be notified? 
What happens if the file is resized between the call to file_size and read?
Well when you have a condition that was always false because you compare pointers instead of values, you can tell there was a serious lack of testing. And that's just one example. Who the hell writes a new branch without testing if it actually works?
Then the problem is you, not cmake. cmake is so ubiquitous because it just works.
Sure thing! If you have questions or run into issues, don't hesitate to create an issue in the repo!
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b0epy1/header_works_in_one_msvc_project_but_not_another/eiext03/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Mind blown
What about using boost::serialization to store a settings object? The decision between xml, json or binary is then easily changed. encryption/checksumming/compression can be implemented as a filter
If you want it to be configurable after compilation, you stick it in a json, yaml, ini, etc file. If it really doesn't need defined after building the program, then you hard-code the values into the program. If you don't want the user getting into the config, I guess you could obfuscate the contents of the config file somehow, but things like that can get goofy really fast. Having said that, this post probably belongs in r/cpp_questions, not in r/cpp.
But I wanted the exact opposite of that. I don't want it to be user configurable. I'll also cross-post it with cpp questions, sorry.
Modules are new so if the existing practice makes it much harder and more error prone to include third party code then maybe we should stop following existing practice. would it be hard to include a way of importing everything inside a module into the global namespace if i wanted to for backwards compatibility ? `import speech as global;` &amp;#x200B; I'm sure all this has been discussed in depth before but cant find it 
oh come on
They use their own tool (actually this article is marketing to better sell it).
I bet they reused old code. There is no other reason to use C++/CLI.
Maybe you can try [GuiLite](https://github.com/idea4good/GuiLite) Only 5k lines code
&gt; slf4cxx I know about it but it seems old and unmaintained for quite a while - not really a project that you would start using nowadays.
How does it compare with [junction](https://preshing.com/20160201/new-concurrent-hash-maps-for-cpp/)?
Does it work with C++o3? Or C++11? I've made my own wrapper for rapidjson pointers, but no reflection.support. i still have to manually write to_json and from_json helper functions for.all of my structs
read will just fail, no UB
Well, yeah C++17 offers better API for file reading.
CLion won't offer you the same level of assistance as VS for build management (especially for small projects, with larger projects it doesn't really matter). However, when you add a new source file to your project (using clion's interface...), it should ask you if you want to add this source to known compilation targets. In particular, assuming that you have a variable in your cmakelist with the list of input source files and a target (probably the executable or library that has to be build) using this variable : it should ask you if you want to add the new source file to the list. &amp;#x200B; See the "add to target option" in [https://www.jetbrains.com/help/clion/new-c-c-file-dialog.html](https://www.jetbrains.com/help/clion/new-c-c-file-dialog.html)
C++ never ceases to surprise me. I have never seen this syntax, but it makes sense. Since code is executed in member initialization list of constructors, there should be a way to catch exceptions there. What about member initialization in classes? E.g. class Foo { B b = makeB(); }; You cannot use B b = try { makeB(); } catch(...) {}; Maybe in C++ 42.
what about vs gtk?
No, you can't do everything QT can do. QT is a huge ecosystem.
This is very cool, I'm a fan of minimal libraries like this. I suppose you're aware of [ImGui](https://github.com/ocornut/imgui), which competes in a similar space, how does your library compare to it?
Even ignoring all the Qt stuff other than graphics it's hard to imagine a small library doing everything that Qt GUI Widgets do. From a glance at the code it looks like it provides you with a (fairly decent) foundation on which you'll have to all of the nice-to-have stuff manually that Qt/GTK provide you with.
Hm latest commit was 19 days ago https://github.com/apache/logging-log4cxx By quick google I got also an alternative https://github.com/malirod/logger-facade But here is the last commit 2 years ago
You can catch those exceptions in [constructor (wandbox)](https://wandbox.org/permlink/i1VGqrEdFHwCo2k5): struct Foo { Foo() try { } catch(int e) { std::cerr &lt;&lt; "Caught in Foo(): " &lt;&lt; e &lt;&lt; '\n'; } B b = B(42); }; 
In a variable yes. In a member function no.
Thanks! That makes sense. So the constructor try block catches all exceptions that occur while the class is being initialized?
Yeah, however you cannot swallow the exceptions that have occurred. Even if you try the compiler is required to rethrow the exception, otherwise you could end up with object that are partially constructed. 
Thanks for the correction :)
It's alright, apologies aren't necessary (though I appreciate the thought). I think, regardless of how you intended, you make it seem in many cases like you're the only one that has certain problems, or certain understanding, in situations where it's clearly not the case. In other words, you say it's game dev's fault, not C++, but in a super justified kind of way. This isn't really at all what people would call "nice", but really just the standard sort of game dev view that says C++ isn't a good fit for game dev. It's "nicer" insofar as you aren't saying C++ is a bad language in general, I guess is what you mean. So, you are nicer than say Jon Blow or Cassie Muratori, but this is not a very high bar :-). I'll give another concrete example beyond the paragraph I already cited. &gt; It’s hard to overstate how bad this chasm is growing, with some direction being truly infuriating, but let me just bring a concrete example. Take the modernization of STL containers, say r-value references, initializer lists and all the ecosystem around that. Clearly, a huge feature for C++, allowing even significant savings for certain uses of the STL. And what you would call “a zero cost abstraction” - if you don’t use it, you don’t see it. Everyone’s happy, right? &gt; Quite the contrary! The prime example of something that is entirely useless for people who already know about the cost of constructors, temporaries and the like, designed their code thinking of how to layout and transform bits, instead of higher level concepts sketched in a UML diagram. This is, to put it mildly, patronizing, and I really have to scratch my head and wonder how you did not know it would come across this way. You are basically dividing C++ devs into two groups: 1. People that know performance, and understand how rvalues etc are useless/bad. 2. People that don't, and implied to be pseudo Java-devs, who like them. I personally know the cost of constructors, temporaries, and design my code as you describe. So do pretty much all of the devs where I work, an HFT, where we are very performance conscious. And yet, pretty much nobody where I work would agree with your statements regarding rvalue references. Rvalues are at the heart of making something like unique_ptr possible, which is the only owning pointer where you don't need to sacrifice either correctness nor performance. That's amazing! It may not be faster than using an owning raw pointer, but it's basically impossible to use owning raw pointers 100% correctly. Getting something equally performant and far more maintainable saves dev hours. Saved dev hours can go back into the optimization loop. So, I agree with the premise of the article, taken literally. I think the problem is not with game dev use cases, but game dev culture (or, the culture of the minority of game devs who write these kinds of articles, including yours). I work with people equally obsessed with performance, people who very accurately find faults in the language. Yet, we focus on doing our work with it as best we can and contributing back where possible. And we derive a ton of value from that over C, or "Orthodox" C++, or whatever. Both in terms of maintainability, and performance. That a significant minority within game dev are so prone to finding faults instead of value, whining instead of improving, entirely says more about those peoples' attitude and engineering skills than about C++. 
That is actually the reason why they exist in the first place: struct foo { foo(int* i) try: m_ptr{i} { } catch(...) { delete i; } int* m_ptr; }; int main() { auto f = foo{new int{23}}; } It should never be necessary with well written code, but it does work.
It's called unity build. It's being done, but since you always recompile everything, the edit-compile-debug cycle is quite long. Though, I'm aware of a few libraries who do that to simplify compilation. 
I've been using the for ages now and I can only recommend it to everyone: They are easy to understand even for people who have never seen them, keep the good path and the error path very clearly separated and reduce the necessary indentation which directly correlates with the felt complexity of a function.
That's really subjective. Especially when it's passed as a parameter. Also, it's more like `[capture,list,here](args){ }`. Coupled with the fact that the PHP version would likely conflict with a lot of existing code or, even if it's figured out, would be hard for human to parse (is this type object named function or anonymous function declaration?), the C++ version is much more preferable. It's all subjective of course, but the overwhelming majority of languages went with shorter/terse lambda syntax. 
An alternative, if you have control over the format of the JSON sent, is to use the [JSON mapping in protobuf](https://developers.google.com/protocol-buffers/docs/proto3#json). It might not be as flexible as your library but its a mature library and has support for other programming languages (lots of them!). 
This library [has been spammed](https://www.reddit.com/user/idea4good/submitted/) a few times in the past two month, previous discussions [here](https://www.reddit.com/r/cpp/comments/ag44sz/the_smallest_ui_frame_for_all_platformsinclude/) and [here](https://www.reddit.com/r/cpp/comments/alznht/crazy_stm32f103_powered_by_guilite_none_os/). I'll repeat what I've said before: this library draws basic elements to a bitmap, but it is left to the application to create a window, blit the bitmap to it as well as handle inputs and forward them to the library. It is "for all platform" in the sense that most of the platform-specific code has to be written by the user. Now, can start removing submissions for this library? It has nothing to do with C++.
That is interesting! I was not aware of junction, but I'll have a look and see if I can run the benchmark.
I don't know, but if they are, given that C++23 is likely the earliest landing point for that, C++20 still needs to handle it.
I tried that, but got this error: #include &lt;ostream&gt; namespace foo { class A { public: int k; }; std::ostream&amp; ::std::operator &lt;&lt; (std::ostream&amp; ostr, const foo::A&amp; a) { ostr &lt;&lt; a.k; } } foo.cxx:10:70: error: declaration of ‘std::ostream&amp; operator&lt;&lt;(std::ostream&amp;, const foo::A&amp;)’ not in a namespace surrounding ‘std’ std::ostream&amp; ::std::operator &lt;&lt; (std::ostream&amp; ostr, const foo::A&amp; a) { foo.cxx:10:70: error: ‘std::ostream&amp; std::operator&lt;&lt;(std::ostream&amp;, const foo::A&amp;)’ should have been declared inside ‘std’ So there's no way to "opt-out" of an enclosing namespace. So, it would need semantic changes.
&gt; If a function (any function, not just main()) has a return type other than void and the function-try-catch does not have a return statement in the catch block then the behaviour is undefined. Not exactly. It's only UB if the program actually flows out of the catch block without a return, and in the case of `main` even that is not UB.
Your syntax is correct but your code will never actually enter the catch block.
Hmmm... I'd rather say C++ don't support standard library modules yet.
Did you compile with \`/experimental:module\` and \`/std:c++latest\`?
Cool. What is the performance loss of such a block function for code that normally works?
Yes.
Visual Studio doesn't support c++20 modules yet.
Same as the usual performance implications associated with exceptions. If the exception is never thrown, there's little to no loss of performance. Otherwise, it's slow, but if you're actually using exceptions for the exceptional case, that's not really a problem.
The standard library isn't modularized yet. You'll need to wait for at least C++23 and potentially longer, depending on how well modules do in real life. 
One possible use for function try blocks is to build up a stack trace for an exception. Ordinarily one uses a debugger for that, and polluting the code with macro calls to do this feels very unclean. But I imagine that it can worth knowing about this usage, just having that in the toolbox.
Chill out it’s not even 2020
Here is a suggestion how to make it work: https://developercommunity.visualstudio.com/content/problem/286211/c4996-stduncaught-exception-is-deprecated-in-c17-w.html
your is exactly the same minus not declaring the type you want to return with...
I think the point here is that without the direct support in the language, error handling code with expected/outcome will always look inferior to exceptions which do have such support.
Yes, because it's redundant in most of the cases. If you want to declare it, you don't need `decltype`.
Looking forward to that :)
It's important to note that the above code may still terminate with an unhandled exception! For a function-try block wrapping a member initializer list, there is an implicit `throw` at the end of the catch block, which will be executed if the catch block doesn't throw anything itself. See [this example](https://wandbox.org/permlink/E8SRl5rFjg6ZDl88) for instance. That is to say, it's impossible to "swallow" an exception thrown by a member's constructor -- all you can do is translate it to some other exception type instead, and possibly do some cleanup/logging. 
&gt; By the way, using auto makes the error even more subtle. That is one of the reasons I don't like auto for non-generic code, and I am against AAA. If I see string_view foo = ..., at least I can recognize the bad smell if it is not consumed immediately. Thank you. It's the first time I saw a valid argument against `auto`. If `auto` meant *value* (and only value) and `auto&amp;` meant *reference* (and would be required for any reference-like types – pointer, values and views), it would be much better. And obviously it should be `const` unless specified otherwise, but C++ default aren't the right one.
Does ccls work with headers? Everything I've tried so far doesn't work with headers, but with YCM I can just script it to load flags from similarly named .cpp files, or just use manually specified flags.
Have you evaluated using constexpr functionality? Particularly something like Frozen library [https://github.com/serge-sans-paille/frozen](https://github.com/serge-sans-paille/frozen) ?
Agree with you.
GTK is huge, and more powerful, maybe easy to use. GuiLite maybe easy to understand. If you understand it, you master the essence of all GUI library
Hmmm ... Not for arguing, but in which case `constexpr` does not mean that 'whatever' is `const` as well? 
I really do like the expression "felt complexity".
You have some pretty deep misunderstanding how c++ works as a language, community, and governance model; not to mention basics of how most people do software engineering. That's not really surprising in and of itself because I've been hearing it for a long time; the surprising part is how entitled the game devs are suddenly. There's an avenue of participation and if you don't use it you lose the ability to complain about the result.
So working with the developer, we found if I reduced number of threads that ccls uses, then this issue does not occur. I was using ccls on a 72 core machine, and ccls tried to spawn 72 threads and each thread wanted a large amount of memory. Will need to work on finding the best memory/thread tradeoff.
I see it as the difference between a fix (which works 100% of the time) and a partial mitigation (which helps in some cases but doesn't fully some the problem). When I first learned about this idea of deleting the rvalue-ref-qualified overload of a function, I assumed it was supposed to be a fix for the issue of calling a function on a temporary, and it was surprising to me that it's only able to catch a few common instances of this error. 
C++ can't be fixed, best you can do is try to apply patches ;)
Not to steal OP's thunder, but here's Herb Sutter on the topic... http://www.gotw.ca/gotw/066.htm
I wondered why there were flashy ads in the middle of the page but apparently it's only Boost.Beast changelog .__.
It's not just functions, you can also attach use exceptions to most flow control. (I'm not necessarily recommending that you /do/...) For the truly bored and/or perverse: https://godbolt.org/z/aO-QK3 I believe the original purpose, as other readers have pointed out, relates to not leaking certain exceptions out of ctors. There's been discussion from both Scott Meyers and Herb Sutter on this before. Have fun!
What keeps me from considering boost libraries in the modern era is that I don't know what dependencies they will bring in, how much they will increase my binary size and how much they will increase my compile times. The features and updates are all a distant priority. If using a boost library means that everyone now needs all of boost to work with me, it's a huge consideration and often far outweighs looking up a few OS specific functions to make a Windows, Linux, and OSX compatible single file library. Things like file dialogs, directory iteration, memory mapping, shared memory, dynamic libraries and network IO all fall into the same category. The boost solutions end up as huge double edged swords and every time I investigate what it would take to just do the same thing with three different APIs, it ends up being way more elegant to google each OS and work out the quirks.
if your class's ctor/dtor may throw, it may better use explicit open/close methods like fstream dose.
Right, sorry, perhaps I wasn't clear. At the moment, the fully qualified names can be used to *refer* to names outside the current namespace or its children; I think it would be a simple enough change to allow it to be used for definitions, too. I don't think it can change the meaning of any existing code. I'm not in front of my compiler at the moment, but I wonder if functions defined as friends can break out of their namespace? They already break out of the lexically enclosing class.
"import std.core;" should work then.
Outcome is coming out! (Yeah I know that technically it's pretty easy to get right now, even graft it onto an existing boost install, but I couldn't resist the pun.)
It should work with C++11 and up, need to double check that.
I think that boost should rarely be in your interface, but that it does have room as an additional library for an organisation to adopt internally. Back at an old job getting approval for using **any** external library was extremely difficult, so getting something like boost was pretty great, since any internally adopted library was basically already available org-wide, and boost has so many solutions to a bunch of existing problems. Granted, back in that job we were limited to C++03 (+ whatever made it into vs2010) so a bunch of things that are now standard weren't available to us.
&gt; Websocket streams use PCG as the fast random number generator, for increased security. This is weird, and doesn't seem to match the code: it seems streams are ['secure' by default](https://github.com/boostorg/beast/blob/79e6c61db5d8d9ba12ad9d2371d34e4bc5a4b9ff/include/boost/beast/websocket/impl/stream_impl.hpp#L119), and use ChaCha20, and if `secure_prng(bool)` is set to `false`, [it uses PCG](https://github.com/boostorg/beast/blob/master/include/boost/beast/websocket/detail/prng.ipp#L209-L212). So where is the increased security here? I don't get it.
Definitely, for production code stick with protobuf/flatbuffers or something similar. This is just a side project for now!
&gt; If using a boost library means that everyone now needs all of boost to work with me Well (most) stuff is header only, so you just have the parts you need as a git submodule? Not sure what you mean by "everyone now needs all of boost". If it's in the source tree they don't need anything?
Generally, if you right click on the project root in your Project pane and choose "New Class" (or whatever) from the pop-up menu, CLion will add those new source files to your CMakeLists.txt automatically. At least that has been my experience. For things like adding external libraries and stuff, that can be a bit trickier and I haven't found any way other than manual adding to handle it.
Can someone smarter than me explain how the destructors for `bar` are no-ops, and how a double-free situation doesn’t happen with its copies? Surely `memcpy` just copies the numerical value of `bar::x`
Hey I’m the original author and just saw it got posted here. In general yes, a double free is possible but the trick is to use a container that does not free the memory in a way that invokes the destructor of the stuff being moved from (aka a relocation). I’m not sure I explained it super well and may well go back to try and clarify it better when I get a chance.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b0jqf3/clion_and_the_cmakelisttxt/eig02jf/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Ah, yes. That makes sense. I was thinking what would happen if you passed stack-based instances of `bar` to `copies`. Thanks. Great post!
Aha! I actually knew about this one... Did you know about arraying across an index? :) &amp;#x200B; int foo\[10\]; &amp;#x200B; for(int i = 0; i &lt; 10; ++i)
Can you expand on how this relates to the proposed trivially_relocatable attribute?
Two-phase initialization is not for me, thanks.
In a nutshell, the attribute allows you to annotate a class to show that when containers resize, it’s ok to not invoke the destructor on the old region so long as the new region contains a byte-for-byte copy. I’m doing this today in a (possibly controversial) unsafe way by authoring all classes to be trivially relocatable (which isn’t hard) and leveraging this information to optimize my data structures, cleaning up a good deal of code in the process. The new attribute will help the existing STL leverage this optimization as well but will be a bit more verbose, purely for backwards compatibility reasons (and possibly other reasons I don’t grasp).
Hmm... yes, actually I did think about that, but decided to not go that way. In this case, &gt;90% of the mapping is done at runtime (loading an image of an arbitrary pixel format, for example), so no much value in having these `constexpr` — and if people *really* want to avoid the (already very small) cost of mapping, they can use the API-specific values directly. Besides that, looking at Frozen, I'm a bit concerned about [compile times](https://github.com/serge-sans-paille/frozen#troubleshooting) (too bad they don't provide compilation time benchmarks): &gt; `note: constexpr evaluation hit maximum step limit; possible infinite loop?` In other parts of the library I'm [doing extra work to reduce compile times](https://blog.magnum.graphics/backstage/lightweight-stl-compatible-unique-pointer/), so I'm not sure if the minor runtime speedup for &lt;10% cases (which are always off the hot path anyway) would warrant the (potentially very serious) compile time increase.
There's no such explanation. This code either fails to destroy one of the two arrays or double-frees. Destructor isn't a no-op, it's freeing stuff.. This can't possibly work in a general case.
ok,got it,maybe i should try for it
Interesting article. Some criticism: &gt; Verbosity [...] All of these concerns are invalid if you follow the *rule of zero* as much as possible, and the *rule of five* when you need to write a resource-managing class. That is the best practice that I teach my students and that is commonly seen online. --- &gt; `if (this == &amp;f) return *this;` Why? Is this a common occurrence? You should motivate this check. --- &gt; `if (x) delete x;` You can safely `delete` null pointers without checking beforehand.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b0p2g2/help_with_using_tdd_for_making_simple_compiler/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I’m on mobile so apologies for the lack of formatting. Thanks for the comments. To me verbosity is there even with the rule of zero because in the case of relocation, the copy/move constructors and assignment operators for resources are unnecessary altogether, and don’t forget, there is a cost to separating everything out into independently managed objects (bad cache locality, heap allocations, pointer memory overhead). Move assignment must ensure that an object is not moved to itself for exception safe guarantees to be met. Yes that’s true for pointers but not resources in general (file handles, sockets, semaphores, etc)
Assuming you use the correct import (i.e. **import std.core;**), then your code should build cleanly with the following command line: cl /experimental:module /std:c++latest /EHsc /wd5050 /MD test.cpp I've tested this with both VS2017 (version 19.16.27027.1) and the VS2019 preview (version 19.20.27404). But note that you'll have to have installed the "Modules for Standard Library" component. The module support is still quite buggy, and not feature complete, but it does basically work.
That code shouldn’t work in the real world, it was really only meant to underscore differences in the underlying code. A relocation of an object that is unmovable and uncopyable is safe though under easy to fulfill conditions (and remember that the compiler stops you from even trying to move it in the “standard” way).
CMake has several sources of complexity. Some are historical, and therefore hard to handle at times. But some aspects can be made simple. In my experience, the key to simplifying CMake management is to reduce variables. One important technique for tis is 'transitivities of targets', another is subdirectories. Getting their mental model right helped me a lot. For the former, I can find [this article ](https://pspdfkit.com/blog/2018/modern-cmake-tips/) today. For the latter [this](https://code.egym.de/how-to-use-modern-cmake-for-an-app-lib-project-3c2ee6018cde). In addition, I prefer CLion IDE as one good option because its symbol navigation rigidly follows the configuration specified in CMakeLists. It chooses the correct header files even if different versions are found in the include paths. It also respects compiler macro definitions. If I am not sure about CMake, I often let CLion parse it and follow the C++ symbols there. (Probably there are more alternatives nowadays.)
&gt; static_assert(SBS &gt; 1, "Small buffer size must be at least 1"); Hrmm?
*And don't forget to smash that star button!*
Boost officially doesn't offer modular packages. There are some from third parties, but they are limited by internal circular dependencies within Boost. What's interesting is Boost will have to fix that problem to support C++20 modules, because they forbid circular dependencies.
While this is valid c++20 (unlike `import std.whatever` which will not be), we voted this less than a month ago.
&gt; Yes that’s true for pointers but not resources in general (file handles, sockets, semaphores, etc) You call delete on file handles, sockets and semaphores?
Not sure if you’re being facetious or not but checking against a null sentinel would be required before releasing them yes. (The act of deleting a pointer is illustrative of the cost of a typical destructor)
The post you answered was specifically taking about delete and pointers.
I’m on mobile so I can’t test it right now, but what does the first one actually do? 
One more: foo&amp; operator=(foo&amp;&amp; f) { if (this == &amp;f) return *this; auto tmp = x; x = f.x; // Ensure we don't double free f.x = tmp; return *this; } Firstly, the naming convention here makes the example hard to parse for a human. Also, why are you swapping and not using std::swap? You actually don't need to swap, you just need to set the source of the move to null.
Just for illustrative purposes, if I wrote this at home I would just swap as you say. Thats said, not swapping is a leak and a mistake I make from time to time. If the destination contains valid resources, they will not be freed post move
Any chances of getting Clang-like \`-Weverything\` in GCC? &amp;#x200B; Yeah I know that \*some\* of them doesn't make sense etc. etc. but selectively disabling 50 or so warnings is so much easier than looking for useful (but not enabled in -Wall for whatever reason) options in the haystack of GCC docs.
It does the same thing as foo\[i\].
&gt; I don't think it can change the meaning of any existing code. Probably not, but you'd still need to nail down all kinds of details. Would you require starting from the global namespace again? Is there a way to say "in my parent namespace"? Grandparent? What if you ask for the parent of the global namespace? How does `using namespace` affect this? What namespaces are in-scope in the definition? In the argument list? Template arguments?
Its not a big deal for modularization: The cirular dependencies are between repositories, not files. You can e.g. easily split boost serialization support into a separate module for each lib and get rid of most of the circular cycles.
`*(i + foo)` instead of `*(foo + i)`.
As far as I know, the answer is "no". GCC developers are opposed to `-Weverything`.
Well simpler than that, you could just clone boost as a submodule and include the headers you want. Easy-peasy
Looks like: { alloy::vector&lt;int&gt; vec; vec.reserve(1); } will leak memory, because `reserve()` doesn't check for the new capacity being smaller than the old. `resize()` doesn't destruct elements when the size shrinks either. `rbegin()` does not return a reverse iterator. This is very far from being a drop-in replacement for `std::vector`.
It makes a lot more sense thinking of it like that
 if (x) delete x; really ;) Also regarding the move assign code itself: What it should actually look like is this: foo&amp; operator=(foo&amp;&amp; f) { delete(x); x = f.x; return *this; } IIRC there is an explicit part in the standard saying, that the standard library may generally assume that an R-value reference is not aliased (so this can never be the same as &amp;f 
In this example there's nothing to catch. The `new int` is evaluated before the try block is entered; and `m_ptr{i}` cannot throw. 
oh yeah a 100mb clone for a few headers
There's scripts out there that will figure out what set of flags are equivalent to -Weverything for you. I find it to be too much. Honestly I get most of the warnings I want with just -Wall -Wextra -Wpedantic