&gt; The Google style guidelines basically bans value types. Say, what?! I'm not seeing this at all, can you be specific? &gt; It makes sense why Google bans exceptions, but you don't have to because you don't have Google's problems. Er, right, that's exactly what I was saying, and Google too - there's no need to ban exceptions - the reason they give is _admittedly_ specific only to their code base. 
Does the templated draw method get SFINAEd so that the user supplied draw function gets resolved? Usually in SFINAE examples both functions are templated.
Feel free to post an answer if you think it's correct. There's a lot of discussion on this question but nothing useful seems to come out of it.
The video I referred to linked in the article: http://www.youtube.com/watch?v=_BpMYeUFXv8&amp;feature=youtu.be It's a ~50:43 that he shows the technique of having a base class, *concept_t*, and then defining a templated function, *model*, which calls the user-supplied *draw* function for whatever type the model holds.
are unsigned integer really guarenteed to wrap around? further more you could just use the constexpr numeric_limits function std::numeric_limits&lt;T&gt;::max(); Also is `max_size` guarenteed to be the integer can hold? can it not have some other "arbietary" max?
So relevant username.
Wild!
I think someone has yet to execute non-Microsoft-signed code on an Xbox 360, right? I hear rumors that the next generation of consoles will use x86/x64 chips, which will make PC emulation a lot easier...
I suggest [Programming: Principles and Practice Using C++](http://www.amazon.com/Programming-Principles-Practice-Using-C/dp/0321543726/ref=sr_1_19?ie=UTF8&amp;qid=1351723527&amp;sr=8-19&amp;keywords=c%2B%2B), its an intro book written by the creator of C++, I've read it cover to cover and it's the best intro book I've seen. 
how did microsoft do it then ?
Accelerated C++ seems to be the most recommended book here. There's a [nice list](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) of books on SO if you want a complete overview.
Definitively go C++ Primer 5th Edition, It covers C++11, and its from the author of Accelerated C++. 
No, quantum computers will not allow this. Eventually, the computer must know what it's supposed to do. A quantum computer isn't magic. The algorithm isn't the thing that's fuzzy, the results are.
Ah, it seems that my information is old. http://www.instructables.com/id/How-to-JTAG-your-Xbox-360-and-run-homebrew/ Anyway it held off for a long time. It basically has to be some special hardware in the CPU that is supposed to make sure the program you're about to execute is signed with a private key Microsoft owns, the public key being encoded in the chip itself. That's the general gist of stuff like this. 
&gt; Well obscurity is not security. That applies to communication through an insecure channel, not necessarily to protecting software. In cryptographic terms, your software contains the secret and the key. For a cryptographer, this means: game over. So we step back, and see what we can do: increase the cost of tampering. For that, obscurity is great. (Usually not as good as one things at first look, but still one of the better weapons.) ---- To make it "strongly secure", you need to secure everything: the hardware it runs on, the hardware and software it interacts with, [your compiler](http://scienceblogs.com/goodmath/2007/04/15/strange-loops-dennis-ritchie-a/), the hardware your developers work on etc. The best you can do now (to my knowledge) is offloading a nontrivial, essential calculation to a secure system (say a really good hardware token, or a remote server). None of these solutions are permanent. Your second best bet is blocking generic solutions: e.g. a generic crack for your super hardware token that everyone uses because it's so good. 
This book is phenomenal!
&gt;load it up and mutate it before you replace it Not if you cannot mark memory pages as executable, e.g. on iOS. But I agree: Developers should spend their time on making their software better for the paying user. That's what their business is after all, not creating a puzzle for crackers to solve.
Both of which are unrepresentable in any finite precision.
You're right. And luckily the code will not compile for std::complex&lt;double&gt; (because there is no operator*(int, complex&lt;double&gt;)), where a = { 0.0, 0.0 }, b = { 0.0, 1.0 } will return false. So I guess the code is in the clear.
As long as it is compile time reflection, it doesn't seem *that* bad.
I've actually done some research and have looked online and have seen the list of books on Stack Overflow(as I mentioned in my post). I'm not incompetent when it comes to internet usage. From searching online, it seemed that both of those books would be good for me but I thought maybe one would be better suited for me based on my prior experience in programming so I thought to ask reddit instead of just picking one and possibly being unsatisfied with my choice.
I second the hate for video-only talks / articles. Bjarne talking about something? Awesome. Talking about it for more than one hour? Really? Nope, won't watch that. Hope that there will be a transcript of Sutter's talk tomorrow.
I recently started learning C++ using *C++ Primer*, a highly recommended book that has recently been updated to include C++11. Think of it as a more intensive *Accelerated C++*. If you decide to use this resource, [check out my blog](http://primertime.blogspot.ca) and contribute!
&gt; binary literals 0b10010001000001000 This seems like the sort of thing which should have been included in C++ from day one.
GCC does have them (since 4.3), and I believe I have seen implemented them (might not be this exact syntax though) using user-defined literals.
If it's compile time "reflection" I have no qawms with it, as that is simply an extension to the existing triats system already in place. What I really don't want is RTTI on steriods. The abillity to reclain type infomation, at a runtime cost. Almost every use or RTTI is because of poor/lazy code design. &gt; Integrating with a script interface is very cumbersome without it C++ is not a scripting language. . .
All I can say is you are using the wrong language. What you are describing is EXACTLY why games programmers use LUA, it is perfect or the use case. C++ is big enough and meets enough use cases, the last thing I want the language to add is: &gt; I can also read method names from the file and fire them at runtime and &gt; "EnemySquid" squid = new "EnemySquid" It's not a problem that I don't have to pay for them if Idon't use them, but it is a problem that you are giving people (co-workers, library writers...) tools to write inferior code -- this is already the case with RTTI, where if I link to a library that uses it, I have to pay for it.
That's exactly the point :) Anyway I understand that writing down the topics you usually present can be like writing a book. Also, probably publishing a video is much better than publishing nothing at all. I really like your posts in the vcblog, I'm subscribed to it from some years now and I'm always following it. The STL11 : Magic &amp;&amp; Secrets slides are interesting! I ended up downloading the slides :) BTW, I hope you didn't take it as a post against your videos, it's just the first link I found when looking for an example!
Why not both? But if in doubt I'd take compile-time reflection first. 
You don't need runtime reflection for most interesting cases; compile-time reflection is the really useful thing that C++ developers need for many things, integrating with scripting languages, serialisation, databases, ...
Wherever I integrate C++ with a scripting language compile-time reflection would solve all my problems. (Of course C++ is not a scripting language, that's why it sometimes makes sense to extend it with one.) 
OK, then we are on the same page. Compile-time reflection is missing and would be very useful, however rtti from a void* would indeed mean "horrible" things behind the scene that don't fit to the language. 
Oh, we agree then. I wasn't sure before what you meant by "compile time reflection".
Parallel algorithms [already exist](http://gcc.gnu.org/onlinedocs/libstdc++/manual/parallel_mode.html), albeit not at the 'part of the standard' level and you have to be using gcc. 
Unrelated to what was happening at the standards meeting, but given that this comes from Axel Naumann and with his emphesis I am not sure how to feel about. The ROOT people always had a heavy tendency to write code in their very particular style (e.g. hardly any template use) and suffer from severe NIH syndrome (and their own container or e.g. string classes interface poorly with modern C++). They usually claim all of this is because ROOT being older than standard C++ or so. For me it looks more like Stockholm syndrome 10 years after TR1 came out. Anyway, I am really looking forward to their new interpreter and ROOT dictionary interface which will allow me to write modern C++ at least in my code. I just hope after they are done with that fantastic work they turn their own code upside down and eliminate the duplication and overly verbose code which has accumulated in the last 20 years.
Improving C++ is like flogging a dead horse.
You beat me to submitting my own link - I was going to put "variadic templates in VC" in the title. :-&gt; Quick summary for people who haven't clicked on the link yet - the big news is that **six** C++11 features have been implemented in a VC compiler alpha, downloadable now: * Variadic templates * Raw string literals * Explicit conversion operators * Default template arguments for function templates * Delegating constructors * Uniform initialization In this video, I walked through all of them, with somewhat realistic examples (I mentioned variadic templates first but saved that example for last).
What? Clang on Mac OS X has full support for initializer lists with libc++.
clang and gcc still seems to be ahead
After having had just a quick glance through their course syllabus I believe they teach C++ in the old-old way, i.e. they do not teach modern C++ (starting with C++11) and they do not teach top down (as Accelerated C++ do). Thus I can not recommend this course, and I cannot recommend Accelerated C++ as that book does not use C++11 (it used to be the best introductory book). For now, C++ Primer (5th ed) by Lippman, thoroughly revised by one of the authors of Accelerated C++ (Barbara Moo), is the book I can recommend.
**TL;DW:** Nov 2012: CTP of compiler update - explicit conversion operators - raw string literals - function template default arguments - delegating constructors (finally!) - uniform initialization - variadic templates (woohoo!) [Download here](http://www.microsoft.com/en-us/download/details.aspx?id=35515) Note: The CTP is an update to the "core" compiler only, Intellisense and std library are not updated yet. ---- [editx2] and the future: Independent study groups have been formed to research: - Concurrency, - Modules, - Filesystem (final version scheduled for 2013, based on boost file system) - Networking (first version scheduled for 2013, final for 2015) - Transactional Memory (planned for 2014) - Numerics, - Reflection, - Concepts, - Ranges, - Feature Tests, - Databases. Next *major* standard with new features will be C++17 (base 10, I assume). (Note that Herb, wearing his Microsoft hat, emphasized to expect "out of band" updates to the compiler) Next "minor" standard C++14 with "whaterer is ready", on the table (*tentatively*) are currently - generic lambda's, - return type deduction, - local runtime-sized variables, - static if ("concepts lite") - std:: literals - reader-writer-locks - thread safety for streams - concurrent queue + hashtable - File System - Networking --- [isocpp.org](http://isocpp.org) as go-to site for C++ standard news ("CNN + NY Times for C++") 
I for one welcome the return.
I didn't get the memo about C++ becoming non-mainstream ever. Maybe in the MS world, but that's just a fraction of computing, really.
Depends on the university though. My undergraduate CS &amp; games tech. was C followed by a looooot of C++.
Was talking about really-really-entry-level. As in, high-school level, where a lot of intro to programming seems to be moving. It's mandated by the AP Curriculum, and even though the material covered in that is pretty bad, it still forces people to start at higher level languages, without grasping any lower level concepts. I'm pretty sure AP's in the US only, though I haven't bothered looking much into that. 
I can send you one of mine if you like. But seriously, the rise of the web, and the increase in processing power have diminished C++' role for *end user* ("top level") applications. On the other end, it hasn't quite caught up in the embedded market. In the meantime, all the other languages got the fun features. Parallelism support (another shift in technology) - while implementable on the library level is at odds with the C++ memory model. Lamdas went mainstream and do require compiler support. Then, the rise of the IDE: static code analysis for navigation, intellisense / library discovery and correctness has gained big momentum. C++, being hard(er) to parse, strongly context dependent and with a broken build model*, has been lagging behind languages that were designed with IDE support in mind. So yeah, I didn't need a memo to plot a possible future without much C++. --- CLANG has "technically solved" the parser problem, mobile has somewhat countered the effects Moore's law making efficiency matter, and the lack of revolutionary progress in GC and JIT has shown some limits of managed languages (not only in the "Microsoft world"). Plus, the standard commitee didn't fail on the C++0x monster project, *and* they realized they need to be more responsive, 10+ years for a standard update isn't acceptable anymore. ---- *) artists rendition
&gt; It stopped getting taught as an entry level programming language That's not true in many locations. My alma mater, as many, consider things like memory management to be something that is fundamental to becoming a programmer. My alma mater also required assembly (on real computers, multiple OSes) by the end of Sophomore year.
It is about time. I suspect MS realized that pushing their crap down the throat of professionals wasn't going over well. It just bad mojo to align yourself with proprietary technology. 
I couldn't agree more this. I recently started guarding all preconditions to functions with asserts (and singalling failed postconditions with exceptions) and it has made debugging a hell of a lot easier.
Sorry, I misremembered the exact details. Here is the bug report: http://www.llvm.org/bugs/show_bug.cgi?id=11851 First reported over 10 months ago. Still no fix in the master branch of the git repo (just rebuilt it). There are workaround patches in bugzilla but they cause regressions. Neither gcc nor icc have issues with constexpr.
Note: Constexpr functions don't *need* to be evaluated at compile-time, but they *can*. :)
From wikipedia http://en.wikipedia.org/wiki/C%2B%2B11 : Make C++ easy to teach and to learn without removing any utility needed by expert programmers. Attention to beginners is considered important, because they will always compose the majority of computer programmers, and because many beginners would not intend to extend their knowledge of C++, limiting themselves to operate in the aspects of the language in which they are specialized.[1] Not really going to bother finding a source, but I can assure you that C++ is definitely not considered beginner friendly (or at least, its beautiful parts often require a deeper understanding of what you're doing). Java is definitely a much more forgiving language. We should also consider that a lot of people who take these entry courses may or may not actually care about low-level stuff, nor have the level of understanding which the majority of people reading this subreddit would. If I were learning a programming language only to go to web development, or if I was learning a programming language just to fit a school's requirement, I probably wouldn't even understand the concept of a pointer. The aspects of other languages also makes it easier to go between windows/Mac/Linux easier, which is pretty important in a school environment, where you really don't want to fiddle with "I can't run your code" issues. That becomes especially important when we want to do things like graphics, networking, threading, IO without Standard Library, etc. More things come out of the box with languages like Java; you install Netbeans or Eclipse of a given version, and you pretty much have the same thing for everyone.
Now "static if" is a pretty big thing. It could lead to much better template code if it has enough type information available at compile time (compile time polymorphism would no longer be done as blind fire).
Is it useful anywhere?
no runtime performance comparison makes the article bit disappointing. 
Sorry, but a meaningful comparison is so dependent on cache effects (i-cache and d-cache), the size passed, and the number of bytes actually compared, that detailed measurements are unlikely to be meaningful. In particular, the performance impact of code bloat (more i-cache misses sometimes) is highly variable, but all else being equal, larger code is worse. I did previously verify that comparing byte-by-byte is about four times slower than comparing DWORD-by-DWORD.
The same way PHP is used to make a website. When the web server receives a request, it can redirect the HTTP request to some plugin - in this case a plugin which can interpret C++ code and generate a piece of HTML. Either that, or a CGI binary. There's Web Toolkit (Wt), which is very similar in design to Qt: http://www.webtoolkit.eu/wt. If you're interested.
It doesn't matter what is the language. What you do not understand is other methods of building websites. Try to build the website just with print from php and you will understand how you can do the same in any language. This is just another way to return text when it is requested. These days embeding language code into the html is not a good practice any more. Now it is supposed to use html templates and clearly separate your logic from the text that you build. Another example of templates and c++ for web development is [CppCms](http://www.cppcms.com)
You can use a framework that exports a interface to your program receive web requests and respond with the HTML. A few examples: http://cppcms.com/wikipp/en/page/main http://code.google.com/p/tufao/ http://pocoproject.org/
It depends on how well you're taught, and how you apply what you're taught. I do also believe that higher level languages are better suited for teaching the majority of concepts, though. C++'s standard library + STL sort of fell behind in that regard. Languages like Java tend to offer better error messages, too, as opposed to STL's occasional hundreds of error messages for a single mistake, or Visual Studio's error messages for if you forget an include. Moving from syntax to actual application is what makes those high level languages so appealing to instructors. Being self taught, C++, C, and a dip into assembly were the sorts of things which made me appreciate what computers, high level languages, OSes, etc do. Understanding how lower level stuff works can make coding at a higher level much more intuitive (ie: what is a file handle, what is endianness).
haha, ok. That makes sense, I have a temp code directory on my system, and it's got so full of test cases that more often then not a file already exists with the short name I have chosen.
I sort of hope people were using algorithms and containers rather than raw memory and memcpy, memset, memcmp :/
I never mentioned anything about "runtime" checked reinterpret cast.
I was kinda hoping that people use the right tool for the right job, insead of preferring the fancy stuff for being fancy. memcmp is perfectly ok if you have to compare memory (Which is a rather uncommon occurence for me)
well, std::equals provide the same semantics as memcmp but has a uniform interface. Secondly, there really isn't much causes these days to be working with "unmanaged" buffers of data, the only time I can thing of is when dealing with a C library
I do hear you, it just the number of uses cases where this is actually relevant is so few that it's not really writing a post about. If this was a post about optimisation of memcmp for a platform where C was taken seriously then I would be strongly in favour of it.
I checked the code base I'm working on (&gt;~1.4MLoc), most of the memcmp's are in zlib, pnglib and sqlite; for the rest - a few dozen still - about 50% are in tests. I'm fine with that :) 
Exactly C libraries. It sounds like your working with a half decent code base? (unless that functionality is peformed with manual loops :P).
Judging from his blog, the author seems to have an almost pathological aversion towards C++ because he, as many game (and C) developers, apparently knows only cargo cult OOP (lots of interfaces and factories and meta-factories, proxies, facades etc) and cargo cult C++ (virtual methods and inheritance everywhere, unintuitive operator overloading et.al). It's one of the reason I stopped reading his blog: Too much ranting against what he perceives to the the flaws of C++, too little content. Which is a shame, because I found his [series on data-driven vector fields](http://bitsquid.blogspot.com/2012/09/a-data-oriented-data-driven-system-for.html) really interesting. &gt;Because we don't have move constructors now? Even if we don't (I'm not sure of compilers used for console programming already support C++11): A good STL implementation will use memmove for POD objects anyway.
I think I understand what alignof/alignas do, but as primarily a Java developer could someone either explain (or point me to a good explanation) why I might want (or need?) this? Is working with alignment typically needed in an average C++ application?
&gt; It's one of the reason I stopped reading his blog: Too much ranting against what he perceives to the the flaws of C++, too little content. Same, what appears to be be flaws in C++ are actually gaps in his knowledge. RAII makes things easier. A more valid critism is that C++ is a huge language and hard to learn.
One common area where alignment makes a big difference is using [vector instructions](http://en.wikipedia.org/wiki/SIMD) that operate on many elements at once, such as in the SSE instruction sets.
You'll mostly have to deal with alignment when working with [SIMD](http://en.wikipedia.org/wiki/SIMD) instructions / when writing allocators / other areas where high performance is needed. While this probably isn't needed in an "average c++ application" it's good to have standardized for library developers.
For a brief motivation, see "Remarks" here: http://msdn.microsoft.com/en-us/library/83ythb65.aspx (non-standard MS extension, but roughly corresponds to the standard features discussed here). For more: http://www.devx.com/print/cplus/10MinuteSolution/38542 http://www.ibm.com/developerworks/library/pa-dalign/ I wouldn't presume to know what's "an average C++ application", C++ is a *very* versatile language :-)
Since *std::vector* has a "non-trivial" destructor, the standard forbids a function taking one to be *constexpr*. Besides, operations on sequences require loops, which also cannot be in a *constexpr*. I have experimented with changing loops to recursive folds, but the assebly produced is no where near as efficient for the general case. You can trick the compiler by templating the function. It's like saying "there may be some type, X, for which vector&lt;X&gt; is a constexpr", but I don't know whether this is a good practice or not.
And even if you aren't yourself using inline assembler and/or the intrinsics, it can still be helpful to tell the compiler to align something so that its auto-vectorizer has a much easier time vectorizing your code without having to worry about the alignment edge cases. 
Yay, now even IO is incomprehensible, complicated, and … What a breakthrough. Sarcasm aside: Interesting way to demonstrate the flexibility and multiparadigmatic possibilities of C++, and nice work. But please don't ever use this in production code. :)
Bring on the awesome abuses of Boost.Context!
Agreed. :)
It's awesome but has issues running on Windows.
I thought it wasn't fully ready for prime time in 1.51
Please post some code. What are you trying to do?
Again, usefulness of the code is not the point. It's about the concepts behind the code, and the foundation behind this particular programming model.
Hmmm.. I guess someone has to start using it or it will never get the issues flushed out. :-(
Where might I find information about the working group assigned to the Networking features? 
Randomly skimming the changelog... "~thread(): Version 3: If the thread is joinable calls to std::terminate. Destroys *this." http://www.boost.org/doc/libs/1_52_0/doc/html/thread/thread_management.html#thread.thread_management.thread.destructor WTF!... my code using implicitly detached threads was sitting on a land mine waiting to go off with the next version, boost 1.53... Did I miss some gigantic stop signs anywhere to warn about the fundamental change in the thread destructor?
The most interesting thing I got from this was that [GCC developers found that inlining `memcmp` was almost never faster than calling glibc, even for sizes of 4](http://gcc.gnu.org/bugzilla/show_bug.cgi?id=43052#c11). That is quite surprising. The explanation is probably that branch predictors in modern CPUs are extremely good at their job, and depending on context, a function like `memcmp` is quite likely to be in i-cache for any code that depends on its performance. Interesting read all in all.
You might try r/cpp_questions, not sure what kind of content/participation they have over there.
I've read the article many times, but I can't get see what the fuss is aboutThe article shows function composition, that's nice and all, but what do monads have to do with anything in this case? In other words, if we created the same example using functional composition, without referring to monads, then what would the difference be with this? 
 typedef std::pair&lt;int, int&gt; point; typedef std::pair&lt;point, point&gt; move; typedef std::list&lt;move&gt; path; path find_a_path(const point &amp; from, const point &amp; to) { path ret_val; // apply lee algorithm return ret_val; }
What is your current level of programming knowledge?
I totally agree that this shouldn't affect how we write code. I just enjoy finding and reporting on bad code-gen, and trying to get Microsoft to fix it.
well, this program would exit the second it was done running. so if you have no way to see the window that pops up fast enough to read it, you wont see anything at all. try running your program from the command line, or if you're working in visual studio, put a break point on the return statement and look at the window.
You are correct. In fact, no class or type, in C++ *or* Haskell, really *needs* to define things in terms of monads because they could just implement more explicite functions--and it's good when that happens. Type classes (of which a monad is) are to Haskell what virtual base classes are to C++. They allow the implicite use of code. Though, instead of being interface-oriented, some monads can be composition-oriented, some data-oriented, process-oriented, and on and on. In terms of the importance of monads, they're just a mathematical generalization of operations that happen in programming an awful lot. It turns out that this abstractions is fairly complete in that whole programs can be written in it. When we build algorithms around these generalizations, and then build objects with monad instantiations, these objects work automatically with these algorithms, which achieves a greater level of genericy than virtual inheritence. See the [wiki article](http://en.wikipedia.org/wiki/Monad_%28category_theory%29) for more on the mathematical concept. As I said in the article, monadic IO isn't really something you benefit from in C++, but I wanted to at least be able to prove it's possible. It's a necesity in Haskell since it forbids state, but we C++ programmers are the lucky ones since we can use this or vanila IO, or anything else. 
I was typing up a big long reply and then scrolled below and saw you had written almost exactly what I had was about to post. Basically the gist of the difference is, imo, C# is faster to iterate and easier to learn. It also manages a lot of things for you such as memory. The cost of this is that you end up with things like cache misses and you cannot control the low level and set up memory pools, etc. Also, I don't think you can do things like floating point select to avoid branch misses in C#. If you have more horsepower than your require, C# is fine for the job. If you need to squeeze out all the performance you possibly can, you need to use a lower level language.
I almost entirely agree with your comment here. However, two things: &gt; A memory allocation is a slow operation, even in C++, even without the need for a garbage collector etc. Depending on the application, such allocations can easily become the performance bottleneck of an application. Memory allocation is *extremely* cheap in C#; basically `heapEnd += allocationSize`. It's the GC that's relatively expensive, and particularly for small objects, [the GC will actually outperform alloc() and free()](http://stackoverflow.com/questions/755878/any-hard-data-on-gc-vs-explicit-memory-management-performance) (small objects are a bigger win for GC because they have to be tracked by your `malloc()` implementation, but can be ignored completely by a mark&amp;sweep GC). On the other hand, the GC has a memory cost that's always present (as-yet uncollected garbage). &gt; Also, putting them in a vector (as opposed to putting C# references to class objects in a C# list) means you have no "jumping around" in memory which help a lot if your working set is big enough so that it doesn't fit in your L1 cache. That's possible in both C# and C++; a List&lt;&gt; of structs should work (though honestly value semantics may make that still slow, so you might have to get into using "unsafe" and pointers to get full performance; I'm not sure). There'd still be "jumping around" on some GCs, but the cost of filling the L1 cache once per GC is tiny.
That coupon code has expired so the course is now $99. But I can recommend Jeremy Siek's "C++, Short and Sweet": http://www.udemy.com/cpp-short-and-sweet/ This course is based on Accelerated C++, which is pretty universally acknowledge as the best "intro to C++" book. At $29 for five and a half hours this is a no brainer for anyone looking to get a solid introduction to classic C++.. 
must go to a *great* school
I think it's worth mentioning one other point though: in the Rico vs. Raymond series, it seems fairly apparent that Raymond did a couple of rounds that were basically intended to string things out. I, at least, find it difficult to imagine that Raymond (or any other halfway competent programmer) would even consider, much less actually implement, most of the intermediate steps he took in that series (at least when/if he cared about optimizing the code, rather than supporting a good series and the company party line). No, optimization isn't free -- but it's not nearly as difficult or expensive as that series makes it seem either.
Have a look at http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3491.htm for the study group's Portland meeting minutes.
Where is the C support? Also the C++ support is pretty lame. It's more of a mockup than anything else.
Alright, I'm intrigued. Any examples of using these libs with C++? Or do I have to download the while thing for samples once I am not on mobile?
I think this is more linq for c++ than Rx for C++. the Linq c++ has what looks like an real implementation. The Rx for c++ is actually a header file in a sample with a bunch of TODO's in the code.
&gt; But there are errors in the code that make this function useless: the private data will remain there. That is disingenuous at best. Incorrect *usage* of the `OPENSSL_cleanse` function is useless (the author only finds 2 places), but that can be said for a lot of functions. --- *EDIT/ADDENDUM*: I'm not sure what version of the OpenSSL software he's looking at, but the usage of `OPENSSL_free` is correct in `ec_pre_comp_clear_free` as of 1.0.1: static void ec_pre_comp_clear_free(void *pre_) { int i; EC_PRE_COMP *pre = pre_; if (!pre) return; i = CRYPTO_add(&amp;pre-&gt;references, -1, CRYPTO_LOCK_EC_PRE_COMP); if (i &gt; 0) return; if (pre-&gt;points) { EC_POINT **p; for (p = pre-&gt;points; *p != NULL; p++) { EC_POINT_clear_free(*p); OPENSSL_cleanse(p, sizeof *p); } OPENSSL_free(pre-&gt;points); } OPENSSL_cleanse(pre, sizeof *pre); OPENSSL_free(pre); } 
In our codebase, there are also memcmp, memcopy, memmove versions templated on size. That way when the size is known ahead of time, the compiler has no excuses for picking the wrong way to copy some small buffer. Expecting too much from a [sufficiently smart compiler](http://prog21.dadgum.com/40.html) can lead to surprising, though not always unpleasant, results.
Filling a buffer with random numbers where the compiler can know the buffer will never be used again is still the same as calling Memset...
The sorting thing is interesting, but the C++ is average: you should replace your dynamic allocations of your temporary vectors/arrays by stack allocations and C arrays by *std::array*. Since you are using C++11, you should never write "delete" again. You could also use foreach loops in a few places like: for (auto&amp; i: C) { i = 0 };
Would be interesting to see which implementation of quick sort was used. std::sort()? Also, I took the liberty of calculating the time increase (factor) between 5m and 1m elements. I figured that those numbers have the least amount of setup (allocation) overhead in them per element. So a factor of 5.0 would be linear increase. Lower numbers are better. | Algorithm | m = 10n | m ~= n | m = n / 2 | m = n / 10 | |:-----------------------|-----------:|-----------:|-----------:|-----------:| | quick sort |5.4|5.5|5.5|5.2 | counting_sort |5.6|8.5|11.0|10.4| | in_place_counting_sort |5.0|8.3|10.7|6.2 | binsort |5.8|6.1|6.7|8.8 | radix_sort |5.7|5.6|5.7|5.5 You can see that quick sort does pretty well (ignoring the constant factor, which is discarded in the big-O-notation anyway). I think the reason is that quicksort makes pretty good use of the CPU cache(s) and does almost no "random" memory access.
is `std::sort` measured?
Fixed. Also... Your interpretation is not quite accurate. clang was actually strictly conforming in this case due to the exact wording of the c++11 standard. However this wording isn't as useful as what g++ does. clang now behaves like g++, but the issue has yet to be resolved by the committee. Note that constexpr is now considered 100% implemented in clang. 
std::sort is not pure quick-sort though. It is usually intro-sort (on g++ and VS), which is a quick-sort/heap-sort/insertion-sort hybrid. But I agree that it should be measured against those algorithms instead of pure quick-sort which can degrade rather easily!
Not C++.
...And these should really operate on iterator ranges, and full container overlaod is fine too, but the iterator version should exist.
*qualms
Did I miss the content or is this just a workshop announcement?
That can't happen because `OPENSSL_cleanse` is in a different object file and will not be optimized across object boundaries (until LTO, but I'll get back to that). What if `OPENSSL_cleanse` alters the global program state based on the buffer contents? The compiler doesn't know that it doesn't. Besides, in real life that C function isn't used. The real `OPENSSL_cleanse` implementation for x86 lives in `crypto/x86_64cpuid.pl`, is written in assembly and treated as a volatile function (aka: tell the compiler that it can't optimize calls to it away). So even with LTO, it will work just fine.
I was thinking the same thing. Goes against everything I know.
I've updated the article to use plain C++ as asked by several person. I haven't used std::array because the arrays in the algorithms are too big to be kept on the stack but I used std::vector instead of plain-old dynamic arrays. The only reason I haven't done that before was to concentrate on the algorithm performance. This has not been a good decision...
Yes, I updated the article. it is indeed not a real quick sort, but introsort. 
There's [a proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3394.html) for a [[deprecated]] attribute in the next C++ standard. Check out http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/ for other proposals.
It's an article by Koenig about assert statements. Close enough I think.
I think it's just a workshop/course announcement. BoostPro earns money doing these things.
I hope they also add something like GCC's pure/const function attributes. They can be used to tell the compiler that a function only reads its arguments (for pure also globals) and has no side effects. Thus the compiler can call the functions fewer times than specified in the program. 
I agree with your more global point, but took issue with the way you implied that `OPENSSL_cleanse` was useless because it could possibly be used incorrectly. You probably didn't mean it like that. What version of the OpenSSL software are you running your tool against? My `ssl3_get_cert_verify` has the correct `if ((peer != NULL) &amp;&amp; (type &amp; EVP_PKT_SIGN))`.
Whole ES operating system is written in C++ while TCP/IP stack is particularly interesting.
Well obviously a lot of thought put into this article but I'm sort of scratching my head here wondering what the justification for all this additional work is. I'll admit ignorance on this, but I don't see what benefit one gets from this. Is it simply that one can now make copies of an object? Is there an actual use case where this approach provides measurable benefits? Perhaps if I had a motivating example it would make sense, because frankly right now I see a lot of code and maintenance being introduced to recreate a kind of polymorphism that is already present in C++ and fairly simple to use.
Typically, polymorphism in the OOP sense requires the types to be related. This article shows code that is just as powerful as OO-polymorphism, but works on unrelated types, making it more.
*model_t* holds some type, *T*. *model_t*, not *T*, inherits from *object_concept_t* and defines *print* as *T::print*. It then uses *object_t*, containing a pointer to a *model_t* as a part of the pointer-to-implementation pattern. So, for any unrelated type you define *print* for, you can store it in a *model_t*. It took me a while, when I first saw the youtube video, to wrap my head around this. Just keep staring at it.
There was a fairly interesting article I read recently advocating rewriting Unix programs like *less*, *echo*, etc.. There's always Project Euler. Plenty of understaffed open source projects. Libraries that have yet to be written. Games. This is a really broad ToD.
Contribute to ReactOS.
I have been using boost.context for over a year in code that runs in production and handles tens of thousands of requests a second.
It's just like std::tuple, except I think that's a right-recursive, not left-recursive type. You know, *terrifying* is how I feel looking at it, too. This is an unexpectedly powerful abstraction.
OK, I couldn't think of how exactly to describe this last night, but I think this is correct: This code demonstrates how the mathematical property of associativity can be generalizable on types.
Cool! So is the specialization happening through inheritance in a way? Eventually it should call the base class operator() 
If you enjoyed that, I highly recommend Alexandrescu's *Modern C++ Design*, one of the most mind-bending programming books ever written http://en.wikipedia.org/wiki/Modern_C%2B%2B_Design
Think of something that you wish you could do on your computer. Some application or tool that would make life easier. And do it.
Ill also briefly comment on how the proposed solution doesnt make any sense by being convoluted and using features for the sake of doing so while obfuscating the process of function calculation. His first solution is much clearer and doesnt require much to arrive at clean nice code that lazily does stuff. Something like that would probably result in this simple case: #include &lt;iostream&gt; #include &lt;vector&gt; class fibs { public: fibs() { values_.push_back(0); values_.push_back(1); } int operator()(int x) const { for(int i = values_.size() - 1; i &lt; x; ++i) values_.push_back(values_[i] + values_[i - 1]); return values_[x]; } private: mutable std::vector&lt;int&gt; values_; }; int main() { fibs f; for(int i=0; i&lt;10; ++i) std::cout &lt;&lt; f(i) &lt;&lt; ", "; } The point being, use new features where it makes sense. 
Very cool! It looks like you search for the key twice, once with memos.count(i), and once (if true) with memos.at(i). Could this be optimized to only find the correct key once? Also, would an unordered_map make more sense? I believe map requires operator&lt; be implemented for key types, but unordered containers do not (not sure if they require a custom hash method or not for non-built in types).
 template&lt;class I, class O&gt; function&lt;O(I)&gt; memoize(function&lt;O(I)&gt; f) { map&lt;I, O&gt; memos; return [=](I i) mutable -&gt; O { auto it(memos.lower_bound(i)); if (it == memos.end() || it-&gt;first != i) it = memos.insert(it, make_pair(i, f(i))); return it-&gt;second; }; }; An unordered map would be faster but would require a custom hash function for non-standard types. For most types these are pretty easy to write. Edit: Depending on how well your compiler does return value optimisation, it may be better to return a const O&amp; instead of a plain O. 
I have attempted that as well, and I can definitely agree with you on that. I would also love to see such a library include things like gui and databases, done in a purely functional style. 
Taking this to the extreme, here's a version which works for any function, even if it takes more than one param. :) template&lt;class... I, class O&gt; function&lt;O(I...)&gt; memoize(function&lt;O(I...)&gt; f) { map&lt;std::tuple&lt;typename std::decay&lt;I&gt;::type...&gt;, O&gt; memos; return [=](I... i) mutable -&gt; O { auto args(std::tie(i...)); auto it(memos.lower_bound(args)); if (it == memos.end() || it-&gt;first != args) it = memos.insert(it, make_pair(args, f(i...))); return it-&gt;second; }; };
http://www.reddit.com/r/cpp/comments/g5l93/automatic_memoization_in_c0x/
I'm really waiting for modules :) 
&gt; Anyway, you will find that in real-word usage most of code-points rapresent a single unicode character. And of course Apple loves to be different: http://vemod.net/filenames-and-unicode-normalization-forms I'm not sure how widespread decomposed strings are in OSX, but if they are used in filenames, then it would make sense that the rest of the system uses the same normalization form. &gt;you cannot interpret an ASCII text as UTF8 without doing a conversion Yes you can, that's the whole point of UTF-8. Various 8-bit charsets are not ASCII, and thus you can't interpret those as UTF-8, but good old 7-bit ASCII is 100% correct UTF-8. &gt; I strongly suggest to use BYTE instead of char when handling UTF8 unicode strings. I don't think C++ has `BYTE` type. I guess you could use `uint8_t` if you wanted, but imho `char` is fine and interoperates well with various libraries. And `wchar_t` should die in a fire. and btw the word you are looking for is "r**e**present" 
Wow, that's almost identical to the tuple'd version I commented above, but he got there way before I did. That being said, he doesn't consider reference input types, and input values to the function get copied 1-2 times per call, which I avoid with the use if std::tie instead of forming a tuple of the inputs. 
&gt; The map is copied into the closure, where it is mutated to record new results (only allowed by the use of the mutable modifier). Any reason to not use a static map inside the lambda? It wouldn't make a lot of difference, but it removes the necessity for `mutable` and potentially avoids a copy (though the copy is not expensive and I'd be surprised if the compiler didn't get rid of it anyway).
I prefer the classic Joel Spolsky article on unicode. Not C++ specific, but a very good summary on code-points and encodings. http://www.joelonsoftware.com/articles/Unicode.html
I wrote a blog post expanding on this concept if anyone is interested: http://yapb-soc.blogspot.com/2012/11/generic-function-objects-or.html
Nice article, I'll wait for the rest with links being posted here in reddit :)
&gt; Not every unicode character is composed by a single code-point Actually, they are. Unicode defines a 1:1 mapping between code-points and characters (which is why the tables are called the "character database"). The standard calls the rendered versions 'glyphs'. So, multiple characters can combine to form a single glyph. The standard also discusses things like the 'ch' in Spanish, which is multiple glyphs, multiple Unicode characters, but one logical unit in the target language. When the Unicode standard discusses these it uses scare-quoted "characters" or the longer 'user-perceived characters' to distinguish them from Unicode's abstract characters. (There is also a language-independent version of this which it terms a 'grapheme cluster'.) This latter concept seems to be what you mean here by 'characters', and I think it's helpful to follow the usage in the standard to be consistent. Every *Unicode* character is a single code point, but what users interpret as a character may not be.
yes, you're right. I didn't wanted to talk about these aspects (along with normalization forms,etc...) and I picked the wrong term. Anyway supplementary characters require two 16-bit surrogate values to define a non BMP character, probably this is what I was thinking about :) ...need to figure our how to make it clear! 
I'm curious, where is this going to end up, what are you going to suggest people do by the end of it? I.E. Are you going with a UTF8, 16, or 32 internal storage approach?
I'll wait until `std::ustring` :S
And why do I hear of that only now?
Yeah, I live in Düsseldorf and completely missed that! If only it had more advertisement about it happening. :(
Well hopefully from now on isocpp.org will help this problem.
I will not give that suggestion at all :) The whole point of these articles is that people must be aware of what is doing. Personally, I prefer using the type supported by the operating system you are going to compile into, or if you use a framework , just use it's preferred datatype. So, basically, UTF16 in Windows, UTF8 in linux, QChar when using Qt. I will strongly emphatize the most important point : when doing input/output you have to let the user choose it's preferred format. 
&gt; I see here a lot of complexity with little benefit. Isn't that sort of the fundamental problem with C++?
Interestingly she talks about how the AT&amp;T switching systems are too complex for one person to fully comprehend, and then goes on to say that a C++ compiler isn't. I could never imagine fully comprehending a C++ compiler, it seems like such an impossible task.
She said "That wasn’t the case for a project like C++." I think she was referring to the language. But either way, that was a long time ago. Both the compilers and the language are far more complex today. (Paradoxally, it's easier to program in C++ today, but it's far harder to understand all the dark corners of the language.)
I'm learning C++ from the Kindle version of Primer 5th edition right now. It's really good. I'd started learning from an older book, but when I heard about C++11 I wanted to learn that style from the start. Thanks Barbara!
What features would a module offer that couldn't be done with a single struct or class object? I guess more apropos syntax but I can't think of any other benefit.
I would LOVE to see that!
haha, ok. I (clearly) thought you mean user defined type.
Acronym / initialism conflicts are a common concern of mine; I'm surprised it didn't occur to me to disambiguate preemptively. 
Contribute to Clang.
Couldn't you just implement memoization using static variables. It would be a hell of a lot clearer. &gt;use new features where it makes sense +1 (even tho I still fall foul of this :D )
I am curious to see if it's even possible. Clang and GCC both have hand written parsers, I am wondering if there is a reason for that. Bear in mind that C++ (let alone C++11) is damn complex.
As someone who recently started learning programming and has been told that Android apps use Java, I am confused.
2008 era Android phones like the G1, while expensive and relatively powerful, were sluggish and unresponsive. The latest phones have quad core processors and several gigs of RAM... all we've done is throw hardware at the problem. To some extent the same is true on all platforms over the last decade.
That's why I love templates for code organization. The structure they put up is an aide to the programmer (type safe, all that) and poof! The scaffolding disappears when it's showtime, leaving you with fast native code.
To be fair the "poof" is an hour long compile. I really wish D wasn't garbage collected... I would do some crazy shit for a programming language with C++'s features and D's compile time.
I'm sorry, but maybe the whole black and white approach is - as often - not the best one? &gt; I filled the index with all places with a known population. In the end, the database contained 270 000 city names. What they don't tell you - not even in the linked Android documentation about performance - is that optimization is not at all about using e.g. less getters and more attributes directly. It's more about how to use the provided abstraction and tools in a way such that your constraints are met. Maybe this means using a different data structure for the 270 000 cities, pre-fetching near cities, or even switching to sqlite. There's no standard procedure to do these kind of optimizations, it heavily depends on your situation. It's **easy** to blame your environment, **hard** to think about your problem for yourself.
Objective C is C. You don't need to make an object out of everything. And you shouldn't be running through the dispatcher unless you need to... 
Good approach, at the end this is exactly what we have done.
I was referring very specifically to what is done in the linked article. I suspect that compile times for brainfuck programs "compiled" this way would not be super fast :D
I had a problem with this article too. Not being well versed in Objective C I can't really argue strongly but it sounds to me like a lack of experience with Objective C is an issue here. 
I am the author and I appreciate your scepticism :) I started programming in C++ in 1996 and started Objective-C in 2004. It took me time to understand all small details of Objective-C, but honnestly I like this language and the post is not a criticism of Objective-C. I wrote this post when I was working on an indexing datastructure and I paid attention to all small details like code inlining, reducing of page faults (mmap), reduction of cache misses, ... Objective-C is nice but it does not give you any way to optimize your code like C/C++, you can be septic but this is the reality. But the biggest strength of Objective-C is to be based on C, so calling C/C++ code from objective-C is a child-play, this is not the case of Java where you need to write all this long JNI code...
Me too. I used to do quite a bit with ObjC++ on NeXTSTEP.
http://developer.android.com/about/versions/android-2.3.html ctrl+f native, second result.
It doesn't matter, it wasn't available on the platform the team was developing on, whatever version that was 2 years ago.
I would hope you consider the order of your chosen algorithm, otherwise you can end up with something that os O(n^2) when something could have been done in O(n log n), in which case your inefficient algorithm written in C++ could be out performed by somebody else doing a better way in Java.
mmm, I could not understand what you mean. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2073.pdf modules will be a way to fasten compilation times, by avoiding the usage and parsing of headers in each compilation unit. There are other benefits too...
Actually it is. It just probably doesn't do what you would like on exception, if used nakedly.
I think the post is overcomplicating the matter slightly. Just make sure that all your strings are always UTF8 and you'll be fine, especially if you are on Linux. On windows you should be using the unicode API anyways, so it shouldn't be easily mixed up with strings as it uses wstrings (which are pretty horrid for any real use).
It's pretty typical C++: it gives you the unsafe tools to build a solution at the level of safety/performance you require, but not an out-of-the-box solution.
This is probably the only class in the whole C++ library that needs to be wrapped in yet another class for exception safe usage. I'm merely seeing a problem here, not how it is better solved (maybe with two classes "AsyncThread" and "SyncThread" instead and the semantics of std::unique_ptr: the destructor frees memory, but one has the option to do this earlier via "release") Considering the behavior of std::thread a better name seems std::impl::thread_base.
Clearly a choice "detach/join" has to be made. But I'd argue one can make this choice up front in most cases. So instead of having ~thread terminate the whole program due to a contract violation one could have two threads classes instead. This would make it improssible to use incorrectly....well, except for the other threading-related issues, that is ;)
Same goes for collections (including std::string): they took so long to enter the standard that every library has its own half-assed version. That's the reason why Qt still has its own version of containers in 2012.
&gt;[Why was cooperative thread cancellation removed from C++0x](https://groups.google.com/forum/#!topic/comp.std.c++/Sv5Ss57ByW8/discussion) Ha, i wondered that also. Wtf they were thinking? Now i know. Ehhh, committees :(
Thank you! I will definitely read up on this :]
What you are looking for is a GUI (graphical User Interface) toolkit. I personally use Qt which is very well written ans has the most comprehensive and explicit documentation I have ever used. There are lots of other options though. From the top of my mind : GTK and wxWidgets have quite some users. Have fun! 
That is the easiest place to optimize it :-)
This is true but Qt is cross-platform. You write once, run anywhere (for various definitions of everywhere.)
Correct. I forgot all about frameworks.
Qt is very good and you can do all sorts of things with it. Problem is you need the Qt libraries to run anything built with it, Ubuntu comes with the Qt packages installed, so it's no problem. Windows does not, you will be required to package all the dll files with your executable for it to work on another user's computer WxWidgets is pretty good as well, I used this before switching to Qt, it has a good range of widgets to use in GUI applications, and you can compile as a static executable, so you have only have one exe file that you need to distribute. Although the exe file is usually bigger then 3Mb. Both wxWidgets and Qt are cross platform, so you can write once, and compile on windows, mac, and linux. The question you should ask yourself is, are you going to distribute your program? If you are, do you want to deal with the shared libraries of Qt? The Qt libraries is MUCH more powerful than wxWidgets because it comes with other non-gui related things as well.
Qt has its own containers and data structrues to ensure binary compatibility.
&gt;So I've been taking C++ at my college for quite a while now and I think I'm decently proficent at it. No one should claim to be proficient at C++, ever
I'm using gcc/4.7, and believe me - it's far from complete. I've considered upgrading to 4.8 but the few features it adds haven't justified the labor in rebuilding gcc &amp; all of the 3rd party libs I've already built against 4.7. (gcc is about a 3-4 hour build from scratch, would take me a few more hours to rebuild the other libs). One particularly annoying omission are the lack of emplace functions on associative containers (which I understand may be fixed with 4.8). 
Yes you can, but I think it changes the terms of the licensing. I believe you have to release the source code of your work if you link statically. I looked into it a while back, I could be wrong though.
I need to read about what you're saying, but what I'm saying is that modules have a lot in common with singleton classes (you can put stuff in a smaller namespace and refer to it as needed). Maybe modules are more like ordinary libraries in this proposal, however.
&gt; It's ridiculous to say it's "all we've done". It's like saying "all we did to reach higher speeds in our car was to put a better engine in it." Yes, but if you did this because the breaks were constantly rubbing against the wheels which was slowing the car down significantly, then while it is true that you technically solved the problem by upgrading the engine to reach normal speeds, you are *still* wasting a lot of potential performance due to the issue with the breaks, not to mention the energy costs that you are paying for all that extra engine power that is getting you only a normal amount of speed.
I think this kind of introduction to "objects" should be the first port of call for people coming from a C background. Once you see how multiple inheritance and virtual base classes are implemented, oddities like the so called "Diamond Problem" quickly become obvious.
I eschew the toolchain because it's just bad for the ecosystem all together. Being able to write cross-platform code helps everyone, using all systems. It's not just C++ where Microsoft are lagging though, their adherence to web standards and the all round *buggy* nature of their Javascript implementation makes it so that anything on Windows is either a mish-mash of `#if __WIN32` or conditionals checking for the version of IE. Overall, I genuinely think this is their actual tactic. Why innovate to remain relevant when investing nothing and adhering to the bare minimum of the spec pretty much achieves the same thing?
Right, I can understand that then. Personally I'm just glad things are moving in the right direction and at least it has momentum, unlike C99 support which is pretty much a lost cause. I'm hoping windows development with gcc and clang becomes less burdensome in the future. 
For Microsoft C++ what they care about, in what concerns system programming and performance related applications. C is dead on Windows for Microsoft, officially only C90 gets supported as legacy, and Herb already announced in his BUILD 2012 talk that the Windows team is moving Windows subsystems from C to C++. Personally I am ok with it, since I am more than happy not to deal with plain C since 2001, but I do recognize it would be nice for other developers to have C99 support.
I always find funny how Microsoft gets bashed all the time, mostly rightfully so, but developers tend to forget there are more compilers out there than just clang and gcc, and all other commercial vendors tend to have a level of support similar to what Microsoft does.
In case I wasn't the only one wondering what the heck CTP stands for and had to look it up, it means "Community Technology Preview" and is Microsofts fancy word for what the rest of us calls a Beta release.
Agreed. I am unlikely to use C99 personally for any new projects, but would love to be able to compile other libs that use it within the msvc tool chain. 
Yay! somebody reads my blog! (I wrote the blog post cabbageturnip mentioned above) I wrote that as I was learning about variadic templates and new C++11 features, so I didn't care about efficiency at that point. Thanks for the tip about std::tie, I didn't know it existed :D
It is based upon boost function/bind/asio libs.
OK. As I wrote, I just looked it up quickly because I had no idea what CTP stood for and I imagined I couldn't be the only one. Thanks for clearing that up.
"Inside the C++ Object Model" by Lippman is a great book that covers this kind of thing in great detail. People say it's outdated, but I think it's still great for understanding the issues involved, even if the solutions have changed over the years.
Pro-tip: Use some other compiler Whats all the noise here? 
You are right. constexpr seems to imply the same as GCC's const attribute. But pure allows access to globals which is afair not allowed in constexpr. 
Which also isn't free and used by most Windows devs. If you're a library targeting Windows and don't support MSVC, you're pretty useless to most Windows devs. The fact is that Microsoft is the one holding C++ back.
So how exactly would I use this? I have that trouble a lot when I see a new piece of "middleware" - it seems cool but I'm not sure what problem it's actually solving. Sometimes I think it's a solution looking for a problem - sometimes when I see it used the light dawns and I wanna use it right away...
Some of us through no choice of our own need to support Windows.
This is unfair. According to http://wiki.apache.org/stdcxx/C++0xCompilerSupport Microsoft had lambda before clang. Right angle brackets came in MSVC 8.0. Also MSVC 11 has one of the most complete C++11 std library.
GCC and clang have lots of money put into them by multiple companies. And both of them are released by commercial vendors as fully supported products.
Right angle brackets are so hard to implement... And having a few features incorrectly implemented early doesn't make this post unfair. As for the standard library, STL has done a great job given what support the compiler has, however, it is still severely lacking due to unsupported compiler features and outright bugs in msvc that give incorrect behavior. clang has had to implement quite a few hacks under -fms-extensions to get the msvc standard library to compile. And "extensions" here is very forgiving. Most of it is implementing bugs.
at least we can dream though :)
Manipulating UTF-8 is no harder than manipulating UTF-16, which is what wchar_t gets mapped to on Windows. wchar_t is horrid for portability.
There are but the integration of MSVC, Visual Studio and various other tools means that it's rarely feasible to anything else.
OK.. but how does this fit into the narrative of the blog - "Microsoft has held back the C++ community" when there are tons of other vendors. Why isn't anyone asking them to improve their Windows platform tools.
There are. Intel's compiler is more compliant and integrates with VS.
That's what I call using your critical thinking skills. It is extremely odd that the compiler with Herb Sutter on board is not leading the industry with the most correct and complete language implementation.
So it's good that they did that? I'm finding it hard to detect sarcasm in your post.
Exactly. Lambdas did exist, but were buggy (most notably, not being able to cast non-capturing ones to function pointers) Nevertheless, hats off to the MS team (mainly Herb and STL) for beginning to take C++ standard seriously. The days of portable modern C++ code is closer than it ever was.
&gt;But you must realise that people are just going to moan no matter what? I just don't agree with the position that MS somehow "held back" anything which is the point of the blog post. In fact, its completely untrue. I guess its boring to simply make yet another table chart comparing compilers and features. Throwing around wild accusations makes for juicy link-bait.
That's correct. And you should know that sarcasm and irony often get lost in written medium.
Great suggestion, thanks!
&gt; Right angle brackets were in gcc 4.3 back in '08. MSVC 8.0 was probably the same year. VS 2005 == VC8 == _MSC_VER 1400 VS 2008 == VC9 == _MSC_VER 1500 VS 2010 == VC10 == _MSC_VER 1600 VS 2012 == VC11 == _MSC_VER 1700
Still correct. Qt is LGPL licensed, and so can only be dynamically linked without releasing your source. That said,I doubt this is a concern/problem for a college student making a calculator app.
Well I made a not-awake mistake! I've updated the post with a disclaimer at the beginning summaziring the main point, but I'm leaving the original body alone (I'm not hiding the fact that I legitimately screwed up), so have a laugh.
You can mix c++ and obj-c without any problems. Apple calls it obj-c++ and it's exactly how it sounds. As a former c++ dev, I found obj-c to give me less grief but I still love both languages equaly.
&gt;But they (Google ) state clearly that you are better off using Java in most situations. Probably. Then again, even Angry Birds ship with an \*.so
Hi, I work on a top ten App Store iOS app. We use a mixture of C++ and Obj-C. I personally prefer C++. As someone else stated, Obj-C and C++ play nice together, you can wrap the Obj-C stuff and do everything in C++ if you want.
I only ever use the NDK when doing massive calculations. This makes sense with angry birds since they are doing on-the-fly physics calculations that can cause a severe performance impact when using java.
What you said is true, but C++ is the only language that runs on all major phone/tablet OS's. So not only is it fast, it's great for cross-platform.
"The only non-C++ bits are the links to platform API calls for Android (in Java) and iOS (in Obj-C)f or things like getting the graphics context, audio buffers and input data." That sounds like quite a bit of dependency on Java though. Graphics, audio data input: those are parts of the app that a user actually interacts with and it would be great if they were all written in C++; don't you think?
At least in the case of Apple's iOS is derived from Next Step / Mac OS. This software has a long history with Objective C. In any event Objective C mixes very well C++. 
I don't think you quite get how it works. The Java stuff on Android (and the equivalent Obj-C stuff for iOS) is merely wrapper code. All of the logic is done in C++. The graphics context is the gl context that android gives you it when you ask it to create it. After its creation, everything else in C++. For audio, we ask Java for a pointer to the audio buffer, then fill it in ourselves in C++. For input, we ask for the latest input data from java and then process them in our peripheral system (of course in C++). The engine itself runs on Android, iPhone/iPad, Playbook/BB10, Mac, Linux, PS3 and X360. It used to run on the Wii, but that slowly got left behind as its architecture is annoyingly different. The non-C++ code is really very minimal for Android and iPhone and is mostly just a bunch of method bindings. 
Hello, I use C++ on one big android market application - for heavy network data processing - and I've been working on mobile platforms for few months only. 
Something like the Marmalade SDK will let you write your app once in C++ and then it'll work on most modern smart phones. That one is targeted at games, but of course you can do anything with it...
Straight up ANSI C also works, unless I'm mistaken ...
I think it depends what you want to do. If you want your app to be a crossplatform game and you don't want to buy or use middleware C/C++ is a no brainer. Android + iPhone use OpenGL ES, if you're also targeting PC / Mac / Linux OpenGL ES is pretty much a subset of modern OpenGL on those systems. It's actually the Windows phone that's a bit of pain because it will expect DirectX. (Marmalade lets you do crossplatform in C++/C but I didn't find it very nice to use, the website is unbearably slow for looking stuff up, and you have look stuff up a lot because they've added quite a lot of cruft setup files that aren't particularly straightforward. Try and write an app that prints Hello World from scratch and you'll soon see what I mean! They do have a reasonably nice interface for using the native API for each system - though it needs more examples and to be better documented) If you're doing an app that is more standard GUI stuff then on Android Java is best, iPhone Objective C. If you want to do non-game cross platform then I've heard phone gap is good for that (but I've never used it). I've only really developed for Android but I'd guess the Windows phone would be the nicest to develop for, as it'll be tied into Visual Studio and the integration, profiling and debugging will probably all be excellent. My experience of Android dev is that it comes from a very linux, commandline, gnu toolchain world, which as a game dev is something I had to learn a bit more about to become productive. 
Qt recently adopted ANGLE to get OpenGL ES on top of DirectX. But I'm not sure if it works on Windows Phone too...
Most of the stuff discussed in this article should be handled by your locale abstraction. You shouldn't have to worry about string literals, because for the most part, you should not be using them.
Probably, but unless you just "pass" strings around, there will be a big difference between an UTF8 locale and a "8bit code-paged" one, even if your strings are not directly literals. At very least you have to test your code twice.
Too bad the audio is so poor. I can't hear or understand what they are saying.
agreed, the qt5 one I'm sure would be interesting if listening didn't give me an instant headache
That isn't exactly true unless you are talking about multithreaded programs. iOS applications have to respond to the internal message event system.
I have yet to look through the 5th edition version online but I am just starting chapter 4 of Primer Plus 6th and it has been introducing the C++11 concepts along the way. I think I'll stick with it for now. Do you know if the 5th edition covers STL? I am new to C++ but I have heard the STL is a most know. 
It covers the STL, albeit not as in depth as a book dedicated to the subject. You'll get a good idea of how to use sequential containers, associative containers, and the generic algorithms. But I think more importantly, it gives you a good overview of how most of the algorithms are structured, which you can use to figure out what isn't covered explicitly.
I'm currently reading an introductory book on C++ dated circa 1996. As far as I'm aware nothing in that will be factually incorrect as things don't get removed from the standard. Correct me if I'm wrong, folks. EDIT: Also, is that 'primer' book a good one for a complete beginner to programming to look into getting?
Do yourself a favour and throw that shit away. Get a modern book. Whilst you can still ~~make many of the same mistakes~~ write code from 1996, you will be far better off using the more modern features.
I would be caucious, a book from 1996 PREDATES standardisation. Before 1998 there would be plenty of C++ platforms with jarring differences, of which not all could be standardised (E.G: old version of MSVC had `new` returning null if it failed to alloc, rather than throwing bad_alloc). Also older books may use the old headers, string.h, iostream.h... Finally, C++ style has moved on a lot from 1996.
The Primer and the Primer Plus are two distinct books. Out of the two just go for the Primer 5th edition, this book is well regarded as are it's authors. Another book (although it doesn't cover C++11) to consider is Acclerated C++.
Indeed, the book makes many references to the 'draft' standard, as it was then! Would you suggest an upgrade, then? I do find the book very helpful in that the style used is very accessible for complete beginners to programming.
If you are still learning, then yes, you should definitely consider a new book (AC++ or Primer as already mentioned)
If you are still learning at that level, then it doesn't really matter. Just make sure once you get beyond the basics you are clear about RAII, using the stack instead of newing objects all over the place, using smart pointers (start with unique_ptr and move on from there) when heap allocations are necessary and learn the STL the containers and algorithms. You say you are a UK resident, so http://www.amazon.co.uk/gp/offer-listing/020170353X/ref=sr_1_1_olp?ie=UTF8&amp;qid=1353343854&amp;sr=8-1&amp;condition=used and http://www.amazon.co.uk/C-Primer-Stanley-B-Lippman/dp/0321714113/ref=sr_1_1?ie=UTF8&amp;qid=1353343920&amp;sr=8-1 Very good value I would say.
Two very different books. Avoid the one by Prata (the 6th ed. one), it's too C-style, which is an obsolete way to learn C++ -- e.g., introduces std::vector significantly later than C-style array[]. I can definitely recommend C++ Primer 5th ed. -- for more, see: http://www.reddit.com/r/cpp/comments/11gkqt/c11_timing_code_performance/c6nfzpb
BTW, what happened to the article? When I'm trying to open it, it 404s. It seems that your previous articles -- e.g., http://bryanstamour.com/2012/06/26/need-polymorphism/ -- also got removed :-/
&gt; and their standard library support is actually better than GCC/CLang. I think I heard another person say this as well, but unfortunately every source I attempt to use to evaluate the truth of that is out of date. &gt; Implementing standards early (other than in proof-of-concept form) can lead to users being burned when the feature changes during standardisation. Witness ConceptGCC. This isn't entirely true. It's hard to standardize something theoretical since there's no proof it works. Concepts are a long way down the road and since Stroustrup has worked on both ConceptGCC and the concepts proposals, no one can tell me that it's bad that he is or has attempted to implement his own ideas. I'm sure the more recent proposals have been informed by the actual experience with ConceptGCC, that would not have come from late adoption. Finally, I want to note that the standard isn't *that* volitile. Proposals seem more refined then changed over time. One does not need to wait until the standard is published to peak inside. The changes that *do* occure to long-running proposals usually seem more subtle than overt. Concepts are an unfair example because of how experimental they are. Things like default template arguments on functions and variadic function templates are good examples of proposals where the risk of implementing before standardization was extremely low. The former was an oversight by the standardizing committee. The latter was an obvious and useful extention to the language.
C++ Primer Plus is NOT THE SAME as the C++ Primer. It is not 'the Primer with more info', it is a completely different book with different authors. I believe C++ Primer is the better book.
It's more than decent, it's brilliant (if you're actually a beginner with C++). My 3rd Ed copy started me on the career I have today.
Avoid the Prata book.
I had a bit of a server hiccup a while back :-( As for this article: instead of trying to salvage it, I just wrote another one on the same topic.
[The Definitive C++ Book Guide and List](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list)
I think the key point is the following: &gt;Two containers instantiated with different allocator types refer to different types making interoperability between them difficult and limiting the allocator type to a per-class (as opposed to a per-instance) basis using BSL will do the following: &gt;The type of an object is unaffected by the passed-in allocator and the user has full control over the scope of an allocator instance
So, basically, you need the BSL when (and only when) your application needs different allocators for different instances of the same container, right?
&gt; different allocators for different instances of the same container Is that not what the std:: currently provides std::vector&lt;T, alloc1&gt; v1; std::vector&lt;T, alloc2&gt; v2; And for the case where you want 1 allocator for two types can't you just use some thing like std::scoped_allocator_adaptor 
I always preferred allocators based on type, using specialization: class &lt;T&gt; class allocator { bla bla } class allocator&lt;MyType&gt; { bla bla } 
Right - the idea is that the allocator is not part of the type. Once you firmly follow this methodology, it becomes somewhat trivial to switch out allocators for various parts of your code for instrumentation, debugging or performance. If you have to change your type to do any of these things, it becomes much more difficult.
If you have it cached, then if you want can you send me the C++-related posts? I really don't care about the rest of them, as they're either published elsewhere or just quick "I farted today" type posts.
That's right.
Now try scope(failure) ;)
It *is* RAII. It's just more explicit and succinct. 
 int * ip = new int[16]; SCOPE_EXIT(delete [] ip); FILE * fp = fopen("test.out", "wb"); SCOPE_EXIT(fclose(fp)); These are ridiculous. The first should be a vector and the second an ofstream. There's no need for these kludges if you just use the proper tools in the first place, as vectors and iostreams automatically relinquish their resources. Maybe they are supposed to stand in for cases where there is no proper equivalent, but if that's the case then write a simple class to handle it instead of trying to write bad C. 
If the `exec()` call fails, then execution will continue in the process, so it's up to you to decide what to do. A sensible thing might be to terminate the process with a non-zero exit status. When that process is then reaped by the parent, its exit status can be checked to see if it was non-zero. This assumes that when the `exec()` does succeed, that whatever it's running will also exit with a zero status for success and non-zero for failure. The return value of `waitpid()` is not the exit status of the process being reaped. That is stored in the pointer you pass. The return value of `waitpid()` is about whether the function itself was able to successfully reap something: -1 if there is nothing to reap or there was some kind of error; 0 if you passed `WNOHANG` and there are child processes but none of them have terminated yet; positive (and equal to the pid) if a process was reaped. Your use of `WNOHANG` here makes no sense, because it's a race condition. If the parent immediately calls `waitpid()` after forking, then there's a chance that nothing yet has happened in the child -- it hasn't even attempted to `exec()`, for instance. Or maybe it tried to `exec()`, but failed, but it hasn't yet exited. In either of those cases, `waitpid()` with `WNOHANG` would return 0 because there's nothing yet to reap. But that's like saying "no answer yet". It's not a useful result, you'd have to keep calling `waitpid()` in a loop until you either successfully reap something or you get -1. That looping behavior is exactly what you get without passing `WNOHANG` (except there's no spinloop burning up CPU doing nothing constantly.) The call either waits until there's something to reap or it returns -1, there's no indeterminate result. 
I agree. This seems like some sort of bad joke.
Sure! Is the contact info at https://github.com/bstamour valid? I'll try to remember to do this before the next week :-)
No it's not. This, and RAII are not functionally equivalent. On is bound a type, the other requires being place in each function by the programmer.
Maybe the venerable STL himself could give his opinion about this? Strictly non-professional, that is.
For game development, go with [gameplay3d](http://gameplay3d.org). Runs on Windows, Linux and Mac OS X, iOS, Android and Blackberry. Source code available under Apache 2.0 license. It's awesome too.
Cool. We have our own OpenGL-based framework setup and running, but seeing stuff like this is always fun.
While ACCU reviews are probably better, I don't think Amazon reviews are useless. You just have to know how to interpret them. When reading reviews of technical books you are looking for two kinds of reviews. One is the reviews of beginners that used the book to learn material. Here what you are looking for are comments about how easy it is to follow and how confusing it is or isn't. But this isn't enough because beginners can't judge if the material covered by the book is complete or even accurate. (In the C++ world there are many books that are worse that useless because you'll have to unlearn some of what they teach you.) There are usually very many reviews of this type on Amazon and they aren't useless, they just aren't sufficient. So you then have to look for reviews of people that already know the material and are reviewing the book because they are always on the look out for good books. In these reviews you are looking for accuracy, completeness, and things like good coding style. This type of review may be more difficult to find, but there are usually a few of these on Amazon. If there is a review of the book on ACCU, it usually of this type. For C++, there is an even faster heuristic to determine if the book is good. (Note that this method isn't fool proof, there are exceptions.) Here is the secret: Look on the binding. If it says "Addison Wesley" then odds are it is a good book. If it doesn't say "Addison Wesley" odds are against it. (Exceptions that come to mind right now are from Anthony Williams and PJ Plauger.) Full disclosure: I currently work for Amazon and I've done book technical reviews for Addison Wesley. (Look for my name in the latest edition of the Primer. ;) 
&gt; That is stored in the pointer you pass. Actually that int has a bunch of information stuffed into it: there are a bunch of W** macros to get the pieces out. It's a bit like a brain damaged little sum type. Testing for successful exit of the execve'd process would be something like `WIFEXITED(status) &amp;&amp; WEXITSTATUS(status) == 0`. &gt; Your use of WNOHANG here makes no sense I'm not so sure about that. Say the parent expects the child to do a considerable amount of work and wants to remain active in the meantime, it might be reasonable to check every now and then using WNOHANG, essentially polling on the child pid (as opposed to installing a handler for SIGCHLD). It's hard to say whether the OP intended something like that or not.
W
Also, in the case of `new int[n]`, you can use an `std::unique_ptr&lt;int[]&gt;`. (if you _really_ don't want to use `std::vector`)
The example is bad, but the idiom is dearly needed in C++ for exception safe coding: "run this code on *both* regular and exceptional return paths". The related idiom "run on exceptional code path" is called scope guard. Uses: Wrapping Win32, Posix APIs or C-style APIs in general (which occur very often even in C++)
TIL isocpp.org is blogspam.
 auto FB_ANONYMOUS_VARIABLE(SCOPE_EXIT_STATE) \ = ::folly::detail::ScopeGuardOnExit() + [&amp;] What is happening there? Is [&amp;] equal to [&amp;](){} (that would make sense, I guess, although I'm still not sure on how operator+ would be determined between a lambda and an enum class) or am I missing something?
Good stuff. Getting boost built for iOS can be a pain. I build my stuff for Win/OS X/Linux and iOS. My build system is around 20k lines of bash scripts. Just now starting to port to Android. Thanks for posting this. 
Have you considered Scons? 20k lines might be a lot to translate, but I would think anyone would prefer Python over shell scripts.
 if (condition == failure &amp;&amp; std::uncaught_exception()) f(); Show me [Teh codz](http://ideone.com/jyuu7b)
This was, of course, a red herring. Your code is seriously flawed, because it sometimes appears to work. This (scope fail) cant be done in C++ as of now. See [here](http://www.gotw.ca/gotw/047.htm) as to why this is so and when the std::uncaught_exception function should be used.
The following fixes your problem. Be prepared for an influx of further comments on how this is 'evil', your code has many other problems, and the classic 'Why would you need this?'. #include &lt;iostream&gt; #include &lt;vector&gt; using namespace std; //! This line here solves the problem, it basically says that Myclass //! is a class and will be defined at some later point, but not now. class Myclass; vector&lt;Myclass*&gt; myVector; class Myclass() { public: Myclass() { myVector.push_back(this); } }; int main() { Myclass test; } 
Think it through. What type does the expression "myVector[0]" evaluate to?
Because I defined my vector with a * (&lt;Test *&gt;) I think it evaluates to a pointer but when I try calling cout &lt;&lt; myVector[0].myInt &lt;&lt; endl my compiler tells me classes.cpp:22:22: error: request for member ‘myInt’ in ‘myVector.std::vector&lt;_Tp, _Alloc&gt;::operator[] [with _Tp = Myclass*, _Alloc = std::allocator&lt;Myclass*&gt;, std::vector&lt;_Tp, _Alloc&gt;::reference = Myclass*&amp;, std::vector&lt;_Tp, _Alloc&gt;::size_type = unsigned int](0u)’, which is of non-class type ‘Myclass*’ Edit: Here's the full code #include &lt;iostream&gt; #include &lt;vector&gt; using namespace std; class Myclass; vector&lt;Myclass*&gt; myVector; class Myclass { public: Myclass() { myVector.push_back(this); } int myInt; }; int main() { Myclass test; test.myInt = 5; cout &lt;&lt; myVector[0].myInt &lt;&lt; endl; }
Can't wait for Qt to properly support both Android and iOS, will make this so much easier.
Curiously, what are you trying to use this for?
I think that modules are the right idea, but I think that ignoring the preprocessor state is going to have some unintended consequences. I understand that the preprocessor with includes is part of the problem, but I see getting rid of them as the same argument as to why some langugages get rid of things like multiple inheritance (it can be a pain and only used rarely) and I don't know if it's really the correct solution.
Why use a loop, rather than xmin &lt;= x &amp;&amp; x &lt; xmax &amp;&amp; ymin &lt;= y &amp;&amp; y &lt; ymax? Unless I misunderstood what you're looping over.
It's part of a macro definition, but note that the macro does not contain `()`, allowing you to write: SCOPE_EXIT { delete foo; }; ...which will expand to something like auto some_automatically_generated_unique_name \ = ::folly::detail::ScopeGuardOnExit() + [&amp;] { delete foo; }; (The `()` on a lambda is optional if it takes no arguments.) Here there is an overload for `operator+()` that takes a dummy empty type on the LHS (as a "recognizer" of sorts) and a templated `FunctionType` on the RHS. It constructs and returns a `ScopeGuardImpl`, the same as `makeGuard()`. It's an elaborate trick to create a macro that allows writing a block of code naturally without needing an END_BLOCK type of deal to supply the closing paren of a function call to `makeGuard()`, or without the user having to remember to do it. Although there's still that pesky semicolon after the block which is not ordinarily required, so it's not a perfect emulation of a block. 
Could you explain why it would be better compared to [Kranar's solution](http://www.reddit.com/r/cpp/comments/13km3b/is_it_possible_to_add_the_address_of_an_object_to/c74rvvm) please?
I'm not sure I'm understanding you.
I don't see how this GOTW applies, I don't give a destructor different semantics. The only problem I see is that this kind of scope guard should not be used inside destructors.
Its not about this construct not being used in destructor. Its the code that uses it can be used in destructor and there is no sane way to guarantee that its not. The problem is that uncaught_exception is just not the right primitive to use here. In your example, users of both 'foo' and 'bar' need to know the implemention details of them. Providing primitives that mostly work, like such scope guard, is just dangerous.
The way you have it now, MyClass has a dependency on myVector that is not immediately obvious to someone using your class. Say that MyClass actually represents a button. Should all buttons go into myVector? What if you want different vectors of buttons depending on which state you're in? By disconnecting the creation of MyClass from the tracking of it through a vector, you give yourself more control over what happens, and you make MyClass more useful.
Note that you should either handle or disable copy-construction.
One of the most important pieces of software maintenance (and 99% of all software work is maintenance of some sort) is ISOLATION. Each piece of code should be as isolated and independent from every other piece of code as possible. This idea has many names - encapsulation, modularity, abstraction, opaqueness - but they all boil down to the same idea. The more someone else knows about you, the less freedom you have to change. Information should flow in one direct on a need-to-know basis. Does MyClass need to know that it is managed by myVector? Almost certainly not. 
How about if the scope guard checks `uncaught_exception` in its constructor and assumes that if there is an uncaught exception there will not be another exception? (otherwise `terminate` will be called)
Fully agree with the article. I'm just curious: did you evaluate any other unicode libraries before starting your own one?
[Boost.Unicode](http://mathias.gaunard.com/unicode/doc/html/) looks promising. I was not too enthused by other libraries, like ICU. EDIT: more info. EDIT: link.
I have had need to manipulate code points at work before. I am not saying it happens often or anything. I am saying that this is a property of UTF-32, and you can choose to make use of that property if it suits your needs. This property also lets you trade memory for speed, which you may or may not be interested in. I don't know. The point is that I don't want to choose for you, and I don't want you to choose for me. And yes, having an interface to deal with characters directly might be useful too. It just needs an actual definition of the much overloaded term character. Even though I don't see how it is obvious for UTF-8 ("decoding UTF-8" means converting the code units to codepoints, because, just like UTF-32, UTF-8 is a mapping between codepoints and code units; you don't get any other "characters" from that ). I think the fact that for some it is obvious for UTF-8 and not for UTF-32 might help argue my main point: I don't want the encoding to leak to the interface. I don't care about the serialization format outside of serialization. EDIT: refined explanation
Which unicode? How do we serialize it? Which is more efficient for the most cases? *That's* the point of C++, the choice to do what is most efficient for *your* particular use-case or not to be otherwise stuck with misfit defaults.
But that assumption is not correct - we will end up terminating perfectly legal code (and detecting that there was another exception thrown is impossible anyways). 
&gt; *Which unicode? How do we serialize it? Which is more efficient for the most cases?* This doesn't mean the default has to be verbose or hard or broken. 
&gt; Is there any point at all to manipulate code points? It's not like one code point = one character. Even if it were, how often do most programs need to manipulate character sequencing for human consumption? Most programs will only ever need to deal with lines ((\r)?\n) or perhaps whitespace, so treating strings as blobs works just fine for a lot of things.
I'm not really sure that changing vector at this point in time would do any good. The issue is well documented in all of the standard texts, and it's just one of those things you need to learn, along with a million others. Changing it now wouldn't really get you much, because you'd be in a holding pattern for years waiting on tool vendors to update and users of tools to upgrade their tools before you could safely use `vector&lt;bool&gt;`. If you want to store bools in standard containers and you don't care about a compact representation, there's `deque&lt;bool&gt;`. If you do need a compact representation and the length is known at compile time, then use `bitset`. What's lacking is when you need both a compact representation and dynamic size, so if any change is going to be made standards-wise it would probably be to simply import `dynamic_bitset` from Boost and call it a day. I think the more interesting story is how the standards body used `vector&lt;bool&gt;` as a showcase for what they thought would be an innovative concept with the proxy objects, which turned out not to be the case. I'd really like to read more about how the problems of proxy objects were not immediately visible and why such a grand experiment made it so far without anyone realizing that it was stillborn. 
Changing vector&lt;bool&gt; would eliminate so many headaches it's not even funny. Anytime someone writes generic code involving vectors, they basically need to special case vector&lt;bool&gt; either by specializing the template, or using conditional types, like: typename if_c&lt;is_same&lt;T, bool&gt;::value, std::deque&lt;bool&gt;, std::vector&lt;T&gt;&gt;::type As an example: template&lt;typename T&gt; class SomeClass { ... std::vector&lt;T&gt; elements; }; Now if you make a SomeClass&lt;bool&gt;, you're likely screwed. The above is just a highly simplified scenario, but the problem is that any time you have std::vector&lt;T&gt; where T is a template parameter, you need to worry about the case when T is bool.
cool, I didn't know about if_c, I really need to "invest" time in MPL. Of course `std::vector` and `std::deque` have different properties in many case (deque is no contigous)
May i ask the relevance of declaring this as a a struct vs a class?
Because I would just have to make all the members public anyway. *I guess* I could encapsulate `val`, but there is no point. (I don't know you skill level) But in a C++ a class *is* a struct with the exception that they have different default protections; a class is defaultly private, and struct is defaultly public. Because of this we (I) can use it as a sort of form of documentation, a struct denoting a "value object" (a logical grouping of values, no encapsulation) and a class denotes a fully encapsulated entity which provides a service and has "implementation details" which I don't want the user to mess with. This is neither, it's a widget or doo-dah, I am merely exploiting C++ ability to provide conversions operator and implicit constructors. The same way template meta programming might exploit template specialisation.
Thank you. I'm out of practice, completely spaced the default protections.
&gt;This worked quite well for the "auto" keyword. Only because the presence of 'auto' is by default implied, hence it was never used. std::vector&lt;bool&gt; gives usefull functionality that is used way more often then legacy 'auto'. As such, it is very similar to std::strstream which is not going anywhere as well - this is the correct thing to do here and i cant see std commitee doing anything but that in such cases (at least currently).
The main problem are probably templates, template &lt;typename T&gt; class Foo { std::vector&lt;T&gt; foo; } which need to be specialized. 
I agree that it is good that early versions of features be provided, I experimented with conceptgcc extensively but, until standard this should be regarded as at risk, otherwise the standard ends up constrained by compatibility with premature implementations.
&gt;But why would anyone want to do that when you can just grab an existing reusable ownership policy instead and get the same effect? Because HANDLE being void* is implementation detail and existing solution is not general enough to handle cases where resource is not a pointer. Consider wrapping file descriptor thingie.
Woooosh.
&gt; What is wrong with this? For one thing, what if the bit I want to set is a variable, like 23? These kind of data structures are often used for set operations, where the bit to be set/cleared/tested is simply an integer. And there could be millions of bits -- that's why it's important to keep the representation compact instead of using a byte per like `vector&lt;char&gt;`.
You are not allowed to do allocation, so you need a pure functional library, with linked lists and finger trees and stuff like that. Probably modelled on Haskell. There is nothing like that in the standard library, but I have seen at least one effort on github to implement pure constexpr containers.
Thanks. It makes sense, I suppose. Feels like a handicapped Lisp to be honest.
When you declare an array like miles[4], the 4 is how many elements there are. But they're numbered from 0, so you have 4 elements, numbered 0 to 3. Your loop runs from 0 to 4; that's 5 elements total, so you need to declare miles[5], gallons[5].
I am talking about deprecation, not removal. Latter should be only in years to come. At this point every "good" developer will have migrated long ago and the actual code-breakage will be minor and consisting of compilation errors only, which are easy to spot.
Has it not already? There's actually a proposal to allow ifs and static variables in constexprs. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3444.html I even remember reading that someone had an idea for a "static for", which could be used in constexprs. I see no reasons to use TMP techniques anymore except for the few places where pure constexprs are impossible, like string litterals.
Beware ABI issues with C++ modules. Once burned, twice shy. I only use straight C across module boundaries, now. 
Well don't I feel retarded now. Somehow got it in my head that the number used in the array declaration was the same number used to call the last element in the array and was too stubborn to look it up. Thanks for pointing that out to me!
No, it's still an issue if you use the same toolset to build everything. The mangled names of types aren't guaranteed to be sane across module boundaries, which means calling into a different module is UB. POSIX requires this to work for C, but doesn't say anything about C++. I don't know if it's an issue on Windows or not.
this model has potential for mismatched new/delete. it's why COM uses IUknown::Release.
well, as long as you use the same toolset (version as well, though) it really isn't an issue. http://blog.qt.digia.com/blog/2009/08/12/some-thoughts-on-binary-compatibility/
Requiring that the same toolset be used to build all plugins defeats the purpose of decoupling your main application from its extensions. Nobody who's going to write plugins for your app wants to see this in the documentation: "You *must* use version x.y.z of compiler Bazfoo++ with the following settings, or nothing will work; and this may change in future versions so have fun trying to avoid long periods of unnecessary incompatibility." Much better to just provide a pure C interface, or use something like Python for your extensions instead. ;)
I was thinking more in the context of apps that are in house produced only so third parties won't be creating plugins, and just using for this sort of systems to aid development.
Just use XPCOM.
Thought I'd come in here to help, noticed class derp, lol'd.
Googlemock has a python script to parse the class and generate a mock automatically. However, unless I'm missing something your example doesn't really make sense. How are you going to feed a MockObject&lt;derp&gt; instance to code that expects a derp? Without inheritance mockDerp is not a derp, and even with inheritance you can't override non-virtual functions (CRTP non-withstanding). You should have an interface IDerp and code against it, not against derp directly. This way your mock just inherits IDerp and can be passed to the code you want to test. (If you can't modify the class because it's from a library and really want to mock it, you may have to wrap it somehow.)
I've gotten A LOT of mileage out of Google Mock. It's an excellent testing library.
It not possible in general, without some form of reflection support in the language. So to answer your question -- currently you cant do this in c++. Edit: at least not in portable way ;)
That is true, I guess I am just apply to much personal experience in this situation, since my company is small and has about 10 engineers all in one location it isn't an issue, but if it had to scale greatly beyond that being more independent would definitely add benefits. 
Please ELI not Ken Museth's drinking buddy. 
"efficient storage and manipulation of sparse volumetric data discretized on three-dimensional grids." Can somebody please explain to me what that means? 
No. "Primer PLUS" is not suitable for anyone. Seriously. Read its ACCU review by F.G.
&gt; It's fine on Windows Unless you use mingw. In practice it's actually easier on linux.
Thanks! Can you explain how a lot of data is zero? Because you use pixel data and have a non-rectangular object in a rectangular box? (all other storage methods I can think of wouldn't have a large amount of 0)
You are completely right, it depends on the image data, and how you look at it. I'm not quite sure how it applies to what they do at Dreamworks. My expertise is more with sparsity after a transformation, which we can choose to get the most-sparse representation of the data. This could be the discrete cosine transform for example (used in JPEG). Although an image exists of a lot of different intensities, we can represent it by a small number of coefficients that represent the cosine frequencies you need to reconstruct the image. Thus, we get a sparse representation of the original image. Of course, more difficult and better representations exist. To know more about this you'd have to look at wavelet (used in JPEG 2000) and (related transformations)[http://en.wikipedia.org/wiki/Wavelet_compression#Wavelet_compression]. But now I really moved away from what OpenVDB does. What they use it for is for efficient filtering, discretization of partial differential equations, voxelization of polygons, compositing, etc. Apparently, they store everything in octree-type datastructures, but with varying branching factors to reduce the footprint. They will publish more info in an upcoming paper in ACM Transactions on Graphics apparently. 
# **Fixed your link** I hope I didn't jump the gun, but you got your link syntax backward! Don't worry bro, I fixed it, have an upvote! - [related transformations](http://en.wikipedia.org/wiki/Wavelet_compression#Wavelet_compression) ^Bot ^Comment ^- ^[ [^Stats ^&amp; ^Feeds](http://jordanthebrobot.com) ^] ^- ^[ [^Charts](http://jordanthebrobot.com/charts) ^] ^- ^[ [^Information ^for ^Moderators](http://jordanthebrobot.com/moderators) ^]
One might note that most slides are not yet available and won't be until after the US event, thus December 8th.
This can be useful for C++ linq.... for in-place struct definition
If it can be done via just gcc or clang and visual studio that'd be enough for me.
The python script doesn't work at all for me. All it does is generate this: class A { } Which is totally useless.. Is there some specific way to use it?
How do you you expect them to just deprecate vector&lt;bool&gt;? Just advise people not to use it? That's no better the current solution. The specialisation has to be cut out so the proper functionality can be restored, and (as the author suggests) provide the old functionality via a separate container.
No, not unless it becomes a completely different feature than what we have now. IME the most useful cases for TMP are for computation *with types*, like traits and things like that, which you cannot do with constexpr. Well, sometimes you can, but you get something that isn't any less convoluted than the regular TMP thing. Who the heck uses TMP for actually doing non-type computation?
"kills"? More like "anti-malware software uses system resources for scanning for malware". :)
Common issue. Annoying as hell, especially when dealing with a braindead IT department who sees any request to change the virus scanner as a secret attempt to create a backdoor into their system...
tl;dr Windows 8 is shit. We already knew.
This is actually a problem with any malware/antivirus scanner. On Windows they operate using file system hooks that intercept file operations. Code bases tend to be made up of a very large number of very small files. This means anything that operates on the code like a compiler or preprocessor will be negatively affected. Standard practice should be excluding your code directories. 
http://isocpp.org/blog/2012/11/modules-update-on-work-in-progress-doug-gregor
To be honest this was more or less exactly what I was expecting, lists really are very slow. I what I would love to see as extension to this is comparing an `std::vector` that had be `.reserve(...)`ed against a `std::vector` with a constructed initial size (overwriting their values), and a default initailised `std::vector`. Ideally for both POD's and an ADT like a `std::string`.
Like bob1000bob said, it is indeed a linear search followed by an insertion. The difference with the linear search search is that the vector has to move elements for the insert whereas list does not. In the case where the iterator is already, it would be much faster for a list than for a vector. 
Sure, but the text in this section is misleading. The operation being benchmarked is *not* O(1), and the list is not expected to be faster in theory.
Right. I edited this part. I hope this is better now. 
Automatic linking support. =D
**You should probably debug your own homework assignments. I highly recommend learning how to use a debugger so you can step through your code and validate your assumptions. I'm going to answer this because the bug is not with operator loading, which is presumably your assignment. Your operator overloads work fine. The bug is here: double NumDays::getHours() { hours = days*8; return hours; } Your -- operator only changes hours. You store days independently and do not update it with the -- overload, but the return value for getHours is calculated only using days. Therefore, when you call --test; cout &lt;&lt; test.getHours() &lt;&lt; endl; test.hours has changed, but not test.days, and so test.getHours() resets the value of hours and returns the same old value as before. **In general, getX methods should be const.** They should not change the observable state of your class, and they should only return a value without modifying any internal class members (unless you've explicitly declared them mutable). This guideline will help you avoid similar problems in the future :).
When you use uniform initialization on a `vector&lt;int&gt;` and give it a single int, it does not call `vector(size_type)`. It calls `vector(initializer_list&lt;int&gt;)` with an initializer list containing a single int. His example creates 100000 vectors with 1 element (initialized to 1000) each, whereas the original code created 100000 vectors with 1000 elements (initialized to 0) each.
Isn't that what he did? He called it vector_pre. 
well , I guess we'll have to wait at least 5/6 years to get this...
Poor std::deque, always overlooked...
Lists are very fast if you use them well. A good use case for a linked list is as an ordered sequence of *pointers*: the trick is to put the list pointers inside the object that you want to point to, which gives you O(1) insert and remove and makes search unnecessary. Unfortunately `std::list` doesn't work this way, so it is largely useless. Because linked list are only strong when used as sequences of pointers, a more intelligent benchmark would be `std::vector&lt;T*&gt;` against a good intrusive linked list. I would expect lists to thrash vector for that use case, except possibly for small sequences.
Yes you are right, but still even that is more elegant that the loop.
No, that just constructed the vector with an initial size. I am interested in the difference between that AND a reserved vector (pushing back into the reserved space). 
I do this type of declaration out of laziness far more than I probably should, would you mind giving a quick tl;dr on why it's 'evil' ?
It's true that intrusive lists are sometime necessary, but I certainly avoid them where I can, and encapsulate them behind an interface. I don't see it as a general arguement to say that lists have good performance because you can make them intrusive. 
I think the author's example for move semantics can be easily taken one step further. Internally, the vector moves stuff around instead of copying it, gaining some performance. However, you could get even more performance if you are *aware* of moveability and explicitly move the outer vector "into" the inner vector, as such: vector&lt;vector&lt;int&gt; &gt; V; for(int k = 0; k &lt; 100000; ++k) { vector&lt;int&gt; x(1000); V.push_back(std::move(x)); } Correct me if I'm wrong, though. I'm not 100% acquainted with move semantics.
In a game programming school, a student there once told me "a vector, it's basically a list". I was not accepted for the next year at this school, but oh god, I felt so bad at the time, I was not even in the mood with arguing with the guy. I guess it really demotivated me to see so many dummies around me. In a freaking private game programming school class. Turns out, you can't really teach statically compiled programming language without telling students how CPU runs machine code and how RAM works.
His point is that the old C++ 98 code will be faster because of the move semantics in the C++ library even if you don't change it at all. 
Does the described also occur on Windows 7? Isn't it possible to disable anti-virus scanning for the cl.exe processes?
Yes, it was replicated under VirtualBox Windows 7 clean installation, with active Microsoft Security Essentials. We've already added cl.exe itself, as well as all of its' parent processes from its' process tree and all of the relevant paths (compiler path, source file folders, etc.) to MSE exclusions, but it had no effect.
Anecdotally, on GCC 4.7 (Linux64) I get the following: Initial run: total heap usage: 331,089 allocs, 1,330,575,432 bytes allocated --std=c++11: c++11 total heap usage: 200,018 allocs, 806,291,432 bytes allocated --std=c++11 with move(x): total heap usage: 100,018 allocs, 406,291,432 bytes allocated [edit: this is from Valgrind output, so the "bytes allocated" is total allocation, not peak allocation.]
The **most** common? I'd love to know where you acquired that fact, because if it's true, it's a sad indication of the state of computer programming. List are not designed for random access, vectors are not designed for random insertions/deletions. Anyone who doesn't know that needs to be sacked or sent back to school. There are data structures designed for both these operations, skip lists spring to mind. But less important than having an encyclopaedic knowledge of all the data structures out there, you really do need to know when not to use the ones you're familiar with.
Oh! My bad then. I forgot what the original snippet did. You are correct.
I didn't even know of that new addition to the C++11 std::vector, thanks for pointing it out.
m42a correctly suggested V.emplace_back(1000). Saying V.emplace_back(vector&lt;int&gt;(1000)) would construct a temporary, defeating the purpose.
Well it's a compromise, of course you can't spend so much time teaching hardware if you want to teach game programming, but I really feel it should be an issue where you should spend at least 3 weeks on it, introducing how different container paradigms work out in term of performance. The most difficult is making them understand the (performance/number of lines of code) ratio, since you don't want to waste time teaching them how to achieve perfect optimisation: minimal basics is already a lot of wisdom, and is easier to teach. Limiting the damages is much more accomplishment than gaining a few ms on that game loop. Tougher: how do it ? Well you could start by asking homework by simulating a rpg with N ennemies with different attributes like strength life whatever, and each second: * select 50 random enemies, remove a random value of life from 10% to 50%. * remove dead monster. if there are less than N monsters, fill half of the remaining room with new monsters. See how their program work when they increase N. Basically just try to make them understand what happens with their container choice, and why it matters. You could also use any kind of other example, like the one described in the article.
Thank you for the explanation.
I only use std::deque for when I recognize I might get memory overflows for collecting an unknown amount of output. Well, also I've used it for FIFOs as well (woah, real queue stuff!).
I'm reading it in a phone, but does he tell which g++ version he's using? I suspect that move semantics (if he was using a POD struct for the 1024 case) might have changed the discussion entirely. Also, he doesn't compare the GNU reserve *2 pushback performance vs the Dinkumware pushback *1.6 performance. 
Templates can inherit from their template parameters, provided the parameter is, obviously, a class. Thus, MockObject can be a derp. The following is valid and compiles in VS 2010: class foo {}; class bar {}; template&lt;typename base&gt; class baz : public base {}; ... baz&lt;foo&gt; a; baz&lt;bar&gt; b;
&gt; higher lever data structures To increase your code-torque?
Sorry, I don't. I'm not involved in the conference organization. 
You are correct. Giving a variable a name makes it an lvalue, whereas "variables" that have no names or are `move`d are rvalues. The compiler can optimize rvalues more aggressively since their lifetime beyond the expression they appear in is irrelevant.
I’m slightly dismayed by this. The article says: &gt; two most used data structures are the std::vector and the std::list Is this even remotely true? In my experience, `std::list` usage is practically nil. And if it isn’t, it *should* be: like the article concludes, it’s almost never more efficient than `std::vector`, even on its “classical” strong sides, such as front insertion. And here’s where my dismay comes from: wouldn’t `std::deque` be the much more natural choice here? Without having benchmarked specifically, I’d claim that it should. `std::list` is the odd one out: it’s taught prominently in data structure classes because it’s elegant; but its practical use is waning. Even more so, as @twowheels has noted, with the introduction of move assignment. I can’t find it now but there was a good article a while back which (backed by benchmarks) argued to simply ban `std::list` from one’s toolbox (disclaimer: unless, of course, one knows *very* well what one’s doing).
Also known as "23 things that still piss me off, because my current project is using VS2010"
Gotta say, I'm somewhat hyped for one of these. Does somebody here know when you will be able to buy them?
Yeah the badly used memes really ruined this article for me.
VS2005 and 2008 had way fewer bugs than 2010. 2010 is honestly a nightmare to use. 2012 is an improvement in some respects but honestly it's still frustrating to use. You basically get a better compiler but at the cost of working with an even bulkier and God awfully slow IDE.
I use Emacs anyway so I'm probably insulated from the bloatiness of the IDE. Thanks!
Eclipse is great although the setup can be a bit tricky. It's also multiplatform (Linux, Windows, OS X). I use it because I am in a similar situation to you and I like that I can move between Windows and Mac when working on a project. I haven't used Xcode for C++ but I'm sure it's great too.
I have to ask, why are you so embarrassed about owning a MacBook? That said, I've always have used QtCreator.
I use Xcode primarily myself, but I highly suggest getting TextWrangler (free download.) I swap between the two quite often during development. It's mainly a text editor, but it does have syntax highlighting for multiple languages. You can also open "folders" with it, and bam, now you have a list of individual files on the left side of your screen. My favorite thing about TextWrangler is it can do a similar "Find in files" function like Visual Studio does.
Or Emacs instead, if you swing that way... 
We're still using 2008 on major, major projects and will not be updating to either 2010 or 2012 for just the reasons you mentioned. When any improvements come with such baggage they are not worth it.
Op here; So I have never used the terminal before, I've seen a couple of you here mention that I should use a separate compiler from the editor; What is the difference between doing that, versus using an IDE with a built in compiler?
Right on.
VS2005 was the buggiest one ever when it was released. Remember the Intellisense that would make the IDE unresponive? And the memory leak in iostreams? Fortunately, most issues were fixed later.
Very nice blog post :-)
 &gt;Op here; So I have never used the terminal before, I've seen a couple of you here mention that I should use a separate compiler from the editor; What is the difference between doing that, versus using an IDE with a built in compiler? First off some guys can be a bit obsessed with the command line and the use of text editors. In the end you need to use what works for you! However I strongly agree with the idea that when starting out you are at a great advantage if you learn the command line tools to develop a deeper understanding of what happens behind the scenes with an IDE. So if your programming experience amounts to zip start off learning C++ with the command line tools, preferably from a text that starts off that way. It may be frustrating at first but after a bit you will come to a deeper understanding about what building software is all about. By the way this doesn't mean that you should dismiss XCode out of hand, I would recommend installing it right away along with the command line tools. Further download the free help files that Apple supplies. XCode does take up a surprising amount of space so that may be a concern on an older machine. My point is that it pays off in the long run to learn a bit about the command line approach to building software early in the educational process. By the way, in most IDEs the compiler is not "built in" as you say. An IDE, like XCode or Eclipse is really just an editor on steroids. You get to see the compiler output with in the IDE instead of in a command line terminal. An IDE can effective automate much of the cruft related to development, as much is done behind the scenes. However this is almost meaningless if you are just starting out in C++. Learning to code is a very long process, in the end you have to make the decision as to which way you will go. That is you will have to choose at some point between command line focused development processes or IDE focused. I say focused here because any non trivial development will be aided by the capabilities of both approaches. In other words if you switch to XCode in a year you will still find yourself at the command line from time to time. For example you may need to build a library or work with an open source program that isn't XCode ready. The key is to be open minded and to not to dismiss new techniques out of hand. 
I have been programming with different languages for a while now (Java then Web Programming then Visual Basic and C#) but like you said, I have been using "Editors on steroids" (I like that haha). But Now I want to get into c++ and I'd love to learn how to compile it through the Terminal. Would you recommend anything to help me out with that?
With 2005 I usually just deleted the intellisense DLL entirely because it made the IDE completely unusable and there was no other way to disable it.
I'm calling BS on this whole article as it seems to be contrived to support his argument and nothing more. Apparently he is working with list and vectors containing trivial data types. Admittedly there are cases of these containers containing trivial data types, but such an argument needs to consider objects that these containers might contain in real world programs. Not to mention that just using C++11 might significantly impact the results in any case. In the end I'd want to see the results of real programs using the various containers. 
Sadly most likely. Something is needed though and the quicker the better. Programmers really shouldn't have to deal with the include file mess that we have today. I realize that that mess is in part the result of the technology of the day but this is a new millennia. I do like how this proposal though seems to provide for a clean transition away from the evils of include files. 
Seems awfully complex for what it does. Further could you imagine debugging code using this technique, your records could end up being redefined anywhere. 
Same as it is for every other OS: vim
What is "vim"? 
That will be added on the new version of the article that I plan to release monday. 
I forgot to mention that, sorry. It was GCC 4.7.2. For your second point, is Dinkumware the STL implementation for Visual Studio ? I don't have the necessary tools to make the comparison, but that would be interesting indeed. 
You're right, I should have included std::deque. Perhaps I was wrong about the "most used data structures", that is more the "most taught data structures" or "most known data structures" ? That will be done on the new version that will be published on monday. 
I agree that it is theoretical workloads, but that's the only ones that are easily benchmarked. I'm open to all suggestions to improve it. 
Regexs do have their place, but I would rather use a lexer/parser for anything more than a simple task.
Yes, it is, last I checked. Knuth wrote some proof that their 1.6 reduces fragmentation and was generally better, but the details escape me. I'd google it, but on my phone again. :) With g++, did you compile with -std=c++11 ? Not sure if move semantics are enabled if you don't. 
OK, I am a strong advocate for using a shell, compiler and text editor. A good text editor at that, that usually means Vim or Emacs, I really don't care which but if it helps I like Vim. 1. Firstly it's one of these things that you have to actually build up a rapport with your text editor, once you have done this, there is no going back. And for good reason. 2. IDE's are OK at tying together parts of a toolchain, however the vast majority are really quite substandard at editing text most of them have a click and type style interface, this is good because it gets you going quickly, but not so good in that you are never going to get much better. With a text editor the more you learn about it, the faster you get. 3. An IDE hides your toolchain, your tool chain is very important, I personally want to know as much about it as possible. 4. You might not be now, but if you have to develop over ssh, your going to be thankful you don't have to relearn everything. 5. It's easier to swap parts of the tool chain around. Maybe I get tired of vim and want/have to use something else, no problem the rest of the tool chain doesn't care. 6. IDE's really don't work that well for C++, IDE's admittedly work quite well for languages like Java or C# where every "method" is accessed by '.', which cause the intenseness to open up it's suggestion box, C++ is a much rich language with templates, free functions, MACROS... in my experience it does't work as well. 7. Whilst there are some cross platform IDE's they are often not very good, like the Java based Eclipse (I am sorry but CDT is just slow), many are linked to the platform you are on like XCode and VS, this simply is acceptable to someone who could be asked to develop for a variety of system. 8. What you learn about your IDE for C++ isn't going to help you with pyhton or LISP (for example), you will have to learn new tools, a text editor is language agnostic, it's work just as well for any language. 9. IDE's made ME lazy (the bad kind of lazy) when I used an IDE's I developped completely differently, I would write half of a large function, step through with a debugger making sure it works, write a bit more and repeat. Now with separate tools, I RARELY use a debugger, I try and develop in a style that makes debugging simple with little more than output to console, asserts and exceptions. My functions are much more concise now and my types have much strong separations of concerns, my code is just better. http://www.vim.org/ (I believe OSX might ship with vim, as do many linux distros). http://www.gnu.org/software/emacs/ 
It might have been a typo, but in your first point, what do you mean " you have to actually build up a rapport with your text editor"?
&gt;rap·port/raˈpôr/ &gt;Noun: &gt;A close and harmonious relationship in which the people or groups concerned understand each other's feelings or ideas and communicate well. I didn't actually know it was spelled like that either until I looked it up.
&gt; it's nearly impossible to customize its key bindings There's a "Key Bindings" tab in the preferences window
looks like its google time for you my pal :) I will give a short description but its a pretty deep subject which will take some googling to understand. Vim : It is a comman line (hope you know what that is) based text editor. It is created for speed and versatility. F.x. You will never have to move your fingers away from the "home" row on your keyboard to use it. Its full of shortcuts, hotkeys and functionality. It is very popular because as a native command line program it is very very very light-weight and works well over terminal connections such as SSH. It is not the prettiest editor around, but boy does it get the job done. Shell: Simple terms: It is a set of commands added to the command line to add functionality such as grep (a text string search utility), chown, chmod and more. With most shell adaptions (The most popular one is called Bash) you can write shell scripts which will allow you to automate a shitton of work for you. I use both of the above and more. If you know how to use Vim, the shell of your choice and GDB properly then you are ready to program on a *nix based system :) (which the OS-X is). But it might not be for everyone. Some prefer the bling of a graphical IDE over the purely utilitarian approach VIM, Shell and GDB use. (You might notice I added GDB to the list. If you dont know what it is, it is a comman line driven debugger. If you dont know how to debug, learn it. Cant call yourself a programmer until you do. As a old teacher of mine said : "If you program without knowing how to debug its like taking part in a marathon right after someone cut your dick off.") 
Oh dear. A shell is a command-line interface that is immensely useful for development. Terminal.app is the default choice for accessing it on a Mac. If you've ever written a non-GUI program (Hello World, for instance) you can run it in the shell like a true baller rather than running it in your IDE. I'd recommend looking into basic BASH (the default shell on most systems, including Macs. Vim is a classic text editor that can be run in a shell, or via a GUI (MacVim is pretty swank). Given its terminal-based roots, it relies heavily on keyboard shortcuts and has even has its own command-line mode where you can type in things that are essentially cheat codes to work magic on your text. I'd say Vim is worth learning, but nobody will judge you too harshly if you don't bother. If you decide that you want a lightweight but powerful editor and Vim is too intimidating, I'd recommend looking at Textmate. Looking past its clearly Emacs-inspired design (we all have our faults, after all ;) it's pretty spiffy and exceptionally Mac-ish editor.
Not if the IDE is getting in the way of actually coding.
I know... Have you actually tried to use it? Many bindings cannot be cleared, and assigning a custom binding to something often results in a conflict with no way to resolve them...
Others seemed to have summed it up quite well, but I'll gloss over it all the same * The shell is what you interact with in your terminal, it is used to run and chain together (pipe) programs and direct their out put as well as allowing for automation and scripting. Most systems use Bash as their defualt and some zsh, but there are plenty of others. * vim is a text editor that run in your shell, it doesn't need (there as GUI versions I don't recommend) a GUI everything is done by the keyboard, this make it fast. To get going, simply type `vim-tutor` (then enter) into your terminal, and follow it's guide. Once complete write a basic hello world and save it. The compile with something like: `g++ mycode.cpp` and run with `./a.out`
The answer is almost certainly no. Even if things seem to work initially, you will probably find yourself later with weird crashes. That said, the the DLLs only expose a carefully crafted C interface, and don't, for example, exchange C++ objects across the DLL boundaries, then it could well be safe. In summary it all depends on the DLLs and API, but as a rule of thumb, no.
If you have both VS2010 and VS2012 installed, you can use the VS2010 compiler/linker/libraries (project properties-&gt;General-&gt;Platform toolset), but I suggest you do this for all your project files. As a general rule, it's NOT ok to mix multiple runtimes into the same executable, this can cause very painful crashes.
&gt; List are not designed for random access, vectors are not designed for random insertions/deletions. Anyone who doesn't know that needs to be sacked or sent back to school. As the article clearly shows it is not that clear cut, a vector IS better suited to random insertions when you have to iterate to where to insert first.
You can make the libs/DLLs compatible with different versions of Visual Studio if you do the following. Expose only a C api ( extern "C" { } ) in your DLLs/libs. Also disable "whole program optimizations". Then rebuild your DLLs/Libs. Your libs/DLLs may now work across different versions of Visual Studio (provided you don't run into any issues with the C-runtime).
COM interfaces are explicitly designed to be sharable across DLL boundaries where the DLLs are built with different compilers etc.
I can confirm. I make a lib that follows these guidelines- it's compiled for shipment on VS2008 and works just fine with programs compiled in 2010 or 2012.
Thanks for the great bits of entropy everyone. To be clear, I actually knew about how to make a version-portable library, how to compile with the older compiler from within the new toolset, and that it's virtually guaranteed that VS2012 won't happily work with VS2010 libraries. However, I'm looking for a definitive proof rather than conjecture -- does anyone know of somewhere I can cite or quote that SAYS they can't be mixed? This is more for the benefit of a larger uninformed community beyond myself -- I would never try this craziness personally. ;)
Sorry about that, this was a combination of "don't send to the publisher the day your write it" and "the bug you figure out by explaining". I thought I had removed it quick enough that I could just rewrite it instead of having to elaborate post-factually on the problem. Though, in hindsight, I realize that would have been more sane.
Here are the precise rules: If you include any C++ Standard Library headers, you have to play by its rules, and we intentionally break binary compatibility between major versions (but preserve it between hotfixes and service packs). Any representation changes (including but not limited to adding/removing data members) break binary compatibility, which is why this always happens and why we jealously guard this right. For a bit of history, this has happened between all of: * VS 2003 to 2005 (the addition of _SECURE_SCL security checks and _HAS_ITERATOR_DEBUGGING debug checks requires extra data members) * VS 2005 to 2008 (after I joined VC, my first major fix was for _SECURE_SCL swapping which required a new "aux" object). * VS 2008 to 2010 (massive STL rewrite, and _HAS_ITERATOR_DEBUGGING received a "proxy" object) * VS 2010 to 2012 (we eliminated allocator/comparator bloat from all containers) At some point I eliminated bloat from iterators, but I forget when that happened without looking it up (it was either 2008 or 2010, probably 2010). See the bottom of http://blogs.msdn.com/b/vcblog/archive/2011/09/12/10209291.aspx for my table comparing container sizes between VC9 SP1, VC10, and VC11. So, if you're playing by the STL's rules, you need to ensure the following: * All object files and static libraries linked into a single binary (EXE/DLL) must be compiled with the same major version. We added linker checks, so that mismatching VS 2010+ major versions will trigger hard errors at link time, but if VS 2008 or earlier is involved we can't help you (no time machines). Because the ODR applies here, you really should be using the same toolset (i.e. same service pack level) for all of the object files and static libraries. For example, we fixed a std::string memory leak between VS 2010 RTM and SP1, but if you mix RTM and SP1, the resulting binary may or may not be affected by the leak. (Additionally, you need to be using the same _ITERATOR_DEBUG_LEVEL and release/debug settings; we have linker checks for these now.) * If you have multiple binaries loaded into the same process, and they pass C++ Standard Library objects to each other, those binaries must be built with the same major version and _ITERATOR_DEBUG_LEVEL settings (release/debug should match too, I forget if you can get away with mismatch here). Importantly, **we cannot detect violations** of this rule, so it's up to you to follow it. * Multiple binaries whose interfaces are purely C or COM (or now WinRT) may internally use different major versions, because those things guarantee binary compatibility. If your interfaces involve the C++ Core Language (e.g. stuff with virtuals) but are extremely careful to never mention any C++ Standard Library types, then you are probably okay - the compiler really tries to avoid breaking binary compatibility. Note, however, that when multiple binaries loaded into a single process are compiled with different major versions, you'll almost certainly end up with multiple CRTs loaded into your process, which is undesirable. Bottom line - if you compile everything 100% consistently, you just don't have to worry about any of this stuff. Don't play mixing games if you can possibly avoid it.
&gt; If you have multiple binaries loaded into the same process, and they pass C++ Standard Library objects to each other, those binaries must be built with the same major version and _ITERATOR_DEBUG_LEVEL settings I can confirm this condition from direct experience. * We use one very old C++ third-party library that doesn't use std::string, std::vector, etc. in any of its APIs and that manages its own object lifetimes (Open CASCADE - probably because it was written before these things were truly standard.) We are able to build our application with VS 2012 while linking against binaries that were compiled with VS 2008 and VS 2010 and everything works just fine. * We also use some straight C third-party libraries that were compiled with older versions of Visual Studio - we have no problems linking these into our application. * However, when using more modern C++ libraries (e.g. Qt), some operations will work but we get the expected access violations and crashes when calling functions that pass or return std::string/std::vector/etc., because the internal memory layouts of those objects differ from one release of Visual Studio to the next. For internal development, feel free to try it and see what happens. But I would never ship a product using C++ libraries compiled with different versions of Visual Studio. *Total tangent*: This is one big reason to avoid closed-source libraries - you can't recompile them yourself and you end up being held hostage to the library vendor whenever you want to upgrade your internal tools and process. 
It is homework, is that not ok? I'm allowed to seek help as long as people don't write my program for me. I understand the shell quite well, as well as fork, wait, redirections(which I still have to add), pipes, exec, etc. I actually tokenized the input lines separated by "|" last night, and told my teacher about it this morning. However he told me that was a waste of processing power, and that I should simply loop through the string, replace "|" with 0, and then pass each sub command recursively to my shell, telling it what output to use. I actually preferred the tokenized method as it was more organized and clean. I have this part completely finished, if I pass my shell this information it works flawlessly. My problem is figuring out *what* to pass to it, at least for 2 or more "|" characters. Lets say I have this: echo a | echo b | echo c So first I would call the shell like this: processline("echo a", 0, fd[1], flags); .... processline("echo b", fd[0], NOT_SURE_GOES_HERE[1], flags); .... processline("echo c", NOT_SURE_GOES_HERE[0], NOT_SURE_EITHER[1], flags); On a different note, were you also a CS student at one point? This class(advanced programming in the UNIX environment) is fun as hell, but the teacher is extremely vague in his descriptions.
&gt; It is homework, is that not ok? I don't know, but if you were more upfront it would've been appreciated. &gt; However he told me that was a waste of processing power, and that I should simply loop through the string, replace "|" with 0, and then pass each sub command recursively to my shell, telling it what output to use. That also works, I wasn't following the pattern. This does have the added advantage of processing only what the shell needs to know at the time of execution. However pre-parsing all the commands upfront is a nice way to separate the parsing from the shell execution. I went for the latter trade-off. Anyway, in regards to the rest of your post. Like I said, write a junk program to test a fork/exec, maybe using cat and sort. You will want to use ``dup2`` and manipulate each process stdin/stdout descriptors using the pipe file descriptors. Draw it out on a piece of paper. You won't figure it out by randomly coding. &gt; On a different note, were you also a CS student at one point? This class(advanced programming in the UNIX environment) is fun as hell, but the teacher is extremely vague in his descriptions. Yes I was, and yes, my professor also was vague, because he wants you to figure it out for yourself, probably by reading the manpages for each system call pipe(2), dup(2), dup2(2), fork(2), exec(2). 
When you have homework, it is important to be up front about that and do not ask questions that talks or suggests to somebody doing it for you. I might suggest stackoverflow as a better venue than here – for one thing this isn't even C++ code.
Trust me, I'm all over the stackexchange forums, the c programming forums, multiple irc channels, etc. This is a last resort, my teacher hasn't responded to my emails the last 3 days, I don't know where to get help now. Whether or not it's homework, there's nothing wrong about asking for help, there's no law that says you can't get help, just no turning in other people's work. However, next time I will include that in my original post, I wasn't aware of the rule. I know it's C code, but they're super similar. This could be compiled by a C++ compiler right?
C++ is not strictly a superset of C. However, most of the C language makes it into C++11 for compatibility. The reason why I tell you this isn't C++ code is simply that this isn't doing things the way you would do it in C++. Which is what this forum is about.
I think you found the relevant places. I will forward this question to a person that might be able to offer some suggestions.
ok, first thing my one friend says: I think he's forgetting that each process has two file descriptors open. stdin and stdout. A pipe means connect stdout to stdin. If this isn't enough, I will see what I can do tomorrow.
Replace processline() with several more specialized functions. So have a function that parses the line, then a function that iterates through tokens, and another function that actually does the heavy lifting of creating pipes and spawning.
Don't I also need to connect the stdout from the current command to the stdin of the next command? Is there a way to loop through each command and do it with one(or even two) pipe variables? The only way I could figure it out was by doing this: if((pix = findUnquotChar(line_itr, '|'))) { line_itr[pix++] = 0; if(pipe (fd) &lt; 0) perror("pipe"); processline(line_itr, inFD, fd[1], pl_flags); close(fd[1]); line_itr = &amp;(line_itr[pix]); while((pix = findUnquotChar(line_itr, '|')) &amp;&amp; pix &lt; line_len) { if(pix != 0) line_itr[pix++] = 0; if(fdFlipF) { if(pipe(&amp;(fd[2])) &lt; 0) perror("pipe"); if(!pix) fd[3] = 1; processline(line_itr, fd[0], fd[3], pl_flags); close(fd[3]); close(fd[0]); close(fd[1]); } else { if(pipe(fd) &lt; 0) perror("pipe"); if(!pix) fd[1] = 1; processline(line_itr, fd[2], fd[1], pl_flags); close(fd[1]); close(fd[2]); close(fd[3]); } line_itr = &amp;(line_itr[pix]); fdFlipF = !fdFlipF; } return; } This is a pretty crappy solution as far as I can tell, also I haven't even gotten it to work yet. Is there a better algorithm? THANKS :)
I have a function that parses, and I have a function that iterates through tokens. I could create a function to make pipes and spawning though, that would really clean things up. Thanks.
For each pair of consecutive processes you'll need a pipe, so you'll have n - 1 pipes for n processes; don't try to get away with less. Second, closing the write end of a pipe will make the read end unusable, so you will only be able to close the write end when the reader (process) quits. Unfortunately, this applies transitively, so one process quitting will break the whole chain. You will only be able to close the descriptors when the processes quit. As for your code, I'm afraid I'm a bit too groggy to follow the use of recursion; it seems to me that the while loops will end up processing input that was already processed by the recursive calls. I hope this helps. **EDIT:** You gave this in a comment as a code example: processline("echo a", 0, fd[1], flags); processline("echo b", fd[0], NOT_SURE_GOES_HERE[1], flags); processline("echo c", NOT_SURE_GOES_HERE[0], NOT_SURE_EITHER[1], flags); As I mentioned, for three processes you will need two pipes; I'd store then in slices of the same fd array. processline("echo a", 0, fd[1], flags); processline("echo b", fd[0], fd[3], flags); processline("echo c", fd[2], 1, flags); Since you seem to prefer doing only one pass over the input, this comes with the complexity of allocating an array of the right size (i. e. knowing the number of the processes) or realloc-ing it.
The "here is an alternative"-post is now up: http://blog.knatten.org/2012/11/30/how-to-avoid-includes-in-headers/
I'm about to go to my class, and I'll ask my teacher about this. Then when I get back I'll try it out. Thanks a lot for the tips. Wait, so if you close the write end of a pipe you can't read it? I thought you could, I'm pretty sure I did it in my shell for command expansion. As soon as I was done executing a command and outputting it to the write end of the pipe, I closed it. Then I read it and put it back into my expanded command line.
yep, OCC uses mainly C datatypes, with all the containers rewritten internally. I had troubles with streams anyway, which are seldom used here and there (i.e to save/load a BREP). 
Why no destructor in the C++ Naive and Mature Class Approaches?
[&amp;&amp;name] ?
So, basically, he proposes to use something which moves on copy like auto_ptr while C++11 deprecates auto_ptr ...
Reminds me of *std::ref*. *std::rval*?
That's what I thought so; from the pipe(7) man page: &gt; If all file descriptors referring to the write end of a pipe have been closed, then an attempt to read(2) from the pipe will see end-of-file (read(2) will return 0). If all file descriptors referring to the read end of a pipe have been closed, then a write(2) will cause a SIGPIPE signal to be generated for the calling process. I admit, though, that I don't have experience with Linux/POSIX programming.
Ideally header files only define interfaces, and don't actually result in compiled code themselves, in which case, into whatever form they are compiled, they will still have to be parsed by the compiler in order to create an object file out of a source file. Perhaps a small gain in compile time reading a binary format as opposed to text, if the same options and defines are used and can be reliably identified and represented in the db (both of which are non-trivial), at the cost of db creation, writing, and maintenance, as well as disk space and compilation time for the first run with each option set. I don't foresee that ever being worth the effort to implement, nor being implemented, to use. Besides which, the reaction to a non obvious bug is always going to be "clear cache and recompile" before it is "fire up the debugger". If the header file actually results in code (requested inline funcs not inlined, gad knows what the stl does, what have you) it gets worse, because now you have to put all this specialized database knowledge from the compiler into the linker. Should the linker then know what program was used to create the object file? If i compile with both clang and g++ but only use gnu ld, what's the plan for that? It's been years since i wrote anything in VC(++) but even then, with a monolithic compiler/assembler/linker suite, the precompiled header system (.pch?) was an endless source of heartache and caused more pain than than it saved time. (This assumes an xpain == ytime equation, but for any reasonable values, etc.) 
The difference is that existing implementations of precompiled headers require that there be only one precompiled header for the entire program, and that it must be included first before anything else. The poster's proposal is that these restrictions should be lifted, but that is not realistic for reasons that I've explained.
C++11 lambdas should've had move-capture support built-in, like so: Foo foo; auto lambda = [&amp;&amp;foo]() { foo.bar(); }; But meanwhile: Copy elision is likely to actually catch those copies during optimization. I haven't tested if it actually does in current compilers, but it's a relatively simple analysis to perform for the obvious cases. :)
Hell, we should be perfect forwarding with out lambdas!
Well, it seems to work. The pipe only goes away if there are no fd referring to either end. Now I'm just having trouble waiting on all those zombies I created.
Templated classes must be in headers.
&gt; Templated classes must be in headers. Absolutely not so. You can have the declaration in the header, and then have the body in a .cpp file and use [explicit template instantiation](http://publib.boulder.ibm.com/infocenter/comphelp/v7v91/index.jsp?topic=%2Fcom.ibm.vacpp7a.doc%2Flanguage%2Fref%2Fclrc16explicit_instantiation.htm) within that file to actually instantiate it for the classes you need. I use this technique several times in my current project to hide messy template classes from the person reading the header files. Of course, it only works if you know exactly which class instantiations you need before hand, so it's useless for libraries, but perfectly usable for most other projects.
&gt; Besides which, the reaction to a non obvious bug is always going to be "clear cache and recompile" before it is "fire up the debugger". How often does _that_ work for you?! That's magical thinking in my book. I write C++ every day... the number of times I try that is perhaps once a month... the number of times it works is perhaps once a year.
The new idea here is to not only cache the compilation results but the preprocessor inputs as well. 
Is there any reason why this requirement is not trivially solved by a simple reference? [&amp;foo]() { foo.bar(); };
Returning a lambda from a function. This ~~is~~ would be OK, `foo` is moved into the lambda and returned. std::function&lt;&gt; baz() { Foo foo; return [&amp;&amp;foo]() { foo.bar(); } } This is not OK, `foo` gets destructed at the end of `baz`, but there's a reference to it in the lambda std::function&lt;&gt; baz() { Foo foo; return [&amp;foo]() { foo.bar(); } }
This is only useful if you only want your templates to do their code generation when declared, not when used.
Ok, but the same concept can also work for non-preprocessor things. No matter what the dependencies of a file is, they can be cached. 
Doesn't std::move work by lambda? the capture specification should be 'copy', and inside the lambda the function std::move would be used to move the data.
There is actually a "trick" to do this easily using bind. Consider the following: struct s { s() { std::cout &lt;&lt; "MAKE\n"; } s(const s&amp;) { std::cout &lt;&lt; "COPY\n"; } s(s&amp;&amp;) { std::cout &lt;&lt; "MOVE\n"; } }; int main() { s s_; std::bind( [](s s_) { }, std::move(s_) ); } Output: MAKE MOVE
No problem with that as well. The compiler would simply have to keep a precompiled version of the header that contains the type 'foo' that does not have any preprocessor define for type 'y'. 
y is not a preprocessor symbol. And the compiler *can't* parse the header without a declaration for y, and that declaration may come in the past or the future.
Couldn't agree with you more.
I think it's interesting. Whereas asymptotic complexity is extremely important, depending on how much data you need to work with, a vector can still be much faster than other specialized data structures. I was especially interested in actual benchmarks since Bjarne Stroustrup has said that the vector is the standard container type, and that asymptotic complexity only really starts to matter for really large amounts of data, larger than what you'd often actually work with.
I don't think it's a big change, our almost looks like an oversight, it clearly fills some gap since people are working around it, and the whole point of lambdas is to get rid of trivial function objects.
I'd say you're absolutely incorrect in your assessment. All of them provide very very similar interfaces, the biggest difference between them involves their performance characteristics. In other words, they are mostly drop in replacements for one another since they all provide more or less the same functionality. The choice of data structure to use hence comes down to which of them provides the best performance for your particular use case, which is what these benchmarks are intended to highlight.
Even if the underlying algorithms are different, it does not change that the interfaces are very similar and that a lot of people are not conscious of their performance differences. Asymptotic complexity is clearly useful, I do not deny it, but it is not enough. 
A most interesting benchmark would be gsl vs blas/lapack vs armadillo vs eigen vs std::vector vs std::array vs C arrays for computational stuff
So, comparing STL containers to numerical libraries?
I'm not sure if such an extension would fit into the current C++ rules without demanding yet another exception, of which there are already way too many: [&amp;&amp;foo]() would be equivalent to a temporary functor with declaration (simplified): struct Tmp { Tmp(SomeType&amp;&amp;foo); }; Just because the functor takes an r-value reference doesn't mean that "foo" is one. So for this to work we would need "[&amp;&amp;foo]" to implicitly "std::move(foo)". This raises the "cost" of this design beyond a mere extension...
I am actually about to write a project on this for the generalized eigenproblem, I plan on comparing vecLib to Eigen3 to libflame. I highly doubt that any naively handwritten DGEMM or eigensolve could even come close to these libraries even if using std::vector or std::array. This project is due by Dec 17th so I will try and make a post later in December outlining my results. 
Isn't that in fact the point? To illustrate with actual performance numbers the theoretical differences in the data structures/algorithms? I didn't think the article implied that it's apples to apples. Obviously there are no surprises in there to anyone familiar with which data structure is modeled by each container type. But to someone not so familiar, it's useful information. (For example, I wasn't familiar with a std::deque before reading the article, but now I feel that I have a good grasp on how it works and when it should be used.) The fact that, for example, std::lists are slower to sort until their underlying data type becomes large is also an important concern that might be overlooked by someone without a lot of experience. Of course, if you understand the theory and what is going on "behind the scenes", you can predict this. But not everyone has that knowledge and articles like these can be quite edifying (especially since the author took the time to provide actual benchmarks). 
It's not just defines and typedefs that must be tracked, it's all declarations. My original example showed this, because y could be a function or a type. You have to track everything that the header says, not just select parts. Look, build times of large C++ projects have been an issue for at least two decades. If fixing it was as easy as "just treat every header as precompiled" then someone would have implemented that and made a lot of people happy. But they didn't, because they can't, because the problem is much more difficult than it seems at first. And *that* is why you have very smart people like Doug Gregor who have extensive experience in the complexities of parsing C++ proposing sweeping changes to the language to add modules rather than proposing "just cache things". 
In your example, v1 and v2 have different types. You cannot say: v1 = v2; if (v1 == v2) ... swap(v1, v2); or, most importantly void f(const std::vector&lt;T, alloc1&gt;&amp; v); f(v2); // Argument type mismatch So why is it so important for two vectors (or lists or maps, etc.) to have the same type? It helps if you think about large programs, not toy examples. Suppose you have some sort of data-collection library that has a function: int findElements(std::map&lt;int, std::string&gt; *m, Filter f); This function reads some data input, filters it according to some specific criteria, inserts matching elements into *m, and returns the number of elements inserted. You call the function like this: Filter myFilter1("name = Jack"); Filter myFilter2("name = Jill"); std::map&lt;int, std::string&gt; myMap1; int numFound = findElements(&amp;myMap, myFilter1); numFound += findElements(&amp;myMap, myFilter2); assert(myMap.size() == numFound); Now I want to control pool from which myMap gets its memory, so I create an allocator template that allocates memory from a contiguous buffer: template &lt;class T&gt; class MyBufferAllocator { ... }; and I use it to instantiate a map type: char buffer[BUFSIZE]; typedef MyBufferAllocator&lt;std::pair&lt;const int, std::string&gt; &gt; MapAlloc; MapAlloc alloc1(buffer, BUFSIZE); std::map&lt;int, std::string, std::less&lt;int&gt;, MapAlloc&gt; myMap2(alloc1); But when I try to use my map-with-allocator, this code doesn't compile: int numFound = findElements(&amp;myMap2, myFilter1); // Oops, type mismatch How do you solve this problem? You can try this: template &lt;class Alloc&gt; int findElements(std::map&lt;int, std::string, Alloc&gt; *m, Filter f); But there's a **big problem**: 'findElements' is about 100000 lines of closed-source code. You do **not** want it to be a template! Using type-specific allocators gets very messy very fast. Using bsl, you would simply replace the 'std' types with the 'bsl' equivalents: int findElements(bsl::map&lt;int, bsl::string&gt; *m, Filter f); class MyBufferAllocator : public bsl::Allocator { ... }; char buffer[BUFSIZE]; MyBufferAllocator alloc2(buffer, BUFSIZE); bsl::map&lt;int, bsl::string&gt; myMap3(&amp;alloc2); int numFound = findElements(&amp;myMap3, myFilter1); numFound += findElements(&amp;myMap3, myFilter2); assert(myMap3.size() == numFound); Note that neither MyBufferAllocator nor findElements is a template. This code almost as simple as the original code, you've added no new templates, you've preserved separate (closed-source) compilation of findElements, and you've ensured that not only is every element of 'myMap' allocated from 'alloc2', but the contents of all of the strings within 'myMap' are also allocated from 'alloc2', because BSL allocators are both polymorphic *and* scoped. king_duck Wrote: &gt; And for the case where you want 1 allocator for two types can't you just use some thing like &gt; &gt; std::scoped_allocator_adaptor Scoped allocator solve only half the problem, that of controlling the allocator used by the *elements* of a container, but they do not make a container's type independent of its allocator type. (When originally proposed, scoped allocators were supposed to be polymorphic, exactly following the BSL model, but that's a long story. I'll be proposing polymorphic allocators for a future standard.)
vector doesn't have push_front() at all, because the STL tries to avoid encouraging inefficient code.
As a hobbyist programmer, in the sense that my day job function doesn't revolve around coding, C++ is my go-to language because I feel more comfortable having access to low-level hardware with a language that provides sufficient high-level abstractions. To be fair, if I do any work-related programming, it's usually Linux systems-level stuff in C to explain concepts to my team, so C++ would naturally be one of my choices when I want to "relax" and write code in my free time.
I come from a C++ background. In college we wrote a web site that presented the user with a table, and allowed the user to add new values, modify current ones, delete rows. It then synced the table to an SQL server, really basic stuff. It's around 5 minutes work in C#, in C++? I don't even know. I know of one C++ library that's around 2 years old that gives you similar functionality, but that's definitely not C++'s domain. How about a Java client that talks to a Java web service? That sort of 'Enterprise' stuff is so natural in Java, it's a breeze. In C++ there's a lot you need to consider before you can begin designing such a project.
I'm watching these right now... [Michael Caisse: Introduction to Modern C++ Techniques (Part I)](http://www.youtube.com/watch?v=9TFV2JxX7L0) [Michael Caisse: Introduction to Modern C++ Techniques (Part II)](http://www.youtube.com/watch?v=urshrBatNo4)
They are indeed pretty awesome, in general, also all the c11 videos/conferences.
I find it kind of sad and terrifying how much people are still in the "C with Classes" mindset. Just how many of the commentators of the original article went on and on about how "low-level" and "manual" memory managment supposedly is in C++. How there is no garbage collector. They just don't get it (sadly). Memory/resource management is *automatic* (and deterministic) by default in C++. A garbage collector in modern C++ is entirely superfluous. Only if you explicitly ask for it ("new") is control manual. One of the commentators even sad how "wrong" it is for a language to have both high-level abstractions and low-level facilities. Great, now morality is entering the equation? That said, the (original) article raises many valid points. Much of the existing code in C++ is terrible. But not worse than if it were C. C++ has its uses, and they are manifold, but I don't thing Herb Sutter's evangelism is always believable. Aside from that I love and respect him to death for the things he has done for standard C++.
Right, my bad — it's called `v.insert(v.begin(), value)`. ;-)
I figured it out. It was quite embarassing. The file with the int main() was not added to my solution formally. oops :|
The fact that the standard library doesn't include something is not really a show-stopper. A couple of days ago, I implemented a WebSocket server with boost.asio. It took me more time to understand the relevant RFC than to implement it. In java, without unsigned ints, packed bits, without lambdas (for the time being) etc. I don't even want to imageinw what the code would look like.
This is why I rarely trust operator precedence except in trivial situations. Brackets everywhere...
A better explanation is on the wikipedia page: http://en.wikipedia.org/wiki/Operators_in_C_and_C%2B%2B#Notes If you want to be pedantic then talk about the formal grammar, not precedence.
Well the brackets you've included in your "*extreme*" example are actually entirely redundant and would never do anything regardless of precedence **unless** you're writing a macro in which case they should **absolutely** be included or you have a macro with unreliable/undesirable behaviour. For example consider: #define NEW_MACRO(c,d,e) c(d+e) and I use the macro like: a[b]=NEW_MACRO(2+4,-8,12); this expands to: a[b]=2+4(-8+12); Which yields the answer 18, rather than the correct: #define NEW_MACRO(c,d,e) (c)((d)+(e)) Which yields the correct/desired answer of 24. I'm talking about writing: a[b]=((int)c)(d+e); rather than a[b]=(int)c(d+e);
A few days ago someone posted the slides for Doug Gregor's talk. Now with the video you can actually understand them. I have to say that I still haven't fully grasp how modules supposed to lower the include overhead, isn't including stdio or importing std.stdio results in the same size?
Can someone explain why true?x:y=5; would leave both x and y as zero? If it's consistent with true?x:(y=5);, y should be 5, no?
I think it's over of a case of flame vs PLASMSA vs MKL. Aren't most of the C++ LA libs just wrappers around a vendor LAPACK &amp; BLAS lib? PS: if you need any help with PLASMA let me know I use it a fair bit.
because y=5 is never evaluated. since true is always true, 'x' is simply evaluated as an expression and does nothing. It's pretty much the same as: if(true) x; else y=5; Or were you referring to the fact that the parenthesis don't get executed first? I may have misread your comment.
Yea, I forgot that the ternary operator uses lazy evaluation! Thanks!
Ah yes. I was doing Physics IRL. Good thing I was just commenting about code and not writing it... xD 
Seriously people, just use if (var) x = 5; else y = 5;
It's required, or else every null pointer check in code would break. Eg: if (pX != null &amp;&amp; pX-&gt;value &gt; 10) { // don't crash }
 var ? x = 5 : y = 5; this is concise and everyone understands it. But it's a dumb example.
FWIW, PC-lint/FlexeLint flags the code: true?x:y=5; ternary-test.cxx 9 Warning 1563: Suspicious third argument to ?: operator
Seem's interesting, but I can't find a download link. The sdk and library links are down. edit: The download link is in the text. I can't find how to register to the Bolt forum. 
I'm sure all of us familiar with C++ would agree. However, all the articles bashing C++ are coming at things from a different perspective. As well as the general C++ language bashing, complaining about lack of library support is their favourite pastime. If I needed to implement a webserver myself I would indeed turn to boost.asio (or even one of the many other possibilities out there). The point is that this is non-obvious for the beginner and even with the required knowlege about boost etc. it still takes time to setup. Compare that with just including a reference to a built in library and off you go. It's also interesting that Herb Sutter is blogging about a slimmed down C++. There really seems like a lot of energy behind C++ at the moment. Personally I do think it's time for C++ to take a leap forward again with the same impact as when we all moved from C to C++ originally. I think there is a ton of untapped potential for compile time computation, even if it's used for code integrity checks (static_assert is the mere tip of the iceberg). Metaprogramming needs to be explicitly supported and needs to be much more powerful. C++ does need to catch up with managed languages when it comes to convenience, but that is not enough. It needs to leave all the others in the dust - just like it did originally! :-)
Aha, it's a [C++11 feature](http://www.cprogramming.com/c++11/c++11-nullptr-strongly-typed-enum-class.html) I wasn't familiar with.
Updated: http://yapb-soc.blogspot.com/2012/11/arrows-and-kleisli-in-c.html
Updated: http://yapb-soc.blogspot.com/2012/11/arrows-and-kleisli-in-c.html
I feel the whole including header files issue is overblown immensely. Maybe 3-4 years ago I remember trying to be super strict about include files thinking it would speed up build times etc... it didn't have much of an effect. I mean it might have provided some speed ups but nothing dramatic that it was noticeable and worth the cost of keeping track of all the rules or using Pimpl idiom. Now I've actually taken the complete opposite extreme, and all my files are header only. The absolute convenience of not having to build a library and just being able to include a file and get its functionality without any additional build complexity outweighs the small performance benefit there may or may not be.
(what is wrong with conditional expressions == nothing) ? That's right I use them all the time, bitch. : throw(FUQ); 
That is not even in the article... I assume you are being sarcastic right? If not, I have nothing against ternary operators, I have something against dubious code that makes me think (about semantics of syntax)
I agree with you completely. I love when a library is just an include away, while the others can make me scratch my head a little...
Well, the code I work on is &gt;5 million LOC and comprised of 500+ shared libraries. Cross compiles to both Windows and multiple flavors of Unix. No hand-crafted makefiles to be seen (on Unix, the per-project makefiles simply forward to a standard makefile template). We don't need an all-encompassing solution file because nobody in their right mind builds the entire "solution". The nightly builds execute a script that simply traverses the canonical list of projects. Maybe I've misinterpreted what you mean by "hand-crafted"...
I try to avoid private methods, and instead use anonymous namespace functions in the cpp. This means you change the header less when developing (hence faster builds), and avoids the need to have extra forward declarations and includes in the header file. Yes, pimpls work well, but I try to avoid them because the extra level of indirection can be annoying. They have their place, however. Also (I hope I'm correct on this), template classes don't need includes of classes used inside the methods defined in the header. This is because they aren't compiled until they are instantiated. So the includes need to instead be in the cpp file that instantiates the template. 
Now that is awesome. I wonder what kind of compiler errors this produces, for example given a tuple of several types, with one of the types undefined ;)
It's certainly true that C++11 hasn't suddenly become better than Java or C# at all the things that Java and C# are best at. At the same time, there are quite a few tasks for which none of Java, C#, nor C++03 was a clear or obvious choice (but for which none was obviously drastically inferior either) -- any of them was going to have some advantages and some disadvantages. For many (though certainly not all) such situations, if C++03 was even marginally competitive, C++11 may be an easy choice. I should add one more thing though: especially in the case of C# (and .NET in general) for a long time the biggest advantage was *not* anything inherent to C# or .NET itself at all -- the big advantage was simply that it was the choice that got the most support from Microsoft. At least for people who are targeting Windows, the simple fact that Microsoft isn't treating C++ as a third class citizen rather quickly makes it a much more attractive choice all by itself.
You're correct on your third point, although they still have to be declared so the compiler knows they're types. If (for example) you want to use istreams you still need to include `iosfwd` but not the full `istream`. EDIT: And obviously, this only deals with things that use the templated type. For example: #include &lt;iosfwd&gt; template &lt;class T&gt; class foo { void bar(std::istream &amp;in) { int i; T t; in &gt;&gt; t; //Works in &gt;&gt; i; //Doesn't work } };
&gt; I love when a library is just an include away Me too. Because external libraries rarely change. (By "rarely", I mean "less than once a week".)
To the best of my knowledge flame is optimized for Goto2 blas normally, but can link to what ever blas you have. I think Flame and Plasma have similar goals as in lets improve upon Lapack. I don't really know too much about eigen except that it is an option. I don't have MKL on my laptop and am not interested in getting it since the systems I am interested in eventually running on aren't intel. Finally the real bottle neck I have in writing this isn't so much the LA libraries, but the application. I am using the packages to run Hartree Fock (chemistry application). I also plan to write a Hartree Fock using elemental for scalable code. 
A parser has to work that way. Once it consumes the ?, it should shift into a state of building an expression until it hits the : for a reduction. 
By "hand-crafted" all I mean is the make file/make system is created and managed by a human rather than by the IDE. In a tool like Visual Studio the making of the system is totally managed by the IDE, but that can cause issues for large system made up of large numbers of projects and files.
Why avoid forward declarations?
While I'm all for people writing blog posts, I think the Pimpl Idiom has kind of been beaten into the ground by now. Let's advance the state of things: for instance, at the end of his article he talks about how normally a generic class can't use this pattern, but he'll talk about how that can be overcome *in his next article*. How about writing that next article now, and just adding a paragraph at the front saying "This is about advanced uses of the Pimpl Idiom. If you don't know what that is, here are some resources that have existed for a decade."
What™ does™ this™ do™ that™ [thrust](http://blogs.amd.com/developer/2012/12/04/bolt-gpu-acceleration-for-your-c-application/)™ hasn't™ done™ for™ several™ years?™
Licensing and how does this differ from AMP?
That's the point. The ?: have to match up the same recursive way that [] and () have to match up. By the placement of the two operator symbols, the programmer is already forced to be explicit about the scope of the contained operand - in ?:, as in [] and ().
I've worked for companies that have invested hundreds of thousands of dollars in static analysis tools, code refactoring tools, and all manner of IDE plugins. Why have I never seen a tool that can accurately and simply generate a list of unnecessary header includes, and/or a list of classes that can be forward declared? I can only assume it's a much more difficult problem than it appears to be, or else it would be built into our refactoring tools already. Anyone have any insight as to why this is so difficult?
you are right in most cases however if rhs is not just "5" but some complex expression - I would not like to write it twice... so i would use my version....
Yet neither that one nor this mention the main use that Qt and KDE have for the pimpl: Binary Compatibility. For more information, see the [Qt documentation](https://qt-project.org/wiki/Dpointer) page and [KDE's](http://techbase.kde.org/Policies/Library_Code_Policy#D-Pointers).
I'm confused here. Since you're replying to my message, you're talking about Sutter's article, right? 
This is correct. A header should only include other headers that are needed for the API it exposes. If their implementation depends on other types, they should be included in the cpp.
Functions defineds as `inline` are allowed to be merged into a single function at link time. Methods defined inside of a class definition are implicitly `inline`.
Author here. If it is not clear from the article, the code described is not a complete implementation of such a tuple (far from it). It is merely a first step, which is to compute the final intended layout. For what is worth, I have written a full implementation here: https://bitbucket.org/martinhofernandes/wheels/src/3bde0eaa9f56a6c8714f76ef56924eb0e41de6fa/include/wheels/tuple.h%2B%2B?at=default. The code in there is probably hard to follow, and is very inefficient because it was written only as a proof of concept. If you want to see an article that provides anything resembling benchmarks, that will have to wait until I am done writing the series. If you are interested, you can [play with the proof of concept](http://www.stacked-crooked.com) online. Here is the simplest example I can think of: http://www.stacked-crooked.com/view?id=38eb85843f422b5a235ce2a84e6cb3d8 (and there you go, your first benchmark) EDIT: link to playground
wheels::tuple does this sorting by alignment, right? That's significantly better than the worst one could imagine. Pretty good, pretty good.
Tutorials?
Crap article. There is not a single fucking reason why you would _need_ to avoid includes in headers. 
Please newbies, stop writing these new "rules" and "considerations". Accept that you know nothing about programming until you have 2-3 million lines of code behind you. In fields where you write other things than fuck with other code. At hardware-/human-interface, the rules change and rest of the code must adapt. If you do not understand what code does, or it seems terribly complicated to you. It is your fault, not the former coders. If the compiler eats it, it works as intented and someone _competent_ in the language can read it, it's fine and perfect. Just out of spite, I'll start using goto's again to bail out of complex I/O and allocation stacks to cleanup. Nowadays the novice coder doesn't even know _why_ they should avoid goto. It's because of assholes parrotting an article for a decade, which' intention was not even to _forbid_ using goto. Just to use common sense with it.
Exactly. I recall in late 90's I actually sped up compilation quite a lot by optimizing includes. This was with ancient Borland C++ builder that could not even optimize or cache search paths. Nowadays, it means exactly dick where you include as long as you have all the forward declarations you need.
Great.
Supports OpenCL (I haven't looked at thrust in a while, but last time I did it was CUDA only).
m_pImpl
How do anonymous namespace functions work with private class data?
Yes it does.
.ƃuıʞoɾ ǝq [ʇsnɯ](https://www.google.com/search?q=operator+precedence) no⅄ 
Interrupts are implementation-specific, so every compiler deals with them differently. You've probably have better luck looking at the compiler documentation, or any officialish forums you might find.
&gt; Declaring the same construct multiple times Wait. What?! Where do you do this? There are no multiple declarations. All you're doing is _forward referencing the names of classes._ That's it. You're simply telling the compiler, "This symbol is a class." Where's the fragility there? Every big C++-using organization does this - and most small ones including my own.
What advantage is that?! Most header files only have a few forward references to classes - you can put them right in the header file and it's very clear what's going on. On the other hand, my medium-sized personal project contains forward references to over a hundred classes. Corporate codebases will have thousands... And you pollute _every_ compilation unit with a forward reference to _every_ class that has a forward reference anyway.
You don't need a million lines of code to see the benefits. My personal C++ codebase is just over 40,000 lines of code total - and I'm very strict with using forward references if possible. I found a few large header files that were included in a lot of places and changed quite a bit, and used forward references (and a little splitting) to prevent them from being included. Net result - when I now change these files my compilation time is a few seconds instead of a few minutes - enough time I don't have to context switch to another problem.
Older than Cinder. Kind of average library design.
No namespaces and prefixed functions/classes in 2012!?
"in descending precedence. 1, 2, 3, 4" The definition of "precedence" in C++ is obviously messed up :D 
Why would an [ALGO](http://en.wikipedia.org/wiki/ALGO) coder be interested in a C++ book? ;-)
&gt; "Although we don’t know yet the quality of the booklets," we definitely do know the quality of their cover art. I hope there is an inverse relation between their graphic design knowledge and their C++11 knowledge.
Seriously, these covers, especially the left one!
I think his point was that with a private member function, you have access to private member variables of the class, whereas with an anonymous namespace function you don't automatically. For helper functions that don't need to use any of the object's private state there's no problem, but if you do need it you either need to pass it and return it in the parameter list or make the anonymous function a friend of the class (which kind of defeats the point, since that's going to disturb the class definition like the private member function would).
The one on the right is the main sample from the PGF/TiKZ manual.
In defence of the authors, this book isn't intended for competent, intelligent users. It's more for the students of the hundreds of cs mills in India that still teach C++ using Turbo C++. Furthermore I'm quite disappointed that the newly minted ISOCPP site has little to no standards when it comes to content submission. 
That cover is cool and reminiscent almost of an r crumb comics style. These look like they were created by a young seapunk who just opened the Gimp for the first time. The upside down reflected text, aliasing, illegible fonts ... I really hope the booklets are awesome and prove the adage about not judging books by their cover. 
There is also a pun in there. Barbra *Moo*, with a *Cow* in the background. Anyways the book is very good. Another [bad cover](http://www.amazon.com/Standard-Library-Tutorial-Reference/dp/0201379260) is here
I've been learning from C++ Primer 5th edition, which as far as I know is the only book that's for beginners that's been thoroughly updated for C++11. It's very good.
There’s actually quite a decent [Wikipedia page about C++ 11](http://en.wikipedia.org/wiki/C%2B%2B11), which is mostly a list of the differences from the earlier standard. How immediately useful this will be if you don’t already know C++ in some detail is debatable, though. In practice, many of the smaller changes in C++11 are there to clear up common irritations or to close awkward gaps in the earlier versions, so these won’t make much difference to anything you learn from tutorials based on those earlier C++ standards and you can probably pick them up as you go along. There are a small number of much more significant changes as well, which obviously won't be covered by older tutorials or reference materials. For one thing, that means the workarounds we used to be stuck with are no longer necessary if you can use the dedicated features from C++11, so some of that older material would be obsolete today. There are also some completely new language features like the lambda functionality and type inference that are probably going to be game changers in how “typical” C++ is written. In short, you’re probably better off with up-to-date tutorial material if you can find it. If not, I don’t imagine the sky will fall if you learn like the rest of us, starting with material based on the earlier standards and then picking up the recent changes afterwards. It might not be quite as efficient, but you’re not going to accidentally delete the universe or anything.
There's always [BugMeNot](http://www.bugmenot.com/view/ssl-developer.amd.com) if you only need to log in to download something :)
C++11 _adds_ stuff on top of 98, and makes some old idioms/patterns/ways of doing thing obsolete, but since C++11 will be _the_ C++ standard for at least another 4-5 years, it's what you should be eventually competent in.
The reason for including MKL is because it is generally considered as the reference "vendor library". Any way, looking forward to any future article on the matter.
(a) Stay away from std::auto_ptr. Use std::unique_ptr instead, as it has none of the disadvantages of std::auto_ptr. (b) Returning complex objects such as std::vector or std::map is no longer in danger of being slow (because there are move constructors now). So don't do this: void foo(std::vector&lt;int&gt;&amp; result) { result.push_back(1); ... } Instead do this (unless you need to add to an existing vector of course), it won't be slower: std::vector&lt;int&gt; foo() { std::vector&lt;int&gt; result; result.push_back(1); return result; } Or (in this simple example it's possible to initialize the vector directly): std::vector&lt;int&gt; foo() { return { 1 }; } 
nice the article about the phisical memory :) "In other words – even if every memory cell can be represented by a single atom, we would need 1 to 10% of all the stars and planets which we can see (with most of them being light years afar), to implement 2^256 bytes of memory. Honestly, I have serious doubts that I will live until such a thing happens." never tought about that!
Doesn't seem like the slides for most of the Keynotes are available 
Will LLVM implement this as well? :O
Read the article. The point is not auto. But auto foo() { return X; } vs. auto foo() -&gt; decltype(X) { return X; } Which is quite a pain and makes auto as return type almost useless because you end up writing the function twice. And auto returntype already works for lambdas so why didn't they add it in C++11. http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2012/n3386.html
Or, since we're highlighting new C++11 features: std::vector&lt;int&gt; foo() { std::vector&lt;int&gt; result; result.emplace_back(1); return result; } Probably doesn't matter much for a simple int, but for complex types, it will save you a copy/move.
Probably, but I, and I think many others, would find the static if more intuitive and perhaps less error prone. Besides, would you rather write one function or two?
Except building from source of course.
Why not? -march=native is a real blessing
I wouldn't use emplace back for that use case (it has no benefit over push_back, unless you are inplace constructing). That said you could better write foo simply as std::vector&lt;int&gt; foo() { return { 1 }; }
I think there are currently two good ways of learning C++, 1. Pick up the C++ Primer 5th edition, but be warned, this book is very long and teaches from the bottom up, so you really have to read it all to get any real benefit from C++ http://www.amazon.com/Primer-5th-Stanley-B-Lippman/dp/0321714113 2. Get a copy of Accelerated C++, this book is shorted and in my opinion a better book as it teaches from the top down, it also leads really well into other books like Effective C++, however it does not cover C++11 so you will need to pick the additions from various sources (Wiki, Bjanes site, cppreference have you covered). http://www.amazon.co.uk/Accelerated-Practical-Programming-Example-Depth/dp/020170353X My personal preference lies with AC++, but the Primer is good if you think you can finish it.
That's what I miss about running a Gentoo box.
True, but isn't that one scheduled to be mostly about housekeeping? They don't plan to introduce anything groundbreaking in terms of new features or syntax, no?
&gt;you might end up recompiling As far as I know it's not just might. You compile gcc with your native compiler and then gcc recompiles itself, so it would have all the compile time optimizations that come from the new version. &gt; -march=native Optimization for your specific cpu family. It makes binary somewhat faster, but it's not portable, so you can't upload it to a repo for every cpu to use.
To extend on what you said, imo the more important relaxation is allowing multiple returns (which article doesnt delve into much): auto foo() { if(bar()) return X; return Y; } Its really cool feature, hope they manage to push it to tr2 (slim hope, but still).
Is it just me, or this provides very few actual decent arguments in favour of C++? I got the impression that the poster does not really know C++ (mentioning smart pointers as something new is something that always rings warning bells to me). Anyway, I just had to laugh at this remark: &gt; Especially bit twiddling (which I assume pays better). 
It's really not that big of a deal. You can significantly reduce build time by disabling the bootstrap and disabling multilib. The former means that you use the existing compiler to build gcc and that's it. This is fine if the existing compiler was already a recent version of gcc; the bootstrap is mainly meant for the situation where you have a vendor compiler that you don't trust, and you want to make sure it has no influence on the final product, so you use it to build gcc and then use that gcc to build another gcc, and then use that gcc to build another gcc, and compare the object code of the last two to make sure it's the same. Disabling multilib means you can't build 32 bit code on a 64 bit host, but that's usually not an issue, and it saves the work of having to build all the target libraries twice (libgcc, libstdc++, libgomp, etc.) You can always enable it if you need that. MPFR and GMP are both packaged by most distros, so you can just install the -dev packages. Here's an outline sketch: # adjust to taste (if you choose a dir with spaces, adjust quoting) basedir=$HOME/tools/gcc version=4.8-20121209 set -e sudo apt-get install libmpfr-dev libgmp-dev mkdir -p $basedir $basedir/build $basedir/inst cd $basedir test -f gcc-$version.tar.bz2 || wget ftp://gcc.gnu.org/pub/gcc/snapshots/$version/gcc-$version.tar.bz2 tar xf gcc-$version.tar.bz2 cd build ../gcc-$version/configure -C --enable-languages=c,c++ --disable-bootstrap --disable-multilib --prefix=$basedir/inst make -j2 make install export PATH=$basedir/inst/bin:$PATH if [ -n "$LD_LIBRARY_PATH" ]; then export LD_LIBRARY_PATH=$basedir/inst/lib64:$LD_LIBRARY_PATH else export LD_LIBRARY_PATH=$basedir/inst/lib64 fi On a virtual machine with only 1GB RAM this takes less than 8 minutes all said and done. (If you do have more RAM, you can use a larger -j value which should speed things up considerably.) (Edit: oops, forget the /inst on some paths.) 
I usually get a .dsc file for 13.04 with dget and then use it to build a .deb package on my 12.10 machine with debuild (disabling the test suite first somewhere in rules.defs). This process produces a deb package installable on 12.10 (i.e. it doesn't complain about dependencies found only in 13.04 anymore). There are some examples of how to do that here: https://wiki.ubuntu.com/PackagingGuide/HandsOn
Uhhm, as far as I know for gcc to use optimizations inside gcc code (faster compile time of other applications) you need to build it with some build flags. Ofcourse there's -mtune=native which optimizes for your cpu family, but still runs on different cpus. The thing is, it adds extra logic (if, else and friends) for generic cpus. So in the end you get bigger binary which takes longer to execute.
I just added a practical example in the consecutive post, how to read a text file with any encoding using qt streams.
Very awesome. I'll build the snapshot tonight and play around a bit :-)
Expected&lt;T&gt; is not a monad, doesn't really behave anything like a monad. It's more just a wrapper over a sum type. If anything, one of my biggest frustrations with boost::optional&lt;T&gt; and I guess also Expected&lt;T&gt; is that the type system isn't being used to ensure correct usage, so you basically run the risk of misusing it and then having your program crash at runtime. The way one can fix this in C++11 is exactly by making Expected&lt;T&gt; or optional&lt;T&gt; behave a lot more like a monad. Basically you can not get direct access to the underlying value, but instead must pass in a function that takes a single parameter of type T. If the optional&lt;T&gt; is initialized, then it will invoke your function with the underlying value, otherwise it will do nothing. You could extend this somewhat with Expected&lt;T&gt;, but having it take two functions, one function to call if the operation succeeded, and another function to call if it failed, and it can pass in an std::exception reference to the failure function. Now you have something that looks a lot more like a monad (although still far from it), and you're using the type system to ensure proper usage. Expected&lt;int&gt; result = someOperation(); result.With( [&amp;] (int value) { std::cout &lt;&lt; "Passed: " &lt;&lt; value &lt;&lt; std::endl; }, [&amp;] (std::exception&amp; failure) { std::cout &lt;&lt; "Failed: " &lt;&lt; failure.what() &lt;&lt; std::endl; }); 
Yes, I thought it was an unfair comparison because boost::optional and the other derivatives from Maybe mentioned are derivatives from *Maybe*. To claim that Expected is a better Maybe demonstrates ignorance of what Haskell coders actually use for the desired behaviour. I agree that Expected is most similar to Either, but without supplying some form of monoidal composition (definition of a monad), it isn't a monad (unless I stopped watching too soon). However, it could be one if this was defined.
I guess I didn't really mean "error" in the compiler error sense, but I did mean coding-practice-wise. Other than the ones you mentioned, I can't think of any specific examples off the top of my head, but the changes from "sequence points" to "sequenced before" and "sequenced after" have removed ambiguity from some minor expressions.
I wish that Ubuntu's GCC team would actually update the gcc-snapshot shipped with Ubuntu regularly or at least provide an official PPA for it. Currently the gcc-snapshot package is only updated when a new Ubuntu release is rolled out (every six month).
&gt;Yes, I thought it was an unfair comparison because boost::optional and the other derivatives from Maybe mentioned are derivatives from Maybe. To claim that Expected is a better Maybe demonstrates ignorance of what Haskell coders actually use for the desired behaviour. I think that's not quite the case. Either T String gives equal semantics to its two "branches" T and String, whereas Expected&lt;T&gt; behaves quite differently for its expected vs. unexpected branch.
expected&lt;T&gt; is indeed a monad. It effectively has the same interface as Maybe T from haskell, and with a few operators (or global functions) defined, expected&lt;T&gt; would make a totally fine monad. Maybe those global functions aren't defined yet but what's stopping us from doing it?
But now you're back to Go's style of error handling: You always have to check the returned value for an exception (of course you can always just use value.get() -- but this is just standard exception handling style). It's not very useful unless you can chain functions and have them fail automatically if their input failed (without explicit checking). It does let a library author support both exception style and error-values-style using the same code -- so maybe that's an advantage. 
On slide 22, is the last *std::swap* really needed? Surely both *gotHam* and *rhs.gotHam* are *false*?
No it's not needed.
If you are going to "use" the Expected&lt;T&gt; code from the slides beware that there is an issue with either not calling the destructor on the exception_ptr in the swap function, or using swap on a null exception_ptr. (you should still call the destructor, but it probably won't do anything, and therefore should be optimized away)
Duplicating an interface doesn't make something a monad. It isn't even a monoid. There's no binary operation that creates a third Expect&lt;T&gt;. Haskell's Either and Maybe both have well-defined monoidal operations. This has only the equivalent of Data.Either (or whatever comparison is to be made) defined. You could define one. *Then* you could claim it fits the definition of a monad. But until then...
Uhh ... provide 'operator|(Foo,Foo)' ?
Sure that would work, but what if you also want to use the enum as an array size, or as a template parameter that takes an int? Like: template &lt;int a = enum_value(Foo::B)&gt; struct blah; 
Yuck, macros + stuff happening at runtime.
I guess I wasn't talking specifically about an enum used as a bit flag but for enums in general.
I think enums are the wrong tool for the job here the fact that C enums allow for ORing is just a distraction, why not just: namespace flags { constexpr int a=1, b=1&lt;&lt;1, c=1&lt;&lt;2; } auto a=flags::a | flags::b; http://ideone.com/3th4QX At the end of the day you aren't enumerating anything, you are "orring" named constant integers, so why not use them?
Yes, and you can still combine different values from the same enum. But this prevents you from accidentally combining values from completely unrelated enums.
Why so complicated? Why not just: #include &lt;cstdint&gt; #include &lt;iostream&gt; enum class Foo : uint32_t { A = 1, B = 2, C = 4, }; uint32_t operator*(Foo f) { return static_cast&lt;uint32_t&gt;(f); } Foo operator|(Foo lhs, Foo rhs) { return static_cast&lt;Foo&gt;((*lhs) | (*rhs)); } bool operator&amp;(Foo lhs, Foo rhs) { return ((*lhs) &amp; (*rhs)) != 0; } int main() { Foo a = Foo::A; Foo b = Foo::B; Foo c = Foo::C; Foo ab = a | b; std::cout &lt;&lt; std::boolalpha &lt;&lt; *ab &lt;&lt; std::endl; std::cout &lt;&lt; (ab &amp; a) &lt;&lt; " " &lt;&lt; (ab &amp; c) &lt;&lt; " " &lt;&lt; (c &amp; Foo::C) &lt;&lt; std::endl; return 0; } Note: I used : uint32_t because std::underlying_type wasn't available in ideone. But you get the idea. 
Has anyone used this on mobile platforms?
I did something similar, but I wrote [generic bitwise operators](https://bitbucket.org/martinhofernandes/wheels/src/3bde0eaa9f56a6c8714f76ef56924eb0e41de6fa/include/wheels/enums.h%2B%2B?at=default) that do not lose the type of the enum. With this I can just write one tiny specialization: namespace wheels { template &lt;&gt; struct is_flags&lt;Foo&gt; : std::true_type {}; } ... and it activates flag-like stuffs for free (tests that work as more examples [here](https://bitbucket.org/martinhofernandes/wheels/src/3bde0eaa9f56/test/enums.c%2B%2B?at=default#cl-56)): auto e = Foo::A | Foo::C; static_assert(std::is_same&lt;decltype(e), Foo&gt;::value, "no type information lost"); e |= Foo:B; // can use or-assign, and-assign, and xor-assign auto e2 = ~e; static_assert(std::is_same&lt;decltype(e2), Foo&gt;::value, "again, no type information lost"); bool has_a = wheels::has_flag(e, Foo::A); // equivalent to (e &amp; Foo::A) == Foo::A auto e3 = wheels::clear_flag(e2, Foo::A); // equivalent to e &amp; ~Foo::A static_assert(std::is_same&lt;decltype(e3), Foo&gt;::value, "never lose the type"); auto e4 = wheels::toggle_flag(e3, Foo::B); // equivalent to e ^ Foo::A static_assert(std::is_same&lt;decltype(e4), Foo&gt;::value, "..."); auto e5 = wheels::set_flag(e4, Foo::A); // equivalent to e | Foo::A static_assert(std::is_same&lt;decltype(e5), Foo&gt;::value, "yeah, these assertions are repetitive"); auto i = wheels::to_underlying(e); // if you really want to go there All of these are `constexpr` when appropriate, so you can even use them in template parameters and such.
Interesting I was about to say what the hell then it occurred to me that the GUI is platform independent. Makes me wonder how well it is done and how tightly it is tied into the rest of the lib. If the GUI works well with C++11 it might be a lib worth investing time in. 
I think you and Kranar are making some very good points here. Which technique(s) you choose, and indeed if you need any of them at all, depends a lot on the type of the project. How important is shaving off a few seconds of compilation time? (Important if doing TDD) How important is avoiding virtual functions so you can't do pure virtual classes? (Maybe important for a numerical engine) How important is that the compiler can inline things? (Again, numerical engines, real time systems etc.) And so on. Personally I currently like: -Pure virtual classes (for OO-parts of the software. I also like to use FP in some parts) -Simple value types, which compiles instantly anyway -static functions in cpp files for helper methods (though many of these now end up as lambdas instead now) (Regarding OO vs. FP I think Michael Featers is onto something in http://michaelfeathers.typepad.com/michael_feathers_blog/2012/03/tell-above-and-ask-below-hybridizing-oo-and-functional-design.html)
Wait. 'signaler' is condition variable? I think i saw enough.
I don't know what you would want from a GUI library to work with C++11, but dlib is clearly targetted at pre-C++11. It reinvents things like the standard smart pointers (and scoped_ptr has no release()... :/), and has no move semantics anywhere in sight.
Visual Studio does not support user-defined literals.
Typical. I hope that factor ISN'T considered when coming up with the TR2 "standard".
My (brief) Google-fu has so far failed me and I'm running a bit late for work else I'd dig deeper, but I'm curious about a couple of things. - Is there any kind of authoritative list of what's actually going into/already in TR2 right now? The most recent I could find was a brief mention of it on Wikipedia in an [article about TR1](http://en.wikipedia.org/wiki/C%2B%2B_Technical_Report_1#Technical_Report_2), but it mentions a 2005 date. - Is there any kind of list/summary of which compilers support any (or all) portions of TR2? Obviously Visual Studio 2012 is on its way toward implementing TR2; I'm just curious if the likes of GCC or LLVM are as well. Thanks for posting this, btw! I'm glad to see more bits of Boost sneaking their way into the technical reports and/or the standard itself.
dlib is on sourceforge: http://sourceforge.net/projects/dclib/ it's a hot project, many ppl like it.
They have a bunch of examples like this one: http://dlib.net/custom_trainer_ex.cpp.html look under the "Examples" link.
I like it. It's like programming in a scripting language, but with the type safety and performance of C++.
boost::filesystem is probably my favourite boost library, though a bit on the massive side. (I mean, people used to complain about std::string being too big!) Still, very nice to see it in standard C++, and with boost::filesystem's smart operator overloads, which shows a loosening in the std:: library on the practice of operator overloading. Although, why is there no interaction with the range-based for loop for iterating over directories, both linearly and recursively?
Being used to type inference in other static languages, I like using auto. Additionally since I am an happy IDE user, a quick mouse hover always lets me know the real types.
&gt; Additionally since I am an happy IDE user, a quick mouse hover always lets me know the real types. IMO you should be writing code such that everybody can read it, not just you and your IDE. I'm an IDE user as well, and scanning large bits of code, I shouldn't have to hover over things to figure out what they are.
http://boost.2283326.n4.nabble.com/TR2-is-dead-multiple-TR-s-coming-instead-td4397935.html
For those of us who don't spend too much time in C++ land, how many "competing" frameworks are there in this space? I can think of Boost, Qt, POCO, and now dlib. What other ones are you using, or seeing in use? Are any of them incompatible with C++11?
No, I think all the uses of auto here are ok. Understand where concerns about auto come from, however the point is if you use auto for long var' names but not short then you have "arbitrary" inconsistency. I think it makes sense to use auto in most types of assignment like statements (including copy ctor from a function). Finally if you are having issues know about the types of automatic vars' in a function then you should consider splitting that function up.
One of dlib's design goals is to be easy to compile. So as part of this, it doesn't have any dependencies. I would imagine, though haven't done this myself, that it would be easy to use on any mobile platform that had a decent C++ compiler. There is also at least one publication which talks about using dlib on smart phones: http://www.scribd.com/doc/50150091/MOBILE-MIND-A-FULLY-MOBILE-PLATFORM-BASED-MACHINE-LEARNING-APPLICATION
It depends on what you want to do. QT's GUI is much better for building complex graphical interfaces. The things that set dlib apart are largely it's numerical, machine learning, optimization, and related tools. You also don't have to install or configure anything to use dlib. So even for the things it has in common with other tools, I think a lot of them are easier to do using dlib.
No... the difference, as explained in the talk, is that you can defer dealing with the potential error until a later point in time, and also that you can not accidentally ignore the error. The type system forces you to have to acknowledge the possible error, whereas with normal exceptions in C++ you might simply forget to do the try/catch and then your program crashes. That was the entire point of having Expected&lt;T&gt; in the first place.
The top answer was provided 3 minutes after the initial question was asked. Something fishy going on - it would have taken more than 3 minutes to write all of that text.
PLEASE format your code, especially if you are looking of help, I am not even going to read it.
auto i = f(); i /= 2; g(i); Is there a problem with this code? Maybe f returns an int, g takes a double? There is a clear loss of readability, especially in numerical applications. Herb's "use auto everywhere" should clearly be refined to "where it makes sense".
&gt; Additionally since I am an happy IDE user, a quick mouse hover always lets me know the real types. That doesn't help with reading articles like this one.
&gt; I think auto makes the code more resilient to changes (e.g. type names) and easier to read. Perhaps in some scenarios, but not when you are posting snippets of code in an article. 
Well, to be honest it is no different than using a dynamic language.
forgetting try/catch is a horrible argument. One does not 'forget'. You can make that argument for anything and is equivalent to "well, if you write bad code..." Anyways, my point was that your snippet looks (visually) like try/catch in that your expected and exceptional paths are 2 separate blocks that aren't nested. Exceptions are used when the error can't be differed so the assumption that you can differ an error makes it a non-exception worthy error. Finally, it's bare-bone because I'd like to see you cascade 2 of these operations where the first depends on the second. You'll end up just like the first C-style rcode example. 
Sounds like a [QuickCheck](https://en.wikipedia.org/wiki/QuickCheck).
I'd suggest watching the video to get an understanding of what Expected&lt;T&gt;'s purpose is. All I did in my example was extend it so that you are forced to handle the error case and that enforcement is done statically at compile time using the type system. You can not access the result of the value without also explicitly providing a way to handle the error. That makes it different from exception handling or error codes because in either case you can construct a syntactically valid C++ program which forgoes handling the error and then results in either undefined behavior or a crash. With my extension to Expected&lt;T&gt;, it is not possible to construct a syntactically valid C++ program unless you explicitly handle the error scenario, this eliminates the very possibility of a runtime crash or undefined behavior. That is the purpose of a type system; type systems are used to reduce, or in some cases eliminate entirely the possibility of constructing syntactically valid programs that crash at runtime or contain undefined behavior. No one is trying to revolutionize how error handling is done in C++, there were a set of pros/cons with error codes and exceptions, and Expected&lt;T&gt; was proposed as a way to preserve most of the pros and forgo some of the cons. All I said was let's take it one step further and enforce that the error is properly handled by leveraging the type system so that more checks can be done statically at compile time.
How does this play with other libraries? For example could i convert say a gsl , armadillo or eigen matrix to dlib format than back?
I'm pretty much learning both as I go along
You'll have to give it more information than just a simplistic function signature--how is it supposed to know what a "fringe" case looks like without understanding, logically, what the public contract of the function is. Think about it like this: it would be quite easy to write a preparser that could look at a function signature and generate a boat-load of data for passing it during testing. That's the arguments taken care of. But what to assert on? Is this a personal project? Business? School? If it's anything but personal, you're best off just writing the tests. Is it a bitch? Of course, but then unit testing has never claimed to be anything but.
Oh. Using a namespace to encapsulate stuff you don't want leaking? I like that. Only used namespaces to encapsulate auxiliary classes and functions for libraries so far.
Where is the template concept at? I don't see any documentation on it, as there is no links to it.
MPI for some is easier to understand because you don't have to worry about shared memory however, on a multi-core system there is a high likely hood that threading is going to be better to avoid the message passing over head. But I share your sentiment in that MPI is a lot of times easier even if its not the proper use.
I still don't see what needs to be implemented to implement `set_kernel_abstract` concept? 
&gt; Oh. Using a namespace to encapsulate stuff you don't want leaking? It provides a level of scoping, which is what we want.
I like the "where concurrency != parallel". Not everyone remembers that.
My [unit test suite](https://bitbucket.org/moswald/xunit) tries to make it somewhat less of a bitch. (Shameless plug.)
I'm amazed that constexpr and unions work so well together.
Ooo, no that looks quite cool. I've been absolutely loving all the new functional goodies in c++11. It's been a long time coming~
One example: under C++03 `std::string`s weren’t considered contiguous storage and in particular the effect of reading or writing `&amp;str[0] + x` (with `std::string str; std::size_t x;` and `x &lt; str.size()`) was UB, which meant that you couldn’t pass `&amp;str[0]` to a C function accepting `char*`. You had to use a `std::vector&lt;char&gt;` instead. C++11 on the other hand guarantees that `&amp;str[0]` points to contiguous storage sot his is now fine.
So how does this compares to Boost?
Slightly bummed they exposed the unsafe operator* instead of providing something like: template &lt;typename Func&gt; void opt_if(optional &amp;opt, Func &amp;f) { if (opt.init_) { f(ref(opt.value_)); } } Which makes it almost impossible to write unsafe code. But I guess it wouldn't be hard to subclass std::optional and make the unsafe parts private if you really care.
tr2 is library only. Furthermore something like this is WAY out of the scope of both tr2 and next (minor) standard C++14.
OT: Full RSS feed, pretty please!
There is a lot to be said for easy to use and understand systems. If you end up with a functioning and useful program I'd say it is proper use. 
what do you mean with Interface ? User interface? abstact classes?
Just like a text box or some buttons a user can interact with. 
Qt is probably a good place to start
Oh man, I ran into a wall with this exact problem last night.
Don't miss the comments! The first one is from Bjarne Stroustrup and sets off an interesting discussion on the role of these esoteric "expert level" posts.
Don't be coy, what was Richard Smith's solution to this?
God damn, C++ looks more and more like Perl. I'm starting to think I'm really too dumb to use this language. I mean, seriously: template&lt; typename Head, typename ...Tail, typename Impl = back_impl &gt; auto operator()( Head &amp;&amp;, Tail &amp;&amp;... tail ) const -&gt; decltype( Impl()( std::declval&lt;Tail&gt;()... ) ) { return Impl()( std::forward&lt;Tail&gt;(tail)... ); }
German engineering...
Yeah, I have no idea what the purpose of this code is...
Cheer up, if you look later in the article you can see the new syntax that will soon work and it's much easier...
Think of it as an attempt to do the following: template&lt;typename ... Initial, typename Last&gt; Last back(Initial&amp;&amp; ..., Last&amp;&amp; last ) { return std::forward&lt;Last&gt;(last); } Basically, just discard all parameters except for the last one and return it. I don't know if C++ has the expressive power to compile the snippet I gave above, so maybe a whole bunch of language tricks and jumping jacks need to be done in order to acheive it.
&gt;Unfortunately this only works for **heterogeneous** argument lists (all the arguments are of the same type). *(emphasis mine)* Heterogeneous is the wrong term, you meant homogeneous. 
I guess my question is then, why would you want to do that?
Honestly man... I don't even know. One of the side conversations spawned by this article is why the heck so many C++ articles focus on exotic language features instead of using the language to accomplish actual practical goals like the articles written about Python or C#. C++ seems to attract a certain kind of audience that likes finding twisted ways of abusing the compiler in order to return the last parameter passed into a function.
Couldn't they just use va_start macros or whatever? Or pass in a pointer of Type* and iterate over it until null?
I think it's unfair to characterize the "C++ Primer" as a bottom-up book in contrast with the "Accelerated C++" (note, that the bottom-up, C-before-C++ approach is followed by a completely unrelated but similarly entitled book called "C++ Primer Plus" -- perhaps that's a source of confusion). It's no longer true since the fourth edition when Barbara Moo (co-author of "Accelerated C++") joined Stanley Lippman and Josée Lajoie. Straight from the horse's mouth, here's Andrew Koenig on the differences: &gt; Today's C++ implementations are good enough that we no longer see any excuse for avoiding the Standard Library. Accordingly, the biggest change between the third and fourth editions of the C++ Primer is that the fourth edition places much less emphasis on the "C" parts of C++ and much more emphasis on the "++" parts. Like Accelerated C++, and unlike the third edition, the new C++ Primer teaches the standard vector and string classes early, and covers arrays and C-style strings only to the extent that programmers really need to know about them. Moreover, like Accelerated C++ and unlike the third edition, the new C++ Primer shows how to use notions such as constructors and generic functions before showing how to define them. As opposed to bottom-up vs top-down (which describes the differences between the "C++ Primer Plus" and the "C++ Primer", respectively), there are two teaching strategies that distinguish "Accelerated C++" from "C++ Primer" (while top-down fits both): &gt; What every C++ programmer needs to know to write useful programs. &gt; What C++ programmers might potentially need to know to handle a wide range of applications. It's still fair to say that "Accelerated C++" will offer a more, well, accelerated learning experience, but not for the reasons you suggest. For more, see http://www.drdobbs.com/learning-teaching-c-programming/184401918
See Richard Smith's attachment to this gcc bug report: http://llvm.org/bugs/show_bug.cgi?id=13263
It happens in more cases that you might think. `back` is just a trivial example. Variadic templates are heterogeneous, forward-only collections; that is, you can only peel off the first N elements and recurse to process the rest like a Lisp cons list. Thus, by the very nature of this important core feature, recursive algorithms are *required*. If the return type depends on the type returned by the recursive invocation, you WILL hit this problem. Think of a variadic variant of `std::accumulate` and you'll begin to see why this problem is real.
Hi yelp, I think you would get better responses over at /r/cpp_questions. To do what you want, I suggest finding a library that can retrieve and parse HTML pages for you. Realistically, C++ might not be the best choice for your app. For what you describe, I suspect you will find more suited libraries in Python/Java/C#.
I like the namespace idea. Taking it a step further for convenience, you may want to look into using `std::bitset` to keep track of flags if that is what you are using it for. You can use an enum to index into the bitset and in combination with the namespace idea, you don't have stuff leaking into the global namespace. The following code is my adaptation of the example from "The C++ Standard Library: A Tutorial and Reference, Second Edition" Section 12.5.1 #include &lt;array&gt; #include &lt;iostream&gt; #include &lt;bitset&gt; namespace Colour { const int count = 3; enum {red, green, blue}; const std::array&lt;const char*,count&gt; name = {"red", "green", "blue"}; } int main() { std::bitset&lt;Colour::count&gt; usedColours; // Set two of the bits. usedColours.set(Colour::red); usedColours.set(Colour::blue); // Output the bitfield. std::cout &lt;&lt; "bitfield of used colours: " &lt;&lt; usedColours &lt;&lt; std::endl; // Display all colours that are used. if(usedColours.any()) for(int c = 0; c &lt; Colour::count; ++c) if(usedColours[c]) std::cout &lt;&lt; "Colour " &lt;&lt; Colour::name[c] &lt;&lt; " used\n"; }
I've never used C++ to screen scrape web pages (which is basically what you're describing). I'd probably use Python. BUT if someone did ask me to... I'd just go ahead and haul out the big guns. There's probably a lighter-weight library, but I'm pretty used to Boost::Asio, so I'd probably use that to do the page retrieval. For the parsing, it kiiiiind of depends on what my source is like. If it's actually well-formed XHTML I'd be tempted to use Codesynthesis' XSD toolkit. If it's not that well formed, I might just degrade to using regex to find the needle in the haystack. Ugly but sometimes ugly calls for ugly. If I wanted to be a smartypants I'd try for parsing it as XHTML first, then failover as best I could to looking using some set of regular expressions. But that's if someone told me it HAD to be in C++. And this is, frankly, not something I'd suggest for a beginner in C++. Python, Ruby, Perl, PHP, etc etc are all going to make this sort of thing much easier.
Increasing power by increasing complexity is the simpleton's brute force solution, one you don't need another language for. 
I am not entirely comfortable with this definition of "fun" or "clever". 
You should write there. 
thats what boost seems like to me sometimes too
&gt; std::async and std::future I wouldn't, I would expect a good parallel algorithms library to be built on something like Intel TBB, or MS's PPL. The quality of `std::async` varies tremendously and provides very few actual guarantees about parallemism that you might want from a Parallel algorithms library.
Isn't TBB free to use in free software (which I assume extends to libraries)? Which from the looks of it your code is. It was a just a thought anyway.
I think it makes pretty strong guarantees about *parallelism*, but not *concurrency*. It's entirely a quality of implementation issue, but since Microsoft's version is based off of PPL, it's highly likely Clang and G++ will soon offer equivalent versions (if they haven't already).
BTW, one of the earlier attempts (using OpenMP) is that of GCC: http://gcc.gnu.org/onlinedocs/libstdc++/manual/parallel_mode.html
For processing the html, use project Arabica at https://github.com/jezhiggins/arabica What you are interested in is Taggle (there are some examples). This will take html and turn into to well-formed xml. You can then use an xml library to easily manipulate it. I personally used pugixml from http://pugixml.org/ to process the xml. This is made easier because of xpath support (you will want to learn xpath as this will make it a lot easier). Finally to get the html from the internet, you can use libcurl. Or if you want a more c++ flavor you could try my jrb_node which uses boost asio. https://github.com/jbandela/jrb_node 
http://curl.haxx.se/libcurl/ That's what everyone uses for webscraping. std::regex for text matching.
Cool! I did not know about that :) The design that they have chosen requires you do some manual setup and set the number of threads you want to use. Also, from what I've read, once you tell it to run the algorithms in parallel, you have to pass aditional flags to turn parallel off. For example: (from docs) std::sort(v.begin(), v.end(), __gnu_parallel::sequential_tag()); The one I have queries to find the number of threads available via. const unsigned num_threads = std::thread::hardware_concurrency(); And if you want to use a non-parallel one, just call the one from the `std::` namespace :) The underlying implementation `in_parallel` in generic so you can make any algorithm parallel by simply defining the *map* and *reduce* components though a struct with 2 static functions. One improvement that I would like to make is instead of having to define the 2 functions in a struct, that they should be taken in as *callable* objects (whether that be function pointers, `std::function`, or lambdas), and then have `in_parallel` use that. Unfortunately, the underlying implementation of the results of the sub-ranges, currently implemented as a `std::vector&lt;return_type&gt;` where return type is defined in the implementation struct, must be specified explicitly in the lambda. I do have a version implemented that takes the functions as arguments, but it's quite ugly to use lambdas currently. The corresponding code for a parallel count is: auto num_twos = in_parallel( begin(v1), end(v1), [](std::vector&lt;int&gt;::iterator first, std::vector&lt;int&gt;::iterator last, int v) { return std::count(first,last,v); }, []( std::vector&lt;decltype(std::count(begin(v1), end(v1),2))&gt;::iterator first, std::vector&lt;decltype(std::count(begin(v1), end(v1),2))&gt;::iterator last, int ) { return std::accumulate(first,last,0); }, 2 // The value we wish to count ); Because there is no generic lambdas yet, the paramater types are disgusting to type. If generic lambdas make it into the standard eventually, this would be simplified to: auto num_twos = in_parallel( begin(v1), end(v1), [](auto first, auto last, int v) { return std::count(first,last,v); }, // Algorithm to apply on each sub-range. [](auto first, auto last, int) { return std::accumulate(first,last,0); }, // Algorithm to generate the final result. 2 ); Much nicer on the eyes :) Because of the way it is implemented (and I haven't found another solution yet), both functions must take the same arguments, even if they aren't all used. If you look at the second lambda it ignores the int paramater and hardcodes `0`, the identity element for addition. I'm crossing my fingers for polymorphic lambdas being in the next standard, major or minor. 
With respect to the comment about restricting the type `T` from being a class derived from `std::exception` and creating a constructor taking and exception and setting *spam*, this can easily be done with an `enable_if` trick. The old code that had to be written was: (from Alexandrescu's talk) expected&lt;int&gt; parse_int(std::string const&amp; s) { int result; // ... if (nonDigit) { return expected&lt;int&gt;::fromException( std::invalid_argument("not a number")); } // ... if (tooManyDigits) { return expected&lt;int&gt;::fromException( std::out_of_range("overflow")); } // ... return result; } He mentioned how Herb said that the middle part: return expected&lt;int&gt;::fromException( std::out_of_range("overflow")); was ugly (haha) and should just be: return std::out_of_range("overflow"); If you add a constructor taking `E e`, you can create an exception out of it and set `gotHam` to `false` and set `spam` to `std::make_exception_pointer(e)`. With a basic implementation such as: template &lt;typename E&gt; expected(E&amp;&amp; e) : except_(std::make_exception_ptr(std::forward&lt;E&gt;(e))), hasT(false) { } you'll notice that `E` will match `int` even when returning `1` from a function returning an `expected&lt;int&gt;`. This is obviously a problem as it should be a successful return and not try to make an exception out of `1`, but we can easily fix this by adding `std::enable_if` to make sure that `E` is an exception as follows: template &lt; typename E, typename std::enable_if&lt; std::is_base_of&lt;std::exception,E&gt;::value, int &gt;::type = 0 &gt; expected(E&amp;&amp; e) : except_(std::make_exception_ptr(std::forward&lt;E&gt;(e))), hasT(false) { } Now the code works as expected :) 
Fair enough, I'll agree with you there :) I was more interested in the design aspect of separating the map and reduce and having the `in_parallel` handle the concurrency, details of configuration aside. Thanks for the advice though, I'll definitely keep that in mind :)
Is it normal that creating HTML5 application through qt creator gives 'No valid kits found'?
I saw a mention of this in the [Known Issues](http://qt-project.org/wiki/Qt500KnownIssues) page. It's likely picking up an older installation of Qt and getting confused. They mention a couple fixes (one w/selecting the right build kit, the other involving resetting all QtCreator settings).
&gt; You need to convert the weak_ptr reference to a shared_ptr to use the pointed to object which has unneeded overhead though. There is also nothing to stop you from keeping the extra shared_ptr which breaks the ownership model entirely since there is only one owner and if should be able to destroy the pointed to object. How do you ensure that the object isn't destroyed while you're using it without reference counting? Basically if you do: if (weakptr.isValid()) weakptr-&gt;someFunction(); you end up with something a lot more dangerous with little benefit, IMHO. In the context of the question though, passing raw pointers sounds fine. In practice you'll want to define clearly the lifecycle of classes in the app so that whatever is holding the unique_ptr isn't destroyed before the users. It's more of a design problem than a language one.
&gt; First, unique_ptr is right out. It has the single owner bit down pat but can't really be used to share the contents without exposing the raw pointer as far as I'm aware. Pass by const reference. &gt; It would appear a scheme with something along the lines of unique_ptr and weak_ptr working together would be ideal. What if you had a shared_ptr to a unique_ptr? You could share the shared_ptr and, while you couldn't make the data const and still have the single owner not modify it, you could also just not write any code that modifies it outside of where you wanted to.
Congratulation to digia for continuing Qt post-Nokia. 
They got a C++ port yet?
I'm using it from the first beta , Qt quick 2 is awesome!
I try to use constexpr as much as possible at work.
Can you give examples for "real life" uses
My strategy these days is to use unique_ptr to express my ownership, and anything that needs to "look at it" can just use the raw pointer. As long as I never call delete on the raw pointer the lifetime is still controlled by its original owner. For example, consider a binary tree where each node can view it's parent. Parents own their children. I'd represent this as template &lt;typename T&gt; struct tree_node { unique_ptr&lt;tree_node&gt; left; unique_ptr&lt;tree_node&gt; right; tree_node* parent = nullptr; }; and as long as I never try to delete my parent, life is good for the child :-)
I think it's because C++11 is still "new" and the experts are still having fun exploring the landscape :-) Once things settle down a bit I think we'll see a shift away from "check out this new craziness" towards more practical usage.
Yeppers
well compile time random number generators are useful for certain things,having a look up tables that won't change, to name a few
Ok I just made some changes and compiled the code on a Mac with OS-Lion. (I will post the binaries for people to use) I would only check out llvm and then clone my repository into clang - do not check out anything else because it will expect a different revision of llvm and will certainly crash. Please let me know if you can get it to work on ubuntu. Thanks again for working with me here.
I'm not sure you're thinking things through. If a std::vector&lt;std::unique_ptr&lt;T&gt;&gt; gets resized, iterators to the vector elements are indeed invalidated, as are const references to the unique_ptr objects themselves. However, the suggestion is to pass by const T&amp;, not const std::unique_ptr&lt;T&gt;&amp;. The const T&amp; reference will not be invalidated in that case.
Is it possible to use msvc 11 compiler with Qt Creator without too much hassle? I have visual studio 2012 installed, but I get "no kits found" if I try to compile a template app in Qt Creator.
There's places in my code where constexpr data structures would allow the compiler to unroll loops since it knows exactly how many time to iterate.
This guide is useful when compiling on windows http://qt-project.org/wiki/Building_Qt_Desktop_for_Windows_with_MinGW With two mentions: - an extra requirement is to have python in your PATH (I used Python-2.7) - in your qtdir\qtbase\configure.bat there is an if that checks for the existence of .gitignore. if it doesn't exist configure.exe won't build It also looks like qt-5.0 breaks [QCustomPlot](http://www.workslikeclockwork.com/index.php/components/qt-plotting-widget/), for instance the toAscii() method from QChar is gone. Also QPrinter doesn't exist anymore.
Ok just committed a patch that should fix the issue with iostreams - and tested it briefly on my mac. Please let me know if it still crashes for you. 
lol wat
Yeah fuck investing my attention span to learn something. Can't you just directly insert the information into my brain?
Can you easily sit and watch a 30-60 minute video at work? I can easily read an article during compilation and testing.
The funniest thing is: I watched this exact video this morning at work. My reasoning is that this helps my code. If my place of work do not provide adequate training; I'll provide it myself.
Yes, that's my point. The only really safe solution requires reference counting.
Heck, for us this is an issue with people listening to streaming music!
On non-Windows platforms
c++ offers a lot of tricks that can improve the program's type safety. With a little discipline, even changes across time could be tracked. And by using templates, one could do some dependent typing. 
Argh. If only you had posted this two days ago, it would have saved me quite a bit of headache. I've been refactoring a lot of code that needs this kind of fix.
I have never heard anything bad about qt creator. But I have never really used it and I like code::blocks. But on the other hand I have never actually used qt with code::blocks, it might be painfull.
Shame there is no *nix version.
It looks like they don't build it, but it's available for [most distros](http://pkgs.org/search/?keyword=cppcheck).
This is a great tool any serious program with a beard should use.
CppCheck is a really good tool. I use it for my own engine development. The first time I was blown away with the huge amount of warnings :D But it is really good to see bad style failures and decisions.
I think they only update the compiler with OS releases.
I've tested it with some of my code. Here's a simplified version: #include &lt;string&gt; struct S { bool exists; string value; }; static bool f (S const&amp; s, string const&amp; expected_value) { return s.exists ? (s.value == expected_value) : (expected_value.empty()); } I get (on the last line) the error "(warning) Ineffective call of function 'empty()'. Did you intend to call 'clear()' instead?" OTOH, if I replace `expected_value.empty()` with `expected_value==""` (which doesn't really change anything), the error disappears. Is that a bug in Cppcheck, or did I miss something?
Tagging, thanks!
The apple compiler shipped with the latest version of xcode is based off 3.0 the version flag makes it seem like its not even on the release branch of 3.0 as well. There is something to be said for keeping the compiler paired to the OS and waiting 18 months to 2 years isn't terrible for updates to a compiler.
Anything's possible, but it's likely not something you'd want to attempt. You'd essentially be implementing a symbolic algebra system, which is a large undertaking and quite a lot of work. It would be better to use an existing system (e.g. Mathematica, Matlab, Octave, Python + Sympy, etc.) or an existing C++ library (e.g. SymbolicC++.) Of course if you do the part of rearranging the equation so that it's in terms of x by hand, then it's trivial to write a C++ program where you plug in some numbers and it spits out a result for x. But that would just be hard-coding the equation into a special-purpose program that can only work with that particular equation, and it wouldn't be doing any actual solving in the mathematical sense, only automating some basic arithmetic.
Can you tell me what a symbolic algebra system is? How would I implement an existing C++ system. Are those the headers like #include &lt;iostream.h&gt;. No, I am interested in doing this because when solving in terms of x, it doesn't have a value, more attached to another number (3X). 
&gt; Can you tell me what a symbolic algebra system is? It's a set of rules and techniques for manipulating equations, essentially the same techniques you learn in school. &gt; How would I implement an existing C++ system. Like I said, I doubt that this is a possibility for you. Go to Wolfram Alpha and have it solve a simple equation. [Here's an example of a cubic polynomial](http://www.wolframalpha.com/input/?i=solve+3x^3+-+29x^2+%2B+2x+-+42+for+x) that I just made up. Click on "Step-by-step solution" and then "show all steps". There are dozens of steps and the equations get very large and complicated very fast. And it's not always the same steps -- you'd have to write code to figure out how to get from point A to point B, the same way that you would do it by hand with pen and paper. Most people can't even do that, let alone write the code to do it. &gt; Are those the headers like #include &lt;iostream.h&gt;. No. There is nothing in standard C++ that even comes remotely close to addressing this sort of problem. (By the way, it's `&lt;iostream&gt;` without the .h. If you're using something that has an iostream.h, you are using extremely old and outdated tools.) A third-party library might be implemented as a header-only library, or it might also have a library to link against. 
It sounds to me like you need to learn C++ before you can reasonably begin to attempt this. For that you need both a good book and a good compiler/IDE. I suggest *C++ Primer 5th ed* and something from the "recommended" section of the [/r/learnprogramming tools wiki](http://www.reddit.com/r/learnprogramming/wiki/tools), probably Visual Studio or Code::Blocks. That said, if you are a complete beginner, I suggest you learn something other than C++ first, like Python or Ruby.
[SymbolicC++](http://issc.uj.ac.za/symbolic/symbolic.html) is indeed composed of headers like STL headers! I just checked it out - it comes with tons of examples and it's free. Best way would be to download it, and try to some of the examples and change them. On my Mac, I was able to compile and run one simple example, expand.cpp, by going to its directory in the command line and typing g++ expand.cpp -I ../headers -o expand ./expand You'd need to install the Mac development tools first. Or, basically, however you are compiling C++ now will almost certainly work.
Only error I get with your code is: $ cppcheck --version Cppcheck 1.55 $ cppcheck --enable=all main.cpp Checking main.cpp... Checking usage of global functions.. [main.cpp:11]: (style) The function 'f' is never used If your version is newer then it might be time for a bug report. You could also try to remove the () around the `expected_value.empty()` to see if that changes anything.
Agree: OP definitely should not start with this as his first project, and Visual Studio or Code::Blocks are much superior to Dev-C++. Disagree: I think there's nothing wrong with learning C++ first!
I just finished a half year class in high-school covering the basics and I'm looking to expand.
Simply put: C++ and most other popular languages might look like a math, but they really aren't. Instead they simply evaluate the commands you give them and those commands all boil down to very simple reading and writing of memory. The math knowledge of C++ does not extend much beyond some simple multiplication and addition, as those are really the only things your CPU knows how to do. You can of course write a solver for symbolic equations with those simple commands, but the language doesn't have that build in to it, so that would be a lot of work. However programming languages that can do what you want exist, [Prolog](http://en.wikipedia.org/wiki/Prolog) being one of the more known ones. It however doesn't get much use in normal programming work, as most programming revolves around doing GUI stuff, webstuff or hardware, not solving math equations. For math there exist also exist plenty of special software that can solve symbolic equations, such as Mathematic or it's free online variant [Wolfram-Alpha](http://www.wolframalpha.com/). 
Thanks! I downloaded a new one...are there any noticeable differences?
That's all well and good, but developing a general symbolic algebra system is something I'd expect to be challenging for someone with dual degrees in Math and Computer Science. I've been working as a software engineer for 5 years, and I'm not sure I'd be able to do it in the general case. I mean, if you're only trying to solve equations of one particular shape, that'd be doable; just parse the text, and do the math. If you're trying to get it to work in a general case (where you could provide *any* equation and it would work), then you're definitely overreaching. Scale things back.
Well, it's been at least 3 years since I've used either of the versions, but I know that they upgraded from GCC 3.4.2 to something in the 4.5 range, and that's a MAJOR improvement, in terms of problems that the compiler will catch, general performance, bugfixes, etc. I think the newer version also has support for building GUIs with wxWidgets, which is a cross-platform UI-building toolkit. Bloodshed's Dev-C++ was fairly buggy, and the updated version seems to clean up a lot of that.
Thanks so much, I'll look into these! And C++ is the only language I know, besides a little TI-BASIC.
Yes, the new 5.3.0.3. does do much better in handling code than my older version. It does not color code as much however. 
I don't think there's anything wrong with it either; never said there was. I learned C++ first myself. You can learn anything first. However, I think concepts are the most important thing for beginners and I believe it's easier to learn those concepts in less complex languages. I find beginners get too easily caught up in the syntax and minutia of C++ rather than actually doing what they set out to do: learn programming. Just to support my point a bit more: http://hammerprinciple.com/therighttool/items/c-2
Troll. 
You need to buy a book on programming in C++. I suggest C++ Primer 5th edition. The one by Lippman, Moo, etc. Do *not* get the Stephen Prata book. Regarding what you want to make (a symbolic algebra system) Best explained thusly: As Gandalf once said of a Balrog - "This foe is beyond (any of) you, RUN!"
Do you want to (a) obtain explicit zeros for a function f: R -&gt; R, or (b) compute a symbolic expression that yields the zeros of f(x) in terms of x? You need to be more specific about your problem definition (characteristics of the domain of f, behavior of f on its domain, etc.). In the general case, neither (a) nor (b) may be possible.
Before you can program a computer to solve an equation symbolically, you should have at least some clue as to how to do it yourself. Seeing as you likely can't, you need to come up with a subset that you can. Then find a good internal representation of the equations you want to solve (likely a tree) and define some transformations on the tree to yield you the result.
Preferring pre increment to post increment is so 2011! ;) Currently it's the other way round (for integers): http://redd.it/155ivw
Anyone had luck getting it to run on Windows?
I've been skiing for most of my life, so bring on this khedoros' challenge! 
hahaa okay! Thanks!
I'm looking more for (b). Something that will yield say: 3x+4 as an answer. I'm just looking for a way that i can tack on the x to the three.
Okay, I'll look into this!
Thanks...I'll try and figure stuff like that out. 
A language like Haskell may be the best bet at symbolic manipulation. I've been wanting to naively try something similar to what you are suggesting. Haskell took me through tree traversal and turning an equation into something that looks like it can be worked with. For next step, I want to try using some bond graph/modeling framework. Sounds like you want to stick to these ideas, don't get discouraged. It will take time. I'm quite green and I don't really know what I'm doing either. But it's fun trying as long as I have the energy for it.
On the other hand. I think you can learn a lot by trying the seemingly impossible. I certainly have learnt some by doing that. Just don't get too discouraged by not getting results. :)
This. Almost all books on any language will go into *far* more detail as to why certain things are done certain ways than any number of YouTube videos. Why do I need to know the 'why' of everything? Because you'll have a deeper knowledge and greater understanding of you do; which will lend itself to learning other languages or frameworks, or if you end up writing your own language (scripting or otherwise) of tools. *Edit: I accidentally a spelling. Thanks for pointing it out grunzl*
&gt; Almost all books on any language will go into **car** more detail as to why certain things are done certain ways than any number of YouTube videos. Also, doing cars instead of animals will put more emphasis on composition as opposed to inheritance.
If you really want to learn C++11, highly advisable at this point, you need to spend more time on the net. If you are an absolute beginner Accelerated C++ is a good place to start for older C++ versions. 
Err XCode releases. Sadly XCode seems to me tied to iOS release with Macs as an after thought these days. In any event I do believe that Apple is betaing XCode right now. 
Finally, I was able to get a copy of the book : "Foundation of Algorithms in C++11, Volume 1: Using and Extending C++11, Boost And Beyond by Chandra Shekhar Kumar and Aditya Kant Sharma" from amazon. It was an interesting read for me. It helped me re-learn proper usage of C++11 language and library features, indepth treatment of which was missing from present resources like : The C++ Standard Library:2nd Ed by Nicolai", C++ primer : 5th edition, Scott Meyers new C++11 material and C++11 standard draft 3242.pdf, as far as pragmatic programming in large scale software is concerned, especially topics like : template alias, intemediate traits idiom, deducible/non-deducible context, private cast, sfinae, writable concept and trailing return types. And needless to mention that it is full of beautiful code snippets, all in C++11. It looks like they are setting the tone for lifting boost to C++11 with this kind of booklets. Earlier this was only accessible only to experts. I applaud the quality of the book and look forward to reading forthcoming books in this series to help me become a better C++ programmer.
This is a fantastic reference. PDF please!
thx. corrected.
Think of programming like playing an instrument, you can read and watch videos all you want, but the only way to actually become a master is through practice, that being said find some projects your interested in and work on them.
XCode releases which come out when there are new iOS releases and new OS X releases.
using Haskell code I tried to explain to my colleagues what is in the left side of slide :)
This thread was worth it to learn about SymbolicC++!
Actually, you should ignore it. It's not what *normal* C++ code looks like.
Almost '13 and I haven't gotten around to learning C++11, barely got around to updating my compiler a few months ago. I feel like some old fogey not learning it yet. But what is this lambda thing, it looks more convoluted than the ternary operator?! Seen it in C# and that looks nice and slick, but this is nasty looking.
&gt; Also as an asaide, std::thread suck compared to boost::thread. What makes boost::thread better? Edit: Good list of things is at: http://stackoverflow.com/questions/7241993/is-it-smart-to-replace-boostthread-and-boostmutex-with-c11-equivalents
Could somebody explain why `constexpr` is needed? Why can't the compiler figure it out on it's own if something is a `constexpr` or not? It feels kind of redundant when we already have `const`.
Are any of the series on here good for beginners wanting to learn c++?
No, this series assumes some working knowledge of C++. You need to be at the point where you care exactly how the standard defines things. It'll explain why the things you know are as they are. It's a great series though.
[Cppcheck vs PVS-Studio](http://www.viva64.com/en/b/0149/)
Try [it](http://www.viva64.com/en/pvs-studio-download/) and tell us about the result, an.
One thing that seems to be missing from `Expected` is a variadic emplacement constructor (such as that used with `make_shared`).
You might be fine, but he did show quite a bit of code so seeing the video may help.
I missed the most obvious one: Putting it in to practice. When you put things in practice you often encounter alternative methods which might be better (or worse). 
Here's one more: http://algo2.iti.kit.edu/singler/mcstl/ :-)
C99 7.18.1.1/3: "These types are optional. However, if an implementation provides integer types with widths of 8, 16, 32, or 64 bits, no padding bits, and (for the signed types) that have a two's complement representation, it shall define the corresponding typedef names."
looks VERY interesting, any benchmarks out or still too early? Also are there any white papers on this?
There was a presentation on it at Meeting C++ 2012, which includes some benchmarks -- http://www.youtube.com/watch?v=No1knGsLGko Unfortunately, there were some issues with video recording which adversely affected the (mainly audio) quality; if it's too hard to watch (or listen), the slides are available here: http://meetingcpp.com/index.php/talkview/items/4.html There's also a separate GitHub repository which may be of interest: https://github.com/STEllAR-GROUP/hpx_benchmarks/tree/master/benchmarks
&gt;Almost '13 and I haven't gotten around to learning C++11 I read this as "I am almost 13 years old and I haven't learned C++11 yet"... :p Anyway, C++11 was released in August 2011 and it takes a while before compilers adopt the standard (especially since this update was a rather large one) so I wouldn't feel guilty for not having learned C++11 within a year. Not to forget that the first few C++11 books have only been out for a month.
Super nitpick: char, signed char, and unsigned char are 3 distinct types (unlike everything else). char's range is identical to either signed char's or unsigned char's, but it's implementation-defined which.
FWIW, related publications can be found here: http://stellar.cct.lsu.edu/info/publications/
There was another talk at C++Now 2012 (better audio!): http://www.youtube.com/watch?v=rNl0KqGF12U
&gt; In the context of your video, char is as guaranteed to have range identical to signed char as long is to be 32 bit, isn't it? No. VC even has an (evil) option, /J, that changes the signedness of plain char. My implementation of find()'s memchr() optimization is carefully independent of the signedness of plain char. &gt; Anyway, I was confused, because at the beginning of the video, you're telling that searching for value 255 should yield no results, yet at the end you're making sure that it still happened (for unsigned values, though). That's incorrect. (I hope I didn't screw that up; I try to speak with complete precision, but it's a single take and thinkos slip in from time to time.) -1 as a signed char can't ever be equal to 255 of any type. The integral promotions (which are value-preserving) widen signed char to int, so the left hand side is just -1 as an int. Let's consider all of the possible types for 255 on the right hand side. "Tiny" types (e.g. unsigned char, signed short, etc.) are immediately widened to int, value-preserving, and compare non-equal. So the "interesting" cases are unsigned int, signed/unsigned long, and signed/unsigned long long. The cases of signed long and signed long long are easy - both sides are signed, so the smaller one is widened to match the larger one, and this is value-preserving. -1 is still not equal to 255 here. (In the C9 comments, someone noticed that I screwed up and said "unsigned" here, while getting everything else right. D'oh.) The cases of unsigned int, unsigned long, and unsigned long long are the trickiest. In these cases, -1 as an int is converted to the big unsigned type. This makes it 0xFF...FF. I might have glossed over this too quickly (focusing on the last two hexits). This value is not 255. It is either 2^32 - 1 or 2^64 - 1, which is really big. This does not compare equal to 255.
// Not an author, only submitted the link; That's exactly what I'm longing for! Right now, I rely on Boost.Fusion + Boost.Phoenix (since it has polymorphic lambdas; a helper struct is another solution, but it loses code locality) for tuple-iteration, would be nice to have a standard way to do this. // Although, thinking about this, we'd still need something to replace Boost.Fusion part of the equation -- range-based for-loops only do type-inference once per range, which won't do. Perhaps it will be deemed "minor" enough for C++14 /* http://isocpp.org/std/status */ but that's a mere speculation (if not wishful thinking) on my part ;]
[]{} is even shorter syntax for a do-nothing nullary lambda. Saying "Coordinate(const Coordinate&amp;) = default;" and "Coordinate(Coordinate&amp;&amp;) = default;" is unnecessary. The (int, int) ctor suppresses the implicitly-defined default ctor, but not the implicitly-defined copy/move ctors.
Nah. This is (at least as presented) way too awkward to use in anger. I'd certainly use it were it a real language feature.
The next minor C++ release is planned for 2014 and the next major for 2017: &gt;[We are just beginning work on new revision of the C++ language and standard library targeted for technical completion in the 2015-16 timeframe and formal ratification in the 2017 timeframe. Before that, we also intend to complete a minor revision in 2014 that contains bug fixes as well as a few smaller useful additions.](http://isocpp.org/std/status)
Problem is, the company I work for is attracted to Qt *because* they've managed to handle source compatibility well over time. The project I work on is just about 20 years old, and choosing a library you can rely on to stick around without having to constantly chase a moving target is attractive. That said, this kind of backwards compatibility is also what holds C++ back. I think Qt would be surprisingly easier to work with if all they did was support/enforce move semantics where appropriate and use std::unique_ptr &amp; std::shared_ptr anywhere they expect a pointer type (else use references). I'd also love to see QtConcurrency work well with the new concurrency features in the standard library.
&gt;Lambda expressions have the fascinating property that even syntactically identical lambda expressions don't have the same type. This ties into the fact that they cannot appear in an unevaluated expression like decltype or sizeof. I don't understand. Is unevaluated expression a common term or is there some other concept I can research to try to understand. Also, why/how are they not the same type -- I'm inferring that every lambda expression is given its own type, lambdafunction1, lamdafunction2, etc. Is this correct assumption? How could I learn more to answer that for myself - is the topic how the compiler handles lamda expressions? Is the reference I want the spec? Seems like you could use lambdas and never need to know this about them. Oh wait, are decltype and sizeof examples if unevaluated expressions? Ha! I read it as though he was comparing lambdas to size of and declspec in that size of could be in an u evaluate expression but lambdas could not. I still couldn't tell you why sizeof is an unevaluated expression. Aren't allexpressions unevaluated? Thanks in advance to anyone who points me in the right direction. 
The problem with this approach is 1. This will take longer to compile, since every new variable means you have another template instantiation. 2. If your compiler doesn't fold functions with identical assembly together, this will bloat your executable. On my machine this adds almost 10K to the executable, which is not insignificant considering the executable is 24K to start out with. You could probably lessen this effect by deriving from a private common base which contains the actual functions and having inlinable wrappers, but that might lessen the effectiveness, complicate the implementation, and there'll likely still be some cost.
Oh, I get it now. Thank you.
I can't say for sure, but I think it comes from the idea that "instantiation" is where a template function or method is first defined, and you can't make any guarantees on template parameter types until the instantiation point. So the code doesn't exist until you try to use it for the first time. Consider a template class that has an increment method and a get value method, like so: template&lt;T&gt; class whatev { public: T bleh; void increment() { bleh++; } int getValue() { return bleh.toInt(); } }; You can instantiate whatev with an "int" and you're good if you never try to call "getValue." Similarly, you can instantiate whatev with a class that has a "toInt" method with no operator++ and you're good. This answers a possible "benefit," or "side effect," I'd say-- as to "why," I'd guess again that "instantiation happens when you first use it," and it's likely you can't tell with 100% certainty what errors you might have in the code until a type is solidified.
This is rather unfortunate, what he's basically saying is that `const` and `mutable` actually now mean `thread-safe` and `inherently-thread-safe`. A bit like, ["It's spelt _Luxury-Yacht_ but it's pronounced _Throat Warbler Mangrove_"](http://www.youtube.com/watch?v=tyQvjKqXA0Y).
Why is it unfortunate?
This is a little bit of syntactic sugar macro magic for case statements in C++, so that you can, for example, write the Ackermann function as: int A(int m, int n) { return CASE((m, n), (0, n) = n + 1, (m, 0) = A(m - 1, 1), (m, n) = A(m - 1, A(m, n-1)), -1); } 
I don't see how you can guarantee thread-safety if constant member functions can still have implicit side-effects such as modifying completely unrelated state like global variables or class static variables. I also can not see anything different about the mutable keyword except just warping your view of them in the context of concurrency, you can still mark any data member you want as mutable like a non-atomic integer right? 
I'd imagine it's an escape hatch for compiler writers. Being able to detect *all* possible errors could potentially be a tremendous amount of work. I'm sure you could come up with some kind of pathological case where it would require parsing the entire remaining translation unit or something, similar to tjgrant's example. It would have to do all that work and then stop and forget everything it just did, unwinding all that progress back to the point where it first considered that overload. It would have to somehow have a way of distinguishing internally all that speculative work it did, which could require either a ton of duplicated code or tagging every data structure in the compiler what a special tag so that it can all be undone. By allowing the compiler writer to bail on evaluating anything but the immediate context allows skipping this herculean and potentially difficult-or-impossible-to-implement task.
It affects all code existing or new because these rules apply to the standard library, *and all types and operations that can be used with it*. The example Herb used was that pair&lt;T,T&gt;(a, b) will invoke a copy constructor on const T. Hence, the standard requires that T's copy constructor must be thread-safe. This is true regardless of what T is. Rinse and repeat for every known operation and type and you end up with something like "it is trivially true that any type T can be used with the standard library. The standard library requires that, for any type used with it, operations on const objects must be thread-safe. Hence, for all T, const must mean thread-safe."
As I understand: Herb would *like* the new definition to extend beyond the STL. I had the feeling of some hand-waving happening at first watch, and his definition &gt; const == threadafe (bitwise const or internally synchronized) &gt; mutable == ditto isn't sufficient, sicne it would make them exchangable, which they are clearly not. He does illustrate that distinguishing between "language-const" and "STL-const" usually doesn't matter, since your types are affected as soon as you are using the STL - see slide at 14:30. Upholding the difference would mean tagging your types with "incompatible with STL". That leaves us in an awkward position that we can *teach* the stricter meanings consistently, even though we know it's a little more complicated. Fast forward five years, to a blog post "you don't know mutable and const", where someone tries to baffle by telling the simple meaning does not hold as long as you don't use the types with STL. 
This forces all legacy code to be updated and to make matters worse this isn't enforced in the language (thus never enforced by the compiler). If this is going to be a breaking change at least do it in such away that code does not compile in C++11 mode so it will help to make it easier to find and fix legacy code that a programmer wants to be C++11 compliant and not live in the land of undefined behavior. 
I think that the focus of the talk was toward code that **would** be used in a multi-threaded application, in which case everything he said is valid. I agree with you that enforcing everything to be implemented with locks would be completely ridiculous, especially if it is never intended to be used in anything but a single threaded application. I think it was just the wording of some of the things that caused some ambiguity.
Interesting, such a clarification would be appreciated. My suspicion and it's pure speculation, is that this language is being introduced so that it opens the door for STL implementations to use threads behind the scenes. Say, purely as an example, an implementation of vector that behind the scenes when resizing it allocates the new array and then moves over elements in multiple threads to gain a constant speedup. I can not think of a good reason why this new language would be imposed otherwise.
All true and a fair point. However my question is with respect to template argument deduction only. If `getValue()` were called after the function template specialization and overload resolution completed, it's no longer an failure that can be discarded, it becomes an error. If, however, such a use happened *during* function template specialization, then I don't see why it couldn't be ignored and go on to the next overload.
$1.10/21 "...contains a data race if it contains two conflicting actions in *different threads*... Any such data race results in undefined behavior." So if there are not two threads, there is no undefined behavior. It does not meet the requirements to be undefined behavior.
I don't think detecting all possible errors or rolling back a bunch of work are issues here. I'm only asking about what happens *during* function template specialization. If the class template in the example can be instantiated with a type without failure so far as the function is concerned, great. Any use of functions or members in that specialized class template that generates an error after function template specialization and overload resolution have completed is a separate, non-ignorable error.
Nothing is broken that wasn't already broken. Thread-unsafe code continues to be thread-unsafe. And thread-unsafe by definition (street definition, not C++98 standard definition) means undefined behavior. So code that previously compiled but was wrong continues to compile and be wrong. The only difference is now we are acknowledging that there exists a concept of thread safety. Although it is not enforceable, it can at least be talked about in the standard.
No, as per the video and explicitly stated by Herb, a lot of code that would have been valid in C++98 results in undefined behavior in C++11. In C++11, the STL has requirements which specify that any const operation must be thread safe, period. It doesn't say it must be thread safe only in cases where it is used in multiple threads, it says that it must be thread safe period in order to be used with the STL. Previously, say in C++98, you only made your code thread-safe if you were writing a multithreaded application. If you weren't why on earth would you go to the trouble of using mutexes or atomics when you had absolutely no need or intention of writing multithreaded code? The STL had no requirement period about thread safety, as in C++98 there was no notion of threading at all. Now, however, const operations that are not thread safe and are used with the STL result in undefined behavior. That's an enormous change, one that is entirely unneeded and one that only adds to the existing confusion and obscurity present in the language.
Yes. That code could overflow the int, which is undefined behavior. Nothing has changed to make this code any more or less undefined.
You are incorrect. Watch the video posted where Herb provides an example with std::pair&lt;widget, widget&gt;. If widgets copy constructor is not thread safe, because it happens to increment a global int, then widget can not be used with any part of the STL as the STL requires a thread-safe copy constructor. That's not dependent on what happens at runtime, that is something that is statically verifiable and hence it is a change from C++98 where one did not need to make a thread safe copy constructor period.
Fair enough. I did not refer to the standard on this issue, only going by what Herb said in the video. He says at the 13 minute mark that: &gt;Any copyable type T that anyone could ever copy in a std::pair&lt;T, ...&gt; or std::pair&lt;..., T&gt; is required to support thread safe copying. This is different from C++98 where one did not need to write a thread safe copy constructor in order to use std::pair. I mean it's not just std::pair either, Herb is saying any type used with the STL must support thread safe copy construction. If this is incorrect or I am misinterpreting it then that is my mistake.
At the 13 minute mark Herb states the following: &gt;Any copyable type T that anyone could ever copy in a std::pair&lt;T, ...&gt; or std::pair&lt;..., T&gt; is required to support thread safe copying. It's not that it must support thread safe copying if T is used in multiple threads or in a multithreaded application, no, it's that T must be thread safe period. It may or may not be used by the standard library from multiple threads, that's an implementation detail and has no bearing on whether it's undefined behavior or not. The language is clearly specifying that the STL reserves the right to use multiple threads in its implementation and so you must always provide it with a thread safe copy constructor or else you're invoking undefined behavior.
I haven't watched the video, but it sounds like you're interpreting this statement as it was intended, and that this statement conflicts with [res.on.data.races]/8. If you have an X whose copy constructor increments a global counter, and you copy a pair&lt;X, X&gt; (e.g. directly, or during vector reallocation, etc.), that is unquestionably conformant C++98/03. My reading of /8 is that this is also conformant C++11. As /9 helpfully points out, /8 forbids autoparallelizing STL implementations from observably breaking user code. It's possible that I could be reading the Standard incorrectly here, but I consider /8-9 to be very clear. (While I'm not a multithreading expert, I do read the Standard for a living, with a special focus on what STL implementations are allowed to get away with.)
Wouldn't this be easy to generalize with a parameter pack?
[Yes](http://www.reddit.com/r/cpp/comments/12zw1u/memoization_in_c11/c6zmlxu).
&gt; static map&lt;InType,OutType&gt; memo; [I had the same idea](http://www.reddit.com/r/cpp/comments/12zw1u/memoization_in_c11/c6zsri9) to use a static map about a month ago and an issue was highlighted to me then: the map will be used for every call to `memoize` where the function has the same types. That makes it significantly less useful. Fortunately, it is simple to capture a map by value every time a lambda is created, and that keeps the memoized values separate. map&lt;InType,OutType&gt; memo; return [=](InType n) {... Edit: This implementation has some opportunities for more efficiency, like using iterators instead of `count` followed by an access with `operator[]`, which traverses the map twice. See the full post of the comment I linked - it has a rather nice implementation.
See also: http://www.reddit.com/r/cpp/comments/g5l93/automatic_memoization_in_c0x/ http://www.reddit.com/r/cpp/comments/12zw1u/memoization_in_c11/
So we can now change the observable state of an object in a const function as long as it's done in a thread safe fashion? I don't think so. Because if that were the case, the cleanest way to handle thread safe objects would be for them to have no public const member functions at all. If a lock is inherently thread safe, then why does using it require a non-const (or mutable) "view" on it? No, I much rather think that thread safety is an *additional* requirement now (at least for code that might be used in a multi threading context at some point), not the only one. I appreciate that he wants to have a catchy and nice talk where he can step up like Santa Claus handing out the gift of making C++ easier to grasp, but I don't think that's actually the case. Multi threading means we have more rules to follow, not less. Or more concepts to understand, not less.
The real power of pattern-matching in functional languages is to switch on the various values an algebraic datatype (aka discriminated union type) value can take. In languages such as C++, which don't provide direct support for ADT's, they're typically implemented as sub-classes of a common base class, and this library doesn't appear to support switching on types. See [this paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3449.pdf) by Stroustrop et al for a more comprehensive approach which works with ADT-style sub-classes.
Pattern matching is much more than just case analysis and destructing algebraic data types. match/case expressions are a small subset of the functionality possible in most programming languages which support pattern matching. 
And how do you think "thread safe copying" is defined? Probably also with some wording about "two threads" and "data races", right? When you aren't using multiple threads, everything is "thread safe".
could this be combined with the new C++11 std::function? say you have declared two functions double genFunc(double x, std::function&lt;double (double x)&gt;f) { double res = f(x); return res; } double square(double x) { return x * x; } double root(double x) { return sqrt(x); } //than in your main() double A(double m, double n, std::function&lt;double (double x)&gt;f) { return CASE((getFunc(m,f),getFunc(n,f)....... 
If const means thread-safe. Why isn't the method std::mutex::lock defined as const (as its internally synchronized)?
I think I agree and I think you answered my question: &gt; *If const is thread-safe. Why isn't the method std::mutex::lock defined as const (as its internally synchronized)?* Here, observable state is changed (it gets locked or blocks) even though its synchronized ... so it would not be a good idea to slap const on it.
One thing that may become an issue is the fact that std::map is a bit slow as it is a sorted datastructure when you only really need a hashmap like structure. In C++11 you could use std::unordered_map or if you are using g++ and pre-C++11 you can use the backported std::tr1::unordered_map in &lt;tr1/unordered_map&gt;
Because const doesn't just mean thread-safe, it also vaguely means read-only. When you lock a mutex you are performing a write to it. Yes that write is thread safe but it also produces a side-effect. Just like for example the following is thread-safe, but it's not const: std::atomic&lt;int&gt; x = 0; ++x; No one would suggest making the pre-increment operator const even though it is thread safe. But honestly, I think your bigger picture point that this is creating more confusion than it's solving is a valid one.
&gt; *and all types and operations that ~~can be~~ **are** used with it.* FTFY. I think if your class will never be used with the standard library, then it can revert to the C++-98 definitions of const and mutable.
Well, the advantage of using a template is you can specialise the cache based on the function and/or other parameter types. For factorial() you wouldn't map&lt;&gt; 32bit or 64bit integers anyway. factorial(21) is going to be greater than std::numerical_limits&lt;unsigned long&gt;::max().
factorial() accesses previous results sequentially, so sorted order is exactly what you need. There's no random lookup, or sparse keys, so you want something flat, like a &lt;vector&gt;, for best performance and good data locality. I'll grant you that you don't need ranged queries but, unless you use "key modulus table-size" for your hash function, it's not going to perform as well as a &lt;vector&gt; in sequential cases. There's also the tiny overhead of the bucket list indirection. Which is my point... a template allows you to specialize the memoization code for different algorithms. Which is good, because different algorithms have different access patterns.
Fix8 takes a different approach to QuickFix. The primary benefits are: low latency; ease of development; complete FIX schema flexibility; lightweight; ongoing development.
I see what you mean and I agree. Sorry for the confusion, I initially thought you meant templating the types of the std::map. Not the much more clever notion of actually templating away the storage container.
Yes, this is just a bit of syntactic sugar. To add ADT discrimination, I'd probably add global tag objects for each type in the union, with overloaded == operators; I'm not sure how one could come up with an elegant/simple syntax for destructuring though, still thinking about that one.
When talking about throwing exceptions if the precondition isn't met: "Exceptions are used to signal a failure inside the function (failure to do what it is expected to). We are now abusing the exception mechanism a bit to signal a bug outside of the function." The same way std::vector::at() abuses exceptions if your index is out of bounds? Shouldn't you throw exceptions when your function is being misused? I think you should.
As you said scanf is a relic of the C language, you shouldn't use it in proper programs, and if you do you should feel bad! But C++ is retro-compatible with C, so if you really want you can use it.
In my opinion scanf is a much terser way of doing formatted input processing. Let's say you have a CSV file with some fields: 1,2,3.0,4.0 With scanf it's trivial to read the formatted input (note I spaced out the format string, so it'll also match any amount of whitespace in the fields, including none): int aa,bb; float cc,dd; if (scanf(fgets(str, BUFF_SIZE, stdin), "%i , %i , %f , %f", &amp;aa, &amp;bb, &amp;cc, &amp;dd) == 4) { &lt;do stuff&gt; }; With cin you'd have to do something like this, that people seem to not even be sure works (or maybe you can use a 3rd party library as the second answers suggests!): http://stackoverflow.com/questions/1894886/parsing-a-comma-delimited-stdstring cout's similarly limited in generating formatted output compared to printf: printf("% 3i, % 3i, %7.3f, % 7.3f\n', aa, bb, cc, dd); Will give you: &gt; 1, 2, 3.000, 4.000 (though HTML is messing up some of the whitespace) While the same using cout is...verbose: cout &lt;&lt; setw(3) &lt;&lt; aa &lt;&lt; ", " &lt;&lt; bb &lt;&lt; ", " &lt;&lt; setw(7) &lt;&lt; setprecision(3) &lt;&lt; cc &lt;&lt; ", " &lt;&lt; dd &lt;&lt; endl; It's a relic, but it's a terse relic that works. There's a couple things that iostreams do better though: * You can have issues with overflowing char* when processing %s, which can lead to security holes however, cin gets around this by reading into std::strings which expand to hold the data. * You can't expand printf to work with new types. If you have a class and want to be able to output it, you can overload &lt;&lt; to make it work with cout, but not with printf (I usually just create a print function overloaded on the type of the class myself). Similarly if you want to be able to initialize a class from stdin, you can overload the &gt;&gt; operator and make it work with cin. 
"verbose"? i'd call it hideous and nearly unreadable :) 
You honestly need read no further. This man speaks the truth. It really comes down to preference and context--as long as you remember the "gotchas" of each approach (such as scanf and char* overflowing), either one can be happily used. On a side note, since you're in college, if your professor seems to be of the opinion that cin/cout are the only ways you should ever do IO, juuuust listen to him. Professors tend to get like that for whatever reason.
You aren't quite being fair, however, because in your example the task is to read exactly 4 fields into two ints and two floats. In the example "C++" solution link you posted, the problem was to parse an arbitrary number of comma-separated arguments, which is a significantly harder problem. The "cin" way to solve YOUR problem is this code: int aa,bb; float cc,dd; char comma; cin &gt;&gt; aa &gt;&gt; comma &gt;&gt; bb &gt;&gt; comma &gt;&gt; cc &gt;&gt; comma &gt;&gt; dd; Notice how it ALSO matches any amount of whitespace in the fields, including none. Notice how it ALSO ignores the failure case (although with an exception handler we could detect it if we wanted to). However, the "C++" version only needs 1 byte of storage in the tertiary variable, not BUFF_SIZE. It also will not fail if BUFF_SIZE is too small (what if you put 10kb of whitespace between the two letters?). It also doesn't create potential buffer overflow exploits (like yours might), AND its fewer lines of code and less memory allocated on the stack. Notice as well that the cin version doesn't need to even be AWARE of the types of the variables at all. If we someday decide to make aa a float, then all the input code magically adapts, which is NOT the case with scanf and its derivatives. cin is safer, simpler, less memory, and more terse, in pretty much EVERY case, than scanf. You do have a point about cout's formatted output being more verbose than the alternative, but imho its significantly more readable. If you don't actually know ALL the format codes by heart and exactly how to parse them, then reading both lines of code at a glance, the cout one is a LOT clearer. It could probably be understood by someone who doesn't know C OR C++, whereas a novice could read the C one quickly and not even realize that any special formatting rules were going on.
You should not use `scanf()` in C++. It's not type-safe, and it also requires that you use C strings. That's a recipe for undefined behavior (crashes, corrupted data, vulnerabilities, etc.) if you're not careful. C++ strings are vastly superior, and I question the competence of anyone using C strings in C++ code. C++ instruction is generally terrible, and it results in people being taught this "C with classes" nonsense, where none of the proper C++ abstraction techniques are used, and the language is treated as if it was C with a few extra features instead of a completely different language. If you want to write C that's fine, go and write C. But don't try to pass that off as C++. Of course, the education pattern results in a lot of people that see nothing at all wrong with writing this style of not-C++, and who see nothing at all wrong with sacrificing safe, reliable, maintainable programs for saving a few keystrokes. 
I wonder how old [those photos are.](http://isocpp.org/files/cnb.PNG)
&gt;C++ strings are vastly superior, and I question the competence of anyone using C strings in C++ code. Question all you want, people who need the performance stick to using sscanf because it really is significantly faster than using the C++ alternatives in certain cases. Boost, which has a type safe variant of sscanf posts benchmarks that also show that using sscanf is faster. In applications that I work on where performance is critical, such as high frequency financial applications, those 'incompetent' developers are using a lot of the lower level facilities provided by C. C++ is not a perfect language, and just using the 'proper' C++ way because of some ideological affiliation with the language is not a sensible approach to engineering. Some people put aside ideology for the sake of actual productivity and in some cases, although not all, the C standard library is significantly simpler and also faster; that's why people still continue to use it.
Using scanf for performance issues is fine, but be sure and measure on your own system, you mileage may vary. And as noted you'll want to be sure that you have a moderate control of the inputs so that you won't find a hacker using the %s overwrite trick and suddenly wonder why your application is no longer doing what you intended it to do. Thirdly if you are writing code for which you have no control over who else may use it, the C++ version using cin will run if they have created their own overloaded istream &amp;operator&lt;&lt;(istream &amp;,T)
One major reason scanf and similar functions are discouraged in C++ is because of security risks. I would suggest if you're writing a paper this, you should include a section discussing security. Here is a [stackoverflow](http://stackoverflow.com/questions/2430303/disadvantages-of-scanf) question and an entry on a [security site](https://buildsecurityin.us-cert.gov/bsi/articles/knowledge/coding/816-BSI.html) as a starting point for research.
But people often have the wrong impression about this. As that stackoverflow page says: &gt; Most of the answers so far seem to focus on the string buffer overflow issue. In reality, the format specifiers that can be used with scanf functions support explicit field width setting, which limit the maximum size of the input and prevent buffer overflow. This renders the popular accusations of string-buffer overflow dangers present in scanf virtually baseless. Claiming that scanf is somehow analogous to gets in the respect is completely incorrect. There's a major qualitative difference between scanf and gets: scanf does provide the user with string-buffer-overflow-preventing features, while gets doesn't. 
Well, it's only talking about multiple threads here. So if your copy constructor isn't thread-safe and you're invoking it from different threads at the same time, it can fail, just the same as any other function. Another note here, though, is that you need to worry very hard about the copied object. The thing you've copied had better be a total and complete deep copy, not a shallow one that retains handles to the same resources that the original had. If that's the case, then not even the new definition of const will help you. It simply comes down to knowing what code is safe to call on multiple threads concurrently, and what code is not. It's the same as C++98 or whatever. Now that threads are in the standard, the standard has to think about them. It wasn't in the standard before, but we sure as heck use threads with C++98, and see these same problems. If you look in for example VS2010's iterator debugging version of std::vector, you'll find all these same mutexes, and that's DEFINITELY not C++11.
&gt;So if your copy constructor isn't thread-safe and you're invoking it from different threads at the same time, it can fail, just the same as any other function. If your copy constructor is not thread safe and you use it within the STL, it's undefined behavior, regardless. Herb Sutter has clarified this and Bjarne will be devoting a chapter to it in his revised C++ reference book. &gt;The thing you've copied had better be a total and complete deep copy, not a shallow one that retains handles to the same resources that the original had. This couldn't be further from the truth. I don't even know the premise of this statement. Plenty of copy constructors avoid making deep copies for performance reasons or even just semantic reasons. When you make a copy of an std::shared_ptr, you're not making a deep copy of the object pointed to, that would defeat the purpose. Some implementations of std::string don't make deep copies either, instead using copy-on-write optimizations. Immutable objects also often don't make deep copies because it would be a waste, for example large bitmap classes will avoid deep copies or implement copy-on-write. &gt;It's the same as C++98 or whatever. If it was the same then Herb Sutter would not, after numerous conferences, talks, and an update to his book, say over and over again that perfectly valid code in C++98 is now invalid C++11 code. It is not the same as it was before. &gt;If you look in for example VS2010's iterator debugging version of std::vector, you'll find all these same mutexes, and that's DEFINITELY not C++11. VS2010 is C++11.
C++11 doesn't make threads appear out of nowhere. Only threaded programs suffer from these issues. Ok, you're correct that my phrasing of the deep copy thing is poor. What I meant to say was that once you call a non-const method on the new copy, it had better not modify the original in a thread-unsafe manner, as a shallow copy might allow. So it still comes down to knowing what function changes what data, and on what thread. VS2010 only supports parts of 11, but you're right there.
&gt;C++11 doesn't make threads appear out of nowhere. Only threaded programs suffer from these issues. What Herb is trying to convey in this video is that the C++ standard library has been changed in C++11 so that it is allowed to use threads as part of its implementation. That means when you use a type with a C++ container, say for example an std::vector, the std::vector is allowed to use multiple threads as part of an implementation detail completely isolated from you the user. So, how does the STL know that it's safe to copy, or move an object as part of say... a resize operation on a vector? Say Acme Inc's implementation of the STL decides to implement the resize by spawning multiple threads and each thread copies/moves just a segment of the vector... how does it know that it's safe to do so for a generic type T? Well the answer is that in C++11 the standard has changed its language to specify that any const operations on a type T must be thread-safe. This way, the STL is able to perform any const operation in multiple threads if it so chooses to do so. It may or it may not, you as a consumer of the STL just have to be prepared for the situation where it does, meaning that if you want to use your types with the STL they need to have thread-safe copy constructors, and thread-safe const operations in general. This is the BIG change Herb keeps referring to. He keeps on trying to repeat over and over again that this is a significant change from C++98 that will invalidate a lot of old code. He isn't saying this and emphasizing this for no reason and if you look on isocpp.com or C++ discussions elsewhere, it seems to be a point a lot of people don't realize and are misunderstanding.
Your point is well-explained and well-understood. What does the standard say about thread spawning in seemingly-non-thread-related functions like vector.push_back()? My mind has been warped by game console programming, so an STL implementation that chooses to do what you described didn't even occur to me. Thanks for the insight.
I've been using Scanf over cin for a while now. I think you have just changed my mind.
furthermore, the real problem with scanf is when used with user defined format strings. scanf isn't evil, it's just an old API that is highly effective; even with the modern constructs of iostreams and variadic templates it remains stubbornly difficult to improve on or replace. in short, it's difficult to improve upon a hammer.
Good way of putting it.
I meant the other line above the one you edited (it's now slide 13): if I understand things right I think it should be `auto it = m.cbegin()` for it to guarantee returning a `map&lt;yadayada&gt;::const_iterator`. Sorry for my late reply.
I can't claim to know all of the format codes by heart, but I know the 40% I regularly use, and I can look the rest up if I need to. There's something to be said about having all of the information in one place and not needing your eyes to move that much. I do agree that cin ought to be used over scanf, hands down no questions asked. But I find myself gravitating towards libraries like tinyformat to get printf style functionality in a properly C++ context. (Without the format vulnerabilities.)
&gt; Notice how it ALSO ignores the failure case (although with an exception handler we could detect it if we wanted to) You don't even need that (in fact, iostream objects don't throw unless you explicitly turn on that behaviour). You only have to put an `if (!cin) { ... }` check after you finish reading the line. Simples!
will this be put in any linux (ubuntu, fedora ?) repositories in the near future?
Web Development Framework
Comet? aren't they missing the websocket boat?
I am working on a project of mine that necessitates a lot of compile-time tree manipulation. I recently wrote a library that implements generalized postorder/preorder traversal on n-ary trees, permutation of a variadic parameter pack given a permutation vector of indices, and a lot of other goodies. All of the algorithms rely on sequence concatenation, replication, and reversal at their core, which is kind of interesting.
There's a field called symbolic computation that deals with this sort of thing. Assuming that you have a minimal mathematical background (calculus, differential equations) and have studied algorithms, then I would recommend an introductory book [like this one](http://www.amazon.com/Computer-Algebra-Symbolic-Computation-Elementary/dp/1568811586/ref=sr_1_3?ie=UTF8&amp;qid=1357450039&amp;sr=8-3&amp;keywords=symbolic+computation) to you. If you have just started to learn how to program and have not studied algorithms, do not buy this book now. Instead, you'll need to gain a good grasp of C++ (a language that is already difficult to learn how to use properly), and then read a [basic algorithms book](http://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844/ref=sr_1_2?s=books&amp;ie=UTF8&amp;qid=1357450348&amp;sr=1-2&amp;keywords=algorithms). It would help if you know how to write mathematical proofs, and have some experience with discrete math. If you want to read more advanced material in the field, then I anticipate that you will need a much more rigorous mathematical background (linear algebra, abstract algebra, analysis, etc.).
Thanks, I'll check them out.
I found Accelerated C++ a bit... "accelerated", C++ Primer goes more in depth and the new version covers C++11 and all of it's features.
&gt; What does the standard say about thread spawning in seemingly-non-thread-related functions like vector.push_back()? vector&lt;UDT&gt;::push_back() is forbidden from using multiple threads. See N3485 17.6.5.9 [res.on.data.races]/8-9, mentioned in my other comment here. vector&lt;int&gt;::push_back() could copy separate elements with separate threads, because that would be unobservable.
I definitely recommend *[C++ Primer](http://www.amazon.com/Primer-5th-Edition-Stanley-Lippman/dp/0321714113/ref=sr_1_1?ie=UTF8&amp;qid=1357520517&amp;sr=8-1&amp;keywords=c%2B%2B+primer)*. I'm just starting out learning C++, and the primer does an absolutely amazing job teaching me. The *exercises* section at the end of each chapter are particularly helpful.
"Allow the user to choose output encoding". Nooe, nope, nope. Just use UTF-8. The only reason to do otherwise is performance and this better be documented and measured. I hope he has a post where he says why I'm wrong.
That's good to hear. At least it's sane! Thanks, Stephan! Of course it would not be observable with respect to correctness, but would be observable with respect to runtime. Perhaps someone is running 8 processes on an 8-core machine in some kind of data center, and copies a lot of vector&lt;int&gt;s around. More threads wouldn't help that program run faster in that situation. I'm using the process example because intra-process thread communication might at least be relatively easy, whereas such communication about CPU availability inter-process would be a bit harder. Once again, I fully admit that my mind has been warped by trying to fit large codebases onto small systems, but it's *super* annoying to have unpredictable threads like this. One of the things I like about the STL, by the way, are the very explicit iterator invalidation rules to do with types like vector and basic_string. That means you can control the time and size of allocations and deallocations very well, given some upfront care. I would expect the same to be true of any implementation of the STL w.r.t. memory, and I'd expect the same for threads. Anyway I'm not making any points about the STL as it is or as it might be shipped by Microsoft or anyone else, because my office has its own implementations of common STL containers. We keep them compatible with the STL itself, so we can switch to the excellent iterator debugging support that comes with many STL implementations when the need arises. EDIT: Here's kind of a long-shot that's a little bit relevant here. Let's say that rather than optimizing runtime on a sparsely-used multi-core computer, a vector&lt;int&gt; implementation were trying to optimize memory use in the case of a push_back that runs over capacity. It *could*, in magical theory, write the container's contents to a file, de-allocate the buffer, re-allocate the larger-sized buffer, read the old contents from disk, and celebrate. It could even do that based on failure of the re-alloc. But I'm not aware of anyone actually doing that. It's optimizing *some* case of program execution, at the expense of some other. Using threads under someone's radar is the same kind of thing.
I like this source: http://www.utf8everywhere.org/
Since appears the OP and blog author are one in the same: Please link to the other 4 parts of the series on the blog post. In fact, you should probably do that for each of the posts. Ain't nobody got time to track'em down.
Yup. Dealing with multiple encodings is a horrible PITA. Even in stable, mature apps like Emacs occasional encoding problems pop up. UTF-8 everywhere is the way to go.
If you plan on learning C++ from books and given how much detail might matter I would suggest you to pick up some "Careful reading" skills. If you had e.g. checked the lower end of the sidebar (on the right) you would have found a section "Books" which has a link that contains an excellent list of suggestions.
Depends on the application. It should certainly not be in the "normal path". But while I appreciate the lure of "UTF-8 everywhere", there are millions of people still using thousands of applications that don't accept it. Don't leave them hanging. Ideally, the format conversion would be isolated, but that's not always an option. 
&gt; Nooe, nope, nope. Just use UTF-8. No, input and output encoding of user files it's a user decision, not a programmer's one. you may propose UTF-8 as default if you like it, but the user must have a chance to change it!
Actually UTF-8 may be a good choice but as today there's not a standard portable C++ way to handle UTF8, and unless it will arise you are forced with other frameworks. You are free to do that for your internal encoding. And remember that the most spoken language in the world in not English :) Many good points of utf8 everywhere apply to other encodings as well. The truth is that having to handle a single encoding would be much better. And *personally* I would choose UTF16....
tnx for the hint! I will add these links ASAP
u can shoot the author an email...
&gt; Of course it would not be observable with respect to correctness, but would be observable with respect to runtime. That's what's referred to as a "quality of implementation" issue. As an STL maintainer, I can tell you that I have no desire to secretly autoparallelize stuff. That would introduce significant implementation complexity, in addition to harming performance for some users. I love secret optimizations, but only when they can't harm anyone (e.g. vector&lt;int&gt; reallocation invoking memmove() to blast bits faster than a Core Language for-loop). (The VC11 compiler back-end has an autoparallelization mode, but it has to be explicitly requested.) &gt; One of the things I like about the STL, by the way, are the very explicit iterator invalidation rules to do with types like vector and basic_string. Me too. STL implementations have to be surprisingly complicated, but in the end you can count on them to do predictable things on the hardware.
UTF-8 is less efficient with east Asian languages, where the multibyte encoding is much more likely to assign 3 or more byte to a codepoint (as opposed to Western languages, where usually 1 or 2 bytes suffice).
&gt;The unicode standard discourages the usage of the BOM in UTF8 text files. Anyway, at least in Windows, using an UTF8 BOM is the only way to automatically detect an UTF8 text file from an "ANSI" one. So, the choice it's up to you, depending on how and where the generated files will be used. Personally, I tend to prefer the presence of BOM, to leave all the ambiguities behind. Please don't do this. [From the FAQ](http://www.unicode.org/faq/utf_bom.html#bom5): &gt;Note that some recipients of UTF-8 encoded data do not expect a BOM. Where UTF-8 is used transparently in 8-bit environments, the use of a BOM will interfere with any protocol or file format that expects specific ASCII characters at the beginning, such as the use of "#!" of at the beginning of Unix shell scripts. Windows Notepad's interpretation of a UTF-8 file as ANSI is broken. Please don't create broken UTF-8 files for notepad's sake. 
This is the 5th and hopefully final time that I have taken all the papers on my desk and just thrown them straight up into the air.
The other legitimate reason for that would be a text editor, at least until UTF-8 utterly takes over.
Something wrong with http://utfcpp.sourceforge.net/ ?
because IMHO it's the best trade-off between storage, manageability and performance
Exactly what I said. If you are using UTF8 in place of ASCII, you don't have to put a BOM. But, in Windows, you simply can't automatically detect an ANSI file from an UTF8 one. If the world was "UTF8-everywhere" it may have been ok, but in Windows MOST of the text files are saved in the active code-page because in Windows 8bit data tend to be interpreted that way. This is the real world, and a BOM is useful in this regard. BTW defaulting to UTF8 when all the text data was previously saved in ANSI is not a good compatibility choice. Linux went the UTF-8 way , Windows went for the compatibility way. Everyone is right, but this is reality, you just can't assume UTF-8 input. 
The .NET XmlSerializer does not insert a BOM when serializing to utf-8, and it throws a parsing exception deserializing if the input contains a BOM. So even in Windows, using a BOM for UTF-8 breaks things. It's a good article and I'm not trying to knock it. You are right that the BOM is technically optional for utf-8, but in practice it's presence breaks more than it fixes, even for windows, at least in my experience. 
export option? why make it easy to allow mass fragmentation when utf8 is the right way to go?
nope :) It's one of the ones that I would like to try!
In reality I don't have a strong opinion about this, just a personal preference resulted from my specific experience. I knew it was discouraged by the standard. Anyway, in windows I found that having to handle user text files is really ambiguous , since most user have ANSI code-paged files, but sometimes these files were saved in UTF8 (indeed these users had a modern editor :) I may agree that saving a BOM can be breaking, but I think that at least "reading" a BOM should be a valid (maybe optional) operation. That said, I see that many programs and text editors still save the BOM , even on linux and as today I never had a breakage issue with any software (except , ironically , with Windows INI functions :) Instead of the BOM, an ideal solution would be storing the encoding as file metadata or something similar, so there would be no ambiguity at all, but I guess it's not possible :) I will remove that suggestion in the post, since it's too personal and specific! tnx
I use it, works well.
ahah :) You'd better buy a ream of paper: I'm already thinking about the next series, a survey about unicode support in various frameworks and toolkits!
Great. The next religious war in computing, only this time not between Emacs and Vim, but between UTF8 and UTF16.
Thank you for this series! I found it very interesting. I personally am using UTF8 at the moment because it works well with Lua strings (which are essentially byte arrays).
You're also in /r/cpp YOUR OPINION DOESN'T COUNT.
Actually `assert`s have long been used to ensure that preconditions and invariants are guaranteed. Given that calling a function incorrectly is not "exceptional" it's just straight up a bug 
Default counterargument: even the Wikipedia body would not benefit from UTF-16 encoding (probably mainly due to the HTML markup). This is frequently referenced in this discussion, but I couldn't find an authorative source of someone who, I don't know, counted the bytes or something. --- I understand how the choice of UTF-8 as default appears to have "western bias", but I still see solid neutral arguments that support this choice: **Populace.** while most spoken language is certainly a good thing to ask for, for the state of the art we could as well look at the most *written* language. Also, how big is the margin? I don't have any numbers ready, but I see this as a weak counterargument anyway. **Backward compatibility:** As I understand, the non-Unicode writing systems for east asian languages were very fragmented and specialized (please correct me if I'm wrong). An UTF-16 implementation could not have been backward compatible with these, without sacrificing UTF-encoding robustness. So the choice would be "Backward compatibility for plain ASCII vs. backward compatibility for noone". (While that might have improved early implementation and awareness, it would also have slowed adoption.) **Amount of data.** It is true that large bodies of east asian texts encode tangibly shorter in UTF-16 than in UTF-8. Processing speed as such I doubt, since you still have to handle surrogates. It is also true that the information density of east asian synbols is higher, some quick google translate experiments show that with a German --&gt; Chinese (simplified) translation, you have about 1/3rd of the symbols in the translated text. Meaning: if you take a German text, translate it, and encode both as UTF-8, there won't be a large size difference. ---- Now, it still remains that if you do process a large body of text in an east-asian language, you are better off with UTF-16. This is one reason why I don't subscribe to "UTF-8 fundamentalism". However, for *most* applications this will be a tradeoff between a little more data vs. a wider range of libraries + implementations available, and I'd not hesitate to pick the latter. 
The proposed version allows things like this: auto future = async(heavy_function); // do more stuff that doesn't rely on the result of future future.then(when_ready);
I would like to know too. But whenever i'm looking for something I use [cplusplus.com](http://www.cplusplus.com/reference/)
If by STL you mean the standard library, then it's way too big for a cheat sheet, but the best online resource is by far [cppreference](http://cppreference.com) If you are on linux you can always pull up the man pages by typing out it's prefixed name. man std::string for example, you can always read the source too at `/usr/include/c++` on most *nix systems.
yup that is the best documentation
I guess there's some good point in that, thanks. They recommend using cppreference which seem's pretty good.
STL source is the worst kind of STL documentation, not only because it's most likely somewhat obfuscated to make sure none of its identifiers accidentally clashes with identifiers in the application using it, but also because it doesn't mention all the details such as algorithm complexity, iterator invalidation etc. (at least not explicitly). Also the STL implementation might have bugs.
I've always liked [SGI's STL Documentation](http://www.sgi.com/tech/stl/table_of_contents.html), even though it has non-standard extensions. But that doesn't include the rest of c++...
I would like something like this too. The STL containers, algorithms, and a few other odds and ends should fit in a &lt;20 page cheat sheet if you can use a small font and/or multiple columns.
Can someone explain the difference between the Standard Template Library and the Standard Library? Wikipedia says they are two different things. But is there a rule of thumb about it or something? Can someone explain how to think about the two in practical terms? Thanks in advance.
On my Gentoo system there is no manpage for `std::string`. Do you know where that manpage comes from on your system?
The standard library is just that (i.e. everything that resides, according to the C++ standard, inside the namespace `std`). The [Standard *Template* Library](http://www.sgi.com/tech/stl/) is a proprietary library developed by SGI in the 80s / early 90s and which formed the basis of much of what is today the C++ standard library, notably the containers and algorithms part of the library. However, although there are pedants who’ll always correct you when you use STL instead of standard library you can take solace in the fact that even compiler and standard library developers occasionally use STL as a shorthand since the the term has by now become almost synonymous, and since the original STL is no longer in use anyway.
On gentoo this should come with sys-devel/gcc. Maybe you have to the doc USE-flag for gcc.
What's the difference between that and: auto result = async([](){ auto result = async(heavy_function); // do more stuff that doesn't rely on the result of future when_ready(result.get()); }); I'll start, two futures instead of one.
Maybe it's not be appropriate for `do more stuff` to be included inside of a call to `async`. One could always write auto result = async(heavy_function); // do more stuff auto v = result.get(); auto final_result = async([&amp;]() { when_ready(v); }); // do even more stuff? I definitely prefer the proposed version.
With the proposed version, the future could be returned from some callee and have different "then" functions tacked onto it. Basically it separates "what you do when the future completes" from "future creation".
Good point.
Are the changes you make shotgunned all over the code, or are you working in specific areas? When exploring something new I'll often spend some time grepping around the code to narrow down the area(s) I have to concentrate on. Once I find a particular function that looks interesting, I'll set a breakpoint there and when I hit it start walking back up the stack to get a feel for how I got to that specific point. Very often I'll have a notebook next to me where I'll sketch out call chains or data references. Sometimes I'll draw the data structures as they get modified and walked so I can fully grasp what is happening: I'm not able to visualize complex data interactions without pen and paper. If you have unit tests that allow you to isolate the code you're working on, that can be really useful. In the codebase that I work on (also a huge amount of C++) I've gone so far as to add "unit" tests (using Google Test, but pick your poison) that attempt to isolate the functionality I need to work on so I can focus on it without the rest of the baggage. Honestly it just takes a lot of practice. Cross-referencing tools are useful, but I started doing this long before these were readily available so I don't use them as much as I should (though I've recently started using GNU GLOBAL, which is pretty nifty.) 
By "debug" do you mean fix some sort of crash? If so, are you talking about something highly reproducible? Are the runtimes really long? A lot of stuff I've had to debug needed to run for hours before hitting the problem. Can you get your hands on core dumps? See, the advice really depends on exactly what sorts of problems you're fixing: memory corruption type thing vice a logic error of some sort vice a race condition. More generally: Step #1 in debugging anything is nail down the simplest and fastest way to repeatedly recreate the problem. Even if just getting to the point where you can easily recreate the problem takes a few days, then so be it. You may have to go to great lengths to mock-up data and infrastructure surrounding the misbehaving thing. That's time better spent than randomly wandering around in code pondering things. Once you're as close to that point of easy recreation as you can get, home in on the instant the problem manifests. Again, you may have to go to lengths to setup logging infrastructure; litter code with print statements and so forth. Ideally you don't have to do that and can use the debugger. Once you see the instant the problem manifests and where, examine possible routes to the state that causes the problem, if that's necessary. Sometimes I've had to litter print statements in constructors, destructors, and accessors of all the stateful types immediately relevant to the problem in order to trace backwards to where things went wrong. A useful trick is to include the address of "this" in all the print statements so you can track which is which. Use static ints that get incremented to track when what happens.
Looks great!
If the two "things" you want to do are within the same scope and both controlled by you, then put them in the same lambda. But the whole point of this exercise is to handle the case *when you get a future from somewhere else*. Maybe you have a file IO library that opens a file asynchronously and hands you back a future. You want to be able to say "whenever that future completes, run this lambda".
That's a nice looking library. Thanks for sharing. I did notice one small error in the tutorial under "Custom Generators" you have `return std::move(xs);`.
It sounds like you're just reading code rather than using debugging tools available to you. Is this the case?
I'm still figuring out when and how to use rvalue references; maybe you can help me. My thinking here was that when I return the local variable `xs`, the copy constructor will be invoked. I'd rather call the move constructor, so I wrapped it in `std::move`. What should I do?
C++11 will invoke the move constructor if it exists if you return by value, unless the object can be constructed in place (RVO). You don't need to invoke move to accomplish that, since foo() is an rvalue (caller's perspective). Hope that helps.
You mentioned having to revert your changes. Are you making patches before you revert? That can save you time and effort, so you're not having to code / revert / recode.
That's ironic, recently my big job has been to architect some "unit" tests (the code is complex enough it's a stretch to call then "unit tests") using Google Test. From this you can probably gather that I don't really have unit tests at my disposal, but I am currently writing them for the team. :P So, since I'm basically putting the skeleton of this new architecture into place, it kind of feels shotgunned since there are many places it needs to reach to run at all. I was afraid of the "it takes practice," answer. I have a feeling that I have really good basics and programming practices ingrained, now all I really need to do is suck it up and ~~take the pain~~ do the practice like all other decent programmers. I also keep a notebook at my desk for notes and diagrams like you mentioned. It is handy. :) Still like to write things out even after having worked so much with computers. Thanks for the response! Hopefully I will find my groove in large code-bases. 
So far all the bugs I've dealt with were my own and very reproducible. As I said in my reply to treerex, I'm writing new test code so I'm not really worrying yet about memory dumps or timing or anything that would really require tools outside Visual Studio, actual code, or the repository really. Thanks for the advice! For me personally it sounds about the same vein as treerex's advice since I think I do a lot of that stuff already. I am just very new to the field (graduated in comp sci last May), so debugging to this extent is new to me. That being said, are there ever times where programmers get completely stumped and can't keep "following the trail" so to speak? I know sometimes I feel that way, but then I'll ask for help and I see how other programmers found a route that I had missed or didn't think to follow. 
I don't think I've ever heard of patches in terms of repositories before. I have heard of "stash" which I'm not totally familiar with either...
Not a problem. Are you using TortoiseSVN? They make it easy. You just have to right-click on the folder and choose 'Create Patch' from the context menu. This creates a diff file of all the changes you've made. To apply those changes later, you choose 'Apply Patch' from the context menu. http://tortoisesvn.net/docs/release/TortoiseSVN_en/tsvn-dug-patch.html If you're using linux, you can create a patch like you would in any other code-base: http://lab.ac.uab.edu/node/1153
That does help, thank you.
Just graduated in May? Congrats, and welcome to the field. Hopefully you'll find it as rewarding as most of us do. As far as debugging goes, my go-to advice is to not forget the "Science" in Computer Science: hypothesize, test, etc. etc. For me, I try to narrow down which "module" or object-grouping it's in. Then it's just to keep narrowing down the search. It doesn't matter how big of an area you're working in, as long as you can say with certainty where the problem isn't.
Thanks! It certainly is rewarding - especially on my smaller project(s) which don't overwhelm me quite as much. :P I have started to get very comfortable with the "narrowing things down" routine. It's just that sometimes the narrowing can result in my problem splintering, if that makes any sense. But one coworker suggested just brute force commenting out large chunks of code so at least there are less errors in your face. (Sorry I'm making that jump between compiler errors and run-time errors again) That seems to help a lot. I am working on the practice part of programming. I used to think that programming (my dad is a programmer) was just something you did and didn't necessarily require practice to get better at. I suppose I'm still trying to shrug off that old mentality. :) 
Ooo yes I am using TortoiseSVN, how fancy! I will have to look into this a bit. :) I am amazed sometimes by how bad programmers can be at using the repo. I think I'm one of maybe 3 or 4 programmers that seem comfortable using branching. This surprised me greatly, being the noob that I am. And unfortunately we use Windows at work, but I am not unfamiliar with Linux so I might look into that for more educational endeavors. Thanks for the useful tip! :) 
Some of the "tricks" I use * Before you even start debugging, think of what could cause this bug. E.g. why is it that the bug happens when I do this, but not when I do that? What could cause the difference? It helps me to narrow down the most probable sub-system that can cause this problem. Then I could write additional test to test my assumption. E.g. If I do it this third way, it should be OK? * Turn on first chance exceptions (Debug-&gt;Exceptions... and check C++ Exceptions). For some MFC crashes, the place which the crash brings you and where exception is thrown is different. * Learn to use more advance breakpoints (e.g. data break point/conditional break points). For unit tests, since the way it is run is always the same, the Hit Count break point is your best friend. Trace points can be useful for debugging "matching problem". E.g. memories leak, where object constructed have to match object destroyed. * A heuristic I use is that, most often, the code that breaks are new code added into the system. 
Very cool! I haven't gone quite into that much depth yet, I had a couple other thinks going on over the holidays and school will keep me at least partially busy in the coming months but I'll deffinitely explore some more! Question of style for you w.r.t. TMP: for a purely TMP library, would you opt for or against using template aliases as opposed to structs for the usable interface and what are your reasons? For example, take the following: **Without Template Aliases** typename any&lt; typename map&lt; std::is_arithmetic, tlist&lt;char*, int* double&gt; &gt;::type &gt;::type; **With Template Aliases** any&lt;map&lt;std::is_arithmetic, tlist&lt;char*, int*, double&gt;&gt;&gt; One obvious reason to opt for their use would be the cleaner syntax of their use. Since you know the result is always going to be a type, the `typename` and `::type` seem somewhat redundant. The only issue that I see with is is that it's not conformant to the syntax used in `&lt;type_traits&gt;`, creating an inconsistency on when you have to do `typename ...::type` and when you don't. Any thoughts? Edit: Added last paragraph, hit submit before I was done.
What sort of bugs are we talking about? From other comments it looks like you are developing on windows. While I am not sure about your bugs but if you are dealing with crash bugs learn to use windbg and dmp files. Made so really hard to find crashes for me instantaneous. You can also use dmp files in VS but this never worked for me, something with the encryption/protection on our release builds, so it may be even easier. The worst bugs are bad threading/timing issues. If there are crashed the above will show where it crashed, but just because it crashed there doesn't mean the issue happened there, though it helps a little to know. Data break points help a lot here, understand how to use them. Also Application Verifier can be great to do a lot of things, like PageHeap, putting non writable blocks before and after ever allocation so if something is overrunning it will cause an access violation. Broken functionality is usually easier to trace through a system because it is easier to reproduce. Large code bases just take time, with some experience you will start naturally understanding the how the system works and even if it is a mess which many large old code bases are you will just knowing when an issue might be somewhere in the core system or in a subsystem. It took me about 2 years before I had a good handle on the code base I worked on and I don't even know really when it just clicked into place. 
I was more recalling what I have used doc in the past with no internet. I do completely agree that it is "poor" doc. That said, I do think it is a very good thing to read, just like reading any good code.
First, to allay any fear or anxiety you have, everyone goes through that. It's completely normal, you're not a dunce - or at least you're not more of a dunce than the rest of us. Onto the meat of the question: It's easy to debug your own work because you wrote it. Even if a code base is huge and is yours, you'll still be able to navigate it easily because it follows your natural thought processes, both past and present. I promise you all of my 100,000+ LOC projects were easier for me to navigate than everyone else's; easy enough that I was surprised to even find they had gotten that big. When it comes to understanding other people's thought processes then everything becomes a mystery. Running through the code with a debugger may help, but people have a tendency everywhere to avoid doing the hard work that really pays off in the end - thoroughly, *exhaustively* understanding the code and the motivations of its authors, even finding out what materials they recommend and reading them. The funny part is people learn these techniques in school but abandon them once they get into the working world. In school what do you do to pass a course? You get an overview, you take notes, you draw diagrams, you memorize, you analyze deeply, you cross-reference, you conduct interviews. Well, a lot of people cram, but you get my point. Now it's the big time and cramming doesn't work anymore. I think I know why people do this too, or at least I understand why I do it. There is immense pressure from all sides to create a working product in a given timeframe, and no time is worse on a person than at the very beginning when they have just been introduced to a new code base and asked to fix something quickly. Additionally your primary introduction to code, school, may have lent to you the habit of writing and working with only your own code, especially the nearer to graduation you get. It's really hard to suggest that an author's examples "count" because they were dumbed-down to illustrate a point, not to be part of a working model. My advice is to make the up front investment and study the code thoroughly. Do the hard work. Since you'll likely be looking at it for years to come, you might as well get the icky parts over with now. Don't code by instinct based off what you know. If you're not looking at code that you don't understand very often, you're either a programming god or you're stagnating (I'll let you decide which of those is more likely). Not taking shortcuts *will* separate you from other developers and the upfront investment will pay off in faster development time, even if it seems slower becase you don't feel like you're writing much code. Well, shit, you shouldn't be writing much code anyway. You should be thinking and studying, mostly - especially at first. Measure twice, cut once. Study chess board for five minutes, move piece for one second. Sorry about the length. I hope it helps. 
All of this goes back to a common problem in programming languages. Once a language is deployed it is nearly impossible to add new keywords. Any word that you chose could break existing code if it was used as an identifier. So, they had the option of punning existing keywords like they did with 'auto' or introducing new operators.
Thanks for the tips! It really is reassuring to hear other programmers talk about it just taking some time and practice. Hopefully it will just click for me soon. It already has on my side projects - there it feels like breathing. :) I will also look into the applications/softwares you mention when I start writing code for the actual product. Thanks again!
Gah, I could use one of these for java badly.
I'm an STL maintainer, and the term isn't confusing at all. See: http://en.wikipedia.org/wiki/Metonymy If necessary, I'll say "STL proper" to refer to "the subset of the C++ Standard Library that is clearly derived from Stepanov's original work" (vector = yes, algorithm = yes, shared_ptr = honorary member, string = maybe, iostreams = no), and "C++ Standard Library" if I want to refer to the whole thing (including iostreams) with no potential for confusion.
&gt; X(const X&amp; x) { I thought the concept he was describing was about particular functions being marked `const`, like `void doSomething() const {...}`, and not functions(/members/constructors/whatever) that take `const` parameters.
The license change from LGPLv3 to MIT between 0.0.2 and 0.0.3 makes me a little sad.
Doubtful, if the community isn't specifically asking for it. C++ as a web application language is extremely uncommon. It's rare even for Wt to make it into the community repos.
I can't see why they shouldn't use C++11 features if it helps the code base. C++11 is the new standard, and it's not hard to learn, in case users have a problem with it
If you read the discussion, you'll see that it's mostly focused on what versions of compilers they need to remain compatible with. They want it to be possible to compile LLVM with MSVC 2010 and with some sufficiently old version of GCC (probably somewhere from 4.4 to 4.6). That severely limits the C++11 features that they can use.
TL;DR The C++ renaissance didn't materialize, Java survived intact, and Objective-C kept on rolling.
according to Google search statistics :/
I understand they are trying to support users with outdated compilers. But it's quite sad that LLVM is being held back because of non-C++11-compliant compilers (I'm looking at you, Microsoft) or older versions. I think that making the switch to C++11 could incite users to upgrade their compilers, though.
Do you have any intention of licensing this project in any particular way?
I've been looking for the same thing. Currently, I use a template class taken from a Dr. Dobbs article. It's the observer pattern with C# like multicast support. It's built upon C++11 **std::function**. **Generalizing Observer** *Herb Sutter* http://www.drdobbs.com/cpp/generalizing-observer/184403873 For me compatibility is more important since I use it across multiple compilers and processors. Unfortunately, it does not use variadic templates because one of my compilers doesn't fully support it (Visual Studio 2012). Gist of multi_function template https://gist.github.com/4519483 
I was wondering if there was any interest in creating a open source collaborative C++11 version of FastDelegate. We could set up a GitHub repo and work on it. I'm not very experienced in template metaprogramming, but I'm sure I can create a primitive version, which can then be improved with time. 
I have a somewhat related question: I have recently been wondering what Functors can possibly be inlined. Could anyone shed some light on this? When I have: template&lt;typename T&gt; void foo(T t) { t(); } Can the call of t be inlined if: 1) T is a struct with an operator() ? 2) T is a normal global namespace function? 3) T is a C++11 lambda function? 4) T is a std::function? 5) T is a std::function that was previously bound with std::bind? Is there any difference depending on how t is passed? (by value, by reference, by r-value reference) Currently, my assumption is yes for both 1) and 2). I am not sure about 3,4,5. I have found some info on the web indicating that 4,5 should be false. However, if 1) was true, which I am currently assuming, whats the key difference there? The std::function should be implemented as a struct with some operator(), so it should essentially be the same as 1). The same goes for 5) since you could simply simulate the call with a struct containing the bound parameters as member variables. Thanks!
&gt; 1) T is a struct with an operator() ? Yes. This is the easiest case for compilers, because the thing being invoked depends only on the type T. Therefore, the compiler can inline t() in foo() regardless of whether it can "see" all the way from the original functor being passed, down to foo() (there may be many intervening layers). &gt; 2) T is a normal global namespace function? Yes, but this one is harder. Long ago, compilers couldn't do this at all. Now they can, but they have to "see" the original function pointer being passed in, in order to figure out what t will be. If there are many complicated layers between the original function pointer and foo(), this may not happen (depending on how aggressively the compiler acts). &gt; 3) T is a C++11 lambda function? Lambdas stamp out structs, so this is identical to #1 - inlining is easy. (Stateless lambdas are convertible to function pointers, but in this case the lambda's original type would be preserved.) &gt; 4) T is a std::function? &gt; 5) T is a std::function that was previously bound with std::bind? std::function is essentially a brick wall to inliners, because of the type erasure it performs. std::function's whole purpose in life is to store functors of arbitrary types (structs, function pointers, lambdas, etc.) as long as they all conform to a given signature. This is achieved (either effectively or literally) by new'ing up an internal object Derived&lt;FunctorType&gt; that stores the given functor, which derives from Base&lt;Signature&gt;. This has a virtual function call operator. The stored functor can then be invoked after FunctorType has been "erased", through the usual magic of virtual functions. This machinery is really cool (especially because it's obnoxious for users to write in full generality, so it's best to stick it in the Standard Library), but it also does all of the things that interfere with inlining. The virtual call (or moral equivalent thereof) stops inlining unless the compiler can perform extremely advanced devirtualization. Additionally, the way the Derived&lt;FunctorType&gt; is stored, is also problematic - it is either heap-allocated, or stored directly within the std::function with placement new (the "Small Functor Optimization"). Compilers have extreme difficulty seeing through this. It is not *impossible* for inlining to occur here, but I am not aware of any compiler capable of doing so (and as MS's maintainer of VC's STL, I know for a fact that VC cannot inline std::function). This is one of the reasons why std::function should be used only when necessary and not overused - it has nonzero costs. When you can template your algorithms on functor type, you should do so.
(1) Assuming the operator() is not virtual or the compiler can de-virtualize it: Yes, can be trivially inlined. (2 + 3) If foo is inlined: Yes, can be inlined (but requires that the compiler simplifies "load address of function into register; call register" to "call function"). (4 + 5) *Maybe* if the compiler can inline everything between the construction of the std::function object and its call (which possibly includes memory allocations). I doubt it though, but haven't tested it. In all cases passing by value or by reference shouldn't make a difference. Key difference between (1) and (4 + 5): An std::function object can store anything that can be called as a function with a specific signature, from a function pointer to a lambda function object. And while the size of a function pointer is fixed[*], the size of a lambda function object depends on its captures, so copying it into the std::function object most likely requires a memory allocation. This makes it different from (1). The same goes for (5) only that it's even more complicated as std::bind essentially creates a lambda function that calls the function/method/whatever being bound (or as you said "a struct containing the bound parameters as member variables"). [*] At least that's how I interpret §5.2.10p6 of The Standard: &gt;A function pointer can be explicitly converted to a function pointer of a different type. [...] Converting [the result] back to its original type yields the original pointer value [...] This seems to require that all function pointers have the same size.
Thank you very much for your clarifications. About 5) What if I call foo(std::bind(...))? At that point, the type has not "decayed" to an std::function. Can that be inlined? If not, I guess it should always be preferred to "bind" arguments using a lambda function?
Thanks!
These don't have to be abstract questions you know. Here's a simple testcase: $ cat 20130112.cpp #include &lt;functional&gt; template&lt;typename T&gt; void foo(T t) { t(); } struct { void operator() () {} } functor; void function_pointer() {} auto lambda = []{}; auto std_function = std::function&lt;void()&gt;([]{}); auto std_bind = std::bind(function_pointer); void bar() { foo(WHICH_TEST); } $ for t in functor function_pointer lambda std_function std_bind; do printf "\n---%s:---\n" $t g++ -std=c++11 -O2 -S -o - 20130112.cpp -fno-exceptions -fno-asynchronous-unwind-tables \ -masm=intel -DWHICH_TEST=$t | c++filt | awk '/^bar()/,/^\011\./' | head -n -1; done ---functor:--- bar(): ret ---function_pointer:--- bar(): ret ---lambda:--- bar(): ret ---std_function:--- bar(): push ebx sub esp, 40 mov DWORD PTR [esp+24], 0 mov eax, DWORD PTR _std_function+8 test eax, eax je L22 mov edx, DWORD PTR _std_function+12 mov DWORD PTR [esp+28], edx mov DWORD PTR [esp+24], eax mov DWORD PTR [esp+8], 2 mov DWORD PTR [esp+4], OFFSET FLAT:_std_function lea ebx, [esp+16] mov DWORD PTR [esp], ebx call eax mov eax, DWORD PTR [esp+24] test eax, eax je L22 mov DWORD PTR [esp], ebx call [DWORD PTR [esp+28]] mov eax, DWORD PTR [esp+24] test eax, eax je L21 mov DWORD PTR [esp+8], 3 mov DWORD PTR [esp+4], ebx mov DWORD PTR [esp], ebx call eax L21: add esp, 40 pop ebx ret L22: call std::__throw_bad_function_call() ---std_bind:--- bar(): mov eax, DWORD PTR _std_bind jmp eax (This is gcc 4.7.2 on MinGW x86) The first three were inlined. `std::function` was opaque to inlining, as was `std::bind`, but the latter resulted in only a simple pointer indirection.
Assumptions on optimizations are things you should not do. If you care about some optimization, check whether your compiler does it. Consider this code: int foo() { return 4; } int main() { auto ptr = &amp;foo; return ptr(); } VC2012 generated following code for main: 00C51010 jmp foo (0C51000h) it only does a jump to foo here - it knows that the pointer is foo and it optimizes the tail call, but bails on inlining. gcc cares about such cases more and removes everything (optimizes main to 'return 4'). What to take out from this? If you care, check for yourself on platform/compiler version you care about - only because optimization is possible doesnt mean its implemented (or enabled/configured etc ...).
&gt; What if I call foo(std::bind(...))? At that point, the type has not "decayed" to an std::function. Can that be inlined? bind() by itself is an intermediate case. It's going to store the bound functor and bound arguments as data members of a struct. So if the bound functor is itself a struct (e.g. std::less), or a lambda (which is mostly pointless but possible), then the function call operator might be inlined (although it is less likely that any bound arguments will be optimized away, as they have been stored as data members). If the bound functor is a function pointer, then you are asking the optimizer to realize that the bind-struct's data member is always going to be that function pointer. Some compilers may be capable of that (now or in the future), but VC currently is not. Therefore, bind() given function pointers and mem_fn() given member function pointers will not trigger inlining. &gt; If not, I guess it should always be preferred to "bind" arguments using a lambda function? Yes. Lambdas supersede bind() in 99% of cases, and the remaining 1% are better dealt with by writing structs in the old-fashioned way. This is for several reasons: (A) efficiency, (B) syntax (lambdas involve writing "normal" C++ with just a bit of new syntax outside; bind() requires learning a new convention which is strange, especially for nested bind()), (C) immunity to Standard Library bugs (unfortunately, VC's bind() has had numerous bugs; I hope to fix them in the future but cannot promise anything), and (D) simpler compiler errors when things go wrong (I eat templates and drink compiler errors for a living, but bind() errors are still scary). The thing that bind() does that lambdas don't do (yet) is be "polymorphic". Lambdas have a single fixed signature. If you want compile-time polymorphism, you are better off writing a struct with a templated function call operator; although verbose, it is perfectly efficient, with simple syntax. bind() was cool before C++11 lambdas, but we have better technology now.