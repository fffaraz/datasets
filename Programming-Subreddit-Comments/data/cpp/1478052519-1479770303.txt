In addition to the other good points made here, I wanted to point out that this: explicit operator bool() const { return !error(); } bool operator !() const { return error(); } is redundant, since if `operator bool` is defined for a type and `operator !` is not, the built-in `!` will call the defined bool conversion. All you've done here is repeat yourself and create a possibility for a mistake later.
Yes, I know ASCII technically predates EBCDIC. My point was mainly that ASCII was a competing superior standard. And EBCDIC was widely used by the largest computer company during the 60's and 70's, and as you point out EBCDIC had a longer history as it was an extension of even more ancient text encodings. The WWW and Gopher were also developed at around the same time, although I'm not sure which is technically older.
Average web developer will never invest required time to learn C++ anyway, but what about C++ developers? Does it pay for them to learn a new language and interface it with their C++ code or is it better to use a quality C++ web framework without the trouble of interfacing?
[There is one in Chicago supposedly](http://www.meetup.com/Chicago-C-CPP-Users-Group/). Found it in this [list](https://isocpp.org/wiki/faq/user-groups-worldwide#starting-a-user-group) not sure if it's the same kind of group.
I want to like this, but inevitably bad programmers will downvote you. I'm sorry.
- The slides are from 2002. Several issues (anonymous functions, foreach) have been solved since. - The author is overly dramatic, writing we're coding 100's of iterators. Err, no. Good dev write their containers classes (and thus their iterator), sure, but it's not that common, and is often not a big deal. The presentation becomes better after that rant, but many have stopped by then.
I know it's from 2002 but the UI of that page is horrible, not user-friendly at all. I made it half way through (pressing "next" about 100 times). The content is not really relevant anymore in 2016, so much has changed.
On reddit, hackernews and etc... we know Amazon as one of the worst places to work... is A9 any different?
There is a user group in Chicago, but please note, that you are only in that list, if your meetings are online at the beginning of a month... On how to get started, the details are listed at the User Group page on Meeting C++: http://meetingcpp.com/index.php/user-groups.html
&gt;All websites are different too, and nobody complains there Erm, yes they do. Websites that don't display native UI (e.g. by using `&lt;form&gt;`) and draw their own equivalents are annoying because they are inconsistent with the target platform, and defeat screen reader software.
I wonder the reason of reinventing [fmtlib](https://github.com/fmtlib/fmt)
Was about to link to it too.
&gt; As printf can't reorder arguments you can do it like this printf("%2$s %1$s","one", "two"); 
By "work", I meant CPU work. So more CPU cycles are expended to do async i/o than sync i/o, not least because it's quite hard to sanely design a scalable async i/o system which never uses malloc() for example. You are however correct that all i/o in NT is *modelled* as being async, so for example in AFIO my read and write implementation on NT is written in a way that you can feed it overlapped or nor non-overlapped handles and you'll get the synchronous behaviour from the synchronous APIs no matter because it follows similar steps to that blog post (which is actually missing a step, but no matter). But internally inside NT drivers do take special notice of the FILE_SYNCHRONOUS_IO_xxx flags on the HANDLE and take optimised code paths. At least, this is what my benchmarking on very high end storage suggests where synchronous i/o beats alertable async i/o by a bit, and both beat IOCP async i/o by a large margin. One of the frustrating things with the Networking TS is that I suspect it has a deeply suboptimal async i/o and concurrency engine on contemporary OSs. I think the design was great on the XP kernel, I have growing suspicions it fits poorly with the many optimisations done by the time we reach the Win10 kernel. But Windows is not the world, and I don't have empirical proof the Networking TS is horribly flawed, and without doubt the Networking TS as proposed is much better than the committee inventing a networking library without the decade plus of battle testing ASIO has received. So I'm saying nothing.
$ is not a valid character in a [conversion specification](http://en.cppreference.com/w/cpp/io/c/fprintf).
Isn't that a POSIX extension?
I really hope I'm wrong (Edit: turns out I'm partially wrong), but I think this video is misleading. You can't just play with your APIs by loading a single .cpp. Where will cling find the implementations of those functions if you tried that? In a complicated project, the workflow described here will be useless, since very very few of your .cpps will be runnable without the rest of your project precompiled and loaded into cling. I think cling is an amazing project, kudos to the people behind it, but I think its biggest (and arguably fatal) flaw is that you can't easily load precompiled dynamic libraries into it. Edit: I'm partially wrong, hurray! The lastest version of cling actually is able to load existing shared libraries if you start with the `-l` command line argument! Now it's actually possible to use it for playing with your APIs.
This is quite contradictory: "The library does only depend on C++11 (or higher) and the STL (&lt;tuple&gt; and &lt;type_traits&gt;)." "However, in some projects, C++ is used without streams, sometimes even without the STL. This library was designed to help out developers of such projects with some type safety and comfort."
technically yes, though I don't know any implementation which doesn't implement this. glibc, uClibc, musl, newlibc implement it, msvc does it through printf_p. But there is probably some weird implementation outhere who doesn't (and your compiler have to support C++11)
But they say: &gt;The STL dependency can easily get rid of by reimplementing some type traits. 
When you say interleaved memory, do you mean xxxxxxxxyyyyyyyyzzzzzzzzxxxxxxxx memory ordering? (eight of one component, eight of the next, etc.) 
I doubt anyone ever looked at the win api and thought to themselves that that is how it should be.
It sounds like you would best be served by just the header-only date.h library (which is ignorant of everything but UTC). And perhaps chrono_io.h which makes printing durations pain-free. Indeed, this is *exactly* why the timezone portion is a separable library: timezones are messy.
Handling of string literals as template parameters is very interesting.
Not every calculation is doable in UTC. If you need to use time-zone-dependent reference points in time, such as the start of the week, you need to be able to translate this to UTC, which requires time zone information.
Yes, which is why I said if you can get away with it.
I was actually going for std::chrono mostly, but having duration printing easily done is a plus.
* that kind of question is for /r/cpp_questions (see sidebar rules) * though I doubt your question will be well received there, as it looks like a simple homework one. I suggest providing what you have tried so far.
Very cool! One comment (and shameless plug) regarding performance: no overhead compared to `printf` is better than many formatting libraries like Boost Format, but if you don't rely on `printf` you can even do better: http://zverovich.net/2013/09/07/integer-to-string-conversion-in-cplusplus.html
I do not think you need a list of scopeguards to solve this problem at all, you can simply have a single scopeguard acting on a list. void add_batch(std::initializer_list&lt;employee&gt; employees) { std::vector&lt;int&gt; guard_id_list; guard_id_list.reserve(employees.size()); // to avoid making copies of the strings std::vector&lt;std::reference_wrapper&lt;const std::string&gt;&gt; guard_name_list; guard_name_list.reserve(employees.size()); auto guard = makeScopeGuard([&amp;] () { for (auto i : guard_id_list) { m_id_map.erase(i); } for (auto s : guard_name_list) { m_name_map.erase(s); } }); for(const auto&amp; empl: employees) { m_id_map.insert({empl.id, empl}); guard_id_list.push_back(empl.id); m_name_map.insert({empl.name, empl}); guard_name_list.push_back(empl.name); } guard.dismiss(); } In addition to reusing the same base abstraction instead of having to write a new one, this one will most very likely produce better assembly. The other version will probably result in a loop that repeatedly hits the indirection of the `std::function`, whereas here there's no indirection at all.
Which compiler extension is being used?
Even MSVC warns about this now.
It allows you to not write format specifiers. The benefit is easier development without compromising safety/speed. Something like `auto` in C++11
how about: struct deleter { auto operator()(FILE *fd) const { fclose(fd); } const -&gt; void; }; using file_ptr = std::unique_ptr&lt;FILE, deleter&gt;; this solves both problems, no?
Your argument makes no sense. How does it apply to something like the "Adapter" pattern where you want to wrap another entity's interface for easier use by another entity? Design patterns are a means of organizing a system's components and having them cooperate with minimal friction. No language can do that design for you.
A few points. First, I am presenting an alternative. Your article makes it seem like this is the only way to do it: &gt; How could we use the concept of scope guard to make this atomic? We will need a list of operations to do the rollback, a list of scope guards. It does not mention this approach, or compare to it. Obviously if you had done so, and mentioned the points you wrote above, then I would not have commented. Second, just because I don't prefer your solution, does not mean I have missed the point. Abstractions have cost, so if you're going to write a new one it should be reusable in a wide enough set of cases to be worthwhile. Otherwise, maybe the energy spend writing or reading the abstraction would be better spent writing/reading the code without it (as I've done). There's already one situation where you cannot use this abstraction, which is anytime you care about performance in the error path. There's another: because the code to be executed is passed into a lambda and executed in another context, it can never early return out of the function. Another consideration is that you only actually need the scope guard list when you're doing something in a loop. If you have to do 3 distinct steps and you want all-or-nothing semantics for the 3 of them, you can just use 3 scopeguards and again don't need this. For me this is far more common, I think the example is slightly artificial (in the sense that after an individual employee is inserted, all class invariants are maintained). But maybe in your domain this is more common than in mine. In sum, I agree my solution has more boilerplate, but only slightly more, in exchange for using fewer abstractions, better perf, and more widely applicable code. If this problem came up a few times in my codebase I'd probably stick with this solution. If I really needed to do this ubiquitously then I'd probably adopt yours, but personally I've found the exact setup of the problem relatively rare.
This is great but unfortunately not for custom functions. 
&gt; The execute function returns the value of the executed function. My mistake, sorry. &gt; Yes but if you don't use the exception_guard, you'll have to call dismiss() three times (or if you have to deactivate the guard for another reason than an exception). That is a good point about calling dismiss three times. This can be avoided with an alternate design that is still performance optimal, a scopeguard based around a tuple rather than a vector: func_one(); auto sg = makeScopeGuard([&amp;] (rollback_one());); func_two(); auto sg2 = scopeGuardExtend(std::move(sg), [&amp;] () { rollback_two(); }); ... sgN.dismiss(); Maybe I should write up this alternative, it's fairly simple to implement. Though frankly I'd prefer for 17 to just arrive as exception guard will handle most of these cases. Btw I should also say, I think your blog post was good, sorry if my initial post came across too critical.
If you give a ~~mouse~~ user a ~~cookie~~ warning...
So ideally every library should push/pop both in headers and source files then? Maybe the language needs a better tool?
It's wrong because including a header for some library should not negatively affect other code you write. I was unaware of this instance, and frankly am quite shocked. I always endeavour to make my code "warning clean", approaches like this break the confidence I have that such code is guaranteed to be correct (to the extent warnings can guarantee correctness).
Right. This is exactly what the article proposed.
I see now. https://github.com/tfc/pprintpp/blob/master/include/pprintpp.hpp#L150-L156 I think that can be resolved with C++14 constexpr function.
Nope! Don't have it, so can't audit for it.
/Wall contains lots of warnings that aren't intended for everyday production use. Not even the STL's headers attempt to be /Wall clean.
Note that GCC and Clang's `-Wall` is similar to MSVC++ `/W4`. GCC and Clang's `-Weverything` is similar to MSVC++ `/Wall`.
T-1000
IMO the point of it is mostly for compiler test suites :)
Oh wow, this is awesome, and incredibly useful too. Thanks! Points * You should prefer straight lines in your graph, it makes it easier to read. Locking to a grid would be nice too. * A lot of line intersections are not clear or clean. Fix these up. It's hard to see at a glance, but is this graph planar? (A planar graph would mean you could draw it with no intersections). EDIT: looks like it isn't planar, looks like something similar to a K(3,3) subset in there. Best I could make was 2 intersections. * What do the dotted lines represent at the bottom? * What is the difference between square-edged boxes and round-edged boxes?
What about using one set and a reverse iterator?
I wasn't aware that Amazon was seen as a 'bad' place to work on Hackernews and Reddit. We all know about the NY Times article, but I thought this was widely regarded as false. Anyway, without making a statement about what it's like to work at Amazon proper, I can tell you that A9 is a very good place to be. For example, I've never felt any pressure to stay late at work, work on weekends or anything like it. I pick my schedule (I like to come in early and leave early). Working from home is also accepted and many people do it, although I don't because I live very close to the office. I also feel like we have a nice teamwork culture (small teams, lots of cohesion). All the managers I've interacted with so far are great; they have a strong technical background and they understand the difficulty/nature of what needs to be done on the technical level. They mainly make sure that we have everything we need to work effectively and they handle "the boring stuff" so we don't have to. However, this is a no-bullshit environment, which can be overwhelming if you're of the kitten type. If you're good at what you do and you're a driving force in the team, you'll be recognized. If you have bad ideas, these ideas will get called out no matter what seniority level you have. We are encouraged to have (civilized) technical discussions, and we do have them. Really, I think this is a fine place and whoever is talking badly of Amazon has had a different experience than what I've had so far. 
They ignore it?
~~Since nobody has bothered to point it out: this appears to have been fixed at least as of 5.6 (what I have locally).~~ Thiago mentions a change in the Qt policies for this at least as of Oct. 2015 in that thread. ~~Obviously not great for people on the older versions/platforms, but the new stuff has moved to a more local push/pop paradigm.~~ EDIT: I'm 99% wrong. As /u/Ono-Sendai points out, they just hid it behind a macro, so I missed it in my code search. They do have some push/pop in certain headers, but the real problem remains. At least the behavior can be turned off with QT_CC_WARNINGS. Time to go check some of our code. Blegh.
Indeed. I'm pretty sure that if your proposal gets in (or you forego standard conformance), it could get as good as `printpp("..."_c, ...);` with a template and a readable error for mismatched arity or bad format specifiers, at least until we have `constexpr` parameters. In this case, accepting a normal string literal or other runtime string wouldn't be desirable, so that part's easy (accept only `string_c` instead of any string-y type).
&gt; Your argument makes no sense. On the contrary, the biggest flaw of my argument is that it's tautological. You say "adapter pattern". If you google "adapter pattern" you'll get many links that describe what it is, so you see, it's a library in the English language. I have to use my brain to compile it to a computer language. You say, "would you please write an adapter from this class to this interface?", and if the two entities are semantically well defined, the "adapter" will be uniquely derivable (and that derivation won't necessarily be computable by a turing machine). You can take the argument further. The one true source code for any engineering product (including nuclear reactors, biochemical materials and software) is the requirements specification. Then experts come together to compile it into lower level forms that can be fed into currently-not-so-clever machines like compilers or CNC benches. Coming back to the "Adapter Pattern", it's an artifact of object oriented programming. For example, in a language with typeclasses, such a pattern would never emerge, since that's what typeclasses do.
I have this in headers for a driver interfacing a DSP from Texas Instrument :-( #ifdef linux #pragma pack(1) #endif //... header content #ifdef linux #pragma pack(2) #endif They screwd up the #pragma pack() at the end - not a fun debugging session... 
No! Please use lock guards, so that you don't have to lock and unlock a mutex manually. Calling lock/unlock is a bit like calling new/delete directly...
Thanks! This is apparently causing trouble on ARM as well which is in love with single-letter macros. What exactly is the key part that I have wrong in the library? The lack of parenthesis around the operator? Edit: I tried this on MSVC and it didn't seem to make a difference. Function-like macros don't seem to conflict, but definitions like `#define _T ...` do.
I don't use them, because to explicitly show the "unlock". Usually I would use lock guards, of course :)
Nah, Doctor Who.
} //unlock
&gt; unlock Good point. Thanks
Thank for the test on 5.6. It is not fixed in 5.5.1 (what I have) To reproduce : #include &lt;QtCore/qglobal.h&gt; int foo(int a) { return a+1; } int main() { double f = 0; return foo(f); // should display warning C4244: 'argument' : conversion from 'double' to 'int', possible loss of data } compiled with -W3 
Turns out I was wrong. I missed that they'd snuck it into a macro, so I missed it when I just searched for `#pragma warning`. I should've done what you did. It *can* be disabled by defining `QT_CC_WARNINGS`, but I'm gonna bet you get a lot of warnings.
My second example should be similar to what you have, but I don't know why it wouldn't work like that. Perhaps it's an MSVC bug?
But each time you pushed NEXT the website clocked up another "hit" ... so, mission accomplished? :( 
In your "right way" example, wouldn't the body of the "if" need to use "val" rather than calling "get()" again? Wasn't the whole point that the subsequent call to "get()" could fail because the value was removed? val = cache.get(1); if (val) { // &lt;-- What if here thread#2 removes "1"? assert(cache.get(1)-&gt;size() == 1024); // &lt;-- then this would fail, because cache.get(1) would be null } EDIT: OP has updated the article and fixed this mistake.
If something in the code between the lock and unlock throws an exception, it's game over. The lock will stay locked. Your code is broken. And you won't even know it until it happens and you spend a lot of time debugging it. It's just not the right way to do it. Edit: If you want to be explicit, you can use a unique_lock and call unlock on it. It'll still automatically unlock when destructed. But hardly anyone actually does this unless they need to unlock early. You can just use a lock_guard. When you see it, you already know that the rest of the function is synchronized.
I actually agree with GCCs policiy in the single aspect that there is no `-Weverything` because it is useless. It is possible to think up scenarios in which warning about the use of C++11-features is usefull, but it is not something that normal users would want. That being said the entire remaining warning-policies of GCC are trash, the default should really, really be `-Wall -Wextra -Wpedantic -Wconversion -Wsign-conversion` with the option to disable some parts.
Nice. &gt; Beyond Simple Accesses &gt; Sometimes you need to perform an operation that requires multiple accesses under protection of the same lock, and that's what the synchronize() method provides. By calling synchronize() you obtain a strict_lock_ptr object that holds a lock on the mutex protecting the data, and which can be used to access the protected data. The lock is held until the strict_lock_ptr object is destroyed, so you can safely perform multi-part operations. So, to use the OP's cache example, it sounds like you could do this: boost::strict_lock_ptr&lt;Cache1&gt; lock_protected_cache = syncronized_value_cache.synchronize(); // or maybe with auto? auto lock_protected_cache = syncronized_value_cache.synchronize(); if (lock_protected_cache-&gt;contains(1)) { lock_protected_cache-&gt;get(1); } } // lock_protected_cache destroyed and lock released
Exactly.
This one, I am really with MSVC -- this should not actually compile. If you can trivially show that NONE of the execution paths return, compile time error. If some execution paths don't return, warn.
One extension that would be Nice To Have (TM) with N3980 type hashing is [support for tabulation hashing](http://stackoverflow.com/questions/27527135/tabulation-hashing-and-n3980) (e.g. [Zobrist hashing](https://en.wikipedia.org/wiki/Zobrist_hashing) that is used in all chess / Go engines). To reap the benefits of tabulation hashing (cheap incremental updates, this probably requires some sort of `hash_update()` functionality. 
Indeed. I made a copy-paste mistake :-D
libcuckoo is their C++ implementation: https://github.com/efficient/libcuckoo
I see, thanks for the clarification. I wasn't familiar with tabulation hashing. I agree that N3980 doesn't support this. I'll give it some more thought.
Thanks for bringing this up! The issue was that the toolset version was bumped to "v141", so our MSBuild string compares no longer worked. I made sure to test the latest NuGet packages and ensured they work with VS "15" (cpprestsdk.2.9.1).
BTW, the code snipped I've provided above is meant to be a direct translation of your `std::function` solution. In real code, I'd probably do something like this: struct Object { template&lt;typename T&gt; Object(T&amp; ref) { ref_ = &amp;ref; static vtable_t vtable { [](void * erased) {return ((T*)erased)-&gt;can_attack();}, [](void * erased, int arg) {return ((T*)erased)-&gt;some_other_function(arg);} }; vtable_ptr = &amp;vtable; } bool has_attack_concept() { return vtable_ptr-&gt;has_attack(ref_); } int some_other_function(int arg) { return vtable_ptr-&gt;some_other_function(ref_, arg); } private: void * ref_; struct vtable_t { bool (* has_attack)(void *); int (* some_other_function)(void *, int); } * vtable_ptr; } This way, `Object`s size wouldn't grow with new functions.
Since when have we ever done anything in C++ because it was easy =P 
Vtables at the language level are rigid; one is forced to derive and create hierarchies. Once you manage them yourself like this, it's possible to do some very flexible, amazing things at the cost of losing the type hierarchy, which might be a good trade. 
For me the best is by Dan Saks: [CppCon 2016: "extern c: Talking to C Programmers about C++"](https://www.youtube.com/watch?v=D7Sd8A6_fYU&amp;list=PLHTh1InhhwT7J5jl4vAhO1WvGHUUFgUQH)
&gt; Our STL attempts to be /W4 /analyze clean Kudos! It took me about 2 years of spare-time effort to get Boost's full regression test suite compile /W4 clean with vc14. And support /std:c++latest on top of that. /analyze is probably too big a challenge, though. Along that path I've found quite some bugs in a few Boost libs, some of which are fixed now in mainline Boost and not only in my forks.
Even in clang it is only warning. WTH? This is pure mistake.
Relics you say? At the moment, generics and FP are in fashion. IMHO they can do amazing things! Are they the right tool for everything? No. With every hype (structured programming, OOP, generics, FP) it was the end of all problems, according to their evangelists. Was it true - No. Problems get solved, preferably with the most fitting tool. This is one of the strengths of C++. It supports all paradigms at once, not forcing one over another, and the language/library gets better and better. Dynamic polymorphism at a language level has its strengths and weaknesses. Sometimes strong dependencies a class hierarchy introduces are the right tool, even desired. Sometimes it's not. Reimplementing the mechanism, just because you can, with more boilerplate and more complex technology it not evolution. Is it an interesting exercise? Yes. Is it able to solve real world problems, Yes. Is it the right tool for everything, No. 
Yes I use it for the exception_guard and exception_guard_list mentioned at the end of the article with a link to the code on GitHub. I didn't go into details in the article as it uses the same code more or less.
If you have the source code at hand, why not inherit from it? Otherwise, a better solution would be to have this: class Object { virtual bool can_attack() = 0; }; template &lt;class T&gt; class ObjectRef : public Object { T &amp;m_object; public: ObjectRef(T &amp;obj) : m_object(obj) {} virtual bool can_attack() { return m_object.can_attack(); } }; The above works for inheritance and for duck typing. 
Sure, and also the object class can be used for defining wrappers, like [this](https://www.reddit.com/r/cpp/comments/5b11bz/a_type_erasure_for_interfaces_method_i_havent/d9lepd6/).
Rigid is good sometimes. It all depends on what you're trying to achieve. My preferred way of non-rigid hierarchies is [this](https://www.reddit.com/r/cpp/comments/5b11bz/a_type_erasure_for_interfaces_method_i_havent/d9lepd6/).
We use Coverity. I evaluated several free static-analysis tools, but none came anywhere close to what Coverity does. It's pricey but worth it.
That requires binary modifications of the layout of every class that can "attack". It must inherit. It must store a pointer to the vtable. Storing it off the heap is a pain, and if you want non-heap polymorphic storage it is really annoying. The language-level virtual is one way to handle virtual dispatch. And it doesn't give you access to the other ways. The manual vtable approach lets you add functionality without changing the binary layout of the data. It lets you store the vtable pointer separately from the instance. It lets you override methods on a per-object basis (creating classes algorithmically! At runtime!), permitting efficient and "simple" aspect-oriented programming. It doesn't require that the binary layout of the interface "live" somewhere. You can see these advantages with std::function. `std::function&lt;R(Args...)&gt;` does not require its data inherit from `callable&lt;R(Args...)&gt;` which has a `virtual R operator()(Args...) = 0` method. With the manual vtable, I can take anything that matches a *concept*, and treat it polymorphically. I can take simple standard layout value types, and write polymorphic views on them. These are things you cannot do with built-in virtual methods.
Then you'll have to pass around `ObjectRef` as an `Object &amp;`, so it doesn't have value semantics anymore (like how pointers themselves have value semantics.), and it's not a POD type either. For example, now you can't have a `std::vector&lt;Object *&gt;`s (In my solution you can have `std::vector&lt;Object&gt;`) anymore, since that wouldn't let you manage the lifetimes of the `ObjectRef`s. You can instead have `std::vector&lt;std::unique_ptr&lt;Object&gt;&gt;`, but that means you have to allocate the `ObjectRef`s on the heap. See, that's what I mean in my other comments as well; using the OOP features slowly remove your options and corner you at one point.
It supports most of the features I like in a language, with good performance and reasonable development speed. Being simpler and less verbose than Java doesn't hurt either.
First question, why not? I tend not to go for C++ for performance - heck, javascript can get close enough to not care about the difference. Most of the time the algorithms are a bigger difference. I really like C++ because it allows me to *fix* problems. Not repeat a workaround, copy/paste another bit of code, actually fix them. Those fixes compose, so that I can solve more complicated problems with simpler code. In the end I have less code that does more and is easier to test.
Not to mention, `Object` will probably not be the only way you'll want to type-erase your existing structs, so this will happen every time you need some new kind of erasure.
[CppCheck](http://cppcheck.sourceforge.net/) is another pretty good one. I've used it on several occasions. Best bet is to use multiple ones: each one will find a slightly different subset of issues. Also turning on all warnings in your compiler. I've use Coverity and C-Stat (targeted at embedded market) as commercial products. Coverity does some nice stuff, but it's really pricy.
C++ is a strict, mathematical language (when used correctly). C++ supports _Value-Oriented-Programming_ C++ allows me to write libraries and types that are easy for you to use correctly, and hard to use incorrectly. ie allows you to "fall into the pit of success". Not all (or even most) libraries do this well, but C++ makes it more possible than most common languages. The above particularly help with large projects, possibly even to the expense of small projects. Which may be why many don't see the benefits of C++ when starting out - because they are using it in small projects. Later, when that same project becomes big and unwieldy, they may, with experience, see what C++ offers. (Yes, C++ can also be unwieldy, but I find it has better tools - when used - to combat the chaos.)
He probably prefers Java more. That's why Im bringing up the languages because if C++ has a more managable design, he should have used that instead of making a larger game size. I don't know hos philosophy or preferences though other than not needing to add effort for cross platform compatibility
Type deduction, first class functions, polymorphism that doesn't depend on inheritance (by way of templates), a useful but not overwhelming standard library, decently strong type safety, etc. I just wish it had ML style pattern matching, and native garbage collection (though RAII is close enough and even better for destroying non-memory resources like open files).
As I already said: I agree that generics are powerful. No one denies that. I still prefer the right tool for the specific job. Which means generics-everywhere is wrong approach. I also find the capabilities of the "new" (C++11/14/17) features cool and interesting, but at the end of the day, I have to solve real-world problems. However, to me, it seems you don't like dynamic polymorphism. Ok, to each it's own. But: hype much? 
Except for the correct VC runtime that needs to be installed, or on Linux, the correct libc version (latter one is usually not an issue at all).
cmake 3.6 integration is described here: https://cmake.org/cmake/help/v3.6/release/3.6.html#properties Haven't tried it though, I wonder how it finds the clang-tidy binary on Windows!
If you compile with mingw in windows you just need to provide two or three small dlls with the executable. You can even compile statically so you don't need these dlls. Sounds great to me compared with a java or .net runtime. 
could you provide some examples?
Why do you think value semantics are desirable? copying Object struct values here and there with pointers to objects inside them will soon make object lifetimes intractable. In fact, if I had to share objects like that, I'd create this: template &lt;class T&gt; class ObjectRef : public Object { std::shared_ptr&lt;T&gt; m_object; public: ObjectRef(const std::shared_ptr&lt;T&gt; &amp;obj) : m_object(obj) {} virtual bool can_attack() { return m_object-&gt;can_attack(); } }; So at least I wouldn't have to track where my objects are manually. 
For me, the real problem lies in wanting to create things like duck typing, like in the example, which don't offer anything really over the classic approach. 
Enforced arbitrary rigidity is never good. You can always express YOUR rigid rules, so that you don't have to hope your problem doesn't evolve out of those arbitrary boundaries.
Can you eleborate? I am genuinely interested to see how you would define linting, since it is a bit blur d'or me
**Modern** C++ is a rather high-level language. With well-designed APIs it can read like a scripting language would. It is certainly a higher-level language than Java is.
I will address the advantages you mention one by one: &gt; Storing it off the heap is a pain No, it is not. Smart pointers and pools make heap allocation a breeze. &gt; and if you want non-heap polymorphic storage it is really annoying You don 't need non-heap polymorphic storage in the first place. &gt; The manual vtable approach lets you add functionality without changing the binary layout of the data No it does not, because the vtable is data itself. Each time you add a function in the vtable, you will have to add the corresponding function or an empty stub to the target object, and then you have to recompile both the target object and every piece of code that uses the vtable. &gt; It lets you override methods on a per-object basis (creating classes algorithmically! At runtime!) Waste of resources, as well as waste of valuable cache space. &gt; ou can see these advantages with std::function. std::function&lt;R(Args...)&gt; std::function uses heap allocation behind our backs. &gt; With the manual vtable, I can take anything that matches a concept, and treat it polymorphically. I can take simple standard layout value types, and write polymorphic views on them. These are things you cannot do with built-in virtual methods. You are not doing something that provides more flexibility than the traditional method. For each value you have, the set of functions of the vtable you are going to define must match the member functions available for those types. If you want to add a new function to those 'values', you have to modify or subclass them, then add a new entry in the external vtable. Not only it is double the work, but you also have the problem of object lifetime tracking, since your external vtable will hold a raw pointer to an object. 
Mostly because C++ is the go to in the industry I work in and if I sent someone Haskell code they would look at me really weird.
Yup
I hope it doesn't get a garbage collector Pattern matching would be nice though
It is. For many reasons good and bad. I still think that OS development in C++ might be a really good idea. I have been playing around with my own small FreeRTOS inspired C++ OS at home and aside from a few things it is fine and for embedded the assembly output can be surprisingly succinct especially with constexpr around. As for a larger Linux or Windows like OS I don't know because I have no experience developing much OS/driver level stuff on those. I keep hearing that Windows allows or uses C++ at the WDDM level but I don't know for certain.
Holy strawman batman! &gt; [...] that embraces the heavy use of templates as a natural way [...] well... ok... no, no hype there /s The 90's: everything is an object / class. &gt; [...] you'll miss a very rich space of vastly different architectural styles. I am well aware of the power of generics, as I wrote more than once, and I am very fond of that power, using it constantly. On this point, it seems, we don't even disagree. But: different for the sake of different is still not better. I think you still (want to?) miss the point. Thank you for the smalltalk.
I evaluated Klocwork on a 100k C project in ~2012 and it was comparable to Coverity in performance and similarly priced.
Type erasure doesn't offer less rigidity though than the classic OOP method. 
Few reasons to use C++. * Portability - C++ is one of the most portable language ever, behind C (and probably a few other like FORTRAN and Ada). Run on linux, windows, mac, android, mars rover, cars, rocket, particles smashers.... * Specification - everything is specified, from the unspecified behaviors to the algorithmic cost of every function of the STL.. * Easy to reason about. At low level, there is not black box and I can determine the cost of everything at a glance... * Deterministic - I know when everything is going to happen. No hidden latency like in GB collected languages. * Maintainability - Everything being strongly typed and specified, I don't have to worry too much about changes having silent damaging side effects. * Support - That program I wrote in 1990 still work and still will in a few decades. * Flexibility - There is very few things that can't be done with C++ . ^(The exception being proper reflection). * Integration - You can call C from C++ meaning you can integrate to whatever system function you need. Higher level language are cool for sure, but at some point someone has to pay for the meal. * Either the language is a bit complex, maybe a bit slow to compile * Either the language is not really flexible and has a limited domain of application * Either the language has a runtime cost, so your users pay the price 
I don't really run into performance problems other a stack overflow from messing around with things. And AFAIK they design these higher level languages to be flexable. But they could die out and be less portable wich you make a good point about. The thing is, I'm usually making games or tools. While it is good to have them last a long time, I'm not sure how necessary it is. But I'm really interested in c++ language design and how it can boost my productivity and such
I usually give the following advice : Don't use C++ for small, short lived projects. Because in the short run, C++ won't increase your productivity. Quite the opposite. In the long run, however, it very well may. Other way to look at it : C++ is not what I would consider a good prototyping language.
Ah. Its mostly a save for large projects. So my roguelike wont be worth the switch. I just like using new languages. Motivating i think
You don't want to throw when failbit is set. That's set when it can't read requested data, like when you hit the end of a file (at which point eofbit is also set).
I won't go into why values are much nicer to work with. That code doesn't solve the problem though, you now also have to store an `ObjectRef&lt;T&gt;` as a `shared_ptr&lt;Object&gt;` introducing ANOTHER indirection through a `shared_ptr`, meaning an entirely unnecessary extra heap allocation. 
&gt; (tip 3: cmake 3.6 and later can be asked to call clang-tidy magically for you with no further configuration if you're using either Makefiles or Ninja. And this works just fine on a MSVC only build) Do you mean that you generate a Makefile or ninja build just to run clang-tidy, while using the Visual Studio generator for normal development builds?
A program for static code analysis to enforce coding guidelines.
I totally unaware of `boost::synchronized_value`. It's a wonderful day when I learn a new technique like this. Thanks!
Try something like this: unset(CLANG_TIDY_EXECUTABLE) if(EXISTS "${CMAKE_CURRENT_SOURCE_DIR}/.clang-tidy") find_program(CLANG_TIDY_EXECUTABLE "clang-tidy" DOC "Path to clang-tidy executable") if(CLANG_TIDY_EXECUTABLE MATCHES "CLANG_TIDY_EXECUTABLE") unset(CLANG_TIDY_EXECUTABLE) indented_message(WARNING "WARNING: .clang-tidy file found for project ${PROJECT_NAME}, yet clang-tidy not on PATH so disabling lint pass") endif() endif() ... if(DEFINED CLANG_TIDY_EXECUTABLE) if(MSVC) # Tell clang-tidy to interpret these parameters as clang-cl would set_target_properties(${target_name} PROPERTIES CXX_CLANG_TIDY ${CLANG_TIDY_EXECUTABLE};-fms-extensions;-fms-compatibility-version=19;-D_M_AMD64=100; ) else() set_target_properties(${target_name} PROPERTIES CXX_CLANG_TIDY ${CLANG_TIDY_EXECUTABLE} ) endif() endif() 
Not necessarily. If you are building for example a .deb package for Ubuntu 16.04, you can just specify the relevant dependencies as package metadata and the user can use the vendor provided library packages rather than making your package giant and duplicating what's already available for no reason. You just need to provide different packages for different OS's. If you want to get your app/library packages as part of the OS repositories, it's generally required.
Distribution problems are not applicable to the Linux model (if we're talking about desktop), because the canonical workflow assumes that you provide the source code to the maintainers of the distributions, and the maintainers make sure that it's built so it fits into the dependency graph of that distribution. (or, if you distribute yourself, you become a maintainer, but without a say on the dependency graph questions, so you start bundling some dependencies :) )
That sounds incredibly useful as a generator! Any chance of trying to push it upstream to CMake? Or sharing it?
GCC has an attribute to apply the warning to custom functions, maybe MSVC has one too?
Have you seen Rust as well?
JVM is still a memory hog. I'm using Clion(for cmake integration), and it currently uses 4G for a small project. Meanwhile Visual Studio uses less than 3G all the time doesn't matter if the project is big or not.
Totally agree with that. I can't really see why they implemented it in that way. Well, I guess the rationale is that a static analyser is kind of (in terms of the warnings) an "extended compiler", and thus, as for compiler warnings, you want to run it and see them on each compile...
I'm searching a more general solution to use in personal computers and continuous integrations serves (with automated scripts to check the code).
How does this compare to boost signals2?
I'm using it because I'm familiar with it and because it allows me to do a lot of really powerful stuff at compile-time. Template meta-programming has no equivalent in any other language that I know (though I expect languages like Agda or Idris to have similar capabilities, from what I've heard). RAII also used to be a big seller, but most other popular languages have an equivalent these days. C++ is also the language of Qt, probably the best widget toolkit out there. Portability and performance are also big sellers, though I can't say they're big priorities for me. There's plenty not to like about C++ too, which may outweigh any benefits that you get out of it though, YMMV. My biggest pet peeves are its syntax (it often ends up looking really ugly compared to cleaner languages, to the point that MACRO_SHOUTY_CASE becomes an attractive choice) and its package management situation.
&gt; it does a ton of in-depth analysis ... Which ones exactly? Let's say compared to Visual Studio?
&gt; If you have an rvalue reference as parameter, it is not actually an rvalue reference but a forwarding reference. No - only `T&amp;&amp;` where `T` is a template parameter on the function itself (not a surrounding class). `const T&amp;&amp;` isn't a forwarding reference, and neither is `vector&lt;T&gt;&amp;&amp;`. &gt; Because due to something called reference collapsing No, it's not reference collapsing - that happens later. The real explanation is that `T&amp;&amp;` (in the situation described above) activates a special tweak to template argument deduction, where `T` is deduced to be `X&amp;` for lvalues of type `X`. It is literally a special sentence in the Standardese. This then goes through reference collapsing. &gt; For rvalues, T will be an rvalue reference and reference collapsing will keep the &amp;&amp;, taking and returning an rvalue. No. When `meow(T&amp;&amp;)` is called with an rvalue of type `Y`, then `T` is deduced to be plain `Y`, **not** `Y&amp;&amp;`. You can observe this for yourself. (This is what template argument deduction ordinarily wants to do - only lvalues receive the tweak.)
I use VS 2015 with Resharper C++, it does static analysis too, but the memory usage difference is still huge. When Clion does GC, the pause sometimes is unbearable(just try boost), especially when you are typing. There's latency VS too, but it's consistent and low most of the time. 
&gt; Why bother packing the entirety of the JRE in when you could just have a native app in the first place? I guess packing the JRE is similar to static linking your c++ app to your choice CRT.
The first problem is that boost can't serialize pointer to pointer. The second one is that it doesn't know the size of your array, in fact it can't tell if it's an array or just a pointer to pointer to a single string. Option 1: change your array to vector&lt;vector&lt;string&gt;&gt;. Option 2: serialize the dimensions of the array, then serialize each element individually in a loop. (you will have to allocate the array before deserialization).
Maybe have a look at pointer serialization in Boost serialization? It should be in the docs. But anyway I really don't think you should be using `string**`, you probably have an underlying design problem. Solve this, and then your serialization problem will be solved too. For example maybe see /u/miki151's answer.
I appreciate the feedback. Re: dynamic memory allocation. I agree this can be a downside, but it's not really an issue for my use case. Besides, most of the articles I've seen (cplusplus.com article included) include dynamic memory allocation through a `unique_ptr` or `shared_ptr`, so my goal wasn't to avoid dynamic memory allocation. Although your solution resolves the dynamic memory allocation, it has the same problem as the other solutions I've seen: a lot of boilerplate, and you need to specify the signature for the method three times. Notice that I only specified the method signature once. This is purely a code style opinion, but I like being able to write less code to get the same effect. I hadn't seen `boost::type_erasure` in a concise manner before. Looking into it more now, it certainly seems that my goal of "define the method signature only once" can be accomplished with the `boost::type_erasure` library, combined with `boost::mpl::vector` Thanks! :)
I don't do a lot of Java, but these are what I can think of. (Feel free to tell me how and why I'm wrong) * Operator Overloading * RAII for resource management * Templates (for the library user because of template argument deduction and the power of template metaprogramming) * Free functions are allowed. * Namespaces are much simpler than packages
This sort of question is off-topic for our subreddit; please read the sidebar.
Why do people keep posting links to isocpp.org that just link to another blog? This could just link directly to the blog post, or github repo.
It's using the right tool for the job.
I hope you mean it's enlightening in that either whoever wrote that is a moron or what gets ignored must have changed after it was written. At least 4244 (conversion from 'type1' to 'type2', possible loss of data) is pretty much the opposite of useless and stupid. No matter what, having a library header silently poison your codebase like that (despite available alternatives to doing so) makes it a "particularly stupid" library header.
Not having forced GC and the associated VM is one of THE major advantages of C++ over most other languages. As soon as you add GC the code is no longer self contained but instead depends on GC running in background which makes calling from other languages or writing in-process plugins painful.
That's kind of weird but if it works then cool. I personally just use the clang one even though I can't actually use the clang++ compiler since it can't find the standard library so the only I have that compiler installed is so that atom can use it but I actually compile with g++. In any case for the time being g++ has a huge leg up over all other compilers in terms of making the most efficient binaries, or so I'm told. 
C++ (especially C++11 and onwards) is a great language once you've learned how **not** to shoot yourself on the foot. The learning curve is steep, but once you're past it you can enjoy all the nice things listed above in addition to performance. 
I could see it being valid when it's supposed to be jumped to (*not* called) from some ASM and there's more asm following it in the binary.... And there's linker magic to make everything get placed correctly. . . . Nah. It should be an error. 
Audio Programming! As an audio engineer, C++ is really the only option for both platform compatibility (Audio Plug-Ins for example) along with performance &amp; flexibility. You can get really low level to do some crazy complex audio manipulation (with a sample rate of 44000 per second) and still be able to connect it to platform-independent Object-Oriented GUIs (most good frameworks will build for Windows/Mac/Linux/Android/iOS, and the backend audio code will work on everything else).
No; just send future questions there.
Thank you for taking care of that!
I'll attribute my apparent continued misunderstanding of your statements to the fact that I'm not a native English speaker. We do seem to agree a lot though. Have a nice day!
Please don't take this personally, but I'm really tired of Rust coming up all the time with these conversations. Once and for all, Yes! Many of us have seen Rust, envied its borrow checker, learned about its traits, realized they're not powerful enough to carry their own weight and came back...
C++ does have garbage collection. It has `shared_ptr`, `unique_ptr` etc. But if by "garbage collector" you mean "a magic thing that'll just solve the hard problem of memory management for me without me ever knowing about what it does", then such a thing unfortunately doesn't exist yet.
This is true. But I will say that the more I've used it, the better I've gotten at developing quickly, and I find that many applications I could script quickly in Python (moderate complexity) I can write in not much more time, with immensely greater performance. I like to say that C++ provides both the expressiveness of higher level languages and the power of C. At least, a lot of that expressiveness, and it keeps getting better.
Nice talk. At the end, the host (and I bet a lot of the audience) didn't understand at all what he answered in response to the question about humans and communicating. I've made this experience a lot, most Chinese people are so incredibly hard to communicate with professionally. (Not talking about Chinese people that grew up in the Western world, they naturally have very good English!)
The bundled JRE will be limited to that application. So unless the application itself reads data from an untrusted source nothing can happen. An offline game will be completely fine, a game that only connects to the developers own servers without user generated content will also be fine. With user content there could be a risk depending on the nature of the content, however that is true for any game with user provided content - you don't need Java for a buffer overflow in some string handling code ( C is better suited for that ).
For me it's mainly RAII, move semantics, well-defined object lifetimes, value templates, variadic templates and operator overloading. C++ allows me to write very powerful abstractions, like an N-dimension vector, while staying type safe at compile time (e.g. preventing me from adding a 3-dimensional and a 2-dimensional vector).
&gt; Either the language is a bit complex, maybe a bit slow to compile Slower to compile than C++? Is there any apart from Scala? I'm still wishing for modules to come :(
There are a couple issues with Rust at the moment, as far as I am concerned. All are due to the language's youth, and will hopefully go away with time, but for choosing a language now they are relevant nonetheless. 1. IDE support is its infancy 2. Library availability is rare; there are some very high-quality ones (regex!) but it's mostly a desert (even compared to C++) 3. A few missing language features: lack of non-type generic parameterization (fixed-size arrays, matrices, etc... are second-class citizens), lack of variadic support (tuples are second-class citizens), lack of associated type constructors (in the works) 4. Compile-times are still sluggish, though compared to C++ it's not too bad And that's for new projects, of course. If the existing codebase is already written in C++, switching to Rust calls for rewriting, and that's a costly investment.
That's good for deterministic execution, but it shifts the burden from the developer (once) to the user (any time it's used). Painful.
I agree when it comes to the dependency to tuple, that beast is not easy nor trivial to implement yourself. But when it comes to &lt;type_traits&gt; that header is really part of the language masquerading as a stl header. A lot of stuff in it is either trivial or implemented using \_\_builtin\_\* type compiler enabled introspection, type_traits being a portable way to speak to the compiler (in case those builtins are not part of the language, not sure).
That's a hell of a generalization. 
Portability is probably C++ biggest advantage right now.
Now I actually understand what variant is about and I am starting to like it. I associate the word variant with the old VB/COM style variant which is something quite different (and a terrible style).
Cool post, but did you know you can display text on the web without javascript? 
As I've said, the boilerplate is mechanical enough that you can actually capture it nicely with some metaprogramming, and that's what `boost::type_erasure` does. Also, be careful with the `std::function` way because you'll get another dynamic memory allocation for EACH method that you erase, EACH time you copy your type erased object references around. Cheers!
Linus will totally accept that to kernel source tree and even use it himself ;)
For anyone out of the loop: [Torvalds on C++](http://harmful.cat-v.org/software/c++/linus)
So you selected the students that you accept randomly from all applications? You could maybe add to the blog post that the seed you provide to the MT is not sufficient (probably doesn't matter for your task, but it will for others). Also may I just ask why you use `vec.begin()` and not `begin(vec)`? Using the latter seems to be best practice, is it not?
I have very little (read none) experience with programming at such a low level. I understand the need to have no hidden allocations, and manually managing memory. With the recent updates to the language, would his criticisms still hold true? What about the issues that are addressed [here](http://yosefk.com/c++fqa/defective.html#defect-10)? edit: a word 
A big part of his rant is about stupid programmers using fancy language concepts to make stupid code. That, obviously, wouldn't change with C++11 &amp; friends. And the few things he directly addressed: &gt; the whole C++ exception handling thing is fundamentally broken. It's _especially_ broken for kernels. In my (somewhat limited) experience Exceptions mean trouble. They create unforseen jumps in code execution and have a bunch of weird rules attached to them. So yea, I agree with him there. &gt; any compiler or language that likes to hide things like memory allocations behind your back just isn't a good choice for a kernel. This hasn't really changed either since it's a pretty fundamental part of C++. Some language features such as inheritance add "hidden bytes" to an object and much of the stl allocate memory without making it bloody obvious to the programmer (string, vector, etc etc). And considering how much stock Linus puts into the quality of programmers I don't think he trusts them to make good decisions about those "convenience allocations". &gt; you can write object-oriented code (useful for filesystems etc) in C, _without_ the crap that is C++. I think a decent argument against using C++ is that the language is much more complex than plain C. Simple languages make it easier to reason about them. And by disallowing some of C++'s convenience abstractions you force programmers to put a lot of thought into their code (e.g. you can't just slap a unique_ptr into your module and never worry about when exactly it'll be dealloc'd again). For a project like the Linux kernel I see the use of making it hard for programmers to, basically, keep up discipline.
Hardly none of it is true. Go watch this talk: https://www.youtube.com/watch?v=zBkNBP00wJE C++ is and has always been about zero overhead abstractions. He's probably right on about two points: Exceptions may be troublesome (I have too little experience in that), and that there is loads of stupid or inexperienced programmers writing stupid code. That's true in any language. Torvalds seems to think it's less true in C.
Sure, why not?
depends on your use case. CRTP will be useless if you need something like plug-ins (or you have to hide it behind a `virtual` layer)
It's really quite fast, and I like that you can get such high occupancy, which makes it memory-efficient. We recently chose not to use it for a project because it doesn't serialize. (Yet) They also produced the cuckoo filter, which in my experience gives typical 0.18% error rates at nearly full occupancy, at which point bloom filters would nearly always return false positives. And it has fewer expected cache misses. It will only work for one set of bits per item, though. It's templated, but none but default values work. [growt](https://arxiv.org/pdf/1601.04017.pdf) claims to have nearly an order of magnitude better performance than libcuckoo or Junction. I've not tested it, but I'd be interested if it lives up to the claims.
And that's why we call it class and not type :o)
Sutter always gives good presentations.
the timing for this with my project is way too scary lol. awesome!
I wonder if the debugger will be able to invoke constexpr functions in natvis in future? Those are guaranteed to be side-effect-free.
This explains perfectly why I picked up the language. The amount of control over hardware and usage of modern trends are sweet. Too many programming languages make things too implicit and deny awesome tools like the stack or flat arrays for simplifying code. 
I literally just discovered cloud9 after discussing one of my projects with a non-profit mentor of mine doing a slightly different niche of what I'm aiming to do...after I tried making my own version from scratch. (I'm stubborn and tend to think I can whip things up faster and better, but that's a different story). For the price and support of the educational version, depending on your needs, I recommend it. otherwise, coderpad.io is used for many interviews. 
JVM languages can do that. In fact I've written Android games as well as windows, linux, osx supported ones in Java alone. But It's more likely c++ is used in mainstream consoles though.
Cool! I think it would be possible to have a custom container that either contains or extends the variant, and has the -&gt; operator implemented, so that you can directly call your type's methods.
Hmm last I checked, you could actually call arbitrary functions from gdb.
Sometimes I'll try out ideas in a scripting language (like Ruby), and then translate it into C++, but yeah, it depends on what you need from the language. Ruby or Python can be great for rapid development, but they're both dog slow if you have to handle complex tasks or large chunks of data (at least when using their standard libraries). C++ can be in the ballpark of 10-100x faster than scripting languages at some tasks. 
But build times, arn't they a big problem? I've seen people have to wait minutes where I can run something on the JVM on seconds
Pretty usable as-is for basic stuff. Will be adding serialization soon.
I see available mutexes: interprocess_mutex, interprocess_recursive_mutex, named_mutex, named_recursive_mutex. Others probably are the implementation details.
~~That, and they castrated RAII.~~
Don't forget the cache abuse. *kugh*Java*kugh*
No you should not. If you learn C, you will then go into C++ thinking in C and that will cripple you, especially as a beginner. As a warning, I'm sure I've seen a lot of C++ educational resources that actually start by teaching C and as such do the same damage. Thinking in C++ is fundamentally different to thinking in C, and if you start off thinking in C (especially as a beginner with no other experience), you will do yourself no favours.
Oh ok. It's just I thought C++ was like an improvement to C so they would be similar. but alright thank you. That clears things up.
Actually, you need to call visit just once to cast to Base and then continue using virtual functions with the Base* pointer as usual. You wouldn't cast to Base at every usage. Once it is done, you have a stack allocated polymorphic object that behaves just like the classic heap-based OOP.
C++ is pretty much just C with a bunch of stuff added if you look at what you have available, but you solve problems very differently. 
How is C++ not a superset of C? Sure they changed the meaning of static and one or two other things but that's very minor. Templates is another language feature added on relative to the set of language constructs in C.
I suspect your comment is badly received not because it's not true, but because it's unhelpful. It's true that C++ is (almost) a strict superset of C. However, saying it to a beginner will encourage that beginner to think of C++ as C with some extra features, which will encourage that beginner to think in C and then try to come up with ways to jam C++ extras in, which is entirely the wrong way to go about it.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). 
If you have the time, learn C first. Unless you're thick-headed you actually shouldn't have any trouble shifting your brain between "thinking in C" and "thinking in C++". Both languages have their usage models and complement each other quite well. C is indeed "lower level" and will require you to understand pointers, structures and memory allocation in great detail. You will have much better insight into what C++ is doing for you (a whole lot!) and the knowledge will pay off nicely especially at debug time. Also: it's not like learning C is a waste of time, browse the Linux sources, you may find some of it in use there.
FYI this is a rather old video.
I use (and always have since exactly 20 years) exceptions for all things which can fail -- and this is not only memory allocation failure!!! I've always used this especially for system resources -- to wrap them via RAII as it is called today -- I call this resource wrappers. And there are what I call functional wrappers -- wrapping a system call which does not create a resource into C++ so that it throws a system exception on failure. I'm VERY curious that this is still controversial today after 20 years of availability of C++ exception handling (long before the google "guidelines" where published). But I'm used to this state of being curious -- potentially in another 20 years the general wisdom will have caught up. And I'm also very curious about many people always stating "I'm using them ONLY for &lt;put_restriction_here&gt;". I've never had any issue where I was wondering whether to use exceptions or not.
I'm curious now how IncludeOS get around that!
Do you mean in a gui that uses gdb, or whein directly doing `print` in gdb ?
I've very often seen and worked with code, which under certain conditions silently fails. And then the big panic and debugging starts. Some minutes earlier it was still working and now it doesn't. And hopefully after some time somebody finds out what is happening -- using a debug executable and a debugger -- and potentially a business trip to the customer -- that a certain shared library or dll cannot be found anymore and dlopen()/LoadLibrary() was silently swallowing errors or that the disk is full and fprintf() was silently swallowing errors. Or even that the executable of a child process could not be found and of course nobody knew (or even cared about the potential) how to report the error from execvp() back to the parent process (this applies to unixs). And then I'm thinking -- again -- that these are the problems resulting out of not using C++ Exception Handling -- and this after 20 years of availability of working compilers (for Windows and OS/2 and IBM but not for Solaris, HP and LINUX) -- so much wasted time finding the reason for a problem, which in a healthy environment would have resulted in a hierarchical error message propagated to the caller, telling him exactly what went wrong and the reason would have been obvious.
So just reactive programming then ?
in 20 years I've never -- NEVER -- worried the slightest about the performance of C++ Exception Handling. They are used mostly for system resource failures and in this case there is anyway nothing else one can do. I think this performance issue is just used as an excuse not to use exceptions.
Oh yes, it's a lovely language. Just like how I prefer to write C++ (traits instead of interfaces, no exceptions etc.), it's just that their mechanisms for expressing polymorphism aren't flexible enough in my opinion. I hope they improve the situation, then I'd probably migrate some of my programming there.
I guess. At least, that's the main use-case for me.
Like I said, you can do it, but you need to be very careful and/or use a limited subset of C++. 
Hmm. I can't think of a pretty way to do that. You might be able to convince the object to format a string in memory when it's created and whenever it gets updated, and then just look at that string. That would probably add more crap to your object than you want, though. Possibly you could also only build that when the program is compiled with DEBUG on, but debug specific code is a great way to introduce unwanted side effects in your code. If your debugger is open source, it might be easier just to come up with a convention of how you want it to work and patch the debugger to do what you want. Ultimately I think it would require a fair bit of work to set up -- you'd still need to tell something how you want your object's string representation to be formatted. The only time people ever actually think about that is when they're debugging, and they don't usually seem to want to add a bunch of code when they're chasing down a bug.
This is exactly what you can see in the sample. Hold any container of Base* (with the variants in another container or anywhere else accessible) and you can just use operator-&gt; to access the virtual methods as usual. 
**Company:** Affectiva. [careers page](http://www.affectiva.com/company/careers/) **Type:** Full time **Description:** Affectiva is an MIT Media Lab spinoff focused on understanding human emotion. Our vision is that technology needs the ability to sense, adapt and respond to nonverbal signals, not just commands. We are building emotional artificial intelligence (Emotion AI). C++ Engineer to help contribute code to our video and audio analysis runtime. Ability to write efficient and portable code to target multiple platforms (Linux, Windows and Android). Familiarity with machine learning concepts is desired. Experience with other languages such as Python also desired. **Location:** Boston, MA **Visa Sponsorship:** Yes **Remote:** Yes **Technologies:** C++11, Boost, Python, Linux, computer vision, machine learning **Contact:** [Apply Online!](http://grnh.se/c2uw761) or email [careers@affectiva.com](mailto://careers@affectiva.com) for questions.
In this case you are paying twice for the call: once for the visit and once for the virtual function (and maybe once for the operator-&gt; too). Though maybe virtual function elision might happen inside the visitor... I need to measure but my guess is that virtual function calls would be faster than a visitation. 
How about [Nim](https://github.com/nim-lang/Nim)?
Hi Robert, Absolutely, I plan to do so today or tomorrow.
I got this working on windows with a bit of trouble. After setting up everything correctly, "the magic configuration" i guess, it works smooth. Right now we are using make instead of cmake which doesn't help. I would like a way to use clang-tidy from visual studio without using any cmake.
Everyone likes a different style. I personally did not experience that. 
What's the advantage of this over a simple std::unordered_map?
Oh the dreaded printf call overhead. 
Looks nice! I hope this becomes part of the standard library.
This type of comparisons never seem to care much about compilation times, sadly.
Hard to cover everything in one post, but you can find compile times here: https://github.com/fmtlib/fmt#compile-time-and-code-bloat. These timings are a bit outdated though, the code using the current version of fmt has approx. the same compile times as the one using iostreams. I didn't see any compile times reported for pprintpp.
*Increasing compile time overhead with variadic templates* No seriously, one of the reasons I stick to printf and family even though their inconvenient and not type safe is that STL containers already severely inflate my compile times -- adding iostreams or fmt or pprintpp or what have you is only going to make this worse. Still, not to dismiss your work -- it's just a problem with the language/compilers as a whole
I kind of agree with it. Even I did not find the book that interesting to read, not sure whether its with how the book is formatted or the writing in general. But it is useful nevertheless. 
&gt; And if I want to build a rpm too I need to build on the specific Fedora machine? Oh and if I want a 14.04 package too then..... This hasn't every really been true. Tools like chroot (or better, schroot) allow you to choose the user space you're running (I developed a tool, mkschroot, to simplyfy management and reproducible schroot enrionments for doing builds). These days Docker make this even easier to do.
The alternative was GTK and they gave a talk on why that was just no longer an option. 
I'd rather have a slightly inflated compiler overheads than dealing with `printf` shenanigans. Even John Carmack lamented about these problems [1]: &gt; Printf format string errors were the second biggest issue in our codebase, heightened by the fact that passing an idStr instead of idStr::c_str() almost always results in a crash, but annotating all our variadic functions with /analyze annotations so they are properly type checked kills this problem dead. Variadic templates make compile time checks even easier and they really kill these problems dead. 1. http://www.gamasutra.com/view/news/128836/InDepth_Static_Code_Analysis.php
Yea, I know of those, although it's only for gcc (and I think MSVC might be slower when it comes to templates) and like you said doesn't include printpp, which is mostly what your article was about. Also, it only mentions `printf`. I'm more curious about the overhead fmt has for `format`, which is what I use the most.
... And as he says this is easily solvable. MSVC checks all printf calls now without even using /analyze.
As respected as Carmack is, maybe he should turn up his warnings; `__attribute__((format(printf)))` is a thing that exists, as are `-Wnon-pod-varargs` and `-Wformat`. I've personally tried switching away from printf in several of my codebases -- files that used to take less than 500ms to compile would take over a second, and that's on a freestanding codebase without any STL bloat. Sure, I don't have a mighty powerful processor, but it's not some 10-year old Pentium. In the end, I always end up going back to simple `va_arg`, because it works for me. If compile times don't bother you, I fully respect your decision.
Do you imply that you would trade performance for faster compilation times?
I was hoping to see RAII used in a transaction to allow automatic rollback on exceptional exit. Seems a missed opportunity.
Well, there can be situations when it makes sense. For development, if you have to recompile something very often, you'll probably want it to compile as fast as possible, and then when you have something you can release, you switch the fast-compiling code with the better-performing slower-compiling code. Of course then you'd have to probably test it again to check if doing that broke anything unexpected, and stuff like that, but you get my point.
Given that committing or rolling back a transaction could itself fail, how would that work since it's common wisdom that destructors shouldn't throw? 
generally yes. however, what's not so clear is the tradeoffs with respect to binary size. with templates you have a large number of binary implementations doing basically the same thing. this impacts the various cpu caches in a negative way and for large multithreaded applications cache efficiency is a big deal if your'e counting nanoseconds. 
with modern compilers printf is typesafe assuming warnings are properly set and heeded.
Why not just stuff the differently-typed objects into one contiguous stretch of memory? If `dX` corresponds to DerivedX in the figures on [this page](http://rawgit.com/joaquintides/poly_collection/website/doc/html/poly_collection/an_efficient_polymorphic_data_st.html), it would be like: d1 d3 d2 d1 d2 d3 d2 You'd of course need a separate vector to store all the base* pointers (for uniform access) and derived pointers and sizes (to enable insertion/deletion).
In terms of compile time, `fmt::print` and `fmt::format` should be about the same. The latter is inline so it will generate larger code, but I'm not sure it's worth it so might uninline it which will result in similar binary code too.
If you already use C++ in your project you will probably won't notice too much difference in compile time whether you use fmt or printf, because much of the time spent in compiling standard headers. For example, if you add `#include &lt;algorithm&gt;`to printf compile time test which is reported [here](https://github.com/fmtlib/fmt#compile-time-and-code-bloat) it will blow the time 20x making it comparable to fmt's compile times or even worse because fmt has recently reduced its use of heavy includes. [Moved the comment]
Those will be in the precompiled header, so they're pretty irrelevant. I'm not too concerned about the time it takes to include &lt;algorithm&gt; or &lt;format.h&gt;, but more about the compiler having to instantiate the templated functions for every translation unit for every different set of arguments.
Unfortunately I don't have a benchmark that accounts for includes, but I'd love to see one.
So long as the destructor also drops the database connection then the failure is safely ignored.
I did some work on compile-time printf-style format checking. It was inspired by [this open ticket](https://svn.boost.org/trac/boost/ticket/6815) on Boost. We use it in our internal logging library, and it allows us to `"printf"` user-defined types and other non-pod types, like `std::string`, giving a compile-time error if you pass a formatting flag (eg `%d`, `%s`, etc) with an incompatible type. I can't pase the code here because of comment-length limits. However, I did submit the code to [codereview.stackexchange](http://codereview.stackexchange.com/questions/85031/compile-time-printf-style-format-checking) if you're interested in seeing it. [Also, here it is running on ideone](https://ideone.com/EzstNy) It makes heavy use of templates in order to parse the format string at compile-time, so all the concerns regarding increased compile-times etc will apply here. However, for our use we accepted longer compile times in favour of compile-time format string checking and the ability to log user-defined types. 
Stuffing all your data on the heap by default is a great way to have a uniform 2x slowdown in your application. Default to storing data locally within a structure. Only use the heap for large, variable sized, or otherwise unwieldly data. C++ *loves* value types. It is one of its big advantages. Next, functions (methods or free) on objects are not part of the binary layout of an object. If you use a free function way to direct your dynamic dispatch, you don't even have to change the definition of the object in a header file, let alone its binary layout. Adding or removing or changing an entry in a vtable *is* changing the binary layout of that object. All clients who interact with that object must be recompiled. Changing a manual vtable system only requires clients who interact with the manual vtable system be recompiled. (There are some assumptions that allow limited automatic vtable changes without binary layout changes. They are somewhat fragile in my experience.) In large projects, reducing dependencies is extremely useful. Binary compatibility of data permits libraries be distributed without a rebuild of client code. Both of these have, in my experience, have had great ROI. I'm glad you think that per-object dynamic classes are always a waste of resources and/or cache space in **all cases**. You are wrong, but I'm glad you have courage of conviction. Sure, usually don't bother, but when the tool is useful, use it. `std::function` only does heap allocation on large function objects. In MSVC, for example, it only does so if the function object is larger than two `std::string`s, and their `std::string`s naturally also do SBO so sometimes store their data locally. A `function_view&lt;Sig&gt;` intended to *never* store the underlying function object would permit even large captured function objects to never heap allocate. When passing in a synchronous callback to a function this saves an allocation. Such a strategy is easiest to do via a manual vtable. However, because passing `std::ref(blah)` to `std::function&lt;Sig&gt;` basically gives you an only slighly inefficient `function_view&lt;Sig&gt;`, I don't really see a strong need for it. --- Yes, it des provide more flexibility than the traditional method. The vtable does not have to dispatch to methods. Take a look at `std::begin`, which dispatches to a method *or* a free function *or* a set of default behavior for some types. I can write a manual vtable that routes to `std::begin` and `std::end`. I can have the return values tossed into `any_iterator&lt;T&gt;`s. Now I can write: template&lt;class T&gt; struct any_range which (usually) involves zero heap allocation, and manual vtables. Or I could just use boost's implementation: http://www.boost.org/doc/libs/1_54_0/libs/range/doc/html/range/reference/ranges/any_range.html The external vtable does not hold a raw pointer to the object. Instead, it has function pointers which take a `void*` or similar in place of the object. These are populated with functions that know what the `void*` is. The direct user of the manual vtable is required to manage the lifetime of the object. It could be via a `std::any`, a `std::shared_ptr&lt;void&gt;`, or even a raw `void*`. They define the lifetime; it could be value lifetime, view lifetime, shared lifetime, unique lifetime, or whatever. All of those lifetime management patterns are useful. None are ideal everywhere. You take the manual vtable, mix it with a lifetime management provider of the `void*`, then hook them up into one easy to consume type. Or you use the boost library that does it for you: http://www.boost.org/doc/libs/1_55_0/doc/html/boost_typeerasure.html (naturally with some decisions made for you) --- The point of all of this is simple. C++ picked an OO system with a particular kind of polymorphism. Using it has advantages, because you get some language support. But that is not the only form of polymorphism, and some problems are better suited to *other kinds of polymorphism*. When you run into a problem better suited to other kinds of polymorphism, having techniques to use those other kinds is useful. Otherwise, you are forced to force the problem into being nail-shaped, because what you got is a hammer, and you'll use it god damn it.
Yep, that's what [ODB does](http://codesynthesis.com/products/odb/doc/manual.xhtml#3.5) and it feels pretty natural.
Destructors only roll transactions back. If that fails (e.g., a connection to the database got dropped), there is nothing really you can do except ignore it. The good news is the database will roll that transaction back sooner or later since you never actually committed it.
I wouldn't count on it before C++30
Java 10 will fix it.
&gt; they are slow because they need to unwind the stack cleaning up after itself as it goes until something catches it. If an exception is not thrown, overhead is negative compared to error-return code. If an exception is thrown, it is only slow if there is too many errors. &gt; you need to think about the state of your structures based on what sort of guarantee the throw offers No, that's false. C++ offers very good tools to deal with exceptions (RAII and ScopeGuard spring to mind). Certainly beats vb-style function-local exception handling of "On Error Goto ErrorLabel" that the kernel code uses. The reason why you wouldn't use the standard containers is that they do not go far enough to avoid allocation and presume the standard library which is not available in a kernel. Word of Linus is not that of God :-).
The most crucial thing in this whole page for me was the final conclusion bullet: * This story demonstrates that there is something useful in code coverage tools. Here I was lucky that the input data caused all the code to execute. It might be different some other time. 
Ignoring, for the moment, the issue with seeding, there are a few other things about this that strike me as...less than optimal. One is that I really dislike creating uninitialized variables, then writing their values to them later. If at all reasonable, I strongly prefer to initialize them with their intended contents. This remains true even with types like `std::vector` that initialize themselves to usable "empty" values. I'd also note that this uses a couple of things I've seen often enough that I think they're worth writing up in generic ways instead of repeating them constantly. The first of those is reading an input file line by line using iterators. Though you can write a `LineIterator` class to do this, iterators require enough boiler-plate code that it ends up fairly long and clumsy. Another possibility is to use a proxy class like this: class line { std::string data; public: operator std::string() const { return data; } friend std::istream &amp;operator &gt;&gt; (std::istream &amp;is, line &amp;l) { return std::getline(is, l.data); } }; With this, we can create `vec` initialized like we'd like: #include "line.h" // ... std::ifstream in{ argc &gt; 1 ? argv[1] : "./input.csv"s }; std::vector&lt;std::string&gt; vec{ std::istream_iterator&lt;line&gt;(in),{} }; Although this may initially look like it does extra string copying, my experience is that the compiler "sees through" this, and generates code essentially identical to your original using a while loop. Another one that happens all the time is doing a random selection of items from a collection. You did this by shuffling the collection, then selecting the first N items. For small collections like you're dealing with here (N=10, M=38) that's probably perfectly fine. I'd prefer, however, to solve the general case, then apply that solution here. For the more general case, this method can be fairly inefficient. For example, if you were selecting 10 out of, say, 10 million items, it would shuffle all 10'000'000 items, then ignore 9'999'990 of them. Obviously it would be better to only shuffle the number of items we're actually going to use. To do that, we could write up a more generic algorithm on this general order: template &lt;class RanIt, class Size, class OutIt, class Rand = std::mt19937_64&gt; void random_select(RanIt b, RanIt e, Size n, OutIt o) { Rand eng { std::random_device()() }; for (auto count = 0; count &lt; n; ++count) { int dist = std::distance(b, e); std::uniform_int_distribution&lt;Size&gt; gen{ 0, dist-1 }; std::iter_swap(b, b+gen(eng)); *o = *b; ++b; } } We can then use that to select some items: std::vector&lt;std::string&gt; temp; random_select(beg, vec.end(), 10, std::back_inserter(temp)); [Yes, I realize this doesn't initialize `temp` as I recommended above--you can't win them all.] The final big point is the final `for_each`: std::for_each(it,vec.end(),[&amp;out,del,&amp;i](const std::string&amp; line){out &lt;&lt; line &lt;&lt; del &lt;&lt; ++i&lt;&lt; "\n";}); I've started to think of use of `std::for_each` as a code smell--not a guaranteed disaster, but a problem often enough to give it at least a second (and probably third) look. The problem is that `for_each` only tells us the basic fact that we're doing *something* to an entire range of objects. If we can use a different algorithm, it'll immediately tell us quite a bit more about what's actually being done (and leave less that we have to define in that lambda). In this case, we seem to be taking an input range, modifying each of those inputs, and writing the result through another iterator. That's exactly what `std::transform` does, so it's probably the most obvious choice for the task: int i = 0; std::transform(temp.begin(), temp.end(), std::ostream_iterator&lt;std::string&gt;(out, "\n"), [&amp;](std::string const &amp;s) { return s + delim + std::to_string(i++); }); This leaves more of the work to the algorithm, so all we have to deal with directly is the modification to the string itself (i.e., adding the `index` column). If you include the line count for `line` and `random_select`, this works out to more code than your original--but if (as I think things should be) you treat each of those as a single `#include`, the result is a bit shorter and simpler: int main(int argc, char *argv[]) { std::ifstream in{ argc &gt; 1 ? argv[1] : "./input.csv" }; std::vector&lt;std::string&gt; vec{ std::istream_iterator&lt;line&gt;(in),{} }; assert(vec.size() &gt; 1); std::ofstream out("random.csv"); auto beg = vec.begin(); char delim = (beg-&gt;find(';') != std::string::npos) ? ';' : ','; if (beg-&gt;find('@') == std::string::npos) { out &lt;&lt; *beg + delim + "index\n"; ++beg; } std::vector&lt;std::string&gt; temp; random_select(beg, vec.end(), 10, std::back_inserter(temp)); int i = 0; std::transform(temp.begin(), temp.end(), std::ostream_iterator&lt;std::string&gt;(out, "\n"), [&amp;](std::string const &amp;s) { return s + delim + std::to_string(i++); }); } I'm also *tempted* to change the `if` to instead partition the data on whether it contains an `@` or not, but that would be a significant change in specification that I'm not sure is really justified. Anyway, I've probably pontificated enough for a while, so I'll leave it at that for now. :-)
&gt; Android Studio intends CMake to be a permanently supported solution. +1000!
Jonathan Blow is working on Jai. Potential, eh? And maybe Rust will catch on.
I've had a pretty bad experience with the cmake support in gradle/AS. Originally, my project used a handwriten Makefile with a standalone toolchain from the ndk. It had dependency resolving and such, and clean builds would take about 4 minutes when run on 8 threads. Moving to cmake and eliminating the standalone toolchain from the build process sounded great. Writing the cmake file itself was pretty painless, but clean builds now took around 16 minutes and were somehow even more cpu intensive than before. My entire machine locks up during a build (maxed out macbook pro 2015). The results are just sad. I can understand SOME slowdown because of gradle or ninja or whatever is inbetween, but 4x slower is unusable. My project is rather large, around 300 source files, so your results may vary. edited for clarity. I was very tired.
You raise an interesting point. I think if all the alternatives in the variant inherit from the common base as their first parent, the compiler will figure out that the currently held element index has no bearing on the physical value of the `BaseType&amp;` returned by `cast_to_base`, then emit a noop in place of the call to `cast_to_base`. But your concern still holds in the general case. An interesting solution to this problem could be to define a new `variant` type from scratch. Instead of remembering the currently held element by an integer index, this `variant` type could explicitly generate a `vtable` for each element type and use a pointer to the `vtable` of the currently held variant to distinguish between the elements. Such a `variant` type would have no overhead over classic OOP, but it would still support a less efficient form of static polymorphism by decoding the currently held element based on the `vtable` pointer. I think this decoding can be done very efficiently, since the mapping is known at compile time.
I could easily be wrong, but in my experience variant visitor code seems quite "thick" and it's hard for the optimizer to work through it all. If you mess around with it on godbolt and see something interesting, I'd love to see a link. This decoding could be done efficiently, but it seems like it would be very heavy to code. Right now by using integers, you can do most things in tuple land, but it's still quite dense to code a variant in C++. With what you're suggesting you'd basically need a heterogeneous map indexed by compile time pointer value. In principle doable but it seems like quite hard code to write. I think that inheritance and variants, as forms of polymorphism, are mostly cleanly separated by whether or not you know all the types in advance. This tends to be a pretty black or white thing IMHO. I've never really been in a situation where I was interested in these hybrid structures. Pity that it's the kind of thing that's hard to give a good example for without a ton of background.
I'm the author but I didn't post the link here; someone else did. This is where confusion about C++ comes from. Only the last section is C++-related (btw, can you comment on that? Am I missing something important there or doing something totally wrong?) The ~0xFFFFL is indeed a bug, thank you. Well spotted. I still can't get used to the fact that we have types with exact widths but no reliable way to write down constants of those types. Except for explicit casting; ~(uint64_t)0xFFFF would work, but sum &gt;= 0x10000 is indeed much neater. It produces better code, too.
I've only had a very quick look - the material looks ok and some of it actually really cool! I'm sure some of it is not done in a perfect way but it looks like a great resource overall. Just take some things with a grain of salt, like his C++ style. It could be a bit rough for a beginner though. And, it would not replace an OS course at your Uni - the contents would be massively different.
&gt; I still can't get used to the fact that we have types with exact widths but no reliable way to write down constants of those types. In C++ you can easily make your own #include &lt;cstdint&gt; #include &lt;type_traits&gt; std::uint64_t operator "" _ui64(unsigned long long int); std::int64_t operator "" _i64(unsigned long long int); std::uint32_t operator "" _ui32(unsigned long long int); std::int32_t operator "" _i32(unsigned long long int); auto x = 123_ui64; //x is an static_assert(sizeof(x) == 8, "8 byte"); static_assert(std::is_unsigned&lt;decltype(x)&gt;::value, "unsigned"); static_assert(std::is_integral&lt;decltype(x)&gt;::value, "integer"); auto y = 123_i32; //y is a static_assert(sizeof(y) == 4, "4 byte"); static_assert(std::is_signed&lt;decltype(y)&gt;::value, "signed"); static_assert(std::is_integral&lt;decltype(y)&gt;::value, "integer");
I've been using: Checks: '*,-llvm-header-guard,-google-build-using-namespace,-clang-analyzer-alpha.clone.CloneChecker,-google-runtime-int,-cppcoreguidelines-pro-bounds-array-to-pointer-decay,-clang-analyzer-alpha.deadcode.UnreachableCode,-misc-use-after-move,-cppcoreguidelines-pro-type-vararg,-modernize-use-emplace,-cert-err60-cpp' So, all turned on minus: * Proper header guards used (the check is very brittle and incorrectly assesses my guards) * Use of "using namespace" (the check fires even on non-global using namespace, which is daft) * Copy and paste detection (the check fires on unit test code which is by its nature very copy and paste) * Use of traditional integral types * Array to pointer decay (the check fires on static constexpr string arrays, daft) * Unreachable code (the check is too naive and misses CRTP injected code) * Use after move (my unit tests test semantics when you do this, most shouldn't need to disable this) * Use of printf * Use of push_back instead of emplace (unhelpful check, emplace isn't exception safe like push_back) * Throwing exception objects which aren't nothrow copy constructible (Dinkumware STL does this, not my fault) 
I should clarify something about what I wrote above: until you get a standard runtime, std::terminate() doesn't exist. What modern kernels have is usually something like **kernel panic** (Linux) or **stop error** (Windows). It's just the kernel saying "fatal error" or something like that, and then shutting down. The problem is that std::terminate() has no knowledge of the caller. At least things like kernel panic or stop errors also include some info for the OS developers. The best thing you can do is use static analysis tools to ensure you don't throw exceptions out of `noexcept` functions, or use exceptions more sparingly. What would be best is the standard allowing you to change what unhandled exceptions do, which you can currently do with OS calls on some platforms.
Yes, it would be nice if there were suffixes for fixed-width types, to avoid having to use a cast to be portable. You could write `~0xFFFFULL` which works because `unsigned long long` is guaranteed to be at least as big as `uint64_t`, but it still feels hacky. Personally I try to avoid bitwise operations on signed types completely; and generally prefer, even for an unsigned bitwise operation, to use non-bitwise arithmetic if it can do the same job. This case turns out to be a good example; on code review you can instantly see `sum &gt;= 0x10000` is correct (well - you do have to look up to check `sum` is unsigned), without having to mentally examine the suffixes and go over the possible cases of various implementation details and so on. Re. the C++ issue, the page opens up with "tags: C++ optimisation alignment" as part of the title area so I assumed it was about C++ only. You didn't mention C until somewhat down the page, "Well write it in plain C", which I interpreted to mean that you were indeed talking about C++ before but now switched over to C as part of the investigation. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). 
Alright, thanks
Yes, I agree. The material is deep and Anthony does not shy away from getting his hands dirty. I am not aware of any other book that goes into the same level of detail.
&gt; Variadic Templates from C++11 is probably not a feature that you use on a daily basis. Well...
that's why I wrote "probably" :) The case in the article was only a little introduction to this feature. I expect library developers (and others) do use it on a daily basis.
Your `StackPolymorphic` is a good idea, but it'll be in trouble if you construct it with a class that doesn't have `Base` as its first parent. Even if it's the first parent, the `reinterpret_cast` is probably technically undefined behavior since it's not a POD type. You can easily fix that by having a polymorphic `operator*`, but then it'll be the same unnecessary double-indirection as in the post. BTW, `StackPolymorphic` is a weakened form of what I suggest with explicitly generated `vtable` pointers. `StackPolymorphic` is still paying for the price of a pointer, but it can't access that pointer within the language, for checking for things like type equality (or recovering the ability to do static polymorphism). 
It looks really nice. It actually came in a very good time for me, as these days I have been experimenting with the linker to reduce the size of some libraries I've been working on. If you used any sort of documentation to learn all the required background, I would really appreciate if you could share a couple of references!
Would you consider new graduates by any chance?
Use the sub's sticky for hiring.
How do templates cause bloated code? If you're using different versions of a class/function, wouldn't you have to compile that anyway?
They make it easy to accidentally get unnecessary bloat, e.g. one might be passing several different closures to a templated function `f` in cold paths, so it would make sense to use `std::function` for the closures (the cost of the allocations/virtual calls is fine) to have a single version of `f` in the binary rather than monomorphise it for each different closure type.
I have a 250 mb object file sitting right here because of a very generic visitor that does something like : struct visitor { template&lt;typename T&amp;&amp;&gt; void operator()(T&amp;&amp; value) { ... some_util_function(std::move(value)); } }; for a shitton of functions, which becomes after compilation : struct visitor { void operator()(int&amp;&amp; value) void operator()(const int&amp; value) void operator()(float&amp;&amp; value) void operator()(const float&amp; value) void operator()(char&amp;&amp; value) void operator()(const char&amp; value) void operator()(std::vector&lt;...&gt;&amp;&amp; value) // for these it makes sense void operator()(const std::vector&lt;...&gt;&amp; value) /// roughly seven other types, some of them benefiting from move }; If i was not lazy, I'd specifically provide overloads for each type which won't really benefit from perfect forwarding, such as : void operator()(int value) but then what's the point of templates ? (of course, the large sizes are only during debug ; at release with `-Os -flto` it's roughly a two megabytes .so ; three megabytes with -O3 instead) 
My intention was to use the tool for self-education mostly. I am not an anti-template heathen :)
How does it compare to [templight](https://github.com/mikael-s-persson/templight) ?
Does the same problem with alignment and casts exist in C++?
&gt; Now the linker *could* merge them if the language allowed for two functions to have the same address, but alas C++ requires two functions to have a different address. Digital Mars compilers implement this by having a single function and implementing each duplicate as a simple `jmp` to said singleton (each duplicate having its own `jmp` to keep addresses unique).
&gt; Before 2010, C++ compilers had a whole lot of bugs, incompleteness, inconsistencies. Still do. Unfortunately, the same is true of C compilers. At least in my experience, C compilers tend to be slightly worse on average than C++ compilers in this regard.
Yeah. That helps for one level, because one level up it has to differentiate which of those two it's actually calling, so now they *subtly* differ - but not functionally. This may be better fixed in the C++ standard. The opposite is already not true - asking for the address of a function may or may not give you the code that's going to run (inlining), and it may give you a different pointer than somebody else (PLT).
These are completely different tools. Templight shows how much *compilation* time and *compiler* memory templates take. Templight is basically a specialized compiler profiler. Bloaty shows how much space various thing take in your *binary*. It's like a very advanced analog to `nm --size_sort --demangle`
Okay, so I'll bookmark this for future reference then. Thanks!
The performance is more or less a happy circumstance. I'd say, choose C++ for the type system. It's incredibly powerful and a lot of the logic can actually be put on that. Type safe code is code that's very hard to use incorrectly so it's a good thing. It also self-documents.
Thank you! If I understand right you're now using Gradle + CMake. While I haven't had much experience with Gradle, I've usually found it slow. CMake on the other hand for my C++ projects on Visual Studio generates nice and fast solutions. Though I have modified it with a couple compiler options to allow better multi-core compiling, incremental linking and such.
What would be really cool would be to base it on the header-only version of ASIO that doesn't rely on Boost. 
[This](https://github.com/liancheng/amy/blob/93977c052f6ac6c64fd5cfb3f9a2051aeb6a065d/example/async_connect.cpp#L19) and [this](https://github.com/liancheng/amy/blob/93977c052f6ac6c64fd5cfb3f9a2051aeb6a065d/example/async_connect.cpp#L38) look strange.
What do you mean by asynchronous ? Is it thread based or select/epoll based ? For those who want to know what the async api of mariadb look like, here are some tutorials: https://mariadb.com/kb/en/mariadb/using-the-non-blocking-library/ https://mariadb.com/kb/en/mariadb/non-blocking-api-reference/
So not [Boaty McBoatface](https://www.google.de/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjFnO_q35vQAhUkBcAKHZeDBcMQFggdMAA&amp;url=http%3A%2F%2Fwww.bbc.com%2Fnews%2Fuk-36225652&amp;usg=AFQjCNGbRJUgGhb_oq8-7YfBrBrqu1WByA&amp;sig2=FIkqS2Y1yGftnS_FHoKeAw)?
&gt; Native string type, other than char*, rather a language built-in std::string What is the practical difference between this hypothetical native string type and std::string?
If you didnt like the native string type, you probably couldnt easier replace it with your own because the native one would have been capabilities that used-defined types arent allowed. (Not C++s style, but then neither are native string types.)
&gt; Native datetime type, that would allow us to specify points of times without a built-in resolution (probably nanosecond) What is wrong with `&lt;chrono&gt;`? &gt; Native interfaces, other than abstract classes with pure virtual functions only as it is currently possible, because such classes can also contain data members. What is wrong with a pure abstract class with no data members? `Can contain` does not mean `Must contain`. &gt; Extension methods that would enable extending exiting types with new methods without modifying the type itself. There is a golden rule that says `prefer non-member non-friend functions to member functions`. Plenty of reasons for that. We extend by providing non-member functions. Some convenient syntax for this is in the unified-call-proposal, which was unfortunately rejected. &gt; Finally block for a try-catch so we can specify code that should execute regardless of whether an exception occurs or not (this can be basically achieved by implementing the RAII idiom). Yeah like you said we have it already, it is called RAII. I would argue that is superior to a `finally` block because I don't have to write any additional code. &gt; Static classes, that can contain only static members, and static constructors, that are called before main and have access only to static members of a class (there is actually a proposal for static constructors under discussion for standardization). What is wrong with Meyers' singleton? Why do we need a core language feature for this?
Could you explain why? Really, I don't have an opinion on this stuff, because I'm not nearly proficient enough in C++, but maybe I could learn something.
Oh man I want reflection, it may be my \#1 missing feature right now. Others on the list are mostly in the works already: modules, UFCS, concepts.
If it's anything like pthreads, it's for predictable scheduling: "The pthread_cond_broadcast() or pthread_cond_signal() functions may be called by a thread whether or not it currently owns the mutex that threads calling pthread_cond_wait() or pthread_cond_timedwait() have associated with the condition variable during their waits; however, if predictable scheduling behavior is required, then that mutex shall be locked by the thread calling pthread_cond_broadcast() or pthread_cond_signal()."
As POSIX puts it "if predictable scheduling behavior is required". I had to notify under lock when doing realtime programming.
&gt;Extension Methods I think he meant C# style extension methods where you can add methods to a class in place. like i could add `string.split();` into `std::string`, bjarne's `.` operator proposal would have been helpful for this.
It has to throw away the code, since otherwise, all the translation units in a project would be compiling it unnecessarily.
Oh! Yeah, but you don't need `operator.` for that. You can simply use inheritance! With value semantics, you don't need to "Add a function to a class" after it's declaration. Simply define something like that: struct StringExtension : std::string { using std::string::string; void myAddtionalMethod() { /* ... */ } }; Now just replace `std::string` by `StringExtension` everywhere you need the additional method. With value semantics, receiving that or a string makes no difference. The `std::string` will be moved to your string, and you'll get that additional function ;) but anyway, in that case just use free function. That's something missing from C#.
The think is that the inline keyword is used mainly in header files, where it can be included in several translation units. This is because the compiler is not able to inline code if the definition of the function and its usage are placed in different object files. [Guepier post](https://www.reddit.com/r/cpp/comments/5c1dbt/inline/d9svfoz/) explains the rest.
So anytime a thread is waiting on a signal from another thread?
It is not completely necessary to hold the lock when notifying but this does not mean that you should not expect any race conditions. In the following case: // Thread A if( atomic_counter &gt; 0 ) condition.wait(); // Thread B atomic_counter--; if( atomic_counter == 0 ) condition.notify_one(); there is a race condition, in the sense that thread A can perform a *wait* after thread B has called *notify*.
&gt; What is wrong with &lt;chrono&gt;? Not OP, but, personally I find it rather hard to use even for really simple things.
IMHO they make it too easy to hide side-effects, e.g. what looks like a simple assigment could in fact result in a huge number of function calls doing who knows what.
We already have a language like that. It's called C#.
Mh, I see, thanks.
&gt; It has to throw away the code It doesnt *have* to, and there are situations where it cant  for example nontrivial functions that are non-tail recursive: such functions need to be callable (from themselves). Such functions will either need to be present in all TUs, or the linker needs to join definitions if it can prove that they are identical (which isnt hard).
&gt;idoms &gt;idom not sure if it's just two typos or a trend (sorry for not contributing anything related to the thread, I mostly agree with your statements).
Another [expert beginner](http://www.daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner/) boasting tens of years of experience, offering coaching and training (for serious money, mind you) while clearly not being knowledgeable about the subject.
Try out [Howard Hinnant's talk](https://www.youtube.com/watch?v=P32hvk8b13M). It gives a pretty good overview, and there's a followup on his date library.
Why the "raw" calls to `unlock` in `send_work` and `worker_thread` instead of just defining a block scope and relying on the powerful `}` to unlock the mutex? All it takes is one teammate adding one non-exception-safe statement or a `continue` and you are in trouble. Plus, readers of this code must really think too hard "why is there a raw unlock, why didn't he use a block scope to indicate the mutex lifetime?" 
hmm... yeah, You'll need to store a list of names that match order of what magic_get returns you. But it kinda defeats the purpose of having reflection capabilities.
We are probably using different parts of Qt then. My worst experience was with QML types and QtChart. Documentation is terrible for those modules. For core modules though, yes, it is very good.
Most languages with natives strings have features in those strings that cannot be implemented by someone within the language. Interpreted languages use uninterpreted code to make them faster. Languages without operator overloading often have operator overloads on strings. User defined literals are an example of the "C++" way to solve this problem. Instead of adding a language feature of built-in strings, they recognized that the `std::string("hello world")` was awkward, and made `"hello world"s` work. The functionality to do this was then exposed to end users, with a slight restriction (that only `std` is permitted to have user defined literals that do not start with a `_`) for expansion. It does mean you have to #include &lt;string&gt; using namespace std::string::literals; before you can use `"hello world"s`. 
- Native string type No. - Native interfaces User defined "categories" of classes. Using compile-time reflection and reification, we can define the category "interface". This gives us syntax like: class&lt;interface&gt; bob { void print(); }; where `&lt;interface&gt;` is a bundle of reflection and reification tools. It gets fed the `bob` type, reflects over it, and reifies a type output. The output could look like: using bob = class bob$__some_guid__$ { static auto interface_guid = "__some_guid__"; virtual void print() = 0; }; or whatever. - Native datetime type No. - Properties The ability to embed access to `this` pointer in the special member functions and operations of a member object. So `bob.foo()` where `foo` is a member of `bob` would resolve to `bob.foo(&amp;bob)`, implicitly passing in the `this` in the operation on `bob` the same way members get it implicitly passed. The same for other operations on `foo`. Also, non-unique objects, which do not demand unique addresses. Now I can write a concise property: property&lt;int&gt; bob = { [](auto* self) { return self-&gt;x; }, [](auto* self, int newval) { self-&gt;x = newval; } }; property&lt;int, &amp;Foo::y&gt; alice; property&lt;int&gt; eve = &amp;Foo::z; // eve has storage, magically property&lt;int, generic_property&gt; sally; // type erased property plus I can do a whole pile of other things. - Extension methods This is being proposed, with a unified call syntax. The ability to double-dispatch or virtual dispatch with non-member functions is tricky. - Template type constraints Concepts. - Events Almost every event system I've seen has different compromises. Please be more specific. - Switching on other types Relatively uninteresting, but sure. First fix switch so it isn't quite as fragile. - Finally block Anonymous variables might make this not required? As in: auto = finally( [&amp;]{ /* cleanup code */ } ); creating an RAII block of code that runs when the current scope exits. - Static classes The only thing interesting here is the static construtor? I don't see the high value in restricting someone from creating an instance. With template meta programming, passing empty instances of static classes to functions and invoking their methods on them would be an interesting alternative to traits classes. A static constructor that is called prior to main has interest. There are ordering problems with things happening before main, however. --- In short, in C++ instead of adding feature X, you add sufficient language support to implement feature X, then *let people do better than your plan*. 
"Syntax sugar" is what programming languges _are_. 
To be fair, gcc source code seems to raise the inline score of a function that is declared inline, [a little bit](https://github.com/gcc-mirror/gcc/blob/master/gcc/ipa-inline.c#L1216-L1217). else if ((hints &amp; INLINE_HINT_declared_inline)) badness = badness.shift (badness &gt; 0 ? -3 : 3); 
Mr. sumo952, I would greatly appreciate it if you would directly criticize my post by writing comments to my post. Therefore the other readers can benefit from it. I added a few word about ORD. If you have any suggestion or addition, please let me know. If it is possible, I will added them to the post. Thanks, Rainer
I shouldve marked the sarcasm.
I add files constantly when I program. I used to work in a (relatively at least in my experience) large project where some of the busiest C++ .cpp files were about 5k lines to 10k lines. There files would have tons and tons of temporary throwaway structs and functions defined just for that compilation unit, and sometimes have global variables specific to that compilation unit for caches and whatnot, and go on and on. Each CPP file would have like different "chapters" at least as I organized it in my mind. After working in that project I experimented with a style where almost all of the "throwaway" structures are instead defined in header-only .hpp files about 100 - 200 lines long each, with a docu blurb in comment at the top. There are no .cpp files with multiple "chapters", whenever that happens, it's time to split it up into multiple CPP files or one cpp and a few hpp. Now almost every file is &lt; 500 lines. It's not less code overall, it's just divided up far more finely, but I consider it vastly more readable and it's much easier to remember where things are and where to find them. I've now become fairly religious about this. Almost any significant patch I make is likely to involve adding a few files and deleting a few files. I think the main reason people don't do this is that most build systems make it a huge pain in the butt to add new source files, you have to manually list them all. And if you have to support multiple (parallel) build systems for different platforms, which is pretty common in open source at least in my experience, it multiplies this labor. If you are going to use this style it's really much better for the workflow IMO if (1) you commit to using cmake or scons or something on all platforms, and / or (2) you set up your cmake / scons to just glob the whole source directory. I guess I've never worked on a project large enough to see any negative consequences of that for build times. I'm not an expert, this is just my 2 cents. I think you end up with a far more readable and approachable code base in the end. It depends what your goals are, if it's more important to just ship it ASAP than it is to maintain it or bring new people on later.
Can you share it ? I would like to see it :) 
Just a note, std::async does not create a new thread always.
Sure. Here is a [gist link](https://gist.githubusercontent.com/TheGoodPlaceJanet/fe6903bc4e84bd5a2ee1b99e8512ec2e/raw/3c6e0201146f688f4852fd10be3a1d2769d07ce0/collog.hpp). This is supposed to work like this: log::print(log::tag("main", "info"), "is 25 equal to:", 25, "?", (25==25)); should put to std::cout this: [main] [info] is 25 equal to: 25? 1 Keep in mind that although it is not buggy (I hope), it's not production ready either. I needed this fancy output stuff for remote debugging at work while I was on vacation, and this did the job. But I am sure there is a lot of boilerplate there, and it's far from efficient. I would appreciate all feedback though.
Sorry for the late answer. {}- is always applicable. You have only to keep the exception in your mind and then it is quite easy. One exception is the interplay with classical constructors (as you mentioned it) and the other is auto in combination with initializer list. I discuss both exception to the generale rule in my seminars and the audience is afterward quite comfortable. For me, the new proposal http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3922.html brings more harm than good. Now we have an exception of the exception in case of auto. 
Can you elaborate? I always thought that'd be the case
&gt; std::async has two policies: async and deferred. If deferred policy is used then provided function is executed when &lt;future&gt;.wait() or &lt;future&gt;.get() invoked. But is this case async does not provide async capability, it just delays a sync execution (http://stackoverflow.com/questions/12508653/what-is-the-issue-with-stdasync). 
Properties ("just because you can, doesn't mean you should"): template&lt;typename T&gt; class property { public: template&lt;typename Functor&gt; property(Functor&amp;&amp; on_value_cb); operator T() const; operator=(T x); ... }; class something_with_properties { public: property&lt;std::size_t&gt; size; }; _If one really needs them properties are _easy_ to implement._ They are also overkill (unless you have a specific need) and should be replaced by getters and setters (if you have pre/post conditions) and public member values if you have no conditions on the value.
Thanks!
 template&lt;typename T&gt; class property { public: template&lt;typename Functor&gt; property(Functor&amp;&amp; on_value_cb); operator T() const; operator=(T x); template&lt;typename Index, typename std::enable_if_t&lt;has_subscript_operator&lt;T, Index&gt;::value&gt;* = nullptr&gt; decltype(auto) operator[](Index index) const { return value[index]; } }; ... with has_subscript_operator defined [here](http://stackoverflow.com/a/31306095/186997). 
I know. My point was that it is possible, but a bad idea (because it's over-engineered and what it adds, requires too much effort).
Your example really just proves trying to implement it like that would be a bad idea, not that properties are a bad idea. Operator-dot should solve many of the issues that make a real properties implementation impossible with the current language. 
Because the article may be modified later, the code that was quoted is: extern int a; extern int b; int foo(void) { return &amp;a != &amp;b; } There is in fact a possibility that variables a and b are in the same address. This may happen if a linker is aliasing different symbols into one. Here is an example: /* test.c */ extern int __wrap_test; extern int test; int main(void) { return &amp;test != &amp;__wrap_test; } ` ` /* test2.c */ int test, __wrap_test; Compile with: gcc test.c test2.c -Wl,--wrap,test The return value of the program will be 0. If you remove the -Wl,--wrap,test option, the return value of the program will be 1. While compiling test.c, the compiler cannot possibly know what will happen in linking. If, however, you move these two pieces of code into the same compilation unit, GCC will in fact do the optimization.
To be precise, it depends on the implementation. AFAIK Visual C++ will use a (per process) thread scheduler (which usually means a thread pool, but you can change the number of threads), check [this](http://msdn.microsoft.com/en-us/library/dd984036.aspx) for more info. For more information about other implementations check [this](http://stackoverflow.com/a/15775870/5723188) StackOverflow answer.
Thanks for pointing it out, I was not aware about MS implementation details. That just confirms that std::async should be avoided.
Right okay, so you don't see them as syntax sugar after all, but instead as a seemingly pointless alternative to getters and setters that don't offer any advantages. Properties are useful for clearly modelling higher-level abstractions. It's not like they're a new concept - most modern languages provide them, but C++ unfortunately doesn't. yet..... Hopefully operator-dot will change this.
Other languages force me to eat faeces, why is it only optional to do so in C++!!!
same here #1 missing feature is reflection. this cannot be done properly at the moment (with proper i mean no macros)
Question: what is the current status of C++ AMP? Seems there haven't been many updates. I'm particularly interested what the situation is with C++AMP and Intel graphics accelerations, since AMP used to have issues with this. Also, any info on uptake of AMP in other compilers, such as Intel? I think AMP makes sense when it's available on many compilers/OSs, not just on Windows and tied to DirectX.
Info === I wrote this using C++ for no real reason at all, except because I could and because I was bored and had nothing to occupy my time. If you wish to run it, all that info is found in the README. I have posted this here so that maybe I could get one or two people to try it out, and maybe they would think it's cool, and just *maybe*, they would improve my code! If you guys want to try to make it better, or you can think of a cool feature I could add, let me know! Windows users: I would love it if you would update the Makefile so that it could be compiled one Windows. I am not at home right now and only have access to my MacBook Pro. I love this thing, but I refuse to install Windows on it. Finally, if you have a huge number of cores, it would be awesome to see some benchmarks! If you specify, for example, 18 threads, how long would 10 billion iterations take? It takes me about 18.8 seconds with 8 threads here. Hope you guys find this interesting! **Edit 1:** as suggested by /u/lurkotato I have switched to the `std::vector` to use RAII instead of C-style arrays. ([commit](https://github.com/WillEccles/calcpi-cpp/commit/2fab8d52d00d97c1faf10eee23e0c58ca2d044ea))
First obvious target for improvement: use RAII, news and deletes are a code smell, especially in something this simple.
Bottom line is I still read it and found it useful, it was a nice to have. Thanks for writing it.
:-). Do check out Stephan's other tutorial videos and let us know if there are more areas youd like to see
Now that [I have updated the program](https://github.com/WillEccles/calcpi-cpp/commit/2fab8d52d00d97c1faf10eee23e0c58ca2d044ea) to use RAII, would you mind explaining what you mean? Do you mean the loops where it sets each thread's start/end, etc?
Okay, I have now [updated the program](https://github.com/WillEccles/calcpi-cpp/commit/2fab8d52d00d97c1faf10eee23e0c58ca2d044ea) to use RAII, namely the `std::vector` collection instead of the C-style arrays. There are a few things I did in this program that are inherited from C, since it started as a C program and I eventually just updated it to C++ in order to add threads in an easier (and more portable) fashion.
It was kind of a rhetorical question; I watched your recent talks at CppCon. Great job!
&gt; set(COMPILER_GENERATOR_NAME "Visual Studio 14 2015") I don't think you should ever set the generator in a CMakeLists file? &gt; list(APPEND BUILD_ARCHITECTURES x86 amd64) How cross-platform is that?
Interestingly... implementing them *efficiently* as a library is from slightly complicated to impossible. A property needs to be a data member of the object (for the desired syntax) *and* need to have access to the surrounding object. The naive attempt is to have a `Property&lt;int, ParentObject&gt; mProperty;` however this means storing both `int` and `this` which doubles the size (and make assignment... interesting). It might be possible to do something like `Property&lt;int, &amp;ParentObject::mProperty&gt; mProperty;` and then use an `offsetof` approach to recompute the `ParentObject*` from the current address of the property, but I am not quite sure whether it works right now. Of course, it gets much simpler if no access to the parent object is required; but then it's not as powerful as properties in other languages.
Is chaining possible, aka: has_properties.property_with_properties.leaf_property = 5; ?
&gt; but anyway, in that case just use free function. That's something missing from C#. Maybe not as convenient (syntax wise) but immensely preferable to inheritance.
It's using boost::asio, so it's using epoll/kqueue/select (and possibly others) based on what's available.
I think you are missing part of the point. IIRC in C# you can use a setter on a member *to change another member*. See https://msdn.microsoft.com/en-us/library/x9fsa0sw.aspx Of course just because you can do it, does not mean you should do it. The core language is quite big already.
Tensors still unsupported. 
Is is true, but the fact that it is mentioned in the official announcement and that it is backed up by an external team (google) is promising. http://eigen.tuxfamily.org/index.php?title=3.3#Unsupported_Tensor_module
For those interested here is a [performance comparison](http://eigen.tuxfamily.org/index.php?title=Benchmark) with other BLAS libraries. Unfortunately, it does not completely support parallelism.
Man, I wish I had the money for one of those. What compiler are you using? If it's MSVC that would make sense. `unsigned long` is an absolutely *MASSIVE* number on my system, but I'll look into the std::unit64_t and get back to you if I use it.
I learnt about 90% of the stuff I know from myself. It may be longer to learn, but the knowledge is rock solid. You don't have to make up tricks to remember things, you understand them.
"This page was last modified on 15 July 2011, at 10:52."
Yep, following /r/cpp is a good idea for people and professionals that post about C++ and have blogs ;-) (You don't have to mention me at all). Anyway the short answer is that nowadays `inline` is not about inlining functions anymore at all. I'm not sure whether compilers completely ignore it but the result is that the compiler completely decides which functions to inline and which not, you basically don't have control over it with the `inline` keyword in 99% of the cases. The more or less only use-case for `inline` is to mark functions for ODR correctness. Just read the stackoverflow post at the top of the thread :-) (and the rest of this reddit thread)
Sweet, was unaware of `std::uint_fast64_t`. Now that I know this, how about `long double`? Is that the same across platforms? I would assume not. I'll have to look into that too.
Yes, you are right. To be honest, I don't understand why a BLAS library like this does not include an updated performance evaluation. I think this is one of the most important features, if not the most one, to take into account when choosing the appropriate library for your project...
Why do you think it's aimed at people who want to learn C++? What about people like me, who have been programming in C++ for 15 years, but have never used cmake or gtest?
I was just thinking about this. I think I'll leave out the `static_assert` and just go ahead and leave in there the `long double`. One thing I should do, however, is make sure that because I am telling the program to do `number * 2 + 2.0` and such, that if you put in more than `UINT_FAST64_MAX/2-5` it will not try to calculate that. Though to be fair, if you put in more than that, you might be waiting for 99% of your life for the program to finish, so on second thought, I think I'll leave that out... Thanks for the help, though! Edit: Do you have any idea how I can convert from a `char *` (from `argv`) to a `std::unit_fast64_t`? I know I can use `strtoul` for this, but if I had to convert to a `std::string` and then use something akin to `std::stod`, I wouldn't be too upset. Edit again: Decided there is only one real option, which is `sscanf` with the type specifiers for the `stdint` types. Oh well, I guess it will work, at least.
Here is a comprehensive performance evaluation from 2016, bleeding edge branches of a lot of libraries, including Eigen in all benchmarks: https://www.youtube.com/watch?v=w-Y22KrMgFE The summary is that Eigen is good but mostly somewhere in the middle. But it has a lot of features that none of these other libraries have, like a lot of solvers (FullPivLU, ColPivLU, several QR, LDLT, etc... for various kinds of matrices). Overall, Eigen is definitely one of the winners, even though it could improve in certain aspects. Edit: And here's some more benchmarks from the 3.3 branch: http://eigen.tuxfamily.org/dox-devel/group__DenseDecompositionBenchmark.html
**Company**: GreatCall is the leader in connected health for active aging. With health and safety solutions for older adults and their family caregivers, GreatCalls innovative suite of easy-to-use mobile products and award-winning approach to customer care helps aging consumers live more independent lives. For more info, visit www.greatcall.com/careers **Type**: Full Time **Description**: As a Senior member of the software development team you will help with efforts in the areas of enterprise software design and development. You will be counted on for complex problem solving as well as encouraged to recommend solutions. You will have the unique opportunity to make a difference in peoples lives, developing and optimizing applications in support of health, wellness, and emergency response systems. * Design, build and maintain efficient, reusable and reliable C++ code for mobile and embedded devices * Adapt existing codebase to new platforms as required * Work closely with product owners and teams to lead feature implementation and source third party solutions when appropriate * Contribute to standards and best practices around development processes, coding, and peer reviews * Optimize existing applications to improve performance and scalability * Design and build automated (e.g. unit/integration) tests where necessary * Coach and mentor mid-level Software Engineers **Location**: San Diego, CA **Remote**: Unlikely. Usually, we need people in a team. **Visa Sponsorship**: Not for current opening **Technologies**: C, C++ is required. Lua, and FreeRTOS are desired. Java, Objective C, Swift, Android, IOS, and Javascript are nice to haves. **Contact**: Email Karen.leckrone@greatcall.com or apply online at [greatcall!](https://chj.tbe.taleo.net/chj05/ats/careers/requisition.jsp?org=GREATCALL&amp;cws=1&amp;rid=1107) 
Why not just use the C version?
std::istringstream?
If you aren't capable of understanding the c implementation, why do you think you'll be capable of understanding the c++ implementation? 
There's potential for silent code breakage, which is not nice. X = (A*X).cwiseAbs(); // OK in 3.2, but not OK in 3.3 because X gets resized X.noalias() = (A*X).eval().cwiseAbs(); // Correct solution in 3.3 (also OK in 3.2) EDIT: ok, it's not as bad as I thought: "However, by default Eigen uses a run-time assertion to detect this and exits with a message like..." from http://eigen.tuxfamily.org/dox/group__TopicAliasing.html
That is a problem that should be solved by the IDE (probably already solved by all the clang-based parsers), not by the language.
&gt; As it stands today, I had to invite not the 38 first students (your sampling), but the first 55, as many students aren't able to come due to having tests etc. So I want this to be once randomized, and based on this do my selection of the first n. And I'm still not in? There must be something off... 
I think Bjarne Stroustrup's operator-dot [proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4477.pdf) should allow this. Unfortunately it just missed the deadline for inclusion in C++17, so we'll have to wait until C++20 for this.
[Original thread](https://www.reddit.com/r/cpp/comments/5as20e/terminators_in_c/)
You can use ninja with msvc ? Oo
I think this is a good reference for how to write those properly (add_library / add_executable / target_include_directories / target_link_libraries): https://github.com/tomtom-international/cpp-dependencies/blob/master/src/CmakeRegen.cpp#L93 It can also generate those for you. The compile options and target_sources aren't auto-detectable, but you also should want to not need any of them. The idea is that you have PUBLIC stuff, which is propagated to your clients (such as include directories and link libraries), INTERFACE stuff (... silly cmake not accepting public if you have no code to compile yourself, so) read this as PUBLIC, and PRIVATE which is anything that you require, that your clients should not need. 
It seems a bit over my head
Well you'd probably not want to use this because you don't learn cmake from using some one else his setup IMO. I am not familiar with GTest but from my understanding all this project template does is link it. So you won't get any benefit by using this template if you want to use it (Also IMO).
100% agreed.
Great article! Very information dense. It would be illuminating to see an contrived example showing a file that goes over the 32k sections limit and one that is just under it. Also, why is a legacy 16 bit counter still used? I'm surprised something like that has made it so far without being updated in either coff or elf.
nope, this thread points to the github repository, while this one posts to the blog post about it. Two different things.
This might be part of reason for the umbrage directed towards that book!
The wisdon is that exceptions should not escape destructors - not that they shouldn't fail. In this case, if the rollback throws an exception, there is no need to do anything more as the operation did not succeed. Any other approach would make RAII a useless idiom.
First one is a technique to convert to bool.
Okay, so I updated the program to use the `stdint` types, you mind trying it now?
First of all, thank you for the input. I would like to point out that I have already made a bunch of these fixes, and have the rest of them planned/not pushed yet. Also, yeah, precision is peaked at 20, but I just went with the maximum precision you *can* set. Finally, if you have any recommendations for a good big-float library, I welcome it with open arms, since I haven't a clue what a good one might be.
For a complete beginner [Programming -- Principles and Practice Using C++](http://www.stroustrup.com/programming.html) is a great book.
I can second this recommendation, /u/delux_bg . If you want other solid recommendations, though, check out the [stack overflow c++ definitive book list](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) I used primer personally when making a language switch in my career after having worked professionally programming for a few years. That book is indeed difficult for someone if they are not an experienced developer. Principles and Practice goes a lot deeper on explaining the "why" of things, which is really helpful to build understanding for a beginner in my opinion.
Sure, here you go: https://i.imgur.com/2UmNPBs.png Was to be expected that it is 1/0.43 = 2.33 times slower, so 2.02s. The variance is probably due to background programs, task scheduling etc.
I didn't know about stackoverflow's c++ book list, thanks for bringing it up!
Unfortunately i also tried that book, its as hard as Primer, but with much much worse explanation. 
Thank you, I'll check them out.
That is ridiculous, mine is much, much slower. Might I ask what clock speed you're running that at? My 4980HQ (2.8GHz, though it boosts to 4.0... not sure what it was actually running at) with 8 threads took about 10 times longer: http://i.imgur.com/mD03AkK.png Edit: According to Intel Power Gadget, the speed was about 3.3GHz on average. It peaked around 3.9, but since the fans weren't spinning at the time, it throttled itself. If I made sure the fans were going when I ran it, it probably would have been a little faster. Your CPU also probably is a lot more powerful than mine, is however, and clock speed is not the only factor here of course.
Could you explain &gt; "Calculates" (read: guesstimates) to me?
I've seen this excuse used to justify re-writing the STL to avoid undesirable symbols in objects and the associated binary size increases. It's the wrong solution to solving a problem that the programmer doesn't understand. The fact is, you need to understand your tools, such as the compiler and linker, and know what it takes to tell these tools what it is you want them to do. Things like specifying [visibility](https://gcc.gnu.org/wiki/Visibility) in a shared object is vital to reducing unnecessary binary size. Enabling [link-time optimization](https://en.wikipedia.org/wiki/Interprocedural_optimization) ([GCC page](https://gcc.gnu.org/wiki/LinkTimeOptimization)), can radically cut down on emitted binary size, by performing cross-module optimizations that aren't available otherwise.
Okay, so I figured out a few things. First of all, I forgot that my GCC is aliased to clang on macOS. Secondly, a few of the options are unavailable to me, since clang doesn't support them. Third, I have no clue why I chose to use `-Os` before, since I would rather have speed than size... Anyway, here is the output of my compile and calculations (its about 8 seconds faster this time, much more reasonable): http://i.imgur.com/Ri0sk6z.png
Been reading and practicing mor c++ and i have to say i feel dirty with how messy i was with objects in java. I wish i could easily delete them like c++
/u/BillyONeal - can you comment on why PE/COFF uses a 16-bit section counter? Has the compiler team looked at whether a 32-bit/64-bit counter shows improvement for larger C++ projects?
I don't see anything in the link that is similar to the second example.
Awesome podcast! And I very much like the tangent it took towards the end! (in fact I think it's important and not tangential :-) ). Great guest :-)
The `c2` example does not work and is an error.
[More info here](http://stackoverflow.com/questions/40556822). It seems that even the variadic version is not valid C++17 - an explicit initializer is required, as [T.C. says](http://stackoverflow.com/a/40556997/598696). int main() { X x1{1}; X x11{}; // OK! }
It is a good read, I read about 50% of it (I just skip everything that has no mathematical information in the interest of time).
The "Committee Draft of C++17" link isn't pointing to the document.
I put up a new link.
Can you elaborate please?
Thanks! I have so little to say, though : )
What's "Poisoning the hash"? What about the syntax problem of structured binding (conflicts with attributes when nested)?
Poisoning The Hash says that types are either hashable or not. When a type is hashable, `hash&lt;T&gt;` works. When a type isn't hashable, `hash&lt;T&gt;` isn't even constructible. This also makes `hash&lt;optional&lt;T&gt;&gt;` work if and only if `hash&lt;T&gt;` works. (The paper introduces "enabled" and "disabled" terminology.)
&gt; new rules for auto deduction from braced-init-list It seems that clang and GCC consider this as a defect against older standards rather than a new C++17 feature. They use the new rules even in C++11 mode.
From the proposal paper: &gt; Direction from EWG is that we consider this a defect in C++14.
What /u/bigcheesegs said, and there were also some concerns that the current wording would place it in the global namespace as well as `std`, which would create a conflicts with existing code.
Is this question about a possible performance impact (on a yet to be specified metric) of a 32 or 64-bit section number in object files? Or is it a conceiled feature request to Microsoft's compiler team? Anyway, in our company we throw in /bigobj /Gw /Gy in release builds and let the linker sort out duplicate and unreferenced stuff. This creates sections like crazy but the 32-bit section counters due to /bigobj make this policy feasable without objections from my colleagues.
A couple things I've found when trying to compile using g++ on ubuntu: a) "-stdlib=libc++" won't compile, but removing it works fine as g++ will find the stdlib by default. b) On "g++ (Ubuntu 4.8.4-2ubuntu1~14.04.1) 4.8.4" I need to add the flag -pthreads to overcome a g++ compiler bug with multi-threaded programs as described [here](http://stackoverflow.com/questions/19463602/compiling-multithread-code-with-g). Also this all compiles and workes fine on the "Linux subsystem for Windows" dev system which is convenient.
&gt; Other argument parsers are: &gt; bloated &gt; non-extensible &gt; complicated No 2 people can agree what a command line parser should look like. Yours do not offer a short form/aliases (single dash ), do not support the getopts format, has no support for documentation, requiered arguments, list/repeatable arguments and a bunch of other things. You wrote one because you wanted to write one. which is fine. That being said, at a glance * I really dont like the trend of writing header only libs. I get why people do it, but... * Having absolutely 0 copy is great... on the other hand, it's really optimisitc. argv is non-const and could be modified - Qt is notorious for modifying argv, for some reason. * Have you tested the code with a c++17 compiler such that you don't need experimental headers ? * you could use `make_array` rather than `std::array` * ~~Having `get_or` only take a rvalue-ref for the default value will complicate the use of your api~~ * you could rename `get_or` to `get`, I think it would make the api more elegant. 
It would be great if MSVC compiler had some profiling diagnostics. I mean for profiling the performance of the compiler itself. We have some files that take a really long time to compile, and it's hard to find out why. Is it too many includes? Is some specific include taking a long time? Are there too many include directories? Are there complex templates somewhere that could be optimized? Is there a half megabyte function somewhere that takes a long time to compile? (yes, that happened once,) I am thinking maybe there could be a compiler switch that would enable profiling output, and then the compiler would print out some timing statistics after compiling each file. It could itemize the time spent according to compilation phase, according to time spent processing each header, perhaps top 5 functions that took longest to compile, etc. This does not need any big changes in the compiler, just add some time measuring to some strategic places in the compiler and print out the result. It would really help a lot.
Thanks this is awsome. Definatly gonna read trough this.
Yes, I have read it. Unfortunately, that does not have the granularity required to debug these kind of issues. The most details you get look like something this (taken from the article): 1&gt; time(C:Program Files (x86)Microsoft Visual Studio 10.0VCbinc1xx.dll)=6.914s 1&gt; time(C:Program Files (x86)Microsoft Visual Studio 10.0VCbinc2.dll)=0.064s What I would like to see is more detailed itemization, on header file level, on class level, on function level, on compiler pass level -- anything that is possible would likely help. From these two numbers above, I don't get enough information to find out why some specific files in our 4 million lines of code project compile slowly. I can start removing includes, run preprocessor only and inspect the output, move stuff around, and see what helps and what does not. I am not saying we are completely helpless, there are some tools available to us. But it is hard to remove includes or move stuff around in a 20 year old codebase where everything depends on everything, and still have it compile. The correct approach to optimization is to find out the biggest culprit and fix that, then repeat. I could improve MANY things and each of them would probably help a bit, but there is probably some complicated template lurking somewhere or some other single problem that would help a lot with minimum investment. If the compiler could tell me what is bothering it, what takes it the longest time to process, I would concentrate on that thing. It's like optimizing an application when all you can do is guess and experiment, vs. optimizing an application if you have a proper profiler. You can do only so much by guessing.
&gt; constexpr std::chrono::now what would it mean ? the time at time of compilation ? 
For those who prefer text to video: https://bitbucket.org/blaze-lib/blaze/wiki/Benchmarks 
LTO helped immensely - it's where I got my 80% number from. It did also require half an hour per target to link, and required me to activate a swap partition as it used about 20GB of memory to link it together. For obvious reasons, we'll only use it on releases - so all developers are still stuck with the huge binaries.
Yup, I think this aspect of `std::unique_ptr` deserves its own article. They are really handy for managing resources from C libraries.
Does anyone have any hints on when/if the update to this book is supposed to arrive? 
Serious question: how would the IDE help with that?
This was well written. Thank you.
You didn't say anything about unique_ptr of forward declared class and its caveats, nothing about custom deleters and factory methods applications.
 struct Base {}; struct Derived : Base {}; // ... std::unique_ptr&lt;Derived&gt; derived = std::make_unique&lt;Derived&gt;(); std::unique_ptr&lt;Base&gt; base(std::move(derived)); Note that generally, you would need to give `Base` a virtual destructor (`virtual ~Base() = default`), since you are probably going to be deleting an object of type `Derived` through a pointer to `Base`
Thats not how I'd heard it... I think the discussion you're referring to is still the naming issue? Did I miss this part? Someone said std::byte would be a fine name, since its meaning is same as the description of "byte" as a "term of art" in the standard. The counter to this is that we cannot expect our users to have to know all of the "terms of art" in the standard.
Thanks for the feedback! &gt; No 2 people can agree what a command line parser should look like. [...] You wrote one because you wanted to write one. which is fine. Yes, mostly upset with having to use `gflags` at work. :) &gt; . Yours do not offer a short form/aliases (single dash ), I will look into this and add something. &gt; do not support the getopts format, has no support for documentation, Very true, I'll take a look at documentation. I'll see if I can find a spec for `getopts` so I can support it. &gt; requiered arguments I will look into adding validation. At the moment, a user can use `std::all_of` on a `std::vector&lt;bool&gt;` which has had the `optional`s inserted. Definitely not the cleanest and could be improved. &gt; list/repeatable arguments and a bunch of other things. I'll look into switching to a multimap. Might not be worth it to keep everything simple. &gt; Having absolutely 0 copy is great... on the other hand, it's really optimisitc. argv is non-const and could be modified - Qt is notorious for modifying argv, for some reason. I'll look into this. &gt; Have you tested the code with a c++17 compiler such that you don't need experimental headers ? I actually use `std::experimental::{optional, nullopt, string_view}`, I was just too lazy to type it out. I will update the docs. &gt; you could use make_array rather than std::array &gt; you could rename get_or to get, I think it would make the api more elegant. Agreed! Will do. ------------------------------------ [edit] I hadn't seen `make_array` before this comment and have to say, it's pretty nice. [lots of other edits] I'm bad at formatting.
Yeah sure, but what do you want us to discuss in this thread? Why didn't you just link it in the other thread? Do you know how Reddit works?
Can you not open a second instance of VS, and then attach the profiler to the first instance? I guess the debug information (pdb's or whatever) might be missing to produce valuable output?
On what basis do you hire people? What are the chances of an Indian engineer getting this job?
On what basis do you hire people? What are the chances of an Indian engineer getting this job?
On what basis do you hire people? What are the chances of an Indian engineer getting this job?
On what basis do you hire people? What are the chances of an Indian engineer getting this job?
On what basis do you hire people? What are the chances of an Indian engineer getting this job?
Sadly we can't have this as it would make breaking the ODR really easy.
So far its the only book that seems easy and well explained to me.
[You need to explicitly link `libatomic` by adding `-latomic` to the compiler's flags](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=65756). I don't know why it isn't there by default.
[removed]
Missing virtual destructors are easily the main cause I see of memory leaks these days so that's a good addition. On those lines it might be worth commenting that if there's a virtual destructor somewhere in an inheritance chain, it's unnecessary (but arguably good form) to additionally provide them lower down. With regards to the up-casting, a pattern I use a lot is a typical factory method, something like template&lt;typename Args&gt; std::unique_ptr&lt;BaseClass&gt; BaseClass::Create(Args&amp;&amp;... args) { return std::make_unique&lt;Implementation&gt;(std::forward&lt;Args&gt;(args)...); } and implement it in the implementation's .cpp, which (as you doubtless know) helps enforce very strong PImpl since nothing else gets to see anything other than a pure virtual interface and a static create method. It also allows for multiple Creates for different implementations, all held by base class. (And without rigidly enforcing virtual destructors that's a good way of leaking pretty much everything you allocate...) When you come to your shared_ptr article, by the way, it might be worth noting that for a unique_ptr any class that owns it (obviously) needs to include the owned class' declaration, while for a shared_ptr it's sufficient to forward-declare it. But don't get me wrong - I enjoyed the article. I only came back to C++ at C++11 (having last experienced whatever on Earth Borland put in their compiler around 2000; I'm guessing C++03) and smart pointers were a welcome surprise :)
Ah, interesting, thanks! I had found a (clearly out-of-date) page that said that library was referenced but not actually implemented yet.
&gt; if there's a virtual destructor somewhere in an inheritance chain, it's unnecessary (but arguably good form) to additionally provide them lower down. Would you be so kind to elaborate on that? Thanks :-)
No problem! :) My personal, unpopular opinion is all open source software should be public domain: completely free. It ensures it can be used in any situation and live forever.
First, well done for writing and publishing code. A code review should give you an honest critique. Here's my feedback: * flags simply provides a view of argv, a way to query it. It allows me to programmatically interact with what was specified on the command line, but gives me no way to control it, and I must implement the constraints myself. You stated that it's not bloated and not complicated, which justifies this. Just saying. * flags would ideally support a command line like this: "program -v -v -v" where I want to know that the verbose level is three. The std::unordered_map implies it cannot. * flags would ideally automatically support options like '--foo' and '--no-foo' providing true and false values for the 'foo' option. * flags does not have any declarative capability, so I cannot specify that the 'bar' option is an integer, and should fail otherwise. Similarly that an option should have a value, but does not. * flags does not permit me to limit the number of positional arguments. * flags does not provide me with support for generating usage text. * If a program does not support a '--whatever' option, flags will not reject it. * The license should be included or referenced in the source. * There is code that deserves comments, but has none. * No unit tests means I can't tell whether it works. Hope this is useful, it was intended to be.
*Here's the declaration of a variable:* then I see a old style for loop... wut? And I lol'd at "c++ is more secure because oop" and specifically at "c++ is an oop language" if you use c++ for oop only you use it in the wrong way IMHO.
I was wondering why I couldn't find an example of how to use it. That was until I found it: https://tls.mbed.org/kb/how-to/mbedtls-tutorial. Seriously: This is WAY to complicated. Have you looked into libtls by the libressl-guys? While it is a C-API as well, it looks like it would be trivial to wrap and appears to be well designed. A good C++-API would look somewhat like this: const auto accepted_root_certs = tls::get_system_certs(); // throws if anything goes bad: auto tls_stream = tls::connect("example.com", 443, accepted_root_certs); // tls_stream is a regular behaving std::iostream A server might be harder, but I think the following could work as well: const auto cert = tls::read_cert_from_file("/path/to/cert.pem"); auto server = tls::server(443, cert); // will start parallel task for each incoming connection and calls the provided function: server.listen_parallel([](std::iostream&amp; stream) { /* communicate over stream */ }); Granted, there might be room for minor improvements in the details and it should be possible to configure it in more detail, but given sane defaults, something similar to this should be possible.
Thank you to all the committee members who posted live updates for making the meeting more transparent and accessible to the community! We appreciate it.
Look at how rust does this 
Why not instead of returning "::Thing" just return "ChoiceX::Thing", make external references to thing use "Actual::Thing" and get rid of the virtual interface?
I second this. Rust guarantee that you can not use a value after it was moved, removing the need for a moved-from state /u/foonathan raises. Also, as references can not be null, Rust guarantee that `Optional&lt;&amp;T&gt;` will have the same size as `&amp;T`, and will use the [NULL value for the `None`](http://stackoverflow.com/a/16515488/4692076) variant of the enum.
&gt; Rust guarantee that you can not use a value after it was moved, And how do you guarantee that in C++?
&gt; I'd have to change every function and type that would previously take a `System` or `RenderModel` into a template; basically, my entire program. There are a couple of another ways to do this without using templates. The first is to have your two different classes, but get rid of the RenderModel base class, and conditionally (at build time) typedef each specific renderer to RenderModel globally. I.e: #ifdef USE_OPENGL typedef OGLRenderModel RenderModel; typedef OGLRenderer Renderer; #endif #ifdef USE_DIRECTX ... #endif That's one approach. A second method is have a single header for your types, but implement different backends. This one is harder to explain, but it's generally how many cross platform libraries are built. Renderer.h // contains class definition for Renderer. Renderer_Ogl.cpp // Implements the functions in Renderer.h in terms of OpenGL. Renderer_Dx11.cpp // Implements the functions in Renderer.h in terms of Dx11. This gives you complete seperation, no class hierarchy, no complications due to typedefs, and the rest of the application doesn't care. Edit: Formatting.
I came in with 8 years. Is it a college in USA? 
Fixed. Apologies, was on mobile and struggling.
&gt; Stack unwinding or object destruction and not guaranteed and is completely up to the compiler implementation. So if youre code depend on your object destructor Stopped reading there. If the writing is this bad, one can only assume that the facts are bad too. Also, what's with the black borders? Why are you wasting my screen space?
How does it compare to other TLS implementations in terms of performance?
OP might not be a native english speaker? Poor grammar is not necessarily indicative of whether the technical details are correct.
The mbedtls tutorial is verbose but seems pretty straightforward to me - and I like the style of showing the HTTP code first. The resulting example (https://github.com/ARMmbed/mbedtls/blob/development/programs/ssl/ssl_client1.c) is, again, verbose and has lots of white space and debug printfs, but I don't think it's complicated at all if you look at the core usage.
This answers the question given since it only needs to be changeable at build-time, but I'm also curious whether there's a better way of solving this problem if you're selecting which implementation to use at runtime. It's very common to be able to configure a game to run using opengl or directx at runtime via a menu option/command line flag/etc, so it doesn't seem like an unreasonable thing to strive for. I can't think of anything that has compile-time guarantees that wouldn't involve templates propagating everywhere through the codebase, but I'm curious if some pattern exists because it seems like it *should*
It's nearly always a bug to use a variable after having moved it. To be honest, I see that happening and it's a problem. We need static analysis tools that detect this category of bugs. I would love to have the compiler issue a warning if you do any const operation on an object that might be in a moved from state (maybe some contract library can go further than just const methods, but it's a start). So std::unique_ref does have an invalid state to support move operations. It's still incredibly valuable because it: - Indicates the intention (it indicates that a method requires the object to be provided, that a method never return null...) - It removes a whole category of bugs (null dereference), trading for another one that already exists (reading from a moved from variable). - It reduces the frequency of those bugs: a unique_ptr often *starts* null, a unique_ref can't start null and can enter an invalid state after a move. It's just easier to find a null unique_ptr than a moved from unique_ref, in particular because returning unique_ptr&lt;T&gt;(nullptr) is seen as legitimate in some cases, whereas returning a moved from unique_ref is not (it would be UB unless RNVO can kick in, since copying/moving a moved from unique_ref would be UB) 
I believe you can not do it (at compile-time) in a library, you need compiler support for it. You could still have an assert for checking it at run-time, but then you would need to be able to differentiate between valid and moved-from state, and thus use a kind of `null` value.
Nope. India. btw, does Trump have a policy against australian workforce? Word on the street is that trump loves Indians
I'll add a section about that shortly, thanks!
I'll add a section about that shortly, thanks!
It's time to ask yourself a different question : do all these objects that your are creating through a factory really have to live on the heap?
No, I was writing on a phone and didn't feel like googling, scrolling through, copying and pasting, that's all.
&gt; It's nearly always a bug to use a variable after having moved it. Not at all. It is perfectly fine to use std::unique_ptr after you've moved it. Or any standard library type in fact. &gt; So std::unique_ref does have an invalid state to support move operations. It's still incredibly valuable because it Yes, I totally agree. A non-null std::unique_ptr is a great addition. I just would not add move semantics.
Runtime meaning you pick ChoiceA or ChoiceB at runtime, but with ChoiceA::System knowing at compile-time that handle_thing is always called with a ChoiceA::Thing and not a ChoiceB::Thing I suppose one answer would be dynamic linking. Have it load either ChoiceA.dll or ChoiceB.dll at runtime (similar to your solutions), but even then we could take the problem one step further and ask how to solve it if you wanted to have both a ChoiceA::System and a ChoiceB::System exist in tandem, with ChoiceA::System::handle knowing at compile-time that handle_thing always gets a ChoiceA::Thing, and having the same guarantee for ChoiceB. At that point it feels like templates are the only answer
Accelerated C++.
It's doesn't require templates. One way I can think of is to implement both backends and then import them into different namespaces: namespace Dx11 { # include "Renderer.h" } namespace Ogl{ # include "Renderer.h" } Then create a small class that virtually wraps the public interface of the renderer.
&gt; It happens to be perfectly, fine to read from a unique_ptr after you've moved it. [...] I had many discussion with /u/JonKalb and others over it. There was no real conclusion. &gt; Reading from moved-from std::string is unspecified, Reading, yes, but you can safely call functions with wide contracts like `empty()`, `clear()`, or, more importantly `assign`. foo(std::move(str)); str = std::string(10, 'a'); Might be less efficient than: foo(std::move(str)); str.assign(10, 'a'); And I think the first version might be useful to allow, so why not the second as well? Both are assignment, after all. &gt; Non-null unique_ptr without move semantic is very limiting, isn't it? You couldn't have vector of them say... Yes, and that's because C++ lacks destructive move. I'd rather go for the "safer" version without move. After all, you can write a adapter over `unique_ref` that *does* support move semantics and use that in the container. It's not guaranteed (I think), but very unlikely that vector will access a moved-from object, so the "unsafe" `unique_ref` with moved-from state is contained. For everyday use, I think it kinda defeats the purpose, but I can totally see your point.
&gt; A non-null std::unique_ptr is a great addition. I just would not add move semantics. That's just an object, right?
&gt; templates only need to be in headers if you don't know all the instantiations in advance. If you know all the instantiations, like here, you can declare templates in header files and instantiate them in .cpp files, just like you would any other code. So the entire build time concern is a non-issue. That means I have to put the #ifdefs of the chosen platform in every single source file in order to instantiate the templates for the right type. Not very nice or maintenance friendly. &gt;But frankly, I don't see why you even need the factory in the first place. Real factories allow you to select the type being constructed at run time, that's the whole point. You are selecting the type being constructed at build time. Yes but the code that's calling create_thing doesn't know the actual type of the system. Otherwise we're back at the earlier suggestion of typedefing the derived types. I'll refer you to my reply there. Factories are not just for choosing the implementation at runtime. In this case it's for hiding the details of the derived type. &gt;Note that you can still keep the base class interface, and use it wherever you like. Our thing will implicitly up-convert wherever you pass it in by reference to base. I'm not aware there is such a thing as implicit upcast. Could you give a working example? 
No, you can still pimpl those bits if you want so the headers don't leak. class Renderer { struct Platform; } Then each specialized cpp file would include the relevant platform bits and use the platform struct to store any state it needed. 
We hire people based on merit, like pretty much everywhere else I know of. The chances of an Indian engineer are the same as that of any other equivalently-qualified engineer; we do not discriminate.
I've dealt with a somewhat similar situation. We had some generic code at the bottom of a beefy callchain that was doing some heavy math in tight loops (unsuitable for virtual dispatch on those particular functions). However the call chain was tall enough and the underlying object needed to be created early enough, that the resulting proliferation of template parameters seriously affected our compilation times (even with explicit instantiations). I don't have access to this code base anymore so I'm pulling this from memory, but I believe what I did was first forward declare my children types, and then created an alias for a boost::variant&lt;&gt; over pointers or something to those types. Then I defined the base class with whatever virtual interface it needed, with one more virtual function to return itself as the boost::variant. This way functions high in the call stack could avoid templates completely and deal with the virtual interface, and whenever computational efficiency was about to become an issue, a quick visitor could dispatch to some generic code that operates directly on the concrete child classes (gaining access to the non-virtual interface).
Can you define merit? Like good portfolio of projects or work experience?
Have you looked at [CRTP](https://en.m.wikipedia.org/wiki/Curiously_recurring_template_pattern) it's generally how one would do static polymorphism.
Both, really. And not only "good", but "relevant" for what we need is usually better. What we're looking for (in my team, other teams have different needs) is what I posted above in the Description, i.e. "very strong C++ engineers with good knowledge of computer science fundamentals and systems programming".
&gt; I'm not aware there is such a thing as implicit upcast. Could you give a working example? All upcasts are implicit. 
&gt; So I have to new both Thing and Type. This is stupid. I shouldn't have to. Actually you don't. There are two ways around it. But before I get into that, I really feel like you're making this more complicated that it needs to be. You actually have two problems here that require two solutions; 1 How to abstract away platform specifics. You're trying to do this by creating distinct types and using inheritance. Don't do this. Instead just design the public API and then figure out how to hide the platform specifics. 2 How to shield clients from implementation details, such as platform specifics. For this, you are forced to use some type of type erasure and to call "new" somewhere. This can however be placement new, now for the details of getting around the second allocation in the pimpl. a. Use std::aligned_storage and placement new to create the hidden type. This way there's no extra allocation. This comes at a cost of always allocating the size required for the worst case. b. If, like in your case, you're allocating the outer type anyway, you can do something like; // In thing.h class Thing { public: void method(); private: Thing(); friend Thing* create_thing(); }; Thing* create_thing(); // In thing_ogl.cpp class Thing_Ogl : public Thing { public: void method() { } }; void Thing::method() { static_cast&lt;Thing_Ogl*&gt;(this)-&gt;method(); } Thing* create_thing() { return new Thing_Ogl(); } This is similar to your option C, but thing is guaranteed to be of the right platform type, because there's no other way to create it. The problem is that you still have at least one allocation per object, which is necessary to hide the details.
I think when it comes to things like this it becomes more of a matter of intent and whether the extra layer of abstraction makes sense (e.g. with a factory).
Beginner questions are off-topic for our subreddit, please read the sidebar.
This was a great answer. Thank you.
Doesn't solve your problem but here's another nonnull pointers library that supports smart pointers out of the box: [nn: Non-nullable pointers for C++](https://github.com/dropbox/nn)
you're an ass
You may want to consider mentioning related chapter in standard for curious reader to peruse (15.5.1 for C++11)
I think we'll be ready at Kona. Time-wise, Toronto would be cutting it short.
I can't seem to find std::variant on here? Is that on another list?
GCC page [of C++1z language features](https://gcc.gnu.org/projects/cxx-status.html#cxx1z) still lists Structured bindings as unsupported.
Yeah, it was added only a few hours ago: https://gcc.gnu.org/git/?p=gcc.git;a=commitdiff;h=9c8aeb661a9d6cc82186dde40839f7353188c187 The page will be updated soon.
libstdc++ status is here: https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.201z
I'm impressed that they managed to be ready before clang, that's great :)
It'd be nice if you can at least add the missing includes in the post too: #include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; #include &lt;string&gt; and fix the typo in std::vector vec; =&gt; std::vector&lt;std::string&gt; vec; This way it's possible to copy/paste it from the web to give it a try.
Sorry if this is an ignorant question, but how would I get C++17 to work with Sublime 3? Build a new system?
Hi, /u/spd69! We hire all sorts of people from all sorts of backgrounds. Its all about your talent, your potential and what you can achieve with us. Please send me a message and tell me a little bit more about yourself and your experience with C++ game development. Thanks and all the best, Rebecca 
&gt;What is the problem with defining the types in such a way that, while they would have a special moved from state, all operations except assignment and destruction are UB when an object is in that state? This says nothing about the existing types, and adds value in that it makes it harder to do the wrong thing and allows to document intent through the type system rather than comments. First of all: I'm completely in favor of non null pointers and using the type system instead of comments. I've designed my entire type safe library around it. But I don't see much value of a type with two states: value or UB. I'd rather have a true non-null type with one state or a two state type with value or null *but* where it is easy to handle the null state. Given that we can't really do the one state type and move semantics in C++, I'd implement it without move semantics instead of allowing the UB state. You correctly argument that you should not access moved from states and that it is difficult to do accidentally. But I'd rather be save and limited instead of unlimited and possible still unsave. But that's just my personal preference. &gt;I acknowledge that it's hard but not impossible to access a moved from unique_ref. You can indeed do something like: auto x = make_unique_ref&lt;Widget&gt;(42); auto y = move(x); x-&gt;Bar(); // UB &gt;I think this is comparable to using deleted objects (in that it's also UB, also hard to get to, etc...): auto x = Widget(42); x.~Widget(); x.Bar(); // UB You are correct with your example, but replace x-&gt;Bar() with x.reset(..) and that should be defined behavior, see also my string assign example. 
Back when I was at the university (mid-90's) the cheapest books for my degree were around 50 , I had to buy a few close to 100 .
Right. But as far as I can see these are all "minor" features. And clang also hasn't implemented them yet.
http://melpon.org/wandbox has a build from yesterday. 
What would be really nice is a gcc equivalent of [apt.llvm.org](http://apt.llvm.org) with ready to install nightly build packages. That would allow people to test it for their own projects and give feedback before the release date.
&gt; std::aligned_storage needs to know the size of the of object, i.e. `sizeof(PlatformSpecificData)` I should have been more clear: just hard code the size. It needs to be the max of all your platforms. Of course, this creates a small maintenance burden. &gt; That looks like a virtual call, but statically. Why not just make it a virtual call? I guess this avoids the virtual dispatch overhead. Yes, since there's only ever one inheritance chain in this scheme, there's no need for virtual, so why pay the cost? &gt; In my case, I'm passing it round like a resource (with some platform-independent properties I can query, sure) Anytime you erase the actual type, you are going to pay somewhere. Either through an indirection, an allocation or manual code maintenance. It's a fundamental trade off in the language. 
What is `hash&lt;nullptr_t&gt;` good for?
The links seem to be inaccessible to the public. Any other place where I can read about those features? Which national body made those comments?
As it is, the article feels incomplete to me. It mentions places where std::terminate will be called implicitly, and focuses on double throw scenarios, and a throwing before the main call. What I would have wanted covered: - alternatives to triggering a terminate call. - scenarios where you want to call terminate from the code explicitly (for example, critical environments where you can afford no side effects at all) - scenarios where you do not want a terminate call (a bad/explicit call to terminate in library code will cause the entire application to exit - and probably breaks expectations).
After a destructive move operation, would you not want undefined behavior for every access to the "destructively moved from" object, except maybe placement new? You can see the similarity with the current move semantic where every access to the moved from object is specified as UB, except maybe assignment... PS: I want destructive move for performance (it can be implemented more efficiently for some objects) and for having the ability to say it's always noexcept (some implementations of std::list want to keep a heap allocated sentinel after the move to keep the invariant of the class that would for example allow assignment to work).
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/5cw1kt/girl_tries_to_kill_a_chicken_in_her_house/d9zua2p/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
For libstdc++, Feature | Proposal | Status ---|---|---- Adopt the File System TS for C++17 | P0218R1 | No Variadic lock_guard | P0156R0 | No Removing auto_ptr, random_shuffle(), And Old &lt;functional&gt; Stuff | N4190 | No (kept for backwards compatibility) Here's hoping they are ready for the 7.0 release. Not getting rid of the fully deprecated stuff is sad, but understandable. I hope they pull it from the docs so new users won't try to use it.
&gt;After a destructive move operation, would you not want undefined behavior for every access to the "destructively moved from" object, except maybe placement new? After a destructive move everything should be, yes. I am always talking about current move. &gt; You can see the similarity with the current move semantic where every access to the moved from object is specified as UB, except maybe assignment... And what is your definition of "assignment"? 
Might I be so rude to ask you to reconsider your learning strategy? http://stackoverflow.com/questions/18943456/is-it-worth-to-learn-microsoft-foundation-classesmfc-nowadays If you still want to learn MFC I found this tutorial website that seems to be covering MFC pritty well. http://www.tutorialspoint.com/mfc/
Just curious, how long is that going to take approximately on an "average" Core i5 Quad Core or something like that? Just looking for ballpark numbers.
Apparently I need something like ten lines of code to initialize it and a further five for cleanup (and this is without managing the socket). This is definitely too much. The common case should be simple! While I understand, that C-API are always more verbose, but this is simply too much, to be acceptable. If there is indeed a way that avoids all this boilerplate, I'll be happy to learn about it, but the fact that the code-sample is so well hidden on their website makes me doubt it. Libraries that have good APIs tend to put code-samples to the front-page to show how easy to use they are. (And ease-of--correct-use is nowhere else as important as when dealing with crypto-libraries!) I am not saying there shouldn't be options to configure many things, I am saying that the defaults should be sane so that this isn't required under normal circumstances.
We're at GCC 6.x already? Dammit, how are those of us maintaining niche cross-compilers supposed to keep up? I'm still working with 4.8...
Well under 10 minutes if you use make -j4 or higher.
I actually liked C++ Primer Plus. It's dated. The book's title is unfortunate (implies a relationship with C++ Primer where there is none). And there's a strong movement in the C++ community to teach C++ without teaching C first. But 20 years ago, Prata's book was the first one I read where things made sense to me. So it holds a certain amount of sentimental value. But unless it gets revised for C++11/14/17, I can't recommend it for newbies.
At least the last one is permitted by the standard's new zombie names notion.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5cx3z1/is_this_book_bad_for_a_complete_beginner/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yeah, we should handle all sizes &lt;= 8, not just powers of 2. Filed as VSO#291269.
I tried solving many of these issues : https://github.com/I3ck/FlaggedT
Clang is beaten, long live gcc
Isn't networking N4612?
Odin can definitely talk but i was very interested in what he had to say
&gt; Tell me if I'm misinterpreting you: your point is that because after "move(x)", "x.Something()" is sometimes valid, the move version appears normal whereas the destructive_move version shouldn't. Yes, that's my point. &gt; In my code, I actually use "move" the same way I would "destructive_move". And that's why I spent many hours discussing it. 'cause you might not do that. &gt; If you do that, I feel you get the benefits of the destructive move you desire, don't you? Yes, but it is not *guaranteed*. With destructive move I want a strong guarantee, a compilation error would be amazing, if you use a moved-from object. With current move, it is a convention at best.
Works now.
I'm just curious, is variadic `lock_guard` less trivial than it seems? It seems like a trivial RAII handy wrapper around variadic `lock`. I'm just going through Anthony Williams multithreading book and my first thought on seeing variadic lock followed by passing the locks into regular lock_guard/unique_lock was that that boilerplate could easily be encapsulated.
This is like asking: how can I drink orange juice while coding C++17? Answer: the same way you drank orange juice while coding C++14. There's no relationship between a text editor and the compiler that you use. When you use a text editor, you change the source code, and then you separately run some command (which the editor can give you a shortcut to) to build the code. You would just change that command. Note that if you use an IDE or something that actually parses source (which Sublime does not without specific plugins, AFAIK), then there is a question of whether that IDE's parser/indexer supports the latest C++. But even then, this will only affect little red squiggles and goto definition, it will not stop you from compiling your project.
Seriously. clang has been a huge kick in the ass for the gcc team to clean up their codebase and get things done.
Wow, I can't believe it optimized this for loop away.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [code::dive 2016 conference live stream (links and agenda in comments)  \/r\/cpp](https://np.reddit.com/r/programming/comments/5d1ify/codedive_2016_conference_live_stream_links_and/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Ok ! I wonder if in a far, foreign future, it'd still be seen as "jokingly" as today ? For instance F# is able to infer some informations for its *type system* from filesystem or even web data thanks to [type providers](http://fsharp.github.io/FSharp.Data/library/CsvProvider.html) (even if it's interpreted, not compiled, IIRC?). &gt; Utilities such as `floor` and `round` can make use of this. are they constexpr ? I was under the impression that everything in `&lt;cmath&gt;` was not (sadly).
&gt; &gt; Utilities such as `floor` and `round` can make use of this. &gt; &gt; are they constexpr ? I was under the impression that everything in `&lt;cmath&gt;` was not (sadly). `std::floor` et al are not; [*`std::chrono::floor`* et al](http://en.cppreference.com/w/cpp/chrono/duration#Non-member_functions), which are new to C++17, are.
The variadic version will be renamed (most likely to: scoped_lock). 
Just trying to help out... a) The make file defines the compiler as gcc hence the warning. b) I would say that a project not having the "-pthreads" flag it's compiler args went it needs it to compile is worth mentioning, also the the labeling of it as a bug is from the link and not just my opinion (no modern compiler should need a flag to run threads...). 
&gt; Just trying to help out Me too :) &gt; no modern compiler should need a flag to run threads... Perhaps, that's debatable. I guess it comes down to control, as there is multiple threading libraries (libthread/libpthread) it comes down to the dev to choose.
If all you need is the _TS_ then I believe GCC started shipping it beginning with GCC 5.3. What remains to be done is taking everything out of `std::experimental`, renaming the `experimental/optional` header to `optional`, etc. I.e., if you just need the functionality and have a somewhat recent GCC then it should already be there, you just have to use `std::experimental::filesystem` rather than `std::filesystem`.
I have to agree that the presentation is really off-putting, especially compared to libtls. Just compare: Example code: * https://gist.github.com/kinichiro/9ac1f6768d490bb3d9828e9ffac7d098 vs. * https://github.com/ARMmbed/mbedtls/blob/development/programs/ssl/ssl_client1.c API reference: * https://tls.mbed.org/api/index.html vs. * http://man.openbsd.org/OpenBSD-current/man3/tls_init.3 I don't want to to sound too negative, maybe mbedtls is really good under the hood, but...I mean, come on: void mbedtls_ssl_init(mbedtls_ssl_context* ssl): Initialize an SSL context Just makes the context ready for mbedtls_ssl_setup() or mbedtls_ssl_free() int mbedtls_ssl_setup(mbedtls_ssl_context* ssl, const bedtls_ssl_config* conf): Set up an SSL context for use.
I randomly checked the paragraph about exceptions. There is no correct information on that page. catch(int i) does not catch a divide by zero. And the bad English grammar hurts my head.
I'm not really sure what point you're trying to make here. This has nothing to do with the situation I discussed, i.e. when, for some `struct T`, `alignof(T) &lt; sizeof(T) &amp;&amp; sizeof(T) &lt;= sizeof(void*)`. Your situation doesn't really apply to my question. Also, why do this: static_assert(sizeof(Foo) &lt; sizeof(Bar), ""); static_assert(alignof(Foo) &lt; alignof(Bar), ""); You never have a situation where you use `Foo` and `Bar` together. You overaligned `Bar`, obviously it will have padding. Yes, value initialization will zero out the padding bits, while `T{ 0 }` won't if there is padding. Maybe I'm missing your point.
You also need to use `-lstdc++fs`. Do note that the last time I tried it a month ago, some `std::filesystem` stuff that worked on MSVC14 wouldn't compile on GCC and even after I fixed those, it still failed with a few linker errors for some reason (even though I added `-lstdc++fs`). I'd rather probably wait it to be moved out of experimental and be considered somewhat "finished".
Fair enough! In that case, Boost.Filesystem has been "finished" since Aug. 2010 (when Boost 1.44 was released), and has **far** fewer bugs than even the MSVC implementation... ;-]
Is there a code snippet to test all the new core language features at once? Or most interesting of them.
Thanks! Good call, I suspected I was missing something like that.
Nice article! As I posted on Twitter, here's a solution using [`std::apply`](http://en.cppreference.com/w/cpp/utility/apply) and a fold expression over the *comma operator*: template &lt;typename Tuple, typename Func&gt; void for_each(Tuple&amp;&amp; t, Func&amp;&amp; f) { std::apply( [&amp;f](auto&amp;&amp;... xs){ (f(std::forward&lt;decltype(xs)&gt;(xs)), ...); }, std::forward&lt;Tuple&gt;(t) ); } 
&gt; use std::forward&lt;&gt; when you want to ensure that rvalue references get passed as were. Typically the same rvalue reference is consumed exactly once. Here, f is invoked several times, so it's not a once- That was my reasoning as well. I think that `f` can safely be *perfectly-forwarded-captured* into the lambda, but I don't see any benefit in doing that.
I'd split the foreach argument do something from the rest. We can replace `std::forward&lt;decltype(x)&gt;(x)` with `decltype(x)(x)` so long as `x` is an `auto&amp;&amp;`. auto foreach_do = [](auto&amp;&amp;f){ // or [&amp;f] return [f=decltype(f)(f)](auto&amp;&amp;... xs){ ( (void)( f(decltype(xs)(xs)) ), ... ); }; }; std::apply( foreach_do(f), std::forward&lt;Tuple&gt;(t) ); Also, we need to cast `f` to `void` before chaining `,` in case `f` returns a type that has overloaded `operator,`. In general, splitting `std::apply` from `foreach_do` is useful. template&lt;class F&gt; auto foreach_do(F&amp;&amp; f) { return [f=std::forward&lt;F&gt;(f)](auto&amp;&amp;... xs){ ( (void)( f(decltype(xs)(xs)) ), ... ); }; }; which now makes the `for_each` function pretty pointless. std::apply( foreach_do(f), some_tuple ); is short enough that having a function composing them is not worth it. And in the case where you have arguments already available: foreach-do(f)( a, b, c ); 
To clarify, that is the output of the executable file, including where input should be given (shown in grey highlighted area) the input is then convertrd to Pesos and spat out at the end of the program where it shows what the input entered again, then shows the conversion
Heh, if gcc won, it's only because Clang gave them a fight to win in the first place. Absent the fight, everybody loses.
Maybe I am missing something, but MSBuild already has built-in support for parallel builds. [Building Multiple Projects in Parallel with MSBuild](https://msdn.microsoft.com/en-us/library/bb651793.aspx)
That only works for projects that are not dependent on one another.
The comma operator. You can overload it so that `foo(), bar();` would do something other than just evaluate `foo()`, throw the result away and evaluate to `bar()`. There are very few reasonable cases for this IMHO (DSLs being one of them), but when writing generic code we want to let client code do whatever crazy stuff it wants!
Again, only for non-dependent projects. Otherwise is goes sequentially based on the project build order.
Guaranteeing build order is not the problem. As the article says, dependent projects will be serialized, which is what we're trying to avoid.
From what I'm getting from your posts, don't bother and just stick with c++14 for now.
Are you aware of any benchmarks?
The big problem with VS parallelization is that it does not seem to be global to the solution. That is, you can either parallelize per each project or run multiple projects in parallel, but trying to do both is not easily possible. This yields the same problems as recursive Make, which is discussed in detail [in this blog post](http://nibblestew.blogspot.com/2016/11/building-code-faster-and-why-recursive.html). tl/dr: when building with [Meson](https://github.com/mesonbuild/meson) + Ninja, the build system evaluates the entire build graph in one go and can keep all cores 100% loaded all the time.
2.95 was the first version of GCC I ever used. That was a long time ago... :-S
Nothing about concepts?
That was the implicit question: if compiled with the right /arch switch, does atomic support double-wide CAS?
Is the executors proposal agreed on the one that's here: https://github.com/executors/issaquah_2016 or has the github not been updated with the latest changes yet?
Oh I see! Thank you to all of you for the information. You've made it much clearer now :)
If they remove auto_ptr, then Boost.Python will break...so I'm hoping they will leave a deprecated version of it laying around somewhere, it's not like it hurts anyone :/ 
Functors should be taken either by value, or by forwarding reference, not by const reference. It's impossible to use `mutable` functors if you do: http://coliru.stacked-crooked.com/a/52ad4ad3e448405a I don't really understand the point, insofar as the statement "`for_each`can now be implemented in a single function without any weird tricks" isn't really true. It's still implemented as two functions (actually, 3 now), and you still have the same weird tricks, just pushed into `make_index_dispatcher`. In fact, personally I find `make_index_dispatcher` more confusing than the original code (by far). Really then, the argument would have to be made that `make_index_dispatcher` is actually very reusable and its existence is justified in that now you can not only implement `for_each`, but also a bunch of other things. This (as far as I can tell) seems to be taken for granted in the article; it suggests that you implement variations yourself. Well, what are my variations? If `for_each` is the first, obvious variadic thing to implement to operate on tuples, the second and third are higher order functions that map tuples to tuples, and tuples to arrays. But you can't implement `tuple_to_tuple` and `tuple_to_array` in terms of `make_index_dispatcher`, because `make_index_dispatcher` discards the return of calling the functor. The same is true about implementing a fold-like function on tuples. And so it goes. In other words, I don't think that `make_index_dispatcher` is really that generic. I have implemented all the primitives listed above. Each implementation is two, 3 line functions, and quite easy. Once you have those primitives, In my experience it's extremely rare that you ever need to reach for anything else. And it's not really worth trying to factor out some reusable bit of code, from 4 functions that total 6 lines each, and are very generic.
Hey Spongo! I didn't even see this comment but gave you a shout out as you deserve it :)
Not necessarily. It is an object with a pointer interface and an explicit clean-up operation (which happens to be operator delete by default).
Yes, I was unclear there.
Why so?
If you have a dependency between projects, why would you build them out of order? That's a risk to not build your projects properly.
As a reminder, the [feature tables](https://blogs.msdn.microsoft.com/vcblog/2016/10/11/c1417-features-and-stl-fixes-in-vs-15-preview-5/) in my Preview 5 VCBlog post also apply to RC (no compiler features added between Preview 5 and RC, several STL features added). Significantly, RC contains my `vector` overhaul for correctness and performance. I rewrote almost every member function. Billy also improved `basic_string` slightly as part of implementing `basic_string_view`.
I wish we have VS running on Linux in the near future!
It's still a release candidate, but the new installer is truly new, not just a coat of paint slapped over the old terrible stuff. It's really supposed to not suck this time. I'm not sure if they've perfected the "uninstall shouldn't leave stuff around" part for RC, though. (Note that the VCRedist is separate from the new installer.)
This conversion overloading make visual studio unable to compile this code: template&lt;typename T&gt; void foo(T* f) { f(); } int main() { foo(+[]{}); } That code compile fine under other compiler, but because of that "magic", it can't.
it's not VS, but do please try VS Code. :) 
building on what /u/STL said, we certainly are TRYING to fix the old installer issues. Please leave feedback if you feel like we haven't nailed it. There are a lot of people working on this, and we still have some time until RTW and there are updates to follow, of course, so I promise that feedback won't route to /dev/null.
Yes
VS is the most comprehensive and mature IDE I believe. The only downside is it doesn't support other platforms but Windows. VS on Mac is out there but not for Linux.
VS Code looks nice, but I prefer "IDE". To me, VS Code is a feature rich editor powered by many plugins but not an IDE.
&gt; VS on Mac is out there but not for Linux. It's [Xamarin Studio](https://www.xamarin.com/studio) rebranded and doesn't support C++ &amp;mdash; _not_ the Visual Studio we want.
Boost is riddled with `auto_ptr`. Compiling any Boost stuff with gcc-6.2 gives lots of warnings about it (as well as lots of broken placement new. But that's a whole other discussion). I would imagine this is just one of many examples as the driving reason not to remove it from libstdc++.
What was incorrect about the implementation of vector?
The Boost devs are working on it; here is an ongoing thread discussing it on the Boost ML: http://lists.boost.org/Archives/boost/2016/11/231400.php
 cool enough!   
I'll be shocked if there's not a forthcoming article on [VCBlog](https://blogs.msdn.microsoft.com/vcblog/)... ;-]
Almost everything, surprisingly. It was terrible about aliasing (e.g. `v.emplace_back(v[0])` crashed, `push_back()` was affected by a more subtle problem, etc.). It didn't provide the Standard's various EH guarantees. And it performed way too many element operations when inserting/emplacing in general. Also, it wasn't very good at invalidating iterators in debug mode. All of these problems have been purged, to the point where the Standard's wording defects are the worst remaining problem (i.e. it mandates overly-strong EH guarantees that my implementation bends over backwards to fulfill).
Oh God, I just installed Preview 5 yesterday :)
okay iam going to add code in description as well
Not using Turbo C++ would be a far more important thing. (Why isn't that 20+ years obsolete compiler left to rest in peace?!?)
then what is that important thing ?
Use a modern compiler that supports C++ standards and current operating systems, not a DOS based one from the early 90s.
Win98 all over again...
I'd really like to use VS code, but for reasons passing understanding, it just sometimes doesn't like C++ code ;D https://github.com/Microsoft/vscode/issues/11597
impressive
... ASIO is an event-loop library, with `io_service`.
I quite like VS code, give it a try and you won't regret it!
Try ruby then!
My independent implementation matches libc++'s numbers of performed operations, except in one scenario where VS is correct and libc++ is wrong (reported and acknowledged; they have a bogus aliasing check that tries to skip operations, which cannot be done with full correctness).
yes. :)
MSVC Dev Manager saying &gt; /dev/null VS 2019 for Linux confirmed!
OMG https://github.com/vyasgiridhar/Feed-Parser/blob/master/Feedparser/feed.h#L16
This whole subthread begs the question &amp;mdash; what's wrong with the name?
... and I would have gotten away with it if it weren't for those pesky .... 
Oh no, why have you kept the year number? Now the possibilities to refer to the VC++ version are really confusing: 2017 (some will say '17) 15 14.10 19.10 Both uninstalling Preview 5 and installing the RC were extremely fast even on my Surface 3 and even though it required 13 GB on my desktop computer, only took a few minutes.
Yeah can confirm I only needed to reboot at the end. Was able to build and run some small test apps without the reboot too!
sweet
This video goes through some of the benefits https://channel9.msdn.com/Events/Connect/2016/129 To summarize: * Solution Explorer shows the real disk layout of your sources * live-update of IntelliSense and debug targets as you make changes to CMakeLists.txt and your sources without having to "build"/reload * create as many CMake configurations/caches as you need and switch between them from inside the IDE * avoid all of the MSBuild-based project system artifacts in the UI that get in the way sometimes (e.g. project properties, project references, Configuration Manager, etc.) * potential to support (in the near future) for other generators than the VS ones * appropriate source-control integration inside the IDE (edited for formatting)
I just want to be sure that the current std library gets renamed to `std1` so that we can alias it to `std` because then we can choose which version of the library we'll be using.
Alright, I'll make sure to test it in a VM soon.
I believe that the maintainer of Asio plans to keep it in line with the Networking TS. See the [release notes](http://think-async.com/Asio/asio-1.11.0/doc/asio/history.html) for the latest development version (1.11)
Not being able to compile a code that the standard says it should is not a tradeoff, It's a bug.
I will profile it against my runtime library tonight. Does 2017RC have a go-live license?
I have used asio largely. You can use it in combination with coroutines. FWIW, in my opinion, it is a well-designed library: 1. you can tell where to allocate handlers. 2. you can use it with futures/coroutines/callbacks. 3. you have tcp/udp 4. the event loop is nice. Another story is that you want a higher-level API. But you can build on top of this easily and I think it has the right primitives. Now they are adding executors, which, IMHO, was the missing part. I think it is the right design for a general-purpose event-loop and networking library. I am using it myself, now, at work, together with beast http + websockets and it is working great. 
:D Time to install it. I'll let you know the results, though my stuff operates differently than `std::vector`, they're similar in use. Will VC2017RC run properly side-by-side with VC2015? 
It's supposed to, according to the FAQ.
It is in the release notes. They provide this option with two caveats: - currently the offline installation requires internet connection to check certificates but they will fix it - installing Android SDK requires internet, but this is a problem only Google can fix :D
I am still unhappy with how budling of features work. VS installer just **loves** putting SQLServer LocalDB on my machine. I don't want it. Really. Truly. This time the culprit is .Net core. So, how do I install VS 2017? - I click on the workload - make screen shots of all the selected components - deselect the workload - check all the features which the screen shots indicate must be selected **except** LocalDB or Azure or whatever you want to push at me I actually like new experience for the installer, because with the previous ones this was not possible. But it is annoying, and I hope you will make the experience even more flexible, supporting scenarios like "creating command-line utilities with .net core" or "creating Electron-based desktop apps with TypeScript" - these are actual projects I am working on at the moment. 
1) Here's an example whose behavior varies: #include &lt;stdio.h&gt; void f(int) { puts("Standard two-phase!"); } template &lt;typename T&gt; void g(T t) { f(t); } void f(double) { puts("Microsoft one-phase!"); } int main() { g(3.14); } 2) Declare everything before you try to call it. The example above cares about two-phase lookup because it tries to call `f(t)` before declaring `f(double)`. 3) All I know is that two-phase lookup has never given me trouble in the STL (where we declare everything before we try to call it). I rarely use Boost at work (only for bug repros, performance comparisons, etc. - actual development would be a circularity paradox). Two-phase lookup is legitimately important in some cases, but overall it's pretty ignorable. Unlike Expression SFINAE which is much more useful to advanced template metaprogrammers. 
I would like to leave feedback that neither Preview 5 nor this RC would install successfully on any of my computers. I may have disabled one too many services? Errors vary between machines; I googled the error from Preview 5 but no one else seemed to have run into it. With the RC installer, it starts right off the bat asking to be run with Administrator rights; when I do, it makes the *same* request again. Then after a lot of churning installing the C++ stuff, it gives a long error (I haven't saved it, will try again later).
[removed]
did you choose the report a problem link in the installer? that will batch up the log files and submit them to our setup experts and we are vigorously investigating setup failures.
i think the reboot is required if you have previously installed the Dev14 redist somewhere on the box.
I've always installed vcredist before VS itself &amp;mdash; and here I thought I was just being dogmatic... ;-]
A static cast to the function pointer type wouldn't have this problem. ;-] It's really a shortcut to force _implicit decay_ to _a_ function pointer type.
I heard some people had some good results generating a Visual Studio solution that would later call Ninja to build. But there isn't anything like that available in CMake, it was all custom. In my tests, building with msbuild with /MP and /M flags work ok on dev machines since they don't have too many cores and it doesn't overprovision too much. But on my beefy CI machines with 32 cores, we switched to Ninja to get much faster compilation speed (otherwise, you end up with potentially 32^2 compilation processes). There's no good solution, and the msbuild issue to get a global resource manager hasn't changed for a while :(
Unless you have generated files in your projects, like headers that are shared. This works as a custom solution but it won't always be correct in all cases. Use with caution!
With a static cast you must specify the type, including the calling convention, so there is no ambiguity; OTOH an unguided decay is ambiguous and causes an error (hence the subthread we're posting in ;-).
I'm more just trying to figure out how to get it do more than one file at a time *at all*. I can't seem to get it to do file parallelism of any kind, CMake or not. I feel I must be missing some obvious thing.
What's the characters at the end? I can see the stars, but these ones are only empty rectangles?
I'm interested in hearing about the EH problems. Was the `vector` ending up in UB territory if a move operator threw?
A TS is not the standard. We could throw a TS into the trash and start over. Prefer not to, but could. We have definitely made changes between a TS and what eventually went into the standard.
Primarily we were providing the basic guarantee when it should have been strong. For example, insert-one-at-end (including push_back) is supposed to provide the strong guarantee (except when a movable-only type has a throwing move constructor). That's supposed to be implemented through `move_if_noexcept()` and careful action sequencing. We were unconditionally moving.
In other words, Clang is a superior compiler to Borland C++. Who would have thought? A serious discussion on the "advantages of the Clang compilers" would compare it to gcc and msvc, not an outdated compiler from the MS-DOS days.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5dh7sm/please_help_this_is_a_couple_practice_test/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I was waiting to see if someone posted this but it looks like no one jumped on it. This is a really important feature for our compiler--it introduces an opt-in conformance mode that can contain breaking changes. It's incomplete now--e.g., no two-phase yet--but will eventually be made the default mode. It's both a blessing and a curse to have a huge base of developers stretching back decades. Having an opt-in conformance mode--kind of the opposite of GCC's /permissive switch--allows us to make those breaking changes without breaking developers. We really, really need /r/cpp's feedback on this one!
I'm going to have you pick stocks for me.
This post has instructions for the build tools installs, including --quiet and --passive options for installing without user input. Edit: This is the post: https://blogs.msdn.microsoft.com/vcblog/2016/11/16/introducing-the-visual-studio-build-tools/
Have an example of a bad/explicit call to a terminate in a lib? (Not on oom, surely nobody does that? :-))
Why a separate `/permissive-` and `/std`? I would guess most people who use `/std` will also use `/permissive-`, and it would make for one less switch to explain. &gt; For example, the standard library headers compile correctly both with /permissive- and without I can't test it right now, but do all the Windows and MFC headers also compile correctly? &gt; There are currently a few places where the IntelliSense in the IDE will conform better to the C++ standard than the Visual C++ compiler :)
This is the first release I've been happy to dogfood without putting it in a VM first.
This sounds really nice. My code has to port to a lot of platforms and "Use of qualified names in member declarations" is one that gets me way more often than you would think it should. All compilers are non-conforming to one degree or another -- what is the rationalization for which "features" are affected by this switch and those that are not? I assume binary compatibility is guaranteed between permissive and permissive- libraries? EDIT: I'm also surprised "Error when binding a non-const reference to a temporary" has not been addressed yet since that is a potential source for runtime bugs.
Haven't read the whole thing yet, but I don't quite get the naming? If it's the opposite of GCC's `permissive` i.e. it's an opt-int for conformance, rather than opt-out of it, why choose the same name? UPD: Just notice that it has a little `-` at the end. Is it supposed to signify "not" or minus? Like it's the opposite of permissive? Not confusing at all, yup. I really hope you'll get this naming thing sorted out soon.
Any plans on integrating the new CMake server mode?
&gt; I really hope you'll get this naming thing sorted out soon. It's pretty common. gcc has `-Wno-` to disable warnings, so you end up with things like `-Wno-no-return-local-addr`. As for `/permissive-`, it seems to be based on [gcc's `-fpermissive`](https://gcc.gnu.org/onlinedocs/gcc-4.5.4/gcc/C_002b_002b-Dialect-Options.html).
But that's exactly the problem: GCC: `-fpermissive will allow some nonconforming code to compile` It **permits** nonconforming code. MSVC: /permissive^- - try to be as conforming to standard as possible. Ok... This surely won't confuse anybody.
I agree. Cool to see this posted here, but honestly I doubt you (or this whole subreddit) is the target audience :) A lot of our customers still use the old, "classic" compiler, which we still ship for the simple reason that people use it, and this is a talk for them, to encourage them to switch to the newer generation of compilers. A talk meant for here would compare performance and features as you say, but also talk about our compiler extensions for properties, object-method pointers, COM or interfaces, or ARC - stuff that might make you interested in our compilers. 
Our intention is to have `/permissive-` be the default, but still have a `/permissive` switch--pretty much the same as GCC. We'll get there, but if we did that right now we'd break a ton of existing code and Satya's phone would ring off the hook with angry developers. Seriously. We recognize that it's a little odd to have only the negative form of the switch, but it's a first step. Developers who want a more conforming mode--pretty soon a completely conforming mode--can opt-in until that date when we can take a breaking change and flip the default. Like I said, having customers is a blessing and a curse :)
See the above: One day we want `/permissive-` to be the default. Devs will need to type `/permissive` to get the non-conforming behavior. If we started with `/strict` things would be easier today, but not in the long run. We're trying to plan for the future. 
Why separate `/permissive-` and `/std:c++NN`? Because they're different functionalities. You can adopt C++ latest features but still want to rely on the old, nonconforming MSVC behavior. Also, we intend to one day switch the default for `/permissive-`. See my other comments for more rational. All the headers that the VC++ team ships should compile cleanly with `/permissive-`. I haven't tried them all myself, but if you find any that don't I welcome you to type angry words in the general direction of /u/spongo2. (Heck, you're welcome to type angry words his way even if you don't find bugs in the headers. He thrives on developer feedback, even unwarranted abusive feedback!) The IntelliSense thing is an unfortunate but temporary condition. When we're done implementing language conformance (Real Soon Now^(TM)) it'll all be good. In the interim, we could have asked EDG to implement bug-for-bug compatibility with MSVC. But that's ridiculous. As is, it shouldn't practically be an issue. If you do see red squiggles where you shouldn't, White-Out on the screen does wonders. 
Thanks, /u/mcmcc. The reasoning behind each feature is whether the fix to the nonconforming behavior would break existing code. The general rule is that if you throw `/permissive-`, you're opting in to having your code break because MSVC is now more conforming. The fixes should generally work either way, but you're still opting into breaks. ~~Also, if something has a warning, it may not be necessary in `/permissive-`. Just turn on the warning.~~ We'll get to all the features soon. We hope to be done with this switch soon. 
I understand the default (and do care about Satya's phone). Is `/permissive` currently implemented as a no-op or does it give a D9002 for an unknown option? If it's the latter, it might be worth adding it just for symmetry.
Didn't knowingly use one. This was the link Disqus gave me to the comment. 
Unfortunately, that's out of his control. But feel free to blame him anyway! The VS Year thing works out ok except when they're both the same number. VS 2015 and VS "15" was rough. We should be past that though.
Yes, most switches have an `/opt` and `/opt-`. 
Thanks, /u/Harha. We're trying to make life easier for folks, including cross-platform devs. 
It's been confusing [for much longer than that](https://en.wikipedia.org/wiki/Visual_studio#History) (08/9, 10/10, 12/11, 13/12, 15/14, 17/15), and will continue for the next few releases. We're also approaching a confusing period for `cl`, which only got bumped to 19.10 for 2017.
Oh, I like that suggestion! Should have talked to you a month ago : ) Edit: But note many of our switches have a positive and negative form. 
The equivalent is now at `%WhereverYourVSIs%\Common7\Tools\VsDevCmd.bat`. For example `C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\Common7\Tools\VsDevCmd.bat`.
It's unimplemented right now. But soon enough we'll have `/permissive`. 
Thanks! In the past, I would pass x64 to vcvarsall.bat to set the architecture target. How is this done now, because it doesn't seem to work the same way?
Conformance with existing standards is a higher priority. But we have a number of C++17 features implemented already, as well as some TSes that are working their way through the committee now. 
Yes, fully sympathetic to C++14 first, just curious about the C++17 pipeline.
Windows 11 is Ubuntu confirmed 
the generators haven't changed, but when you load a CMake project with VS2017, the IDE will create 2 CMake configurations by default (one x86 and one x64) that you can switch between and get differentiated IntelliSense, build and debug experiences for each. check out https://aka.ms/cmake#configure-cmake
At least your problem seems to have a path to completion in the near future. :D
I'd still very much rather an official single ISO file with an associated MD5/SHA. btw I just tried the process and it crashes right at the start and keeps a zombie process spinning doing nothing no disk or n/w io - so it's not a problem free solution either.
Oh yes, we're definitely still hiring. If you're interviewing at Amazon, you are still eligible to apply at A9 and must do so separately if you want to be considered. The link in the post above is very specific; if you follow it, you're basically applying to work in my team on the challenges that I outlined above (and more!).
Maybe you're the wrong person to ask, but I'm curious about one thing: why is further in-house development of VC strategically important to MS now that there's clang? From an outsider's POV it would be more rational for MS to fully adopt clang and contribute to, while maintaining MSVC at status-quo for old(er) projects unwilling to migrate.
I appreciate the effort with VSCode, but I've tried it for Qt-development and never managed to make autocompletion/intellisense to work. I did set up include search folders in the json file as described in the manual, but to no effect. I wasn't able to make it work in 10 minutes, so I just gave up and reverted to Netbeans (using it on Linux). EDIT: it's also not clear from the docs whether specifying, say, "/usr/include/Qt" will make it search recursively there.
I don't know if RC will upgrade to RTM cleanly. It should, because the new installer is supposed to not suck. Yes, 2017 RC will coexist with 2015. Just don't be running 2015 while you're installing the thing. 2015 (RTM + all Updates) is binary-compatible with 2017 (RC, RTM, all future Updates). This is the first major release where we're doing this. You should still build everything consistently with 2017 to get all of our bugfixes, but mixing these versions will work. There are many different notions of "debug", almost all orthogonal. /MD versus /MDd and /MT versus /MTd controls the debugness of the CRT/STL. There's also debug info (/Zi or not), optimizations (/O2 or /Od), assert behavior (NDEBUG or not), etc. The thing you totally can't mix is debugness of the CRT/STL. You can compile with the release CRT/STL, but with debug info, no optimizations, and asserts enabled. You just won't get the CRT/STL's debug checks.
thanks for the feedback... I've pushed it to the team. We know we still have work to make autocomplete better. I hope you'll continue to try out builds as we continue to iterate.
Pretty sad that there isn't embedded support in the STL already.
Out Of Memory
What's the advantage of a vector of fixed size? What usages does it cover that aren't covered already by ```std::array&lt;T,size_t&gt;```?
Looks like it's a fixed max size (with an inline _untyped_ allocation), where `std::array&lt;T,size_t&gt;` is a fixed size. But wouldn't it be better to have an inline allocator type which was compatible with the regular std::vector instead?
The majority of the STL takes allocator objects when it needs to perform allocations, and so you can use "pool" or "inline" allocators if you are running on a heap-less platform. It's a pity there aren't standard definitions of those, though.
The OP summed it up better than I would have. Although having a pool by default would be nice.
&gt; Custom allocators don't _solve_ the problems of dynamic allocation, they just eliminate the heap from the equation. The same can be said for 'allocating everything up front'. I've often seen the case where someone allocates an array up front and then uses it as a dynamic sized pool; reusing elements as necessary. This is typically the big misunderstanding about avoiding dynamic memory because it doesn't mean just avoid the heap, it means avoid reusing memory for anything and as soon as you allocate an array up front, but then use it as a pool, you are using dynamic memory. All of these libraries that try to solve that completely miss the point, in my opinion. 
Is there any? I'm really interested, always used MSVC on Windows.
The switch is great, but unfortunately ATL's atlwin.h not supporting it is a blocker for me :-( Being able to programmatically push/pop this option would be very helpful.
&gt;This is typically the big misunderstanding about avoiding dynamic memory because it doesn't mean just avoid the heap, it means avoid reusing memory for anything I don't think you are exactly correct here. My understanding of why to avoid dynamic memory allocation is these 3 main issues: 1. Allocating memory using `malloc` (or a derivative such as `operator new`, which is always, as far as I know, implemented using malloc) requires a system call, which can be expensive (context switching, etc) 2. `malloc` must be optimized for a huge variety of use cases. It must be able to combine smaller blocks into a bigger one, allocate tiny blocks and huge blocks, worry about alignment, etc. A user program has a much smaller set of use cases, so it can optimize for those. (If you are interested, check out the Linux implementation of `malloc`, it's complicated but very cool) 3. `malloc` and friends will have poor memory locality, since they can give you memory from anywhere on the heap, while a pool will give you memory that is much less dispersed. I'm not really sure why you oppose these kinds of solutions (or what an alternative would be)
It's still dynamic in that memory is reused within the system for different objects at different times. 
If I have a thing I know there will be at most 16 of, but sometimes I only have 3, a fixed-max vector is really nice because it lets me do all the things I'd normally do with a vector (ranged iteration, insert, pop, etc). An array doesn't let me do that unless I also have a count of elements to go with it. And then I'm doing everything manually and I lose some of the easy benefit of STL containers. I also get cache locality -- there's no pointer dereference to go from the vector to the first element of the vector.
First off, you have to know that 80% of our codebase targets Linux HPC, with the remaining 20% being an OpenGL C++ desktop app that must look and work identically on Linux and Windows. We started our codebase in 2014 in C++11. Originally, we evaluated MSVS and the Intel compiler on Windows. Both of them suffered ICEs and crashed on code that `gcc` and `clang` both compiled 100% fine. The last time we re-evaluated MSVS was this spring, and my guy still couldn't get it compiling our code without significant structural changes. Mind you, our code isn't weird. There's no magic or compiler abuse. We just have never paid attention to avoiding MSVS's warts. When clang and gcc compiled our code without warning, but MSVS and ICC started crashing on the same code, I simply de-certified both compilers for our project. So given that clang-on-windows wasn't ready yet, MinGW was actually our *only* option for a functional compiler on Windows. Right now, we use MinGW instead of the MS compiler because: * `MinGW` accepts the same code as `gcc`. As a result, we've only got about 2 or 3 instances of OS-dependent conditional compilation across our entire codebase. The new `permissive-` mode this thread is about might change that. When it's ready and available, we'll probably re-evaluate MSVS. * we cross compile the Windows build from Linux. This is obviously quite convenient for automated builds, but it also means we can write our various build-time and codegen tools for only one operating system. * MSVC compiled code can be binary-incompatible based on different compile flags. Given the nature of our code, it often behaves very differently without optimization. So we tend to compile everything except the module-of-interest with optimization, and leave debugging symbols only in *part* of the code. &gt; always used MSVC on Windows. Honestly, I kind of expect you to dismiss everything I've said. Most people who've primarily programmed in a Microsoft environment think it's somewhere between "pretty good" and "awesome". It's [Stockholm syndrome](https://en.wikipedia.org/wiki/Stockholm_syndrome). I've programmed for probably half a dozen systems, and the only one I consider less developer friendly than the Windows C++ ecosystem was BREW. (Now, if we're talking about .NET, I'm happy to concede that it is quite developer friendly. But this is /r/cpp.)
Wow, an error in the first statement: "C++, like Java and many other programming languages, does not come with a built-in graphical front end." Actually, Java has always provided a GUI front end. It was always godawful, but there since day one.
The stl works fine on small embedded chips (arduino, etc). 
The point is that if you do all your allocations up front you'll know that they will always pass. You have to limit the number and sizes of buffers, but you'll never get halfway through running and go to allocate a buffer that you SHOULD have room for and have it fail. Avoiding dynamic allocation also helps avoid memory leaks; yes, you can still leak your statically allocated buffers and such but it's less likely and easier to diagnose where the leak is. Failing 2 years into runtime is much worse on most embedded system than failing on setup/initial boot.
The standards committee has created a monster.
Actually it is. The alternative is that you can fit all of your state in memory at all times. 
The topic seems interesting, but unfortunately the slides are almost meaningless without the talk itself.
Oh wow indeed; they "fixed" it, now it states: &gt; C++, like *Python* and many other programming languages,* does not come with a built-in graphical front end I suppose they haven't heard of Tkinter...
Now let's wait for someone to make a compile-time C++ compiler...
You did ask a question which requires a picky answere. But I don't believe he's being picky. Being picky would be saying that `int` is wrong because you could use `unsigned int` (Some compilers warn for this actually) But using `std::size_t` is actually faster the `int` ;p On the topic of what is better for each, for (ranged based) or for: I believe it does not matter apart from readability and code style since compilers will probably optimize any difference at all if there is any. (Take everything I say with a grain of salt because I am nowhere near )
There are a number of reasons we have to maintain MSVC. One motivation in particular is that we'd like to be able to enable older codebases to move forward at the pace that they can. This requires that we have both new feature work and old MSVC-isms in the same compiler. Now that we are months away from being conforming it's not as much of a big deal anymore. 
&gt; let me know how it works for you Sure thing!
Some would argue to not use `auto&amp;&amp;` when `auto&amp;` or `const auto&amp;` works just as well. I'd say the OP's example would be fine with a `const`.
`const auto&amp;` is great when you explicitly want a non mutable reference. However, there is no reason why you would want `auto&amp;` . Iterators has no guaranties that it will return a reference. If you refactor some code and something changes what iterator you used and happens to return an rvalue, you just broke all of your for loops. For the love of your code use `auto&amp;&amp;` when you want it to "just work".
The author should give up on trying to drag other languages into this. 
I like how elc.hpp is so large that GitHub can't display it. Metaprogramming in C++ is whack.
A couple years ago when varidic templates were first implemented by GCC, I implemented an arbitrary precision arithmetic library close to GMP. I was able to calculate arbitrarily precise value of pi, cos and other cool stuff like that. It took a day maybe two for me to implement what is akin to constexpr mpz_t and constexpr mpf_t with very basic functionality. After that day I realized what kind of a monster I created, annihilated it immediately and never looked back. But creating a whole C compiler... this was only a matter time, I knew. We can merely wait until a constexpr AI starts ruling our lives, and worse, our code and maybe even more...
 auto result = eval("/* some code */");
make_shared gains come not really from the cost of an allocation, but because each subsequent dereferencing reduces the chance of multiple cache misses since both the control block and the managed memory are on adjacent cache lines. 
Just seen today at meetingcpp the constexpr if and constexpr for.. What a monster
I would use std::cout &lt;&lt; s &lt;&lt; std::endl; (Yes, I know, this is not included in your choices. If I had to, I would use #2 then) Edit: Oops, as others pointed out, that code does something completely different :)
That doesn't even have the same behavior.
&gt;many embedded and mission critical systems avoid allocations for reliability and that means any dynamic usage, which is what I was talking about. Can you go into more detail about why *any* dynamic usage is going to fundamentally hurt reliability? Use of the heap can lead to memory fragmentation, which leads to huge reliability problems such as "have enough memory, but not enough contiguous memory". However, small pool based dynamic allocations can, with care, avoid this kind of problem. You can also avoid this kind of problem with uniform sized allocations (you avoid fragmentation this way) and not using too much memory. Keeping heap allocations short (as a function of stack size) also reduces this issue. Or is your argument basically that it is always preferable to not dynamically allocate in order to avoid ever having to deal with these kinds of issues?
The _best_ code wouldn't flush the stream after every newline... &gt;_&gt;
haha, you got me :) I was focusing of the loop itself, I thought that was OP's intention too.
&gt; In standard C++ STL when a data structure reaches an allocation limit it will throw a std::bad_alloc. Technically, it isn't the data structure that throws, it's the allocator you specify to that container. In this scenario you're _already_ using a custom allocator, so ...
If the C program contains undefined behaviour, can the C++ program launch missiles?
For anyone else wondering, this seems to have done the trick! Thanks!
And get it to compile itself.
Don't forget to pass `-host_arch=amd64` if you want to use the native toolset (which you probably do). It unconditionally defaults to x86, which I find a bit silly.
Checkmate, Turing.
That's just because of the method used to generate it. They wrote a backend for ELVM to generate constexpr and fed 8cc to it. If you look at the code it's just the memory setup then a switch loop over instructions.
&gt; The size and time of the allocation will only be known at runtime. &gt; depending on what code runs the allocation could be of theoretically any size, and it could be made at any time. I don't understand what your saying. If that's true then none of your container work since they all specify their size as a compile time constant. What I think your trying to say is that your containers have a fixed max size and allocate *all* of the memory upon initial construction. Hense when elements are added at runtime they never cause another "allocation". Is that what you mean by "more deterministic allocation behavior"? If so you can easily achieve this with custom allocators in the STL. In fact your `pool` implementation is so close to being such a custom allocator. With a few tweaks you could easily write `std::list&lt;T, etl::pool&lt;T, 42&gt;&gt;` and have it act exactly like `etl::list`. 
Now what we need is a way to get user input at compile time. Yes, I would like to play a game of chess with the AI while my program is compiling, thank you.
If the shared object is small enough. 64B/line is typical; with two 8-byte reference counts (strong/weak), that leaves 48B for the object itself.
Um isn't `etl::vector::full()` just the same as `std::vector&lt;T&gt;::max_size() == std::vector::capacity()`? 
&gt; make_shared_from_this() NO, the article recommends (quite correctly) that this is almost never a good choice!
&gt; you can simply use raw pointers to these bodies. Never ever use raw pointers. If it's a non-nullable pointer, for gosh's sakes, use a reference...
&gt;If it's a non-nullable pointer, for gosh's sakes, use a reference... You cannot store references in a vector. I think that there are situations, such as this one, where it is appropriate to use non-owning raw pointers.
When you disable exceptions the compiler simply inserts an abort anywhere an exception would occur. There's now no way to handle critical runtime errors except to restart the whole MCU, which is less than ideal. Ideally an embedded-focused standard library would use return values for errors (C-style error handling) or allow you to choose between exceptions and return values.
I couldn't believe that at first, but TIL about `reference_wrapper`. #include &lt;functional&gt; #include &lt;iostream&gt; #include &lt;vector&gt; using namespace std; static int a = 0; static int b = 1; int main() { vector&lt;reference_wrapper&lt;int&gt;&gt; woot; woot.push_back(a); a = 5; cout &lt;&lt; woot[0] &lt;&lt; endl; return 0; }
Can you link to me documentation about that? I can't find any.
Yes, they definitely go together. But also, you can't mix object files, static libraries, and (in general) DLLs with different debugness of the CRT/STL. (The only thing that works is mixing DLLs when their interfaces are binary-stable - e.g. pure C or COM.)
Hunh, TIL about reference_wrapper too.
Run `VsDevCmd.bat -?`.
Because after compiling `fileout &lt;&lt; gcc.exe` you get a compiler. You then have to run your program through that. With this, you compile and you get your C program embedded in the binary as well!
Great article :) Just one note about shared_ptr's atomic nature (and if I'm wrong, I'd love if someone could explain why!). I've seen almost all sources make the same claim you do: &gt; Thread safety includes assigment, reference increment / decrement and all other operations But... I've also seen segfaults due to shared_ptr assignments. [Here's a proof of concept](http://melpon.org/wandbox/permlink/oAXbYnkKE5BR7Wig) . read_g does the not-guaranteed-thread-safe operation of reading the shared_ptr, but only after making a supposed-to-be-thread-safe copy. So, while `shared_ptr`s are modified simultaneously across threads (which is claimed to be thread-safe), the data it points to is only accessed from one thread at a time. Interestingly, I ran more tests and don't get a segfault on clang 3.8.0 with `-O3` (`-O0` does give the crash). GCC gives a crash on all optimization levels. In any case, it's my understanding that copying a `shared_ptr` isn't really guaranteed to be atomic for *all* operations (as almost every suggests), which is why you have [`std::atomic_...&lt;std::shared_ptr&gt;`](http://en.cppreference.com/w/cpp/memory/shared_ptr/atomic)
"If multiple threads of execution access *the same shared_ptr* without synchronization and any of those accesses uses a non-const member function of shared_ptr then a data race will occur..."[0](http://en.cppreference.com/w/cpp/memory/shared_ptr)
&gt; std::vector&lt;T&gt;::max_size() will return the number of elements that can theoretically be stored in the vector. If the specified allocator provides a `max_size()` method then the containers should report that. If they don't then you should file a bug against them (And there are bugs to be filed here).. Even then you should be able to use `c.get_allocator().max_size()`. &gt; Theoretically you can set the capacity with std::vector::reserve() and std::vector::shrink_to_fit(), but in practice it's up to implementations whether they respect requests to resize a vector's underlying storage. `capacity()` and `reserve(n)` are very well behaved (`shrink_to_fit` not so much). From the C++1z standard: &gt; [vector.capacity]p3 &gt; 3 -- After reserve(), capacity() is greater or equal to the argument of reserve if &gt; reallocation happens; and equal to the previous value of capacity() otherwise. Reallocation happens &gt; at this point if and only if the current capacity is less than the argument of reserve(). &gt; 5 -- Throws: length_error if n &gt; max_size(). &gt; 6 -- Remarks: Reallocation invalidates all the references, pointers, and iterators referring to the elements in the sequence. No reallocation shall take place during insertions that happen after a call to reserve() until the time when an insertion would make the size of the vector greater than the value of capacity(). The standard technically allows the implementation to reserve more than requested, but no implementation does this AFAIK. `shrink_to_fit()` is documented as being non-binding, 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [Compile-time C Compiler implemented as C++14 constant expressions](https://np.reddit.com/r/programming/comments/5dqus6/compiletime_c_compiler_implemented_as_c14/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
You could have the generated output be a C++ file with the board state, then you set some move variable and each compilation with the generated output file would be a turn.
yo dawg
`&lt;&lt;` respects padding though. I doubt that it will ever be as fast as `put`. Also, for apples to apples, the C version to compare for `put` should use `putchar`? 
but, why?
No, but watch out for nasal demons
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to /r/cpp. 
"And for my next trick, I will create a compile-time C++14 compiler in C macros!"
Not sure if religious nutjob or agnostic moron.
This is a simple C compiler translated into a very simple VM code which is executed in compile time as a `constexpr`. 
&gt; That is not dead which can eternal lie, yet with stranger aeons, even Death may die. FTFY.
There's a version included in Visual Studio 2017. That should support it :)
Turing never claimed that a Turing Machine can't compile another Turing Machine. If anything else, I don't think they compiled programs back then. Are you by any chance confused by other [undecidable problems](https://en.wikipedia.org/wiki/List_of_undecidable_problems), such as the [halting problem](https://en.wikipedia.org/wiki/Halting_problem)? Turing machines running other turing machines is a common pattern in computational science.
It's in C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin But you can find it by just searching for cmake in the VS root folder. cmake --version reports 3.6 for it. It reports VS2017 generator support, although it's not sure whether it's 2017 or 2016 :) &gt; The following generators are available on this platform: &gt; Visual Studio 15 2017 [arch] = Generates Visual Studio 2016 project files. 
I can't even, but I'm sure the compiler can.
&gt; STL has serious deficiencies when operating without exceptions/RTTI. This depends on the implementation, but in practice is just false. Many companies are using the standard C++ library with exceptions and rtti disabled in the complier. My company is one of them, so is Google, from what I understand. Edit: I read below that you were concerned about the abort call when hitting something that would normally throw. That's valid and indeed isn't handled. But, I can't think of an interface in the standard library where this condition isn't avoidable. For example, vector::at throws on out of bounds, but this is detectable ahead of time. Can you provide an example where the throw is unavoidable? 
That's a universal Turing machine, not just any old Turning machine.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5dstqi/need_help_in_this_c_projict/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Right, I can't use the one included, because I need to FindVulkan module that's in CMake 3.7. I guess I'll need to wait for Visual Studio to support the official server API. Though I'm having problems while trying to compile wxWidgets and specifying `TARGET_CPU=X64`, but it still building 32-bit files, though in a 64-bit output folder. Any ideas for that?
D CTFE is not an extension of C++ constexpr, it has existed for way more time than constexpr but I get your point. Sorry, I originally misread your comment, can't even recall what exactly I thought but it rubbed me the wrong way, I thought you were somehow implying C++ had no ability to do similar things without this project :P I also read that post yesterday, I'm excited about it, every time I write D I end up doing lots of compile time evaluation so it should be a great improvement!
Or he's read Lovecraft... Is agnostic moron better or worse than ignorant moron?
I was referring to those "predict the program output" halting problem counterexamples, where you run the program against itself. (Turing proved the halting problem impossible.)
[What is the C++ iostream endl fiasco?](http://stackoverflow.com/q/5492380)
Great article, you should also mention one disadvantage of `make_shared` that is: when you release all `shared_prt`s, but have at least one `weak_ptr` alive, the managed object `T` will be destroyed (by its destructor), but the memory it occupied cannot be deallocated, because we need to manage the weak count and the weak count was allocated together with `T`. So, when using `weak_ptr` with large objects, consider avoid using `make_shared`.
Working through one book, you're likely to miss out on a lot of basic tips, etc. It may be worth your while to skim through a couple of free beginners courses, alongside the book. Breadth of knowledge makes further learning easier, aswell as boosting the likelihood of those ah ah (insight) moments happening more frequently.
Have you considered presenting this to SG14 (the games, real-time, low-latency, and embedded study group) ? There are containers or concepts here that may be useful to standardize or to use as inspiration/education for other standardization efforts. https://groups.google.com/a/isocpp.org/forum/#!forum/sg14
Range-for loop is least powerful, if you use `const char&amp; c : s` or `char c : s`, using just a reference if you aren't modifying should be a big no-no.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5dtre4/i_need_help_with_this/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's always "predict the arbitrary program output" - predicting the output of a specific program is (relatively speaking) trivial.
&gt; what you mean by accumulator Look at `for_each`'s return value.
People have been abusing compilers for a long time. For example, "Is the C99 preprocessor Turing complete?" http://www.ioccc.org/2001/herrmann1.hint 
The most common example on a microcontroller with bytes/kilobytes of heap memory would be a `std::bad_alloc` when there's not enough free contiguous memory left. Another example would be the exceptions thrown by `std::stoi` and friends on conversion failure. In general the data structures in the STL usually provide escape hatches for avoiding exceptions, but not all part of the STL are so generous.
Beginner questions are off-topic for this subreddit, please read the sidebar, and learn how to format code examples.
bad_alloc doesn't come from STL though, it comes from your memory allocator and I assume you're replacing that and just terminating on OOM. Of course, this means you don't have an opportunity to abort the operation when OOM occurs, but that's rarely a recoverable situation anyway, in my opinion. As for stoi, I'm really surprised those throw an exception on failure, but oh well.
Interestingly, GCC made `f2` and `f4` just aliases to `f5`. Update: but it did not merge `f3` and `f5` despite them being identical.
Why not simply had get_if overloads deleted for rvalue? It would have solved the problem.
[removed]
Nothing worse than an ignoramus who cannot read subtext.
Right, I tend to forget about that. The lambda isn't doing anything you couldn't do without local variables though, and in fact it's pretty hard to use a lambda as an accumulator without capturing some local variable by reference. Still think for_each is the least powerful.
&gt; A const lvalue-reference would allow temporaries, and returning a pointer into a temporary isn't exactly sensible ;-] But you can already do that with the regular `std::get` eta: and it's perfectly sensible as long as you don't use the pointer after the temporary has been destroyed
&gt; What's the difference between `get_if(&amp;rvalue)` not compiling or `get_if(rvalue)` not compiling? `&amp;rvalue` is illegal. As to the rest, I'm only speculating to begin with; Axel Naumann would have a more authoritative answer. ;-]
That's my point. And `get_if(rvalue)` could be made illegal as well. So both versions do not compile and do not just "always work" as you said.
`&amp;rvalue` not working has nothing to do with variant or `get_if`.
I know. You said: &gt; Personally, I'd rather an API that always works vs. one that gives me compiler errors if I pass an rvalue. I wanted to point out that you have a compilation error *regardless* of the API choice.
One error has to do with the API, the other has to do with the language; I don't know why you're trying to pass the latter off as the API's fault. Honestly I'm sick of this 'debate' and regret posting in this thread at all. _I didn't write the library, I don't have the answers_, nor am I invested enough in its design pros and const to defend it ad nauseum.
&gt; One error has to do with the API, the other has to do with the language; I don't know why you're trying to pass the latter off as the API's fault. I'm not, I'm trying to negate your argument. &gt; Honestly I'm sick of this 'debate' and regret posting in this thread at all. I'm not discussing with *you*, I'm discussing with your arguments. :) This is nothing personal, I know that you didn't write the library, I just really dislike this API choice here, and want to make it clear by attacking possible reasons for it.
&gt; If get_if took references and you passed an rvalue and got a static_assert, the error would occur in the library. Why would it matter where the compilation error occurred? In both cases you have to change your code and deal with the rvalues, I'm not really seeing your point here.
No, I wouldn't have to change my code, because I wouldn't attempt to take the address of an rvalue in the first place. I _would_, however, happily `std::forward` a forwarding reference in from generic code and be annoyed at not knowing it was a problem for rvalues until _after_ I build (or possibly later on, if my initial use of said generic code only used lvalues). EDIT: To rephrase, it matters where the compilation error occurs because for one it means I did something stupid and obviously avoidable, and for the other it means I did something apparently (or maybe ostensibly) sensible and the library choked on it.
So you're not using std::ref then? Or std::regex_search? (granted, you could not actually use that one) Or any other function where you must not pass rvalues, because in generic code you could accidental forward there. You might say: It's obvious that std::ref() must not take rvalues because it returns a reference to that, who would it do that for rvalues?! Well, I say: It's obvious that get_if() must not take rvalues, it returns a pointer; how would it do that for rvalues?
&gt; So you're not using std::ref then? `std::reference_wrapper` is a glorified pointer, and I treat it as such. It's already "special" in many ways, this is just another small one on the list. &gt; Or std::regex_search? I don't use `&lt;regex&gt;` due to implementation deficiencies, so I haven't run into this one. (I use Boost.Xpressive in the rare occasion I need regex.) &gt; Well, I say: It's obvious that get_if() must not take rvalues, it returns a pointer; how would it do that for rvalues? It's _apparent_ given some minute amount of thought. But you know what makes it _obvious_ given zero thought whatsoever? Taking a pointer. ;-]
I had this problem with my initial install as well. Re-run the installer, but make sure that the C++ tools are selected since they don't get installed by default it seems. It's mentioned in the post Andrew linked to. Edit: after repeating on another system, I now have the same issue.
Oh, good point. I missed that detail, sorry!
Interesting. I made my own C++ database, but wrote a C++ code generator instead of using templates. This makes me think about using templates instead. You can take a look at what I did there: https://www.remi-coulom.fr/joedb/intro.html . Maybe I could somehow use your code.
On the same topic, I thought I'd go ahead and recommend Herb Sutter's ["Leak freedom in C++... by default"](https://www.youtube.com/watch?v=JfmTagWcqoE) talk from CppCon. It's a pretty nice rundown of the new fancy smartpointers, when to use what, etc.
I disagree with the idea of returning a (bare) `void*`. One of the things that annoy me the most with allocators is that they rountinely allocate *more* than you asked of them, but do not tell you so, so you cannot take advantage of it. For a single allocation, this is rarely interesting, but for an array allocation it is very much. I would rather an array allocation returned a `(void*, size_t)` and told me exactly how many items can fit in there; possibly saving a further round-trip with the allocator (the alternative being exposing a `resize_in_place` operation that will either actually resize or fail, atomically, but it does not compose as well).
A split function may sound simple, but it can get a little more complicated when you want to cover all possible use cases and make it as fast as possible. Boost does have two different versions: * http://www.boost.org/doc/libs/1_57_0/doc/html/string_algo/usage.html#idp430824992 * http://www.boost.org/doc/libs/1_61_0/libs/tokenizer/ 
- The algorithm should not pre-define the kind of container it returns. - The algorithm should be highly configurable (in terms of acceptable delimiters). - The algorithm should be lazy, so as to efficiently deal with large data. - Input iterators (something akin to an istreambuf_iterator) seem more suitable than an algorithm. Then, `regex_token_iterator`?
I don't know why you're downvoted, this is the best answer so far :)
I suspect it has to do with C++'s preference for streams. For example, you can do this to get the words in a string: istringstream ss{str}; string word; while (ss &gt;&gt; word) { cout &lt;&lt; word &lt;&lt; "\n"; } While I kinda hate streams, this could be the reason there isn't a split method in the standard.
Presumably they mean that it shouldn't do any extra work beyond what is requested. The value returned should be an iterator that performs the next split operation each time it's incremented. For example if you split a 10MB string containing a large text file but only examine the first three lines, then that's the only work performed, you don't create thousands of lines if only the first few are needed. I would add that string splitting kind of depends on having a string view class in the standard library, since ideally each substring would be a view into the original string so that you can do it without allocating anything. That could explain why it's never been added in the stdlib, since we only just now got string_view. 
But it loses the ability to tokenize on a custom delimiter.
You don't lose them, it is just ugly and involves a custom locale where you change the specification of whitespace characters.
Just use [`std::getline`](http://en.cppreference.com/w/cpp/string/basic_string/getline) with the custom delimiter. Name aside, that's exactly what it's for. istringstream ss{str}; string field; while (getline(ss, field, ';')) { cout &lt;&lt; field &lt;&lt; '\n'; } EDIT: N.b. I'm not advocating this as a general approach to string splitting; but, if you're _already_ extracting from a stream, ...
I've gotten mostly everything working with RC now. Where is OpenGL32.lib? I downloaded the Windows SDK from the RC's installer, but it isn't where it usually sits.
You, sir, want /r/cpp_questions.
&gt; But, I also installed the 'Game development with C++' workload, in case that matters. That might have done it. I don't have a lib folder there, only a bin. I'll check that workload out and report back. Thanks for the quick response!
I would also be interested in hearing why dereferencing requires going through the control block.
Added, thanks!
I made that text bold, thanks!
that is a fine point - thank you! (added)
To be honest, I really hope `std::string` gets completely redesigned for STL2. And by that I mean remove all that npos nonsense and add proper iterator returns **like the rest of the STL containers**. On that note, having some common utility functions for strings wouldn't be bad. `split` and `replace` are good candidates in my opinion.
After installing the game kit, I still don't have that lib folder and can't find the GL lib. :&lt; Any ideas?
Please report any issues you find with MFC and `/permissive-`.
Yeah, compared to something like 'print "quick brown fox".split(" ")' in Python, the STL version is remarkably unintuitive when figuring out how to write it, requires figuring out regex syntax as just one step, and anybody who hasn't figured out how to write it isn't going to understand it by reading it. It seems like this is a case where perfect is the enemy of the good. I usually only want a 'good' split function that doesn't have to guarantee a whole lot about performance on multigigabyte strings, or weird corner cases. So having a good split function seems way more useful than having no split function and debating about obscure cases where it wouldn't be optimal.
&gt; For all intensive purposes, they are roughly equivalent. Hm..
Sorry, I do not see the problem there. Intuitively means something that splits a string which is what both methods do. How they handle empty strings is part of the API, so what. Whether they take only a character, a string or a regexp is also part of the API and not really a problem in C++ thanks to overloading. To make it a little bit more C++-ish it could take an output iterator. Yes, this is not an ideal situation and maybe we just call it simple_split and reserve split() for when we have a better name but not having any trivial split functionality is really not good. We have whole talks given on using std::transform and other algorithms instead of a for loop but we cannot provide a simple split?
Oh man, that's horrible. I'm on linux, but you're right in that for something as small as "items from a split string", std::vector is the correct container. I don't remember why I wrote this using std::deque. In fact, I don't remember why I have this routine at all in my personal toolkit since I rarely ever hit the need for it.
&gt; In fact, I don't remember why I have this routine at all in my personal toolkit since I rarely ever hit the need for it. **That** is the exact statement I've been waiting for anyone in this thread to say. I honestly cannot think of the last time I actually _wanted_ to do this. It's fine for a quick and dirty hack sometimes, but in real code? No, never (that I can remember).
And why do people complain? This is clearly easier than what people usually do. Honest.
Atheist moron, actually.
 template &lt;typename T&gt; inline std::vector&lt;std::string&gt; split(const std::string&amp; s, T delimiter) { std::vector&lt;std::string&gt; result; std::size_t current = 0; std::size_t p = s.find_first_of(delimiter, 0); while (p != std::string::npos) { result.emplace_back(s, current, p - current); current = p + 1; p = s.find_first_of(delimiter, current); } result.emplace_back(s, current); return result; } 
split as in chop a string into lots of substrings based on a delimiter?
In reality, things get deprecated and forward compat is broken many times.
doing UIs as web frontend seems to be the hot new thing. Probably just a talent thing, and also easier to customize and make consistent with your web offerings.
You rock. Thanks
Ideally, everyone wants to get it right the first time. I'm pretty sure python implementation returns deep-copied immutable strings
It's obviously a tongue in cheek joke, but it is also actually touching at the heart of the problem. Some developers don't want to implement such a function unless they can do it so flexible that it can solve all possible problems. Even when in reality a very simple function would solve 99% of the problems. This leads to the current situation where we instead of having a decent function that everyone can use, we are stuck with nothing and having to implement a thousand different versions ourselves.
If you'll excuse the self-promotion, I wrote a blog post [a while back](http://tristanbrindle.com/posts/a-quicker-study-on-tokenising/) about a STL-based generic splitting algorithm that outperforms `stringstream` (and `strtok`) by a healthy margin. It's also worth noting that [Range-V3 has a `split()` view](https://ericniebler.github.io/range-v3/index.html#range-views) which (lazily) returns a range of ranges. Whilst views are not part of the current Ranges TS, I remain hopeful that we'll see them some time in the future.
How can that be? Doesn't `std::deque` require O(1) time for random access?
It's still random access, but each bucket is only max(16, sizeof(T)) bytes, so you end up with one bucket per object and zero cache coherency.
Thanks. I thought this was sufficient, but I've now repeated the installation on another system (Server 2008R2) and it's not creating the `VS150COMNTOOLS` env var at all, no matter whether the C++ features are selected or not. Are there any circumstances which can prevent this happening? I initially ran the installer as an unprivileged user, and then switched to an AD admin user when prompted for credentials. Repairing the install, uninstalling and reinstalling, with or without rebooting after installing and uninstalling have no effect. Edit: Now repeated with a second full VS Community install on Win7 Enterprise x64, and it's again missing from the environment.
&gt; The value being added is constructed into the vector, not assigned. I don't understand what this means. Both `push_back()` and `emplace_back()` construct elements. (In VC 2017, `push_back()` is literally a synonym for `emplace_back()`, although they still differ in the types that they take, so they are not equivalent in that sense.) Here's what I would say: 1. Reserving immediately after vector construction is okay (although I generally don't bother with this). However, never write code that calls reserve() on a vector at any other point in its lifetime, unless you are absolutely sure what you're doing won't trigger quadratic complexity, and you understand how repeated reserve() calls can trigger quadratic complexity. 2. shrink_to_fit() trades time for space. Don't call it unless you have time and need space. 3. The "swap idiom" is different from shrink_to_fit() in the New World Order of stateful allocators. (We still need to teach basic_string this, although vector has done the right thing for a little while now.) 4. Range insertion also performs only one allocation (when the iterators are fwd+). However, it has to execute more general code for mid-insertion, which may or may not be possible to optimize away (I wouldn't count on the optimizer noticing that end() is being passed). So it is true that assignment (when possible) is better than range insertion, which is better than push_back() or copy()-to-back_inserter(). 5. at() is bad and should feel bad. Completely agreed here. 6. I'm betting emplace_back() profiled as faster than push_back() because of 2015's lack of an aliasing check in emplace_back(). I burned this code to the ground in 2017 and the implementations are completely different now from what they used to be. 
That's not what I was suggesting, sorry if it came across that way. The point I was trying to make is that most of these "tips" are very basic and I would be surprised if any entry-level C++ book/tutorial didn't cover them. I believe that anyone who's interested enough in C++ to visit its subreddit in search of new content has very probably used the language long enough *(or read enough related material)* to know all the things mentioned in the article. 
Do they post the talks on YouTube?
Nice, is there an equivalent t for join? ie. In python: `",".join("the", "quick", "brown", "fox")`
It's "all intent and purpose" for those wondering why this was called out.
Well, I know how the above code works, but I can see quite a few perfectly reasonable complaints about it: 1. The magic -1 parameter. There's no way to know what that means without digging through the documentation. Something like a `mode` enum would be easier to read. 2. `ostream_iterator`? What does it mean to iterate through an *output* stream? That doesn't make sense. Better go read the documentation again. 3. Why do we need to create *two* `sregex_token_iterator` when we only want to iterate through the string once? That doesn't make much sense. Back to the documentation we go!
You can use boost is definitely not a good answer for something so fundamental as a string split function.
&gt;I think it's because this implementation's insert can make use of the fact that it's passed two RandomAccessIterators to find out how much capacity is needed and calls reserve under the hood. This behaviour is mandated for forward, bidirectional, and random access iterators ([vector.cons]/10).
There's a const overload for []
-_- Not in VS2013 is it? I mean certainly I am not that stupid. Certainly. I hope.
\*cough\*
Does... does this work?
I didn't see it was for the "Build Tools", however, with the usual installer (`vs_Professional.exe`) it just won't define the `%VS150COMNTOOLS%` environment variable. I've uninstalled 2017 RC completely, then reinstalled and made sure C++ was selected (and nothing else), and then tried to add more and more items. And to be on the safe side, I restarted my computer every time I modified the installation. No `%VS150COMNTOOLS%` variable is defined in the environment. If I run `vcvarsall.bat`, `%VS150COMNTOOLS%` get defined in the current shell. But that's just it. I really want `%VS150COMNTOOLS%` to be defined in the system environment just after a reboot.
Fair enough.
It's unreasonable to expect anyone to intuit what an output iterator is, or even what an iterator is, if they don't know C++. That doesn't reflect poorly on C++ or output iterators.
Let me find out for you. 
Thank you for your insights and taking the time to write this up. What i meant by constructing into the vector is the element being added is created from arguments passed into the vector . For example, passing a string literal into a vector that contains std::strings. Can you elaborate a bit on reserve triggering quadratic complexity if used at any point other than immediately after its construction ? 
Yep - the results are computed using "release" mode - the test results in debug are quite different.
operator[] in map will return a reference to the held element. If it's not found, it must construct a new one to return it. Or else it won't be able to return anything, which is bad. If one makes it const, then it must throw if the element if not found, or else it's undefined behavior. At that point, you can use `.at()`, which already does that.
Not really. In many ways, Boost should be considered an extended standard library.
This is the best answer. :-)
Yes and no. The " and "; seem to be a bit tricky. The following c programm works if you enter them. End with Ctrl-D. #include &lt;stdio.h&gt; main(){ char * c= #include "/dev/stdin" printf("Hello World! &lt;%s&gt;",c); } 
The clang compiler (the LLVM project really) doesn't even use the STL for its data structures. Too bloated and inefficient, and can't resize containers (move elements) in some situations due to bad design. That should tell you something. Most languages standard libraries shoot far too high (ambitious) and end up not being a good fit for anything. The fact is, most of the time you want something easy and inefficient. e.g. when parsing a config file. Only 10% of the time would you want to spend cognitive load for something "fast" - and you'd want something faster than the STL is anyway, not something that was designed by committee to be lowest common denominator.
Basically some people want to create puzzles / problems instead of solve them. And the people that design the STL are firmly in the "create puzzles" camp.
Actually "intents and purposes", if you're going to get pedantic. :-)
For point 2 (about shrink_to_fit) also keep in mind that the standard doesn't truly require it to release extra memory (if any). 
&gt; Line 3 is completely alien and extremely unintuitive to me. So you're saying I don't know the language? Yes, it is a basic iostreams idiom. Have you read any books on iostreams? C++ allows one to get by (even insofaras to "do a day job") only learning certain areas of the language. Probably you know some parts of it well, but not stream iterators. 
Implementers aren't actually trying to stab you in the back. Source: am implementer.
Suppose you're appending 3 elements to a vector, so you try to be cute and say `v.reserve(v.size() + 3);` before the push_backs. If this is called in a loop, you trigger quadratic complexity, because reserve() is allowed to give you exactly as much memory as you ask for (when it grows), instead of triggering geometric reallocation.
[Done.](http://ideone.com/vpI2GP) #include &lt;string&gt; #include &lt;iostream&gt; #include &lt;algorithm&gt; #include &lt;regex&gt; #include &lt;vector&gt; std::regex operator ""_re (char const* const str, std::size_t) { return std::regex{str}; } std::vector&lt;std::string&gt; split(const std::string&amp; text, const std::regex&amp; re) { const std::vector&lt;std::string&gt; parts( std::sregex_token_iterator(text.begin(), text.end(), re, -1), std::sregex_token_iterator()); return parts; } int main() { const std::vector&lt;std::string&gt; parts = split("Quick brown fox.", "\\s+"_re); std::copy(parts.begin(), parts.end(), std::ostream_iterator&lt;std::string&gt;(std::cout, "\n")); return 0; }
Not yet standardized: http://en.cppreference.com/w/cpp/experimental/ostream_joiner
Most entry level C++ material doesn't use vectors at all. Unfortunately.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5e1mq9/help_setting_up_c_environment_on_new_mac/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I know--in fact, I can even imagine implementations where ignoring it is probably (at least usually) the best choice. Come to think of it, that could pretty easily be most implementations most of the time. I've lost count of the number of times I've sped code up by removing calls to `reserve`, but probably at least half the time I see it, its effect is neutral to negative (and I'd guess shrink_to_fit will work out the same).
Holdover from Boost.Variant, probably.
I started working on a new split. It's not yet complete, not yet customisable. It's been tested on strings, but the code isn't string specific. It should work for other iterable containers. It does only use iterators so should be quite efficient. If ranges were a thing already the interfaces would be a bit cleaner. https://github.com/KayEss/f5-cord/blob/feature/split/include/f5/cord/split.hpp 
Standard library maintainers can change the internal implementation of a container as they see fit, so long as its behaviour ultimately conforms to the standard specification. If maintainers were required to expose configurable parameters to users, I imagine backward compatibility would seriously constrain the maintainer's flexibility to improve a container's implementation.
well yes, normally you'd make a real function object (not just some lambda), run it over a sequence with for_each and then extract stuff out of it - see boost.accumulators for examples. My point is that for_each does work you didn't ask for if all you ask for is iteration (although, to be fair, a compiler can see through it)
&gt; Have you read any books on iostreams? I'd laugh if this weren't so painful. I want to print out the words in a string, one per line, and you're suggesting we *go read a book* to understand how you think it should be done? No, `std::copy` for printing is a little ridiculous, the two-iterator idiom is terrible, and either they will be left to the pages of history or C++ will. I don't follow C++'s development any more, but I remember hearing ranges were happening. That's a start. Once you've done that you can just turn this into a `for` loop and it'll be shorter, clearer, less error-prone and no less efficient.
&gt; at() is bad and should feel bad. Completely agreed here. Why? If you need bounds checking it's completely fine, no?
&gt; Or alternatively, inappropriate language choice. So even if your code is C++, you're going to pipe your text to perl each time you need to split a string?
None on this seems to negate that it would be nice for the modern std::string implementation to come with some basic string manipulation methods so that the language's usability can potentially compete with other modern systems languages. If having to split a few strings in your program means that you should use a different programming language, then the programming language in question is pretty god damn bad.
C++ has a very conservative following. For a long time that meant that libraries for a lot of stuff just didn't exist and companies that used C++ built up huge libraries of their own. Two things changed that now: 1. boost came along and 2. there is a huge investment into the standards process at the moment. That means in most cases that the standards committee doesn't take existing libraries to standardize them, but new libraries are basically *designed by committee*. You have a ton of domain experts sitting in working groups trying their hardest to create the best libraries there can be. The idea is to bring C++ to the same (or higher) level of library functionality as other mainstream languages quickly, but with way higher quality. The hope is that we don't have to learn new frameworks every 2 seconds.
I'm not the author of the linked-to ETL library, though I have written something very similar for my job. [I've made the fixed-capacity vector class to use C++11 features available on Github](https://github.com/KevinDHall/Embedded-Containers) and would love to present it to SG14. I haven't been able to actively work on it for a while due to work and family, but I hope to update it after the holidays. If anyone here on reddit has questions about my library, why a few "ETL" libraries have been written, or why these strategies are preferable over boost::static_vector, I'll be happy to reply. Another similar library is [ESR Lab's ESTL](https://github.com/esrlabs/estl-teaser). However, like the ETL in the original post, it relies on C++98 behavior and doesn't offer the semantics found in C++11/14/17 containers. 
If you are not *absolutely certain* that you're working with valid indices, something is deeply wrong.
I think a more intuitive and "modern" way will be this one (also compiler can optimize these things pretty well as opposed to streams): string s = "Quick brown fox."; auto rs = ranges::v3::view::split(s, ' '); for (auto&amp; x : rs) { cout &lt;&lt; x &lt;&lt; '\n'; } auto rs1 = ranges::v3::view::join(rs, ','); cout &lt;&lt; rs1 &lt;&lt; '\n'; Still the library needs concepts and a more intuitive documentation to make it "easy to use correctly and hard to use incorrectly". Also maybe there should be strings extensions in range library so it have an intuitive API to work with strings.
 const auto myVariable = bCondition ? (bCond ? computeFunc(inputParam) : 0) : inputParam * 2; *ducks* 
Pretty sure, that there should be a return in the lambda of the IIFE version. 
the way you have formatted the code...everything is perfectly aligned. 
An obvious straw-man claim doesn't prove anything. If I want to split a string once or twice in an application that's generally well suited to C++, I'm just not going to care that the string split is more awkward than it should be - the important thing is whether the language is well suited to the application as a whole, not to every tiny little piece. And if the only string-related awkwardness to keep recurring is string-splitting, I'll wrap that in a function and forget about it. But if the focus is on doing lots of string-processing things that are a better fit for Python than C++, and there's no strong reason to use C++ anyway, I'll use Python. It's not hard. Most people make practical choices between imperfect alternatives every day. 
You should use boost::python. http://www.boost.org/doc/libs/1_62_0/libs/python/doc/html/tutorial/tutorial/embedding.html 
Boost is almost always the best answer. Boost::Python is a particularly great example of this.
My BlockAllocator concept returns a memory_block struct which is void* + std::size_t, because it is designed to decided about the size. I can understand why you want that, but that is part of a specific allocator, so add a member function for that. Generic code cannot make any assumptions there and such the generic interface (through the traits) returns void*.
From the Qt documentation: QString str; QStringList list; str = "Some text\n\twith strange whitespace."; list = str.split(QRegExp("\\s+")); // list: [ "Some", "text", "with", "strange", "whitespace." ] 
Hijacking the thread, but what is the most sane programming culture? I don't fit into the hipster web developer culture much.
&gt; What is the C++ development culture like? We're the best ;-) The community is quite conservative, like other posters have written. There is however, since the dawn of modern C++, an increasing numbers of language enthusiasts, so the diversity in this regard is growing (a good thing IMHO). However you like it, you will find similar people in the C++ community, except we don't suffer the "web-framework-of-the-moment" syndrome. 
You expect to go to a C++ board, ask who the most sane culture is, and not expect to hear C++ as the return? I mean, come on now, I'm the OP and even I know the answer to this, haha. In all seriousness though, the C++ community sounds like my place!
Where is "container_node_sizes_impl.hpp" included from here: https://github.com/foonathan/memory/blob/master/include/foonathan/memory/detail/container_node_sizes.hpp
It will be generated when you run CMake or the nodesize_dbg executable.
Machine code is too high-level. Programming at such a level of abstraction makes for lazy programmers. For maximum efficiency, you should be implementing your program as CPU microcode and sneaking it into new hardware releases.
Yes, it's a fair option I should have mentioned. Which is appropriate depends a lot on your situation - if you're on a platform that already provides boost::python pre-built, or if you use other boost libraries as well, then the bigger user audience of boost probably makes it the right choice. But if you have to build something from scratch, with a modern compiler, and don't want any of the rest of boost, then pybind11 is a good option that looks like it will save you some hassle.
[Image](http://imgs.xkcd.com/comics/real_programmers.png) [Mobile](https://m.xkcd.com/378/) **Title:** Real Programmers **Title-text:** Real programmers set the universal constants at the start such that the universe evolves to contain the disk with the data they want\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/378#Explanation) **Stats:** This comic has been referenced 954 times, representing 0.6994% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_da9ehfr)
Said code wouldn't be isolated though, it would be in a function with `split` in the name. Dependent code would then _call_ a function with split in the name. So no, I don't see the problem. EDIT: For a bunch of pedants, you /r/cpp folk suck at following Reddit's rules: if you want to _encourage_ meaningful discussion, stop downvoting opinions. Grow up, people.
The dead giveaway that the code you're trying to understand is splitting a string on whitespace would be that it'd be in a function with split in the name. Who reads 5 lines of code with zero context whatsoever with the expectation of its purpose being obvious. Context matters; ignoring it is counterproductive.
'Split' simply isn't how you print out the words in a string, one per line, in C++. C++ has different idioms for this sort of thing, and everyone obsessing over the lack of `std::split` seriously needs to learn to "Do As the Romans".
There's none of this 'hipster' JS nonsense in C++ land. People are largely conservative, in that they enjoy C++ without feeling a burning need to promote C++ to Java/C#/etc. developers. In terms of a zillion frameworks being used, people mainly stick to STL and Boost and build on top of this. Keep in mind there's no 'standard' package management infrastructure except NuGet (and that is Windows-only AFAIK). The demographic, at least from going to and talking at user groups, is a bit older, which isn't bad really, as you get to meet people with ridiculous amounts of experience. People are also very realistic, for the most part, about C++'s weaknesses compared to managed languages (weak standard library, lack of metadata, etc.)
An exception may or may not have a stack trace; an exception may or may not have unwound the stack. Whereas a segfault leaves all memory, stack included, intact and gives you an EIP. If you're finding it easier to debug the former than the latter then IMO you're not using your tools effectively. ;-]
&gt; The dead giveaway that the code you're trying to understand is splitting a string on whitespace would be that it'd be in a function with split in the name. If you look at the example, it's actually in the `main` function, but if you're having to define your _own_ `split` function to hide the code that does it using standard library calls, then that really just further proves the point, doesn't it? You wouldn't *have* to define your own split function if the standard library method was easy to read and understand in the first place. &gt; Context matters If you have to rely on the contextual clues of surrounding code in order to figure out that the code you're trying to understand is merely splitting a string on whitespace, then that's indicative that the code that performs the actual string splitting is not very readable. It's an operation that's simple enough and common enough that really all the information required to understand what it's doing should be there in the immediate code. Take a simple example of boost's string_algo split: split_vector_type splitResult; split(splitResult, stringToSplit, is_any_of(" ")); Show that code to a programmer who doesn't know any C++ - a Java programmer, a Python programmer, a C# programmer, whatever, and ask them what it does and almost all of them will be able to guess. None of them are going to respond by saying "*Hmm... it's hard to say without any surrounding context.*" Or what about this example using the experimental `ranges`? auto splitResult = ranges::v3::view::split(stringToSplit, ' '); That's clear, concise and readable. You don't need to study the surrounding code to understand that this is splitting a string on some whitespace.
I used to use boost, but I eventually moved to using the C api directly. The boost python library is pretty powerful, but even after using it for a year I just plain couldn't grok it. I also got tired of spending forever deciphering the mystical error messages I would run into. For me moving to using the C api directly has unquestionably been a huge win. You might consider just using it directly yourself. That said, I have some example code lying around for exactly this, but unfortunately I can't track it down at the moment. The official docs are pretty good really: 1. https://docs.python.org/3/extending/embedding.html (the embedding portion) 2. https://docs.python.org/3/c-api/index.html (the C api in general) edit: For the OP I should say that I haven't tried pybind11 though I've heard good things. Maybe that is something that would fit my brain better.
&gt; If you look at the example, it's actually in the `main` function If all we're doing is nitpicking the example and not relating it to real code, then who the hell cares? &gt; If you have to rely on the contextual clues of surrounding code in order to figure out that the code you're trying to understand is merely splitting a string on whitespace, then that's indicative that the code that performs the actual string splitting is not very readable. The point is that it doesn't _matter_ whether it's readable, because in real code it would be encapsulated in something whose name gives it away. Just as would be the case for any domain-specific logic, which is what most _real_ code is anyway. Tearing apart single and double-digit LOC C++ examples is absolutely a waste of time. C++ is about larger abstractions and the bigger picture, and it does that quite well.
Good god, it's a five-line function. Write it and call it a day. https://i.imgur.com/02NJHQw.png
Why do you keep telling me what "we" are discussing? _I_ am discussing the actual topic: "Why doesn't std::string have a split function". _You_ can continue your rant if you like, but direct it elsewhere, please.
&gt; Why do you keep telling me what "we" are discussing? I am discussing the actual topic You [responded](https://www.reddit.com/r/cpp/comments/5dxnwm/why_doesnt_stdstring_have_a_split_function/da8mq9z/) to [my comment here](https://www.reddit.com/r/cpp/comments/5dxnwm/why_doesnt_stdstring_have_a_split_function/da8llxm/). If you don't want to have a discussion with me, feel free to stop responding. If you're going to continue to disagree with me then please address the points that have been made [here](https://www.reddit.com/r/cpp/comments/5dxnwm/why_doesnt_stdstring_have_a_split_function/da9ffhr/), [here](https://www.reddit.com/r/cpp/comments/5dxnwm/why_doesnt_stdstring_have_a_split_function/da9fmwm/) and [here](https://www.reddit.com/r/cpp/comments/5dxnwm/why_doesnt_stdstring_have_a_split_function/da99bi9/).
Any idea on how to make this work on arrays? e.g: https://github.com/kloetzl/biotwiddle/blob/master/hash.h#L58
Why std::copy in split, when you can initialize the vector directly form the token iterators? Also I find this more generic and lazy: http://ideone.com/L6heVN I guess it could be improved even more by using string_view, but that's not included in C++14 :-( Anyways, the only requirement for the target is, that it can be initialized from an iterator pair with value type std::string. Other than that it is pretty generic. Code: #include &lt;algorithm&gt; #include &lt;iostream&gt; #include &lt;regex&gt; #include &lt;string&gt; #include &lt;utility&gt; #include &lt;vector&gt; std::regex operator ""_re (char const * const str, std::size_t) { return std::regex { str }; } class split { public: split(std::regex splitter, std::string original) : splitter_ { std::move(splitter) } , original_ { std::move(original) } { } auto begin() const { return std::sregex_token_iterator { original_.begin(), original_.end(), splitter_, -1 }; } auto end() const { return std::sregex_token_iterator {}; } template &lt;typename Container&gt; operator Container () const { return { begin(), end() }; } private: std::regex splitter_; std::string original_; }; int main() { using namespace std::literals::string_literals; std::vector&lt;std::string&gt; const words = split { R"(\s+)"_re, "hello\tdarkness my\nold friend"s }; for (auto const &amp; word : words) std::cout &lt;&lt; word &lt;&lt; "\n"; for (auto const &amp; number : split { ","_re, "23,42,1337" }) std::cout &lt;&lt; number &lt;&lt; "\n"; return 0; } 
I suppose you could return a std::array, if you really want to use this construct for initialization. Btw, in your example, the array named "table" is not zero-initialized - you might consider doing the following: static char table[127] = {0};
Probably not, since it claims to be basically a fork of boost::python with support for old compilers cut out and some wizzy new features added. Crap error messages are a problem with pretty much any template library.
But the exception is deterministic, the segfault may happen immediately if you're lucky, but it may also not happen and just read garbage memory happily (e.g. if you read past `size()` but before `capacity()`). See for instance : http://ideone.com/Tn9YDf
use a lambda like this: auto const table = [] (char const c) -&gt; char { switch (c) { case 'A': return 0; case 'C': return 1; case 'G': return 2; case 'T': return 3; default: return 0; // or Unreachable() } }; and then return_value |= table(kmer[k++]); edit: that's indeed verbose, and using the switch directly won't make a difference, because this code gets optimized away anyway (the lambda gets inlined). In fact, I don't know why C++ deprecated that `{field = value,}` C thing (it is very useful for explicit initializing structures' fields). You could, however, do this instead: static const auto table1 = [] { auto table = std::array&lt;char, 127&gt; {}; table['A'] = 0; table['C'] = 1; table['G'] = 2; table['T'] = 3; return table; }(); But [things get a little complicated at the binary](https://godbolt.org/g/jOowM5). So I'd stick with the lambda + switch thing. It won't make much difference at runtime, as clang is using the vector registers to initialize the array. Though the binary becomes bigger. GCC is actually doing a [good optimization](https://godbolt.org/g/qQj8Tt) here, by the way.
All I actually care about are the four entries for ACGT. In C one can do `static const table[127] = {['A']=0, ['C']=1, ...}`. But C++ doesn't understand that syntax.
You're right, 'twas a brain fart.
Yeah it looks silly at first, but after over two decades of C++ programming one eventually learns to format in self-defense. Every C++ programmer is their own worst enemy. I do that to my code to keep my eyes from bleeding, and it allows me to work on much larger codebases and still keep my sanity than would otherwise be possible.
To be very frank, the `std::string` type is there mostly to claim that there's a string type in the standard. It's not really usable for anything other than as a resource-managing wrapper over a C string. If you had C-style strings in your code, you should use `std::string` instead. It gives not much in the way of other functionality, except for cheap `size()` that is `O(1)` vs. C's `strlen` that was `O(N)`. For anything practical, you need a string library of some sort.
&gt; Note: This module doesn't consider 0 to be a positive number and doesn't distinguish between -0 and 0. **If you want to detect 0, use the positive-zero module.** What I can only imagine if something like this happened in C++-land: &gt; Module: LabelWidget &gt; Note: This module doesn't auto-wrap words. If you want auto-wrapping, use the WrappingLabelWidget module
I updated the answer.
I assumed you meant segfault due to `assert`/`std::abort()`. Apologies.
This has to be the funniest thing I've seen in weeks.
this is the beginning tutorial of c++ so stay tune for more high quality program :)
Pretty sure someone makes this comment every time a [reveal.js](https://github.com/hakimel/reveal.js/) presentation is linked here. It's a wonder it's so popular since everyone seems to hate it...
Nuget has been around for quite a while, but only ever supported C++ as an afterthought. It was never really designed to work for the kinds of things you really need (or at least badly want) with C++. There have been a number of attempts at a package manager oriented more toward the needs of C++ and its users. A few of them have failed. Some were trying to create a money-making business, and this is an area where it's pretty hard to make much money. Fortunately, there are also some people working on it who don't care about making money on it directly. The obvious example (at least for Windows) would be Microsoft's (fairly) new [vcpkg](https://github.com/Microsoft/vcpkg). This is open source, and works pretty well. Its most obvious shortcoming is that it's new enough that it doesn't support a huge number of packages yet. Its initial release only included 20 packages or so. It's now (a month or so later) up to around 100 packages. I think this has roughly the right mix of features to become a relatively general-purpose system (and given that its open source, I wouldn't be surprised to see it ported to Linux at some point, though some of its most difficult parts are relatively specific to visual studio right now).
And it's at version 3.1. I don't even.
Likewise F# &amp;mdash; very proactive and progressive, and nearly obsequiously welcoming.
As a general rule the mature ones tend to be. The issue with web development is that it's all relatively new, ever changing and subject to a lot of trends. It's also the hip thing to do and most of the younger developers migrate towards web work. But back end stuff is a bit less sexy, the technologies have been around for longer and the communities are a bit more weary of sweeping trends - if you've lived through the last couple of decades of software engineering trends you'll have become cynical of people claiming to have solved the problem for all development, be it patterns or SCRUM or Agile or whatever. That being said, what is sane will depend on the developer. Up until her retirement my mom often boasted that COBOL was doing exactly what it was intended to do with little interference from anyone and because the people who were proficient in COBOL had been doing it for so long they could easily dismiss more enthusiastic but less wise developers who wanted to shake things up for the sake of shaking things up.
This definitely has hidden meaning :)
&gt; Are usually a thin layer of abstraction around the cpp toolchain. Please explain how this would be an issue. When integrating code from various projects. Some teams at my work use scons, i use cmake. Other legacy projects we have contain complex makefiles that we dont have the budget to rework. Merging these projects together at anything but the binary level is a pain in the ass. &gt; are themselves covered by standards. The main ones are fairly standard compliant already and standard compliance is done with increasing speed. I have code in my project that functions when compiled with g++ and crashes when compiled with clang++. It certainly is just a code generation bug that will be fixed, but i would not stake my career on those two compilers being drop in replacements without testing, especially if you're using the new standards, which i am. &gt; machine arch has no impact on the implementation of a library Java you can use compiled jars in your project across platforms. C++ you can't without matching architecture. Add in all the compiler flags that you can select that affect code generation, i.e. AVX2 or SSE, and the binaries produced may or may not be viable on a given platform. &gt; How would this prevent the standards committee from developing a set of libraries/functionality? It doesn't. But code reuse goes a lot further than the standard libs. Im talking ecosystem libs like java has. All of these issues ensure that we will never have a "maven central" for C++. It's just not going to happen.
The standard library is just the start of the ecosystem. Let's ignore the fact that the compiler authors implement the standard at different rates. Im talking about reuse of 3rd party libs across the internet like we have on Java. I need a webserver framework i can drop a line in my gradle build file and choose from dozens without recompiling, checking out source, or changing the structure of my system or build. You're not going to do this on C++ anytime soon. You guys seem to have tunnel vision. The world doesn't stop with libstdc++.
I wouldn't call them trolls. Many people are probably bitter, because they've tried to help in the past, and it turns out that many of the people asking for help have not actually put forth any effort, and many of those people don't actually want to learn, they just want to turn in their homework assignment. Learning happens in the struggle. When the answer is given to you, you don't learn nearly as much. Finding open source projects and studying their code is very useful, but only when you're also trying to solve your own problems and struggling through them as well. StackOverflow has become a somewhat toxic environment for beginners because there are so many burned out people, but it is an excellent resource for finding questions that have already been answered. Finding developers in your city who would be willing to mentor is probably the best approach, if you can find them. Such people almost certainly exist, unless you're in the middle of nowhere. But, as of 2016, there are limitless learning resources on the internet. No beginner ever *needs* to ask a question anymore, except for asking Google questions. If they want to read book-style materials, they're available. If they want to get more personal tutoring, there are videos where people walk through the various concepts and code. If they want exercises, Project Euler and many others offer excellent challenges, and the answers and tutorials are out there for the searching. If they need a specific beginner question answered, it has already been answered a thousand times on hundreds of forums. I taught myself programming starting back in 2006 or 2007, with nothing but the internet and a lot of free time. No one I knew could help me, and I didn't ask on forums. But, even though no one *needs* to ask questions as a beginner anymore, there are Reddit communities where such questions are welcomed, like /r/cpp_questions
It matches the `dynamic_cast&lt;T&amp;&gt;` vs `dynamic_cast&lt;T*&gt;` pattern. Casting from a pointer-to-pointer dynamically can fail and return null -- casting from a reference-to-reference dynamically can fail, but if it does it throws. This could have been done with an overloaded `get` taking a pointer, but they split it into `get` and `get_if`. This pointer-vs-reference design comes from `boost::variant`; it would have taken a good reason to break this design when porting to `std`. 
It can do it even if the C program doesn't have undefined behaviour.
Yeah the toxicity really surprised me when I read through some of the responses. I can see getting burned out and I can see the homework-completion [only] driven student, but even so -- wow. We likely have a few local resources I can ask about, but the best bet may just be a codeathon in the local library or computer lab where they can go swap ideas and ask each other (me, and other mentors?) these questions. Thanks for the post, I'll look into these.
Thanks for the *vckpg* pointer, looks interesting, I will need to investigate this and see if it works. Of course, the test for any package manager is to be able to handle Boost under the right settings. Currently we have packages like Boost that just take up tons of time to compile (event in RAM) and packages like Google Test that even Google recommends just including in your projects wholesale, source code and all.
I'm glad C++ doesn't hold my hand because hand-holding usually leads to being led into dark alleys with scary monsters. I'm glad I can be sure that a number is a number, a string is a string, they can't be compared and that's the end of it.
Have you seen this talk by Kate Gregory? [Stop Teaching C](https://www.youtube.com/watch?v=YnWhqhNdYyk)
&gt; I don't think the cycle of clone-&gt;make-&gt;make install is too onerous and is fairly easy to automate. It's actually quite a pain to automate, relatively speaking. - i may have to install a different build tool - i may not have all the dependencies that the project requires - i may have other libraries that have the same name installed - i may have older/OS-level packages of the same lib, or a dependency already installed that i cant remove - i may not have the necessary privileges on the machine I've been down this road recently. I'm using containers now, which helps (although it's still a pain since some of my targets are ARM). In my Dockerfile im actually pulling and build/installing the libraries into my image ahead of time. I was amazed at what a kludge it still all is. Amazed.
&gt; Said code wouldn't be isolated though, it would be in a function with split in the name. Dependent code would then call a function with split in the name. Indeed. And that function is so useful, it should be in the standard library: a member function of the `string` class.
&gt; Up until her retirement my mom often boasted that COBOL was doing exactly what it was intended to do with little interference from anyone and because the people who were proficient in COBOL had been doing it for so long Exactly. I worked with some large COBOL shops that modernized their business by leveraging COBOL -&gt; XML/Web technologies that added new capabilities without changing any of the existing code. It's really the way to go with things like that, services front-ends to well-written, well-maintained, fully debugged code. Shit that's been running for 40+ years now. What scares me is when all those programmers die off and people start wanting to convert to the new language de jure. 
The c++ channels on Freenode are decent.
I don't get what the down arrow is for.
I'm on mobile.
&gt; Or alternatively, inappropriate language choice. I think splitting strings is a pretty common sense thing for any general-purpose programming language to support. It's not like, some obscure operation that you could only find support for in Perl. &gt; Finally, technically I'm not sure `-1` is really code for all-bits-set at all - that assumes a 2s-complement representation for signed integers which, historically at least, wasn't guaranteed by the standard. The more obvious assumption is that the mask type is unsigned and in that case `-1` is necessarily all-bits-set because an unsigned type's value is modulo its maximum value, but the standard doesn't require it to be unsigned either. &gt; why I prefer ~0u for all-bits-set That's not all-bits-set for a type that is larger than unsigned int. &gt; I personally don't worry about actually undefined vs. platform-defined unless I really need to, which is unusual. That's pretty strange considering how many things are implementation defined. Used a value larger than 2^15-1 in an `int`? Undefined behavior (according to you)!
Any particular reason you chose Eclipse over Visual Studio, given that you are on Windows?
&gt; This is suspect. &gt; Who says that such systems that avoid dynamic memory allocations for reliability are using dynamic memory pools instead? Surely, if that's the case, then yes they're missing the point, but I don't believe this is actually done by a significant number of projects so I don't see the reason to pick on this particular point. I agree with you. I believe you are correct that this practice is neither endorsed nor rampant in actual production code. But do I find I am constantly having to correct people on what it means to *actually* allocate everything up front and *actually* have no dynamic memory use in the runtime. &gt; Likely there are other reasons for projects using memory pools and other such dynamic memory allocation tools that aren't malloc, which you exclude from conversation. Yes, there are many other reasons, but that wasn't what I was talking about. The library linked here, as it's *second* main feature claims to be suitable for embedded because it avoids dynamic memory allocations, but that's really not true at all because not allocating from the heap is only 1/2 the story in many environments. 
&gt; but no one sane will expect you to know library X I'm not sure anybody really knows X. ^^Sorry
&gt; Nobody knows what most C++ programmers do.  Bjarne Stroustrup (creator of C++) The are an estimated 4.5 million C++ developers out there the spread across a large number of different cultural groups each with their own history and beliefs. These beliefs founded or unfounded will determine which libraries, frameworks and even language features may be used at any particular company. My experience writing desktop apps and some game development is that there are plenty of experimental libraries and band wagons to jump on but your exposure to this is mostly controlled by you. The C++ standard library is small but very stable with great effort made to avoid breaking changes. 
The reason it irks me is because there is no context on the "slides". We're discussing code here and the moment one goes to the next "thing" the rest of the context is lost. Oh look, another bullet-point quote. When one looks at videos of powerpoint presentations there is a speaker going along with the slides, to provide context. And I guess attendees of conferences get the notes afterwards. Maybe I'm stupid - but I quickly lost the flow and context of what the author was trying to do as we bounced around code and quotes. Is it pretty? Sure - I think that might answer your question as to why people try and use it. Is it useful to explain dependency-injection? No fucking way.
Boost has been around for ages - that's not something that "changed now". Your second point is also not that correct - in fact few new libraries are _designed by committee_, most emerged out of existing libraries, from boost mainly, and other places. It's proven stuff, not something new the committee invents.
A formal DI framework remains one of those things that I've never felt the need for in any project I've worked on, and nobody has persuaded me to seriously consider adopting one. It's not that the framework doesn't have benefits I can see, it's just that the benefits seem minor. Some of the people who are pro DI seem to put the cost of adding a new abstraction layer/dependency between you and constructing your objects at nearly 0; I actually think this cost is significant and would expect significant benefits from the framework in order to use it. I'm not saying DI frameworks are bad, just that I haven't seen someone make the case for it, in what I felt was a strong manner.
Here is one issue I have with C++ relative to C#, the build system for C++ is (in my opinion) horrible compared to other languages like C#. Attempts at improving this like CMake do a decent job but it still is terrible compared to what Rust or Crystal have. And library discovery I feel is still crummy relative to what Ruby has via RubyGem or Rust has with Cargo/crates. Sadly, efforts to fix this don't seem to have much enthusiasm compared to what the Rust ecosystem has, but it is improving lately. C++11 and C++14 and C++17 and onward are doing a fantastic job, and I am very eager to see how C++ improves over time.
That is a good point. I just like Python and saw it was used by Gimp.
&gt; case where perfect is the enemy of the good. I Well said, There are many cases like this in C++ unfortunately. I get the desire to have the best libraries possible but too often good ideas are shot down because they are not perfect. The recent Boost review for process control library is a perfect example. The library has been in development for more than 6 years. It passed the review this time around but some folks were still proposing to start from scratch.
Same technique has been presented few days ago at MeetingCpp by Phil Nash: [Functional C++ for Fun and Profit](http://meetingcpp.com/index.php/tv16/items/19.html).
They may be mature but no sane person would enjoy that forced indentation and dynamic typing. 
something something more vespene gas something something not enough minerals
[The C++ Culture](http://wac.450f.edgecastcdn.net/80450F/kikn.com/files/2014/02/cat_herders-630x335.png)
Well, these problems don't go anywhere. Here they are solved on the OS distribution level. Maybe for the programmers that work with one language is harder to deal with the OS distributions, so they create language libraries distributions. JS as an example: they are now building entire distributions of the js standard libraries on per-application basis.
Well, I don't know whether I have strong enough case for you but I tried to describe benefits and use cases of using DI in the introduction to the [Boost].DI library here -&gt; http://boost-experimental.github.io/di, usually, you will see the benefits of using DI much easier in bigger projects, though, where testing and quality are important, also the 'Clean Code talk' is pretty good too -&gt; https://youtu.be/RlfLCWKxHJ0