Actually mingw by default links the runtime static, so that you don't have to ship anything yourself. Some things go from there into the vc6 runtime as shipped by MS with all modern Windows OSs for a long time. I used that to write a small library using C++11 that could be called from Excel via a simple C API.
No one's stopping you from doing that with MSVC or Clang. ;-]
If it can tightly integrate with cmake (import/export of targets and their properties) and gets IDE support: Great! Otherwise I don't care about yet another build system. That does not mean it isn't a great too, but for me as an End-User, tool and ecosystem integration are much more important to me than slight syntactic inconveniences.
Actually I used msvc first, but the person deploying it kept running into problems because he kept forgetting to install the msvc runtime of the (newer, C++11 compliant) compiler. At that time I wasn't aware that msvc has a flag to link its own runtime static. So I guess you are right.
Are you trying to troll the OP? He explicitly asked if there is a comparable Webserver library in c++ because that would determine what would solve "his problem best".
As someone primarily working on Linux using Visual Studio and setting up a project seem highly complex, so that's mostly about perspective. Anyway, CMake is much simpler than C++ so I don't get all the complaining. Sure it could be better but all things considered it's hardly a problem.
I'm just waiting for a meta-build system that makes CMakeLists.txt
That's what I understood, thanks. Precise communication is tough.
Thanks for the hard work. I use CMT since the beginning.
That's no reason for UB though. If the compiler realizes what you are doing and manages to optimize for it, great, it can do it if the underlying CPU supports it. But it would be a pretty esotheric optimisation, and no reason for the shift operator to require UB. 
well, it's not potentially worse, it's potentially no better.
IIUC in C++20 `[[assert axiom: (a + b) &gt;= a &amp;&amp; (a + b) &gt;= b)]]` will have the same effect.
FYI GN does spits CMakeLists too if you want. 
It can generate VS project files, XCode and qt creator (not sure about this one) files.
Note that my personal opinion is of course: don't standardize anything like this and just give a standard specification of shared libraries and C++ modules and C++ ABI that allows these use cases easily with package managers as so many other people mentioned. I'd much rather have metaclasses &amp; reflection as soon as possible, and happily continue to use graphic libs relevant to the domain of my apps - maybe Qt, but maybe sometimes raw vulkan, or maybe sometimes openframeworks or cinder. Graphics are cool, but in most other languages (java, python, etc), libraries build upon reflection to allow for instance to generate UIs automatically, and THAT'S the interesting part. That being said : &gt; From http://doc.qt.io/qt-5/classes.html, there are 1,594 classes in the Qt 5 API. From http://doc.qt.io/qt-5/functions.html, there are 12,984 functions. I don't know exactly how much committee time would be spent on each function, but I think 10 minutes per function, on average, seems optimistic. If we stick to our "regular" schedule at meetings of approximately six 12-hour days, it would take approximately 30 meetings to get through the entire API. We generally have three meetings per year. This seems completely impractical, and moreover, the library working group already has lots to do. I'm not saying to standardize the whole of Qt. Only the parts that would have to be re-made if there was to be graphics in the standard - so no need to port all the [modules](http://doc.qt.io/qt-5/modules-cpp.html), or the custom containers which predate the STL (QVector, QMap, QHash, etc), the SQL, D-bus, etc classes. An immense majority of Qt projects only use [QtCore](http://doc.qt.io/qt-5/qtcore-module.html) (which implements XML and networking, not relevant for graphics), [QtGui](http://doc.qt.io/qt-5/qtgui-module.html), the most relevant with support for windowing, painting, and event handling (what's the point in showing a window if you can't get an event when you click inside?), and either [QtWidgets](http://doc.qt.io/qt-5/qtwidgets-module.html) for traditional-looking desktop apps with all the usual button, lineedit, etc or the pair [QML](http://doc.qt.io/qt-5/qtqml-module.html) (which provides the base scripting language) and [QtQuick](http://doc.qt.io/qt-5/qtquick-module.html) (which provides a scene graph to use either from C++ or QML). The QML / QtQuick combination is much more closer conceptually to the webview proposal than QtWidgets. For instance here's an example of usage of the Qt API to show a QML window [from the Go language](https://github.com/go-qml/qml/blob/v1/examples/controls/gallery/gallery.go). As you can see, there's no need to reimplement 12k functions to get something to show up on screen, BUT there is a pre-existing path to extensibility for the day where someone actually need to do more stuff than just open a view. &gt; I'm sure that there are some aspects of Qt's current design that reflect a history of (primarily, I presume) targeting desktop applications, and changes would be desired to make things more natural for mobile platforms. And so on. Qt has been targetting mobile and embedded for years. Hell, there are entire mobile operating systems shells based on Qt (Jolla, Blackberry, [KDE Plasma Mobile](https://www.plasma-mobile.org/), Ubuntu's abandoned mobile initiative which still lives as [UBPorts](https://ubports.com)). Remember, it was once owned by Nokia which made multiple Qt-based phones... and that was almost ten years ago. Even [smartwatch operating systems use Qt](https://asteroidos.org/). If you have a LG fridge or TV, or a recent Mazda or Mercedes car, you're looking at embedded Qt UIs in your daily life. &gt; In short, I think that, even starting with a fairly-holistic preexisting API, such as Qt, what we ended up with would be obsolete before the document could be published. most of the Qt API (for instance Qt GUI) hasn't changed much since when it was introduced: here's the [QPainter class from 1998 for instance](https://github.com/KDE/qt1/blob/master/src/kernel/qpainter.h), versus the [2018 one](http://doc.qt.io/qt-5/qpainter.html). If it has solved problems for the last 20 years, chances are that it will be able to be useful for a few more years - in any case the Qt guys don't plan to change it for Qt 6 so it means at least 10 years of having QPainter be used successfully in projects. There's only so many ways to write a `drawRect` function. 
Another Google build system? What happened to bazel?
Hurray! By the way, can CMake output GN files?
&gt;It is not yet (?) another build system. Well Google itself also has bazel build, and let's not forget the myriad of other meta build systems like CMake, SCons, ... Tbh I dislike this practice of just piling on your own software because you suffer from the "not invented here" syndrome instead of improving existing tools for everybody.
and keeps crashing / freezing at every corner
The concept of "lightweight" software is interesting to me. People don't like heavy things, and that's understandable. However, when you add new features, the software will get heavier, inevitably. So keeping software "lightweight" either means that you keep it dumb and simple and refuse to add new features - or you just rewrite things every few years (which seems to be what people do). &gt; But I think for the most part we can agree it is like torture to work with CMake. Speak for yourself. Modern CMake can be used pretty smoothly and efficiently, if you know how. Granted they don't have very great tutorials that are publicly available, but they released a book recently.
Video Tutorial: [YouTube](https://youtu.be/u7JfatQdGs0)
I don't understand. OpenGL is bound to one thread only so the idea of a threaded renderer makes no sense. It's not an arbitrary blob of data either. You likely want to run the same shader program on all vertices of a mesh. I don't understand the idea of meshes having responsibilities, it is just data. Consider it as a logical group of similar vertices. Maybe just explain a better design if you don't like this design.
Since you can specify the compiler (using `CC`, `CXX` and `AR`), you should be able to wire in `ccache` or `sccache` I expect.
I've just put up the latest video. This one is a bit of long one (30mins), but i've got the basics of being able to call a native class method from Lua. So it's quite a bit of setup (and still requires more refactoring to support parameters and return value), but it is quite powerful in that it can call class methods on any registered type. [Embedding Lua in C++ #28 - Calling Class Methods Using Run Time Type Information](https://youtu.be/6mtVdtzGCAc)
Perhaps the compiler gets some kind of optmisation from the order of evaluation of function parameters being undefined, but I've never found any value to it. Microsoft &amp; Clang evaluate in the opposite order to each other. [https://ideone.com/TpdFI7](https://ideone.com/TpdFI7)
cringe
If you need a book for a build system, I think there's a problem.
No.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/90p7cm/easy_c_web_server/e2tvey2/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
`class` is the devil, use `struct`.
:C
you've got the list of all ABI breaking changes here: https://docs.microsoft.com/en-us/cpp/porting/visual-cpp-change-history-2003-2015 hint: there are a lot see also : https://msdn.microsoft.com/en-us/library/56h2zst2.aspx &gt; The decorated naming conventions have changed in various versions of Visual C++, and can also be different on different target architectures. To link correctly with source files created by using Visual C++, C and C++ DLLs and libraries should be compiled by using the same compiler toolset, flags, and target architecture.
&gt; But if you wanted a more educated opinion you can read this: &gt; &gt; https://gyp.gsrc.io/docs/GypVsCMake.md (GYP is predecessor to GN) This is wildly out-of-date (well it's from 2010. who the hell takes engineering decisions in 2018 based on 2010 mailing list posts ?!). &gt; Generation of a more 'normal' vcproj file. Gyp attempts, particularly on Windows, to generate vcprojs which resemble hand generated projects. In 2018 if you use CMake *you don't even need vcxprojs* since VS supports CMake natively. Same for Android Studio. Same for QtCreator. Same for CLion. Same for KDevelop. &gt; Abstraction on the level of project settings, rather than command line flags. In gyp's syntax you can add nearly any option present in a hand generated xcode/vcproj file. I frankly don't understand what they mean by this. &gt; Strong notion of module public/private interface. Gyp allows targets to publish a set of direct_dependent_settings, specifying things like include_dirs, defines, platforms specific settings, etc. This means that when module A depends on module B, it automatically acquires the right build settings without module A being filled with assumptions/knowledge of exactly how module B is built. Additionally, all of the transitive dependencies of module B are pulled in. This avoids their being a single top level view of the project, rather each gyp file expresses knowledge about its immediate neighbors. This keep local knowledge local. CMake effectively has a large shared global namespace. that's exactly how CMake works too. And it was already the case in CMake 2.8 which is contemporary of this mail (2010) : public / private flags, includes, etc... on targets already existed at the time : https://cmake.org/cmake/help/v2.8.12/cmake.html#command:target_include_directories &gt; Cross platform generation. CMake is not able to generate all project files on all platforms. For example xcode projects cannot be generated from windows (cmake uses mac specific libraries to do project generation). This means that for instance generating a tarball containing pregenerated projects for all platforms is hard with Cmake (requires distribution to several machine types). did they even read the cmake docs ? the cmake generated build files aren't made to be moved from one machine to another anyways, and that's by design &gt; Gyp has rudimentary cross compile support. Currently we've added enough functionality to gyp to support x86 -&gt; arm cross compiles. Last I checked this functionality wasn't present in cmake. (This occurred later). CMake had cross-compile support since 2.6 released in 2008.
If you're only have tiny toy projects, I agree. But with size and portability comes complexity. If your build systems helps to abstract things, it can actually save work. But first you need to know how. The notion that everything must be instantly obvious is a bit silly. I believe, it's a sign that your build system is overly simplistic and lacking in features.
If it's enough to build whole Chromium, I'm pretty sure it'll do.
GN has been around for several years and was designed to replace Chromium's original build system, Gyp. It's designed quite differently from Bazel, with more of a focus towards being cross-platform (remember, Bazel didn't even work on Windows for a long time) and fast (this *is* Chromium, after all). 
(copied from another comment I gave...) GN has been around for several years and was designed to replace Chromium's original build system, Gyp. It's designed quite differently from Bazel, with more of a focus towards being cross-platform (remember, Bazel didn't even work on Windows for a long time) and fast (this *is* Chromium, after all). Compared to CMake, GN barely has auto-configuration features. You must pass anything you want to configure explicitly. This is intentional; again, on a project Chromium's size, explicit configuration isn't a bad thing. 
Out of curiosity, where did you see all this? I've been following the project for ages, and I never knew...
I don't think it's really going for that right now. GN is more just trying to be rather basic and stay out of the way; e.g. it barely has auto-configuration features, since Chromium and Fuschia tend to have more controlled build environments and there's no reason therefore to spend time on detecting the C compiler and such. 
&gt;I'm not saying to standardize the whole of Qt. ... This is a good point. Qt has a lot of parts not related to user interaction (e.g., networking and filesystem functionality). Just scrolling through the function list, however, makes it appear to me that about half of the functions have to do with user interaction. &gt;pair [QML](http://doc.qt.io/qt-5/qtqml-module.html) (which provides the base scripting language) and [QtQuick](http://doc.qt.io/qt-5/qtquick-module.html) (which provides a scene graph to use either from C++ or QML). The QML / QtQuick combination is much more closer conceptually to the webview proposal than QtWidgets. Interesting point, but I'm not sure why standardizing something which looks like QML/QtQuick would be more useful than using web content. QML also uses JavaScript. Also, the discussion of "Quick Controls 1 vs. Quick Controls 2" ([http://doc.qt.io/qt-5/qtquickcontrols2-differences.html](http://doc.qt.io/qt-5/qtquickcontrols2-differences.html)) seems to be provide some non-trivial choices around desktop vs. mobile development. This could be a viable path for a standardization effort. It would, however, almost certainly invite design discussions around the API, the controls, etc. (because we can't hand that off to another standard, so we'd need to do that part ourselves), and we'd need a small-enough API surface for that to be practical. &gt;As you can see, there's no need to reimplement 12k functions to get something to show up on screen, BUT there is a pre-existing path to extensibility for the day where someone actually need to do more stuff than just open a view. I certainly agree that it doesn't require thousands of functions to display a window, draw a rectangle, and so on. However, in my experience, developing production applications requires a lot more than that. In short, I think that the day when we need more than opening a view is now. &gt;Qt has been targetting mobile and embedded for years. Point taken.
CMake is more general-purpose. It has a myriad of auto-configuration features, a powerful (though kinda bad IMO) build language, and support for tons of targets. GN isn't really going for all of that, or at least not to the same extent. It has virtually no auto-configuration features; there's no point in spending time detecting system characteristics if your build environments are going to mostly be controlled. The language is really nice but also intentionally not Turing-complete. There's an awesome integrated help system accessible from the command line via `gn help`. Ninja is intentionally the only target (**G**enerate **N**inja), and IDE support is all designed to still invoke Ninja. 
At the time GN was created, Bazel wasn't open-sourced yet, and even once it was, the Windows support was rather finnicky for a while. In addition, Bazel still has some major dependencies (the JVM, MSYS2) and platform restrictions (only 64-bit Windows is supported). This is all fine for Google's internal project build system, since the code is only ever going to be built on Google's already-prepared servers. For public projects like Fuschia, though, it's a bit subpar. As for CMake: http://www.reddit.com/r/cpp/comments/90vabm/-/e2u0xhf
I am a fan of stateless rendering. It's a perfect match for newer APIs like Vulkan and is still a really elegant design win elsewhere. Take a look at some of these http://gamedevs.org/uploads/firaxis-lore.pps https://blog.molecular-matters.com/2014/11/06/stateless-layered-multi-threaded-rendering-part-1/ http://realtimecollisiondetection.net/blog/?p=86
&gt; &gt; &gt; Interesting point, but I'm not sure why standardizing something which looks like QML/QtQuick would be more useful than using web content. QML also uses JavaScript. it's not that it would be more or less useful, but that the groundwork of "how do we exchange data both ways efficiently between a UI DSL and a C++ backend" is already done in Qt, much better than it is in web browser, since the first one is a library made to build C++ apps with in the first place. All this work would have to be re-done from scratch if using webviews. For instance, how do you add a button from C++ code to your web page at run-time ? In Qt / QML it would look like : auto b = new MyButton; my_page-&gt;addItem(b); b-&gt;setPosition(200, 300); // or whatever I'm not saying that it's the best API, but the API at least exists and is made possible because QML has been tailored for these use cases (being changed efficiently from C++). Good luck doing this with HTML / JS / CSS, especially if you want some performance out of it - Qt runs on [microcontrollers without GPUs for instance](http://blog.qt.io/blog/2018/05/03/qt-microncontrollers-mcu/). And, for the love of everything holy, don't standardize UI controls in C++. What's a good UI control today will be hated by designers in 5 years. Apps of 2018 don't look at all like apps of 2008, which don't look at all like apps of 1998. Just MS Windows has 4 or 5 different control sets, the "native" system ones (Win32), Windows Forms, WPF, WinRT. The last three ones aren't even C++-native, they primarily target C# and the windows runtime, yet they are the "official" platform ones. 
Sorry, I really should have linked to [Mana](https://github.com/hioa-cs/IncludeOS/tree/master/lib/mana), which is their web app framework.
Sorry, I should have linked to [Mana](https://github.com/hioa-cs/IncludeOS/tree/master/lib/mana), their web app framework. You do not have to use the whole of includeos, you can instead just use mana. Check out [this blog post](http://www.includeos.org/blog/2016/middleware-implementation-in-mana.html) which talks about Mana, and how they modelled it on express.js
You can also look at [acorn](https://github.com/hioa-cs/IncludeOS/tree/master/examples/acorn), which is an example showing how to use mana 
I disagree in this case, because of Chromium's scale and Google's quality of engineers. With competent engineers and huge yet specific use case, building something from scratch can make much more sense than adapting some other tool. It also makes a project simpler, because you don't need to fight with tools that aren't tailored for your use, and deal with complexity that you don't actually need - yet you have to get responsibility for and maintain.
GN is amazing. I moved all my projects from CMake and I couldn't be happier. No more string concatenation mess, every build flag can be accounted for. It's trivial to find out which file/config contributed the flag and where. The syntax is way cleaner and by design the build files can't get too messy. That said, there is a learning curve and because the toolchain definitions are part of project it can be tricky to adopt, unlike CMake where you can start by adding tiny file to a project. Still, in my opinion for non trivial projects it is in the end cleaner than CMake. I was not quite happy with the Xcode/MSVC projects generators though so I wrote a JSON project exporter patch for GN (which was accepted) and custom [JSON -&gt; MSVC and XCode](https://github.com/knopp/gn-project-generators) generators. Benefit being better indexing (i.e. taking different sub projects build flags into account), and possibility to compile single file in MSVC (ctrl + F7).
I'm big fan of GN as well. It just makes so much sense. The system of configs is day and night compared to mess of build flags string concatenation. Two years ago I migrated CMake based project to it and never looked back. The thought of having to make non trivial changes to those CMake scripts still gives me shivers.
For me, apart from being massively frustrated by CMake syntax it was mostly these two things: 1. For every compiled file each build flag can be traced to specific build file and section. The compiler/linker/etc flags are organized into configs that can be easily enabled/disabled for each target 2. The build is consistent on all platforms. While Xcode / MSVC still index the project, the build itself is done using ninja. We spent lot of effort keeping consistent results with CMake where the build itself was performed by xcodebuild/msvc, this all went away with GN. It's just ninja and python scripts.
It's nice to know that when the zombies come I'll still have some reading material...
Why not just do a find . -name "*.c" and then in visual code or whatever editor supports multi line cursors, add the root path? I recently had to move over a project (~50 .c files and ~100 headers) to cmake. Importing the files into cmae with the previous command took me maybe a minute, including scrolling through ensuring nothing bogus was thrown in.
&gt;OpenMP We're using it on ARM at work.. works fine so far. Haven't gone to production yet but passes a ton of tests on our product.
Let me define my terms. This project isn't quite a rendering library, I called it a rendering library because I don't have a better word to describe it. The library aims to provide fundamental primitives to allow building higher level designs. I have implemented this so far by raising the abstraction level with C++ templates and by allowing customization of behavior using a plugin architecture. Ideally you could implement stateless rendering on top of this library. I would argue that what you call "stateless rendering", is a domain specific problem. So when you look at the code and say "this library doesn't do stateless rendering!", you are correct. I wouldn't implement a specific stateless rendering technique but try to create a set of templates that would allow creation of your own command pipeline as an example. Understanding how the physics engine works would be a good example of how I would approach creating a command pipeline, but just to explain, the physics engine should work with any generic primitive and any combination of spatial database. I have proven this idea and it works quite well, although quite hard to visualize. As another example, I stated previously that meshes are triangles but that is **incorrect**. **Meshes are data**, described by the **vertex_type** template parameter on vertex_buffer, and can generically describe points, lines, triangles etc. So by extension this command queue would need to work generically through templates. I think that is more powerful than just creating a single implementation. That is the goal of this project, to generically describe useful abstractions. So when you say an abstraction is bad, you need be specific because likely functionality is defined by an input parameter rather than just the class name. 
Start with something simple and small. Try to do your stuff and when you find a recurring problem, then solve it and share your solution. &gt; The usual advise that people give is start something small; let me tell you something, it doesn't work How about stop trying and do it? Because let me tell you something, it works. If it doesn't, try again. Try again for *years* if that's what it takes. It took me that for instance. For example, I was trying making a small game engine for fun, and then I realize dependency injection was tedious to implement manually. I didn't found a satisfying solution online so I made my own. I shared the solution and I consider that project successful; it got users and I love the result, and it solve the problems that I had.
Ok, good point. I thought you guys had better tools in Linux land? I have assumed that qtcreator favors Linux
Sorry to answer late. Nowhere specific. Talking to maintainers for the most part 
lol not denying it, what are you using? 
We actually should probably add one extra constraint: `(a - b) &lt;= a`
And another vid. Refactoring the existing code that can call global/free functions (with parameters and return values) from Lua, and using it to call class member methods as well. [Embedding Lua in C++ #29 - Class Method Parameters Using Run Time Type Information](https://youtu.be/PPx6V9VrUOM)
Visual Studio at work, which makes me question its market share. QtCreator / Vim / Atom at home. IntelliJ was really nice for Haskell and Rust, so it's likely fine for C++ as well (or CLion or what it's called)
I only use `enum struct`. That is just to be consistent with the fact that I declare all my UDTs as `struct`. Never as `class`.
I once tried to slightly optimize a sorting algorithm and it eventually turned into a full-fledged library providing sorting algorithms stolen from everywhere and related tools. Over the course of its lifetime the main components changed several times, design decision were made to try to provide a consistent interface, it gathered more quality algorithms from everywhere and even includes algorithms reimplemented from research papers (not the most interesting ones though) and several small side projects have spawned to work more on specific components. The project eventually had a decent documentation, a testsuite with code coverage and contiguous integration. I wouldn't say the project is useful but it was useful for job interviews and I eventually contributed to the projects I stole code from when I had improvements. Thing is: it started small and is now big enough and rather stable, and while it's mostly useless I still managed to contribute a bit and gain some experience from it. Starting small does work.
MS C++ NOOOOOOOOOOOO
I moved from Java to C++ many years ago. Here is what i can tell you: * Don't be afraid of free/global functions. Use them whevever you can. [CppCon 2017: Klaus Iglberger “Free Your Functions!”](https://youtu.be/WLDT1lDOsb4) * Compilation Units (are not a problem in Java), in C++ you need to work out where to put your code just as much as what it is. * Cyclic Dependencies, avoid them, watch this [CppCon 2017: Charles L. Wilcox “The Three Layers of Headers A Curious Discovery”](https://www.youtube.com/watch?v=su9ittf-ozk) * Remember that you call "new" on everthing in Java, but in C++ this is a heap allocation and you should avoid it if you can. * Local Memory Allocators, are now something you can and should look into. [CppCon 2017: John Lakos “Local ('Arena') Memory Allocators (part 1 of 2)”](https://youtu.be/nZNd5FjSquk) * Build Systems are not standardised in C++, everyone has a different build system, nobody knows how they work. * Eventually somebody (maybe you) is going to trample some memory that you didn't intend to, get used to debugging that. * Macros, Macros, Macros, Macros, as far as the eye can see. They are both fantastic and evil at the same time. * long in java == 64-bits, in C++ it's "maybe" 64-bits * Learn Python, it will make you a better C++ programmer
Don't worry, most of it is commented out.
1,001 way to cool squirrel? And did someone noticed that creepy head on the upper shelf?
Been using for the better part of the year, got any question? Shoot away!
I don't know about that in general - with iterators any algorithm that doesn't allocate could work on a custom structure.
I'm _pretty_ sure I'd continue reading programming books even after the last computer was destroyed.
If they don't have to be in any order than you could set up 3 Boolean flags then make a loop to check each letter for a match. If they match turn the flag on. After the loop just check to see if all the flags are true.
I maintain a C++ oss library. I originally wrote it for myself but no longer use it. I am the main contributor but do accept contributions from others. What I like about it is I’m the owner and I make the choice on where the library goes. Of course I pay attention to what people want but sometimes you have to say no, and learning when is a good skill. In terms of motivation, sometimes it’s hard as I have a full time job I enjoy plus a long commute. Also have a wife :). So my free time to myself is less than it’s ever been. However I squeeze in bug fixes when I can but big changes are definitely more difficult to get done, and sometimes that feels bad because people are depending on you. Like others have said, you just have to start somewhere and keep improving. My library has several alternatives from other developers and I think that’s great, but most of them have stopped being developed while mine keeps chugging along, so I keep getting new users. Also add tests. Tests give your code high confidence and let others know your product is of good quality and can be safely used in their codebase. Trying to get as close as possible to 100% code coverage for libraries is a nice “achievement.” Lastly, have fun and write something for yourself. There are no hard fast rules for oss. In the end it’s your life and your free time, no ones paying you, so do you first :)
Since we here don't write programs for students, but the goal is to teach the students, here's some explanation how your solution should work: For each word: set the 'position' to 0 For each letter of your search sequence find it in the word starting from 'position' if the letter was not-found - skip the word remember the new 'position' + 1 (so that next search will continue from the next character) If reached end of the search and did not have a not-found error, take that word.
“Awesomeness in a jar”? Sure, maybe after the garbage collector gets its sh*t together. Smh.
I'm not talking about generating project files that then become out of sync. I'm talking about an IDE understanding GN files (maybe via a plug-in of sorts).
I remember someone on another thread this week also learned about this. What surprises and worries me is the number of people that don't know this. Perhaps compilers should at least warn about such usage in macros and outside of the std namespace.
For standard layout structs no pb -- it is actually mandated by the standard. But is the layout in other cases the same across different MSVC versions? 
The VC6 runtime you are thinking about is just a libc (and old, so non-compliant as hell, and missing tons of parts). It's even worse than that: MS has never recognized that it is usable by applications. Well, everybody did it anyway, so they will maintain it virtually forever in practice now. But in theory, nobody should link to it. 
yeah i tried to get into clion i get it, it's the same as pycharm and intellij and it's a good IDE I still have a problem with it, it just feel slow, not snappy, i hate that
Lmao 
Cook
Most of my OSS contributions have been to Python libraries, out of necessity. They got me 95% of the way, but just didn't make it over the hump. I remember one fix in the pysbase module - didn't handle nulls correctly in the back module. Was literally a one line fix to correct an uninitialized member. Still took like 2 or 3 months to solve it. Also did some work on odbcpp. Not sure that work ever made it to main. The work was for 64 bit compatibility on both windows and Linux. Another was a minor big fix in ACE in the high res timer for 64 bit. Again, out of necessity.
Yeah, that makes more sense
Lol
Signal connection/disconnection is relatively expensive, so if there was a way of avoiding it for single-shot “connections”, it’d be preferable. For timers specifically, a specialized method would be better — one that doesn’t use QTimer, but a thread-local object. 
Care to share the DI library you made?
Yeah of course! It's [kangaru](https://github.com/gracicot/kangaru).
Just in case humanity was restored to the point of computers 1000 years later
Nice le gem 
It's 5 min. WITH distribution. We use Sharpmake to generate FASTBuild files, and we are using distribution. Note that while Sharpmake doesn't have much public activity today, it has a lot of private activity; we are looking to put someone full-time on Sharpmake to make the Github repo always up-to-date.
Pretty much every big Ubisoft production is using FASTBuild and Sharpmake. A few were using FASTBuild without Sharpmake, but they are switching to Sharpmake.
There is no cache for these numbers, which have increased a bit since then. Using unity builds and have proper template code is the pretty much the main things.
IMHO, if using FASTBuild, I think it's better to use Sharpmake as well.
What does "not usable by applications" mean? Don't applications compiled with VC6 use it?
Good work! I have found this extension incredibly helpful. I have been using it for some time now and it feels like it is just getting better. Since you are here, I was wondering if there is currently a way to have different build directories for different kits, gcc or clang?
&gt; Don't use a hashmap to store sizes. Allocate 1 size_t worth of memory extra, and store the size in the first sizeof(size_t) bytes, and return the address of the byte following that. I thought the 1337 thing to do now was to have a bitmap in a block of memory allocated when you initialize your allocator so that the metadata is stored out-of-line. Did your deleted comment discuss that?
Really? Maybe you can do these: 1) Write a blog post about you experience with GN. 2) Contribute to their documentation. thanks 
First of all I'd recommend clarifying for yourself what your primary motivation to contribute to open source is. Is it just to having something looking good in your CV when applying for a new job, improving your development skills, or developing a product useful for other people? I'd say "starting small" is a good approach for junior developers who want to improve their development skills, or to professional (experienced) ones who cannot spend too much time and/or dedicate themselves to the development due to having a family (or any other personal circumstances). It can also be suitable for people who think having "open source contributor" in their resume adds them value on the job market. In case you want to develop a real product / library useful for other developers, you need to identify a problem or a business need, that requires a solution. Usually it's the problem you encounter in your job, and available solutions are inadequate (that's where you decide to "re-invent a square wheel" on the job and develop a solution from scratch as your personal project), or missing an essential feature (that's where you dive in to implement the required functionality and become a contributor). I also think it's a bad idea to choose OSS project based on its "coolness" instead something you personally are interested in. Once you decide to develop your personal product / library, the main thing you are going to need is **dedication**. I think, it should be like a pet (or even a child), i.e. if you don't have time to constantly look after and develop it, you shouldn't start it at all. Me personally, I have 1.5 hours a day of train commute time to work and back (sums up to 7-8 hours a week). I use this time to work on my personal projects. There is one more thing worth mentioning is the existence of so called "wicked design paradox". It states that any problem needs to be fixed / implemented **at least** once in order to clearly define it, and then (re)implemented again in order to create a **solution that works**. When encountering a problem in your day job you probably "re-invent a square wheel" in order to fix it. In many cases you won't be happy with the solution you provided and using your own words it will "scream a beginner from miles away". However, you won't have an opportunity to polish your solution or implement it properly, after you finally understood how it should look like at the end and how it should have been implemented. You can use this experience to implement something generic and useful for other developers. Besides, you won't have any restrictions on re-implementing it again and again until you reach the point that someone else will be "awestruck" when he/she sees it. For example, I'm the author of [COMMS library](https://github.com/arobenko/comms_champion#comms-library) which allows easy implementation of binary communication protocols. I started working on it 5 years ago and current state (which I'm personally happy with and quite useful for other developers) is my fourth or even fifth development iteration, which completely breaks backward-compatibility and changes inner architecture. The bottom line: Don't expect to create something awesome overnight. **Dedication** and **perseverance** should be your main friends. Many people like to quote [Thomas Edison](https://en.wikiquote.org/wiki/Thomas_Edison): "Genius: one percent inspiration and 99 percent perspiration." Hope it helps.
No I didn't address anything like that. The design that I had just a few bullet points on is the generalized description of the various allocators that I use at the day job for caching small(ish) memory allocations to save on having to call the system allocator for every single thing. We use atomic compare exchange for the fixed-sized free lists because our application is very jitter sensitive, and don't want to risk the blocking allocator suspending the thread.
I started doing the same for consistency sake. It can also improve readability when you have verbose return types written in Haskell style.
This is pretty wildly off topic for this sub.
Some of my best work is what I've open-sourced because I don't get a chance to do it at work so that's how I find the satisfaction of writing (what I consider) good software.
I know your project, and it's great, the question is, why would one want a whole shitload of different sorting algo's. One radix-sort and one other should/could do it all. Nice to be able to try many of them from one library with a consistent interface, though.
unit tests don't all pass.
There are two compilers shipped with RAD studio: "legacy" Borland complier with C++03 and clang 3.x with C++11. Just don't go in there if you don't have to. 
Thanks. That very question of why would you want it is why I consider it pretty much useless though :p
It's exactly written like "awesome-ness In-a Jar". Is it done this way to reflect pauses in middle of execution?
There probably are some tools that would solve the issue like perf or valgrind or even gdb but I would have to know them better to be sure.
There are two issues. First is that 'move' is really not the right name. Proper name should be 'movable', or 'yield'. Second is that such a fundamental construct should not be part of the library but of the core language. What should be proper syntax? Maybe a prefix operator ^x or postfix x! 
This not what 'move' means, because moved object can be still assigned to. Look at the lower implementation [here](https://stackoverflow.com/questions/25286544/how-does-the-standard-library-implement-stdswap). 
Just a bit of fun I thought.
the profilers on linux are awesome. * For memory you have heaptrack : https://www.kdab.com/heaptrack-v1-0-0-release/ * For perf: hotspot https://www.kdab.com/hotspot-gui-linux-perf-profiler/ * Qt Creator has integrated support for valgrind's callgrind / cachegrind tool but you can also use the great KCacheGrind : http://kcachegrind.sourceforge.net/html/Home.html The UI looks are not as good as VS's that's for sure. But the power of those tools is incredibly higher in my experience. 
&gt; Most of the time, I want overflow to be defined and to crash the application. That way, I can quickly and easily figure out if I have a bug and where it is. The minor performance improvement is worth it only in rare cases. In my experience, that won't help at all. Most of my overflow bugs were with unsigned overflow which is perfectly defined and legal... but still a logic bug if you're not in a hash function. Had very few signed overflow bugs in comparison.
r/cpp_questions ; also, indent your whole code with 4 spaces to have it show up correctly on reddit
That was very helpful but most often than not I have to look for inspirations outside of my day job because the code size of my work project is humongous (in millions of locs) and also most of those are black box to teams that are not working on that specific component. How do you go about that ? 
Game study lol
I have trouble grasping who is the user group for this feature...
You claim that this can be used for e.g. CUDA which I'd deem challenging especially as you don't provide examples. For a many-core (incl. CUDA) allocator look e.g. at https://github.com/ComputationalRadiationPhysics/mallocMC. It is used in production and hence well tested for (very) high performance code. One thing that I see your allocator fail is when used from inside CUDA (kernels). Copying your allocator data to the GPU, especially with the hash table, PIMPL etc, is expensive and hard (even with unified memory) Summary: Have a couple of real-world examples and use-cases where you'd like your allocator to be used and maybe some where it might not. Especially back your claim of usability with CUDA with an example. On the implementation: Without blocking, I'm pretty sure you'll run out of memory pretty fast. You call the allocator with every size requested and basically never free that memory. If an application requests lots of big memory chunks first, then frees them and then lot's of small memory you'll be out-of-memory very soon. So what I'd like to see would be: a) Reusing of allocated memory of different sizes b) Blocked allocations (allocate a bigger chunk once, the serve multiple chunks from there c) Don't allocate every odd-size (multiple mallocs of 7 bytes anyone?) Can be solved together with a) and b)
The move operation is part of the core language, but the core language syntax required to invoke it (in some scenarios) is complicated. `std::move` is a library addition that provides syntactic sugar. You could modify a program to use more verbose syntax instead of `std::move` without changing the program's behaviour. The idea of adding simpler syntax for a move is fine, I was just responding to the bogus claim that moving is not in the core language. 
Whenever you find yourself saying "do X, and then wait for Y, and then do Z, and then wait for A, then do B, and then wait for C, etc", where "wait" involves yielding control back to the system until some condition is met, that situation is ripe for conversion to a coroutine. Instead of writing a state machine, with a state subclass for each of X, Y, Z, A, B, C and so on, you can write a single coroutine function that reads like natural code, where the internal state is encapsulated in the coroutine and automatically managed for you behind the scenes. As the article points out, this kind of situation is very common in UI-based things, where you're waiting for the user to do one thing, then another thing, then another thing, etc. It's also really common in game programming, for the same reasons.
You’ll be the next Bill Gates.. right? 
Why? It has the word "C++" on it.
Interesting. It would be nice if the project page started with some kind of explanation of its goals and primary audience. My only specific feedback: Why header-only? This will make it slow to compile and makes the headers hard to read, especially since they seem to be the only API documentation there is. Given the heavy work done by the GL driver in each function call anyway, I do not quite see the point.
So like Visual Studio.
After Visual Studio/SQL server/Windows SDK you need new computer :D Never got clean computer afterwards without reinstalling system :(
Well, anyone who would use P0709 *Zero overhead deterministic exceptions* if standardised! https://wg21.link/P0709
Not trying to bash the article, but isn't it kinda a given that operations with `std::string_view` which don't require deep copies will be considerably faster than those with `std::string` which do require deep copies? That's basically why `std::string_view` exists.
&gt; How about stop trying and do it? Because let me tell you something, it works. If it doesn't, try again. Try again for years if that's what it takes. There's no trick to it. It's just a simple trick!
It sounds a bit like "chicken and an egg" problem. In order to create something worthwhile you need to have certain level of expertise and/or proficiency is a particular subject. Looking for inspirations outside usually means you haven't gained the expertise yet, that you are still looking. It's difficult to recommend something without knowing you and/or your circumstances. Try focusing on a solution to a particular problem instead of size of the code and interdependencies between various components. Do you see any particular logic that you wish you had an independent third party library that solves your problem? It could be a good place to start. If you don't like what you do in your job and looking for subject that might interest you (and you don't know what it is yet), then keep looking. In **my personal experience**, employers don't pay significant attention to what's going on in your github profile, unless it is big and valuable (for the employer) project you developed mostly yourself. Few people will have time and interest to look over your patches and/or contributions to other projects in order to evaluate your coding skills. I'd say having multiple forks of various projects in your profile just shows "lack of focus" rather than multiple interests (IMHO).
Wow, returning a reference is faster than copying. Who would've thought...
My bad, the files are actually listed, they are in a collapsed directory entry in the tree. But due to the way it is indented, I completely overlooked it. Keep up the good work!
Read the file in as one string and then use std::string\_view instead of string (when you are just splitting and reading from the string). This should speed up things significantly.
I'm definitely not an expert in cmake, but I had a similar issue before, try to add link\_directories(${BOOST\_LIBRARYDIR})
Exactly. `std::string_view` was designed to optimize cases in which the ownership semantics of `std::string` are simply not needed. Of course that makes things faster, that's the nature of optimizations.
Just to put in a good word for this post, I think an interesting point is showing that the compiler is able to do optimizations that could eclipse string_view a bit when static strings are involved (and it other situations that the article is not presenting). To give you a bit of context, a few days ago, Bartek commented [my article](https://marcoarena.wordpress.com/2017/01/03/string_view-odi-et-amo/) reporting he did not expect that string outperforms string_view. The problem was that the split was on small and fixed strings. Then I suggested him to split over a long and dynamically (e.g. random, from file) generated string. Doing so, he finally got more sensible results and he decided to share this experience through a blog post.
Enable the optimizer.
even with enabled optimizer the d version is faster
Everyone who wants sensible error handling in C?
Not quite sure if this really solves the problem doesn't this just shift my problem to become a memory problem on huge files?
Joel will be like "What... the hell... is C++?" 
The people here making snippy comments about the value of this article have clearly never had to convince their management that a major refactoring is worth the labor-hours for the scale in performance improvement that it will deliver. Benchmarks have value, even if the result matches what you intuitively expected.
C++ keeps on surprising us all.
Passion and Perseverance, in that order. On average, interacting with open source projects is pretty high friction. When I worked at Ubuntu on the commercial side of things I got so side tracked and irritated with the ceremony of "getting my patch in" that I would literally hand it off to a colleague who already had the community street cred to push it upstream. I didn't care about the credit, I just want to solve the problem and move on. The best open source projects to contribute to are the ones you own. Working in your spare time, after work is a hobby by definition. If you're not passionate about your hobby it's going to languish. For me, excelling at my hobbies starts with staying organized so I can put a few hours in and get some satisfying results. My 2 cents. Forget about open source. Do it because you want to do it for your own satisfaction or personal growth. If others find it useful, that's great too. Eventually you'll stumble over the idea that you're really passionate about and that will blossom into notable "open source" project.
Since most of the classes are templates, you can use **extern template class** to separate compilation into an external library and link normally if that is what you want to do. In my opinion separating C++ classes into a .h and .cpp file leads to an exponential increase in complexity. The library does more than just calling GL functions. In fact calling GL functions isn't even 25% of what the code does. Most is 3D math and collision detection.
Was that with plain make though or CMake generated Makefiles?
haha yes! Thanks for that: I think my fingers went ahead of my brain on that one.
&gt; ain. The only way build systems get robust to that is to bump into enough of the weirdnesses that they end up not having assumptions that are too stric If only. I would love to be that strict. It's a hard sell to management though saying "sure we could ship the feature quickly using this library but we don't like the build system so no dice". Also, unfortunately no build system stops its users from being "clever". Every dev and his dog seems to (a) not read the docs and (b) think they know better anyway and so goes and does something awfully clever (rather than using the standard mechanisms). The end result is that a simple cross compile is 2 days of work. I don't think meson or anything can fix that :(
The way you have programmed this you have the whole file in memory anyways so I don't see a problem here. For split operations string\_view is just so much more efficient than generating a new string for each split. The downside is that the string you want to split can't be temporary that's why I was suggesting to load the whole file at once. Btw. there is also a very easy fix in your code to improve performance: &gt; for(auto rep: columns) This will create a copy a vector&lt;string&gt;, you should really add the reference here &gt; for(auto&amp; rep: columns)
The article shows that they aren't always faster. Also `std::string` does not always require deep copies. I think benchmarks between `string` and `string_view` are very useful, not everyone immediately converts their code to new C++17 goodies, people want to know how much they can gain.
&gt; The move operation is part of the core language I don't understand that. I think that &amp;&amp;-types are part of the core language, but std::move is not. I think that C++ has no move operation at all in its core language. There is only the fact that in certain cases an expression automatically binds to a &amp;&amp;-type. (temporaries and returns of variables.) It is hard to find a name for std::move that covers all uses. 
Yeah it doesn't always require deep copies, but for the substr test... I think we knew what would happen there. But yeah it's still good to have tests to see exactly what happens and the real performance differences.
Almost every project I've worked on is some combination of C, C++, and sometimes other languages as well. I welcome anything that helps these languages interoperate better.
C++'s IO is notoriously crap. Relevent: [https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python](https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python)
I'm not sure of the details, but it might be that they were supposed to ship their own .dll side by side, or something like that. Instead there was a period on old Windows (like 9x) where the system .dll was sometimes overwritten by newish versions and used from there. Maybe exactly VC6 was supposed to use the very first version of it shipping with Windows, and the next are retro-compatible, but it was certainly not planned by MS that application took a dependency on new symbols in the next version of the system .dll, and even less that some installers replace the system .dll. Well, they did it anyway, so the "don't use it" is very much theoretical for Win32 programs at this point, and MS probably will maintain it forever (and given the number of programs built with MinGW, they better have to). I guess it does not exist or is not usable for Arm builds or UWP programs though.
You're mistaken about the core language issue. If you post any code you like using `std::move` then I will show how `std::move(x)` can be replaced by a core language expression with the exact same meaning.
Good point. Although the "scale of performance" that you expect based on these benchmarks might not match the results that you end up getting. Plus the use of string_view requires careful evaluation. In somes cases (e.g. when storing the string_view or constructing it from a temporary string) it might cause subtle bugs that are hard to find and eliminate. Don't get me wrong it's always a great idea to modernize your code base; especially in this case where it avoids unnecessary overhead. Sadly, economically speaking, it often makes little sense to rewrite wast parts of the code base for what is eventually an unknown performance result. But if these benchmarks helps to convince your management about the importance of using new C++ features: great!
1. /r/cpp_questions 2. -ENOMEASURE: there's no timing information here. Measure. 3. as /u/konanTheBarbar noticed, `for (auto rep: columns)` creates a copy of a vector of strings on every iteration. Use a const reference. (This is probably the problem, but again no measurement.) 4. Really, just use awk. The development time to speed ratio is good.
changing it to reference of the vector did some improvement but didn't get it near the D version. I only read the first file at whole. the second is read by line and so i shouldn't have the whole file in memory.
That's exactly right. And it can work the other way as well: A developer who's convinced that they need to replace every `std::string` with `std::string_view` because it will be *so much faster* might change their tune if benchmarks show that it won't pay off as much as they expected, and that it's not actually worth the time and effort to replace.
I use it to cast member function pointers to void* as described by Sergey Alexandrovich Kryukov https://www.codeproject.com/Articles/1170503/The-Impossibly-Fast-Cplusplus-Delegates-Fixed
SYCL? Never heard of it. Seems very interesting!
It *should* be always faster. If it isn't, there's a problem. Fortunately the problem is identified in the comments. Apparently `std::find_first_of` is significantly faster then both `std::string::find_first_of` and `std::string_view::find_first_of`, *at least for this particular string*. The author has used `std::find_first_of` for strings but `std::string_view::find_first_of` for string views, hence the counterintuitive result.
I don't get why the bit it tagged volatile, and I'm not sure that having a structure automatically named like the function is the best idea (it risk to prevent the ability to, standardly or by compiler extension, compile some select piece of C source code with a C++ compiler, which is something that is for now somewhat possible if we limit to a subset of both languages, but this would probably put that ABI feature out of reach of that source level subset, or induce potential additional risk on the C++ side if not the case) Also I'm not sure what the "Testing for error returns" chapter is trying to say: testing the bit ASAP at source level is not extremely well-defined, and the rational given of it being because the big is in a flag of the CPU that can be overwritten makes no sense (maybe except for very old/simple compilers), because that is the job of the compiler to know it and to save it if he needs. And the example does not seem to use the feature anyway. Now thinking about it that might be the reason for which the bit is "volatile", although this is completely at odd with modern compiler technology. Well, this could maybe work, but by unnecessarily constraining the source code by requesting that the bit is used before the next sequence point, and this constraint would be completely arbitrary in modern compilers and would not really prevent them from doing the hard work. Maybe this is interesting in other compilers, for example some very simple ones for microcontrollers (given even microcontrollers benefit greatly from having a good compiler using a modern approach for e.g. register alloc, CSE, etc., I'm not even sure). Also what will happen if trying to access the bit from a point where it has been invalidated? I hope the program won't compile, because stating it would be UB would be criminal. Also "The user can request that this feature should be turned off." is curious too. I can't make sense of the proposed behavior when it is turned off (and it is not very well-defined anyway).
Good point! string\_view looks like a magical wand that makes code super fast... but it's not that easy. You get some "default" perf boost, but you have to be careful with all of its caveats. What's more the performance might sometimes be slower if used wrong - as the article presents. As always: measure, measure, measure.
it's quite surprising as one may think that a member function of string\_view should be faster than the generic STL algorithm. And it also depends on the implementation, so each STL version might give different results.
Do people really use lots of substring operations on std::string in performance sensitive code?
Have you tried using the ranges-v3 library?
I suppose it will be a kind of cast.
No…i also wanted to have the code more or less the same in both c++ and D.
It should be up to the compiler to take care of the carry flag and make sure it doesn't interfere with further calculations. After all, C++ has no notion of a carry flag.
We hit alignment issues backward compatibility at work. One of our engineers had 2017 15.8 (preview) installed, while the rest were on 2017 15.7. We also pre-compile some open source libraries, and we've hit a problem due to alignment. More info here: https://developercommunity.visualstudio.com/comments/279328/view.html To quote: (Casey Carter from Microsoft): &gt; When you compile this program in preview 3 with /std:c++17, you'll get a static_assert informing you that the the "traditional" behavior of aligned_storage with extended alignments has been fixed, asking you to define either _DISABLE_EXTENDED_ALIGNED_STORAGE to get the broken behavior back, or _ENABLE_EXTENDED_ALIGNED_STORAGE to get conforming behavior. We can't enable the fix unconditionally, since it potentially breaks ABI if you need to link against libraries whose structure sizes and alignment depend on the previous erroneous behavior. Then someone asked question: &gt; Hope the static_assert and the macro mechanisms will not be present when 15.8 becomes regular. i.e. when 15.8 is released, we will not need to define _ENABLE_EXTENDED_ALIGNED_STORAGE to get correct behaviour. Would you please confirm? And the answer was that it would be ABI breaking change (from Casey again): &gt; Unfortunately, no. Despite being a conformance fix, the change is ABI breaking. We'll leave the macro machinery in place until the next ABI breaking release of the libraries to allow users to choose whether they prefer ABI stability for their misaligned over-aligned types, or proper alignment. (Yes, this seems silly - but every bugfix breaks someone (https://xkcd.com/1172/ )). 
e.g. We were assuming that having pre-compiled version (compiled with) vs2015 would work, and although we've precompiled a lot of the m with vs2017 once we moved to it, there in the vs2017 compilers themselves seems to be (future) ABI incompatibility. This sucks, as we have to switch at once. Also the bug we had did not manifest clearly - since it was due to struct alignment (code from pre-compiled lib would see it one way, while from newly compiled code another). 
Sure, but once you remove the UB around it, you unfairly limit the ability for other processors to compete. This would be a situation where an entire class of optimizations (carrying flags through for logic) is illegal on some processors. The C++ committee is VERY reluctant to 'bless' certain implementations that much. In fact, the Two's Complement decision only succeeded because no one actually uses the alternatives anymore.
`std::string_view::find_first_of` is `constexpr`, `std::find_first_of` is not – the `constexpr` requirement likely prevents use of SIMD and/or intrinsics and runtime suffers as a result.
I don't make management decisions based on intuitions and what I think should or shouldn't happen. I make management decisions based on evidence. Providing actual data showing how much of an improvement one approach has versus another informs my decision making as to whether it's worth it to convert uses of `std::string` to `std::string_view`. If it's a tiny improvement because most strings are on the other of 10-20 characters (small enough to use SSO), then it's not worth it to change our coding conventions and adopt the practices needed to avoid the various pitfalls that `std::string_view` introduces. If it improves performance by an order of magnitude, then it does become worth it at that point. In my particular case doing benchmarks on a subset of my codebase, I have not found that replacing `const std::string&amp;` with `std::string_view` resulted in any noticeable difference. Now that's a completely different situation than the one the article presents... but there's also been promotion among C++ "thought leaders" that all codebases should switch from `const std::string&amp;` to `std::string` simply on ideological grounds. Having data is always beneficial, even if that data simply confirms what you already suspect, strengthening your beliefs on the basis of sound, reproducible evidence is always better than maintaining beliefs on the basis of suspicions and intuitions.
&gt; but there's also been promotion among C++ "thought leaders" that all codebases should switch from `const std::string&amp;` to `std::string` simply on ideological grounds. Citation needed; this sounds like nonsense.
oh boy
Putting something complex like this into the standard is asking for too much non-comformance. Just talk to the millions of Windows devs who had compatibility issues with every OS release with the Win32 GUI, and that's controlled by one company. Now throw in 4 major GUI platforms (Mac, Windows, Linux [x11, wayland]) and at least 3 major compilers (Microsoft, clang, gcc) and that's just the problem with hitting the majors. Now imagine all the smaller platforms (QNX, BSD, etc). This really shouldn't be part of the standard - it's TOO platform specific. Threading was a stretch, but 15 years ago it was difficult to get thread semantics on a lot of platforms. Now even Arduinos have threading. If framebuffer support becomes consistent on all platforms in the next 10 years, maybe I could get on board with something that gives direct access to the FB, but building a windowing system, especially one build on a browser, I think is asking for nightmares you don't want. I'm happy using Qt. If I wasn't maybe wxWidgets would be an option. I've used it many years ago and had decent success. I can only imagine it's gotten better over the years. 
&gt; I think what you meant was "Graphics is not going to be commonly used, whereas insert proposal here is going to have an effect on almost all projects out there, so why aren't we working on those things?", but I had some difficulty parsing your sentence. Yes. Threading/co-routines, lambdas, etc. May not be used by all programs, but are tiny in scope (comparatively), have dependencies that can be easily understood, and are often single vendor sourced (windows threads, pthreads, etc.). So yes, the TRs of the past that have made it into the standards have been limited in complexity, but wide in coverage of platforms. Not all platforms have threading, but most can use coroutines/lambdas, for example. This is a proposal that does seem simple on the surface but hides its complexity in third party products which bring their own ever-changing issues (Chrome obsoleting features, for example). 
Wrong thread, pal. 
Can't speak for the others, but I can vouch for Caffe. If all you need to do is run inference, then caffe should be fine. The important thing IMO is to be careful about data formats. For example, convnets are usually trained with 4d batches of data that follow a specific format, such as 'channels first' or 'channels last'. During inference, your input data must follow exactly this format. Also, must networks during training perform some preprocessing of data (mean subtraction, etc). You must remember to apply he exact transformations during inference.
Interesting proposal. Good: I like that things are quite explicit - it shows exactly what is happening. The syntax is quite minimal. Bad: &gt; The calling function must test right after the call the state of the error bit This seems error prone. It will be easy to overwrite the carry bit. One possible fix is the compiler must issue a warning whenever the carry bit is not tested immediately on function return. However, this seems the perfect opportunity to introduce `_try / _catch exception handling into C, with the compiler taking are of the failure bit testing. Maybe that can be proposed in a separate paper? &gt; if (doSum(data)/23 &lt; threshold) { } //WRONG If doSum can return an exception, the value returned could be invalid (or even worst, it could be an error code!) and should never be used in further calculations. But this is already the case in current code that tests for a status return, so this is not a real problem. But it is a problem. No one will write `if (doSum(data)/23 &lt; threshold)` if `doSum` returns a status code, since the return value will be the status code and not the result of the function. But they will write such code in case doSum does actually return the result, and overwrite the carry bit. &gt; To discriminate between integers and pointers we require that all pointers must point to data aligned at an even address, and that all error codes should be odd. We use then, the least significant bit of the error to discriminate... This seems superfluous. Is it necessary for a function to return both an error code and a pointer? Why not encode what a function will return in its declaration - _Exception* double process(double *data); // returns a pointer on error _Exception double process(double *data); // returns an error code on error or some other syntax. Then the compiler will know statically what the function returns and wouldn't need to test the LSB at runtime, saving a few instructions. Bikeshedding: Instead of if (buffer == NULL) { fn.error = ERROR_NOMEMORY; // Set the error member return _Exception; // Set the "failed" bit } why not: if (buffer == NULL) return _Exception(ERROR_NOMEMORY); 
There is not yet, but that is a common feature request.
Thanks for the advice, I will look into it
I don't have a lot of experience with it, but imho ranges would make the code more similar to D than it is now. That being said: what do you mean by `more or less the same in both c++ and D` and why!
tiny-dnn. header only.... and you can import cafe models. [https://github.com/tiny-dnn/tiny-dnn](https://github.com/tiny-dnn/tiny-dnn)
Thank you for the reply, I will look into it
Pst, `than` not `then`. Then, like `if then`, is a causal relationship / is a relationship in time. Than, is like a comparison operator. Eg, a Ferrari is better than a Mazda. Eg, if Bell eats the cake, then she will be full. Eg, Bell jumped on the trampoline then opened presents.
I use tensorflow c++ api to do inference in c++. It's not perfect but it works quite well. 
From what I was able to understand from their GitHub page twnsorflow does not build in Windows...am I wrong?
You can! I used it in Linux and Windows machines. 
Wow that is really good to know, I will look into it again, thank you
What I really find `string_view` (or `array_view`) useful for is in *parsing*. Rather than awkwardly manipulating indices around, it's easier to just pop characters/bytes off the head of your container. With `std::string` or `std::vector`, the performance is disastrous... but with `string_view` or `array_view` it's just a regular pointer increment!
 union member_pointer_cast { void (Child::*member_pointer)(void); void* void_pointer[2]; } naughty; naughty.member_pointer = &amp;Obj::print; void (*c_callback)(void*) = (void (*)(void*))naughty.void_pointer[0];
In addition to the mentioned tiny-dnn and tensorflow there is * [Dlib-ml: A Machine Learning Toolkit](http://dlib.net/ml.html) * [frugally-deep](https://github.com/Dobiasd/frugally-deep) Use Keras models in C++ with ease
The frugally-deep looks amazing! I will look into it, sounds like exactly what I was looking for!
It may not be perfect, but it's very robust and has gotten much simpler over time.
In this case just because the D version is what came to my minde without any hard thoughts. I think it's easy to understand and after it took quite long for the first bigger files (about 4 seconds for a 20 line hosts file and a 6,8 mb iptables log file) i thought maybe a c++ version is faster ( also because at work we mostly use c++) but after i saw that the c++ version is even slower i was curiouse what needs to be done to get the same speed and if this version is still readable
It's not wrong, because the pointer that is being dereferenced also wraps, once you reach the end of the address space. Whether it is the offset wrapping or the pointer itself makes no difference, so the compiler can ignore it in either case. You can try this yourself on godbolt; not only do compilers ignore any possible wrapping behaviour in generated code for 64-bit offsets (assuming a 64-bit pointer of course), but in some situations it will actually generate better code than when assuming UB on signed integers. 
My point is that you most likely get faster and easier to read code if you use a proper library. The c++ standard library sucks compared to most other languages but you have a lot of great open source libraries at your disposal - use them!
Generally the standard library won't use SIMD intrinsics, but leave it to the optimiser to figure that out. It would be hard to maintain for all targets (even within x86), would not respond to flags (e.g. -Os), and the optimiser can typically do a better job anyway, e.g. statically determining string contents, loop counts etc. You can verify this by looking at -00 vs -O3 in godbolt, or the source code, e.g. https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/bits/stl_algo.h Indeed as speculated in the comments on the blog, the string/sv versions end up with an non-inline call to memchr, so that might be the problem: https://godbolt.org/g/kLVSTJ
It's not that I find string_view not useful - far from it. I'm saying that I expected most code shops to already do something far more efficient than using std::string::substr in their performance critical code (like using their home-grown string view type). Performace of std::string::substr not something I usually care much about but I was curious if production code in other companies looks differently.
Usually I choose one form or the other based on whether I was able to use all *RAII* supporting types. If I'm reduced to creating custom wrappers around things that are not, e.g. C libraries like sqlite, the single return using `do { ... } while(false);` (who, me *goto*?) is usually where I'll default.
\[Sane\] Unicode and UTF-8 support would probably be required for this to be useful.
The fact that the ternary version would not be optimized further is a testament to how bad the C++ compilers are at applying simple transformations and deduction. Frankly, I expected better asm to be generated out of that.
I know. I'm making a lot of spelling mistakes lately, in every language I speak :( I'm getting old and my memory isn't what it used to... wait, what we were talking about?
&gt; the constexpr requirement prevents use of intrinsics Why would it? 
Are there any advantages to use `do { ... } while(false);` rather than `goto`? 
yes, parsing and trimming fields in json dor example
Using while will make it easier to see where the end is as ut will be at the end is and it will also be very easy to see where you could have came from at the end. With a goto you can go anywhere and have jumped from anywhere.
I wouldn't use std::string::substr for that
This is certainly not universally true, but often, when the compiler fails to perform some obvious and basic optimizations it is because the c++ language standard doesn't allow it to. C++ gives you a lot of low level control, but this in turn greatly restricts what the compiler can do without extensive program analysis.
That this is an thing makes me sad
intrinsics aren't constexpr. You can't write a constexpr strlen or memcpy which uses SSE instructions for instance.
Due to the hilarious number of upvotes, we're going to permit this fun for now, but this is not a general change in policy - future image posts will be removed (unless they are informative).
Why are you using glew instead of glLoadGen or GLAD? Glew adds a dependency and is less selective on what it provides. Also, it's imo kinda hard to grasp the scope and intended usage of this project - extra confusion ensues when I read "minimalistic rendering lib" and then see libvorbis etc listed as dependencies. I think this lib is a bit to broad and vague for people to be enticed to use it. My two cents
I'm not convinced that the lesson here is necessarily about single vs multiple returns, but that we should be using `std::string_literals` more.
Yes, i totally misread your question
I literally only use libvorbisfile to read OGG files... I initially bundled GLEW into the library, but the Linux people bitched about not using the system GLEW so I removed it. I thought I would see what /r/cpp thought and obviously the total reverse of the Linux people. I use this library for my own open source game. That is it's purpose. I just thought I would share what I did in case anyone could give me some ideas to improve. 
GLAD seems kind of interesting, I will play around and see if I can get it to work.
It's just composition pattern.
&gt;With a goto you can go anywhere and have jumped from anywhere. Not really? You can only come from `goto` statements and you can only jump to labels.
It is missing an open source compiler. But basically it is OpenCL done in modern C++ way. There are some issues they need to work on. But mainly, we need an open source implementation.
You can have way more fun by implementing it with the hashlife algorithm. That's not common to see exponential speedup. It's like going in hyper-speed!
But that goto statement and label can be anywhere within the function. With the while you only need to look for the break within the while "loop" and to find where you go from a break you only need to find the end of the "loop". 
Awesome. I'll try that
I have written recursive descent parser with std::string\_view and analyze its performance against traditional iterator pair approach using valgrind. Turns out, string\_view didn't perform well as I expected. First noticeable problem was its representation. Many of its operation access memory via base address + index, that make it harder to optimize than traditional iterator (pointer) based implementation. Second problem was its use of SIMD intrinsic. Iirc it was a comparison operation. I noticed many instances that naive loop outperform SIMD operation. It wasn't make sense to me so I google, and I found Linux kernel folks talking about naive loop outperform SIMD situation. According to them if string is short enough naive loop outperform. They are talking about path string and I am not but I also dealing with not-so-long string. In the end I settle using string\_view for interface, iterator pair for actual parsing. 
With a do { } while (false); block, you can be guaranteed that you will never revisit the statements you have executed. Using goto, you can pretty much jump where you want.
Problem is: Benchmarking individual operations will not tell you how much faster your application will run when you refactor it. 
Nothing is preventing a compiler writer from making those intrinsics constexpr
&gt; Want speed? Pass by value! Sounds familiar? Although the "hype" dimmed down a bit.
Yes, it does, though [the actual article](https://web.archive.org/web/20140205194657/http://cpp-next.com/archive/2009/08/want-speed-pass-by-value/) only pertains to function parameters that you would have made a copy of anyway, which is neither hype nor the same as "pass everything by value everywhere".
&gt; nor the same as "pass everything by value everywhere". No one suggested that. And no matter what the article said, it was a bit of a hype (that is always the problem with catchy slogans). I got suprisingo many review comments that said "you should pass that by value" where it made absolutely no sense (e.g. remember Herb's talk at cppcon where he showed how it can pessimize setter-type functions)
The google build system of the week. Next week something totally different that all the projects will migrate to.
As soon as the user-created documentation catches up to one of their projects, they change the build system so all the docs are wrong again.
Did you even read or google the project? It seems not! :)))) Google uses this project to compile chrome (which is way bigger than almost all projects most of us has worked on) at least for past 3,4 years.
I'm not sure it's that simple. Most implementations of library functions are set up with a runtime detection of the host CPU. e.g. if you have an AVX2 cpu, you'll get an AVX2 memcpy, and if you have a SSE4 cpu, you'll get a SSE4 memcpy. Having the intrinsincs be constexpr wouldn't help for this.
Shameless SPAM: If you like frugally-deep, take a look at [pocket-tensor](https://github.com/GValiente/pocket-tensor).
Yes, and I had to start using that when they switched v8 to it somewhat recently. Before that it was some other proprietary google build system. 
Interesting read and no doubt could be used in specific situations. I slightly fail to see the reason, though, to go through such lengths for things like AI behavior and RPG battle system calculations, which are usually just done purely on the Lua side and kept away from C++. 
You can't just write naive code that does lots of memory allocations (and your C++ code does *a lot* of allocations) in a deterministic memory language like C++, and expect it to perform as well as a GC'ed language like D (or Java). GC'ed languages have the luxury of being smarter; they can grab more memory than they really need up front, re-use memory, etc. In C++ you have to handle this manually. Returning and even storing that vector&lt;string&gt; is pretty terrible for your programs performance. You can pass the index already at that point, and return and store a single string, which is far more efficient. Probably the best though is to iterate over both files simultaneously. Pass both lines, both column numbers, and the output handle into a function. The function writes up to the replaced column, then the replacing column, and then the rest of it, into the output file handle. In this way, you are never doing redundant copies or heap allocations in memory. It's not the most elegant but the main point of C++ is to faciliate tightly controlled, performant designs, as elegantly as possible... not to faciliate the most elegant, reasonably performant designs (that may be closer to D's stated objectives).
Does Microsoft even support this anymore?
proprietary? :))))
Sure, but it's better than guessing from your intuition? You can at least do a benchmark on some segment of your code base before committing to a complete refactor.
&gt; However, this seems the perfect opportunity to introduce &gt; _try / _catch &gt; exception handling into C, with the compiler taking care of the failure bit testing. Maybe that can be proposed in a separate paper? WG14 have indicated no wish to implement auto-propagation of failures. 
It's missing in the default installation for Visual C++ 2017. You can enable it. Looks to me like Microsoft is embracing standard C++ now.
However its still incredibly useful and if you pay for the whole jetbrains suite you get it regardless.
That issue is completely orthogonal to the question of constexpr. Irrespective of how the intrinsic is implemented at runtime, the compiler knows at compile-time what the semantics of that intrinsic is and hence can evaluate it at compile-time.
shouldn't the suggeste change from `for(auto rep: columns)`to `for(const auto&amp; rep: colums)` trustical reduce the allocations?
Those aren't benchmarks from some segment of my code though. They are Microbenchmarks that test individual operations. And yes, they can be valuable in very particular situations e.g. when you have to decide whether you should use method A or B to implement a particular functionality. Or they might be valuable to point to the STL provider that some of his functions are unnecessarily slow. Unless you have already verified that those exact operations are a bottleneck in your application, they won't tell you anything about whether or not it is "worth" to refactor your code from a performace perspective.
You'd hope that by then Security by Obscurity would have died out, but...
Yes - C++/CLI is still required for interfacing between C++ and C# code. The older "Managed C++" was deprecated, and C++/CLI replaced it. There's also a newer "C++/CX" - which while it seems similar at first glance is actually not for the same purpose, and is also somewhat deprecated - being replaced by the library-only (no language extensions needed) C++/WinRT.
It will reduce it as well but having a split which returns a vector of strings also inevitably triggers unnecessary allocations.
those split is just for the small file (3K) and shouldn't make a big difference when the second file is about 100MB
The only difference between equivalent D and C++ implementations of a program that allocates a lot is that the D version will be faster in the case of not exhausting memory since the GC will never run and the allocated memory will never be freed. There's no "being smarter" about it or "grabbing more memory", etc.
The size of the file doesn't matter for this particular aspect, it's just the share of time the program spends allocating memory instead of doing something useful.
Hand-written Makefiles.
I don't know if it'd work for you or even anyone else, but I got started with OSS because I get easily annoyed by anything that is repetitive and/or is harming my productivity or work happiness. I'll look for existing software to fix whatever problem I have, and often enough nothing exists that does what I want, or whatever I find has serious issues. So I write my own. Other times I fix bugs in software I use because it's faster than waiting for the maintainer to do it. Time passes and suddenly I have dozens of repositories on github.
I've no idea what "exhausting memory" means here. You're saying that D will never deallocate until the OS runs out of memory?
It would be great to have full C++17 support as well!
D will never deallocate until the GC runs out of memory. I'd have to look at the implementation to know the details of how it gets that memory from the OS to begin with. I guess that would justify your comment about grabbing memory upfront, but that would make start-up time go up. You can have deterministic guarantees in D too: just write it like you would in C++ and use RAII.
I was excited to see this video. Great insight, but i hoped for "more". The example case was a bit "easy" because both path could return in one line. Oftentimes i have something like this: ReturnType func() { // - - - - early breakouts ... if(...) { return {}; } if(...) { ReturnType ret{...}; ret.xxx = xxx; ret(xxx); // some work... return ret; } // - - - - ... early breakouts ReturnType ret{...}; ret.xxx = xxx; ret(xxx); // some work... return ret; } So in principle you have some early breakout conditions which get some special handling with maybe one line returns or with automatic variables. The main calculation will follow. So for sure i want nrvo and rvo, though you can not always easily mix these in one function (an obvious problem arises when 2 different variables are precalculated and only one will be returned on some condition in the end. thats a problem because you have only one "return spot" but 2 candidates). I was hoping for some clear advice which covers this. Looking forward ;-)
but it matters for overall performace i get a difference of about 1 second when both files are small (3k &amp; 6,8MB) and a difference of about 1 Minut if the second file is &gt; 100MB so the allocations while splitting shouldn't really matter in this case 
Fair enough. I thought this post was gonna be downvoted to oblivion tbh. Glad it wasn't :D 
&gt; As a rule nobody uses C++/CLI as a primary language. Oh I wish that were so at a place I used to work. C++/CLI Windows Forms applications.
You can either profile your code, follow suggestions like mine and others here and do a quick rewrite of the c++ to minimize heap allocations and redo the benchmark; either of these will do more for you than arguing on Reddit based on guesses.
Sure, I can do this. Their documentation, though, isn't really lacking. I could do pretty much everything by looking at it. It's just not entirely obviously available. It can be accessed via gn itself: \`gn help all\`. Alternatively you can output markdown directly: \`gn help all --markdown\`.
i tried the changes in the for loop this reduced allocations (valgrind) alot. The next thing i want to try is change from getline to fgets. but i don't understand how your suggestion about reading both files simultaneously should work :(
Huh! Do you know roughly (order of magnitude) how big the project was?
Why?!?!?! I'm so sorry...
Are there any non-MS compilers that support C++/CLI or C++/CX?
You can do it without CLI extensions, it's just more painful.
What C++17 features are you missing?
Slightly related - what is the reason that partially-specialized functions aren't allowed? Also, what's the reason that in classes, templated member functions need to be outside of the class? MSVC used to (possibly still does) allow it as an extension. Also, what's the status on the proposal to limit `typename` usage?
That's the thing with "rules" - there are always exceptions! Do you really write the whole app in C++/CLI? I've suspected such cases existed but I've not yet heard of them in the wild. And, to echo @timbatron, you have my sympathies!
I think @kiwidog was referring to C++/CLI being supported, not ReSharper C++
Documentation in a pdf instead of .docx file would be nice. 
you are lucky that all third party libraries you use are compatible with the switches demanded by C++/CLI. If I start a project now I won't make the main exe C++/CLI.
You're not using RAII if you depend on single return and your code is likely not exception-safe either. Patterns like do...while(false) are common in C, but in C++ you can do much better. Since C++14 it's almost trivial to create a macro that executes clean-up code on scope exit. Take a look at SCOPE_EXIT/FAIL/SUCCESS macros from Facebook Folly library, for example: https://github.com/facebook/folly/blob/master/folly/ScopeGuard.h 
&gt; Do you really write the whole app in C++/CLI? Yup and multiple applications as well. One large project, no DDD, just a mess from start to finish.
Yeah people always try to be way too clever... But since Rust managed to get it reasonably right, I think by not giving people too many freedoms, it has to *somehow* be possible for C++ as well, I'm convinced.
Good Idea. I just added it
Why don't you ask the author himself? His email is right in the proposal. By they way I also think there should be a site that tracks the state of every C++ proposal, so people don't have to ask around blindly.
According to [P1018](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1018r1.html) the status is "Further work is expected for San Diego, no approvals yet." One point of discussion was about the interaction with concepts.
There is no problem with ternary operator optimization if you use string literals: https://godbolt.org/g/Zo8Z3Y. The bottom line here is that you should create the value of the desired type (here, std::string) as early as possible and avoid type conversions.
&gt; Also, what's the reason that in classes, templated member functions need to be outside of the class? MSVC used to (possibly still does) allow it as an extension. Template member functions *can* be defined in the class definition. What makes you think otherwise? 
Great work! Curious, how would you compare your code against: [https://github.com/QuantStack/xframe](https://github.com/QuantStack/xframe)
Most of the unsupported C++17 features have already been implemented in 2018.2, you can try a preview build today - https://www.jetbrains.com/resharper/eap.
Hadn't seen those macros before, thanks for the tip! May have to clean up some code today ;)
Ameisen meant specializations of member functions.
Structure binding https://godbolt.org/g/sLNs6d
It's implemented already.
`xframe` is also a great implementation. I have a star there. `xframe` is based on two other libraries. What I like more about my implementation: It is completely self contained. It is much more flexible in terms of covering all built-in and user defined types Also I like the interface better. It is more similar to Pandas.
&gt; Slightly related - what is the reason that partially-specialized functions aren't allowed? http://www.gotw.ca/publications/mill17.htm &gt; templated member functions This is one thing I get annoyingly pedantic about: they're called **function templates**, *not* templated functions. Same with class templates, variable templates, etc. "Templated" is never an adjective; "template" is the noun. And yes, I think this matters for a good reason. :) Having taught C++ a lot, I've found that having a very firm understanding that function templates _are not real functions_ is helpful to understanding how templates work (sames for class templates and so on). I've many times watched as the above lesson causes a bunch of light bulbs to turn on in people's minds and the suddenly start grokking templates in ways they hadn't previously. :) In particular, the fore mentioned link makes a little more sense with all that in mind.
But the example above do not work with 2018.2.
Thank you, we will check!
What exactly is not working? Could you take a screenshot?
`auto p1` will be deduced as `void` not as `int` as it should. 
I see! This is something I will definitely check out, as I like all of those comparison points. Excellent work sir!
This is likely because they've listened to the community and have worked towards trimming down the default install size. I would say it not being installed by default is more because it's not a widely-used feature rather than an indication they plan to end support for it.
Sorry, I can't reproduce it - R++ deduces `p1` to `int` for me. What versions of R++ and Visual Studio are you using exactly?
Damn, If only it worked with Embarcadero it would be useful at my work.
[Nope](https://github.com/dotnet/coreclr/issues/659#issuecomment-113530781)
This two are not recognized too. [New rules for auto deduction from braced-init-list](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2014/n3922.html) [Direct List Initialization of Enums](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0138r2.pdf)
Visual Studio 2017 (15.8.0 Preview 4.0) and R++ 2018.2 EAP 4.
Oh. Thank you! We are heavy resharper ultimate users and use C++/CLI for C# interfacing so this is appreciated. Nobody really enjoys working with C++/CLI, but this will precumably make is a bit nicer.
&gt; non-MS compilers that support C++/CLI Yes, but only barely, https://github.com/LADSoft/OrangeC https://github.com/LADSoft/Simple-MSIL-Compiler but it's NOT usable for Unix
Oh My bad. 
It's not supported or on the roadmap for .net core, though. 
You should really be using xaml now, legacy winforms don't dpi scale (and if you try, they break)
Oh I know. I no longer work there.
I've tried 15.8 Preview 4.0 and still no luck. Would appreciate if you could create a request in the [issue tracker](youtrack.jetbrains.com) and attach a sample project, could be something in the project settings.
I don't get the C++Now tag?
New rules for auto deduction and direct list initialization of enums are supported - if something does not work on your code, please create a request. Hexfloat literals have not been implemented yet (here's the tracking [request](https://youtrack.jetbrains.com/issue/RSCPP-20364)), but to be fair, we've yet to see their use in production code and haven't received any user requests about them either. 
I've added an issue already, but it's better to #include &lt;DataFrame/DataFrame.h&gt; than #include &lt;DataFrame.h&gt; especially if there are extra files where DataFrame.h lies (like BaseContainer.h), and as it happens "BaseContainer.h" might be a very common name. Looking forward to try it out :) 
I'm not sure about diagrams, but "clickable" source code browser (where by clicking you can explore the actual function implementaion, or places where it's been used) do exists, like: Woboq's code browser - https://code.woboq.org/ Google's Kythe - https://github.com/google/kythe cppindex - https://github.com/chenshuo/cppindex DXR - https://wiki.mozilla.org/DXR While I was at Google there was the cs/ web-tool, which was very valueable, and it looks very close to what chromium is using - https://cs.chromium.org/ For example: https://cs.chromium.org/chromium/src/sql/initialization.cc Is this what you are looking for? I'm also curious about it, though it's always the details that "kills" it - especially for C/C++ where it matters how the actual code was compiled - so preprocessor would act differently, and your code browser must do so (hence your "build" configuration must be present there, and known about) 
Yes. Why the smiley face? Are you trying to be condescending about something?
No. Can you elaborate why are you saying it is proprietary? When the license is not.
`strlen` and `memcpy` are library functions. An implementation can use whatever non-standard compiler magic to make them constexpr *and* use intrinsics. 
It's automatic, probably the "C++ now" substring in the title.
In case anyone is interested, I have made public an example project built with Architect. The original post has been update with the link to its GitHub repository.
The first thing I graduate from the moment I write a Conway's Game of Life implementation is to eliminate any Matrix-based implementation of the game. For several reasons: * Matrix evaluation is just slow. Even if you speed up via multithreading—and it is convenient that a Matrix-based Conway's Game of Life is one of those [Embarassingly Parallel Problems](https://en.wikipedia.org/wiki/Embarrassingly_parallel) that are easy to multithread—you're still iterating over millions of cells each generation even if your actual pattern only has a couple thousand cells * Matrices have to be expanded, or else you violate the ruleset that the GoL grid is infinite. Toroidal grids can be fun, but they still don't obey the main convention The solution? Sparse Grids. In Java, I use a `HashSet&lt;Point&gt;`, and in C++, I use `std::unordered_set&lt;point&gt;` struct point { int64_t x, y; constexpr point() : point(0,0) {} constexpr point(int64_t x, int64_t y) : x(x), y(y) {} constexpr friend bool operator==(point const&amp; a, point const&amp; b) {return a.x == b.x &amp;&amp; a.y == b.y;} constexpr std::array&lt;point, 9&gt; get_neighbors() const { return {{p.x - 1, p.y - 1}, {p.x - 1, p.y - 0}, {p.x - 1, p.y + 1}, {p.x - 0, p.y - 1}, {p.x - 0, p.y - 0}, {p.x - 0, p.y + 1}, {p.x + 1, p.y - 1}, {p.x + 1, p.y - 0}, {p.x + 1, p.y + 1}}; } }; class conway_rule { typedef std::array&lt;bool, 9&gt; array; array _births, _survives; public: constexpr conway_rule() : conway_rule({false,false,false,true,false,false,false,false,false},{false,false,true,true,false,false,false,false,false}) {} constexpr conway_rule(array births, array survives) : _births(births), _survives(survives) {} constexpr bool births(int neighbors) const {return _births[neighbors];} constexpr bool survives(int neighbors) const {return _survives[neighbors];} constexpr bool evaluate(bool alive, int neighbors) const { if(alive) return survives(neighbors); else return births(neighbors); } }; typedef std::unordered_set&lt;point&gt; conway_grid; int count_neighbors(conway_grid const&amp; grid, point const&amp; p) { auto neighbors = p.get_neighbors(); int neighbor_count = std::accumulate(neighbors.begin(), neighbors.end(), 0, [&amp;grid, &amp;p](int sum, point const&amp; o) { //We don't count the cell itself, and we don't count cells that aren't in the grid if(p == o || grid.find(o) == grid.end()) return sum; else return sum + 1; }); return neighbor_count; } conway_grid get_next_generation(conway_grid const&amp; grid, conway_rule const&amp; rule) { //In order to figure out which points are going to show up in the next generation, we need //To know where all it is possible for new points to appear. So long as you don't have a //ruleset where cells with 0 neighbors are born, it's sufficient to only grab the cells //adjacent to the cells that currently exist. std::unordered_set&lt;point&gt; candidate_points; for(point const&amp; p : grid) { auto neighbors = p.get_neighbors(); candidate_points.insert(neighbors.begin(), neighbors.end()); } conway_grid new_grid; //Now we do the actual evaluation for(point const&amp; p : candidate_points) { int neighbor_count = count_neighbors(grid, p); bool alive = grid.find(p) != grid.end(); bool next_point = rule.evaluate(alive, neighbor_count); if(next_point) { new_grid.emplace(p); } } return new_grid; } This code represents a tremendous speed up over traditional Matrix evaluation, and also allows you to easily evaluate grids that might have cells spread out across vast empty gridspace.
Ahh yeah figures :P. At least the solution [here](https://github.com/vector-of-bool/vscode-cmake-tools/issues/151 discussion) resolves quite a bit of issues 
As it happens, I was looking for some specific change done in Qt4, Qt5 and found this link too: http://cep.xray.aps.anl.gov/software/qt4-x11-4.8.6-browser/d0/d57/class_q_widget_private.html I was looking actually when this code was introduced in Qt: ``` static int disableSubtractOpaqueSiblings = qgetenv("QT_NO_SUBTRACTOPAQUESIBLINGS").toInt(); if (disableSubtractOpaqueSiblings || q-&gt;isWindow()) return; ``` 
nevermind, this is probably doxygen generated above.
woboq's commercial (though does look pretty). There's [cquery](https://github.com/cquery-project/cquery), an LSP server (with a suitable editor you get not just find-definitions/find-uses, but also get class/struct contents in a clickable tree). Not quite the same, but really useful if your editor has LSP support. (Like many such tools, works best if you have a compile_commands.json.)
Robotic auto-flair has doomed us all! Fixed.
Replying to thread just so I can keep it saved. Looks like some cool software recommendations.
Aye. Been on my phone. I have difficulty with tiny onscreen keyboards.
My apologies: *generic methods*. &gt;:}
I've never understood this mindset. If you like software and make your living from it, why would you object to people selling and making their living from it? If someone makes an incredible tool that does what you want - particularly if there aren't other good options that do it - why wouldn't you be willing to pay for it? Heck, Sourcetrail even has a free non-commercial license. Support good tools. I bought Beyond Compare. I bought Sublime Text before VS Code was an option. I've bought plenty of other software in the past. Good work is worth supporting.
Java generics are basically just to avoid explicit casting everywhere. That's all they're for.
Reddit has a save feature built in
I'm familiar with mozilla's DXR. Alas I'm looking for something more graphical
&gt; a macro Hard pass.
It's the reason I'm having annual license to all JetBrains ReSharper tools. They also have such flexible licensing, that I'm allowed to use my own copy at work (not that work won't buy it, but I don't need to excuse expenses - I use it even more at home - CLion, etc. while at work Visual Studio + ReSharperC/C++ - and occasionally using some of the other IDEs (Rider.NET and others, if I have to)). 
We had a large custom make based build system and we needed to make it faster. Our 10mloc code base was taking over an hour to build. Just parsing our insane nest of makefiles (which where really meta in design) took over 10 minutes. We reorganized the makefiles and did tests of both cmake and gn to build some subprojects; we wanted to know how hard the porting would be, and if we'd get a speedup. We found projects ported to gn/ninja built something like 20%-30% faster than the cmake based projects did. That was surprising. And maybe we did cmake wrong. But the speedup over our old system was large, and porting took about as much work. So we went eith GN. So now we are a bit more than half way through converting our built system over to gn. Parsing the makefile birdsnest is becoming shorter, and gn/ninja is really ridiculously fast when no changes are detected. Just a datapoint.
It seems to be on life support. No evolution of the language extensions or IDE support, /clr:pure and /clr:safe deprecated, and when I filed a bug about the compiler generating invalid metadata for valid C++ it got closed WONTFIX. 
Thank you so much for sharing this. Can you write a more detailed blogpost about your experience? I mean this could help a lot of people.
Thank you so much for sharing this. Can you write a more detailed blogpost about your experience? I mean this could help a lot of people.
Another alternative: [https://github.com/Ericsson/CodeCompass](https://github.com/Ericsson/CodeCompass)
Good luck selling anything to Stallman that isn't open source.
IDE support: structured bindings and if initialization still give intellisense errors.
They also provide very significant type checking enhancements you know... I'd consider that much more important than obviating casts. They're connected of course, but just because templates are a lot more powerful doesn't mean that generics are just syntactic sugar to avoid casts.
Could you elaborate, please. What versions of ReSharper and Visual Studio are you using, and what code gives errors? Perhaps it would be appropriate to move this conversation to issue tracker (https://youtrack.jetbrains.com/issues/rscpp).
Given that generic types in Java are considered the same: ArrayList list = new ArrayList&lt;Integer&gt;(); list = new ArrayList&lt;Float&gt;(); // This compiles. It's not very significant at all. It's not even about power. The fact that both `ArrayList&lt;Integer&gt;` and `ArrayList&lt;Float&gt;` are the same type shows that it really is no more useful than making explicit casts unnecessary.
Lynch me, but I'd say that 99.9% of the time, readability is what matters, not if the code gen is optimal. Most of the time, I find multiple return statements more readable, especially in cases of early exits. Other people might disagree and say single exit is more readable, but in any case, the argument should be about readability not code gen in a particular scenario (of course, I'm aware that there are those cases, where optimal code gen really matters).
I believe the implementation of those macros violates the ODR rule when used in headers, but if FB is making use of them with no I'll effect it is probably one of those cases where UB doesn't produce a bug in practice.
how was the make system structured?
Indeed, not even mentioning string_literals in the video is a big mistake.
Keep a look out for [triSYCL](https://github.com/triSYCL/triSYCL). 
? After disabling sync it runs faster
 foo(get_string()); Says it all, really. The language doesn't currently allow us to have what I'd consider a good solution to this. 
Stallman hates open source. There is a huge difference between permissive licenses like MIT or Apache compared to GPL
Same problem as with min/max algorithms. Take and return by const reference.
Ideally I guess you want to be able to construct an rvalue `string_view` from an rvalue `string&amp;&amp;`, but not an lvalue `string_view`? Correct me if I'm wrong but in this example an rvalue string_view is implicitly constructed to be passed as the argument to the function, which appears as an lvalue string_view from inside the function? (but that's fine, because the "rvalue" string it references will outlive the function call).
This seems more like it!
I don't want to depend on other people's property and it's also unreasonably priced for third world countries IMO.
I would almost prefer to do the copy on return instead of the reference... Is this std::min/max safe with global constexpr variables? Or only constexpr static? 
It is just a C++17-cy instance of the "Do not return reference to local variable" motto (aka. Do not return string\_view built from local string), isn't it ? Although \`g++\` do not warn about it: [http://coliru.stacked-crooked.com/a/8818a14d292f7bbe](http://coliru.stacked-crooked.com/a/8818a14d292f7bbe). :(
Considering that returning iterators from a local container is also still possible, there are plenty of edge cases floating around.
As a fairly happy Clion user, who doesn't mind that it's commercial, I'm wondering what advantages you see of Qt Creator these days.
OpenGrok is another one. I use it and it does a fairly good job with c and c++ code. https://oracle.github.io/opengrok/ 
&gt;the library-only (no language extensions needed) C++/WinRT I thought WinRT requires a custom compiler or at least some custom preprocessor tool (like moc or something like that) or something like that. At least it was so in the beginning IIRC.
Besides that, there's also the fact that you can get a const char* from string and play with the lifetime of that at will. Functionally, string_view is no different from that - except for, say, having the size determined at construction, and the various utility functions on it being able to validate against that. It really needs to be constantly reiterated on whatever guidelines for string_view there are that, w.r.t. ownership and lifetime, that you should only use it if you would be comfortable using a const char* in its stead.
here you have a full article on that: [https://foonathan.net/blog/2017/03/22/string\_view-temporary.html](https://foonathan.net/blog/2017/03/22/string_view-temporary.html)
You're thinking of C++/CX
I'm not a Java programmer, but do non-generic types see any appreciable use nowadays? To me, that's like someone in C++ saying that "pointer + length" for arrays is error prone, or complaining that you can cast between pointer types, or any number of other things, except a much less well-founded complaint. You can't assign an `ArrayList&lt;Integer&gt;` to `ArrayList&lt;Float&gt;`. You can't put an `Integer` *into* an `ArrayList&lt;Float&gt;`, or take one out. If you think that doesn't have significant value, I have no idea what to say to convince you otherwise.
r/cpp_questions
Cpp WinRT requires a custom compiler to generate scaffolding code (activation, marshaling, translating from standard C++ value semantics to WinRT/COM reference semantics...) from metadata files that describe the WinRT APIs. Since the APIs are cross language, they need to be declared separately (or, have a language extension that does the declaration like C++/CX)
&gt;I'm not a Java programmer, but do non-generic types see any appreciable use nowadays? Of course they do, since generics isn't a first class citizen, as demonstrated. &gt;If you think that doesn't have significant value, I have no idea what to say to convince you otherwise. It has value, it just isn't significant. That kind of thing was never a problem before in Java, since all casts are checked at runtime, unlike in C where casts are mostly silent and tracking a defect at runtime takes too much time. The only value it has is that it saved typing out a cast, and the IDE can easily help out.
&gt;That said, that's only if you need to make a new Cpp/WinRT component. If you're writing apps, the scaffolding for UWP APIs are all pre-generated in the Windows SDK. So in that sense, you just have to include those generated header files. Aah cool! Thank you very much for that explanation! :-)
Hey thanks for that info and for digging that up! Too bad!
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/91tj17/the_standard_for_c_size_of_the_base_class_need_a/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Oooh, clangd support sounds absolutely great! More accurate error highlighting is exactly what the IDE has needed.
Ok, I made an issue describing the errors: https://youtrack.jetbrains.com/issue/RSCPP-22835
How exactly do they violate ODR? Due to the use of __COUNTER__ in FB_ANONYMOUS_VARIABLE?
Exactly
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/91hc7y/is_anybody_aware_of_a_foss_alternative_to/e30pkdy/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
VS compiler support is still experimental?
I used the wrong term. I guess I just meant another one-off we-have-too-much-time-on-our-hands google build system.
I think it's because the VS compiler itself is experimental. Joking beside, we had the VS2015 linker crashing on a regular basis, and had to do full rebuilds more than we liked.
I have a lot of false compiling errors in CLion with VS2015 toolchain, otherwise it's ok
std::string values still not showing in the debugger? 😭 Is that just my machine?
`string = {std::\_\_1::string} "works on my machine"` what does it do for you?
`string = {std::___cxx11::string} &lt;incomplete type&gt;`
https://stackoverflow.com/questions/41745527/cannot-view-stdstring-when-compiled-with-clang
Yepp, `-D_GLIBCXX_DEBUG` did the trick. Thanks.
my problem was that the completion engine couldn't see through unique_ptr in versions of libc++ shipping with the past few versions of clang. I had to make the op-&gt; in unique_ptr look like the op-&gt; in shared_ptr. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/91vzpk/need_help_setting_up_clion/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
good call - didn't think of that - thanks
Does your spacebar not work? Your spacing after commas and between brackets are so inconsistent.
Thanks! How did you do that?
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/91xqh9/anxiety_about_the_learning_process/e31kq8x/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Well so far this looks pretty amazing... I am still investigating.
Thanks I didn't realize. Should have been more careful. Will remove.
Why header only? Is apt-get + pkg-config really hard for people?C++ programmers are smart people. Header only just equals laziness or incompetence with their build system (which doesn't really add up for c++ programmers).
I love JSONPath utilities in this project. But the performance of JSONPath when query with filter expression is not very good. And it will be better if support JSON operator like jq: [https://stedolan.github.io/jq/manual/#Builtinoperatorsandfunctions](https://stedolan.github.io/jq/manual/#Builtinoperatorsandfunctions) 
You would have to be daft to think that this would get packaged by Debian first of all. Secondly the amount of build systems in C++/C are retarded. I may on any given day have to build a project with CMake, Meson, Autotools, or even build2. Header file only libraries are perfectly fine especially for single purpose products like this.
1. Post in /r/cpp_questions 2. Turn on `-Wall` 3. https://en.cppreference.com/w/cpp/language/ub
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/91xzl9/weird_cout_initialization/e31mgrb/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
There are multiple build systems but any given project will typically just use one (and it will be a build system the team has experience with). Seems easy enough to add files to the build system of your choice. Maybe this stuff is hard for a Python developer coming to C++ but for a seasoned C++ developer header only has no real advantages. Oh well. I'm not saying don't use header only I'm just trying to understand why it has become so popular.
You need to initialize “result” with 0.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/917wyp/running_neural_net_in_c/e31mu98/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9154e1/c_performance/e31mvmf/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
We noticed that after deleting line 13, however before deleting that line the function worked without initializing result to 0.
My pessimistic guess is that then it's easy to ignore licenses, make changes that will never get upstreamed and stay in old versions forever. But as upstream you get more popular and some stuff will make it back and give proper attribution. And the ones not contributing weren't likely to anyways.
I used my moderator powers to remove the flair.
This version has better WSL integration too! 2018.1 couldn't detect your WSL instance unless it was the bare Ubuntu from the Microsoft store, but now it'll find the different version specific Ubntus (Ubunti?) too.
&gt;Is apt-get + pkg-config This fine, if you know, you don't mind locking your users into a specific operating system.
Still no community edition like IntelliJ?
which is weird since primitives should always be safe to copy and faster since they're small and primitives. why add reference indirection to something thats the same size as a reference/pointer in the first place?
Still no nice qt integration 😞
I guess so you can use them with non-copyable types and perhaps also for guaranteed efficiency with larger types before guaranteed copy elision.
Für ne it's less about new feature, but more about bringing defaults, the environment and the implementation to modern standards. - Make x64 the default target - Store files as utf8 without boom - Provide a 64bit Version that doesn't regularly crash/slow down due to hitting the 32 bit memory limit on a 32GB Dev machine. - Support paths longer than 260 characters - Provide a utf8 CRT - Provide a windows.h version that -by default- doesn't define all those pesky macros
References to built-in types are inlined and optimized to copies. It's for bigger types and non-copyable ones.
And toolchains.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/91zz0j/dont_know_here_to_start_learning_dx911/e321rjb/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The fact that VS is still 32 bit is indeed weird, i understand there are some good reasons for it, but you should at least be able to provide a 64 bit build in 2018. We especially encountered this in large profiling cases and now switched to a different profiler, while the VS profiler is quite user friendly in comparison
Srsly, it's a great product. It includes a fallback licence so you essentially pay 70$ once and get all bugfixes for that year. Sometimes you just need to pay for a good tool.
Do you have any plans for integration with Conan? 
Gradle support oh yes! :D (Does anybody use that other than me ?Oo)
So glad to see Italy speaks C++ too. Keep up the good work guys
&gt;EDIT: Support DPI changes in Windows 10 Visual Studio at least supports the older global DPI system, but support for per-monitor DPI would be awesome. My primary development system has a 4k main monitor and a 1080p secondary, with different DPI - VS 2017 is great on the main monitor but any windows on the secondary are blurry because they are resampled from the higher DPI. Better utf8 support would be amazing, for both the IDE and the CRT. Ditto long paths - Windows has laid the groundwork, now software needs to catch up!
I don't think they're going to do things like UTF8 without BOM, and a "clean" windows.h file - that would be breaking compatibility in a fairly major way. I'm kind of indifferent about the x64 thing, as last time I tried VS created 32 and 64 bit targets, it just defaulted to 32. Otherwise, I agree, needs a bit of "modernisation". I'm also not majorly keen on the "move everything out of VS and into Node" that seems to be going on in the last few versions. I'd rather if we got _less_ features that worked well and performed better, personally. It's 2018 and my IDE still stalls for multiple seconds when I change from Debug to Release!
For the Nth time: **Having a standard library for a language is a very bad approach to the problem of creating an ecosystem around a programming language.** Does anyone responsible for C++ (in the committee, or close it it) listen? C++ needs an official language library repository, where everyone on earth can submit a library, libraries are reviewed, rated against the official standard. In this way, people will create all the libraries needed for a programming language ecosystem, and we wouldn't have to wait for 20 guys in a committee to decide if we need 2d graphics or an interface to a web browser. 
1. How about foo &lt;- bar ? 2. Move used more and more? i.e. Rust got this right in that move is the default operation? 
I'd be happy if they just focused on two things (IDE-wise): performance and IntelliSense not sucking. VS isn't really *bad* in terms of performance (compared to, say, Android Studio, ugh; I know, I know, different languages and all, but still), but it can use some improvements. And IntelliSense still regularly fails to find a correct symbol, especially in the context of a lambda or a template.
Our C++17 filesystem implementation supports long paths (when enabled in the OS).
Well, it is a wish list - not a list of features I expect.E.g. they already announced that they won't make 64 bit version of VS. Regarding UTF8 without boom: Why would that be a breaking change? You can already store individual files that way, but I'd like to have an option to store all new files that way AND make that the default. Regarding windows.h: They don't need to change the existing header files, but they either could provide a "clean" alternative (windows_cpp.h) and/or define all those lean and mean macros by default. The problem with lots of my whishes is probably that they require a lot of effort to implement but have relatively little visible output with which the team can justify it to their managers compared to the implementation of some new shiny feature they could add to the IDE. As a final wild guess: this "moving everything out of process into node" is a symptom of their inability to a) move to 64bit and b) understand, refactor and fix their decades old code base.
Ah, I see. AFAICS there was no way for me (as non-mod) to do so :-(
Oh nice!
I would still like the ability for the error and warnings log to show me, in a merged log, the errors and warnings from both MSVC and clang simultaneously i.e. VS runs both compilers, and shows me a unified errors and warnings view. MSVC is getting better at diagnostics, but I still regularly get diagnostics with zero usefulness in indicating what is upsetting MSVC. Flipping into clang very often yields the cause, and is far better than the old "trial and error and see what sticks" approach to fixing MSVC compile failures. Another gain is that concurrent clang diagnostics would show the MSVC dev team where to improve their own diagnostics, such that this feature could be retired once MSVC does much better than now.
Which version of VS are you using? I've found intellisense to be much improved in VS 2017, especially the later updates!
It's still called experimental as we don't support the debugger for this case and has a few code analysis issues. But overall it should be fine.
Conan team is maintaining a plugin for CLion: https://github.com/conan-io/conan-clion-plugin. Not yet in the official repo as it's still at very early stages. But works fine. Give it a try!
Do you mean qmake? Or what?
Meanwhile the competition is already dropping support for all 32bit applications. Other IDEs like Qt Creator or CLion are 64bit on Windows, too, so why can't VS?
I mean, you can build Qt projects using cmake. But what i am looking for is mainly code insight and completion features using Qt libraries. I have never found a real solution to this.
VS 2017, and still when I try to "go to definition" from inside a lambda, it fails as often as not. Also, I don't like that "go to definition" never suggests going to virtual function in the base class, unlike VisualAssist's does.
Don't ever hang the gui thread and by default load nothing like news and updatea (!) at startup (or easy setting via installer thaat we can use when installing our dwvelopers machines). Don't stop me from moving around windows, flipping tabs, open dialogs just because I for example edit debug settings. Make it easy to disable (for all users/via installer) all those "extension x slowed down by1 second" dialogs for specific extensions. Make it easy to turn off notice about new updates. We need to check new versions (interactions with third party libraries, cuda etc) before our developers update to new minor versions. Make it easy to disable solution loading dialogs to update toochains. We need to do that in a controlled way. 
That is great to hear! But I was talking about long path support in the IDE / development tools 
&gt; nother gain is that concurrent clang diagnostics would show the MSVC dev team where to improve their own diagnostics, such that this feature could be retired once MSVC does much better than now. Thats a great idea! I haven't tried that in a while now: How stable is clang integration in MSVC (I'm assuming you are talking about clang/llvm not the discontinued clang/c2 right?). 
6GB of source files. Somewhere in the order of 20k - 30k files.
I can't remember. I also don't think it matters. Writing Makefiles by hand and getting dependencies right (never mind how slow make is to execute in the first place) is like writing C code without any security vulnerabilities. The probably tends to 0 (and fast!) as the size of the project increases.
My guess (and it is really just a guess, I have no insight into the VS code base technical roadmaps or development practices inside of MS): The code base is so old and crufty (in MS speak: "mature") that just compiling VS in 64 bit mode breaks the world with no easy/obvious way to fix it. So (technical?) management is not willing to pledge the necessary funds/development time to refactor / rewrite the code base from the ground up, as long as there are more incremental workarounds that can be applied onto/around it. Maybe they hope that by moving more and more stuff out of process, the core IDE code base will eventually become small enough that the switch becomes possible (and then they can try to integrate everything back to improve performance).
&gt; I'm kind of indifferent about the x64 thing, as last time I tried VS created 32 and 64 bit targets, it just defaulted to 32. And I'd really like the default to be just the x64 targets. Nowadays I see as much need for a new project to run on a 32bit target as on a windows arm target: Both are necessary sometime but it is an exception rather than the rule. 
Yes, LLVM clang. I've not found the clang integration into Visual Studio to be problematic, if that's what you mean. cmake support for clang + ninja and clang + msbuild is usable as well. clang does still struggle a bit with MFC and ATL code. That said, I did get - with a bit of source editing - a simple MFC app to successfully compile with LLVM clang which is quite astonishing if you think about it. But more complex MFC apps still befuddle it due to (I'd guess) incomplete support for the COM magic attributes and other such MSVC malarky in the MFC headers. All that said, you don't actually need clang to link code or make executables which actually work. A front end pass is all you need for greatly more useful VS2017 diagnostics.
Oh OK interesting, thanks! I've never used Make on a project of quite that size.
I'd like to +1 this as well. Recent Visual Studios (the 15.7 series) like to hang themselves when you're typing into them. By hang, I mean you need to kill the process, and I've lost work from it. It's quite irritating, and I'm hoping the 15.8 series doesn't do that.
\&gt; Don't stop me from moving around windows, flipping tabs, open dialogs just because I for example edit debug settings. I agree with this so much. "Modal" windows shouldn't prevent moving / resizing windows, or copying text. Besides, I cannot understand the obsession with having modal dialogs in so many GUIs. They make sense in only very few cases. Usually they just prevent efficient workflow. Want to copy settings from one window to another? Nope, you can't touch the other window until you close this one.
Please simplify moving the common parts of several vcxproj in a solution to .props/.targets. It's possible now, but requires a lot of manual work. Something like "create a project template" and then "create a project from the template" maybe? Please make .vcxproj/.filters parsers &amp; generators smarter. A lot of things there can be de-duplicated: &lt;ClCompile Include="stdafx.cpp"&gt; &lt;PrecompiledHeader Condition="'$(Configuration)|$(Platform)'=='Debug|Win32'"&gt;Create&lt;/PrecompiledHeader&gt; &lt;PrecompiledHeader Condition="'$(Configuration)|$(Platform)'=='Debug|x64'"&gt;Create&lt;/PrecompiledHeader&gt; &lt;PrecompiledHeader Condition="'$(Configuration)|$(Platform)'=='Release|Win32'"&gt;Create&lt;/PrecompiledHeader&gt; &lt;PrecompiledHeader Condition="'$(Configuration)|$(Platform)'=='Release|x64'"&gt;Create&lt;/PrecompiledHeader&gt; &lt;/ClCompile&gt; This is neither user-, nor source-control-, nor review-friendly. If the value is the same for all possible conditions why not just: &lt;ClCompile Include="stdafx.cpp"&gt; &lt;PrecompiledHeader&gt;Create&lt;/PrecompiledHeader&gt; &lt;/ClCompile&gt; ? IDE is already able to read and update such 'conditionless' values (if created manually), but it would be nice to also produce them by default where possible. Things like `&lt;ClCompile Include="*.cpp" /&gt;` (i.e. "I don't care and don't want to update the vcxproj every time, just include everything") more or less work already, *until you edit the project in the IDE*, which will turn it into mess.
Also working support for case sensitive directories in NTFS. Another thing that Windows provides but VS fails miserably at working with.
Actually (and ironically), disabling auto recovery has helped here. It seems auto recovery itself is one of the most common triggers of the white-out hangs.
There have been several blog posts from Microsoft about this. [Here](https://blogs.msdn.microsoft.com/ricom/2015/12/29/revisiting-64-bit-ness-in-visual-studio-and-elsewhere/) is a somewhat recent one, with links to some older historical posts such as [this one](https://blogs.msdn.microsoft.com/ricom/2009/06/10/visual-studio-why-is-there-no-64-bit-version-yet/), which at the time I felt was persuasive. At least in these posts, the claim is that switching from 32-bit to 64-bit might actually degrade IDE performance.
No matter how nice the rest of Visual Studio is (and it is very nice), the frequent hanging of the UI thread is, in my opinion, inexcusable. Keeping long computations out of the UI thread is a basic tenet of user interface implementation, prominently covered in every UI implementation article that Microsoft ever wrote. How could they have got this so wrong?
actually, that's a good point, but making move default operation is gonna break a lot of legacy code. An idea would be: foo = bar; // performs move foo = const bar; // performs copy 
I'm still unsure. If you have a CMake project and Qt libraries linked via CMake, it should work nicely. But Qmake projects are indeed not supported and lacks code insight. However, you can generate a compilation database from qmake project and open in CLion with full code insight.
I would even pay to make VS not steal focus when it finishes building, or starting the debug session, etc. I guess this is a Windows issue, but if VS could be configured in a way that it doesn't want to be in focus every time it finishes a task (maybe just blink on the taskbar, or use some kind of more subtle notification), I would be a much happier developer for sure. Right now when I start a C++ build, which takes time and I start to browse in the meantime, or do something else, VS pops right into my face when its finished, and its really irritating.
\&gt; If you have a CMake project and Qt libraries linked via CMake Tried that. It did the build nicely, but still no code insight. Also, its kinda bothersome to use cmake if you have a qmake project. \&gt; However, you can generate a compilation database from qmake project and open in CLion with full code insight. I have never heard of that. Can you point me to a source on how to do that using a qmake/gcc toolchain?
CLion and compilation database: https://blog.jetbrains.com/clion/2018/05/clion-2018-2-eap-open-project-from-compilation-database/ How to get compilation database from your project model: https://sarcasm.github.io/notes/dev/compilation-database.html#how-to-generate-a-json-compilation-database
That's really useful to learn, thank you.
If it's written in .NET, then it'll be theoretically written in non-blocking design patterns. However one can still hit cyclical dependencies in any large code base, or blocking on a single critical path. Large, complex code bases with many execution paths through them become prone to random pauses like that. I also personally find the cmake support so slow to load that it isn't worth using. It'll get there after many *minutes* of parsing and thinking. And that's *minutes* after finishing running cmake configure. It shouldn't take that long to parse a set of targets. I wrote a Python script which parses out all the targets in a generated ninja file, and it takes less than a second to run. I also dislike how cmake support insists on its own build directory. I want the build directory I told you to use dammit!
Please please please don't stop the vs2017 support before there is a wdk version for 2019. until RS4 I was stuck in a limbo where the VS2015 linker was always crashing, and there was no Wdk for 2017 where those linker bugs were fixed:(
Seconded. 64 bit, UTF-8 and let me automatically trim trailing whitespace.
Some (probably minor) things that annoy me about VS15 and could be improved: * Input latency, which seems to have gone up over the years. Please process input / text-editor part in its own thread rather than having other tasks (such as extensions) block the updating. * Reloading extension-settings when opening CMake projects / saving the CMakeLists trigger. Right now I have to go into the settings, select the "Remove trailingwhitespace" plugin's settings, and closing to enable it. (could also be nice to have as a built-in feature). * Loading components on demand / default environment configs. All I want is Git, the text-editor / file-explorer, and running the build script. Having the IDE frozen for 30 sec just to display a single file (for when I accidentally forget to open with Notepad++) should not happen. * Hotkey duplication, it'd be nice to have F7 for both CMake-build and msbuild (dependant on the project). * Templates for files, e.g. adding a license header with file-creation-date and author information to .* files. * Global CMakeSettings.json variables. Having to copy an entry for CMAKE_TOOLCHAIN_FILE in each new project gets a little annoying. * Debug-watch values with automatic namespaces. If a breakpoint is hit in namespace::namespace::namespace then it would be nice if adding 'globalVar' to the watch would try to add those namespaces rather than complaining that the var can't be found. * Proper instruction-tracing when debugging, which may require Intel PIN or such. But trying to debug with a messed up stack is really annoying. A simple "E/RIP was %p 5 instructions ago" would save sooooo much time when things go wrong. * The option of using hardware-breakpoints by default while debugging.
I'd like to see full support for `-std=gnu++17` in Intellisense someday.
lmfao yep watched my coworker struggle to delete a boost directory yesterday.
Wow, that makes using Qt in CLion so much better, now i can finally use CLion in my Qt projects. Thank you very much! BTW just saw that you are a part of the CLion team. It is awesome that you guys help us out here! This makes JetBrains even better!
Download | | | v
This. Slightly related: if you have focus-follows-mouse (~"sloppy focus") enabled in Windows, moving focus to (i.e., mousing over) one of the source editor subwindows causes VS to raise its window to the top. That behaviour is really annoying. Mousing over other parts of VS doesn't trigger this. I've seen this reported a few times, but apparently using FFM on Windows is not common enough for anybody to care. VS is also the only application that I know of where this occurs. I'd put that on my wishlist for all the VS versions. I doubt it will ever be fixed, though.
&gt; let me automatically trim trailing whitespace. Can you use extensions from the market place? There is one (probably several) that let you trim whitespaces on save
I just want a tool that allows me to express, analyze and manipulate actual data.
Though I don't agree with the apt-get+pkg-config part, I agree with his questioning on header only library. And I don't understand why he got so many down votes.
u/blelbach I meant this thread on the DM.
Better CMake integration. It works but still needs more polish. "C++ IntelliSense information may be out of date" toast popup is super annoying and cannot be disabled. Ninja builds can blowup the command line with &gt; 32K char compile/link due to how it concatenates full paths of everything. Basically, please fix the bugs. No new features. 
Make the output window have automatic timestamp, filtering &amp; user-based coloring. 
r/cpp_questions
This is off topic, not a C++ question. You can just google "game entity component system" and there are a lot of articles. https://www.google.com/search?num=30&amp;newwindow=1&amp;source=hp&amp;ei=3dBZW5exBYG-zgKo4pKwBA&amp;q=game+entity+component+system&amp;oq=game+entity+component+system&amp;gs_l=psy-ab.3..0j0i22i30k1l9.53.53.0.673.2.1.0.0.0.0.573.573.5-1.1.0....0...1c.1.64.psy-ab..1.1.573.0...0.hdsVxk9EIzw
&gt;GCC 8.2 &gt;This is the [list of problem reports (PRs)](https://gcc.gnu.org/bugzilla/buglist.cgi?bug_status=RESOLVED&amp;resolution=FIXED&amp;target_milestone=8.2) from GCC's bug tracking system that are known to be fixed in the 8.2 release. This list might not be complete (that is, it is possible that some PRs that have been fixed are not listed here). &gt; &gt;General Improvements &gt;* Fixed LTO link-time performance problems caused by an overflow in the partitioning algorithm while building large binaries. &gt; &gt;Language Specific Changes &gt;C++ &gt;GCC 8.2 fixed a bug introduced in GCC 8.1 affecting passing or returning of classes with a deleted copy constructor and defaulted trivial move constructor (bug c++/86094). GCC 8.2 introduces -fabi-version=13 and makes it the default, ABI incompatibilities between GCC 8.1 and 8.2 can be reported with -Wabi=12. See C++ changes for more details. &gt; &gt;Target Specific Changes &gt;IA-32/x86-64 &gt;* -mtune=native performance regression PR84413 on Intel Skylake processors has been fixed. From here: https://gcc.gnu.org/gcc-8/changes.html
Agreed for everything, except your last point. I quite like the fast paced compiler updates, though I perfectly understand where you are coming from.
**Company:** [Spire Trading Inc.](http://www.spiretrading.com) **Type:** Full time **Description:** At Spire Trading, we're constantly identifying new opportunities to increase efficiency and liquidity to capital markets. For this role we are seeking a software developer to build an application that continuously gathers news and information from the web and analyzes it to build out our financial knowledge base. This involves developing a high performance web crawler, coming up with efficient storage and versioning systems, and modifying JavaScript engines to operate on downloaded web content. In the process of developing these components, you will become intimately familiar with the business of proprietary trading, market making, and the various tools and methods used to analyze and forecast financial markets. No knowledge of finance is required. **Location:** Toronto, Canada **Remote:** No. **Visa Sponsorship:** No. **Technologies:** * C++17 using MSVC 2017 and GCC as our main compilers. * Both Windows and Linux are predominantly used. * CMake * git **Requirements:** * Excellent communication skills both verbal and written. * In-depth knowledge of the latest C++ standards (C++17/C++2x) * Proficiency with HTML5, DOM parsing, JavaScript. * Solid understanding of fundamental data structures and algorithms. * Strong automated testing discipline. * An impeccable eye for details. * Self-starter and proactive. * Take ownership of your code. **Contact:** Email [careers@spiretrading.com](mailto:careers@spiretrading.com) with your resume and preferably a GitHub account (not required), and/or visit [https://stackoverflow.com/jobs/198082/c-plus-plus-software-developer-spire-trading-inc](https://stackoverflow.com/jobs/198082/c-plus-plus-software-developer-spire-trading-inc)
let me drag&amp;drop a directory structure and don't flatten the whole thing. (or is this already possible? i'm still on vs15)
I think that's fair comment, about header only libraries in general, and a defensible point of view. But there's another side to it. Writers of open source software need users, and header only libraries do make it easier for users to try the software. Also, writers of open source software need motivation. In C++, the most energy seems to be going into generics, as found in the standard library and in boost, so it's natural for open source writers to see what they can do with abstraction through generics, how far they can go. Which means header files. And when you write software for free, you can do what you want :-)
Is 8.2 unstable? My understanding was that even subversions were unstable versions.
X64 visual studio please
The argument for 64 bit VS isn't performance, it's that the 4Gb memory limit is a real problem for some workflows.
&gt; References to built-in types are inlined and optimized to copies. Not in our testing. We got a 4% overall program performance improvement by replacing std::min/max with a simple static function which takes by value and returns by value. That's with every optimization flag enabled that I could find + LTCG. On MSVC C++17 at least.
A few additions to your list: [*] Provide an apply button to the Tools - Options dialog box. Its a pain to preview your changes. [*] Provide a semantic colorized theme by default. I guess a lot of users don't know that VS can do semantic syntax highlighting or are too lazy to set it up. [*] Improve documentation for IDE features. The Font and Colors dialog has probably 200 items without any documentation on what applies to which languages and which setting overrides which. VS has a great inbuilt diff &amp; merge tool, yet the documentation on how to set it up is lacking. [*] Add a context menu to see the preprocessed output of a file. This is invaluable for XMacro debugging. Maybe this can be done in an extension? [*] Mark some intrinsics as constexpr - eg mulh, popcnt, etc
What is semantic syntax highlighting? Isn't that what VS does by default?
Sure but this *has* to be an option in the IDE.
Very nice.... Have you seen [https://github.com/nlohmann/json](https://github.com/nlohmann/json) ? Curious to hear your thoughts on how the two compare.
No, it is stable. Only *.0.* is experimential/prerelease. See here for version scheme: https://www.gnu.org/software/gcc/develop.html
It doesn't _have_ to be, the functionality already exists in extensions. I've had [Trailing Whitespace Visualizer](https://marketplace.visualstudio.com/items?itemName=MadsKristensen.TrailingWhitespaceVisualizer) installed for years.
Oh, yes, once I had a project under `C:\Users\username\PROJECT\…` and used vcpkg (or nuget?) to install a package. The IDE/compiler barfed on a too long path name.
I disagree. This is something that belongs into a good editor or IDE in 2018.
VS does it by default, but the default color scheme doesn't show it. IIRC, VS uses the same color for local, global and member variables. Changing that alone is a huge usability benefit. Also, it names things annoyingly. The entry called "C++ Variables" actually controls the color of the global variables. There is a hierarchy - setting for certain things override other settings - but its not documented. My setup is currently heavily customized and I do not recall what exactly I had to change. But I recall that it took me a lot of trial and error to figure it out - it was a pain.
&gt; ... the claim is that switching from 32-bit to 64-bit might actually degrade IDE performance. My IDE performance is already degraded when it hits the memory ceiling and starts stalling while it tries to find memory to free. So that's a non-issue and just a PR guys safe-face excuse.
It's a matter of perspective, of course, but I do believe reading and writing code go hand in hand, so what you could do if you don't want to get into full time coding is to experiment by starting a lot of personal projects. Focus on integrating open source libraries just so you get exposed to differing styles of coding and API design approaches. Just one simple example: write a small program that reads png images using libpng from disk. This projects tend to be short but very educational.
Batch build... add function to save/load configurations. Waiting for this for ages...
- Have name-completion work on include files when the file is in a directory: `#include "foo/bar&lt;ctrl-J&gt;` - Support intellisense for modules. - Fix this: https://developercommunity.visualstudio.com/content/problem/185559/debugger-called-twice.html 
I do have vcpkg in the exact same location and didn't have any issues yet. But yea I totally agree with the overall gist of this thread! :-) 260 character limit is just ......
&gt;"move everything out of VS and into Node" that seems to be going on in the last few versions I'm curious, what do you guys exactly mean with that? Moving VS stuff to node.js? In what sense?
Are you guys talking about a 64-bit VS IDE process (64-bit devenv.exe) so that plugins and stuff can use more than 2 (4?) GB of RAM? Or are you talking about making x64 the default target when building app with VS. I feel like these two things got a bit mixed in the conversation?
You would be using clang-format anyway, and clang-format does this, doesn't it? And the latest VS has pretty good clang-format integration, directly integrated into VS (without a plugin).
Totally agree with you (sooo much for hanging the gui thread and modal dialogs!!!) - except for the last point. You can install all the minor toolchains side-by-side. VS IDE and VC toolchains are pretty much separate nowadays.
I've found reading to be particularly helpful when you already have some hands-on experience with the language. Reading exposes you to different ways of doing things. It's a bit like learning a "human" language, reading helps much more when you already have a basis. I certainly wouldn't recommend it as a beginners' strategy. 
Good news about CUDA compatibility - I've added a test, run for every pull request, that verifies that CUDA 9.2 can compile all of our STL headers. This prevents us from accidentally breaking CUDA while making STL changes - e.g. just yesterday we were thinking about unconditionally using `if constexpr` but that doesn't work for CUDA yet, so we're going to preserve the old codepaths when `__NVCC__` is defined. The compiler team has also added regular (although not per-PR) builds of NVIDIA's [Cutlass](https://github.com/NVIDIA/cutlass) to our suite of open-source projects that we test the toolset with. Note that our testing currently relies on disabling the `#error` for newer `_MSC_VER` versions in CUDA's headers; we're working with NVIDIA so CUDA will automatically accept newer VS 2017 updates but we can't yet share an ETA.
Thanks a lot!
\&gt; wrapping it in either Boost Python or Cython I highly suggest you to have a look at pybind11.
So x.0.0 and x.0.y are always experimental/prerelease. Everything else is stable. Correct?
Just wanted to jump in and say THANK YOU to NVIDIA people who worked on this with us. we really appreciated it. 
\-fdiagnostics-show-template-tree looks really awesome. 
&gt;reads png images using libpng from disk That's pretty much all C though, not C++.
So UIDelays is a metric we specifically try to drive down. You won't be surprised to know that the root cause of these is frequently the weird interactions between the multiple generations of UI tech that combine to make it a semi-manual task for developers to know if they are doing something correctly. Extensions also frequently play a role here. That said, I look at my role when it comes to this area as making sure I advocate for the specific UIDelays impacting the C++ developer. Are there specific ones that are the worst offenders? We are working on addressing the underlying issues, but in the meantime, I would appreciate any specific pain points to lower their impact.
i strongly suspect the issue you are referring to is this: [https://developercommunity.visualstudio.com/content/problem/299046/vs-locks-up-editing-c-file.html](https://developercommunity.visualstudio.com/content/problem/299046/vs-locks-up-editing-c-file.html) Root cause was a change to the QuickInfo control for improving layout of the UI that had an unexpected side effect. Apologies for the inconvenience on this one for sure.
Intellisense indeed improved in VS2017, but it fails in a lot of cases. Just a simple example of a header with multiple derived classes with the same base class all overriding a specific method.. intellisense doesn't know where the implementation is of each of those.. i now always toggle header -&gt; source and then ctrl + f..
I want to see both. This particular thread was about a 64bit IDE process.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/923u1x/focus_on_learning_to_read_c_over_writing_it/e3329ko/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
With regard to the CMake issues, I can tell you that the performance issue you're likely referring to is known and something we plan to address. The AnyCode basis for the CMake integration does a LOT more than just handle CMake. It basically scans and potentially has to process any "interesting" build-related files or folders anywhere residing the folder that was initially open. However, this doesn't mean there isn't changes we can make to improve performance, especially for CMake users. With regard to the build directory issue, can you be more specific? Are you referring to the CMake cache directory or the folder build artifacts are built into? 
The C++ IntelliSense information toast popup can be disabled in Tools-&gt;Options-&gt;CMake. Uncheck "Show CMake cache notifications". The ninja build problem, if I understand correctly, is a problem with Ninja itself. Can you provide a bit more detail with what you're running into? 
Please integrate the guidelines extension (from power productivity tools) straight into VS. It must be one of the simplest features to add and I genuinely cannot live without my 80CL marker. That is all :)
Hi Aistar, thanks for the feedback. Have you had a chance to check out our new[ Template IntelliSense](https://blogs.msdn.microsoft.com/vcblog/2018/06/26/template-intellisense/) feature (released in Visual Studio 2017 15.8 Preview 3)? This should greatly improve your IntelliSense experience within templates, and we will be continuing to improve this feature. IntelliSense for generic lambdas is also a great suggestion.
Its copy elision.
Isn’t there an option to auto format on save? When using an editorconfig it removed trailing whitespace for me on format.
Performance is particularly bad if I do a git pull while I have a large soln loaded. It's often quicker to close the IDE and open it fresh, rather than letting it try to figure out what's changed.
So there are two ways of opening a cmake project. One is to open the CMakeLists.txt. In this situation it's fair enough that VS uses some external build directory. The other is when I open a *specific* build directory i.e. I have already created a build directory on the command line, configured it how I want, and now I'd like VS to use that specific build directory and configuration. In that situation, I would open the CMakeCache.txt in the build directory I've configured. Yet, inexplicably, VS ignores my carefully configured build directory the one I've explicitly told it to use, and goes and makes one of its own. That is very irritating. Often I have set up cmake variables and such just-so on the command line. I want VS to just use what I tell it.
My particular list of asks would be: 1) Catch2 test runner integration 2) Allow breakpoints to be set in lambdas that are defined inside macros. We use a testing framework that has assertion macros that can take a predicate lambda. The VS debugger doesn't break on breakpoints set within the body of such lambdas. 3) Performance of the IDE in figuring out what's changed during a source control update. It is quicker to shut down VS, update the repo and restart VS than to leave it running while I update. 4) Better support for header fixing. Something like IWYU in order to make sure that headers are correctly included. Automatically suggest replacing an include with a fwd declaration and have a refactoring tool to do it. 
No, I don't usually install previews, but if you improved IS in these situation then I will await the release of 15.8 eagerly!
Just go away and never come back vs2019.
I guess our projects is too small to notice this. But I also do not use Git integration in IDE. Maybe this is the problem?
I'd like to get proper modules support for the windows headers! and improved performance for the compiler and the ide, even if that got already much better in vs2017! 
Note that previews are now installed side-by-side with your production release, so you can try 15.8 Preview without affecting your 15.7 installation (as long as you have sufficient disk space).
Yes, that's how I read it.
Great @STL and @spongo2. I'm *so happy* to hear that you have a fruitful collaboration with NVIDIA on this! Thank you all at MS for this work and for sharing what's on the horizon. It's extremely valuable, especially since NVIDIA just do not answer these kind of questions. A bit of context: We are actually still on msvc from VS 2015 due to unfortunate combinations of issues with CUDA (and their low release frequency) and unrelated issues with the particular msvc versions supported by NVIDIA. The current latest msvc should be great, but as far as I understand (there's no official information and generally very little information) even CUDA 9.2 can't work with msvc in C++17 mode which would be the most important reason for us to switch. We have considered ways out of permutation/dependency hell, for example splitting out CUDA into separate projects, with some working msvc minor version, c++14 - and moving the rest to C++17, latest msvc.
If you are making the statement with regards to min/max specifically, maybe. If you are saying that *in general* references to built in types can be changed into copies, this is definitely not correct.
And that was just an example, didn't even give it much though. On one hand. On another hand, blessed be the soul who only ever works with pure C++ code. Especially when reading code maybe written long ago. 
In general, not. Only when the code allows it (templates and lambdas are inline).
will take a look
&gt; 1) Catch2 test runner integration Seconded! Running it in the console from the IDE is so awkward.
I don't use it either! Good point, I should try disable it. If that is the culprit it needs to improved.
Ooh, nice. I have used the one that comes with RSC++, but a standalone extension would be great.
This time we make it so we can read the public members of a class object. So we can read a value in Lua like this "local x = spr.x", which maps to the native member on Sprite::x [Embedding Lua in C++ #30 - Reading Class Properties Using Run Time Type Information](https://youtu.be/7X6P2aAgcJA)
There is no checkbox "Show CMake cache notifications" that I see. Help -&gt; About says Microsoft Visual Studio Enterprise 2017 Version 15.7.5 I have a 3 option radio button for CMake: Always run configure step automatically (Recommended) Run configure step automatically only if CMakeSettings.json exists Never run configure step automatically For ninja, try adding some external projects. ExternalProject_Add(OGRE) for example. I recall having problems with CEF, OGRE, possibly GoogleTest. I'm sure there are others. Changing the generator to Visual Studio magically fixed everything. The problem is ninja would compile a file e.g. 'hello.c' as c:\&gt; cl (options...) "C:\users\foo\CMakeBuilds\MyProject\hello.c" but with visual studio build it's invoked something like c:\&gt; cl (options...) "hello.c" When you have a library with 100+ files that command line gets pretty big for ninja, to the point where cmd limit exceeded is reached. 
The golden goose would be a toolchain independent from the IDE I guess.
&gt; as far as I understand (there's no official information and generally very little information) even CUDA 9.2 can't work with msvc in C++17 mode That's correct; the [NVCC compiler option documentation](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html) lists "Allowed values for this option: c++03,c++11,c++14". (MSVC's front-end and especially its STL will never support a C++11-only mode, making 14 the only valid option if you include our headers.) I'll ask them about C++17 mode, as it would additionally be valuable for using `if constexpr` internally (which we STL devs are obsessed with, since it will improve throughput and debug codegen size).
\+1 for being able to use CUDA with \`/std:c++17\`. Kind of a basic requirement in 2018, that switch has been around for so long. Thumbs down to nvidia for their very slow progress on that front (they're in general quite slow on updating MSVS/MSVC and modern C++ support in their toolchain - always takes ages).
This is anecdotal, but I've noticed this week that starting and stopping debugging, particularly when VS has been running for long sessions (multiple days) is problematic. Another one I've noticed is when switching build configurations (debug to release) in a large project. Happy to provide repros privately if needed.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/926r0z/c_barcode_library/e33gl7x/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Nice! If only I can build it on msys2, or get it updated there.
The settings are under Options&gt;Environment&gt;Fonts and Colors in VS2015 (iirc) for those like me who wanted to find them. Slowly going through the process of finding colors that aren't terrible to look at but distinct enough from the existing scheme.
msys2 is normally pretty fast at pushing new versions.
MSYS2 is on gcc 7.3.0 as of me typing this after doing ```pacman -Syy``` and then doing ```pacman -Ss gcc```
Does it include battle royale? 
I'd like to have better support for external source directories and subdirectories in those source folders. If I have to support multiple build systems, I usually have a toplevel src directory and folders for each build system next to that folder. While I can add every file manually and it will build correctly, the file selector always starts in the solution directory and I have to navigate a few directories up first. VS will also not build projects with files with the same name in different subdirectories correctly by default. I first have to change the the build output to contain the directory path as well and I have to be carefull to use the absolute path, because the relative path contains a few `..\..\..`, which can really mess up my project folders. The absolute path makes a lot of deep file hierarchies, but at least it is contained to the build folder. I would prefer it, if I could specify a root for the source folder and all source file paths were relative to that. Also I would like it, if VS wouldn't confuse itself, of two files have the same file name. Additionally it would be nice, if I could set the default file encoding to utf8 without BOM and I could use the directory structure of my external source directory in the solution explorer (like the show all files), without having to duplicate all the directories as filters. Otherwise, VS improved a lot in recent years, especially the compiler/std library. Good job!
I love @foonathan 's blogs, but this is probably his best yet. Extremely useful tips That anyone can use to build (better) c++ libraries that are easy to build and link to. 
It made sense when people had small screens and putting many windows on the same screen was simply not practical, and it stayed that way.
It comes from FAT32 that had this limitation right?
If you don't hit the memory limit and use a less powerful machine, you would probably see some performance degradation. If you have a huge project, the additional memory will be welcomed.
I wish it worked out of the box without the jarring default settings... and do what CLion does. I would never use VS without ReSharper C++ either, so there's a lot of ground for VS to cover. A trend I notice in VS (any version, including 2017 which I exclusively use now on Windows) is that whenever I have to do something, it's usually an inconvenient or annoying thing that is handled for me correctly when using CLion. When I have to bounce back from CLion to VS2017, it feels like a death by a thousand slow cuts where there's always these things that don't work quite right or I have to go force VS to do the way I want because it does it some other way. At first you don't notice it because it's just small things but over time they add up and wear on you. CLion feels intelligent and just knows exactly what I want _all the time_ and does it right. This struggle I deal with has me at the point where I would easily fork over $300+ USD to use CLion on Windows if it had better support just to avoid the ample minor inconveniences from a free or paid VS. The big plus VS has over CLion is handling large as hell codebases, but CLion has been bridging the gap with recent updates. It would be nice to see VS succeed (and continue succeeding), because it's got a lot of good stuff in it and a solid set of developers.
The IDE should always put conditionless values if you selected all configurations in the interface. I'd say it's fair enough not to ask for automatic merging for now, but when you edit properties it should be easy enough to do what you say. I also agree on the .props files thing, it can be pretty annoying to copy/paste settings across multiple projects in a solution.
CMake 3.11 added the [FetchContent](https://cmake.org/cmake/help/latest/module/FetchContent.html) module, which is a wrapper around [ExternalProject](https://cmake.org/cmake/help/latest/module/ExternalProject.html) that downloads at configure-time instead of during the build. IMO much much better to use that than `git submodule`, since: - It keeps your dependency configuration in CMake - If the project you're pulling already uses CMake, you can just `add_subdirectory` it (if it doesn't you can do the same things discussed in the OP to fake it) - If you have a tree of dependencies, and some of those have common dependencies, using submodules all the way down would mean you have redundant copies of the same thing. `FetchContent` avoids that. - For example, say top-level project `A` depends on `B` and `C`, but both `B` and `C` depend on `D`... - Submodules would give you `B/D` and `C/D`, which are is at best redundant and at worst different, incompatible versions of `D` - `FetchContent` lets the parent project `A` dictate and override the details (repo URL, branch/version, etc.) and also makes sure you only have one copy of `D`. --- With respect to "[Case 3: A library that must be buil[t] by another buildsystem](https://foonathan.net/blog/2016/07/07/cmake-dependency-handling.html#case-3-a-library-that-must-be-build-by-another-buildsystem)", I've recently done that. It works pretty well, but here's what I did: - CMake dummy project configured to build the desired way (optional static or shared library), with output/export names to match the real project. - It's dll/lib names match the eventual real output, it sets up the `target_include_directories` and `target_link_libraries` you'll need, and does a proper job of exporting its targets and installing its export. - `ExternalProject` unpacks the real source, builds it with MSVC `nmake` (*shudder*), and puts all the build output where it needs to wind up, basically overwriting the output from the dummy project (except the exported target config files!) - Downstream projects can't tell the difference, great success!
&gt; Another one I've noticed is when switching build configurations (debug to release) in a large project. Well, I write small projects and sometimes they takes 30 secs to switch as well.
&gt; ... be valuable for using if constexpr internally (which we STL devs are obsessed with ... Once one drank from the if-constexpr-chalice, there is no turning back.
&gt; Support paths longer than 260 characters Isn't this (if on Win10) simply a matter of Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\FileSystem] "LongPathsEnabled"=dword:00000001
You can pass --abbreviate-paths to the b2 command-line and your paths will fit in 260.
That's excellent information. This wasn't a copy we built ourselves personally, but it _was_ built in-house and pushed in to a repo to use as a dependency. It's probably worth just me re-doing it for that and other reasons (don't need the docs, for example).
Just make your own 64-bit project template and you're good to go.
Another one that I think is missing is to clear the undo history from the IDE.
Yes, and if you then export your settings (in a safe place), you don't lose all that tweaking when upgrading or re-installing, or simply on another machine. I've been moving my colour scheme since VS2008.
The IDE actually does pretty well at coping with custom .vcxproj setups outside of the file list. I recently overhauled my current project to hoist all of the per-configuration overrides including the configuration/platform definitions themselves into a common .props file, and VS2017 hasn't had a problem with it. .props files are underutilized, they are *way* more powerful than what is exposed in the IDE. The Properties Manager and default templates, however, aren't so good. Properties Manager gets very slow with a lot of .props references, taking 5 seconds or more while only letting you move a property sheet reference up or down one step at a time. I gave up on it and just edit the references in the .vcxproj directly. The default C++ project templates also have too many project-level overrides. IMO the default project template should just give you a project with no config overrides in it and a reference to one central solution-level props file. 
&gt; Something like "create a project template" and then "create a project from the template" maybe? Maybe I mis-understand you, but Project -&gt; Export Template... does that. It creates the template in ..\documents\Visual Studio 2017\My Exported Templates. If you then move/copy it to ..\documents\Visual Studio 2017\Templates\ProjectTemplates\Visual C++ Project, it will also show up when you use create project and will be listed as an option in the startup page. 
It doesn't set focus for me when it finishes building.
The [VSColorOutput](https://marketplace.visualstudio.com/items?itemName=MikeWard-AnnArbor.VSColorOutput) extension has some output window colouring.
With no industry or larger-scale experience using the tools, beginner. This kind of question is probably more appropriate for /r/cpp_questions though.
You mean if that's their only exposure? It's a bit like reading a dictionary, and then expecting to write a story. Code examples are useful, but there's only so much that you can learn from them. The rest takes practice and reading code from those more experienced than yourself, along with seeing useful patterns that aren't directly part of the language, but that a proficient developer would know (RAII is one of the core concepts that I don't see mentioned in those pages, for example).
Also, in my experience, the code at geekforgeeks doesn't follow many of the best practices.
I've not used that site before, but after 30 seconds of browsing, I found [this](https://www.geeksforgeeks.org/execute-else-statements-cc-simultaneously/) terrible piece of code on the 11th example. #include &lt;stdio.h&gt; int main() { if (1) //Replace 1 with 0 and see the magic { label_1: printf("Hello "); // Jump to the else statement after // executing the above statement goto label_2; } else { // Jump to 'if block statement' if // the Boolean condition becomes false goto label_1; label_2: printf("Geeks"); } return 0; } Though they may have provided some useful information, it looks like you may need to unlearn some of it, as well. Please do not ever write code like this.
About as proficient as somebody is at driving if they studied YouTube videos of cars.
Doesn't help if the app doesn't support it. Sadly even the windows file explorer doesn't support it.
A minor, but annoying way how installing the preview affects my system: The file explorer context entry "Open folder with VS" now opens the preview instead of the release and I haven't found an option to change that.
&gt; You should use interfaces for this purpose. Vtables with VC++ (and Clang targeting Windows) must be compatible with COM calling conventions. Yep, I used this technique for an API that works fine on Windows, Windows RT, MacOs, IOS, and Linux...using MS Visual C++ 2005 - 2017, GCC, LLVM and Intel compilers. You have to specify the calling convention of "stdcall" on some platforms, and it pays to explicity specify the packing of structs.
I've also used FetchContent + execute_process to grab and build tools (e.g. flatbuffer generator) during configuration; it is quite nice! Although now I am looking at moving a couple of dependencies to conan.io with cmake_paths generator.
I read that example and thought it was ridiculous too. 
Accurate I guess. 
Always useful to see how people do their dependency management in CMake. Right now, I’m having good success with a *SuperBuild* pattern (example: https://github.com/Sarcasm/cmake-superbuild). It handles diamond dependencies and projects using other build systems very well.
I'm not familiar with then but you would be a beginner, if that. What have you written? What experience do you have? C++ (and any programming language, really) is not something you learn merely from reading and following tutorials. You may now know the syntax of the language and basically what all of the features do, but that is nowhere close to a level of expertise. And this is not unique to that site. If you only read Stroustrup's book and do no coding then you're more or less in the same boat. These resources are there to give you the basic information needed to get started, there is no resource that will take you much further. What you need to do now is start writing code and reading code. Start learning more about the language itself and how the features work, start familiarizing yourself further with the standard library, etc. And this is not something that is really handed to you in tutorial form, you just have to start writing and learning bits and pieces as you solve problems or make mistakes. Hopefully you'll also not be working alone. Being able to work with more experienced programmers who will (gleefully) tell you your shit stinks and why is a huge, huge leg up.
Thanks for writing that up. I absolutely agree, and am finding myself to be struggling with think about the actual patterns. Gotta go deep into problem solving! 
I'm not familiar with FetchContent and ExternalProject. Why is the wrapper needed? When to use which?
So you learned all the languages of the Indian subcontinent from a website in the safety of his home in the rural US?
Not. I would say they are not proficient.
I don't recommend anyone to build external dependencies with CMake or any other tools. C and C++ are not node.js where you constantly re-download the world each time you build something. We have the chance that C and C++ offer shared libraries, so I encourage people to use the system libraries instead of building over and over the same ones. Furthermore, using the system libraries offer ABI compatibility under Linux distributions and security updates during the lifetime of the distribution release. Also, some distributions may patch the libraries for better integration within the OS, another reason to not ship yours. Note though, I have nothing against shipping your own library when it's very very small or meant to be integrated bundled (e.g. sqlite, lua, catch).
I'd love to see a better support for the XML documentation. Currently, one can write comments and IntelliSense will perfectly render hints when you use the functions, but there is no way to export and generate the documentation from it. 
That's surprising.
You're missing the point. The motivation of this build-dependency management is to work around outdated or unavailable system libraries. If there's a system library available in a suitable version for your project, there is indeed no reason to use a custom build.
Which is fine until the system library is version 1.1 and you need a feature from v2.0. Or you need a library that isn't included on the system.
You are right, unfortunately. I think this [issue](https://github.com/Alexpux/MINGW-packages/issues/3949) prevents gcc-8 being available.
Then limit the distributions you support to recent ones. There's no reason for desktop apps to support LTS releases, for instance.
Okay, how about this. Could you do this in an hour? 1. Write a container class for integers. Using only C++ 03 features. 2. Needs to have fairly clean code for Add, Remove, Insert, Pop, Push, Count. 3. Template it for all primitive types. I feel like this is something I could do in an hour, and I'd do a pretty good job of it. Maybe some other people could suggest 1 hour exercises that would help you figure out if you're really proficient.
&gt; And I don't understand why he got so many down votes. While I did not downvote him, I'd say it is because more and more cpp developers are getting pissed off at all those people that let the ecosystem rot, and kill every attempt t fix it by a "you suck and should just use whatever I use even if it obviously don't apply to you". In 2018, the state of the build systems are beyond awful, and are the primary threat to C++ survival. But if you mention that "virtualenv + pip install / pip freeze" is good, you get flooded by people telling you that C++ doesn't need anything like that. Headers-only libraries are a gross workaround to not suffer from the terrible state of build tools. People would prefer not be forced to do that, but as you have to do headers for template anyway, headers-only library are a loophole that dramatically reduces friction.
Case 5: A library that you don't want to include your own source tree and rather install from a known URL / repository? 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/9298ii/how_proficient_would_you_say_someone_is_in_c_if/e34d30r/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The older module, `ExternalProject`, only fetches external sources at build time, not configure time. This makes is difficult to resolve external dependencies (`find_package`, etc.) at configure time because they're not actually there until a `cmake --build .` / `make` command is issued. I haven't used it yet but `FetchContent` appears to address this issue, meaning there are much less reasons to use `ExternalProject`.
Eh fair enough.
This looks pretty promising. We use a pretty deep submodule structure and it's really quite painful. There's also a complicated cmake script to recursively update all the submodules (handling more cases than foonathan's simple example) duplicated in every repository. However, I'm concerned about the workflow when you actually work on the project that's currently in a submodule. It can be convenient to be able to edit / commit / push code within a submodule while working on a project that uses an in-house library. Also I wonder how well this works with indexing within an IDE.
then, containerize you build env would be a simpler and better solution.
Can you elaborate please? I don't see how that solves the problem of missing/outdated system libraries: You'd still have to get them into the container which brings you back to the initial problem.
This is a fine note. ☺
&gt; Unless otherwise required for some reason, always use std::from\_chars() to perform character conversions! 
Why no mention of `sscanf`? Processing 100,000 numbers as string with size 788,893 bytes as_sscanf Converted 100,000 in 1,407 ms as_atol Converted 100,000 in 5 ms as_strtoul Converted 100,000 in 3 ms as_from_chars Converted 100,000 in 1 ms as_stream Converted 100,000 in 12 ms as_stoul Converted 100,000 in 11 ms
`from_chars` is only available for compilers which support C++17, though. `atol` and `strtol` are available on practically every compiler.
Thanks for the link to jq. I'm impressed by the issues log - 361 open and 992 closed! It sounds like a lot of people are trying this.
&gt;Batch build... menu -&gt; build -&gt; batch build &gt;add function to save/load configurations. Waiting for this for ages... menu -&gt; tools -&gt; import and export settings 
For something so simple as: `while ('0' &lt;= *p &amp;&amp; *p &lt;= '9')` `value = value * 10 + *p++ - '0';` I'd be tempted to write custom code. It would have been interesting to see how it compared performance-wise.
This is something close to my heart, but unfortunately we're not on C++17 yet. It'd be interesting to put boost::lexical\_cast&lt;&gt; in there too.
Those return 0 on failure. How are you supposed to know if the original string was "0" or "derp"?
Stoi?
What about negative values, floats, out of range values, different bases, strings without terminating character (in your case &gt; '0' or &lt; '9')?
Eh, number parsing is annoyingly prone to errors and edge cases. While the code probably outperforms it also just doesn't work. What about negative numbers, strings that just aren't numbers, numbers out of range, leading whitespaces, optional \`+\` prefix and so on. 
Your solution handles overflow? Negative numbers?
I tested that against the [usual suspects in 2010](https://tinodidriksen.com/2010/02/cpp-convert-string-to-int-speed/), and it naturally performed really well. But it lacks so many features.
True, but what is your alternative? Do you write your own string conversion function?
It does, mostly `folly::to` of various flavors.
The pointer returned in the second parameter and errno. If it fails to parse anything the value of the second parameter will be the same as the value of the first. If the value is out of range it will set errno to a range error. 
When I compared this implementation with others it occurred that it performed very well. See the "naive" line on [this graph](https://cdn-images-1.medium.com/max/1200/1*a_qMM52klA1ku-Pgc6wVAg.png). [Link to the article with the full benchmark](https://medium.com/@julienjorge/benchmarking-atoui-a-follow-up-to-writing-fast-code-90e722590f4d).
maybe split it up into different headers so people can pull in just what they need.
I would love to see this kind of benchmark on mobile devices. Compilers have a long history of optimizations available for x86 architecture and x86 processors also have a long experience of optimizing the execution of instructions. What happens when we switch to ARM ?
This code assumes ascii and isn't locale safe.
 find\_package(dependency \[VERSION 1.42\])
The article includes atol(). atol() doesn't handle most of those things either. Skipping whitespace is easy, as is handling sign if necessary. We know what base we want, and we know the string is terminated. 
atol() doesn't handle overflow either.
In there (that family of functions, anyway) as std::stoul
Many people actually do
In this case, the (first) article specifies that all of the numbers are unsigned integers, and not ascii and not floating point. So no +/-. The article includes atol(), which doesn't handle numbers out of range, or strings that aren't numbers. The article includes std::from\_chars(), which does not skip leading whitespace, and the test code for the functions which do often skips it manually anyway. So my code conforms to the article's specification and could have been included. It's wrong to say "it just doesn't work".
from\_chars uses the "C" locale.
Please support all ligatures from Fira Code https://github.com/tonsky/FiraCode
The reason i found this article to be really helpful is because i work in an industry where i don't have administrative privileges on my computer. That means that **i can't install anything**. So, for me (and ask the people on my team), building every library from source for every projectis truly the best solution.
&gt; However, I'm concerned about the workflow when you actually work on the project that's currently in a submodule. It can be convenient to be able to edit / commit / push code within a submodule while working on a project that uses an in-house library. You'd have several options to make that easier. It can still pull git repos, so you should be able to work on them similarly. You could temporarily use `FETCHCONTENT_SOURCE_DIR[_&lt;ucName&gt;]` to point at another local copy of the dependencies, or `FETCHCONTENT_UPDATES_DISCONNECTED[_&lt;ucName&gt;]`while you make changes in the copies CMake pulled down. What I've done currently is provide a project-specific cache variable that sets `FETCHCONTENT_BASE_DIR`, defaulting it to a folder inside the root of the top-level project. Then, if `FETCHCONTENT_BASE_DIR` is relative to the project folder, CMake runs a `git init` inside of it which causes git commands in your project (like `git clean -dfx`) to ignore/skip it so that it's more permanent. We're considering defaulting `FETCHCONTENT_BASE_DIR` to somewhere more global, like `$HOME/.cmake/deps` or something like that for even more permanence, but that would probably necessitate always decorating the `&lt;name&gt;` given to `FetchContent_*` with a version or something like that, so multiple versions across multiple projects could be cached if required. &gt;Also I wonder how well this works with indexing within an IDE. I think as long as you don't constantly delete and re-download them, it should work normally.
IIRC Boost.Spirit.Qi handily outperforms then all. But it's of course a huge dependency, just to parse a number.
/discuss what exactly?
the fact that this thread exists is pretty depressing
Are coroutines actually useful for the real-life code, or it's a new `goto`.
I think it would be more idiomatic if it would look like this `FileMetaInfo meta_info = co_await FetchMetaInfo(file_path, &amp;meta_info);` and none of the explicit thread switching, but I don't know enough about this to say if you can implement it with your existing primitives.
Most OSS projects are an itch that somebody scratched. These itches can range from trying out some new technology, API or research paper, over being unsatisfied with current solutions to unavailability of any solutions. If you just pick a bug from a random project to work on you have no stake in it and thus no real motivation. But if you're using a library which has a bug or unimplemented feature which you really need sooner rather than later (or never, if the maintainer has no real interest in implementing it). Or if you're lacking a helpful tool noone wrote yet. Or something to automate some boring task you're doing yet again. It's much easier to stay motivated and see it through if it directly benefits you.
I think co-routines are the new inheritance. It might seem to make something difficult easy, but the reality is that is likely a double edged sword that doesn't buy you nearly as much as a better architecture. 
If you wanted discussion on whether coroutines in general are useful, why is the post solely focused on using them for this one particular purpose? 
Good Point! Updated my comment to be more factually accurate. Thanks:)
Tested on 6 different devices and only 1 compiler and OS... Could be better
The only man with rights to commit to mingw-packages repo - namely Alexpux - has just went on vacation for a month, so don't expect anything soon. Source - https://github.com/Alexpux/MINGW-packages/pull/3877#issuecomment-408123298
This "PostTaskAndReply" pattern is very common in Chromium project which is quite large C++ codebase.
x64 inline asssembly (I have not checked on this in awhile). Compiling mixed C++ and CUDA projects will not actually recompile .cuh and .cu files even after the files have been changed, and re saved multiple times. Note: this does not happen all the time, but it happens quite frequently. std::embed support, or at least something similar for embedding assets into a executable at compile time. Allowing multiple configuration windows be to shown at once, for different projects inside of a solution. Make the default header .hpp, or at least let the developer choose to make it the default. Fix the visual highlighting on the keywords that are not part of the C++ standard. For example, event, array, interface, literal and their double underscore prefixed counterparts.
The test code for the simpler use case is wrong. It generates inputs with leading spaces: vs.push_back(" " + to_string(i)); while `from_chars` does not support this and always bails out immediately. There really should be checks that you actually benchmark the correct results. And use [google/benchmark](https://github.com/google/benchmark/) for writing benchmarks.
&gt; Most important: Fewer, higher quality updates. What prevents you from just not updating as often? I'm really liking the faster update cycles compared to old VS versions. And the compiler point releases can also be installed side-by-side.
Format document and/or clang-format remove trailing whitespace.
&gt; it's usually an inconvenient or annoying thing that is handled for me correctly when using CLion. Like what? Without examples this seems rather unhelpful.
First thing I'd question is this part: auto current_task_runner = GetCurrentTaskRunner(); auto weak_this = weak_ptr_factory_.GetWeakPtr(); auto file_path = file_path_; because I'd do that in the lambda `[]`. Next I might want to try to find a way to combine these: co_await SwitchToTaskRunner{current_task_runner, FROM_HERE}; if (!weak_this) co_return; into one. Somehow have `co_await` trigger a `co_return` if `weak_this` is gone. I am not a coroutine expert, but I remember something like that was possible. Of course if (!weak_this) co_return; is a complete anti-pattern; you never check if a weak pointer is valid, you lock it. A next step would be to do compositional coroutines. This code is a function from file_path to meta_info: // We're on the background thread now. FileMetaInfo meta_info; FetchMetaInfo(file_path, &amp;meta_info); that happens to run on file_task_runner_: co_await SwitchToTaskRunner{file_task_runner_, FROM_HERE}; and this code is returning it to the this object: DidFetchMetaInfo(&amp;meta_info); So we have auto fetch_meta = [](auto file_path)-&gt;FileMetaInfo { FileMetaInfo meta_info; FetchMetaInfo(file_path, &amp;meta_info); return meta_info; }; and auto deliver_meta = [weak_this = weak_ptr_factory_.GetWeakPtr()]( FileMetaInfo meta ) { if (auto self = weak_this.lock()) self-&gt;DidFetchMetaInfo( &amp;meta ); }; which we then write a way to compose these tasks and pick which threads they run on? auto task = using( file_path ).on( file_task_runner_ ).run( deliver_meta ).then_on( current_task_runner ).run( deliver_meta ); task.launch(); but I guess that isn't coroutines (except maybe under the hood). 
&gt;always use std::from\_chars() to perform character conversions! I'd say always use your own function implemented in terms of std::from\_chars, because std::from\_chars interface is abominable.
&gt;always use std::from\_chars() to perform character conversions! I'd say always use your own function implemented in terms of std::from\_chars, because std::from\_chars interface is abominable.
I don't know what you mean. A batch build is relative to a Solution, and "import and export settings" is independent from any specific Solution.
Agreed. I use boost::lexical\_cast&lt;&gt; all the time when I need these conversions.
My understanding is that boost::lexical_cast is a wrapper around stringstream, so it is likely to have the same (bad) performance as the &gt;&gt; version. With that said, it is my first choice in non-performance-critical code.
It's an enterprise thing really. Each update cost developer (down)time and it's not easy (but now technically possible) to back out all developers to an earlier minor version. But it's mostly about quality and not frequency of course. Many releases from MS is not a problem as long as there's enough versions without critical bugs so that all third party tools etc can work with at least one modern version. We would likely benefit from a model where new features or higher-risk refactoring would stand out more as not just another routine, minor update. Or, something like an stable release stream which only contain a selected fraction of the minor releases. In regulated areas like medical, just making a new release can cost a lot both for sw producers and users so users don't get or want continuous delivery, but quality is crucial. 
"Just" find a container that already has all the system libraries you need, then require that everyone else has the same container available at runtime. Depending on context this can be anything from a neat way to bypass the whole issue to a completely useless unworkable idea.
I think it can be, especially for legacy single-threaded codebases. You can get the benefits of being able to do 'multiple' things at once, but without having to either a) rearchitecture things to support explicit callback-oriented asynch style, or b) hunt down and fix all global/shared state contention and go fully pre-emptive multithreaded. We did this recently at where I work, where we used stackful coroutines and boost::asio to update a legacy server codebase. I mean, in this particular case it would still be a great idea to clean up the existing architecture to be able to go pre-emptive multithreaded, but at least now that we have the coroutines in place and working, we can work on the cleanup while still enjoying the benefits of better responsiveness.
According to the standard, `from_chars` has a lot of limitations in order to be fast and it should be used only to convert things that you already know being correct numbers or preprocessed strings, such as inside a parser that already recognised something as a well formed number, e.g., inside a JSON / XML parser. On my machines, with GCC 8.1.0, the following cases are enough to convince me not to use it in the general case * "+1" is **not** converted (as anything starting with plus) * " 1" is **not** converted (as anything starting with space) * Both "0x1" and "0x01" are converted as 0 (this could be a big source of errors!) * "x1" is **not** converted Where "not converted", mean that it returns an error.
As I said in my answer, it's little things that add up. You don't generally remember all the little things _because_ they are little (what is unclear about this exactly?), but lets talk about some things that I don't even need to think of: The way it just knows how everything needs to work is the most immediate and most obvious one without even needing to give it any thought. It will just load anything and do it right the first time (VS will usually fight, complain, or load it wrong and you have to go change stuff), indent everything right, autocomplete functions and set them up right without missing things, warn you about things as you're doing them, refactors across entire projects and even catches refactoring mistakes in strings that VS will just not catch for me, the intelligent search that is actually intelligent and is aware of everything, the way it will seamlessly work with cmake but when I try to do it in VS it just explodes in my face and becomes such a burden that I default to having vcproj's now _just_ to avoid VS' cmake support, the way it's so easy to configure and navigate, I could go on. As I clearly said, these are all little things (minus cmake) that just add up. I have used VS longer than CLion, yet within literally 30 minutes or less I was more at home in CLion than VS which I've used for 5-6 years. That is a pretty serious problem for VS if a competing editor can make someone think that. IMO if VS doesn't get their shit together and CLion became free one day, VS would be in serious trouble. I've seen the same stuff happen between Eclipse and Intellij, Eclipse was the go to thing back in 2005-2006 onwards, then eventually Intellij came out and has been kicking its ass ever since. If CLion goes down that path then I see VS having the same problem happen since history will just repeat itself.
Shameless plug: [My library](https://gitlab.com/FJW/str_to_integer/) is even faster for most strings and has a nicer and more general interface. (Errors are for example reported as exceptions.)
They(MS) have been moving some long running tasks out of the main devenv process to a node.js subprocess. In task manager, if you expand VS2017 in the Processes tab, you can see all the spawned subprocesses and one of them will be a node server.
Ah, yes, understood. You didn't say it explicitly but by opening the CMakeCache.txt you are going through our CMake Import Cache process. I agree that needing to rebuild the cache when it's already there is less than ideal. The main reason we implemented it that way to begin with is so that we could better deal with multi-config caches (typically created by VS generators) and not have to use heuristics to guess what variables need to be set for any type of cache. That being said, we intend to address these problems as soon as we can. If you have any particular opinions or suggestions, feel free to let us know.
In response to the CMake specific items: *Reloading extension-settings when opening CMake projects / saving the CMakeLists trigger. Right now I have to go into the settings, select the "Remove trailingwhitespace" plugin's settings, and close it to enable the plugin. (Could also be nice to have removing unnecessary whitespace as a built-in feature).* I'm not following what you're saying. Can you provide more explicit steps and/or more information about what plugin or extension you're referring to? *Global hotkey duplication, it'd be nice to have F7 for CMake-build, msbuild, and any other systems.* Yes, this is a common piece of feedback that we plan on addressing sooner rather than later. *Global CMakeSettings.json variables. Having to copy an entry for CMAKE\_TOOLCHAIN\_FILE in each new project gets a little annoying.* Yes, this issue is on our radar as well. Thanks for the feedback!
I think there is an error on page 11. Should not the code in the cpp file be: `#include "multiply.h"` `#include &lt;iostream&gt;` `double MathToolbox::multiply(int x, int y)` `{` `return x*y;` `}` `int main()` `{` `std::cout &lt;&lt; MathToolbox().multiply(3, 11);` `}` The function could also be made static, but then I would need to write the header code as well ;)
Your understanding is outdated. lexical_cast uses specialized implementations for most common source/target type pairs. Try it on godbolt: https://godbolt.org/g/sVpNvz. A lot of unused code is generated, but there are no stringstreams, and the conversion is performed at compile time in this case (search for the main function).
Yes; I hope that `from_chars` will turn that around!
Sure, but paying for paying, someone can go for Visual Studio, which is also awesome, but still, VS comes with a commun edition, just like IntelliJ. Why the Java community can get more love than C++ one? 
&gt; Although no timings have been done for floating point (not yet implemented for VS2017 at the time of this writing) Floating-point from_chars() is available in VS 2017 15.8 Preview (currently Preview 5). I worked on its performance for months, and I benchmarked it as being ~40% faster than strtod()/strtof() on my machine. Note that while I implemented integer from_chars() and to_chars() with some attention to performance, they aren't hyper-optimized yet (in particular, I am aware of techniques to make to_chars() faster). I focused on getting a correct implementation with extensive testing first, so we could optimize it behind-the-scenes later. I'm working on floating-point to_chars() right now - the performance of the shortest-representation (non-precision) overloads will be *amazing*. (Over 10x to 40x faster than sprintf() - times not percent.)
So, you successfully proved than a user error resulting in a no-op is faster than actually performing the work?
clang-format does not do this, neither does it force a single newline at the end of the file either. Getting VSCode to do this for me when I save is trivial.
I feel like I want so little: * Ctrl+Backspace in the global find+replace box. * Escape hides auto-hidden panels (even when the cursor is over them). * Refactor should not show the output window (global find+replace does not do this, nor does vs2015). * VS crashes quite a lot, and although it can auto-save code, it fails to preserve other user data (open tabs, bookmarks, breakpoints, etc). * An optional compiler warning for when overriding a virtual method without using the override keyword. * Fuzzy intellisense working like it did in vs2015 (don't know what its doing now, seems plain broken).
... no mention of LTO ? is this serious ? 
I don't want to be very negative, but this is very shallow. I posit the author did not really know C++, even his conversion program is written in C# (and then no mention of the many cases that program would not work).
Also it was a missed opportunity to be constexpr. from_chars in libstdc++ looks like it is implemented like a standard naive loop of result = (result*10) + (c-'0') in the godbolt assembly
&gt; Over 10x to 40x faster than sprintf() Wow! awesome!
Relying on the compiler to fix slow bad code seems like the wrong thing to do imo, especially when it can be trivially fixed. just because optimizations exist, doesn't mean you should write slow code. not that anyones writing min and max, since it's in standard and all. Ideally there would simply be two versions of the functions that simply SFINAE for primitives or not, doing the correct thing for them(by value). or could make it smarter and have it SFINAE on the object size, going by value if it's small enough. especially since someone commented to say that it actually *doesn't* get optimized/optimized enough.
The entire concept of header-only performance is confusing. It just means you're putting the code in the same translation unit - headers aren't magical. LTO effectively does *the same* thing.
This is due to the awesomeness of Ulf Adams' novel [Ryu algorithm](https://github.com/ulfjack/ryu), which is faster than the previously best-known algorithm Grisu. It's also due to the relative expense of sprintf; printing a given precision requires bignums.
Ofcourse, the extension in the example (although I have experienced it with others in the past) formats the document when it's saved; specifically removes whitespace at the end of lines. It has a settings page (Tools-&gt;Options-&gt;Remove Trailing..) where you can toggle auto-formatting on saving. When VS15 is first started, some code is written, and the doc saved; the auto-formatting is not triggered. I have to go into the options (where the auto-formatting is listed as enabled), mark the option and then just close the options popup via the 'ok' button for it to (I assume) load its configuration. After which it works as intended. I only experience this when loading CMake projects, vcxproj projects work as intended. https://marketplace.visualstudio.com/items?itemName=Predelnik.RemoveTrailingWhitespaces
&gt; Ideally there would simply be two versions of the functions that simply SFINAE for primitives or not, doing the correct thing for them(by value). &gt; &gt; or could make it smarter and have it SFINAE on the object size, going by value if it's small enough. &gt; &gt; especially since someone commented to say that it actually doesn't get optimized/optimized enough. I would expected that compilers either* do this or have reference-to-copy optimization. Not having any of these is surprising. *: first might be mantaded by the standard
Character conversion mult and add. If you can use sse/mmx to do it in parallel that should be fastest.
I'd just like it to use the build directory I told it to use. All my testing and other libraries rely on build directories being in a certain place so it can discover the exported targets. That's no good in a CMakeBuilds directory hidden somewhere in /Users. Super extra brownie points if it realises it's a WSL generated build directory, and automatically runs the build from with WSL. That would be ice cream buying time.
&gt;fluentcpp.com/2018/0... Is there a possibility of these super fast implementations being available as a separate library for use with us c++11/14 people at some point?
Why is it difficult for you to enable `/std:c++17` mode?
&gt; LTO effectively does the same thing. I seem to remember some post by the LLVM guys that showed that there was a slight performance gain when using LTO vs for instance a unity build, since apparently it gave a bit more leeway to the compiler, but I can't find it anymore.
I've always used stoi without looking too much into it... has my whole life been a lie?
A Unity build generally doesn't merge *all* translation units, but rather just common ones together.
On platforms like Windows threads are very cheap and using a bunch of even short-lived ones to just download URLs simplify the general architecture and the code while using co-routines —at least in C++— would make the code more difficult to follow as you have to consider all the cases such as time outs, connections dropped etc. and not only the good cases. I would probably just use a thread-pool to limit the amount of parallel connections. Notice that long time ago I used to be a great fan of co-routines, that was before realising that the ability of understanding the code —i.e., debug, modify etc.— has a much greater importance than "efficiency to the last bit".
Ah, sorry. Changes are coming quick these days, keeping track of the builds that have specific fixes is challenging at times. :) The ability to turn off the notification will be in 15.8 (you can check it in the Preview build if you'd like). As far as the ninja behavior. We'll take a look. Thanks!
In a lot of the code I write, I **don't** want locale support. Parsing little languages, reading data from well-defined formats etc. atoi/strtol charge a huge runtime price for the possibility of locale support even when the locale is always known to be "C" at compile time.
dont get caught optimizing too early. worry about the maths and overarching structure first, then do the tidbits. atleast thats what you should do
Finally! I'm surprised this took this long, but I'm glad it is there. Does this mean that libc++ + clang can be used on windows along with &lt;filesystem&gt; now? I remember this was a road block last time I tried to convert to using clang on windows. 
Default off, see [https://github.com/llvm-mirror/libcxx/blob/8634f6fcca8961d4a7db9dedaebf2ce216cd0592/CMakeLists.txt#L73](https://github.com/llvm-mirror/libcxx/blob/8634f6fcca8961d4a7db9dedaebf2ce216cd0592/CMakeLists.txt#L73). I will test it.
Because we compile on Debian Jessie with clang 3.5. Not really possible at the moment to update the OS as this is an "embedded" application where we sell hardware to the customer. 
Wow thanks! :)
While I admire the goal, I am still saddened by the poor separation of concerns. What is needed is a separate tool to perform portable package management and building which is not based on CMake. Not because I don't like CMake, this is my go-to build system, but because there are projects that don't and on which I may need to depend. A good package manager, with one file config per project that CMake can natively generate, and link to, is much better. pkg-config is so close to meeting that requirement it is sad we don't just add the missing features to it.
Keep doing what you do Mr. STL, making lives of C++ devs better everyday.
because the visual effects industry typically adheres to the vfx reference platform https://www.vfxplatform.com for compatibility across software apps/libraries/plug-ins. it's quite behind what I would like it to be personally. 
That got me thinking, would a hardware implementation of converting between strings and integers give a noticeable improvement to servers running server side scripts or databases?
This is beyond pointless.
"CMake - the de-facto standard build tool - and git - the de-facto source code version control system." - WAT? Not in plenty of game studios, not in google, not in facebook, not in many, many other places. 
i don't think that would technically be standard compliant, though it would have no visible affect to the user.
Ah, I see! My Ryu-derived code will be Boost-licensed but not the entirety of charconv, so it won’t be separately usable, at least for now. Perhaps you can use Ryu directly? It doesn’t follow the charconv interface (no bounds checking, etc.) but can write directly into a buffer with null termination and no memory allocation.
I work for one of those groups you mentioned that don't primarily use cmake or git. Yes, git and cmake are still the de-facto standard. We just use special purpose tools to fit our special purpose needs.
According to my vague understanding it should be possible to build and run newer Clangs on older OSes, but I see the difficulty. Like I mentioned to danmarell, perhaps you can use Ryu directly to print floats/doubles.
Microsoft's implementation of `&lt;filesystem&gt;` on Windows is pretty good (even has &gt;260 path support), I wonder if it's possible to use that?
Conan fulfills all your requirements and more. 
Is it confirming already confirming to c++17? I've heard there were some changes between the TS and what landed in the standard.
Is it already conforming to c++17? I've heard there were some changes between the TS and what landed in the standard.
His general point stands though: having two related pieces of code in the same translation unit vs in two might produce slightly different results even with lto enabled (I'm not up to date with the latest development in that field though). In fact that would have been a more meaningful benchmark: Compare unity build with LTO build.
&gt; Unless otherwise required for some reason. If you need to be able to compile with older standards that qualifies as "some reason"
clang-format does remove trailing whitespaces for me.
&gt; On platforms like Windows threads are very cheap **[to create?]** and using a bunch of even short-lived ones ... when did windows become not-the-slowest OS at creating threads?
All the unity builds I've worked with have always been with all the translation units in the project
if you are using clang 3.5 you are not using the reference compiler of debian anyways so why aren't you just using a clang-6 deb ? 
Yes, You can use it.
See https://github.com/llvm-mirror/libcxx/commit/789c3724564b1592fc1f0f6235dfc9195664febd
Not unless rdtsc (below) is correct; he indicates that from_chars was simply used incorrectly and didn't do any work. 
 Some issues I regularly encounter: 1. File recover == please delete my file. If my computer crashes, on restart of VS it will sometimes ask if I want to recover some file, saying yes is always a terrible idea as it will turn the file into garbage. If I click no, the file is generally fine. 2. The IDE is still locks up for around 1 minute when I rebuild project files using premake 3. Many things cause IDE to pause and become unresponsive, such as switching between debug/release, but this happens everywhere, just switching between files will sometimes cause the IDE to hang briefly. 
Hi, reproc is my first open source library. I got the idea when looking for cross-platform process libraries to use for implementing CMake support in [https://github.com/cquery-project/cquery](https://github.com/cquery-project/cquery). I didn't find any that fit my needs so I decided to make my own. The core of the library is written in C but a C++ wrapper is also included that makes reproc easy to use from C++ and adds an extra function that makes to allow for parsing separate messages from an output stream (stdout or stderr). Any feedback on code or documentation is highly appreciated.
I just skimmed it, but it appears there is no comparison of compile time performance, typically the huge problem associated with header-only libraries. There is also no comparison of runtime performance. "Programmer performance" is an interesting metric, but given that programmer performance differs wildly between individuals, a sample size of 10 seems a bit on the low side. &gt;Care must be taken to ensure the code still follows the constraints of the C++ standard. Notably, the use of templating when appropriate to prevent unwanted internal linkage Eh? 
I had included a x platform process caller in my library, but I could never get stdin working! 
Nlohmann json is excellent. I recently replace all my rapid json code with it. A pleasure to use by comparison.
You would need to store the current time when it gets executed first and check on each subsequent call if the elapsed time is greater than one day. But this qsounds like the [XY Problem](https://en.wikipedia.org/wiki/XY_problem). What do you want to achieve with this?
cron?
`void at_most_once_per_day()` `{` `static time_t last_day;` `time_t today = time(nullptr) / (24 * 60 * 60);` `if (today == last_day)` `return;` `last_day = today;` `// do something interesting at most once per day` `}` Note that it's not thread safe.
Forward and backward loops. 
just do the text substitution of the arguments in your head.
I think they are short hand for various for loop variants. REP for repeat (exclusive) probably and FOR for “for” (inclusive). Then the last character is the direction (F = forward, B = backwards). Don’t be fooled by the underscores, they are just names. Instantiate REPF(i, 0, 5) { } and you will get “for (__typeof(0) i = 0; i &lt; 5; ++i) { }” for instance...
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The guy who does the clang packages for Debian also makes backports for older Debian releases. Unfortunately this doesn't include libstdc++ or libc++, so we can get new language features but not new library features. 
Clang 3.5 is the compiler shipped with Debian 8 (Jessie).
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
We have boost.process now, what is the difference apart implementation in C?
yes, but the reference compiler for Debian is GCC, not clang. 
I see what you mean now. Yes, I could go to apt.llvm.org and get a clang-6 .deb (even made by the same guy who does *all* clang packaging for Debian). But that doesn't get me a new libstdc++ or libc++, so there are a bunch of new features I can't use. 
&gt; Eh? This really shows that the author of the paper doesn't really know C++ and that he shouldn't use a random forum post as a reference. He refers to the second post of http://www.palabos.org/forum/read.php?4,1110 Anyways, that forum post is also completely wrong and that author seems to misunderstand linkage.
There's the usual arguments against Boost that apply. There are projects that do not want to have a dependency on Boost (including the project that reproc was created for: cquery). It should also be a lot lighter on compile times (although I haven't compared). I also think reproc is a lot simpler than boost.process, both in API and in implementation. While this means not all features of boost.process are supported I think this leads to a smaller surface for bugs and an easier time getting started for both users and contributors. As far as implementation goes, from a quick look at the boost.process source it seems boost.process and reproc mostly apply the same solutions to making sure file descriptors and handles are not leaked to child processes. boost.process doesn't document any of this however so it's hard to say in which cases it will leak file descriptors and in which cases it won't (it's not trivial to never leak file descriptors). Boost.process also does not allow to stop child processes while still allowing them to perform cleanup. reproc does support this with reproc\_terminate which sends a SIGTERM signal on POSIX and a CTRL-BREAK signal on Windows. These signals can be caught in the signal handler of a child process which allows them to perform cleanup. The Boost.process terminate method calls TerminateProcess on Windows and sends a SIGKILL signal on POSIX. Both do not allow the child process to perform any cleanup and could result in resource leaks. Even if a signal handler for CTRL-BREAK is not defined, it's default implementation for console applications still allows for a lot more cleanup compared to calling TerminateProcess. It doesn't have a default implementation for non-console applications but since working with console applications is the main use case of reproc I think that's an acceptable trade-off. In short, if you're already using Boost you're probably better off with boost.process. If you're not using Boost then reproc should be a good alternative.
This video shows that we can write "user values" to the object in Lua. This will allow the person writing the script to add information that doesn't existing on a the native type that we are binding. This isn't something you need to support when binding your native type to Lua, but it's a pretty handy feature to have and it doesn't take much extra work. [Embedding Lua in C++ #31 - Handling User Values Using Run Time Type Information](https://youtu.be/4shj4fxhcvk) There isn't a whole lot to do with the run time type information in this video, we are really just making sure that we don't interfer with it when we are reading and wriing user values.
When you fork a new process, file handles and other resources are copied to the new process. So you'd create some pipes with the pipe (man 2 pipe) system call in the parent process, fork, close the child process stdin, stdout and stderr and dup2 the new pipe handles over stdin, stdout and stderr in the child. Then you can drive the child process by sending character data through the child input pipe endpoint and reading the child output ones. That always seems to be a little fiddly to get working, but once you know how everything fits together it's not too hard.
I'd add that this isn't terribly complex even if it's kind of hard to find a "everything you never wanted to know about processes but were forced to learn" document on the internet. It's probably not a bad idea to know how to do the low-level stuff raw. Especially since I've never seen a process library that gives you the same level of control over the child process as a custom-made hand-rolled one. It's an incredibly powerful tool to have in your toolbox -- on one contract I was working, the code we were maintaining was prone to crashing, which inevitably led to one of us being called in on the weekend. I don't like being called in on the weekend, so I wrote a launcher that started the main program with one file per iteration and watched the process return code that you get with wait. If the program crashed, I'd move the offending file off to a crash directory and continued processing other files. After deploying that we never got called in on the weekend again. 
That's basically what reproc does on POSIX. Although there is a lot of extra logic to make sure all resources are always cleanup and to avoid file descriptors getting leaked to child processes. This is especially hard when processes are started from multiple threads since even setting the FD\_CLOEXEC flag immediately after creating a file descriptor does not avoid race conditions. Luckily most systems (except for MacOS) support the O\_CLOEXEC flag on the pipe2 function which does eliminate this race condition. Although in a library you can't assume that every pipe or other file descriptor is created with the FD\_CLOEXEC flag set so just to be sure reproc closes all open file descriptors below the file descriptor resource limit before calling exec to avoid any of those file descriptors leaking to reproc child processes.
Sure I can do this - or jsut remove the 32 bit target, but I want it to be the default for all templates on all machines so that I don't have to do it again and again myself - thats the purpose of a default.
They need some products to advertise and some to make money with
Is that a yes? That paper talks about some (minor) open issues that will be addressed by LWG. Have those fixes (whatever they are) also been applied?
When you need support async read/write ，you should use CreateNamePipe under windows. see libuv https://github.com/libuv/libuv/blob/v1.x/src/win/pipe.c under linux You need to pay attention asyn signal safe when this library used for multi-thread pocess.
I'd rather see these systems (buck, pants, bazel, pleasebuild, gn, etc.) take over than CMake. For one, they provide sane syntax, and uniform way to describe your targets, deps, etc. As for git, I stay back. I'm happy p4 user now, though was much happier with g4. 
Isn't it kind of arbitrary in a sense? I have to guess it's just author preference, people writing what their comfortable with. A text editor is not necessarily something that is going to stretch the limits of the features of a language, and it doesn't demand very high performance. 
You also have Kate and, if you consider IDEs as text editors you have Qt Creator and KDevelop.
Poor handling of Unicode, perhaps?
When you use project templates, your template is your default. Otherwise you'll have to mess with the .props files, not undoable, but I never tried.
Why should I mess with the props files?
 1. Not everyone is living in first third country, able to easily afford a "small" 20+ dollar license. Heck, even in first world countries there are many who barely scrape by, and can't afford 20 dollars. 2. Not everyone has a way to pay for them - some people are underage for example, and can't easily buy stuff online. 3. FOSS is a great thing. It's best to support free as in freedom software. The OP asked for FOSS, which makes it vastly more likely that it's a matter of philosophy(libre versus proprietary). but OP also talked about "commercial" instead of proprietary, which indeed makes it not obvious - I assume that Op knows about the gratis version of sourcetrail, as the first googlesearch for "sourcetrail" gives the website with downloads for all platforms, instead of something like "purchase"/"licensing". 
Kakoune (r/http://kakoune.org, source code at r/http://github.com/mawww/kakoune, disclaimer: I am the main author) is a C++ text editor. As to why there are few of those, I am not sure that is the case in the grand scheme of things. I think it is definitely the case in the Linux/Posix world, but not in the Windows world, however open source is not as common (historically) in the Windows world, so implementation language used for those applications tend to be hidden. For the Posix world, I think one reason is that text editors tend to need to be portable across systems (when one invest time in mastering a text editor, they want to be able to use it easily on the various platforms they work with), which was not a perceived strenght of C++ for a long time (No standard until C++98, flaky portability between compilers for several years after that). That means C was favored, often alongside a scripting language (implemented in C). Things have changed nowadays, with many core tool in the Open Source echo system moving to C++ instead of C (I am thinking of GCC and Gdb for example). But in the mean time, other languages appeared (Go, Rust...) and writting a text editor is usually a good playground to experiment with a new language (one of my own motivations when starting on Kakoune was to play with C++11, that I could not use at work yet). Hope this makes sense, if you want to take a look at Kakoune's code do not hesitate to ask questions.
If anyone here is having issues with CLion performance (I know I was), hit me up, there's a good chance CLion's java performance environment settings are killing you. I've changed up my vm options quite a bit, and it's a night and day difference! Highlighting and syntax changes are quite slow to propagate still, but it's no longer freezing for seconds at a time.
go back to working on beast Vinnie!
try this one https://www.scintilla.org/
Hey, if you and the other CLion team are still around, I was wondering if you could give me some pointers on optimizing my vmoptions for better performance. CLion is pretty laggy in my projects if I don't have these settings just right.
&gt; Stallman hates open source [source needed]. My research says, that Stallman: 1. Hates using the term "open source" to talk about software that is free as in freedom. 2. Hates proprietary software. 3. Loves copyleft licenses.
All the other editors work well enough that I don't feel like writing my own. You'd probably have to roll all your own GUI components, which is an exhausting idea. I suppose you could use QT if its text input widgets are flexible enough to suit your needs. I always look at QT and realize how much kool-aid I'm going to have to drink to use the library, so that's really about as far as I ever get with it.
Kate and KDevelop are amazing. My favorite editor/IDE.
Yes.
&gt; (r/http://kakoune.org, source code at r/http://github.com/mawww/kakoune, Your links are incorrectly formatted.
Because all the good ones have already been written before C++.
Yup, you can only ever go full Qt. No half measures.
When it comes to the Qt Kool-aid, you can avoid a lot of it by seperating the GUI from the core of the program. I write the core of the program as a library with standard C++, then write command line, console, and gui tools that link to it depending on what I need.
Code::Blocks is also written in C++
codelite as well.
Text editors demand very low latency for a smooth editing experience, and most editors choke on large files. I wouldn't say that text editors don't demand high performance.
&gt; you can avoid a lot of it by seperating the GUI from the core of the program. Well, that's why we have (UI) design patternss such as view-controller-model. &gt; Qt Kool-aid I wonder what people mean by this, I couldn't write a nice GUI if my life depended on it, but I have written a few small UI applications and tested quite a few APIs in labs during my UI design class. Qt is actually a pretty decent framework, especially compared to stuff such as WPF and GTK3. I have found using it rather pleasant, in spite of few problems that I encountered (mostly related to shipping it and using C++17 compiler).
Maybe it does, but certainly not when I use it with VS. 
I'm going to trust them extra hard just because you said not to.
Don't trust microbenchmarks
Why not the way around then?
Chandler Carruth did a couple of good talks about benchmarking C++. One of them is [here](https://youtu.be/nXaxk27zwlk). Worth a watch.
A bit of topic, but i want to thank you (and every other contributor) for Kakoune. It's definetly the best editor I ever worked with. 
Saw this CppCon - 2017 talk recently [https://www.youtube.com/watch?v=PNRju6\_yn3o](https://www.youtube.com/watch?v=PNRju6_yn3o) which talked about the same problem and implemented a solution which was much more difficult to read. How are other C++ "alternatives" like Rust, D or Crystal fare in these kind of things? One of the main motto of using C++ is Zero cost abstractions, if that needs the programmer going all way out to use some meta programming and it is not taken care of by the language/compiler, then it really does not worth it. Sorry if that sounds like a rant. But for application developers, understanding so much language intrinsics like forward reference, reference collapse rules and a bunch of helper functions, is too much. If you are going to say that application need not care so much about performance, please no, then we wouldn't be using C++ in the first place.
Mine does, within VS. Though I am honestly not sure whether I am using the clang-format plugin or the new VS integrated clang-format support. I do have the plugin installed, so I think both are active, and I normally press CTRL+R, CTRL+T, which I believe is mapped to the plugin. Actually I think CTRL+K, CTRL+F is the shortcut to invoke the VS-integrated clang-format, and indeed you're right, that shortcut formats the code too, but it doesn't remove trailing whitespaces. Might be worth filing a bug report?
A Kate developer here: The source code of Kate is split into a highlighting framework called [KSyntaxHighlighting](https://github.com/KDE/syntax-highlighting], the Text Editor component [KTextEditor](https://github.com/KDE/ktexteditor), and the application [Kate](https://github.com/KDE/kate). Although a bit hidden, there are also some [interesting articles](https://kate-editor.org/2016/11/15/ksyntaxhighlighting-a-new-syntax-highlighting-framework/) on the Kate Editor homepage. If you are interested in contributing, please let me know.
&gt; I wonder what people (you and /u/FlyingRhenquest) mean by this. You kinda have to commit to Qt to use it. There's nothing wrong with Qt and it's a great library, but I like to make it an optional dependency which requires significant amounts of extra work. If you're writing a very GUI heavy program, then by all means go all in with Qt, but most of the stuff I write is frontends for programs that already have TUIs or CLIs, and are coded with standard C++(11) in mind.
Just to make sure: You know you can set the build directory in the CMakeSettings.json right? 
Sure, but if I have to edit json files, it's now faster to not use Visual Studio at all and just use the command line. The whole json file thing is unhelpful anyway in my opinion. It suggests they haven't got the use case flow mapped out right yet. Let me put this another way: no other IDE which supports cmake project loading has or needs such a thing. Neither should VS.
&gt; like moc and qmake if you decide to use it. There are build systems such as meson that handle all of that: qt_preproc = qt5.preprocess( qresources: 'dvc_toggler_linux.qrc', moc_headers: [ 'main_window.hpp','profile_selector.hpp' ])
If you are using cmake, you can use catch's crest integration, which in turn is integrated with VS. A bit brittle at times, but it works.
I am interested in contributing, got any pointers?
what is it?
using random inputs or reading inputs from `stdin` / `argv` helps avoid this kind of "known input" optimizations.
&gt;Adding it into a proper modern CMake build is tricky. CMake is literally the only supported build system for the single largest user of Qt libraries ([KDE.org](https://KDE.org)). Qt itself exports CMake metadata, and the KDE CMake support isn't hard to use either (it's a library that deliberately has no other KDE dependencies called "extra-cmake-modules"). moc really only applies if you're making heavy use of custom QObjects and their related features or GUI event loops. Even if you have to use it, CMake natively supports moc (assuming you don't want to use qmake), so it's typically transparent in use. Qt is modular enough that it's quite nice to use as a CLI-only or TUI-only library (you strip out QtGui, QtWidgets, the QML bits, but leave in QtCore and perhaps QtNetwork or QtSql). I would actually expect the use of things like QString and QList to be more annoying than moc or qmake in that context. Qt has quite a few STL and C++11-compatibility additions to make it easier to use from more "standard C++" code, but it still typically uses Qt types throughout, and that's where it can be annoying to try to use from non-Qt code (at least in my opinion). Especially if you're trying to make Qt an optional dependency! But even there, one can "buy into" parts of Qt at a time without having to go whole hog or go crazy with Qt-specific features, and even from CUI/TUI Qt has features that can be *extremely* helpful, like support for network, database, event-driven or asynchronous I/O codes, JSON, etc etc. Personally though, I've taken to using scripting languages for things I'd do at a TUI/CLI, since they usually end up being I/O bound anyways for the problems I've had.
\[Ewig\]([https://github.com/arximboldi/ewig](https://github.com/arximboldi/ewig))
I've had really bad luck with getting moc and Qt working with CMake, it's been a while though. I remember having a lot of problems getting automoc to work correctly.
Errr.... popen()?
&gt; I usually prefer keeping the benchmarked function in a separate translation unit in order to guarantee that the compiler cannot take advantage of the code setting up the benchmark What about Link Time Optimization? Or is that almost never used?
Benchmarks are such a tricky subject. You don't want to allow optimizations that bypass the procedure you want to benchmark, but at the same time you need to allow all other optimizations that would apply in a real world scenario.
I personally wouldn't use VS on Linux, but I think a lot of people would do. 
SublimeText is c++
In 2018 this is not what I consider "very high performance."
It interoperates with other stuff quite well. You can use it for its UI and not much else, if you so wish.
Qt is an application development framework. It gives you I/O, networking, a javascript engine with a jit (for the platforms that allow jit, iOS not being one of them), asynchronous goodies, etc. moc is a code generator. I presume if you're not using code generator, you're not good at your job, so you're not too qualified to talk about it much. I'm serious. Code generation is there so that you don't have to be like a high-level assembler. It works under cmake just fine. Really. And qmake is cmake's precursor - it does the same job. At least it's a very small code base, so if you want to understand it - it's right there, and small enough to comprehend in an afternoon. If you're serious about your work, you'll be depending on lots of other big libraries, like boost for example. The world isn't uniform. Dealing with something the size of Qt is no biggie anymore - or at least it shouldn't be for anyone competent.
Personally, QString seems like a class that's missing from just about everything, including C++ itself. `std::basic_string` is a stripped down academic curiosity, not supporting even a third of common things people need to do with strings. It's kinda sad.
I deleted that (so that says it all), but not fast enough.
Don't use coros to mimic the old system behavior, think differently from a design standpoint. In your case you have a job, which is owned by a task runner. We post a task on the file_task_runner and then run the continuation on the job's original task. This can be rewritten as: ``` void URLFileJob::Start() { cuurentTaskRunner-&gt;Do(urlFileJob(file_path, myOutput)); } SimpleFuture URLFileJob::urlFileJob(string file_path, shared_ptr&lt;outInfo&gt; outInf) { FileMetadataInfo info; co_await file_task_runner-&gt;Do(FetchMetadataInfo(file_path, info)); // returns on our current task runner // continuation here/ } ``` This does require more refactoring than your original code, but you can get more out of coroutines. 
In 2018, most text editors still choke on large files. Call it what you want but it seems to be a problem that most struggle to solve.
That's all true, however the vast majority of my projects are fairly simple. On the big ones I do use code generators and big frameworks like Qt and boost. I've found that taking proper advantage of templates post-C++11 has eliminated the vast majority of my use cases for code generation anyway, and I like to keep my dependencies simple for easier distribution. Really post C++11, I find the the standard library can do most of what I used 3rd party libs like boost for previously. Specifically when I tried to get Qt to work with cmake, I couldn't get automoc to work properly with a nested include directory combined with file globs without resorting to some nasty hacks.
So what to do (serious question)?
Only if you like shell vulnerabilities...
Someone will say this eventually, so to get it out of the way... Drop the IDE entirely, switch to VIM (or EMACS), and learn how to use GDB/DDD for debugging. There, it's been said. We can move on with other suggestions now :D Seriously though, it's not a terrible suggestion, though it's definitely not integrated. The other top options would be Eclipse or Netbeans, but I never had any luck getting them to work worth a damn.
I've been fairly happy with CLion (https://www.jetbrains.com/clion/). It's free for students. 
Let's also get out of the way: Visual Studio Code. No, it's not "an IDE", but it has integrated editing, building, and debugging, and only relies on an external build system.
Or just keep using windows. 
There is a GDB extension for VS Code that adds pretty good breakpoint support. You can also configure GCC to treat certain warnings as errors.
What is an IDE in your definition then? Because integrated editing, building and debugging usually meets the definition.
I am curious as well. I have found that without a paycheck my motivation write c++ code is nullptr. Although I can see some minor motivation to open source it after the fact except in my experiences I was fortunate enough to retain copyright otherwise I would in a heartbeat.
Femtobenchmarks.
I'd certainly call VSCode an IDE. Even VIM can be made a IDE of sorts if you stuff around and install a stack of plugins but it always feels fragile and unwieldy compared to a proper IDE like VSCode.
Using YouCompleteMe in Vim is as good as using an IDE for code completion.
Not sure if we can use /u/STL distro as a drop-in replacement for gcc in the ming64 repo. Anyone tried this before?
It continues to improve, but there are some odd false positives in its semantic analysis. Notably using the address-of operator on the result of a function call returning `T&amp;` for whatever type `T` will give you the red squiggles, though compilers are happy, do not warn, and as far as I know, is legal; please educate me if I'm wrong.
Clion would do the job, still have some glitch though, but overall integration has done quite well. I don't like vscode either, its IntelliSense still work on progress (no local variable support) and debug require you to create a profile for the executable (Clion can does this automatically). VIM/EMACS is the pain in the ass when it comes to refactor.
I'm an emacs person, so naturally I think you should join my side of the holy war. ;-) In all seriousness, I'm not sure you're going to find a complete, feature-for-feature replacement of Visual Studio, so you might be disappointed... I've used Qt Creator lightly in the past and it's actually pretty good. You don't need to be using the Qt framework in your project to use the IDE. Qt Creator understands CMake projects out of the box. If you're not using CMake, it lets you customize the build configuration so it can theoretically be wired up to work with any build system. Debugger's built right in (though I'm not really qualified to speak to its effectiveness). There's also a [list of C/C++ IDEs on wikipedia](https://en.wikipedia.org/wiki/Comparison_of_integrated_development_environments#C/C++) you might be interested in perusing. My opinionated take on this topic is that a GNU/Linux system \*is\* an IDE.
QtCreator is free and gets regular updates. It's written in C++ and is not as memory intensive as Java based IDE's like Clion or NetBeans. Also it looks great. 
You can certainly use *emacs* with [cquery](https://github.com/cquery-project/cquery) LSP support. `cquery` is very easy to setup and works very well out of the box.
You can certainly use *emacs* with [cquery](https://github.com/cquery-project/cquery) LSP support. `cquery` is very easy to setup and works very well out of the box.
&gt; Femtobenchmarks ? 
&gt;a GNU/Linux system *is* an IDE. Instead of typing F5, I type `make`. Instead of clicking Run-&gt;Start With Debugging I type `gdb myCoolProgram`. I’ve never heard it expressed this way before. I wish I could say you bagged a convert, but...I’m already an emacs user. In any case, that’s an excellent framing.
Any chance of marrying the Kate components with neovim? I know Kate has vim emulation, but neovim is much more advanced.
QtCreator and Kdevelop are my GoTo IDE for C and C++.
That has nothing to do with language performance. It's how you handle large files. Older more mature text editors for example only load in part of the file so it seems really fast even on massive files.
You missed the quotes, and the point. ;-] I would call it an IDE, but this is the "get it out of the way" subthread – it doesn't call itself an IDE, and every time this thread pops up there's a pointless subthread on how it's not a "real IDE". Attempting to debate that here is _entirely_ defeating the purpose.
Can you provide a MWE? I just tried with this: #include &lt;iostream&gt; #include &lt;iomanip&gt; template &lt;typename T&gt; struct Something { T value; }; template &lt;typename T&gt; T&amp; get_value(Something&lt;T&gt;&amp; something) { return something.value; } int main() { Something&lt;int&gt; s{15}; std::cout &lt;&lt; std::hex &lt;&lt; &amp;get_value(s) &lt;&lt; '\n'; return 0; } and I'm not getting any issues.
Ok, no worries ;)
Kdevelop is a very solid alternative too. Visit kdevelop.org and see what it has to offer. 
KDevelop is my favourite, but is quite heavy on memory.
Thanks for all the quick responses everyone. There are definitely a few that I want to try out here
https://en.wikipedia.org/wiki/Metric_prefix
People need string _algorithms_; algorithms do not belong directly on data types (in C++). `std::basic_string` is not the issue, and `QString` is _not_ the solution.
Is there going to be a to_chars() compatible with constexpr? Currently relying on hacks + recursive template functions to get my compile-time string generation so I can print number-formatted strings during compile time.
Not unless it’s mandated by the Standard, as I need a couple of intrinsics on x64. Would be possible, though.
Sure, ideally, but in reality if they aren't already that doesn't help the stdlib dev... https://www.reddit.com/r/cpp/comments/92bkxp/how_to_efficiently_convert_a_string_to_an_int_in_c/e384xjr/
Well, until such a time comes, I have to rely on techniques like ones from [template tetris.](https://blog.mattbierner.com/stupid-template-tricks-super-template-tetris/) Or template stuff like: template &lt;size_t A, size_t B&gt; struct TAssertEquality { static_assert(A == B, "A != B"); static constexpr bool _cResult = (A == B); }; #define STAT_ASSERT(object, size) static_assert( TAssertEquality&lt;sizeof(object), size&gt;::_cResult, "Don't match!"); In order to get my compile-time strings to show within a static assert, which displays: note: in instantiation of template class 'TAssertEquality&lt;4, 3&gt;' requested here If you know of a better way of getting these numbers into a static assert error message, I'd love some suggestions.
Any particular reason, why those intrinsics aren't constexpr?
Right, but as most standard libraries are somewhat tied to a particular compiler, I don't understand, why there isn't more collaboration there. 
Would you be up for doing a constexpr version so we can do itos within, say, a static assert?
The constexpr evaluator needs to be taught each new intrinsic, it doesn’t happen automatically.
Ok :-)
Linux is certainly an DE, but imho it lacks the integration part of an IDE. As a simple example: If I call make and the compiler gives me an error, how do I quickly get to the line of code that produced it? An IDE will allow me to double click on the error and open the appropriate file at the appropriate location. Or where is the refactoring support? Syntactic and semantic checks during typing? Autocomplete ... An IDE is much more than a collection of buttons that start individual command line tools. A properly configured and extended EMACs most likely is an IDE though (Although I don't have any personal experience with it)/
Again, ideally. :-] I think reality unfortunately begs to differ, at least so far – there's been a big wave of "`constexpr` all the things" accepted into the draft in the last year, so compiler devs will have to come around sooner rather than later on this.
Sure, but wouldn't a generic fallback solution be to replace it with the equivalent c++ code? If I understand this correctly, intrinsics already come with multiple different backend implementations depending on the target architecture. Imho compile-time evaluation could just be treated as a different architecture, for which c++ code is the "machine language". Does it show that I have no Idea how a compiler looks like on the inside? ;)
You pretty much got it right
I think they fixed it for some things; try overloading operator() and returning a reference. 
I think many, if not most of us, will admit that our libraries did not start off like that. Continuous improvements to the code base accumulate over time and manifest as a more comprehensive library. Open sourcing will without a doubt help you improve in both the way you approach developing new libraries and improving on existing libraries, be they yours or other open source libraries. As for the motivation, I can tell you from personal experience that it is very easy to kill your motivation if you do not set realistic and **achievable** goals that you can reach in the relatively near future. The easiest way to kill your library is to set really high-level, abstract goals that you would have trouble articulating. It is not easy to work for an extended period of time towards a highly-ambitious goal and not have much in the way of progress that you can see.
Smart or raw?
I prefer NetBeans.
I am quite disappointed that this is getting down-voted. Have we all been convinced that it is more worth out time on optimizing everything than to optimize after developing working code? Good performance is important, obviously, but I will argue that correct behavior is more important, at least to a point. I would much rather have code that is somewhat less performant but whose behavior is known to be correct (or we have at least a reasonably high degree of certainty that is is correct) than faster code whose correctness would be more difficult to verify. As a GTA for a software engineering class, I have seen far too many students spend an inordinate amount of time focusing on writing the most optimal code they can from the get-go. I have seen their rate of development noticeably increase when they put a majority effort into developing working code that behaves as it is expected to. The code they write has fewer bugs, and they can optimize the correct code from there. Do not prematurely optimize. It is getting easier to optimize code and compilers improve and the language grows. As the language grows and the kinds of software we can wrote grows, focus should be spent on making sure your code behaves correctly. If you are not developing for a performance-critical system, don't micro-optimize and spend an inordinate amount of time trying to find the most optimal version of some bit of code. Now that is NOT to say you should just code without any regard to performance. Keep performance in mind while developing, but if you can implement an initial version that behaves correctly it will be more worth your time to develop that and then work to optimize the working code. There are exceptions. And there are so many bad string conversion libraries out there, and string conversions are used so frequently, that this kind of functionality does deserve a focus on optimization without a doubt. Just don't let that mentality bleed to all of your development practices.
I'm surprised no one has mentioned CodeBlocks yet.
I'm always surprised when someone mentions it. &gt;_&gt;
Why is that?
&gt; meson For reference, here's would be an equivalent CMakeLists (for the whole project): project(foo CXX) find_library(Qt5 5.11 REQUIRED COMPONENTS Core Gui Widgets) set(CMAKE_AUTOMOC ON) set(CMAKE_AUTORCC ON) add_executable(foo window.hpp profile.hpp project.qrc main.cpp) # I guess there's a main somewhere target_link_libraries(foo PRIVATE Qt5::Core Qt5::Gui Qt5::Widgets) that's in my opinion much clearer.
A serious microbenchmark compares results from different compilers specifying compiler version, compiler flags, and even the assembly code generated to make sure the benchmark was not optimized away. 
So I work in aerospace and as of now the goto ide for C++ is still eclipse. We tend to use it for both C, C++ and Java projects and it does the job although like most IDEs it is not without fault but it has wide enough support that my company as a whole has decided to promote the use of this IDE for all our projects. The one exception is that we use GNAT Pro for Ada. We also primarily run everything on RHEL so Cent OS is a good distro to become familiar with. 
The additional features I'd demand from a C++ IDE is: * Tagging support: the ability to find/go to the definition(s) of a function, its declaration, and list the places where it is called. * Refactor support, the ability to rename or change the signature of a function, and to do so everywhere it is used. * Built-in source control. I'd like to see which files have been touched, to easily diff multiple versions, etc. With the proper configuration and extensions, Emacs -- and VS Code -- can do all of this. Personally, I'm inclined to view VS Code as a newbie-friendly Emacs: at their core, they are both simple text editors with heavy emphasis on extension using a real programming language. I do not consider them IDEs by default, but they certainly can be if so desired. Being an Emacs user, I support the "use Emacs as IDE" suggestion. The [learning curve is weird](http://mrozekma.com/editor-learning-curve.png), but being in complete control over your tool is quite rewarding.
&gt; moc is a code generator. I presume if you're not using code generators, you're not good at your job, so you're not too qualified to talk about it much. I'm serious. This is ridicuous. Different people have different use cases. Personally I've never needed code generation for anything but reflection, and that's very well handled by Hana using the preprocessor. I understand that protobuf or MOC have fancier capabilities that some people need, but personally I haven't and I find that protobuf at least often has pretty bad impedence mismatch with a lot of the other C++ that I write, so I prefer to avoid it where possible.
KDevelop
The Affinity range of apps are written in C++, and include text editing. Not open source though. Generally people have used C rather than C++ because it was more portable, and occasionally because they don't trust C++ performance. Often they use rare languages like Lisp as a learning exercise in that language, rather than because they want a text editor. I remember having to write a text editor in C as part of a University course. At the time I felt it was a fantastic exercise that helped demystify the tool-chain.
vim + ycm + ctags + cmake + gdb
As a student you can get free license for all of the JetBrains products. Therefore Clion would be great for you. QTCreator is another great feee C++ and C ide. Also as a student if you never did source code compiling troughterminal its worth to give it a try and use some simple editor like Vim/emacs ( the holy war still rageing haha) for once or twice. it could give you some underthehood xp,.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/92s80i/best_linux_ide/e38awcc/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I would like to see the option to search in selected subfolders. Especially for big projects a search over the complete solution takes ages.
website available @: [www.vsdebug.pro](https://www.vsdebug.pro/)
&gt;People need string algorithms; algorithms do not belong directly on data structures (in C++). std::basic\_string is not the issue, and QString is not the solution. Partially true, however algorithms operate on iterators and iterators don't have any context associated with them that will let the algorithm perform optimally. For example, doing std::find on a pair of iterators from a std::set will perform worse than std::set::find()
because then the Java version of you would complain
I do not use Link Time Optimization when benchmarking this kind of small functions...
I learned programming in code::blocks. Last I checked they hadn’t done a release in ages...
&gt; The system I’ve presented here is quite simple to setup (provided that the dependencies are setup properly…) Exactly. &gt; But sometimes you aren’t lucky. In this case you have to bite the bullet and require the user to have the dependency installed by themselves. Whenever I see these "hey, dependency management is easy"-type articles dismissing more serious package managers I'm always frustrated a bit. Of course it's easy if you impose some very strong simplifications and assumptions (like "oh, this is too hard, let's require to the user to have the dependency installed"). The solution outlined in the article works only if you only have a couple of dependencies and only a fraction of those have to compiled. What if you have over 50 dependencies that need to be compiled? Are you sure you want to clone and compile each and every one of those every time you clone your project? What about libraries that have different build systems for each platform they support? How do you make that "work on every platform"? I do see the merits of this setup, but presenting this as the solution to dependency management in general is disingenuous. It might be a good solution in a very specific and narrow use case, but not in general.
Well, yes, you do gain some performance, since you're making everything inline. You also avoid the hell that is library management in C++. You do pay for that with compile time, executable size and might have to solve some linking issues because of the way the particular header-only library works and how your project is set up (multiple libraries, mix of static and dll linkage in different configurations, etc. ). I also cringe a bit each time I see only simple programs used for performance analysis. Feels incomplete - let's see what's the impact on a big piece of software, with performance-critical parts (hi unreal).
Inputs can also use a *black-box* functions, typically a couple assembly statements using memory clobbering instructions so that the compiler must assume that the input may have been modified.
Which is why verifying a benchmark requires verifying the assembly generated to ensure that inputs and outputs were properly isolated. Also, any benchmark should come with an *explanation*. Deriving the explanation can help notice subtle mistakes, such as some optimizations applying in one case but not the other for reasons unrelated to the expected difference.
Use micro-benchmarks, but do not blindly trust them. Micro-benchmarks have two flaws: 1. Some optimizations may or may not apply, which are unrelated to the benchmark and spoil the results. 2. Performance in a micro-benchmark is not necessarily indicate of performance in-situ.^1 Therefore, when optimizing: 1. Use micro-benchmarks to quickly iterate over the design space, and negate "random" optimizations behavior by *investigating* the performance difference (ensure inputs do not influence code generation, outputs are fully generated, expected optimizations occurred, ...). 2. Once micro-benchmarks have pared down the number of candidates, benchmark them in your complete application. ^1 *There are multiple examples. The most common is using pre-computed tables in micro-benchmarks, which work well since the micro-benchmark has the CPU cache to itself; if in the real application the cache is shared, however, then algorithms which do not trash the cache may offer better performance. Another is using AVX512. Those instructions are so costly, power-wise, that they lead to downclocking. In a micro-benchmark where a single core uses them intensively, it's a net win. In an application which uses multiple cores, or uses AVX512 once in a while, it's a disaster.*
We still can implement an utf8_iterator adapter that will return codepoints instead of bytes comming from and underlying iterator, then for_each and all the general algorithms will work. Its true though that for certain data structure where the algorithm can be specialized (such as std::set::find) a specialized algorithm is better. I am not sure why we dont actually have overloads for std::find that work on std::set&lt;T&gt;::iterator to make that transparent (might be that we would quickly get in overloading hell).
&gt; to make sure the benchmark was not optimized away. Yes, that seems obvious, but not necessarily easy to do.
[juCi++](https://gitlab.com/cppit/jucipp) is written in newer C++.
Thanks a lot.
I will never understand that. How would it let you make a long path in the first place but not let you delete it?
Different APIs I'm pretty sure. git for windows (msys/cygwin runtime) created it, he was trying to delete it from cmd/explorer. But I guess it's still dumb. Seems like it could at least trap that error on deletion and do whatever it needs to to delete it.
medium rare
&gt; - Automated documentation search (C++) &gt; - OpenCL and CUDA files are supported and parsed as C++ Ok, now I have to check this It uses clang for autocompletion?
&gt; I am not sure why we dont actually have overloads for std::find that work on std::set&lt;T&gt;::iterator to make that transparent (might be that we would quickly get in overloading hell). `T` is non-deducable in that context, but ranges will enable this.
You just sent me on a 30 minute research deviation from this topic since I didn't even know downclocking was a thing with AVX512.
That's weak
I found this article very useful for two main reasons: 1) i am a beginner/intermediate level c++ programmer, and this is one of the simplest and easy to understand forms of 'package management' that I've seen. 2) i work in an industry where we don't have administrative privileges over our computers, so installing anything is impossible. What if you have over 50 dependencies that need to be compiled? Are you sure you want to clone and compile each and every one of those every time you clone your project? In my case, compiling each library each time i clone the project is truly the easiest way to go. Yeah, i might have to wait an hour for everything to compile the first time, but, if these aren't 'header only libraries', then i will only have to pay the compilation price once. I do agree that it is not the perfect solution to package management, but it offers a clever solution that is much more appealing and understandable to entry-level c++ programmers.
Yes, libclang is used. If you are using CUDA, it is slightly more complicated than OpenCL. Here is an example CMakeLists.txt I used when testing this integration: cmake_minimum_required(VERSION 3.1) project(cuda LANGUAGES CXX CUDA) add_compile_options(-std=c++11) include_directories(/opt/cuda/include) add_executable(cuda main.cc gpu.cu)
we need strong pointers and strong type aliases
Why exactly is SYCL incompatible with MPI exactly? I’m not familiar with the details, but surely there’s some mechanism for accessing your buffers on the host? A DG solver restricted to one node seems pretty limited! Also you seem to have written “Syklake” several times.
Had nothing but trouble with git submodules. Never again.
For constexpr, the replacement needs to happen in the front-end (so the result is usable in templates etc.) instead of the back-end. It can be done, but not all at once for all intrinsics, AFAIK.
Fair enough.
Thanks
Thanks also! Please tell me about any issues/advises if you have :)
Certainly! The level of "integrated" is quite different. If you run make and the compiler gives you an error, it generally prints the file name and line number where the error happened. The editors that I've worked with let you invoke them with a file name and line number. Not as integrated as a double-click, but still quite efficient. Refactoring is admittedly limited. Maybe it's because I've never really had it, but I don't see the need for it. When I need to make code transformations, the macro facilities of vim or emacs have been my tool of choice. It could be that refactoring tools are less useful on smaller projects like the ones I tend to work on. As for emacs as an IDE, you can make it that way if you want. I've got it set up to run linting with irony-mode, tight source code navigation with rtags, and emacs has always(?) had the ability to invoke a build. I still tend to use make directly in a terminal to do the build. That's just my tastes! People brains work differently and I respect everyone's way of doing things. At my office we believe in giving the developers full control over the environment they want to use. We develop for embedded systems so theoretically you should be able to use Linux, macOS, or Windows with whatever text editor or IDE you choose. CMake is a pretty big help in making it possible.
&gt; Do not prematurely optimize. maybe the author is at the optimization part 
I see how my comment comes across like I am implying the author's code is of sub-par quality. I did not mean to, however. My comments were merely intended to defend my position I with regards to premature optimization. They weren't directed at OP, but instead at those down-voting someone providing a similar position. Though it should be noted that the analysis given in the link posted by OP is benchmarking the string conversion utilities/functions that are provided as part of the standard libraries.
Ah sorry. For future readers, this was brought to my attention by https://blog.cloudflare.com/on-the-dangers-of-intels-frequency-scaling/ As far as I know, there are two mechanisms: - in older cores, the whole CPU is downclocked, - in newer cores, a consensus algorithm between cores determine which cores to downclock. In either case, attaining consensus takes time, on the order of microseconds if memory serves me right, and the downclocking also lasts for some time, so that using a single AVX512 is foolish and instead they are best used in batch.
&gt;That has nothing to do with language performance. It's how you handle large files. I don't disagree. I'm simply refuting the claim that "text editors don't require high performance," not any claim about language performance. 
How is that different from the original `PostTaskAndReply`? Also, &gt; I'd do that in the lambda `[]` Why? &gt; Somehow have co_await trigger a co_return if weak_this is gone. I am not a coroutine expert, but I remember something like that was possible. You must be remembering it wrong. `a.await_resume()` could throw an exception and `p.unhandled_exception()` could catch it, but exceptions are banned it Chromium, and even if they weren't, you don't really want to use exceptions for simulating `return`, unless your application is called `hello_world.cpp`. &gt; Of course `if (!weak_this) co_return;` is a complete anti-pattern; you never check if a weak pointer is valid, you lock it. It's Chromium's `WeakPtr`, not `std::weak_ptr`. There is no `lock()`, and objects don't die on random threads.
Although this is a C library, I thought this subreddit may be interested as all the benchmarks use `std::string` for comparison with various compilers. The library is header only and entirely C++ compatible, so using it in either language should be a breeze. Hope you guys like it!
I don't understand your snippet. What does this `Do` function do? Also we're talking about a big codebase, any refactoring should be localized. &gt; the original code is super tricky why, it's quite idiomatic - `base::Bind(&amp;URLRequestFileJob::DidFetchMetaInfo, ...)` outlives `base::Bind(&amp;URLRequestFileJob::FetchMetaInfo, ...)`. Btw [it haven't been changed since 2013](https://chromium.googlesource.com/chromium/src/+blame/443c01a022c767d8baf38772bd9ebedd6773c3e1/net/url_request/url_request_file_job.cc#68). They could've use `unique_ptr` (as I did), but it looks perfectly fine even without that.
As a side effect of this, thanks also for the nice and concise example of using gRPC in C++.
Well, we could put those two `co_await SwitchToTaskRunner{...};` inside `FetchMetaInfo`, but would that improve it much? void URLRequestFileJob::Start() /* override */ { // We cannot change signature of |Start| but we can use a lambda-expression: [this]() -&gt; SimpleFuture { auto weak_this = weak_ptr_factory_.GetWeakPtr(); FileMetaInfo meta_info = co_await FetchMetaInfo(file_path_); if (!weak_this) co_return; DidFetchMetaInfo(&amp;meta_info); }(); } Future&lt;FileMetaInfo&gt; URLRequestFileJob::FetchMetaInfo(base::FilePath file_path) { auto current_task_runner = GetCurrentTaskRunner(); co_await SwitchToTaskRunner{file_task_runner_, FROM_HERE}; FileMetaInfo meta_info; base::File::Info file_info; meta_info.file_exists = base::GetFileInfo(file_path, &amp;file_info); if (meta_info.file_exists) { meta_info.file_size = file_info.size; meta_info.is_directory = file_info.is_directory; } // On Windows GetMimeTypeFromFile() goes to the registry. Thus it should be // done in WorkerPool. meta_info.mime_type_result = GetMimeTypeFromFile(file_path, &amp;meta_info.mime_type); meta_info.absolute_path = base::MakeAbsoluteFilePath(file_path); co_await SwitchToTaskRunner{current_task_runner, FROM_HERE}; co_return meta_info; }
Those benchmarks, which OS, compiler and library versions were they taken on?
Benchmarks seems promising, is there any doc that explain how you achieved this?
\&gt; it's also unreasonably priced for third world countries IMO. I feel the same way, one of the nice things about software is that most of the resources and infrastructure you need to get started is available for free and documented on the web -- there's a firehose of information out there and the only limit is your ability to learn. I don't have a problem with people selling software tools for profit, but I'd rather find an open source tool that I can use and support (via bug reports, or patches if necessary) in general. Many of the tools you have to pay for are not meaningfully better than their open source counterparts anyways.
Thanks. I guess that there are a bit less the examples for gRPC with C++.
The GCC and Clang benchmarks were done on Linux, and the MSVC and ICC benchmarks were done on Windows 10. The clang version definitely used SSO based off the construction benchmarks (which don't have the graphs made yet). The results were 1ns to construct a 12 byte string, but 13ns for a 24 byte string. I think clang's implementation is a 23 SSO capacity.
Not at the moment, but the essential mindset was to limit the amount of instructions to the absolute minimum. For example, setting the SSO string length implicitly sets the heap flag since they are aligned to be in the same location in the union. Many small tricks like this along with `builtin_expect` for compilers that support it for better branching.
C is so ugly :-((( I understand your use-case probably demands C, but in principle couldn't you (anyone) make exactly the same but just use C++? (And proper constructors and everything you need to not have to write something like \` rs\_init\_w(&amp;s2, "Hello World!"); \`.)
It most certainly could be done in C++, but most would simply just stick to `std::string` because it's already there. As for C, there are very few string libraries out there, the primary one being [sds](https://github.com/antirez/sds) which isn't maintained, depends on GCC extensions, can't be compiled in C++, and is around 15x slower than rapidstring.
Yes, I'm aware they have a non-commercial option available, however will it be available for the foreseeable future? What if they decide to change the product in a major way that I happen to dislike? I've really liked software that got bought and then shutdown. Then what? I have asked for a FOSS alternative because it is in my best interest, just as it is in their best interest to make a living selling it.
It does seem nicer indeed, but the point I was trying to demonstrate is that you are not limited to Qt build system.
This is one of the things I use [Compiler Explorer](https://godbolt.org/) for. Even if you can't really read asm it's pretty easy to tell if your benchmark code is doing *something* or if it's been entirely optimized away.
Is there something in the C++ standard which prevents the optimizations used in this library?
lol
Would there be anything stopping someone from creating a C++ wrapper, providing ease of use (e. g. RAII) , that compilers will be able to 'optimize away'?
You've only tested against std::string, if you're going to make clickbait claims maybe test other libraries as well? It's not hard to beat a lot of things in the standard library if you make certain assumptions, and have specific use cases in mind.
\yawn...C code.
C with classes is the best way to write C++. Y'all can fight me
Nobody who’s not a masochist is going to be willingly writing some equivalent of `std::search(str.cbegin(), str.cend(), foo.cbegin(), foo.cend())!=str.cend()` in place of `str.contains(foo)`. Let’s not be ridiculous. Maybe ranges will fix it. Maybe. But, for the most part, a string type should have syntactic sugar for all the common algorithms. It’s almost always much terser than alternatives, and no less expressive, and no less understandable. `s.contains(foo)` reads like English. It’s just about the most self-documenting construct there is, I think. 
I originally had comparisons against folly's string library, but it has it's own allocator which changes quite a few things. Do you have any suggestions of other libraries to compare? I would be glad to add them to the benchmarks.
All optimizations could be adopted, but some would require additions to `std::string`. For example, there is a macro `RS_AVERAGE_SIZE` which should be redefined to the average size of a string within a project. This will be used to create better branching using `__builtin_expect` (for the compilers that support it) by favoring stack strings or heap strings, depending on whether the average string size is short or long, respectively. Furthermore, if you know for a fact your string is on the heap, you may call heap functions directly which avoids a flag check entirely.
I have a very strong urge to make one point: you should, if you want this to be absorbed by heavy C++ users (notably C++ developers that make heavy use of RAII and exceptions), provide some way of disabling c-like assertions in favor of exceptions. By providing an easy way to stub in our own handlers, by providing a way for use to define some macro that can override your assertion macros, or by some other means. Exceptions help guarantee proper memory management and if you're in release mode and something goes wrong, assertions won't alert of an issue (unless you keep them on in release mode) and we will just totally implode. We can't do any cleanup, attempt any data recovery, or even attempt to gather information about what was happening that lead up to the crash. A failed assertion shouldn't happen if code is properly tested, but I think we've *all* fallen victim to an edge-case and watched our programs go down in flames. For example: If a C++ wrapper class for rapidstring calls out to make an allocation (for expanding the string, allocating it in the constructor, etc) and the allocation fails, the usual assumption is than an exception will be thrown to indicate the failure (std::bad\_alloc in most cases). Now I really don't want this to come off as if I'm trying to attack you or make a negative critique of your library, it is just something I think you might want to consider, as it would certainly make the lives of C++ developers easier.
The vociferous use of c-assertions. We'd need to replace the use of those with exceptions. An assertion failing in a heap alloc should be just as exceptional and uncommon as, say, std::string throwing std::bad\_alloc, but we get to keep the benefit of exceptions without just immediately burning down in flames.
Not sure if this has been addressed since vs2017, but a solution wide search for just one "next result" can take incredibly long, locking up the UI too. Solution wide next search should first do an in-file next search.
&gt; entirely C++ compatible Only for compilers which define union aliasing. Technically, rs_is_heap invokes UB.
Ranges are a thing, and `std::search(str, foo) != end(str)` is perfectly fine by me. For all `str.contains(foo)` reads well, it's an unacceptable separation of concerns for the stdlib.
I didn't use myself but I've seen EASTL recommended (though mostly for it is containers), as far as I remember they provide mostly compatible interface with std:: counterparts.
Is it union aliasing if both the `flag` and the `left` fields are of the same type, `unsigned char`? I thought this only applied to union fields with different types.
There's a rule for common initial sequences of UDTs, but primitive types aren't UDTs.
Contract programming is an old and very widespread paradigm, which, for your information, is what you're criticizing. The comparison between an assert and a `std::bad_alloc` is very nonsensical, because contracts don't handle this kind of errors. That is, contracts cover preconditions, post-conditions, and invariants. You could use exceptions for that, but it really doesn't matter, because contracts should never be broken in releases. So, throwing an exception, aborting, whatever, are just ways to stop the program and show the broken contract to the programmer. Exceptions, on the contrary of contracts, can happen in releases. For example: handling invalid user input, invalid environment, unexpected outcomes etc. Now, if you're just literally talking about the use of the macro `assert`, and that a custom macro for that would be better, then we could agree. Nevertheless, it's really not important, because you, the user of the library, should not get broken contracts. If you do, just fix what you're feeding to the functions. That's what contracts are somewhat for: correct usage of APIs, not handling of invalid user input.
Can you give an example of a compiler that doesn't
This is not an academic exercise. A standard library is meant for human use. Some ideals of purity maybe apply to German beer, not to code people actually use. Common constructs should be easy to express. Separation of concerns is good where it helps. Here it actively hinders. It’s not somehow automatic that separation of concerns is always better. It often is, sure. Not always though. 
Now that we have ubiquitous continuous integration support for Linux via github and gitlab, and other services, this would be a killer feature: - Docker image for the build tools So that we can hook up a Windows system (local or cloud-based) to services like gitlab, and have it pull down and use a current VS build tools image. This currently requires a lot of tedious manual setup. Having it provided directly by Microsoft would be wonderful. Being able to use an existing local Windows Server 2016 with docker, or fire up something on Azure or some other provider and have it scale up automatically would provide a lot of value.
In the case of algorithms suited to be generic, it is. Beyond that we'll have to agree to disagree.
One of the reasons we do not have good developer tools is because we choose to not pay for them. I understand and sympathize with the fact that pricing often does not take local purchasing power into account, but would request people to pay for tools when they can to encourage more people to write tools for software developers.
GCC and Clang, if you specify `-fstrict-aliasing`. None that do by default, of course.
It's very easy to design a library around a benchmark but that doesn't necessarily mean it is viable in other use cases
Objective BCPL is where it's at.
I've never looked into it, but it MIGHT be possible. I won't promise that I'll do it soon, but feel free to open an issue.
C++... all my runtime errors seem so far away. Now my strong types are here to stay. Oh I believe in C++.
By all means! I would be glad to add some benchmarks for other use cases. If you have some suggestions I could probably get them in by tonight.
There is also better string library for C
fstrict-aliasing is the default IIRC. Maybe not without -O, but I guess tyring to achieve max speed without compiling with optims would be a quite rare use case.
At least in C++ even if some fields are of the same types, they don't alias if accessed though a different structure. Now if those are char, the situation *might* be different because char is special, although I'm not sure of who wins between the char-is-special thing and the accessed-through-different-structures. So short of doing a study on that subject, I'd not risk it.
Ah yes! That's a very good point indeed. Thanks!
Unlikely, noone is working on that. If you want that, you need to get your hands dirty :)
Subscribe to the kwrite-devel@kde.org mailing list. Follow articles about how to build KDE Software, build KTextEditor, Kate from git. Read reddit/r/kde, this is also a very good place for discussions.
This one covers being able to write class members on objects from Lua. This video just covers number (and specifically just int &amp; short). [Embedding Lua in C++ #32 - Writing Object Properties Using Run Time Type Information](https://youtu.be/W2rB7v_G5aI)
`-fstrict-aliasing` is turned on at all levels except `-O0`. Maybe that's what you meant (since `-O0` is the default) but someone could read your comment and get the impression that it's not enabled for "normal" optimized builds unless specifically enabled.
Although in practice recovery from heap allocation failure is next to impossible. E.g. if you fail to allocate the string you may also fail to allocate the bad_alloc exception object, or anything in the stack unwinding might use a `string` or otherwise allocate memory, or the place execution ends up might do so , etc., and all those code paths are probably untested. 
There is; only the most recently-written member of a union may be read. However there are features of the Windows API and Posix API which rely on union aliasing, so in practice I would not expect a mainstream compiler to not have OP's code work as intended. 
Where you using libc++ with clang ?
Fair enough, thanks for clarifying.
Did you forget to include the actual source code in the repository? I can’t find a non-test/benchmark related .c file anywhere. Additionally, the build commands give me this error: CMake Error at test/CMakeLists.txt:11 (add_subdirectory): The source directory /home/bisqwit/rs/rapidstring/test/lib/Catch2 does not contain a CMakeLists.txt file. CMake Error at benchmark/CMakeLists.txt:11 (add_subdirectory): The source directory /home/bisqwit/rs/rapidstring/benchmark/lib/benchmark does not contain a CMakeLists.txt file. -- Configuring incomplete, errors occurred! See also "/home/bisqwit/rs/rapidstring/build/CMakeFiles/CMakeOutput.log". 
&gt;There is; only the most recently-written member of a union may be read. Isn't this also true in C? I would assume so by backward compatibility.
The library is header only :). As for that build failure, you need to clone the repository recursively to get the submodules: ``` git clone https://github.com/boyerjohn/rapidstring --recurse-submodules ```
I'll agree that it's definitely not going to be easy, or often even possible, to completely recover from that, but one might at least attempt it. At the very least, it provides the option.
Yeah, I noticed. For some reason, when I was viewing the .h file on github’s web, I could not see the function definitions in the header file. Somehow I missed them.
Yes, I was.
No. The C Standard explicitly permits union aliasing. The languages started diverging in the 1980s, before either was standardized.
You compiled the library in the debug version. Recompile it with this flag when generated the cmake files `-DCMAKE_BUILD_TYPE=Release`.
Like this? $ cmake -DCMAKE_BUILD_TYPE=Release . $ cmake --build . (Never used cmake, I always do makefiles directly.) Allright. In that case the benchmarks become: ------------------------------------------------------------- Benchmark Time CPU Iterations ------------------------------------------------------------- rs_cat 604 ns 604 ns 1160491 std_concat 1215 ns 1215 ns 588787 rs_reserve_concat 247 ns 247 ns 2822873 std_reserve_concat 784 ns 784 ns 888002 rs_12_byte_construct 1 ns 1 ns 538561781 std_12_byte_construct 2 ns 2 ns 438011143 rs_24_byte_construct 2 ns 2 ns 443477410 std_24_byte_construct 20 ns 20 ns 35893493 rs_48_byte_construct 15 ns 15 ns 49530112 std_48_byte_construct 21 ns 21 ns 34602935 rs_resize_test 22 ns 22 ns 31097302 std_resize 54 ns 54 ns 13048971 
I do not think you are understanding the intent of my criticism. I am not equivocating std::bad\_alloc with assert, nor am I somehow implying that the use of contracts is not beneficial. I mentioned std::bad\_alloc explicitly because rapidstring goes forward after allocating under the assumption that an allocation succeeded. OP asserts that &gt;nearly all applications brutally fail either way when memory runs out Running out of memory does not *have* to result in a catastrophic failure, and the developer of a library shouldn't force the program to fail when it could be recovered from. This is a major motivation behind exceptions. Even if a program cannot continue its normal execution, a well-developed program should be able to handle this unfortunate situation and at least somewhat gracefully terminate. No, contracts *should* never be broken in releases, but I'd argue we shouldn't assume we are completely correct, and unless I have some way of guaranteeing that I do not violate any contracts *and* the developer of the library does not violate any their *own* contracts, I would much prefer some way of reacting to this. Contracts, as they are proposed, will provide a mechanism for reacting to a contract violation without just imploding, and provide the obligatory information to debug it, so we can at least do *something* in response, even if all we do is report it/log it/etc and do not attempt any form of recovery. If your program is already deployed, the reaction can simply be to alert the developers so they can quickly patch it before it occurs more. If your program is interacting with another, you may want to let that other program know that something has gone very wrong and that it should expect to immediately lose contact. It would likely be better to say *something* than simply just disappear.
Yes, that is perfectly correct. Sorry for the unclear build instructions on the README, I'll add more information about debug/release modes.
How does this library fare with other character types than `char`, such as `char32_t` or `wchar_t`?
Allocation failures can still be handled as mentioned in that same bit of documentation you quoted. &gt;If your application must handle allocation failures, you may set errno to 0 before calling a function that either intializes or grows the heap buffer, and then check errno after this call. All modern compilers will set errno if malloc() fails. It's not ideal, but if your application needs to handle all allocation failures, you could create a macro wrapper for all `rapidstring`'s heap functions.
It wouldn't, at least not at the moment. To make this library generic would require placing every function inside a massive macro or making everything `void*`, neither of which I am willing to do.
A side note on `std::bad_alloc`, their is a proposition to remove it from the standard. It is proposed as an extension in Herb's paper [zero-overhead deterministic exception](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0709r0.pdf) for C++23. The pool was strongly in favor (unlike what he was expecting).
Ugh
They are all wrong
Other character types are useless, given that utf-8 is what you *always* want.
I grabbed a copy of Kate and took a look at the bug tracker, is that where I should be looking for work?
Can you care to explain? The paper details exactly the migration process for all types of users (both the one who don't handle, and the one who handle memory exhaustion). Also a `try-alloc` function was proposed in another paper (as explain in the one I linked).