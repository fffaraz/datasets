For the original article, I think he makes some points, but I think he fell victim to comparing C++ against &lt;whatever language does well for this particular issue I have with C++&gt; It is like saying I hate my car because a camaro is faster and a caravan has more room!
Nobody can know, in general. First of all I will note that it depends on the number branches you are aiming at. A single branch is a binary choice, whereas a virtual call could point to an arbitrary number of targets in general, so the two are not necessarily equivalent. Secondly, you have to know that modern CPUs have branch-predictors. Binary branch predictors (used for `if` statements) are quite tight and fast whereas multi-choice branch predictors (used for switches/virtual calls) are slightly bigger and slower. Thirdly, on the other hand, you have to know that compilers will routinely attempt to eliminate branches and indirect calls: - prove the condition is always true or false - prove that the caller is always X, and de-virtualize the call - prove that the caller is more likely to be X, Y or Z and speculatively de-virtualize to those And of course, given a chance, all that is hoisted outside the hot loop to start with, because the best way to make a loop faster is to trim its body as much as possible (before unrolling/vectorizing).
Not to be that guy but there are tons of cases of non jit compiled c#
If you cannot AOT compile to machine code then it is not native, which by definition makes Python not native. 
Because the member function has preference. Basically they did propose both version at first, and they always proposed as "g.f(x) will call the member function f(x) if it exist, otherwise, ADL for f(g, x) will be performed".
My (really naïve) idea is introducing a new operator (e.g. `` ` ``) to call free functions in a member function call way. std::vector&lt;int&gt; v; v.begin(); // std::vector&lt;int&gt;::begin() v`begin(); // same as begin(v), ADL finds std::begin() EDIT: I changed my mind. ADL should happen here. The advantage of this syntax is that typing `v.` won't spam the autocompletion list. 
C++ is the most difficult language that is actually used because it is arguably also the most powerful. Giving up on it either means you're not capable of using it the right way or you're using it for the wrong things. Would I write web application or a text parsing script using it? Hell no! But for many situations where you deal with huge gaps in abstraction levels (screwing around with pointers vs. making highly abstract framework calls) while maintaining control and performance, I wouldn't change it for the world. And you know what the biggest plus is in my eyes? The language is very much alive and evolving. And not in a fast, bad way, but in a very transparent and controlled fashion. This is also true for the toolchains.
I'm so confused about people saying this. I hear it all the time. I have never found something the VS debugger does that gdb doesn't do. Do people repeat this just because they're impressed by any debugger, and they've never tried a different one? 
Both compile C# ahead of time directly to native code just like C++, no interpretation happens, can gladly provide documentation links.
It's not the fastest IDE out there, specially if you're running it on limited hardware. QtCreator feels way snappier and it's a very solid IDE all around. Autocompletion, refactoring, cmake support, an amazing vim mode... I mean, pretty much everything just works as one would expect. To me it is the least annoying multiplatform C++ IDE there is. Plus, you know, it's free.
Kdevelop is the shit, especially the 5.x betas with Clang integration. The documentation engine is also mind blowing - it can trace doxygen and its help documentation infrastructure to either give you popups of documentation or entire html pages.
Tabs, for one.
Gdb and VS debugger don't do the same thing. One is text-based, the other is not. If you memorised gdb commands, you are fine. If you didn't, a visual debugger is easier. I use gdb from the command line. It is just so menial. Sure, I achieve my goals, but it is just harder. Situation is probably different for the one who spends 4hours a day in it, every day, but I don't.
No C# implementations are interpreted. Besides, a language can be both compiled and interpreted (probably all of them).
&gt;Java is a better C++ Whoa, [citation needed] :-)
Where do you swap between push and push\_back!?
So this is literally just about the UI? Fair enough. I just always hear people talk about VS debugger like it had some magic features. And every time I've used it, I'm just like, "yes, this has all the features I expect from any debugger, what am I missing?" Like, both gdb and vs are competent, but neither has the advanced analytic magic of something like IDA Pro. It appears what I missed is that many people consider the UI itself to be a feature. Which is probably while they're still messing with the awful Widows development experience.
IDA is something different though. About the GUI, an example: in gdb, I l type out where I want to break (file:line, or function name; one casing error and I have to repeat). In VS, I locate the place by scrolling and issue the "breakpoint" command. The latter is easier for me. That's the "menial" aspect I mention. It is not about features at all, it is about my efficiency in using them.
&gt; However, under Manageability he/she listed source/header split and namespaces as problems? PROBLEMS? Headers are little more then code duplication, while they can be useful to get a quick overview, that's really something your IDE should be doing automatically. The problem with namespace is that they are a cludge build on-top of the header mess. They are a necessary evil, but they aren't a good solution. A proper module system would have been much better. 
You can cycle through all the open files in QtCreator with Ctrl-Tab, instead of having tabs wasting space. Also, Ctrl-K + name of file will get you to where you want to go. 
&gt;Java is a better C++ *triggered*
Oh, OK, that's a good reason, perhaps. I still don't know if the non-friend free functions in place of members are a blessing or a curse. One could take this approach to the extreme and make all methods free functions, with a sufficiently arcane naming of data members to discourage their "unauthorized" use. If a class has a member named `___1djkufhe_size_ptr` nobody sane will be using it even if it's public :) I'd like to think that any function that takes a structure by pointer or reference as the first argument should simply get access to private members. Then we could get rid of methods :)
Yeah, once they fixed the template related crashes KDevelop started getting better and better.
Yeah, I really think all the hate namespaces get simply comes from them being unfamiliar. &gt;what's this :: &gt;This confuses me!
Vector has push_back and queue has push. Both add a new element to the end. Seems odd.
Yet those same people will praise packages. WTF? I get it, namespaces that worked like java packages do would rock, but there's way too much complexity there to do, I think. 
You can probably hire 2 or 3 PHP Programmers for the price of one C++ programmer. I do see why people use easy but inefficient languages. For very large Websites server costs start to get significant though.
If you need a high level language, C# and Java is the way to go. If you need low level access, C is the way to go. C++ is in this weird position where it's not as fast as C but it's also not as easy to use as C# or Java. There aren't very many cases where you should go with C++ over C#/Java unless you need cross-platform support and the Java VM is too heavy for what you're trying to do.
Well start one or two VMs, have Firefox running with lots of open tabs and of course the OS and all the little gadgets want memory as well. Memory footprint and speed are super important. In the time you have to wait for your Jetbrains IDE to be up and running I am compiling my first application ;) So whats so big about CLion that I am not able to do with vim? EDIT: As you edited your answer I'll do the same. IdeaVim is nowhere near to standard vim. Why? How do I use CtrlP, Ack, Ultisnips, Tabular, Surround, Easymotion and so on with it? Not possible? Well... So tell me, what can CLion do that I can't do by using vim + gdb? EDIT2: There is one more thing you forgot to mention. When you are talking about big, do you mean the amount of money Jetbrains is charging you to **rent** their software?
C is not faster than C++. Not so long ago there was a talk here, from code:dive, where a dude shows how C++ code beats the C equivalent in speed, and amazingly, how the difference is biggest on an 8-bit micro-controller.
When I have a class::method, I still need to type the whole class name for tab completion, and I didn't figure out how to deal with namespaces. So I type a lot. Yes I know that gdb has gui front-ends. Are they better than the VS front end? Not really.
No it was same code as much as possible. Source: http://codedive.pl/en/previous-events/year-2015/materials/, see C++ vs C, the embedded perspective.
&gt; This can already basically happen if you just have two cpp files definitions of equally-declared functions So, two TUs that give you different definitions for e.g. `MyThing::foo`? That's an ODR violation, so you're already in the realm of UB there. :) &gt; If member functions and static functions were interchangeable, it shouldn't make a difference Which is why I said "And the authors of ThirdPartyLibrary add quux to MyThing *with different semantics*." Pretend that `::quux` returned a pointer that was guaranteed to be non-null. Now consider what would happen if the authors of ThirdPartyLibrary made `MyThing::quux` identical to my `::quux`, except in that `MyThing::quux` may return null in rare cases. When you upgrade, you'll have use-of-null errors silently introduced everywhere in your code. That's not a very good thing. &gt; The only issue with this is backwards compatibility, but hey, fuck anyone who has two functions foo(bar) and bar.foo() that do different things, right? Plus, it's an issue for the proposal, too! I'm not sure what you mean here. With this proposal, UFCS is used only as a last resort, so it will not change the semantics of any code written prior to its introduction.
&gt; In VS, I locate the place by scrolling and issue the "breakpoint" command. That seems incredibly cumbersome compared to just typing.
Depends on how far you are. I normally have files of interest already open, and I put break points in places close to one another. If I need to place a breakpoint in some faraway place, chances are I won't know what to type anyhow, so looking for the place takes me there.
Because it's API is ugly and it is unnecessary slow. Also at least Visual Studio version has also some bugs in it too.
Namespaces are rather unrelated to headers. One is about the "logical" code organisation, other is largely the vestige of C.
It's less prone to have subtle bugs than something that's been reviewed by thousands of people and is already in use on millions of devices? Yeah, I get that modern C++ is *generally* better - but as Jules said in the talk, zlib is probably completely bug-free. You can't get any less prone to bugs than that. If refactoring it means losing this security, it's not worth it. Also, what sort of "progress" does zlib need? It works and it does what it's supposed to. It doesn't need any more features. Reinventing the wheel just for the sake of progress isn't progress.
Has Clion gotten up to date with C++11? Because that was a major blocker last time I tried it. 
&gt; My vim has a memory footprint of ~250MB (of which 200MB are used by YouCompleteMe). That shocks me. I looked at the memory usage for Visual Studio where I had a simple two line test project open and it is using 227 megs. I also looked at a medium size personal project with several files opened and looking at code using boost graph (so intellesense has to parse complex template code), and it was sitting at 128 megs (which also surprised me, why was it so much less?). Why does Vim + You Complete Me need that much memory?
Could be. I remember reading it in one of 2015 posts so It's impossible to find now. Now that I think about it probably meant that the support is planned for the next release at least. But I definitely sensed tone of "we want to remove it asap and only keeping it because our manager thinks it's viable"
Example seems to be a bit artificial since such small structs rarely need any vtable shenanigans. It's obviously won't be any good if you class is very close in size to a pointer.
Thats even worse idea. I mean c++ is already full of magic characters that hurt readability. I think c# extension methods make sense - you specify that this method is intended to be called in this way like what UCS would provide. Then ambiguity error is not a problem because you sign up for it explicitly.
Can gdb easily move the PC or change a line during debug and live patch the running executable? Those both come to mind as nice features that VS has which I don't know how to do in gdb. The other thing I find is that sometimes I really want to see what 3 variables are as I step through the code. I don't know how to do that in gdb without typing 4 commands over and over, but again, maybe I just don't know the right gdb command.
They also do way too much! Why in the 4 hells of dakota does a binary stream have a locale attached to it?!
I think so, didn't have any issues with it 
Theoretically Vim and Emacs are arbitrarily powerful. But practically, with IDEs, I frequently stumble across new functionality. Moreover, until I am familiar with a new feature there are suboptimal but easy ways to do it. With Vim I am limited to what I already know how to do, in fact to what I already know how to do with enough familiarity that I've memorized it.
There are hundreds of plugins for vim that add pretty unique functionality that I've never found anywhere else. 
Employment. But seriously, vector and shared_ptr.
Yes. Again, theoretically Vim and Emacs are arbitrarily powerful. They are also much more extensible if you want to customize something yourself. That is a "Pro." A "Con" is what IDEs offer and they do not: discoverability and usability of features you are not aware of / are not familiar with.
woosh
It's the locale that determines what op&lt;&lt; some_int and op&lt;&lt; some_float etc actually write to the stream buffer. The 'binary' flag in iostreams only changes the way newline sequences are read/written.
Woah, how did you make that animation? Is it hand-made, or is there some specific tool?
When talking about IDEs why is Qt Creator always left out? I don't use Qt on most of my projects, and I don't us QMake at all, even then Qt Creator easily provides me the best IDE experience of any IDE I have used in any any language.
You might have read something I wrote, and while I never said "we're dropping XP", I do *want* to remove XP (and to a slightly lesser extent, Vista) targeting support. It's a headache, and it's making our STL implementation more complicated and slower than it would otherwise be when targeting Win7+. (There is Only One STL, and on x86/x64 we don't know what platform we'll be running on, so XP/Vista support implies runtime branches.) Go debug through `std::mutex` and `std::condition_variable` to see the complicated logic. Ultimately, our continued support for XP/Vista targeting simply means that the business reasons to do so (money!), outweigh the costs involved (mostly me grinding my teeth, although there are costs elsewhere).
Can gdb break and evaluate almost any kind of valid C++ expression you enter? I'm curious because I use that feature alot in VS.
&gt; Can gdb easily move the PC [Yes](http://www.chemie.fu-berlin.de/chemnet/use/info/gdb/gdb_12.html). You can also simulate returns, and you can assign to variables. &gt; or change a line during debug and live patch the running executable? [I had to look this up](http://stackoverflow.com/questions/9426339/live-editing-code-with-gdb), because I have never once thought it was a good idea. It has to come from the same line of thought as the famous `MOV EDI, EDI` binary patch space at the beginning of functions. Windows devs must just love patching binaries. &gt; The other thing I find is that sometimes I really want to see what 3 variables are as I step through the code. This is something that is easier with a GUI front-end. Almost all of them let you watch a variable automatically. You can also set [watchpoints](https://sourceware.org/gdb/onlinedocs/gdb/Set-Watchpoints.html), which are breakpoints triggered by a predicate on a variable. &gt; I don't know how to do that in gdb without typing 4 commands over and over, but again, maybe I just don't know the right gdb command. I mean, you don't have to *type* them. The command history should let you recall them in a couple of keystrokes. But, I know that's not the same as already having them displayed in a table.
You've got me there, I don't know how to do that other than using symbol+offset breakpoints.
I've been using both a lot and VS is clearly better. Both feature wise (for instance "step into specific") and more importantly it's way more stable. But the best debugger I've worked with is windbg. Nothing else comes close when it comes to the features and stability.
Well, that's sad. But hopefully not for long.
Yeah, and that's fine. But actually *shipping* this code (as he suggested near the end of the talk) is probably a bad idea, when dealing with code as widely used - and *especially* as widely reviewed - as zlib.
It's definitely about the UI/UX. Nothing beats VS's debugger for its ease of explorative debugging, i.e. looking at a whole lot of state at once, along with the code, with loads of easily accessible features. It's like Vim or Emacs. They can both do all the things I need an IDE to do (with varying amounts of kung-fu required), but they require a large up-front investment and will never (because at their heart they're text editors) be as simple to use as a well-crafted IDE for the purposes of developing software (and I don't mean just writing code, I mean soup-to-nuts development). GDB can do all the things I use VS for. So can WinDBG for that matter. In fact, they can both probably do things I can't do in VS. However, it's just plain easier to do it with VS, and it's definitely easier to get a new developer up to speed with it. The flip-side, though, is that I still think it's necessary to know *how* to use GDB, at least at an introductory level, just like I think knowing a helping of Vim and Emacs is useful. QtCreator's Python add-ons/wrappers for GDB go a long way toward making the experience nearly as easy, though, so it's not like there's some VS magic that can't be beaten.
Fair enough. I like an IDE myself. In fact, it was in reference to an IDE (CLion) that I expressed my confusion over VS's defenders, since CLion's gdb integration provides most of the features I typically hear expressed as "nice" in VS. And even before CLion, for at least 5-7 years now, Eclipse and Netbeans have both had reasonably competent C/C++ IDEs. And as you mention, QtCreator. I've always found VS's debugger both adequate and nothing special. I only avoid it because GUI-based project configuration makes it hard to develop across multiple platforms.
Sounds about right. The only power-feature I know it has (and I'm sure it can be done by GDB, I just don't know how myself) are the custom visualizers for user-defined types. It can be very handy, *especially* if you do a lot of PIMPL-based programming, to do a more informed visualization of complex types/classes.
Personally, I tend to avoid PIMPL-style shenanigans and dynamicism in C++. I rarely have a business need to hide implementation details as IP protection. And if I know I'm going to be doing a bunch of dynamic behavior, I try to either decompose it into separate processes or I use Java. I have sympathy for anyone who architecturally *needs* a C++ PIMPL or plugin framework.
Promising? I've been using it in production code for over a year. ;-]
That is amazing!
I haven't used gdb's Python scripting, but have used lldb's, which is somewhat of a mixed bag. It's certainly far more powerful than VS's debug visualizer, but it's overkill for simple things, and for complex things I ended up having to spend a significant amount of time doing nontrivial optimizations to make the performance acceptable for use in an IDE that may be updating a bunch of fields on every step (the initial version made stepping over a simple int increment take 10+ seconds...).
I mean discovering, not finding. For more complicated things, where you think you know what you want to accomplish, yes. But if say I go to turn on some testing option and I notice another interesting one next to it, then I have discovered something I didn't know to look for. Disirregardlessly, the point about using/reusing/refinding features that you are unfamiliar with stands.
The "front" and "back" of a stack or queue aren't really meaningful concepts in the way that they are for a vector or a deque. A queue which had push_front() and push_back() operations wouldn't actually be a queue.
I find more than 2 levels of nesting is too much. I like the style organization::project. Anything more is wtf. boost namespaces are really wtf, some of them only have 1 thing exported, like wtf why make a namespace for that one class. Recently I used boost spatial index, and there was a namespace with just 3 classes for algorithms. The namespace above was already highly nested like wtf.
Care to explain, please? I don't see how modules affect extension methods.
Alas, I haven't had a chance to try it out. I saw the CppCon talk, which was great.
C+=2
Mostly from scratch. Used libuv (the netlib under node.js) for networking and Redis for state. I ripped the Redis protocol parser from an existing Redis C API. Used RapidJSON for json parsing. The rest I just put together. Writing an HTTP 1.1 handler is pretty easy after the 10th time.
I fall into the second group. I would love to code in C++ all the time, but as a researcher deadlines matter more than memory efficiency.
The fact that this is even an issue is just extremely sad. Converting an integer to a string? Hello? Java (dunno about C#) can even do this with a language built-in: "" + number And don't get me wrong, I hate Java. But this is just insanely sad. Shit like this is what turns people away from C++. I have been bitten by to_string missing myself. This bug has not been fixed for YEARS, I think it still exists. I'm not sure who is to blame, but whoever implemented this stdlib, is insanely incompetent.
Namespaces are just insanely inconvenient to use and are stopping me from being productive. When I write a header file, I have to make sure to prefix everything with its namespace, as using namespace defeats their purpose. Here's what's going to happen: Once modules have wide-spread support, people are going to put a using namespace for every namespace they're using into every single module. Why? Because there is no reason not to. And then we're going to wonder what the purpose of namespaces was in the first place, all they do is force us to put using-directives everywhere in addition to the imports, for no good reason.
If you're actually manipulating binary data via `char*` then you're working with a streambuf, not a stream.
Yeah but iostreams are notoriously verbose, complicated, *and* slow as molasses. Sufficiently so that I don't think "use iostreams or fall back to C" is a particularly satisfying answer.
Don't fall back to C everywhere, fall back to C one time to write your own to\_string. It isn't ideal, but I don't think this is a particularly _unsatisfying_ answer either – the C++ standard library incorporates the C standard library for a reason.
There is plenty of reason to use namespaces even with modules: - Maintaining multiple versions of classes. - Two different modules might still have same class names and thus potentially violate one definition rule. - Third party libraries will need namespaces when importing into some other project to prevent clashes. - Sometimes you want to keep things nicely organised, period. For example `Geometry::Circle`, `Geometry::Rectangle`, or `Element::Body`, `Element::HTML`, `Element::Div`, or `Action::Attack`, `Action::Sleep`, `Action::Retreat` etc. Like with most other things, just because some people make really poor design decisions with a language feature, that doesn't mean the feature in question is bad. Pick anything in C++ and I will probably can show you a way to abuse it.
&gt; In Visual Studio, I can position my cursor inside of the lambda and issue the set breakpoint command, and the breakpoint will be inside the lambda Huh? I've never been able to do that in VS. At least not in C++. Pretty sure it only works in C#, unless I'm missing something.
You have to enable statement-level debugging (disabled by default).
Rather than trying to get these attributes standardized across all compilers, they should be useable by code generators. Combined with (for example) libclang, you could achieve your goal. Unfortunately, the standard requires that compilers ignore unrecognized attributes, so libclang does not preserve them in the AST Hopefully, that will change in the future. On the other hand, both GCC and Clang support `__attribute__( ( annotate( "your text here" ) ) )`. These attributes can be used for code generation.
Think of it from a generic-code standpoint: if your generic algorithm cares where an item is inserted (and it almost surely will), right now you can use SFINAE to control/tell where a 'push' is taking place, because the name tells you. `deque`, for example, has `push_front` and `push_back`. If `vector` only had `push`, which would it mean? With `queue`, `stack`, etc, the meaning is obvious given the semantics of the adapter; with a container, it is semantically ambiguous, because you don't know which container you're working with.
google 'vimtutor' and then be amazed as you don't have to hunt and peck through menu's hoping to find something new. Most people don't become aware of new features in Visual Studio by opening up a menu, it's a silly argument.
Neat, going to have to try this out with the NDK
Where? I can't seem to find it.
It works in both C# and C++. I wrote the test program in VS to test it before posting just to make sure I wasn't misremembering. I tested with VS 2015, but I recall using this feature as early as VS 2010 when lambdas were introduced. Contra to what /u/dodheim said, I don't recall setting any special option and I believe my setup is fairly vanilla in terms of the debug options. I also can't find the feature he named. 
The people who "own" the Visual Studio version would like to know about bugs you find so that they can be fixed.... /u/STL did fix a bunch of floating point stuff...
 using std::string;
Then my middle initial would be _, obviously.
 http://Google.com?q="when to use classes" http://Google.com?q="what is const in C++" Guys... We hit a new low with this question. Did the eternal September start here? :-) 
My personal favorite is SWIG in this category of tools. It's very powerful, easy to use and supports so many target languages. There's a lot to learn about how it works and its interface definition language, but the process is incremental; it's useful from day 1, and you benefit more as you learn more.
So really dumb question here... but what does this do exactly? Is it something where you can take Java code and convert it to C++? 
Sorry.. i'm new and the documents I have used words I never heard before and the tutorials on YouTube begins with deeper knowledge 
Classes are a great way to organize and manipulate data more easily. For example, you could have three ints for the time as seconds, hours, and minutes, and have a function you call to print out the time. Using a class, you would just have one instance of a Time class, and define how Time gets printed so that you can do something like cout &lt;&lt; time; And get a nearly formatted output of the time it contains. It would also be easier to pass the time around since it would be one variable instead of 3.
Less crashes - Qt Creator crashes almost one or twice a day. Much better refactoring. Much better code browsing and symbol lookup. Better cmake integration. The list goes on and on.
Did you mean "dead **a tree with** his book"? :-)
Basically a wrapper around JNI that does all the ugly stuff for you and lets you access more CPP stuff from Java than normal JNI allows.
One of my favorite SWIG features is cross-language polymorphism using directors: http://www.swig.org/Doc3.0/Java.html#Java_directors
&gt; They show their intent pretty well and generally only have functions that don't have a hidden complexity cost. Iterators though... I have been bitten in a nasty way by checked iterators in Visual Studio. In Debug build, an interactive portion of the program went from unusably slow to acceptable when I changed an innocently-looking statement like std::find(vector.begin(), vector.end(), ...) to if (!vector.empty()) std::find(&amp;vector.front(), &amp;vector.back()+1, ...) I didn't want to change build settings because checked iterators are generally useful. Using pointers instead of iterators disabled all checking in that particular instance because, hey, pointers can't be checked :) (Checked iterators in VS have additional metadata that enables checks for, e.g., iterating out of bounds etc.) 
Which compiler(s) compile ::count directly to popcnt?
In C++, classes are used to: 1. Group things, which are logically together, together in memory. eg: Group the X integer and Y integer of a position in a single Position class instance with members X and Y. This way, you can talk more abstractly about Position instead of passing integers around. 2. Couple data with related functions (methods). eg: Define the distance function (which takes two Positions and returns the distance between them) as a method in the class Position. This way, you can have multiple implementations of the distance function for different types (Position, ThreeDeePosition, ...) 3. Reuse code by defining a new class which inherits from an other. This way the new class will get the same methods and members of the other for free in addition to its methods and members. 4. Hide implementation details: by declaring some class members private and protected. This is called abstraction. Hiding details makes code more understandable and manageable. 5. Unlike other languages which separate classes and interfaces, C++ uses abstract classes to define interfaces. As you can see, C++ uses classes for many different things. It's no surprise that they are hard to grasp at first. ---------------------- Constructors are how you initialize things in C++. You write in the constructors the code which initialize your class members using data provided as arguments to each constructor. You can have many constructors: * In class C: `C(int a, int b) ... `, `C(Position x) ... `, `C() ... ` .. etc. * The constructor `C(const C&amp; x) ... ` is called copy constructor. Its code is supposed to copy data from an other variable of the same class (C). The compiler will call it automatically when it sees code like `C variable = otherVariableOfClassC` with `otherVariableOfClassC` as argument. * The constructor `C(C&amp;&amp; x)` is called move constructor. Its code is supposed to move data from an other variable of the same class (C) to our newly declared variable. The compiler will call it automatically when it sees code like `C variable = std::move(otherVariableOfClassC)` with `otherVariableOfClassC` as argument. The compiler will also call the move constructor in some other cases. 
It lets you call functions and instantiate classes written in C++ from Java. It does this reading C++ code and spitting out Java code and C/C++ code that use the Java API for C called Java Native Interface or JNI. There is no technical reason this code code not be hand-written, but it is a huge pain to get right and because the JNI API is icky and terrible it is hard to use and takes a long time to get even basic things working.
That is what happens when Oracle doesn't care about mobile support and C++ is present in all official SDKs, but seen by the Android team as a nuisance.
Until you actually use it for anything meaningful. NSString* str = [NSString stringWithUTF8String:"really?"] *edit* I see you've made the same point below. 
I was thinking of 'highlight entire source line for breakpoints and current statement', apparently.
I tried it recently, I have very high opinion of jetbrains as I use idea a lot when writing java, but I found some problems, like the auto import constantly imports the wrong headers eg when including std::string
It's all on one line, and breakpoints apply to lines by default, not statements. Try the option I mentioned. ;-]
&gt; &gt; &gt; Might not always suit everyone, though. I don't think there are any plans for this to work: &gt; &gt; Container&lt;Arithmetic&gt; cont = get(); &gt; Couldn't there be type inference for this case, where Arithmetic is defined on the first usage ?
What? I changed from classic IDEs to vim two years ago --&gt; resistant to change?? I find it much easier to work this way. Better workflow, no bloated Application that constantly tries to tell me how to do things. And how said gdb is the gold standard? You guys are great. You think your IDE writes good code, I say you should do it yourself. 
It has its cost, and when I look at C++ as a language in a vacuum, there is a lot of things I don't like. But when I have to spend days fixing my Haskell code _every year_, it's disheartening.
Backwards compatibility causes most of the weird and sometimes annoying things in C++, but it's also the most important feature. Not only can you use 10 year old code, you can even use 40 year old C code without much hassle.
Well, there's even an argument to be made that bad rep for C++ is good for C++ programmers. Bad rep -&gt; less people learning it -&gt; less competition -&gt; higher salaries. 
What do you use?
The option you mentioned just highlights the whole line. It's only visual.
I'm not sure what you're getting at here. It's almost always possible to work around this with local typedefs, then if you're using those types with functions, the functions will be found via ADL. No need to keep typing boost::foo, or whatever. Do you have an example where this doesn't work?
So, similar to JNA?
That's why I had to disable them on case-by-case basis.
So, bleeding-edge vs 8 years old? Totally fair comparison there...
I use Sublime Text so its hardly an IDE. GDB, however, leaves a lot to be desired and thats coming from a primary GDB user of about 4 years. When you say "what can CLion do that I can't do by using vim + gdb?" I read that as "what more can you ask for?". In my opinion, this is an unimaginative position. &gt; You think your IDE writes good code, I say you should do it yourself. Do you think the IDE's cannot help prevent bugs? Do you think you're environment you develop in has no impact on your productivity? Clearly there is a subjective nature to this, but I think its equally clear that there are right and wrong directions to go in as a whole. 
Except when they are not, as anyone that has ported code across multiple compilers and OSes, even across UNIX only systems. The fun of ANSI compliance, vendor specific behaviour, undefined behaviour, POSIX compliance, hardware specific behaviours, ....
The complexity ;) vector, iterator concept and algorithm.
You know, I'd actually be interested in feedback to the points I raised in my comment. There is hardly anything to learn from a downvote other than that some people disagree.
Which implementations, you mean? libstdc++: https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/std/bitset#L212 (msvc does a byte-wise table lookup, libc++ loops)
You may find http://qmlbook.github.io useful :). I'm not sure of many other resources as I prefer to learn by experimenting and reading other people's code a lot of the time.
I don't understand, if you are in your namespace, it will take that. Otherwise, you have many solutons to not type namespases, like using type, using namespace, namespace or type aliasing. It's not that much of an issue, if it is.
https://wiki.qt.io/Books
&gt; Last Build: May 12, 2015 I think quite a bit has changed since, Qt 5.5 and 5.6 is nearly done as well, with lots of changes in GUI and OpenGL stuff? But still probably the most up-to-date complete resource you can get. A good resource with _really_ up-to-date info is the kdab blog (e.g. [newest post](https://www.kdab.com/integrate-opengl-code-qt-quick-2-applications-part-2/)).
That has nothing to do with the lack of Namespaces. That's Apple's coding convention for their Cocoa framework. People have the same issues with Java, and that language has always had an analogue for namespaces. The fact that Apple uses 20+ character Property names in their frameworks isn't a language issue that namespaces can fix. If they used C++, they'd do the same thing.
That's not a language issue, that's an Apple/Cocoa issue. People are confusing Apple using a very verbose coding guideline/style with the language being structured that way. Someone can write a C++ Application Framework using similar coding guidelines to Cocoa and that would not make C++ any more or less verbose than Objective-C using this very flawed definition of "language verbosity," for example. 
Well undefined behavior is portablly undefined across all platforms.
If you look at how the algorithms work, we try to perform checking on ranges once, then "unwrap" the iterators to raw pointers, in order to accelerate the work of the algorithm. u/BillyONeal just overhauled find() for Update 2 (hopefully; still needs to merge into the release branch). By the way, to get pointers to the beginning and end of a vector, you should say `v.data()` and `v.data() + v.size()`, which work when the vector is empty, and aren't sensitive to overloaded address-of operators. They'll also bypass empty-vector checks in front() and back().
From Objective-C, you can just give the Objective-C source file a .mm extension and directly #include C++ headers, and just call them. Most things just work. You can't throw C++ exceptions through Obj-C on the call stack, though, so if you throw C++ exceptions, you have to catch them and re-@throw them as Obj-C NSExceptions. For Swift, you have to wrap your C++ API in a C or Obj-C wrapper, then import that into Swift. Much more cumbersome.
I am not sure python is a good example. I have been bitten more than once when people used a number for durations in python instead of timedelta. And that is not always clear from a variable's name. Yes it works often. In your example I would wonder what else an employee provides. Not knowing its type makes that harder to find out. Also if there are different kinds of employees or if choosing auto was just for convenience. I'd also wonder why the function takes references instead of const references. Is it a pure function or not would be something I'd ask myself. I might come of as old school, but actually I am advocating c++11 features at work (no 14 for us unfortunately). auto is something I am really hesitant about though. Maybe bad variable names used by some colleagues added to that. Also proxy types are something I dread in connection with auto. Take QstringBuilder for example. auto name = first_name % ' ' % last_name; output(name); process(name); Looking perfectly fine, the code above contains a performance issue though. Following our polices % was used to concatenate QStrings, since it is more efficient. Yet name is not a QString, instead it is a QStringBuilder. This leads to the implicit creation of a QString when calling output and again when calling process.
&gt; You can't throw C++ exceptions through Obj-C on the call stack, though, so if you throw C++ exceptions, you have to catch them and re-@throw them as Obj-C NSExceptions. With the "modern" runtime obj-c and c++ exceptions are the same thing. You have to compile obj-c code with `-fobjc-arc-exceptions` to have it not leak memory when unwinding obj-c frames, but that's true regardless of what exception type you threw (and as a corollary, you can't safely throw a non-fatal exception out of something called by a system library, even if it's an `NSException`).
Thanks to you, I've learned something new today.
Agreed it would have been better to have used const references to make it clear that there is no intent to change the employee or pay table. Your statement "I would wonder what else the employee provides" seems more like a writing than a reading issue, but I do see your point. Using more explicit names to differentiate is a possibility. Performance is a tricky issue, since it is difficult to generalize. Using a QStringBuilder might be more efficient in some cases or in some (future) versions of Qt. If you have a specific case where you've profiled the code, found a bottleneck, and found that using an explicit type makes it faster, then I don't see any problem with using the explicit type. I think "auto everywhere" is an overstatement. "Use auto except in cases where there's a good reason not to" is probably closer to the intent. I think if you have code that uses clear names, auto usually works fine, but not always.
I hate CMake. But there is nothing better for now. So, use CMake and everyone will be happy.
And there are filesystems without symlinks, hardlinks, user/group/other permissions, uid, gid, sticky/execute bits... yet those made it in.
Algorithms are so useful over such a wide variety of software that any effort such as the Ranges TS is very welcome. It's about time we had the algorithms with a more functional approach to using them (which is coming later, not in this TS).
Sure, we could pretty much agree that just about none of the languages mandate particular naming style and length, as long as its a valid name. However, much of these discussions treated terms "Objective-C" and "C++" synonymously with the ecosystem of each respective language, and in the Objective-C case, that includes [Apple's conventions](https://developer.apple.com/library/ios/documentation/Cocoa/Conceptual/ProgrammingWithObjectiveC/Conventions/Conventions.html). 
Full UFCS certainly is very controversial every time time it pops up here on r/cpp. That said, since it seems like there are people who really like dot-complete, why not let the IDEs find the free functions too? Even if c++ got full UFCS that's still something that needs to be solved by the tooling (the lookup part at least).
For example, for systems without hardlinks you can always report `1` as a hardlink number. Likewise for 'equivalence': you can always assign a meaningful result. But what would you return as an inode number for systems without inodes? I don't say the design is ideal, but I think it is reasonable enough for 'everyday' use. There is no API that would fit every OS/filesystem. If you need more functionality, you'll need OS-specific API anyway. And I completely agree with you about the `stat` issue. `boost::filesystem` calls `stat` more often then necessary (I have not tested any implementation of `std::experimental::filesystem` yet). But, as fas as I remember, specification explicitly allows to cache the result of `stat` call.
I get what you're saying, but you're missing the point... Completely.
To that end, this doesn't even have to be a C++ feature. Say `std::split` comes out and it has a special overload for `std::string`. It would be cool if there were a tool that supported me typing `str.`, selecting `split`, and having the tool automagically turn my call into `std::split(str,|)`. Or to use one of the examples I've seen, I have a `FILE* file`. I type `file.`, select `fclose`, and it turns into `fclose(file)|`. Edit: Just to clarify, *this part* doesn't need a C++ feature. The dot notation still also offers a nicer left-to-right chaining syntax without any operator overloading tricks.
I've been working with Qt for the past year and a half. Easily the best way to learn to use it is to take a look through all of the examples, and find the ones that most closely contain projects similar to what you are trying to do, then look and see how they are built. Other than that, read the documentation and look at the examples for how to properly use them.
I'm in full support of this.
You could use a really solid variadic printf library that C++ empowers you to write. Fast, safe, and concise: https://github.com/cppformat/cppformat. Most languages actually cannot write something this awesome, because very few languages have proper variadics.
I highly dislike arguments against `auto` that rely on badly named functions and variables. auto x = snarfgalflu(); zomg!! unreadable! farlogermorap x = snarfgalflu(); So much clearer! Auto sucks!! The reality is that good names are what make code readable, not whether or not someone chose to spell out a typename. I'd like to see a real example where `auto` makes code legitimately harder to read that wouldn't benefit from better names. 
&gt;"people whose experience and opinion I respect insisted that x.f(y) finding f(x,y) would seriously compromise their ability to design stable interfaces" Can anybody give a bit more detail about exactly why this might be?
\*cough\* pot \*cough\* kettle &gt;_&gt;
Nobody ever said anything about preventing people from organizing their code. I'm comparing the current/future state of C++ to the ideal. In the ideal, namespaces are completely unnecessary, because modules already introduce scopes. That's how many mainstream languages do it. Personally, I couldn't give less fucks about what other people think of my ideas. As someone who designs their own language: By default, anything you do differently is bad, more complicated, etc.. That's what people say all the time, without even thinking about the bigger picture. It's very unfortunate, because current languages have so many design mistakes in them, it hurts. I'm just gonna keep doing my thing.
I don't think there was any "unwrapping" in VS2008, and maybe not even in VS2012, because I remember stepping through the code and it dispatched for some reason to iterator- not pointer-based loop. In any case, my memory is vague after a couple of years and you know best about this stuff :) What *is* certain that the code was in a tight loop which noticeably affected run-time behavior. Oh, and even in 2015. I didn't have the luxury of using C++11 features, so `data()` would be ruled out. (The product deliverable was a bundle of DLLs and headers, and VS in particular is finicky about compiler versions and configuration settings. Also it had to run on an ancient, stock RHEL5.) But thanks for the tip, I wasn't aware of it until now :) A related "feature" which bit me was that erasing elements one by one from a linked list ended up being O(n^2) instead of O(n) when using checked iterators, because each node's destructor checked the connectivity of the whole list. Ouch. (Long story short: I erased elements one by one because it was a LRU cache of disk chunks, and I had to flush the cache when I was done with the database.) 
vectors since they might be slow, crappy, for newbies and whatever you like but in the end 99.9% of people use them because C++ lacks anything else and nobody wants to fuck around with folly and other 3rd party libraries (or even worse shit on github).
`s/find/copy/` :)
So true. Qt docs are crazy good.
It's helpful even in release builds to make `std::vector::iterator` a class type rather than a pointer type though, to fail compilation for things that should not compile; e.g. assigning a `vector::iterator` to `uintptr_t`.
Let's just say there's a reason it's still in `std::experimental` :) (There are a bunch of issues we found in the spec I still need to file but our (Visual Studio's) implementation is particularly problematic)
Why not use Gtkmm? My impression is that Gtkmm is more modern and better designed than Qt. Not saying that Gtkmm is 100% perfect, but on the other hand, GUI libraries are pretty hard to get right. 
Oh grr, I got confused between find and fill. Can't tell my algorithms apart.
If you find a performance issue with `vector` we would seriously be interested to know about it. Unless you're talking about the inability to ask for garbage-init of a vector?
&gt; f(x, y) wouldnt be able to access private members of x while x.f(y) can Unless its marked as a friend function in x's class declaration
I don't like that much (euphemism here) package visibility in Java - the fact that package/namespace visibility doesn't extend to sub-packages/namespaces.
Three letters: ADL.
Oh right, `x.f(y)` gives priority to member, and `f(x,y)` gives priority to non-member, so nevermind. My point about ambiguity still applies: the only way to introduce silent breakage is if one type of function is preferred over another for a particular syntax. That is, if `x.f(y)` prefers calling a member, or if `f(x,y)` prefers calling a non-member, then silent breakage is possible since you can always construct a case where hijacking is possible. However, what Bjarne originally proposed prevents silent breakage. That is, if `x.f(y)` and `f(x,y)` always call the same function, then silent breakage is impossible. If both a member and non-member function are equally good candidates, that would introduce an ambiguity and generate a compiler error. That means the user would need to explicitly state which function should be called.
I made it about 6 words in.
&gt; "So, we are left with a simple proposal to allow f(x,y) to find x.f(y) where f(x,y) wouldn’t work today. This solves the problem for library writers and their users along the lines of the STL:" aaarrrgghh. DISASTER. This is exactly the wrong version. we need ```x.f(y)``` to allow superior chaining ```x.f(y).g(z)``` and, more importantly, *dot-auto-completion* (which is about discovery, not typing), everywhere. If there are concerns, why not merely allow it with an explicit 'this' pointer, so it requires a deliberate opt-in ? e.g. ```void foo(Bar* this);```. Advantages: (i)no surprises for existing source bases, and (ii)a clear ability to search for UFCS-able functions; (iii) it would be easy for a style guide to ban it on specific projects (enforceable with checkin script). (iv) easier to refactor code either way (into or out of member functions) (v) You could even move toward using smart pointers for 'this'. It's not about 'OOP' ('selling out to the OOP crowd'); it's about discoverability, readability &amp; refactorability. *It's the OOP crowd that want's to keep ```a.f(y)``` special.* The discoverability of dot-autocomplete in mature IDE's is the main reason I haven't migrated to Rust already. So, we're going to be stuck with code bouncing between the styles.
[removed]
&gt; Why not use Gtkmm? Because (from what OP writes), chances are good that he has no say at all in the choice. Also, Qt is much more than a GUI library; Qt cross platform support is better than for gtkmm. This is not a stab at gtkmm, I agree with you about its virtues, but you are too early to push it :-).
&gt; No. ADL will "fix" it even without the using. I completely forgot about that, that's actually scary. This means my example is less contrived than I thought and what `reverse(list)` would call really can depend on implementation details or contents of any other header you use. ...now that I think about it, I sound very similar to people that were scared about function overloading making it harder to reason about code. I still think it's way worse here.
Nowadays, when a device (wifi etc.) on a Windows machine fails, I try to boot it with a live Linux USB to see if it's a software or a hardware issue. It usually ends up being a software issue because it almost always works out of the box on Linux. Please take your 25 year old outdated opinions elsewhere.
I fully agree on 1) and 3). Concerning the presentation, I've seen some articles of this blog on reddit (maybe this one?), the grumpy side is simply a persona - though a tad extreme. Some points are good ("Open source is fad-driven")
well personally I think it's partly trolling. But some of the rants on his website are kind of funny. This doesn't have anything to do with c++ though, other than his single sentence about modern web apps being much worse than 1990s c++ applications (which in large part I entirely agree with).
Writing `std::move(object).member` never occurred to me. This article taught me a new idea. Thanks! Regarding the last example, correct me if I'm wrong, shouldn't `Window::Window(WidgetCfg w)` work better and still benefit from move semantics? 
Adding functionality can always lead to ambiguity if you don't clearly state who can add stuff to a namespace. Suppose you have your `class Point` in a `namespace N`, some user defines `length(N::point)` in the global namespace, and you later decide to add a non-member function `length(Point)` inside `namespace N`. Relying on ADL by calling `length(N::Point{})` will then be ambiguous. 
The sad thing is that during overload resolution, member functions are already normalized to a prefix syntax with an implied object argument given by the `this` pointer. So the compiler already has all the machinery in place.
Passing the cfg object by value will cause the object to be created. If there's a move constructor this is probably cheap but still more expensive than no copy at all. In the end only some of the fields may be copied/moved). Also remember that there may not be a move constructor defined in the first place. 
Would making Widget::config_name const have the same result?
I love this combination of complaints, just a few lines apart: &gt; **It’s a barely manageable language** &gt; 1. The split between source and headers, which makes project management quite slow. &gt; 2. You still can’t write template code in .cpp files. So he both hates the fact that there are both .cpp and .h files, but he also hates that he can't split his code into .cpp and .h files when writing with templates. Huh.
Interesting article. I've been a programmer since age 13 and professionally for 30 years. In the past 15 I don't get to do as much every day since moving more to architecture and leadership but still love it. Competitive Coding gives you a chance to keep your skills sharp. Thanks for posting.
There is also this point to consider struct Widget{ unique_ptr&lt;Data&gt; getPayload() &amp;&amp;; shared_ptr&lt;Data&gt; getPayload() &amp;; }; Widget foo; Where auto data = std::move(foo).getPayload() will produce a very different meaning than auto data = std::move(foo.getPayload()) I find the first use case to be much more "confusing" than the second. But since the behaviours are very different... I am not sure if this is good code (readability wise)
Whether it actually performs a move or not is irrelevant. If you use `move` then you are clearly signalling that you don't care about the object any more, and the compiler (or the `move` implementation) should be free to completely destroy it at that point.
[removed]
The big picture is good; the details are a little off. The compile cannot "destroy" a variable when it's been moved out of - it has to wait until the variable actually leaves the scope. For example, in that constructor, `w`'s scope is all of the constructor - if you had more code inside the `{}` braces, then `w` would be in scope for all of it, even though it had been moved out of. Howard Hinnant explained this to me as follows: when you "move out" of a variable, it's left in an _unknown_ state, one where you know it can be destroyed, but one where no other methods or operations are guaranteed to work. But it isn't actually destroyed until the end of its scope, and you can still do things like take its address, for example. 
I agree with pretty much everything you just said. Just to be clear I never said VIM is the wrong direction. As previously mentioned by another user, VIM and emacs are 'arbitrarily' powerful. I am very skeptical about out-of-the-box vim, to where certain plugins are 'necessary' to really get the full experience out of it. As soon as you start bundling features or plugins together it starts looking IDE like. I will say I think GDB is the wrong direction. It is an amazing tool but we've come a long way since GDB was built and there is no reason we should still be using it. We can do much better.
tl;dr "I like Windows better".
&gt; And what benefit is there In your example where everything's references, of course there are no benefits to move semantics! Indeed, if everything's references and you never have to destroy anything, there is never any need for move semantics in the first place. The benefit comes when one of the parameters, say, `config_name` is actually some sort of value which is expensive (or even impossible) to copy, but cheap to move.
I wrote a little tool that records my typing, then another tool that plays it back (sped up :) ) and inserts the responses. I ran that second tool in a terminal window and used a third tool to record it to a GIF (LICEcap, but any recorder should do).
I didn't say the compiler would actually destroy the variable, I said that it (being the compiler or the `move` implementation) "should be free to" as in "your code shouldn't break if it did". In other words, a reference to a *potentially*-moved-from object should be treated like a dangling reference. The only reason I can think of why the compiler can't destroy the variable at that point is simply because `move` is a standard library feature rather than a language feature. It's easy to imagine a `move` keyword where the compiler would happily destroy it at the next sequence point as if it was a temporary, and that is what I like to imagine.
N4567 5.2.5 [expr.ref]/4.2 "If E1 is an lvalue, then E1.E2 is an lvalue; otherwise E1.E2 is an xvalue." `move(outer).inner` doesn't call Outer's move constructor.
I've approved your post, which was caught in the spam filter for some reason. Usually we send questions over to r/cpp_questions, but this is more advanced than the usual beginner stuff. And as it so happens, I'm qualified to answer this one. This is not a defect, but a design choice. Compare vector and list. vector is better at most things: it has the highest locality (which translates directly into speed), its contiguity is compatible with C APIs, it has the least space consumption, and its iterators are the most powerful. vector is so great at almost everything, but it has a couple of notable limitations. It doesn't like insertions and erasures anywhere other than the back, which is occasionally an issue. And vector reallocation provides weak pointer/iterator stability guarantees (you can ensure that reallocation doesn't happen with reserve, under certain conditions, of course). Now think about list. It's worse at most things, which is why we don't use it often: it has poor locality even with a friendly allocation scheme, its non-contiguity rules out C APIs, it has piggy space consumption (with an overhead of two pointers per element, plus any invisible allocator overhead), and bidi iterators are annoyingly weak. list has only a few strengths that make it useful: its ability to insert and erase at the front is convenient, its ability to insert and erase elsewhere is theoretically convenient (but much less useful in practice; this includes splicing), and it provides very strong pointer/iterator stability guarantees. Now consider the "optimization" of container-internal sentinel nodes. This is permitted, but not required by the Standard. This *weakens* one of list's strengths, i.e. one of the reasons to use the container in the first place, in an attempt to save exactly one dynamic memory allocation per container - when that container will be allocating a blizzard of nodes for all of the other elements. And the weakening is significant - pointers/iterators to end nodes no longer remain valid during swapping/moving (instead they are parented to the original container). Thinking back to vector, which has weak iterator guarantees - even vector inherently allows end iterators to be preserved during swapping/moving (being reparented along with iterators to elements). I argue that losing the ability to have arbitrary ranges (which typically include end iterators) remain valid during container swapping/moving is not worth saving one allocation in wildly-allocating containers. Yes, the Standard doesn't guarantee that end iterators remain valid in these situations, but our Dinkumware-derived implementation historically has, and I have no desire to break user code at runtime which has chosen to rely on this behavior. You are free to disagree with me, as long as you understand that this is an intentional design choice, and not an oversight.
&gt; Vimtutor exists because it acknowledges a problem. It's a tutorial for a program. Yet it's existence implies a problem with said program. As I said, people will believe anything.
The tutorial program is not the problem. It is a particular solution. Smoke, not fire. The problem is that in order to use Vim you need a tutorial program. Ideal tools don't require this. Hence, a problem. Have graphical editors solved this particular problem? No, but they are closer than Vim is. Or at least *within personal opinion* of being closer. Are there other pro/cons to consider? Yes. I hope that this is straightforward enough for you.
&gt; Ideal tools don't require this. As someone who recently purchased CLion, you're full of shit. I found myself spending a lot of time in their documentation because I hadn't ever used one of their IDE's before. vimtutor is a way to ease people into vim. CLIonTutor would absolutely be useful.
Oh, right, sorry: I really meant ideal, as in, no such thing exists. If you reread with that in mind, I'm saying simply that many would - do - consider IDEs further along the gradient. I mean, you know, I use emacs anyways. But it seems to me that IDEs have been improving in this respect over time while Vim/emacs, culturally, don't even think it's something that should be improved. See, now I'm actually saying things you should disagree with, but until this point all I've been trying to say is that this is an area where the graphical editors have a different take, and thus, it is a reason that some people use IDEs.
&gt; For example, for systems without hardlinks you can always report 1 as a hardlink number. Likewise for 'equivalence': you can always assign a meaningful result. But what would you return as an inode number for systems without inodes? That'd be presumably covered by: ``` If an implementation cannot provide any reasonable behavior, the implementation shall report an error as specified in § 7. ``` To me it feels like someone who is only familiar with POSIX filesystems and has used Boost.Filesystem has put together a proof-of-concept for a potential std::filesystem, but there hasn't been the further exploration of future expansion, edge cases, non-POSIX filesystems etc. that I'd hope to see in a proposed core language standard. It's not completely without merit, of course - just seems half-finished. The end result is that a filesystem library would need to integrate with the platform-specific APIs directly rather than being able to build on them, taking advantages of features where available. Granted, that's not any worse than we have at the moment - there are plenty of cross-platform filesystem wrappers around. It does discourage me from spending any time using std::filesystem because I'd expect to run into the limitations pretty quickly and have to rewrite things to use a different API: better to start with something else instead. &gt; And I completely agree with you about the stat issue. boost::filesystem calls stat more often then necessary (I have not tested any implementation of std::experimental::filesystem yet). But, as fas as I remember, specification explicitly allows to cache the result of stat call. ah, I didn't notice any specific wording about caching stat() info... seems unlikely to be an option in most cases, though: unless the filesystem guarantees some form of notification mechanism, I don't think you would be able to detect whether another process has modified things in the meantime? That process/thread may not even be running locally, if this is a network filesystem. There's also the question of memory usage - would this cache just the most recent value, or some form of LRU unordered_map&lt;path, stat&gt; structure?
You seem to be confused about what `std::move` does. This function only converts the reference type. It does *not* change object state. It does *not* call a move constructor. X x1; X const&amp; x2 { std::move(x1) }; This does *not* call a move constructor. The `std::move` is superfluous. It has no effects. X x1; X x2 { std::move(x1) }; This *does* call X's move constructor `X::X(X&amp;&amp;)`, if there is one. *Edit:* Fixed `X&amp;` -&gt; `X const&amp;`.
I mean, go watch someone learn Vim for the first time and then tell me Vimtutor isn't intended to ease a few quite Vim-specific problems. Regardless that's not the point: Even if everything needs a tutorial, it's a gradient. Some things need tutorials *less*. It's arguable how good IDEs are this way, but many many people feel that they're more amenable than Vim - that's literally it, right there, that's all that needs to be said. Is this a criteria on which some people choose IDEs over Vim? *Yes.* I really don't think I'm saying anything controversial.
I tried HackerRank, but I am too much of a purist and perfectionist, trying to find generic and high performance solutions. So I tend to overengineer solutions which takes me significantly more time than others. Although finding a functional solution in as little time as possible is the target, and a quick solutions are appropriate in said environment. I fear that it may lead some people to prefer quick and functional solution that work for some cases, neglecting important traits such as scalability, performance or cross-platform compatibility. 
I once had an IDE specific problem. I couldn't figure out how to autocomment/uncomment my code. And you know what the weird thing is? I didn't find the answer by trolling through the UI looking for the entry next to the comment/uncomment entry. I googled. because it was easier and faster. And you know the really weird part? That was a Visual Studio specific problem, because when I went to do the same thing in CLion I found myself googling again. --- The question then is, why do people use IDE's over vim when you google for most of it anyway! The secret is in the first letter of that acronym. __INTEGRATED__ Development Environment. Visual Studio, for example. you get a project manager, an editor, a debugger, a source control frontend, a frontend for editing/looking at/designing DB's and their data, and so on and so forth. The other reason? the modern GUI allows you to access functionalty without memorizing hotkeys. It has very little to do discoverability because, as I said when I entered this conversation, most people learn about their tools of choice, including their IDE, by googling. and since vim has vimtutor, it could technically be considered 'more discoverable', although no one would really make that argument. OTOH, no reasonable person would make the argument that vim was somehow __less__ discoverable because it had vimtutor!
It's all right to have intuitive ideas about what std::move does (i.e. _move_), but it's also **very** important to understand what it _actually_ does. std::move never calls any constructors or any other functions. It's just an unconditional cast. The way it interacts with constructors and other functions is when you pass std::move(x) to them. There, functions can choose to do things, based on their knowledge that their input is an rvalue. If you don't pass std::move(x) to a function and that function does something, nothing will actually happen. In this case, std::move(w).height is not std::move(w) being passed to some function, it's just being used to refer to a property. No rvalue constructors are being called, and w itself is not modified.
&gt; Obviously if you are a professional c++ programmer you won't need to use c much, but we are talking about teaching computer science students here. Kate Gregory is talking about teaching C++ and she's _not_ specifically talking about CS college curriculum. Furthermore, even as part of CS curriculum teaching C++ badly does not help one learn C++, nor does teaching C require teaching C++ badly.
No, that's not at all what she said. You could learn C first, and as long as C++ is taught as a _different_ language, not using the C way of doing things in C++, then C++ can still be taught correctly. I feel like maybe you didn't hear the first 40 seconds of the presentation: &gt; Lets be clear: Obviously if you're teaching 'Intro to C' that's a fine thing. My complaint is for people who are not teaching 'Intro to C' but who nonetheless start their 5 day [C++] course with 2 days of C material. This [presentation] is my suggestion for how to have a course that is more enjoyable and makes better C++ programers, which is probably the whole point of teaching anybody anything.
I see. I guess I missed that. Obviously if you have such a short C++ course then it makes zero sense to spend 2 days out of it learning C. I was thinking more about how undergraduates are taught, where you have a course on C and then a course on C++ (or in my case it was a course on C and basic programming in general, and then a subsequent course on more advanced aspects of C and C++). So for me, I did learn C++ as an extension of C, and never felt that it was a negative experience or had negative consequences.
 &gt;I fall into the second group. I would love to code in C++ all the time, but as a researcher deadlines matter more than memory efficiency. Even for personal projects I find the efficiency of using Python to be a big win. That is productivity beats anything C++ has to offer in most cases! I do keep an eye on language developments and in this respect I'm watching Apples new "Swift" language with a close eye. Will it succeeded as a compiled language that is as easy to use as interpreters with expressiveness like Python? Swift isn't the first language to attempt to bring the advantageous of both worlds to a developer. I say "worlds" here because at times developers using compilers, be it C++ or something else are often from different planets that developers using interpreters such as Python. We really haven't seen a language that bridges both worlds and be successful. Will Swift do so? I don't know but it appears to be the only compiled language in the running right now that might draw in Python programmers. One thing is certain though, Python isn't going anywhere soon. It has actually become entrenched in various niches as the best solution out there. 
&gt; Not sure I see the problem with breaking code which relies on iterators being valid when the standard doesn't guarantee it. (1) It would be a runtime break, which I am far less comfortable with than a compiletime break, and (2) I think that assumption is entirely reasonable. &gt; emit a warning if the flawed-strong-guarantee-assumption is detected. Determining that requires high-level understanding. &gt; If this is not possible to detect, make the stronger (but slower) guarantee a compile flag. No? No - that's a mode that affects binary compatibility. Have too many of those already. Yes - I have thought about this extensively.
 &gt;Well, there's even an argument to be made that bad rep for C++ is good for C++ programmers. I can't ever see having a bad reputation as being a good thing for a language. I've seen people, probably people without real C++ knowledge, justify taking alternate development paths simply to avoid C++. In the end if too many people do this C++ will die. Thankfully right now there is little in the way of good established choices when it comes to performance. &gt;Bad rep -&gt; less people learning it -&gt; less competition -&gt; higher salaries. That is one way to look at it, but I think it is missed placed. Bad rep means far fewer people specifying the language. This leads to lower demand. Bad rep also means people look seriously at developing alternatives that supposedly address C++ problems. Let's face it; D, Go, and Swift are all directly the result of problems the world believes C++ has. Eventually somebody will get it right and there will be a rather rapid shift away from C++. There is a flip side here too, many people won't admit this but in the industry a good C++ programmer is often thought of as being more intelligent than the average programmer. I'm pretty sure knowledge of C++ has been used to weed out programmers in the hiring process. 
Stephan, thanks for managing my question and your answer, i've expected this exaclty from you :) So, let me summarize. We have those args with current design: Cons: possible exception on default construction; unexpected (by most ordinary developers) construction flow - and it is hard to catch ever in runtime; eh frames in any object hierarchy constructors, that 've used containers (and no chances to compiler to optimize whole object); memory allocations for default constructed containers; ever worse locality in many cases (one more indirection required to use begin/end); harder memory usage (in addition to self container allocates head node with "uninitialized T"). Possible i've missed others drawbacks... Pros: end iterators are remains valid after swap (that is not required by standart), so that poorly written (non C++) code is working - could be resolved as runtime check or with compile time code analizer; binary compatibility (joke - it was changed constantly from VC8 up to 14). For some reason it seems to me if we ask a spherical developers in the vacuum to choose a suitable option, they will choose the option without the allocation of additional nodes :) So, are there any chances to move to another design (yes - like gcc/clang/ whatever)? Maybe with macro. How could we (as a customers so far) push you to think one more time about this issue? Thanks!
That's just flat wrong. You can't write "extension methods" for people who use the x.f(y) syntax. You get essentially the same effect for people who use the f(x,y) syntax, such as the STL.
&gt; fuck anyone who has two functions foo(bar) and bar.foo() that do different things, right? I've been thinking that's the most logical way to distinguish between "modifies target" and "returns a modified copy", eg: //where ltrim = left-side string-trim, rtrim = right-side string-trim string x = "hello!"; string y = rtrim(x, "o!"); //y == "hell" x.rtrim("!"); //x == "hello" It certainly beats out having to force everything to be immutable (painfully slow), or using: string y = string{x}.rtrim("o!"); string z = x.clone().rtrim("o!"); ... but I'm open to suggestions. I think Ruby likes to put ! at the end for mutability, eg x.rtrim!("o"), but the only symbol we could *maybe* use in C++ would be $, and uh ... just no.
I can't help but feel like the majority of hate I've seen for C++ as a language has been from people who just lack the desire or ability to understand it...
Interesting! That's actually a convention I haven't seen before, and I can see it has a certain merit. &gt; ... but I'm open to suggestions I'm a fan of using present-tense to communicate "modifies target" and past-tense to communicate "returns a modified copy." So in your example: &gt; fuck anyone who has two functions foo(bar) and bar.foo() that do different things, right? I've been thinking that's the most logical way to distinguish between "modifies target" and "returns a modified copy", eg: //where ltrim = left-side string-trim, rtrim = right-side string-trim string x = "hello!"; string y = x.rtrimmed("o!"); //y == "hell" x.rtrim("o"); //x == "hello" This convention would be more compatible with full UFCS, and I think it reads very well. The past tense communicates the return of an object that had an action applied to it, where the present tense communicates the action itself.
Interestingly, Python uses *both* of these conventions to differentiate `lst.sort()` and `sorted(lst)`. The free vs member function wasn't chosen for aesthetic reasons, though, it's of some practical importance.
If you're okay with ghastly unique syntax, something similar can already be done: struct string : method&lt;string&gt; { using method::operator[]; using method::operator(); ... }; void transform(string&amp; self, const string&amp; from, const string&amp; to) { ... } string&amp; strip(string&amp; self, const string&amp;) { ... } int toInteger(const string&amp; self) { ... } int main() { string s = "Hello, world!", t = " 348 "; s[transform]("e", "a")[strip](" "); int x = t(strip, " ")(toInteger); } The foo(function, args) syntax calls function(foo, args) and returns whatever function returns. The foo[function](args) syntax invokes function, discards its return type, and returns foo&amp;, so you can method chain to your heart's content. For the most part, it won't interfere if your class already has operator[] or operator(), because the overload on the first parameter being a function pointer would be an exceptionally rare thing to encounter in regular code. The source for the method class is here: http://board.byuu.org/phpbb3/viewtopic.php?f=7&amp;t=51&amp;p=724 But be warned ... it's a thing of horror. If you tried that on my production codebase as my employee, I'd fire you :P
To be fair, having a class with a public non-const reference member is a pretty fruity thing to do in the first place. I would prefer to avoid the issue entirely by making sure that class invariants are controlled by access functions (i.e. encapsulation). It should not even be possible for a user of `WidgetCfg` to destroy the global state.
I do like that, but I have a lot of functions that don't take past-tense words very well, just in my string class alone. Like my tokenizer: what's the past-tense of split? Trick question! It's also split :P (of course, you're unlikely to want split to assign an array of strings to a single string, so this isn't a valid case. But the point stands ... English is a nasty language for tense/plurality/etc changes.) Definitely though, UFCS, if it ever came about, would not play well with my idea at all. And I don't entirely like my idea either, because nested functions evaluate right-to-left, whereas nested method calls evaluate left-to-right. Any kind of mixing of the two results in pure hell, eg: split("\n", lowercase(string.reverse().rtrim("#"))).strip(); //vs string.reverse().rtrim("#").lowercase().split("\n").strip();
Yes, this might lead to a different function silently being called after a recompile. However: * Can't the exact same argument be made by symmetry in the other direction? i.e. with this proposal I rely on `length(line)` calling `line.length()`. Then version 2 of the library silently adds a new include which causes a valid `length(line)` to come into scope (possibly by ADL). Now my code still compiles, I get no warnings, but it possibly does something different. Isn't that the same problem? * It's always been the case that a newer header could add another overload which is a better match, and thus call a different function. This doesn't seem any different * Presumably this is this case in D and other languages with UFCS. How do they deal with this problem?
nice blog post, definitely agree with every point made
Indeed. At first I thought, well, std::move(object.member) is one questionable use, but the other is questionable just as well. It is like TFA forgot what move semantics are here for: to speed up wholesale object assignment/construction, normally with temporaries. BTW, not using features for what they intended, is one of things C++ people do and then wonder why C++ gets bad rep.
And what problem this addition solves?
The other way around: `x2` is a lvalue-reference and it cannot bind to non-const rvalue reference.
It's funny how some people (ab)use C++ on topcoder by just using a ton of utility `#define`s they copy to the top of their code. The problem with using `&lt;algorithm&gt;` however is that most of competitive programming websites started to support C++11 like 2 years ago at best. It's good that now most of them support it though.
Could you please explain me why don't you allow x.f(y) to f(x,y) conversion? In papers I found something about "backward compatibility" but didn't understand what you meant.
I do like x.f(y) over f(x, y). But... Alternatively, couldn't you just solve this dilemma via a tool. Why not just let your tool do the conversion/transformation from x.f(y) to f(x, y)? All it would have to do is determine what functions accept `x` as a reference or pointer for the first parameter, which would have to be done if the specification was the other way around, right? For instance, if you type `x.f|` -&gt; `Tab`, then your code will transform to `f(x, |)` (`|` is your cursor). &gt;it would be easy for a style guide to ban it on specific projects. This could be implemented via an option (e.g. Transform Call Syntax = {Always use UCS, Only use UCS in Generic Code, Never Transform} or via a custom key-bind (if you preferred). Though, relying on tools might be some-what of a bad thing. However, I think it's quite possible to implement this independent of an editor/IDE with libclang or any other library that you can analyze the AST with.
I had a small problem with this once - it complicated my custom memory management system. Because I had static global-scope containers (I know, I know), I had to create the memory management system as early as possible, before even `main()` run, which meant I couldn't modularize it well and couldn't run any setup for other dependent systems, before the memsystem was (expensively) constructed. This was a solvable problem, but it DID increase code complexity, which is sad :( The arbitrary order of static initialization didn't help here either.
I'm off my meds, so I shouldn't elaborate, but eww, competitive programming. Ignoring the fact that most "programming" competitions are actually "algorithmic" competitions, competition in programming increases aspects detrimental to it's overall goal - contests/competitions tend to value: * speed over precision/clarity * "cleverness" * intuition-based problem analysis * aggressiveness towards your peers (subconscious, obviously) * prize-oriented thinking * individualism in problem solving * ignoring real-world concerns like performance, scalability, readability None of the above are beneficial to the programming ecosystem, and yet they are trained into people via competition.
&gt; I do like x.f(y) over f(x, y). But... &gt; Alternatively, couldn't you just solve this dilemma via a tool. the compiler is a tool. we could solve it there :) I realise we could make the tool transform ```x.f|``` -&gt;```f(x,|)```, as you suggest , but it would be nicer to have coherence between what you read and write - how you mentally think about it. Smoother interface between man, machine, source code, and between programmers. I guess the tool you suggest could be done independently as a backup plan, and it would help with existing free-function sourcebases. Another idea I had in mind was to make a tool respond to _ wildcards, e.g you write ```_(foo,bar)``` and it would list functions taking a 'foo' and a 'bar' as a menu of replacements for the '_' ; perhaps allowing larger expressions, with more complex inference (see haskel holes for inspiration). e.g ```Baz x = _(foo)``` // find functions taking a foo, returning a Baz. ... but the natural flow of 'dot-autocomplete' is better; it corresponds to the order of operations, and you don't have to move the cursor back &amp; forth balancing brackets. The fact that we *can* get the same logical result with f(x,y) should nullify all the arguments against x.f(y) :) 
Now, hold on a moment; yes, the code is *bad*, but I don't see anything in there that is actually illegal. You should be able to construct the headers such that that code would compile. E: Nevermind; syntax errors -- missing parenthesis and semicolons. Fix those, though, and I'm pretty sure it's valid.
Oh no, don't get me wrong, I have nothing against solving programming puzzles! But wanting to compete doing something you enjoy is not motivated by the need to do something you enjoy (as you can do that on your own), but the need to compete. And it would not be healthy if a person brought that need into the work place.
You don't need to return from `main`.
Fixed, pull last commit from repository.
Yes, I want to submit this to Boost, but I have to get moving on changing the license (have to discuss with former employer), and making some remaining improvements first.
Your are going to want to spend a lot of time getting familiar with "signals and slots", know how to use them and how they can be used to make thread safe code. Learn about the QML scene graph, and if it's threaded or not threaded on your platform. Also learn how to create your own QML type with subclassing QQuickItem. Know how to register this type with qmlRegisterType(). So it can be used in QML. Know what qmlMetaRegisterType() does and how it can be helpful. Everything else, read that QML book and the Qt docs. Newest version is 5.5. Cheers! 
&gt; they released another proprietary driver again I understand the ideological reasons people have not to use the nVidia drivers, but pragmatically... they're the absolute best 3D acceleration drivers available on linux. Only nVidia's proprietary drivers are on par with Windows drivers. 
&gt; Only nVidia's proprietary drivers are on par with Windows drivers. Performance wise maybe, feature wise they're far from being on par.
Maybe because from now on you can use it in your C++ applications.
From a graphics developer's POV, they seem pretty identical. The same OpenGL extensions mostly seem available both on linux and windows. But if you're talking about user-facing customization, tuning, profiles, etc... you're right. But that has more to do with X's shitty architecture than it does with nVidia's choices.
C1XX generally warns about the Evil Extension at /W4, at least. Always compile with /W4.
Ok, so the standards committee rushed std::async, but couldn't they at least have picked an actual default for it instead of rolling the dice? Unless they for some reason also want it to work on systems without actual threads.
Well doesn't matter any more. With Vulkan they are on par both performance and feature wise.
OP are you the author? If so can you clarify your reasoning for nº6?
Rant of the day, language X is better... yes yes, we get it. (meanwhile the world continues to use software written in C++) 
This is weak rant. Is C++ a perfect language, of course no. Just like the world we a living in. Is Haskel better language as C++ ? Hm, may be in some cases, I do not know it well enough to say this. But I think that it is not perfect language too with its own "hack's". Why use Haskel as a new language if one can use say Rust ? 
I'm going to remove this, partially for having been submitted with an even more clickbaity title - the linked gist doesn't mention Haskell. But mostly for not contributing to any sort of useful discussion, due to the poorly reasoned arguments.
OpenCL = Run C on a GPU so that you can use the GPU to make some parallel algorithms run faster, and free up the computer's CPU to do other stuff. OpenGL = A C API for using the GPU to draw triangles for 3D graphics. You can now run some GLSL code called shaders written in GLSL which control the lighting on the triangles, but the basic API design is based on the way that single CPU SGI workstations in 1991 drew triangles with fixed functionality hardware. Vulkan = A new C API for using the GPU to draw triangles for 3D graphics. It's designed around the fact that modern systems tend to be able to run multiple threads, and have GPU's that have lots of general purpose programmable functionality. Supports programmability for shaders and such using an intermediate representation kind of like what llvm (and clang) use called SPIR-V. You can compile GLSL to SPIR-V to you can compile from whatever shading language you can dream up to the well specified intermediate representation that is easy to make work on any kind of GPU hardware. But at its heart, the purpose is still to draw triangles on the screen. DirectX = A whole bundh of Windows COM API's, including Direct 3D. Direct3D = a Windows API for drawing triangles that was created as a competitor to OpenGL. It has evolved over time to be a competitor for Vulkan in the newest version. Broadly speaking, it has feature parity with Vulkan. It is limited by being proprietary and vendor specific. It benefits from being part of a large family of API's that work together for things like sound, input, video codecs, and other stuff that is all pretty useful if you are making a multimedia app like a game. Metal = An Apple API for drawing triangles. It eschews some of the legacy cruft of OpenGL, but isn't quite as forward looking as the Vulkan API design. Like DirectX, it is supported by a single vendor and works on Mac OS X and related platforms like iPhone, iPad, and Apple TV. Mantle = An AMD C API for drawing 3D graphics that was proprietary. AMD decided to donate the spec to Khronos (the folks who make OpenGL and Vulkan) rather than carry the weight of promoting and creating yet another proprietary API that would only work on AMD GPU's. It was used as the basis for Vulkan, and heavily influenced the newest version of Direct 3D. CUDA = An nVidia API similar to OpenCL for running C++ on an nVidia GPU. There's a bunch of other stuff generally in this space, but that should be a solid cheat sheet for you.
Adding macros that change *layout* of containers result in bug-hell for customers, when they try to link source files with the macro set to different values. We already have one such thing with `_ITERATOR_DEBUG_LEVEL`, the cost of adding another pitfall for customers here is too high.
&gt; You can now run some GLSL code called shaders written in GLSL which control the lighting on the triangles A better description of shaders is that they're mini-programs which the GPU can run for every pixel in a triangle, and they have a strange name because their original and most trivial use was for such lighting. (And yes, this description is not completely accurate.) 
Remember seeing this live, was quite a show :) Find the common theme across the slides xD
About macro - could you explain? Macro should be set in project/solution/make wide manner, and we already have a plenty set of such macro - so one more is not a big deal. I think, that a choice in such situation is a much better than nop (and, o-coz, a clang-like implementation is better then macro :) ) PS if you care about ODR - just mixin tags to impl, so macro will change the tag and there will be linking error, not runtime.
Yes, I read the article, thank you. In this case, the same logic still applies to `inner`. You wouldn't continue using `outer.inner` after this.
In theory things would be project-wide like that. In practice we have customers who run into problems with this; e.g. when they get static libraries from vendors or similar.
Nonsense, competition and cooperation are both natural instincts that individuals of many species have evolved and take advantage of, as a way to achieve meaningful progress in some way or another, either for themselves or for their communities. If anything, they're often two sides of the same coin ("us vs. them" mentality - the strong bonds communities that form through tribalism are well known). As much as many people think of "this day and age" as some sort of ultra-high-tech utopia that's beyond the laws of nature that formed us, I have no reason to believe that the modern workplace and all its social complexities are anything unprecedented to us as a species. Yes, programmers who check in so-called "three-star" C code are total jackasses with huge egos, but they're not doing it to compete, they're doing it to brag and be obnoxious. They don't have an "us vs. them" mentality, they have an "I'm better than everyone else" mentality.
This announcement is a big deal. I'm sure C++ devs would find Vulkan useful. Also nVidia has a C++ wrapper for it. :)
Also note that MinGW is a dead project, and the code works fine in MinGW-w64 (forked in 2007 and under very active development). This is kind of like saying PCs are stupid because GTA4 doesn't work in MS-DOS. 
Hm, maybe I interpreted the commit comment a bit wrong then: &gt; This way std::async with no explicit policy or with any policy that contains launch::async will run in a new thread. I read that as "will launch a new thread for each task". Also this sounds like the same: &gt; Apparently libc++ does the same and they aren't getting lots of complaints about fork-bombs, so let's try the same thing. But I hope you're right :-)
Given the speed at which Android phone makers and carriers update devices... Years.
Or simply making sure their hack to fix whatever didn't break every other bit of functionality the product had and was working fine.
It looks like it's a single file with 15k lines. Not sure that's to like. Also it looks a bit like the file is auto-generated from an xml file or something like that? At the least, a single big file makes it a bit hard to contribute. In my opinion they should've gone much further. They hardly adopted any C++ idioms. Since they have decided to offer a C++ API in parallel to the C API, why not go all the way.
Now that Apple has such a large install base they don't need open standards anymore. They know the majority of mobile developers will need to adapt to Apple's own standards anyway. Fortunately there's work being done on a Vulkan library on top of metal, for those who have to support Apple's platforms: https://moltengl.com/metalvk/
Couldn't they have hidden it in the binary already? Well, in a hex editor or disassembler it would probably still show up as plain text? Or is there another drawback to it? Humongous executable file size?
If you want to, you can set a breakpoint in VS without scrolling to the line or opening the file, though I'll openly admit that *how* you do so isn't always obvious or intuitive. There are a couple of ways to do it though. When you're doing debugging, there's a breakpoint window, where you can click "new breakpoint", and type in the location, and modify everything about a breakpoint (condition under which it should trigger, what to do when it's hit, etc.) An even less obvious way is to click to set a breakpoint on an arbitrary line. Then right-click on the red circle, and select "location..." from the pop-up menu, and select the new location for that breakpoint.
Hey Andrew! Sorry to bother you. [Right here](https://youtu.be/_rBhX-FJCdg?t=4779), you said there was a paper for extending the `ConceptName{IntroducedName}` syntax. I presume you mean [N3878](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3878.pdf). I have to apologize because I completely missed this paper when having a [similar idea](https://www.reddit.com/r/cpp/comments/3vden2/naming_deduced_types_proposal_idea_discussion/) somewhat recently. Would you consider reading my rough take on the idea? Rather than focus purely on Concepts, I had the idea when considering what language changes would make my life easier and how `std::forward&lt;decltype(x)&gt;(x)` is pretty ugly, and how `decltype(x)` is not necessarily equivalent to some type parameter `T` when references are considered. One thing that might be of interest, particularly if Concepts inclusion is delayed to C++20, is that someone graciously [pointed out](https://www.reddit.com/r/cpp/comments/3vden2/naming_deduced_types_proposal_idea_discussion/cxs8thi) that my proposal would work well to counter concept names representing the same type when used in a parameter list: auto copy(InputIterator first, Sentinel&lt;InputIterator&gt; last, OutputIterator result) requires IndirectlyCopyable&lt;InputIterator, OutputIterator&gt; As pointed out to me, my proposal would allow this: auto copy(InputIterator {I} first, Sentinel&lt;I&gt; last, OutputIterator {O} result) requires IndirectlyCopyable&lt;I, O&gt; That is, `I` is the type deduced for `InputIterator`. We then pass the *type* to `Sentinel` as an argument. Finally, `O` is the type deduced for `OutputIterator`. Both of these *types* are passed to `IndirectlyCopyable`. I like that we can keep the distinction of a concept being a set of possible types (with `auto` acting *mostly* like a `True` concept) and give a name to the actual type attached to that instance of the concept. I also personally feel that deducing one type per concept instance in parameter lists is more intuitive, but that is beside the point, as many feel the opposite way. Ideally, the most useful option will proceed, including an elegant way of accomplishing the other option. Unfortunately, being a student, I have not yet found much time with which to pursue this proposal. Flying out to standards committee meetings would also be a challenge. You two are absolutely free to adjust your paper using any of my ideas that you like. If you'd ever like to discuss this outside of Reddit, I can PM you my email address. Thanks for taking out some time to read this comment. --- On a side note, thank you very much for the Concepts implementation! I've been building GCC 6 and using it for one of my own projects. It's been great to see bugs get fixed and error messages improve. IIRC, I ran into a bug (before `std::disjunction`, although there are pros and cons to this approach) where the following wouldn't compile and it was fixed, so thank you for that! template&lt;bool... Bs&gt; struct any : std::bool_constant&lt;(Bs or ...)&gt; {}; Great talk as well. I've enjoyed watching these talks on Concepts. Your CppCon 2014 two-parter was also a great watch!
They can't immediately switch completely over anyway, since the current drivers just don't support enough hardware. They would just support it on platforms and hardware that can deal with it.
There is an equivalent in the LLVM toolchain(gcov --version on my Mac gives 'Apple LLVM 7.0.2'). Building with '-coverage -O0' and running the executable should give output you can feed into gcov.
Considering I will never buy an Android device we better see how other cell phone platforms adopt it. 
Qt is highly flexible in having different support for plattforms, so Vulkan is just another rendering Technology they add support for. Since the port to iOS already exists for a while, and will surely receive continued support. Yet Qt gains with adding Vulkan support a lot of future options, and maybe at someday apple will also start supporting Vulkan.
I'm using [coveralls](https://coveralls.io/) + [travis CI](https://travis-ci.org/) and am liking it. It gives you nice coverage report for each build and pull request and coverage history for the whole project and each source file. To use it: * Project is built in travis as usual then tests are run, just ```--coverage``` is added to compiler and linker flags. For CMake, I setup a special build type: SET(CMAKE_CXX_FLAGS_COVERAGE "${CMAKE_CXX_FLAGS_DEBUG} --coverage") SET(CMAKE_EXE_LINKER_FLAGS_COVERAGE "${CMAKE_EXE_LINKER_FLAGS_DEBUG} --coverage") SET(CMAKE_SHARED_LINKER_FLAGS_COVERAGE "${CMAKE_SHARED_LINKER_FLAGS_DEBUG} --coverage") and build with -DCMAKE_BUILD_TYPE=Coverage * A couple of lines are added to .travis.yml to upload coverage info to coveralls: * Before build: ```pip install --user pyyaml cpp-coveralls``` * After successful build: ```coveralls``` or ```coveralls -i &lt;dir&gt;``` if you need to limit coverage with specific directory * Sign in to coveralls and add your repo. With next build you'll get coverage info. Example project: https://coveralls.io/github/libSDL2pp/libSDL2pp
It's API and implementation change to be able to support Vulkan as the OpenL supported now. Because in Qt you can retrieve an OpenGL context that Qt uses. And you can also pass an existing OpenGL context to Qt to use. To be able to do the same with Vulkan, the Qt has to learn to render its scenegraph with Vulkan and also must have something like QOpenGLContext.
Thanks! But you probably have to thank Jason Merrill for the compiler fix :) There won't be any action on this feature in Jacksonville. We get to debate whether concepts will be added to C++17 or if it will get a second TS (actually, both could happen). I think this feature (or something like it) should happen eventually. I'm finding the inability to introduce names for placeholders to be increasingly frustrating. Shoot me an email (I'm easy to find on the Internet). I'll make sure you're attached to the paper whenever it comes back up.
Good points. AFAIK, TLS is handled on a very low level at least on Linux (ELF level) -- there's a Drepper article on the topic that's easy to Google for. While it shouldn't be impossible to simulate such TLS behavior for thread migration, it's at the very least very inefficient. 
I was hoping for a good comparison of, for example, Haskell's implementation of type classes compared with C++ generics. Boy was I disappointed. 
Thanks! This will come handy.
Thanks!
Could anybody share an example of the output, i.e. example index.html?
[Here](http://ltp.sourceforge.net/coverage/lcov/output/index.html) you go.
Thanks a lot! Is there an issue tracker to report 404 errors? For instance, http://eel.is/c++draft/copyconstructible and http://eel.is/c++draft/moveconstructible do not work.
thx, I'll edit the answer
I've never tried gperftools on OS X -- when on a Mac I usually just end up running Instruments.
not necessarily
Well, outside of non-hosted embedded systems that are left up to their own implementation defined behavior, yes necessarily.
You'll want to read section 3.6.1 of the standard.
It's in people nature to be afraid of something they don't understand. And preventive attack against something scary is proven to work survival technique. So it could be people are subconsciously trying to "scare away" C++.
The biggest laugh I had regarding someone complaining about C++ was a Perl programmer complaining the STL was too hard to use! Ahahahaha! This is the same guy who wrote search loops in Perl that didn't break on match, but carried on looping anyway even though he only expected one match. So, yeah, people like that in my experience...
The language is pretty complex, and when you throw templates and macros around too, signatures and other things people are used to seeing start to look pretty foreign. Once you get more familiar with it, it starts to even out, but I'm sure it's not until you've spent close to a decade of daily use will you hit a point where you're not seeing new stuff every so often.
Yes, the argument is usually: * If you are going to go low-level, choose C (or Rust, or &lt;favorite new low-level language&gt;) where it is obvious what the compiler is doing. * If you need high-level abstractions, use .NET or the JVM. The thing people don't understand is that C++ offers good high-level abstractions with a fairly predictable code generation. The real challenge which brings on these comments in my opinion (and so is wrongly attributed) is that C++ has a complex grammar and a small standard library.
I wonder if it isn't kneejerk reactions to how it was taught in school. Kind of like you see about English class.
I think that the main problem of C++ is that it built on top of C. C is a wonderful language. It's just close enough to the architecture to be able to code low level, just high enough not to make you angry. It's simple, straightforward, and generally does what you tell him to do. Like any other language, the main problem is interaction of features. C has a very limited amount of features, hence it's easy for a brain to handle this workload. With C++, a whole lot of features has been added on top of C. C++ had to pay the price of feature interaction both among themselves and with the legacy. Closeness to the platform has made the language willing to jump to more abstract concepts, while limited to the fundamental nature of its runtime. The result is a clusterfuck that humans brains have a hard time disentangling. There are simply too many pitfalls and astonishing interactions. Programming is about control. If your compiler and/or language deceives you, there are problems. When you then add compiler incompatibilities to the mixture, it's pure hell. I have limited experience in C++, but my experience tells me that it just grew to a level of complexity most programmers are not comfortable with, and when they do, they are either lying, victim of Dunning-Kruger effect, or to a technical level that renders them unable to work in a team. 
&gt; How often do you do heavy TMP in your job for that matter? I have to dig under the hood into some expression templates, every now and then! 
C++ is hard to use. People don't like things that are hard to use. It's not complex.
That's why you avoid copy constructors by making them private, delete them (C++11), or derive from boost::noncopyable. It is fairly easy to remove and/or not use the scary parts of C++. 
It's really large, complex, has a ton of weirdly interacting features, it's continuously updating, and it's really easy to blow your leg off. On multi-person teams, you can only survive by being extremely strict with codebase standards, otherwise the entire thing quickly devolves into an incomprehensible mess. New C++ features are great! However, for the sake of backwards compatibility, we also have a valid language using all the previous "outdated" features... For projects that demand explicit memory management in the future, I'll use Rust and C. EDIT: Is the harsh downvoting due to my comments on C++, or saying that I would use Rust and C? I stand by my C++ comments; I work with it professionally, in everything from video streaming to machine learning. C we can't get away from just yet, simply due to it being used EVERYWHERE.
There are two types of programming languages, those nobody use, and those people complain about. 
C++ is great, but its a cruel mistress with a very hard learning curve and no training wheels
C++ has always been an easy target. Its not a better C, but that what many people try to see in it. Also it has been often teached as this. With the missing standardization between 2003-2011, the language was seen as legacy. C++ does not have a marketing department*, there is no sales person trying to sell it as part of some corporate package. But a little FUD about C++ and "unsafe" and lowlevel languages is always good, if you market your new, corporate software package. *this has changed with isocpp.org and Meeting C++ existing, plus the ongoing standardization, the IT Mainstream seems to slowly see, that C++ is evolving into something of its own, a quite powerful language.
He and Terence Hill were my surrogate dads.
The lack of jobs in my country makes me even sadder.
Link for the lazy: https://webchat.freenode.net/?channels=##C++
Xcode's refactoring functionality only supports Objective-C and C, and not C++ or Swift.
There are languages people criticize and there are languages no one uses.
I think most of it comes from Java fanboys. Some 15 years ago, they were taunting how their language had less features than C++ and only kept the best stuff, they claimed, had almost no syntax sugar -- why need templates when you can copy paste, keep the compiler simple, who cares if you write more -- was more secure and they didn't have to be bit twiddling as the plebes do. Boo C and C++. C guys used to dislike it because let's face it C++ is damn complex, and at the time it could add a lot of hidden costs when there were no move semantics and so on. Also there are guys that reason that if Linus hate it, perhaps they should hate it too. 
The best way is to write code that is simple and works . 
&gt; they are either lying, victim of Dunning-Kruger effect, or to a technical level that renders them unable to work in a team. Project much?
The problem - speaking from a lot of experience seeing these problems - is that it's _even easier_ to forget to remove the scary things when they are supposed to be removed. e.g., automatic copy operations mean that you can very easily accidentally break the rule-of-three/rule-of-five, and there's just too many cases where the rule-of-zero doesn't work. Modern C++ didn't help as much as we'd like, either. Sure, new uses of RAII get us closer to being able to use the rule-of-zero everywhere, but the newer standard comes with all new pitfalls. Take the vast number of new bugs we encounter were someone moves out of a function parameter and then mistakenly uses the parameter later, without any compiler error nor even a warning on any modern compiler. It's not that C++ has magic, it's that it has the _wrong_ magic defaults. Operations that should be always explicit are defaulted as implicit. Features that should be opt-in are instead opt-out. You can't just avoid bad features, you have to actively suppress them. Overall these aren't showstopper problems. I'd take a real-world C++ code base over a toy Rust one any day of the week. As time marches on, though, the cruft just keeps building up, and unless someone figures out a way to add proper versioning to C++ - modules and the eventual "death" of preprocessor includes are likely a prerequisite here - the cost of said cruft is eventually going to be outweighed by the cost of switching languages. With the power of Clang and alternatives languages now being able to automatically generate high-quality bindings to even complex C++ interfaces, that cost of switching languages is starting to drop pretty quickly. :)
But I keep cruising **Can't stop, won't stop move()ing** It's like I got this music In my mind Saying, "It's gonna compile." 'Cause the players gonna play, play, play, play, play **And the haters gonna hate, hate, hate, hate, hate** Baby, I'm just gonna shake, shake, shake, shake, shake I shake it off, I shake it off 
&gt; The thing that scares me is that sometimes there is no way to know if pass by value will perform better than pass by reference. Why does this bother you? Use pass by reference and then, maybe maybe later, if pass by value is better then use that. My prediction - you will never notice the change in benchmarks...
Your example said std:: three times for C++, but no namespaces for D (assuming it has namespaces; I don't know D). This visually bloats the C++ example, making the comparison unfair.
I'm going to throw the probably soon-to-be Concepts out there: std::string test(Floating_point t) { // ... } I'm not saying it's a fair comparison, as this isn't standard C++ yet, though it works in GCC 6. It's just out there to show that there is a better alternative coming. And I'm not saying it will make everything match D in elegance, but it's good for many common use cases. If you need the `T` in this example, I hope* the following will be possible: std::string test(Floating_point{T} t) { // ... } \* I actually plan to work on proposing this or something like it, not just sit around and hope it goes in.
C++ is awesome, but I totally understand people who don't want to work with it. It is full of pitfalls and doesn't have the forgiveness of many other languages.
I don't like using c++ libs that do operator overloading. There is reasonable operator overloading and down right abusive overloading. Most cases it's just me being a salty programmer from dealing with too much Ruby crap during the day. Templating is also a bit of a cluster fuck compared to Java but it definitely beats defining macros everywhere.
And what code gets executed with the following? assign(A, B); If I don't maintain the library or look up the information somehow, I don't really know. It's hidden. *Any bit of code could be executed!* It's for these reasons I don't buy the 'any bit of code could be executed' argument. Any language and any function can violate The Principle of Least Surprise. Just choose a bad function name, or a poor operator, or do something unnecessary or hidden. There's really no difference between C++ and other languages in this regard except that those that allow users to overload operators (including C# and for string objects in Java), one must just remember that operators can call functions.
Why is there so much navel-gazing about other people's views on C++? Why do we spend so much time discussing this pointless, meaningless topic? Why do we care what stupid, uninformed people say about C++ and why do we have to have this conversation four times a week in this subreddit? Is it karma whoring? Is it back slapping? What is it?
In C, you have a reasonable idea of what the underlying machine code would be for A = B. This is not true of C++. Having to remember that operators can call functions is part of the problem. Again, this was more important for the Linux kernel as code _fragments_ needed to be analyzed out of context before being merged in. 
I had a 10,000+ line error message once, I think from forgetting a `&gt;` somewhere. I laughed so hard. 
I have done quite a bit of consulting where I am exposed to a Java codebase. The sheer volume of objects and the great branching tree that they are a part of makes the C++ part of my brain run and hide. Quite simply I couldn't envision such an architecture working in C++. It is not to say that such a design is inherently bad, but that with C++ keeping it simple is not merely a good thing, it is a job requirement. With C++, hoards of objects would result in runaway entropy that would bring any project to its knees. 
It's also not exactly so much that C++ is complicated as it is that the typical user of C++ tends to want something that C++ offers for some reason which is rather complicated. If you care about performance, for example, C++ is typically going to do much better than Python. This isn't to say that other languages don't have complicated areas, it's more that the typical uses don't particularly need the programmer to touch that. There's a rather interesting 3 hour talk on metaprogramming in Python [here](https://www.youtube.com/watch?v=sPiWg5jSoZI) which ends up walking you through the Python type system and then ultimately showing you how to "hack" the `import` statement so that you can import an XML file as Python code. Yes, an actual legitimate standard XML file being parsed into Python code and properly imported so as to end up with a set of Python classes.
In C, you only use that for POD types. In C++, POD assignment will work the same way and is easy to know what the underlying machine code will be. If, however, you need to deal with handles in C, you have to write an assign() function (or whatever you want to name it). That's no different that writing an assignment operator in C++. If you need to write some custom operator in C++, you'd likely have to write some custom function in C anyway (which I won't be able to know what the underlying machine code is from the call site). So, I still don't buy the argument. Yes, it takes a shaping of the mind to recognize that assignment in C++ can mean a function is called. But that barrier usually only exists when coming from C or Java. C#, Smalltalk, Swift, D, Object Pascal, Perl, Python, Rust, and Ruby all allow operator overloading.
I am speaking as a person who back in 2010 switched my career away from C++ on purpose. Before despairing, I used C++ to write stuff like device drivers, profilers and other highly specialized and performance sensitive systems. On the top of my head: tl;dr: Go see this [presentation](https://www.youtube.com/watch?v=48kP_Ssg2eY) - it is very instructional to see how a C++ crowd *does not know how a language keyword works* Back to my rant. - C++ is one of the only languages, where programs are portable among computer architectures but not among *compilers*. The C++ standard has optional parts, which the compiler may elect to omit implementing, yet still be conforming. Therefore, you can write a C++ program, which a C++ compiler cannot compile, but they *are* a C++ program and a C++ compiler, indeed. This is before compilers genuinely not implementing parts of the language or the standard library (Visual C++ being the worst offender). - C++ is actually 3 languages bolted together in unholy union - the C preprocessor, C++ proper and the template metaprogramming "language". The funny part - the three are proven to be Turing complete. - (cont'd) Because C++ are actually three languages, you *need* to know all of them. Also, there are no 3 people in the same room who can agree to code in the same style, therefore switching among different teams / companies is very hard. Any non-trivial program is a mixture of different C++ styles - C++ is so complex that all people I know actually understand, feel comfortable and use only selected subset of the language. Get together ten C++ programmers and there is a good chance that they cannot understand each other's code at all. - The tools often do not work. If they work, they are hideous and insidious to use. I mean debuggers, profilers, memory bounds checkers, etc. Also, they are not unified, and each compiler chain / OS combo having their own tools with different semantics and UI. - The lack of binary compatibility. For example, two weeks ago as a weekend project I tried following a tutorial to create a roguelike game. The tutorial author has created a binary lib with utility functions. Guess what? It targeted an older version of my compiler, and it turned out that my current version cannot link it. I ended up writing a simple implementation of the interface from the headers, which was boring and enormous waste of time. - Language semantics and syntax are atrocious. Examples are abundant. In my career I got proficient with Lua, Pascal, C#, Assembler for x86, and JavaScript. I also used Java, Objective-C, Tcl, Ruby, and Python. These languages are more consistent, simple and therefore - productive. Well except JavaScript, it can be even more evil than C++ when in the mood. By the way, Assembler is simpler too - it needs a bit more discipline but at its heart is not insidiously complex. To be honest, I felt in love with Lua and to this day it is my favorite language. C++ 14 and 17 are somewhat better, but still not there yet. - (not really relevant anymore) C++ lacked semantics for boring stuff like threading and async programming (call it futures, promises, coroutines/generators). Regexps were not available in Visual C++ until (I think) two years ago. - C++ lacks infrastructure for complex but needed stuff like Unicode. Other languages have this as a solved problem and moved on. - The standard library lacks stuff like networking - being it sockets, or high level stuff like http/2. Zlib compression? Please, are you crazy :) - (not sure if still relevant) Because the standard C++ library is lacking, all larger libraries reinvent the wheel again and again. At one project I was developing, my code had to convert among FOUR "string" types, everyone having slightly different semantics for basic and common operations. This is especially funny combined with the previous problem (Unicode). And these libraries are always incompatible. Try combining, say, QT for the UI and dlib for networking. Now throw Cap'n'Proto for data interchange in the mix. Other languages have extensive basic libraries which are guaranteed to work across different OS, processor architectures and are mostly compatible across language versions. Also, because the base library works and is consistent, user libraries stepping on it have sane interfaces. Have anyone of you casted among two string types in C# to make the UI and networking libraries work together? - All these combines well to create the ultimate hell. Every library I have ever used starts with a header file in which basic types are typedef'ed (if I am lucky) or #define'd (if I am unlucky). Ever tried compiling two libraries which #define two semantically different things to the same string identifier? Then you know the pain. - I actually lied. After you beat the ultimate hell above, there's a hidden level. Let's say that you want to mark a function inline. inline is a fucking *keyword* in the language, so it should be a blast. Well, compiler A insists on &gt; void _ _forceinline f() {} Compiler B insists on &gt; inline f() _ _attribute_ _((always_inline)) {} Compiler C knows the best (I have forgotten the exact syntax but it used pragma): &gt; \#pragma force_inline &gt; &gt; void f() {} Now, - every library has "common.h" which has two screen pages, ten levels nested preprocessor kludge which define's INLINE_PROTOTYPE satisfying every compiler, *except* the one you are using. - every program looks like that: &gt; INLINE_PROTOTYPE(void myclass::myfun(int x)); I mean, it is "readable" and it "totally looks like" the C++ you have learned. For some peculiar definition of "readable". - But wait, one more thing. As if you are playing a good horror game (say Doom (a *very* fitting name in the given circumstances), if you are very keen, in the hidden level you are, you can find a hidden door to *another* hidden level. The compiler starts complaining that your function does not return. It helpfully suggest to use a particular, non-standard syntax to tell it that you know what you are doing. Luckily, as a library writer, you write yet another two-pages, ten-levels nested kludge to satisfy it. Let's call it NORETURN_PROTOTYPE. Now, your code reads: &gt; NORETURN_PROTOTYPE(INLINE_PROTOTYPE(void myclass::myfun(int x);) (notice where the semicolon is) And I *lied* to you, again. This does not compile! The way to use it: &gt; INLINE_PROTOTYPE(NORETURN_PROTOTYPE(void myclass::myfun(int x);) By the way, at this moment you have forgotten about my complain couple of points above. Bless thy heart, naive one. Because you add another library in the mix, which helpfully #define's INLINE_PROTOTYPE to be only *just* one-page nine-levels nested kludge and there IS NO POWER ON THE EARTH which can make this compile. Ever. Now, the boring stuff. - Compiling times. Using distributed compiling, with 12 machines participating, my last C++ project required 40 minutes for full rebuild and couple of minutes if I changed a "leaf" cpp or .h file. Kills the productivity very efficiently. Most languages either does not compile, or times required measure in seconds. - Lack of unified toolchain. Google use ninja and gyp, others use make, yet others gnu make. Or Scons. Ever being in a project where you need to use four different build systems to build it? I mean, what the hell! Good grace that Cmake becomes a winner, except that Google owns some very important libraries and they love reinventing the wheel. - Lack of unified distribution method for libraries. NuGet? CPAN? LuaRocks? Ruby Gems? npm? Every other language has it, and it works and programmers do not even think about it. - A REPL in the IDE? Do most C++ programmers even know what I am talking about? - Templates require the program code to be in the header files. You cannot structure your program like "interfaces goes into idempotent headers, implementation is in the cpp files". No, the implementation is part of the interface! Whoever reads the code cannot consult "just the interface". - classes needs to put their private members into the headers. Again, implementation is part of the interface! PIMPL is an idiom to alleviate this but the fact that it exists shows a language weakness. And so much more ... To sum it up, C++ program is hard to write, extremely hard (borderline impossible) to read and extend and the programmer needs to fight boring infrastructure tasks to make all this work. Until a new compiler must be supported, then all hell breaks loose. As to the OP, "it is too complex" is *valid* criticism.
This is one of my favorite quirks of C. *(a + i) == a[i] == *(i + a) == i[a] I don't know if it's more helpful or harmful to inform people about pointer arithmetic early on, but it could definitely be a source of jokers putting goofy array access expressions into their code.
But it is **trivial** to avoid, yet useful (and safe) when needed.
&gt; Why would you work with such a complex language? It provides the tooling to write memory safe code that C never will and is available in all OS SDKs. Looking forward to the day Ada, Swift, Rust, D, Go, System C# or something else get into that privileged position of being in the majority of OS SDKs.
Actually a great deal of those complains are also valid in C, the culture that Bjarne and other C++ designers add to appeal to.
The compiler knows better than you if inlining code is worth it. Stop trying to use extensions to enable forced inlining of code? That complaint of yours is moot because forceinline it's not part of the standard in any form.
This. The franken-codebase I'm working on has parts that are 20 years old, yet I compile it fine with a C++14 compiler. Sure there were some breaking when going from C++03 to C++11, and again from C++11 to C++14, but they were easy to fix and exclusively because some people wrote non-standard code that the old compiler sadly accepted.
The reason we encourage prefixing with the namespace in C++ is because we know there will be collisions otherwise. C++ is an old language compared to C# and C and we have learnt our lesson when it comes to things like "using namespace std;" in the global scope, you know the way most books and classes teach C++.
Of course I use templates. I build my own for my needs, but they typically don't extend in the reaches of "compile time computation"
So what, every language deals with that stuff. Write anything moderately complex in Java and C# and you need to implement copy constructors and assignment operators as well. 
&gt; If = is overloaded, any bit of code could be executed. The wonders of using a modern IDE. Right click on the '=' and you can jump to the code that implements the "operator=" Also, if you didn't write the 'operator=' yourself then do you really need to care? If you're using a library you should assume the guy who made it knew what he was doing. if A and B are POD objects you made yourself, again you don't have to care, the compiler will do the right thing. Only when A and B are complex objects that you implemented yourself, then you have to care and then you should probably implement the rule of 5.
 #define A (*GetSetFormatC()) #define B (FormatD())
Well said. All of your points are valid and I personally experienced them in one job or another. To be fair, some of these are problems caused by inadequate c++ developers, and legacy systems. New c++ project architected by someone worth his salt will not have some of the problems you mentioned. The core problem with c++ is that c++ is expert friendly only. It is just so darn hard for non-experts to be productive in c++.
I could definitely see that. Even implementing a linear class hierarchy (e.g. jeep inherits car inherits vehicle inherits transport) can be a headache when trying to remove memory leaks caused by C++ classes automatically inheriting destructors.
https://youtu.be/OaqxIXs_mn4
Curious how you get into c++ standards work. Are you in academia (grad student, professor)?
I have exactly that on corpnet - my "stlbuild" script runs self-extracting archives for the toolset, WinSDK, and UCRT. I don't know whether that would be possible to do for external use (at a minimum I would need signed binaries, which my ordinary dev builds don't generate).
Yep, sometimes there's no point in reading the message, just look for the line number and then stare at the offending line until it becomes clear what made the compiler angry :-)
There is too much hostility towards C++ because it has one of the steepest learning curves between programming languages. Even the simplest of exercises, for example, input a name and print 'hello name' requires the programmer to know about pointers, memory management and operator overloading. For example, in Basic this program could be (excuse me my rusty Basic skills, it's been over 15 years): dim name as string input name print "hello " + name In C++, it is: #include &lt;iostream&gt; using namespace std; int main(int argc, char *argv[]) { std::string name; cin &gt;&gt; name; cout &lt;&lt; "hello " &lt;&lt; name; return 0; } If I was a Basic programmer in my first C++ steps, I might have written the above program like this: int main(int argc, char *argv[]) { const char *name; gets(name); printf("hello " + name); } Which would be invalid. Then I'd have to understand memory management (how strings are stored and why do I need to use std::string), what namespaces are, why I have to use the operators &gt;&gt; and &lt;&lt; for input and output, why "hello" + name doesn't work, etc etc. 
Boost::spirit awh gosh
&gt; In C, you have a reasonable idea of what the underlying machine code would be for A = B. This is not true of C++. How come? `A = B` generates an assembly call instruction for a function called `operator=`. The only way to not know that is to not be a C++ programmer. Still, even if you are not a C++ programmerm, that wasn't that hard was it? I surely wouldn't want anybody that cannot understand that writing any C code at all. For some reason this only seems to be a problem for those C programmers that think that C/C++ is a thing. 
Under which license is the compiler toolset published? Can one build software in an enterprise without having to license / without Visual Studio? 
Yeah. The compiler support was a mess for quite a long time. Now at least the major platforms have great ones. There was a discussion of why many people disliked the STL and for me it was also partially because of bad compilers back in the day https://www.reddit.com/r/cpp_questions/comments/3lh24q/stl_debate/cv6u9on
Are you kidding? C++ really isn't that hard of a language. I mean, I'm no TMP expert, but fairly normal C++ isn't harder for me to read than JavaScript, in fact I find it easier. 
Slightly related, I'm not sure why C++ people don't like it when I overload the `+=` operator on a vector class. If you know it's a vector/container, it can really only mean one thing, and it's clearer than `emplace_back`.
How would that be written with tag dispatch?
I'm an undergrad student. I've been following all of the standard committee stuff for a while, but I haven't yet participated.
Google guys has something similar: https://chromium.googlesource.com/chromium/tools/depot_tools/+/refs/heads/master/win_toolchain/package_from_installed.py which can create a standalone toolchain. Its pretty hacky but it works. It would be really nice to have something "official" from Microsoft like that.
IMHO one of the problems with this is that a lot of introductionary material and even university classes start teaching C++ in a way that is closer to your 2nd example, i.e. they start with PODs, raw pointers and lots of stuff that leads to problematic 'C-with-classes' coding style long before they touch all the 'real' C++ features like STL, smart pointers and so on. If it were the other way round and people learned the more abstract things first and looked at the gory underlying details afterwards to get a better understanding how the higher level stuff works internally it'd probably be easier on them.
I used to think that, until I started looking into Rust. 
I agree with most of your points - c++ can be nightmarish. But things are improving. C++11//14/17 each take great strides to become a better language. And its not just language itself - compilers are becoming more standard compliant these days. I find latest GCC, clang and VC++ pretty good. Compared to problems that existed just say 5 years ago ... And future looks brigher! - Modules support. Latest VC++ includes experimental support! (and I think clang as well?) - no more header file nonsense. Just implement and export :P hope they make it into c++17 - Reflection (compile &amp; run time) - this will be huge I think. Especially if they manage to add compile time introspectable attributes. Will be sweet! - new libraries - filesystem and networking - long way to go, but man this will make easier writing crossplatform code. These are few samples and there is more in the works. More importantly all big companies these days seem committed to c++ and the standards. So there is light at the end of the tunnel :)
Lot of the problems stems from the way c++ is taught and presented these days. Very recently I happened onto a lecture at the uni and structure was all C++98 style. Sprinkled with plain C, preprocessor macros, pointers everywhere. It was boring and outdated and caused more lots of confusing silly questions.
templates are okay but people treat them as if they were hammers and everything else is a nail. 
templates have very little to do with algebra I 
It's moving at the pace people are going from python 2.7 to 3.x. There are two problems, one is things like threads were only added 5 years ago - every big library still has its own threading interface (some of which are smart enough to use the standard behind the scene now) and for that to change we need to wait for everyone to move to C++11 or higher then wait for all of the libraries to catch up to that fact. And that's just for threading which has been out for 5 years, networking **needs** to be part of your standard library, filesystem **needs** to be part of your standard library, easy modules **need** to be an established standard. Until all of this happens (and all of it is actually adopted) the same problems are going to exist. The light at the end of the tunnel looks to be 2025 for what we wanted in 2010 and needed in 2015. I've stopped waiting for the light and just accepted when I use c++ it's always going to feel a decade behind in usability.
Yes, that is the idea. [See here for Herb Sutter talking about it at a conference](https://youtu.be/yKYcybUEX3I?t=4723). At that time, C#'s language specification was slightly smaller while Java's was slightly larger. (So maybe I was wrong today about C#'s specification; stuff has been added to C#, but I don't know what the exact length is.) Java's language specification today is [close to 800 pages](https://docs.oracle.com/javase/specs/jls/se8/jls8.pdf)[warning: PDF].
Thanks!
In mathematics, adding two vectors implies adding corresponding elements: For example adding the vector &lt;1,2,3&gt; to the vector &lt;8,7,2&gt; yields the vector &lt;9,9,5&gt;.
* very complex grammar * slow compile times * tons of 'action at a distance' (what does '+' really do?) * lack of standardized ABI Don't get me wrong, C++ is a great language -- I used to use it and still miss it. However there's just too much cruft that's built up over the years. It still has a place in game development because of its speed and richness but most other disciplines have moved away.
I'm talking about `std::vector`, which is basically a dynamic array, not a mathematical [vector](https://en.wikipedia.org/wiki/Vector_space). So in math this would be more akin to set [union](https://en.wikipedia.org/wiki/Union_(set_theory\)) where `{1,3,5} ∪ {2,4,6} = {1,2,3,4,5,6}`. The way I see it the only confusion it could bring is where the elements are added. I see `operator+=` in a container to mean "I leave it up to the implementation to add it where it wants."
For mathematical vectors, yes, and those are often overloaded. I'm talking about element containers though.
If you've used a language that supports vector math, like matlab or R, then it seems perfectly natural to have a whole bunch of math operations that operate element wise on the vectors.
&gt; where it is obvious what the compiler is doing. Even for C, it hasn't been obvious for some thirty years now, thanks to optimizing compilers.
Basically people fear it's raw power.
I learned CPP first, and every time I suggest learning it first I get reamed on here. I figure if you can learn C++, you can learn anything rather quickly, and I did; java was easy, and after that C# came practically for free.
Yea, but not as an operator overload to the container. I guess it depends heavily on context.
Yes indeed, as operators on the containers. http://www.tutorialspoint.com/matlab/matlab_operators.htm http://www.r-tutor.com/r-introduction/vector/vector-arithmetics
wouldnt using operator|= make more sense then?
Hah, true I suppose. I've just never used that for anything other than bit setting so it'd look weird to me.
What I meant by that was: - The going native wave, after Longhorn's failure, which also lead to .NET Native and bringing back COM+ 2.0 rebranded as WinRT with .NET metadata instead of type libraries. - The initial series of going native talks that eventually merged with CppCon - Pushing for safer use of C++, like the latest GSL, contracts and static analysis tools. (I know they are doing this together with others) - Allowing for C++ on the kernel space since Windows 8 - Pushing C aside as a legacy unsafe language better left for other compilers instead of MSVC++ and their clang integration
If a language isn't part of the OS SDK, it means someone has to write the respective wrappers and debugging tools on top of what the OS vendors provide. I never go with second class languages for production code, as what they might add in productivity gets removed in problem solving due to wrappers, FFI, 2nd class tooling and so on.
I think the most animosity towards the language comes from bad C++-teacher teaching C++ the wrong way, so that everything seems far too complex to be handled by a single human mind and if you want to start to code C++ you need atleast a degree in theoretical-mathematics. (I like the [talk of Kate Gregory](https://www.google.de/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjWs_LA1oHLAhVHtQ8KHfnlBJMQtwIIHDAA&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYnWhqhNdYyk&amp;usg=AFQjCNHL_BulZPi3el2xvc5kSkMDmrA7cw&amp;sig2=xCn3lkEtt5pGKwtqnFs8nA&amp;bvm=bv.114733917,d.ZWU) at last cppcon regarding teaching C++) 
You may be thinking about Lisp. C++ is a language with many viable subsets. Choosing one subset among many is not the same as customization. Lisp is much more customizable than other languages, even C++, as macros are more powerful than templates.
It's *not* complex? You must mean something different by the word "complex" than I would, because from my perspective C++ is by far the most complex language in common use. After 20+ years I still don't feel like I have more than a solidly middling grasp on the way it all works - and I have spent most of my career working on programming-language tools, at that! It has such a vast specification, with so many details lurking down so many little design rabbit trails, that I don't know if I *could* manage to learn it all.
Even in that case there is a hell of a lot to learn for even the most basic things.
I'm over two decades in and there are still parts of the core language that escape me. :-) I work with such a complex language because there's nothing I want to do that I can't use it to do, on any hardware I want to do it with. I drifted away for a few years as I got tired of dealing with memory management and the overly-verbose template container syntax, but C++11 has brought me back in a big way.
I'm not going to deny that it takes quite a while to reach a level where you can work in larger projects but look at the basic stuff that is taught in basic programming classes: - raw pointers with new/delete vs smart pointers created through make_unique &amp; co - you need to teach people the basics of manual memory management or you just tell them 'use make_unique and your object will get cleaned up when it goes out of scope / no other pointers are refering to it' - std::vector&lt;T&gt; vs T[] - vector abstracts all the memory management and provides a more or less reasonable interface for basic operations like appending/removing elements while working with raw arrays requires you to understand the details of pointers and how to prevent out-of-bounds access by manually keeping track of the array's size - std::string vs array of char - same as with vector vs arrays + you need to understand about terminating 0 characters the problem with the more C'ish ways of doing things is that it creates a mindset that doing even basic things is very complicated in C++ and therefore the whole language must be hard to master while modern C++ mostly lets you get away without knowing about how all that stuff works under the hood. when i took CS classes things like these were what made C++ look hard for most of the participants who had little or no programming experience before while those who had worked in another higher level language didn't take long to read STL docs and get some sort of useful solutions to the tasks they were given.
I agree with your assessment about the problematic teaching of c++. However, even if c++ education started with stl, sooner than later the programmer would have to deal with many 'strange' (from his perspective) features of the language. 
&gt; I don't talk from experience but my guess it that code must be thoroughly reviewed to avoid accidentally performing allocations and copying buffers. When performance matters, you profile. When you profile, you get the hot spots. If the hot spots happen to be extra copying, you can trim it down. I wish C++ was more explicit, but my performance issues usually were elsewhere.
This might interest you: http://stackoverflow.com/questions/16592511/renaming-nupkg-to-zip 
Interesting! Here is a great question at stack http://stackoverflow.com/questions/27687389/how-does-void-t-work
Yep it is full of such dark corners, but it still is the lesser of two evils in regards to C, until we get OS vendors to jump into something safer.
For new code? Of course not. For existing software that I need to support? Absolutely.
Nice. Is there a simple way to download the nupkg files without having nuget? i.e. a direct http link?
Boost in general takes template compiler errors to a whole new level. 
still does not have two phase lookup. the rejuvenation workstream to add is still in progress. https://blogs.msdn.microsoft.com/vcblog/2015/09/25/rejuvenating-the-microsoft-cc-compiler/ You will see the two phase lookup version feature in this preview stream before the product but we are still working on parser rewrites that are a necessary prereq. NOte that you can use the Clang / C2 work to get two phase lookup in the product today. https://blogs.msdn.microsoft.com/vcblog/2015/12/04/clang-with-microsoft-codegen-in-vs-2015-update-1/
I believe they talked a lot about how to [get involved in the standards](https://www.youtube.com/watch?v=PqU_ot4BlNQ) process at CppCon last year. I don't have a specific time to listen to though, sorry.
It is easy to make mistakes with copies. Especially later on when you or someone else adds new member variables (for example, add a pointer). These may introduce difficult to debug bugs. It can also be difficult to correctly copy an object (what if it contains a unique_ptr?). You usually don't need to copy objects, at least in my experience. Typically only needed for simple data structures. Why would you always implement them for all classes?
By the way, nice username :-)
Regarding [taocpp/json](https://github.com/taocpp/json): It was mostly created as a show-case for the [PEGTL](https://github.com/ColinH/PEGTL), a general-purpose PEG parser library. It provides a similar interface than nlohmann's JSON class, but it has no class-internal parser. Instead, the PEGTL is used to create an instance of the JSON class by only using its public interface. It's not at fast as RapidJSON, but faster than most other general-purpose parser libraries and taocpp/json is thereby most used to make sure that the PEGTL is an actually reusable C++ library and helps to create conformant and fast parsers.
Well this way any language has "magic" in it. If you like then C has less "magic" as C++ and assembler no "magic" at all. Of course not every language has Garbage Collector or Just-in-time compilation or or. But for me all this is much more "magic" as in C++. And i do not say that this is bad to have some "magic" behind the scene. This can make developer live much easier some time. But I do not want to miss destructors and RAII for example. On the other side a lot of peoples what to remove GC from D-Lang, because it appears to be a problem is many cases. But GC seems to work well in Go, or may be I just have not enough info about this. In Go GC will be improved in with every release and in 1.6 it should be much faster as before. So making proper GC is very complicated but it can make developer live much easier some times. In Rust there is no GC but RAII and compiler that has very powerful linter build in. So it is hard to write Rust code at first but this should make writing wrong code harder and correct easier. 
I highly recommend Andrei's D book even if you have no intention of using D. It's well written and is more focused on design rationale than it is on using D (there are better books if that's what you want). I think there is a lot of neat stuff in D that I'd love to see come to C++ (I'm still sad the UFCS is coming in backward though...). As a big fan of your STL videos, I'd love to hear your thoughts on D's approach to Stepanov's STL algorithms someday. I find them so wonderfully composable and didn't really appreciate the design of the STL until I used the equivalents from D. I use the boost range library like crazy in C++ now because of it (though it's not quite as nice, it does the job). Eric Niebler's range stuff will hopefully get us very close. An example I just swiped from a post I left on HN awhile back: Here's a snippet of code I hacked together in D for a bot to scrape titles from pages of urls in irc messages. matchAll(message, re_url) .map!( match =&gt; match.captures[0] ) .map!( url =&gt; getFirst4k(url).ifThrown([]) ) .map!( content =&gt; matchFirst(cast(char[])content, re_title) ) .cache // cache to prevent multiple evaluations of preceding .filter!( capture =&gt; !capture.empty ) .map!( capture =&gt; capture[1].idup.entitiesToUnicode ) .map!( uni_title =&gt; uni_title.replaceAll(re_ws, " ") ) .array .ifThrown([]); It uses D's fast compile-time regex engine to look for URLs, then it downloads the first 4k (or substitutes an empty array if there was an exception), uses regex again to look for a title, filters out any that didn't find a title, converts all the html entities to their unicode equivalents (another function I wrote), replaces excessive whitespace using regex, then returns all the titles it found (or an empty array if there was an exception). Because of what I learned playing around with D I increasingly write C++ code like this: auto dir_rng = boost::make_iterator_range(directory_iterator(project_dir), directory_iterator()); for_each(dir_rng | filtered([](const path&amp; p) { return is_regular_file(p); }) // Files only | transformed([](const path&amp; p) { return p.filename().string(); }) // Filename string | filtered([](const string&amp; s) { return iends_with(s, "YYY.XX"); }) // All accepted files have an YYY.XX suffix file | filtered([](const string&amp; s) { return s.size() == 10; }) // Ensure it's "....YYY.XX" sized | transformed([](const string&amp; s) { return s.substr(0, 4); }), // 4 letter project name [&amp;](const string&amp; project_name) { // ... } (I can't remember why I used for_each instead of range based for loop) Another thing that changed how I approach some problems was H.S. Teoh's article [Component programming with ranges](http://wiki.dlang.org/Component_programming_with_ranges). Eric Niebler seemed to like it a lot too because he used it as the basis for his range talk at CppCon.
I don't really like that mindset, to be honest. Unless you're doing libraries that loads of people use, the chances are the few people that work on your project will get used to it very quickly.
So this also means that you exclusively use (const)References when calling functions?
 A couple of comments: 1: Strictly speaking, it is absolutely legal to move the same object twice, as in a=std::move(x); b=std::move(x); After the first move, `x` is required to be valid (even if empty, for some undefined notion of "empty"), so the second line works OK, although its behavior is probably useless. A definition of move independence that I think captures better the intention is: two operations `f` and `g` are move-independent on `x` if f(std::move(x)); g(std::move(x)); is equivalent to g(std::move(x)); f(std::move(x)); 2: The interference-based formulation of this notion implicitly assumes an additional condition, namely, that the dtor of `x` be trivial or, more broadly, that it reduce to destruction of its data members. 
Oh yes, if you stay simple, it's not difficult to read. It's difficult to say what it _does_ though. 
There is hardly a language out there that can't interact pretty naturally with a C SDK, and there is hardly a platform out there without a C SDK.
The move semantics is like a baked-in auto_ptr, so don't over-think it. Moving from reference is similar to using an auto_ptr&amp;. 
Yes, in most cases that is sufficient and preferred. The exception, again, are simple data structures.
There was a question here recently: https://www.reddit.com/r/cpp/comments/45rv6e/learning_qt_from_ground_up/
&gt; when void_t is significantly simpler `void_t` is still pretty ugly. Its much simpler to use function overloading: template&lt;int N&gt; struct rank : rank&lt;N-1&gt; {}; template&lt;&gt; struct rank&lt;0&gt; {}; template&lt;class T&gt; auto check_for_to_string(T&amp;&amp; x, rank&lt;1&gt;) -&gt; decltype(x.to_string(), std::true_type{}); template&lt;class T&gt; auto check_for_to_string(T&amp;&amp;, rank&lt;0&gt;) -&gt; std::false_type; template&lt;class T&gt; struct has_to_string : decltype(check_for_to_string(std::declval&lt;T&gt;(), rank&lt;1&gt;())) {}; Plus, there is no trickiness to learn like with `void_t`. In addition, this trait will easily work with references. Of course, it can be even simpler using conditional overloading, like with [`fit::conditional`](http://fit.readthedocs.org/en/latest/conditional/index.html): FIT_STATIC_LAMBDA_FUNCTION(check_for_to_string) = fit::conditional( [](auto&amp;&amp; x) -&gt; decltype(x.to_string(), std::true_type{}) { return {} }, fit::always(std::false_type{}) ); template&lt;class T&gt; struct has_to_string : decltype(check_for_to_string(std::declval&lt;T&gt;())) {}; 
This article seems to focus on how to avoid moving out of the same object twice. What about the old principle of leaving the object in a valid-but-unspecified state after a move? Then there is no danger even if you do move twice. 
&gt; x is required to be valid Well, no it isn't, but it is a good idea to leave it in a valid state for obvious reasons. 
Of the more mature libraries, gtkmm is in my opinion the best designed GUI library for modern C++: https://developer.gnome.org/gtkmm-tutorial/stable
Yeah that is kind of my point, Express is more limited so why is it still worked on?
Qt For example this [video playlist](https://www.youtube.com/watch?v=6KtOzh0StTc&amp;list=PL09CA46054E1FD9B2). On the 6th video (they are 5~10 minutes long), you will have your first GUI
Lets assume x is an instance of a scope guard object which enters a critical section on construction and leaves it on destruction. Let f and g be functions which assume the critical section is taken on entry (since x is constructed by definition). The first move would transfer ownership of the entered critical section to f. It is safe to use the resources guarded by the critical section and exits the critical section on the scope exit of f. Entering g, we have an X that isn't owning a critical section and but that destructs cleanly. That almost certainly doesn't match the expectation of X. For this to work, it seems like any function that receives a move would have to assume the object may be in an undefined state (how do we check it? generically?) and handle that possibility correctly. That seems like a huge burden from the perspective of enforcing contracts.
[How's the comma operator work?](http://stackoverflow.com/questions/54142/how-does-the-comma-operator-work) In short, the statement: pieces[(i,j)]; 'effectively' breaks down to pieces[(j)]; since the first number/expression is calculated and then ignored, resulting in the j being used for the expression. Aka yes, things are working correctly, its just fun with the comma operator.
(i,j) will, I think, evaluate to "j" in C++. Look up the comma operator. The comma operator evaluates all expressions, which means it performs the operations in them, but the value of the expression over all is the last one. I can check this with a compiler... but, it's my first instinct from knowing how the comma operator is designed in C. 
That would be the [comma operator](http://en.cppreference.com/w/cpp/language/operator_other#Built-in_comma_operator), which by default evaluates the first expression, performs any side effects, and then discards the result of the expression. Then it evaluates the second expression, the result of which becomes the value of the overall comma operator expression. Yeah, that one tends to surprise a lot of people. Occasionally it is kinda useful, and can result in some really interesting (arguably useful) syntax when overloaded, but you gotta be careful that its use isn't misleading, because it's easy to do.
C++ is probably not a good language to start programming. It's more expert friendly than anything else. What to learn really depends on what you want to do with it. Do you have any idea what kind of project you'll like to do ?
&gt; C++ is probably not a good language to start programming. It's more expert friendly than anything else. &gt; What to learn really depends on what you want to do with it. Do you have any idea what kind of project you'll like to do ? To start with I'd like to make some simple games and apps..I'd really like to build a pong game.
For a game of pong it might be a good idea to get a library like SFML which is a multi platform c++ library that helps with system, window, graphics, audio and network. They have good tutorials and documentation from what I can tell.
Python is what a lot of people will tell you to start with. It's very nice and quite easy to just hop in. Also, interpreted languages have this advantage when learning that you can just run your programs without waiting for compilation to finish. On the other hand C++ is quite fascinating and even though using it is often frustrating, it's also very rewarding experience, especially when everything "just clicks". Makes you feel like a pro :)
It also looks quite ugly with no skinning possibilities, so don't expect to use it in a final product.
Your post has been automatically removed because it appears to be help/homework related. If this has been in error please message the moderators. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'm impressed the fact that my post started the quite hot discussion. To participate into one, I've just created a Reddit account. **** Disclaimer: I'm a new one here, so please don't blame me too hard for message formatting or ignorance of some implicit Reddit rules. I'll learn them, I promise! **** Let me give a one more example. Imagine that you got a const reference to an object and you 100% know that you can modify the object (you get const ref just because of hmm some design limitation you can't fix). So how will you write the code that may modify the object? I'm pretty sure it will be like: void func(const Object&amp; obj_) { Object &amp;obj = const_cast&lt;Object&amp;&gt;(obj_); do_something(obj.get_member()); // [const] Member&amp; Object::get_member() [cont]; ... And not like: void func(const Object&amp; obj_) { do_something(const_cast&lt;Member&amp;&gt;(obj_.get_member())); // Does not play well with `const Member&amp; Object::get_member() const; !!! ... And the reason for this is simple: we know that we can access the object as mutable so we cast a const ref to the object to a non-const ref. We cast the object ref rather then the result of some operation on the object because of the following: * it clearly express our intention (remove constness from object's ref) * it's safer because it can not break the object's invariant (is it better to use term incapsulation here?) There is the same idea under the using of `std::move(obj).mem` instead of `std::move(obj.mem)`. The only difference is that `std::move` is treated by many people as something more than just a simple cast. The argument that some operation might change the object in the way that make it unusable on the next line is not really `std::move` specific. Such a change is possible in any code that can modify the object regardless the object is an rvalue or an lvalue (I agree that it's easier to get with an rvalue, but the problem is possible with an lvalue as well). Fortunately, such errors are easier to prevent because of contiguity of the code working over an object. The more important problem for me is that applying cast to a member rather than to an object can break the object's invariant and such type of error is not so easy to prevent because an object's definition is far from the code using the object and they're often changed independently. 
&gt; value = std::move(obj.resource); // clear -- we want to move If I want to unconditionally move the member then I write it exactly the same. &gt; value = std::move(obj).resource; // not clear -- resource could be moved or copied, might confuse anyone that comes across this code that have never seen it used like this before We allow the member to be moved. It will be moved only if it's safe to do this. I agree that it might be confusing but... for the sake of safety devs should get used to this approach (IMO). I think this **must** be used in very generic code when you have absolutely no idea about the member's type.
Instead of diving head first into cpp for gaming, I'd start with python with the pygame library
To add to this, I like to think of the (non-overloaded) comma operator as a semicolon that you can put inside an expression. It's nearly a pointless feature. It's occasionally useful for loops and initialization, but it's best to avoid it because of its obscurity (in production code).
It depends on `i` and `j`, for the comma operator can be overloaded. If `i` was some sort of funky type, `i, j` could effectively return a pair containing `i` and `j`, which could then be used to index in a 2-dimensional array. I'm not saying it's the case here, or even that it would be a good idea. But the comma operator can be overloaded, so you can't be sure what `i, j` is before checking.
Not really. The direct link changes every time we update the package. You can look at the Packages list on the NuGet server (browsing to http://vcppdogfooding.azurewebsites.net/nuget/Packages will download it) and in it, you'll find a direct link to every package that is published on that server. But that link will break when we update the package. 
Good comments. I'll think about your alternate definition. However, regarding double-moves: while it is not invalid (strictly speaking) to write a = std::move(x); b = std::move(x); it is likely to leave `b` in a not very interesting state, as you say. Sure, your program shouldn't segfault, but it's probably not what you want to do either. What I very much want is to avoid hiding such behaviour inside a generic library, even if it is not UB strictly speaking. 
Not sure if it would be more clear, but if moving multiple times from the same object looks suspicious, can't we just return something from functions, that use moved-from object, and move that instead: auto&amp;&amp; y = f(std::move(x)); g(std::move(y));
Thanks for sharing. BTW I see the 4th version of the modules proposal, it's nice.
&gt; it's too complex But it's true and hardly anyone denies it. Some parts of the language are *unnecessarily* complex. And there are many gotchas. I program in C++ for a living, I can deal with it. There was a time when I considered myself a fan of the language. But since I learned about Rust, that time is gone. :)
I tend to use different editors for different languages. Typically Qt Creator for C++ and Sublime Text (with appropriate plugins) for Go-ish or Javascript-ish bits, sometimes with emacs or something jetbrains added to the mix. I've tried a lot of editors and haven't found an editor that supports all the languages I use in the way I like. Picking the right tool for each part of the job works better for me than trying to use the same editor for everything (even given the additional learning and focus costs of switching apps).
I'm using Visual Studio on Windows and Qt Creator on both Windows and Linux.
Looks like there's currently no debugging on Windows. &gt; MSYS2 does not yet support lldb, but you can still compile juCi++ without debug support. OP didn't say which OS they're on, but I presume Windows, since they used VS before.
TL;DR?
I like [CLion](https://www.jetbrains.com/clion/), however, it only supports CMake projects at the moment.
I really like Visual studio with Visual Assist X. Or the resharper plugin for c++ but that's a little less stable and slower. It's hard to beat visual studio debugger on windows
I really dislike CLion's debugging performance. Especially with a lot of thread, breakpoints take ages to load up. I dont know why, as gdb is there right away..
Indeed easiest "multi-platform" by far from my experience.
Well, this just confirms what I already knew: RapidJSON may have an outdated API, but it's a damn good library.
Good to know! So does that mean I could get Qt working with...say...Atom with QtWebkit and just do all my HTML/CSS in there as well?
Ah yes. I had completely forgotten about that. The example above cannot be decomposed any further. Neither the input or the print function or the sigil operator are things that the Basic user can write on its own, using the language. That makes Basic easy to pick up. The Basic user has nothing else to remember. Unlike c++ that this example is only the surface.
Seconded. Qt5 + CMake 3.2 (or newer) works really well. With this combo it is also easy to use CPack for distribution. Packages like deb, rpm and NSIS for Windows are relatively easy, OSX as well so I have heard. Even without QtCreator, it is quite easy (I use vim + YouCompleteMe). 
Sure. You might need to make use of the "Qt WebKit Bridge" if you want your HTML/CSS/JS application to be able to call into your C++ app to query data etc. Basically you expose your C++ classes to JavaScript, making them callable.
Although it may not be "modern", I kinda like FlTk, which Stroustrup uses in his textbook. It's easy to understand and get moving with. http://www.fltk.org/index.php 
Good work! Glad to see some progress on this one, it's been bugging me for a while that you've had such an advanced standard library but haven't had the core compiler to really back it all up.
Having choice in reusable code doesn't make reusable code bullshit.
&gt;I had a look at Qt but from my understanding it doesn't really work well unless you use Qt creator Hmmm... Chances are, if Qt doesn't work for you without Qt Creator, then no frameworks will work for you without using an IDE who "understands" the framework, whichever it might be.
Because those features can be very important. There is a reason why almost all of the most popular and complex programs in the world are written in c++ (photoshop, internet browsers, media players, cad software, video game engines and so on). Maybe if you are doing a personal project it is easier to use a different language but all of it's extra features are there for a reason
They are either retards who don't understand anything beyond javascript and doing fizzbuzz in meme languages like haskell, or they are linus fanboys who think that using c++ means that you are less intelligent than a c programmer. Or both.
Yes, nana is worth a try, and surely an alternative to Qt and other older frameworks if you build only a small tool.
interesting. Is the pre-processing pass just a binary file I can run with some parameters? if so can't be placed into any build system?
Pretty much, yeah.
yeah I am currently on Windows. Part of the reason I am trying to go multiplatform is because I have a linux machine and will hopefully one day become a full time linux user. Until then, I am stuck with a really crap terminal in CMD.exe :( That said, I find vim EXTREMELY hard to use. Maybe I should just get off my ass and learn vim.
For one class I I was able to raise everyone's grade by two letters when I painstakingly showed the professor that the WxWidget library would only build on one out every 3 student laptops, and only 2 school computers had a working installation.
My point was rather that if you expect your IDE of choice to help you with some framework idiosyncrasies, it has to know that framework. Bar a plug-in, that is less often seen IMO. Qt Creator helps with Qt the best, and Qt being "important", there are Qt plugins for eg VS and Eclipse at least, but I don't know how far they go. For other GUI frameworks, you are less likely to get IDE support, so if you are looking for it, tough. But you can always write it all yourself, you just might need to deal with a lot of detail.
Aren't all child ui elements children of the root widget? I remember it being weird...
&gt; Is the pre-processing pass just a binary file I can run with some parameters? if so can't be placed into any build system? yes, the binaries are moc, uic, and rcc. However the build systems I mentioned are intelligent enough to not have them pass on unmodified files so you would have to recode that logic by hand (or have a bunch of unneeded files recompiled each time).
I hope no one really edits .ui files by hand. QtDesigner and QtCreator are so great for handling them. IMO widgets are still better for doing for example game editor or something similar. QML is better for mobile and touch screen apps.
[Powershell](https://msdn.microsoft.com/powershell) Because a group at Microsoft got too pissed off at the team that owned cmd.exe and wouldn't add new features.
[A good explanation of some of the reasons](http://stackoverflow.com/a/25036704). These are implementation details, so it will not necessarily be that way forever, but at least for now there is a runtime overhead to linking against pthreads, even if you never do anything with threads. **Edit** Not sure why it couldn't link libpthread with --as-needed or an equivalent, though, which seems like it would solve some of the issues.
I haven't listened to this yet but vfx industry is still limited to gcc 4.8.3 due to something called the VFX platform. Look forward to this one.
I'm confused by the parallelism TS. Today, performant GPU code is written in CUDA or OpenCL, which specify where functions execute and memory resides (e.g the CPU or the GPU). They have a lot of inconsistent but analogous syntax (e.g. __global vs __kernel, or threadIdx vs get_local_id). I imagine standardizing this to whatever extent is possible would be of considerable value - but this is not what the Parallelism TS does. From what I gather, the Parallelism TS standardizes a higher-level interface which can be used to create fairly inefficient GPU code. This seems to limit its usefulness. If performances matters, one will still need to use CUDA and OpenCL. If performance doesn't matter, then one should avoid the complexity and use the older STL algorithms. Are people thinking of the current TS as a stepping stone to something with better GPU performance? Or is it a finished solution that is targeting a narrow set of the use cases where GPUs are applicable?
It's amazing that I ran into that exact problem a few days ago, except that I wasn't getting a crash, but got data corruption. I am still wondering what the correct solution is to prevent this bug in the future, and may just use fewer (or never) references from returns.
Several of your points - incompatible compilers, binary incompatibility, lack of standard networking classes - are because of the fact that there actually *are* multiple compilers. Why do Python, Java, C#, Perl, Ruby programs appear more portable? Because essentially everyone uses the same implementation! Why does Java have networking classes? Because it only runs on machines that have networking! That aside, given market demands, people will make compatible compilers. GNU has learned MS extensions and vice versa. People have done Cygwin to have - among others - the POSIX network API on Windows. People eventually did agree on a common ABI. People even agreed upon a unified distribution method for libraries. It's called Debian and it's pretty language-agnostic. Its only drawback is that it was invented last century, so it's probably just not shiny enough for "NuGet", "Ruby Gems", "npm" people who want to reinvent wheels.
&gt; VFX platform http://www.vfxplatform.com/ 
Try [CopperSpice](http://www.copperspice.com/). It's derived from Qt, but is updated to use C++11 and modern C++ principles. It also gets rid of moc file generation.
Good point. I was looking at "The way it detects whether the program multithreaded or not is by checking whether the program is linked to libpthread or not.", but of course as you point out -pthread does more than just link to libpthreads.
Well if you beat in the nail with a rock and it works for you - *thumbs-up*
I linked to this in my post. There's no information on why the standard library stopped supporting it, or whether this is permanent or just until RTM. `/RTCc` is a very useful flag that detects data loss when assigning to a smaller type, I'd be rather sad to see it go.
I wrote this message, which is permanent. /RTCc indeed breaks conformant, safe code. Because the compiler doesn't emit warnings for when RTCc checks may activate (for good reason: such warnings would be insanely noisy, since they would apply even to static_casts), I decided that we couldn't keep spending the time to play whack-a-mole with RTCc truncation in the STL. If you define the escapte hatch, you'll get the previous behavior, but I do **not** guarantee that the STL is RTCc clean - that's the whole point of this message. (Mostly the escape hatch is intended for somebody using only type_traits, ratio, or whatever). If RTCc accepted conformant code, then I wouldn't be doing this.
We have templates that can be instantiated outside the pragma.
I've seen software within major VFX studios running on C++14 and the latest and greatest versions of GCC/Intel...
Definitely type_traits, largely because some of them allow you to do things that would otherwise be impossible! 
Please don't do that. Using web technologies to make desktop software always results in a mediocre user experience and an exploit surface larger than the sun.
Oh I love YCM...
I'm a bit confused by one of the comments there. So if using `std::thread` stuff, is the correct flag `-pthread` or `-lpthread`? And is it correct practice to use it for compiling _and_ linking, or only the latter? And what about clang, I think on clang `-pthread` does not work and it's `-pthreads` instead, with an 's', or something like that? I couldn't find a good place where these intricacies are described well.
I feel like one hasn't had to do that for quite a while now? 
That sounds right. You do need to give `-pthread` to the compiler (or at least the preprocessor) in addition to the linker: &gt; [`-pthread`](https://gcc.gnu.org/onlinedocs/gcc-5.3.0/gcc/RS_002f6000-and-PowerPC-Options.html#index-pthread-2357) &gt; &gt; Adds support for multithreading with the *pthreads* library. This option sets flags for both the preprocessor and linker. Interestingly, gcc appears to accept `-pthreads` on Solaris (and `-pthread` as an alias), but only on Solaris. **Edit:** Oops, I had quoted the wrong option in the manual. But even this one only appears under "RS/6000 and PowerPC Options", despite being more widely-applicable.
One thing that is still baffling to me, and that this proposal reinforces, is the the fact that even expert programmers routinely fail to specify their constraints correctly - and yet, there is no intended way for the user to override the choices of the library author and ignore them. I feel like this will just force people into ugly preprocessor abuse, just like today they have to "#define private public" or worse if they want to get to the private members of some class. Yes, it *shouldn't* be necessary, but sometimes it is.
"Does it have two-phase lookup yet?" is a legitimate question. "Does it support the 18 year old [...] yet?" is being a troll.
Yeah, that's why it sucks. :) If you have a plugin for loading some internal geometry format or whatever, it's a pain to make sure all developers have access to the N different toolchains that they need, and each gets invoked correctly for building the various plugins so artists can shuffle data between the various apps. Especially since a some of the developers inside a VFX studio are actually artists who know enough to be dangerous. 
No expert here, but isn't this available with the correct specs file?
IIRC you never had to do it in C++, but you still have to in C. 
 &amp;var Would probably be "address of var". But in general terms, I would refer to it as a reference. Because that's what it is; int *ptr = &amp;var; Is just you saying, make an integer pointer that points to the address of var; ptr references var. But you could also say 'at var' and it still makes sense. However, and var doesn't. To me, I think of logical AND when you say that. bool expression = (var &amp;&amp; var2); That's what I think anyways.
I read it as "amp" like ampersand. I would say out loud "amp var" but think "address of var."
&gt; \#define private public I never thought about that. I'll keep in mind in case I devilishly need it. :)
Noone has yet mentioned gtkmm? It is better designed and more modern than Qt, and just as mature.
It's not nearly as bad as `#define if(x) if((x) || rand() == 0)`
wxWidget can be very lightweight because you can link statically your application with it. The programming style is of the API is a little "old school" but it didn't require special processor as Qt does. If you target desktop OS (windows/linux/macOS) and you don't need too much "advanced" GUI behaviours, wxWidget can fit your needs.
That would be hard to market though, especially on hardware where atomic operations are slow: "if you want the exact same performance as before, and the same binary size, you need to add this new flag". Also what about platforms which do not have pthreads? **EDIT**: s/boat/binary/
To add to this. If foo is in the global namespace you can still refer to the type as ::foo
Surely the performance hit from looking up the list of modules linked into the program would dwarf any performance gains from skipping using atomic operations?
-lpthread exposes the symbols (like pthread_create). -pthread adds some processor defines. iirc correctly in C you need -pthread (or manually adding -D_REENTRANT) for the standard library to be thread safe (although re-entrancy is useful at times without threading, e.g. if you use signal handlers). I'm guessing that you would also need -pthread (instead of just -lpthread) to disable this string optimization.
I haven't looked at the implementation, but.. not necessarily, if you check the module list just once at the program startup and store it into a flag, it's pretty fast. I'll try and take a look at the implementation when I'm home to see how much bullshit everything I said is
More like "You generally don't pay for what you don't use." There's several places where C++ breaks that principle, mostly due to technical limitations.
Just to avoid being a bad influence, let me point out that theres also the `-fno-access-control` flag which is usually preferrable.
I guess it's still far from being added to the common STL implementations though...
I hope that the committee will be conservative here. Many things have been rushed with C++11 like [std::async](http://eli.thegreenplace.net/2016/the-promises-and-challenges-of-stdasync-task-based-parallelism-in-c11/) or noexcept. The latter, for example, forces you to duplicate generic code, both in the body of a function and surrounded by the noexcept operator. Or think of std::min taking an initializer list, which is seriously [broken](http://nd.home.xs4all.nl/dekkerware/issues/n2772_fix/draft_november_2009.htm) for some use cases. I also fear that coroutines might be rushed. Better have a TS early than a dead end in the standard. An advantage of that is that by the time proposals get actually standardised support exists in multiple compilers already. Not mentioning the experience gained from TSes. Going too fast can be more harmful than going too slowly, especially regarding major changes.
I agree. Also look at the Qt object model. Is no more C++ but a kind of Java.
If you want to know **why** this is done, suppose you have some code already written where you use a variable named ``foo``. Then you find out about a library that has a class named ``bar``, and you decide that it has a really great feature that you want to add to your code. The catch is that the new ``bar`` class inherits a class named ``foo`` whose name is going to collide with your ``foo`` variable as soon as you ``#include `` the header ``bar.hpp``. Without name shadowing, you would have to rewrite your existing code to change the name of the variable ``foo``, which could take some work. Worse yet, ``foo`` might be a **really** good name for that variable, but you wouldn't get to use it anymore without name shadowing.
what are these "specs" file?
I think Haskell is an amazing language, but it's really pointless to compare it with C++. They don't target similar application domains at all. This rant should be aimed at Java, C# or, say, JS developers. I think Haskell is a complementary tool to C++ in a professional programmer's tool set. IMHO, the only reasonable comparison with C++ is Rust.
Do you have other namespaces with Fish? Will it confuse you if you do not write eco::?
Why not use [GLM](http://glm.g-truc.net/0.9.7/index.html) or may be [MathFu](https://github.com/google/mathfu) or [Eigen ](http://eigen.tuxfamily.org) or [Vc: portable, zero-overhead SIMD library for C++](https://github.com/VcDevel/Vc) ? But of course it is fun to make this by it self to learn how it work.
This is vector-light code. It only uses three lanes; it doesn't scale to the architecture, and with things like AVX and AVX-512, this is severely under-utilizing the hardware. If you really want to write fast, scalable code, you're going to have to move to SOA format.
it will not, therefore, I assume not to specify eco?
If you ever planned to use Fish from a namespace outside of eco, then you would want to be explicit eco::Fish. If Fish will only ever come from namespace eco, then dropping eco:: shouldn't be a problem
&gt; you get hardware accelerated rendering If you write in raw C++ do you not get accelerated rendering?
I totally agree, this is the kind of code which causes people to think SIMD instructions are pointless/hard to use. Sure, SSE2 registers happen to be 32bit wide which fits nicely with the 4D vectors used in graphics, but once you get to a dot product all of that blows up and you're back to scalar code...
The problem is that for a major feature like cannot be made perfect for everyone, this there are always different opinions. There are always tradeoffs involved, and there is always someone in the committee against. Rushed you say? Well, concepts have been in discussion in some form or another in the committee since about 2004, for 12 years! And unless committee members agree on some compromise solution, we will never have them. Never. So this not simple in any respect.
If there are only a few uses, I'd leave the namespace prefix. If there are many, I'd add a new type, e.g: using FishList = std::vector&lt;eco::Fish&gt;; FishList fish; 
You can do a SIMD dot product in 3 ops! IIRC it was MUL, then two HADDs. It's not the cheapest, but it's still better than 5 scalar ops. You can also do cross product with 2 shuffles, 2 muls, and a sub.
Go back further. Bjarne discusses some approaches considered in his Design &amp; Evolution book, in 1993. 
let me rephrase, I prefer it with the prefix, I think it looks nice and it makes me happy. It it considered bad practice to do so everywhere I go, even if the code using it is wrapped in namespace eco?
And sadly it's only implemented in GCC so far - with many bugs allegedly.
This is not something to worry much about. Do what you feel comfortable with. I would take bigger care to be consistent than worry which approach is better.
The problem is that you end up with a scalar and only work on two vectors at a time. If you properly arrange your data (in a structure of arrays, instead of an array of structures) you can do 4/8/16 dot products (whatever the width of your SIMD registers is) at the same time in 5 instructions. This is where the real performance differences start to happen. If you only want to do one dot product it doesn't really matter if it's 3 or 5 ops, but if you want to do 1000 it helps if you can do 8 instead of 1 at a time.
That doesn't really answer my question. I'm not advocating including unneeded headers in your math library, I was just trying to get some actual numbers around a pathological case. I don't see why &lt;algorithm&gt; and &lt;iterator&gt; (the two standard headers that were specifically called out), let alone most of the other includes I threw in there, would be needed in a math header rather than letting users include them as needed. And this also assumes that the numbers are a constant overhead per include that can't be optimized away with precompiled headers or header caches or other means.
In library code, which should be hardened against user code, you should worry about ADL hijacking. In particular, this means that if you're in namespace Ecosystem, and you want to call Feed(), and you don't control all of the arguments (e.g. Feed() is a template, and might be given UserAnimal), then ADL can hijack an unqualified call. In production-quality libraries, such calls should be qualified to prevent ADL. Since it's hard to notice when arguments might be user-controlled, this generally means qualifying all free functions. (Member function lookup suppresses ADL, so you don't need to defend them.) But unlike functions, types can't be ADL hijacked. So you can freely refer to other types within your namespace, without the fear that users (even with using-directives, global names, etc.) can hijack them. In our STL implementation, we avoid qualifying types unnecessarily.
It's not supposed to scale to the architecture, it's supposed to scale to the problem domain. If the problem is "I need to work with this one 3D position and this one 3D matrix", no amount of SoA will help you. Not all problems can be phrased in SoA format.
No, no good reason really, just habit. An inline function would probably be a better option.
I can't imagine such a domain where you have enough operations on a single point and a single matrix to make this worthwhile. If it does exist, it's so limited and specialized that teaching this mode of SIMD utilization is a disservice to the general population. I work professionally in computer graphics. We never have one point.
Your first example exploits 3.3.10.4 which explicitly states that lookup of fully qualified names is allowed. I am not worried about that one because fully qualified names are not the same as unqualified names (if they were, it would preclude name collisions across namespaces which is silly). Your second example is an example of variable shadowing which is *not* the same as name hiding of types. You must explicitly introduce a new scope to shadow a variable name whereas such a thing would explicitly not be allowed for types by the first half of 3.3.10.2.
Disclaimer: I am an author of [Sciter](http://sciter.com) - an embeddable HTML/CSS/script engine with plain C and C++ API. Answer depends on type of your application - it's main function. There is no silver bullet unfortunately. And yet on what exactly you want to do with C++ on UI layer. I don't think that C++, as a language, is the best at defining layouts, styles and for "code-behind-UI" cases. Implementation of those - yes, but not as a definition language. If you want your application to be up to date with modern UI trends then you will need styles - something detached from your code and what can be changed without major code update of your application. Check this [example](http://sciter.com/from-skeuomorph-to-flat-ui-evolution-of-one-application/) - that application survived transition from skeuomorphism to Material Design UI transition without changing their UI related C++ code. If you have complex UI handling logic a la "on-click-here-hide-section-there-and-expand-that-and-at-the-end-of-transition-highlight-those" then that is better to be defined in script that allows to define such things shorter and safer. Consider script as "UI reactions definition language", same as CSS for styles and HTML for structure/semantic. If you want your application to be accessible, to comply Section 508 rules, then you probably need HTML where you can define "aria-***" attributes. At least your framework shall support IAccessible and the like features. But again it depends on functionality of your application and your requirements... If you need for example [printing](http://sciter.com/printing-support-in-sciter/) , WYSIWYG HTML editing or any sort of formatted text output then you shall consider anything capable to render HTML/CSS. 
Inline or lambda? Just asking to be clear. Edit: ASSHATS. Edit 2: Super ASSHATS (as if the previous update wasn't clear enough). 
Inline I guess? I can't imagine what use a lambda would be here.
I'm not sure why you brought a C example to my C++ question. Also, I explicitly stated that I have no issue with member function name hiding. In C++, you can have a member function and a type with the same name so long as they are in the same scope. struct foo { struct bar{}; void bar() {} void baz() { bar(); bar b; // error: 'bar' is not a type here } }; 
Nope. Qt Widgets aren't GPU accelerated, only QML.
For types and functions (outside that header file) you should still qualify them in library header files, the reason being that you can forget to include the file which has your type or function in your namespace, and the user code may end up including something before it that adds a different type or function of the same name in the gloabl namespace, even if the other header file didnt define it the user could have the IWYU method of #include &lt;some lib&gt; using some_type_or_func; #include &lt;some other lib&gt; using some_type_or_func;
&gt; Hence why precompiled headers exist. If they only work reasonable well on all platforms and in all circumstances. 
A mistake, but might not show up until used in a different environment (unless you run something to check IWYU) What do people use to verify IWYU? Does MSVC have a nice way to verify IWYU?
In the STL, we have a test that includes every header individually, and we run it (via undocumented options) against the EDG front-end cranked up with extra conformance for two-phase name lookup, which catches most issues. (Ideally, we would instantiate everything provided by each header.) When I can run tests against Clang/C2 I'll probably switch to that.
You're absolutely right, but my original point stands: this doesn't scale.
You can also do: struct foo { int i, j, k; }; int main() { foo foo = {1, 2, 3}; struct foo f; // perfectly legal. } --- &gt; Why? ***Why?*** It leads to insane code like this which is perfectly legal. It makes that possible, but it's only the programmer that 'leads' to such code actually being written. There's nothing a programming language can do to really prevent programmers from writing insane code.
There was [apparently backlash](https://isocpp.org/blog/2016/02/a-bit-of-background-for-the-unified-call-proposal) over `.` finding free functions: &gt; &gt;To my surprise, many people came out strongly against x.f(y) finding f(x,y) – even if member functions were preferred over free-standing functions by the lookup rules. I received email accusing me of “selling out to the OO crowd” and people whose experience and opinion I respect insisted that x.f(y) finding f(x,y) would seriously compromise their ability to design stable interfaces. I think those fears are greatly exaggerated, but I could be wrong. Also, I prefer the dot syntax in some cases; for example, I find x.f(y).g(z) more readable than g(f(x,y),z). However, there was no chance of acceptance of a proposal that included x.f(y) finding f(x,y). Maybe modules will eventually help here. Furthermore, David Vandevoorde pointed out that because of the two-phase lookup rules having x.f(y) find f(x,y) would complicate the task for compiler writers and possibly be expensive in compile time. &gt; \- Bjarne Stroustrup
It only has to scale better than the alternatives ;) Most programmers aren't very comfortable with the sort of contortions you need to do to turn ordinary code into an SoA-style affair - so this isn't a very high bar.
That's unfortunate. Other languages (D, C#) seem to have no problem with this feature, and I've certainly found it useful when writing in those. 
Yeah, I was definitely looking more forward to this one.I'd still say having the other is better than nothing. Unless I'm missing something it lets us do `swap(foo, bar);` without `using std::swap;`. The main place where I did ADL calls was `begin` and `end`, though, which are hopefully "going away" with the Ranges TS. There's still stuff like `std::size` and `std::erase` and whatnot now, so being able to omit the using declaration is nice, especially without waiting for yet another proposal involving Eric Niebler's customization point improvements.
I just want std::string::format() and std::string::split().... This gets me that.
Oh boy, that's what c++ is known for, it's speedy compile time /s
Whoever the naysayers were, they've successfully damaged C++'s evolution significantly. Instead of selling out "to the OO crowd" (whatever that means), Bjarne's instead sold out to the crowd that lacks vision. Put simply, when you want to write: string.reverse().rtrim("#").lowercase().split("\n").strip(" "); You now have to write this instead: strip(split("\n, lowercase(reverse(rtrim(string, "#")))), " "); And this is being described as "half a loaf of bread." What a joke. The order of operations evaluate backwards, and the parameters to all but the innermost function are greatly obscured. Yes, I know you can (and probably should) break that into up to five lines. That's not the point. There are many valid use cases for chaining; especially in user interfaces and string manipulation. x.f(y) isn't just a nicer way to write f(x,y) ... it tells you something very important about the nature of x: that it's the direct object of the function. It removes so much pain from the language to have this, especially when the order of x,y is very important for f, which is surprisingly often. Just look at the mess PHP has made of things with the order of arguments to functions such as str_replace vs strtr. Everyone could already write free function wrappers to member functions: both users and library authors. Sure, it might eat up a few extra lines of code, but the entire process can even be automated. The major limiting factor of C++ is that classes are arbitrarily sealed off permanently after their initial header declarations, never to be extended again. A completely arbitrary limitation. And so in the absense of extension methods, UFCS was our only workaround. Yet this change dooms users to whatever they were given initially, unless you want to treat C++ like a purely functional language. There's nothing you can do about f(x, y)-&gt;x.f(y), short of a language extension. So you're given std::string, which is basically a glorified version of { char* data; size_t size; } ... absolutely no useful string manipulation functions in there: no string-replace, no tokenize, no lowercase/uppercase conversion, no simple pattern-matching (albeit very complicated and separate regex), no evaluation, no trimming, no transform, nothing. And so what do people who don't want to use C++ like C or Lisp do? They make their own string classes. Maybe they inherit from std::string ... but that breaks the second a project ends up with two incompatible subclasses of std::string. But they worry about this same problem, and know users can't extend it. So they take to trying to implement the kitchen sink into their classes, and you have a million functions in there. Most of which you'd never use. It's anti-encapsulation. The functions become part of the interface, and now you're stuck with them. Only, it's not just std::string. It's every class. Instead of just adding the functions we need, and passing around standard library objects, those of us serious about the x.f(y) syntax all go about reinventing the whole thing. And that's exactly what I've done: my projects use my own standard library. Which leaves me looking like a loon to others, but is the only way to end up with a coding style that is a joy to write in this language. The people ragging on this being a sell-out to the OO crowd have entirely missed the point. This was the solution to that: a decoupling of functions from structure. And now it's gone. Way to go. 
Did you have a question? I was just replying to your assertion about including unnecessary headers not actually being that bad when it definitely is. At least it is when they're included from very commonly used and heavily inlined headers like those found in your math library. Which is what I thought was being discussed.
I get why it needs to be there for cases like this, but I don't get why people do it deliberately. Our local university mandates the following style for constructors: class foo { int x; foo (int x) { this-&gt;x = x; } }; 
It's getting better at least. Modules will help. Things like variadic templates and fold expressions help newer metaprogramming libraries.
But changing the way shared pointers work from one compiler to another will create a huge problem. A program that works with one compiler will not work with another one. What does the c++ standard say about shared pointers? Should they increase/decrease the ref count atomically?
In the case of shared pointers, why aren't shared pointers customizable through template arguments? The default should be atomic ref counters, but it should be allowed to parameterise shared pointers via template arguments. 
Re being a sellout, this is not something Bjarne decides.
What comparable language is faster to compile?
It's pretty scary. No warnings, just wrong runtime behaviour. https://gcc.gnu.org/bugzilla/show_bug.cgi?id=58929
D is way faster than C++ and probably the fastest I've seen.
Have their been any proposals for including something like the F# (and now Elixir) pipe operator in C++? Your example would become something like: string |&gt; reverse() |&gt; rtrim("#") |&gt; lowercase() |&gt; split("\n") |&gt; strip(" "); I'm not sure if I prefer it to UFCS, but it certainly seems to capture a common use-case.
&gt; Furthermore, David Vandevoorde pointed out that because of the two-phase lookup rules having `x.f(y)` find `f(x,y)` would complicate the task for compiler writers and possibly be expensive in compile time. On top of that, I think there were concerns about look-up. The problem of C++ is that look-up is open: when calling `f(x, y)` the `f` can come from about... anywhere: - it can be a member function of the current class (if in a class member function), in which case there is an implicit `this-&gt;` which does not appear here - it can be declared in the current namespace - using Koenig's lookup (aka Argument Dependent Lookup) it can be in the namespace of any of the argument - if no `f` was found yet, it could come from any of the surrounding namespaces of the namespaces already mentioned This unprincipled approach is unfortunately quite crippling. Any change to the look-up rules means that existing programs could suddenly start pulling functions from ever more exotic places, and would be even more brittle than they already are. The main objection, after all, is that introducing a new `f` in a library could cause client code to **silently** switch to that new `f` instead of its own `f` it had been using for years. This is compounded by implicit conversions, of course. --- So, what of having `x.f(y)` finding `f(x, y)`? The worst of it, I think, would be in template code. As it based on ad-hoc polymorphism, it is even more susceptible to the issue. For example, some code may have relied on the fact that `x.f` did not find any name until now to selectively disable some functions (using `-&gt; decltype(x.f(y), std::declval&lt;Return&gt;())` for example); a new look-up could pull out a `f` from somewhere and thus allow the function to start compiling. I think that transforming `x.f(y)` into `f(x, y)` is unlikely to ever happen. Ever since the inception of C++: - classes are **closed** scopes - namespaces are **open** scopes suddenly opening classes scopes will undermine all software that has been written assuming they were closed. The other way around: `f(x, y)` into `x.f(y)` is not as problematic since namespaces have always been open anyway, although as mentioned above since it modifies the look-up rules extra care will be necessary to avoid accidentally switching existing code from one function to another; and nothing can be done for SFINAE suddenly no longer weeding out a function from the overload set... 
This should really be avoided in most cases anyway by always capitalizing the first letter of class names, and always having the first letter of variable names be lower case.
An ugly syntax can mostly be cobbled together today, but it'd be positively frightening to outsiders. [Using this class](http://board.byuu.org/phpbb3/viewtopic.php?f=7&amp;t=51&amp;p=724), where function(Object&amp;) is global and unknown to Object's class definition, you could do: object(function, params...)(function, params...); object[function](params...)[function](params...); The major limitation is that each class has to opt-in, so you can't apply this to any existing class (most critically, to the standard library classes.) It's also likely to have lots of other problems. It's also ugly as sin to have a hybrid blend of the two in real code, and a burden to keep track of which functions use which syntax: object.realClassFunction(params...)(globalFunction, params...)[globalFunction](params...); Since you mentioned piping ... if we were designing new syntax, I'd want to solve the method chaining problem separately. Take the case of a string trim function: you want to call rtrim("}") to remove a close bracket from the end of a string. But what does this function return? If string&amp;, then you can chain it: string.ltrim("{"}.rtrim("}"); If bool, then it serves as a test as well: if(string.rtrim("}")) then...; What we want is a way to pick either bool, or a chain. If we had operator.., we could do this: print(string..ltrim("{")..rtrim("}")); //object..function returns a reference to object, discarding the original return value if(string.ltrim("include ")) ...; //object.function returns original return value Of course, if we had operator. overloading, we might be able to rig up a new Chainable&lt;T&gt; type for this (we could do it now with the hideous operator-&gt;); but it'd lead to ambiguities that might end up requiring explicit casting at times. A chain operator.. would be superior.
I by far do not know all features of boost range and boost pheonix, but do they offer things like [a monadic maybe type](https://github.com/Dobiasd/FunctionalPlus/blob/master/include/fplus/maybe.h#L148) or functions like [split_by_token](https://github.com/Dobiasd/FunctionalPlus/blob/b44aeb7e75d4661d617f5b68600796258b679ce0/include/fplus/split.h#L197), [count_occurrences](https://github.com/Dobiasd/FunctionalPlus/blob/b44aeb7e75d4661d617f5b68600796258b679ce0/include/fplus/split.h#L220) and [transform_map_values](https://github.com/Dobiasd/FunctionalPlus/blob/997db1b95014e5aea511e20d61afd09728736fc0/include/fplus/maps.h#L149)?
Sorry for the totally off topic question, but could you tell which color scheme are you using on Visual Studio? I'm sick of the default dark theme. 
Is it hard to package and distribute the app on each platform?
Isn't the commercial license expensive and required to develop if your not doing open source?
Well if concepts gets what you propose, that is, checking of function definitions, the leap to "concepts replacing base classes" is actually pretty small since one could then auto-generate a vtable from the archetype/concept-map and allow "pointers to concepts" implemented as a fat pointer: one pointer to the object, one pointer to the concept's vtable. A lot of people have argued in the past that concept-based run-time polymorphism is more suited than inheritance-based run-time polymorphism for a wide range of applications, but a multi-paradigm language should provide both.
&gt; because they generate worse code. I think that topic would make for another very interesting blog post.
This was one of the features I was looking forward to the most. It's very sad that we won't get it. Hopefully, as /u/asb mentioned, we can get some kind of operator that does the same thing but preserves backward compatibility: string |&gt; reverse() |&gt; rtrim("#") |&gt; lowercase() 
So, if I have an argument `x`, and use `f(x)`, `g(x)` and `h(x)` then I have to somehow put it in constraints. And if later I refactor my code to use `h(x, true)`, or add or remove something else - then I'd have to update the constraints? And what about conditional compilation? What should I do if I want to add `#if _DEBUG \n log_dump(x) \n #endif`? 
It really depends on what your goals are. You can do so many things with Python, and never have to touch another language - but Python hides a lot from you, by design, to make programming simpler (things that you will want to be familiar with as a programmer.) Keep in mind that Writing a C++ program is easy, but the language has so many features that it has the potential to be horrendously complicated. 
Man, I like C++, but after a couple years writing Go, I have really come to appreciate "less features is a feature". This is a disaster. What a horrible clumsy mess it is becoming.
Im sure that you would be able to write a kernel module in C++ if you'd like (with or without STL). I'm quite certain that you won't be able to get it accepted into the mainline.
I've written a lot if code using the STL with exceptions turned off. Works fine. That is how nearly all c++ at Google is written, including Chrome and Search. Only issue is if you need to handle out of memory in some way besides crashing, which could well be an issue writing a driver. 
I believe that's Visual Assist's coloring in the README screenshots. VA is a visual studio extension from Whole Tomato Software. It's great!
Not as long as Torvalds has any saying in it... :-)
What happens when you compile code that uses exceptions without allowing them? Does it just turn `throw` into `abort`?
The problem is, `&lt;algorithm&gt;` is too broad. It is a kind of "god header". It contains some very wide-used things like `std::min` which almost every cpp file needs as well as rarely used things. The right solution would be to break up `&lt;algorithm&gt;` into many separate headers so one could include only what's needed. Something like `&lt;algorithm/sort&gt;`. 
If you need them then obviously you need them. But it can be worth jumping through some hoops to avoid including things sometimes. Especially when it's something huge and heavily templated like an STL header. And especially not including anything from another header. For example, making your interfaces in terms of raw pointers instead of iterators. Or redefining a constant. Or even using pImpl. And a large chunk of the time spent compiling is just opening and closing files. That's why unity builds are a thing and why you should probably have an SSD. So yeah, I would agree that unnecessarily including anything at all is prohibitively expensive. At least on large projects. If your project only takes a couple seconds to build regardless then obviously your time and effort can be better spent elsewhere.
Throws become compile errors, although setting fno-exception causes STL implementations to swap out throws for aborts. If one calls into code that is compiled with exceptions which then throw, the program will abort when the unhanded exception reaches the code without exceptions. So throws do basically end up acting like aborts.
Go
Funny, the author recommends *disabling* automatic inlining, for the sake of assembler readability! 
tl;dr: C++ is screwed.
I only work on POSIX systems that has precompiled packages available. On OS X I would use homebrew, and on Windows I would rely on MSYS2, but there are alternatives: http://www.gtk.org/download/windows.php. No idea how to use gtkmm on Android though, since I have no experience with their NDK, but it should be doable somehow. 
I've tried to give a more formal definition of this concept [here](http://bannalia.blogspot.com/2016/02/a-formal-definition-of-mutation.html). Not that it sheds much more light than the intuituve notion itself that it tries to model.
A bunch of great points, but my general advice is this. Learn one compiled language, one interpreted, and one functional. Picking up languages really isn't hard once you've learned your first. And I just want to make a case for learning C++ before Python. It's not what I normally recommend, but since you're interested. I learned C++ as my first language. It was really hard. And my second language was assembly. The hardest part about Python is that they hide so much from ou that you have no idea why your code is slow or wrong. Computer science concepts are independent of language, but writing a good program is more than writing a good algorithm. And you won't learn much about how to write efficient code by learning Python. And some people may say you never need to learn C++, but in my field, robotics, C++ is the only language. Maybe C and maybe Python for really high level or wrapper stuff, but we all use C++. Same for graphics programmers and systems side. So C++ is very important for some very exciting fields. 
Because writing embedded systems with exceptions is very problematic. It has very large overheard and encourages coding practices that will get you into trouble down the road if used in critical systems.
Kinda. For embedded, exceptions are really a no go. For non embedded, I still shy away from them. Here is a brief run down: http://www.codeproject.com/Articles/38449/C-Exceptions-Pros-and-Cons For me, it boils down to them being expensive and make code more difficult to reason about
Anyways as always I say do something you want to do, if you can do it in python do it. Learning how to do what you want to do is more important than what language you want to do it in. If you need the speed of C++ use C++, if you don't then you're free to use something else. It's also not a bad idea to try new languages either. I prefer when experienced programmers use languages like C++ with a focus on speed. Because once they know how to program what they want in whatever language it's nicer to run a higher performance program.
Certainly not in the way of intuition, but you need to formalize when you want to prove things (much like, say, the mathematical definition of a continuous function adds little to the intuitive understanding of the concept).
It becomes very problematic when your assumptions about when exceptions occur are not correct. And also when you have little control over the code being written or included, so you can't guarantee that. Even if it's all internal code, you can't review everything the intern writes. Exceptions also let programmers be lazy. Instead of seriously evaluating code to see how it can fail and handling those correctly, it's much easier to catch an exception and spit out some logs. That approach is good enough for a lot of things, but will ruin someone's day if you do that in pacemaker software or in a missile guidance computer.
This guy knows what's up
Linux over commits anyway. It pretty much always tells you your allocation worked, so exceptions wouldn't be thrown anyway. 
Not really, you're free to use threads and never use shared pointers, and you will not pay anything for them having atomic reference counts. *If* you use shared pointers, then of course you have to pay for them providing the properties guaranteed by the standard. In theory, there could be a separate `unsafe_shared_ptr` which doesnt provide those guarantees, but the standard library doesn't provide such a class because it wouldnt be very useful, to say the least.
I would say learn C first to get experience dealing more directly with algorithms and data structures. C++ is all about separating high-level concepts from implementation details. As a noob, you kind of need to struggle a bit, I think, in implementation details.
This is true at the user code level. I'm not sure about this in the driver level, it might actually need physical pages, but maybe someone more knowledgeable can comment. 
This is not exactly true. Games historically havent used them in the vast majority of code because they're unnecessary in such a closed system. But that is starting to change in certain levels of the code bases because some platforms are now using exceptions to communicate errors. 
Maybe I'm missing something, but &gt; (x * c) cmp 0 -&gt; x cmp 0 If ```x = 1``` and ```c = 0``` then the left side is ```0 cmp 0```, and the right side is ```1 cmp 0```. Can someone explain how that's a valid transformation?
...(x, and y are signed integers, c, c1, and c2 are **positive** constants,
Ah yep, thought I was missing something, thanks.
you'll likely have a much higher probability of seeing allocations fail in kernel mode, as non-pageable memory is a much different type of resource than the stuff you deal with in user land (which is the reason that you see relatively small, fixed-size stacks in both Linux and Windows on the kernel side). This is especially true if you're in a situation where you have to do non-blocking allocations. 
Again, it depends on the application. For regular software that can tolerate crashes, I would definitely agree with you. But there are applications (missile guidance and pacemaker being the ones I gave above) where turning a non critical exception into a fatal error by failing to catch it would be disastrous. Of course those applications also spend a ton of money making sure that there are not unchecked return codes.
anything in &lt;algorithm&gt; that might be useful? used with lambdas?
How many of these transformations require the full definition of undefined behavior, as opposed to simply unspecified or implementation-specified behavior? (Loosely: undefined behavior → "this can't happen", unspecified behavior → "this can happen and the result falls within this range of possible results")
I think the OOM killer makes a lot of sense actually. Keep in mind that since memory isn't even checked really until you try to use it, there isn't really a place to check for NULL and throw or even handle it. You could do away with the OOM killer if you did away with lazy memory allocations, but I expect that would make things go much slower in general and I don't think it'd be worth the tradeoff. 
Give up and pickup botany instead.
&gt; 1) We say x ~g y iff g(x) = g(y), but this equality does not hold in the case where two functions are working on different tuple elements [...] You're absolutely right, I've just updated the entry so that ~*g* is correctly defined in terms of *gQ* alone. &gt; 2) "this can be extended to the case where f and g read from (but not write to) any component of x except the j-th and i-th, respectively." If they read from other tuple elements, how do they not effect each other? They're allowed to read, not write. The only components of the tuple changed are `i`-th and `j`-th, so both `f` and `g` can freely read from the rest.
&gt; C++ is an old language compared to C# and C 
If a loop cannot terminate then it's sometimes possible to perform loop fusion, turning two adjacent loops into one. His point is irrelevant in modern C and C++ because infinite loops are undefined behaviour: http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1528.htm
I don't write much C++, what C I do touch is in the form of embedded AVR code, which is more or less a macro language for rendering ASM. That said I do think it's interesting that C++ continues to improve, and that the tooling (LLVM, Clang, etc) are constantly evolving. Briefly, I watched recently Rob Pike's keynote from dotGo2015 in Paris, he claimed it to be a huge victory of Go that you don't have to even *have* an ownership concept, the garbage collector takes care of it. Rust on the other hand holds this out as one of the principle reasons to use the language. I'm sure this is a "marketing" decision driven by trying to select a willing and open target audience for the respective languages. I do think adding more and more and more features to a language which suffers from people using many poorly understood features is a blessing and a curse. Many of the C++11/14 changes are bona fide improvements to previously difficult to solve problems. Conversely the unstoppable march towards ALL THE FEATURES is a little disconcerting, differentiation in programming languages is important to the expressive nature of the code, and informing the way we think in the same way that that being able to choose between charcoal and water color affects the way an artist renders what they see before them.
I want an unsigned integer type that causes UB on overflow.
I posted it because the title was amusing, and the HackerNews discussion is a balanced a reasonable (for a change) discourse about the pros and cons of a) articles such as this, b) the underlying topics that the article raised.
&gt; Is Qt with C++ hard to learn? Well, that depends on how you look at it. Qt is a very high-level GUI/General/Util toolkit if you want to. But more often than not you have the ability to really dive into the implementation details part of it if you want to. I'd say that with moderate knowledge of C++ you can definitely start working with Qt's GUI parts. That being said, I **strongly** recommend you read [Qt's documentation](http://doc.qt.io/) whenever you find time. Especially [this](http://doc.qt.io/qtcreator/creator-writing-program.html) and whatever else you may find there. &gt; It doesn't seem familiar with what I know about C++ That's because it actually is quite different from time to time with a boatload of macros that does different things for you. However, just start out with some examples you can find in Qt Creators "Example" section and you'll get the hang of it quickly. `qDebug()` is a convenience that in its default implementation writes to std::cout (I don't know about std::cerr though). You can override this implementation [like this](http://doc.qt.io/qt-5/qtglobal.html#qInstallMessageHandler) if you want to handle log messages differently (write to file for example). If you have any questions I'd recommend these resources: - [Qt's documentation](http://doc.qt.io/) - [Stack Overflow](http://stackoverflow.com/questions/tagged/qt+qt5) - #qt on irc.freenode.net
Why wouldn't it be useful? There are many cases were threads work with their own private data sets. 
I would rather like to have a scientific study than a few sentences in a talk
User can `#define` some identifier before including library header. And sometimes it even compiles instead of showing _Figure 1_ . Though in this case it is better to let user to shoot himself in the foot instead of trying to prevent it.
It depends what you want to do. If you want to do anything low-level or with graphics where speed is of prime importance (eg games) then the answer is probably yes. If you want to do anything else then the answer no. 
I second this, there is nothing in this, that is sufficiently interesting for a wider audience to justify putting it here.
Not directly c++ related, but that's too much documentation before each function. Your version control system will have most of that information you put there.
Yeah that i can agree with.
Disclaimer: I am bit new to C++, so the secondary reason of this post is to check if I have just did something horrible :). So feedback is welcome.
CppCon people thought they were worth their while and gave them these slots at CppCon2015: * [CopperSpice: A Pure C++ GUI Library](https://www.youtube.com/watch?v=LIiwBNvTllk) * [Doxygen to DoxyPress: A Journey from C++98 to C++11](https://www.youtube.com/watch?v=hQphBQMwk7s) * [Compile-Time Counter Using Template and Constexpr Magic](https://www.youtube.com/watch?v=gI6Qtn4US9E) 
C with STL. Have never seen that before. To start looking like C++, you need a bit of RAII.
A small tip, pushing std::endl onto the stream flushes the buffer, so no need to call it again
Thanks for writing this. I didn't have anything against moc before reading this, but it's nice to know how it works under the hood.
Great post. I really like this technique for managing subscribers. Only downside is you have to create+destroy a shared pointer for each subscriber on each event, which could be costly.
Your call to `forward` inside of `add` is not forwarding anything because `C` is not a forwarding reference.
You wouldn't need a dependency to clang compiler. You'd be using libclang which only parses your files and generates additional source files to pass to your actual compiler.
I think ideally it would be technically superior to have a general runtime introspection solution with attribute(()) declarations and a custom compiler plugin, to extend RTTI so we can eliminate the moc.
There you go: https://woboq.com/blog/moc-myths.html This provides the evidence you are looking for - CopperSpice is simply a bad choice for projects with a long lifetime. Much better spend your resources on Qt.
Use the secure functions as much as possible, as a security oriented programmer there is a large attack vector. strlen_s in windows. But overall it was pretty decent. Also note what /u/yibers have said as well. EDIT: See https://msdn.microsoft.com/en-us/library/z50ty2zh.aspx Or for other independent os's http://man7.org/linux/man-pages/man3/strnlen.3.html since people don't seem to understand that instead of nitpicking at one platform or another and start to understand the concept behind.
I would like to address points 2 and 3. When writing Qt code you are not writing real C++. This is not a myth. If to work correctly, you require a custom preprocessor, your code is not pure C++. It is an extension of C++. For example, if you use Thrift, it is also not C++. It is a preprocessor that generates C++ code. Having a custom pre-processor is definitely a negative in my opinion. The question is whether the enhancements provided by the pre-processor are worth more than the negative of having a pre-processor. To compare this with doxygen is misleading. Your program does not depend on doxygen to have correct behavior. Moc makes the build process much more complicated We can argue about "much", but it does make it more complicated. In fact, it was enough of a bother to enough people that CMake and qmake developers actually took the time and effort to integrate support specifically for Qt into their tools. Are there any other libraries that build tools treat specially to make it easier for the library user? I say this not to disparage Qt, but to reinforce that Qt because of moc is different that other C++ libraries, and moc is a negative aspect of Qt. Effort should be taken to migrate from moc where possible. 
Well, what do you expect `forward` to do without any reference collapsing present? ;-]
&gt; You'd be using libclang So, a dependency on clang (the project, not the executable in /usr/bin).
Moc is a header file generator -- they are perfectly readable. You could write them yourself if you were insane. All it's doing is putting the stuff that C++ doesn't make introspectable (function/class names) into some structures that make them available at run time -- it's making up for a deficiency in the language. The compiled code is 100% C++; and is all human readable. When C++ the language catches up, I'm certain the moc will be removed (and there are plans [already toward that](https://woboq.com/blog/reflection-in-cpp-and-qt-moc.html) thanks to new features in C++11 and C++14). If I had a bitmap that I wanted to include in a binary, and used a binary-to-C-header tool (`xxd -i` if you're interested) -- would that application no longer be C++? Or would I have to remain pure and type in every encoded hex byte myself? If I use bison or yacc, am I not writing C? If I use OpenSSL am I not writing C because my program won't build without OpenSSL headers installed? Having to run `moc` can, I'll agree, be a bit annoying. But it's not the end of the world, and Qt is the nicest GUI library you'll ever use.
I don't think it's something that warrants study, if I work in ASM I think in terms of jumps, loops and the specific *instructions* to achieve the result I need, if I am working with C++ or Go I think in terms of "objects" (sic) and their relationships. If I could bend my mind to think in Haskell, I'd be thinking in terms of iterators, monads and side effects rather than thinking about IO as a 'first class' concept as I might with a procedural language.
It may not have been clear, but my question is : In which qunatity does this matter ? Yes, you can mentally change paradigms according to the language you're using, but does it make you produce better code ? For instance even when I work with objects in c++ I always try to keep in mind how it's going to be translated in actual CPU instructions, or I can help the compiler produce more optimized code, which is the only goal in the end.
Do you have the "std_lib_facilities.h" in your project. 
I don't know what hasn't been said about CPP that wasn't said already. Why does everyone feel the need to bash on CPP?
This is incorrect argue, i think. We've already had hundreds lines of such code, that efficiently works with another impls. Why should we change something and potentially have a maintenance issues? I've already provided an example - function-builder, that provides an very optional heavy object list as output. It's a real example from our codebase that was caught only with perf analyzer (and only in specific, but important - as microsoft requirement - scenario) and couldn't be replaced with vector as is. Another real example - is a usage of the globally constructed list of the message hook contexts. In such scenario we have an security issue problem, coz out-of-resource attack is possible on loading of such module. It's a popular application - several tens millions of the customers around the world. And i should admit again. Each of the cases in *our* code potentially could be rewritten. But: 1. Third-party libraries/binaries. 2. Lack of the perf tests for all scenarious. 3. Need a very qualified developer to manage such issues. 4. Unexpected (from generic point of view) behaviour. In this cases we have an major issue in main usage scenario. All of the popular C++ compiler stl implementation have no such issue. Clang, gcc, boost, eastl and so on have no such issue. It seems for them this is an valuable usage scenario?
yes offcourse :P
As I note in my SO answer here: http://stackoverflow.com/a/30988141/1708801 C11 does provide an exception for the case where the controlling expression is a constant expression. For example: while(1) // not undefined behavior in C11
&gt; This is not a myth. If to work correctly, you require a custom preprocessor, your code is not pure C++. 1) The preprocessor is not required. 2) Why does it matter? 
Not only "[language whatever] sux" posts are tiresome, this is also a repost for the millionth time. 
A friend of mine does hard real time. He tells me (and I am repeating what he says, so I can't vouch for its accuracy) one of the problems they encounter is that their tools (Greenhills embedded compiler) cannot analyse the runtime of code in the case where exceptions occur. Since missing an update would result in a critical failure (people die), they are unwilling to use exceptions. It's a bit like a GC stop-the-world pause.
Perhaps you should first answer the question - which language, comparable or not, does _not_ compile faster than C++?
&gt; It's very sad that we won't get it. "Very sad" involves people dying. For a marginal C++ language feature, I'm not willing to go higher than "regrettable".
&gt; As far as worrying about code silently switching to new functions, the same problem exists with global function UFCS already: once f(x) is being invoked, and f isn't part of the class itself, f could change. I think you're completely missing the main problem here, which is not "once we add this feature, there is perhaps further chance of breakage during maintenance" - it's "adding this feature could immediately break a great many existing programs out of the box".
So it's only useful when you want to mash Qt components together.
I do the same in Boost.Hana, and it works quite well. It prevents most forgotten `#include`s to ever blow up in a user's face.
You could also write assembly by hand, if you wanted to.
Thanks for the information, I was actually not aware of this. I naively thought it was required that move-constructing or move-assigning be valid from a moved-from object, even if it wouldn't mean anything interesting. The fact that we can't even rely on that stresses even more the importance of having well-defined semantics for calling different functions with the same xvalue. Also, one motivation for writing this article was to put some words on the requirement that Hana needs. This way, Hana can document that `hana::at` must behave as I need it to, otherwise you just shot yourself in the foot and it's not my problem.
I wonder how it came to be, given that RAII was already a thing before the major C++ compilers adopted exceptions in a workable manner.
QML bytecode compiler works on moc-generated IDs.
&gt; Qt code constantly triggers my 'code smell' sensors with manually allocating classes (naked new's!) and then how ownership is transferred when passing newly allocated raw pointers into functions (there must be a memory leak!). Current QtQuick programs don't look like that. There are around three specific cases where you have to write factories that return stuff via naked pointers, and that's it.
Weird, I think in theory the way it is is supposed to work is that it kills young processes which are taking up the lions share of memory. You can disable it too it seems: http://unix.stackexchange.com/questions/153585/how-oom-killer-decides-which-process-to-kill-first What kind of development were you doing that you ran into these issues? I guess I could see it for long running server-type applications which were leaking memory or something like that?
This is all nice, but the only instance for strlen in this (sorry) awful code is to get the length of a c_str from a std::string! Best advice here is to just stop and go read a C++ book and learn what std::string has to offer.
I'm sorry to not provide a detailed constructive answer but I'll sum it all up, your code is bad, really bad. You should read a C++ book, learn C++ proper. Your C++ is completely messed up with C functions for no reason. For example, you do strlen on fileName.c_str()... WHY? std::string already provides you with safer and faster functions for that. And not only code, you must study project management, you're commiting compiled binaries in your repository. Source revision control is for source revision! Take a look at doxygen and similar to document your files and functions, you're doing it awfully. Best
I did know about that before, but this is about C++, C11 is completely out of question, even more on microsoft platforms. This code is not going to be compiled by a C11 compiler, nor does C++ standards embeds C11.
I never understood this bias against exceptions. All software techniques can be misused of course! But exceptions are perfectly useful when used to deal with _exceptional_ conditions. My current project has no bias against throwing exceptions and it's worked extremely well for rapid development - when we find a new issue, we can put a check right there, and do nothing else. So there are a ton of one-line statements like this: THROW_IF(map.find(key) != map.end(), "Duplicate key", key, "value", value); where `THROW_IF` is (yes, it's true!) a macro that includes `__LINE__` and `__FILE__` in the exception report (we have very very few macros, but this one was unavoidable). My previous project in the same organization has a huge bias against exceptions (though I see that exceptions are thrown over 400 times in the code - consistency isn't great...) This resulted in some near-pathological code - particularly in the input section, where there were huge possibilities for errors, all of which involved nested if statements and return statements leading to more if statements in the levels above. In particular, this meant that the return value optimization was almost never applicable, because of multiple return statements of different variables. Since we were returning complex JSON types from input request parsing, this was a serious issue. I'm always being called to add a new error case! In my new project, nearly always this is literally a single line of code. In the old project, it was typically a dozen or more lines of code... I would also add that C++ exceptions are cheap. If you _never_ throw an exception, then it is almost certain that your `try ... catch` block costs you nothing - and if your normal return path involves an expensive return value, it's perfectly possible that the exception path will be _faster_ than your normal return path. In modern C++, I never have to work on writing exception-safe code, because most of my projects have no raw pointers at all, or the tiny number of places where it is necessary are buried deep in the central core. I really see little if any reason to avoid them in 2016.
This technique is appealing, but as I argue elsewhere on the page, for 95%+ of new development in C++ there is no reason not to use exceptions. (Of course, there are embedded systems which can't use exceptions; there are compilers which don't even allow them; but these represent a tiny number of developers. And there are systems with a great deal of legacy code where exceptions would cause too many problems - but that's why I specified "new development"!) 
I agree. I have no fundamental problems with exceptions. I don't think they're perfect, but I also probably don't use them perfectly well. They're definitely a useful tool.
Oh, I remember a huge debate in the late 80s in a company I was in over just this. If you aren't using exceptions, then you can RAII or not as you please. But if you are, _all_ your resources - not just memory but other things like file handles and database cursors - have to be RAII'ed. This means you theoretically need to scour every line of your legacy codebase and convert all such resources to RAII. I think Google still disallows C++ exceptions for this very reason. So everyone had huge debates over "exceptions and RAII" so they became a "thing" as the result.
We have experienced serious slowdown in moc performance while testing migration to Qt5. It matters only for full rebuild but still is kinda annoying. Would like to see this myth debunked :)
Yeah we have quite a few `_qobject_base` classes to have at least some workaround for this problem
It really depends. LLVM has overflow checking intrinsics: - on a typical program, the performance overhead is within the noise &lt; 1% - on a heavy numeric program, the performance overhead is huge (&gt; 30%) But then LLVM's intrinsics are naively implemented (for correctness and accuracy of reports rather than performance) so do not provide a good benchmark of what could be achievable with a carefully tuned implementation. If you want to test further, Rust today has unspecified behavior on overflows. With just one flag, you can turn on overflow detection (based on LLVM intrinsics) in Release mode (it's only on by default in Debug) and thus compare the performance of the same program with and without overflow checking. You can then download the programs from the [shoutout benchmarks](http://benchmarksgame.alioth.debian.org/u64q/rust.html) and test them on your machine in both configurations to see the impact.
Why can't Qt add function overloads for unique_ptr moving forward?
That wasn't addressed to you.
Yes. [This article](https://wiki.qt.io/D-Pointer) explains how they do it, essentially with the pImpl idiom and a few helper macros.
While I can't comment on your specific case I would think that most people would recommend handling such big amounts of data outside kernel. Most solutions I saw tended to move most(if not all) then handling to userspace. I think this might be waaaay easier than implementing the C++ API &amp; ABI inside kernel space for all the supported architectures.
Well, I am not entirely sure how to run Debian on Windows 10 or FreeBSD to use it as a way to distribute libraries. Besides, would Debian make a library compiled with GCC 4 usable in GCC 6? Or in MSVC? or in Clang?.
I agree, I even mentioned that some of the points I said were becoming irrelevant. But still, when they were relevant, they contributed to the "hate" towards C++ and they are still valid for already built systems, which one has to support and enhance in the decades to come.
Tell this to the guy who wrote Protocol Buffers and Cap'n'Proto [here](https://github.com/sandstorm-io/capnproto/blob/master/c%2B%2B/src/kj/common.h#L147). I am sure he'd love your pull request which removes this non-standard code.
Even if not using exceptions, premature exits need RAII (and TFA says as much). Arguably one can control premature exits a bit better without exceptions, but it is not impossible otherwise.
Yes exceptions are now (in C++14) less evil as say for 10 years using C++03. But there are sill problems with exceptions that can not be solved. They do not work at all with C interfaces and interface to another languages. Dow about exceptions in multiple different DLL/Dylibs, possible build using different compilers (or versions) ? So why refactor the whole code base that exist for more that 15 years now and start using exceptions ? There is simple no reason for this. It work as it should everyone who use it know how to use it without exceptions. But it is C++ so always use RAII ! 
Unfortunately for some programmers missing file is already exceptional cases.
Regarding C interfaces, there's an interesting technique called a [Lippincott function](http://cppsecrets.blogspot.ca/2013/12/using-lippincott-function-for.html). If you look in the comments, you can find a similar approach using lambdas.
While not ideal, you can use `std::make_unique` and then `.release()` the widget when you pass it to a Qt owner.
The HackerNews discussion was surprisingly interesting.
or, you know, trivially add JS scripting capabilities to your software
He is missing an example of "failing to acquire a resource [in the constructor]". For this you do need an exception for safety.
I use similar approach in my code, but with the difference that caller is responsible with (optionally) providing a `std::shared_ptr` - most subscribers are calling it with `shared_from_this`. This way you can avoid creating a pointer if you already have one, and can use one pointer to manage multiple events to given subscriber. 
There is a QML Camera and MediaPlayer. I agree that for some non-gui cases QCamera is still needed, but that's rare.
Yes, you can use a default argument: void foo(source_location sc = source_location::current()); If you need to pass along a location other than the callsite, you can pass an explicit argument.
&gt; The first few optimisations are obvious enough that a human looking at the codebase would do them. Often these are not written directly in code as-is, but are exposed through aggressive inlining or macro expansion. [Chris Lattner puts it well](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_21.html) (in the context of "why doesn't clang warn when it exploits exactly this type of undefined behavior?"): &gt; warning: after 3 levels of inlining (potentially across files with Link Time Optimization), some common subexpression elimination, after hoisting this thing out of a loop and proving that these 13 pointers don't alias, we found a case where you're doing something undefined. This could either be because there is a bug in your code, or because you have macros and inlining and the invalid code is dynamically unreachable but we can't prove that it is dead.
[Here's an experiment I did](http://nibblestew.blogspot.com/2015/12/are-exceptions-slower-than-error-objects.html) a while ago. tl/dr exceptions are slower than error objects when thrown but faster when not thrown.
QML and QtQuick is just the right tool to do the GUI. And it doesn't work at all without a good C++. The QML is written to instantiate stuff and hold it together. If the application logic leaks into the script and something more than the oneliners start to appear - that's just wrong. So, look at QML as at new extendable *.ui files mixed with possibility to make new components from C++ scratch or composing existing ones.
COW can be useful. So I think there still should be those container classes, even if they are just small wrappers around STL containers. And if you look at QString there is nothing like it in the standard. UTF support of the standard is a shame. Especially considering that this is a solved problem for decades now in other languages. Still there is lots of Qt stuff to get rid off like many of its multi threading classes, except QSemaphore and the threadpool.
Will there be special mechanism in place to make this work? The same trick with `__LINE__` [doesn't work](http://ideone.com/e1a1gY). #include &lt;iostream&gt; using namespace std; void foo(int line = __LINE__) { cout &lt;&lt; "got " &lt;&lt; line &lt;&lt; " at " &lt;&lt; __LINE__ &lt;&lt; endl; } int main() { foo(); } Output: &gt; got 4 at 5
I would love to See Qt-6 be willing to break quite a bit of backwards compatibility and focus on modernizing the API rather than adding oodles of new features. Qt-5 is already huge and does a bunch of stuff. Focusing Qt-6 on some new API design would set the stage for whatever new features they want to add to 6.1, 6.2, etc. That said, maybe Vulkan is interesting enough that it's worth doing a lot of work refactoring out the assumptions that everything should be powered by OpenGL for GPU accelerated UI. 
One of the things I like about only using C++ on my own projects nowadays is that I never have to worry which parts of the language to turn off. Never liked that they decided to make RTTI and exceptions optional, to cater to performance minded C developers. It is only of the reasons why it is so hard to combine C++ libraries, compiled with different sets of enabled features.
I third my disdain for this terrible, short-sighted decision. It's something I'm used to from Qt though...terrible, short-sighted decisions.
what are you talking about? Qt Widgets has 1st class support: - its fully portable - might not look 100% native, but neither does QML, in QML you have to draw stuff yourself - you can draw stuff yourself, if you want, with Qt Widgets, and have full hardware acceleration on all platforms, check out the new classes QOpenglWindow and QOpenglWidget - theres not a single Qt update that doesn't have a lot of Qt widgets fixes personally i think qt5 qt widgets is a fine option for multi-platform development. and it plays so well with c++14
Well, there's a shit ton that can be bashed about bash. I was actually planning at some point to maybe make a replacement. Then I started thinking about how the the parenthesis free syntax works really well for piping and filesystem operations and such, and how you could replace a lot of functionality with consistent rules, but some shorthands for common expansions make one liners far more simple. And pretty soon I had designed bash.
If I'm not writing a web browser, why in the everliving fuck would I want to do that?
I guess the zsh folks already did this as well! (Since it's effectively bash on steroids.)
[removed]
You might want to see why lua is pretty popular. With Qt, embedding JS is trivial, even if JS itself is a broken language.
Requiring custom compiler plugins is even worse than requiring a third party tool.
IRC Client with scripting? Macros in a document editor? So many use cases...
You could also use something like `iostream`'s "invalid state" if construction fails. You get an object successfully, but everything you try to do with it fails.
+1. It's still a nice, well-engineered framework but the Trolls seem to have lost a lot of interest in developing desktop applications and moved to focusing primarily on embedded and 'phone. As part of that they've [abandoned many modules to rot](https://wiki.qt.io/Qt_Modules_Maturity_Level). Given their licensing and business model that's not really a surprise, and it's *probably* a good decision for the project. The statement that "*Qt Quick-based development is expected for the future of UIs*" means javascript and XML. If I want a cross-platform UI library based on javascript those are easy to find. And if I want cross-platform C++ support for other features (network, say) those are also easy to find. I've been using Qt since Qt2, and while I'll certainly be maintaining Qt5 based code for a while yet I'm probably not going to be using Qt for new work.
multi sensor payload processing (aerial, ground based, etc) I build and test on a 40 core (with HT) machine and 128GB ram. It's pretty easy to mess up on a test driver that's just started to build.
His original post has been reposted to death. This was written 9 days ago, though, so it's fresh fodder. His opinions are better worded, and as a very heavy C++ advocate/career user, I don't really disagree with much he says. I just think it's irrelevant, and C++ is still the best choice for a lot of problems.
I think at the last meeting or the one before that, this was deemed too powerful. It would certainly be cool with what it lets you do, but the more powerful it is, the harder you're going to have to convince people that it won't be a bad decision down the road. Just for anyone wondering where that proposal went (I probably read this in a trip report, probably from Kona). I agree it would have been fair to include it. 
of the popular ones -- Scala
&gt; like moc-ng: a re-implementation of moc using the clang libraries which; Which what?
Documentation tools are pretty simple to use. Just document your code and run the tool (doxygen for example) for it to generate HTML pages with the documentation, which you can then host at Github or somewhere else. I've only used doxygen, but I think there are a few other ones.
Have you debugged C++ with gdb or lldb? Have you used a profiler?
This looks like a fantastic addition to the language. 
"I ripped out all the threading code and compilation was faster" well duh.
Most network appliance vendors (He said DPI, so assuming juniper/f5/crowdstrike variant) build on linux but either have an underlying need to stay in kernel (Hypervisor access or security) OR want to control preemption eg. Inspecting an active packet can't be interrupted prior to completion.
You're right, my title was not very good :(
Ah, I see. Unfortunately async needs to go through `invoke()` which does do quite a lot of metaprogramming stuff to work against all function types (and pointers to members and ...)
Don't these guys think that C++ should get rid of preprocessor instead getting new keywords?
Here is a more recent analysis of the cost of exceptions that was used for the WG21 meeting in Kona : http://h-deb.clg.qc.ca/Sujets/Developpement/Exceptions-Costs.html The TL;DR version : * There is, in general, a non-null cost to using exceptions * There are use cases where exception handling is consistently faster than error handling * The cost in terms of binary size exist, but does not seem to be as high as some would expect * Important variations between compilers seem to suggest that implementations could be improved, at least as far as execution speed goes 
Oh, come on. C++-based GUIs are a pain in the ass to make changes to and "widget toolkits" such as WinForms, VCL, Qt Widgets or WxWindows are very constraining when the design calls for anything that is not part of the standard visual palette. QtQuick is VERY liberating in that respect. After a couple of years working with VCL and Qt Widgets I can't fathom abandoning QML/QtQuick because it's so versatile. Also, I don't see a problem with desktop apps being written in QML/QtQuick. There is a ton of reasons to use it for UI in your next C++ desktop app. I feel that a lot of the "old" Qt crowd are dismissing it as "silly" just because they find it hard to readjust or because they've been hating non-C++ languages from day one.
&gt; Finally, let's see the full '#using package ' directive in all of its glory: &gt; &gt; #using package "foo" \ &gt; ("foo/foo.h", "bar/bar.h") \ &gt; [foo, bar.baz] \ &gt; version "1.2.3" Hell... It looks so awful. &gt; In general, the compiler will be expected to retrieve the given package from the specified location (and very likely cache it). Here is example usage: &gt; &gt; #pragma package_source("example", "http://example.co/svn/trunk", \ &gt; "svn", \ &gt; "revision=1266; username=guest; password=guest") I wish we had something like this in CMake... Oh, wai... [ExternalProject](https://cmake.org/cmake/help/v3.4/module/ExternalProject.html)
You can, but it's only feasible if your object can be "legally" in an invalid state. Otherwise, you will either have an API that doesn't really express "this object is invalid", or force all client code (for ever) to check for the invalid state whenever the object is used.
All the time lost configuring those project, and the time spent writing cmake script, I'm sure many people are having a hard on reading this.
If you want to interoperate with modules written in other languages, then there is scarcely anything that you can rely upon. 
*moc* kills build time see: https://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/9604311-allow-custom-build-tools-to-run-in-parallel
&gt; he claimed it to be a huge victory of Go that you don't have to even have an ownership concept, the garbage collector takes care of it. For a GC language the roots own everything that is reachable from them - these roots can be thread stacks or native code referencing objects. There are enough GC languages which also have the concept of a weak reference, just like C++ has a weak_ptr, to explicitly limit this ownership. People claiming the GC takes care of ownership tend to run out of memory when they keep around unneeded references. 
The preprocessor is far too useful to do away with.
Yep, yesterday I suffered the pain of compiling Swift on my humble core-duo / 4GB. After two hours it was still compiling LLVM part. :(
This entire approach seems to be based on the assumption that you can combine projects on the source level while ignoring their build system. This is just not possible. A look into real world projects shows that almost all of them have autoconf or equivalent functionality (for example, to generate a `config.h`) and/or custom build steps (build executable to generate source to build into a target etc). In order to join these two projects you either need to rewrite the build system on one (or both) of them or make all build systems in the world follow the some universal convention, which does not exist and which would be equivalent in scope to rewriting the build system.
An earlier presentation on the build system part [can be found on this page](https://www.youtube.com/watch?v=KPi0AuVpxLI).
The "exceptions are for exceptional cases" is a hopeless mantra because: * it is open to interpretation (one persons exceptional case is another's normal case) * it is context-dependent (e.g. some timeout somewhere is always expected, whereas in some other situation, it is life-threatening). &gt;I also just hate the code that comes from using exceptions, it moves the error handling logic away from the main logic. And I like them exactly because of that! In a typical C codebase, error "handling" is so pervasive that one can hardly see the main logic. Handling is also quoted intentionally because rarely ever an error is handled, it is just being passed forward (which, incidentally, exceptions do automatically).
Well that's only D that we can talk about. C# has *special syntax* for extension methods, which is slightly different because it narrows down the range of possible searches - instead of searching for *all globals* (which C# doesn't have, at all), it would have to search all `static` classes having `static` methods where the first parameter is of matching type and has a `this` in front.
D and Rust have blazing-fast compilation.
Okay, is its source publicly available? Did OP look at that code or wrote his own game? The title says OP played M:tG, I don't see how that contributes to his programming skills.. 
Does moc help me embed lua?
Yes, I have posted the update to the blog post and did exactly what you suggest while also safeguarding against re-entrant events.
Step 1: Make the preprocessor useless Step 2: Get rid of the preprocessor
You can also wait until after the meeting, when trip reports would appear. Here are examples from after the last meeting in Oct 2015 in Kona: * by Bjarne https://isocpp.org/blog/2015/11/kona-standards-meeting-trip-report * by Herb http://herbsutter.com/2015/10/25/2568/ * by Botond Ballo (very extensive one) https://botondballo.wordpress.com/2015/11/09/trip-report-c-standards-meeting-in-kona-october-2015/ * by /u/STL https://www.reddit.com/r/cpp/comments/3q4agc/c17_progress_update_oct_2015/ These provides a good summary of what happened at the meeting and which papers were accepted or declined, and point out the most interesting ones. All these reports provide a bit different perspective, because it is absolutely impossible for any single person to attend all the sessions (there are several in parallel) and remember all the papers and discussions. Everyone focuses on his own area of competence/interest. 
&gt; Modules are THE #1 priority for C++. Or should be, at least.
Then I think we can safely say that OP has no experience in C++ whatsoever and should definitely not be working on a game in UE4. But that's just my opinion :)
&gt; Additionally, language-specific packaging system is just a wrong design. Until we get an OS agnostic packaging system that avoids having to redo packages for every single OS that the developer might want to use the package, language-specific packaging systems will always win in productivity and distribution.
Really, forget about C++ for now. Programming *is not* nearly like playing a game, particularly lower-level programming in C++. On the other hand once you grasp the concepts behind programming and get more used to how computer works behind the scenes, going down to C++ will be a lot easier than trying to learn it by yourself from the beginning. For resources on learning python, there are free online courses on Coursera and Udemy. There is also [Learn Python the Hard Way](http://learnpythonthehardway.org/book/) which is very good.
&gt; Visual Studio And what if you wouldn't use it? You will need a build system anyway. &gt; Obviously that can't work without having CMake installed, because it has a huge CMake file which executes very complex configuration and code generation steps. CMake file often quite small. Complex configuration? Maybe, but it lets you easy to link with libraries. And it will run just once to generate makefiles. &gt; find_package (Nameit REQUIRED) &gt; add_executable(app ${SOURCE_FILES} ${HEADER_FILES}) &gt; target_link_libraries(app Nameit glm ${ASSIMP_LIBRARIES}) That's all.
Yeah, they're not going to work like that. How the standard one works is as if a variable named that appears as the first line of the function body. 
So what is the proposed solution to package library X in language Y for: - Debian - Ubuntu - Aix - HP-UX - Windows - Mac OS X - iOS - Windows Phone - Android - iOS - zOS - Red-Hat - SuSE - Contiki - L4 - Arch - Mint - Gentoo - *BSD - Solaris - Iluminos - &lt;place favourite OS name here&gt; Without forcing developers to package it N times? 
I recommend you watch the builds video from LCA2016 that is currently on the front page of /r/cpp to see one solution. (caveat: the presenter is me)
Modules are coming. That doesn't mean people should start looking beyond. Various features for C++17 were in the minds of the cmomittee while they were working on features in C++14. Progress doesn't stop at the next increment.
Take a look at [yotta](https://github.com/armmbed/yotta) (while the docs and ecosystem focus on cross-compiling for ARM, its designed to be used for native compilation too).
What about pip, RubyGems, etc...? They're language-specific, are they not? I'm genuinely asking, since I'm not that familiar with them, but their design, to have one central official package repository for the language, seems to be very successful.
From the document, page 3: &gt; This document has settled on the preprocessor directive '#using' as its mechanism for using packages. We &gt; know that the C++ language is averse to adding new features to the preprocessor, so consider the directive &gt; as a straw-man for the purposes of exposition. For a discussion of the different syntax options, see Section &gt; 5
I have to disagree--it's exactly this kind of overload that means this has to be handled by more than one person. The committee is pretty good about rejecting papers/ideas that just don't fit. They do publish all the papers they receive, but that's in the interest of keeping the process open. Most of these are almost certain to be rejected--but it'll be done in an open, public process, not in secret. Also note that a fair number of these papers aren't proposals for additions to the language either. Some are just things like minutes of meetings of the various study groups. Others are specifically rejecting the idea of adding something to the language, such as: [SG5 is NOT proposing Transactional Memory for C++17](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0265r0.pdf).
yes
Sorry. `__FUNCTION__` sprung to mind as "thing that begins and ends with `__` that looks like it's from the same family as `__LINE__` but is (has to be...) implemented very differently" (which is probably why the standard went with `__func__`). It never occurred to me that any interaction with default arguments would be relevant. Though looking back, that does seem a bit odd, since that *is* the topic at hand.
Yes, I should have referred to that proposal. That approach was not adopted, but it was definitely part of the discussion. When I wrote my brief note I failed to find that reference (I don't know how I managed that; I think it was late), and I couldn't mention that proposal without a reference. Sorry.
**Company** ELI Beamlines **Type** Fulltime / Student jobs **Description** Control System Engineer. We're a building a physics facility ("CERN of laser physics") and developing the control system for this. Based on C++, Tango, some Python, Linux, MTCA, qt.. We're looking for people who are good in C++ and have some affinity with hardware. (Also, devops and machine safety / PLC programmers and someone good with databases). There is lots of exciting challenges, and different tasks - from algorithms to timing to data acquisition. **Location** Prague, Czech Republic (Working language English) **Remote** No. **Visa sponsorship** Possible **Miscellaneous** http://www.eli-beams.eu/wp-content/uploads/2011/07/Control_system_programmer_971.pdf ___ I also have a few student projects dealing with web programming / devop kind of work. Please, no PM / apply directly - mention control system team, even if your CV doesn't exactly match the official job description, it will be forwarded to me.
I am the author, I really hate that people don't see beyond the title and I wholeheartedly agree that there are enough use-cases to keep C++ around. If I didn't care about C++ I wouldn't have written about it.
Segmented memory support? Now!? That's pretty hilarious, even if it is (perfectly legitimately) needed by some obscure code in the Linux kernel.
Interesting. I think of the preprocessor more in terms of its similarities to templates.
Good with source control but will check out Cppcheck.
Have a major dependency with a GNU only library but if it ever works with clang I will try it out.
My current project us VC++ and GNU with visual studio and clion respectively. I am not sure if I have used gdb or lldb though. No profilers outside of what is in VS ultimate.
When you work with a library that used doxygen, how useful are the HTML pages?
CLion uses gdb, when you debug a program, go ahead and click the Debugger tab and GDB sub tab to drop to a gdb prompt.
Very! If you don't document your code, you might as well never have written it in the first place. Documentation basically explains how your code works, and having a tool to generate an easy-to-navigate page only makes it better, since you can focus on just reading the documentation without the code bloating up everything. 
Would it allow std::reference_wrapper to be more transparent by eliminating the need for get()?
Yes, I think Conan's approach seems more reasonable, although it can't be a standard way.
I got something for you to pull.
- Get a nice cup of your favourite beverage - Sort them out according to your interests - Print them out, copy them to your e-reader, tablet, laptop - Read them slowly during travels to work. The CppCon videos were worse, being only available on YouTube. 
JavaScript is very successful too. /s
&gt; Build/package/distribute one version of the product along with its dependencies (at a single version) for each platform. One big issue is that pretty much no OS works well with that. It tends to work OK, but in general * Windows will most likely load an incompatible DLL if the original is missing, possibly causing subtle bugs * The soname system on Linux is pretty broken, and FHS isn't really designed to support bundled private libraries. * I'll cry when a glibc exploit is found and every single application needs to patch their own version.
Yes: http://www.nongnu.org/libqtlua/
One problem with Cppcheck is that is is pretty slow. [PVS-Studio](http://www.viva64.com/en/d/0012/) is faster and more powerful but is not free. There is also [Clang-Tidy](http://clang.llvm.org/extra/clang-tidy/). 
It was denied in the past, but things change. I see enough people here that want this specific feature. Hell, I had the same prblem just a month ago. Some exemple implementations and suggestions from the community, and the mainline will accept it.
What papers did people find most interesting? My favorites so far: *string_span: bounds-safe views for sequences of characters* (spans are going to have big impacts on basically all c++ code, I think, and it is a well written paper), *Khronos's OpenCL SYCL to support Heterogeneous Devices for C++* (seems like a thoughtful paper on how to best integrate GPU programming into C++) , and *C++ Static Reflection via template pack expansion* (I do a lot of distributed programming, which means a lot of serialization, and so am excited for reflection).
&gt; Even more maddening is that 31,085 of those lines are in a single unreadably ugly shell script called configure. The idea is that the configure script performs approximately 200 automated tests, so that the user is not burdened with configuring libtool manually. This is a horribly bad idea, already much criticized back in the 1980s when it appeared, as it allows source code to pretend to be portable behind the veneer of the configure script, rather than actually having the quality of portability to begin with. It is a travesty that the configure idea survived -- [A generation lost in the bazaar](http://queue.acm.org/detail.cfm?id=2349257) There are a few things to hate about phk's classic rant but I think the spirit is pretty valid: in an ideal world, most of what build systems do can be entirely avoided, and to a large degree the typical BSD source tree is exemplary in that regard
&gt; Windows will most likely load an incompatible DLL if the original is missing By what mechanism? I have literally never seen somebody put 3rd-party libraries into the WinSxS cache. The only thing that ends up there are Microsoft binaries. If you're actually worried about that, you can use application manifests to tighten the control even further. &gt; FHS isn't really designed to support bundled private libraries Sure, but it works well enough, and using RPATH or other mechanisms like dlopen to get only your versions is a good-enough solution. The alternative (support all the versions) is a dependency nightmare. &gt; I'll cry when a glibc exploit is found and every single application needs to patch their own version. I've never had a need to distribute glibc, luckily. It's a stable ABI and doesn't suffer the same problems other 3rd-party stuff tends to.
Awesome, thank you.
That's why I hate when people write posts like "the Qt developers, **they** must the feature I want".
Could you make type A behave like types B, C, and D simultaneously (without inheriting), assuming B,C, and D were all otherwise unrelated types? (I'm also a bit confused).
Visual Studio users can just use Nuget. 
I don't follow, can you point me in the direction of some documentation? 
That doesn't mean anything (to me at least). Why would you say it?
There's the standard text: &gt; The function-local predefined variable `__func__` is defined as if a definition of the form &gt; &gt; static const char __func__[] = "function-name "; &gt; &gt; had been provided, where function-name is an implementation-defined string. It gives this example: struct S { S() : s(__func__) { } // OK const char* s; }; void f(const char* s = __func__); // error: __func__ is undeclared There's [this reference page](http://en.cppreference.com/w/cpp/preprocessor/replace): &gt; Note: in the scope of every function body, there is a special function-local predefined variable named `__func__` (since C++11), defined as a static character array holding the name of the function in implementation-defined format. It is not a preprocessor macro, but it is used together with `__FILE__` and `__LINE__`, e.g. by assert. It is also mentioned on [this page](http://en.cppreference.com/w/cpp/language/function). You might find [this Stack Overflow question](http://stackoverflow.com/questions/4384765/whats-the-difference-between-pretty-function-function-func) useful for `__func__` vs. `__FUNCTION__` vs. `__PRETTY_FUNCTION__`.
Given that I've heard some committee members (jokingly) characterize their role as "saying no to Bjarne", I'm pretty sure your suggested direction would have the opposite result.
You use exceptions poorly. You are part of the problem.
Thanks for the prompt reply! I thought you were referring to `source_location` when you said that it was defined in the first line of the function. I understand `__func__`, do you have a reference for `source_location`? **Edit:** I found the following which is pretty much as expected, all the magic is left to the compiler... http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4519.pdf 
According to the example at the end of their [paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0252r0.pdf) you can overload the operator.() on their return type, so yes.
Less than I was hoping for since the initial announcement made it sound like the CRT functions would now support a utf-8 locale, but proper support for utf-8 source files without gross hacks is nonetheless a nice step in the right direction.
If you are mediocre in C++ maybe you should concentrate on that before tackling something else. Try https://thenewboston.com/videos.php to get up to speed in C++. BTW win32 is on its last legs as a technology and is being replaced by WinRT which use XAML for its GUI component.
I cannot find any video related to win32. As you said, I scrolled all the way down to find the last lesson and it was about substrings or something. Not a single lesson about win32 in the vicinity either.
I've never seen significant projects with cmake files like that. CMake's own root CMakeLists.txt is almost 700 lines long.
Exceptions weren't used because compiler vendors didn't always support them and they bloat executable size. The latter was a problem as recently as the PS3. Exceptions might have more of a role in C++-based tools, but they still have little use in older game engines. Legacy code was built without any notion of "exception-safe" code and used alternate forms of error handling. Switching over to exceptions has little business value if it requires rewriting swaths of code while providing marginal improvements to a mature engine's existing error handling system.
You said you have mediocre skill in C++ so I directed you somewhere you could learn more about C++ programming. You have to learn to walk before you can run.
EBO will be in the next release (unless something significantly unexpected happens.)
Gcc doesnt even have -Weverything does it? Clang does though, and it does roll new flags into it.
Open-source alternative: http://librocket.com/ 
Ah, thanks for the quick clarification. I'm kinda sad they're not rolled into at least everything, but oh well...
What are you even trying to ask? Whatever the case, it's probably better suited to /r/cpp_questions.
&gt; GCC 6 now defaults to C++ 14. I always wondered why this wasn't the case. I'd prefer that by default it always used the latest version, unless I specifically ask for an old one. Not the other way around. This is especially useful for new programmers, when you're super advance and probably using fancy generators it doesn't matter. But the new guys writing hello world shouldn't need the overhead imho. 
Would it be a too stupid idea to set up a voting mechanism and list the papers according to how interesting/well-written they are?
What is the reasoning for that? Not breaking old builds? Stupid backwards compatibility. They should add a second flag for all missing warning, -Weverything-else
Yeah, I've read your earlier walkthrough summaries with interest and understand that it will be too daunting a task for you to do that again for this batch. Will keep an eye for your series start! :-)
That's what someone else said. They suggested: &gt; --WThisWillProbablyBreakYourCodeNextRelease
I upvoted both of you. I wish there were C++ constructs that could eliminate the preprocessor, but at the same time it's super useful.
I here you say that I should move even further away from work! ;-)
Ahhh, that makes more sense. Jobs + threads made me think you were asking about a threading implementation or library details. Sorry for the confusion. 
I would recommend against spending too much time actively learning OS specific APIs. It will pay off far more to get into a widely used crossplatform library like Qt.
I think they wanted to ensure that they didn't break all that code that used the old auto keyword 
&gt; try to use the same CMakeLists.txt for Linux, Windows, MacOS, Android and iOS Like that https://github.com/forexample/hunter-simple?
Yeah, I guess that makes sense. Although I still reckon that the default behaviour should be to use the new stuff and make it opt out or have warnings etc. My overall feeling is that, if you feel you really want the new compiler you should know that it comes with the 'new language' and you need to opt out. New code should be written in the new standard, unless you have a good reason not to (like compatibility as you mentioned). I feel the defaults should encompass the behaviours you want the most. I guess I prioritise the new stuff over the old, but if I had old incompatible code I wouldn't mind having to opt out of the new features.
I thought it was a reference to MtG being [turing complete](http://www.toothycat.net/~hologram/Turing/HowItWorks.html), but I'm not sure.
&gt; Either way, that has changed recently with all the points of failure on this generation. I don't understand what you're saying here.
CMake is the least horrible of many horrible options.
Is it just me or ... what's the point of this?
Yes, completely forgot about add. My bad. This will most likely turn out into by-index solution.
Yeah about that constructor parameters deduction... How does that work? Any level of detail is great.
I'm not sure what kind of answer you are expecting to this question beyond "because nobody that is hiring for a remote position has posted in that particular thread".
C++ has an advantage over other languages mostly in fields that benefit from people being on-site. Working with embedded devices is a pain if you don't have the device at your desk, and shipping them around to handle remote workers isn't convenient. It's also relatively prevalent among old companies, which are less open to remote workers.
I only know of one place that at least used to hire remotes regularly. Interactive Intelligence. Don't consider this an endorsement of the place. I no longer work there. But they exist...and probably will a while longer.
I did not, but I have a feeling I will learn about that lol 
To the best of my knowledge, nobody has even proposed anything for a future version of C++ that would even begin to replace templates. The number of files to use mostly comes down to a question of keeping development reasonable. Most people don't like trying to deal with editing files that are too big. Likewise, if a file gets really big, recompiling the whole thing gets slow. Breaking it up into multiple small files helps keep recompilation time down, by only re-compiling the parts you've really changed. Static vs. dynamic libraries: depends heavily upon whether your code can benefit from link-time code-generation (aka. link-time optimization). This can be done for code from a static library, but not (at least normally) code that's in a dynamic library.
First, before you write your own library, check out what is available in the C++ standard library and boost (www.boost.org). It looks like you are doing stuff with probability so check out http://www.boost.org/doc/libs/1_60_0/libs/math/doc/html/dist.html to make sure it is not already done. 1. Use templates. The Concepts that people are talking about is based on templates. 2. If you are using templates a lot, why not just use a .h (or .hpp) header file. Header only libraries are actually the easiest for other people to use. If you just have a single .cpp file, I personally would not bother to try to make a library and instead just tell the user to incorporate probability.cpp into your build. Pugixml (http://pugixml.org/docs/quickstart.html) does this. 3. For small libraries, I prefer header-only and if not possible statically linked. Especially, if you are doing a lot of math, the header-only may provide some performance improvement as the compiler can better inline stuff. 
Sorry my bad. I was thinking boost::static_array was something like std::unique_ptr&lt;T[]&gt;. I should have read the boost document first.
Talk to the hiring manager, you got people beggin' for a job!
I've managed to get [OpenCppCoverage](https://opencppcoverage.codeplex.com/) working in my project, and it's useful enough.
If there's no clear ownership then there's no clear design. This sounds improbably silly, otherwise someone needs to (re)familiarize theirself with FSMs. ;-]
Even if you're not a student yourself - help us spread the word! This program is a really great, life-altering experience for young C++ hackers.
Protip: The CppCon videos are also available on Channel 9 where you can download videos for offline viewing.
Seems like it just iterates over every registered type (statically) and tries to create the type successfully. auto create_successful_impl__() const { auto&amp;&amp; dependency = binder::resolve&lt;T, TName&gt;((injector*)this); using dependency_t = aux::remove_reference_t&lt;decltype(dependency)&gt;; using ctor_t = typename type_traits::ctor_traits__&lt;typename dependency_t::given, T&gt;::type; using provider_t = successful::provider&lt;ctor_t, injector&gt;; using wrapper_t = decltype(static_cast&lt;dependency__&lt;dependency_t&gt;&amp;&amp;&gt;(dependency).template create&lt;T, TName&gt;(provider_t{this})); using create_t = referable_t&lt;T, dependency__&lt;dependency_t&gt;&gt;; return successful::wrapper&lt;create_t, wrapper_t&gt;{ static_cast&lt;dependency__&lt;dependency_t&gt;&amp;&amp;&gt;(dependency).template create&lt;T, TName&gt;(provider_t{this})}; } Edit: I am actually unsure now...
Ooh, looks nice.
Exceptions are now being used when interacting with the system APIs on some consoles, mostly in the areas that can fail; i.e. Online, Save Load, etc. 
If you decide to go ahead with C++, and think it's a good idea to do anything ambitious with it before you have a few years of solid experience and if you naturally end up hurting yourself badly, please don't make it your personal holy crusade to bash C++ everywhere on the internet... The language is not optimized to be beginner friendly, it's optimized for professionals to write extremely complex and efficient systems after they've dedicated many years of their lives to learn the language.
That's great news, thank you!
Of the library? It basically provides allocators. From the readme: The C++ STL allocator model has various flaws. For example, they are fixed to a certain type, because they are almost necessarily required to be templates. So you can't easily share a single allocator for multiple types. In addition, you can only get a copy from the containers and not the original allocator object. At least with C++11 they are allowed to be stateful and so can be made object not instance based. But still, the model has many flaws. Over the course of the years many solutions have been proposed. for example EASTL. This library is another. But instead of trying to change the STL, it works with the current implementation. Features: New allocator concepts: * a `RawAllocator` that is similar to an `Allocator` but easier to use and write * a `BlockAllocator` that is an allocator for huge memory blocks Several implementations: * `heap_/malloc_/new_allocator` * virtual memory allocators * allocator using a static memory block located on the stack * memory stack * different memory pools * a portable, improved `alloca()` in the form of `temporary_allocator` Adapters, wrappers and storage classes: * incredible powerful `allocator_traits` allowing `Allocator`s as `RawAllocator`s * `std_allocator` to make a `RawAllocator` an `Allocator` again * adapters for the memory resource TS * `allocator_deleter` classes for smart pointers * (optionally type-erased) `allocator_reference` and other storage classes * memory tracking wrapper In addition: * container node size debuggers that obtain information about the node size of an STL container at compile-time to specify node sizes for pools * debugging options for leak checking, double-free checks or buffer overflows * customizable error handling routines that can work with exceptions disabled * everything except the STL adapters works on a freestanding environment 
Are they? I was disappointed that after the first set of 4 videos at Channel 9, they only uploaded the remaining ones to YouTube, but kept mentioning Channel 9 on the posts. I even complained about it on isocpp forums. I am avid channel 9 user.
If you don't mind consultancy work and are well versed in Qt then you could give KDAB a try.
Jumpshot is very far from pretty, but I've used in the past with fairly large traces. Works decent, but interested to see if there are any other replies with better alternatives.
does it also support dynamic injection ? (e.g. run-time injection of classes provided in plug-ins ?)
Code, code and code. Practice, practice and practice. I'm coding C++ for a living for a few years now and cppreference.com has always a privileged position in my browser tabs. I see this as usual, as only very few people can memorize all the parts of the STL they'll ever need. When it comes to design and structure, its not too different. Though, you can try to learn all the patterns by heart, actually applying them requires practice. Lots of practice.
Not at all. The design can be crystal clear, but onwership must be shared. There are many cases where that is necessary. 
I taught myself C# a couple of years ago while building a 100K line project for work. I lived and died by Google and StackOverflow daily for over a year until I got enough of the framework put together that the code starting feeling routine. But even still, anything I code that deviates outside of what I have implemented, I'm back on Google researching, double checking things, or refreshing my memory. It takes many years to master any programming language, and then you will only master the areas that you focus on. It's normal to constantly refer to online help and tutorials while learning, or anytime you venture into new territory.
didn't somebody ran a search on google code at the time and found that absolutely zero code was using "auto" ?
&gt; Have they changed their version number policy? basically, listen to /u/STL ~~they shifted all the numbers to &lt;&lt; GCC 5 is somewhat what 4.10 would have been, 5.1 -&gt; 4.10.1, and GCC 6 is somewhat what 4.11 would have been.~~
If you are interested in practicing C++, and getting some feedback about your coding technique, checkout: http://exercism.io/ The site provides programming exercises that you can download. You then write the program according to the goal of each exercise, then upload your program to be tested. An automated system runs your program and verifies the functionality. Once it is functional, your code gets posted to a forum where other programmers can review and critique it. You can then see code that others have submitted for the same exercise, make iterative improvements on your submission, or fetch the next exercise. The site supports like 30 different programming languages, so you can also use it to learn other languages.
&gt; make multiple programs about arrays until I feel 100% about arrays this is pointless : in five years you will have forgotten some things anyway whether you want it or not. Better have a broad understanding and "feeling" of the language, and then use the docs for the specific small details.
I just scrolled a bit the list and found an interesting [natural language range generators syntax](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0268r0.pdf) proposal.
I think that the easiest way to come up with a program idea is to look for a hobby you like, and ask yourself the question "what could be done *better*" ? 
All three major implementations use a small string optimisation, so that anything less than a certain size (for example, 22 chars on libc++ 64-bit) doesn't trigger an allocation. If you have an integer with more than 22 digits, I'd imagine `stoi()` is going to complain anyway. It's not quite as good as having overloads of `stoi()` and friends which take `string_view`, but it shouldn't be a show-stopper.
I think part of the reason C++0x Concept got dropped is because it is too huge and complex. Concept TS set out to be the answer to the huge and complex part with an incremental approach instead. If this doesn't work, I guess Concept will never be part of C++, given it has been over a decade since it was started. One step at a time.
I love you. No homo. /favoritesfolder
I love you too. No homo. /slightlycreepyfolder
CMakeLists.txt's might be horrible to read and hard to debug, but at least they're readable and debuggable. The same can't be said about Makefiles...
Omg no u. Stahp. /rarepepefolder
That's the wrong way of reasoning. Don't specify the intent of a program around its requirements. As others have already stated multiple times: Go through your hobbies and interests and look for places where a C++ program you write would serve a specific purpose. That's the intent of the program. When you're done with that, think about the design, structure and requirements. Write them down (notes, sketches, pseudo code). When you feel satisfied with the design, start coding. And always remember: The initial design, structure and technical requirements you specified before should always be subject to change. Think critical about your own reasoning. Do research on the pros and cons whenever you have multiple choices on how to fulfill a specific technical detail. With time (i.e. years) you get a feeling for the language, its features, awesomeness and corners you should avoid by all means.
&gt; And penalizes users by having a package manager for every single language, so they loose in productivity. You should think not only about user but also about library writer. It should be very easy to package library.
Have you spoken to Hartmut? He'd be thrilled to see this blog post.
&gt; Don't expect miracles though...the syntax is terrible Well, there is hope: look at Concepts Lite. They look like regular functions for a relevant amount of cases.
Yes, it does. di::bind&lt;Interface&gt;.to([&amp;](const auto&amp; injector) -&gt; Interface&amp; { switch(some_runtime_value) { case IMPLEMENTATION1: return injector.create&lt;Implementation1&amp;&gt;(); case IMPLEMENTATION2: return injector.create&lt;Implementation2&amp;&gt;(); throw std::runtime_error("Interface not bound"); } ) More examples here. * http://boost-experimental.github.io/di/tutorial/index.html#2-basic-first-steps-with-bindings * http://boost-experimental.github.io/di/examples/index.html#dynamic-bindings * http://boost-experimental.github.io/di/extensions/index.html#xml-injection
I have just updated design documentation which explains how injections and constructor deduction is done, so please take a look. * http://boost-experimental.github.io/di/overview/index.html#design Basic idea is quite simple... struct any_type { template&lt;class T&gt; operator T() { return injector.create&lt;T&gt;(); } }; for (auto i = BOOST_DI_CFG_CTOR_LIMIT_SIZE; i &gt;= 0; --i) { if (is_constructible&lt;T, any_type...&gt;()) { // T(...) T(any_type....); } } Please, also notice that Boost.DI can inject using uniform/aggregate or direct initialization, for example. struct T { int&amp; a; double b; }; auto i = 42; auto injector = di::make_injector( di::bind&lt;int&gt;.to(i), di::bind&lt;double&gt;.to(87.0) ); injector.create&lt;T&gt;(); // will create T{i, 87.0}; This is done via.... for (auto i = BOOST_DI_CFG_CTOR_LIMIT_SIZE; i &gt;= 0; --i) { if (is_braces_constructible&lt;T, any_type...&gt;()) { // T{...} T{any_type....}; } } 
I was wondering that beacuse the telephone field doesnt allow the country number (that is supposed to have + in front), is that going to be a problem? EDIT: I meant that it doesnt allow the '+' itself
I use this to resolve name resolution conflicts: namespace X { class SomeData { }; class ConflictingNames { ConflictingNames(SomeData d); // will not compile due to accessor, below const SomeData&amp; SomeData(); // accessor }; } The moment you add the accessor, the constructor no longer compiles, because there are conflicting names. To solve, you need to use one of: `ConflictingNames(X::SomeData d)` (I use this) or `ConflictingNames(class SomeData d)`. Outside of conflicts with ADL hijacking in client code, this is also a valid reason to prefix with the namespace (but outside of the rare conflicts within your own namespace, you probably should not use it: it will just add more (unnecessary) code to maintain.
Of course, and that's the typical strategy because one still needs to design to the lowest common denominator. But, this *could* be the beginning of a change. 
That is funny. 
I finally got around to building this today. I'm really impressed with these tools. For anyone still reading: I ended up using the most recent commits for both Templight and Clang/LLVM, so I had to [tweak the Clang patch](https://github.com/mikael-s-persson/templight/issues/29#issuecomment-188250611) a bit. I'm on Windows, and templight-cl seems to be working perfectly. Templar is a real pain to build on Windows right now, because graphviz (one of a few dependencies) is having trouble keeping its [main distribution website](https://www.graphviz.org) online. There isn't a graphviz build that's ABI-compatible with my setup elsewhere on the web. I do believe they host MinGW and MSVC builds on their website, however. You don't want to build graphviz from source on Windows, because you're going to do a lot of work building *its* dependencies manually. I also haven't found a Windows package manager that covers all the bases. After a few hours of trying to build Templar on Windows, I switched to Lubuntu and built it in a few minutes with apt-get at my disposal. Note that qmake isn't used anymore with Templar's feature/templight2 branch. It's been ported to cmake. I can confirm that Templar builds with Qt5. I was not able to build Templar with a recent build of yaml-cpp. I didn't look into the errors very deeply, but it looked like the code had simply fallen behind. I didn't have any issues after excluding this. I still haven't tried the Templight "debugger". Edit: grammar, links
libc++ on 64-bit can hold up to 22 ~~23~~ chars, plus '\0' and it is 24 bytes big. std::string from Visual Studio 2015 is 32 bytes big and can only hold up to 15 chars (plus '\0') without any memory allocation.
Currently a of libraries use [double-conversion](https://github.com/google/double-conversion) from v8 to convert from double (and float) to string and vice-versa. 
No, I didn't. But he 'starred' the GitHub-repo of HPX-demos. This was before I published the article. Later I added a link to the 'readme'. Actually, I've only planned to publish the sources but later came to the conclusion that'll be of some help to others if I document a few important HPX aspects (how to write an 'action', what's a component, why do we need a 'stub' etc.). Of course, many other parts of HPX were not mentioned, like AGAS, LCOs, 'High-Level Parallel Facilities' etc. My journey with HPX was full of land-mines because I haven't coded professionally in C++ since 2008. So you can imagine how *exceptional* the own experience can be when one combines nice features from C++11/14 *plus* HPX &amp; Boost. :) Best regards,
Try Paraver. It has a file based format and can handle millions of events. Plus it can compute various statistics.
Wow, thanks! You didn't have to do that, but the technique is valuable. 
Wow :) I'll have to look much further into hunter to be able to say anything more intelligent than just wow. Does this really work for doing real stuff? If so, why isn't everyone talking about this?
Please don't unless it's absolutely necessary and there's nothing else that does it already (unlikely)
I can agree with that. In most use-cases for templates the syntax is going to be nicer in C++17. If you got to do anything further than the basics though it's still going to be ugly.
I had never thought about the nullptr semantics for these inheritance static_cast. I tend to mostly use static_cast&lt;T&amp;&gt; for these use cases, instead of sticking with pointers. This should allow the compiler to optimize away any nullptr test as the reference points to something.
Fun fact: a static_cast isn't even always a compile-time offset or a bitwise no-op for null. You can implicitly convert D * to B * (when the base is accessible and unambiguous, of course), so you can static_cast in that direction too, even for a virtual base class. But a virtual base requires a run-time offset, which you have to look up through the vptr. Extra super fun bonus round for implementers: when converting weak_ptr&lt;D&gt; to weak_ptr&lt;B&gt;, the object might be dead (that's the whole point of weak_ptr), so you have to internally lock to shared_ptr before performing the pointer conversion - and nothing in the Standard tells you to do so. (I learned this from hearing about a bugfix in Boost.)
A reference can point to nullptr which is fun to debug. const MyType&amp; getMyType() const { return *this-&gt;pointerToMyTypeThatIsNullptr; } and now your reference points at nullptr.
Need for `.get()` or something similar would still be there: if contained type happens to declare same name as wrapper, you would not be able to access it. In standard library it could be solved by using reserved names (`foo.__rebind()` instead of `foo.rebind()`) as wrappers members, but user code would have to take into account. Another (potential) problem is name lookup for member operator.
Actually, libc++ is 22 chars; one of them is the "I am not allocating memory right now" marker.
Well, come say hi on IRC. #ste||ar on Freenode.
You're saying that UB can't exist because it's UB.
The remaining videos had been uploaded to Channel9.
Yes are are right, I confused it with Folly string. https://stackoverflow.com/questions/21694302/what-are-the-mechanics-of-short-string-optimization-in-libc
/u/bames53 [reported this](https://www.reddit.com/r/cpp/comments/3nzwtf/cppcon_2015_whats_new_in_visual_c_2015_and_future/cvtjiys) 4 months ago, which I filed as VSO#152122 "C1XX mishandles UTF-8-without-BOM source files", which has now been resolved as fixed. Thanks again for the report.
More importantly, the whole program has been invalid since long before you created the reference. In fact this isn't even a sequential problem where you've deref'd a null pointer and now you're in trouble, spec-wise the existence of an UB in the program make it invalid even if the UB isn't actually encountered at runtime and [modern compilers will use that fact](https://blogs.msdn.microsoft.com/oldnewthing/20140627-00/?p=633/) assuming that the program is valid and thus codepaths which could somehow invoke an UB can't ever be taken.
No, I'm saying according to the standard by definition there is no such thing as a null reference.
Hopefully somebody isn't doing a million derived-to-base conversions per second.
configure scripts typically do more than just find dependencies. Some examples: * enable options based on hardware or software capability This is the killer I think. Your language shouldn't do this. * generate source based on information obtained E.g. I have a file containing a release identifier the identifier is used in multiple languages so having a version.h would mean you have to repeat yourself in java or whaterer else your using. * set the install location (we could leave that to a package manager or build system e.g. make DESTDIR=xx install) There are probably a few more.
QT 4lyfe 
I've had to bundle libstdc++ in order to use c++11 on old platforms. It works but I'm still hoping for a better solution. See http://stackoverflow.com/questions/25979778/forcing-or-preventing-use-of-a-particular-minor-version-of-libstdc
You're clearly more optimistic than I...
&gt; the compiler can optimize the possibility out The difference between *can* and *will* is very important here.
Haha, that is one funny statement. :-) But yes, hitting this particular UB is a way to tell oneself "hi dumbass!"
Also don't forget (since my comments there get stuck in 'awaiting moderation' forever since the new blog software) that sizeof(void *) != sizeof(nullptr_t) != sizeof(int *). Thankfully Harvard architecture systems are rare in practice.
&gt; &gt; &gt; Really? For GUI apps and all the other stuff going on in Qt, a different type of cast is supposed to be noticeably faster? I seriously doubt it. I'd much more believe that way back many applications were simply not built with RTTI support making dynamic_cast unusable. I had some doubt so I ran a small benchmark on my software : Scenario::ScenarioModel* obj; { auto t1 = std::chrono::steady_clock::now(); for(int i = 0; i &lt; 10000000; i++) { obj = qobject_cast&lt;Scenario::ScenarioModel*&gt;(iscore_cst.parent()); } auto t2 = std::chrono::steady_clock::now(); qDebug() &lt;&lt; std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(t2 - t1).count(); } { auto t1 = std::chrono::steady_clock::now(); for(int i = 0; i &lt; 10000000; i++) { obj = dynamic_cast&lt;Scenario::ScenarioModel*&gt;(iscore_cst.parent()); } auto t2 = std::chrono::steady_clock::now(); qDebug() &lt;&lt; std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(t2 - t1).count(); } The times I get with clang 3.7 at -O0 are : * qobject_cast, bad cast ~ 236 ms * dynamic_cast, bad cast ~ 1126 ms * qobject_cast, correct cast ~ 176 ms * dynamic cast, correct cast ~ 240 ms At -O3 -march=native -flto : * qobject_cast, bad cast ~ 111 ms * dynamic_cast, bad cast ~ 0 ms * qobject_cast, correct cast ~ 54 ms * dynamic cast, correct cast ~ 0 ms so, the answer is : it depends :D 
I have been using boost.pool which works well with std containers as well as boost containers, including the boost.multi_index_container, which I use a lot. If your system works with those containers, it would be great to see some performance comparisons. The extended functionality of your library is also cool, and may come in handy down the road, especially the "virtual allocator" which is something that could help me improve the my product scalability. 
1. Templates aren't going anywhere in the foreseeable future, and I have no idea what alternatives to templates you heard of. They may be necessary less often, now that we have `constexpr`, but `constexpr` isn't by far as powerful as actual templates. 2. It's up to you. If you want it to be closed-source, you're going to have to compile it, but, on the other hand, template-reliant libraries are only really practical as header-only libraries. 3. This isn't a C++-specific question per se, but important to know either way. Static linking is done right after the individual compilation of the translation units (I recommend you google for 'C/C++ build process' or something like that for details), and involves merging several files into a single binary file (your final .exe program). On the other hand, Dynamic linking is a platform specific feature provided by most popular operating systems, to allow binding of function calls at runtime, way after the build process. This means that dynamic linking is sort of an OS-provided binary API, that allows you to call into code that lives in separate binary files (as opposed to only running code that's inside your .exe file). For example, Windows has .dll files, which are kinda like an .exe, but don't have a so-called 'entry point' (a location in the code to start executing from), so you can't double-click them to run them. They only serve as containers for functions, and exist for the sole purpose of being dynamically linked to from actual programs (.exe files), or other .dlls. There are many pros and cons to dynamic vs. static linking, like binary size, performance, software versioning and distribution, memory usage, portability (remember, each OS has its own way to link dynamically, whereas static linking is the similar across platforms) etc. Templates instantiated across dynamic boundaries are handled in implementation-specific ways, so they tend not to always obey the normal rules of dynamic linking. As an aside, on Linux, dynamically linked libraries generally have the .so extension ('Shared Object file'). Also note that dynamic linking also involves the static linking of 'stubs' of the external functions that are going to get bound, so the two aren't mutually exclusive, or opposed to each other. They're rather complementary. Word of warning: templates are complicated, and TMP is hard to get right. Practice makes perfect, so don't be afraid to experiment, but prepare for lots of complexity and edge cases whenever you try something fancy. For example, this is unsafe, if `T` happens to be a floating point type: template&lt;typename T&gt; bool areEqual(T const&amp; a, T const&amp; b) { return a == b; } As for best practices, Scott Meyers' books are the best source of best practices, followed by Herb Sutter's blog. Generally, prefer C++ best practices over C's because, despite the commonalities, they are intended to be used very differently.
Thanks for your updates.
Useless in my opinion. But thanks for trying.
I do understand your point, but we have to pay us and our bills somehow. If you buy a Coati license and you experience problems, then I'm gonna help you solve them. I'd rather help a paying customer than a free user. And you can still get your license refunded if you are unhappy.
You can disconnect each view from the main window and put them on separate screens.
&gt; The difference between can and will is very important here. Yes and no, the problem is it's a superposition state, you can only know where you stand for not just a specific compiler version but a specific compiler version on a specific revision of the code. A method getting below some inline threshold might be sufficient to cascade in an optimisation eliding whatever you've been doing due to an UB. 
Totally understandable, but why not something like what [CppDepend](http://www.cppdepend.com/) does, with a limited-time trial, or otherwise limited feature set? And, like you said: paid customers get support. You have to pay your bills, but those of us in corporate environments can't get management buy-off on just toy demos. The best developer tools tend to have feature-full demos and limited time usage, rather than the opposite. 
Mine too :p
reminds me of using smalltalk
[Hunter](https://github.com/ruslo/hunter/) has been mentioned on /r/cpp. The list of packages is growing – [58 so far](https://github.com/ruslo/hunter/wiki), with [WTL (Windows Template Library)](https://github.com/ruslo/hunter/wiki/pkg.wtl) being added three days ago.
Not if you use extra hardware that you have to synchronise with. Lets take the example of the x-ray scanner. In your normal code an exception happens: Is the x-ray on or off? You don't know. Are the timers that run in the background off? you don't know. What if an interrupt happens in your exception routine? and turns on something that you already went past. What if while you are in the exception routine, you blow past a watchdog timer? There are thousands of things when dealing with hardware that require you to have explicit control over your application flow and having an exception skip over the stack is usually a bad bad idea that will give you headaches.
+1 for the Linux support
Why did you choose antergos linux? 
I don't get why you need to access runtime information for a static cast from D * to B *. Even if B is virtual, the memory layout of D is statically chosen by the compiler, including the relative position of its B part. So the cast from D * to B * should still be adding some compiler constant offset (in the non nullptr case).
Because I wanted to try an arch distro again, but I can't remember how to set up a filesystem on the command line for the life of me.
If you have nothing to stop 1 install working N times, then why would anyone buy the $100 license? What stops an individual from getting a personal copy and then installing it on 500 developer machines? If you distrust your customers enough to believe they'd circumvent timed trials, then you have to believe they'd do multiple installs. After all, it's even easier. As for #2, is that based on any kind of worry you've actually heard from customers, or is it just something you came up with? Look at the business models of nearly every successful developer tool: they're free trial and then licensed. I've never heard anyone express concern that ReSharper was going to steal their code. 
Yes, I am. And I'm still awake for a little to cover questions. We are based in Austria.
Yes you are right with the multiple installs, we still might change to timed trials for the reasons you are mentioning. We did it this way, because it was easier mostly. And #2 is based on worries of developers that we actually heard pretty early in the process.
I think I have the same debugger.
Nice that they are finally there, but they weren't when I cared to watch them.
&gt; Does this really work for doing real stuff? Define "real" stuff. I've submitted https://github.com/ruslo/weather to AppStore as a PoC. Also there is experimental https://github.com/headupinclouds/gatherer project which works with camera and OpenGL (ES). Has OpenCV and Qt "monsters" as dependencies. Tested mostly on iOS/Android/OSX but should work on Linux/Windows too.
Is there any limit to the size of a code base that this tool can handle? 
*Anything* can happen if UB is invoked, so "don't exist" means "don't exist in a well-defined program," ofc.
Can confirm. Students get a lot out of this.
I'm unsure if there are any similar frameworks out there for cpp, but at work we use a c# lib called moq to unit test things with components out of our control. It basically allows us to set up "when x is called return y". You have to write your components in a way that's friendly to IOC to really be able to use it correctly, but the core principal is simple: feed it fake data and test it that way. 
I like the concept. I use pretty much similar strategy to emulate 16-bit floats (half floats). Just a couple of things: The way you test the endianness is problematic, because accessing an element in a `union` other than the last one written could lead to undefined behaviour. You should also consider making the endianness test a `constexpr` function and select the swap and pass-through function at compile time using `std::enable_if`.
Thanks for the feedback-- I'm not sure I agree with the endianness test being problematic? Considering I'm specifying the data types in the union as "PODs", my assumption is that they'll be occupying the same memory space and thus this test should be safe? As for the `constexpr`, I like that idea; I'm not 100% familiar with all the new features of C++ since C++98, but this one sounds intriguing. Since I do want to keep compatibility with C++98, I'd likely make that test conditional on whatever macro is set up to check for C++11 and `constexpr` support though. 
googlemock, it's what I'm integrating into stuff at work right now so we don't have to call dibs on a single unit between 5 people before running a 10-30 minute test suite. Unfortunately, getting the dependency injection is a bit of a PITA, requring you either template classes or use inheritance so the mock object can be used. To expand on unit testing, you don't want to necessarily mock up the entire sequence of setting up the hardware for each unit test, you just assume the hardware is in a state to exercise the unit and tell it what comes back when you call X with parameter Z.
&gt; I'm not sure I agree with the endianness test being problematic? Considering I'm specifying the data types in the union as "PODs", my assumption is that they'll be occupying the same memory space and thus this test should be safe? As far as I understand the standards, you can only get portable and predictable behaviour if you read from the current "active" member of a union. See the [Comment section of this doc](https://msdn.microsoft.com/en-us/library/5dxy4b7b%28v=vs.90%29.aspx). You could try something like this instead (not tested): constexpr char* S = "\1\2"; constexpr uint16_t E = static_cast&lt;uint16_t&gt;(S[0] | (S[1] &lt;&lt; 8)); if (E == 0x0201) {/*machine is little endian*/} Can use `const` instead of `constexpr` if C++98 compatibility is required.
That's what I thought initially as well, but after reading the comments here I did some research and found a page that explains it quite nicely. http://www.phpcompiler.org/articles/virtualinheritance.html
This is a vague request – Boost is a rather large _collection_ of libraries, so "Boost book" is about as wide an umbrella as "tools book".
Thanks. The fact that only a few videos originally made it to Channel9 came to our attention (the C++ team) a bit late. But once we learned about the situation, we comminucated with the logistics team to have all the videos, as in the past, available on Channel9. Remember, this was a busy period (CppCon, Guidelines, C++ meetings in Kona, LLVM conf, upcoming Dev14U1) and unfortunately, some things went through the crack. Fortunately, we have some measure in place to ensure we don't have a repeat. If you notice anything like this again, feel free to send us an email. You can reach me at my initials at microsoft.com. I hope your enjoyed the videos you cared about.
Yeah, that was not intended. We care about the entire C++ community, without exception, whether you use Visual C++ or not.
&gt; I'm in a position where it will be a long time before I can use of [C++11 features] D: D: D: D: D:
I've used something similar for C# - [Code Connect](http://codeconnect.io/) - when starting work on an existing codebase. It's been really useful, especially in quickly figuring out how functions interact. If you want a taste of a similar navigation tool and use C# elsewhere, you can give that a shot for free. It could give you a good basis for what Coati will be like for C++.
You're not getting downvoted for not being as smart or for not understanding everything, you're getting downvoted because your comment was useless and added nothing to the discussion
I work mostly with Java and .NET nowadays, but Visual C++ is my go to compiler for when I need a bit of C++ refresh. :)
My only comment: why the necessary 2 includes before yours? If they are necessary and in that order, just do it your header.
You could argue that for C and C++ a package manager is effectively for native code and so is potentially more general purpose. The syntax within C++ must be langage specific but the package manager itself need not be. I think I'd rather a compiler used an API to interact with an external one rather than implement it itself. If you are distributing source code in a specific language or byte code for a specific VM you can't help but be "per language". Any attempt to generalise will come up against barriers. Its not impossible but it is a somewhat orthogonal problem to developing the language itself. 
Coati is based on Qt as well, so there's no problem analysing Qt code, we do it ourselves. The analysis works on the original files, before they were processed with moc. But the analysis does not yet support the SIGNAL &amp; SLOT stuff, so you can't see which slots are called. We had no time to look into it so far, I filed a bug: https://github.com/CoatiSoftware/CoatiBugTracker/issues/28
You can't use reinterpret_cast with constexpr though, that's explicitly forbidden. In fact, inspecting the object representation in constexpr functions is intentionally not possible.
But, I seem to recall Herb Sutter mentioning it as **The Most Important C++ book** in [CppCon 2014](https://www.youtube.com/watch?v=xnqTKD8uD64&amp;feature=youtu.be&amp;t=5m40s)
A function that directly reads or writes to external hardware can't be unit tested, so you need some way of rerouting these calls during testing. This basic idea goes under the heading "dependency injection". The most obvious solution would be to use a mock object: you have an object which is an abstraction of the physical device, and you pass this object into the function you wish to test as one of its input parameters. In real use, you pass in an object which actually calls the hardware; in testing you pass in an object which generates test outputs and logs interactions. You have two options to implement this: you can use use inheritance so that the real object and mock object have the same interface, or you can use templates. Inheritance has the advantage that the object gets a clearly defined interface, but it might cause a performance penalty (in both real use and in testing). 
Thanks /u/egraether. I've added the log files in that issue.
I wasn't suggesting otherwise. I was suggesting using the reinterpret_cast as /u/NasenSpray has done in [this post](https://www.reddit.com/r/cpp/comments/47e9e2/endian_template_c_work_with_endian_types_in_c/d0cx0yh).
Thank you, we will look into this! I keep you updated on the bugtracker. We just publicly released Coati yesterday, there are still some problems we need to iron out unfortunately.
Developer here. Good point. Maybe it was not the best decision to limit the functionality of the trail version. We may look into changing that in the future, but that's how it is right now. Nevertheless, if you want to see Coati applied to a real project, check out this [video]( https://www.youtube.com/watch?v=QpujaFj4NkM )!
keep us updated ;)
This is C++, _somebody_ is ;)
The only way to create a null reference is to dereference a nullptr. That is, you must run into UB _before_ creating any null reference. The moment you run into UB your whole program is invalid. Therefore, null references doesn't exist in _valid C++_. The standard tells you both thing. It tells you what valid C++ is (no null references), and also what isn't valid C++ (dereferencing a null pointer). If there is a way to create a null reference that doesn't involve any other form of UB you basically found a bug in the standard and should fill an issue (which is basically a bug report).
I wish there were a version `__func__` where the string contents are specified as well, rather than "implementation defined". Right now, it's mostly a debugging hack.
You can mock the underlying hardware (as others have said: googlemock or whatever), but for this kind of testing, you really, **really** want to test against the actual hardware in a development environment (it looks like you call this compile-time testing?). I say that because there is always a difference between the hardware, it's spec, and dev team understanding of what the spec is. So avoid it. Sure, do unit-tests, but synthetic tests against the real target are of much, **much** bigger value.
Yes, testing with the hardware attached is not a unit testing. I recommend avoiding mocks. Write the code, so there is a lot of value-semantic stuff going on: you have pure functions that take and return values. Then just write tests that check the returned values.
&gt; If your still following me, how do you test these types of functions? You hide the device API behind an abstraction layer, then write an interface for the abstraction layer. Then, you write your code against that interface, not against the actual API. Then, you mock the API implementation with recorded responses and use the mock implementation to test: Original code: namespace your_code { // you want to test your_class for it's use of external_api_1 struct your_class { int do_things() { return external_api_1() + 24; } }; } New code with abstraction layer: struct external_api { api_1() { return external_api_1(); } }; namespace your_code { struct your_class { external_api &amp;api_; public: your_class(external_api&amp; api) : api_(api){} int do_things() { return api_.api1() + 24; } }; } New code with an interface: struct generic_api { virtual api_1() = 0; }; struct external_api : generic_api { api_1() overrides { return external_api_1(); } }; namespace your_code { struct your_class { generic_api &amp;api_; public: your_class(generic_api&amp; api) : api_(api){} int do_things() { return api_.api1() + 24; } }; } Now, if you run external_api_1(), you can take it's result and use it as such: struct mock_api1 : generic_api { api_1() overrides { return stored_result; } }; You can now call your_class APIs injecting mock_api1 as a dependency, into it. Other answers mention mocking libraries; These would simply allow you to add stored results easier into mock_api_1.
C++ Template Metaprogramming: Concepts, Tools, and Techniques from Boost and Beyond by David Abrahams http://www.amazon.com/dp/0321227255/
[removed]
Typical daily problem for me (on an embedded application, were every byte of memory is precious). Buffer from UART or radio or network, or whatever. Already in memory. Values in this buffer are stored big-endian. I want to read the buffer using a particular protocol. So I might do: struct sPacket { uint8_t type; uint32_t length; uint16_t data[10]; } __attribute__((packed)); uint8_t buffer[1000]; getFromSource(buffer); sPacket *packet = buffer; If the system is little endian, obviously this all goes wrong. Does this template help with the above? The "safe" C/C++ solution requires some extra bytes and you would do the conversion explicitly: sPacket packet; packet.type = buffer[0]; packet.length = (buffer[1]) &lt;&lt; 24 | (buffer[2] &lt;&lt; 16) | buffer[3] &lt;&lt; 8) | buffer[4]; // etc But that's a waste of bytes, since I've now got the same data stored twice. Does this library help with this sort of problem? The best solution I've been able to come up to date is to do struct sPacket { protected: uint8_t type; uint8_t length[sizeof(uint32_t)]; uint8_t data[10*sizeof(uint16_t)]; public: uint8_t getType() const { return type; } uint332_t getLength() const { return (buffer[1]) &lt;&lt; 24 | (buffer[2] &lt;&lt; 16) | buffer[3] &lt;&lt; 8) | buffer[4]; } // ... etc ... } __attribute__((packed)); And live with the overhead (it's actually rare that you access these elements more than once, so it's not a huge overhead of CPU).
No, thats not correct. In the standard, there are two different things: "ill-formed" and UB. The meaning is different. UB is a wholly runtime thing. The program, containing a potential UB but not hitting it at run time is a perfectly valid program.
heh; that thing goes completely out of support in April. Good luck!
There's already a replacement for vector&lt;bool&gt; in the standard library's little leagues, Boost.
&gt; type punning in a union isn't legal. You have to cast then read through a char* or you've got ub Isn't it? As far as I can tell the standard is silent on the matter, it's neither forbidden nor permitted. 9.5 [class.union]/1 talks of "active" members of the union, but there's no mention of what happens if you access an inactive member. I also don't think the standard says anything about things not being explicitly allowed being treated as UB. This is pure standards pedantry, but I figure that's not off topic here. 
If library uses C++11 it does not mean it uses correct C++11. I have no complaints about GCC5 so far.
Err, 'on its last legs' is a bit of a strange statement to make considering it's an underlying Windows technology that will never go away simply by virtue of infinite backwards-compatibility. You can comfortably write on Win32 right now and rest assured that your app will work in eternity. Another question is whether it is practical to do so. I don't have to remind anyone that jumping on various Microsoft UI bandwagons (e.g., MFC, WinForms, Silverlight) is extremely dangerous and not recommended as a long-term strategy. That said, apart from Qt I can't think of what a reasonably safe option would be.
People love the _idea_ of concepts (and rightly so), but very very few have witnessed "the sausage being made", as it were. There is reason to be skeptical about putting it into C++17. If Eric Niebler is skeptical, you probably should be too.
This looks awesome! Keep up the good work. Looks very useful for gamedev projects.
[I *love* D contracts.](https://dlang.org/spec/contracts.html) I think they do everything people would want in concepts - and the way D implements them is very sane, since the in / out bodies are either compile time processed or runtime checked (possibly in debug modes and not in release ones). I wish C++ would consider borrowing that little piece of goodness.
I think deprecation of those is positive, the impact is not too great, and easily fixed. It has to be seen which things go through, and then are at a far future point removed. Its likely that by then we'll have tools auto rewriting your code base. std::copy is not affected, as its not two input ranges, output iterators are not what the author aims at.
&gt; But concepts suffers as modules a bit from that people aren't aware of what it really means and brings. This is exactly the point I was trying to get across. It's a classic software problem: you want to put it out there so people can get used to it but at the same time, you don't want to create an unfortunate precedent that you can't wriggle yourself out of (`vector&lt;bool&gt;`, case in point). That, to me, says put it into a TR.
For the most part it can be used for implementing a wrapper for a managed object where you could intercept access to its members So you could create smart references much like how smart pointers work. This opens new possiblities for things like copy-on-write, or a wrapper that sends signals to slots when an object is being modified, or another wrapper that could trace access to the managed object in a log, or allow arbitratry classes to be a part of an undo system where you create a backup before the managed object is mutated, etc. 
anonymous unions are already allowed: http://eel.is/c++draft/class.union.anon
&gt; Okay, library evolution, cool, but when do we get designated initializers and anonymous structures/unions? &gt; Yeah, seriously. Designated initializers are sorely missing in C++.
Cheers, and yea it's true, moreover, "Fast compilation times" and "Template Metaprogramming" and "Boost" sounds even more ridiculous, however, with modern C++ it's possible, Boost.DI compiles even faster than Java.Dagger2, which sounds kinda funny these days. http://boost-experimental.github.io/di/overview/index.html#benchmarks
&gt; How does the replacement for alloca() work? Basically a `thread_local memory_stack&lt;&gt;` that will be used for the allocation instead of the program stack. &gt; Also is there a thread local heap allocator that doesn't block when used with concurrency? Not yet. I'm planning to add them though.
Contracts can fulfill the same mechanisms concepts do - restricting your expected parameters without having to do runtime type checking, but they add more features and are IMO less a pain to add since you are just adding constexpr or assert statements into pre and post condition bodies. IE, rather than having a concept for an iterator template, you just test for .begin existing as a function body in the precondition that returns a valid iterator.
Right, but for example range-v3's c++11 and c++14 versions do not work with gcc 5 but they do work with gcc 4 and gcc 6. This is particularly suspicious. Boost.Hana is C++14 only and it does not work with gcc 5 either but AFAIK does work with gcc 6. Both of these libraries have worked fine with clang for a long time now. And it is not only about them not working, it is also about how they make the compiler fail. If the compiler doesnt support a particular feature you should get an error of type "this usage of this feature is not fully supported yet". The fact that gcc 5 not only ICEs but also segfaults and gets into infinite loops makes me extremely uncomfortable about the robustness of the gcc 5 series. Sure if you are only using basic C++11 features, or writing C++03 in C++11 mode gcc 5 works fine, but so did gcc 4.
Umm, no modules and coroutines?