Same for free().
&gt; its does not really happened unless surprisingly happened Then it is not *wait-free*. A *wait-free* algorithm (definition from [here](http://www.cs.technion.ac.il/~erez/Papers/wf-simulation-full.pdf)): &gt; **guarantees** that every thread makes progress in a bounded number of steps, **regardless** of other threads’ behavior. Your code is at best *lock-free*.
`_wfq_enq_` and `_wfq_deq_` for internal purpose. Please kindly use `wfq_enq` and `wfq_deq` as README said :-)
The "API" section of the readme uses the underscores.
I've updated the README. Thanks for your correction :)
&gt;A &gt; &gt;wait-free &gt; &gt; algorithm unless surprisingly happened means if keep dequeuing something but it actually empty as it will impact CPU performance so it yield the threads. &amp;#x200B; In this whole context, it actually not waiting anyone unless *expanding* and it is unlikely happened Instead if *it is not lock or wait. (****unless it dequeues something been dequeued by some other thread and check if still value to dequeue. )*** I have updated CAS to SWAP for better understanding :-) &amp;#x200B; For enqueue, it is straight forward enqueuing with wait-free.
Hi, there's a good cppcon talk about allocators here https://youtu.be/IejdKidUwIg
The book is here :-) https://leanpub.com/cpp17
finding first set bit in an int using [de Bruijn sequences](https://en.wikipedia.org/wiki/De_Bruijn_sequence)
Thanks!
Depends on how far it goes, but for example checking which subclass something really is, checking the length of an array, which union member is set, etc. These things are not possible in all cases though (read: external functions).
This one is good if you are after how to do custom allocators https://www.youtube.com/watch?v=IGtKstxNe14 (ACCU 2019) Slides https://github.com/ACCUConf/PDFs_2019/blob/master/andreas_weis_-_taming_dynamic_memory__an_introduction_to_custom_allocators.pdf And this one is good for why https://www.youtube.com/watch?v=V0gmSPICJFQ (ACCU 2019) slides https://github.com/ACCUConf/PDFs_2019/blob/master/john_lakos_-_value_proposition_allocator-aware_(aa)_software.pdf For many gory implementation details (and for seeing what profiling means in this context) there are 2x1.5 hr John Lakos videos from CppCon 2017, but I can't find the slides for that.
Thank you!
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/awzkam/timurs_trip_report_from_the_february_2019_iso_c/eqia745/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This is based off reading your docs. Well: then_finally_expect([](aom::expected&lt;int&gt; v, main_work_queue) { //Do something with v; }); that is a typo; main work queue isn't an argument to the lambda. I would suggest the queue argument goes first; the lambda is likely to be long, and the queue can be lost. Your definition of failed looks wrong. Some docs imply it is first exception, some imply it is every element has an exception. The operation `([a], (a-&gt;[b])) -&gt; [b]` is a fundamental one in this pattern (where `[a]` denotes future of `a`). You almost but don't quite seem to have it. `([a], a-&gt;b)-&gt;[b]` is what you have. That is also useful, but not quite as fundamental. As an example of why the first is more fundamental, you can have a `future&lt;a,b,c&gt;` then `a,b,c to future&lt;x,y,z&gt;` function and it works pretty much by accident. Doing that with the second requires extra specific work. I have done something similar and expoited `operator-&gt;*` as a then, as I find the closing brackets a distradtion. Or even `-&gt;*then*`, or `-&gt;*then(queue)*`. But I am nutz. I am worried about finally; I cannot think of a way to early shut down a program with any of those in it. Shared vs Unique future? The setup vs starting of an async task is a bit of a headache.
I mean, I think my github is pretty impressive, but evidently not.
It is used to allocate a small amount of memory on each call to queue something up.
\&gt; that is a typo; main work queue isn't an argument to the lambda. Correct, I'll fix the doc. &amp;#x200B; \&gt; Your definition of failed looks wrong. Some docs imply it is first exception, some imply it is every element has an exception. Yes this is indeed confusing, there is a bit of a disconnect between what fail means when assigning an exception to a futurem and what it means when comes to time to call the handler. Throwing an exception in a future that generates multiple fields sets all the fields to the error, but a \`then(a,b,c)\` can only be called if none of the fields is errored. I need to clear this up. &amp;#x200B; \&gt; \`(\[a\], (a-&gt;\[b\]))\` -&gt; \`\[b\] vs (\[a\], a-&gt;b)-&gt;\[b\]\` &amp;#x200B; It's not in the documentation yet, but both of these work transparently depending on wether a handler returns a Future or a value. &amp;#x200B; What's actually missing is \`(\[a\], (a-&gt;b?))-&gt;\[b\]\` (where \`b?\` is expected&lt;b&gt;), but that's not a huge deal since you can just do \`return result.value()\` and get effectively the same thing. &amp;#x200B; \&gt; I am worried about finally; I cannot think of a way to early shut down a program with any of those in it. &amp;#x200B; You may have a point in immediate mode, but when the handler is put into a queue, it's just a question of not letting the program terminate with a non-empty work queue The asio example shows this nicely. If anything, In any case, I need finally in order to implement \`get\_std\_future()\`, so I may as well expose it. &amp;#x200B; \&gt; Shared vs Unique future? &amp;#x200B; I personally have no need for shared futures, but I'm not fundamentally opposed to adding them to the library if someone would use it. I just don't want to maintain code that isn't running anywhere. &amp;#x200B; \&gt; The setup vs starting of an async task is a bit of a headache. &amp;#x200B; Yeah, this is meant as a support for a library that handles the setup under the hood, so I didn't bother with it yet. On the flip side, writing an equivalent of \`std::async()\` for your favorite work pool like asio, or, in my case, grpc completion queues is very easy.
&gt; Benchmarks game isn't a reliable source for performance comparisons Because?
A function that's return type is void, returns nothing. cout writes characters to stdout, return means that a value is sent back to a variable where it was called... signed integers can represent negative values, unsigned can only represent positive ones... NULL means that a pointer has no value. dynamically allocated memory is for when you don't know how much memory you need at compile time, for example you're processing a variable size image, the size of the image could be anything, so you have to wait to find out how much memory you need. the stack is for automatically initialized variables, like in function bodies that don't stick around after the function is done running. the heap is to dynamically allocate memory to keep it around for longer than the duration of any particular function. &gt; Pre incrementation an post incrementation That's not something you need to worry about at this point. &gt; Headers Headers allow you to hide the implementation details from people using your compiled code, like in a static library. &gt; ( how many of these are there?) That is just an entirely pointless, and unanswerable question. &gt; Memory leak After you allocate memory with calloc in C or new in C++ you may at some point be done using that memory, which is why you'd free it so it can be reused for something else, a memory leak is the failure to deallocate memory after you are no longer using it. You really don't know the first thing you're trying to do, do you? Read a book, or just a sht ton of code, that's what I did.
First of all, this should go in /r/cpp_questions. A lot of these questions are very basic or general. I don’t think learning the answers to these individual questions will do you any good. I recommend you find a good book or course to get a proper understanding of C++.
&gt; In this whole context, it actually not waiting anyone unless expanding and it is unlikely happened To be called *wait-free*, it must never wait more than a fixed number of times each operation, no matter what. If waiting can theoretically happen, even if it happens very rarely, it should not be called *wait-free*.
Sounds really cool!
Very much is. Thanks. It's totally almost done and I'm very psyched
But no paper? I want paper (I'm old and stuck in my ways).
http://smallmemory.com/book.html
Java and C#.Net attract a different niche of programmers. The latter are mainly for web development (backend).
I don't know about that! C++ has its immense uses in the world of Embedded Systems and IoT. That's why I learned it despite the fact that my University primarily did everything in Java (except for Operating Systems and Computer Organization etch had a fair amount of C/C++)
Inheritance was a mistake.
Well, you can send the same message to Google (NDK) and GNU.
You can choose friends, not family.
Nice, I've never thought about the problem with operators. But in the end, aren't they just functions? Special ones maybe, but still functions.
Are you saying that we need a `family` keyword?
Brb appointing myself the new and only committee member
A `family` class allows the inheritance to be modified at runtime through: - `divorce`, separate the classes, no more relations between them - `marry`, creates a relationship between the classes - `reproduce`, creates a new class that inherits between 2 married classes
What if I want to `reproduce` without marrying? Or creating a new class?
Hmm... But if you `reproduce` a new class and later on wish to cut the inheritance chain, it would be odd to use `divorce`. However adding `disown` would be confusing and would require a programmer to track which classes are `marry`'d and which have `reproduce`'d. Meh... for standard implementers' convenience - `divorce`-ing a `reproduce`'d class and `disown`-ing a `marry`'d class leads to... undefined or implementation defined behaviour?
But those are still quite small worlds, and probably not very typical entrees into programming, compared to the number of people out there who get into it on their own and start by creating a web site or some small phone app or some such.
We might add a `Government` class that tracks families to ease the work of the programmer.
Might want to make an implementation first.
Good question, I suggested a `Government` class that handles the legal problems of adopting/making childs.
I'm sorry I have to disagree with you there. Modern cars, planes, trains, etc all of their systems are in. C/C++. Google's entire backend is in C/C++ although they are transitioning to Golang. Self-driving cars are very much in C++. I personally think web development is lame as anyone could do it. Not everyone is capable of working with Software and Hardware simultaneously.
I've just finished the first video, the one of Andreas Weis and is a very good introduction!
Not in favour of that. For about the same reasons that we don't want a garbage collector. Don't pay for what you don't use and all that...
"I personally think web development is lame as anyone could do it. Not everyone is capable of working with Software and Hardware simultaneously." But that's WHY there are a LOT more people do the former than the latter, and hence why anyone doing a lot of work to create a product is likely a lot more interested in targeting the latter rather than the former.
That sounds like it'd just cause a lot more complexity and rules than is really needed.
I took it to be highlighting that what C++ allows and what it selects as the operators can lead to perplexing behavior that is far from obvious, even if someone knows about the underlying mechanics.
I assume that none of this applies if I use inheritance to "extend" a type by adding some new non-virtual member functions to it. No data members. An example would be inheriting from an `std` container to add some convenience functions. Could slicing, not matter what kind, ever cause any issues in that case?
If I understood correctly, slicing affects methods as well, so even if your data won't be sliced, the methods will.
oops
&gt; The second step is to use dynamic_cast to verify that the assigned object has a compatible type. Wouldn't it just be simpler to only allow assignment from the same type?
&gt; Inheritance was a mistake. Only if your classes aren't designed correctly. I find that it's virtually impossible to run into this situation by accident with correctly designed classes that prevent operations that can result in slicing (by being non-copyable, for example.)
I was half joking, and I'm sure you are right that it can be designed around by deleting certain overloads, but I actually don't necessarily understand what is gained by the complexity.
To address the extension of standard containers for those reading: [If you think the solution to your problem is to inherit and extend standard library containers](https://stackoverflow.com/questions/4353203/thou-shalt-not-inherit-from-stdvector), then you should re-evaluate your problem space and _make sure_ that's what you have to do. They're simply not constructed with that intention. Another option aside from free functions is to encapsulate them in a namespace or encapsulate them in an adapter that has a member vector that it applies those convenience functions to. (its besides the point sure, but breaking it out as a separate discussion)
For me it's convenience. A hierarchy of classes is just easy to use for application development.
Since slicing is the result of partially copied data members, I don't see what slicing of a member function even means.
Well known behavior. Do not use references(or values of an object, because reference is an alias of the value) for polymorphing(OOP).
Bjarne did an oopsie
I don't think getting `Government` involved in `reproduction` is a good idea. `Government` already has enough responsibilities and wasting resources managing `reproduction` has a pretty bad code smell.
Yes. You can force the issue by giving `B` an `explicit` conversion operator for `A` (`explicit operator A()` – which will force you to do explicit casts and won't allow slicing copy shenanigans without them), but bad programmers will be bad programmers and you can only stop a `dynamic_cast` from making this a problem with a blunt instrument.
Of course, there's a tradeoff: Ease of use versus correctness. If C++ had a bit more of a strict type system, and a proper type trait system, most of the uses of inheritance would be made irrelevant. For me, when inheritance seems like the right choice, it's a sign I did something wrong.
Oog this man accidentally typed in an extra p when searching for his favorite sub. 1 billion miles away, you may see my sides, as they are in the orbit of our galaxy
The more I look at this the more red flags I see. It seems like atomically adding 0 is being used to load numbers and compare and swap is being used to atomically load pointers to check for NULL or other special pointer values. More importantly I think there are big race conditions and ABA problems. Dequeueing not only spin locks to wait for a value to be ready, but it uses compare and swap to simply check the value, then just uses swap in a separate atomic operation, with no guarantee of the value.
If the A base class assignment operator called a virtual assign() function, would it do the right thing for an A ref to B? Would this be good practice for a commonly used base class to a tree of derived types?
a wittle fucko boingo (◕ ɔ ◕✿) seriously though reading `//b2 now contains a mixture of b1 and b2!` messed me up lol
It's also a double-post.
You end up with the same problem if somebody ever subclasses `B`. You're usually better off just disabling the copy and assignment operators entirely.
&gt; If the A base class assignment operator called a virtual assign() function, would it do the right thing for an A ref to B? Assigning a `B` to an `A`? No. That'll slice. Assigning a to a `B` through an `A&amp;`? Maybe. I'm fairly sure there are a few cases where it'll still get sliced. It's a bad pattern in the first place, regardless. &gt; Would this be good practice for a commonly used base class to a tree of derived types? No, I wouldn't think so. The only cases where inheritance makes any sense in this kind of situation is when you have collections of objects in that hierarchy. And, in that case, you want to store pointers to a common base class. Even then, this is what I keep blunt instruments around for.
&gt; `reproduce`, creates a new class that inherits between 2 married classes There's an endianness joke here somewhere...
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/byq33n/help_understanding_pointers/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
`cheat`, one or both related classes have one or more undocumented relationships to any of the other instances. If `significant other` or `child` discover this relationship all related `family` and possibly even some `friend` objects enter undefined behaviour. **Can cause child classes not inherited from the parents defined `family`, leading to fatal exceptions.
Jail
Slicing isn’t specific to operators it’s just a common case where slicing occurs. Slicing will still happen when you pass a B to a function that takes an A.
The linked answer explains the problem well, but the "solution" is heinous ... IMO it's better to just disable `operator=` in a class hierarchy if it would lead to unexpected behaviour.
I've worked around this so often I really have to slap myself around a bit to acknowledge that is counter-intuitive. But yeah, obviously operators called on an object of type A will call type A functions, and wouldn't magically know about type B functions.
I'm confused. Is this an actual problem or a misunderstood aspect of the language? It seems obvious to me that `A::operator=` wouldn't know about fields in `B` and would make the `b2` variable a weird combination of the two values. Where might one easily make the mistake of declaring a reference to a base class and assign a derived class instance to it?
TIL that "slicing" in C++ doesn't refer to array slicing like it does in other languages.
How else would you implement runtime polymorphism?
You can even make the syntax shorter, by making the parameter list optional and parameters named automatically `__1`, `__2` or similar reserved names. So for an inline lambda you could just write `[] __1*2;`. Single statement would mean return the statement, saves a word as well. No need for braces for single statements as well.
Range based for doesn't allow parallel processing like `std::transform`. Back inserting prevents it anyway, which is why allocating first is best.
The type system in cmake script is perhaps the worst example of engineering I can think of. It makes JavaScript being written in a week look like fucking miracle work. I can't fathom how such a horrible decision was made to make cmake script the way it is and then continuously over two decades decide that it doesn't need improvement. 95% of the hatred for cmake would be eliminated with any sort of a sane type system, variable system and better handling of the two.
That example is not really surprising, since after all no virtual call = base function is called. I'd say to avoid 95% of bad surprises with slicing when you're not using virtual functions, only put them in const references of the base class or make a copy. Modifying an object as if it was a base class is most of the time a terrible idea.
With data. I've seen that a large proportion of the cases where we tend to use class inheritance for polymorphism can be written more type-safe and functionally correct using pure data with a judicious sprinkling of dynamic dispatch through lambdas and function pointers. It's literally the same thing, except dispatch through lambdas is more explicit and type safety and type correctness is easier to specify and maintain, in my opinion.
&gt;std::ranges::sort(v1 | std::view::filter(condition) &amp;#x200B; \`sort\` requires random-access iterators, and a filtered view is forward at best.
There are also tagged unions, which I guess would be the C way of doing things.
Writing code in C++ is like using a table saw without the guard. If you know what you are doing you won’t have an accident. If you want your guard use a managed language.
What `Government`? We don't want to pay for what we don't use.
Other than the answers given below (or above?) you can use [type erasure](https://youtu.be/QGcVXgEVMJg) to use a type polymorphically but still maintain value semantics Else, you may find other solutions that, depending on your problem domain, can help you, for example: in gamedev to represent entities you don't create an inheritance tree but a relational database (they call it ECS, it's mostly the same thing)
It is "just" a misunderstanding. Probably because the person was assuming that all calls would be virtual without specifying them as such.
I (the author) would love to hear your thoughts on it. What is the use case that you would consider refl-cpp for and why? Would you like to see more examples/documentation? Also, I would be happy to answer any questions about the implementation and reasoning behind it.
It is more like using a delicate fret saw to create a beautiful piece of useful furniture, like a sideboard, but try not to think too hard about it, okay?
Having to create macros to define the reflection information kind of defeats the point of it all IMO.
I would be so excited about this and use it immediately if someone found a way to do it without macros instrumenting the type you want to reflect on. I'll probably have to wait for C++23 for proper reflexpr though...
Having the extra macro is a deal-breaker for me.
This type of reflection was possible in C++03. I've implemented something like this 12 years ago as part of my engine. The problem is, having to use special macros and list all the fields kind make this kind of reflection pointless. Reflection is mostly used for serialization and if you have to list all the fields anyway you can just use boost::serialization or cereal. &amp;#x200B; Also need for public members limits usefullness of this library.
It's an overloaded term. In this particular case they explicitly call it "object slicing" to disambiguate.
I see why you might say that. And yes, there are a few macro-based libraries that implement \*runtime\* reflection. A few things set refl-cpp apart though. First of all, refl-cpp requires you to only specify the names of the reflected members (type-information is not needed; i.e. for resolving overloaded member functions). Second of all, having all members of a type reflected might not always be desirable. Third of all, even the proposed Reflections TS, does not handle some things like custom attributes, for example, which is a main concern of reflection in general. Therefore, if you really need reflection in your project, you are stuck with having to manually specify the interface of the reflected type. (Or use a preprocessor, something which I have in fact considered, but which would require having something like my-file.cpp.refl, and then invoking a preprocessor.)
The reflexpr proposal is scheduled for C++23 but that is a best-case scenario. Besides, even if it gets implemented 4 years from now, the current proposal does not include the ability to decorate members and types with custom attributes. Something which is often employed in other languages. Eg. using attributes on a DAO type's members to mark them as mapping to a certain DB column, or specifying a different name for serialization purposes.
Yes, having to specify all members all over again is not very nice... Still, you are definitely not required to enumerate every single member of every single type. The ad-hoc nature of the REFL\_TYPE macro allows you to specify reflection information on a case-by-case basis. Besides, if you do need reflection, there is currently no other way. What sets refl-cpp apart from other reflection libraries though, is the fact that potentially all type-level operations can be constexpr.
What is your opinion on a having a custom preprocessor that generates the type information macros automatically? For example, you would rather have a User.h file, that has a @refl annotation on top and having to run a custom command before recompilation?
I'm sorry, but I have to disagree with you on your first point. This type of reflection system is not possible in C++03. What is possible in C++03 is a runtime-based reflection system. Let me try to explain the difference between the two. In a runtime-based reflection system, you can request a type descriptor for a given type. Let's say the signature of that type descriptor is: `class type_descriptor {` `const std::string&amp; name() const;` `std::vector&lt;member_descriptor*&gt; members() const;` `}` with `class function_descriptor : public member_descriptor {` `const std::string&amp; name() const;` `std::any invoke(std::vector&lt;std::any&gt; args);` `}` What such a library would allow you, is to invoke a given function, for example, but only by providing arguments that are the exact types as declared on the target function. You would then get the result in an std::any, which you would have to cast to the concrete type. &amp;#x200B; In contrast, in refl-cpp every type-descriptor is it's own type, that conforms to a the following interface: `class type_descriptor&lt;T&gt; {` `static constexpr refl::Ident&lt;num-of-chars&gt; name{ ... };` `static constexpr std::tuple&lt;attr-types&gt; attributes { ... };` `static constexpr refl::type_list&lt;function_descriptor&lt;T, 0&gt; ... function_descriptor&lt;T, N&gt;&gt; members;` `template &lt;typename... Args&gt;` `decltype(auto) invoke(Args&amp;&amp;... args) {` `/* invoke the reflected function with args */;` `}` `}` &amp;#x200B; `class function_descriptor&lt;T, N&gt; {` `static constexpr refl::Ident&lt;num-of-chars&gt; name{ ... };` `static constexpr std::tuple&lt;attr-types&gt; attributes { ... };` &amp;#x200B; `template &lt;typename... Args&gt;` `static constexpr decltype(auto) invoke(Args&amp;&amp;... args) {` `/* invoke the reflected function with args */;` `}` `}` &amp;#x200B; What this allows you to do is \*at compile-time\* enumerate the members of a reflectable type T. (You can also at compile-time check if T is reflectable (using static\_assert) and issue an error for example.) Then you can invoke its members with some arguments (preserving their static type), and get a typed value as a result. Also, it allows you to invoke templated functions, which no other reflection system allows (to my knowledge; since pointers to templated members do not exists) . &amp;#x200B; In addition, refl-cpp allows creating proxy types (something which is missing in this blog post), which conform to an interface defined with REFL\_TYPE, but allow arbitrary user-defined handers.
And yes, reflection is primarily used for serializations (which typically involves public fields only). But refl-cpp allows much more. For example, defining DAO objects or type mappings (similar to AutoMapper). There are not included in the core library, but refl-cpp gives you all the tools to do that. (I have some WIP examples). Also, can you comment on a use-case for reflecting private members? That sounds undesirable to me, but I would like to know your opition.
That fixes some of the problems but probably cuts out half of the possible users who are locked into a particular build system outside of their control. I would also be curious to see what sort of code this generates, compared to something which assumes the details of the type without doing reflection. Is there any overhead in common use cases on common compilers?
That was precisely my line of thought on the matter. Also, it would be undesirable to have incompatibilities between projects using the same library. I will now look at the generated assembly, but my guess is that it would be equivalent to a direct call (as that is generally what happens under the hood).
Never stumbled upon this one before. Looks interesting although almost 20-year old one! Have you got a comment on the book? Does it overlap with what we generally hear on memory-allocator topics or does it extend further?
OK, I confirmed that the call gets completely optimized out with gcc -O1 and up (as if by calling the member directly). Here is the code that I tested with: [https://gist.github.com/veselink1/610b802a273de2ed98d724519cd28288](https://gist.github.com/veselink1/610b802a273de2ed98d724519cd28288)
Version 2.5.9 is available :) [https://forum.adlice.com/index.php?topic=3584.msg9170#msg9170](https://forum.adlice.com/index.php?topic=3584.msg9170#msg9170)
Is it an oopsie though? What's a better way to have designed this?
Please, do consider leaving a comment before downvoting. It would be much appreciated.
If you are interested in iterating member variables, this library \[0\] might help :-) See for example the `cista::for_each_field` or `cista::to_tuple` functions. &amp;#x200B; \[0\] [https://cista.rocks/#reflection](https://cista.rocks/#reflection), I'm the author.
That is, in fact, a very interesting approach for extracting public values of a data-class. Thanks for sharing.
Absolutely agree. 1. Keep simple things simple 2. Use standard libs whereever you can.
I'd super recommend SFML, you can dump a bunch of vertices into a vertexbuffer and render them pretty quickly, [here's](https://github.com/20k/space_space_space/blob/master/entity.cpp#L151) how i'm using some vertex stuff Additionally, playing raw audio samples is also extremely easy to do through SFML, [here's](https://github.com/20k/space_space_space/blob/master/audio.cpp) how I do it adapted from [here](https://github.com/SFML/SFML/wiki/Tutorial:-Play-Sine-Wave)
It's a shame it depends on Boost, seems very unnecessary in my opinion. HDF5 is usually a really big pain to include and to work with from C++, in a cross-platform way. How did you include HDF5 into your build/setup? I can't find anything in your CMakeLists weirdly. Btw, you shouldn't put your release artefacts (i.e. the .deb files) into your repository. They belong on the Releases page on GitHub. If for whatever reason you do want them in the source code repo, at least use git lfs, to not blow up the repo size.
Prevent this sort of fuckery by default and require going through some hoops to make assignment operators behave like that.
Still waiting to see any significant bug due to slicing - especially one that doesn't immediately get caught in the tests. That being said, for code that I have complete control over I follow a simple policy: Classes either have protected constructors and assignment operators or are final (I guess there may be a hand full of exceptions in my code around pod like structs)
&gt; even the proposed Reflections TS, does not handle some things like custom attributes, for example What is a custom attribute?
I don't think there is anything surprising about it (especially not, if you understand the underlying mechanics). But as always c++allows you to easily write broken code, where you don't immediately see that it is broken (you can define operator == to launch nuclear missiles after all)
But that it's usually the benign case: If your function takes an A by value, then it only cares about the A and gets exactly what it expects.
I wonder if this comes mainly from people that are used to java or similar, where almost everything is a pointer and assigning one variable to another has a completely different semantics.
Meaning an annotation of a type or member definition, that can be used as a value in a program. For example, in C++14 there are the [[noreturn]], [[deprecated]], etc. attributes. These are annotations that provide additional information for the compiler or the user. The Reflections TS does not allow inspection of these attributes, and the C++ language does not allow creating such attributes as well. Refl-cpp has its own implementation of attributes. They are essentially user-provided values, that are stored in an associated std::tuple. You can see an example of a "Serializable" attribute in the blog post.
Is SFML compatible with GLFW? GLEW? Does it provide a framework for tessellation?
[https://www.boost.org/doc/libs/1\_52\_0/libs/fusion/doc/html/fusion/adapted/define\_struct.html](https://www.boost.org/doc/libs/1_52_0/libs/fusion/doc/html/fusion/adapted/define_struct.html) was available for many years.
"Reflection is mostly used for serialization" Maybe this is true today. But it is absolutely not true long term. There are much bigger fish out there that reflection can help with. [Andrei's talk on "The Next Big Thing"](https://www.youtube.com/watch?v=tcyb1lpEHm0) gives a few examples. In the game dev space, we use a hand-rolled reflection library to support our in-game editors. Yes, you have to annotate the fields on a struct that you want to be user-editable, but it's helluva lot better than repeating the `make_editable_control(&amp;some_member);` for every control in the UI.
I think you meant "e.g." ("exempli gratia"; "for example") rather than "i.e." ("id est"; "that is").
Yes, that is correct. Thank you for pointing that out.
I do not understand what you are suggesting. Could you please elaborate? It seems to me that BOOST\_FUSIONS\_DEFINE\_STRUCT defines a Random Access Sequence (which looks like an std::tuple with named members). That is not in any way equivalent to what refl-cpp allows you to do.
I believe they meant to reply to the post about cista, and meant to link to ADAPT_STRUCT
or https://github.com/apolukhin/magic_get
Laughs in Dlang ;)
"Keep simple things simple" - I do too, agree with that. Reflection may be useful for serialization but that is certainly not its only use. Please note /u/tylerayoung 's comment. Maybe I need to provide more examples of what is possible with refl-cpp. The reason I demonstrated its use in serialization was that that is what I thought was the most-familiar with people. I now see that this was a mistake. "Use standard libs wherever you can." - I agree on this point also, but do not see how it is relevant. Standard libs do not account for type-inspection (other than what is possible with type\_traits).
I am actually really sorry that D did not get as popular as C++ or Rust at least. I think the fact that it is not cross-platform or suitable for embedded programming, as well as the relatively late open-sourcing of the de-facto compiler is what dragged it down.
Compiler Explorer supports including headers from GitHub (or possibly any URL?), so you can demonstrate such things directly: https://godbolt.org/z/jPvDc2
Maybe, but this problem has existed longer than Java has been popular.
It just seems to be another case, like "functor", where C++ invents its own meaning for a word that already has an established meaning.
Which is the better choice depends on what you are trying to do. If you want to target touch devices, want a fancy UI with animations, and don't care about looking standard on desktop then Qt Quick is the way to go. If you want a traditional desktop app then Qt Widgets is better. It is worth noting that the Qt Widgets API is much richer than the Qt Quick Controls 2 API is. When working with Qt Quick I routinely run across things that don't just work out of the box, but I almost never find that to be the case with Widgets.
That depends on what your app supposed to do, actually. If it's nothing fancy then go for Widgets, otherwise go for QML. If you need both, then you can integrate QML into Widgets app. Looking good is mostly done using available styling options.
Nice post! I noticed you're using fmtlib. Could you please add a small section on how to get / use the library. I know the library is popular with the c++ community but newcomers may be confused. And just one last gripe, I know the animations help in explaining the algorithm but It would be nice to see some explanation of why an algorithm works.
so... additive synthesis?
Yes, techincally the audio values could just as easily be subtractive; though the assembly of the shape is obviously additive and not deductive in this case. There will be advanced 3d geometric waveform-shape interference as well as perhaps some deductive rendering if it ever gets that abstracted.
It’s a solved problem: a generator pass that takes the clang AST and generates whatever info you want. I can’t understand why people try to shoehorn a language that clearly can’t do it nicely into pretending that it can. These days walking the AST is way simpler than all those horrible “reflection” hacks people come up with. Their way is more work, more brittleness, and it’s even harder to maintain. Everyone should know how to handle an AST walk, especially that it takes rather little code, and clang makes this stuff dead easy. The argument used to be that C++ is so hard to parse that it was unfeasible to do much more than ugly hacks, since a full parser was outside of most everyone’s budget. But we now have an industry-strength C++ parser with an API meant for this sort of use. So use it already, duh.
i think you are talking about lock free queue. This is wait free queue, **guarantees** that every thread makes progress in a bounded number of steps, **regardless** of other threads’ behavior.
Seconding this. A very large amount of QT documentation and online help posts center around the widgets implementation, and once you learn widgets you can put QML into a widgets based application like another commenter mentioned. I will say &gt; When working with Qt Quick I routinely run across things that don’t just work outside of the box... The only thing I can think of with Widgets that I really don’t like and few things frustrated me more than QT Charts. Utter trash, IMO, I ended up just going up a level and generating gnuplot commands and using that instead, which is no where near as portable but doesn’t look like trash like Charts
I only thumbed through it 15 years ago :) It’s more about embedded programming in C than what you are looking for. Though, the techniques should translate. The whole book is available as free and legal PDFs. Check out the ToC.
Indeed, there are a lot of reasons for D not getting the popularity it deserves. (and it is extensively discussed every year in D forums, so i'll not go into this again XD). Not sure what u mean by "not cross-platform". D run on lots of platforms(and I already worked on win and linux with it). Unless u are comparing with c/c++ compilers. I´m not into embedded programming but i saw lots of people working with embedded + D. There are a recent thread on the forums about a web game that have the server made in D + Vibe.d and hosted on a raspberry pi :)
I once had a class in numerical analysis, and while it was pretty rough its cool to know and very useful when the time comes. Good article!
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/byzi9o/can_someone_help_me_here/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I just have to laugh at the "no macros" crowd. Yes, debugging compile-time errors in macros sucks. But I've *never* seen a macro issue that was a tenth as hard to debug as "modern" Boost templates. There are going to be tradeoffs however you implement something like this, and rejecting it purely for using macros is baffling to me. Keep it up, u/veselink1. I think this looks great.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bz022g/total_noob_modifying_class_variables/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I have always shied away from D for game dev becauseof worry that major game consoles won't be valid targets without a lot of extra work. Is that a valid concern, do you think?
I 100% agree with your point, but your post comes off as a little condescending. Clang libtooling is the ideal solution for most people, especially in the game dev space.
First, this is at best just a queue since it isn't thread safe and has pretty glaring race conditions. Second, it isn't wait free since it spins when trying to dequeue something that isn't ready yet. If one thread adds to the counter variables and stalls, the thread trying to dequeue that slot will just spin lock waiting for it. That isn't even lock free since one thread stalling will cause the other to stall. It is basically a very poor mutex. These are just the thing is I noticed while skimming it on my phone. Other people have explained this to you but you don't seem to want to hear it. My guess is that a lot of the race conditions and ABA problems don't show up in simple tests since everything being out into the queue is getting allocated with malloc, which locks and serialized all the different thread's activities to some extent. One good way to test is to put large random pauses around all atomic operations. Then you can more easily trigger race conditions and ABA problems instead of having rare issues never come up. Also make sure you actually have multiple hardware threads and make sure they are all working. Malloc locks and printing to a console locks.
I looked specifically if you have sfc64. Was not disappointed, nice work!
I don't know how did you manage to get from [here](http://xoshiro.di.unimi.it/xoshiro256starstar.c) to [here](https://gitlab.com/ianf1/rngpp/blob/master/include/rngpp/xoshiro.hpp) (bonus points for dragging like half of a meg worth of dependencies), but whatever floats your boat, dude... Just want to point out that the checks are mildly wrong (didn't read all your code, so it may or may not be a recurring issue): static constexpr unsigned int digits = std::numeric_limits&lt;StateType&gt;::digits; static_assert(P &lt;= digits &amp;&amp; Q &lt;= digits, "Required for the shifts to make sense."); &gt; In any case, if the value of the right operand is negative or is greater [or equal](https://en.cppreference.com/w/cpp/language/operator_arithmetic#Bitwise_shift_operators) to the number of bits in the promoted left operand, the behavior is undefined. Personally, I'm also a bit peeved when people take something published under a CC-like license and "upgrade" it to MIT. I think that's legal, but, you know... If someone likes the actual algorithm, and not your implementation, they will have to go and check the original to figure out that the algorithm itself is in public domain.
I don´t have the knowledge to answer this properly. But since D can interop with c/c++ , I don´t really think is "a lot of extra work". But I might be wrong.
Linux didn't decide to use char for UTF-8. Char is in the current multibyte encoding, whatever that is. UTF-8 happens to be the most common multibyte encoding, but you can still create a locale using something different.
They are both correct, and it's probably worth trying out both at some point to understand their strengths and weaknesses. For larger projects, I feel like straight C++ gives me more control over everything because I'm used to making those changes from the command line, and then load QSS for styling. As far as integrating, it's not difficult at all and was designed to be able to integrate from the beginning. You load the .ui file and then use findChild or findChildren to get their C++ objects. IIRC there are examples within Qt Creator that already use this method.
Good Lord, good catch. Are there any good random number algorithms with only 128bits of state? Then the state could be treated as a 128 bit atomic (not that this would always be the best approach).
Thank you! I am happy to see that someone has a similar take on the matter.
This is a proof-of-concept / prototype for forward declarations of all major runtime `std` types. I intend to make a proposal to add this to the standard and would like to gather experience, opinions, usage data. --- DISCLAIMER: this is obviously UB, use at your own risk.
Why do you want to make the state atomic? It will be very slow in a parallel environment. It's better to use threadlocal rngs that are porperly initialized
There are several pretty good ones [here](http://xoshiro.di.unimi.it/), but please don't use atomicity as a criteria for choosing one or another. This must **never** be atomic, because atomicity destroys the whole point of having a fast PRNG. It creates an enormous contention between threads. You may get into a situation where an app that simulates something random on 32 threads works slower than an app that does it on 1 thread, just because threads are constantly stealing the same cache line from each other. Thankfully, there are jump functions. You probably know about [TLS](https://en.wikipedia.org/wiki/Thread-local_storage). If you have one global thread-safe generator for states, that just makes a jump by, let's say, 2^64 numbers, and initializes a new thread's TLS with what they got, you can me moderately confident that threads will act as if they have independent RNGs, and will never (in practice) catch up to each other. Moreover, with a 128-bit state you won't run out of "different" initial states for threads (because it's rather hard to create 2^64 threads during the lifetime of an app). The state generator can typically be under a mutex (unless you create an unreasonable amount of threads, in which case more interesting approaches exist). It's also somewhat nice if **your jump functions work**. I'm not an expert, but it looks like yours don't. Well, they probably will work for the constants they were pre-computed by the author, but unless there is some non-obvious math that I fail to see, changing P or Q must change the jump constants. One extra problem: correctness. Vigna's algorithms pass BigCrush test. Unless you can prove that for all accepted P and Q your code **also** pass all tests (and then show that changing these constants is meaningful), I would suggest you to nuke all the extra parameterization. Pros: * Less code. * Jump will (hopefully) work. Makes sense to write a test. * No reason to ponder "ok, how the hell do I use this? Can I pass two zeros or something?"
If the standard headers can be imported as header modules, does this have benefits?
Thanks for the input! * The extra length and dependencies are there for the RNG to actually implement the full interface, you're right in pointing out that some people will prefer the shorter C code. * You're right about the static_assert's, I'll fix it. * I didn't realize that I was "upgrading" the license. All the relevant algorithms are in the public domain as far as I can tell. How else should I be proceeding? * You're absolutely right about the jump functions, they don't work except for some specific sets of values. Good catch.
Hard to tell before C++20 ready compilers are really out but I was told that with the current implementation of header units there is \_probably\_ no price to pay for including std headers anymore. Still, my current info is that it is still unclear how build tools will support modules and if all projects can be easily "upgraded" into using them. So yes, modules kinda diminish the value of this proposal a bit but the impact by implementation complexity ratio should still be substantial.
**This is completely UB and wrong, please don't use it !** C++20 introduces modules and make all standard headers implicitly importable as module units which alleviates the concerns this is trying to "solve".
if the objective is to reduce the compilation time, why not just use precompiled headers?
Because pre-compiled headers are fragile: they usually require you to include the pre-compiled header first before all other headers &amp; require an extra build step. In my experience, pre-compiled headers have never really worked out - they cause more pain elsewhere than you gain.
There is an enormous difference in compile time between using huge precompiled headers vs proper lightweight forward declarations. In a recent project I worked on, compiling an empty cpp file would take as much as 250ms.
Only if your project can easily switch to using module syntax and if importing standard library headers really becomes cheap.
Because they are more difficult to use and less efficient?
In c++20 the compiler will be able to treat all standard headers (#include &lt;vector&gt; )as if it were a legacy header (#import &lt;vector&gt; ) without you doing anything. The more modern syntax `import std;` will not be available for standard modules, that will come later
What about all those people that can't use the latest standard? Maybe they need to stick with C++11/14.
Thread-locals come with their own bag of issues though.
C++11 is 8 years old. I Definitively recommend trying to convince your CTO to use a more recent toolchain if applicable. It will be worth it in term of productivity :D
That's true, for platforms that are problematic we use [apr](https://apr.apache.org/)
One of the mains goals of modules was to make them easy to integrate into gigantic codebases. It's basically a no go for them if it fails to do so. How would it be hard to switch?
Regarding the license: it's up to you. Public domain allows you to do whatever you want with the algorithms. I would personally feel weird if I took a CC thing, added some dependencies and re-released it as MIT, but that's just me. Regarding the dependencies: you made your library potentially available for 2-3% of devs (by my rough and optimistic estimate). Some would just outright reject anything that includes &lt;iostream&gt;. And I'm not talking about someone's pet projects, I'm talking about stuff like [LLVM](https://llvm.org/docs/CodingStandards.html#include-iostream-is-forbidden). Some projects can't use precompiled headers, and thus by dragging &lt;algorithm&gt; you made sure people will say "thanks, no" without reading your code. A huge number of projects won't be able to compile your code. I don't think that anything in the xoroshiro's implementation required you to use "if constexpr" and other C++17 features (if anything, it made your code worse in this specific case, but that's just my opinion). An enormous amount of projects are stuck on C++11/14, and some can't even afford that. Also note that having C++11 (for example) doesn't automatically imply having a standard library, or even a CRT. It all depends on who you are trying to target, ofc. Some projects will reject this code because of the structure. People prefer to include &lt;fooLib/bar.h&gt; instead of "bar.h". There is a reason why the standard layout exists (you know, with all these "include" folders etc). Fun thing is that you actually have "include/rngpp/", and yet you never reference this "rngpp" folder. Some people will reject this code because it tries to do what it should never try to do. If I'm using some ostream for serialization, and then suddenly I can't do that because your library decided to pre-define how exactly the operator&lt;&lt; must look, instead of making a wrapper people are likely to just, you know, not use your code. Finally, a surprising number of people will reject your code because it tries to impose its own style: * seed() sounds like a getter (for both the std style and google style). That's also a questionable method without any args, but that's another topic. * One day I'll probably meet a person who likes Doxygen style bullshit in tiny classes that would be 3 times shorter with normal comments. I hope I'll be able to quickly run away, because it's unsafe to stay close to such people. * It's generally easier to advertise the code if the .clang-format contains one line (related to C++ at least). If you need more than one, there better be a great reason, such as a 90Mb large blob of legacy sources that you can't refactor because each customer has their own support branch. If someone who doesn't like Chromium sees "Chromium," they will think "whatever, it's standard by now." If someone who doesn't like your style will see your style, they won't be nearly as willing to accept it as with something "standard."
&gt;without you doing anything I still have to rewrite them no? Does my build system have to know about them? Will my auto-completion still work? When will common compilers, standard libraries and development tools support those standard library legacy header include mechanism? Do we actually know for a fact that using that mechanism will be as cheap/cheaper as/than the proposed fwd header? The main problem I have with this fwd proposal is that it will come earliest in 23 unless common implementations decide to also provide the header in earlier standard modes.
The includes implicitly interpreted as imports is only compiler and does not involve the build system at all. So you won't have to change anything and it will be noticably faster. Proper modules that let you select exactly what to export and don't leak macros do require changes of tooling and code.
I'd likely prefer this to be more granular, though I'm not sure my opinion matters all that much since I'm an EWG member, not LEWG. I'd prefer a bunch of headers like &lt;vector_fwd&gt; so that one can pick up JUST the required forward declarations.
Again, thank you for the detailed feedback. &gt; Regarding the license: it's up to you. Public domain allows you to do whatever you want with the algorithms. I would personally feel weird if I took a CC thing, added some dependencies and re-released it as MIT, but that's just me. I'll probably end up mentioning more clearly that the algorithms are in the public domain, and that the additional "dependencies" are under MIT. Hopefully this makes things clearer. &gt; Some would just outright reject anything that includes &lt;iostream&gt;. And I'm not talking about someone's pet projects, I'm talking about stuff like LLVM. It seems from this and some comments below that you didn't realize that I'm simply trying to model the [RandomNumberEngine](https://en.cppreference.com/w/cpp/named_req/RandomNumberEngine) concept. (Whether or not this is a worthwhile goal is obviously another question.) One of the requirements is that the serialization functions be implemented, which is why &lt;iostream&gt; is included. &gt; Some projects can't use precompiled headers, and thus by dragging &lt;algorithm&gt; you made sure people will say "thanks, no" without reading your code. I didn't realize that, and I can probably get rid of the heavy dependency. &gt; A huge number of projects won't be able to compile your code. I don't think that anything in the xoroshiro's implementation required you to use "if constexpr" and other C++17 features (if anything, it made your code worse in this specific case, but that's just my opinion). An enormous amount of projects are stuck on C++11/14, and some can't even afford that. Also note that having C++11 (for example) doesn't automatically imply having a standard library, or even a CRT. It all depends on who you are trying to target, ofc. I'm a bit less worried about this point, and I'd like to keep the C++17 features. &gt; Some projects will reject this code because of the structure. People prefer to include &lt;fooLib/bar.h&gt; instead of "bar.h". There is a reason why the standard layout exists (you know, with all these "include" folders etc). Fun thing is that you actually have "include/rngpp/", and yet you never reference this "rngpp" folder. I only refer to "bar.h" inside the library, when writing tests/benchmarks I use &lt;fooLib/bar.h&gt;. However, this is my own convention and I'll change it to the more standard way you mention. &gt; Some people will reject this code because it tries to do what it should never try to do. If I'm using some ostream for serialization, and then suddenly I can't do that because your library decided to pre-define how exactly the operator&lt;&lt; must look, instead of making a wrapper people are likely to just, you know, not use your code. As mentioned previously, the aim of the library is to replace seamlessly std::mt19937 (or another RNG in the C++ standard library) with a more modern generator, and as such I'd like to have serialization functions implemented already. Is there a reason that this doesn't seem useful to you? &gt; seed() sounds like a getter (for both the std style and google style). That's also a questionable method without any args, but that's another topic. Same as above, seed() is part of the [RandomNumberEngine](https://en.cppreference.com/w/cpp/named_req/RandomNumberEngine) concept. &gt; One day I'll probably meet a person who likes Doxygen style bullshit in tiny classes that would be 3 times shorter with normal comments. I hope I'll be able to quickly run away, because it's unsafe to stay close to such people. Granted! &gt; It's generally easier to advertise the code if the .clang-format contains one line (related to C++ at least). If you need more than one, there better be a great reason, such as a 90Mb large blob of legacy sources that you can't refactor because each customer has their own support branch. If someone who doesn't like Chromium sees "Chromium," they will think "whatever, it's standard by now." If someone who doesn't like your style will see your style, they won't be nearly as willing to accept it as with something "standard." I should also be able to implement this. Thanks again for taking the time to write this up.
c++20 adoption in itself will be a slow process itself. In addition, modules will need support from the build system to work efficiently (not sure if that is also true for standard library). Also, the exact performance characteristics of c++20 modules or using the `#import &lt;standard-librar-header-syntax&gt;` are completely unknown at this point. This proposed forwarding header could easily be provided under earlier standard versions as a common extension (similar to feature test macros or even pragma once). Which would address the main problem I see: We would have needed something like this 10 years ago. Not x years after modules, so unless this can somehow be used without c++23, it may be of little practical value.
Tell that to (embedded) companies that provide old toolchains (e.g. based on GCC5.5). I don't even know if there is a C++17 compiler that is qualified for safety critical systems.
If you use SFML it does context creation and handles a lot of OpenGL for you, if you're trying to interop with a non SFML opengl context then I have no idea, you probably wouldn't be able to use SFML to render to a non SFML created window (without going through OpenGL and doing the rendering yourself) Glew is fairly orthogonal as far as I'm aware and should work fine, although if you stick to pure SFML you won't need it As for tessellation, I don't believe SFML directly provides it, but as with everything in SFML you can poke at OpenGL directly if you want
I’ve argued before that not having custom attributes is a completely wasted opportunity and frankly makes the reflection standard somewhat dead on arrival for the game dev space. So 100% with you on that one but not sure what the committee will ultimately do. Without custom attributes all of us are going to stick with our preprocessor based solutions.
If you need `&lt;iostream&gt;` anyway, it's not worth dropping `&lt;algorithm&gt;` IMO.
Aha, as a common extension it would make sense. I agree with these and from a neighbour reply' points too.
yep, that is a major issue !
Good to know. That still leaves the question if this will actually be as fast as this fwd header. But that aside, I think the usefulness of this header will stand and fall depending on whether there will be official or unofficial backports for pre-c++23 modes for common standard library implementations.
You didn't have to write all this up, I was just curious. Being atomic would just serialize the state mutation. I know that it's likely to be an exotic use case or simple at the expense of performance, which is why I added the caveat in the first place.
Is this stack overflow? I would have to see evidence to buy that it would be 'very slow' but either way it is a curiosity that isn't about raw throughput of course. It would serialize the state mutation so it might have some uses over a mutex approach.
I recently removed precompiled headers from my personal project. When they work they were fine, however updating to VS 2019 just broke them somehow. With forward declarations and pimpl the project takes basically the same amount of time to do a full build and is far less dependant on specific VS or Cmake versions.
Looks bug-prone to me, because you need to repeat yourself when using the macros. (Or am I missing something?)
Of course one question is: Do you care if some large scale project like llvm or others that you'll probably never hear about use your code in the first place. Most of the point mentioned by AppleBeam are imho non-issue. I really don't care what format a 3rd party library uses for its code and not everyone is so concerned about including standard library headers for types that aren't commonly used in interfaces). Also c++17 might not be too common yet, but gains momentum quickly.
You don't need to include &lt;iostream&gt; to use &lt;istream&gt; and &lt;ostream&gt;. Generally, you should always avoid it unless you absolutely need cin/cout etc.
He doesn't need &lt;iostream&gt;.
I'd say that depends very much on how much time this would save. This forwarding header is already extremely light weight and I doubt you'd gain much by further subdividing it.
I have GLEW with GLFW, so like it's about the same as SFML without the audio. My friends currently helping me right now all work with GLFW. I'll use SFML as a backup, thanks.
this is not in the standard as far as I can tell. And (personally) I hope it won't get there. import &lt;vector&gt;; I can live with, but the paper you're referring to makes #include special case for stdlib headers in a way that will probably not make it into the standard. Update: indeed the special case of #import turning into include didn't make it into the latest draft standard (good). But header units themselves did, as a way to say "I'm OK with you assuming the header doesn't change import to import" (should result in some fun bugs).
Indeed! Quoting [cppreference](https://en.cppreference.com/w/cpp/header/iostream): &gt; Including `&lt;iostream&gt;` behaves as if it defines a static storage duration object of type `std::ios_base::Init`, whose constructor initializes the standard stream objects if it is the first `std::ios_base::Init` object to be constructed, and whose destructor flushes those objects (except for `cin` and `wcin`) if it is the last `std::ios_base::Init` object to be destroyed. Including this from a header will necessarily affect every translation unit that includes it whether it uses standard I/O streams or not – unacceptably heavy.
Well, people who don't care about their code being used probably won't be open-sourcing it and making a post about it on reddit. I could be wrong, though.
I mistook you for the OP, sorry.
LEWG approved it - http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1502r0.html I don't think it was seen by LWG yet, I could be wrong. It does not special case the standard headers - per say. Any include (not just standard ones) can be implicitly made into a import at the compiler discretion, which I guess msvc and other compiler will implement as a flag or a file or something that I wish will be specified by SG15 but is currently implementation defined. That paper applies that implicit interpretation of headers to standard header based on the assumption that standard headers are not affected by the processor state - this of course not the case as implementers have macros for debugging iterators etc but this didn't stop us. However, while you would be allowed to do that implicit interpretation, i don't believe you would be required to.
OK it looks like it may be in the standard, I can't find it in the latest draft but I do see it in "merging modules"
Best avatar ever. Hope SAC will be available in Netflix someday
This is going to be awesome to see! It would be great to finally have hard statistics on how much dev time can be saved by cutting down compile times with some simple project config shuffling.
I watched a couple episodes before my internet decided it hated torrents, but since then I've noticed the Laughing Man all over the place.
The question is: Used by whom. I know many small projects, for which none of your points would be a problem, maybe that is enough for the OP. And let's stay realistic: Very few big / mature c++ projects will start to take a dependency on some small random OS library on github before it has been around for some time anyway.
Oh dear, I remember coming across this in the first C++ class I ever took. That was an extremely painful thing to figure out.
This came straight out of a C# programming book.
I think calling this value range analysis a scalar-evolution is wrong. Basically, if you don't have a FPAddRec, then it does not describe the evolution, no? This is a great lazy value range analysis.
Just learn both. Right now I’m converting html5 canvas vanilla JavaScript to SFML c++ and back. A lot of head bashing and bouts of discombobulation spiked with moments of eureka and it’s a love hate relationship. :D
Qt widgets are easy to start with, but becomes difficult if you want to improve look and feel. That's why there are very less qt apps which look like telegram. Qt quick is easy to customize. Qt widgets doesn't work well when you use for touch screens(like embedded devices). Even if you want to use qt quick, you need to know the basic Qt(model, view, delegate, signal and slots, events, etc.), and doing everything in Qt quick will be over engineering and slow.
get acquainted with /r/cpp_questions
Блокирао си ме на твитеру
Isn't it undefined behavior to declare things in the std namespace?
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bz604f/problems_building_poco_for_windows/eqq9t5n/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; my University primarily did everything in Java Coding in universities is rarely done so for production purposes but for academic purposes.
Is there a reason to use forceinline at all?
Regarding &lt;iostream&gt;: I didn't look at your code, but could you get away with just using [&lt;iosfwd&gt;](https://en.cppreference.com/w/cpp/header/iosfwd)? I suspect you just need the forward declared types to meet the RandomNumberEngine concept, and not any of the extra baggage the rest of the stream headers give.
Sorry, but you are missing something. You can't just do REFL_FIELD(x, y, z) and expand it with some clever macro trickery, since every field can have different attributes. Besides, there also are different member types (currently functions and fields), and the code generated for them needs to be different.
I started by providing granular forwards but the per file overhead turned out to be bigger than the gain. 3ms for forward declaring pretty much all std types is quite a good deal imho.
[I am excited and fearful](https://www.theverge.com/2018/12/8/18131929/netflix-ghost-in-the-shell-sac-2045-shinji-aramaki-kenji-kamiyama-2020-anime)
I'm not going to take your nonsense survey so that I can check your nonsense blog later for the results.
It doesn't have anything to do with C++ directly, but in the bigger picture I believe it does go hand in hand. Yes, this is my first post here! I wasn't sure how well received the survey was going to be with this specific audience, but I figured I'd throw it in because it couldn't hurt. But I am genuinely interested in every single response and am careful as to what communities I post it in. No worries, you don't have to take it. When I get the results and the post goes live on Nir Eyal's blog, I'll post it back here if you want to check it out.
Well, the whole point of using a small fast rng is that it should be small and fast. If you use an atomic or a mutex for such an rng it will be dramatically slower when you have lots of threads that make use of it. It's not difficult to write a benchmark, you might be surprised how bad atomics are
\&gt; or do they instantiate it with all possible types? &amp;#x200B; That is impossible, because there are infinitely many types. For example `std::vector&lt;int&gt; , std::vector&lt; std::vector&lt; int &gt;&gt;, std::vector&lt; std::vector&lt; std::vector&lt; int &gt;&gt;&gt;.` As far as I see, the compiler looks at 1. instantiations that are declared by the user (template classes and template functions) 2. instantiations that are automatically inferred (template functions and template constructors).
Off-topic; removed.
I just added a workaround for the bug that caused clang to fail compilation on this example. The example is now compilable with the latest version. Clang does too completely optimize the call to Point::magnitude(), but only with -O2. (It still is extremely cheap.)
Ooooooohhhhh
Seems like a very good initiative to reduce compile times. Would be great to hear some official feedback on using this from MSVS, Clang and GCC compiler developers. I.e is there any potential bugs using this?
It's a bit harsh that you got downvoted for this. That was my understanding too.
Happy to answer any questions.
I'd say go for Qt Quick. Writing declarative UI code is such a nice way to work, even if it can be a struggle in the beginning. Consider reading/browsing the [Cadaques](https://qmlbook.github.io/) book to avoid most of the beginners' pitfalls.
Thanks again for your input. I've taken your comments into account and done the following. * Removed completely the dependency on &lt;iostream&gt; and &lt;algorithm&gt;, as well as &lt;iterator&gt; where possible. * Fixed the static_asserts and made the jump functions only be implemented with the recommended parameters. * The library now uses clang-format with Google style. * Standardized the include convention. * Added proper references to all the short public domain implementations in the docs, as well as a "credits" file. This will hopefully make things clearer. Thanks for your help!
Thanks! Do let me know if I missed any good modern RNG. I included all the ones that I could find that did not yet have a complete implementation of the RandomNumberEngine concept.
Indeed, only &lt;iosfwd&gt; was needed. I was not aware of the size of &lt;iostream&gt;, and will keep that in mind in the future.
&gt; I don't even know if there is a C++17 compiler that is qualified for safety critical systems. I don't want to argue about this, I'd like to understand. I would like to understand how/what makes old/outdated compilers more 'qualified for safety critical systems'? On nix I sort of can guestimate. On Windows, the use of old compilers just ties you in to old crt's, which definitely are a safety hazard [so, I don't really get it].
I would be surprised? Cmpxchg16b on has around an instruction latency of around 22 cycles, while cmpxchg8b has around 11-15 cycles of instruction latency depending on the architecture. Real world performance ends up being around 2 - 10 million / s on Sandy bridge and ivy bridge for various atomics under contention in my experience. I don't know if I'm going to be __that__ surprised. I didn't ask for someone to patronize me based on what they guess I already know, I just asked if there are any random number generator with 128 bits of state, (which you didn't answer btw).
&gt; but becomes difficult if you want to improve look and feel That's the main reason I don't like Qt. It just doesn't look "right".
It's already commented on by the author: https://www.reddit.com/r/cpp/comments/bz11bb/stdfwd_forward_declarations_for_c_std_headers/eqokwhx/
&gt; The whole code feels really Java/C# like Doesn't UI code (in general) tend to look very OOP-y?
These safety critical applications are almost all embedded systems, so Windows is irrelevant except as the compilation host (which does not need to be safety critical). The two things which can make for safety critical software are the development process (which is slow and expensive), and/or lots and lots of testing. This combined with the fact that the safety critical world is a fairly small corner of software development means that anything in the mainstream takes a long time to filter through.
Is it meant to be consumed by other tools? Because syntax looks very complicated. Much like augmented Makefile. My prior experience is no good, while looking at many of constructs there is no way to even suspect what they might do. This is not a good thing for something intended to use by humans directly.
No worries. Thank you - won't happen again!
I grew intolerant, over the years, of people doing baroque convolutions when a very simple alternative exists, of not being able to write stand-alone repro cases quickly, of making stuff that should be any professional programmer’s bread and butter sound like arcane incantations. I admit to that :/
&gt; I actually take it as a compliment when someone who use Java/C# says that my C++ feels or looks just like Java/C# It's generally not a compliment. &gt; something else wrong than naming conventions, what actually it is? I don't think your code can be fairly judged by these two snippets. :) But your style seems odd and alien. It's like you're trying to turn C++ into a different language. Why bother wrapping stuff in a `self` member of an anonymous struct type? The code seems to be heavy on classes and mutating states. Your `Text::empty` reminds me of how I used to define constants of user-defined "value" types in Java: public class Complex { public final double re; public final double im; public static final Complex zero = new Complex(0, 0); // &lt;-- Complex::zero public static final Complex one = new Complex(1, 0); // &lt;-- Complex::one public static final Complex i = new Complex(0, 1); // &lt;-- Complex::i public Complex(double re, double im) { this-&gt;re = re; this-&gt;im = im; } ... } In Java this would be an optimization to avoid the dynamic memory allocation of `new Complex(x,y)` whenever you need a value of one of those constants. In C++ you tend not to need those constants because it doesn't force this dynamic memory allocation onto you whenever you want to instantiate a class. I can see a reason why you used `return Text::empty;` instead of `return "";` or `return {};`: You like function return type deduction. But in this case, in my opinion, it's not a good idea because you could have easily expressed the return type explicitly to make the code more readable. BTW: What's the magic behind your `sql` initialization? Did you abuse macros to make this work?
Hey I just came across build2 while googling at work!(my first job) I need to get a compilation database for an existing, large project on VS 2008. I want to run Clang static analysis on it. Is this the right tool to do that?
Wrong subreddit, and please read https://stackoverflow.com/help/minimal-reproducible-example
While you can produce a compilation database with `build2`, it won't be able to auto-magically do that for an existing VS project.
1. It takes time &amp; effort to qualify these compilers. 2. Some people argue with an older compiler being "proven in practice" For real embedded systems windows isn't really relevant. But sure, you probably use an old stdlib as well (for the same reasons) - if you even use one.
It can be used as a target by meta build systems, for sure. However, it is primarily meant to be used directly. Complaints about syntax being very terse and too Makefile'ly come up regularly and there are some valid points, I am not denying that. While many believe the `make` language is the worst thing ever, we believe that its core, the dependency declaration (`&lt;target&gt;: &lt;prerequisite&gt;`), is sound. So we took that core and danced from there. I do believe that using TAB or delayed variable expansion were mistakes in `make` and you won't find any of that in `build2`. If you want a short, 1-page "`build2` philosophy" summary, check out [Introduction](https://build2.org/build2/doc/build2-build-system-manual.xhtml#intro) in the build system manual.
1. I was confused at first thinking this might be a release of Boost.Build, which installs the executable `b2`. You acknowledge some other complaints about the name in the FAQ. 2. CMake also generates "solutions" for IDEs. Is build2 capable of that as well? Seems like it's not a design goal.
The word "qualified" is being used in a somewhat technical sense here. For safety-critical systems, the development tools go through a formal qualification process that involves detailed analysis and testing of the specific configuration of those tools. Any subsequent changes to those tools, however minor, would require a disproportionate effort to re-qualify them that usually does not yield a sufficient payoff (e.g. new language features).
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Holy crap. On the one hand, I really like the flexibility (and can see myself actually using it), on the other hand, I don't see how to get some proper vocabulary types out of it as in: "This is the type all libraries should use to represent a 3d vector in their interface to ensure easy interoperability" . I also wonder, what compile-times and error messages will look like.
There is an effort to resolve this problem too. It's very experimental, but there might be an update shortly.
As an implementer whose life becomes pain if someone does this I'm obligated to downvote, sorry :/
I had this project on [my todo list](https://i.imgur.com/wPb7wNP.png), I'm SO GLAD you took the burden from my shoulders! HELL YEAH! If you need any help (say, getting different headers for each version of the standard, etc.), lemme know. Suggestion: stdfwd is verbose. Just use \`fwd\` as the namespace. Good job. :D
Could you provide some context why this makes life for implementers harder? The public signatures of the types are fixed by the standard, no?
Third-party Linux binary packages (Debian, Ubuntu, CentOS/RedHat, and Fedora) also updated. Link on the bottom of [build2 install](https://build2.org/install.xhtml) page.
Thanks! Yeah `stdfwd` is a bit long, I agree. But I'm not sure if I _really_ want to use this project because it is UB. Ideally, I propose to add this to the standard, it is accepted, and in C++23 we don't need another namespace but have `#include &lt;fwd&gt;` which forward declares everything in `std`.
Not generally, no. It's worse for function templates but the standard reserves the ability to change things around. If the header is *in* the library I have no objections because then implementers can test the thing and fix it up when things change.
Thanks for the answer! I'm not sure why people would want to forward declare function templates but ok. I'm only proposing types ;)
I personally think that build2 or indeed any other build tool should support any IDE. This idea is partially what led to meta build-systems which are an enormous pile of never properly working non-sense Instead, IDEs should support build2. But you might argue that build2 is not popular enough for IDE vendors to care about especially given there are hundreds of build systems out there. That is true. Instead a good solution would be for build systems and IDEs to share a common protocol interface such that IDEs could query any build (even in a language agnostic fashion), as IDEs mostly care about targets, files known toolchains and per-file compilation flags. A similar thing exist for completion, refactor etc https://microsoft.github.io/language-server-protocol/ Using the same philosophy would help the community select the build tool they want independently of the IDE they want.
1. Yes, there is a bit of unfortunate confusion here though we never use `b2` in our naming anywhere -- it is either `build2` or `b`. 2. Correct, `build2` is a *native* (as opposed to *meta*) build system. While it cannot generate IDE project files, it also doesn't require a separate generation step. Also, these days modern IDEs (like CLion) support integration with third-party build systems via the compilation database.
Yes, thanks Alex!
OK that makes more sense. The earlier "Merging Modules" paper had some more wording about turning #include into import. Am I correct in thinking that even the implicit change won't break people who do stuff like importing &lt;istream&gt; and then using stuff from &lt;limits&gt;?
For example, if we want to put different IDL levels in different inline namespaces in a future ABI breaking release to allow them to coexist in a single binary to a limited degree, that would break this.
No it should not because all these headers are supposed not to be affected by one an other and everything is imported in the global modules fragment where duplicated definition are deduplicated (my understanding is a bit shallow at this point, sorry). However if you compile one TU with -D_iterator_debug_level and another without it will probably expose weird undefined behavior. LEWG decided not to care as this is already UB even it it might be "silently working". I hope that makes sense.
Yes, I think IDEs are slowly drifting in that overall direction. Currently we are at the stage where the "state of the art" is the compilation database plus some hooks in the IDE to invoke the build system. But it's plausible in the future it will become some kind of a client-server protocol. On our side, in the next release or two, we are planning to split the build system into the library and the driver. This will allow implementing something like what you've described or even linking `build2` directly into the IDE for a pretty tight integration. If anyone is interested in playing with any of this, do let me know.
Currently such "common protocol interface" is Compilation DataBase. Many tools support it. IDE also needs to run build for project. That's all. IDE to work needs create his own internal project model just to highlight sources. So IDE needs to know how each files compiled (define's, compiler arguments...). It can get this info from Compilation DataBase file and create his own project model. IDE do not need more information, then compiler and linker get from command line arguments. Also IDE needs custom build command to run build system. Nothing more required. Actually in last CLion this mode was implemented (in addition to native cmake support). IDE monitors compilation database file for changes (to reflect this changes in internal IDE project model) and allows provide custom commands to run build.
\&gt; It just doesn't look "right". It's not true, it's usually difficult to make it look stylish. &amp;#x200B; There are many commercial applications where qt looks decent, a perfect balance between performance, look &amp; feel and portability. e.g. are \- qt-creator \- kde applications \- telegrams
It's a "the devil we know" kind of thing. Doesn't mean they aren't bug ridden but they were very expensively stamped.
I recognize that blue hair...
I'd say it would be nice to add a cryptographic rng, from what I have heard ChaCha20 is very good
I think OGRE is pretty popular.
OGRE is great for starting out.
I didn't watch whole 1,5 hours, but how this is going to work on hardware? When math library is a single third-party library, all that math can be optimized for x86, arm and so on. I mean SSE and stuff like that. But when it's in standard library, what does that mean for optimizations? Every standard library provider will have to optimize their implementation for each hardware platform? Or does that imply that same standard library is shared across all toolchains and has same level of optimizations or what?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bzgvo8/need_suggestion_for_opengl_rendering_library/eqsjgow/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
STL implementers already have to optimize for each targeted platform. For example, I’ve worked on improving charconv/Ryu’s perf for x86 and x64 separately. (I haven’t directly optimized ARM and ARM64 but we care about them too.)
But compilation databases don't say *why* a flag is present there or not. In CMake, is it there from `add_definitions`, a manual `set_property(DIRECTORY)`, dependent project usage requirements, `target_compile_definitions`, etc. IDEs can use the compilation database for the source code itself, but it doesn't help with editing the build recipe files either which is something people really want.
Generally library vendors are free to provide any optimizations that they want, or compilers can be taught things like how to vectorize instructions. There's not just one standard library there's libc++, libstdc++, Microsoft , Intel, etc. Library proposals often come with a "here's a reference implementation" but are mostly documentation about the interface and not a specific implementation.
My concerns are more like this: i'm compiling, for example, for Windows with its stdlib and getting OK results because it's optimized, when i'm compiling for another OS with different stdlib, or still for Windows, but with different compiler with its own stdlib, and i'm getting what results? Are there going to be any requirements regarding optimizations or shall i assume that if use vector math from stdlib then in worst-case scenario i'm getting no optimizations at all?
!stoptotalitarianism &amp;#x200B; Isn't it a genuine question ?
That's what /r/cpp_questions is for. Getting-started/help-with-coding questions are off-topic here.
In the Standard world, this is known as "Quality of Implementation". You are always at the mercy of your Standard Library implementers when it comes to performance.
This is already the case with the standard library. In the worst-case scenario you are getting no optimizations at all. Of course, the major providers are not providing worst-case scenario implementations. &amp;#x200B; What is it that you are looking for. Do you want the standard to say: Here is the interface ... oh, and it has to be optimized."? At best the standard will guarantee algorithm order. It will make no other implementation guarantees (nor should it). &amp;#x200B; You are correct that "When math library is a single third-party library, all that math can be optimized for x86, arm and so on depending on platform" but it is also correct to say "When math library is \[in the standard\] library, all that math can be optimized for x86, arm and so on depending on platform." &amp;#x200B; I hope that you see now that although your concern may be appropriate, your fears are not.
&gt;What is it that you are looking for Portability. I understand that optimization levels might vary from stdlib to stdlib, but in other parts of stdlib there might not be hardware optimizations specific for the domain while for vector math there are very specific hardware instruction which i would like to see used in implementation because software i'm writing simply doesn't work well without them. It would be really nice if this would be at least taken into account somehow. I'm sure stdlib implementers can do their job very well, but sometimes i don't have a liberty to choose stdlib or compiler too and it's not clear to me how to combat hypothetical lack of hardware optimizations in a stdlib.
I think there is an attempt to standardize a build system protocol too, but did not get much traction (yet?): * [https://www.scala-lang.org/blog/2018/06/15/bsp.html](https://www.scala-lang.org/blog/2018/06/15/bsp.html) Right now, CMake has a 1 or 2 APIs for IDEs, but this is a custom protocol.
I wasn't aware, thanks a lot for sharing that !
I may have missed something in the article but I am interested to know more on how continuous integration builds are managed in your workflow. I am assuming there is another component of this product that deals with scheduling the builds and uploading the reports. i could not find any details but I would like to know more. thanks!
How is this supposed to fit in the current ecosystem of already well established linear algebra libraries that can do most of what we want? If I understood through a quick watch, it will implement a lot of linalg but not a lot. Instead of immediatly going their libraries, they'll do some work in std::math, then couple what they obtain into the libraries they use? In another tiny example, random number generation. I use the std just for quick prototypes. But for any reasonable case, I don't use them. Still would be nice to have.
Does telegram use QT widgets or QT Quick?
We are using Jenkins currently (sad face), it will trigger on every commit and kick off integration tests, which are run under ASAN and configured to automatically upload all the ASAN logs. The integration test suite will HTTPS POST the raw ASAN logs into [morgue.backtrace.io](https://morgue.backtrace.io), passing along relevant key-value attributes (developer's name who triggered the build, test name, commit information and so on). The aggregation of the memory errors itself is designed to not require any installation of tools locally and so should integration with any CI system (this started off as a locally installed developer tool, but we wanted to avoid installing extra dependencies across our environment and decided to switch to an HTTPS service for that reason). &amp;#x200B; In addition to this, developers will run this same suite locally during development and that's also configured to automatically upload reports so they can easily search for their own errors. They also get alerted in a Slack channel if their build introduced a new bug (the issue must be marked as resolved and run must be clean with respect to non-benign issues before merging into master). &amp;#x200B; Lastly, we have test nodes that are configured to run ASAN 24/7 (usually off the tip of master) that other teams use for development purposes, which gives us additional coverage. This stores ASAN logs on disk which we can later post-process. &amp;#x200B; Two improvements we are working on: \- Post-processing the test instance that runs ASAN 24/7 is manual right now. Just need to add a curl invocation to upload the ASAN logs to the instance. \- Production mirroring to 24/7 ASAN nodes. Currently, our integration test suite runs a corpus of blessed production data through the software under ASAN. However, this doesn't ensure we get full coverage from production. Early next quarter, we'll be investigating mirroring anonymized production traffic and streaming configuration state on test nodes that are running ASAN 24/7 (this is a bit more complicated for us, as we have to be very careful about transferring, storing and deleting the data).
This hypothetically would be (partially) supported with an [LSP](https://langserver.org/) service for a particular build system and its files, not by building support for an IDE into the build tool. Even build tools that came bundled with particular IDEs were never able to do what you're suggesting with any real accuracy. :p For example, the old-style Visual Studio property sheets. You couldn't really tell easily which property sheet set a property on a particular target/intermediate in the UI. The property sheets only really worked for the simple cases (and would be totally broken as soon as you needed any kind of advanced MSBuild configuration), since doing anything like that for a Turing-complete language is somewhat troublesome. What you really want is probably a build system debugger with a [DAP](https://microsoft.github.io/debug-adapter-protocol/) mode that lets you set breakpoints and step through the build system.
Yes, You need to edit build recipe manually (del, add files). Refactorings like rename file or rename class which leads to rename file also become unavalable in IDE. IMHO, manual editing build system files is best way (with good build system, not xml backed). But this is true only for programmers with system administration background. Most developers prefer MSVS project configuration style (GUI). By the way, in build2 widely used way to add files to target is add all files in this directory recursively: lib{test}: {hxx ixx txx cxx}{\*\* -version} hxx{version} So after add, rename, remove files You just need to recreate compilation database, but of course this do not eliminate problem totally (and this is not what familiar MSVS style user want).
I know this is a late response but the guide doesn’t formally indicate how to “become” a reviewer — i do not have access on EasyChair. If you need additional submissions reviewed I’m available to do so.
Looks good! Is there any runtime performance impact?
&gt;In another tiny example, random number generation. I use the std just for quick prototypes. Do you mean &lt;random&gt;? From my understanding (perhaps incorrect), this header is one of the finest implementations of random number generation there is.
I don't try to turn C++ into a different language. I just try use plain C++ like a domain specific shiny tool, so it not looks like a rust, when I use it with relational database. Main point for self wrapping is that I don't like m\_member or mMember style naming and I want that self.member style is forced: no class private member reference without self-point notation, so local variables with same name can't be confused with class members. I agree that I am lazy when I usually not use const for local variables or private methods or lambda parameters in application code (shame!) - my library methods and functions parameters are correctly const corrected (rejoice!). Not rationale reasons, but I usually use Text::empty. Maybe it is not so good thing to always over use auto, but usually good variable names are more important than type names in application local context. I think that C++ preprocessor is still so wonderful tool with #-operator that it is insulting said that using macros is abusing. So I use macros to make sql working. Example try to tell how I use relational database with some kind universal relation assumption variation and why 'universal&amp;'-parameter usually is without const in local context (same key-value map is used usually in many sql-clauses as in/out parameter). ///////////////////////////////////////////////////////////////////////////// auto procedureOf(Text const&amp; script) -&gt; procedure; auto operator "" _sql(char const* script, std::size_t) -&gt; procedure; #if !teroxNoMacros || teroxNoMacrosExceptSql #undef sql #define sql(...) = #__VA_ARGS__##_sql; #endif ///////////////////////////////////////////////////////////////////////////// struct universalAsAttributes // partial of application universal relation tuple ( actionIndex { this, "actionindex" }, arrivalTime { this, "arrivaltime" }, companyId { this, "companyid" }, customerIndex { this, "customerindex" }, customerNumber { this, "customernumber" }, deliveryDate { this, "deliverydate" }, deliveryNumber { this, "deliverynumber" }, orderDeliveryDate { this, "orderdeliverydate" }, quantity { this, "quantity" }, referenceId { this, "referenceid" }, referenceName { this, "referencename" }, referenceText { this, "referencetext" }, remarks { this, "remarks" }, routeNumber { this, "routenumber" }, routeType { this, "routetype" }, warehouse { this, "warehouse" } ) ///////////////////////////////////////////////////////////////////////////// namespace { auto phoneNumberOf(universal&amp; action) { ... } auto deliveryTimeOf(universal&amp; action) { ... } auto appendReference(universal&amp; action) { static auto selectReference sql ( select referenceId from Reference where referenceName = :ReferenceName and referenceText = :ReferenceText and companyId = :CompanyId and customerNumber = :CustomerNumber and customerIndex = :CustomerIndex and routeNumber = :RouteNumber ) static auto insertReference sql ( insert Reference set referenceId = next value for SequenceReferenceId, referenceName = :ReferenceName, referenceText = :ReferenceText, companyId = :CompanyId, customerNumber = :CustomerNumber, customerIndex = :CustomerIndex, routeNumber = :RouteNumber, creationName = 'Sms', creationTime = current_timestamp ) action.referenceName = "DeliveryTimeSms"; action.referenceText = format ( "Estimated delivery time at %", action.status == 3 ? "7-17" : action.status == 1 ? "7-13" : "11-17" ); if(!selectReference(action)) { insertReference(action); } } } auto sms::sendDeliveryTime(universal const&amp; route) -&gt; void try { auto smsFormat = textOf(rSmsDeliveryTimeTextFormat); if(!smsFormat || !boolOf(rSmsDeliveryTimeSend)) { return; } static auto selectRouteActions sql ( select companyId, warehouse, routeNumber, actionIndex, deliveryNumber, arrivalTimePlanned, customerNumber, customerIndex from RouteAction where companyId = :CompanyId and warehouse = :Warehouse and routeNumber = :RouteNumber and actionType = #ActionTypeOrder order by actionIndex ) static auto updateStatus sql ( update Delivery set deliveryTimeSmsStatus = :Status, updateName = 'Sms', updateTime = current_timestamp where companyId = :CompanyId and warehouse = :Warehouse and deliveryNumber = :DeliveryNumber ) auto handleAction = [&amp;](universal&amp; action) { action.status = 0; if(auto phoneNumber = phoneNumberOf(action)) { if(auto deliveryTime = deliveryTimeOf(action)) { auto message = format(smsFormat, deliveryTime); if(sms::send(phoneNumber, message)) { appendReference(action); } else { action.status = -intOf(action.status); } } } updateStatus(action); }; for(auto&amp; action : selectRouteActions[route]) { try { handleAction(action); } catch(Exception&amp; ex) { logExceptionDataAs(ex, action); } } } catch(Exception&amp; ex) { logExceptionDataAs(ex, route); } /////////////////////////////////////////////////////////////////////////////
I'm guessing he means using srand()/rand() out of stdlib? The result is only pseudorandom so you would never use it for production/something you actually need a random number for -- good talk about how it should be avoided here: [https://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful](https://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful) &amp;#x200B; However, &lt;random&gt; introduced in 11 is, as far as I'm aware, about as perfect an implementation as you can get. u/Low_discrepancy, have you come across a reason not to use it or were you referring to rand()?
It's a super useful design pattern, and the Badge class is a particularly nice take on it - I always end up writing one-off private helper classes to do the same thing. The one downside of this pattern is that people who haven't seen it before always stare at me incredulously when I explain it!
Might it be possible for the standard to support optionally handing off calculation to a hardware specific dynamic library that implements a specific interface but does so in hardware?
Having watched the 1.5 hours, it looks like actually it is possible to integrate your 3rd party library. The vector and matrix types are wrappers for an engine, which has a couple defaults but can be overridden. If you want to implement your engine in terms of some existing type that your 3rd party math library supports, then you can do that. On the platform where your library gives good results, you can declare your matrix types as wrappers around an "engine" which implements operations using that library. On the other platforms you declare your matrix types as default and get the stdlib implementation. It does look like it would be a bit of an adventure writing that "engine" -- looks like not any code required at all that would cause runtime overhead, but quite an adventure in getting your template parameters defined just right to hook in your library. I think writing the wrapper to integrate this new API with existing optimized matrix libraries would be a job that the 3rd-party library implementer themselves is more likely to do, rather than Joe Math Coder who is more comfortable with FORTRAN.
This is... a really nice pattern! I’ve never seen it before, but I like it. It’s a way for the class with private-ish functions to give authorization based on. And the badge idea can be to a variety of other use cases. I’m definitely gonna use this :).
Great pattern that I've used a few times, though I know it as the pass-key or attourny-client idiom. One important detail that this implementation does correct but the prose does not make explicit, I'd that you have to add something to the class to disable aggregate initialization. Had they defaulted the ctor instead of giving it an empty definition, anyone could construct an instance via a set of empty braces.
Also called the Attorney-Client Idiom, see http://www.drdobbs.com/friendship-and-the-attorney-client-idiom/184402053 https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Friendship_and_the_Attorney-Client But I prefer the name "Badge" :)
The RNGs in `&lt;random&gt;` are actually not that good.
Could you elaborate on that?
Why not just give a device an interface to register with the VFS instead of interfacing with the VFS directly?
In xorshift.hpp you have the `min()` function return `std::numeric_limits&lt;result_type&gt;::min()`, which is always 0. But `min()` for xorshift* PRNGs should return 1, since 0 is an illegal state.
Not really, as I'm not am expert on this, but there are some relevant links here: https://www.reddit.com/r/cpp/comments/byz0f8/rngpp_a_collection_of_modern_random_number/ And I know I've read similar statements somewhere else, but I'm too lazy to search.
This is even true for all libraries, not only standard.
This actually doesn't add to your point. The Gertsmann piece is on pseudorandom generators, so more like rand(). pcg-random states "most random number generators in widespread use today have one of the following problems" which is actually not specifically talking about &lt;random&gt;, nor do the problems apply. There are valid concerns with &lt;random&gt;, however none of them have to do with the algorithm itself being bad -- just that if you're using it in cryptography or other high-stakes applications, the implementation of &lt;random&gt; DOES store in memory so there are better options for randomness -- see Microsoft option [https://docs.microsoft.com/en-us/dotnet/api/system.security.cryptography.rngcryptoserviceprovider?view=netframework-4.8](https://docs.microsoft.com/en-us/dotnet/api/system.security.cryptography.rngcryptoserviceprovider?view=netframework-4.8) and read its justifications.
I'd advise against pimpl. lots of overhead for small gains with slightly slower code
&gt; From my understanding (perhaps incorrect), this header is one of the finest implementations of random number generation there is. The implementation is taken from boost so of course it will be high quality. But it's high quality from a programmer's POV. To my knowledge, it doesn't have any parallel generation capabilities, other than using kludges like every thread getting its own generator. But there are no guarantees of good statistical properties if you do that. There's little (and I'm being very generous) maths done for that. And generating pseudo random numbers in parallel is the second thing you want to do because of the Monte Carlo algorithm and central it is to probabilities. After this, another issue is implementation for some basic rv distributions. The normal distribution is such a basic one to want to generate, yet many times I've seen the Box Muller method which is kinda slow. I don't know if I've seen any ziggurat method which tends to be the fastest. And normal distributions are so essential. While from a programmer's POV it's a very beautiful design and I've learnt how to improve my code by reading it, from a user's POV, it's more for prototyping, developing quickly some little code.
I think it goes to the territory of trying too hard. The C++ type system isn't sound enough to deter misuse of APIs - it just takes a bit more work to do so here. Before including "vfs.h": template&lt;typename T&gt; class FakeBadge {}; #define Badge FakeBadge Now, depending on the Device's implementation, the above either circumvents the restriction, or results in a compile error.
Interesting pattern, I haven't seen it before. Will it work for template functions too? &amp;#x200B; template &lt;typename DeviceType&gt; void register_device(Badge&lt;DeviceType&gt;, DeviceType&amp;); //... Device::Device() { VFS::the().register_device(/* won't template deduction fail here? : */ {}, *this); }
&gt; The tl;dr of it is that I wanted to write a wrapper with a pImpl class to hide the library I was using because that's good practice and good design. Why it's a good practice or design? Pimpl can often do more harm than good. &amp;#x200B; &gt; This, to me, feels like a limitation of C++ as a language, or an oversight. Maybe modules from C++20 are solution to your problem?
Why bother at all if you join the dark side? #define private public #define class struct
Put the underlying library into a cryptic namespace. Yes, technically it still will be there, but at least you won't use it directly by accident.
Perhaps off topic, but why the sad face for Jenkins? I've been looking into different CI technologies for some cross platform personal projects and I thought that Jenkins looked promising. Is there another tool that you would prefer to be using?
Great write up. Thanks for the article. Does anyone know if PGO takes those architectural effects into account?
When serializing data you obviously have some `memcpy` or `fwrite` calls (depending on whether your target is a memory buffer or a file). But that's it. The next release will contain an option to serialize to a memory mapped file (on Windows and Linux/POSIX systems) which reduced the serialization time for our application from approximately 35min to less than 5min for writing 11GB of data (while still not requiring any additional RAM). &amp;#x200B; When deserializing data, you have two options: (1) With `cista::offset`, you can start using serialized buffers immediately (**no deserialization costs** \- just receive/load/mmap buffer and start using it) but accessing the data costs one addition for each pointer derefenciation. Bonus: the buffer can be read-only which is useful in shared-memory scenarios. (2) The other option is to use `cista::raw` which has **no runtime costs** after deserialization. Deserialization for `cista::raw` is computing absolute pointers from the stored pointer offsets (which is really fast). The loaded data needs to be writable (in order to change stored offsets to absolute raw pointers). &amp;#x200B; I've done some benchmarks here: [https://github.com/felixguendling/cpp-serialization-benchmark](https://github.com/felixguendling/cpp-serialization-benchmark)
qt widgets
:-/ Replicating some of the worst ideas of make, a program that was super-cool when I started to learn programming in the late 70s and is now a legacy thing we are forced to tolerate - but inventing a new language that's a tiny bit similar but basically different from any other language around? Why reinvent the wheel? People only have finite time in their lives! You could easily have represented exactly the same structure in JSON and/or Yaml, and had a format that there exist automatic tools for - a format that everyone's editor already understands, a format that _everyone_ already understands. Yes, it would be a bit more verbose. That's actually good, not bad. It's much easier to read text than it is to read syntax. There's a reason that languages like [APL](https://en.wikipedia.org/wiki/APL_ \(programming_language\)#Game_of_Life) (my first programming language! :-o) didn't catch on. ---- Make is horrible. Makefiles are awful. But we at least understand it by now as a programming culture. Now we have this syntax. It's a little like make, but not really. It uses `{` extensively so that half your templating languages won't work properly. It uses `**` for some purpose I have yet to understand but that will make it incompatible with either bash or make. I look at a line like this - `exe{hello}: {hxx cxx}{**}` - and my heart sinks. And what happens when I make a syntax error? What debugging tools are there? How are the error messages? Can I make errors in syntax that result in a legal build2 document, but one that leads to wrong results? (I believe the answer is yes.) Is there some way to validate that something's a legal build2 document without actually calling build2 on it? If not, how are my tools supposed to write a legal build2 file? On the other side, what happens when I need to do some actual computation? Suppose I need to increment a number in some filename by 1 to produce a new filename - how would I do that? --- I hate to say this, because you seem to be very earnest and you've clearly put a lot of time into it, but I feel the whole thing is misguided. :-/
Not sure what you mean. E.g. the tables in [https://arvid.io/2018/07/02/better-cxx-prng/](https://arvid.io/2018/07/02/better-cxx-prng/) show clearly that the algorithms in \`&lt;random&gt;\` are either slow, require "huge" state, and/or fail statistical tests. The article is not complaining, that those are not cryptographically secure, but it does show, that better algorithms do exist. That doesn't make the algorithms in &lt;random&gt; bad an certainly better than \`rand\` (I actually have repeatedly argued here on reddit and other forums that they are "good enough" for many applications), but \*"about as perfect an implementation \[of a random number generator\] as you can get"\* is overselling it.
No, at least not when you are compiling with optimizations enabled: For `-O3` and `-O2` the compiler produces code without the intermediate `std::tuple&lt;Args...&gt;` step: [https://gcc.godbolt.org/z/wRe\_Wr](https://gcc.godbolt.org/z/wRe_Wr)
The optimiser already knows about these, but can do a better job if you supply the `-mtune` option on GCC to pick various limits and pipeline depths. I wouldn't expect PGO to give you much more than manually providing `__builtin_expect` annotations, these optimisations seem like a later step in the compiler.
Indeed. It's funny that people are downvoting my comment - it was not meant as a snark towards the deficiencies of C++, but rather as a point about users not being malicious, by default. I don't think the "badge" pattern improves the API in the example, rather it adds a non-trivial arg to a otherwise-simple function.
Looks like a wrong solution. `register_device` should return a RAII object that calls `unregister_device` in its destructor. This means `unregister_device` should be private and RAII object should be a friend of `VFS`.
Yes, inline namespaces are the biggest problem. Libstdc++ can be configured to put everything in namespace `std::__8` (or `std::__7` in older releases) which would be incompatible with this header (not a big problem, because very, very few people use that configuration, for good reasons). Libc++ currently puts most things in `std::__1` (though not everything, some types go directly in `std`) which this header doesn't support yet. For GCC 10 there's a chance that libstdc++ will replace `std::call_once` with `std::_V2::call_once` to fix a bug, so if this header declared types from `&lt;mutex&gt;` that could break. For IEEE128 `long double` support on POWER hardware I'll be introducing some new inline namespaces which might break this header. It might already be broken on POWER and DEC Alpha, as there are already additional inline namespaces used for some types (mostly locale facets, which aren't declared in this header, so it might be OK ... for now). Basically this header is fragile, and even if it works with your current compiler today there is no guarantee it will still work with the next release, or with the same compiler on different hardware. But as a proof-of-concept, that's probably acceptable. And as Billy said, if it was provided by the std::lib itself all those issues would be dealt with by the std::lib implementation. It's only a problem for a third-party header that isn't part of the implementation.
In case you're not aware, this was already proposed and rejected for C++11, see https://wg21.link/lwg1002 and http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2009/n2905.pdf That doesn't mean it can't be proposed again, and the outcome might be different this time (although I suspect "no, let's wait and see if modules makes it irrelevant" would be the response).
And it's in the FAQ: https://github.com/Philip-Trettner/cpp-std-fwd#faq tl;dr dae rtfa?
Thanks, I wasn't aware! I might be mistaken but that looks totally different from I want to propose: Those are include-all header, I propose _forward declarations_.
Nice read but computationally loose, Since computation is the process of mapping input states to output states (aka classification &amp; generation) it could be argued that x86 computers are capable of mapping information states extremely quickly, Yet almost no programmer ever attempts to model their task as a many-to-many mapping, it's a real time sink. The very idea of computational "speed-limits" is fundamentally short sighted and or uniformed.
Thanks for your input. I might be wrong, but I believe that although 0 is indeed an illegal state, that does not mean that the RNG cannot output zero (indeed, note that there is a scrambling of the state, in this case a multiplication by a fixed constant). This can be tested with the following code: &gt; rngpp::xorshiftstar32 g{42}; &gt; while(g() != 0) ; &gt; std::cout &lt;&lt; "Found a zero output!\n";
Thanks for taking the time to write your thoughts. I've been seeing "this all looks so foreign to me and I wish it was just JSON" kind of sentiment quite a bit, admittedly. And I've been wondering why is that. Specifically, why things like `make`, or `**`, or unwillingness to author JSON by hand seem natural and obvious to me (and quite a few others, interestingly, whose company I usually enjoy) but so foreign to others. The conclusion that I am arriving at (not surprising, really) is that a large proportion of potential `build2` users have very different cultural background and the resulting intuition. And this is a problem: things are so complex that we can't really hope to explain, document, and provide rationale for everything down to the tiniest detail -- we have to rely on intuition, on things generally making sense. I myself have the UNIX/Linux background. For the past 20+ years (basically since university), my development platform has been Linux (Debian or Debian-derivative), Emacs, and a terminal. I still think `make` is the sanest build system out there (besides `build2`, of course, which is in some way `make` reinvented for the 21st century). Anyone who used `rsync` will know what `**` means. And so on. It would be interesting to compare this to your background.
This. This is how boost would do it.
Doh, sorry, I mis-remembered what the old issue was for (and didn't actually read the issue again). There might have been a different issue for forward declarations, or maybe I'm just confusing it with https://gcc.gnu.org/bugzilla/show_bug.cgi?id=31464 in GCC's bug database.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bzptph/help_image_processing_how_to_know_horizontal/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Something like `-std=c++20`.
I think it should work if you can just be a little more specific: ```cppp register_device(Badge&lt;Device&gt;(), *this); ```
That's focusing way too much on the specifics of an example rather than seeing the bigger picture. This article isn't about RAII, it's about providing limited access to an API.
Why not inherit from an interface that's a friend to the privileged user instead? Like this: [https://godbolt.org/z/cUB8BG](https://godbolt.org/z/cUB8BG) Seems to do the same thing (albeit with virtual functions) without polluting the function signature with a useless parameter.
"Badge" doesn't express the pattern as good as "Attorney-Client" does, imo. With "Attorney-Client" you can think about it as "Client" sharing their private data through "Attorney", but "Attorney" won't give it all to you, only some of it.
I see how this game is played... let me try: Why not use a template class specifically designed to grant access to certain member functions instead? Like this: https://awesomekling.github.io/Serenity-C++-patterns-The-Badge/ Does the same thing (albeit with templates) without introducing useless runtime dispatching.
I'm fully aware that the header is fragile and while I'll use it for some of my projects to get experience with the header, it is not intended to go into production code. I couldn't think of a way to do a proof-of-concept for this proposal without either UB or forking a standard library but I'm all ears if you have a better suggestion ;) Regarding the namespaces: I tried to copy the existing library structure (with its defines). Even if I could make the header more robust it will always be UB and fragile and people should not use it in production I guess.
Yeah, I can do that, but it doesn't look just as cool now :)
I don't know, I could guess what the "Badge" pattern was just from this title. "Attorney-Client" doesn't conjure up any relevant imagery in my head even knowing what it's supposed to refer to.
`unregister` isn't even the point of the article.
I suppose something like class VFS { public: friend class DeviceInterface { friend class Device; static void Register(VFS&amp;, Device&amp;) const; static void Unregister(VFS&amp;, Device&amp;) const; }; DeviceInterface GetInterface(); }; would work - but that also uses an extra class with friend methods, so I'd honestly see it as more or less the same pattern, except expressed in a slightly more complicated (but possibly more convenient?) way.
I see it as convenience vs performance tradeoff: * Attorney-Client requires using an intermediary whenever a class needs to do something * Badge adds a bit of noise in function arguments * Friend-interface adds indirection, but makes usage more elegant There's also the issue of noise in the class declaration and interface: * Attorney-Client makes a part of the interface private, which makes it harder to discover * Badge mixes the restricted parts of the interface with the rest of public methods * Friend-interface complicates inheritance hierarchy, but also clearly divides parts of the interface by usage I guess it's also significant that Badge doesn't use friend anywhere, which might make it the only choice on some teams. Also doesn't add any classes except for the one helper, while the other approaches add at least one class-per-target. I'm too inexperienced to know which of these things is really a big deal, which is why I'm asking.
There is nothing wrong in exposing other library stuff just because it affects your public interface. Boost uses this very often, they just hide what's not indended for public use in `detail` namespace. I would even consider the thing a limitation if a library X was required to use/build library Y but would not be available as X in Y's public API.
Note, though, that public resource releasing allows you to reuse the same handle object without doing in-place destruction and later re-construction. There’s a good reason why e.g. mutex lockers provide `lock()` and `release()` methods: it makes their use way less cumbersome. It also allows to leverage an optimization opportunity if somehow locking (or acquisition) can be integrated with the mutex (or underlying context, like a filesystem): creating an unlocked object has some cost then, a cost that could be amortized as the handle is reused.
Thanks for the very polite response ! :-) I've been working in some variety of Unix for almost forty years, including make. [Here's](https://github.com/rec/Makefile/blob/master/Makefile) a model Makefile I wrote to use for my projects, so you can see what my makefile style is like. I use emacs almost exclusively - M-x praise-emacs. But you know, I stopped doing so many of the things I was doing thirty years ago, because they just aren't good practice any more - because we have learned so much in the last three decades. I am easily two orders of magnitude more productive than I was in 1980 - a lot of it because I have much better tools. Even my emacs has made astonishing strides in that time. Forty-three years ago when `make` was invented there was no good universal data language. Now there are several. &gt; And this is a problem: things are so complex that we can't really hope to explain, document, and provide rationale for everything down to the tiniest detail -- we have to rely on intuition, on things generally making sense. But that's just not engineering! You can't build robust systems starting on intuition and things generally making sense. For example, I use rsync constantly for pretty well all my data copying needs. Heck, I back up my iTunes on my Mac with it. I know what `**` means, _in the context of rsync_. I'm sure `build2`'s `**` is _very similar_ to the one in rsync, but the rules there are [surprisingly complex](https://linux.die.net/man/1/rsync). I can't rely on them being _the same_ and so I really don't get much head start there - I would guess that `**` represents "recursive", but now I have to study your details to make sure I know what's going on. More, what use is that for training new programmers to use this stuff? For every you and me with decades in the industry, there are ten people without. --- In particular, there are two "edge" cases that have become extremely common in the last couple of decades. The first one is great big huge gallumphing systems that no individual can possibly encompass - systems with millions of lines of code. This requires some sort of modularized build system where thousands of tiny little build files take information from other build files, and also lots of automatically-generated build files. The other edge case is some very clever tool or idea written by an individual or a small group that does just one thing, really well, within a larger infrastructure. JSON is a fine example of that. I've worked on both of these sorts of projects. Well, build2 as it is doesn't hit either of those two points. For large projects, it isn't modularized and there's no grammar to allow you to write files that are known to be correct. For little clever tools, it's a lot of work for them to have to read your build2 format and manipulate it. ---- I have to go back again and again to the syntax, the symbol alphabet and the grammar. Too much syntax and grammar are worse than not enough! Look. It's not like I hate syntax, symbols or grammar. I'm really good at syntactical things. In a company I worked for in the 90s, I got the nickname of "the human lint" :-D - that was a great place, even though dysfunctional as heck. My house has twenty grammar books in it - there are a couple that are almost worn out from use. But humans, in general, are better at _words_ than syntax or grammar. Again, here's a bit of APL, my first programming language: life←{↑1 ⍵∨.∧3 4=+/,¯1 0 1∘.⊖¯1 0 1∘.⌽⊂⍵} I know what each of these symbols mean, I even have a good idea of what's going on because this is a classic haiku from back in the day, but to work it out would take me literally an hour. Worse, APL's grammar is actually _simpler_ than yours! It has a lot of weird symbols, but they all behave in much the same way, and there aren't even precedence rules, it reads from right to left. APL is a high-syntax, low-grammar language. It didn't grow into widestream use because it's very hard to use unless you use it every day because of the weird syntax/wide alphabet. On the other hand, I don't know Ruby, but I'm confident that if you showed me a non-obfuscated Life implementation in that language, I could figure it out in a few minutes, and even likely find bugs if there were any. Ruby is a low-syntax, moderate-grammar language. JSON's grammar and syntax are in one page. Except for the stupid "trailing comma" mistake, any average kid could work the language out by example in ten minutes and get it right every time. It's low syntax, low grammar. ---- Now, the tradeoff is that syntax and a wider symbol alphabet is more expressive - you can say things more compactly and sometimes more clearly that way. This is especially true of programming languages where we spend a lot of our time. Would you rather write `a + b - c + d` or `a.plus(b).minus(c).times(d)`? And which would you rather _read_? But in a build system, there are a lot fewer sorts of operations with much shorter chains of operations. More, the use of syntax to represent the actual structure being built is dodgy, because then it's hard to _annotate_ that structure. For example, `build2` uses the `:` to represent the "depends on" relation. But actually, there is a ton of information that I could attach to that "depend on" relation if it weren't hidden behind syntax. If instead of the clever syntax, there was some dull Json/Yaml/etc file that listed explicitly the relations at the cost of maybe a dozen more characters, I could have better "depends" relations: * multiple dependencies (on the left side) * conditional dependencies (which you sort of have I think but you could be more general) * anti-dependencies ("turn off this other rule if this rule fires") * push dependencies (usual dependencies say "I depend on these items"; push dependencies say, "These other items depend on me") I've seen basically all these patterns in real build files in the past, usually accomplished by `touch` and magic targets. --- So yes, this will make your build files considerably longer - but typing build files is such a short part of my day. I've easily spent ten times as much time _debugging_ makefiles as typing into them. What you will get is readable build files with key information expressed in words, not syntax. You will get build files that a newbie will see and say, Oh, I can do this. You get build files that people can combine and transform with off-the-rack automatic tools that already exist today. My guess is that explicating the rules in text over syntax would add about 20% to the size of the file, maybe less (because over 90% of my non-whitespace in makefiles is file paths). My other guess is that if you told people "I have a build system that takes _50%_ more typing, but the build file format is so bone-obvious that you'll be able to use it right first time" that 99% of them would jump at the chance. --- There are definitely challenges to moving to a data-based system. Look at that Makefile again: how do you do variable assignments [like this](https://github.com/rec/Makefile/blob/master/Makefile#L38-L43) in it? (It's solvable: there needs to be some templating system where you can expand your value of `FOO` into something like `$(FOO).bar` or `{FOO}.bar`, and the ability to assign variables for those templates at places...) What about when you actually need to perform a computation? Also non-trivial, also solvable. But IMHO it's the way forward.
It’s not about making it absolutely impossible to misuse an API: after all, in any unsafe language, you can just poke the memory directly. So your point is largely moot. The idea is to prevent common mistakes and enforce proper usage by design, so that compile errors would indicate misuse. If you go out of your way to shoot yourself in the foot, then no unsafe language will stop you. Nor even a safe one: you don’t need to crash, just an endless loop will do the trick.
Variadic functions and templating are not meant to be compatible. Variadic functions are a C functionality that also exists in C++ because of legacy reasons, that has nothing to do with templating which is C++. This isn't an oversight, templating is just meant to wholesale replace variadic functions and I've honestly never had a good use to use variadic functions anywhere that couldn't be solved better somehow else. That said, forwarding a templates pack to a variadic functions is easy and possible though, the reverse is just annoying. From your SO thread I notice you use spdlog, but afaik spdlog does not use variadic functions, it only exposes functions/methods that accept template packs as arguments. That's different to a [variadic function](https://en.cppreference.com/w/cpp/utility/variadic). Could you link to a file on the repo that uses variadic functions? Also templating does promote reuse, but what you're trying to do is obfuscate code (in this case the library you wrap). Depending on how well the library is written, you could include it into a "details" namespace directly and use it like that.
In my experience exposing another library publicly often spreads like wildfire in the consuming project. Later when you decide you want to swap that dependency library out for something else, it becomes massive amounts of work for that consuming project to update to your library's new version. Especially true for the large projects I've worked on. I find that it's better in the long term to keep those dependency libraries encapsulated privately or accessed through an interface publicly where internally the implementation can change behind the scenes if it needs to be publicly used. Of course there is no always/never rule. Sometimes it's not possible or not practical.
FireMonkey is in my opinion best GUI for C++ if you want custom looking GUI. It is comparable with WPF for Windows, but F.M. is crossplatform. The big downside for me is, FM is only for Borland RAD Studio. The best alternative to FM is Noesis GUI (you have it on list) which is based on WPF. It uses XAML, you can build GUI inside VS Blend and use it in Noesis. But Noesis is good for game ui and maybe simple applications. It have some window system but not multiwindow (no more then one window), or you must use external window system like GLFW or SDL. &amp;#x200B; Btw. Nice list, I know almost all (when I was looking for C++ gui).
Well, it's just a very bad example in my opinion.
&gt; You could easily have represented exactly the same structure in JSON and/or Yaml JSON and YAML are data formats. Unless I'm mistaken, they would primarily be useful for a declarative representation used in combination with the build system which interprets and processes the data. In particular, this data representation might work for simple build descriptions, but once you start needing all of the complicated control flow often found in C++ projects, this data representation breaks down very rapidly. You end up with the hybrid declarative-imperative approach of e.g. the YAML for GitHub/GitLab CI which has both data describing the CI inputs, phases, etc., and `script` sections to actually control and execute the CI process. Personally, I don't think this either reads or composes very well for complicated processes, so you might as well just use a hybrid declarative-imperative language. Then you have the clarity of declarative "input produces output" while still giving you some control over how that happens. &gt; and had a format that there exist automatic tools for - a format that everyone's editor already understands, a format that everyone already understands. Understanding the format is one thing, whereas being able to maintain it is another, and as someone who (also) likes using a text editor, I don't find writing either JSON or YAML particularly pleasant. &gt; It uses `**` for some purpose I have yet to understand but that will make it incompatible with either bash or make. I'm not sure what this means. In what circumstance would you be conflating or causing the build2 build files to interact with bash or make?
In my experience in 99% of cases you use `lock_guard` and RAII. In other 1% you use `unique_lock` and RAII. I never needed `release` so far.
Maybe it’s a matter of style then. I prefer a single statement to a pair of braces :)
. since when one function call is lots of oveehead.?
A lot of what you say does make sense, I will admit that. Especially the part about other tools generating `buildfiles`. Theoretically we could support an alternative format which we could also use as a way to save/load the build state (currently you can dump the build state in a `buildfile`-like form but its not loadable). Would you be keen to sketch out such an alternative representation for some real but not too hairy project, say [`libcmark-gfm`](https://git.build2.org/cgit/packaging/cmark-gfm/cmark-gfm/tree/libcmark-gfm/libcmark-gfm/buildfile)? If nothing else, it would be interesting to compare. Though I would suggest using JSON5 so that we can have comments.
The friend relationship isn't necessary in deviceinterface. Just give deviceinterface appointment to the appropriate data that it needs to modify upon a register call. Also, the functions most certainly don't need to be static.
**Example**: Shows very clearly a neat programming concept. **u/Lyberta**: This is example has an unrelated code smell, it's practically useless!
&gt; Any kind of public `unregister`, `close` or `destroy` function just screams bad design. Not really. There are close-like operations on many resources that can fail and taking it into account is needed. Destructors cannot be used in such cases.
But if you forget that single statement, your code will compile and misbehave. If you use RAII and forget a curly brace, your code won't compile.
&gt; Just give deviceinterface appointment to the appropriate data that it needs to modify upon a register call. If you're doing that then you're kind of missing the point of the exercise. &gt; Also, the functions most certainly don't need to be static. I don't recall saying they need to be static. Not making them static is going to make it slightly harder to use correctly though, as now you need to be careful to not let the VFS go out of scope before the created DeviceInterface.
And you're sure that single statement is exception-safe..?
**Example:** Shows very neat programming concept. /r/cpp: This example doesn't do some nitpicky detail... it's literally unusable!
This is way more accurate. RAII is sweet though.
Hi, I'm sorry that this is a dumb question, I'm not really too familiar with C++ modules, but what is the actual practicality of using the module support in `build2` right now? - I know that there are two C++ modules proposals or something along those lines. By using `build2` am I tying myself to one of them and how bad is that? - I assume that I'm not going to get autocompletion in vscode or things since it wasn't designed to handle that sort of thing? If that's right, is that like a *we'll have to wait 10 years or so* situation or a *someone'll probably have the simple part done next week* situation? I'm not really sure where we are technically in this regard. - Is this competing with a microsoft package, I know they have `vcpkg`, that might make them unwilling to add support to VSCode for this?
I actually wonder how feasible it would be to make a libclang-based tool to automatically consume a header and spit out a set of forward declarations...
["Please don't confuse an example with what the example is meant to illustrate." - Bjarne](http://www.stroustrup.com/bs_faq.html)
&gt; Badge doesn't use friend anywhere Yes it does, see: friend T;
I think wrapping at least one existing high-performance math library in this interface should be a prerequisite for inclusion into the standard if that is not possible, the interface is over engineered, for what it actually enables.
Scary. Then it seems any object can make a badge object and use it to call the protected function. Sure wish that the earlier standards had made `=default` actually count as a user provided constructor.
Why is parallel generation a problem, if each engine is seeded with a different, random seed.
Yes, that's the clear intent of the standard -- you can use this API to wrap your implementation and interoperate with other implementations, or transparently substitute backends under your application code without changing it much.
I'm pretty sure this example is on the level of using volatile for multithreading. Remember that this example is very exception unsafe and clearly shooting the user in the foot if they don't write their own wrapper.
Also, I would recommend defining the copy constructor as private to prevent someone from grabbing a Badge and then using it for their own device (somehow). That is, [the form I'd recommend is](https://stackoverflow.com/a/3218920/147192): &gt; template &lt;typename T&gt; &gt; class Key { friend T; Key() {} Key(Key const&amp;) {} }; The full explanation can be found in the answer linked above. *Disclaimer: I wrote that answer, a long time ago...*
[Blend 2D](https://blend2d.com) looks interesting. It is on open beta now. I never tried it, I discover it when I looking for 2d c++ library, but when I found it, it was not released.
I usually have the constructor take a pointer to T and then pass 'this'. Have to try with the default constructor, seems safer.
 If you are interested in static reflection for enums, this library [https://github.com/Neargye/magic\_enum](https://github.com/Neargye/magic_enum) might help :D
Oh, that's very kind of you, but I'm super-over-extended at this point - I take on too many things. I'm trying very very hard to get a bunch of things out and done this week. If you had a document and wanted me to review it later you could send it to me at tom@swirly.com
How does c++20 change this?
&gt; https://github.com/SerenityOS/serenity/commits/master?after=629501049fb2fd1a275e33a8194f861d0fce75d8+2764 Impressive. &gt; 2000 commits since October. That is another level of dedication. Thanks for sharing.
Exactly. Can't listen to them because of this. Scott Meyers briefly mentioned something similar in Effective C++. Like, people remember anecdotes and unrelated stuff but not the real content. I think the talks would be better with minimal such talk.
In C++20, aggregate initialization requires that there are no user declared or inherited constructors. Instead of requiring they be user provided. Let me [demonstrate.](https://godbolt.org/z/7RbcuA)
It looks like template deduction will work just fine. &amp;#x200B; [https://gcc.godbolt.org/z/fcUEs0](https://gcc.godbolt.org/z/fcUEs0)
Feedback is very welcome.
please ask questions in /r/cpp_questions as described in the sidebar
I've never looked into template black magic, so the walkthrough of how this library would handle addition blew my mind. If this works out in practice without destroying compile times, I would love to see some of the work here expanded into a broader std::math library. E.g. std::math::complex (deprecating std::complex), std::math::quaternion, etc.
Not really. Not even PGO, but the optimization in general doesn't effectively use these values. In the strictest sense, the compiler knows about some of the these values, buried array in a machine model file somewhere, and some heuristics might use some of those values in a calculation: but the optimiziations are basically feed-forward-only transformations that use fixed rules and thresholds to optimize stuff. I am not aware of any compiler that takes a loop and understands deeply what is limiting performance and then applies changes that *remove the bottleneck*. Instead you constantly see things like no unrolling where a 2x unroll would double the speed, or giant unrolling when it doesn't really help, and so on. Compilers are good at the optimziation which removes the overhead of lots of HLL abstractions, like function calls, objects, templates, and so on - down to the level where you have some intermediate representation of the needed operations without all the syntactic cruft. However, they are not good at going from there to machine-model-aware optimized loops - here they are still far behind (some) humans.
There's also the fact that using pimpl means that your object generally always has a dynamic allocation for its contents, which can make things slower by spreading out all the data in some compound type.
I think a lot of people would love to hear your thoughts more generically about what an attractive junior C++ dev job candidate looks like. You are exceptionally well positioned to give such advice, I think. Have you written about this before?
As I know modules now is in c++20 standard (and that union both modules proposals existed in early stage).
(not part of Build2 team but currently experimenting a lot with it) 1. The advantage of using Build2 with modules right now is that (so far) no other build systems work with currently available modules implementations (which are not matching the standard yet, as it is not fixed yet). This just means you can try making a modules based project which is bigger than a few files, see what the compiler do currently. The other aspect is that once modules are standardized and implemented, Build2 should be ready to use them before other build systems, because it already have the necessary understanding to do it, most of the rest (if my understanding is correct) is syntax. 2. I suspect autocompletion in vscode could come in less than 2 years. Because it's on my to-do list. But it's not my priority at all, there are more important stuffs to do, though it's not ignored. 3. It's not really competing with vcpkg in the sense that it does more than dependency resolution and it's not bound to CMake. However I suspect (because we had discussions in that direction) that they could become complementary in the future.
Do you know about the fast pimple idiom, where the internal type is stored in a buffer provided by the public one?
When the linker sees two functions with the exact same assembly, it can merge them into the same function. For reference see the note in https://docs.microsoft.com/en-us/cpp/build/reference/opt-optimizations?view=vs-2019 and the documentation of /Gy https://docs.microsoft.com/en-us/cpp/build/reference/gy-enable-function-level-linking?view=vs-2019 . "Ensure distinct functions have distinct addresses" can be needed if you want a tool to actually inject (for example live reloading) new code in your process, profile 2 functions with the same ASM independently , etc etc.
My understanding is that yes, it's for standards compliance, at the cost of a binary size optimization. Roughly, imagine a pair of functions (perhaps templates) like `void foo(int*)` and `void bar(float*)`. Depending on what they do with those pointers, they might end up generating identical machine code. As an optimization, the compiler is capable of "folding" those definitions such that `&amp;foo == &amp;bar`, resulting in a smaller binary. However, this is not legal by the standard! The standard dictates that `&amp;foo != &amp;bar` because different entities in C++ must have unique addresses. Personally, I've never run into shipping well-designed code that actually cared that functions had distinct addresses, but presumably it does come up. `/Gu` is for those people who need standard-compliant behaviour at the cost of a bigger binary.
I haven’t, but that’s a great idea, I’ll think about what I want to say.
[Here it is.](https://github.com/ADVRHumanoids/MatLogger2/blob/master/matio-cmake/cmake/thirdParties.cmake) His integrated dependency looks for the system libhfd5.
Thank you for the thorough answer! I have a much better idea now. The reason why I asked about your CI is because I noticed that bracktrace has a lot of products so I figured maybe you had developed some CI tooling as well. Jenkins is what I'm used to, although in a poly repository environment I think it would be cool to manage multiple CI configurations at once e.g. being able to update the pipeline config for multiple repos at once. Currently each jenkins file must be updated individually to make a wide change and that's not exactly desirable. Also I'm curious to know your issues with Jenkins in general and if you prefer any alternatives or if you all are working on any products in that space. Thanks again!
Dvir Yitzchaki's "179 range algorithms in less than an hour" piqued my interest, but his slides are riddled with nonmatching parens/brackets/... etc. Spent five minutes getting angry at that, then stopped watching. WTF?
I could be confused with what you're asking for, but this sounds very much like a case for [type erasure](http://www.goldsborough.me/cpp/2018/05/22/00-32-43-type_erasure_for_unopinionated_interfaces_in_c++/) (as someone has suggested in the answer to your stack overflow question.)
I wanted to see if this could be extended to allow multiple classes through one Badge. This works: https://godbolt.org/z/60lsE0 This version requires Badge to pre-specify a fixed, but arbitrary limit on how many classes it can cover. I'm sure that could be made variable. But, personally I'd prefer to keep compile type expressions simple.
Watched it. I definitely need speech therapy. Or someone to kick me at every aaaaa.
True! I just hope to see a revised version available in the future.
Looks Nice ! But I think you could make it even more lightweight :) How long is your Bus ride to work ?
I can probably try to make it a little bit more lightweight, any suggestions. My bus ride is about an hour, but it's been two days back and forth.
as useful as anne frank's drum kit
This kind of abstraction is generally called "SVM" (Short Vector Math) and comes with it's own scalability issues. The thinking is that we have types like "vec3" (aka. float3 / float32x3, etc..). This model works great on hardware where there is a lot of implicit concurrency (GPUs) since the computation is replicated to 10-100 execution units running in parallel - scaling isn't a problem. With CPU you have fixed vector widths like 128 bits (SSE-SSE4.2, NEON, MSA, Altivec), 256 bits (AVX/AVX2), 512 bits (AVX512) or more. If your abstraction is three elements of float or double, a lot of power will be wasted on inefficient abstraction. RISC-V's configurable vector width makes this even more profound (not that anyone yet shipped an implementation?). The common wisdom has been to use SOA instead of AOS layout for data and this where templated vector/matrix classes come in handy; instead of declaring: using vec3 = xxx::math::vector&lt;float, 3&gt;; Do this: using vfloat = xxx::simd::vector&lt;float, 16&gt;; using vec3 = xxx::math::vector&lt;vfloat, 3&gt;; The vfloat depends on widest available SIMD vector register type for currently compiled architecture. Now the xxx::math::vector handles code generation but instead of scalar type like "float" the underlying scalar is a wide SIMD vector type. You write code as-if it were scalar: vfloat dot(vec3 a, vec3 b) { return a.x * b.x + a.y * b.y + a.z * b.z; } This would do 4 dot products in parallel on SSE(n), 8 on AVX(n) and 16 on AVX-512. If you try to do horizontal stuff like that within vector registers, you will suffer performance penalties - on the other hand, above code is using very simple full-vector-width operations: addition and multiplication. Most computing problems become exercise in multiply-accumulate throughput of the hardware. :) You have to do branching the same way GPUs do it as much as possible: using compare-and-select (simulating predicated execution). This is the real problem to solve how to make this automatic; GPU shader compilers already do this to a highest degree but there aren't that many C++ libraries that try to attack this problem.. for now we tediously and manually refactor/transform the dynamic flow into static selects.. if you want to detour off C++ scene a bit, ISPC handles some of this stuff automatically, if you like the syntax. At any rate, the back-end stuff is not that interesting a problem to attack if the solution is SVM.. since it's very inefficient as I hopefully illustrated a little bit. The practical benefit the proposed std vector math library brings into the table is "one size fits all" -abstraction that allows to write SIMD architecture agnostic code so the underlying low-level SVM code is taken care of "for you". In this light the abstraction is going a bit off-tangent into inefficient directions when it encourages to declare SVM vec3 -like types. It should instead make "vfloat" as efficient as possible and not try to shoehorn non-SIMD scalar coding conventions in.. that just won't be efficient..
I feel like this could be implemented as something like `badged` instead, where the type has a `protected` conversion operator for itself to a badged version.
I want to give you a hundred upvotes! And not just wrap one/any existing math library in this interface, but do it with Eigen. If you can show that this works, then it's a proposal worth being considered.
I'm not a mathematician. But I read [the paper that introduces xorshift*](http://vigna.di.unimi.it/ftp/papers/xorshift.pdf) and my take-away is that it cannot output zero if it is initialized with a legal value. If it could output zero then that would be a disaster. It would stay stuck on zero.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bzxft3/good_implementation_for_bus_datastructure_for/eqyi51q/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'd argue the devices registering themselves with the vfs is breaking the single responsibility principle. I just don't see a use case for this idiom that isn't just to work around a poor design. Also, making them static means you can only have one instance of VFS, since the data they modify will also need to be static
Very cool. Watched all of it!
Isn't that just the math syntax for ranges? [] is for inclusive, () for exclusive.
So your statement was completely unnecessary.
It's high quality relative to other RNGs from a mathematician's point of view, which is what I am. Parallel generation via a seed and generator per thread is not a practical problem. There are similar tricks with SIMD parallelism. And I don't understand your complaint about it's normal distribution. &lt;random&gt; is generic enough that it allows you to implement your own distributions. Maybe you should make one.
Slide 9 clearly explains the STL convention: [i, k) is an inclusive-exclusive range. However, I suspect that /u/elperroborrachotoo was referring to Slide 7's seriously damaged parentheses. I'm not sure what's going on in Slide 8. Slide 10 is damaged like 7. The damage almost seems consistent, so I wonder if it's related to bidi text rendering or something.
Thank you!
Ohhh I see that now, yeah it's weird.
Technically Code Units, a codepoint is a 21 bit scalar Unicode value. basically a character, except there's still Graphemes which are composed of multiple codepoints.
During development of Mortal Kombat: Deception (2004), we ran into the problem this resolves. The game's Puzzle Kombat mode was written as a state machine with function pointers as the state values. Many of the functions were identical but for name (WaitForPieceDrop, WaitForNewPiece, WaitForLeftMove, etc) -- the function bodies were all the same. The larger logical switch depended on unique addresses to decide what options were available after each. It worked fine in debug builds, but in optimized builds all those identical functions got coalesced into one. It took a long time for us to figure out what was happening. If I recall correctly, only one of the consoles exhibited the issue, which made it even harder to find. At the time, there wasn't a switch to disable that behavior, so we wound up shipping that part of the game code un-optimized.
And it can be significant. A few years ago this was actually broken in the linker for a project I was working on, and it was the difference between fitting in memory and not.
&gt; Technically Code Units, a codepoint is a 21 bit scalar Unicode value. Right, I sometimes mix up codepoints and codeunits. &gt; really graphemes only come into play with accents (E + combining acute, not normalized for example) or Emojis. I've seen users with Chinese characters in their paths, so it's not that rare. &gt; the ladder of abstraction (Unit &gt; Point &gt; Grapheme) There are also grapheme clusters, which I won't pretend I know what they are.
Cool story!
Off-topic, but since I am curious: where exactly do you see problems with make? Personally, I think it’s a rather clean language for specifying dependencies and I use it extensively. I tried to get into cmake multiple times, but it looks very messy and idiosyncratic in comparison. By the way, it’s the same reason why I couldn’t get into build2 - I just don’t understand the workflow...
The half-open range was one of the few ones that made sense. Slide 7: `std::sort(v.begin(), v.end;(()` `std::ranges::sort(v;(` [Slide 8](https://youtu.be/ilN8zRdRQdI?list=PLn4wYlDYx4bszUM8uUJi55czMYuilXfaR&amp;t=163) [Slide 9](https://youtu.be/ilN8zRdRQdI?list=PLn4wYlDYx4bszUM8uUJi55czMYuilXfaR&amp;t=205) and it goes on and on and on...
&gt; The larger logical switch depended on unique addresses to decide what options were available after each. Why use function pointers directly instead of a state index into an array of function pointers? -- Knowing that linker merges same instantiations of a template in different TUs, I was actually surprised to learn now that it's illegal to merge different (but otherwise identical) functions. It reduces code size and is thus more I-cache friendly.
Sad to hear that. I expected at least instruction scheduling (without pgo) to make use of knowledge about the microarchitecture. Otherwise, what ere the `-mtune=...` flags for?
There is a slight runtime overhead and some functions cant be inlined etc. &amp;#x200B; There is a rather massive development time overhead to maintain everything
Nice! Got a few suggestions for improvements: * Lot's of includes... Probably not for everyone especially as all the expensive ones are there too (algorithm, vector, ...) Maybe add an option to compile the guts into a Cpp file/once? * The base class is templated and I don't see why. You usually want a generic base class which does all the hard stuff without a template to avoid the instantiations. Not 100% sure on that (here) though * I'd decouple the file handle handling (open, close, copy, move, ...) in a dedicated class to remove this from the main class
&gt;p * Absolutely, I am not 100% sure what the best way to do it at the moment, maybe a type erasure for the file descriptor, maybe just generate the templates twice and not allow the generic use. * The reason it is templated to be able to down-cast and fetch the file descriptor or release it from the derived class. * There is no copy/move of files being implemented, I think for that scenario using std::filesystem is more appropriate. As for open, it is outside of the classes. The close function is indeed inside the file class and I think that since it is modifying a private member it fits inside the class more naturally than outside.
May/may not help, but when I implemented a file class, my main motivation was (at the time at least), GCC on Windows wasn't buffering files. So a loop to read a file via fgetc() was 20x slower than the same loop on Linux. I know, I know, use fread(). But sometimes I don't want to allocate (and possibly free) a block of memory when I can just do a simple loop of byte reads. And so I wrote my class to implement its own buffering. Adds a 0.1% overhead on Linux, but brought Windows up to similar speeds as Linux. Also, I made file a static class, and file::open(filename, mode) would return a file_buffer. This way I could have file::read(filename) -&gt; vector&lt;uint8_t&gt; and file_buffer::read() versions. Eg: if(auto fp = file::open("foo", file::mode::read)) { uint8_t byte = fp.read(); } auto buffer = file::read("bar"); Because C++ is annoying and won't let you overload static and non-static versions of functions in the same class. Hope that's helpful ^^;
So I understand that file class and the file\_t class contain the same read,write,close,seek,sync functions, perhaps one is calling the other? &amp;#x200B; In my implementation I don't have the static class but I have open behave in a similar way to your file::open, externally to the class.
Cunningham's Law posts belong in /r/cpp_questions
* As there are only 2 instantiations (commonly) used, generate explicit instantiations for them and guard that and the code by macros * Ah I see. * Just seen you already have that file\_handle class there. Well done then, nothing to add :)
Yes and no. The file class has static functions, like file::read() will read an entire file directly into a vector. file::open() can create a new file_t object. Whereas file_t's read functions are for pulling parts of data out from the file. eg read() -&gt; uint8_t, read(array_view&lt;uint8_t&gt;), readMSB(size_t bytes), readLSB(size_t bytes), etc. When it comes to file::open(), it could be implemented as: auto file::open(string_view filename, mode filemode) { file_t fp; fp.open(filename, filemode); return fp; } I worried about having an ::open() function (eg in the global namespace), because it might conflict with other libraries. But if I put open into file as a static function, then I'd lose the ability to say fp.close(); fp.open(other_filename, filemode); later on, for instance. Anyway, there's no wrong way to do this, just wanted to share what worked for me.
For the first point, exactly, I can definitely add a configuration to just use explicit instantiation for the two templates.
Awesome. Regarding the open function it is inside my namespace but can be looked up using ADL which is why it can be called without specifying the namespace.
What’s the point of making real improvements to low level optimizer when you can spend all that effort on using undefined behavior to speed up a benchmark by 0.03%? /s (I wish that was just a joke)
That's a pity. From everyone criticizing `build2`'s syntax so far you have provided the most articulated reasoning and concrete suggestions. So it would have been really interesting to see your ideas sketched out. And just to be clear I am not suggesting that you produce a spec or anything finished really. Just an example of what it could look like, an "artist's impression" so to speak ;-). And thanks for the review offer, I may take you up on that.
That's certainly a valid way to do open, for sure. Maybe it's better to do it that way, and throw exceptions when attempting to call file functions on a file we failed to open, so that we can just presume a file object is always valid. Good foor for thought, thanks! It still unfortunately doesn't get around the file::read vs file.read issue, though. Seriously, why *can't* C++ allow overloading between static and non-static members, anyway? &gt;_&gt;
&gt; compare function pointers(don't!) Why and what alternatives would you suggest?
Maybe have read,write,etc as external functions accepting a raw fd or "weak" file class then the internal functions would call the external ones.
After thinking about it some more, you're right. The point is that a scrambling by a single multiplication by an invertible number will never output 0. So xorshift itself never outputs zero, and xorshift* never outputs zero either. However, what I call xorshiftstar32 is a multiplication followed by a 32-bit right-shift, and this can indeed output zero without the state being zero (this right-shift allows xorshift* to pass more stringent statistical tests). In this library, xorshift32, xorshift64 and xorshiftstar64 do not output zero, whereas xorshiftstar32 may. I'm not sure how I want to proceed. Indeed, as far as I know it's strongly inconvenient that an RNG is such that max() - min() + 1 is not a power of two (for example, this makes it harder to obtain random digits, e.g. if one wants to sample an integer in {0, ..., 2^n - 1}). So on the one hand, I could make the output range tighter and guarantee that the end-points of the range are attained. On the other hand, I could keep the power of two range even though the end-points are not attained. The only other implementations of xorshift* that I found all do the right-shift, and so have a minimal attained value of zero. These correctly have min() return 0. I'm open to hearing other opinions on this issue.
This is likely more general than you are looking for. https://www.youtube.com/playlist?list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb https://www.youtube.com/playlist?list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp
Thanks! But yeah I would like to have it more C++ specific with exercises for example :/
What do you mean by "C++ specific"? Algorothms and structures are abstract concepts. You'll surely be able to find example implementations for everything in C++.
&gt; I'm sure that could be made variable I tried it but due to my inexperience in template metaprogramming, I struggle. Does anyone tried or has any clue on how to do it ?
When I started learning data structures and algorithms, even I wanted everything very specific to C++. And I ended up waiting for too long. But then I learned fundamentals of java (most language semantics are quite intuitive and similar to C++) and followed Robert Sedgewick's courses on algorithms on coursera and I loved both of them. In those courses, entire examples/codes/exercises are in java. I learned java just to be able to follow the courses and the courses were worth the effort.
Ah, great! Will take a note of that, thanks!
Sedgewick's book Algorithms in... is available in C++, and is as good an introductory read on the subject as you will get.
I have some books. I will let you know.
Hi, I'm Dvir. Thanks for your comment. The reason for this is that I prepared the slides in apple's Keynote but when I started the talk I discovered my mac couldn't connect to the room's screen and I had to convert the slides to Power Point and present from the room's windows computer. I hope I'll be given a chance to do the talk again properly at another conference.
Took me a good 3 mins to figure out how ParameterPackElement was working. Interesting.
Your README could do with a quick example of its usage. Also I don't know if this is your specific style sheet or Doxygen in general, but the docs are.. impractical to read on mobile
I don't think there is any book for 4th edition and he (author) himself mentioned in the coursera lectures that there were some issues in 3rd edition. The code examples in 4th edition are quite clean and compact. And, the code examples in that C++ book are more like C codes.
 [https://www.udemy.com/datastructurescncpp/](https://www.udemy.com/datastructurescncpp/) &amp;#x200B; Is probably one of the best Algo / Data Structure courses on Udemy. It's primarily in C but there are sections where you convert your code to the appropriate c++ versions. It's very in depth. The same professor has a youtube channel as well.
You [OP] must have a problem with the eyes: "For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow."
For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
I've just been through those courses, translating the Java to cpp was a helpful exercise
If your open to a book, I highly recommend ["Introduction To Algorithms"](https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844/ref=mp_s_a_1_1?keywords=introduction+to+algorithms&amp;qid=1560423707&amp;s=gateway&amp;sprefix=introduction+to+a&amp;sr=8-1) - it takes a real thorough look at algorithms and data structures. It's less of a code perspective but it's really good for getting a foundation to work from.
Isnt the whole point of data struc and algos that it is abstract and not bound to a language.
YES. This is one of the books that I used the code is in Java, but it does a great job of explaining all the concepts etc.
For some reason, I can't access the page. &gt; Firefox can’t establish a connection to the server at stellar.cct.lsu.edu.
"Algorithms in C++" by Robert Sedgewick is pretty good.
Works on Firefox 67.0 for Android
Thanks, I am digging through the code right now!
The standard was ambiguous here. It states function pointers may compare equal if they are the same address, and never defines when functions ha e the same address. This may be a grammer error.
But it's not specific to firefox. cURL, wget, chromium... all say connection refused.
Mycodeschool channel on YouTube has algos and data structures in c/c++ and are really well explained. But the number of algorithms themselves are not extensive. Have fun learning.
Connection issue from your side though.
What distinguishes it from other fp libs?
Or the other way round: `auto read(... filename){ return open(filename, mode::read).read(); }`
Option to disable this for linker was already there if I'm not mistaken (`/OPT:NOICF`). I wonder if this one prevents similar mechanism which happens within single translation unit?
**Company:** [InstaLOD](https://instalod.com/) **Type:** Full-time **Description**: InstaLOD is a technology company that builds software that enables enterprise and entertainment companies to create magical 3D experiences. Our award-winning tech helps 3D artists working on massive productions to focus on the creative part instead of spending most time with tedious technical tasks. From military companies building next-generation simulations and data analysis to leading automotive and fashion brands such as NIO or Deckers and the biggest entertainment franchises created by gaming companies like 2K Games, Wargaming or Sony London: our technology plays a vital part in delivering their project. We're searching for **passionate C++ software developers** experienced with the **Qt and 3D frameworks**. We're not just looking for coworkers but for stakeholders and adventurers – driven people that want to make a difference through their work. Whether your passion is researching new algorithms, creating beautiful UIs or writing complex real-time shaders, you’re guaranteed to find something that keeps you motivated! **The kind of people we’re looking for:** * *Self-starter with a getting-things-done attitude*: You have a solid C++ background (4+ years) and you’re not scared of big code-bases and tricky tasks. Your work methods are well-structured and self-organized and you love moving tasks from the backlog to done. You also understand the project, and create tasks for epics that need to be worked on next. Effectivity when working is important to you, so you rely on software such as Slack, GIT, Sourcetree, Sublime, Trello and JIRA. * *You love to improve and always seek to learn*: You’re not only part of a team that’s just working on the code base. You’re part of a team that makes sure everybody’s skills and the quality of our code base continuously improves. * *Collaborative and Self-Aware*: You understand what’s necessary to create a collaborative engineering culture. You help build understanding and empathy within your team, and actively work to bring people into the conversation and understand their viewpoint. **Bonus Skills:** * You have shipped titles in the AAA games industry. * You have work experience at major companies or competitors in our space. * Familiar with 3D engine development. **Location**: Stuttgart, Germany **Remote**: Yes **Visa Sponsorship**: Yes **Technologies**: C++, Qt, QML, OpenGL, Vulkan, DirectX, GLSL, HLSL **Contact:** If you have any questions you can PM me, or send an up-to-date resume including sample code of previous work that you can share to [Michael@theabstract.co](mailto:Michael@theabstract.co) or you can visit our careers section and apply directly at [https://instalod.com/career/](https://instalod.com/career/)
Maybe this can help: https://see.stanford.edu/Course/CS106B
Not the author, but just two or three weeks ago I was implementing a fixed point (and a 128 bit *signed* integer to accompany it) for my toy game engine. The first thing I did was to look for some good and clean open source implementations and I found very hard to find a good one. This one looks clean and very readable. I like it.
Is this actually true? [https://stackoverflow.com/a/44864483](https://stackoverflow.com/a/44864483)
I just get a "not secure" warning.
Maybe the Ads are giving problems? I'm using Firefox because it allows me to use uBlock. Finally no ads even on mobile!
Thanks for the suggestion. As far as I can tell, the ChaCha implementation of [Orson Peters](https://gist.github.com/orlp/32f5d1b631ab092608b1) and [Melissa E. O'Neill](https://gist.github.com/imneme/f0fe8877e4deb3f6b9200a17c18bf155) are already excellent, and implement the complete C++11 &lt;random&gt; interface. I'm considering providing Salsa20 and/or trivium, but it's unclear to me whether or not these actually have an advantage over ChaCha.
Does it take a hands-on approach though or it merely covers theory aspect?
It's a good combo of both.
Do you do an actual project or just a few exercises for each data structure?
It's a bottom to top construction of most of the common data structures, how they work, their space and time complexities and some best use cases.
&gt; I'd argue the devices registering themselves with the vfs is breaking the single responsibility principle. You can argue that if you want, but I'd argue that would be incorrect. &gt; Also, making them static means you can only have one instance of VFS No it doesn't.
Have a look at this Udacity nano course: [https://www.udacity.com/course/c-plus-plus-nanodegree--nd213](https://www.udacity.com/course/c-plus-plus-nanodegree--nd213) * Learn to code 5 projects. Modern C++. C++ concurrency. * Very pricey ($1436/4months). * Udacity's nano-courses have good reputation.
Honestly I think a grapheme cluster is just the technical name of a grapheme, at least that's how I've always thought of it.
This is every presenter’s nightmare, exceeded only by the dreaded fly down. I compulsively overprepare, making KeyNote, PowerPoint, and PDF versions of my slides and copies on a universally readable thumb and somewhere on the internet. If I use something like slides.com, I do the same but with Keynote traded for html.
Oof @03:43 Don't slide scares me.
I'm actually trying out reveal.js for my next presentation. Doesn't it solve those problems?
Update: turns out it's actually a problem in the video preparation unrelated to the issues at the talk itself. I'm working with the conference organizers to solve the issue.
I love many things about the API. I do *not* love the fact that your read and write routines work with `void*`. I think all of these functions should be replaced by two overloads each (example given for `write`, but `read` etc. are equivalent): template &lt;typename OutIt&gt; std::enable_if_t&lt;std::is_same&lt;typename std::iterator_traits&lt;OutIt&gt;::value_type, std::byte&gt;{}, std::size_t&gt; write(OutIt begin, OutIt end) const; template &lt;typename T&gt; std::enable_if_t&lt;std::is_standard_layout&lt;T&gt;{}, std::size_t&gt; write(T* obj) const; The first overload writes into a byte range. The second overload writes into a strongly typed standard layout object. For `read` you already do *some* of that with your overload that returns `std::vector&lt;std::byte&gt;` but you still carry these (`void*`, size) overloads around. There’s no need to give up type safety here.
Enlighten me how you can have multiple instances of VFS without introducing global state via the static functions. Global data shouldn't be used to avoid object lifetime management. It's a hack and why singletons and global state are almost always antipatterns.
I think the default Doxygen theme doesn't work well on mobile either.
It helps to have a bit of familiarity with functional programming languages that have pattern matching. Like Haskell or Erlang. Templates are practically a functional, pattern-matching, text-processing language. auto ParameterPackElement(unsigned index, class Types[]) -&gt; class { auto Extract(unsigned i, unsigned n, class Types[]) -&gt; class { switch (i, n, Types) { case (n, n, Head, Tail[]) : return Head; case (i, n, Head, Tail[]) : return Extract(i+1, n, Tail); } } return Extract(0, index % sizeof(Types), Types); }
I agree with the type safety claim and I think there needs to be a solution for it. Regarding the first overload: I am concerned that using output iterators as you state will significantly reduce the performance and robustness, because it would invoke multiple read system calls or require additional caching, unless I misunderstand the proposal. Regarding the second overload: Allowing to read and write objects is ok with me as a separate function outside of file as I would like to keep the file class really simple. Reading or writing objects is not really simple, unless there is a clear proven restriction. I am not sure whether standard layout is the restriction we are looking for, because std::string can also be standard layout. However, I am interested to follow the type safety here, maybe we can brainstorm about something like this here.
&gt; Enlighten me how you can have multiple instances of VFS without introducing global state via the static functions. VFS::DeviceInterface::Register(vfsInstance, deviceInstance); VFS::DeviceInterface::Register(otherVfsInstance, deviceInstance); &gt; Global data shouldn't be used to avoid object lifetime management. It's a hack and why singletons and global state are almost always antipatterns. Neither of those are involved here, so irrelevant. Not sure why you're being so aggressive here while only paying half attention to what's actually being proposed.
&gt;I am concerned that using output iterators as you state will significantly reduce the performance and robustness, because it would invoke multiple read system calls or require additional caching, unless I misunderstand the proposal. Do as the standard library does: Dispatch internally to the most efficient possible solution. In most cases this is as efficient as your `void*` pointer since the iterator type will in reality be a random access iterator (and most likely a pointer) into a contiguous array, so you can perform block reading/copying. &gt;Reading or writing objects is not really simple I might be misunderstanding why you provide `void*` overloads instead of `std::byte_t*` then. I thought the point was to perform object initialisation via byte copying for PODs. I may be missing an `std::is_trivial` requirement (as your claim that `std::basic_string&lt;T&gt;` can be standard layout implies^(1)). If so, add it. I am definitely *not* suggesting to include a serialisation function for arbitrary types which, I agree, is vastly more complex, involving protocol definitions and whatnot. ^(1) EDIT: Uhm, of course it can be. `std::is_trivial` is required.
I'll duplicate with some comments :) Looks tidy, but there are many things to improve. 1. Many guys in C++ comitet works to avoid of using * and raw pointers, in some cases it can be reasonable, when (4example) argument can not exist, but in your case, function read or write, they should always have arguments, so it's better to use references. 2. It will be about references again, there are many places you can use them and you don't. 3. Using "heavy" containers like vector, is it really make sense? 4. "inline static const auto value =" you've asked compiler to put const auto value in any place meet in code and locate it data segment, not sure what want you try to do. Constexpr?
Thanks for your response. 1. I am a strong believer in references, where would you believe that I use pointer where it would be inapropriate? 2. Same, please let me know specifically where I use a pointer that should be a reference. 3. What do you mean by "heavy vector" vector is just a dynamic array in the end it is a pointer, size and capacity. 4. The combination of inline and static data member is never ODR used in the code and since it is inline it will most likely disappear. The static there is not to have multiple copies per translation unit but rather make it a static data member. For Windows it cannot be made constexpr as there is a hidden reinterpret cast inside INVALID\_HANDLE\_VALUE. In Linux, static const is the same thing as constexpr for integral types inside a class.
The reason I am using void\* is mainly to have the user decide what is being written and what not. If I use std::byte it means that any time the user wants to write a char, unsigned char, integers, pod types, etc, the user will have to explicitly reinterpret cast the data which is painful to be honest. I am happy to provide a good restriction and I even consider in changing size to count.
&gt; Instead a good solution would be for build systems and IDEs to share a common protocol interface such that IDEs could query any build (even in a language agnostic fashion), as IDEs mostly care about targets, files, known toolchains and per-file compilation flags. [Meson has a proposal and an implementation for this.](https://mesonbuild.com/IDE-integration.html) There is already support for it in KDevelop and hopefully soon in Qt Creator.
I don't think I ever saw someone do it but I figured it was possible. The problem I see with it is that you have to write so much boilerplate. You'd need to explicitly specify the size of the buffer (since you can't derive it from the implementations size without exposing it), implement functions to delegate copying and move construction and assignment as well as the normal stuff, etc. It seems like a lot of work and the end result is something that is either broken on different platforms (where the size might be different) or inefficient (if the buffer is made as big as the biggest platform)
I see your point about `std::byte` vs other byte types but that can be fixed by slightly relaxing my SFINAE requirement to include all POD types of size one byte. The API I envision requires no (`reinterpret_`)`casts` on the user side — this is an important requirement. However, my API suggestion did miss arrays of POD types. I’d add yet another overload for those (or perhaps even another function with a separate name), since reading/writing arrays of objects is conceptually very different from reading/writing byte buffers. The issue with `void*` isn’t just aesthetics, it’s downright dangerous. Nothing is stopping the user from doing this with your current API: auto hello = "Hello world!"s; file.write(&amp; hello, 4); Unsupported type, and wrong size.
For some reason I can't stand teachers that write code on whiteboard instead of using a simple text editor. I find it terribly boring.
@01:02:40 is much worse if you ask me.
I also wish to know this answer.
You might take a look into this course recording [https://www.youtube.com/watch?v=aIHAEYyoTUc&amp;list=PLHxtyCq\_WDLXryyw91lahwdtpZsmo4BGD](https://www.youtube.com/watch?v=aIHAEYyoTUc&amp;list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD) It is a course held by Alex Stepanov at A9. At the beginning it is a bit slow, but the content is incredible. It is really worth to follow it until the end.
I'm not against doing it, I am actively thinking of implementing some type safety measures. I think something like validating trivial and standard layout just to be on the safe side is a good thing to do.
Yes, instruction scheduling uses this. In fact, a lot of the point of a machine model is to support good instruction scheduling. However, *instruction scheduling rarely matters on modern out-of-order machines*. It matters a lot for in-order machines, and a lot of effort was put into it in the compilers and you still see the effect today: but reordering instructions for "scheduling" makes little difference on modern big CPUs, and in any case compilers probably aren't doing it right. Take a look at any performance tuning advice at the assembly level: none of it is really about scheduling anymore. Huge OoO windows made this mostly obsolete. The `-mtune` options are also used for instruction selection: certain instruction sequences may be faster on one CPU but slower on another. It is also used for a very local scheduling thing: to try to keep cmp/jcc or more generally op/jcc pairs together for macro-fusion on hardware that supports it. So the -mtune is definitely used, it just isn't used to make really important high level decisions about how to optimize loops as discussed in the article: it is lower level and using heuristics and fixed rules. I would go as far as to say that -mtune rarely makes much difference unless you get it really wrong.
Well, the idea was to show that it's a "rich" topic ;-)
I suspect that will get better soon. Especially if people keep on giving talks showing such graphs ;-)
Yeah. It was good. By the end of the presentation it was much clearer.
Thanks!
I'm not really sure why you have a base class at all here. What is it buying you? It's not reducing templating bloat because its CRTP, your derived file inherits from it unconditionally, I don't think EBO is a factor here, you don't inherit from it in multiple places.... seems like it could just be one class? It's quite a bit of C++ design overhead yet misses on some of the biggest wins you could score with C++. For instance, AFAICS there are no separate types for files opened read, write, or read/write. That means that you just have one type that gets passed around and if you happen to pass a file opened with read permissions to a function that needs to write, you get a runtime error. It should be designed so that you can write e.g. `void foo(const readable_file&amp;);`, and `readable_file` doesn't have any write methods, and there is no way to call `foo` without a compilation error without passing the correct flags to actually open a file. I'm not sure I understand why you need the "weak file handle" concept at all. If you write a class `file` C++ already gives you, for free, a type that is a non-owning view of a file: `file&amp;`. You should only write a non-owning version of `file` if there is a good specific reason (the way that classes like string_view, span, etc, have good specific reasons). Other people have mentioned the use of void*, which I think probably can't be justified in a C++17 context... void* + size should be replaced by a lightweight version of span which can be written in a handful of lines, or a pair of iterators. guepier's suggestions around separating array/object reads/writes is also sound. I also don't love the platform specific code being so mixed in and together; it looks a bit like ifdef soup in places, although maybe the alternatives would be worse. This was all based on a quick skim of course so I could be entirely wrong. But it looks like spending a fair amount of design complexity for uncertain gains, in quite a few cases. And missing some obvious big wins that a better type system can provide you with.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/c0bo2c/can_anybody_please_help_me_out_with_this/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
What is a fixed point library in general? is it the same as a arbitrary precision library?
you would know a thing or two about children wouldn't you?
You've generally got that backwards actually. MSVC's standard library has recently gotten better, but in general it's worse than other implementations.
The device interface should be generated from an instance of VFS to begin with, so the concrete class under it should already have a pointer to the data which needs updating upon the registration call. There no need for a static function call back into VFS. I said nothing aggressive. Criticism is not aggression.
another indirection
that's statement is meaningless. It's equivalent to: 2; //this doesn't do anything Think about how you usually call functions.
Hey, thank you for your answer. Now let me give you some context. At first my map of function pointers was declared in main(), the functions it stored were free functions and I would normally call the functions like this. `it-&gt;second(); //Works perfectly when used in main and second() points to a free function` However after putting everything inside a class things got complicated, now if I were to do that same thing I get this error. **//expression preceding parentheses of apparent call must have (pointer-to-) function type** which puzzles me because as I said, when it was in main() it was working perfectly.
That book is frequently mentioned, but I found it completely inaccessible outside the context of guided study. It is simply too dense for a beginner, without any indicators of what's important to focus on.
[Relevant reference here] (https://en.cppreference.com/w/cpp/language/pointer#Pointers_to_member_functions) The issue is that you have to use a certain syntax in order to provide context to the member function. Which means you would need a syntax like: (class_instance.*fn_ptr)(args);
Oh, thank you for pointing me out to this subreddit. As you can see, I new to the whole reddit thing myself :)
To expand on the other comment, the reason just calling it normally doesn't work is that it's a pointer to a *class member* function. Such a function might increment a member variable of that class for example, so it needs an object to work on. Just calling the function normally, you would do `myobj.func();`. Now let's say `fnptr` points to the member function `MyClass::func`, how do you call it on a specific instance of the class? Using the `.*` syntax: `myobj.*fnptr()`
Algorithms and Data structures are language agnostic for the most part
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c0de4s/how_to_call_a_pointer_to_function_member_stored/er3xhkl/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
How is this not the same old terrible OO inheritance nonsense?
The editing in the demo videos is pretty choppy as well. I don't think I'd be able to sit through them.
Can you PM me as well?
Thanks for reading my post. Tell me more. What do you feel is so nonsense about using OO principles?
[Fixed point](https://en.m.wikipedia.org/wiki/Fixed-point_arithmetic) is a real number representation format. In _floating point_, the decimal point "floats", meaning you can move it around (it's roughly scientific notation). In _fixed point_, the decimal point is "fixed", meaning you can't change the `*2^n` factor.
Remind me tomorrow when your name is 20 times older.
Lol someone is writing a program that prints out stats on the ongoing cricket world cup.
I think what he was referring to is that there is many ways to implement polymorphism in C++. There is virtual dispatch polymorphism (the one you used), but also static polymorphism with templates, type erasure and others. For example, you strategy pattern implementation boils down to one interchangeable `std::function` when opting for type erasure. For this particular case is reduces the boilerplate, simplify usage and reduce memory consumption. Also, owning raw pointers in you main function could be replaced by `std::unique_ptr`, but that's more of a detail than anything.
These are some books which are c++ specific. I can not vouch for their quality. Open data structures in c++ by Pat Morin Data structures and algorithms in c++ by jordi petit, Salvador Roura, Albert atserias Data structures and algorithms in c++ second edition by Michael T Goodrich et al. Data structures and algorithm analysis 3.2 Clifford A. Shaffer Competitive Programmers handbook Antii Laasksonen (some c++ here and there) Data structures using c++ by Varsha H. Patil (probably bad)
If he’s taking a course on algorithms and data structures, I’d wager he’s already taken whatever prerequisite math course that teaches inductive proof technique, which is sufficient to grok that text (IMHO, FWIW, YMMV).
It's not an issue with grokking the proofs. That tome of a book is over a thousand pages, extremely dense, and doesn't provide any problems with solutions. Furthermore, treatment of all topics is the same, without any sort of emphasis in areas that are critical at the entry level. It reads more like a reference than a book to study cover to cover. &gt;If he’s taking a course on algorithms and data structures If he's taking a course then the book is fine, because it'll be accompanied by a syllabus and problem sets. The OP asked in the context of self study.
What purpose had your article? You found new "awesome" function in documentation and wanna show it or what? Maybe write something about semicolons. That would be awesome! Do not understimate semicolons!
Video has been deleted and a new version uploaded at https://youtu.be/48oAZqlyx_g
The Force is Strong with this Anti-Pattern
in case anything throws there is a memory leak so mark everything noexcept if throws arent supported. &amp;#x200B; This is just normal inheritance, gets tricky if you want to have aset or vector or similar, then you need to have unique pointers etc. &amp;#x200B; Why do you prefer this over std::variant/visit?
Listing out every book you know in response to someone looking for guidance to the best online resource is not helpful.
Thanks for the response, I will try to cover everything you raised, and see if we can agree on the right changes that need to be made, without rushing something that is not needed or creates another type of issue. The reason I have a base class for just the file operations is isolating the handle management from the file logic. One thing that can be done by that is have an alias for stdin,stdout,stderr without the need to have a data member, another thing would be to use private inheritance and expose only certain file functions for e.g for a socket, or even one of your own ideas such as separation for read only/write only etc. Regarding the weak\_file alias, using a reference to a file instead of a weak file means there has to be some owning file somewhere which is not true in all of the cases - stdout, or some file descriptor received from C code. Regarding the void \*, I am not justifying it, but I don't see an alternative right now. One possible solution would be to make read,write,etc be function templates and then just check for trivial&amp;standard layout types, would that satisfy the concern here? Regarding a lightweight span, it is a valid solution but it still has to be a special kind of span so that reinterpret casts are avoided at the call site, maybe we can build a byte\_view class that accepts any char,unsigned char,std::byte, perhaps another subset of types that are ok, and then replace all the void \* with the byte views, WDYT? Regarding pair of iterators, they have to be a special kind of iterators, perhaps contiguous iterators is enough, but the return code will be incompatible with the input count as the resolution is of bytes, so it might create an asymmetric interface here. Regarding the #ifdef, I tried to only use them wherever necessary, is there a specific suggestion to minimize the use without over-complicating the solution?
The API seems like a mix (mess?) of filesystem, streams and C file streams. It's supposed to be a C++17 library but has a C style argument API. Throwing exceptions when not enough bytes are in the file, what if I read a serial port? Read returns vector&lt;byte&gt;, write has string\_view? I find the API very messy and if you continue with this style it's quite easy to fall into Qt API trap.
I welcome any suggestions to improve the API and make it more modern, this is why I submitted it to this subreddit. Throwing exceptions when not enough bytes - there is an explicit overload for that, the other overloads return the amount of bytes read. Read returns vector only in one overload explicitly made for this scenario. Write has a string view for one particular overload since strings are special kind of C++ literals that you very often want to write to files. Can you CTRL+F the byte\_view comment and see whether this would help improve the messiness as you claim? It can perhaps allow vectors, string views, etc, pretty transparently without explicit overloads.
I'm confused. Is the Strategy Pattern nowadays considered an Anti-Pattern? I googled a bit, and came to this blogpost from 2009: [https://blogs.msdn.microsoft.com/steverowe/2009/11/19/design-patterns-are-not-outdated/](https://blogs.msdn.microsoft.com/steverowe/2009/11/19/design-patterns-are-not-outdated/) We are now in2019... what is the current view on the Strategy Pattern, especially in a C++ world? I'm highly interested in why this pattern would nowadays be an Anti-Pattern (in a C++ world) and what the current Modern C++ alternatives are.
**Company:** [Paessler](https://www.paessler.com) **Type:** Full Time **Description:** Paessler's primary product is [PRTG Network Monitor](https://www.paessler.com/prtg), a network monitoring system. Paessler offers, next to a web UI, several native client applications that interact with PRTG, and is looking to expand the team that works on those clients. Specifically, we're looking for someone with several years of multi-platform desktop Qt and C++ experience to work on [PRTG Desktop](https://www.paessler.com/prtg-desktop-app), and ideally someone who would *also* be interested in working on the [Android](https://play.google.com/store/apps/details?id=com.paessler.prtgandroid&amp;utm_source=paessler.com&amp;utm_medium=pp&amp;utm_campaign=android-app) and/or [iOS](https://apps.apple.com/app/prtg/id326306472) clients, which are written in Java and Objective-C, respectively. You certainly wouldn't need to be an expert in all three languages/platforms, though! The full job listing is available [here](https://www.de.paessler.com/company/career/jobs/softwareentwickler-native-apps). **Location:** Nuremberg, Germany **Remote:** No **Visa Sponsorship:** No **Technologies:** We currently use Qt 5.12 and C++14 and target Windows and macOS. Optionally also iOS using Swift and Objective-C, and Android using Java. **Contact:** Send your CV to jobs@paessler.com
&gt; Discussions, articles, and news about the C++ programming language or programming in C++. &gt; For C++ questions, answers, help, and advice see r/cpp_questions
Please see the following pull request: [https://github.com/eyalz800/zpp\_file/pull/1/files](https://github.com/eyalz800/zpp_file/pull/1/files)
Please see the following [https://github.com/eyalz800/zpp\_file/pull/1/files](https://github.com/eyalz800/zpp_file/pull/1/files)
Who's 'we'? What part of finance do you do? Trading or number crunching? I find it hard to believe that all areas of finance operate the way you do.
&gt; For some reason I can't stand teachers that write code on whiteboard instead of using a simple text editor. I find it terribly boring. I completely understand and usually I would agree. I have inattentive ADHD so I typically can't pay attention to stuff like this. That being said, pointers are just easier with drawings. Since most of the later ADT's are made with pointers, it's a lot easier to explain what's going on with a whiteboard than text.
Thanks, I really appreciate the feedback. I am going to look into the type erasure method.
Check the github for more updated versions. [https://github.com/cinder/Cinder](https://github.com/cinder/Cinder)
AFIO v1 implemented i/o to trivially copyable types. Unfortunately it is UB within the current standard to do this, so AFIO v2 (now LLFIO) dropped that support. Now all you get is scatter-gather i/o of spans of bytes, which is defined behaviour. (Trivially copyable types may be bitcopied under the abstract machine, but original object creation must have been by the current program. So long as your program only ever reads whole objects it previously constructed and wrote, you're in defined behaviour, but as soon as you read an object which the current program did not previously construct, you are in UB) This sucks, but it is what it is. Now, for your library, me personally I wouldn't special case trivially copyable types. Rather, I'd have a zero copy serialisation layer which understands which types are safe to serialise and deserialise as a bunch of bits. Such a layer was going to be proposed as P1631 for Cologne, but right now, it's looking like that paper won't make the deadline. We do have a reference library implementation for P1631 for you to borrow from though, see https://github.com/ned14/quickcpplib/blob/8d1f21c03b2f2be74363a08eb5d1a7ecc7060436/include/in_place_detach_attach.hpp#L51.
Interesting read, but I think my file library is not aiming to do any object serialization. The discussion around here was as I understand mainly about the void\* type erasure that is now converted into what I call byte\_view which is basically a span of byte types. If the user wants to write any object, it his/her own responsibility to make sure it is standard, and explicitly construct byte\_view in that case. In case there is an array/container/string of byte types, the byte\_view is implicitly constructed. Please take a look if you like, I'd like to hear your feedback.
I did already look through your implementation, and pull request. You have missed a key qualifier in my OP: *zero copy* serialisation layer. This is not a full fat serialisation layer, rather it is a serialisation layer for the subset of C++ types which don't need to be copied in order to be serialised/deserialised. So, in your case, it would be a framework that takes in some type `T`, and produces an appropriate `byte_view`. Your users then speak to your library in terms of `T`, and it all just works until someone tries to use a `T` which isn't zero copy serialisable. Then they can implement a customisation point for that type, or manually prepare a serialised copy of `T` etc.
I think we are losing each other over the `zero copy` terminology. Currently the only copy that is being made happens inside the operating system code to take the user mode pointer and send it to the hardware to write it to the disk. The `byte_view` itself is just a pointer and size.
P1631, whenever it gets published, will define within the C++ abstract machine the proposed subset of C++ types which can be in-place converted to an array of byte, and back again. By "in-place", we mean without memory copying, which is currently required by the C++ abstract machine when reinterpret casting between object representations if you want defined behaviour. Basically, I'm proposing to you that you could take the P1631 reference implementation I linked to as inspiration for your own `T`-to-`byte` reinterpretation layer. Right now you're reinterpret casting, that's UB. And using P1631 is also often UB in current compilers. But, reusing it might help you define, with discipline, the precise well defined semantics between library user and library implementation in your library's API. But up to you, of course. It is only a suggestion.
To create a stronger type, CRTP seems to suit that purpose. class Kilometers : public Number&lt;Kilometers&gt;{}; class Miles : public Number&lt;Kilometers&gt;{};
I remember using fixed point math back on the Nintendo DS for a game many years ago. Boy could we have used a better fixed point library.
Can you elaborate which part triggers the UB? I thought that accessing a type T through char/unsigned char/std::byte is not UB.
The ReadMe contains two detailed examples: the [first](https://github.com/ZigaSajovic/CppML#generate-a-list-of-tagged-elements-from-a-parameter-pack) demonstrating basics, and the [second](https://github.com/ZigaSajovic/CppML#creating-a-linear-hierarchy-of-policy-classes-from-a-flat-parameter-pack) demonstrating advanced metaprogramming in CppML.
For something that simple, why wouldn't you just use the enum class scheme?
I'm not familiar with this pattern yet. What is the advantage?
You can copy the byte array of the bytes underlying the representation of a trivially copyable type legally into another byte array, whereupon if the second byte array is then copied into the underlying bytes of another instance with the same original type, then you get a new object of the same type with the same value as the original. This applies to trivially copyable types only. To do byte copies, yes you can read individual bytes one at a time. But no meaning is ascribed to those bytes. To interpret them as anything other than some set of random bits is UB. They only gain meaning when stored into the underlying bytes representing the same type from which they were originally copied. As you can see, that means that i/o cannot legally "spring into existence" any valid type, other than bytes. The relevant section in the standard is `[basic.types]`.
We're a Financial Services group, so we pretty much do it all somewhere. The multi-national, multi-company, infrastructure we exist in can be viewed as a massive set of micro-services, that can come and go at a moments notice. The worst thing we can do is accidentally continue processing with a bad and/or unknown state. Everyone has to be able to trust everyone else. That holds regardless of whether we're front, middle, or back-office, customer facing or in-house. To us, everything is a transaction, and the best way to recover from any kind of unexpected bad state is to fail quickly, and restart / recover from a known good state (possibly on a different system). Also, if you hit an unexpected state, whilst the state you detect may be "recoverable", there is no guarantee that what you've observed is the only bad state you have at that point. Exit quickly, Roll back to known good.
It's like a class with pure virtual functions. So every class has the same interface, but the polymorphism is resolved at compile time. This means that you don't have any overhead. Keep in mind that this pattern can't be used if you want a container of polymorphic elements, like an array of Base*. [https://www.fluentcpp.com/2017/05/12/curiously-recurring-template-pattern/](https://www.fluentcpp.com/2017/05/12/curiously-recurring-template-pattern/) [https://stackoverflow.com/questions/4173254/what-is-the-curiously-recurring-template-pattern-crtp](https://stackoverflow.com/questions/4173254/what-is-the-curiously-recurring-template-pattern-crtp)
Like for `std::byte`?
I am looking at \[basic.types\] section I am just confused as to where the UB happens. Is writing the contents to a trivially copyable using my own byte view to a file and then reading back into same/another object an UB?
Sounds like function pointers would do the job.
So to recap: You have a template class that needs some bits from the outside. Kinda like an abstract base class? In that case I'd go for a CRTP-based approach... (Sorry for short reply, I'm currently at a phone...)
It doesn’t matter. There are no resource leaks whether it throws or not (or else you have a piss-poor RAII handle class).
Looks interesting and well implemented but the examples appear to be very abstract and don't provide me with a kind of intuition or motivation for when I would want to use this, or what problem it solves. Does anyone have experience with using these kinds of meta functions? Do these meta-functions usually form part of a library's API or do they exist instead to help with the implementation of template heavy libraries?
I wasn't referring to whether or not it throws; I was referring to whether or not it gets executed when preceding code throws.
[removed]
If the current program writes all of the bytes of a trivially copyable object to storage, and then reads all of the bytes into different storage with the same type, that is defined behaviour. If it is not the current program, whether a previous incarnation of the same program, or a different program, which wrote the bytes, reading those bytes into a non-byte non-char type causes UB. In the current standard, if you wish to avoid UB for when reading bytes not written by oneself, you must add a constructor which takes a byte array, and copies the byte array into itself, being careful to not write to padding bytes. This implies a memory copy, of course. And it's why all code which implements zero copy i/o must disable strict aliasing optimisation e.g. kernels. We are working to have C++ 26 be less stupid when it comes to this stuff. The hope is that once we get Reflection, we can have P1031 directly scatter write all the valid members of read type, thus avoiding UB. We may *even* permit reading of *some* integral types if the endian is identical, but that's a long shot, to be honest. For example, `nullptr_t` doesn't have a well defined value. It could be `0x0`, `0xdeadbeef`, whatever. It may even have multiple runtime values during a program run, and possibly no runtime value at all if a current discussion on Core pans out in that specific direction. So reading and writing `nullptr_t` is problematic, even though it's an integral type.
&gt; If it is not the current program, whether a previous incarnation of the same program, or a different program, which wrote the bytes, reading those bytes into a non-byte non-char type causes UB. Can you point me to the relevant section that makes what you say undefined behavior?
Inheritance implies a “is a” relationship. I don’t think this is your scenario.
Yeah I can already see the cold sweat when you try to explain difference between const/constexpr/consteval/constinit/is\_constant\_evaluated to an average c++ programmer. Do we really need all this? I mean sure there is someone who wants it but for vast majority of c++ programmers this just sounds insane. I would hope the new education WG would put the breaks on here but they are probably busy with other stuff. Just when I started to like C++20 :/
You have impressively long bus rides. 😉 👍
&gt;Can you please elaborate on it googling it gave me more questions than answers :P
That what I was doing but when some one is reading or debugging doesnt that complicate stuff ?
I mean BasePlanner&lt;2D&gt;-&gt;DerivedPlanner&lt;2D&gt;{get\_h, get\_c, get\_n};
This one was was on my weekend =]
Sure thing. If I understood you correctly, you have a generic path planning algorithm implemented as a class and that class has some "hooks" where a user has to provide his own implementations for certain operations. In classic OOP you would solve this by declaring virtual functions in your base class and call those from the path planning algorithm when necessary. The big drawback of this approach is obviously the overhead for virtual function calls. CRTP is a technique to have a similar design, but not paying the price of virtual functions and additionally getting all the benefits of templates (e.g. heavy inlining). &amp;#x200B; The basic concept of CTRP is rather simple, yet looks strange at first glance: * Define your base class with an additional template parameter * Pass yourself as that template parameter in the derived class &amp;#8203; template&lt;typename Impl&gt; struct Base {}; class Derived : Base&lt;Derived&gt; {}; * Document the required functionality for the algorithm (as we are dealing with templates, the best you can currently get is a comment) * Implement the required functionality in your derived class &amp;#8203; template&lt;typename Impl&gt; struct Base { //Impl must provide "void func(int)" }; class Dervied : Base&lt;Derived&gt; { void func(int) { … } }; * call the implementation in the derived class from the base class, as we are guaranteed by this pattern that Base is actually a Derived after compilation this is a valid call. &amp;#8203; template&lt;typename Impl&gt; struct Base { void do_something() { //this cast is perfectly safe!! static_cast&lt;Impl *&gt;(this)-&gt;func(10); } }; That's pretty much it. Hope this helps, if you're still unsure I can think about some more elaborate example.
No, why would it? It's the simplest possible solution.
Cool. Locking this post; please move discussion there.
Why not have a separate, nested struct for the return value? Mixing them is messy.
I'd be interested in compile-time benchmarks
The new non-C interface is better, even though in principle is the same an before just with little syntactic sugar based on new classes. In what conditions read\_once/write\_once can be used? Why there is no filesystem::path argument to open a file? I always use it for path parsing/checking and std libraries have an overload for it as well, I can of course just return a string, but I think a C++ 17 library has (should have?) access to std::filesystem.
The array could work if the base template class (eg `Number`) inherited from an empty base class. It would be a bit confusing though cause the base would have to have a different name, or be in a different namespace.
I don't understand what the "Static Methods?" section is trying to say. Class templates certainly can have static methods. Are you trying to make the _entire class template_ static? You can't do that with a normal class either, templates have nothing to do with it. Then you declare a couple variables of type `Ingredient&lt;Milliliters&lt;int&gt;&gt;` so maybe you were trying to make the constructor static? Again, you can't have a static constructor in a normal class either.
The functionality sounds pretty good. Can you show me a more elaborate example ?
They’re pure functional, so yeah. Practically, completely.
1. I think there is a little more than syntactic sugar, there is no implicit conversion to void\* and read/write overloads only accept byte types implicitly. What is currently undesirable with the current interface? 2. read\_once/write\_once are useful in an I/O loop when you do not care how many bytes you receive/write such as hash calculation, compression, encryption, or even pipes and sockets where you want to set an upper limit to the reads/writes but not necessarily read/write everything. 3. The filesystem::path class holds std::string internally and as such introduces an overhead to a simple call to open such as open("/tmp/a.txt", ...).
What the standard doesn't define as defined behaviour is by definition undefined behavior! So if you can't create a chain of defined operations upon values and objects, it's not defined. More specific to your situation, you can reinterpret cast from A to B, but can you cannot use as B without UB, except byte copying under certain circumstances. You must always reinterpret cast B back to A, then you can safely use it as A. Most major compilers implement an *extension* to reinterpret casting which aliases A and B, if A and B are C-ish types. But that extension is becoming ever less reliable, and will one day probably only apply to C types only. (Unless the proposed formally specified memory model by Sewell et al gets adopted, then C and C++ both become the same, and different to now wrt aliasing. We will debate that in Cologne)
Hi /u/daveedvdv, great talk! Can consteval function parameters be used as non-type template parameter? For example: consteval void func(int n) { my_class&lt;n&gt; cls; }
Not him but I did ask him that and he said no. This has the same problem of template instantiation as constexpr parameters. I was disappointed too...
... yes, this would be a good evolution
I don’t think it really matters what you use as long as it’s compatible with your backup plan(s). At most of the larger conference venues I’ve attended the internet connectivity is terrible, so I go in assuming no internet. Sometimes the organizers want my slide deck beforehand so they can queue up all of the slides on a single machine to make the transitions between speakers smoother. I am paranoid, but my minimum preparation is: 1. Plan A, whatever it is. Keynote on my laptop, reveal.js on slides.com, doesn’t matter. 2. Something I can put onto any given laptop and have it work, regardless of the laptop’s OS or software. This means having a FAT32 formatted thumb drive. It is usually trivially easy to do both html and pdf, but either of those formats are pretty universally readable across platforms. 3. Have it easily accessible on the internet in case the easiest thing to do is to download it onto something. I really like reveal.js and use it for ~2/3rds of my presentations. It’s easier to typeset math with than PowerPoint and Keynote, and I can easily put them up on the web. I really like that people in the audience can follow along on their iPad or laptop via a slides.com link, though I’m not sure if anyone in the audience actually takes advantage of that feature. (I would!) But as convenient as reveal.js is, sometimes Keynote is just easier. I avoid PowerPoint at all costs. Google’s product, I forget what it’s called, is too featureless to be useful to me.
The pattern I've usually seen for this is a bit different. struct Input { int x; int y = 2; int k = 1; }; struct Output { int sum; int mult; int mult2; }; Output computeExample(Input in) { return { .sum = in.x + in.y, .mult = in.x * in.y, .mult2 = (in.x + in.y) * in.k }; } //... auto r1 = computeExample({1, 2, 3}); auto [s, m, m2] = computeExample({.x = 2, .y = 3}); Even more beautiful, and far less scary.
Why not use function pointers?
I understand from your comment that the standard does not explicitly classify that copying an array of bytes into a type and using the type triggers undefined behavior. Lets say we have a trivially copyable type T. It means that T's value is determined by the value representation which is determined by an implementation defined set of bits in the object representation which in turn is 1-to-1 with the value of the sizeof(T) byte sequence which we agree is the same in a new program using the same array of bytes. What am I missing? Can the set of bits in the object representation that make the value representation change between termination and startup of the new program?
As far as I understand, the flag duplicates the same function code. If functions need to have distinct pointers, why not just pad the beginning of the function with nops, and give each function name a different nop to land on? Or alternatively generate the first function, and generate a jump to it for the other ones?
What happens when you have more than one function built this way? You need to start being creative with the names for input and output structs. It may be not obvious that the structs and the function are connected. Plus you are leaking them into your public API, while the user only wanted named arguments when calling a function.
That answers it I guess. Thanks btw. :D
Heres my take on this topic: [https://bitbucket.org/p2rkw/namedarguments/src/master/](https://bitbucket.org/p2rkw/namedarguments/src/master/)
I like it. Also, obligatory: ***C++ should allow out of order members in designated initializers.***
This is what i came up with. &amp;#x200B; template&lt;class T&gt; struct Base{ Base(); void print(){ std::cout&lt;&lt;"Base Func"&lt;&lt;""&lt;&lt;std::endl; } void do(){ static_cast&lt;T*&gt;(this)-&gt;print(); } }; struct Derived: public Base&lt;Derived&gt;{ void print(){ std::cout&lt;&lt;"Child Func"&lt;&lt;std::endl; } }child; int main(){ child.do(); return 0; }
Wikipedia has some: https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern
None. The only difference between Utf-8, Utf-16 and Utf-32 is minimum "value" size, all of these do exact same thing with different encoding. Generally it's preferred to use Utf-8 and Utf-32 would be for cases where memory usage is irrelevant and you *really* are squeezing every last cycle, because Utf-32 pretty much ensures O(1) access time, compared to Utf-8 O(N).
in my portable project I made a decision to use std::string with utf8 encoding for all file paths. what is your proposed portable api to open a file having unicode symbols in its path? note that the system call for linux will expect a utf8 encoded string, while for windows it will have to be utf16 encoded string. in fact for windows the path does not have to be strictly utf16, it's an array of 2 bytes, that might not necessarily form valid unicode code point, but it's a detail not very much relevant to my above question.
[*The C++ Programming Language*](https://www.amazon.com/C-Programming-Language-4th/dp/0321563840) &amp; [*Effective Modern C++*](https://www.amazon.com/Effective-Modern-Specific-Ways-Improve/dp/1491903996/)
Got it. Ty :)
/r/cpp_questions
If you look at the interface, it provides two versions of open. One version is passthrough to the OS implementation of open/CreateFile. There is also a more simple open version which also calls open/CreateFile accordingly. Both versions accept either char or wchar\_t so although I did not try to open a utf8/16 path it should just work as expected.
&gt;Hi /u/daveedvdv, great talk! Thanks! &gt;Can consteval function parameters be used as non-type template parameter? &gt; &gt;For example: &gt; &gt;consteval void func(int n) { &gt; &gt;my\_class&lt;n&gt; cls; &gt; &gt;} As u/Rakete1111 says, the answer is "no", but let me add some color to that. (This is also a consequence of what I tried to convey with the slide at @09:30.) We tend to think of the C++ model as consisting of "compile time" and "run time". However, that's a bit of an oversimplification. Instead, in this context, think of it as *three* phases: 1. parse/instantiation time: The compiler creates a representation of a construct for execution purposes, either by parsing that construct, or by instantiating it from a template. 2. constant-evaluation time: The compiler evaluates a construct that it created in phase #1. 3. run time: The target machine evaluates a construct that the compiler created in phase #1. Phases 1 and 2 "alternate" during the compilation process, but a construct created during phase #1 cannot be *modified* through a later phase #2 action. For example: consteval int f(int p) { return p; } // #1: Compiler parses this into an internal // representation. consteval int g() { double x[f(42)]; // #2: Compile evaluates representation constructed above for f } // as part of phase #1 for x (and g). That's okay. However, with your example (completed): template&lt;int N&gt; struct my_class {}; consteval void func(int n) { my_class&lt;n&gt; cls; // Error: n is unknown during phase #1 for "my_class&lt;n&gt;". So we } // cannot construct an executable representation. You might think that perhaps the compiler could come up with a "more generic" representation for `my_class&lt;n&gt;`, but even if we did, when we call, e.g, `func(42)`, we'd now have to (temporarily?) "modify" the representation of `func` to replace `my_class&lt;n&gt;` by `my_class&lt;42&gt;`. That's untenable (you can imagine how thing might get more complicated if we did something like `my_class&lt;n&gt;::x`... we cannot even reliably *parse* that for an unknown `n`.) What you've probably seen by now is that for this to be possible \`n\` effectively has to become a \_template\_ parameter. That in turn triggers the need for syntactic disambiguators like \`typename\`, and raises all kinds of questions as to what the type of \`func\` actually is. Etc. I hope that clarifies things a little.
Well, it's a tricky endeavor. Everyone wants a simple language, but also a language that allows us to express all kinds of ideas (and, in the case of C++, high-performance ideas in particular). So, we have to make tough decisions. We (the C++ committee) actually reject quite a bit of "good ideas". But there are *many* compelling use cases and software engineering scenarios out there. And, for an industrial-strength language like C++, we end up having to address those in some way. That does mean it's not a small language and that teaching it requires the development of a careful incremental curriculum.
It's only C++ but I like it; teroxial variation: #include &lt;iostream&gt; inline static struct final { struct in final { int x; int y = 2; int k = 1; int longestDay = 0; }; struct out final { int sum; int mult; int mult2; }; auto operator () (in in) -&gt; out { return { .sum = in.x + in.y, .mult = in.x * in.y, .mult2 = (in.x + in.y) * in.k }; } } computeExample; auto testComputeExample() { auto r1 = computeExample({ 1, 2, 3 }); std::cout &lt;&lt; "sum = " &lt;&lt; r1.sum &lt;&lt; " mult = " &lt;&lt; r1.mult &lt;&lt; " mult2=" &lt;&lt; r1.mult2 &lt;&lt; "\n"; auto r2 = computeExample({ .x = 2, .y = 3, .k = 5 }); std::cout &lt;&lt; "sum = " &lt;&lt; r2.sum &lt;&lt; " mult = " &lt;&lt; r2.mult &lt;&lt; " mult2=" &lt;&lt; r2.mult2 &lt;&lt; "\n"; auto r3 = computeExample({ .x = 4 }); std::cout &lt;&lt; "sum = " &lt;&lt; r3.sum &lt;&lt; " mult = " &lt;&lt; r3.mult &lt;&lt; " mult2=" &lt;&lt; r3.mult2 &lt;&lt; "\n"; auto r4 = computeExample ({ .x = 2, .y = 3, .k = 5, .longestDay = 19440606 }); }
Udemy has good courses, but they were on sale just a few days ago and not anymore
Datastructures will most probably have you implement them by hand so C++ features used will be minimal. Unless it is an advanced datastructures class, but considering last semester was C, it is probably very basic. Check out struct syntax and vector. That should do.
Your formatting doesn't work in good reddit.
Thank you. Well said. :-)
&gt;From your SO thread I notice you use spdlog, but afaik spdlog does not use variadic functions, it only exposes functions/methods that accept template packs as arguments. That's exactly what I'm talking about. Those are variadic template functions. I didn't say that spdlog used regular variadic functions, just that I was generally learning about variadics for the first time (macros, regular variadic functions, and template variadics). &gt;I've honestly never had a good use to use variadic functions anywhere that couldn't be solved better somehow else. Oh man! I totally agree! This has been a learning experience for sure and has literally been the only thing I've been studying and working on since... the 5th? I'm at a good point now though. I know what's wrong and what my options are. Even more so than when I posted here. &gt;Variadic functions and templating are not meant to be compatible. I know, and it is what I was commenting on in my original post. It's not unreasonable for a first time learner to initially assume that they would be compatible, or even that the template would generate the other at compile time, but then to find out that the template variadics were meant to replace the usual variadics was jarring. With most other code you're either creating a discrete thing, or creating a template for a thing. In one case you write C++ directly, and in the other the template writes it for you at compile-time. This duality is broken with variadic functions and their template counterpart. I'm willing to bet there were technical reasons why variadic functions couldn't be improved, but it would be nice if I could safely use them instead of a template. Incompatibility aside, the component insulation problem I'm having exists because template variadics must be dealt with at compile-time instead of run-time. &gt;Also templating does promote reuse, but what you're trying to do is hide code. Exactly! :-D And, if a component that needs to be hidden from the client *can't* be hidden then it can't/won't/might not be reused, depending on the situation. My apologies for not making that clearer. Template code is extremely reusable, but in this particular case, the very fact that the template (and thus the entire library) must be visible at compile-time to my code's clients means that its reuse is discouraged. Using a variadic template in a wrapper interface fails to hide the internal templates and just chains it all together. It's templates all the way down! This is the first time I've ever seen a template, for any reason, discourage reuse and I found that fact very surprising.
That article looks like a fantastic read. Thank you! Unfortunately, I've already looked into that great SO answer (and learned a lot from it) and using vectors to implement type erasure isn't going to help side step the variadic templates used by the underlying spdlog library. The only way type erasure would work is if spdlog provided any sort of list-based interface, but they don't. I would need to somehow shatter any container object I used into individual function call arguments, and do it at compile time in such a way that the compile-time/run-time clients of my library could still pass in literally anything to my wrapper.
Generally speaking, I don't see any problems with using pImpl. The underlying concept is pretty straightforward, the boiler plate is well known and takes seconds to copy/paste, the boilerplate can even be centralized using inheritance and/or templates, and (in my opinion, and based on its popularity) any overhead is outweighed by the gain in modularity along with the added control over the API and (perhaps more importantly) the ABI. &amp;#x200B; As for my particular use, I'm currently only using the pImpl idiom here and will probably need it in just a couple other places. The overhead (both in work for me, and for the computer) should be negligible.
I'm assuming you mean like `namespace Detail {}` or something like that. That sounds good for organization, but that doesn't actually do anything for the problem at hand.
I think for data structures you need mostly classes and templates. I doubt they're going to teach you how to use STL, i think you are likely to re-implement std::list, std::map, std::unordered\_map and such. You might check "Effective STL" (Scott Meyers) to get idea of standard data structures in C++. It's hard to tell really what you would need for data structures course, C++ is broad and "already knowing C++" sounds like pretty insane requirement for students course. My best guess you will need classes, polymorphism, check out references too and how they are different from pointers, something something about templates, exceptions, bits from standard library and all of above combined (e.g. exceptions in constructors). And usual language constructs of course. I guess this describes any classic book on C++. Actually, you already know most of this from Python, but there are differences. You don't need to know them for data structures, i don't think so, but maybe it would be interesting for you to figure out how C++ exceptions are different from Python exceptions or how virtual functions work.
I wouldn't recommend you video tutorials. They take up twice as much time in giving you information in comparison to reading through text and reproducing. Don't try to learn as much as you can within a shot, start small projects and everytime you need a functionality google it and implement it.
See [CheesecakeWaffles's answer below](https://www.reddit.com/r/cpp/comments/bzmyv6/hiding_dependencies_when_using_templates/eqvojxw?utm_source=share&amp;utm_medium=web2x) regarding good practice. I'm not currently looking into any C++20 solutions yet. Maybe when it's specification is done and official. Even then, compiler makers all have a lot of work to do to be fully compliant. I work entirely cross platform and need to know that every major compiler is 100% (or reasonably close).
In which order should they be constructed?
Not the person you're responding to, but I don't think they meant that the _strategy pattern_ is an anti-pattern. Rather, they meant that this form of polymorphism is an anti-pattern. It is but one of many ways to implement the Strategy Pattern in C++. (I personally wouldn't call it an anti-pattern, but it's definitely a bad example in the article!)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c0pame/moving_from_c_to_c/er6vfqw/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Huh, I was actually planning to learn how to use OpenMP in a few months, so I find this library interesting. Why is OpenMP so slow compared to Cpp-TaskFlow? Do they have the same goal? Is it still worth it for someone new to asynchronous programming in C++ to learn OpenMP?
I'd imagine it would follow the same order as the constructor initializer list for consistency: order of declaration in the class/struct. Granted, here it might be more prone to logic errors with bad assumptions of ordering or ordering changing.
Why wouldn't it be the order of member declaration? This is the only sane choice because we only have one destructor, which must execute members destructors in reverse order. The initializer expressions can still be evaluated in arbitrary order like function arguments or from left to right to be consistent with braced init.
&gt; I hope that clarifies things a little. It does. Thanks for the detailed answer.
What /u/yuri-kilochek and /u/AirAKose said. Declaration order like with member initializer list in the constructor. Constructors should have a hard error because there's no benefit to not writing the min the correct order in the member initializer list, and have a manageable number of constructors to fixup when you change member order. For designated initializers though, people want to use them for optional args, allowing people to only set specific members when initializing a struct, and these could potentially be all over the codebase. The language currently has it backwards. Also, any time you bring up C compatibility somebody will say "C++ isn't C". While that's true, if C++ users didn't care about having a certain amount of compatibility with C, the C++ standard wouldn't have upgraded the version of the C standard it references, and there wouldn't be efforts on both language committees to coordinate on the new error return channel being proposed for zero overhead exceptions.
Yeah. Instead of ```` you need to indent the code with 4 leading spaces.
You really don't need to be creative any differently than when naming any class in your code. Input and Output are just generic names for this short example. But, to address your concerns about connecting the three elements, you could do namespace Example { struct Input { int x; int y = 2; int k = 1; }; struct Output { int sum; int mult; int mult2; }; Output compute(Input in) { return { .sum = in.x + in.y, .mult = in.x * in.y, .mult2 = (in.x + in.y) * in.k }; } } //... auto r1 = Example::compute({ 1, 2, 3 }); auto [s, m, m2] = Example::compute({ .x = 2,.y = 3 }); Note: neither this nor u/boredcircuits version works in MSVC because we are relying on GCC/Clang's C99-style initialization.
This course is free (YouTube) and shows full implementations of the most common algorithms and data structures. Each step of each algorithm is explained clearly [https://www.youtube.com/playlist?list=PLMB3ddm5Yvh38U0P5M2n\_VGiPVYNIoS8g](https://www.youtube.com/playlist?list=PLMB3ddm5Yvh38U0P5M2n_VGiPVYNIoS8g)
Those are valid points. But it works the other way around as well -- what if you have multiple functions that use the same arguments? My method allows reusing the same structures. Think about how you'd handle that with your version with minimal code duplication. Now think about what happens when these separate functions are related. Meaning, now I want to have a function pointer to them (or `std::function` if that helps), and then pass in the arguments later when I call that function. How will you handle that? Likewise, what happens if I want to make this a virtual function (another case of related functions)? Or inherited from a parent class? Or a constructor for a class? Ugh. I think there might be ways of doing it, but each one steps further and further away from how functions traditionally work. I don't think the separate structure method is ideal by any means. The main problem, as you said, is that you're *required* to declare a completely separate type. Maybe someday it will be possible to declare anonymous types as part of a function declaration, but for now we can't. One other thought I had about both versions: how do you make *required* parameters? Anything that has a default constructor will get a default value (an empty string for `std::string`, or even 0 for `int`), so how do you mark something as a required input? I haven't thought through all the details yet, but writing a `required` wrapper class might be able to fix this problem. Something like this: template&lt;class T&gt; class required { public: required(const T&amp; arg) : t{arg} {} const T&amp; operator*() const { return t; } private: T t; }; (This is very incomplete, but you should get the idea.) Conversely, `std::optional` could be used to indicate that no parameter was specified at all (as opposed to specified with a default value). I don't know of any language with named arguments with that feature.
You inspired me to try. I also failed. Maybe I'm wrong ¯\\_(ツ)_/¯
&gt; Note: neither this nor u/boredcircuits version works in MSVC because we are relying on GCC/Clang's C99-style initialization extension. No, it's relying on [an accepted C++20 feature](https://wg21.link/P0329R4). GCC and Clang already have support even without `-std=c++2a` because they have an extension to use the equivalent C99 feature, but [it looks like MSVC supports it as well as of v19.21](https://en.cppreference.com/w/cpp/compiler_support).
strong typedefs is the solution for this and many other problems. we use it(with our own implementation) and it works flawlessly. you can read about this idea at link(first in google by strong typedef query): https://arne-mertz.de/2016/11/stronger-types/ and i advise such mechanic to just anyone in c++ development. there is no downsides ;)
Hi, OpenMP tasking is static and not very intuitive, at least from my perspective. So, a lot of time the cost of OpenMP tasking comes from the "supporting code" to maintain the core tasking parallelism. This is also one motivation we developed cpp-taskflow. We would like to have task parallelism run at function level.
You should consider this book as the Bible in your journey of learning DS and Algorithms.
It depends on the OpenMP implementation. Currently the GCC one doesn't have a sophisticated scheduling algorithm. The Intel/LLVM one does.
Those are valid points too! I agree with the `required` wrapper idea, something like this would be needed for required parameters. &gt; what if you have multiple functions that use the same arguments? My method allows reusing the same structures Well, I guess this is business as usual: as soon as you start to see a lot of function using the same set of parameters, a dedicated named input structure starts to make sense. So, I would refactor it in order to introduce a named structure, just like you. &gt; Maybe someday it will be possible to declare anonymous types as part of a function declaration, but for now we can't. Yes, this is exactly the point, but I'm afraid that we might have to wait a long time before we have something like in C++. This code demonstrates that it is syntactically possible to create anonymous input/output types; however it requires to wrap them into a structure instead of wrapping them into a function. This is convoluted and I probably would not use it in production. However there is a real need for something like this, especially in data driven development style.
The "f" approach looks like [continuation passing style](https://en.wikipedia.org/wiki/Continuation-passing_style)
Great writeup. I am thrilled that you are exploring these topics with C++ and that you are sharing your insights with others. However, it seems you are writing Java accented C++. Let me present an alternative. class StarWarsCharacter{ public: StarWarsCharacter(std::string name, std::function&lt;void()&gt; useWeapon) :name_(name), useWeapon_(useWeapon){} void SetWeaponBehavior(std::function&lt;void()&gt; useWeapon){ useWeapon_ = useWeapon; } void Fight(){ std::cout &lt;&lt; name_ &lt;&lt; ": "; useWeapon_(); } private: std::string name_; std::function&lt;void()&gt; useWeapon_; }; int main(){ auto blaster = [](){std::cout &lt;&lt; "I am using my blaster!\n";}; auto light_saber = [](){std::cout &lt;&lt; "I am using my blaster!\n";}; auto cross_bow = [](){std::cout &lt;&lt; "I am using my blaster!\n";}; StarWarsCharacter han("Han Solo", blaster); StarWarsCharacter luke("Luke Skywalker", light_saber); StarWarsCharacter chewy("Chewy", cross_bow); han.Fight(); luke.Fight(); chewy.Fight(); han.SetWeaponBehavior(light_saber); luke.SetWeaponBehavior(cross_bow); chewy.SetWeaponBehavior(blaster); han.Fight(); luke.Fight(); chewy.Fight(); } This is a slightly more modern take on the pattern. One think that you will notice is that we are not doing manual memory management anymore, so there is less opportunity to leak memory. It is also shorter. In addition, we are not using inheritance hierarchies. One thing when working with C++ is to separate the concept of polymorphism from inheritance and virtual functions. If you don't need the runtime flexibility, static polymorphism using overloading or template parameters can be very useful with reduced overhead as well as catching some errors at compile time. Even with runtime polymorphism, many times using some type of type erasure (for example std::function) can be superior to using virtual functions. Here are some stuff that you can do to increase your exposure to these techniques: 1) Watch Sean Parent's talk "Inheritance is the base class of evil" https://channel9.msdn.com/Events/GoingNative/2013/Inheritance-Is-The-Base-Class-of-Evil 2) Try to go through the pattern book and implement C++ versions that use static polymorphism (either using overloads or template parameters) or else use runtime polymorphism but without using inheritance. You probably won't be able to do that with every pattern, but you should be able to do that with at least some and it can help you get away from the habit of reaching for virtual whenever you want polymorphism.
that's the problem, I'm mentioning, there are two versions, but my portable project requires just one version to do the job for all cases. I prefer to have utf8 encoded string on windows and open a file with unicode path, by doing on the fly conversion to utf16. I don't like to have additional ifdef-logic on top of file open api. even std::fstream does not have a solution for this, that's why I had to use boost::fstream.
Both versions of open support both utf8/16 I imagine that since you are portable you would want the simpler cross platform version that accepts path and open mode. The path being accepted is a template so if you send a wstring it would automatically call CreateFileW. Does that solve the issue?
Factorio is close to finishing? Thats news for me!
your proposal is similar to std::fstream. for windows you offer me to call the wstring api. but since I want to have no ifdefs and just one utf8 string in any cases, it will not work for me.
Do you propose that open would get an argument saying whether it should be forced to be interpreted as wchar_t?
not really. my choice is an "open" that takes utf8 string. the rest is encapsulated. if it's Unicode build, then it converts to wstring and calls the createfilew, otherwice createfilea is called. boost goes further, it has filesystem::path, which can be configured so that when used for open will take care of utf8 to utf16 conversion. and for the "list files" api will take care of the opposite - utf16 to utf8 conversion.
How would you know if the encoding of the string is both valid utf16 and utf8?
&gt; you know if the encoding In Soviet Russia, the encoding know if **you**! ^(this post was made by a highly intelligent bot using the advanced yakov-smirnoff algorithm... okay, thats not a real algorithm. learn more on my profile.)
&gt; you know if the encoding In Soviet Russia, the encoding know if **you**! ^(this post was made by a highly intelligent bot using the advanced yakov-smirnoff algorithm... okay, thats not a real algorithm. learn more on my profile.)
it can't be both. maybe I'm getting your question cut off from the context already.
in any cases for this problem to be solved in a usable way, we need some layer of additional abstraction. it can be a string class such as Qt QString, which is aware of how the string is encoded and is able to provide any alternatively encoded copy to any other function, so windows version will choose to work with utf16 encoded copy, while linux version will go with utf8 copy. or it can be done with several types. say, you have utf8string and utf16string types, you choose to use whichever type you prefer in any part of your code. and then you are able to do the right conversion anywhere you need to. my choice was to just work with std::string, but with a fundamental for my application condition - all strings are utf8 encoded. then I had to take care to find proper api-s that would handle the required conversions whenever needed. boost::filesystem::path solves this for me.
I just figured it out, I thought you wanted that open would automatically recognize whether the string is utf16 or 8. In any case it is really project dependent. Let's brainstorm a bit, How about an open overload supporting char8_t and doing that conversion for windows?
!remove
OP, A human moderator (u/STL) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c0ufdv/please_vote_intel_compiler_support_in_clion_here/er7txe0/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
on one hand it is project dependent. on the other, utf8 is almost everywhere, so choosing it is obvious for me. char8\_t overload that is smart enough to handle all cases with internal encapsulation sounds good to me, but it seems to be c++20, I'm not sure. me, personally would choose a string type, not a char type, though.
You are right, char8\_t is C++20, I am looking into assuming utf8 for char, do you see any implication for that?
choosing char does not express that it is utf8. neither does std::string, but I would choose the latter. other than expressiveness, no implications.
I assume there might still be users who want to use ANSI which can be seen as default for char. I am thinking between just assuming it is utf8 for windows or simply inserting an #ifdef so that you can define ZPP\_FILE\_OPEN\_CHAR\_IS\_UTF8 and then get the conversion to happen whenever you pass a char to open in windows.
I wouldn't assume ASCII for a unicode build. we already have that define on windows so I would't introduce additional conditions.
 namespace detail_thirdpartylibrary { #include &lt;thirdpartylibrary.h&gt; }; template&lt;typename... args&gt; auto wrapper_function(args... Args) { return detail_thirdpartylibrary::function(Args...); }
What are real case scenarios for such ML stuff?
Check this out and let me know what you think: [https://github.com/eyalz800/zpp\_file/pull/2](https://github.com/eyalz800/zpp_file/pull/2)
Thanks so much for the feedback and additional info. It was very helpful. I was going to look at the type erasure approach this weekend and re-implement this pattern. Looks like you beat me to it. It is as i envisioned it after some brief research. Thanks!
the wide variety of template possibilities makes it difficult to read, but this time, you have the api to make it for portable use. it seems correct code.
Well that sucks. So let's say I make a game try to optimize it by doing different things, such as using OpenMP, some SIMD operations, CUDA and finally the threading module added in C++11. Then that means I would have to compile with as many compilers a possible to test intensively my software just to check which compilers offers the most execution performance for my game?
Awesome. I agree that the state machine for which CreateFile to use is somewhat difficult to read, but it is a lot less complicated in my opinion than usual library code that I know (I find it hard to believe that boost::fstream is any simpler).
You want the arithmetic operators?
It would also lead to the ability to write something like: consteval auto func(int n) { return my_class&lt;n&gt;(); } So `func(42)` and `func(43)` return... different types?! What is this, Python? But seriously though, while I understand why constexpr parameters cannot work in our correct model I would love to explore the direction of calling that sugar for templates. template &lt;int n&gt; constexpr auto func2_today() { return my_class&lt;n&gt;(); } constexpr auto func2_tmrw(constexpr int n) { return my_class&lt;n&gt;(); } So `func2_today&lt;42&gt;()` becomes `func2_tmrw(42)`.
Since I do mostly performance related stuff (I research in HPC), most of the time you should consider everything before diving into development. BTW, almost everyone in HPC uses the Intel compiler since it's optimized for numerical performance. However it lacks a some language features which makes it an unpopular choice for general development (It also works only for Intel). GCC and LLVM are more suited for your scenario.
Hi, your benchmark results currently doesn't include HPX which is a very popular and well made task parallelism library. Have you compared the raw performance of Taskflow against HPX?
I've revamped the wait free queue, you should have take a look :)
Shared data should always be guarded properly using atomic or acquired writing handles.
&gt; acquired writing handles In my case that's a little more complicate. The processes don't have access to OS handlers. They have a region of the virtual memory that is mapped to the same physical pages.
I assume you could implement them just as you would have to in the class example above. They'd just have to be globals instead of members. In return you get the efficiency of a fundamental type with the enum scheme.
factorio is an awesome game.
boost::interprocess may be what you're looking for, IIRC.
Factorio 0.15 was the last version before 1.0. Afterwards, 0.16 became the last version before 1.0. Then, 0.17 became the last version before 1.0. And while 0.17 is the current version, 0.18 is already announced to be the last version before 1.0!
Quick note that modern compilers can devirtualize virtual methods most of the time, so the old advice "virtual functions are slow" isn't necessarily true any more
I guess by "most of the time" you mean situations where the compiler can undoubtedly prove that the static type of a variable is equal to its' dynamic type. I somewhat doubt that compilers can do that proof with complex situations - though I'd love to be proven wrong on that...
You'd have to manually implement it for all enum classes, while CRTP gives it "for free". And class/struct is no less fundamental than a enum, with the same "efficiency".
This is something you can use for interprocess communication of already serialized data: https://github.com/LiveAsynchronousVisualizedArchitecture/simdb Serialization can be done with a library like cereal without too much trouble. I typically use a combined vector and hash table that is always serialized though, which makes things easier.: https://github.com/LiveAsynchronousVisualizedArchitecture/lava/blob/master/tbl.hpp
Michael spent a decent amount of the time talking about the game rather than the technical technical (C++) side of Factorio :D If anyone's interested I could answer other technical questions.
1. How useful is constexpr to you? (does it actually give more performance etc) 2. How much std algorithms/containers do you use and how much do you make on your own? 3. What extra tools to help with development have you set up? valgrind, clang-format etc? 4. How does std::visit compare speedwise to your own?
I want C++ 2.
What platform are you on? You just described typical shared memory.
Native and web assembly. They actually run in the context of the same process
We use it quite a bit, but it's a bit of a PITA. I hope newer versions support transparent comparators, because using a data structure where the key is a string requires an allocation in the shared memory itself when doing a lookup. Really bad.
Native what? X86? What OS? How does web assembly fit into it at all?
webassembly runs in its own address space
What do you mean by that? It has to be run by some process. Any interprocess communication is going to have to happen by calling a native function from webasm anyway.
IIRC it should technically be possible with STL containers if they all used fancy pointers instead of raw pointers. Not sure if that would help with the 32 vs 64 bit issue though.
&gt; 1. How useful is constexpr to you? (does it actually give more performance etc) We use it, but it's not that common. Most things just can't be done at compile time. It replaces the stray ifdef for some platform specific things ```if cosntexpr is-linux```. The most common if-constexpr we have is doing some special logic if the current type in a variadic fold expression is of some specific type. Overall I don't think it gives any performance gain for us - it just allows for nicer code. &gt; 2. How much std algorithms/containers do you use and how much do you make on your own? We don't have any rules about not using std stuff so they're used heavily. Things which std doesn't have we've written our own. Or, when performance becomes a problem we write a usage-specific implementation of some container/algorithm. Things like the size-check overhead of vector when you *know* at your call site the container will always have capacity and we can just remove all of that. Algorithms get used but not that commonly. Their verbosity is a huge negative. One of the nicer things we did was making simple versions of the common algorithms: ```util::find_if(T&amp; container, Pred&amp; predicate)``` and so on. &gt; 3. What extra tools to help with development have you set up? valgrind, clang-format etc? Our test system runs address sanitizer and valgrind nightly. We don't use clang-format because so far every auto-format tool we've tried always lacks something or gets something wrong. I personally use Resharper C++. &gt; 4. How does std::visit compare speedwise to your own? We don't have a version of std::visit but instead the usage we had of it we replaced completely with a usage-specific bit of logic that operates using a simple taged union. [More on that here.](https://www.factorio.com/blog/post/fff-206) &gt; 5. Any smallish utility functions you find handy and like to share with the wider world? The most useful utility functions (to me) are the ones which wrap all the annoying iterator-based std algorithms to instead take the container and the "work" you want to do (find/if, count/if, erase/if, remove/if).
Is there no limit to the complexity you guys are trying to add to C++?
Have done this before, it’s hard. Also only libc++ STL properly uses fancy pointers.
Looks good. Any plans on your roadmap to generalize cpp-taskflow such that tasks and subflows could be dispatched to run on remote machines? Thinking about horizontal scaling here.
Additionally, you should look into RAII. Unlike managed languages like Java, the default place where most things live in C++ is the stack. Low level details like memory allocation are delegated to the wiring. For example, instead of saying something like `int *x = new int[30];`, mostly we say `std::vector&lt;int&gt; x(30)`. `std::vector` internally is doing some form of dynamic memory allocation like the above, except that you never have to think about it: when the `std: :vector` gets destroyed at the end of the scope, its destructor is called, which frees all the memory it acquired. This is a general pattern known as RAII, and it is used throughout the standard library and all good C++ code bases for managing any kind of resource. For example, say you want to write a file handling class. You could say something like class MyFile { FILE *f_; public: MyFile(const char *filename, const char *mode) : f_(fopen(filename, mode)) {} ~MyFile() { fclose(f_); } FILE* fp() const { return f_; } }; That illustrates the basic idea. You would use the class like this: void whatever() { auto f =MyFile ("test.txt", "w"); fprintf(f.fp(), "test\n"); } // destructor gets called here, f gets closed Now you can't ever forget to close the file. You get a compile-time guarantee that the resources owned by an object will be valid as long as the object itself lives, and no longer. It virtually eliminates any possibility of leaks. Something like this is how `fstream`s are implemented, which is why you don't need to close them. All of this is basically to say that you should almost never have to write `new` and `delete`. Even your original flavor of the pattern would be much improved if you used `std::unique_ptr`instead of bare `new` and `delete`: auto blasterBehavior = std::make_unique&lt;BlasterBehavior&gt;(); auto hanSolo = std::make_unique&lt;StarWarsCharacter&gt;("Han Solo", blasterBehavior); Now you can't ever forget to `delete` anybody. All in all, I greatly recommend this [presentation](https://www.youtube.com/watch?v=AKtHxKJRwp4 ) by STL. He goes over some of the problems in your code, both the lack of RAII as well as some other things we didn't talk about (like the unnecessary construction of an `std::string` temporary).
That's why I super glue my fly shut before every presentation.
There are restrictions on no type template parameters (even with the C++20-expanded model) that I suspect would quickly become frustrating with that approach. A direction that I think is more promising are hygienic macros. There is at least one proposal in that direction that has recently been made to the committee: http://WG21.link/p1221 (Jason Rice’s parametric expressions proposal).
Thanks for the additional feedback. Much appreciated. I have some work to do
I get the point about symmetry of runtime/runtime-compiletime/compiletime, what i don't get is why would you want a function that is available only at compile time. What if i want to call f() at runtime too? Do i need to have two implementations of f() now one of which is available only at compile time and another is available at runtime or both? What is the utility of being compiletime-only? If you would want to force compiler to evaluate something at compile time, wouldn't it be simpler to do something like (pseudocode): ```c++ int x = std::is_constant_evaluated(f()); ``` Which #error's if this can't be evaluated at compile time? Another thing i don't quite get: i've looked into C++2a support in compilers to try and fiddle with this, however cppreference doesn't even list `consteval` in C++2a features and GCC and clang just say "No" on their compatibility pages. Is there any reference implementation for consteval?
I think the prevailing thought is, it would encourage deeper nesting of loops, instead of refactoring code or using better algorithms.
&gt; what i don't get is why would you want a function that is available only at compile time Two reasons: - some stuff doesn't make sense to run at runtime, for example reflection stuff since this requires a compiler to get the information. - you want to guarantee that no runtime code is generated &gt; What if i want to call f() at runtime too? Do i need to have two implementations of f() now one of which is available only at compile time and another is available at runtime or both? You use constexpr. You can't overload based on constexpr, consteval. But constexpr gives you both the ability to run the function at runtime and at compile time. &gt; What is the utility of being compiletime-only? Basically the same as constexpr but you want to force constant evaluation since for example you're doing embedded stuff with not much space. &gt; If you would want to force compiler to evaluate something at compile time, wouldn't it be simpler to do something like (pseudocode): Yes this came already but in this form: int a = constexpr { f() }; Or something like that. The reason why this isn't an acceptable solution is: Do you really want to write that every single time you call some function? Because if you always want constant evaluation, that is what you're going to have to do with your idea. &gt; Is there any reference implementation for consteval? I can only comment on clang: As of yesterday, consteval is in trunk! :) So you can download and build it yourself to try it out, or wait a day until CE picks it up and makes it available the next day.
Labelled for exist because Java doesn't have Goto, or didn't when it was implemented. There's no reason for it when your gave Goto, and it shouldn't be used in 99% of cases because it's confusing, hard to maintain, and difficult to debug.
They are just Goto statements. They already exist.
Short answer, if you find yourself needing this, your code structure is at a point where a `goto` won't be the part that makes people cry. So there isn't much use in specifying it.
But for those 1% of the cases it's usually the simplest and least confusing option. An imvaluable part of the language.
I once heard that they would be easier to implement as `constexpr` than `goto` though (which isn't `constexpr` today).
Even if this is true, you still have to pay the price in the size of the object.....as it almost certainly will increase to accommodate a v-table
Now i don't get it even more. Are you saying that reflection is going to be compile time only and a class coming from factory won't be inspectable at runtime? To be honest, i don't write programs that execute at compile time so this is quite hard to grasp. Sorry if this is somehow a stupid question, but &gt;you want to guarantee that no runtime code is generated Do you have an example? Couldn't compiler just discard unused code during optimization? I don't get why would you want that so badly you introduce a keyword. I see the point in forcing compile-time evaluation instead of giving a hint to compiler, i just don't get why not make a compile-time check for that. There is `enable_if()` and all that "metaprogramming stuff" that works at compile time, can't it be reused somehow? &gt;Do you really want to write that every single time you call some function? Well, as far as i understand, you don't really call it. If you want compiler to evaluate function at compiletime, why wouldn't you want to place a check in that particular place that fails if compiler couldn't do that? What if want compiletime eval in one place and runtime eval in the other place? This really brings us to the same place: do i need to have two implementations of `f()` now? &gt;I can only comment on clang: As of yesterday, consteval is in trunk! Ok, thanks, good to know. I'll check that when it is released. Just strange see "No" on compatibility page if some work has been done on this and it's already in mainline.
&gt; a class coming from factory won't be inspectable at runtime? I don't understand. The factory returns a type, that type is known at compile time so you can
&gt; a class coming from factory won't be inspectable at runtime? I don't understand. The factory returns a type, that type is known at compile time so you can use reflection to inspect it. &gt; Couldn't compiler just discard unused code during optimization?. Yes but a guarantee is nice. &gt; I don't get why would you want that so badly you introduce a keyword. There's also the first reason. &gt; why wouldn't you want to place a check in that particular place that fails if compiler couldn't do that? But if every function calls needs it, it's a bit dumb. &gt; do i need to have two implementations of `f()` now? No, if you need both use constexpr. You either want always constant evaluation or sometimes. I'd that sometimes is very rare than yeah, it's probably a good idea to split the implementation I guess. &gt; Just strange see "No" on compatibility page if some work has been done on this and it's already in mainline. It takes a while a while to update.
I also find it disingenuous to argue there's no reason for it because `goto` exists. You don't even need for loops or while loops or recursion if you have a `goto`...
```c++ std::shared_ptr&lt;Item&gt; Factory::create_item(const std::string &amp;item_id); auto item = Factory::create_item(user_input); bool usable = (!!item-&gt;get_method("use")); ``` There is no chance this is going to work at compiletime because it depends on user input. I guess i need to check reflection proposal too. &gt;if you need both use constexpr &gt;but a guarantee is nice So if i want guarantee i use `consteval`, and if i want to call it at runtime i use `constexpr`, so i have to have two implementations of `f()` is that what you're trying to say?
I can't understand this stance. I work in computer graphics and have to work a lot with 2D data/arrays. I don't run into this problem every day, but often enough that I wish that we had something like labeled loops. Just because most fields discourage nested loops doesn't mean there are areas where they are unavoidable.
Not quite. They're a scoped goto. This tiny restriction makes them significantly more palatable to many than a goto.
Usage of `break label` in Java is discouraged: [https://rules.sonarsource.com/java/RSPEC-1119](https://rules.sonarsource.com/java/RSPEC-1119)
the easiest way would be to make a a vector of nodes `std::vector&lt;Nodes&gt; node_list( numNodes ); ` This will automatically take care of cleanup for you, and you can index each by `node_list[ i ]`
I don’t know, but these are the usual answers. 1. Perhaps nobody has submitted the proposal. 2. Perhaps the committee has bigger fish to fry. 3. Perhaps there’s a non-obvious technical hurdle. Personally, I’d be good with it. I still think we should’ve have gotten “finally” a long time ago, but at least we have good-enough alternatives for that now.
Yep jshakes beat me to it. You simply create a class vector and then iterate that using a forloop. I do this all the time when creating class objects for a physics simulator. Also don’t forget to specify between unsigned during forward loop otherwise you’ll get a warning unless you either use cast or reverse iteration! Good luck.
Personally coming from c# all uses for finally have evaporated after I understood the using and IDisposable interface. When I switched to c++ and got my head around proper RAII it seems even better. No need for a special language construct like the using statement.
Having “finally” is not about not using RAII when you should use RAII. It is about not having to abuse RAII in a situation where you aren’t acquiring a resource and you would use “finally” if it existed.
what do you mean by "specify between unsigned during forward loop"?
awesome, thank you. Now i'm just having issues printing out the contents of the vector. I keep getting "error: no match for 'operator&lt;&lt;'"
I'd like to have a `breakall` or something that does that except it just breaks out of all the parent contexts where break would be relevant. Just a way to get all the way out of nested loops elegantly. Not really because I'd use it all the time or encourage it, but something that's not an exception that could do what it does when one or two nested loops are unavoidable.
No one is saying they shouldn't exist, only that they already exist in C++ so there's no need to implement them, they already exist.
I place my bet on #2. Also, Stroustrup has said something like "we need another control flow structure like we need another hole in our heads".
&gt; it would encourage deeper nesting of loops, instead of refactoring code or using better algorithms I can't really argue against that, but just like not allowing aliasing its a language choice that mostly just really annoys me.
It's rarely needed, better avoided, and if you *really* can't avoid it `goto` and a comment works as well.
That's what goto is for
I'd consider immutable data structures. Then the processes just have to do reference counting in a shared manner, and sometimes pass the identity of new container (a singke pointer) to the other process. Modern immutable data structures can evolve efficiently (add/remove elements), they just change identity as you do it.
I never use break and goto in C++, I don’t even consider them when coding. I think there’s always a way to avoid them with a little effort.
How about a proposal for a `[[scoped]]` attribute that can be applied to `goto` and to labels. A label with the `[[scoped]]` attribute must be immediately before or after a closing brace. A `[[scoped]] goto` must target a scoped label in an outer scope of the `goto`. `[[scoped]] goto` would then be continue-like or break-like and could be in `constexpr` functions.
I suppose they are talking about the type of your iteration variable in the for loop. If you use a vector, the usual iteration is something like for (int i = 0; i &lt; vec.size(); ++i) The size method of vector returns an unsigned int and your compiler might warn you for comparing the signed int i to that unsigned int vec.size(). That is why the user above you recommends to make i an unsigned int as well. However, most modern C++ styles would disagree, as using unsigned int over signed int often brings additional errors or pitfalls while having very little benefit.
&gt; Ok, thanks, good to know. I'll check that when it is released. Just strange see "No" on compatibility page if some work has been done on this and it's already in mainline. It says `no` because it's not finished yet. I think only parsing support for the `consteval` specifier was implemented. For example [this](https://godbolt.org/z/TrcxL8) should not compile. Apparently `consteval` is being treated like `constexpr` for the moment.
Can you give an example?
I prefer `goto foo_break;`
Though I have experience on Java when I wrote code for Android programs, I didn't even know it supports labelled for-loop, till today. I still don't think it is a good practice to use this syntax(feature), let alone I haven't used \`goto\` to break loop in C++ for years.
in general introspection is useful when you know what you want as a function of the type e.g. serialization. I have no idea about this particular library tho...
I am curious what job uses Roman numerals
Can you provide a motivating example where `goto`ing out of a nested loop is the best solution? In my personal experience, every time I've thought I wanted to do this, there's ended up being a cleaner structured programming alternative.
C++ could use a labeled switch though. If you nest switches there's no way to say which switch a particular case should be for and goto won't get you out of this since the target of a goto is statically know at the goto-site, unlike a switch.
Any plans on colorizing Linux output similar to *python-catkin-tools'* **catkin build** command?
Make the nested loops a function, use `return`. A lambda is one way to express it as a function. With a lambda you avoid having to pass a potentially large number of arguments.
Many things can never be forward-declared at all, because `typedef`s and `using` statements cannot be forward-declared in C++ today. If the library's definition is something like: ``` namespace my_library { namespace secret { class SomeSecretType { ... }; } using SomePublicType = secret::SomeSecretType; } ``` Users will use `my_library::SomePublicType`, but it cannot be forward-declared without forwaring-declaring `my_library::secret::SomeSecretType`, and putting the `using` statement in the forward-declaring header. It is currently an error to have multiple typedefs defining the same name, even if they end up referring to the same thing.
I don't fully agree. If you want to break to an outer loop as well as continue on this outer loop, you'll need to have two labels, one just at the end of the scope of that outer for loop, and one after the scope.
That might work for break, but not for continue. And also not when you want to be able to break to different outer loops.
As I see it works for 99% of cases, roughly. Which are rare anyway.
Thanks for your comments! I think this kind of comment is exactly where future C++ should take inspiration from. Not a random bunch of new keywords for initialization like explained in the other post cough cough). And fortunately ranges overloads are already in the draft! One has to use a namespace alias though otherwise the verbosity is still there.
What about providing additional condition as simple boolean variable? bool br = false; &amp;#x200B; for( int i = 0; condition &amp;&amp; !br; ++i) { ... for( int j = 0; condition &amp;&amp; !br; ++j) { ... if( j == 5 ) br = true; } }
You don't need anything special there. Just a break in the inner loop and then the outer will continue executing until it returns. If you want to go to the next item in the outer loop as well, you just need a continue statement tied to whatever condition. Unless I'm not following your example correctly?
That is only possible when there is only code in the inner for loop, to for the following example: for () { // some code for() { // some code if() { goto to_continue; } else if() { goto to_break; } // some code } // some code to_continue: } to_break:
Naturally sentinals will work, but when extra code in between the for loops (inside one of the outer loops but outside the inner loop) this will add extra if-statements. Using labeled loops the intent can be much clearer, IMHO.
&gt; There is no chance this is going to work at compiletime because it depends on user input. ? No it doesn't. You can reflect on types, functions, variables and those are all fixed at compile time. You can't inspect the values yes, but why do you need reflection for this? &gt; is that what you're trying to say? Yes, but honestly I don't think this is needed often.
I work for a defense contractor... Actually dont know how much I'm allowed to tell due to NDAs and all that, but in short, the only acceptable input for a particular field in a window was I-IV. Ended up just using a regex (IV|I{1,3})
weird
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c1358u/trying_to_make_a_series_of_objects_in_a_class/erbgc8c/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
CPP: still struggling to get lambdas consistent. Oof, keep plugging guys, you’ll get there eventually. Maybe then you can tackle async/await. Glad you guys finally got rename refactoring, even if it can’t possibly work 100% of the time due to the grammar of your language.
\&gt; still struggling to get lambdas consistent Can you elaborate on this?
Why is everyone so tribal on everything, even programming languages.
Just warning others that there are significantly better languages out there
[Here, have one. It's on me.](https://i.imgur.com/uIcmgRz.jpg)
That's what `return` is for.
How is it's debugger?
I tried it a few months ago and is was horrendous to install. Something about hardcoded paths in its CMake instead of find scripts. After fixing that by hand and installing it it struggled with completion and syntax highlighting on slightly bigger projects with custom toolchains. It's nice to hear that there is progress, but honestly I'll wait at least another year before trying again
In some tricky algorithms it's not always possible to extract nested loops into meaningful functions. So far I've seen two versions of TimSort use `goto`: one because the specific part of the algorithm was really hard to express without it, and another one that switched to `goto` because it felt easier to read than keeping track of a boolean to know whether to break out of the outer loop whenever we break out of the inner loop.
Small example from a pull request targeting a popular TimSort implementation: https://github.com/gfx/cpp-TimSort/pull/27/files
Does it support C++20 already? Would be the first IDE to do so, if I'm not mistaken
Just another Rust fan spewing inaccuracies, judging by their mention of `await`.
I highly recommend reading this. [https://quuxplusone.github.io/draft/fancy-pointers.html](https://quuxplusone.github.io/draft/fancy-pointers.html) Very similar technique is implemented in \`boost::interprocess::offset\_ptr\`.
Processes have dfferent address spaces and so pointers cannot be reliably shared. You need offsets instead.
&gt;Things like the size-check overhead of vector when you know at your call site the container will always have capacity and we can just remove all of that. You can remove that with introducing of an assert or UB which will force optimizing the check away.
What a strange discussion. Why would i want to inspect something if i know what type is it. Type is a complete description of a.. well, type. The problem is with e.g. pointers/refences to base class which real type can not be figured out at compiletime because it is yet unknown. This is why you might need reflection - to inspect an object at runtime. The only way i see how compiletime reflection could be useful is if it somehow generates a function usable at runtime. But if consteval does not produce runtime code by design, then i don't even know what to think. This is really confusing, i just hope that this will somehow turn out well in the end.
&gt; This is why you might need reflection - to inspect an object at runtime. But we already have this, it's called RTTI. Sure we can't use reflection to inspect the runtime type of the object, but you can do this manually with `dynamic_cast`.
IDE wish list item: Bazel support that doesn't completely suck. &amp;#x200B; Not related to this particular project, just a want.
Yes, the pointers need to be smart. That was more than.covered in the OP's post.
C++17 is very worth it if you actually make use of the features
&gt; -you get to know C++14 -&gt; can be useful if in the future you will be forced for some reason to use C++14 code I don't think that many things in C++17 make obsolete stuff that appeared in C++14. However, there are plenty of things complicated in C++14 which "just work" in C++17 (e.g. returning a std::lock_guard, etc etc)
C++17 is supported by all major compilers: gcc, clang and MSVC. It allows for some very clean code. For example, iterating a map: std::map&lt;int, int&gt; m; for (const auto&amp; [key, value] : m) { std::cout &lt;&lt; key &lt;&lt; std::endl; std::cout &lt;&lt; value &lt;&lt; std::endl; } C++14 is more considered a cleanup and patch for C++11, while C++17 introduced more new stuff. It also allows to make the code faster in some instance (e.g. constexpr functionality has greatly expanded). You don't need to rewrite old code, as both C++14 and C++17 are (mostly) backwards compatible with C++11. Up the C++ version, recompile and fix any errors (which should be few), and write new code with C++17 features &gt; ???? &gt; PROFIT
It uses uses libclang for its C++ related features. As soon as your linclang version supports C++20, it will too.
I prefer when labels describe what they are labeling rather than how they are used: `goto top_for;` or something like that. I find it both more informative and more readable.
What?
__How is it's debugger?__
"But we already have compile-time reflection, just write template specialization for a known type". No, this isn't how it works. You call a virtual function on a pointer/reference to a base class and correct type-specific method is automatically invoked without dynamic\_cast. But this isn't a point of reflection, take a look at how reflection works in other languages.
IME each new version has been more permissive, so I don’t see there being a lot of friction regardless.
Two "etc"s don't compensate for a lack of examples.
Didn’t you just post this?
This looks interesting and polished. Do you know if it supports plugins? I've been searching for an open source competitor to Sublime Text 3, and this seems to have the 3 basic UI features I'm looking for in an editor like that: file tree, text editor, and console. Also, is the text editing functionality custom made, or is it based on something else like Scintilla or Kate? If this thing is only for C++, then it has limited appeal (IMO). How many real-world projects only use C++ as opposed to a mix of various languages and technologies? Sublime works great because it's focused on just being a solid text editor, and language support (syntax highlighting, auto completion, etc) are implemented as plugins. I noticed this thing is calling itself an IDE, so does that mean it's trying to compete more with Visual Studio rather than Visual Studio Code?
OMG I love factorio.
Hey, I'm curious as to why you use Bazel? Does it offer something unique that benefits your particular workflow, or do you just prefer how it works compared to other build systems, or some other reason? I've trying to find a good build system that isn't tied to a particular language so I can transition all my projects.
Yeah true, RTTI is not full reflection. But with RTTI and static reflection you can achieve everything that reflection that other languages give you. And you only need RTTI to find out the dynamic type of an object and once you have that you can use static reflection.
Sorry my bad!!
Shit didn’t realise you can use structured bindings that way.
This kinda makes sense, but static reflection has to be available at runtime too because this happening at runtime. So this doesn't explain why would you make a function available at compiletime only. This consteval thingy looks to me like glorified macros, you do consteval and compiler does substitution, but it does that in a very sophisticated way. Still not clear why constexpr is not worthy to be glorified macros. Also, how do you attach debugger to a function that doesn't exist at runtime?
How is you're English?
You use break; on the if, and goto on the else if.
A break in the if won't work as the last "some code" gets exexuted, so it is different from a goto to_continue
:DD source?
True. I would say that this kind of control flow is too complex and should be refactored to something simpler.
VS 2017supports Coroutines TS, I know (because we use them at work).
It uses gtksourceview to implement the text editor. juci is mainly an IDE for C and C++. It uses libclang and lldb to provide language and debugging features. For other languages it has only basic support like syntax highlighting and to execute/compile code i.e. for Rust or Python by pressing `ctrl + enter`. From their gitlab page it looks like they are working on a python based plugin system.
Well it depends on the logic of the surrounding code. Assume you iterate over a 2D matrix and try to find the first row that contains the number 'a' before any 'b' is encountered in that row. Of course this example is too simple to not be written differently, as it does not account for the "some code" parts. But the if and else if could feel quite logical.
The name 'juicy pp' brings up questions...
I've never heard of that website before, but under c++, it tells me that a function should have only a single exit or that I shouldn't use `//`- style comments. Just because there exist such a recommendation somewhere in some guidelines, I don't think that is evidence it is generally discouraged.
TIL I learned java has labled loops. Every time I bring up the idea for C or C++, it's "like in perl".
Assuming we stick to a 3-year release schedule, you will get your wish in the year 2302.
...... Oh god
&gt; This kinda makes sense, but static reflection has to be available at runtime too because this happening at runtime. Can you provide an example? Because I can only think of the dynamic type thingy. Like most uses of reflection can be done at compile time. &gt; compiler does substitution Well it's still a function call, not just substitution. &gt; Also, how do you attach debugger to a function that doesn't exist at runtime? You don't. This is one of the known problems with static reflection. There are tools to deal with this and the committee is aware of this problem :)
Man, i really wish vscode wasn't an electron program. I wish it was native. It's so slow sometimes, like at startup, and syntax highlighting..
That’s the only reason I paid $80 bucks for Sublime. I can’t stand electron, *especially* for a text editor of all things.
Don't fear the goto; when the source is strong with you - you can even use mighty macros with goto. Let me introduce to you labeled C++ scope blocks (without compiler warning if you have no goto to label): ///////////////////////////////////////////////////////////////////////////// #define scopeAs(_label) goto _label; _label ///////////////////////////////////////////////////////////////////////////// auto HttpServer::run() -&gt; void { ... TP_CALLBACK_ENVIRON* environment = nullptr; HANDLE overlappedEvent = nullptr; OVERLAPPED overlapped = {}; ULONG result; BOOL ok; scopeAs(initializeOverlappedEvent): { SECURITY_ATTRIBUTES* attributes = nullptr; BOOL manualReset = TRUE; BOOL initialState = TRUE; LPCTSTR name = nullptr; overlappedEvent = CreateEvent(attributes, manualReset, initialState, name); if(!overlappedEvent) { errorAs(CreateEvent); goto exitRun; } overlapped.hEvent = overlappedEvent; } for(;;) { ... overlappedWait: { constexpr DWORD kTimeoutMilliseconds = 10000; constexpr BOOL kAlertable = FALSE; constexpr BOOL kOverlappedResultWait = TRUE; DWORD waitResult = WaitForSingleObjectEx ( overlappedEvent, kTimeoutMilliseconds, kAlertable ); if(waitResult == WAIT_OBJECT_0) { ... } else if(waitResult == WAIT_TIMEOUT) { if(!Task::stop()) { goto overlappedWait; } ... goto exitRun; } else { errorAs(WaitForSingleObjectEx); goto exitRun; } } ... } exitRun: { ... } } /////////////////////////////////////////////////////////////////////////////
&gt;you only need RTTI to find out the dynamic type of an object and once you have that you can use static reflection &gt; &gt;Can you provide an example? You're trolling me, right? What RTTI stands for? &gt;the committee is aware of this problem OK, that's reassuring.
&gt; You're trolling me, right? What RTTI stands for? Huh no. My point is that if we have reflection, the only reason why RTTi to exist is to figure out the dynamic type of an object. Stuff like getting the name of the type can be done using reflection.
You want a new compiler, it will do optimizations from C++17, there is nothing what prevents making guaranteed copy elision in C++11. If you didn't need a single feature from C++14/C++17 and don't know if it's worth to port, then it's not worth. It wont hurt if your codebase would compile with -std=c++17 though, but wait for a year and all your pros and cons regarding C++14 will be true for C++17, as you are well aware that C++20 is coming too.
RTTI works at runtime, if reflection isn't available at runtime then this is not going to work.
What do you mean with reflection not being available?
&gt;what i don't get is why would you want a function that is available only at compile time &gt; &gt;some stuff doesn't make sense to run at runtime, for example reflection stuff since this requires a compiler to get the information. I'm fairly sure you're trolling me.
No, I'm not. What information exist at runtime that static reflection cannot get? Well, only the dynamic type of a pointer/reference. Everything else is know at compile time. You don't need runtime reflection for this. Get the name of a variable? Available at compile time. Get return type of a function? Same. Data members of a class? Same. Where does your runtime reflection fit in here?
If it implies compiler upgrade, new compiler often means new warnings. And if you compile with warning as errors, it means you got stuff to fix. This is coming from someone who has been part of multiple compiler upgrades and going 03 -&gt; 11 -&gt; 14 -&gt; 17 in a large code base the last couple of years.
While I agree it involves extra work, you say that like fixing warnings is a bad thing. Mostly, there’s a good reason that new warnings get added. I compiled a Clang codebase under GCC recently and it picked up a bunch of local variable shadowing that Clang hadn’t, which was useful.
&gt;If It Ain't Broke, Don't Fix It
IMHO `mergeLo()` and `mergeHi()` are a bit hard to follow in general and could use more extensive refactoring. But how about this, as an alternative to the `//outer` loop in `mergeLo()`? (Names could probably be improved if I understood the algorithm better.) int count1 = 0; int count2 = 0; auto inner1 = [&amp;] { do { assert(len1 &gt; 1 &amp;&amp; len2 &gt; 0); if (comp_.lt(*cursor2, *cursor1)) { *(dest++) = GFX_TIMSORT_MOVE(*(cursor2++)); ++count2; count1 = 0; if (--len2 == 0) { return false; } } else { *(dest++) = GFX_TIMSORT_MOVE(*(cursor1++)); ++count1; count2 = 0; if (--len1 == 1) { return false; } } } while ((count1 | count2) &lt; minGallop); return true; }; auto inner2 = [&amp;] { do { assert(len1 &gt; 1 &amp;&amp; len2 &gt; 0); count1 = gallopRight(*cursor2, cursor1, len1, 0); if (count1 != 0) { GFX_TIMSORT_MOVE_BACKWARD(cursor1, cursor1 + count1, dest + count1); dest += count1; cursor1 += count1; len1 -= count1; if (len1 &lt;= 1) { return false; } } *(dest++) = GFX_TIMSORT_MOVE(*(cursor2++)); if (--len2 == 0) { return false; } count2 = gallopLeft(*cursor1, cursor2, len2, 0); if (count2 != 0) { GFX_TIMSORT_MOVE_RANGE(cursor2, cursor2 + count2, dest); dest += count2; cursor2 += count2; len2 -= count2; if (len2 == 0) { return false; } } *(dest++) = GFX_TIMSORT_MOVE(*(cursor1++)); if (--len1 == 1) { return false; } --minGallop; } while ((count1 &gt;= MIN_GALLOP) | (count2 &gt;= MIN_GALLOP)); return true; }; while (inner1() &amp;&amp; inner2()) { count1 = 0; count2 = 0; if (minGallop &lt; 0) { minGallop = 0; } minGallop += 2; }
C++17 is a much longer jump than C++14. It is easier to jump once than twice. The only reason not to go to C++17 is this: &gt; -some compilers / systems don't currently support C++17 [could be very important in my case] Well is it important or not? If you _can't_ go to 17 because something doesn't support it, you really have no question to ask. Otherwise definitely 17.
I've definitely heard him say it live, more than once.
Thanks! I recently tried KDevelop and couldn't get over the ugly color pallettes. I switched to VSCode, which works remarkably well. I'll try this out!
While does look a bit better we're forced to admit that we're creating two capturing lambdas to which we can't give excellent names, so the names just describe that they're part of a bigger algorithm. In the end these functions are merely introduced for the sake of not using `goto` but that's almost the only benefit they provide (apart from making the main loop slightly clearer) :/
I can't speak for him, but I can give you the reasons I've been looking into it as opposed to cmake. The conventions are clearer, so it tends to be easier to follow what someone else wrote. Cmake in contrast doesn't emphasize what you're project needs to look like, so more complex projects can become pretty unreadable unless you as a team decide on good conventions. It supports globing at compile time, Whereas cmake only supports it at project generation time. There are technical reasons for cmakes limitation, but it can cause confusion when team members less experienced in it are trying to add new files to the project. "Hermetic builds" and basing those builds off of file contents rather than time stamps means you never have to rebuild/regenerate/clean. This has actually been a huge issue for my team switching from perforce to git, forcing a full rebuild anytime you switch to a branch with older timestamps in the files (this is specifically an issue with visual studio). Those same hermetic builds make it really easy to create a network build cache shared amongst the team. Also, as you suggested, it supports multiple languages like c, Java, rust, etc. And as far as I can tell you can define your own rules to support what you want (that's how rust was supported last I checked). It's biggest drawbacks for 'us' though is: While it has some vscode support, it's buggy (getting better though). It currently has no direct visual studio support, but it does have xcode support (Tulsi). It's evolving quickly, which means new features (yay) but documentation and tutorials are sparse or contradictory. It's conventions also hinder it sometimes when you actually "need" to do something complex (create a Target that compiled as c on Windows, but objective c on ios, it's possible, but not pretty). It forces you to restructure your project to really take advantage of it, which makes it very "all or nothing". They are relaxing that a bit though (recently added an "include" directories option) All in all: all my personal projects are in bazel now, because I can deal with it's oddities. Professionally I'm making it an option, but I'm waiting till 1.0 before I even talk about making it our "default" build system.
It is based on gtkmm, so definitely won't work or look good or even install in windows.
Yeah, installing it still was not fun. Still had to compile from source and they only support aspell which I also had to compile. But, haven't tested it with a custom toolchain but I might try that out tonight.
I have a company and have faced this also. I switched from 2011 to 2017 C++ a year or so ago. Imo 2011 C++ was both late and immature when it arrived. 2017 C++ is the third attempt to get 2011 C++ right. And the third time is a charm. Your point about some compilers not supporting 2017 C++ is the only downside. In the past I suggested back-porting some (mostly library) features to 2011 C++, (so I wouldn't have to require 2017 C++) but am not sure if that has had much impact. Maybe being more patient would have been a good idea, but I'm happy with my decision so far.
Yeah, it looks like there's some sort of primitive plugin support and it works on a basic level for other languages, but nothing advanced and no plugins actually written for it. This is the only random repo talking about plugins that I could find: https://github.com/zalox/jucipp-plugins
How is **your** english? Or maybe you don't know what a [debugger](https://docs.microsoft.com/en-us/visualstudio/debugger/debugger-feature-tour?view=vs-2019) is (while being a total jerk about it)?
It's not really a site but rather a linter/static analysis tool for various languages. &gt;under c++, it tells me that a function should have only a single exit Right. That has been considered good practice for a long time across most (all?) c-style programming languages. It's not a hard-and-fast rule but generally a single exit helps in maintainability and readability. Keep in mind, that the rules are broken down by category. So certain rules fall under 'bugs' while others (like this one) may be categorized as a 'code smell'. &gt; Just because there exist such a recommendation somewhere in some guidelines, Right. Recommendations are just that, recommendations. Typically you should have a good reason not to follow best practices of your chosen programming language. &gt; I don't think that is evidence it is generally discouraged. In this case, labeled breaks have always been generally discouraged - for the same reason why gotos are discouraged in other languages - it makes reasoning about execution flow much harder.
He was intentionally making the same mistake as "it's debugger"... **Obviously** a joke, but we're staying on the downvote train now, people!
Well like I said, someone who understands the algorithm better could probably give them better names. 🙂 Ideally they'd be free functions or at least separate member functions that can be independently understood and tested. When a single function stretches to 2.5 screen heights, I'd start wanting to split it up.
There are a lot of people these days who seem to think that OOP is horrible, and act like anyone writing real C++ doesn't use it. Take it with a grain of salt. There's a massive amount of code out there that uses OOP principles in a fundamental way.
Yeah, if sublime was cheaper or it was more polished like vscode i might buy it, but as it stands, vscode is definitely better.. just slower.
The default color pallette isn't too bad, but I had to customize it to make it suit me. I've just updated the post with the customizations I did.
Yeah, it does technically work on Windows, but I'd expect it wouldn't be fun compiling it. I'm curious what it looks like running on there since they don't provide any screenshots of it.
I know how it feels, neither did I for a long time :D
&gt; For this specific case labeled breaks have always been generally discouraged - for the same reason why gotos are discouraged in other languages - it makes reasoning about execution flow much harder. That may very well be (haven't touched java in quite a while) I'm just saying that your link isn't a strong support for that claim.
It's pretty amazing how much C++ is innovating the systems language space when you go digging into its feature set. Just look at things like concepts and async.
It's not that polished, but you can set break points, it shows you the current line, you can view/traverse the backtrace, view the stack, and step into/over/out. Here's some screenshots: \- [Debug menu](https://images2.imgbox.com/a7/6d/ZivMqzOh_o.png) \- [Backtrace](https://images2.imgbox.com/68/c0/IjdANs1u_o.png) \- [Variables](https://images2.imgbox.com/2d/7e/mTcROsVE_o.png)
juCi++ has builtin lsp support. See here for examples on setting this up for python, rust and flow: https://gitlab.com/cppit/jucipp/blob/master/docs/language_servers.md
Tbf, Sublime is very nice and extremely polished, it just has a glacial development pace and very limited functionality compared to the electron based editors.
HoW iS iT''''''s DeBuGgEr?
That and the fact that I can get sublime to work on almost any Linux variant. Vscode is a non starter due to various x windows issues.
Not sure why you're getting downvoted. I've given you an upvote on both of those.
I don't think I said it like it was a bad thing? It's just reality. I'm usually the one pushing the tools team to do the upgrade, and the one trying to compile with the new compiler or the new C++ version and fixing the problems before they are enabled by default.
In the gitlab page it says they support language servers
yep that's the downside..
Well, at the moment it's not a problem, but there's a chance that this can happen..
how about linking to C++11 / C++14 libs from C++17 ?
Good point.
Change involves always more work on the short term (sometimes not so short..). Maybe moving from C++11 to C++14 breaks also less things compared to the long jump to C++17
Trying to get it to print from lowest to highest, any ideas?
Yep, this is something that will happen in the future too.. change is inevitable, but better to know when and what to change though :)
Cheers
Thank you for your feedback. I'm happy you haven't regretted it.
Well you're looping from highest to lowest, to get it print from lowest to highest, you want seconds to start at 0 and increase until it reaches a sensible limit.
It came across a little negatively, but I may have misinterpreted. I’m always upgrading to the bleeding edge too, but I have the benefit of essentially writing software for myself. I can imagine persuading a big team can be hard, kudos to you for the effort.
Is that stuff you only need to compile yourself, or things the user/ customer needs to compile?
Don’t print out seconds and distance. Add them a vector. Then print the vector in reverse.
SDL is simple to use and does exactly what you want.
Either that, or try out SFML (as its more beginner friendly in my opinion.). Compiles for Mac, Linux and Windows, and soon Android with the same code.
It is not exactly my area of expertise, but I suspect as C++17 is more permissive than C++11/14 it shouldn't cause any big hurdles. Of course, I am not an authority on that area or your projects.
if only they took compilation time seriously (templates).
Thank you!!! It works
Is this a C++ lab where you get a grade after? If yes, your fault. If not, r/cpp_questions is the correct subreddit.
Did you see the [*Why do my tests take so long to compile?* section](https://github.com/catchorg/Catch2/blob/master/docs/slow-compiles.md#top)? The one time I used catch I had the same problem with compiles taking way too long but once I added the `tests-main.cpp` file with a `CATCH_CONFIG_MAIN` define, only complete rebuilds take a long time
Catch is always my go-to unit test framework in C++ because I can just drop it in...
Check OpenCV too.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c1ei3o/output_is_backwards/erctw82/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c1endb/understanding_graphics_in_program/erctxjb/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
note that I missed a _not_ in my original. :-( Kinda changes things.
I think you meant to say "Looks like you beat me to it. Everything proceeded as I had foreseen"
Very Juicy !
&gt;Why do you need to know in which file a certain module is located? Only reason I can think of is IDEs &amp;#x200B; Nothing can be done without knowing where a module interface translation unit source file is. Binary module interface files are specific to one compiler, so, libraries are not to be distributed with such binary files, and the consumers need to locate the module interface source file, and all its dependent source files, transitively, and produce BMI files out of those.
The embarrassing part for me is that I've been using it elsewhere, but never clicked to use them in for loops.
If you've written C++ 11 code in a suitably modern style, there's almost no features I would argue that calls for any rewriting when you upgrade from C++ 14 or C++ 17. C++ 98/03 to C++ 11 was a monumental paradigm shift. C++ 11 to C++ 17 just means a few nice new features to use, or more efficient compilation of existing code. There's really nothing "obsolete" about well-written C++ 11 code, even today. For me, this comes from direct experience with my game engine (which has, oddly enough, almost 100K lines of C++ code), started with C++ 11 code. C++ 14 came out shortly after, and changed almost nothing for me. Likewise, C++ 17 came out, and again, nothing substantial changed. The only difference is that I started making use of slightly newer language features in new code, or made use of new std library functionality when they became available, but that's about it. In short, I think you're vastly overestimating the need to rewrite code only a few years old. Heck, in most places I've worked, I've found you're likely to be working with million+ LOC projects with code written a decade or two ago, which no one is \*ever\* going to rewrite.
If you add a `final` to your derived class, it should be very easy for your compiler. It won't be allowed to remove the vtable though, so objects will still be bigger.
How did you set up your toolchain for releasing on Linux, specifically how did you get a reasonably recent compiler while targeting very old glibc versions that Steam requires? I've been using the chroot environments that Steam provides, but they come with ancient clang versions, like 3.6 IIRC.
I would argue going with a design like the time library for quantities is the best. It will convert units automatically for you, and you don't have to care. To also support any unit, multiplications and the like, you'll need a few template parameters (backing type, length, mass, time, ratio to SI). You don't need CRTP, for names you can use typedefs. The only case where you need strong typedefs for things that are identical in dimensionality but are pointers instead of quantities (example: timepoint/duration, index in table vs offset).
You'll have to compile the C++11 and C++14 libs as C++17.
You don't seem to mention all the parallel versions of the algorithms.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/c1i95r/help_understanding_using_arrays_in_classes/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I think the better question is what is the oldest compiler you must support in your company? If that compiler only supports C++14, then you are stuck there. Otherwise, I would suggest you push for C++17 immediately. FWIW, I'm waiting for CentOS 8 to be official before I change my codebase to officially support C++17.
gtest baby
Have you tried vim8? This has everything you need to replace sublime.
Is vim8 a newer version of vim? I use vim all the time, and for a while used it as my main dev environment along with tmux and the “NERDTree” plugin (for a file browser). I like it a lot, but after discovering Sublime I just found myself to be a lot more productive with a standard mouse and keyboard, especially when I have to switch between other programs that require a mouse.
look at [doctest](https://github.com/onqtam/doctest) if you are interested in compile times
Vim8 is the latwst big patch. It has an console, hence recommendation. Also Nerdtree ia pretty bloated have you tried vinegar by Tpope? Anyway, you do you. We just have a huge vim vs sublime war at work. Hence why I had to give the recommendation.
I often find the code resulting from "I should probably try to write this without using the obvious goto" to be harder to read than just using the goto. Particularly because with the goto, at least you know "here be demons" and you quickly suss out what it's about. Via flags &amp;&amp;d in to a for loop syntax or what... pass, thanks.
It's much faster with a single CATCH_CONFIG_MAIN, but it is still much slower than doctest. The syntax is a bit different and the features too, but overall switching was not too much work.
Ok, basic but decent. Looks like it's worth trying out on Linux :)
&gt; If you didn't need a single feature from C++14/C++17 and don't know if it's worth to port, then it's not worth. Considering, that the porting effort can be zero (or at least very close to) depending on the code (there are very, very few breaking changes between c++11 and 14/17), I'm not sure that statement it's actually true.
Yeah, same. I have to admit that I saw it somewhere else before I realised I could use structured bindings this way. I did not came up with this on my own, so don't feel bad.
It is still really slow to compile though. That being said: I believe they do take them serious, it just isn't the primary focus.
That's what I've been waiting for. Next hobby/demo project I'm giving Mason a try.
xtensor is regularly tested on the following platform / OS (in our CI): \- Linux, gcc 4.9 up to gcc 8 (and probably gcc9), clang 3.6 up to clang 7 \- OSX \- Windows (VS2015 and VS2017, clang-cl) &amp;#x200B; On which platform / compiler did you fail to compile xtensor?
To be fair, most test frameworks are quite easy to setup.
Why should I prefer your class over a simple `scoped_lock`? // std mutex mtx; void f() { scoped_lock lock(mtx); // work } I'm asking this because I don't see the advantages 🤔 Thanks for answering 😊
Great idea!
I see ... BitBucket is cancer as always.
The conference badges mentioned in the conclusion do feel like a nice and simple to implement idea :)
Because it's easy to forget to lock a mutex and there is nothing to tell you that you did. With my class, you have to use one of the methods with an access mode (one of the access tags in saccess::tag::) before you can work with the data, of course so long as you don't leak a pointer to the data outside. It will force you to always lock and to think about what kind of access you need.
Why do you think it's cancer?
This looks pretty cool! Can it also measure the time and make a test fail if the benchmarked time deviates too much from a given value? For example I have an operation that takes around 500ms, and I'd like a test to fail if the measured value is &lt;400ms or &gt;600ms. Or is there a possibility to log those values to somewhere? Then you could later generate a report and see how the runtime of the function changed over time on a particular system! That would be awesome. (I wonder how that could be made work - perhaps with CTest Dashboard or something like that?)
It's excessively slow, and does not work on mobile at all.
Cool idea! I wish i had thought of this ! Thanks again buddy!
&gt; Because it's easy to forget to lock a mutex and there is nothing to tell you that you did. Did you understand what `scoped_lock` does?
I think you don't understand what I'm saying. In your example, it would still compile if you remove the \`scoped\_lock\` line. The compiler doesn't know that a mutex must be locked before accessing your data. With my class, you can't access the data without locking first.
What are you babbling on about?
Hi, plugin support is still in development. I plan to release api + docs as soon as I get more spare time to work on it. ~Q42019.
Ok now I understand your point of view, thanks for the clarification. I will check your class later to understand it better.
Hi, we have windows support through msys2. See https://gitlab.com/cppit/jucipp/blob/master/docs/install.md#windows-with-msys2-httpsmsys2githubio We do not have maintainers on windows so help is appreciated on better windows support.
Support is based on the libclang version. Look here to see what should be supported: https://clang.llvm.org/cxx_status.html
For the first, there is not. As to the second, you can get whatever test output you want via custom reporter, but the default (console) reporter is aimed at human-readable tabular text, and the XML reporter outputs machine-oriented XML.
I'm pretty sure OP means not just flipping compiler switch, but actual porting from one language dialect to another. You can have C++98 codebase that compiles with -std=c++17 but this doesn't make it C++17.
\&gt; **This release replaces the old benchmarking support with a new one, based on donated Nonius code** . &amp;#x200B; That is awesome! Nonius has been my preferred benchmarking framework for the past two years, even in it's unmaintained state, even without CMake support. It's really a great product and I'm glad to see some portion of it see new life in a high quality library like Catch!
Why would I use meson instead of CMake?
Teaching dipshits like you the meaning of "babbling on" cuz it sure as fuck isn't a single sentence.
This is hands down the best explanation of std::enable\_if I've ever seen.
Engineers make some of the worst programmers out there. My main gripe is they don't actually engineer their code. I have rarely seen an engineer, plan, execute, and then test their code. They tend to just sit down and "solve" the problem.
Can we stop with the self promotional spamming of nonsense puzzles with nonsense titles. There are plenty of real problems to solve out there.
You can flip a switch and now start to use c++17 features in the new code and during refactoring though. Especially from c++11 to 14 or 17, there is rarely a good reason to rewrite perfectly good, working code just for the fun of it anyway (you can get rid of some dependencies if that is important for you).
If you watch a bit of the video, you realise he is talking about software engineers vs "programmers". As in an software engineer builds and optimises a software system and his idea of a "programmer" is somebody who hacks out code
There's a TBB open source community that works on patches for some non commercial systems that you could look into
Are you talking about software engineers or e.g. mechanics/electrical engineers? The message of the talk was not that chemical engineers are better at writing software, but that software development is an engineering problem and not just about writing code.
&gt; iterate over a 2D matrix and try to find the first row that contains the number 'a' before any 'b' is encountered That sounds like a find_if with a predicate on the row. Which is just one way to refactor it into simpler parts.
That's really just the difference between a good programmer and a bad programmer. Or, it could be the difference between a good programmer in an ideal situation and a good programmer is a very non-ideal situation. I mean, let's not be hypocrites. Most of the software we currently use wouldn't exist if its creation had been held to space agency levels of engineering scrutiny and up front analysis. Nor would many of the jobs we've had existed if that were the case, because not many companies would pay us to spend a 6 to 12 months analyzing the sub-system we are about to create before we started writing it. And I don't think it would even make sense to do so. The software industry moves so fast that the odds of anyone taking two back to back jobs where they build the same type of large'ish software with the same tools and techniques is probably pretty low, if not almost non-existent. The language they used 5 or 8 years ago when they started such a large project might not even be used by the time they do the next one. Engineering really sort of assumes that you are applying well understood tools and techniques to solve the problem, and hence you can understand it well before you even start by application of those ideas on paper. When that's not the case, in scenarios like Apollo or HST, then they don't necessarily do any better than we do in the software slums. And that's after enormous amounts of money has been spent, amounts that no non-government type gig is going to provide for.
The points I got from the talk are: * Other engineers (mechanical, electrical, chemical, etc...) focus on delivering business value instead of "beautiful process/machines" * Other engineers share their knowledge and software engineers don't? * Automation good * Ideologies are bad (I hate the negative cognition this word, technically, everything is an ideology) I understand that the current state of software engineering is not ideal, that needs to be more 'engineering', but software engineering is completely different to any other engineering fields, it lacks one of the most important things of other fields that is 'a fixed requirement' and that's why I can't take anything of value from this talk. Please, don't misunderstand me, I'm not trying to say that business value is not important, it is, and should be the most important thing in engineering, but in other fields is well defined that you can't increase business value at expense of security/performance/regulations/maintenance/design constrains.
In my jurisdiction, by law, an engineer is someone whose job involves the design and development of critical systems whose failure can result in loss of life. Their profession is held to a very high legal standard and they can face consequences. A software engineer works on medical devices, software to control nuclear power plants, airplane software, etc... Someone whose job is to build and optimize general software systems is a programmer. That's what I am and I see no shame in that or the need to inflate my title. I also hire mostly programmers and have a great demand for programmers finding it very difficult to find ones who are competent. If someone wants to be an engineer that's perfectly fine and they can pursue that path but it is a very different path to the one that most programmers pursue.
All of them were bad? There are like 8 themes by default in Ubuntu's repository version.
I can sympathize with this complaint, but sometimes that is all that is needed. It is very easy to over-engineer a solution, loose sight of the original problem and never solve that problem because you are too busy building tests for some insignificant part of the code. &amp;#x200B; Some projects need ball-peen hammers, others need sledgehammer.
Does anyone else take slight offense at all the comments regarding alcohol at the beginning? I do drink and don't have any issues with it, but the presenter's comments (and the focus on the alcohol in general) just come across quite weird for me.
&gt;A software engineer works on medical devices, software to control nuclear power plants, **airplane** **software**, etc... &gt;Engineer is not just a noun you slap on to your title to make yourself feel superior to lowly "coders". I'm sorry for using this as an example, you know what I'm talking about, and explains why the word engineer is used to feel superior to others 'lowly coders'. &gt;Their profession is held to a very high legal standard, requires accreditation, and can face consequences for failure. Those accreditation, focused on the engineer, the human part of the system... I'm against certifying an engineer (don't confuse with a minimum academic degree), they can fail. It should focus on accreditation of the designs, process and the product (like is actually done) for the use that it claims to do and must have all the "evidence" to back up its claims.
I have always considered "software engineer" to simply be a more professional sounding title than "programmer"... they mean the same thing, the former is just HR-speak for the latter. I just don't buy that there is the kind of large, meaningful distinction between the two terms that this talk suggests. We just want to call ourselves engineers, that's all.
Because that wouldn't move it if it wasn't a p-rvalue?
Ah that's really cool regarding the reporters! I'd love to see the first thing :-) If I recall correctly, OpenCV has something like that in their tests.
The biggest difference (in my opinion, but I'm biased as I'm the lead developer) is usability. Meson build definitions are easier to read and understand, shorter and overall nicer. There is also many features out of the box that CMake does not provide, such as - Precompiled headers - Unity builds - Warning and optimization levels (no more adding `-Wall` manually in every project) - Sandboxed subprojects And so on.
&gt; It seems analogous to the `auto&amp;&amp;` that we'd find in range-for. No, not really. `auto&amp;&amp;` binds either an rvalue or lvalue reference – it's always a reference, never a value. However when you capture by value, you of course need a _value_. It's more analogous to using `auto` with a range created from a pair of [`std::move_iterator`](https://en.cppreference.com/w/cpp/iterator/move_iterator)s.
[HPX](https://github.com/STEllAR-GROUP/hpx)
You hit the nail in the head.
Eli's blog is one of the best technical blogs I've read in general
I said analogy, not equivalence. One uses \`auto&amp;&amp;\` when they intend to move the iterated arguments, which is the extent of my analogy. I think another way to put it: while \`\[value\]\` copies a value \`\[&amp;&amp;value\]\` moves a value. If the lambda function body intends to move the captured value, it first has to be moved at the capture site, and this might be something that the C++ committee considered to reduce verbosity.
Not being versed the new value category terminology, I don't know. I would claim that `[&amp;&amp;value]` allows anything that `[value{std::move(value)}` allows.
&gt; One uses `auto&amp;&amp;` in range-for when they intend to move the iterated arguments, which is the extent of my analogy. No, they absolutely do not. Using a forwarding reference does not in any way move anything, ever, in any context. It's just a reference. You need to clear the hurdle of understanding _this_ to see why your analogy doesn't work. ;-]
Cool your jets. I didn't say that \`auto&amp;&amp;\` moves nor did I say it was not a forwarding reference.
Not sure why you're downvoted; this is a pretty innovative approach to shared access
I am a long time CMake user, generally happy with it, and still use it extensively at work. However, I tried Meson and prefer it. From a high level view, Meson is quite similar to CMake and is very easy to pick up for a CMake user. The difference is in some rather significant details. Some of the things that sway me towards Meson are: * Python-like syntax with python-like lists and maps are much better than CMake's strings with ";"'s pretending to be lists and having to DIY when you need a map. * Dependency objects are separate object types from build targets. This separation eliminates the need for CMake's convoluted distinction between library types and library property types such as `IMPORTED`, `INTERFACE`, `PUBLIC`, `PRIVATE`, `OBJECT`, `ALIAS`, etc. * Files and paths (including `include` paths) are objects instead of just strings. These objects can be used from any directory in the build without further manipulation even when only declared with a relative path, because the object keeps track of the base path it was declared from. This obviates the need for a large amount of path manipulation code which I always have in complex CMake build systems. * Dependency finding: Method of finding dependencies is abstracted, and will try several methods including `Config.cmake` modules and `pkg-config` files, as well as built-in support for finding some common libraries. Meson also helps with generation of simple `pkg-config` files for exporting dependency information instead of CMake's massively over-complicated `Config.cmake` system. * Meson projects can generally be built as sub-projects without doing anything special. This makes composing components that build with Meson very easy. * Build options are defined in a separate file that simply lists the options with the default values, making them much more discoverable and self-documenting. * Meson forbids in-source builds, which prevents people from trying to compile my code in a way that I didn't test.
Good suggestion eheh
well, sometimes when you re-write code it's more time consuming than you think.. behaviour sometimes changes and it's not so easy to find the reason
ahah I think so :D
that's true
at the moment just myself.. but who knows in the future
I don't know about you guys, but to me, SFINAE is one of the **darkest** corners of the whole C++ programming language. I probably had a few dead neurons after trying to wrap my head around it. Articles that teach and simplify the concept, like Eli's, are warmly welcomed.
Not sure why the compiler could not just flag where an address of a function is requested, and avoid COMDAT fold on just those. A variation of this presumably already exists for having to create physical separate copies of inline functions when their address is gotten.
&gt; C++ 98/03 to C++ 11 was a monumental paradigm shift. C++ 11 to C++ 17 just means a few nice new features to use, or more efficient compilation of existing code. There's really nothing "obsolete" about well-written C++ 11 code, even today. Excellent point.
"I would argue that aesthetics are a minor factor in software engineering" I'm vividly against that... if you write code that's going to exist for 10+ years, there's a high chance a lot of people will end up needing to read it. Formatting is important, imagine reading a book that completely ignores standard paragraphs etc. Also the programmer "repainting" a bit of the plumbing might save large costs in the future, when you're now required to add yet another pipe on there but there has also been five other pipes added on through the years, all with chipped paint and rusty steel, meaning you now have to replace all of them and each new pipe costs the client 3 more hours than it should, therefore pissing off the client
I thought it was funny that his example of other engineering not caring about aesthetics was a group of well layed out and aesthetically pleasing pipes with a small chip. I would bet an engineering plant would repaint a chip pretty fast to prevent further rust issues and larger costs down the road.
Were the talks recorded?
Yeh. Other conferences should do it.