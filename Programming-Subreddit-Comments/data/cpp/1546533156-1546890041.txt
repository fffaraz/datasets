Hi! I'm a 23 years old C++ developer living in the Netherlands (Ukrainian born). My main skills include C++(11/14+) and Qt/QML, and I have a basic knowledge of Java, Python, SQL, Git, Jenkins and Perforce. I'm looking for interesting and challenging projects that would allow me to grow as a professional and develop new skills. I'm looking for a full-time job and I'm open to relocation. My linkedin profile: https://www.linkedin.com/in/rinatveliahmedov/
Not author but there were so many references to books and articles and communities. It feels like you cherry picked the stuff you didn’t like which doesn’t seem fair to the author. 
Trouble is in my field (medical image computing), there are a tonne of libraries and inertia towards C++, and sadly I don’t have time to write everything I need from scratch ☹️
It's not, it's fucking terrifying.
But on your blog C++ was faster to compile and run than Rust except in one case?
This is really cool! It's the first time I've seen structured bindings exploited like this. My main concern would be the compile time, especially in relation to structs with many members. Do you have any data on that?
How can you do your job well if you don't have a curiousity and interest to learn about the tools you use?
At the end of the day it's just `copy_if` with one argument less and the unary function negated. E.g. ``` std::vector&lt;int64_t&gt; v(10); std::iota(v.begin(), v.end(), 1); auto it = std::remove_if(v.begin(), v.end(), [](int64_t x){ return x % 2 == 0; }); auto it = std::copy_if(v.begin(), v.end(), v.begin(), [](int64_t x){ return x % 2 != 0; }); ```
Did you use a framework for that?
Seems really good, wish I had it (and C++17) when we started developing Grand Mountain Adventure.
But except if you have a cpp where you define more then one namespace, how does this make a difference? Nothing is going to include my cpp files anytime soon, so I just do not know the use case where this would matter.
Exactly, so remove_if does remove things from the container in the sense that the removed items are replaced with items copied (or probably moved) from the end. 
Most of boost is header only and platform agnostic so it's a non-issue. System level stuff like filesystem, or asio, are different, but that's not what we're talking about here.
Well... you're right! I didn't see those! I stopped after I read "join twitter and discord" (LOL) I have updated my reply.
Assumption is the mother of all fuckups. RTFM instead of "expecting". 
&gt; I've never heard of this guy Not knowing the history of Sean Parent should not be something to be proud of, but an embarrassment. Just kidding! :-) 
Heh. Don’t succumb to reddit syndrome!
Not all the time. If you have the time take a look at the BetterC mode of D and the entire nogc thing that they've got going. They are not done getting the GC into optional mode, but things are better than before.
WOA! You even get your char string out of global code space!
Except that it does not remove (in your sense of the word) whenever the unary predicate is true
"Testing" somebodies reaction of being exposed to such behavior just sounds to me like one of this "social experiment" videos on Youtube. Meaning it just is an excuse for being an asshole on purpose!
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/abuqxn/ask_hn_scolded_on_a_job_interview_for_not/ed5scp2/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
"Almost 40 Years Of Memory Unsafety Yet We're Still Here and 99 Other Reasons Why Rust Will Fail in 2019"
*Part of* doing your job well is to keep learning, and keeping your knowledge up to date. At least that's commonly understood in professions such as engineering, science and medicine. The author is saying nothing more, and nothing less. That this is at all controversial is, itself, an indictment of our profession.
&gt; So I will write, and rewrite code often for a couple of weeks before I even attempt to compile it. Oh, the horrroorrr of compile time errors :D
&gt; what to do The standard advice - always fully qualify, in headers. 
Yeah it's pretty crazy that people are arguing against it. People who have no curiosity to keep learning is the people you learn to avoid working with.
Correct me if I'm wrong, but doesn't the rvalue overload have the side-effect of moving the `m_str` value out of the `foo` instance, thereby mutating `bar` and leaving `m_str` empty? While I can see that as being a potentially useful thing in certain circumstances, having the getter modify the object seems somewhat counter-intuitive. What situations would call for this? And would a differently-named method be more appropriate?
True, but I still can't think of a better name that's not overly long. 
You can understand why I don't believe statements like "it is platform agnostic" when dealing with weird compilers like whatever it is old Nintendos had?
It's not a wasted effort if that's what you want to do. I'm not trying to implement the STL, I'm creating my own entire world, that goes far beyond the STL. It's much closer to Qt than the STL. And I need high portability for all of that code that goes way beyond the STL, and down a lot lower than it as well, providing a virtual kernel on which everything else is based and build tools and loadable resource stuff, etc... All OS and language headers are limited to that virtual kernel, so everything else is in terms of my own interfaces. I couldn't cleanly implement that in a completely consistent way using the STL. So, even if I liked it, I wouldn't have wanted to use it in this case. &amp;#x200B;
Where's my Nobel Peace Prize?
But, in a really large code base, compile time type safety is a massive concern. That sort of scheme, though plenty of us have done it here and there, if used widely in the code base, runs counter to that imperative. &amp;#x200B;
Codewarrior. I assure you, it works with codewarrior. Honestly, I've had far more trouble porting internal code than I've ever had with boost. And even when I have hit the occasional issue, it's open source so I can just fix it. Though, in some cases that's non trivial because the code is indeed complicated, but the community is vibrant and helpful. 
**Company:** [Stevens Capital Management LP](https://grnh.se/f330a6f81) **Type:** [Full time] **Description:** Stevens Capital Management LP (“SCM”) is a registered investment adviser that manages a multi-billion dollar hedge fund that has been in business for 30 years. SCM specializes in the rigorous development and disciplined implementation of empirically based quantitative trading strategies. Our highly productive team works in a fast-paced collegial environment, utilizing extensive data sets, technology and the scientific method to devise and employ trading strategies throughout the world’s most liquid financial markets. We’re looking for exceptional **C++ Developers**. Primary Responsibilities: * Develop new software and enhance existing systems in C++ on a linux platform. * Create tools to process, store and analyze quote, order and financial data. * Work closely with our quantitative research analysts, engineers and other groups to provide software solutions. **Location:** [Philadelphia, PA. USA] **Remote:** [No] **Visa Sponsorship:** [Yes] **Technologies:** [C++, Linux] **Contact:** (https://grnh.se/f330a6f81) 
&gt; If you start with the STL, you have building blocks of formally verified algorithms. has a C++&gt;=11 standard library implementation ever been formally verified ? 
I don't even write the code anymore. I just think about it until I feel it. When I get that feeling, I know I'm there and everything else is just busy work and unworthy of my time. When the people who paid me for the work see that look of perfect understanding on my face, they know that they got their money's worth. They know that I created the perfect solution for them, one not mired in the ugliness of implementation and incarnation, which will never be subject to the violence of delivery, and the fickle affections of users. &amp;#x200B;
Which implementations of the STL are formally verified?
Man, that is so hurtful. I bet you wouldn't say that to their faces.
This has nothing to do with how "strict" your type system is. You can add checked templates to C++. There have been many iterations; they haven't been added because they cost too much at compile time. Checked templates enforce all operations on all template types are supported by the concepts that each type is restricted by. In and C++, *not every type supports variables being copied*. This is *absolutely** *nothing* to do with how strict the type system is. C++ with fully strict types still has types whose values cannot be copied (or moved). In Haskell, where values can all be copied, id is the only T-&gt;T function. In C++, **there is no T-&gt;T function** (that works on all types; alternatively, that checked variants of C++ accept). 
**Company:** [Stevens Capital Management LP](https://grnh.se/f330a6f81) **Type:** Full time **Description:** Stevens Capital Management LP (“SCM”) is a registered investment adviser that manages a multi-billion dollar hedge fund that has been in business for 30 years. SCM specializes in the rigorous development and disciplined implementation of empirically based quantitative trading strategies. Our highly productive team works in a fast-paced collegial environment, utilizing extensive data sets, technology and the scientific method to devise and employ trading strategies throughout the world’s most liquid financial markets. We’re looking for exceptional C++ Developers. Primary Responsibilities: * Develop new software and enhance existing systems in C++ on a linux platform. * Create tools to process, store and analyze quote, order and financial data. * Work closely with our quantitative research analysts, engineers and other groups to provide software solutions. **Location:** Philadelphia, PA. USA **Remote:** No **Visa Sponsorship:** Yes **Technologies:** C++, Linux **Contact:** (https://grnh.se/f330a6f81) 
It's not the message itself, but the lens through which we perceive it. For example, given the context and the tone of the rest of the post, I took it as supporting the mentality that every developer needs to have a github with side projects, in place of taking a weekend with the kids to go camping. There's a mentality that you can't just get the job done and be good at it, but you have to be \*passionate\* about it and have your life encompassed by it. 
The whole library? Not likely. The sequential algorithms bit in &lt;algorithm&gt; maybe, but I don't know for certain. Move semantics add wrinkles since moves have side effects. 
They should return `std::move(*this)` as a value in `&amp;&amp;` overloads.
"These people" aren't being anti-intellectual, and I never claim as much. This is only regarding the comment in question: &gt; C++ way of creating lambdas, and the choice of C++ standard to make things look clever (“what’s an iota? it’s a Greek letter, look how smart I am!“) are both a bit cumbersome. It's not just a criticism of the name, which would have been perfectly acceptable, and something I would agree to. The issue is that _it's a personal attack on the people behind it_. It could be construed as very "anti-intellectual." At the very least it's ignorant and insulting.
Isn't it obvious that `using` introduces potential collisions? People do it anyway because they don't want to type or read huge scopes everywhere. There are some caveats around `using` but saying "never" is extreme.
There's a difference between saying "you should be open to learning new things" and "you should be embarrassed for not already knowing this particular thing". The latter heads straight into No True Scotsman, with "a real programmer would know X".
I'm on the committee, I still don't know/remember what iota does. It is a terrible name and I shouldn't have to remember it.
I mean do I have to download anything to make it work as CMake only depends on a C++ compiler to work.
But then you're left in the situation where you're dulyl qualifying apache::thrift::transport::TTransport and websocketpp::config::asio\_client::message\_type::ptr In headers - which is totally gruelling 
&gt; Correct me if I'm wrong, but doesn't the rvalue overload have the side-effect of moving the m_str value out of the foo instance, thereby mutating bar and leaving m_str empty? Exactly! &gt; While I can see that as being a potentially useful thing in certain circumstances, having the getter modify the object seems somewhat counter-intuitive. What situations would call for this? There is exactly one case where this is a sensible thing to do: If the object that we are stealing from is never needed again. In other words: If it is an rvalue, which is precisely the case whenever this overload will be used. &gt; And would a differently-named method be more appropriate? Since a differently called method should preferably only be callable from rvalues as well, there wouldn't be much of an advantage to adding it (though I'm not saying that it is never useful). OTOH this is a big optimization for getters on rvalues that doesn't hurt, so there is no point in splitting it into two methods.
overwrite_if ? Doesn't say what it does, but at least offers a hint.
Sometimes, rather irrelevant things are upheld as good practice. The meaning of "good practice" is somewhat subjective, as there are sometimes contradictory goals to be attained. I think everyone ought to consider that before taking a dump on a stranger's code.
If that's so confidence boosting, you probably don't use a reasonably advanced IDE. But if you develop C++ code in notepad, you have me serious problems than just conference.
fwiw I found the documentation for Sol 2 to be fine. Had no problems. Thanks again for all your hard work.
So, the magic is contained in `arity.h`^1 and `to_tuple.hpp`^1 . The "reflection" trick only work with `struct`/`class` which can: - be built with the aggregate syntax: `my_struct obj{ 1, { 2, 3 } }`, which I believe precludes both protected/private fields and constructors. - be decomposed into structured bindings: `auto [x, y] = obj;`, which I believe precludes both protected/private fields. Otherwise, serialize/deserialize will have to be written manually; which I guess is fair enough. The library does not appear to help with: - Versioning of serialization format. - Offline viewing of serialized data: the binary data is only decodable if the schema is known. Those are relatively common limitations, and also seem fair given the performance goal, though the lack of versioning coupled with "automatic" serialization of `struct` can easily come back to bite you; a default "version" (single-byte 0) added before each `struct` would make it easier to evolve the schema. ^1 *Please prefer "namespacing" macros with your project name, even if not public, and also please `#undef` the macros after use if you do not intend for them to be available to others.* ^2 *May I encourage some regularity in the extension used? Picking either `.h` or `.hpp`?*
To me, claiming that you write code for weeks without even trying to compile it sounds cocky. I took the "lol who compiles" as a jab along those lines. Seriously, this isn't the 1950s where compiling your code requires scarce and valuable resources. My personal experience has been that people who don't submit code (let alone compile) for weeks are struggling seriously and often worked on projects that ended in complete failure. YMMV.
r/cpp_question is probably a better sub for you.
https://github.com/CaseyCarter/cmcstl2 
Well, that's one of those yes and no things. Clearly it's still relevant in one sense, because the bulk of Windows itself is still probably written in C++. But, in terms of application development on Windows, most of it is probably C# these days, sadly. There are still places where C++ rules, where things like .Net aren't really acceptable, such as really high performance stuff like gaming systems. And it's still used a lot on the back end server side, though probably more in the infrastructure than the actual end business logic these days. As someone who has concentrated on C++ on Windows for a long time, it was sort of the worst case scenario. Windows is still very widely used, and C++ is also used in a lot of places outside of Windows. But C++ on Windows is maybe not dead, but it's definitely checking the papers for a nice condo in Boca Raton. So I have two very useful skills, but not nearly as useful in combination as it once was. &amp;#x200B; But, regardless of what people may think about the above, you don't need to buy any books on APIs anymore. It's all available online. &amp;#x200B;
You'll probably never forget now, though. 
I think much of it is still relevant as Windows 10 is somewhat backwards compatible, but I don't do much Windows development any more. Most of the large third-party sellers use automated pricing bots - a book or CD that is out of print will bounce up and down in price. When I was building my collection of Amiga assembly language books, some of those were also at eye watering prices on Amazon and eBay. I have had success picking up older tech books at car boot sales, in private forums and also in ex-library sales. It is possible that there is a new edition of the book in the works, and as such the publisher isn't doing any further print runs of the current edition - I hope it is! =)
Meh. The argument against it is that it misses (or worse, dodges) the point entirely. The point is that when the new guy looks at your code, he should understand it quickly and easily. And esoteric naming choices work against this. The question of how he should ***feel***, about lacking the specialized knowledge, to easily read your code, is a smoke screen.
&gt;To give more perspective, I worked in places where the `std::vector` replacement assumed types could just be relocated with a `std::memcpy` Is that not what a typical platform-specific `std::vector` implementation does? (With intrinsics).
I'm stuck with c++11 at work, we haven't gotten these toys yet
I might be using the term "formally verified" a little (too) loosely. The definition of STL goes back to the late 70's and is rooted in the axiomatic specification of abstract data types and algorithms. With a restricted subset of C++, the tools are certainly available for a formal verification of implementations. The "restricted subset" of C++ isn't really that restrictive. It's what we commonly assume for value semantics (equality implies substitutability of values, objects represent are independent and not shared). Also, if you read the prelude to the standard library, they explicitly call out "incidental" modification of objects as undefined (e.g., a predicate for find\_if that modifies its objects). That said, "Elements of Programming" (Stepanov, McJones) gives some proofs for STL algorithms. I'm sure that "From Mathematics to Generic Programming" (Stepanov, Rose) also includes proofs (this is on my bookshelf, but I haven't read it yet). I just found "Fundamental Proof Methods in Computer Science" (Arkoudas, Musser), which seems interesting. (Musser worked with Stepanov on the STL for many of years and is the inventor of introsort, which \[I believe\] is the sorting algorithm used by most STL implementations).
&gt;This is really cool! It's the first time I've seen structured bindings exploited like this. Yes, that's the basic trick. Credits go to this blog post which also explains how it works: [http://playfulprogramming.blogspot.com/2016/12/serializing-structs-with-c17-structured.html](http://playfulprogramming.blogspot.com/2016/12/serializing-structs-with-c17-structured.html) &amp;#x200B; Regarding compilation times, I have extended the benchmark repository to measure compile times, too (results are included in the README.md now) [https://github.com/felixguendling/cpp-serialization-benchmark](https://github.com/felixguendling/cpp-serialization-benchmark) (TLDR: capnp 0.440s, fbs 0.857s, cista 1.351s, cereal 1.827s on my laptop) These are of course no structs with many member variables. We have only one real-world project with many member variables (resembling OpenStreetMap data for foot routing for mobility impaired persons) that's using the library. Here, we have only one implementation file (.cpp) that does the serialization. Compilation of this specific file takes about 1.6s/1.7s seconds for clang++/g++ which is acceptable for us.
We recently applied clang-format to the STL's headers, sources, and tests, and the devs who regularly work on it use VSCode's format on save option (configured in the product and test workspaces) to keep it that way. We also have a batch file that recursively applies the clang-format binary to all of the files in question, which allows us to recover from edits made by other devs, or clang-format upgrades/config changes. For static analysis, we're somewhat unusual in that we have a relatively small separately compiled part, and we mostly care about analysis warnings encountered by our programmer-uses. So we run all of our tests with `/analyze` configurations (alongside other MSVC configurations, and more for Clang and EDG). This indeed takes longer, but our tests are now parallelized and distributed, so the cost is minor. We regularly have to deal with new toolsets (not just static analysis) and when new warnings/errors appear, we fix the product/tests where we can, and report bugs and add workarounds otherwise. The main way we mitigate this is by upgrading regularly and not letting the work build up.
&gt; People forget that while Carmack and Acton and others have their opinions and are big names, they are responsible for only a teeny tiny little fraction of the whole games industry. I think Tiger Woods represents only a tiny fraction of the golf industry, but I'd pay closer attention to what he says about his sport than most anyone else.
&gt; I don't have a solution to this because, as was said, the committee members are in there for their own interest. I do: support alternative languages. Rust is looking more attractive all the time and a lot of languages have C ffi's where you can do the performant stuff in plain C but most of your code in a language that doesn't make you want to pull your hair out.
FYI, you triple-posted this in slightly varying forms. I've kept this one (the first) and removed the others.
&gt; "Eric used the name `iota` to be clever and show how smart he is," which is 1) wrong, 2) ignorant, and 3) insulting. I agree that's badly phrased, but it does capture the idea that Eric feels comfortable using that name because he is clever and smart, leaving the rest of us out in the cold. There are other examples. One of my favourites is the set locale method that is actually called `imbue()`. I have no idea what the justification for that was. I just did a quick search, and nothing useful turned up. And really, it doesn't matter if there was a clever or a smart reason. It's a bad name. Another example is `empty()`, which doesn't empty anything. Or `size()`, which is actually a count of items, not how much memory they need (as per `sizeof`), nor an area or volume (as per the size of a box). Many standard C++ seemed designed to add to cognitive load. `iota` is part of a long tradition. &amp;#x200B;
This is again ignoring the context in which the author said that. And the context was that of Aras criticising the choice of name in the ranges library without bothering to research the reasons for this very odd choice of name. And this lack of research (necessary for an informed critique) is, exactly as Sean Parent wrote, cause for embarrassment. Ultimately `iota` *is* a very bad name. But it's not the fault of the author of ranges, who chose it to remain consistent with the algorithms standard library. You might argue that consistency is less important than a good name (and I'd agree in a heartbeat) but *Aras didn't do that*.
I think you’re overthinking this.
It's not uncommon to have a hook in your version control that runs the code formatting. There's two schools of thought on this one: either reformat the file automatically and check that in, or just do a check to see that the format is correct and disallow checkin if it fails. Work with your team to decide which of these two is best for your situation. For static analysis, I've seen this done three ways. The first is to have a "gate" before release where static analysis must be performed. Any new released version must pass static analysis. When you have a new version of the analysis tools then this will reveal additional problems that you need to fix before release. The problem with this method is that a release can be delayed if there are problems. The second way I've seen is to incorporate static analysis into a nightly build process. If there's any problems you'll get a report and you open up a ticket to address them. This stays on top of the problem, and hopefully finds it sooner, and tracks the necessary changes in individual changesets. But it requires more infrastructure to get running (unless you already have a nightly build). The last way is as a requirement before a change can be checked-in to the trunk. It's not automatically checked, but is simply a note on the ticket, maybe by uploading the log from running the static analysis tools. This catches problems very early on, but adds extra overhead to every commit. It also doesn't play well with upgrades, as you noted. The way I've handled that is to open a ticket specifically for fixing new items discovered by the upgrade and giving every other commit a "free pass" until that ticket is closed (which means its also handling any new issues brought up by the commits in the meantime). This can get very messy, depending on the pace of development.
The using directive pulls the names into the closest common "ancestor" namespace. Between `::std` and `::my_namespace`, that is the _global namespace_. [eel.is/c++draft/namespace.udir](http://eel.is/c++draft/namespace.udir) [obligatory godbolt](https://godbolt.org/z/n3Ws5g)
&gt; The problem is that people forget to run them before they commit. This is an editor problem, partly. I have clang-format running on every save operation in some editors and while typing in others. Tools like editorconfig and so-on can also run in editors. Plus you can move these sorts of checks into pre-commit hooks (on git, at least) so folks can get quicker feedback on changes before waiting for CI (which will of course also validate, because commit hooks can be skipped). &gt; Checking formatting takes little time but doing static analysis can take a very long time on our code base. Carefully balance the analysis tools you use with these concerns. There are analyzers like Microsoft's (with the appropriate ruleset) that are so far you barely even notice them being on in every build even in local iteration. Second, remember that CI can run in parallel. You can have static analysis running while also building (on multiple platforms) while also doing other parallelizable work. Hosted CI can charge an arm and a leg for parallel jobs, but a local Jenkins or gitlab-runner setup can do all that for much cheaper. For my hobby work right now, I use a hosted CI system that only allows one job at a time. Paying for more than that would come out to something like $360/year (minimum, and that's for only _two_ jobs; getting the three I'd desire comes out to closer to $700/year). I priced out a small form factor "server" with a huge multi-core Ryzen CPU, 32GB of RAM, and terabytes of storage including SSDs - basically exactly what you'd want for a CI system - and it came out to only $1000, including a Windows Pro license. For a little more than a year's cost of hosted CI, I can get 5x the CI capacity, and more control to optimize the build environments and Docker image caching! In a company, that'd be almost a no-brainer, especially if you have some VM capacity already. &gt; Secondly, handling of new versions of the tools. For example: Lets say that all tests pass on our code base Build environments should be versioned and reproducible. That is, don't just install a new compiler or static analyzer on all your build nodes and expect all current or past code to build. If you're going to upgrade, make a new branch. Upgrade the CI environment for that branch. Version that CI configuration to that branch. Once the branch is building and working with the new CI environment, integrate it into mainline. The only person who should ever have to deal with breakages here is the person doing the upgrade. Plus, by being versioned, that means people working in other branches (that don't have the fixes from master yet) still have working CI, and only have to deal with changes when putting up a PR to integrate to mainline. Docker images work great for this purpose. Jenkins labels for non-containerized build nodes also work. You can even just install many tools in parallel on a single machine and use build scripts to select the appropriate version. There's lots of options to ensure that you can upgrade build environments and fix code in a branch without burdening mainline or unrelated CI jobs.
Never worked at a place that did ANY of that, but I would use the pipeline approach. Each step in the pipeline can take longer than the one before. Build up a system of steps that does quickest, quick, slow, slowest. Last one may have a lot of human intervention steps. You can also make some steps parallel with others. You could run acceptance tests on one system and static analysis on another for example. It's all a matter of how much you want to be able to expand. Now that there are tools like Docker the automation process is greatly reduced... &amp;#x200B; Like I said though...if you do anything at all in this area you'll be miles above any place I've worked.
Thank you for your feedback. I applied your proposed changes ([Link to Commit](https://github.com/felixguendling/cista/commit/f542b45ed1d1cb31acd7c0e84855390fe6615050)) to namespace and `#undef` internal macros. &amp;#x200B; &gt;*May I encourage some regularity in the extension used?* Of course. Thank you, I changed it. The reason was that clang-format thinks that this file is Objective-C with the `.h` extension: [Link to CI build](https://travis-ci.org/felixguendling/cista/jobs/475025802#L696). With `.hpp` it works. But there needs to be better solutions to fix this. I will try something with the "-assume-filename" flag. &amp;#x200B;
&gt; It doesn't actually remove anything from the list Of course it doesn't. You don't give it a list! How could it possibly remove elements from something it doesn't have? It does remove elements from something else though — from something you do give it. What is that thing? The same thing most other `&lt;algorithm&gt;`s work with. 
I have to agree. C++ should concentrate on being C++. It's probably not going to compete with those other languages most likely anyway in their particular areas of application, so adding more and more complexity to try to be like them is just making it even less likely that C++ will be picked up by new programmers coming along. It's a vicious cycle. Fewer new programmers come to it, so add more stuff to it to attract new programmers, which makes it so complex that new programmers are even less likely to come to it, because they may be looking at a good number of years to really master a language that they are worried might be almost totally irrelevant by the time they get there, because fewer programmers are coming to it. Once there's blood in the water, the sharks will come.
If only I could predict the behavior of Doxygen before I compile the doc
Out of curiosity how much did clang-format break things when you first ran that batch file? It's pretty cool you could just take a huge project like that and format it.
I believe Aras was criticizing "general state of C++ lately". The comment on std::iota wasn't about ranges or it's author, but rather about how "the choice of C++ standard to make things look clever" contributed to what he considered the incomprehensibility of the given example. &gt; Ultimately iota is a very bad name. Which I believe is part of the point that Aras was making. And Parent chose to make an argument about the way he delivered it. He decided to own Aras' "look how smart I am" straw man and one-up it with a history lesson - and to returned the favor by attributing a "Real programmers don't need no book learnin'!" sentiment to Aras. And all to make an argument which was ultimately irrelevant to the topic.
In my experience the behavior is much more stable when you don't use the builtin HTML output :D ... and my theme is actively letting you know when it sees some apparent Doxygen issues.
And what's the obsession with time and memory constraints? It seems like everyone of these I've watched is constantly going on about that. Yes, it's important, but it's almost always a tiny amount of the code that is thusly constained and the rest of it requires no more than reasonable optimization. Over optimization makes for more complexity where it's not needed, which is an ongoing burden for ever more. My product is very large, four or six or more servers on some machines, network distributed so ongoing conversations between servers and clients on multiple machines, multiple complex UI clients talking to servres, it's constantly actively talking to ten or twenty or thirty or more devices and off-LAN data feeds, and all that. And it barely tickles the CPU meter of even a modest modern machine. All I ever do is be reasonably careful about optimization, except in a few small places where it has actually proved important in practice. And I avoided a lot of over-optimization that would have cost me up front to do, and then again and again and again over the years as I improved the code. So, it's just one of the last things I'd be going on about if I was interviewing a candidate, unless the job was related to a part of the product where extreme optimization is necessary. If so, I'd probably have made that clear in the job posting to scare away people who aren't really into that subject. &amp;#x200B; I dunno, maybe it's just me.
&gt; When you see cout, you know exactly what cout it is. Right – that's what makes it a terrible example; meanwhile the vast majority of the names in `std` are far less obvious... How about `count`? `floor`? Any of the million names that are in both `std` and `boost`? The _absence_ of `std::` on these names adds to the cognitive load when reading for those people who aren't completely hung up on the awful tediousness of writing a whole extra five characters.
&gt; Of course it doesn't. So you agree remove isn't the best name.
&gt;We recently applied clang-format to the STL's headers, sources, and tests your git blame must be useless now :-)
&gt; It is similar to Polyspace, Astrée or Frama-C (its value analysis). Can you elaborate on the differences?
&gt; This is an editor problem, partly. I have clang-format running on every save operation in some editors and while typing in others. Well, We have been using AStyle ([http://astyle.sourceforge.net/](http://astyle.sourceforge.net/)) for our code formatting. The problem is as I said that people forget to run the formatting tool. I have looked at the possibility for using clang-format instead since it's integrated into Visual Studio (since version 15.7). The problem is that the version that is included in Visual Studio 2017 is something that the user have little control over. The default is clang-format version 6.0.0, but if you install the clang-format extension you will get the 8.0.0 version. Unfortunately, clang-format may change how it formats files from version to version, even if the configuration file is identical. So that could lead to a huge headache if different developers are using different versions. &gt; For my hobby work right now, I use a hosted CI system that only allows one job at a time. Paying for more than that would come out to something like $360/year (minimum, and that's for only *two* jobs; getting the three I'd desire comes out to closer to $700/year). I priced out a small form factor "server" with a huge multi-core Ryzen CPU, 32GB of RAM, and terabytes of storage including SSDs - basically exactly what you'd want for a CI system - and it came out to only $1000, including a Windows Pro license. For a little more than a year's cost of hosted CI, I can get 5x the CI capacity, and more control to optimize the build environments and Docker image caching! In a company, that'd be almost a no-brainer, especially if you have some VM capacity already. The cost of a external CI system is high. But having your own CI server is not free after initial investment, since it requires time for setup as well as maintenance. The per project configuration time is probably why we will chose some form of external CI tool such as TravisCI or AppVeyor.
Just do recursive git-blame. Something like this is not a problem for modern tooling
It required extensive manual work. Outright breaks were rare - there were a couple of cases where header sorting caused problems (e.g. header A wasn't including header B, and source file C included B before A, so sorting A before B caused a compiler error). There was also a clang-format option that outright damaged code, so I avoided customizing that one. More common was clang-format poorly formatting code, which I would group into clang-format bugs/deficiencies (some of which I reported, e.g. aligning consecutive assignments is overall worthwhile but is overly aggressive; also clang-format handles variable templates *extremely horribly*), some of which could be worked around (e.g. by adding trailing commas to nicely format tables, or adding empty comments to preserve wrapping), and some of which required the comments to locally disable formatting (most commonly in tables with intentional whitespace for alignment). At the same time, I did lots of manual work to add braces to all control flow and remove parentheses from return statements.
Your characterization of that comment is what I was replying to because it seems like a big exaggeration to me. I don't believe the comment comes anywhere near being anti-intellectual I already wrote above that I agreed with you that a lot of the commentary on the article (this includes the part of Aras' post you quoted) was rude and unfair. So it's a shame then, unless I've grossly misinterpreted his wording, that Sean Parent has published this post with so many great points only to end it by calling people's lack of PLT history knowledge an embarrassment. Being charitable in debate goes both ways.
I'm used to manually binary searching Team Foundation Version Control (and before that, Source Depot), so having a few commits that are brick walls to git blame is fine. At least we got this done about a year after our git conversion.
&gt; There was also a clang-format option that outright damaged code, so I avoided customizing that one. What would that be?
&gt; It's not uncommon to have a hook in your version control that runs the code formatting. There's two schools of thought on this one: either reformat the file automatically and check that in, or just do a check to see that the format is correct and disallow checkin if it fails. Work with your team to decide which of these two is best for your situation. Regretfully GitHub do not support server side hooks. This means that we have to use client-side hooks and then we are pretty much back to the same problem with users forgetting to setup the correct hook on their development environment. Hence my thought of checking the formatting using a hosted service such as TravisCI or AppVeyor. &gt; The last way is as a requirement before a change can be checked-in to the trunk. It's not automatically checked, but is simply a note on the ticket, maybe by uploading the log from running the static analysis tools. This catches problems very early on, but adds extra overhead to every commit. It also doesn't play well with upgrades, as you noted. The way I've handled that is to open a ticket specifically for fixing new items discovered by the upgrade and giving every other commit a "free pass" until that ticket is closed (which means its also handling any new issues brought up by the commits in the meantime). This can get very messy, depending on the pace of development. Well, this pretty much sums up my worries. :/ &amp;#x200B; &amp;#x200B;
To add onto the "gate" approach. Most CI systems have a manual/approval step available that could be used to allow overriding a failed check in case the thought of a release being blocked in a time-sensitive situation makes you uneasy.
Was that why you were interested in my patch to allow separate formatting of pointers and references from a few years ago?
&gt; Regretfully GitHub do not support server side hooks. If you have any kind of automatic tests (jenkins etc.) running on your commits after pushing, add one that checks if clang-format was applied (it usually produces the same output when run twice). Even better it you work with pull requests, where they allow you to reject the request until the format is right.
Not really, `std::vector` might do it if it can prove it to be safe (usually that means type is trivially-move-constructible and trivially-destructible). The proposed trivially-relocatable attribute tries to help with that. What we had was a type that just assumed this was always the case (regardless of if the type had a non trivial destructor/copy constructor/move constructor).
`move_to_back_if`?
&gt; The problem is as I said that people forget to run the formatting tool If you're using Git, try a pre-commit hook. You can also hook up formatters like Astyle to on-save actions in many editors, even if they lack an official integration. &gt; But having your own CI server is not free after initial investment, since it requires time for setup as well as maintenance No _free_, no, but the ratio works out pretty well. Keeping a machine with Docker and gitlab-runner up and maintained is not particularly time-consuming, and maintaining the Docker images is already most of the time cost of keeping CI running - and that is cost I already incur even on cloud CI providers. I feel better about dropping Docker images with custom CI, too. e.g., with Travis or Azure or whatever, most of the software I need is horrendously out of date (e.g., ancient Clang versions) or key SDKs are missing (Vulkan SDK, DirectX SDK, etc.) so the CI time is 30 minutes of installing deps and then 2 minutes of actually verifying, building, and testing my code. Hence the Docker images. With personal non-containerized CI nodes, I can just make VM images that have all the tools I need preinstalled and let them run builds without messing with Docker shenanigans. (though i probably still will). iOS/Mac is the big sticker against Docker in any case though... it's also the biggest offender in "nothing I need is installed" on the cloud CI providers that offer Mac builders. :)
This is what I always do with projects. CI system runs the code formatter and compares the diff, the build fails if there are any changes between formatted or not.
Pedant note: _trivially-copyable_ is the relevant criterion.
Did you benchmark it against `bytell_hash_map`? https://probablydance.com/2018/05/28/a-new-fast-hash-table-in-response-to-googles-new-fast-hash-table/
I do security research and part of that is game hacking (with permission ofc via bug bounty programs). For example attempting to bypass battle eye for which requires the use of kernel drivers to avoid anti cheat detection. Such things can not be done in C#. This is the field of research I study. I agree with you though. For regular development C# is a solid language and I can't fault the .NET framework. I was more interested to know if the content in this book is still applicable to Windows 10.
&gt;Amiga assembly language books Now you're making me feel old. I have some of these in my mothers attic. And some C64 Assembler books.
We use clang-format, and we run it in a pre-commit git hook to make sure - if there's a change due to clang-format, the git hook changes the files but also fails the commit, so the user has to `git commit` again with the new changes but can actually see the changes too. We strongly recommend to our developers that they run clang-format in their favorite editors on file save, so that the `git commit` step doesn't catch/need any changes - but we don't simply trust them to do so, because someone *will* screw it up. We also run clang-format on the git server side (on Bitbucket) and reject pushes that don't pass... but since you said you can't do that, then I'd add a clang-format check in the CI as an early test step that must be passed. For static analysis testing, we run them on the CI (we use Jenkins, fwiw). Pull requests have to pass all the tests to get merged in, so developers can't "forget" to format properly or run static analysis. But we also spent some time writing some script tools so that we only build and test stuff in CI that actually changed in the pull requests - not *everything* in the code base every time for every pull request.
This. \^\^ I wish this guy's post had -99 points, not +, but it seems there's a lot of people around who like a dishonest twisting around of Parent's words.
Oh, "Windows via C++" is the title of the book. Sorry. 
void counterfeit(const Ming vase) // BAD STYLE! &amp;#x200B; When you're passing an object I certainly agree, but when passing an integer, enum, bool, float, double etc. (something that can be passed on a register) there may be arguable advantages to passing const-by-value. As you say yourself, to the outside world of course it makes no difference whatsoever, but it does guarantee that you literally cannot change the parameter within the called method. If you've taken in something you should expect to be immutable (say, a unique integer index, with which you'll be looking up a value in some shared map) it's very useful to know that it *is* immutable. It's only too easy to accidentally increment it. Sure, you could find this bug with sufficient testing and debugging, but one can say that about almost any programming error; why not let the compiler catch it right at the outset? &amp;#x200B; Of course, at the point that you're passing anything heavier than the size of a pointer I'd ignore what I'm saying and pass by const reference. But certainly at least where I work we're habitually passing ints, enums and doubles by const value if they're genuinely not to be modified, simply to have the compiler catch trivial errors for us.
We use Jenkins with tons of different jobs. One job is https://danger.systems/ruby/ with which you can very easily add very useful custom steps. I also wrote a little article on how we integrated clang-tidy into our Jenkins here: https://pspdfkit.com/blog/2018/using-clang-tidy-and-integrating-it-in-jenkins/
Yep! I'm still interested in getting clang-format to emit `T&amp; r` and `T * p`.
You can make the public declaration use a non-const parameter, but the cpp definition use a const parameter, for by-value parameters. In this case, const is an implementation detail rather than something that the user of the interface needs to care about.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/acbsx9/best_cpp_ide_for_a_beginner/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It was `AlignConsecutiveDeclarations`. I was a bad kitty and didn't file a bug report.
Sigh. Please do read the entire comment.
&gt; AlignConsecutiveDeclarations Yeah I find a lot of the Align* stuff is generally broken or overzealous in some respect.
Actually yes, that's a very good point and that is what we do - we use abstract base classes by default and always include only that unless we explicitly require the implementation, and the abstract base classes take int, double, etc. The implementations then declare them as const int, const double etc. but practically nothing in the codebase ever sees that unless it's had to visit on them. (Even then we could, as you note, declare them as non-const in the header, but we declare them as const simply for consistency between header and cpp.)
'sql' macro with stringizing operator # already do right thing to my use, example trim white spaces and also let do comments with SQL-strings. I once checked how to use raw strings, but stringizing operator # is still better to me. Operator '\_sql' is useful with only very short SQL-strings. Usually I use it only test cases, but 'sql'/'\_sql' is like keyword pair to me. &amp;#x200B; (Maybe someone start to think keyword pair like 'glsl'/'\_qlsl'.) &amp;#x200B; Usually I don't format SQL-strings, because I use prepared clauses with parameters and conditions like 'case when X then Y else Z end' or 'and (:Param is null or column = :Param)'. If I must format SQL-string then I format string and call function 'procedureOf(Text const&amp;)-&gt;procedure'. &amp;#x200B; Below is example with my C++ variations for C# and Python examples - I found those examples from some SQL Server pages. So I show my code for comparison (actually I removed original C# and Python code because too big post). Maybe my C++/LINSQL library is never good enough for general/public use, but to me C++ is the best database programming language. I also did before much Oracle PL/SQL coding and I think it is very good database programming language, but actually I did change one of my production database from Oracle to SQL Server and of course no more any old PL/SQL code but not also any new T-SQL code. &amp;#x200B; Example uses C++/LINSQL vocabulary like second class keyword like things: 'sql'/'\_sql' (script), 'procedure' (inline sql-procedure), 'universal' (tuple/row like 'static dynamic variable'), 'universals' (set of universal), 'nil' (empty universal) and 'nils' (set of empty universal). SQL syntax of 'insert into' is good for some use cases but usually too horrible when you want update one row, so C++/LINSQL support own 'insert set' syntax. Example use also lot infoAs-macro, so it seems that I have some serious problems with double-quote characters. &amp;#x200B; Class 'procedure' uses 'operator()(universal&amp; params)-&gt;int' for datum updates and also for single row selects. 'operator\[\](universal const&amp; params)-&gt;universals' is for result set of database query. &amp;#x200B; I know this comment reply is not right place try to explains my ideas how handle databases with C++, but I don't have any right place anyway, so if someone got some ideas and can do a better C++ data handling library for relational databases (without any external code generators or ORM-tools - 'universal' is opposites for fixed data interfaces - or not to try hide plain SQL - if you use relational database you really need SQL, but you should not stop to use C++, if you like C++ or you like your own variation like C++/LINSQL), then I can be glad that I did this. &amp;#x200B; ///////////////////////////////////////////////////////////////////////////// #incluce &lt;teroxLibrary&gt; using namespace terox; using namespace terox::linsql; namespace demo::sqlserver { ///////////////////////////////////////////////////////////////////////////// struct universalAsAttributes ( companyId { this, "companyid" }, companyName { this, "companyname" }, color { this, "color" }, count { this, "count" }, customerId { this, "customerid" }, demo { this, "demo" }, employeeId { this, "employeeid" }, firstName { this, "firstname" }, lastName { this, "lastname" }, listPrice { this, "listprice" }, name { this, "name" }, orderDate { this, "orderdate" }, orderId { this, "orderid" }, orderTotal { this, "ordertotal" }, productId { this, "productid" }, productNumber { this, "productnumber" }, quantity { this, "quantity" }, standardCost { this, "standardcost" }, title { this, "title" }, unitPrice { this, "unitprice" } ) ///////////////////////////////////////////////////////////////////////////// namespace { auto selectSalesOrders sql ( select c.customerId, c.companyName, count(soh.salesOrderId) as count from SalesLT.Customer as c left outer join SalesLT.SalesOrderHeader as soh on soh.customerId = c.customerId group by c.customerId, c.companyName order by count desc ) auto insertSalesProduct sql ( insert SalesLT.Product set name = :Name, productNumber = :ProductNumber, standardCost = :StandardCost, listPrice = :ListPrice, sellStartDate = current_timestamp output inserted.productId ) } auto csharpVariationAsCpp() try { for(auto&amp; order : selectSalesOrders[nil]) { log::infoAs ( ID: % - Name: % - Order Count: %, order.customerId, order.companyName, order.count ); } universal product; product.name = "SQL Server Express"; product.productNumber = "SQLEXPRESS1"; product.standardCost = 0; product.listPrice = 0; insertSalesProduct(product); log::infoAs(Product ID % inserted, product.productId); } catch(Exception&amp; ex) { logExceptionAs(ex); } ///////////////////////////////////////////////////////////////////////////// auto pythonVariationAsCpp(universal const&amp; params) try { static auto selectCustomers sql ( select top 10 title, firstName, lastName from SalesLT.Customer where (:Demo is null or demo = :Demo) ) for(auto&amp; row : selectCustomers[params]) { log::infoAs(% % %, row.title, row.firstName, row.lastName); } universal product; product.name = "Bike"; product.productNumber = "B1'; product.color = "Blue"; product.standardCost = 50; product.listPrice = 120; product.demo = params.demo; static auto insertProduct sql ( insert SalesLT.Product set name = :Name, productNumber = :ProductNumber, color = :Color, standardCost = :StandardCost, listPrice = :ListPrice, demo = isNull(:Demo, demo), sellStartDate = current_timestamp output inserted.productId ) insertProduct(product); log::infoAs(Inserted Product ID : %, product.productId); } catch(Exception&amp; ex) { logExceptionAs(ex); } ///////////////////////////////////////////////////////////////////////////// } // namespace demo::sqlserver ///////////////////////////////////////////////////////////////////////////// &amp;#x200B;
This has to be the worst thread i ever read on this sub. Most people totally miss the point of seans post and instead choose to make fun of hin or how he works. I believe him, when he says he rewrites code multiple times before he compiles. Just watch his talk where he refactors a complex function using the stl. Todo this you don't need a compiler but a good knowledge about the standard algorithms and time to think about the actual problem. Do work I so? Hell no. I don't have the time nor the knowledge. I need my compiler, my debugger and my printf to guide me along. Did Sean suggest, you should work that way? I did not read it in the article. I did however read, that when you want change you should stop ranting and start contributing. But i guess it is easier to insult people and make fun of them instead of thinking and working on a problem. This thread is the best example. 
Well, I'd personally do something like: 'using namespace att = apache::thrift::transport;', or 'using namespace wm = websocketpp::config::asio_client::message_type;' and those only have to be unique within that translation unit. But you can reuse some set of those in a few files, and you'll get used to what they mean. /my experience
&gt; You can also hook up formatters like Astyle to on-save actions in many editors, even if they lack an official integration. Visual Studio and VS Code both support format-on-save for clang-format. It changed my workflow. I now rarely hit the spacebar and only sometimes hit enter. I Ctrl+S instead, and all is made right with the world. Big efficiency gains for my team and code reviews.
Your CI script should be specifying the exact versions of all dependencies. If you want to upgrade a static-analyzer dependency, you have to make a commit to do that. That said, static analyzers are mostly just saying "my compiler is too stupid to do its job properly." For simple formatting/sanity checks that are individually instantaneous, those get run every time the file is compiled so it's already in the I/O cache (I/O is usually the killer for performing one operation across whole trees), then `move-if-change`d before the rule completes. You do need to deal with headers, but that's perfectly doable with careful, enforceable, source policy.
If you're worried about time, I've seen an async job run the checks and then do an auto-rollback if it failed. I wasn't a fan of that. Run the checks and build as two jobs and do a join the commit happens? For a new version of the tool, it's someone's job to fix all the breakage with the new tool before you upgrade.
Can you answer what "remove" means clearly and unequivocally? I ask because most people expect "remove" to mean that something is actually eliminated or destroyed. \`remove\_if\` leaves objects in a "valid but unspecified state." I honestly don't know what that's supposed to mean. Is the original container still able to iterate cleanly to the end? Was it merely a partition? Elimination implies deconstruction. When does that happen? &amp;#x200B; Then I check the \[Wikipedia page\]([https://en.wikipedia.org/wiki/Erase–remove\_idiom](https://en.wikipedia.org/wiki/Erase–remove_idiom)) and see a warning about resource leaks. &amp;#x200B; I can be Devil's Advocate here in a lot of ways. I'm being meaningfully naive because \*programmers often are\*. Honestly, I don't want any of the programmers that I mentor to see \`remove\_if\` and think that it does what they're likely to think that it does. You can blame my staff if you want. I'll blame the ambiguous API. You may think that it's \*obvious\* that the original container isn't changed, but \*none\* of the other behavior is obvious. Even then, the provision that people seeing \`remove\_if\` doesn't \*actually\* eliminate objects is not an obvious assumption given the name of the API.
I did. It's poor.
static analysis - yes formatters - no
I was thinking the same. It's been a while since I've thought hard about that stuff, but I remember mocking being pretty difficult.
thepiratebay.rocks was my introduction website to that TLD
Not familiar with Node/JS, is there something that makes an asynchronous JS/Node project more difficult to test than an asynchronous C++ application? Maybe things ran in a thread are ripe for unit testing, and testing the threads/interation/etc is an integration or system level activity.
From my limited experience, the asynchronous nature can quite often run amok. A lot of it can be attrbuted to bad design but some times you just need to do 3-4 asynchronous steps for an atomic operation, which can be quite cumbersome.
Recently switched one of my projects to this
This is teetering on the brink of an IT question in some ways. Ideally your workstations are uniform deployments, and a user can't forget to install a hook.
Typing speed is nice, but the increase in readibility and decrease in cognitive load is worth it. In my code, anything in boost gets boost:: prepended to it, so anything in the default namespace is std. It's a very nice code convention. 
If you do happen to use GCC then you get -D_GLIBCXX_DEBUG which enables all sorts of checking on STL containers to make debugging easier. I've found that I don't even need a debugger to catch most of my STL-related fails with the flag set. 
Would you expect the items at the back to be in an ok state after running that? Sure sounds like they should be ok, but remove_if doesn't need to make that promise. 
From an in-house api perspective I'm attracted to keeping them in the declaration because I feel it helps me reason a little more about the function contents without looking. That said, I don't do it because most other developers either disagree or are likely to read it as a mistake (like forgetting to make the parameter a reference or forgetting to remove the const after making it pass-by-value).
Wow, a browser engine is an ambitious student project; this is quite impressive. There's a couple of idiomatic C++-y things I noticed on a brief skim: - Files that end up getting included should usually have a .hpp ending (or .h, .hxx, whatever); ".cpp" is ususally reserved for non-templated definitions. I think what you're going for is "interface vs. implementation", but there's not yet a way to split things up that way yet. - Some of the ownership semantics seem a little confusing; e.g. the `getInlineContainer` documentation says "Get the box an inline node should go into, or a create a new one", which I would take to mean that the caller assumes ownership of the object; here though, it seems that a non-owning pointer is returned. - A syntactic thing is that `int* x` is most common in C++, `int *x` is next most common; I don't think much code at all uses `int * x`. Nitpick-y stuff aside, I like the design choices and documentation quality; they're particularly impressive and thoughtful coming from someone without much experience.
Likewise [`-D_LIBCPP_DEBUG`](https://libcxx.llvm.org/docs/DesignDocs/DebugMode.html) for libc++ and [`-D_ITERATOR_DEBUG_LEVEL=2`](https://docs.microsoft.com/en-us/cpp/standard-library/iterator-debug-level) for MSVC (which is enabled by default when `_DEBUG` is defined).
Thanks for the feedback and kind words! I noticed one place in the HTML/CSS parsers were I was including a `.cpp` file rather than `.hpp`; I'm not sure if you mean that there are more, but I'll fix that up. I agree with your second point that the wording there is confusing, perhaps removing the notion of "getting" an object or pointer would make more sense? The formatting of pointer alignment is unusual, but a purely personal choice - I find it easier to read that kind of middle alignment, but I understand that's opinionated.
As a general rule of thumb that's true enough. OTOH, mine has been around for 20+ years. It's been used for a long time in a lot of ways. I think it's pretty well worked out by now as well. &amp;#x200B;
That's a good point, move_to_back_if does imply valid items.
Because it performs a simple action that could have been named in an informative way that would allow most people to guess its purpose. For example `increment_range`, this conveys information to people who understand english, compared to `iota` which might convey information to people who know APL. I'm willing to make substantial bets about which is more common in C++ community.
Now if you seek a novice-friendly language, C++ is probably not for you. The original complaint wasn't about that. It was about `remove_if` being an illogical name. It isn't. It is logical and consistent. It is a novice-unfriendly name. The entire concept of working with iterators instead of containers is novice-unfriendly. One needs to learn it. It requires making a mental switch. You don't sort a list. There's no list. It takes time to sink in. Sorry about that. 
I would argue that increment_range is sufficiently generic enough that I would still want to look it up. You can argue that the name is problematic, but that's not what I was saying. Just that looking up something you aren't familiar with isn't a ridiculous thing to expect. 
So you agree remove isn’t the best name.
&gt; Just that looking up something you aren't familiar with isn't a ridiculous thing to expect. It is when that something was deliberately made unfamiliar. To take it to an absurd extreme, what if all the new algorithm additions in C++20 were random Swahili words or dog breeds? Would it be seem reasonable because each word could be looked up? Even if `increment_range` isn't perfectly precise, I would think it's much more likely to be guessed and remembered than `iota`.
Yes, sure. You send an iterator range that has unneeded elements. You get back another iterator range, without these elements. Where are they? Removed out of the way. That's what remove does. Think about an immutable list. How do you remove elements from it? You build a new list. Anyway I don't understand how remove_if sneaked into a topic about "modern" C++. It is not modern at all. It's 20 years old.
I would argue that if knowing that a function doesn't modify its by-value arguments helps at all, then you've been unknowingly relying on fragile undocumented behaviour. The language treats a function signature of a const and non-const value parameter the same. Personally, I'm not a fan of using language keywords to promise more than what the language can promise.
fyi a very similar usage of the word iota is common in English already - as in "not one iota" - https://dictionary.cambridge.org/dictionary/english/iota To get the behaviour you also have to know it's a fill-style algorithm, but you can guess that from the function signature. It's not a great name, but really not that bad imo.
Bjarne's books often recommend implementing vector as a good way to learn. And implementing all the various optimizations based on type traits will give a good breadth of the language. I would say, for C++17, nothing has been more instructive than to try and implement variant, with all its constexpr goodness. [https://guan-jing-ren.bitbucket.io/gut\_variant.html](https://guan-jing-ren.bitbucket.io/gut_variant.html) Moving on to higher order function equivalents for map, reduce etc for variants was an even greater learning experience.
that's really the shittiest answer ever. Try again
&gt; but you can guess that from the function signature. You can? It could just as well be a search. &gt; It's not a great name, but really not that bad imo. It's pretty bad, imagine if they created a natural complement to the algorithm that fills with a decrementing range. What would they call it? The answer is obviously had they named it something like `increment_range`. 
I don't _rely_ on it, but it would help inform speculation about implementation details at a glance. At any rate, there's `const_cast` so whether you trust a `const` is already kind-of up to you. It's obviously not something I find so incredibly helpful that I'm willing argue about whether it's acceptable with other developers, it's just an additional piece of information (that could be a lie) that I might consider adding if I were writing something for myself.
I'd expect a search to take const iterators.
Git post commit hooks and in pipelines, though I write in Ruby. I imagine you could get similar though
I really hope that modules will stop this madness of header-only libraries. I get it, but seriously, I'm tired of header-only everything.
You may not intentionally rely on it, but if knowing a value parameter is const affects the way users of that function uses it, they've made an implicit dependency on, at least, an assumption about the way a function works internally.
Is it just compilation time? Or is there some other reason in particular?
I don't think it should affect the way it's used, hopefully, just allow assumptions about the way it works internally. Like I said originally, I'd consider it for in-house apis (i.e. not public-facing so the _way_ it gets interpreted should be mostly knowable). I think developers are sometimes going to make assumptions about the way functions work internally without looking out their definitions, so I think in those cases the additional hint is just a tiny bit of extra information to inform those assumptions. I don't really see what the harm would be given those constraints.
Could you give an example of how it broke stuff? I've only had the header reordering cause problems (and it's taken me a while to figure out why stuff stopped working after a "simple" reformat! :D )
Why not simply use xtensor? https://github.com/QuantStack/xtensor
Maybe I'm misunderstanding you but the language designers don't write the compilers. They're separate jobs so they don't consider whether to spend time adding a new feature vs. optimizing a compiler's implementation for performance. I'm sure some take it on themselves to do that but for the most part that's at least 2 different groups of people.
yes, I've actually done quite a lot of benchmarks with it. In most of my benchmarks my map seems to be faster and use less memory. Some of my results: * Insert 50M random integer, clear, reinsert 50 million ints, destroy map: robin_hood map takes 4.5 seconds, bytell 8.8 seconds. * Find integers: robin_hood is a a bit faster (28 sec vs. 30.5 sec) In general, search performance for robin_hood map seems to be between absl and bytell (slower than absl but faster than bytell) for me. Memory usage for robin_hood is usually below both of them, especially for large data (when robin_hood uses the node based allocator)
CI machine runs a python script on modified files before each run. the script existed beforehand to check things like correct copyright notices, indentation, etc. so folding in a call to cpp_check there was the natural place
With `:Gblame` it is easy to drill down, but how do you get back once you realize you've drilled too far and need a step back?
With a normal library you have headers, source files and some sort of mechanism to build a binary provided by the library. While many projects now use cmake and some even do so in a way that make it easy to incorporate them in your own cmake based projects, many are a hot mess of cobbled together build systems or project files for long outdated versions of visual studio, or are entirely missing any sort of build recipe. Thus, trying to integrate a library build into your own project has long been a living hell. And that's if the project has a source distribution. Additionally, if you're building on windows, there are all sorts of things you have to deal with, like matching up the CRT runtime the project wants to use with the one you do. With header only libs, all of that goes away. All you need to use the library is an include path. Really good projects will have their code set up in such a way that you can use it either as a header only or as a compiled object lib, typically by allowing you to have one file that includes the header in a cop file after some special preprocessor directive so that one file contains the entire implementation, and the headers parse much faster.
&gt; Really good projects will have their code set up in such a way that you can use it either as a header only or as a compiled object lib, This really depends on the nature of the library itself. I've written some that work well this way, and others that are entirely templates where this would not even ultimately make all that much sense to even try unless you were attempting to precompile the most standard options or something...and even that doesn't always make sense either.
wait isn't numpy written in C ?
Then C++'s standard library is not up to your expectations.
just checked it, apparently only half of it is. we might achieve circular library wrappers soon.
Mostly compilation time and API clarity (isolation between public APIs and internal APIs). But also maintainability: I have the same problem, only different. Do I include this in my project by copying it, or do I do git sub-moduling? The only problem it solves is the necessity to have a compiled binary while adding new problems, and not necessarily being better at anything.
Not the best for whom? There is no such thing as best for everyone. 
Next week when I’m back at work, I can try recreating the problem.
&gt; API clarity (isolation between public APIs and internal APIs). I always felt like the public/protected/private keywords were "good enough" for this. It's not really been a concern of mine in well-implemented projects. &gt; Do I include this in my project by copying it, or do I do git sub-moduling? This is really a question for your project specifically. Some people like to grab a current snapshot of an external project so they can make sure their project will always compile...in this case, a copy is best as to completely eliminate any external dependencies. But, if you know that your project will work with anything 1.0 and above, or if you know that it will always work with at least one branch of a dependent project, then a sub module might be better. &gt; The only problem it solves is the necessity to have a compiled binary while adding new problems, and not necessarily being better at anything. Templates are a core part of the library, and they are required to be in headers. Libraries that make extensive use of templates cannot necessarily be compiled down into shared or static libraries. Sometimes, it's done out of a matter of necessity.
Isn't that enough of a reason? I have a project here that includes around 50 external libraries (either directly or indirectly). We update those on an irregular basis, maybe once or twice per year, so it makes very little sense to compile all of those on a daily basis. What makes even less sense is compiling all of those *in every translation unit*, and *every single time we compile anything at all in the system*. We are not talking about adding a few seconds either: if we compiled entire libraries as part of each translation unit, we would be adding hours to the working day of each team member. "But can't you just include the library once in one translation unit?" Generally, no. Resources obtained from such libraries tend to end up in project-specific header files that get included elsewhere as well. Maybe you can pimpl them out of existence for member variables, but as soon as you want to use them in a function signature you are f\*cked. Any translation unit that includes such a header is immediately cursed with having to compile the library as well. Besides, my project consists of multiple executables - I'd still end up compiling the library at least once for each executable. So the cost of header-only is absolutely massive, but what does it gain us? The answer is the one-time convenience of not having to figure out how to compile it. I'll readily admit that's not easy either, but at least it is only a one-time cost, instead of a daily cost, and at least we have package managers to deal with that problem. Luckily there is a middle ground here: libraries \_could\_, in theory, be set up so you would have two header files: one for declarations, and another definitions. The declaration header would be cheap to include, and the definition header could be included as the only entity in a .lib in my own build system, essentially like a unity build. That would give us all the advantages of a normal library, and all the advantages of a header-only library. I haven't yet seen any library set up in this manner though. 
How does your team handles the use of templates? Or do you just largely ignore that aspect of the language?
I tried using `const` like this for parameters, but it's just too much noise.
Would be interesting to compare performance with NumPy. I expext NumPy to be faster but it could give you an idea. Nice work!
I have used [armadillo](http://arma.sourceforge.net/) for this kind of computations. It is highly optimized and uses expression templates for arithmetic computations. 
That is something we noted - when you get virtual const Type&amp; MakeOrGetSomething(const int index, const double parameter1, const OtherType* const possiblyThereParameter) const = 0; it does begin to get a bit heavy on the consts... We decided to take the hit, mainly because we also break practically all parameter lists vertically so it is at least a bit more readable. (Although every line now starts with const, so your mileage may well vary on how _much_ more readable...)
&gt;This is teetering on the brink of an IT question in some ways. &gt; &gt;Ideally your workstations are uniform deployments/platform, and a user can't forget to install a hook. &gt; &gt;This would also solve your concern about tool versions and what not. I agree completely. Regretfully we are a small company and cannot afford to have a pure IT-person employed. So far we have relied on outsourcing as much of this as possible. &gt; As for the actual linting/formatting workflow: we have linting and formatting setup as rules in our build scripts (think make) that does that stuff on modified files only, which keeps it quick. This is something I have considered as well, at least for formatting i.e., adding a custom cmake target which runs the formatting tool during build. For static analysis that would probably be unwise since a full check takes upwards 30 minutes for the full project. Writing a script that only checks the modified files would maybe be a solution in that case. &amp;#x200B;
Yeah, and there's no point clogging up code reviews with confusions or debates about it. I do like doing it but certainly not to the point of dogma; if I swap to a different team that don't put them in declarations, even of the implementation, I'll not do it either.
I really wish peeps would just have one primary .h to #include where you want and one primary .cpp to integrate into the build process. C++ build systems have problems, but I think we can all handle manually adding a single source file to whatever system we are using. The STB-style “it’s a header, and a source, and a dessert, and a floor wax!” tradition strikes me as a bad trade off in complexity vs what I’m asking for.
Yeah that's totally viable, I forgot that you can do that!
Thank you for the tip about danger, it looks very slick. If we decide to go the Jenkins route, this is definitely something we need to checkout. 
I don't like it either but I believe it comes from the syntax for multiple pointers declaration: int *a, *b; Now for why they decided the star has to be repeated in this example...
&gt;every line now starts with const Join the ~~Dark Side~~ East Const!
“Python implementation of NumCpp”
Civilization is payable in debug https://twitter.com/JJcoolkl/status/1079168526664060928?s=19
Does it handle different endianess in serializing/deserializing? I had a quick look and it looks like it does not.
There are no restrictions on TLDs now.
I'm not defending the name. I'm saying you should be embarrassed if you go ranting about something online without doing a minimal bit of research first.
Trying to cast away the constness from an actually const object (such as a const parameter) is UB.
That blog post made me lose some of the respect I had for Sean. I don’t think it came across the way he intended, and it shows exactly the elitist attitude that the game developer community has been venting about. He is the one that should be embarrassed. 
No, currently, the endianess as well as the register width (64bit) needs to match. Basically, it would be possible to extend the library to support something like `struct cista::uint64_t`, etc. that does the conversion on access. Possibly, it would help to look how other libraries accomplish this: [https://github.com/capnproto/capnproto/blob/master/c++/src/capnp/endian.h](https://github.com/capnproto/capnproto/blob/master/c++/src/capnp/endian.h) [https://github.com/google/flatbuffers/blob/master/include/flatbuffers/base.h#L258](https://github.com/google/flatbuffers/blob/master/include/flatbuffers/base.h#L258) Currently, we don't have a use case for this and no real hardware to test on (correctness, performance, etc.). If you have a real use case, we can maybe figure it out together. &amp;#x200B;
I agree with Sean's thoughts on a whole, and also agree that the writer of the post to which he was responding should be embarrassed. But not for not knowing the history of iota. Anybody can be one of today's joyous 10,000. Instead, they should be embarrassed because of a failure of curiosity. Usually, when we encounter an odd name (and I don't just mean misspelled) in our domain, it's because it's been lifted from another domain. If I see "poisson distribution", I do not go off on a rant over how C++ and fish are not an acceptable overlap. *That* would be embarrassing. Instead, I look and see it is terminology that has been imported from statistics. Also, iota was in the original SGI implementation, and has therefore been in our domain for decades, so it's probably the most unsurprising name for the Standards Committee to choose for the operation. [http://www.martinbroadhurst.com/stl/iota.html](http://www.martinbroadhurst.com/stl/iota.html)
&gt; oh I see. I like this subtle admission that you clearly had no idea what `remove_if` actually does, but yet felt qualified to defend it and the documentation.
I don't know about Vim, but in Qt Creator it's easy - when you git blame, you get a view where you can right-click a revision of a line and blame its parent to drill down. This creates a new view that you can go back and forth just like between normal files (Alt+Left, Alt+Right).
Utilize unit tests. It saves cluttering the struct with additional boilerplate and should reduce the amount of regression when someone makes a change .
&gt; I always felt like the public/protected/private keywords were "good enough" for this. It's not really been a concern of mine in well-implemented projects. When you have classes that span over 1000+lines, public, protected, private keywords are useless. I mean sure, my compiler will work perfectly, it will know exactly what is what. But I need the human to understand what the heck they can do. This is the reason why I kept away from the likes of Java and C#. However, it seems quite obvious that headers are no longer used for what they were meant to be used: announcing the API of a module. But probably that's just me, after all we have intellisense and friends. :) Fortunately, templates make things so complicated that not even tools can help us, so hooray! [/sarcasm]
That's What she said? I don't know how to properly react to nonsense.
for addition of params, clang warns when you not provide enough arguments in braced list initialization. I have really no answer for switching around 2 members though
&gt;The C++ standards committee is filled with people with diverse **interests**. Some who make their living teaching the language and so want to be informed, some who represent companies and the **interests of those companies**, some **from academia who are seeking publication, grants, and tenure**. My emphasys
You could use a strong typedef but I’ve found them cumbersome. 
It depends. STL is used throughout. We don't know how much that affects our compile times though; we didn't pay much attention to that in the beginning, so it has always been there. We also use quite a few small templates of our own making, but these tend to have a handful of lines at most. The scary SFINAE stuff is probably less than a hundred lines. Then we have a 30,000 line set of templates that we only instantiate for two types. Those we instantiate in .cpp files, with an `extern template` declaration in the .h file, so it is no different from normal code. And finally, there is code that is somewhat enum-heavy that would benefit from having that enum as a template parameter (instead of being an int, as it is now), but we choose to cast instead because we fear the effect it would have if we did turn it into a template. Since a few years we have become aware of compile times, and been struggling to bring that under control. We now monitor more closely what the effect of new libraries is. This has resulted, among other things, in the decision to not use Chaiscript (despite the language looking interesting), but going for Angelscript instead (similar, but without the slow compile times). We'll look at things on a case by case basis for other template-heavy libraries: how useful is the library? Is there a cheaper solution? Can we limit use of the library to a single translation unit? etc. On principal I don't disallow any language features, but some will require a bit more explanation than others ;-) We can always explore what the best solution is in a given situation, but I'll also think about things like maintainability, coherence with the rest of the source, compile times, and all the other concerns... 
It is very much tied to CPython API, so is imprectical to use in a C or C++ application.
Everybody is sick of idiots trying to look clever at the expense of your preferred professional tool.
yeah good idea with the strong typedef but as you said: for me it feels also like boilerplate code. regarding the constructor: adding a parameter would mean a breaking change. thats good. the aggregate potentially swallows the change silently and is bugged.
This looks similar to Eigen and it's Tensor module. It also offers lazy execution and various compile time checks.
Not exactly the best example because I'm sure that code base is considerably smaller than most modern big AAA games. And that matters. It's easier to ban high level constructs when one has less source code to manage. 
Of course we are using static analysis tools! Currently on developer system only. 
Love the floor wax ;-) As is probably clear from my other messages in this thread, I'm not a great fan of header-only. Having said that, here's a list of things that happened to me over the years while trying to build a C++ (or even C) library: \- They require you to install a new development environment you've never used. \- They require you to run some script that was the rad new thing back in the seventies to generate half the source code. You also need to build the script interpreter yourself, and it's just as bad as the thing you are trying to build. \- Compilation can be configured to support weird-endian 37.5 bit systems, but forget about using a modern compiler. Have fun installing gcc 1.2. \- You are required to 'configure' the build system before it works properly. Failing to supply things like \`-DDONT\_RANDOMLY\_CRASH\` will cause it to occasionally subtly fail. This is only documented in a file called 'private.jvm'. \- Unit tests and examples are great! So let's put them all in the same directory as the library itself. \- Compilation proceeds with somewhere north of 100K warnings. \- Eventually you get stuck with an error that reads something like "int is not a type", or that refers to a symbol that no amount of grepping will uncover. \- Having resolved that, you realize you've only built the top-part of a dependency pyramid that would make Cheops blush. And all the other libraries down there are just as bad... So yeah, I do understand the other side of the argument as well ;-)
And python and fortran
A step in the right direction. Why no LICENSE or COPYING ?
Definitely not just you. A piece of advice I keep coming back to is "don't preoptimize." I work with mobile apps, so there are some memory constraints that I need to think about but usually no time constraints unless work is being done on the main thread (it can cause jankiness in the UI since frames can be dropped). Honestly, it's mainly "don't create too many objects (GC collection overhead)" and to stay away from nonlinear operations. That's normally it. Maybe I'll chose between an Array-based list or a Linked list.
This is the right answer
A static\_assert on sizeof the aggregate will catch some additions or changes (but not all). A structured binding can be used to check the number and type of the fields - it's not constexpr but you can wrap it in a constexpr function to get a compile time failure. A reflection library like [Precise &amp; Flat Reflection 'magic\_get'](https://github.com/apolukhin/magic_get) can reflect an aggregate type as a tuple, allowing to static\_assert on the number of fields and their types (but does not handle array members or bit-fields). &amp;#x200B;
How do you defend against people modifyibg function signatures? I mean: void move_it( T* to, T* from ) to void move_it( T* from, T* to ) ? Answer: you shoot programmers who silently break APIs. And aggregate layout is part of its API. 
My tip: vcpkg (https://github.com/Microsoft/vcpkg) instead of Conan. Easier to use, and has more and better maintained package recipes out of the box.
Try using `git log -L`, I find it far more useful for detective work than git blame.
You of course have to be a little bit careful, but it's not that big of a deal, as you can just insert some garbage type to make compile fail: struct person { std::string firstname; int garbage; std::string middlename; // newly added std::string lastname; }; Now the compiler will complain about all incorrect uses and you can go and correct them. Once everything is working, remove the `int garbage` again, fix up the code again and you are good to go. This ensures that you don't miss any of the calls. Same tricks works when reordering arguments to a function that have the same type. 
Well if i change the function signature i KNOW i break all calls to it and i can happily browse/search the code base and adjust the callside. But when i change the aggregate layout, its not this extreme obvious. At least i think so. In the end you are right. It kinda is part of the API. This makes it a bit more scary to touch any existing code :-P 
NumPy is to a good extent an implementation of Blas/Lapack. One should never use the Fortran reference implementation of those (see netlib.org), but there are plenty of optimized implementations, such as [https://github.com/flame/blis](https://github.com/flame/blis) If you go proprietary, then you can use Intel's MKL. Unfortunately many of those do not have a terribly C++ idiomatic API. So you ask yourself, what's the most important, the performance and reliability or the API. 
C++20 will have named aggregate initialization, so that would eliminate your issue.
Scope. As a private utility of a class or particular API, yes. This automatically limits scope for changes, fixes, tests. As consumable part of an interface, I'd be wary. Changing them might be breaking a caller anyway, if they get to large, named intialization seems almost required for readability (which C++20 should make a bit smoother). 
Now just throw in `[[nodiscard]]` and `noexcept` Honestly though design should be more important than noise, and formatters do a pretty good job of helping with the noise.
Do you mind expanding on your thought a little bit? I find it interesting. The unit test would only save you when the code change is made and then the unit test fails. In that case the developer(s) could go find all references to the structure (in this example) and correct it. What if the developer updates the test case when the code change is made? 
I'm surprised no one mentioned [clang-query](https://eli.thegreenplace.net/2014/07/29/ast-matchers-and-clang-refactoring-tools): $ clang-query p.cpp -- clang-query&gt; match varDecl(hasType(cxxRecordDecl(hasName("Person"))), hasDescendant(initListExpr())) Match #1: /home/thlst/p.cpp:10:1: note: "root" binds here Person p{ "John", "Doe" }; ^~~~~~~~~~~~~~~~~~~~~~~~~ 1 match. [Here's a reference to the Clang AST Matcher](http://clang.llvm.org/docs/LibASTMatchersReference.html). 
you just attacked me for admitting I was mistaken, that seems... you seem hateful.
I don't meant to blow this up into something bigger than it is, but... I often get frustrated with other people's code and this kind of brings home why. I would never guess about what something was in terms of an API. Even if I had no documentation I would write a series of tests to poke at it to ensure I understood what it was doing (and I've done this many times). And I'm not defending the name, but the argument that it should be acceptable for a developer to write code against an API that they've guessed at the usage for seems outlandish to me. But it may explain the quality difference.
By changing the aggregate layout, you're changing the aggregate initialization expression. Imho, I think that's equally as obvious as changing function parameter order. It would require using a code refactoring tool or writing a clang tool to find all the locations to change in the source code, but it can be similarly difficult to refactor all uses of a function when indirect calls are involved right? Aggregate initialization just requires finding locations that use auto.
Currently rely on IDE code formatting at editing time, but have experimented with using clang-format and have dialled in some settings that produce results that I like. So now just need to integrate clang-format into the project's CMake build process. Plan to do this before end of January. There after all code would get a standard formatting prior to git commits
The article is pretty damning towards C++. &gt; We will slowly but surely port every piece of performance critical code that we have in C++ to HPC#. It’s easier to get the performance we want, harder to write bugs, and easier to work with.
&gt; you just attacked me not really... &gt; for admitting I was mistaken not really... &gt; you seem hateful. I definitely am.
&gt; Just convincing all my C/C++ compilers to vectorize my code at all is hard. I can confirm that. But at the same time we have (that I can remember) 3 places in our codebase where we want it vectorized out of 6457 for-loops. Almost all of the for loops we write in game development have side effects that mean they can't be vectorized. I guess maybe if you're writing stuff like particle systems where you just want a large amount of positions updated but that's not what we end up doing. It is incredibly annoying trying to make the compiler generate the code I want it to and the C++ standard does very little to help since it's targeted at making so many different platforms theoretically all work. A great example I keep running into: https://en.cppreference.com/w/cpp/container/vector/shrink_to_fit there's no way to say "do it anyway, fail to compile if you're not going to do it".
No mention of the fact that there are intrinsics and multi-architecture libraries that emit them to generate the vectorized machine code that you want?...
The best way to have memory leaks with circular dependency. When I have such situation, I capture a `weak_ptr` on the object, and lock it in the lambda to access the object if it's still alive.
This is not ideal
Can't wait for this. Right now it is so error prone. Named aggregate should have been there from the start.
“If we stop using all the things that make C# awful, C# looks really good” Why does this logic only apply to C#? The language that can’t even give a clear answer on whether memory is stack or heap allocated. The language that does WORSE than C++’s implicit conversions by allowing implicit boxing. The language where the creator readily admits that language ergonomics is more important than efficiency. C# like Java was invented during the peak of man’s Moore’s Law hubris. Say what you will about the issues with C++, this path is absolute madness and IL2CPP is imo, a lot of work to correct the blunder of C#-ifying everything in the first place. It’s a pretty language for sure, but after spending hours trying to optimize it and even understand what it’s trying to do in the first place, I’d honestly take a more rigid standard thanks. 
&gt;Why does this logic only apply to C#? The language that can’t even give a clear answer on whether memory is stack or heap allocated. The language that does WORSE than C++’s implicit conversions by allowing implicit boxing. The language where the creator readily admits that language ergonomics is more important than efficiency. C# like Java was invented during the peak of man’s Moore’s Law hubris. They explained the reasoning in the post. They enjoy it more, they've got better tools, and they can reliably write better, faster code. If the *only* upside to C++ is performance, and they can do all of the above in C# plus performance, it's clear it should be C#, right?
I like C++ being a value based language with zero overhead and no GC. It has though many dark corners especially when using templates (e.g. two phase lookup; auto vs decltype deduction guidelines; function overloads vs specialization; perfect forwarding). It seems also that the C++ committee is now adding extra crap in every new standard after being in hibernation for more 10 years. Traditionally it had the STL which is great and the iostream library which is pretty horrible. Recently added libraries (e.g. tuple, thread, regex, future) are very welcome but C++ is still lacking in other standard libraries (e.g. filesystem; networking; XML; database; graphics).
I think you might be confusing disagreement with misunderstanding.
I wouldn't call it "damning". They seem to be working with a very specific set of constraints (like "easily see the machine code that is generated for all architectures as I change my code") and they're in a situation where they _already_ use C# as part of their infrastructure. What they're proposing to use also isn't your typical C#: &gt; That said, if we give up on the most of the standard library, (bye Linq, StringFormatter, List, Dictionary), disallow allocations (=no classes, only structs), no garbage collector, dissalow virtual calls and non-constrained interface invocations, and add a few new containers that you are allowed to use (NativeArray and friends) the remaining pieces of the C# language are looking really good. My understanding is that they don't have anything against C++ as a language, but they wish to have more control over the codegen. They apparently "have a lot of experience modifying intermediate-IL" and they want "complete control over the entire process from source compilation down to machine code generation". I mean, sure, go for it, but I'm not sure this says anything about C++, other than it's apparently the wrong tool for that particular job.
See blaspp and lapackpp (and SLATE for that matter), theres a huge push for C++ APIs in numerical linear algebra for HPC applications https://bitbucket.org/account/user/icl/projects/SLAT
ITT mobs with pitchforks proclaiming what a dumb idea it is to think carefully before doing.
| When we use C# we have complete control over the entire process from source compilation down to machine code generation, and if there’s something we don’t like, we just go in and fix it. No comittee to convince of the value of our usecase, or other concerns to be balanced against. This is his strongest point in my opinion, but it's akin to moving the entire problem out of the C# compiler and in userspace. Fine, no argument, but you could have done the same thing (arguably easier) in C++ if you had wanted to?
&gt; because I understand that there's no other way to implement it using just iterators no you don't, there is no law against iterators knowing their containers.
&gt;there's no way to say "do it anyway, fail to compile if you're not going to do it". I'm curious, in what cases would `shrink_to_fit()` do nothing? (besides when `size() == capacity()` obviously)
I was trying to follow that reasoning but the equivalent expression I needed to hear was “we tried restricting C++ usage to XYZ and it still didn’t work out due to ABC”. For tooling and stuff, I would argue they moved backwards because they essentially needed to write and maintain their own compiler backend. They’d be hardpressed to convince me this is somehow a tooling win. 
The problem is that "real simple" is very subjective. On one of my interviews I had to write rate limiter with floating time window. On paper. Not the best experience I had. I mean, if you really want to check some one coding skills, give them a place where they can think and try. Like workstation with working IDE or something. Or better yet - if you unsure about their coding skills, give them a small home work (around 1-2 hours). The amount of work will not alienate the potential candidate (I mean - it should be 2 hours at most) and you get to see how they code without the stress of the job interview. 
Implementations are allowed to ignore it, 24.3.2.4/13: &gt; _Effects_: `shrink_to_fit` is a non-binding request to reduce `capacity()` to `size()`. [_Note_: The request is non-binding to allow latitude for implementation-specific optimizations. —_end note_] It does not increase `capacity()`, but may reduce `capacity()` by causing reallocation. I'm unaware of any standard library that doesn't implement this as you would expect, but I'm sure there's one somewhere.
Depends on the library implementation. It's non-binding so if your implementation decides "no, I don't want to" it can and there's nothing you can do about it. Effectively it means if you want it to actually happen *every time* you have look at what ever version of the library you're currently compiling with to see if they actually do it.
Out of curiosity, since you referred to `shrink_to_fit()` as a "great example", have you ever seen one that didn't? Just so I can avoid it.
Crappy or not, it's true. I can't even mention the names of some of the engines I know that use the STL because they have not been publicly announced and I would technically be leaking to so much as mention their names. Others I can't detail information on because corporate policies disallow me (a non-PR-representative) from disclosing details that have not been publicly disclosed by approved PR representatives. That's how NDAs work, bro. I feel comfortable mentioning [Despair](http://gamearchitect.net/) since it's been publicly disclosed (that blog hasn't been updated in years but the engine is still in use in live games). It was a heavy adapter of Boost in the pre-C++11 days and all of that was eventually modernized to the STL. Note that EASTL _is_ an STL implementation (not 100% compatible, but close enough that it's drop-in replacement in many codebases! same as STLPort or most other third-party STL implementations) so it might be very safe to say that EA as a whole uses the STL. :p Microsoft's studios are - thanks to their internal partnership with Microsoft's dev tools groups - also pretty heavy on dogfooding compilers and libraries. Microsoft has published various blog articles over the years detailing all that. A lot of the STL complaints of mainstream devs have more to do with _consistency_ which is why _vendor_ STLs are often avoided. That is, we need our code to compile on (at one recent point in the industry's history) 4+ vendor implementations on 10+ platform SKUs. Code that relied on Quality of Implementation in vendor STL's would be up the creek without a paddle. Using a third-party portable STL made it much more reliable to know that if a piece of code worked and worked well on your dev machine that it would also work on every console and their bespoke toolchains. 
&gt; I'm unaware of any standard library that doesn't implement this as you would expect, but there's probably one out there. That's what I thought. I mean, if the spec technically allows it to do nothing but all the big implementations do the expected thing, who cares?
This approach has been presented by Vinnie Falco during his talk about Boost.Beast at CppCon this year, but it was rather about extending lifetime of an object until it's no longer necessary and then automatically disposed. https://youtu.be/7FQwAjELMek
Nope. But I still have to check every time we update anything.
&gt; Performance is correctness. I should be able to say “if this loop for some reason doesn’t vectorize, that should be a compiler error, not a ‘oh code is now just 8x slower but it still produces correct values, no biggy!’” If I write "shrink_to_fit" and it doesn't actually shrink to fit it should be a compiler error, not a "oh, it just now holds on to a bunch of extra memory, no biggy!". But, because of the standard I have to keep manually checking every time anything is updated that it still does what it should be doing.
why don't you just use a single stdlib across all platforms. libc++ works everywhere (or at least anywhere where you would run factorio).
It is a common issue in Fortran, Java, .NET and Julia as well.
&gt;Just convincing all my C/C++ compilers to vectorize my code at all is hard. That isn't really a great argument in the first place. The only reason they don't have that problem anymore is because they switched to a single compiler that they can change when it does not do what they want. But this solution is completely independent from the input language. They could just as well use the same c++ compiler for all their performance critical code. Their [burst compiler](https://docs.unity3d.com/Packages/com.unity.burst@0.2/manual/index.html) is build on top of llvm - so had they used clang instead of their .net-IL frontend, it would probably work just the same. 
&gt; Also, these people are not anti-intellectual. It's a principal engineer at the biggest game engine company in the world and the guy who wrote the textbook on realtime collision detection. I don’t mean to say anything about anyone, but just to dismiss this argument. A person’s position says next to nothing about the person. I’ve heard for example of people that are leaders of prominent countries and also are not too bright nor too ‘pro-intellect’.
You could have said the same about CFront back in the old days. IL2CPP is just a shortcut to create a fullblown optimizing compiler from scratch.
Good point, but on the other hand you can have nullptr dereference, when lambda will be invoked with rawptr, and a weak_ptr role is rather observer, so you cannot have any guarantees that object will be alive when you finally will need it. 
This makes me so happy to hear.
In C# you only get UB in unsafe code, while in C++ it is very hard to control what every team member is doing, even with help of analysers.
It's fine since C++11, when we got move semantics.
Please don't submit links as text posts.
The other thing is that Unity uses C# everywhere, and that's not going to change, so I think their reasoning was "if we can make it work and only have a single language, that's probably the best approach to take". 
I haven't tried Polyspace and Astréee myself because of the price of their license. Even if I could try them, I think their license forbid to publish public results. I have tried Frama-C and it is pretty good. The analysis can be tuned if you have the expertize in abstract interpretation, which is not possible (yet) in IKOS. One issue I have is that I don't know how to analyze a whole project with it. It looks like the best way is to analyze each .c file separately, but you lose precision.
Copy elision is guaranteed in [C++17](https://jonasdevlieghere.com/guaranteed-copy-elision/)
Because every stdlib has different benefits when run on the different platforms. For example: the MSVC stdlib has debug iterators which quickly and easily catch use of dangling iterators/mismatched iterators/threadding issues with iterators.
Do you have some process to keep the clang-format version consistent across developers? My reason for asking is that different version of clang-format *may* change how it formats files from version to version, even if the configuration file is identical. 
Do you have some process to keep the clang-format version consistent across developers? My reason for asking is that different version of clang-format *may* change how it formats files from version to version, even if the configuration file is identical. 
I've worked with style guides that have gone both ways. I find the key to be consistent in the code base, and not bouncing back and forth between the two options. My personal preference is to rely on the return value optimization (RVO) or move semantics. But it's more than just a performance concern. Are errors possible? How are errors going to be returned to callers? Exceptions or return codes? How are functions documented? Is there a guide to specify how to determine what parameters are intended for input vs output? Etc. RVO has been around for awhile now. Most compilers have it but there are still cases where it can't be used. 
Yeah, I think the parser was the thing I noticed. Putting the template definitions in a .cpp and then #include-ing them is fairly unusual; usually you'd put them in (say) a "-inl.hpp" or "-defs.hpp" or similar (since the template definitions need to be visible to the compiler by the time preprocessing is done, so it can generate the functions from the function templates). Having #ifdef guards in .cpp files will give a lot of readers pause, since in general you wouldn't want to be trying to include a .cpp file in the first place, much less do it multiple times.
That also leads me to what, these days, may be one of the most important skills of all, which is Search-Fu. My Search-Fu is very strong after decades of just diving into the deep end of one problem domain after another. It's one of those 'gift that keeps on giving' types of things, that will serve you well no matter what you are working on. The answers to almost everything (except why supermodels don't date me) are out there, and learning how to find them is an important skill. It's the modern day equivalent of being a card catalog wizard I guess. It may take some experience to know when you've really found the good answers. But typically if it's the good answer, there will be some consensus. There are some things that, surprisingly, are quite hard to find info about though you'd think they'd be more widely used. Maybe it's sort of chicken and egg. The harder to find info, the more people want to hold on to their solutions when they finally work them out. &amp;#x200B;
If have a type \`T\`, witch is slow to move, and some unrelated types \`type1\`, \`type2\`, then: &amp;#x200B; type1 copy\_elide\_parameter(T t, type2 t2, ...); T copy\_elide\_return(type2 t2, ...); T slow(T t, type2 t2 ...); &amp;#x200B; For both \`copy\_elide\_parameter()\` and \`copy\_elide\_return()\`, the compiler will be able to elide the copy (guaranteed since C++17, done since a lot time). However, for \`slow()\`, the compiler doesn't have the right to elide both the copy during the call, and during the return. &amp;#x200B; So for the last case \`T&amp; fast(T&amp; t, type2 t2, ...);\` is a better prototype. For \`copy\_elide\_parameter()\` use either pass by const reference or by value as you prefer, and for \`copy\_elide\_return() \` return a value. 
You make some great points, and perhaps it's not as damning as my initial read-through suggested to me. The article opens with this quote: &gt; Valid criticism on various things that make C++ not a great language for games (or at all), Which perhaps sets a tone the rest of the article doesn't follow. Still, saying something like "we need performance critical code, and we cannot rely on C++ to give it to us" sort of deflates the one of the primary motivations to use C++, which is "Performance!". We pay heavy compile times, deal with many foot-guns, lack of a standard package manager, and an admittedly steep learning curve for what? Usually performance. When one of the most widely used game engines says that C++ --- the language, the tools, the environment, the community, etc. --- does not address their needs, we shouldn't take it lightly.
Hindsight is 20/20.
This is absurdly unhelpful. "Get rid of programmers who make mistakes and your problems will be solved" just isn't how software engineering works in the real world. In this specific case, changing class layout isn't a breaking change unless callers are using aggregate init, so it's pretty difficult to know when it's safe to change it. 
&gt; intermediate-IL Intermediate Intermediate Language? Is intermediate-IL actually a thing I don't know about or just an accidental case of [RAS Syndrome](https://en.wikipedia.org/wiki/RAS_syndrome).
Changing the order of the parameters in the function signature has no effect when they are both pointers of the same type.
they said that about vectorization.
Haha yea and me takeaway was that because the compiler doesn’t do what I want all the time, instead of using intrinsics like everyone else, I’m going to change programming languages and rewrite the backend. 
Excuse me, are you somehow implying that cmake is anything other that a hot mess of inscrutable crap haphazardly cobbled together?
The most important part of the article is this: &gt; For the performance cricital part of our code, we know what we want the final instructions to be. We just want an easy way to describe our logic in a reasonable way, and then trust and verify that the generated instructions are the ones we want. C++ doesn't do that, so it's not surprising that they want to switch. The rest of the article is just a bit of a rant mixed with some info on their in-house "HPC#". I think you're trying to take a very particular use-case and apply it to C++ in general. I don't, and it's not even the point they're trying to make.
I look at it from a practical stand point. If you are going to change the type of something, you want to grab the whole type info. If it was: int \*b; and you were going to change it to a string, you aren't going to just change the int, you have to change the int \*. That sort of argues that it's part of the type, not the name, and it means there's less work to get to the type info if you want to change it. If you do things in a columnar fashion, it also means all of the names and all of the type info are separate columns that are easily manipulated separately. And it probably makes it more practical most of the time to do search and replace that doesn't mess up the formatting, without having to use a fancier regular expression with replacement parameters. &amp;#x200B;
If you're relying so much on `shrink_to_fit` that you need to check your implementation every time it changes to make sure it behaves are you expect it to, you probably should be using something else.
To paraphrase Churchill... &gt; CMake is the worst C/C++ build tool except for all those others that have been tried from time to time.…
That actually makes sense to me. I am now and then trying to argue with people about the use of C# in the Godot game engine. Since the entire engine is written in C++ (well, a bit C in there as well, probably) I just think it is a bit crazy to also add C# on top of that instead of just using C++. If the entire engine is C# it sounds a lot less crazy. I can understand throwing a small embedded scripting language like Lua or Tinyscheme or GDScript into a game engine on top of C++, but not another huge general purpose language. So Unity going for C# all the way down makes sense to me. However using their own subset and own compiler code like that is obviously cheating and not saying anything at all about the performance in general of C++ vs C#.
And it's not a breaking change to reorder a function's arguments if no one is using it. Your default assumption should be that changing the class layout is a breaking change, not that it's a safe thing to do.
It sounds great in theory but then you consider all the platforms they have to support, and it never quite works like the adverts. I've been burned by this before (though not with vectorisation). I think their strongest argument tho is getting the whole stack and workflow into a single language.
Though, it should be said, you don't have to have language-lawyer mastery to do a large amount of high quality code. It just means you may choose not to use some of the fancier features of the language. Some may consider than a bad thing and some may consider it a good thing. But that doesn't mean it's not following the 'standard', it's just not using all of the things available in the standard. I'm a perfect example. I have a sort of 'three-quarters-Qt' code base that I've worked on for decades, about a million lines of code, that doesn't use the STL at all. People are always getting completely bent out of shape that someone would dare do that. But it's completely compliant C++, and it's not any less powerful or high quality or functional because of that. Though someone told me a week ago or so that, if I don't use type traits, that I'm actually not writing C++ code, despite the fact that C++ existed for decades before type traits did. &amp;#x200B; I wonder how many people out there doing practical work ever bother with that level of mastery, given the language's complexity today? Given how many of us uphold the KISS principle (no, the other one, not wearing makeup and leather outfits), it's odd how far from KISS modern programming languages seem to stray. &amp;#x200B;
Yeah, the only compiler support right now is just using the existing stuff from C99, which are not exactly equivalent to what's defined in C++20. One of the two syntax are not available. I believe it is the braced initialization style that is missing. I would not expect it to be too much longer for compilers to get it sorted out.
What languages other than assembler will give you guarantees about what instructions are generated? I mean maybe C++ should have some kind of extension at some point to make that possible, but I do not see how that is possible other than by allowing inserting some kind of generic assembler syntax. How does that even compile when you target a CPU that does not have the exact vector instructions you want to use? Great for them that they managed to make a tiny subset of their favorite language compile to the instructions they need, but I do not see at all how that could ever be applied to any real general purpose language? Maybe if someone made a special subset of C++ that could only generate code for a very small set of CPUs and made very specific guarantees about what instructions would be generated? But that language would not be able to replace C++ in most places anyway.
Agreed. C++ has always been a general purpose programming language. It's _supposed_ to insulate you from the platform. Trying to work around your compiler and optimizer to get the codegen to do what you want is a waste of time. Get clang and write your own codegen from the IR if that's what you need. Hey, as a bonus, you don't even have to switch to C#.
Indeed. I gained that just because I'm a nut for learning. Professionally, I have only very rarely needed to use some of the more advanced features.
Why is there a circular dependency ? I think the reference goes away when the lambda goes away and call is fine. No?
Another thought as well -- would it be reasonable to use it as an *in-out* parameter? In other words, the function rather than *building* the map and returning it to you might want to *accumulate* into an existing map?
@alexeiz, [www.github.com/cortoproject](https://www.github.com/cortoproject)... looks like that uses bake for a real-world project with more than 30 packages. Couldn't find a single unwieldy JSON file
\&gt; I can confirm that. But at the same time we have (that I can remember) 3 places in our codebase where we want it vectorized out of 6457 for-loops. Almost all of the for loops we write in game development have side effects that mean they can't be vectorized. I guess maybe if you're writing stuff like particle systems where you just want a large amount of positions updated but that's not what we end up doing. I generally agree. The parts of the codebase that I work in that have to be vectorized on all platforms use macros that map to the different architectures' intrinsics. That's much easier now that PS4/XBOne are x86 though. Then there's also the code that could be vectorized but it isn't worth the time to manually do it. In these cases the compilers tend to do a quite good job nowadays, but you can't rely on it. I usually see that as a bonus since no one would have vectorized that code anyway. Another thing that's worth keeping in mind is that even if you make the compiler generate the instructions that you want it's not uncommon that you need different sets of instructions depending on the target hardware (e.g. load-hit-stores were a PITA on PS3/360). Writing them requires you to look at the bigger picture and shuffle stuff around.
I don't really like that C++20 designated initializers break the build if you write the fields in the wrong order, rather than just working.
Yes, that is the strongest argument made in the write-up. I think it could have been made from there. E.g. "can we continue to justify the complexity of using two languages?"
No, the pattern with the weak_ptr is slightly different. It doesn't keep it alive until the lambda is called, it allows you to check whether it's still alive when it is called. The first line of the lambda body should be calling .lock() on the weak_ptr and assigning that to a locally scoped shared_ptr. Then, if that shared_ptr is null return immediately, 'this' is no more. Otherwise the shared_ptr is kept alive for the full scope of the lambda body and it's safe to access 'this'.
Jesus I hate intrinsics and I've only ever worked with x86 code. 
The usual C++ shitstorm from game developers mentally stuck in C++98.
So you have no idea what a string class should do. Why do you want to write a new one?
&gt; It sounds great in theory but then you consider all the platforms they have to support, and it never quite works like the adverts. Well, their alternative is to maintain a backend for each and every platform...
Do you think that would be a good idea? 
I've stayed away from aggregate initialisation for this reason. I see people suggesting that you should consider class layout part of the API, but find that really annoying. If you're really insistent on using aggregate initialisation, then just write a constructor - you only need to do it once and then it's an obvious breaking change when you tweak members later. There are many reasons to reorder class members (eg memory packing, hot/cold, logical grouping for debugger watch windows) and it'd be super annoying to have to adjust a ton of aggregate initialisation calls each time.
I tried doing some stuff with Unity's Jobs/ECS a while back (with "HPC#"). Some things I missed dearly were destructors and templates. C++'s type system really feels vastly superior to C#'s and as a result "HPC#" felt really bare-bones and hacky. It didn't help that their NativeContainer classes lacked much needed funtionality either, though maybe they have expanded on that now. I really like what they are doing with Jobs and ECS, but there were many occasions when I was working with it when I just thought to myself that C++ would be such a great fit for it. I absolutely agree with him regarding the tooling though. C++ tooling honestly feels really crippling when compared to C#'s tooling and I really hope that this is something that will be significantly improved for C++ in the near future.
I don't understand the modern C++ aversion to for or while loops. They are easy, obvious, everyone understands them, you can see in the debugger where you are in the loop at any time easily, and at least for me with my code, it means I can easily see the previous and next objects in the loop easily in the debugger and such because I have the index. And you can easily do pre- or post-check variations, and break out while easily remembering which element you were on when you ended. It also means I can use enums as indices for strictly typed and named indexes as well, so I can see I'm on the Goober'th element of the list. If it's not an indexed collection then obviously I have to use other means. Or if I'm dealing with a collection polymorphically. But, otherwise, for and while loops are just fine with me. &amp;#x200B;
I'm no expert but shouldn't you use iterators for the later case?
Not always. But it can happen by inadvertence, even indirectly. struct A { std::vector&lt;std::function&lt;void()&gt; m_Callbacks; }; struct B { A m_a; }; struct C : public std::enable_shared_from_this&lt;C&gt; { B m_b; C() { m_b.m_a.m_Callbacks.emplace_back( [self = std::shared_from_this(this)] () { }); } }; int main() { auto c = std::make_shared&lt;C&gt;(); } Here is an example where `c` indirectly holds a `shared_ptr` reference on itself, and so `c` is never destructed, unless to clear manually the callbacks table.
i'm curious to hear more about your motivation - what's missing from existing classes?
Output iterators probably would be the "C++y" (whatever that means) way of dealing with this, but honestly I also think there are limits to how much that actually improves things. At some point there's a YAGNI principle that you'll hit, and "I want to support a map that doesn't have an STL-map-like interface" is very possibly beyond that. (That said, my work's code base has multiple C++ maps that don't have a STL-map-like interface...) It also limits what you can do, although now we're getting even *further* into edge cases of what you'll need from your data structure. For example, suppose the function wants to be able to consult the map as it's building it -- now you need something beyond an output iterator. Finally, if you take this argument to the extreme, then even the "I'll return a `map`" design is bad, because what if you want a different kind of map? Really you should use an output iterator even in that case as well! But again, in 90% of cases that's overdesigning, making both that function and *uses* of that function more complex to support a scenario that you'll never use.
Is there a shortage of string classes?
For real simple, here's an example: I ask people to code the pre- and post-fix plusplus operators in cpp (`i++` versus `++i`). I say not to worry if you forget the exact syntax to do operator overloading, I'll correct that part, just pretend you need to implement it from scratch for a simple integer type. Like three lines of code for each one. I also write my own simple code operating on pointers and ask them to tell me what's what at various points in the execution, and if they see anything wrong or weird they'd like to fix before they start answering. For slightly longer code problems, I like doing that during a phone screen. We use a website where we see what we write, and just walk through it. Easier with a keyboard. Still, all the things I ask anyone to write or fill in in C or C++ are really, really elementary stuff, like the stuff you learn in your introductory class(es). Basic pointer math, how arguments are passed to functions, dynamic versus static allocation, pound-defines for register access (for embedded work), that sort of thing. While "real simple" is indeed subjective, I ask only basics and only ones directly applicable to the job being hired for. If someone cannot do basic pointer math in C they are not getting the job, so it's fair enough to ask them that. I wouldn't ask anything tricky or unusual that they wouldn't run into countless times in the first three hours of coding on their first full day of work.
Ah that's quite reasonable. Still, I don't think YAGNI applies so much here, since using output iterators for doesn't seem to be much more work than hard-coding the type. I may be wrong though.
I think this is a good article, and describes very well a sensible decision made by Unity given their specific constraints. However, it seems clear that (and I know the article doesn't suggest this, but) this isn't really a solution suitable for the majority of game devs who are already frustrated with C++. The subset of C# they're using is much like the subset of C++ many game devs adopt right now to wrangle the constrains of game development. Switching languages is a **big** undertaking, especially if you already have a catalogue libraries and legacy code, so if the game dev community as a whole decides to move to a new language it will have to be well worth the cost of switching. My vote for a new language goes to Jonathan Blow's Jai language - not released yet, but hopefully soon!
Why?? Multiple reasons. But primarily a class for fixed length string. Yes, \`std::array&lt;char, N&gt;\` exists, but it is not convenient.
I'm guessing this was put in to allow for implementations that pad capacity() to make full use of the block size given by the allocator. It should at least guarantee that the resulting capacity() is no more than you would get from calling resize() on a new vector with the same size().
You can add the constructors when you add the extra variable. You don't need to add it in advance. (In practice I use aggregate initialisation only for tightly-scoped classes, where all the uses are close to the point of definition. For a shared class I think it's worth writing the accessors.)
But only in some cases, i.e. Named Return Value Optimization (NRVO) is not guaranteed to take place.
What you ask is basically screening, and I fully approve those kind of interviews. Those just check that you can code and understand what you are doing. And props to you for giving a workstation to the candidate - it makes whole process a lot easier. Just don't ask them to implement heapsort using pen and paper) 
Return by value is better if you use a modern C++ standard and a good compiler. With the ref arg you won’t be able to make the map variable `const`. I prefer to think about correctness first, ignoring the urge to optimize prematurely.
It forces you to use iterator syntax rather than map syntax (think `m[key]` is a nice, readable syntax? too bad!), and makes you use a more complicated type `std::insert_iterator&lt;std::map&lt;my_key, my_value&gt;&gt;` instead of `std::map&lt;my_key,my_value&gt;`) at the very least. And so far hasn't even brought you any value, I'd argue, because the real benefit of that design comes from accepting different output iterator types. But now you're talking about turning a function into a function template, so now you have to deal with worse physical code orginization, compile time bloat, object file size bloat, far worse IDE support for code completion and such; all the drawbacks of templates. The cost will usually be small if you compare apples to apples (either a non-template `map` to one with an explicit `insert_iterator` instantiation, or a templated one with the map type templated to the iterator type), but so will the benefits. BTW, I'll also point out that if you want to `emplace` into the map, there's no `std::emplace_iterator`, and I'm not sure that even makes sense to exist.
Code like: T&amp; fast(T&amp; t) { return t; } is scary though. Easy to get dangling references.
It would be an excellent idea to have it as an option via a compiler switch.
Most people don't know that `pkg-config` exists, thus they think libraries are hard.
Qt's QString
I'd rely on copy elision by default, but passing a reference can avoid allocations in some cases. For example: while (condition()) { std::vector&lt;int&gt; v = get_v(); use(v); } versus: std::vector&lt;int&gt; v; while (condition()) { v.clear(); get_v(v); use(v); } The first one will always allocate memory each time around the loop. The second one will often reuse the memory already allocated. However, this is a micro-optimisation that makes the code less clear, so I'd need to justify the change, eg with measured performance data. (In fact the first would probably be written: while (condition()) use(get_v()); so 2 lines instead of 6. Yes, I am counting the braces. I don't like needless clutter.)
Thanks! updated.
If you can write your library as header only, then the equivalent .cpp+.hpp version doesn't need any complicated build setup. You'd just have to compile all cpp files as part of your project (that's effectively what you are doing anyway with your merged file approach) with the benefit of your library files staying readable and - depending on implementation details - faster compile times.
**Company:** [RaySearch Laboratories](https://www.raysearchlabs.com/) **Type:** Full time **Description** RaySearch develops state of the art software for radiation treatment and care. We are recruiting C++ developers to join our 150 person strong development department in central Stockholm, Sweden. As a RaySearch C++ developer you will be part of an important project, developing the treatment planning system RayStation, which is used by clinics all over the world to treat cancer patients. Your focus will be on developing sustainable software, ensuring high code quality and great engineering practices. In your everyday work, you continuously contribute to good overall software design with the goal to achieve a highly structured large-scale software product. We believe that candidates have * An interest in quality C++ development at scale. * 3-10+ years of experience in an academic or industry environment. * MSc or more in computational science, engineering physics, or similar. * Fluency in either English or Swedish is required **Location:** Stockholm, Sweden. Fluency either English or Swedish is required. **Remote:** No **Visa Sponsorship:** No **Technologies:** * C++14, towards C++17. * Visual Studio, boost, google test, ReSharper C++ including clang checkers, Cuda. * Algorithms and core software are implemented in C++ and the application layers in C#/.NET. **Contact:** Apply at out site, [C++ developer? Fight Cancer with code!](https://raysearchlabs.workbuster.com/jobs/56074-undefined?ref=direct-e-452992) Also feel free to PM me. **About RaySearch laboratories:** RaySearch grows and today we are almost 300 colleagues. At RaySearch we are proud to go to work every day because together we get to create innovative software products that we know makes a vital difference in the whole world. We believe that it’s crucial that our employees love what they do for us to keep growing. We encourage a healthy work-life balance because we know that’s the only way to long-term success. We believe in investing in our people and offer great staff benefits, a modern office environment, flexible hours and regular afterwork and activities. For **junior positions,** also have [a look here](https://translate.google.com/translate?hl=sv?sl=sv&amp;tl=en&amp;u=https%3A//www.raysearchlabs.com/career/vacancies/last-datateknikit-fight-cancer-with-code/). We also have other positions (CM, IT, C#, WPF, TypeScript, ...) at [www.raysearchlabs.com/career](https://www.raysearchlabs.com/career) More, [About RaySearch Laboratories](https://www.raysearchlabs.com/About-RaySearch).
&gt; It's not uncommon to have a hook in your version control that runs the code formatting. There's two schools of thought on this one: either reformat the file automatically and check that in, or just do a check to see that the format is correct and disallow checkin if it fails. Work with your team to decide which of these two is best for your situation. In my project, we use both: - a client-side commit hook will automatically generate (and apply) a `reformat.patch` file as part of the commit, and notify the user when it applies something, leaving the user to check the `reformat.patch`. - CI will check that the patch is correctly formatted, and reject incorrectly formatted patches. The combination works *really* well.
None of those points are specific to header only vs traditional libraries.
Boost.Beast has a static_string class.
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/acjf3r/unity_devs_thoughts_on_cs_place_at_unity/ed92ici/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This was my surprise as well. If the performance of a piece of code is so important that it *needs* to be vectorized, then... why not vectorize it from the get go rather than hope the compiler will? Whether doing "ad-hoc" with an abstraction specific to the problem at hand, or leveraging a more extensive library, it seems like the obvious thing to do.
Do you check every time that the compiler doesn't replace integer addition with a looped increment/decrement? The standard doesn't prevent that either. Why are you checking shrink to fit and not that? Shrink to fit was left open to permit compilers to use block allocating vectors and "round" allocation sizes. 
This reads like "I already came up with a (wrong, but pleasing to me) answer, now I'm going to contort like crazy to justify it" logic.
&gt;The unit test would only save you when the code change is made and then the unit test fails. In that case the developer(s) could go find all references to the structure (in this example) and correct it. Yes, this is the entire point of unit testing: to warn programmers when an API's behavior has changed in some critical manner, either intentionally or unintentionally. &gt;What if the developer updates the test case when the code change is made? If the programmer changes the unit test, then by definition, *they must be aware that they're changing the API's contract*. At that point, it's entirely on them if they fail to heed the warning the unit test has given them. There's no real way for someone to claim "Oh, I didn't realize it was a breaking API change" if they had to change the unit test for it to continue working.
Hey reviewers \*asked\* for a silly name. Ask, and I shall deliver.
Also, at least in the case of std::string, shrink\_to\_fit() might do nothing below the SSO threshold. I really don't get the problem either. No major stdlib implementation would ever not free as much memory as is reasonably possible, and and impl that did otherwise likely has bigger problems.
That's changing the semantics though. If you want to guarantee that the objects remains alive, then you have to pass in a strong reference. If you're okay with the object disappearing before the operation can commence, then a weak reference is ideal. I think both have their place, depending on the circumstances. As you pointed out, if you store the lamba in the object itself, then obviously you do need to use a weak reference, since the lifetime of the two objects are then intrinsically tied together.
Since `pkg-config` is not a thing on most Windows toolchains, this is a useless observation. 
It kind of is in some standard library implementations for debug iterators. But, one can't really design an API on that can they? 
Is it not possible to write a set of canary unit-tests that verifies these properties, and then have them fail the build if it doesn't pass when you upgrade any component in the toolchain? Or is the problem that the compilers may be affected by surrounding code in such a way that is would pass the unit-test testing for the issue, but the compiler would generate the undesired code for the production code due to code in context? For the vectorization issue the OP mentions I had the impression that this was the problem, and I can definitely sympathize...
Yep. For a full-time hire we'll probably do one or two phone screens and then a full day of interviews, so we have people asking to code some basics, we have people asking to talk architecture, people asking to talk about previous work, and people wanting to do more "does this person fit in our team" type interviews. We go through it all. Pen and paper coding sucks, IMO free-form whiteboard coding should be at most five lines per problem, preferably just two or three. And never a question strictly of syntax, I always say to write the concepts so if syntax gets in the way then write pseudocode instead. But I have met people who talk the talk but can't write or debug code for shit. So we gotta make sure they can. Vice versa, I've met people who seemingly can write some code but are entirely big-picture-clueless, and we're hiring engineers, not code monkeys coding to spec, so we need people who understand the architecture of what they're doing as well.
But isn't it true that in general Fortran compilers are better at vectorization because (1) the language is simpler, (2) word-class support for arrays (vectors, matrices, tensors), and (3) better "knowledge" whether arrays alias? Concerning (3): sometimes in C you only get good vectorization of functions that accept arrays as pointers whenever you use the __restrict__ keyword. And isn't it true that the Rust borrow checker can potentially prove whether arrays alias so that in principle Rust code can vectorize better than C/C++?
Wow, Thanks.. Much closer to what I was thinking.. 
There are many applications where a fixed-size string would be nice to have. I have one very simple such class based on boost. It falls back on a boost::static_vector or a std::vector depending on its max size. My string type is not compatible with std::string, however.
I am not sure I follow. There are no changes in public API (just like there are none in debug implementations) except if you want to allow using iterator.container() in your own code. But even then it would be optional.
We check in the format file in the root of our project and then manually control the version of clang-format per platform. We have to turn off auto-update for the clang-format extension we use on Windows, and on Linux we set the explicit path to clang-format-6.0 (or whatever) in the VS Code settings. There are still a few differences between Windows and Linux (it may be because of clang build version differences). When formatting differences crop up between developers, we start looking for who has a different version set up. The small team of 10 or fewer so it's not hard to figure it out.
If this is a real concern to you, you should build a test to verify it.
Where they're making their mistake is C# doesn't provide enough control over memory layout to really achieve true high performance. Vectorization is great. Know what's better? Fewer cache misses.
Geez, are constructors evil now, too? Or am I missing something? I mean, you can have more than one constructor, and use that to provide backwards compatibility by defaulting of new values (and generally different setup) in the old constructor. I don't see how that's some kind of horrible compromise or anything, and it retains more compile type safety, it would seem to me. If the API is fairly small, and/or it also needs to change, you can provide public wrappers around internal implementations, which has even more benefits (such as vastly reduced rebuilds because details are internal) and allow for various versions of an interface to the outside world that can adapt as required for compatibility. The bulk of it can be inlined stuff for minimal overhead, while retaining all of the benefits. &amp;#x200B;
This thread had some good questions which were hard to address in a single comment. I wrote a blog post which more thoroughly describes how bake works, and what makes it different: [https://medium.com/@cortoproject/a-closer-look-at-bake-a-tool-that-makes-building-c-c-code-effortless-b2e0409fad8f](https://medium.com/@cortoproject/a-closer-look-at-bake-a-tool-that-makes-building-c-c-code-effortless-b2e0409fad8f)
"I see people suggesting that you should consider class layout part of the API" Wow, what happened to encapsulation? I thought the last thing you want to be part of the API is the internal representation of the data. &amp;#x200B;
This blog does a better job at explaining some of the bake features that make it different from CMake: [https://medium.com/@cortoproject/a-closer-look-at-bake-a-tool-that-makes-building-c-c-code-effortless-b2e0409fad8f](https://medium.com/@cortoproject/a-closer-look-at-bake-a-tool-that-makes-building-c-c-code-effortless-b2e0409fad8f)
&gt;http://design.ros2.org/articles/build\_tool.html This is interesting, as the project for which bake was initially used had a similar structure as ROS, where a single application could rely on lots of small (nested) packages. Both did it so that people could collaboratively work on multiple packages. It will be interesting to see if colcon will be adopted outside of ROS.
Bake has a feature called "interactive builds" that let you do this. The feature is highlighted in this blog: [https://medium.com/@cortoproject/a-closer-look-at-bake-a-tool-that-makes-building-c-c-code-effortless-b2e0409fad8f](https://medium.com/@cortoproject/a-closer-look-at-bake-a-tool-that-makes-building-c-c-code-effortless-b2e0409fad8f)
most people don't bother to *add* it, you mean.
Sure, that is exactly what I implied. I just wanted to emphasize that if you want to keep it alive until callback is called, there might be no other option.
&gt; Rust doesn't have to beat C++ by performing better in benchmarks. That's a strange caveat...
Here is a quick implementation: http://coliru.stacked-crooked.com/a/bec7da13824a0139 template&lt;class T&gt; struct tag_t {}; template&lt;class D, class Sig&gt; struct callable_base; template&lt;class D, class R, class...Args&gt; struct callable_base&lt;D, R(Args...)&gt; { R operator()(Args...args)const { return pfunc(get_pvoid(), std::forward&lt;Args&gt;(args)...); } template&lt;class F&gt; explicit callable_base( tag_t&lt;F&gt; ): pfunc([]( void* ptr, Args&amp;&amp;...args)-&gt;R { return (*static_cast&lt;F*&gt;(ptr))(std::forward&lt;Args&gt;(args)...); }) {} callable_base()=default; callable_base(callable_base const&amp;)=default; callable_base&amp; operator=(callable_base const&amp;)=default; private: R(*pfunc)(void*, Args&amp;&amp;...) = nullptr; void* get_pvoid() const { return static_cast&lt;D const*&gt;(this)-&gt;pvoid(); } }; template&lt;class D, class...Args&gt; struct callable_base&lt;D, void(Args...)&gt; { void operator()(Args...args)const { pfunc(get_pvoid(), std::forward&lt;Args&gt;(args)...); } template&lt;class F&gt; explicit callable_base( tag_t&lt;F&gt; ): pfunc([]( void* ptr, Args&amp;&amp;...args)-&gt;void { (*static_cast&lt;F*&gt;(ptr))(std::forward&lt;Args&gt;(args)...); }) {} private: void(*pfunc)(void*, Args&amp;&amp;...) = nullptr; void* get_pvoid() const { return static_cast&lt;D const*&gt;(this)-&gt;pvoid(); } }; template&lt;class D, class...Sigs&gt; struct callable_bases: callable_base&lt;D, Sigs&gt;... { using callable_base&lt;D, Sigs&gt;::operator()...; template&lt;class F&gt; explicit callable_bases(tag_t&lt;F&gt; tag): callable_base&lt;D, Sigs&gt;( tag )... {} }; struct callable_view_storage { void* pvoid() const { return state; } explicit operator bool() const { return state; } callable_view_storage()=default; callable_view_storage(callable_view_storage const&amp;)=default; callable_view_storage&amp; operator=(callable_view_storage const&amp;)=default; explicit callable_view_storage(void* ptr):state(ptr) {} private: void* state = nullptr; }; template&lt;class F, class Sig&gt; struct invoke_test; template&lt;class F, class R, class...Args&gt; struct invoke_test&lt;F, R(Args...)&gt;: std::is_invocable_r&lt;R, F, Args...&gt; {}; template&lt;class F, class...Sigs&gt; using all_invokable = std::integral_constant&lt;bool, (invoke_test&lt;F, Sigs&gt;{} &amp;&amp; ...)&gt;; template&lt;class...Sigs&gt; struct function_view: public callable_view_storage, public callable_bases&lt;function_view&lt;Sigs...&gt;, Sigs...&gt; { using callable_bases&lt;function_view&lt;Sigs...&gt;, Sigs...&gt;::operator(); template&lt;class F, std::enable_if_t&lt; all_invokable&lt; decltype(*std::addressof(std::declval&lt;F&amp;&gt;())), Sigs... &gt;{}, bool &gt; = true &gt; function_view( F&amp;&amp; f ): callable_view_storage(std::addressof(f)), callable_bases&lt;function_view&lt;Sigs...&gt;, Sigs...&gt;( tag_t&lt;std::remove_reference_t&lt;decltype(*std::addressof(std::declval&lt;F&amp;&gt;()))&gt;&gt;{} ) {} }; 
So you are basically saying, don't do that because it can cause circular dependency in case of a bad design? Sorry I don't buy it.
 &gt;If the performance of a piece of code is so important that it *needs* to be vectorized, then... why not vectorize it from the get go rather than hope the compiler will? Apparently it was easier for the authors to create their own (sub-) language and compiler frontend than learning how to use intrinsics. I'm sort of mystified as well. 
Nope. I don't say it's a bad practice, I say be careful with such design. 
The concrete objections to C++ in this article are (as best as I can tell): 1. Vectorization is tricky 2. Tools are not great at showing what assembly will be emitted for a certain block of code. 3. Thread safety 4. Bounds checking There's a couple vague objections beyond this, with references to C# being better for unspecified reasons, but that doesn't give us anything to work with. The authors' solution is to throw out C++, create their own subset of C#, and write their own optimizing frontend to it. This appears to me to be way overkill. It may make sense for the Unity Devs to do this simply because they're doing a lot of such work in C# otherwise, but it's a mistake for them to generalize from their experience as a C# engine developer (which is what Unity is) to C++ as a whole. It's also a bit aggravating since they're doing an apples to oranges comparison between vanilla C++ and their creation of essentially a DSL with tooling for it. A valid comparison would be comparing Burst against someone adding a pragma or compiler flag to Clang, let's say, that would do what they want. I've worked with vectorization before, and it seems that approach would have been a lot less effort, and wouldn't require discarding rather important things like classes and templates. Absent their completely reasonable desire to make everything in-house C#, their approach seems unreasonable. 
I agree. Author could mention that in couple words in the article. 
Clearly you haven’t read the paper on geo-recombinant value parameters as an influx accelerator. It’s platform-dependent, of course.
For static-analysis, Qt Creator (and others I think) has them integrated in real time as you type your code. It's really neat. It gets a bit slow as a file nears 500+ lines in my experience, but that's a good sign that you probably should split it anyway. We also have cppcheck and various clang checks run as part of the hourly builds, but it just produces a report somewhere that are often never read. Tests in debug also fail in case of a sanitiser error (at least asan/lsan, not sure ubsan, I'd need to check). Lastly individual developers sometimes run those/other tools like valgrind manually, but there's no process for this. For formatting, it's a bit more difficult as people quickly gets touchy about it. We finally managed to have an astyle format file after heated debates about what should be inside. However, no one pushed hard enough to decide when it should be used (git hook, server side, ...), and whether we should reformat repos first with the usual associated issues, or just do it along but then it breaks uniformity for repos that currently follow a different style. Currently, most people have their ide format on save with the astyle file, but nothing is enforced. Code reviews fix the rest.
How does that fix the remove_if problem? 
OH, yeh, it's all starting to make sense now. I was using outflux accellerators. Doh!
No one's going to mention that there's no such thing as `std::shared_from_this`..?
I really think they just saw an opportunity to take control of code gen and consolidate into C#. He says they have experience with IL, maybe he means CIL specifically, which is higher level and LLVM IR, so it just makes sense. 
It's funny because for all the noise about Rust's safety guarantees, C/C++'s const is a better way to specify strong immutability guarantees, vs an immutable binding to a mutable object (yes I know the safety is more about lifetimes and memory safety).
Is no one going to mention the fact that there's no such thing as `std::shared_from_this`?
Boost.text https://tzlaine.github.io/text/doc/html/index.html Boost.Text is composed of three main layers: * The string layer * The Unicode layer * The text layer There are a couple of assorted bits that were necessary or useful to have around when implementing various parts of Boost.Text: segmented_vector and trie/trie_map/trie_set. **The string Layer** The types in this layer are encoding-agnostic. Together, they form an ecosystem of types that consitutes "a better std::string". The types in this layer are: string, string_view, repeated_string_view, unencoded_rope, and unencoded_rope_view. **The Unicode Layer** This layer provides a few Unicode-related utility types, but is primarily comprised of the Unicode algorithms. These algorithms are done in the style of the standard algorithms, with range-friendly interfaces. There are algorithms for these Unicode operations: * UTF-8 &lt;-&gt; UTF-16, UTF-8 &lt;-&gt; UTF-32 * Normalization, including the four Unicode normalization forms, plus the FCC form from Unicode Technical Note #5 * Text segmentation (line breaks, word breaks, etc.) * Case mapping (to_upper(), is_lower(), etc.) * Collation, including tailoring using the LDML syntax and serialization of collation tables * Collation-aware searching, including caseless searching * The Unicode Bidirectional Algorithm, for laying out text that includes both left-to-right and right-to-left text These algorithms are independent of the other two layers; it is possible to use Boost.Text as a Unicode library without using the either of the string or text layers. **The text Layer** This layer is built on top of the Unicode layer. Its types encode text as UTF-8, and maintain FCC normalization. Much of their implementation is done in terms of the algorithms from the Unicode layer. The types in this layer are: text, text_view, rope, and rope_view. **The Assorted Bits** Finally, there are some items that I wrote in the process of implementing everything else, that rise to the level of general utility. First is segmented_vector. This is a discontiguous sequence of T, for which insertions anywhere in the sequence are cheap, with very cheap copies provided via a copy-on-write mechanism. It is a generalization of unencoded_rope for arbitrary T. The remaining assorted types are trie, trie_map, and trie_set. The first of these is a trie that is not a valid C++ container. The latter two are analogous to std::map and std::set, respectively, just built on a trie instead of a binary tree. 
Hi. I'm an experienced American C++ developer and entrepreneur. I'm interested in partnering with a small company or individual. I'm willing to spend 16 hours/week for six months on your project if we use my [code generator](https://github.com/Ebenezer-group/onwards) as part of the project. There's [more info here](http://webEbenezer.net/about.html).
My point wasn't "let's make Rust generate better machine code than GCC and Clang" so much as to make rustc generate machine on par with GCC/Clang and make optimizing it less obtuse than C++ through tooling and libraries. And it was pointed out in the comments that rustc was better at autovectorization with a few tweaks. 
Yes, Fortran is usually way better as you say. I just wanted to list all major languages that take SIMD into account, besides C and C++.
It’s interesting to know the Unity team is moving in this direction but I can hardly accept their decision and "success" as a proof for their claims. First reason is that the anecdotal hardship to get a hot loop to vectorize is poorly substantiated. While it is true that there is no way to express that failure to vectorize should be a compilation error, working on that specific requirement seems like a very reasonable project to undertake hacking on clang. Plus the article fails to mention attemtping reliable ways to get the vectorization to happen as pointed out in other comments. Second reason is the claim that the HPC# subset of both the C# core language and standard library, in addition to their own library components makes it easier to express solutions compared to C++ is not substantiated at all. They do touch on the tooling subject as being an advantage, but that’s a different subject. Third reason is the obvious bias towards C#, both in the article and in the Unity team. Considering Unity wants its users to program with C#, there is an obvious benefit to a single workflow throughout the lauers of Unity. Also, the C# expertise they have could very well surpass the C++ expertise available in the team and cpuld skew the results regarding the claims of getting better performance with HPC#. Fourth and last reason is that the article is not upfront about their results and seems to focus on evangelizing an anti-C++ personal preference. The only downside regarding their choices that gets mentioned is the one implicit to the notion of the HPC# subset. This article reads just like a marketing push. The additional cost of maintaining compilers and not getting as much benefit from sharing tools with the larger community is not even mentioned. The trap of believing you’ll do better alone on your own is one that led many companies to radically downsize or outright fail in the long run. What’s the plan for Unity’s team to avoid that trap? Overall, this article is mostly interesting for anyone interested about Unity in general and where that platform is headed. In regards witg what language to choose to do HPC, there is nowhere near enough evidence to counterbalance confirmation bias.
Off-topic. Consider r/ProgrammerHumor but please don't post this kind of thing here again.
The real world benefit is that programmers can depend upon the implementation to actually be effective instead of either having to check it as the thread OP or writing their own implementation. It's good that the major implementations implement it as expected but you would have to validate that assumption on each one since they aren't always consistent in QoI. "This function may do nothing" is a particularly weak specification for a function that programs may depend on to keep memory usage within bounds. 
I don't see anything relevant here.
Minor grumble: clickbait headline phrasing makes me grind my teeth :-/
Indeed. You might even be led to think all of these things happened while building traditional libraries, if you were to read carefully.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aco7eu/best_resources_to_learn_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I wonder what proportion of C++ coding is done by game developers vs everyone else?
Suggesting that all Windows developers being unable to use a library that uses pkg-config is the fault of the developer rather than the library author is asinine. For one thing, many developers in large organizations don't even have a choice. If I add it, suddenly my dev-ops organization needs to support it on our CI servers. If I'm building my own library that is going to be used by others downstream, I've just put that burden on them. At this point, my attitude is that I don't add a build dependency unless I can add a CMake or Python script that automatically makes it available to the rest of my build. You might as well have said "all developers should all move to Linux"
They address the memory layout (somewhat) by providing a bunch of "native" types/structs for you to use with guaranteed performance characteristics.
Uh... IIRC Boost does have Boost.Locale which supposedly completely wraps ICU (C++) UnicodeStrings. Has that been (morally) abandoned or is that approach very disliked or something? 
Just me or C++ snippet is much readable than Rust one? 
Only my own file and low-level networking libraries. but by the end i had quite a nice web-serving framework.
The article was not trying to speak for the generic c++ as a whole case as far as I could tell (some examples): Title: "C++, C# and Unity" "Let’s talk about the place C++ will have at Unity:" "Yes. C# is a very natural choice that comes with a lot of nice benefits for Unity:" Is there something I missed? 
I've been meaning to check vcpkg out, I've heard others say it was good.
it would have fixed it by way of having a std::really_really_remove function that would at the end call erase on the container that owns the iterator. 
We’re usually targeting 5 different instruction set architectures, with at least one going obsolete and another new one showing up every year. Maintaining all those assembly-level versions of every loop in a major code is daunting, although some codes that spend most of their time in just one loop and are well funded do this
Do you look up the API for the `+` operator for every data type before you use it, or do you have some pre-conceptions about what it might/should do? This affects future development of a suite of related functions. For example if you knew `begin()`, it's reasonable to guess `end()`, if you know `copy()` it's reasonable to guess `move()`. What if a related `decrement_range()` were named `ichi()` because the Japanese character looks like `-`? Can you guess `ichi()` from `iota()`?
Can the downvoter explain where my statement is incorrect?
Noob!
If you allow aggregate initialization for your types then the class layout is already part of your API.
Well, yeh, hence why I was complaining that it's a bad idea because it pretty much tinkles in the general direction of encapsulation, which is one of the most fundamental concepts of C++. And, though maybe I'm misunderstanding it, it seems to me that it reduces compile time safety, which is one of the dwindling reasons these days not to just use another language. &amp;#x200B;
Multi-arch libraries such as [libsimdpp](https://github.com/p12tic/libsimdpp) targets x86/x86-64/PowerPC/Mips/ARM and their individual SIMD variants so the cost/overhead of maintaining multi-arch variants at an individual function or procedure isn't really an issue either given the many ways C++ allows you to abstract away(with little to no overhead) stuff like that. I guess they just really, really, really want to stay in C# so much that they're willing to make a compiler-derivative to do something that C++ already has? This whole thing is weird to me.
in a normal case I prefer to return. returning is also the [cpp core guidelines recommendation](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Rf-out) for functions. I like returning because its easier for me when calling the function: i can just call your function, and i dont have to set up a map before the call. I also have the option to declare the map as const when its returned, while as an in/out parameter i must make the map non const. There is also more wondering for me with an inout param. are you expecting my map in a certain state? are you adding/removing from the map? are you reassigning the map? So for me, returning can be easier to think about. the scenario i would consider not returning (already mentioned in the comments) is maybe you want to reuse the map capacity over multiple calls. In that case using an inout param is really nice. I think there's also the option to heap allocate the map and return a unique_ptr. although I dont have much experience trying that option.
&gt; Do you look up the API for the + operator for every data type before you use it, yes I do. And I believe you do as well because I want to believe you're better than that as a developer. operator overloading can be fairly contentious specifically because it can unexpectedly hide things. Anyone who thinks they can look over random code in C++ that's using custom types and not check to see exactly what operator+ is doing will cause a lot of harm in your codebase. Even your example of end(), I would suggest anyone not familiar with end() to look it up so that they understand that end() returns 1 past the last element. That's not something you're going to glean from the word end(). I'm honestly flabbergasted that you typed that out thinking you were showing something ridiculous. 
Why not just have a function that takes a container and calls remove_if? You can even write it yourself. template&lt;typename C, typename P&gt; void erase_if(C&amp; c, P p) { c.erase(std::remove_if(begin(c), end(c)), end(c)); } But then, it's also a one liner, so it's probably not necessary. But either way, making every single iterator carry an extra 8 bytes all of the time just for this is probably undesirable. One thing: this won't work for arrays. Also, this doesn't work for arbitrary ranges. Actually, now that I've done this, remove_if looks even better than it did before because it works for everything. 
I didn't downvote you, but can you explain how your statement is correct? Rust has const too, in fact things are const by default there. How is C++ better here?
&gt; I don't rely on it, but it would help inform speculation about implementation details at a glance. I fail to see how that is even remotely possible.
The llvm project uses some custom string types : https://llvm.org/docs/ProgrammersManual.html#string-like-containers
The fact that boost.locale wraps ICU inherently limits it somewhat. I don't have any major complaints with it as a nice C++ API for ICU, but ICU is a very heavyweight dependency and the wrapper layer imposes some overhead that is occasionally a problem.
I know it's not a guarantee, so I don't rely on it. However, while I don't rely on it, if I am aware it was written in good faith in the context of this conversation I may decide to accept it as additional information. What exactly do you fail to see?
I kinda don't hate it when it's clearly tongue-in-cheek. I'll never click actual clickbait out of sheer hate.
? https://en.cppreference.com/w/cpp/memory/enable_shared_from_this/shared_from_this
Thank you for pointing out that these are not acedemics. It really annoys me that so many engineers in the games industry think that they're the only ones who ship important software using C++. However, I will say that there are games industry people involved, and what happens is, they get involved, and then, get educated. People tend to change their minds once they realise that the problems claimed by the games industry are not unique, yet overblown. But due to the toxic environment of many games studios, they don't spread the knowledge, instead they keep their heads down and keep quiet. I know this from personal experience. I left the industry partly because of type of attitude that turned up on Twitter and Reddit over Christmas. 
The fix is to not do allocators the stupid way, which passing an allocator to everything that needs memory. A better design is to use a stack based tagging system where a tag is pushed onto a thread local stack that the memory allocator then reads the top of in order to categorise the memory. You can even pass other parameters this way because it should generally be rare enough that it's overall a smaller burden. 
An immutable object in C/C++, mutating it is a compiler error and casting to non-const is undefined: const int i = 5; An immutable type in C/C++, it can only be instantiated and then read. Mutating its members is a compiler error and casting its members to non-const is undefined: typedef struct { const int i; const int j; } X; X g_x = {1, 2}; int main() { auto imm = std::unique_ptr&lt;X&gt;{new X{7, 8}}; // imm-&gt;i = imm-&gt;i + 1; ERROR // need to make new object from old object auto cpy = std::unique_ptr&lt;X&gt;{new X{imm-&gt;i+1, imm-&gt;j}}; std::cout &lt;&lt; cpy-&gt;i &lt;&lt; std::endl; } Rust only has compile time constants: fn main() { const CONSTVAR:u32 = 100; //const var:Box&lt;u32&gt; = Box::new(5); ERROR let a = Box::new(5); let mut a = a; // wow. such immutable. *a = 6; println!("{}", a); } &amp;#x200B;
I fail to see how const in the header tells you anything at all. It's completely useless. Example: void foo(const int i) { // Some code here .. int x = i; while(x--) { // Other code here... } } What exactly did you get from having const i in the header? 
I think they're just saying it's not enough information to make any meaningful assumptions about what is the function actually does. At least not adding anything more than the function name itself.
As I understand it, they use all the regular C# tooling for things like debugging. That's why it's a win.
In C#, `struct`s are laid out sequentially in memory, just like in C++. How is that "not enough control"?
&gt; In regards with what language to choose to do HPC, there is nowhere near enough evidence to counterbalance confirmation bias. What makes you think the article is trying to convince you that you should use C# for all your HPC needs?
Oh, okay, I misunderstood you. I thought you somehow wanted to use aggregate initialization without exposing your class internals, which is nonsensical. Carry on!
&gt; Get clang and write your own codegen from the IR if that's what you need. How is that any better than what they did? Using (subset of) C# means you get better tooling, better compilation times and better safety.
&gt; But this solution is completely independent from the input language. It's not. The advantages of C# here are: * Better tooling. * Better compilation times. * Better safety.
I would never expose my internals. My parents raised me better than that. Well, if you paid me $20 of course, but that's different. &amp;#x200B;
In that example, nothing, it's an example of a mistake. In my theoretical case I would be able to trust that somebody would remove the const before doing that.
The debug iterators have the added benefit of being a total performance disaster, to the point that sometimes debug builds are unusable. And maybe it's my style, but I haven't found them terribly useful.
But what if it's not a mistake? It might be genuinely nice to have the i as const for the top half of the function. I suppose I could make a const x at the top and use that, then the i at the bottom, but geez that's getting crazy.
I have had the unfortunate experience of working with developers who would simply comment out tests whenever their changes made one fail who were then surprised to discover that they broke things. I have no idea what you do with people like that.
Is it common to do AST analysis in production code?
To be pedantic, if he writes a constructor, he’s no longer using aggregate initialization. 
This also prevents default initialization which might be beneficial 
I mean, theoretically almost anything can be a breaking change. You added a new overload of an existing function? Oops, somebody was depending on being able to capture it as a function pointer. You added a completely new function to an existing class? Oops, somebody was using SFINAE to detect its non-existence. You can call it evil or stupid or whatever, but at some point it just comes down to making a subjective judgement about what's generally agreed to be safe to change and what isn't, and that judgement is different for different codebases. (The STL might consider adding an overload to be a breaking change, while application code almost never would.) Given that OP is coming at this from a position of "should we even use aggregate init?", we can probably assume that their codebase does not already use it, in which case changing class layout is currently a reasonable thing for people to do. It's only unsafe *because* aggregate init is a thing. 
I think they meant changing the semantic usage.
If you need the parameter to behave two different ways you might consider two different functions, but I haven't implied the information gleaned from the _const_ decorator is infallible. It's a hint. I _might_ take the hint for a function I believe to be basically trivial and I would look at the function definition for anything else.
I’ve generally found it worth it enough to enable using them in existing code, since they’re a pretty widely supported extension (ex: GCC + Clang).
&gt; I have no idea what you do with people like that. Unfortunately, if you're not a person of influence at such a company, there's little you really *can* do about such things. Otherwise, the answer would be: code reviews, education, and mentoring. I don't blame programmers for not knowing things. We all start out that way, and I'm still learning new things all the time, even after writing C++ code for decades. But I do blame a company for failing to set up an environment where programmers can help each other improve their craft.
What do you mean by near equivalence?
How about the Join Us section at the end of the article trying to capitalize on the arguments provided in favor of replacing C++ with Burst?
I have no idea of advance c# tooling, are they really advanced ? Can you give some examples ? 
&gt; Is there something I missed? The OP suggested the article is pretty damning of C++. https://old.reddit.com/r/cpp/comments/acjf3r/unity_devs_thoughts_on_cs_place_at_unity/ed8ccsr/
I just dropped some runtime from 2 minutes to 2 seconds by making the entire workload fit in L3 cache, even though I used a worse-complexity algorithm.
I'm guessing something like: struct Base {}; struct Derived : Base {}; struct Derived2 : Derived {}; Base* x = new Derived2; dynamic_cast&lt;Derived*&gt;(x); // not nullptr 
Then that doesn't sound like a feature parity replacement in another way :)
No, even the success case needs to walk the tree to prove that the cast is unambiguously valid in some cases. For example: https://wandbox.org/permlink/vbiRZqcJIuqxenZg #include &lt;assert.h&gt; #include &lt;stdio.h&gt; struct Mixin {}; struct Base { virtual ~Base() {} }; struct Derived1 : virtual Base, Mixin {}; struct Derived2 : virtual Base {}; struct Fails : virtual Base, Derived1, Mixin {}; struct Succeeds : virtual Base, Derived2, Mixin {}; int main() { Base* f = new Fails; Base* s = new Succeeds; assert(!dynamic_cast&lt;Mixin*&gt;(f)); assert(dynamic_cast&lt;Mixin*&gt;(s)); puts("Test done."); } 
We're kind of past the one out there stage. There's basically 3 standard libraries that cover basically everything, including I suspect every single platform a typical game would target.
You can write unit tests surprisingly easily. You just write a custom allocator, and use it in the vector and in that way you can see exactly when the vector is taking or returning memory.
A small fraction.
Dart
The logic applies only to C# for Unity because somebody who loved Mono convinced them a decade ago to use it, so they built all their infrastructure around it and used the infrastructure being built up with Roslyn and .Net core and it turned out to be a pretty solid bet. The logic applies to many other gamedevs because it applies to Unity. Also, a bunch of game programmers who started getting into it seriously ~10 years ago started with C# because of XNA. If C++11 hadn't come out with all the marketing push and conferences, the generational shift for gamedev would have been exclusively about C#. I don't even like C# all that much (I just dealt with a bunch of irritating databinding crap today working on a tool for design). It just has a few qualities that C++ sorely needs IMO.
When Roslyn came out it enabled some really impressive code navigation features in Visual Studio: https://docs.microsoft.com/en-us/visualstudio/ide/find-code-changes-and-other-history-with-codelens?view=vs-2017 Here's an implementation of the C# equivalent of `-Wswitch-enum` using it: https://github.com/abjennings/EnumAnalyzer/blob/master/EnumAnalyzer/EnumAnalyzer/DiagnosticAnalyzer.cs I don't know why the C# compiler doesn't have this built in, but some rando on the internet was able to throw this together with a relatively small amount of code and now it's a thing that anybody can add to their sln. It's just easier to do this stuff for C#.
The intro text of eastl is hilarious: "EASTL is used for apps. Apps can use EASTL. It implements a containers. A linked-list is an example of a container. This is a template library. We're not going to explain templates to you. That is all."
Are their really no compiler macros or annotation to hint to the compiler we want vectorization?
It is actually kind of weird that a language that claims "not to leave any space for another system language underneath" does not have built-in types for common CPU types like float4 (i.e. 4 32-bit floats packed together), and their associated operations. That would be a lot easier to use than intrinsics.
How is this well written article a 'shitstorm'?
&gt; I guess they just really, really, really want to stay in C++ so much that they're willing to make a compiler-derivative to do something that C already has? This is what mid-90's game developers used to say.
How is this any different from using C's subset of C++?
Same happened to C when game developers were forced to move away from Assembly, followed up latter on by the introduction C++ SDKs on the PS.
It is also dangerous because such statements tend to gather a weight of their own. Today it is a QoI issue; tomorrow it may very well be considered a great optimisation opportunity to just do nothing. After all, those words are enshrined in the standard. And if you think this is mad, this is exactly what happened to UB, which also started in the exact same way, and has grown into something completely different.
Because Unity already has a couple of ex-Insomniac Games helping them, including Mike Acton. Also in an way using HPC# as C#'s subset, it is hardly different from the typical C++'s C subset that game devs tend to use.
Where does [Tera](http://terralang.org/) stand in the game dev world? I'm aware of it's existence but I haven't had the time to dig into it at all.
There’s [CsString](https://github.com/copperspice/cs_string) from the CopperSpice people. They had a [talk bout it](https://www.youtube.com/watch?v=ysh2B6ZgNXk) at CppCon 2017. In a nutshell, it’s their attempt to do UTF encoded strings properly. I’ve never used in in a real project, but from what I’ve seen and played around with, its a promising approach. Btw, food for though: A string class that has no concept of encoding, like `std::string`, is that a string class or a vector of bytes in disguise?
&gt; you can always move the object to a new, mutable binding, either through assignment or passing it to a function that takes a mutable owned binding. You cannot pass a nonmutable binding as a mutable reference to a function, that's a compile time error. To sum up, C++ has a const_cast that results in undefined behavior, Rust has an explicit very limited form of const_cast that has a defined behavior and a limited scope. Although I don't like the ability to change mutability of a binding, I still fail to see how according to you C++ is safer here.
&gt;So why would you prefer a raw loop rather than iota? Because I have half a dozen people working in the same office who don't follow this group. I'm happy to accept iota as a historical mistake, one more doesn't really matter. But here's a question for everyone who's defended iota: would you be ok with giving up on the idea that function names in the C++ standard library should be normal English words? If you accept Greek letters, would it also be ok to accept, for example, German words or Chinese letters? 
Game development has been one of the major application areas of C++ for many years. [2018 ISO C++ survey](https://isocpp.org/files/papers/CppDevSurvey-2018-02-summary.pdf). [2015 JetBrains survey](https://blog.jetbrains.com/rscpp/page/3/).
If you are willing to accept C as a comparable language, we had a [posting](https://www.reddit.com/r/cpp/comments/a9nktu/c11_way_of_initializing_integers/eclzvsc) the other day where somebody compared the compilation speed of C and C++. I'll just quote the relevant part here: \&gt; Good example is Chromium - 40 minutes to build 6.7mln loc on i9 vs Linux kernel 39 seconds to build 25 mln loc on the same CPU. That's around 230x faster...
There are multiple implementations of GSL. The only other implementation I can name off-hand is [GSL-Lite](https://github.com/martinmoene/gsl-lite) but I'm sure there are more.
i'd say they are a lot easier to use than bit shifts and masks, i enjoy having them (even though you have to pay attention to how the bits are packed). But yes the standard would be simpler by taking them away, but the same is true for almost everything (templates, lambdas, auto, ...). The C++ standard is not meant to be simple it is meant to offer all the tools a programmer expects from a programming language. And since backwards compatibility (no braking changes) is priority number 1 for C++ simplifying the standard by removing anything will never happen.
If I remember correctly, gsl-lite started as an independent implementation but now uses big parts of MS/GSL (as seen in the copyright and in the code). I also found [this one](https://gitlab.com/mattia.basaglia/Melanolib/blob/master/include/melanolib/utils/gsl.hpp) but it seems to be quite outdated: `array_view` was replaced by `span`, `Final_action` was renamed `final_action`. 
I would completely ignore GSL and any guidelines that recommend using it.
Bitfields are just a tool for minimizing memory used by your state, while (mostly) keeping syntax and semantics of regular member objects. They are not a tool for accessing specific bits in hardware registers.
This is actually the point I was trying to get at. I don’t consider C a comparable language to C++, because there are abstractions that C++ expresses as part of the language that you have to manually write the code out for with C. Your comparison suggests (as I suspected) that the compilers are still slow to take those abstractions and generate the code you desired. If you give the compiler a lot more hints (write more code yourself) then the compiler has less work to do and it’s all much faster. I’m amazed the Linux kernel compiles that fast. Seriously impressed. I still thought it was a couple-of-hours type endeavour.
Yes but what is it?
 Having no guarantee over auto vectorization is a totally valid complaint, there really needs to be a way to enforce it, otherwise it is a useless compiler feature(I don't care that it isn't part of the language yadda yadda). The rest about C# is just Unity specific, outside of them, I doubt many gamedevs are terribly excited to use C# for engine programming. Also, at least for me, I prefer intrinsics to auto vectorization, and its perfectly possibly to write portable intrinsics wrappers in C++. &amp;#x200B;
Why?
And going over this again, this time with my BS detector enabled... A bit of googling suggests that building the Linux kernel takes far longer than 39 seconds. Times reported differ widely, with the lowest I can find about 8 minutes on a powerful machine but usually reported as a couple of hours. Moreover, it is not clear if it is really 25 million lines of code; Phoronix mentions this number but also says this includes documentation. Anyway, I'm still ready to believe there is a big difference between C and C++ (it matches my own, 25 years out of date experience). I suspect reasons include that C++ has far more code in headers, a much more complex lookup mechanism for names, and instantiation and compilation of (the same) templates in numerous translation units. 
The guidelines themselves are an incomplete, jumbled mess. No suprise that the library mirrors that.
I'm using Doxygen to produce the XML database of my public interfaces, and then some custom XSLT to turn that into Boost docs. For example this page is generated from that workflow: https://www.boost.org/doc/libs/1_69_0/libs/beast/doc/html/beast/ref/boost__beast__http__async_read/overload1.html Does Doxygen now support modern C++? Template type aliases and the like? constexpr? Has anyone heard of Doxypress?
My simpler point is that in C++, once a data member/variable is declared const, as far as the language is concerned, you are not *allowed* to change it. Regardless of whether is it runtime initialized or compile time constant. C++ const_cast resulting in undefined behavior is because the compiler cannot check every use, e.g. within a linked library, and for all intents and purposes, it is programmer error and frowned upon to do it in invalid circumstances. In rust this you are indeed allowed to change it as per of the language. I don’t have a problem with this, as it simplifies many issues of “const poisoning”. This is very cut and dry, to me. These are different philosophies, and a common source of confusion when trying to explain one in terms of the other. However, given the above, (and that I have more experience in C++ :P) the concept of “this object shall never be modified” is much stronger in C++, as Rust is more concerned about *shared* mutability vs pure immutability. You can probably guess which camp I was I during the mutpocalypse. You’re right on the copy. That was an oversight in my rushed example. My stronger point was
Contracts in C++20 are nice tho
and Windows ?
It's not really hindsight when designated initializers have been in C for almost 20 years
There habve been others, but without a proper specification they can do little other than trying to stay bug per bug compatible with Microsoft's implementation (and there where lots if bugs in the beginning). Also the api has been changing quite frequently for years, so replacing one implementation with a different one in non-trivial code-bases wasn't realistic. All that knowledge is 1-2 years old. Things might have improved in the meantime. 
IMO implementations of GSL are not meant to be anywhere near serious, however, are good to study the idioms and best practises.
Have you seen [this](http://bit.ly/runtime-compilation-alternatives) list?
Uh, yes, of course it does, I'm documenting a C++11 codebase with it -- see the images and links in the article for a proof ;) ... though I had to contribute a few patches to have things like template aliases, enum classes etc. exposed in XML, the rest like noexcept and override/final I have to extract from the function signatures directly in the XML because Doxygen doesn't care about these. I know about Doxypress, the problem is that I would need to re-apply all those XML export patches I submitted to Doxygen to have the same feature set. And so far that wasn't worth the bother for me.
Because it's full of clunky half-baked utilities that nobody actually uses.
He explicitly states "no" but there is [blink](https://github.com/crosire/blink)
IIRC in one of his first two Effective C++ books, Scott Meyers also wrote that developers could *consider* using a vector-of-char instead of std::string... I don't know what C++ experts think about that suggestion these days though.
Awesome, I'll dig into that next time I'm waiting for a compile :)
Exactly. Probably one day, but not in the nearest future.
That doesn't seem true. The guidelines often refer to using gsl alternatives in some cases. And it goes even so far that clang-tidy has the same messages that refer to `gsl_` functions. This implies I should be able to use it in production software.. Because how should I know that clang-tidy is referring to half baked "study" libraries? That's really not good :/. 
They are not evil. But for a class with only loosely coupled data members it's just boilerplate code. Nothing more. The constructor does not maintain an invariat between the data members. (Well in the context of this discussion and as you said it also provides a layer of abstraction between the data members and the initialization call). It's boilerplate you have to write everytime you just want a bag of data. nothing special. But this is a burden. On the plus side the constructor makes the usage of the class a bit easier for the points already stated. And therefore i started this discussion to get some insight in what other devs use and think about it.
Yes, I saw your images and links they look very nice and I am excited to improve my documentation!
They have some use, I'd guess, but between being ill-specified and being limited to built-in integral types... they're not exactly stellar indeed. I personally prefer to use a library abstraction, offering stronger typing, rather than bit-fields directly. Something like: `BitTuple&lt;32, BitField&lt;Type1, 4&gt;, BitField&lt;Type2, 8&gt;, ...&gt;`. This allows me to both (1) have a known memory layout, allowing hardware interaction if I so wish and (2) have strong types, rather than built-in integrals. As far as I am concerned... bitfields are a prototype that remains in limbo to this day.
You are mixing different arguments here. My main gripe with all the talk from the unity guys is that most of their arguments don't really hold up that well if you look a little deeper. If you look at their [Burst User Guide](https://docs.unity3d.com/Packages/com.unity.burst@0.2/manual/index.html#memory-aliasing-and-noalias) you will actually find a lot of advise on how to write your burst enabled c# code to make sure the compiler can actually vectorize. Convincing their compiler to vectorize does not look all that easy either. Sure, using the same compiler everywhere is not their only goal, but many of their other arguments are pretty sketchy as well. Lets look at yours: &gt; - Better tooling. Are you sure about that? You can't just look at all the c# tooling to work out which tooling is better for this actual use case. Remember that c# is not build for performance critical code, so you will not find much tooling or libraries for this in their existing ecosystem. Even worse: Burst is not a full .net-IL compiler. It only understands a very narrow subset of the standard. How much of the existing tooling actually works with burst? I'm not even sure they have a debugger for it. From skimming the documentation I guess the only way is to disable the burst compiler (which is very easy to do), run the code through the normal .net jit and use the standard .net debugger. Remember all the talk about slow c++ debug builds? I don't think running the .net-IL jit with a debugger attached is going to be any faster. Slow debugging of c# code seems to be a common complaint for the unity engine. &gt; - Better compilation times. Probably their best argument. But still... I'm not sure I can really take this seriously. While everybody complains about compilation speed, I have yet to see a sane build environment in the games industry - doesn't mean those don't exist... They just don't seem to be very common. They are usually using the slowest compiler I know as their lead platform, often on under-powered hardware driven by non-optimal build systems (often developed in-house) and often without any form of distributed compilation. I know that requiring real workstations and a build cluster to make bigger c++ project bearable is not optimal. But at the end of the day, game engines just are not that large - so the build time problem isn't actually insurmountable for them in most cases. Many posts of the unity guys (and other gamedevs) in the last week all talk about how c++ is going in the wrong direction - while the committee is actually hard at work making c++ compilation faster. &gt; - Better safety. Again a very generic argument just taken from c# proper. I don't think this holds for unity Burst today. They only support a very small subset of IL code. As far as I can tell, even things like foreach or references do not work. So you are forced into unsafe c# (and unchecked pointers) even quicker than in c++. Pretty much nothing of the .net library is supported, and neither is garbage collection or any other form of memory management, beside the stack. They are giving a lot of reasons why they are moving away from c++... But I think they are missing the most important one: unity is full of people who would rather write code in c# than c++. That's why they have a large c# code base to begin with. And that's why it makes a lot of sense for them to write many of their performance critical sections in c#, right next to all their non critical logic code. The point is: these are not good arguments against c++ in general. If you don't like c# as much as they do, their system will not buy you much at all. 
&gt; Having no guarantee over auto vectorization is a totally valid complaint That's a compiler problem, not a language one though. [Clangs support for working with vectorized loops](https://llvm.org/docs/Vectorizers.html) looks pretty usable to me. Not sure about other compilers.
My question was not if C++ was meant to be simple, we all know it is not, but if this specific tool is really expected or used, cause in my experience in different industries it seems not widely adopted and I've never felt it wqs useful for me. 
Parts of the GSL are kinda outdated, IIRC parts of it are for owning/non-owning pointers but now we got smart pointers. But tbh, i got no idea if clang checks for those.
Boost::hana::string https://www.boost.org/doc/libs/1_68_0/libs/hana/doc/html/structboost_1_1hana_1_1string.html
probably because most hardware people are more C programmers than C++ programmers. Most of the people i worked with (electronics engineers) are programming C in C++ and feel very comfortable with pointers, memory management and bit wise operations. Most of those things probably come from a lack of C++ knowledge and working with sometimes really old tools and legacy code. People just tend to stick to what they know and bit-fields aren't exactly the first thing you can find in a C++ books (i'm pretty sure most books i red barely mention them if at all). But they are great for all kind of headers (files, communication protocols, ...) If you get a definition that says something like 0-3 | File ID 4-13 | User ID 14-17 | Compression Level 17-22 | Codec It's just nice to be able to read them out of memory without doing tons of bit shifts. Or the other way round it's awesome to just being able to assign values and save the file.
they are use in the firmware of the tools of the company I work for. All the memory layout is a giant struct containing union of a bit field and an unsogned int of the same size.
Well to be honest i don't feel. I'm C first, quite the oppositr and i'm quite comfortable with C++ templates smart pointers containers boost... Still... 
You are downvoted by people who haven't actually tried it. I wasted a lot of time on it until removing it from the codebase. The idea is valid, but the implementations are half-baked.
I don't think anything around tooling is easier in c++. The fact remains that c as well as c++ are languages that are inherently hostile to optimizations, due to the power they give the user. That power means in turn that an optimizer can make very few assumptions about code it doesn't see and whole program optimization is difficult. At the same time, they are also languages in which it is easy to write low level bugs (you can make a mistake in the implementation of your algorithm in any language, but memory bugs of all sorts and UB in general is pretty specific to c++). So if they can use a safer language (c#) and have even more control over the code gen in the important areas thanks to their tight coupling between library, language and compiler that seems like a better value proposition to me.
I’m not a game dev so this has no immediate impact on me. Looks like they are hoping to get in on some of that sweet sweet vendor lock in! Don’t write your business (game) logic in portable c++. Use our proprietary extension that is tightly integrated into making apps that run only on unity... in exchange you might get better performance and compilation speed today. Ironic they’re leveraging a newly open sourced language that traces its origins from another company’s vendor lock in push.
It's interesting. The GSL states that it is meant to help you think about how you want your code to look in 5 years, 10 years.... However, it's also a living document, subject to change. An anology to building would be something like the GSL is like a building code. Microsoft's implementation, then would be similar to a hardware store, selling lumber and components, which are to code (but apparently selling other things as well). Now consider yourself as a house builder, you design blueprints around the code, you start building the house, deciding you'll be using pre-cut lumber from your to-code hardware store. It takes you some time to complete your project. The building code changes, as does what the hardware store sells. Now, you have two choices, to rebuild to the home according to new code, or to continue building against the old building codes. If you choose the latter, now you're behind, you're no longer following 'guideline codes', and you risk your house not being up to code. If you choose the former, you risk getting caught in a loop where you're chasing the building codes, and constantly having to buy new material, use different materials, etc. You exceed your budget and the house never finishes. In my opinion, we have to be cogniscent that the guidelines are just that. They are guidelines, they're not commandments. It's our job as developers, to use our brains and understand the though process behind the rules. We have to understand the problems these ideas are solving. When we're choosing a library, we have to select that just like we would any other third-party library. Cautiously. In summary, there's a reason there is written building codes, we have them because they document things people have learned over the ages. You can choose to build a home that isn't to code, but it might be dangerous, and have leaky pipes, though it could still function as a home. These building codes change over time, but we've still got houses built in the 1800s. I agree there is some messiness to it all, but that's life. I guarantee that everyone can learn *something* from the GSL text. As for choosing an implementation library, treat it as you would any other third-party library. Because that's what it is.
Visual Studio + Resharper gives a very smooth coding experience with good refactoring and diagnostics. Nothing I've tried for C++ has even come close.
The granularity of the unit tests are important and should try and enforce that tests fail at each level where this class could break something when it is used. Say we change class A and have a test harness around it then those tests should break which is all well and good. The person who breaks it then fixes the tests. We then have Class B that utilizes class A. The change in A has caused some undesired regression in B now. We should have another test around B that catches this. If you try and keep this up and make good use of things like interfaces and dependency injection then changes to classes should not be allowed to regress the system without being caught in all the places they are used.
/u/Pragmatician &gt;half-baked Would you two care to give any examples of something in GSL that's half baked and explain why it's half baked? I use final_action (very rarely), narrow/narrow_cast (sometimes), not_null (sometimes), and Ensures/Expects (a lot). And I appreciate those, but I'm really open to hearing constructive negative feedback on the library. I know some things they mention in the core guidelines are not in GSL which can be confusing/dissapointing but are there serious issues with what's already been implemented? Note: I'm just talking about the Microsoft implementation.
To me, the documentation (either in the core guidelines or in Microsoft's implementation) a very limited/incomplete. Does anyone have a good guide/documentation replacement or alternative?
&gt; However, it's also a living document, subject to change. The problem is not the change (after all, in GSL, there are types that are now in the standard), the problem is that some things change (the implementation) while others don't (the documentation). If GSL was considered a sandbox for good practice or an eternal experiment, I would agree with all you say. But it was presented as something complementary to the standard library that would ease some usages and diagnostics. It's not a random library, it's the only library of the C++ Foundation. In fact, at the moment, my conclusion is : pick what you need from GSL and reimplement it in your own library (anyway, I already have a span-like type and others). You loose the few diagnostics (like those of clang-tidy), but you gain time. 
I think of GSL as basically just MS GSL, since, like you said, there is no consistent documentation to allign different implementations. I also think of the MS implementation as the GSL documentation. Ik that's not right but idk another option until there's actual documentation. That said, IMO, there is still some useful stuff in MS GSL. Some things like span and not_null I think are more oriented at trying to make old style code (raw ptrs, ptr + length interfaces) more safe/clear. Then some stuff like Ensures/Expects and span mirroring some future C++ features. Also stuff to help with complier warnings like you said (e.g. narrow/narrow_cast) Maybe look at just MS GSL, and adopt what you like from there, if that implementation looks good to you.
And it should be noted that their motives might not be exactly pure as they're selling a C# game dev ecosystem. 
&gt; not_null What is the use case of not_null ? If i want a pointer that is guaranteed to be valid is use a reference instead. If the pointer comes from somewhere else i assert that it is not null. &gt; Ensures/Expects Aren't this macros simply wrappers around assert ? 
I see what you're saying. I agree with you. I guess I was misunderstanding, also misrepresenting my thoughts. I think the core guidelines, is a very good reference, there is knowledge to be had there. I think the implementation by Microsoft of the GSL, should be treated as any other third party library. Therefor given it is built off of a living document it is subject to not always align with that document. In fact, I think you're decision to craft your own is the right one. I think treating the guidelines as a Bible will I fact cause more harm than good. Using a library that is in flux, will also be a pain. Crafting your own, allows you to follow guidelines, pick and choose and adapt at your pace. Thank you for your response as well. I appreciate that you read my reply.
Looks interesting If you want to make sure that your function is patchable the gcc attributes ms_hook_prologue,noclone,noinline and an asm (""); in the function body is useful. The problem with all the hotpatching/reload tools seems to be the transfer of state, especially if the memory layout of a function or struct changes
Do you plan to keep a separate length, or use a NUL-terminated string? I ask because for small values of `N`, using `std::size_t` as a length type causes a large overhead. It's possible to use template meta-programming to compute the smallest unsigned integral in which `N` fits, which reduces this overhead, but still has some overhead... and when N &lt;= 8 or N &lt;= 16, there are efficient CPU instructions to get `strlen` (on x86). Or do you plan to have two flavors maybe? Also, what of the encoding? Neutral? UTF-8?
I think that was mostly because std::string wasn't guaranteed to be stored contiguously in memory prior to C++11, so for interacting old C-APIs it was better to use a vector of chars.
That still all makes sense. The code-in-headers and multiple template compilation are the parts that really bug me with C++. I know these are hard problems to solve, particularly with parallel compilation split across translation units/multiple calls to the compiler, but I would really like to think they could be solved. I guess in my own code (which is heavily templated) it would help a lot. I had hoped modules were going to help, there is a video hanging around from 2017 (CppCon I think, can’t remember) showing massive compile speed up times with modules. But then the most recent posts I saw here on reddit said they weren’t going to fix anything and weren’t worth the effort 🤷‍♂️ 
Cheating is undefined behavior in C and C++ so we can assume it's impossible.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/acvutl/how_do_i_approach_this_project_need_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
You can also check out this paper proposing a std::basic_fixed_string: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0259r0.pdf 
Took a break from work (flight simulation industry) and spent some time for self study and playing around with new technology. It is work in progress, but I thought I might as well post an update here :)
Never being null is not the only difference between references and pointers. Another important difference is that you can't rebind references. So they are not interchangeable.
Hot code reload is very useful for game development, maybe a few people over at r/gamedev might want to have a look at this. Can't hurt to post there, too.
That hasn't been my experience, at least with TI C2000 (spent the last 5+ years on the platform). Bitfields are used extensively for registers in their libraries. We use bitfields quite often for serial messages where minimizing message length is imperative. Every bit counts, pun intended!
I disagree vehemently with this sentiment. For one, structs are not functionally equivalent to a class, and misses many features. Passing structs invokes copies. Trying to optimize a C# application is just finding all the places where excessive copying is happening OR excessive loose heap allocations are happening. Having distinct value and reference types makes things "simpler" but is a huge concession in control.
At a glance I have no idea what this library does. It just says real time control, then immediately goes in to details about parent-child node architectures (wouldn't that be an oxymoron?) and tensors. 
And you would incur the performance cost of that safety. UB isnt some magic defect that the C++ standard just overlooked how to deal with (mostly). Different languages make different tradeoffs.
Sure, just [did it](https://www.reddit.com/r/gamedev/comments/acwfq2/is_anybody_interested_in_c_hot_reload_under_linux/)
The trade-off is: simpler standard versus a bunch of broken code. My vote is: not breaking code wins, hands down. What I find interesting is the randomness of the feature to take out. There's so many to choose from and this one isn't particularly disliked, I wouldn't think... 
Please don't use URL shorteners - they trigger the spam filter. I've manually approved your comment.
Yep, these attributes are useful, but I wanted to make it in the least intrusive way, so you just `add_subdirectory` and `target_link_libraries` it, and it just works with existing code. About state - yep, it's tricky, and the library tries to do its best on static variables, but the transfer of heap/stack allocated data is totally up to the programmer, I have no idea how to do it "uniformly"
Sure, thanks, will add it. About blink - afaiu jet-live works the same as blink, the only difference is it is windows only, and actually on windows you have some support from the compiler for such things (refer to `/hotpatch` and `/FUNCTIONPADMIN` flags). And also I don't know if blink does smth with dependency tracking. But generally it uses the same approach.
&gt; Here p is a reference to a const-qualified int. Is that int’s value constant, immutable, unchanging? No! Funny, I would say that this reference produces an immutable object, but not that the referenced object itself is immutable. Really not the same thing. It's a case of playing stupid games and winning stupid prizes, no?
Thanks. I've updated the naming and removed the learn-to-bike-with-tensorflow blog post for now. I hope that the [pendulum](https://oconomy.gitlab.io/page/post/pendulum/) example and [oconomy](https://oconomy.gitlab.io/page/post/oconomy/) post help to clarify what the library actually does.
reference\_wrapper to the rescue!
But we're not talking about regular C# here, we're talking about HPC#, which does not have classes in the first place. So yes, you're losing features like inheritance. But I (and the post I was replying to) was specifically talking about control over memory layout.
So you would need two different libraries to handle all three major desktop operating systems? dlsym/dlopen are _so_ similar to LoadLibrary/GetProcAddress that I don't see how it be _that_ hard to make a cross platform library.
The thing is `dlsym/dlopen` doesn't help you in this area, this api works only with **dynamic** symbols, so to implement proper "code reloading" you should parse program headers/sections which is similar, but kinda unique for each platform. So yes, for me as totally a non-windows user it is too hard to implement all these PE/COFF parsing and testing things for windows implementation. But ofc pull requests are welcome, I guess it should be not a big problem to add windows implementation since I've tried to make the code extensible. Create an issue please if you need a help with it.
The JUCE library has also its own string class! [https://docs.juce.com/master/classString.html](https://docs.juce.com/master/classString.html)
Huh? The `unique_ptr` and `shared_ptr` types were added in C++11. The first commit to the CppCoreGuidelines repo is from 2015. So you're saying as soon as the guidelines were released, they were already at least 4 years out of date?
They are often used also in games, when you optimize for cache misses. It's pretty handy to be able pack your data and still be able to use it without any extra unpacking code.
That's exactly the point :)
Probably i am missing parts of the reasoning or it is meant for compatibility, but e.g. `owner` is used to mark transfering ownership while new codebases usually can make use of smart pointers and old codebases also should move towards them where possible.
Well `std::bitset` could be used usually: you already know ahead of time how many bits you're gonna need, so you can quite easily specify how large the bitset is gonna be. This has some downsides too though, and it won't be as clear or as self-documenting as bitfields can be (as otherwise, you'd either want to say what bits of the bitset mean what or someone will have to identify this by seeing the code). I certainly don't think it should be removed from the standard though. Are there any ways it's holding us back from progress, or ways it's stopping us from improving the language? If not, leave it.
What I gathered from that is that (at a glance) is that this seems to schedule events and maybe it does some sort of physics simulation but I can't really tell. If it does schedule events, it makes me wonder how it is better than a simple game loop, if it simulates physics, it makes me wonder how it compares to other physics libraries. 
I'm also not really sure what problem this library solves 
I always take the approach that I'll write it once and maintain it for years or decades. So writing a little boilerplate is not remotely a bad trade-off if it provides even a little extra compile time safety and safer flexibility down the line. I also always write copy ctors and assignment operators, even if it's a trivial class that would have gotten them automatically generated. The reason being that, if I wait until I actually need them to write them, I (or someone else is) is going to write them with probably considerably less care, because we'll just be trying to get them done so that we can get back to the thing that now needs them and for which this is a distraction. You can easily optimize too much, or think too much, or over-engineer. But it's lot harder to argue that, at least on larger scale projects, that you can be too compile time safe. I guess it can be done, but I kind of doubt that any of us have ever been in danger of getting to that point really. Obviously if it's something smallish, it matters a lot less.
You can do the same with bitmasks, shifts, and bitwise operators, but bitmasks let you do the same things with code that closer represents the intent of the programmer. That's the main benefit I see. I like building viewers for old file formats, emulators, and embedded stuff where you might have a bunch of registers that have subfields. I'll often represent that with a union of an integer value and an anonymous struct containing the bitfields.
MFC CString
Isn't UB to use the union like that? 
The Guideline support library is that: a guideline. Kinda like a rule of thumb thing, I guess. And not to be treated as any more than that.
So... is Boost.Text still expected to be proposed to Boost? What's next?
Implementation-defined, I believe.
&gt; If in ... (and L142) you happen to misspell "executor_type" with, for example, "ececutor_type" ... Not sure I see how it would cause problems. You'd just give that type a different name. I believe if you used "executor_type" on both lines L139 and L142, everything would be OK. And if you misspelled it only on one of those lines, you'd get a compilation error. On another note, I believe I managed to fix the problem in asio-utp by replacing use of `std::function` for handlers with a [custom `handler` type](https://github.com/inetic/asio-utp/blob/master/include/utp/detail/handler.hpp#L9) which doesn't implement the `operator()(...)` but does implement `post` and `dispatch` methods which always use the correct `executor`.
Looks like it has an option to print out a "remark" if it fails, but doesn't say anything about failing the build. Also until MSVC/GCC support it, pretty much irrelevant.
&gt; I like aggregates. you can use them when you just need a "bag" of losely coupled data without any invariants between them. It's easy to reason about, If your "bag" is not really a bag, then *don't use it as a bag*. A string that is a name and a string that is a surname are two different strings, you can't juste expect to grab one of them from a bag and it be the one you want to. Use a constructor.
Theoretically you could use LIEF (https://github.com/lief-project/LIEF) for the binary parsing on various platforms.
I only took a quick look, but between the code and the blog posts on the pages there by OP it is a dynamic control system library. So, yes it schedules events and yes it can be used for physics simulations; however, the point of the simulations here is just to demo the functionality of the code. At the end of the day, I think this is supposed to be a real time control system library that is attached to an actual physical device. The examples they provide simulate the outputs/inputs, but if applied to something physical, inputs would come from sensors, the code would do its calculations, and the outputs would be articulated by a physical device. It would be the responsibility of a user to program the nodes needed to represent their physical system (it seems as though "nodes" correspond to the blocks in the block diagram representation of a physical system). &amp;nbsp; The intended audience seems to be people familiar with control systems engineering.
I liked the idea and just implemented it for one of our real-life projects. It doesnt work. It doesnt work because it leads to really confusing undo-redo-orgies that enrage the users and lead to very unexpected outcomes. Consider this: Let's say we have a single textfield and we always replace the entire content. #Traditional way 1. set to "A" 2. set to "B" 3. set to "C" Now if we undo twice, we will be back at "A". Redo twice and we will be back at "C". Undo twice and and set to "D", we lose some history and the new history looks like this: "A", "D". # Your no-loss way 1. set to "A" 2. set to "B" 3. set to "C" Undo twice, we are at "A" and the history looks like this: 1. set to "A" 2. set to "B" 3. set to "C" 4. undoaction: set to "B" 5. undoaction: set to "A" Now the problem: If the user hits "redo" as many times as he can he expects to be back at "C". But he's not, he's at "A" due to the undo-actions being tacked on. This is unacceptable from a UIX point of view and probably the reason why everyone uses the traditional way. Or did I miss something?
New codebase should still use raw pointers when they need a non-owning rebindable "reference" to something. I also never use reference members. The semantics are too strange and prone to UB. Much simpler to use a pointer. Same goes for const data members.
Probably yes, thanks for the link. LIEF looks interesting, but is too huge for my needs. I think its better to find some header-only parser like [ELFIO](https://github.com/serge1/ELFIO) one for each platforms rather than use 100+ `.cpp` files library
Sorry to not answering before. I didn't because I don't have a good grasp about what solarflare onload is. From the little I read since you asked this question I gather it is somehow gives you an interface to do network IO in userspace and somehow that also gives you a better latency. They write that their API is "standard posix", how does that work? Does one simply link to their library and use it as if it was using the system libs? If so, how would the linker not confuse the two? Or is is "posix _like_" API? Or something else? If it was the first option of the three, than I'd say that Asio already is such wrapper. I don't know how much overhead does Asio add. It's an interesting question, I've seen some benchmarks but did not pay _too_ much attention. If solarflare provides a "posix _like_" API, then one would probably indeed need to do a wrapper to use it in Asio. The nice thing about the `libutp` library that I use in `asio-utp` is that it doesn't actually do any IO on it's own. It's pretty much just a state machine and the IO is left to the `libutp` users to implement. In my case, for the IO I use Asio's UDP sockets. By this I'm trying to say that wrapping a "posix _like_" API would be a different situation to what I'm doing in `asio-utp`. In either case, the best answer I can give is that it would add the same amount of overhead as whatever Asio adds on top of the underlying IO primitives (whether it's BSD sockets, or windows sockets or something else).
&gt;i'd say they are a lot easier to use than bit shifts and masks, i enjoy having them (even though you have to pay attention to how the bits are packed). I feel like I'd enjoy doing those a lot more if there was a [[flag]] attribute similar to C#'s [Flag] attribute...
I'd also like to thank you for being the most helpful library dev I've ever talked to. You've answered many of my stupid questions in the discord :)
Like emptyel, I just mandate a specific version of clang-format. You can point Visual Studio at a specific version and you can have your scripts or editors search for the versioned binary name (e.g. clang-format-7). In most work projects (even on small teams) in my experience there has been strict requirements on tooling, down to specifying which IDE/version to use (for support reasons). &gt; My reason for asking is that different version of clang-format may change how it formats files from version to version, even if the configuration file is identical. clang-format can't even read .clang-format files (without error) from different versions much of the time in my experience. If you're using that tool, you have to specify a specific version and require everyone to use it specifically. This isn't really specific to clang-format, though. If you change compiler version, you might find language fixes or new warnings pop up and break the build. Likewise if you update a library dependency. Or change anything, really. Your environment configuration _is part of the code's build specification_. Version it just like you would a Makefile. If you want to support multiple versions of clang-format, you'll need to make sure CI is testing with multiple versions, and make sure your format configuration is written in such a way that both versions format identically. If users with wildly different dev environments is for some reason a real need, then _test all those environments_ in CI just like you test everything else.
Aren't bitfelds available in c too?
People that do not understand intrinsics will probably be good programing language designers! /sssssss
It's been like 2 years ago, so I'm not sure, but if I remember correctly, it was compiler incompatibility and bugs in string_span.
You can turn off the parts you don't use. In my experience, LIEF is superior to other libs because it is unit tested and fuzzed.
For C++, I use a union of BitField&lt;type, startBit, endBit&gt; members, and have BitField implement all of the math operators and do the shift+masks for me. The only member variable of each BitField is &lt;type&gt;, so they all share the same underlying variable due to the union. It may still technically be implementation-defined, but I feel it gives me more control than C-style bit packing, which can behave quite unexpectedly at times, and lets me do other fun things like having overlapping regions and alternate names for shared fields. The biggest use case I found was for [NES graphics chip emulation.](https://gitlab.com/higan/higan/blob/master/higan/fc/ppu/ppu.hpp#L50) It turns [absolutely horrendous bit-twiddling](https://wiki.nesdev.com/w/index.php/PPU_scrolling#Coarse_X_increment) into [vastly more readable code.](https://gitlab.com/higan/higan/blob/master/higan/fc/ppu/render.cpp#L108) In general, I don't use bit fields much because, even when I need individual values, I end up having to transform them anyway. For instance, an 8-bit I/O port register that holds a 6-bit tile data video RAM address and a 2-bit tile size. The 6-bits end up being the upper 6-bits of the address, so I still have to do value&lt;&lt;10 anyway, and the tile size means (8x8, 16x16, 32x32, 32x32 again), and so just accessing the raw bits isn't so great. So I either pre-transform them on the write assignment to separate variables, or I'll write functions that extract the bits I need out from the packed values and transform them for me, eg: vramAddress() { return (value &gt;&gt; 2) &lt;&lt; 10; } When it comes to processor flags (carry, negative, overflow, etc), I find that accessing individual flags is so much more common that it's better to just have them be separate bools, and whenever I need the bit-packed 8-bit flag register, I put it back together then: carry|negative&lt;&lt;1|overflow&lt;&lt;2|...; So unless it's embedded hardware with *extreme* resource constraints, it's usually easier to just keep regular variables for each field and transform when reading/writing to the bit-packed areas.
We keep our code on Github and have Jenkins do CI. Any branch, except for `master`, is subject to server-side formatting: running clang-format is the first step in our CI pipeline - if any source file changes due to reformatting, it's committed, pushed back to the original repository, and the current build is *aborted*. The commit triggers another build for the same branch, this time no files change due to reformatting (it was done in the previous commit) and the build proceeds normally. As a developer, you don't have to care about installing clang-format and keeping it up to date, formatting locally, git hooks, or failed formatting tests. The code is formatted unconditionally, always using the same version of clang-format (we control the version with a separate Dockerfile and can bump it whenever we like).
Have you tried the ref returns feature recently added to C#? I haven't, but I k ow it was introduced to alleviate the struct copy problem.
Okay I see. Half baked in terms of not being fully compatible and bug free. Obv thats something that can easily be a deal breaker. At least if you think the ideas are good, if all of the issues you faced were worked out, you would use it? last year Microsoft GSL released 2.0 with "numerous bug fixes" so hopefully your experience is better if you ever try again :p
Chunks of the Standard Library -- the STL in particular -- were most certainly designed by people who believe OO is bunk. http://www.stlport.org/resources/StepanovUSA.html
It's undefined behavior in C++. But then, unnamed structs aren't allowed at all.
Not so much "constructive negative feedback", but maybe some context: The gsl is intended as part a package that includes the core guidelines document and the compile-time code checkers. The idea (or one of the main ideas) is to "shrink" the C++ language to a (memory) safe subset, recognized and enforced by checkers, with the gsl providing elements to enhance this restricted subset of the language. The checkers, in particular the key "lifetimes" checker, were still a work in progress last time I checked. Without the lifetimes checker, elements like `span` (and `string_view`) are arguably dangerous "pointer hiding" objects [prone to use-after-free bugs](https://github.com/isocpp/CppCoreGuidelines/issues/1038). So in the meantime, [some feel](https://abseil.io/blog/20180531-regular-types) it prudent to mostly restrict the use of these types to function parameters only. (Even then, there's no guarantee right?) I'm sure many users aren't that concerned about the dangers, but presumably the designers were and intended that these elements would (ultimately) be used in conjunction with the associated safety enforcement tooling. The lifetime checker will at some point sufficiently enforce the intended safety restrictions, but those restrictions will be [somewhat draconian](https://github.com/duneroadrunner/misc/blob/master/201/8/Jul/implications%20of%20the%20lifetime%20checker%20restrictions.md) (akin to Rust). I think working around those restrictions while maintaining (memory) safety might call for [pointer](https://github.com/duneroadrunner/SaferCPlusPlus#norad-pointers)/reference and [dynamic container](https://github.com/duneroadrunner/SaferCPlusPlus#make_xscope_vector_size_change_lock_guard) types with efficient run-time safety mechanisms, and I think the gsl might eventually have to consider including those as well. (Shameless plug alert on the links). 
[TL;DR](https://external-preview.redd.it/6KXBnnAAlbCsV5A-4d23dS-FrxjNxyO5FGVMKIL_SCk.gif?width=400&amp;height=170&amp;s=16ae6ba4fe35567bc4edfd93ed09d1c1cc117c13)
This is quite literally perfect. I should have seen this sooner. I'm add it as a TLDR for any poor souls who stumble onto my site (giving credit where credit is due of course)
Man I keep wanting to really learn C++ but every time I come into this subreddit they convince me not to.
You can learn C++! Ack! I added some more context on HN. My point at the end is that the (relative) simplicity of C is better in an academic environment where you don't want to get lost in the weeds of the peculiarities of the language. I think C++ is great specifically for its peculiarities--it lets you do lots of awesome abstractions than span programming paradigms, compile-time programming, and all the low-level bits of C! Eric Niebler's talk at CppCon mentioned how the new ranges library even accelerates GPGPU programming in some cases through code fusion as compositional functions get combined together! &amp;#x200B; But it has to be something you accept early on, otherwise you'll be fighting the language. My point in my post was merely an acknowledgement of all that stuff that's unnecessary for early programmers.
TBH you don't even need to use anything but `struct`s in C++. You can be as C-like or as C++-like as you want. New C++ programmers will probably want to ease into the language. 
I hate these articles. Initialize your member variables in a constructor. That fixes all the stuff mentioned in the article except for `initializer_list`, which you should rarely need. If you do, just keep in mind that it can interfere with other constructors. Be explicit in what you write, and you'll be fine.
Solid use of memes for education
It’s most painful for the implementers of the compilers
Originally from here i think: https://mobile.twitter.com/timur_audio/status/1004017362381795329
Say I've got code like this: struct int_flags { union { struct { unsigned vblank:1; unsigned lcdstat:1; unsigned timer:1; unsigned serial:1; unsigned joypad:1; unsigned unused:3; }; uint8_t reg; }; }; What part is UB, when accessing the different fields? Why doesn't it trigger any warnings in any compilers I've tried it in? And why are the unnamed structs allowed?
but POD though.
Just take 5 seconds and write your damn constructor.
Syntax theme name please. 
I didn’t get what they were talking about in here today but maybe someday I will. 
He literally says this at the end of the article. His point is that c++ is a huge, complicated mess, and it's better to stick with the simpler C *if you're trying to learn systems programming stuff*, instead of getting bogged down in learning all this syntax. 
These edge-cases with initialization don't show up unless you don't bother to write sane defaults for your class's fields. 
Well, that's me not reading his epilogue. When you title your post "Initialization in C++ is Seriously Bonkers", then talk about "creating a frickin’ variable" and write stuff like "and to emphasize how many more… _features_ …C++ has compared to C", don't be surprised if people don't realize that "this post is (_mostly_) tongue-in-cheek ". Maybe put the epilogue in your prologue next time. The second comment posted here down below is from someone who says "Man I keep wanting to really learn C++ but every time I come into this subreddit they convince me not to." That _pisses me off_ and makes me write angry comments.
The whole point about solarflare is that it bypasses the linux kernel and the POSIX API (glibc). It manages the completion queues/DMA by itself directly against the card. 
I never use them. I just use bitmasks. And typically wrap up usage with tiny inline functions. If it wasn't needed for backwards compatibility, I'd just get rid of them.
I can't, because that's not POD.
Since C++11, as long as you provide a trivial default constructor, you can have other constructors.
&gt; why it's half baked? &gt; &gt; I use final_action [Bug #1](https://github.com/Microsoft/GSL/blob/master/include/gsl/gsl_util#L54), [Bug #2](https://github.com/Microsoft/GSL/blob/master/include/gsl/gsl_util#L56), [Bug #3](https://github.com/Microsoft/GSL/blob/master/include/gsl/gsl_util#L78) and [Bug #4](https://github.com/Microsoft/GSL/blob/master/include/gsl/gsl_util#L84) - unconditional noexcept. Calling std::move does not guarantee you're noexcept in those constructors. [Bug #5](https://github.com/Microsoft/GSL/blob/master/include/gsl/gsl_util#L66) - impossible to throw an exception when leaving the scope 'successfully'. With [SCOPE_SUCCESS](https://github.com/facebook/folly/blob/master/folly/ScopeGuard.h#L285) you can totally do this as it is not noexcept. [Bug #6](https://github.com/Microsoft/GSL/blob/master/include/gsl/gsl_util#L78) and [Bug #7](https://github.com/Microsoft/GSL/blob/master/include/gsl/gsl_util#L84) - missing [[nodiscard]]. It is easy to misuse: `finally([](){...})` will call the lambda immediately. Bug #8 - CTAD. [Bug #9](https://github.com/Microsoft/GSL/blob/master/include/gsl/gsl_util#L63) - this line should contain a very long comment explaining why this move-constructible class is not move-assignable. Bug #10 - does not distinguish between success and failure ([`SCOPE_FAIL`](https://github.com/facebook/folly/blob/master/folly/ScopeGuard.h#L279) and `SCOPE_SUCCESS` do). This `final_action` class is not a real solution to the problem, it is a toy example.
The thing is, humans make programming languages. The fact that there’s so many landmines to avoid to just “do the right thing” is a failure in the design of a language, and it should be criticized. If the single right way was truly that obvious, why not force all initialization through that mechanism?
&gt; C is better in an academic environment where you don’t want to get lost in the weeds of the peculiarities of the language Strongly disagree. Professionally, I’ve been involved in many low-level critical infrastructure projects (high performance, memory constraints, etc.) and it’s very common for such shops to eschew C++ for exactly that reason: needless complexity. A language with nuance and complexity isn’t necessarily something that’s attractive when you’re trying to write code that’s rock solid and maintainable/extensible by a large number of people. It can, in fact, be dangerous. 
By definition, a trivial constructor cannot be user-provided. And that's missing the main point: trivial constructors leave garbage spread across all the object's memory.
You are incorrect on both counts. A trivial default constructor for a `struct S` can be added with `S() = default` and a neither constructors (of any kind) nor (non-virtual) member functions have any effect on whether a struct is standard-layout or not.
“one mental stack level.” incredible. 
"There are only two kinds of languages: the ones people complain about and the ones nobody uses.". Don't be discouraged, C++ is a great tool for many problems and is very widely used. Also the language is very complex, but you can always picks parts which you like and stick to them.
Initialize your members where you declare them. Only initialize in the constructor if you need to override these default initializations.
“Cooking is bonkers, you can boil, broil, double boil, pan fry, stir fry, sauté, flambé, blanch, poach, sous-vide, bake,.. so why not start with making lunchables or a PB&amp;J or something?” /s
But it still misses the most important fact, which is that C is a small, but equally complicated (for entirely different reasons) language, and, frankly, if you're not veering off the main roads, even more of a mess. If you're trying to learn systems programming stuff, and you're not working in a platform that only has C (or C and mostly-archaic C++), you have three options. C, modern C++, and Rust. Maybe D, Fortran, or Julia in a few cases. Straight asm isn't going to cut it for anything as big as modern systems. C, lacking RAII, isn't going to be as easy to not blow yourself up with once you get to large scale systems, especially if there's concurrency and non-fixed resources. Yeah, it can be done, but there's a lot of reasons not to do it. The biggest one is that starting from C teaches some really atrociously bad habits that are very hard to unlearn.
That link just explains what I said. You cannot have an actual POD and ensure it gets initialized properly on the stack. Now, if trivially-copyable and is-standard-layout are enough, that's great.
I once heard from our programming teacher that one is truly not a programmer in languages like C or C++ until they have published their own String class.
I mean, my cooking is frequently just making basic-ass sandwiches.
C++ seems to be taking a beating as of late for some reason
A must read for anybody preaching uniform initialization nonsense. 
The problem is when some moron wants to use list initialization everywhere just because. 
the price of freedom.
as long as you don't implement crazy constructor overloads to structs you're probably fine.
Hmm, I'll take a look, thank you.
Because it is a gigantic ugly beast, i'd say that's a well established fact. I'm in a long love hate relationship with it and at this point i am just to invested to leave it. 
Can you provide a reason why not the latter? It has been my experience with NXP that it is the case.
This is also true for quite a lot of other non-SIMD operations that have been historically supported as basic operations in CPUs but not exposed in C or C++, such as add with carry, widening multiply, rotation, and overflow detection. The standards haven't provided abstractions for these operations, so you are either required to use intrinsics that vary widely between compilers and platforms or rely on the compiler to recognize idioms for the operations. As the C++ Performance Benchmarks show, the latter is surprisingly fragile. Encouragingly, there has been some movement on trying to grow the standard library in these areas. 
Well, I'd argue that everyone should completely abandon the class keyword and use struct everywhere. Think about it: when was the last time you actually wanted private inheritance? When did you write a class that did not immediately start with public:? struct defaults are far more sensible, and reflect how the language is used in practice. Death to class!
It's a dumb, bloated language that I only use because everything else is worse. All I really want is C+, which is C with classes and simple containers. Instead, I also know about things like SFINAE, and enable_if_v. It's a classic example of building yourself into a corner. enable_if needs to exist because templates are bad, but templates didn't need to be bad, they just became that way over time (well, sort of, the syntax was always bad). Unity's HPC#, if sufficiently divorced from having to use Unity eventually, might just eat C++'s cake.
I use float x { 0 }; in my class body nowadays instead of writing default constructors. Doesn't work for classes, but if everything uses it then it's not a problem.
I can tell from the username. Maintaining C++11/14/17 programs in 30 years is my retirement plan. Because there's not going to be that many people who understand it anymore, so the salary is bound to be pretty decent, considering how many places the language has got its tentacles into.
5 minutes ago. In practice, private parts of a class are a guideline for the user of the class which functions he’s supposed to use.
Did I miss something or you didn’t mention the default initialization of members? Like [here](https://arne-mertz.de/2015/08/new-c-features-default-initializers-for-member-variables/) . For me, it solves pretty much every problem with class/struct initialization.
I Dezember that the supposedly "safe" `narrow` was implemented incorrectly for at least a year. After that, and due to the horrid design of span (e.g. shallow copy, but deep comparison), I decided to ignore it. 
Oh, I thought he was going to talk about *ORDER* of initialization and multiple translation units for a second... 
If you don't want to use enable_if then stick to C++98 where templates exist but enable_if doesn't. The fact that some feature is available does not mean you must use it at all times.
They are supposed to be serious, but at least for quite some time, the GSL was imho a rather low-quality lib. Things might be better now.
Owner is explicitly designed for cases, where - for whatever reason- you can't use a smart-pointer. A low level tool of last resort - not a tool recommended for general use.
I had a lot of fun reading the article. :-D Yes, if you dive too deeply into the details of the C++ standard its hard to keep reading at times because you’re facepalming so much. That’s sad and funny at the same time. Also, I appreciated the article’s epilogue. That writing sane code – as you should do anyway – is enough to avoid most of the pitfalls in most cases is something too few of these snarky, ranty articles bother to point out. However, one thing irked me a bit. The notion that C is any more beginner friendly than C++ is a bit silly, isn’t it? Just one example: You want to use an array? Fine. int an_array[3] = {0, 0, 0}; You want to pass it to a function? No problem: void foo(int* an_array, size_t length); // intuitive simplicity int an_array[3] = {0, 0, 0}; foo(an_array, 3); Wait … Why did your eyes bulge? Of course you can’t just pass arrays around. They decay to pointers at the first opportunity. No, they don’t track their own size. You do it yourself. What do you say: Repeating the number of elements is error prone? Aha! You’re one of the intelligent students, aren’t you? You’re right, of course. But that’s easy to fix: foo(an_array, sizeof(an_array) / sizeof(an_array[0])); See!? Simplicity! Beautiful, beginner friendly simplicity! … Why are you laughing? Yes, I know that C++ uses the same crazy design for its own built-in array – but at least there’s `std::array`. The point though is that C has enough warts, historical cruft, pitfalls and craziness of its own to make beginners run away screaming. So … should we all learn Python instead. … Hahaha! I could tell you about Python’s pitfalls! But, granted, they don’t hit you as hard as early on. I tend to think that a successful major programming language that’s been around for decades is bound to have its baroque corners. And maybe the only way to manage that is to teach beginners best practices and guidelines that steer them away from the cliff’s edge.
&gt;My mom always said C++ was like a box of chocolates. You never know what you're gonna get.
Thanks for the feedback. The library is usefull for both simulation and control and is written with embedded applications using higher update rates (e.g. 1kHz) in mind. I'll make sure to add some use cases and/or examples later on. The pendulum simulation is just an example to demonstrate usage of the library. The same pendulum node could also be used in conjuction with a controller node to balance the pendulum in a upright position. Another use case would be to write a motor controller and balance a physical object such as a pendulum or a bicycle in real time. Here, simulations can be usefull to speed up development and training/tuning of the controller, after which the result is deployed and tested on a physical device. The OCON nodes act as building blocks where the same control node could be used to control both physical devices (HITL) and software simulations (SITL). 
Post like this makes appreciate C++. I am happy to know I have much to learn about initialization.
It's missing [non-vacuous initialization](http://www.eel.is/c++draft/basic.life#def:initialization,non-vacuous).
More like the cost of compiler implementers working on features we don't really want instead of cool new optimization features or language features we actually want like co_return
I am a beginner to c++ and can totally relate. The amount of details required to be known is overwhelming and intimidating
What if you have to read or maintain other people's code that uses the various forms?
Using `= default` means the constructor is user-defined, not user-provided. I think the other poster is correct to say that a user-provided constructor cannot be a trivial constructor.
Because people have enough of this mess. There is a way to calm the community down, deprecate old stuff. People say the language has to maintain compatibility with old code, but does it? Eg. They have to use weird names like co\_await for new keywords because some code could use await. So what, we all have to strugle because one doesn't want to update his code? Yet they have no issues with changing the behavior of various functionality from one version to another with is much harder to catch compared to reserved keywords. &amp;#x200B; Old codebases rarely updates to new standards because it would have to be recertified and thoroughly tested. I've yet to see a C++98 project migrating to C++17, so they don't really care what happens with new standard, they are not gonna use it anyway (for this 20 years old project). &amp;#x200B; Why does the majority have to struggle because of the 0.01%'s needs? And why that 0.01% can't adapt to the rest. If you want to migrate your old codebase to new standard, what does it change for you if you have to rename some variables or functions, you are gonna review all of the code anyway.
The private parts of a class shouldn't even be in the header . Separation of interface and implementation. Unfortunately the compilation model requires it currently (or using revolting hacks to hide the private details)
It's missing dozens of topics , which illustrates his point really!
The C and C++ standards describe different behaviors for union member access: https://stackoverflow.com/questions/11373203/accessing-inactive-union-member-and-undefined-behavior/11996970 &gt; Why doesn't it trigger any warnings in any compilers I've tried it in? Because UB isn't required to be diagnosed.
Maintaining Fortran is my retirement plan. I'd be happy to get an early start...
&gt; Any C programmer worth anything knows that this initializes `i` to an indeterminate value (for all intents and purposes, `i` is uninitialized). Does it? I would have expected Undefined Behavior here, and possibly the deletion of any branch attempting to inspect the value of `i`.
C has warts but muuuuch less than c++.
I fully agree with the keyword mention. Compilers already have version switches anyway, so just making it a keyword in a new version is easy enough; and from a development perspective, `s/await/awaits/g -i` is an easy enough cure when migrating. I wish C++ was bolder in deprecating across versions; backward compatibility is nice, certainly, but not at the cost of increasing complexity.
The comment about Meson only supporting a single per project precompiled header file is incorrect. We have always supported per-target PCH files. In fact we have never had a "projet global" pch because it makes no sense, pch files need to be tailored to each target.
Boy Scout Rule: Leave the place in a better state that you found it.
&gt; but equally complicated I do think C is a simpler language than C++. For work, I'd rather use C++ because it is simpler *to use*, however for a student's project a simpler set of rules, even it requires some tedium/boilerplate, may very well be much easier to follow.
Well this is an old topic ... Lots of CPP con talks or talks in general were given about this especially from Timur or Simon brand (2017 same title and same time ) https://blog.tartanllama.xyz/initialization-is-bonkers/ (as mentioned in the article) or cppcon / meeting C++ talk https://youtu.be/7DTlWPgX6zs by nicolai josuttis ... It looks like people wanna join the bashing C++ round because it's so popular? The question for me is now just: Are they just complaining or actually hand in propsel to fix issues or raise awareness in the committee? Start a open petition ? Or anything? Or do they just wanna generate clicks for their blogs ? We will see....
I think that for low-level programming, one of the issues with C++ is implicit memory allocations. It's really easy when using `std` to accidentally allocate memory with implicit or copy construction; completely invisible in the code! Working on low-latency code (!= real time), we skirt the issue by having our own low-latency memory allocator, and benchmarks to catch egregious cases; however I'd definitely understand that a project with more stringent requirements would want to just avoid the issue altogether.
How about maintaining COBOL in the banks?
The problem is companies often can't easily modify code i.e. for legal reasons - they're using an external library with not permissive license, each change in the code has to be audited for certification, they don't have full test coverage etc. Or they simply don't have time and resources to stop production of new features to start migration. I'm not saying I like the state of things, but this is the reality of big projects.
No, I would not accept anything non-english in the source. I want to be able to type reasonably fast and I have no idea how to type a greek letter. And a question to you: would you not expect your coworkers to look-up a function they don't know? And is iota really that bad? Iota is an official english word, and I would believe that most will be familiar with the expression "I don't care one iota". So if you know that expression, std::iota does make sense and if you do not, C++ helps you learn english. 
Unfortunately (fortunately?) I don't know any COBOL, but I do know a lot of Fortran and the domains it's used in. Now I just gotta find those jobs...
But it just forces people to rewrite the same warts over and over again. How many OO implementations in C are there? How many out-of-bounds accesses are there, and how many ad-hoc libraries to work around them? How many leaks are there and reimplementations of RAII and reference counting? &amp;#x200B; The warts in C++ are standard and no one has to rewrite them again.
&gt; Or they simply don't have time and resources to stop production of new features to start migration. Sure... but isn't switching to a new compiler or a new standard version a migration anyway? I know that each time we upgrade the compiler we use, we have to: - fix some code which the former compiler accepted but was incorrect, - fix some code which the former compiler did not warn about but was incorrect, - fix some code to work around issues in the new compiler, - evaluate the correctness and performance of the generated code, often delaying the migration as issues in the new compiler are uncovered and not trivial to work around. Asking suppliers, or sending patches to open source projects, to fix the code is part and parcel of the migration. We don't have to deal with auditing, but I guess such a change of compiler would also warrant auditing anyway, and the new toolchain would have to be certified as well.
Once you start writing in C++, and if you're the right type of mindset, you'll like C++. Like any other language you know, you'll learn to get over the annoying parts. At least most of C++'s annoying parts are compile errors and not customer-site errors.
You are correct, but now the newer standards break compatibility only in few places for features deprecated for 3 or more years, If the breakages happened more eagerly (or worse, if they didn't happen at compile time), it would add much more effort the above migrations and they would happen even rarer across the industry.
`enable_if` works in C++98 just fine.
int i = 0; problem solved. no need for constructor or any other fantaisy
 Initialization in C++ is Seriously Bonkers Maybe. There are some corner cases, but it's not \*that\* bad, in my opinion. Just Start With C Hell. Fuck. NO! STOP TEACHING C, or learning it, for crying out loud! [https://youtu.be/YnWhqhNdYyk](https://youtu.be/YnWhqhNdYyk)
I've never seen it before C++11 https://en.cppreference.com/w/cpp/types/enable_if
All that code smell must have rubbed off on that guys keyboard, because I can still smell it lingering on his comment.
It was in Josuttis' _C++ Templates_ in 2002; not sure when it entered Boost but likely around that time. And, it's 6 lines of code to implement. ;-]
C++ is Seriously Bonkers. It was designed by a committee and it was one of the first OOLs. Looking back, it's not surprising it has a lot of weird stuff.
You can't win every battle. Sometimes you have to use your best judgement as a programmer for what to do - it might make sense to refactor the other code to behave better/to adhere to your standards, or it might make sense to just leave it alone and break convention sometimes.
I wasn't even talking about non-ASCII characters. Would you be ok with having a function called \`sihao\` (that's Chinese, in case you are wondering)? As for \`iota\` being a normal English word, it is, but it means something completely unrelated to what the function does: "an extremely small amount", according to this [dictionary](https://dictionary.cambridge.org/dictionary/english/iota). And maybe that would be ok, if there were no reasonable alternatives. But what's wrong with something like \`create\_series\`, or \`make\_sequence\`? Surely there is a term that is far more descriptive than the mystifying \`iota\` - a term you can only be expected to immediately understand if you come from a very specific, and rather uncommon, background.
But how else will I write code that silently stomps on memory in rare circumstances long before crashing instead of code that fails to compile in the first place?!?!
I don't see a problem. Structs can have private parts too, it's just that the default accessor is public
What's the value of your post?
C++ is a general-purpose programming language. It has imperative, object-oriented and generic programming features, while also providing facilities for low-level memory manipulation. ([Wikipedia](https://en.wikipedia.org/wiki/C%2B%2B)) &amp;#x200B; On this subreddit we discuss topics related to C++.
The total number of warts isn’t interesting. It’s the amount and seriousness of warts you *have* to heap onto a beginner to enable them to program anything useful. Beginners only deal with a limited amount of craziness until they run away to another language. C++ has the abstraction facilities to hide most of the cruft. C doesn’t. That’s a severe disadvantage. Let’s take an example that combines two mega fundamental things: sequences and text. Yay, a list of strings! In C++, no problem: std::vector&lt;std::string&gt;&gt; Then use `push_back()`. Done. In C you use: char** Then you implement memory management for the list itself. Do it completely manually, and don’t you screw up a single one of those mallocs and frees, or bad things will happen. Once that works continue with managing your own memory for each of the character arrays in that list. Yes, do it completely manually. Then deal with the necessary reallocations when the list grows. Congratulations, you just implemented `push_back()`. If you haven’t lost your beginner after a week or two of fumbling, you can now start to explain the C string processing functions. If you’ve even looked closely at things like `strtok` you know what a cesspool that is. Novices go to die there! Meanwhile the C++ novice is happily writing small programs and is graduating from beginner to intermediate.
&gt; or worse, if they didn't happen at compile time That's a very important point indeed. Backward incompatible changes MUST result in compile-time failures; it's hard enough to deal with the optimizer taking advantage of the lingering UB in the codebase, let's not add to our woes.
I am amused that \*this\* is the reaction to the article. I am facetiously pointing out some of the dark corners of the language that exist in the name of backwards compatibility, but I never explicitly say, "this is bad!" because I don't actually think it's bad. It's everyone else who sees the dark corners and implicitly assumes it must be bad. I had to add a clarification in my epilogue about how I think list initialization is actually a good thing (although I'm not sure how std::initializer\_list made it in). Remember my point is mostly to young programmers just starting out learning fundamental data structures and systems programming concepts, that it's in their interest to skip all this jazz for now. As I said in my HN comment, C++ is the way it is for a reason, because people needed it to be this way. Legacy support and backwards compatibility is a great thing for an organization trying to adopt new features.
That's the point, it's supposed to be a fast moving community effort to complement the slow standardisation process. An inspiration is the community driving development of new languages (such as Rust)
Most of these questions do have obvious answers. The only considerable questions are those in the format of *"Should the committee do XYZ?"* which, I think, is what this post boils down to. And the answer to most of those is that the committee should keep standardizing existing practice: identify the pain points and try to alleviate them. The questions regarding the efficacy of the standardization process are another discussion.
What the actual fuck, /r/programming? The private methods are a guideline for using a class? How is this nonsense being upvoted?
The anti-C++ snobbery/elitism has been lingering in the air for years now but I think this moment in history is when it blew up in our faces. The fuse was lit years ago and was rotting away in twitter and other social media. So: what can we learn from all this? I tell you: absolutely NOTHING. Write code in language your boss tells you to and if you are in position to choose, then do it wisely. If we had one-language-fits-everything we would know by now. Here's a few ideas for replacing C++: Rust! C#! Swift! D! F#! OCaml! Fuck C++, right? I don't really have any point here except that use what you want and stop whining, get the job done. From three decades of experience I know one thing: the good result come from a lot of good and bad decisions along the way and a lot of hard work. Making something that works is easy enough. Making something perfect is not so easy.. it will be endless tears, sweat from hard work and hardships but you all knew that already. Perfect is often impossible because of economical reasons. It's elusive and rare, and, from what little I do know, language agnostic. Also, careful out there, don't confuse popularity with quality.
Without coming off as picking what others may be fine with, perhaps some formatting and clustering of the text on the page? Feels a bit like it's all been spat into one section, and there's not enough contrast with the italicisation alone. 
I understand your pain and empathize with my own students, especially when one starts to think about how much prerequisite knowledge is needed to really grok the language. I always tell them it's completely normal to feel confused at first, the same way someone learning advanced calculus would be confused at first--there's no context. C isn't taught within the context of building up from assembly, coming from ALGOL languages where structured programming was this amazing thing, using compiled for the PDP-11 where memory was limited and special instructions existed for null-terminated strings. It wasn't taught in the context of pre-malloc days, so malloc becomes this magical thing that for some reason can't just return my object, but instead some handle to it and I just want my object dammit! So when I say "undefined behavior is very bad and incorrect", and they run their code and it looks fine and they have no idea *why* they're wrong except for me being a prick and telling them its wrong, it gets very frustrating. I get it. We were all there. I always tell them as long as they keep a curious and open mind, then they'll be fine :).
You could say the similar things about C++ after pointing at another modern language like Rust. That still doesn't stop people from using C++
C is not beginner friendly because it assumes you are not a beginner. It assumes you've been programming in ALGOL or FORTRAN and assembly. But it's what we got for teaching the basics ¯\\\_(ツ)\_/¯ See my response to the child comment.
Here, maybe this helps: https://en.wikipedia.org/wiki/Constructive_criticism
Wow XD. So "should-at-least-do-something" initialization. 
C++ is not a beginner language! And if you can't even understand C, then you can't really produce good programs for what C++ is used today: performance critical stuff. These require you to know how computer work. If you don't care about performance, then you can use all those other languages which are 100x more beginner friendly. If you don't understand computers, then the benefits of C++ is useless and you may switch to java and spit out programs which work well enough. Understanding pointers and other things is a **requirement** for doing performance critical stuff. C++ is just a language which you upgrade to after learning C. That's how it should be. If you don't do that, then you will have programmers who write java but in C++. 
Just congenially pointing out that you are not, in fact, disagreeing with that quote. :)
I've mentioned a few times elsewhere and alluded to in the post, this was aimed at beginners learning systems programming concepts, veering them away from the shiny lights of C++ until they have better fundamentals knowledge.
The standard says both happen. i is indeterminate value, and using it an expression is undefined behavior (although I believe it defined behavior to initialize another variable with it and use that variable). In any case it's probably from some edge-cases that needed to be supported for historical reasons.
You could also argue we should stop teaching assembly.
It's amusing that there's a section of the (un?)official FAQ that calls it a fiasco.
Anonymous structs are not allowed in C++[1] (but some C++ compilers allow them for compatibility with C, which does allow them). Try compiling with `-std=c++17 -pedantic` and see if you still don't get any warnings. If you give the struct a name it is C++, but accessing a non-active member of a union (aside from shared elements of a common-initial-sequence with the active member[2]) is undefined behavior. Since only one of those elements is a struct, they cannot share a common initial sequence[3]. Finally, there is no portable relationship between any of those bitfields and a particular bit in the punned byte. Alignment and layout of bitfield members are implementation-defined[4]. Other than a special case for zero-width unnamed bit-fields[5], implementations are free to put padding between bit-field members as they would be any other member. 1. http://eel.is/c++draft/dcl.dcl#5 2. http://eel.is/c++draft/class.union#1 3. http://eel.is/c++draft/class.mem#22 4. http://eel.is/c++draft/class.mem#class.bit-1 5. http://eel.is/c++draft/class.mem#class.bit-2
I don’t see why you should be granted any respect higher than your excessive condescension. Being condescending while being wrong. Have you heard of irony?
Thank you! As a wonkish person, C++ gives me something to be wonkish about. This isn't anti-C++ propaganda. Just an acknowledgement of how in depth things can get.
Because I don’t know how I’m wrong. I’m not saying what I commented was right. It’s not even about respect. I presented my ideas in a neutral way and you proceed to call it “nonsense” and ask “why the fuck it is upvoted”. I don’t want to discuss things on that level. If we can return to a neutral tone, I’ll be grateful.
Bitfield layout is implementation defined so it's not portable. You can only get away with it if you're targeting a single architecture. Trying to use bitfields for information interchange in portable code leads to monstrosities like this: https://svnweb.freebsd.org/base/head/sys/netinet/ip.h?revision=335837&amp;view=markup#l51
Sure but I think before people were scared and repressed by the Modern C++ Gestapo. Now that more and more folks are coming out of the woods to Criticize, there has been a deluge of accountability calls.
You can have a trivial private default constructor?
I'll be calm when they concede the Whole STL was a very bad idea and replace it with Qt.
Lots of Fortran libraries in any Linux distro. I always compile clang with C, C++ and Fortran
Seriously, it's literally language genocide at this point.
Yes sorry if it sound very aggressive. I did not want to attack you or anything. I should have posted this as a seperated post rather then a comment. I am with you (as you mentioned in the article) that a good foundation is important to use C++ or learn it. It's just that at the moment everyone seems to write stuff about C++ which is more or less true but then they don't do anything about it... Other then just complain.
The bane of my existence.
I can continue this trolling thread by simply answering: use C++.
This is currently my favorite question "Should C++ be usable without the standard library?"
For any one individual they likely do have obvious answers. But I would not be surprised if there's a large range of opinions on all of them.
Sure but this would apply differently for hardware registers right? Those are already architecture specific.
Because private is not a guideline for how to use a class? That’s is what public and protected do. If you’re needing to inherit private, that is a code smell “somewhere”. So saying you needed to inherit private 5 minutes ago isn’t a condemnation of that users comment, but of your crappy codebase.
Bubba perhaps python is a better language for you. You can even call yourself a scientist if yougo work with data
That's exactly what the modern mom is doing
What does it mean "a systems language"? What kind of programming language isn't used for systems? 
As a prerequisite for leaving other languages? Hell yes we should stop doing that (but it's rarely ever done). As a language in its own right? No, that's a completely orthogonal argument.
White bread and Walmart mayonnese
just because his ego does not fit in his head
Quantstack is making some high-quality packages :)
I'm still using 4.4:7 for most my codebases because it runs like a charm and nobody is crazy to touch it unless there is a new feature. Imagine I upgrade, shit fails? How am I going to justify? uh modern c++ functional yada yada?
I don’t inherit private. I wrote a class that doesn’t immediately start with `public:`. I have a single class, not meant for inheritance, that a user is supposed to use, and I put everything the user isn’t supposed to use into `private`, like raw data pointers, internal functions, typedefs, etc. There’s no reason to clutter the user’s UI by letting his IDE suggest functions he’s never supposed to use.
Yes
you don't code kernel modules in PHP.
&gt; C is a small, but equally complicated [...] language I find that extremely hard to believe. For example, the C standard is [552 pages](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf), whereas the C++ standard is [1368 pages](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf). 
&gt; sizeof(an_array) / sizeof(an_array[0])) And it turns out that that doesn't work in all cases either. :-D See e.g. [this discussion](http://www.cplusplus.com/forum/general/33669/). 
Could this vectorized compilation check be added to the attributes supported? Something like [[vectorized]] for (...) and issue a compile error if it does not work (modulo unknown attributes must be ignored by the standard)
Ok! So what I mean is why is a kernel module a "system", as opposed to the things you do with php? 
I usually call this strategy vendor lock-in. Yes, it is convenient to use C# in their use-case, but take this Burst blabla... you have been locked-in.
No accessible default constructor means no arrays, among other things.
I think you are using the auto keyword way too much.
I wonder if a library solution can provide some intrinsics + static asserts and solve what they suggest better than adding all the tooling. They do it because they use C# and bc they wish like the hell vendor lock-in.
Would you classigy it as abuse or not?
you may just choose those make sense to you. It's always better to have more choice.
When I tried it, I did so because string_view was not implemented by compilers and I wanted to substitute it with string_span. Now string_view is available everywhere. That said, if the tooling is better now in that static analyzers pick up on the semantic meanings of the specific, non-enforcing types, then yes, I'd use it.
Provide ABI compatibility and let me specify which language version I'm using in a preprocessor statement.
Just wanted to drop a note it's pretty cool. I'm planning to try out some motion control modeling with it in a bit
&gt; unconditional noexcept True, those are only noexcept if F is nothrow movable (or copyable in #3 :o)? do you think that has anything to do with the guidelines recommending move constructors to be noexcept? regardless i see your point. bug 6,7, and 8 yea i see those are all things that could make the class better in c++17 bug 9 fair enough. overall it also looks like folly's scope guard is a better tool for the job. Thank you for the detailed response! you have definitely helped me understand what types of shortcomings to expect. If you feel like roasting any of the other utilities in GSL, i would look forward to that!
Out of those 1368 pages, 772 (438 - 1210) describe libraries, i.e. the things that make the language easier to use, so, if we are judging by the number of pages, I'd venture a quess that the raw languages themselves are equally complicated.
Why do you think that?
Did you read the part of the SO answer where it says that POD has been deprecated and what you actually want is Trivial and/or StandardLayout?
I don't code kernel modules in anything else but C though...
it is usable, no? at least... i'm pretty sure i'm using it without. 
Baby don't code me...don't code me... no more...
The prime example would be initializer lists. But there are others (unimplementable type traits mostly), and there may be more in the future (coroutines, static reflection, etc). Some believe that to be an issue.
"System" in this context means interfacing with physical hardware or contributing to the platform's foundation: operating systems, firmware, BIOS, device drivers, core libraries, etc.
I would say the opposite. Few of these questions have obvious answers.
Most peripherals like USB controllers, NICs or drive controllers can be used in a variety of architectures. Also, in the specific case of registers you usually want to pair any access to a register with appropriate memory barriers (both compiler barriers and cpu barriers), so you usually want to restrict direct access to registers to a small set of APIs that automatically issue the appropriate barriers, and then driver code can call those APIs rather than trying to access the registers directly and having to get the barriers right in every single driver. So for register access, bitfields aren't likely to be all that helpful.
As far as I see, it could be the case that he is not using it *enough*.
Thank you for the context! this gives me a better idea of the ultimate purpose of GSL in combination with the written guidelines and automated checking. So if I understand correctly, a big issue is that view types have a safety concern until lifetime profiling is complete, and even then the limitations in the lifetime profile lead to limitations in how we can code (at least without getting scolded by the lifetime profile)? I mostly just skimmed that article but i think i see the idea of structurally safe vs logically safe and how that relates to the limitations of the lifetime profiler. If we're mostly talking about view types, that subject in general seems unsolved at this point, even in terms of "are view types a good idea at all?". your first two sources highlight some issues: not just lifetimes but just in general having to know information about the original type being referenced. Towards the end of [this talk] (https://youtu.be/2UmDvg5xv1U?t=4668) Titus talks about reference types as an open ended issue, and maybe even concepts/ranges are a better direction, or maybe some other cool stuff like your always null after free pointer, and your container reference that doesnt let you screw up the container reference by modifying size etc. (sorry if i understood those wrong). overall I think view types definitely have issues but maybe i wouldnt blame GSL for that, as afaik they have implemented span at least up to par with the current state of view types. Although i still see the limitation regardless, so thank you for pointing that out. besides that, would you say any of the GSL utilities are useful on their own (i.e. without the checkers and written guidelines)? Thanks again for the detailed response!
&gt; the supposedly "safe" narrow was implemented incorrectly :O well thats unfortunate, hopefully thats fixed by now. and yes as others have also pointed out as well, i now realize GSL has its fair share of bugs. although for the "horrid design of span" afaik thats how string_view works, so are you also not a fan of string_view? just wondering. thank you for your response!
You can already do that with `__cplusplus` and the ABI didn't change since C++11. Am I missing something?
[https://github.com/richleland/pygments-css/blob/master/monokai.css](https://github.com/richleland/pygments-css/blob/master/monokai.css)
As someone who's been using cpp for a while I actually don't know the answer to this question.
GCC 4.4 doesn't even have full support for C++11. Even outside of new features that make writing the code easier and safer, you are missing out on performance improvements like move semantics, constexpr and copy ellision.
I just wanted to mention that my company has a 35 year old codebase which upgraded from Fortran to C, then to C++ and our last yearly release was already with C++17... The size of the codebase is &gt; 10 MLOC...
Isn't Modern C++ wonderful? ...
I don't think it's a big deal regardless.
I don't see any particular issue with it other than being inconsistent: `json config;` And a few lines later `auto posts = json();`
Following up on this I created a [poll](https://goo.gl/forms/iBfYshHQFrP3oVoS2) ([https://goo.gl/forms/iBfYshHQFrP3oVoS2](https://goo.gl/forms/iBfYshHQFrP3oVoS2)) for people to give their answers to those questions.
I do. When the keyword removes context or readability it's not good. \&gt;auto iterator = myvector.begin() is fine in my book \&gt;auto result = CreateWindowEx(); leaves a lot open.
You forgot to sticky it.
I think the goal is so complex that it would take several years more to begin to settle into a stable version. For starters certain things are impossible to implement nowadays with current C++. Others only if you apply a complex static analysis. On the other hand, the library changes frequently because of the complexity of the goals, not to mention when it uses new C++ standards. The guidelines and the reference library are not synced. I don't know how a free static analyzer can keep up with that. Even with MS Visual Studio team support (for sure life is ironic). Not to mention beginners like me that are one of the targets of the guidelines. It makes me want to return to C or one of these restricted C- like proposals (Orthodox C++ and stuff).
For anyone that wants to do something similar or look for small project inspiration, it looks like this is derived from the [cpr-example](https://github.com/whoshuu/cpr-example) project, cpr being the HTTP library used in the OP. The dependency management is handled using git submodules and compiling both cpr and json as part of the CMake build (supported by both cpr and json).
Nice! Was there any specific pain point that hit you the most during migration to C++17?
If you read code with plugin to deduce type, like ide or YCM or rtags, it doesn't bother you.
&gt;To me, C++ \[...\] then assumes you've been programming in assembly, and have learned C That’s where I think you are wrong. C++ doesn’t assume that at all. Below I’ve already seen a link to [Kate Gregory’s “Stop teaching C” talk](https://www.youtube.com/watch?v=YnWhqhNdYyk) – that really should have the less baity title “Stop teaching C++ as if it was C”. She makes the case a lot better than I ever could. And a Kate Gregory talk is always worth watching anyway. ;)
Very true, but it's annoying if you will have to do this for every line that has a new variable on it.
&gt; Imagine how many programmers we would help and save time of using Neutron. Looks absolutely horrible way to compile a program that wastes ridiculously lot of time and only supports compiling a single file. All this could be replaced with a single couple line shell script which would be easier and faster to use. The actual problems people have with compiling Windows code on Linux are mostly related to setting up development environment. (installing MinGW, compiling required dependencies, CMake toolchain files, etc.) and this doesn't help with those at all. 
&gt;C++ is not a beginner language! That may or may not be the case. And it wasn’t what I wanted to say. I’m arguing that C is *worse* for beginners than C++, nothing more. &gt;And if you can't even understand C, then you can't really produce good programs for what C++ is used today: performance critical stuff. I disagree. For performance critical stuff you need a firm grasp on how your hardware works – CPU caching being the canonical example. Why do you need C for that? With C++ you can go as deep into each individual bit as you need. But you still have all of the rich type system and abstraction facilities to make your live easier and save mental capacity for the parts of the problem that really matter. Why not take advantage of that? &gt;And trust me, all these people who advocate for learning C++ without understanding its roots (C) started in C. Can’t trust you there. My personal experience is exactly the opposite. &amp;#x200B; On a bit of a different note, let me go out on a limb here. What I seem to read between your lines is the notion that C++ with all its high level abstractions is less efficient than C. If I’m reading that wrong then ignore this paragraph. But anyway, C++ people like to speak of “zero cost abstractions” for reason; because that’s exactly what we mean: no runtime overhead. As a case in point see [Jason Turners CppCon 2016 talk](https://youtu.be/zBkNBP00wJE?t=4118) where he uses C++17 with all bells and whistles to implement Pong for the Commodore 64. In an optimized build all those fancy abstractions just go away. (The link goes to the part of the video where he lists all the abstractions he used).
A *data* scientist, even!
This is such a terrifying feature. Shadowing is already a problem worth avoiding and adding struct/class members can now affect all sorts of code in unintended ways. I would not want such a feature or would likely move to forbid it in codebases I work in if it existed. 
Can you elaborate on shadowing? What does that refer to?
Also would it improve things in your view if this forced a scope introduction, and only had effect in the new scope?
`std::nullptr_t` is defined in the standard library too. 
Of course it should. Otherwise it's impossible to use for embedded platforms, operating system kernels, etc. Where a full (or even remotely close to full) standard library cannot be implemented. If there is no filesystem, `std::filesystem` isn't going to work. If there is no "kernel"/scheduler what's the point of `std::thread` and co? And let's not get started on the case where there's no dynamic memory allocation...
Oh well, if *you* don't do it then obviously nobody else has any reason to... (Also note that Linux is not the only kernel in the world.)
Well no. If the code is written according to the language rules (eg not relying on undefined or implementing defined behavior) then by definition updating to a new compiler must not change any visible* outcome of program execution. If it does, then either the code was doing something wrong or the compiler has a bug. \* I suppose you could have a performance or memory regression, since those are not part of the language contract. 
&gt; GCC 4.4 doesn't even have full support for C++11. Exactly! Not needed. &gt; performance improvements like move semantics, constexpr and copy ellision. not needed. I use intrusive pointers. 
Take this: struct S { int a; int b; }; void f(S s, int x) { // .... { using s; x = x * a + b; } // ... return x; } and consider what will happen if you add `int x` member to `S`.
What do you think about: bool contains(rectangle rect, point p) { auto&amp; [x,y,width,height]=rect; return (p.x &gt;= x) &amp;&amp; (p.y &gt;= y) &amp;&amp; (p.x &lt;= (x + width)) &amp;&amp; (p.y &lt;= (y + height)); } ? ([On Godbolt](https://godbolt.org/z/aObOL1))
Not bad, little bit more verbose but that might be okay. It does explicitly show you what's coming into scope, on the other hand it's maybe more of a maintenance burden.
This would be basically the with statement in Pascal and related languages like Modula 2/Oberon: https://www.freepascal.org/docs-html/ref/refsu62.html Only there it is scoped, which makes more sense imho.
This reminds me somewhat of C's strange scoping rules with regard to nested structs: struct A { struct B { int i; } b; }; void foo(struct B* b); /* okay */ I don't think this is a good thing, I'm afraid.
I'm a bit confused by your example, as you're returning x from a function that says it returns void. Also since the parameters are by value is there really any problem here?
I think the migration from C++14 to C++17 was not the worst, we are basically only compiling with MSVC under Windows (Clang support gets better and better, but we are not there yet), which makes everything considerably easier. 
No because it still means every time I add a member variable, I risk introducing a variable that collides with a local variable in some scope somewhere in the codebase. Basically this is a feature that won’t scale well with codebase size. 
This is similar to the 'with' statement in Pascal. It wasn't that popular since, while it decreased verbiage, it can make it more difficult to understand the code particularly in longer sections and where there are multiple 'with's active at once. https://www.freepascal.org/docs-html/ref/refsu62.html
gotcha
It's just `decltype(nullptr)`.
There is also Pascal, even for embedded devices.
Oh, yeah, I forgot that existed.
For me safety trumps performance, even when I write C or C++ code. If with that rule, performance does not match the desired "definition of done" then there are profilers to sort out issues locally, and not across 100% of the code base.
C++ is the swiss army knife of languages
 `//I know it's bad But i don't have other json libraries And don't plan to make one` `using namespace nlohmann;` Why do you think it's bad? I find this library quite inspiring when it comes to c++
My bad, I intended `f` to return `int`; fixed. The problem is that the meaning of `x` in `x = x * a + b` is changed. Instead of using the argument `x` to compute the return value, instead `x` from `S` is used (and updated), which is clearly not what the original author of `f` intended. Thus by adding a new member to the struct you just silently broke code elsewhere.
Is this just a hundred line tkinter wrapper around `g++ -o file.exe file --static`?
looks pretty much defined here : https://github.com/llvm-mirror/libcxx/blob/master/include/__nullptr#L24
but look at this beautiful readme
Any PhD level work in image analysis or remote sensing ?
That's inside `#ifdef _LIBCPP_HAS_NO_NULLPTR`.
What's that feature? I've never seen square brackets used like this.
There are diff tools, search tools, Github, and other web front-ends for viewing code history, performing code reviews, etc., and not all of them will have this add-on functionality. Most don’t. If you’re using auto in a way that additional editor/IDE hints are useful, IMHO you’re probably overusing it.
Am I supposed to read all of this? 
only if you want to maintain the moral high ground when downvoting
Well to late
Type checking is nothing, I need my editor for searching for references and jumping to definitions all the time during code review. I learned that reading outside my editor is a waste of time. Even cross referencing with diff is more effective.
Or, MXE http://mxe.cc
&gt; I learned that reading outside my editor is a waste of time. This crutch doesn't work well in many environments, especially very large code bases, so it isn't something your coding style should impose on others.
Use an std::vector for the original data and when you need it sorted put it inside and std::set or std::multiset which will give you the ordering you require. Now the only thing you need to be careful of is if you want to modify one element for it to update in both places you may need to use a reference.
A lot of the C++ standard doesn't apply to most normal usage. That said, the complexity of C mostly comes from the combination of what that standard *fails* to specify, and what it fails to even consider.
Can it depend on codebase?
&gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
Maybe we should strive for better variable and function names when using `auto`. In your second example, even if you weren't using `auto`, a variable named `result` doesn't give me too much insights about what's going on; even if the type had been there, it wouldn't help me all that much. IMHO the knowledge of types is not strictly required for good code to be readable. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I don't know why folks don't just use the link markdown \[text\](URL) it is so much simpler.
The gig is up, you should do a 30-second google search. https://www.snopes.com/fact-check/program-management/
It is the Swiss Army Bus of Awesomeness.
`#define class struct` Here, problem solved.
I don't know. Do all your coworkers use the exact environment? Can they easily switch to your branch (or non-git equivalent) and compile or index the code so they can see the hints? A suggested rule of thumb: consider the effort to write the code vs. the number of times it will be read over the next 1, 2, 5, 10, 20 years, and by how many people. There are articles and blogs all over the place about this and no grand consensus. I find 'auto' to greatly simplify the code in some cases like: for (const auto&amp; salesItem : outstandingSales) { salesItem-&gt;DoThing(); } And not for ietsrondsofzo's excellent example which I will reclassify as: auto result = parent-&gt;CreateWidget(params); This requires some digging, especially when CreateWidget is overloaded in a class hierarchy and can return different things with different semantics, maybe even due to covariant return types -- though I don't pretend to know offhand how those work with auto, which becomes part of the problem. C++ is such a complex language that not understanding all the type inference nuances can lead to problems in these scenarios. Avoid unnecessary cognitive overhead.
Lots of times people get angry, when they see usage of using namespace std or something like that saying it's a bad practice. And it will lead to clashes if I have a json type by myself . So I wrote it's bad
That's correct, but it didn't make sense as an answer to what I said, so I assumed a confusion in terms and interpreted that as "By definition, a programmer cannot write a trivial constructor", which is incorrect.
I will try to be consistent... Also I did this in a small time window (not a valid excuse), so didn't look at consistency 
You misunderstand: #include &lt;type_traits&gt; struct S { int a; S() = default; S(int aa) : a(aa) {} }; static_assert(std::is_pod_v&lt;S&gt;); // passes If you remove the trivial default constructor, the struct is still standard-layout, but it's not a trivial class anymore, so it's not a POD. Most people who want a "POD" nowadays are really talking about a standard-layout class, so you don't even need the trivial default constructor.
Did you read the part of the real world where "deprecated" means "universally-used"?
&gt; I don't know. Do all your coworkers use the exact same environment? Can they easily switch to your branch (or non-git equivalent) and compile or index the code so they can see the hints? In my environment, we are exchangeable. Someone may use Intelij and someone may use vim, but the always have some kind of intellisense. If they don't then it's their problem, they can set it up like others, it will make them more productive. It's best to review the code by answering the question: "If that guy quit the job, would I be able to do the remaining work from here? What would annoy me?".
I don't disagree, but coming from a background where I lived with Hungarian notation for &gt;10 years, this seems backwards. :)
Remember: preprocessor -&gt; compiler -&gt; intermediary language -&gt; optimizer-&gt; code generator. Your static assert disappears after the compiler phase, so you can't check anything about the codegen. You are correct that intrinsics can be passed down to the codegen, but they're a poor tool to control the output. They're really meant for short, specialized functions like `memset`. It _would_ allow them some control though. Really, the best way to do it is to modify the code generator itself (the last part in the chain above). Either replace it altogether (like a transpiler C++-&gt;JavaScript would do) or hack it to get what you want. You can do that in C#, but you could also use clang, which eats C++ and spits LLVM intermediary language, and write a codegen for that.
That's not an uncommon tradeoff to make. 
The whitepaper is very light on details and is missing some key details - eg. How does it scale with the number of messages and peers? What is the routing algorithm? How does peer discovery work? If I understood the whitepaper, this is essentially encrypted multicast where every message is broadcast to every peer, which is why scaling is especially important (or catastrophic). If could imagine all sorts of interesting analyses here, like what the average number of hops that message delivery would take as a function of peers. WhatsApp said they delivered about 500,000 messages per second on average in 2017, and if you assume 140 bytes per message, you'd end up with about 500 mbps of bandwidth required for that (ignoring overhead). However, with this P2P multicast idea, every node is going to need that amount of bandwidth because it had to process every message broadcast to it. I could imagine that with some partitioning scheme and just a little finessing of the routing, you could do significantly better than having every node processing needing to receive every message. If the network is partitioned so that each node is processing only 1% of every message on the network, that would still preserve anonymity, and reduce the bandwidth required by 100x...
Am I misinformed or is `&lt;concepts&gt;` also needed for the concept feature?
It reads as you criticizing `nlohmann` json library, not the `using namespace`.
That library is awesome. It was unintentional though
It's becoming more like a statically typed Perl: a swiss army chainsaw, but with types.
Hence the 'I don't know'. We live in different universes and I strongly prefer favoring code readability over time and in various contexts, instead of reducing keystrokes when originally writing the code. There are good arguments for correctness (and intentional flexibility) when it comes to 'auto', which I'm trying to understand and accommodate. The good news is that in the several large code bases I either work in or need to regularly browse, I rarely see **auto abuse** like in the CreateWidget or CreateWindowEx examples. Hence the world is saved and I'm happy.
`&lt;concepts&gt;` only contains concepts defined by the standard library. You can define concepts without including any headers.
am still learning the ropes, but there is a comprehensive file it can dump all config settings into - seems to be a dot file name in a user directory so look to see how to make clang-format use one that's specified explicitly. Then could check that into git and teams could reference a standard file but alas this is a lower item on my current priority list
The concept of POD isn't deprecated, it's just been split into _trivial_ and _standard-layout_ concepts. A class that is both is a POD and can be checked with `std::is_pod`. C++11 9/10: &gt; A _POD struct_ is a class that is both a trivial class and a standard-layout class, and has no non-static data members of type non-POD struct, non-POD union (or array of such types).
Structured bindings from c++17
std::is_pod will be deprecated in C++20: https://en.cppreference.com/w/cpp/types/is_pod Same as the "concept" of PODType: https://en.cppreference.com/w/cpp/named_req/PODType
Yes.
ain't nobody got time to remember what order they go and which punctuation goes around which. 
They will almost certainly not be identical. If your program is standards-compliant and doesn't have any undefined behavior, then the programs they produce will give exactly the same outputs, but the instructions they use to make those outputs will differ.
True, I've amended my comment. Thanks.
No, there are always differences, even if they both compile there may be differences in behavior. 
Besides undefined, there's also unspecified and implementation-defined behaviors to watch it for.
Right, I don't run into those very often.
C++ is particularly suited to 'systems', which I would interpret as something that is probably broad and definitely deep. Deep in the sense of vertical layers, where the bottom ones may be doing very low level things (manipulating CPU registers, interfacing to hardware, handling system interrupts) and the highest levels may be stuff that end users are interfacing with. The canonical example is an operating system, which covers the range from hardware manipulation at the bottom to the desktop/UI at the top. Single languages that can cover that sort of range (in a practical way that anyone actually risking their own money would accept) are pretty rare. C is one that was often used in the day, but it would be a sort of unlikely choice these days. It's too low level for the massive amount of code that makes up a modern operating system, though it could be done. Something with more tools would be a better choice. C++ is a 'compromise language' in that is capable of both very low and quite high level code, depending on how you write it. And it can do both of those things in one coherent code base. You could do it in two languages, once for the low level stuff and one for the high level stuff, but that brings in its own big raft of complications. Unless those two languages were designed from day one to be used as a whole, you get into kinds of issues when you cross between them, and you may get limited compile time validation between the two sides. If someone were starting an OS now, I'm not sure that they would use C++ either, since it's sort of in its twilight years. But it is still absolutely capable of that sort of work. Though, I'm not sure what they would use if it wasn't C++. Not that there is much chance of a new major (aka well financed and widely accepted) OS coming along at this point. If it's not a phone or a browser or a cloud based service, most people don't much seem to care anymore, where 'people' might be loosely translated into 'people who have money to invest in software projects and get them widely used.' &amp;#x200B;
So you don’t use things like int?
`int32_t` for life. Technically that's implementation-defined too, but I can't imagine two compilers on the same platform with the same ABI using different definitions for it.
A miserable pile of UB
You made a few edits after my other response, so I'll only focus on this. And I mean the best. &gt; Honestly, I'm not a fan of this trend of self documenting code. I was on this bandwagon a few years ago, but after some years of writing and reviewing, I actually prefer code that is "quiet" and easy to inspect with intellisense. This is why we're in different worlds. I merely have a 16-core/32-thread machine with 96 GB RAM and a 1GB PCIe NVMe for primary source plus a few lower-perf SATA SSDs plus a few TBs of spinning disk, and I can't for the life of me figure out how I'd load/index all of the source locally that I need to access on a regular basis in order to do things like code reviews as you said above. However, we have server-side indexing and cross-referencing for every supported version of the project we've released, just not at an extreme level of detail like autos. (And even the cross-referencing for definitions, etc. is limited.) And I work for one of the largest companies in the world. How is that a quiet and easy way for me to inspect anything with IntelliSense that has the fidelity of type inference? Your understanding of the persistence of code behavior also seems lacking in detail. I'm possibly gonna out me for this, but methods similar to CreateWidget return objects that behave radically differently from October than they do now in January in ways that require digging. So no, you're wrong. I understand this works for you, but the reason I push back against certain C++ coding practices (see my earlier post about lambdas) is real-world experience and not just because I'm a curmudgeon. Almost everything I've posted or complained about is based on real-world experience in the last year.
As you wish, but that would fail a code review from me if the variable wasn’t for a size specific purpose. 
It's not UB, it's just likely to break. Probably on old templates that use class instead of typename.
well it's there if you do find the time.
What is C++? Well, you know how people sometimes compare programming languages to vehicles? Popular scripting languages like Python and Ruby, for example, are good quality suburban commuter cars, Hondas and Toyotas and the like. They're perfect for driving to work, taking the kids to school, picking up the groceries, and the occasional long distance holiday trip. You wouldn't want to drive them onto a farm or construction site, but most people never have any reason to do that. (C is a good reliable off-road motorcycle. Assembly language is a mule.) C++ is an army surplus Land Rover. A succession of owners over the years have fitted it with every aftermarket upgrade imaginable, and several that nobody should have imagined. It's got winches, radios, searchlights, snow chains, snorkels, and power take-offs coming out of the kazoo, everything that opens and shuts. Whatever you need, it's probably there somewhere, although you may find it in the last place you expected, welded onto some random corner to suit the convenience of the left-handed Australian mechanic who installed it. It's got seventeen forward gears, six reverse, and three sideways. It's survived two wars, seven international disaster relief operations, and three royal garden parties. You'll probably spend your first six weeks behind the wheel muttering, "What idiot thought it was a good idea to put *that* lever way over *there?*" It's not exactly the ideal vehicle to learn to drive in. But as you get used to it, you gradually discover that it will take you *anywhere* - you've been driving it up mountains and down canyons, through swamps and ice and jungle, and it's taking all the punishment you can dish out and coming back for more, at least as long as you remember which tool kits you need to take with you. And you find yourself laughing as you cruise past the spots where all those other vehicles are stuck in the mud, their drivers perched on the roof, plaintively calling, "Where was it you told me to stick my `finally` clause?" 
Are you thinking about a universal string class, like one to rule them all. If you do manage to accomplish this, name it Highlander. /s
Sure, but anything except C is highly uncommon and is but a small subset of C++. I am not aware of any non-C kernel going out of a niche or an experimental status. From that standpoint, and following the PHP mention above, there is, in practice, **one** systems language and that is C. Nothing against C++, on the contrary.
I would still say that you should strife for the best readability possible. Its very easy to write auto, I do it way too much myself, but when I reread it in code reviews I always come back to the point I'm making above. If it took the other guy to open an IDE besides the diff tool to read it, it should be improved
Using macros on keywords is not allowed by the standard if you include any standard header after doing so, so it would be UB. It is indeed not UB and very well defined (if not evil) to do so outside of the standard library. Source: [stack overflow](https://stackoverflow.com/a/2726221)
AFAIK the mac os kernel uses a subset of C++ in the IO subsystem, even though the vast majority of the code is C. 
&gt;If it does, then either the code was doing something wrong or the compiler has a bug. That is exactly what he just described. 
It takes legibility away just to save a few keystrokes. I prefer more explicit code.
&gt; Is there One True C++ or are there a multitude of dialects? The answer is yes, bad [or-]question,my wife does the same.
I do agree. I've no doubt the language could be a lot less verbose but this is what we have, and sensible formatting helps wonders. (Well, "a lot" might be more sensible than "wonders".)
&gt; I am not aware of any non-C kernel going out of a niche or an experimental status. Well, except of course Microsoft's Windows... Windows kernel modules (Microsoft tends to call them "drivers", even if they don't actually drive hardware, although some Windows drivers run in usermode so it can be confusing) are very commonly written in C++ and the API is designed as such.
I don't get the point you're trying to make.
Jai has this because it doesn't have methods. Even C#'s extension methods don't implicitly bring members of the target parameter into scope. Why do this in C++?
&gt; guidelines recommending Recommendation sure is a good thing, but I'd prefer at least `static_assert(is_nothrow_...)` or some magic tool that will warn me every time I (accidentally) add a call to `std::terminate`. 
All the issues mentioned in the article are due to the fact that C designers thought not initializing a variable should be the default. It's not a million dollar mistake, but it certainly is a 100k dollar mistake. The proper way to design a programming language is safety first, performance second. Non-initialized variables should be allowed with a special keyword only, for those cases initialization hurts performance.
Isn't that already possible to a lesser? Structured binding and aggregate initialization (hope I remember that correctly) are already two features where the user code makes assumptions about the number and order of member variables. So if you change the members of a struct, you might already break someone's code.
&gt; particularly in longer sections and where there are multiple 'with's active at once. Then don't do it. Not that I'm a particular fan of the proposed feature, but you can use any feature to produce unreadable code.
At least for member variables I would just use individual references or structured bindings. 
It's very interesting to see how much this affected compile times, given the recent controversy around ranges. But it will almost certainly degrade runtime performance - \`hyper\_function\` has no small function optimization. Still, I bet you could add one and still keep most of the compile time improvement. What other facilities is this implementation getting that \`std::function\` gives you?
Any significant differences in functionally? Of course the other question is if using something like std::function everywhere is desirable in the first place.
I notice your call operator only takes by value meaning you're going to copy anything passed to it if it was being passed by reference/const reference before.
I agree, but its definition is in `&lt;cstddef&gt;`, it's not a builtin type. 
Not really strange (although certainly annoying) since C doesn't do name mangling.
How many instances of `std::function` were used in the code? And how many of them can be replaced with something like `function_ref`?
[JavaScript also](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/with) (infamously) has the `with` statement.
Coming from Pascal I first missed the with syntax. But after some time I found it easier and less error prone to use references with arbitrary very short names. And since auto they are even more easy to use. bool contains(rectangle rect, point p) { auto&amp; r = rect; return (p.x &gt;= r.x) &amp;&amp; (p.y &gt;= r.y) &amp;&amp; (p.x &lt;= (r.x + r.width)) &amp;&amp; (p.y &lt;= (r.y + r.height)); }
[this](https://github.com/tacticalmelonfarmer/handlebars/blob/master/include/handlebars/function.hpp) function class uses type erasure and perfect forwarding, and can deduce return and parameter types through c++17 deduction guides and sfinae; It's very simple, yet also very flexible, all of this is allocated on the stack.
Args... is a class variadic template parameter, so they will be whatever types/qualifiers the class is declared as taking
I'm not sure how useful this is, given that the headers were only included but not actually used. One would assume that every project at a decent size would use precompiled headers, which should save time parsing the headers. Now when you actually start to instantiate templates, that's where the fun begins.
No-one is opposed to using namespace, they're opposed to using namespace in headers (as you have done). The header file is your public API - that means that anyone who includes your file automatically gets everything in that namespace as well, which they may not want
\&gt; One would assume that every project at a decent size would use precompiled headers An optimistic assumtion.
So it’s *not* a discrete event system?
&gt; when was the last time you actually wanted private inheritance? I use private inheritance a lot, mostly to do exploit EBO when doing composition with empty classes (for policies). I also use variadic inheritance, so maybe I shouldn't be listened to. I agree that `class` should die. We don't need two keywords for the same thing, and public by default makes a lot more sense. 
&gt; I'd venture a quess that the raw languages themselves are equally complicated That’s extremely unlikely if for no other reason then because C++ has *substantially more syntax* to describe than C. Let’s stop claiming that C is as complex as C++ — it’s obviously false, and a waste of everyone’s time. Now, is it *worth* the increase in complexity? I’d argue that yes, many times over.
Right, I guess that's what I get when I look at code at 4 AM.
I have, but thanks for the tip anyway. Anything in particular you'd like me to consider?
Perhaps. In our case precompiled headers make the debug build about 15-20% faster, which is not a bad gain for 8 additional lines in build configuration. I mean it's one thing to complain about slow compile times, another is to not do at least rudimentary effort to try improving it.
Can you be more specific on what it is supposed to do?
&gt; std::function&lt;void()&gt; f = []() { return false; }; That's a feature. Not a bug.
And there I thought you actually had some way to profile the template instantiations of specific classes to measure the impact...
Thanks for the insight. I'm actually impressed that - in such codebase - you get to use any IDE features at all! I have never worked on such a scale. I'm not really sure if we should treat such codebases as a standard, or a separate thing. Many of my experiences as a developer would not apply to such environment. The fact that I can't test (or even compile?) my code quickly and easily, would require me change my approach to coding. Now I'm pretty reckless, because I can afford mistakes. I am like this because with today's tooling, with ~100k lines code bases, it's optimal. I can imagine that existence of such codebases is a reason why microservice approach and server apps (instead of desktop apps) has became so popular.
At this moment the library contains an implementation of popular and basic [type classes](https://en.wikibooks.org/wiki/Haskell/Classes_and_types) (Eq, Functor, Monoid, Applicative, Alternative and Monad) with helper functions like `liftM`, `liftA` from Haskell. Also, it has an analog of [do notation](https://en.wikibooks.org/wiki/Haskell/do_notation) and one working type ([Maybe](https://en.wikibooks.org/wiki/Haskell/Understanding_monads/Maybe)) :) More information you can find in unit tests and examples. In future, I have plans to add other data types like immutable lists and tuples (in Haskell manner of course) :-)
Depends on whether you think of types as a contract, or merely a suggestion. Of course, if you think of types as a suggestion, why bother having them in the first place? :-D I personally would prefer that if I have a container for functions that take no values and return nothing, that it accept exactly such functions and nothing else. Of course, I understand entirely that function signatures in C++ (and C IIRC) do not include the return value for (basically) historical reasons... If you ever needed to convert, you could do it in one line: bool someF(); std::function&lt;void()&gt; f = []() { someF(); }; 
What causes the bulk of std::function compilation overhead?
First question that came into my mind... really curious about this.
Dream on. Not even LLVM uses PCH to my knowledge.
The codebase I'm currently working in uses std::function all over the place, and compillation times are really killing me.
It seems like C++ modules partly solve some of these problems.
you might also like the size after preprocessing for such headers from [my unity builds blog post](http://onqtam.com/programming/2018-07-07-unity-builds/) - scroll a bit to the table.
Well, the c++ build system is broken, and it has been known for years. We rely too much on having implementations in headers for inlining. Headers are a legacy thing, but sadly I doubt the current version of modules will fix the issue.
As useful as Anne Frank's drums kit
**Company:** [Lumicks](https://www.lumicks.com/) **Type:** Full time **Description:** Lumicks is bringing novel tools for single-molecule biophysics to market, enabling scientific researchers across biology and medicine to unlock new types of experiments. Our primary technology, C-Trap, can be used to "grab" a single molecule, and apply precise mechanical forces to it. At the same time, one can visualize the molecule using highly-sensitive fluorescence microscopy. Our customers use it to watch DNA being copied by the molecular machinery of the cell, or observe molecular "engines" walking across the scaffolding structures of a human cell. Lumicks systems are currently in use in opinion-leading labs across the globe, including Rockefeller University, ShanghaiTech, Max-Planck, and Pasteur Institute. We're an academic spin-off from a research group at VU University Amsterdam. We care deeply about providing our users with easy-to-use, reliable software that actively supports Open Data and Reproducible Science. To make this happen, we're looking for: * C++ developers: [https://lumicks.com/vacancies/c-software-developer/](https://lumicks.com/vacancies/c-software-developer/) * Qt developers: [https://lumicks.com/vacancies/ui-developer/](https://lumicks.com/vacancies/ui-developer/) * DevOps engineer: [https://lumicks.com/vacancies/devops-engineer/](https://lumicks.com/vacancies/devops-engineer/) **Location:** Amsterdam, NL **Remote:** No **Visa Sponsorship:** Yes **Technologies:** We use the following technologies. When applying, it's fine to be familiar with a subset of these. We use C++17 for the core libraries, Qt5 for the graphical interface and Python 3 for the scripting interface. CMake builds everything. The core libraries make use of abseil, asio, caf (c++ actor framework), catch2, cereal, fmt, hdf5/highfive, opencv, ranges-v3, spdlog. The GUI is a mix of Qt widgets and QML. The Python bindings are implemented using pybind11. On the hardware side, we have lasers. Lots and lots of lasers. **Contact:** Apply directly at: [https://lumicks.com/careers/](https://lumicks.com/careers/)
You could easily realize the layout must not change, because there is no constructor. No need to check your whole code base.
hitler agrees https://m.youtube.com/watch?v=ND-TuW0KIgg
hitler agrees https://m.youtube.com/watch?v=ND-TuW0KIgg
&gt;Your environment configuration *is part of the code's build specification*. Version it just like you would a Makefile. &gt; &gt;If you want to support multiple versions of clang-format... No, I certainly do *not* want to support multiple versions of the clang-format executable. And I totally agree that the build environment should be versioned. The problem (in my experience) is that the Microsoft platform makes this a bit harder since compilers and extensions gets updated in a more implicit way than Linux users expect. The Visual Studio platform just makes this a bit more complicated with all this auto-updating and different version in different versions. For example: I discovered that I have three different versions of the clang-format executable on my machine: 1. 6.0.0 version included with Visual Studio. (Invoked typing or by pressing Ctrl-K+Ctrl-D.) 2. 7.0.0 version included in the ClangPowerTools extension. (Invoked by format on save.) 3. 8.0.0 version included in the ClangFormat extension. (Invoked by format on save.) At least all of them was disabled by default. And the first one can be manually configured to use another executable. The other two are installed and updated with the extension. So each developer must take care not to unintentionally enable the wrong version. &amp;#x200B;
Shouldn't it be implemented as ``` R operator()(Args&amp;&amp;... args) const { return ptr_-&gt;call(std::forward&lt;Args&gt;(args)...); } ``` ? I thought one should prefer `&amp;&amp;` in variadic template functions.
Yea. In my original post I mentioned that shadowing was already a problem. I’m loathe to dramatically increase its surface area
No, `Args...` is correct. If the user wanted value parameters, they should get value parameters... not rvalue references.
Technically, it is a built in type, but it doesn't have a name. A name for it can be found in the library, however.
There is nothing unusual: as stated in the article, hyper_function is really minimalistic compared to std::function. std::function supports few deprecated things (like unary or binary function, allocators) depending on the version of C++ standard and, the most important part, it does support small object optimization: e.g., there are more code to compile/switch: version that uses raw new, version that allocates on stack. More, there is stuff like type_info and all this comes in huge header: see, for example, clang [1]. Compared to hyper_function - it's only about 70 lines long, includes only type_info and does not use std::forward directly. [1] https://github.com/llvm-mirror/libcxx/blob/master/include/functional
This. Things in `std::function` that are missing here: - `target()` - throwing on invoking in empty state - small function optimization - using `INVOKE` (i.e. `std::function` is usable with pointers to members, this version is not) It would be interesting to know what the relative contribution to compile time each of these provides. 
It's not a function template though. It's a member function of a class template. Very different. 
Types are a contract, but implicit conversions are part of that contract. And any type can be in some sense (at least arguably) implicitly converted to void by simply throwing it away. `std::function` is essentially looking for a target that can help it fulfill its own contract. If the target has inputs implicitly convertible from the inputs that `std::function` needs, and it has an output implicitly convertible to the type `std::function` returns, then it can be used to satisfy the contract. If you didn't allow that then some might argue you're breaking the contract of a type that includes implicit conversions. Also: &gt;Of course, I understand entirely that function signatures in C++ (and C IIRC) do not include the return value for (basically) historical reasons... No idea what you mean by this. For example: using func_t = void(*)(int); using func2_t = int(*)(int); void foo(func2_t x) { func_t y = x; } Does not compile.
C++ *is* far more *complex* than C. Having used both professionally for upwards of 25 years, I remain unwilling to concede that it is significant more *complicated*.
I'm using this kind of approach at work and it works very well. Every project has a &lt;project&gt;Config.cmake at its root, which will add_subdirectory itself in case it is compiled from sources, and with a little bit of boilerplate it also makes prebuilt packages very simple to do and they can be used seamlessly instead of source packages. I also created https://github.com/berenm/CMakeBuildPackage based on this idea, but with additional conventions to make build rules even easier (any packages using it can be composed very easily, regardless of whether they are checked out as source or prebuilt archives). 
Well, he broke `std::function&lt;void()&gt;`.
So it is not possible to (but that is cheating I know) to predict what a code generator will spit (even if it is by detecting architecture) and just pretend u did it right? Even going further, compile some code in ur build chain and detect but this solution is already too much in my opinion, since it adds a step to your compilation chain. Maybe it is more complicated also (cannot compile all permutations)
&gt; predict what a code generator will spit Generally, no. If you disable optimizations, you might get a pretty close relationship between machine code and source code (which is helpful for debugging), but once the optimizer gets to work, all bets are off. &gt; compile some code in ur build chain and detect You mean have tests that make sure the generated code is as expected? My guess is that they already have something like that for very particular cases, since they seem so concerned about the codegen, but it's really not a solution that scales well. You also get many false positives from small, inconsequential changes in the codegen. Checking things _before_ the codegen runs is at the wrong end of the process. Checking things _after_ the codegen is a pain in the ass. You _have_ to control the codegen itself, which is what they're trying to do by switching to a different toolchain.
&gt; function_ref does that exist? "c++ function_ref" didn't show any docs for it.
Well, it has been proposed. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0792r0.html I am not sure how the current status is, however. @SuperV1234 may have some insights.
Args&amp;&amp;... And forward will still pass value parameters, but you loss the rvalue references. So if the user wanted rvalue references it would be lost with Args... . Args... Is almost always the wrong thing to do unless you are expanding in a template list. This is standard practice when working with parameter packs being passed through many call depths.
I tested on a small project of mine. I had to disable future/promise for a moment since they rely on the functional. Compile times (10 compiles, average - no signification variations, -j12 on a 6-core i9) Before: 13.7 real, 1m55 user. After: 13.6 real, 1m52 user. The performance of std::function was on average ~10% better for my use cases. The fastest hyper_function runs were faster than slowest std::function runs so there is some overlap because of variation. I got other std bloat there which is more difficult to disable so the compilation improvements can't really stand out that well unless replace more of std. 
No. This is not correct. `function&lt;void(int)&gt;` needs to provide `void operator(int)` and NOT `void operator(int&amp;&amp;)`. That's why just `Args...` is correct here. If the user wants references, they can write `function&lt;void(int&amp;)&gt;` or `function&lt;void(int&amp;&amp;)&gt;`
They're not exactly legacy. The fact that the language is textually manipulatable like this is a feature that's used in many large C++ programs. It allows us to do things that other languages require language support for. For example, partial classes in C# is a language feature for a pattern that can be solved in C++ by adding a #include in the middle of a class definition. 
**Company:** [Zivid](https://www.zivid.com) \-- 3D machine vision **Type:** Full time **Description:** Zivid creates a high speed high accuracy 3D video camera for use with robots in industrial automation. We are looking for an experienced 3D UX developer. This person hired for this position will be a significant contributor to the development of our Zivid 3D Studio. The current state of this project is that we have a mature C++/OpenCL library for our cameras. This is used in our 3D studio where the 2D UI is actively implemented in QML, and a basic OpenGL 3D view is created for image rending. We have high ambitions for the usability, look, and performance of the 3D view. Therefore we are looking for an expert in this field. The stack for this 3D view is not decided and you will have an important say in this. Therefore, we do not list OpenGL, Vulcan, Unity, VTK or anything similar as a requirement for this position. Your general portfolio and experience will be the deciding factor to get this position. **Location:** Oslo, Norway **Remote:** No **Visa Sponsorship:** Yes **Technologies:** Cross platform C++17, OpenCL and Qt/QML (and git, python, clang-tidy, clang-format, Jenkins, cmake, catch2, docker, vagrant, kvm, C++/CLI) **Contact:** PM or [mathias.nedrebo@zivid.com](mailto:mathias.nedrebo@zivid.com) **Applications:** Online form: [zivid.com/jobs](http://zivid.com/jobs)
Look it up. This misses a lot of edge cases. I used to think the same thing but it burns you more often than you think at runtime. It might be okay for a single call level but as you get into deeper levels of a call stack you start to see the consequences of not, and type erasure is always a deep stack.
It is built-in type, take a look at clang https://github.com/llvm-mirror/clang/blob/master/include/clang/AST/BuiltinTypes.def#L222 &gt; BUILTIN_TYPE(NullPtr, NullPtrTy) 
it would be interesting how smart build systems deal with headers, i guess you only have to build them once so it should barely affect people working on bigger projects. I think i red ninja does this? Not sure if make does it too - i hope so!? Never really considered it but i think my cmake make combo doesn't recompile all the things. 
Key things to improve/fix: hyper_function_state_base { virtual R call(Args...) const = 0 should be hyper_function_state_base { virtual R call(Args&amp;&amp;...) const = 0 as we only "pass through" the `call`; the `operator()` should be `(Args...)`. This will save some junk copies. template&lt;class Callable, class = decltype(R(std::declval&lt;typename std::decay&lt;Callable&gt;::type&gt;()(std::declval&lt;Args&gt;()...)))&gt; hyper_function(Callable&amp;&amp; t) this needs a SFINAE that `std::decay_t&lt;Callable&gt;` is not `is_same` as `hyper_function`. Otherwise: hyper_function&lt;void()&gt; a = []{}; hyper_function&lt;void()&gt; b = a; this doesn't copy construct; instead, it creates a heap copy of `a` and stashes it in `b`. Basically, `hyper_function&amp;` prefers your `Callable&amp;&amp;` overload to `hyper_function const&amp;`. --- The next big thing is performance related. Your `hyper_function` doesn't do small object optimization. The cleanest way I know of to do this is to split the vtable from the object state. We take this: template&lt;class R, class... Args&gt; struct hyper_function_state_base { virtual R call(Args&amp;&amp;...) const = 0; virtual hyper_function_state_base *clone() const = 0; virtual ~hyper_function_state_base() = default; }; and translate it to this: union sbo_buffer { void* heap_ptr; char stack_data[1]; }; template&lt;class R, class... Args&gt; struct hyper_function_vtable { // in heap case, `void*` points to pointer-to-pointer R (*call)(sbo_buffer const* buffer, Args&amp;&amp;...) = 0; void (*dtor)(sbo_buffer* buffer) = 0; void (*copy_to)(sbo_buffer* buffer, sbo_buffer const*) = 0; void (*move_to)(sbo_buffer* buffer, sbo_buffer*) noexcept = 0; }; template&lt;class T, class R, class...Args&gt; hyper_function_vtable&lt;R,Args...&gt; heap_vtable() { return { [](sbo_buffer const* ptr, Args&amp;&amp;...args)-&gt;R { // call return (*static_cast&lt;T*&gt;(ptr-&gt;heap_ptr))(static_cast&lt;Args&amp;&amp;&gt;(args)...); }, [](sbo_buffer* ptr)-&gt;void { // dtor delete static_cast&lt;T*&gt;(ptr-&gt;heap_ptr); }, [](sbo_buffer* buffer, sbo_buffer const* src){ T const* pt = static_cast&lt;T const*&gt;(src-&gt;heap_ptr); buffer-&gt;heap_ptr = new T( *pt ); }, [](sbo_buffer* buffer, sbo_buffer* src) noexcept{ T* pt = static_cast&lt;T*&gt;(src-&gt;heap_ptr); buffer-&gt;heap_ptr = pt; src-&gt;heap_ptr = nullptr; } }; } template&lt;class T, class R, class...Args&gt; hyper_function_vtable&lt;R,Args...&gt; stack_vtable() { return { [](sbo_buffer const* ptr, Args&amp;&amp;...args)-&gt;R { // call return (*static_cast&lt;T*&gt;(ptr-&gt;stack_data))(static_cast&lt;Args&amp;&amp;&gt;(args)...); }, [](sbo_buffer* ptr)-&gt;void { // dtor static_cast&lt;T*&gt;(ptr-&gt;stack_data)-&gt;~T(); }, [](sbo_buffer* buffer, sbo_buffer const* src){ T const* pt = static_cast&lt;T const*&gt;(src-&gt;stack_data); ::new( (void*)buffer-&gt;stack_data ) T( *pt ); }, [](sbo_buffer* buffer, sbo_buffer* src) noexcept{ T* pt = static_cast&lt;T*&gt;(src-&gt;stack_data); ::new ( (void*)buffer-&gt;stack_data ) T(std::move(*pt)); static_cast&lt;T*&gt;(src-&gt;stack_data)-&gt;~T(); // moved-from is invalid! } }; } template&lt;std::size_t limit, class T&gt; constexpr bool store_in_small_buffer() { return (sizeof(T) &lt;= limit) &amp;&amp; std::is_nothrow_move_constructible&lt;T&gt;{}; } template&lt;std::size_t limit, class T, class R, class...Args&gt; hyper_function_vtable&lt;R,Args...&gt; create_vtable() { if constexpr( store_in_small_buffer&lt;limit, T&gt;() ) { return stack_vtable&lt;T, R, Args...&gt;(); } else { return heap_vtable&lt;T, R, Args...&gt;(); } } template&lt;std::size_t limit, class T, class R, class...Args&gt; hyper_function_vtable&lt;R,Args...&gt; const* get_vtable() { static const auto vtable = create_vtable&lt;limit, T, R, Args...&gt;(); return &amp;vtable; } template&lt;std::size_t limit, class F, class R, class...Args&gt; void create( sbo_buffer* here, F&amp;&amp; f ) { if constexpr( store_in_small_buffer&lt;limit, std::decay_t&lt;F&gt;&gt;() ) { ::new ((void*)(here-&gt;stack_data)) std::decay_t&lt;F&gt;( static_cast&lt;F&amp;&amp;&gt;(f) ); } else { here-&gt;heap_ptr = new std::decay_t&lt;F&gt;( static_cast&lt;F&amp;&amp;&gt;(f) ); } } that is the vtable work. struct emplace_t {}; template&lt;std::size_t limit, class R, class...Args&gt; struct hyper_function_state { hyper_function_vtable&lt;R,Args...&gt; const* vtable = nullptr; union sbo_t { sbo_buffer base; char stack_data[limit]; sbo_t():base() {} }; sbo_t sbo; R operator()(Args...args)const { return vtable-&gt;call( &amp;sbo.base, static_cast&lt;Args&gt;(args)... ); } explicit operator bool()const { return vtable!=nullptr; } hyper_function_state&amp; operator=(hyper_function_state&amp;&amp; o) { if (this == &amp;o) return *this; reset(); vtable = o.vtable; if (vtable) { vtable-&gt;move_to(&amp;sbo.base, &amp;o.sbo.base); } o.vtable = nullptr; return *this; } hyper_function_state(hyper_function_state&amp;&amp; o): vtable(o.vtable) { *this = static_cast&lt;hyper_function_state&amp;&amp;&gt;(o); } hyper_function_state&amp; operator=(hyper_function_state const&amp; o) { if (this == &amp;o) return *this; reset(); vtable = o.vtable; if (vtable) { vtable-&gt;copy_to(&amp;sbo.base, &amp;o.sbo.base); } } hyper_function_state(hyper_function_state const&amp; o) { *this = o; } template&lt;class F&gt; hyper_function_state( emplace_t, F&amp;&amp; f ) { create( &amp;sbo.base, static_cast&lt;F&amp;&amp;&gt;(f) ); vtable = get_vtable&lt;limit, std::decay_t&lt;F&gt;, R, Args...&gt;(); } void reset() { if (vtable) { auto* tmp = vtable; vtable = nullptr; tmp-&gt;dtor(&amp;sbo.base); } } }; that gives you the state machinery, including calling/destroying/etc. template&lt;class R, class... Args&gt; class hyper_function&lt;R(Args...)&gt;: private hyper_function_state&lt;sizeof(void*)*6, R, Args...&gt; { using base=hyper_function_state&lt;sizeof(void*)*6, R, Args...&gt;; public: using base::operator(); using base::operator bool(); template&lt;class Callable, class = decltype(R(std::declval&lt;typename std::decay&lt;Callable&gt;::type&gt;()(std::declval&lt;Args&gt;()...))), std::enable_if_t&lt; !std::is_same&lt; std::decay_t&lt;Callable&gt;, hyper_function &gt;{}, bool &gt; = true &gt; hyper_function( Callable&amp;&amp; callable ): base( emplace_t{}, static_cast&lt;Callable&amp;&amp;&gt;(callable) ) {} }; and there are probably typos. About 3 times longer. But small buffer optimization can be big, performance wise. Untested. Also plays fast and loose with union aliasing a bit. 
That made my day thank you. I was laughing hysterically in public drawing awkward stares from onlookers.
I think you’re mixing up the complexity of the language and the complexity of programs *written in* those languages. C, the language, is objectively less complex *and less complicated* (whatever that means) than C++, as can be seen both by the size of spec (ignoring the library) as well as the size of complete compiler implementations. This is a known trope amongst compiler writers. Put differently: try writing a [TCC](https://en.wikipedia.org/wiki/Tiny_C_Compiler) equivalent for C++.
&gt; For formatting there is clang_format which seems to be a nice way but I am using gcc for compiling my code and to format my C++ I have to suddenly install clang tools. This just leads to more work and effort. sudo apt install clang-tools You call that ‘work and effort’? &gt; Coming from a JS background, npm set high expectations in this area. One word: left-pad. Have fun with C++, though!
Less complex, absolutely. Less complicated? No way in hell. The mental load when using C scales very poorly with the complexity of the problem being solved, and the percentage of the load that comes from addressing the combination of defects and deficiencies in the language design, as opposed to the problem being solved, becomes ridiculous. The language ergonomics make avoiding devolution to spaghetti coffee a full time job, initialization and cleanup procedures become all-consuming, and... well... complications abound in even the most disciplined C codebase. C is **complicated**. That's not to say that C++ is not, but most of its complication comes from its complexion.
Yep that or question was a mistake on my part of missing fixing one of the various such question phrasings from Corentin's original text. It's a bug in the poll. We should all be familiar with bugs ;-) As for the second question.. Think of it this way.. Which one should the committee spend more time and resources on?
Uh what actual problem does this solve? I've never used includes in the middle of a class definition.
It has been accepted by LEWG both in Jacksonville and Rapperswil (after some minor changes), now it is in LWG. I wasn't in San Diego and I won't be in Kona either, but hopefully I'll find someone to push it forward in Kona. 
&gt;One would assume that every project at a decent size would use precompiled headers Unfortunately, I have had a hard time getting precompiled headers to work well with my CMakeLists, and that means I'm not going to bother setting them up for any build system (as I found that setting them up for MSVC, but avoiding them for Clang/GCC wasn't particularly easy or tidy at all)
&gt; hopefully I'll find someone to push it forward in Kona. I really hope so. It's a really useful tool to have.
&gt;You call that ‘work and effort’? To be fair, getting that working on Windows is significantly less easy. It's honestly probably easiest to install it on the WSL, and then just run and interact with it through that haha. I think the JS environment probably sets high expectations for ease-of-use here: struggling with installing tools, configuring them, and dealing with tons of those sort of "environment" issues seems to be a struggle that's especially unique to C/C++ devs.
I'd say starting it and posting a link to your repository with a decent read me will get the job done. People will tell you their opinion about it, all that's left for you to do is listen.
In plain old C, it was a macro hack used to generate code operating on some data but in different ways. For example, you could have a \`.inc\` file containing something like: X(int, quork, 5, "Hello") X(char, bork, 7, "cruel") ... X(short, blork, 42, "world") ... and then, in your C file, include this shortly after having (re)defined the macro: struct foo { #define X(type, name, val, desc) type name; #include "definitions.inc" #undef X }; Perhaps later on, you'd like to generate a piece of code that does something for every member of the struct: #define X(type, name, val, desc) if (mystruct.(val) &gt; 5) printf("%s\n", mystruct.(desc)); #include "definitions.inc" #undef X Basically poor man's templates.
If you're using it for reflection purposes, there are much cleaner ways to do it than includes in the middle. But I see the overall point, it seems to basically be for separating generated code and non-generated code that are part of the same class.
Woah woah woah. Just install LLVM is easy. Or use Visual Studio since it comes with clang-format support out of the box. Or for older versions the clang-format plugin comes with the tool itself. Or just copy the .exe file from somewhere.
&gt; adding a #include in the middle of a class definition. please don't
&gt; To be fair, getting that working on Windows is significantly less easy if you use an IDE such as visual studio or qtcreator it's included by default in recent versions, and if you're not using visual studio you're certainly using msys where it is just a `pacman -S clang-whatever` away
Boost.Typeindex is definitely not a full replacement for RTTI. But you'd be surprised how many code bases only ever do exact dynamic casting. One example codebase is the whole of Boost, I remember Antony replaced all use of RTTI in the whole of Boost with Typeindex to demo this, and all the unit tests passed. As Boost can mostly still work with exceptions globally disabled, it is possible to use almost all of Boost with RTTI and exceptions globally disabled. Few in the wider C++ world realise stuff like this about Boost. It is not documented at all :(
The point is that it's possible to work around limitations of the language using tricks like this. Sometimes language features come along that deprecate such a tricks by being better/cleaner/safer, but it will never be 100% possible therefore the include mechanism will never be legacy. 
&gt;Or use Visual Studio since it comes with clang-format support out of the box. Or for older versions the clang-format plugin comes with the tool itself. oh piss that's right
Why not?
yeah, totally forgot about that :x
Well, they are measurable improvement. And given that there's no permanent solution in sight it's certainly something worth doing. As for CMake - we ditched CMake long time ago, but in particular precompiled headers were not that difficult to setup as far as I can remember. Granted we only had it enabled for [https://pastebin.com/MYuhnq27](msbuild and xcodebuild). After ditching CMake all projects were migrated to gn, where enabling precompiled headers is pretty much trivial config("precompiled-header") { include_dirs = ["//build/config"] precompiled_header = "prefix.h" if (is_win) { cflags = [ "/FI$precompiled_header" ] precompiled_source = "//build/config/empty.cpp" } else { precompiled_source = "//build/config/prefix.h" } } 
 $ iex (new-object net.webclient).downloadstring('https://get.scoop.sh') $ scoop install llvm $ clang-format thethings 
I'll quote an answer I gave not long ago when speaking about why headers are a pain and why I thought just throwing more build servers at your team is not a solution: &gt;I'll try to answer this, but it would really need a full article to explain everything correctly (might write one if I get some free time in a few weeks). Note that I am no compiler dev, so I might be wrong on some things. I'm not sure what you call ecosystem exactly, but the build model of C++ is (kind of) broken, and the tools too. (I'm not saying it's easy to fix though!) By that I mean that we rely too much on having things in the headers. Hell, for templates we don't even have the choice. That's fine for very small functions, but as soon as you have such functions that start to call a few other functions like this (templates!) this becomes oh god so bad for compile times. Why will you ask ? There are many reasons, the 1st one is that for each TU, the frontend of the compiler will need to instantiate those functions if called. FOR EACH TU using them. Unless you use extern templates. The best of optimizations is to do 0 work. This is not (yet?) possible because of the header approach we have for interfacing code. Sure, we have ODR, but I have yet to see a toolchain that properly uses this correctly. We do need a shared frontend for compilers (mentionned in https://youtu.be/b\_T-eCToX1I for example) but that's not easy considering the amount of stuff we put in headers. The good part about the current system: it's easy to scale, just fire up more processes, each TU is independant! The downside ? It has a HUGE IO and processing cost, because you do the same thing over and over again. Maybe modules will help for that, maybe not. And then the fact we now rely so much on things getting inlined! How many times do people say "it's ok, the compiler will inline it". Sure, in optimized builds, but in debug, nah. That's how you get 100x difference between debug and release. You might argue this is not the standards problem, that it is a QoI issue. I tend disagree with this, way too many papers advocate zero-overhead when it's actually "probably zero-overhead in release if lucky with the optimizer". Still a QoI issue, but we might want to have optimized std:: in debug builds, unless we opt in to debug the lib. (and actually it would be good for any namespace we chose so). A good example is the overhead in debug of std::atomic... (especially msvc) https://godbolt.org/z/QYzHjR I sort of understand why it is a library type, but this should really just be a builtin type. And we keep bloating headers, because it's fast, it's templated, it's easy to use ! (and precompiled headers are not the right solution to this.) This one is more a of a community and cultural issue though. To sum up, I think "put things in the header" approach is, for me, a broken legacy of C and old template machinery. &amp;#x200B;
Note: not LITERALLY on fire!
This should be fixed by reflection, not playing with XMacros. They are useful (in some rare cases such as this one), I'm not saying we should remove them. However I do maintain my claim that the header system is a legacy thing, and not a good way to handle dependencies. 
I could be wrong but I suspect that with reflection + metaclasses you would be able to handle all reasonable use cases. Even now, using a combination of faking reflection and CRTP, I've dealt with issues like this often and there's always been a better way than to use includes in the middle.
When you need to support the tooling of many dozens of c++ developers, and deploy clang-format from a central hub such that it works properly in windows, linux, and mac, while also integrating with your own build system, it's not as trivially easy as a one-liner.
It's used in LLVM for including TableGen'ed results. Like https://github.com/llvm-mirror/llvm/blob/51f78de4177ffd2ba7b6b650bc88e53effb725e3/lib/Target/AArch64/Utils/AArch64BaseInfo.cpp#L32
 Company: Transunion Type: Full time Description: We are looking for exceptional developers to join our fast growing Information Technology Team in sunny Florida. Looking for generalists with strong computer science fundamentals. We use latest compiler and language features (gcc 8.2, boost 1.68) and are very agile team Location: Boca Raton, FL Remote: No Visa Sponsorship: Yes, H1B Transfers only Technologies: C/C++/C#/Python, Linux, Machine Learning, AI, Networking Protocols (TCP/IP, UDP), Big Data, Compilers, multi threading and distributed systems Contact: We have openings at different experience levels. You can send email to smukkam @ transunion.com or apply at [https://transunion.taleo.net/careersection/tuext/jobdetail.ftl?job=18002695&amp;lang=en&amp;sns\_id=mailto#.W-Mmk5VVDMw.mailto](https://transunion.taleo.net/careersection/tuext/jobdetail.ftl?job=18002695&amp;lang=en&amp;sns_id=mailto#.W-Mmk5VVDMw.mailto)
Can you break this up into paragraphs? It's difficult to read.
\&gt; My quest for relearning C++ started in November 2018. &amp;#x200B; So \*Learn C++ in 30 days\* is not a marketing gimmick? Or is this guy just a fucking miracle?
&gt; I have had a hard time getting precompiled headers to work well with my CMakeLists Why? Have you tried [cotire](https://github.com/sakra/cotire)? In my experience it worked like a charm.
&gt; A good example is the overhead in debug of std::atomic... (especially msvc) https://godbolt.org/z/QYzHjR I sort of understand why it is a library type, but this should really just be a builtin type. 1) What overhead of debugging std::atomic? I've written my own implementation of std::atomic with an API that's like 90% identical, and there's no difference to the assembly generated between "release" and "debug" builds beyond some assertions that get added to debug builds. 2) If you made this built in, you just crippled my ability to work around parts of the standard that my compiler doesn't support (properly, or at all). I regularly have to re-implement many std namespace features in my own namespace, but anything that's a built-in type is completely opaque to library writers, and therefore unavailable to anyone who doesn't use one of the big-three compilers, or uses an older version of them. The less "built-in" stuff, the better.
&gt; Which one should the committee spend more time and resources on? Well, I don't know, these 2 things are orthogonal. Type-punning should be standardized IMO, under certain conditions, Linus thinks the current std is unnecessarily restrictive, and it "just works" in practice. 
I've been adding PCH support to the buildsystem I work on at work (It's an internal thing, not publicly available) It's had support for MSVC precompiled headers for years and years, but we wanted to get some compile speedup out of GCC and Clang. GCC's precompiled header support is utterly broken, at least on Windows. As in, I can trivially cause internal-compiler-errors, or just straight up segmentation faults, with GCC by attempting to use PCH files. Clang works, but only 7.0 or newer, and it's *very* particular about where things are located on the filesystem, and even then I was able to crash the 6.0 release on a regular basis. Clang 7.0 doesn't seem to have the same problems of crashing, but Clang is producing binaries that fail our internal testing (with or without pch files) so we're not currently able to use it. We've got a couple of million lines of code, and our compile times for the entire code base is measured in terms of "How many days", so we have a strong incentive to decrease compile times, and I'm really frustrated that PCH support was so hard to get out of GCC / Clang.
!removehelp
&gt; For example, partial classes in C# is a language feature for a pattern that can be solved in C++ by adding a #include in the middle of a class definition. [Actual footage of the code review](https://youtu.be/YcR9k8o4I0w?t=53s)
&gt; Would Stackoverflow be the right place? I'm not sure... Your asking for an opinion, that's not acceptable on SO. &gt; ... and it doesn't seem that you will have much feedback on your idea there. You might get more response, iff you would actually share your secret with us, but it better be good!
Even a genius would require more than 30 days to learn [those initialization rules](https://www.reddit.com/r/cpp/comments/ad07zw/initialization_in_c_is_seriously_bonkers/).
Everyone's got an idea. Ideas are cheap.
Didn't he say he learned C in 30 hours?
but this guy is a *fucking* genius. unlike Scott Meyers [As you may know, I retired from active involvement in C++ at the end of 2015, and in the ensuing two and a half years, I’ve forgotten enough details of the language that I am no longer able to properly evaluate bug reports regarding the technical aspects of my books. C++ is a large, intricate language with features that interact in complex and subtle ways, and I no longer trust myself to keep all the relevant facts in mind. As a result, all I can do is thank you for your bug report, because I no longer plan to update my books to incorporate technical corrections. Lacking the ability to fairly evaluate whether a bug report is valid, I think this is the only responsible course of action.] (http://scottmeyers.blogspot.com/)
I doubt the guy learning C++ for the first time is doing that.
how about "basic readability"
Secret open-source project is something that doesn't make sense :) I think of creating an analogue of [Microsoft's PPL](https://docs.microsoft.com/en-us/cpp/parallel/concrt/parallel-patterns-library-ppl?view=vs-2017) library, but cross-platform. I also want to add some features that i personally miss in PPL. Yes, that's an ambitious project. I know about pplx, which is a part of CppRest SDK. It IS a cross-platform version of PPL, but it's VERY lopped. It lacks many core features of PPL. I've also heard about [Intel's TBB](https://www.threadingbuildingblocks.org/), wich IS cross-platform. But as far as i can tell it isn't that handy and 'cute' as PPL (maybe i'm wrong i haven't dig in that too much yet).
coughPrecompiled headersCough... I mean... really?!
Yes. What i'm asking here, is how do i validate an idea? Is there a PLACE where can ask other people's opinions to find out if that even worth to spend time on?
&gt;It's not a function template though. It's a member function of a class template. Very different. 
That's not quite in the middle of a class. I mean this is just a different style (AFAICS) of platform normalization where you conditionally include different files rather than have preprocessor branches in a single file.
&gt; Yes, that's an ambitious project. You have to tell me where you get that kind of weed, man [or women, or it], you're out there. Why don't you just contribute to TBB f.e., that will certainly keep you busy and at least you know that you're not wasting your time [or you'll be told quickly that you do]. 
 \*\*Company:\*\* \[Athena Capital Research (Asia) www.athenacr.com\] \*\*Type:\*\* \[Full Time\] \*\*Description:\*\* \[ We are a quantitative trading firm, specializing in algorithmic strategies. Our passion and expertise lie in technology, mathematics, and finance. We unite these strengths to create a best-in-class trading infrastructure and generate superior investment results. We are looking for a well-rounded and driven individual with a strong background in Computer Science to join our team. You will participate in the whole development cycle of a high frequency trading operation. You will be working together with a dynamic team of software engineers.\] \*\*Location:\*\* \[Hong Kong\] \*\*Remote:\*\* \[No\] \*\*Visa Sponsorship:\*\* \[Yes\] \*\*Technologies:\*\* \[Required: C++, Python.\] \*\*Contact:\*\* \[Please apply by sending your resume to [careers.hk@athenacr.com](mailto:careers.hk@athenacr.com) \]
I every much would prefer a language feature for that. Such clever tricks are one of the reasons, why tooling in c++ is so bad.
No one prevents you to write your own my::atomic (you could do that already in c++98 and in fact boost has done exactly that). That doesn't mean a built-in type that the compiler knows intrinsically wouldn't have its advantages and imho there are many types in the standard library that fall into the same category.
I had a similar thought when I saw your post but I'll be gentler and say that C++ is humongous and by far the most complicated programming language ever invented. It's so complicated that it is often said that no one completely understands it. I could say more but I don't want to discourage you. Stay enthusiastic and keep learning. There is so much much much much more to learn.