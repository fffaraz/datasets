When you already want to bind to a function (rather than implement inline), bind has less boilerplate since you don't repeat all the arguments and their types. I have just implemented such a bind that works with my Function class (in the already linked file). Now the following works: struct Foo { int x; int func(int y) { return x + y; } }; Foo foo{1}; Function func = AIPSTACK_BIND_MEMBER(&amp;Foo::func, &amp;foo); Note that this bind is not coupled to Function and can generally be used instead of std::bind (possibly passed to std::function) when the advanced capabilities of std::bind are not used.
obviously, but in theory it can be "compressed". I a same way as "pointers" into small array can be short indexes if you remember the starting offset.
I was hoping for some elaboration on the topics from her talk and that's what I got. Great episode! :)
It might be possible to optimize this in the statically linked world, but it is basically impossible in the dynamic linking world. If you linked statically, you could imagine putting all the vtables in some compressed area and then knowing the offset of the beginning. But if you link dynamically, the location of each vtable is controlled by whatever shared library it is compiled as part of. Loading a bunch of different shared libraries, the vtable would be all over the place. The vtable itself would contain function pointers that have offsets that need to be taken care of in the dynamic loading process, so relocating to the binary during shared linking probably isn't practical. Anyhow, not an expert in this sort of thing but it seems extremely difficult for shared linking.
Since every other pointer in the app would still be 64-bit, you'd (probably) not see much gain, especially in any performance-sensitive app that should be written better than to be abusing `virtual` and dynamic polymorphism. If you can limit all your data to the 32-bit address range, just use something like [x32](https://en.wikipedia.org/wiki/X32_ABI) (32-bit address ranges in the x64 ISA) instead and get heavy gains (supposedly +40% across SPEC) from "compressing" _all_ pointers and not just vtable pointers.
Loosely related this talk was amazing: https://www.youtube.com/watch?v=gVGtNFg4ay0
Since C++11/14 is not a verison of C++, you can't talk about compiler support for it. icc support for 14 has really lagged, with support for template variables only landing in icc 17. So it's not correct to say that icc 15 supports 11/14; even icc 16 does not.
Thanks for detailed hints! They should be resolved now! The missing part is this VS versioning, but I made a remark below the table. Don't blame me for the lack of https... I am using blogger that cannot handle https at the moment. Should change in 2018 as I plan to move to some different platform.
Have you or anyone else involved thought about bundling Meson into a standalone package? (i.e. having its own bundled python interpreter) This would accomplish similar goals as `meson init`, making the get-up-and-go experience for C++ much simpler. The only reason I have Python 3.4 and pip ready to go is because I have a single Python project that I work on, and even then I'm going to no longer be working on it later this year. That's one nice thing about CMake and Premake/GENie: you just need the one binary. Regardless, thank you for adding `meson init` :)
My status on C++ status is "I desperately need modules"...
have you tried experimental versions? Clang and VS have their implementations already available.
Yup, I tried VS, but it feels a bit clunky, with no IDE support. It just made me more hungry for it, IMO it's the most groundbreaking addition since move semantics, we need it so much.
yep, I totally agree - that we need it. Still, the change won't happen overnight, there's a lot of existing cpp code to be ported to modules... 
Lets see. March: Embo April: CppRussia, ACCU May: C++Now June: NDC OSLO September: CppCon October: Pacific++ November: Meeting C++ Incomplete, out of my head right now...
No, because he is articulate and deeply knowledgeable.
Even there, this is because there lacked range based algorithms; in particular range based in/out ones. A library deficiency. Now, creating and sorting an otherwise const array I give you; but that is a langue deficiency, the inability for reference lifetime extension and elision to generalize. But I do use that trick sometimes. When the operation is bespoke and not worth solving more broadly. 
Using the latest clang and gcc in Godbolt generate same assembly (at a glance) as the ones I am using.
Try clang, I've been using it for multiple projects and enjoy it!
Maybe I'm missing something? I can't see how this switch would enable a jump table: int a=2; switch a { case 1: DoStuff1(); break; case ObjEquals2: DoStuff2() break; case 3: DoStuff3(); break; }
It wouldn't. But jump tables are only one possible optimisation, not a mandatory implementation. It's not as if every possible switch gets compiled into a jump table today...
This is the top-level comment for **meta** discussion. Reply here if you have questions or concerns about this post.
This is easy to find scenarios where unsigned is slower than int. Look at this, and removed 'unsigned' on the 1st line, to see the difference. https://godbolt.org/g/t9CmhQ 
**Company:** NVIDIA **Type:** Full Time, Internships **Description:** We make parallel computing platforms! You've probably heard of NVIDIA, but you may not know that we have a rich history as a C++ shop. C++ is the programming language used by CUDA, our parallel programming environment and SDK, and a large part of our codebase is written in C++. We do make hardware, but we're also a software company. NVIDIA is a great place to work for C++ devs these days, as we're at the forefront of a number of booming technologies, like parallel computing and machine learning. Come join us! **Location:** Our global headquarters is in Santa Clara, CA, USA, but we have offices all over the world, including the US East Coast (Boston), Europe and India. **Remote:** Some teams and positions can be remote. **Visa Sponsorship:** Yes. **Technologies:** C++03, C++11, C++14, CUDA C++, Boost, Vulkan, OpenGL, DirectX. We are primarily a Windows and Linux shop. **Contact:** blelbach@nvidia.com, @blelbach on Twitter or wash on the C++ Slack/Freenode IRC.
While the thread is young, I'd like to encourage people to hire more people remotely. Asking someone to work for you is one thing, expecting them to move out, leave everything behind, etc is another. I have been working remotely for a long time, it works great, don't be scared. Try it out !
It's well overdue
That's good to know, thank you.
I have yet to see anything that isn't either a contrived example, or an outright bug that needs to be reformulated in order to not get defeated by the optimiser, and I do believe that C++ in general would be able to survive having a well-defined signed overflow, but yes: you can write code that behaves significantly differently depending on your optimisation flags. Whether that's a good or a bad thing I'll leave for others to decide. I find the more interesting result of your program to be what happens when you compile it with icc 18, which happily reduces it to `return 10;` for both signed and unsigned types. It's been doing that since at least version 16 (version 13 generates different code for signed and unsigned). Version 16 was released in august 2015, so either the type of code that gets optimized out just doesn't happen very much outside of, well, contrived examples, or people just completely failed to notice large numbers of bugs in programs compiled by icc for the past year and a half. Again, I'll leave it to others to decide which it is. 
**Company:** [RaySearch Laboratories](https://www.raysearchlabs.com) **Type:** Full time **Description:** RaySearch is a technology company with a difference - our software is a vital weapon in the ongoing battle against cancer. We help save lives through innovative software for radiation therapy, which is one of the most important forms of cancer treatment. Our success has led to rapid growth and we are therefore looking for talented software developers. RaySearch believes in investing in its people. We offer outstanding staff benefits and excellent career development opportunities in a flexible and stimulating environment. We prioritize knowledge-sharing, creativity and collaboration, and you will work together with some of the most talented and highly educated people in the industry. You will work in a modern office environment with access to the latest hardware and tools. We encourage a healthy work-life balance and have created a strong social culture, with regular events and activities for employees. RaySearch is committed to equal opportunities. We value diversity and are dedicated to preventing discrimination. [About RaySearch Laboratories](https://www.raysearchlabs.com/About-RaySearch) **Role** We are recruiting skilled C++ developers to join our development department. Our development department is organized in agile teams with physicists, algorithm developers, application developers and test specialists, all dedicated to designing and evolving cutting-edge medical software. Developers generally participate in all steps of the development process, including analysis, architecture, design, implementation and testing. We recruit for full-time positions based at our head office in central Stockholm. **Education &amp; Experience** * MSc in engineering physics, computational science, or similar. * 3-10 years of experience in an academic or industry environment. * Strong programming skills, especially in C++, modern C++ and architecture. * Strong algorithm skills preferably including parallel computations on CPU and/or GPU. * CUDA skills are meriting, but not required. * Specialized knowledge in physics or algorithm development is required for the respective competence groups. * Software development in C#/.NET is meriting. **Location:** Stockholm, Sweden. Fluency in English is required. Fluency in Swedish is a strong advantage. **Remote:** No **Visa Sponsorship:** No **Technologies:** * Parallel algorithms both on CPU and GPU. * CUDA experience very much appreciated (we currently rely on C++Amp). * C++11/C++14, will adopt C++17. * Visual Studio (currently Visual C++ 2017), boost, google test with visual studio integration, ReSharper C++ &amp; C#. * The algorithms are implemented in C++ and the application layers in C#/.NET, under Windows, for Windows. Scripting in Python. **Contact:** To apply, email your letter, CV and transcript of records including course listing with grades to work@raysearchlabs.com, subject "reddit c++". Questions are asked to the same address. More information and positions, in Stockholm and elsewhere: [RaySearch Laboratories Career and other open positions](https://www.raysearchlabs.com/career), [RaySearch Laboratories at Stack Overflow](https://stackoverflow.com/jobs/companies/raysearch-laboratories). 
Should we apply through your contact email?
signed to be preferred to unsigned, in most cases, has been discussed many times in many places. For examples: https://www.youtube.com/watch?v=wvtFGa6XJDU https://www.youtube.com/watch?v=equbUrX-ZWQ&amp;t=9s https://www.reddit.com/r/cpp/comments/6ngkgc/2017_toronto_iso_c_committee_discussion_thread/dk9ssly/ 
I stand corrected - to be fair, this has only been an option (outside of enterprises) since Windows 10 Fall Creators Update. A great improvement.
This is excellent. Did you have to do any particular porting to get it to build, or did it Just Work?
I had to apply some bug fixes and workarounds plus create new tooling (e.g. a specialized wasm linker in JS). Most of my time was tracking down failures.
Cool, thanks! This project is really exciting.
I gave up on it, to be honest. 
Sure, send me your resume.
Regarding class member initializers -- how do you organize your classes? I put data members first and then constructors --https://github.com/Ebenezer-group/onwards . 
https://google.github.io/styleguide/cppguide.html#Declaration_Order
**Company:** [PhishMe](https://phishme.com) **Type:** Full Time **Description:** With more than 90% of breaches attributed to successful phishing campaigns, it’s easy for organizations to point to the everyday employee as the root cause – as the problem to be solved. We disagree. PhishMe believes employees – humans – should be empowered as part of the solution to help strengthen defenses and gather real-time attack intelligence to stop attacks in progress. We are seeking a [Senior Software Engineer, Windows](https://careers-phishme.icims.com/jobs/1547/senior-software-engineer%2c-windows./job) and a [Application Security Engineer](https://careers-phishme.icims.com/jobs/1532/application-security-engineer/job) to join a team of C++ Software Engineers. This team is responsible for developing applications on Windows Operating Systems that may impact over 10MM endpoints globally. * [Senior Software Engineer, Windows](https://careers-phishme.icims.com/jobs/1547/senior-software-engineer%2c-windows./job) - We are seeking a C++ developer with 8+ years of experience in Software Development, at least 4+ years in Windows development. This position will join additional Senior level C++ engineers. Extensive experience with C++ and Windows APIs, and knowledge of Windows COM APIs is a HUGE plus! * [Application Security Engineer](https://careers-phishme.icims.com/jobs/1532/application-security-engineer/job) - We are seeking a Application Security Engineer that can demonstrate an understanding of C/C++ programming skills and are comfortable learning new languages. The ideal candidate will be able to both create/identify backlog items and work those items. Your experience should demonstrate that you have professional experience in information security, as a vulnerability researcher, QA engineer, or developer. It would be OUTSTANDING if you have experience with secure code quality practices and tooling to support quick engagements and rapid analysis - static analysis tools (Coverity, Checkmarx, or similar), dynamic scanning (Rapid 7, AppSider, or similar), Fuzzing (AFL, Peach, or similar) and code coverage (Bullseye, LDRA, etc). **Location:** Leesburg, VA or US Telecommute **Remote:** Yes, majority of employee's are remote **Visa Sponsorship:** No **Technologies:** * Required: Software Engineer = C++11 (C++14 &amp; C++17). Application Security Engineer = C/C++ or proven experience with OOP (object oriented programming design and principles). * Optional: OS system expertise for core concepts and subsystems. A strong knowledge of C#/.NET application development. Experience with Microsoft Office plugins. Knowledge and Experience with Objective-C or Swift. Knowledge and experience using relational database systems especially SQLite. **Contact:** * [Senior Software Engineer, Windows](https://careers-phishme.icims.com/jobs/1547/senior-software-engineer%2c-windows./job) - You can apply for this job at the following link: https://careers-phishme.icims.com/jobs/1547/senior-software-engineer%2c-windows./job * [Application Security Engineer](https://careers-phishme.icims.com/jobs/1532/application-security-engineer/job) - You can apply for this job at the following link: https://careers-phishme.icims.com/jobs/1532/application-security-engineer/job If you are interested in learning more about this position or the work environment or anything related to the role, please DM me here on Reddit. Thank you!
Visual C++ supports using 32-bit (zero-extended) pointers within 64-bit code, so this is possible, and my personal benchmarking shows it's quite gainful. I expect it's not being prioritized because of the pervasive use and adoption of Address Space Randomization to increase security of 64-bit programs. If you force all code into the first 2-4GB of process address space, you lose most of those randomization gains.
Regarding the last point, I realize it's hard to find a good heuristic. That's part of why it would be so great if the user could unfold as they please, but alas, it never caught on early. As you say, an editor or terminal could at least provide the means to do this based on a more knowledgeable parser for the error. I don't have much to offer in the way of a good heuristic here, only an idealistic view :/ For the first point, I was thinking along the lines of operators, where there are many possibilities for what `a + b` could be referring to and compilers currently list them all alongside why each doesn't work, such as in [this example](https://godbolt.org/g/SiUJTe). Extra lines of clarification for any concept-enabled overloads doesn't do much to help that. Naturally, C++ isn't the only language that has to deal with this. For example, here's what happens if I try to add two instances of my own empty class in Kotlin: Error:(5, 6) Unresolved reference. None of the following candidates is applicable because of receiver type mismatch: @InlineOnly public operator inline fun BigDecimal.plus(other: BigDecimal): BigDecimal defined in kotlin @InlineOnly public operator inline fun BigInteger.plus(other: BigInteger): BigInteger defined in kotlin public operator fun &lt;T&gt; Array&lt;???&gt;.plus(elements: Array&lt;out ???&gt;): Array&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Array&lt;???&gt;.plus(elements: Collection&lt;???&gt;): Array&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Array&lt;C&gt;.plus(element: C): Array&lt;C&gt; defined in kotlin.collections public operator fun BooleanArray.plus(element: Boolean): BooleanArray defined in kotlin.collections public operator fun BooleanArray.plus(elements: BooleanArray): BooleanArray defined in kotlin.collections public operator fun BooleanArray.plus(elements: Collection&lt;Boolean&gt;): BooleanArray defined in kotlin.collections public operator fun ByteArray.plus(element: Byte): ByteArray defined in kotlin.collections public operator fun ByteArray.plus(elements: ByteArray): ByteArray defined in kotlin.collections public operator fun ByteArray.plus(elements: Collection&lt;Byte&gt;): ByteArray defined in kotlin.collections @InlineOnly public operator inline fun Char.plus(other: String): String defined in kotlin.text public operator fun CharArray.plus(element: Char): CharArray defined in kotlin.collections public operator fun CharArray.plus(elements: CharArray): CharArray defined in kotlin.collections public operator fun CharArray.plus(elements: Collection&lt;Char&gt;): CharArray defined in kotlin.collections public operator fun DoubleArray.plus(element: Double): DoubleArray defined in kotlin.collections public operator fun DoubleArray.plus(elements: DoubleArray): DoubleArray defined in kotlin.collections public operator fun DoubleArray.plus(elements: Collection&lt;Double&gt;): DoubleArray defined in kotlin.collections public operator fun FloatArray.plus(element: Float): FloatArray defined in kotlin.collections public operator fun FloatArray.plus(elements: FloatArray): FloatArray defined in kotlin.collections public operator fun FloatArray.plus(elements: Collection&lt;Float&gt;): FloatArray defined in kotlin.collections public operator fun IntArray.plus(element: Int): IntArray defined in kotlin.collections public operator fun IntArray.plus(elements: IntArray): IntArray defined in kotlin.collections public operator fun IntArray.plus(elements: Collection&lt;Int&gt;): IntArray defined in kotlin.collections public operator fun LongArray.plus(element: Long): LongArray defined in kotlin.collections public operator fun LongArray.plus(elements: LongArray): LongArray defined in kotlin.collections public operator fun LongArray.plus(elements: Collection&lt;Long&gt;): LongArray defined in kotlin.collections public operator fun ShortArray.plus(element: Short): ShortArray defined in kotlin.collections public operator fun ShortArray.plus(elements: ShortArray): ShortArray defined in kotlin.collections public operator fun ShortArray.plus(elements: Collection&lt;Short&gt;): ShortArray defined in kotlin.collections public operator fun String?.plus(other: Any?): String defined in kotlin public operator fun String?.plus(other: Any?): String defined in kotlin public operator fun &lt;T&gt; Collection&lt;???&gt;.plus(elements: Array&lt;out ???&gt;): List&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Collection&lt;???&gt;.plus(elements: Iterable&lt;???&gt;): List&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Collection&lt;???&gt;.plus(elements: Sequence&lt;???&gt;): List&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Collection&lt;C&gt;.plus(element: C): List&lt;C&gt; defined in kotlin.collections public operator fun &lt;T&gt; Iterable&lt;???&gt;.plus(elements: Array&lt;out ???&gt;): List&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Iterable&lt;???&gt;.plus(elements: Iterable&lt;???&gt;): List&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Iterable&lt;???&gt;.plus(elements: Sequence&lt;???&gt;): List&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Iterable&lt;C&gt;.plus(element: C): List&lt;C&gt; defined in kotlin.collections public operator fun &lt;K, V&gt; Map&lt;out ???, ???&gt;.plus(pairs: Array&lt;out Pair&lt;???, ???&gt;&gt;): Map&lt;???, ???&gt; defined in kotlin.collections public operator fun &lt;K, V&gt; Map&lt;out ???, ???&gt;.plus(pair: Pair&lt;???, ???&gt;): Map&lt;???, ???&gt; defined in kotlin.collections public operator fun &lt;K, V&gt; Map&lt;out ???, ???&gt;.plus(pairs: Iterable&lt;Pair&lt;???, ???&gt;&gt;): Map&lt;???, ???&gt; defined in kotlin.collections public operator fun &lt;K, V&gt; Map&lt;out ???, ???&gt;.plus(map: Map&lt;out ???, ???&gt;): Map&lt;???, ???&gt; defined in kotlin.collections public operator fun &lt;K, V&gt; Map&lt;out ???, ???&gt;.plus(pairs: Sequence&lt;Pair&lt;???, ???&gt;&gt;): Map&lt;???, ???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Set&lt;???&gt;.plus(elements: Array&lt;out ???&gt;): Set&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Set&lt;???&gt;.plus(elements: Iterable&lt;???&gt;): Set&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Set&lt;???&gt;.plus(elements: Sequence&lt;???&gt;): Set&lt;???&gt; defined in kotlin.collections public operator fun &lt;T&gt; Set&lt;C&gt;.plus(element: C): Set&lt;C&gt; defined in kotlin.collections public operator fun &lt;T&gt; Sequence&lt;???&gt;.plus(elements: Array&lt;out ???&gt;): Sequence&lt;???&gt; defined in kotlin.sequences public operator fun &lt;T&gt; Sequence&lt;???&gt;.plus(elements: Iterable&lt;???&gt;): Sequence&lt;???&gt; defined in kotlin.sequences public operator fun &lt;T&gt; Sequence&lt;???&gt;.plus(elements: Sequence&lt;???&gt;): Sequence&lt;???&gt; defined in kotlin.sequences public operator fun &lt;T&gt; Sequence&lt;C&gt;.plus(element: C): Sequence&lt;C&gt; defined in kotlin.sequences I do find it intriguing that this compiler groups overloads by failure reason like that so that it doesn't have to repeat the reason a bunch of times.
That sounds insanely complicated tbh. My logger is basic af, it's literally just a function that takes in a few strings, uses a global variable to store the program name, and outputs everything to either a FILE handle if it's not NULL, or stderr if it is. What does this offer on top of that?
&gt;&gt; C++2a Please do not use C++2a, we are still mentally scared from C++0x. :P Other than that: if you are willing to give us an access to the build of the compiler with the concept changes that would be much more helpful than the screenshot. Maybe even ping godbolt to add it to the compiler explorer. As for errors in the screenshot: they look ok to me, but if you want more realistic examples try porting some simple ranges code to concepts and see if your error is at least as good as the Niebler's C++17 black magic. :) 
I can see why you say it "spreads the code too much" if you go by that. I put data members first followed by functions.
I was going to write about my cppcon experience but was embarassed doing it so long after... thanks for taking away the stigma, now I'll do it too :-).
**for** (**int** *i* = 0; *i* &lt; *K*; ++*i*) { **bool** broken = false; **for** (**int** *j* = 0; *j* &lt; *K*; ++*j*) { **if** (*something*) { *broken* = true; break; } } }
``` for (int i = 0; i &lt; N; ++i) { bool broken = false; for (int j = 0; j &lt; M; ++j) { if (something) { broken = true; break; } else { do_software_things(); } } } ```
As minor addition: while it is nice to feature some IDEs such as VS or CLion, it would also be very much appreciated to mention e.g. KDevelop. It has many features based on clang, and even had it before CLion. I am just noting this, since if you already reference IDEs, it would be smart to also include the free software community a bit more, since the contributions do matter.
`for (int i = 0; i &lt; N; ++i) { bool broken = false; for (int j = 0; j &lt; M; ++j) { if (something) { broken = true; break; } else { do_software_things(); } } }` 
[Not in its current merged form.](https://botondballo.wordpress.com/2017/08/02/trip-report-c-standards-meeting-in-toronto-july-2017/#concepts) This, along with the other abbreviated function template concerns, will hopefully be settled before C++20. If not, then at least we have what we have.
**Company:** [IMC](https://www.imc.com) **Type:** [Full time] **Description:** [IMC Financial Markets is among the world’s leading proprietary trading firms, and a market maker in securities listed on exchanges across the globe. Our software makes millions of trading decisions daily. As a [software developer] (https://imc.wd5.myworkdayjobs.com/IMC_APAC/job/Sydney/Software-Engineer_REQ-00008-10) you’ll be working alongside traders to implement strategies which will challenge you to be creative with your implementation. You’ll need to produce solutions which compete in the extremely latency sensitive environment, whilst managing complexity. You’ll be working in a highly motivated team, controlling end-to-end product development. You’ll be placed in an environment consisting primarily of C++ and Java. We have a build chain which has been designed around the concept of daily production releases. A variety of systems and technologies keeps life interesting. We are hiring developers at all levels from graduates through to seniors. We believe in fostering a truly flat environment in which great ideas can be recognized as well as put into practice from anybody within our organization] **Location:** [Sydney] **Remote:** [No] **Visa Sponsorship:** [Yes] **Technologies:** [C++11, C++14, C++17, Linux, Boost] **Contact:** [Apply directly to our website] (https://imc.wd5.myworkdayjobs.com/IMC_APAC/job/Sydney/Software-Engineer_REQ-00008-10) 
In your screenshot, I see the following lines that confuse me slightly: test.cpp:34:22: error: Constraints not satisfied for alias template 'BigPtr' [with T=int], because static_assert(sizeof(BigPtr&lt;int&gt;)); test.cpp:31:12: note: 'int' does not satisfy 'IsBig', because: requires IsBig&lt;T&gt; test.cpp:28:17: note: 'sizeof(int) &gt; 100' (4 &gt; 100) evaluated to false concept IsBig = sizeof(T) &gt; 100; This diagnostic is made a bit more difficult to read, because the code after `because:` generally is the code that is "triggering" the note rather than the underlying cause. For instance at this line: test.cpp:31:12: note: 'int' does not satisfy 'IsBig', because: requires IsBig&lt;T&gt; The diagnostic line as written here is nonsense -- `int` does not fail to satisfy `IsBig` because of this `requires IsBig&lt;T&gt;` line. It fails to satisfy `IsBig` because of the *next* line, which is the definition `concept IsBig = sizeof(T) &gt; 100` I think the diagnostic would be more readable, and more "grammatical" / "formally correct" / whatever if the word "because: " is replaced with "at line: ". Here's how it would read then: test.cpp:34:22: error: Constraints not satisfied for alias template 'BigPtr' [with T=int], at line: static_assert(sizeof(BigPtr&lt;int&gt;)); test.cpp:31:12: note: 'int' does not satisfy 'IsBig', at line: requires IsBig&lt;T&gt; test.cpp:28:17: note: 'sizeof(int) &gt; 100' (4 &gt; 100) evaluated to false concept IsBig = sizeof(T) &gt; 100; 
Actually, I think you can see this both ways: For me, not matching the concept IS the reason for the error. There might then be several reasons, why that concept isn't matched, but one idea behind concepts (e.g. vs plain requires / sfinae clauses) is to think on a higher level about the types.
First of all thank you for your work. Regarding the warnings: First, I'd remove the green hat, as it doesn't provide any useful information. Second (and this is probably non-trivial), I personally would prefer to separate the message about the failed concept match and the message about why the concept wasn't matched. In particular if there are multiple different candidates, I'd prefer to first see a list of the candidates with a short explanation, why it could not be picked ("could not pick foo1, because type doesn't match concept bar1, could not match foo2, because type ...). And then an explanation for each of the failures (one could ever been imagine the use of numbers to link the two). The reason is that I'm usually only interested in one overload and this structure would allow me to find the relevant problem more easily.
Pleas e provide the source code that generates those messages.
That may be true at a high level, but the point of the diagnostics is to explain step-by-step what the problem is so that the programmer can understand. The explanation test.cpp:31:12: note: 'int' does not satisfy 'IsBig', because: requires IsBig&lt;T&gt; is simply incorrect -- `requires IsBig&lt;T&gt;` is not part of the definition of the `IsBig` concept. Here are some alternative diagnostic lines that would be correct, in my book: error: Constraints not satisfied for alias template 'BigPtr' [with T = int], because: requires IsBig&lt;T&gt; This would also be correct: note: 'int' does not satisfy 'IsBig', because: concept IsBig = sizeof(T) &gt; 100; note: 'sizeof(int) &gt; 100' (4 &gt; 100) evaluated to false I'm not saying that `int does not satisfy IsBig` is not related to the appearance of the code `requires IsBig&lt;T&gt;`, I'm saying that `because` is not the relationship.
The because here was originally meant to refer not to the source code below it but to the next note, did you understand that and still think it's a confusing place to set that because or did you not see the next note explaining why IsBig&lt;T&gt; is not statisfied? test.cpp:31:12: note: 'int' does not satisfy 'IsBig', because: // This because refers to requires IsBig&lt;T&gt; test.cpp:28:17: note: 'sizeof(int) &gt; 100' (4 &gt; 100) evaluated to false // this sentence concept IsBig = sizeof(T) &gt; 100;
Even with plain integers you only end up with a jump table if the cases are sufficiently dense. I don't see how that is an argument for or against that feature.
I had the exact same issue understanding, as I also thought the because was referring to the code below it. I think a lot of people will read it that way 
Maybe a "(see next note)" after or instead of the because would make this more understandable? 
Where is that *Analytics.h* file coming from?
Why remote is limited to US?
Even with plain integers you only end up with a jump table if the cases are sufficiently dense. I don't see how that is an argument for or against that feature.
**Company:** [www.zividlabs.com](http://www.zividlabs.com) -- 3D computer vision, startup, well founded **Type:** Full time **Description:** Zivid creates a 3D video camera for use with robots in industrial automation. We are looking for generalist C++ developers, C++ QA developers and C++ machine vision and robotics developers, or any combinations of those skill sets. The detailed job listings can be viewed at [www.zividlabs.com/jobs](http://www.zividlabs.com/jobs). As a developer, you will mainly work with C++, everything from hardware programming and library development to UI programming. You are also expected to tackle most other aspects of software engineering: scripting, testing, automation, packaging, cloud services, docker, CI, bindings for other languages, documentation and working with multiple platforms like Linux and Windows. Or in other words, we are looking for all-round developers and quick learners with strong C++ skills. **Location:** Oslo, Norway **Remote:** No **Visa Sponsorship:** Yes **Technologies:** C++17 (anything passes VS2017, latest Clang, GCC, clang-tidy, ...). C++/CLI, GPGPU, Python, Bitbucket pipelines/Appveyor/Jenkins, libclang, boost, Qt, CMake. **Contact:** Questions: PM or [e-mail](mailto://jobs@zividlabs.com). Applications: [Online form(s)](http://zividlabs.com/jobs). There are check boxes in each form if you would like to apply for more than one position.
I could actually submit 2 simple proposals.
It's just a timing class I use for everything... It's just a wrapper for some time math using `std::chrono::steady_clock::time_point T1 = std::chrono::steady_clock::now()` and `std::chrono::duration&lt;double, std::milli&gt; T2 = std::chrono::steady_clock::now() - T1;` that I can call with `auto x = Test();` for a timestamp and `auto y = Test(x);` for the spread in milliseconds.
It's implemented in clang trunk, which godbolt has an image of. You can download the code yourself if you want to.
What exactly do you mean with "in-text folding"?
Use one of the existing libraries [for instance](https://github.com/VcDevel/Vc)
Anyone had success finding new gigs/clients in these events?
I've noticed that a few people changed jobs through the contacts they made at these events.
#pragma once isn't related to C++17. It's still non-standard. 
Ah okay. But that is not so easily done in terminals I assume
Hey, I know all about this stuff---and all the problems you're going to have trying to find a sweet spot for diagnostics :) 
[Eigen](http://eigen.tuxfamily.org/) is another
cannot agree more
Take a look at implicit conversions ;-) http://en.cppreference.com/w/c/language/conversion
This doesn't really belong here, probably a better fit on /r/cpp_questions/. /u/std_exceptional raised good points. Further issues are passing strings by value and using namespace std for 2 symbols.
I was thinking along the lines of the [ANSI escape sequences](http://ascii-table.com/ansi-escape-sequences.php). The text itself contains a hint to fold a particular section and rather than display the hint, the editor/terminal folds that section, letting you unfold it if you want. By [folding](https://en.wikipedia.org/wiki/Code_folding), I mean the ability to collapse and expand sections of the text, giving it a more hierarchical feel.
Ah, I understand now. You would embed meta info using the escape sequences, and programs that support them could display interactive code folds, maybe using a little "[+]" or similar. That's neat.
Why not just make an abstract base LearnerConfig and pass that to the factory and then to the constructor?
I skimmed the doc earlier. I did not see any comparisons against existing libraries and I would like to know the writer's motivation in creating it,eg what does he use it for?
After using libsimdpp and Vc, I'd caution against blindly using a library. Always check the assembly. In the end I ended up using a relatively simple header that selects overloads based on a cmake selected instruction set. https://pastebin.com/bgi5VUs6
How about moving the "because" to the beginning of the next message? That would remove all ambiguity I think 
Do you advice against libsimdpp and Vc? Is the resulting assembly bad? If so, do you have any concrete example at hand?
If the optimizations make debugging more difficult, I am fine with them being opt-in. I'd rather that good debug info be opt-out because I can usually get a result faster if I spend a day fixing it and a day letting something run than if I spend a week fixing something and then an hour letting it run because the result is better optimized. Obviously, not every optimization is going to make debugging strange, but when the call stack stops showing certain functions because they got inlined and such, I am probably going to get a little lost.
Not at all, just double check it's what you expect. Using these libraries is no substitute to understanding SIMD, you should have an idea of what it should look like. In my case there was an any_set instruction that looped through each element instead of something simpler. Submitted a PR and it's fixed now.
That's what -O0 to -O3 are for.
I find projections are easier to work with than comparitors. template&lt;class F, class Base=std::less&lt;&gt;&gt; auto order_by( F&amp;&amp; f, Base&amp;&amp; b={} ) { return [f=std::forward&lt;F&gt;(f), b=std::forward&lt;Base&gt;(b)] (auto const&amp; lhs, auto const&amp; rhs)-&gt;bool { return b( f(lhs), f(rhs) ); }; } template&lt;class F&gt; struct transparent_callable_t:F { using is_transparent=std::true_type; }; template&lt;class F&gt; transparent_callable_t&lt;F&gt; make_transparent( F f ) { return {std::move(f)}; } then overload template&lt;class...Fs&gt; struct overload:Fs...{ using Fs::operator()...; }; // deduction guide goes here now much of what you are doing falls out auto s = set_from_compare( make_transparent( order_by{ overload{ [](auto const&amp; x)-&gt;decltype(auto){return x;}, [](person const&amp; p)-&gt;std::string const&amp;{return p.name;} } } ) ); and you can bundle those helper functions up. (code is a mixture of C++14 C++17 and pseudo).
One thing: using Accesses = flag&lt;0, 1, 3&gt;; namespace Access { auto [Read, Write, Readwrite] = Accesses::values; } I've added another flag type with two individual values. Now I can accidentally pass one of these to a function taking an `Animals`. One way to get around this is a tag type: using Animals = flag&lt;struct AnimalsTag, 0, 1, 3&gt;;
**Company**: [Cruise Automation](https://www.getcruise.com/) **Role**: C++ Software Engineer, **Type**: Full time **Description**: We're the driverless car company. We believe in improving people’s lives by making transportation safer, more accessible, and more convenient. Our team is small and we move quickly. We’re currently testing a fully driverless solution on city streets in San Francisco. We're looking for smart, ambitious people to help build the world’s largest fleet of driverless cars. We are looking to hire C++ engineers across the entire company so please check out our [open roles](https://boards.greenhouse.io/cruise)! Check out [this video](https://www.driverless.id/news/video-analysis-new-gm-cruise-self-driving-video-shows-more-mastery-sf-roads-time-with-pip-proof-0176178/) of our car driving fully autonomously through SF! [How we built the first real self-driving car] (https://medium.com/kylevogt/how-we-built-the-first-real-self-driving-car-really-bd17b0dbda55) [Why testing self-driving cars in SF is challenging but necessary] (https://medium.com/kylevogt/why-testing-self-driving-cars-in-sf-is-challenging-but-necessary-1f3f7ccd08db) [How we’re solving the LIDAR problem](https://medium.com/kylevogt/how-were-solving-the-lidar-problem-8b4363ff30db) **Location**: San Francisco **Technologies**: C++ on ROS **Visa Sponsorship**: We can transfer Visas **Remote:** No remote work **Contact**: Anthony@getcruise.com
Agree. Extra damage points for when a third party library has its own build system. I've been bruised by Mozilla's software build process with their Mozbuild/mach system too many times.
&gt; "Full version, and up to date can be found @cppreference" - I guess you've copied these table cells from them, but somebody should go fix it. Specifically, referring to MSVC as "19.0", "19.1", and "19.5" is incorrect (and yeah, our versioning story is a dumpster fire orbiting a supernova). Either IDE versions (e.g. 2015 RTM, 2015.2, 2017 RTM, 2017 15.3, 2017 15.5) or compiler versions should be used (which have the advantage of being more uniform, although less helpful for the old 2015 series). The mapping is: 2015 (and all updates) was compiler 19.0, 2017 RTM was 19.10, 2017 15.3 was 19.11, 2017 15.5 is 19.12, and 2017 15.6 will be 19.13. I think I fixed all the dumpster fires. The table also now uses a (MediaWiki) template to normalize the version number. Hopefully that will reduce the likelihood of future fires. 
Don't think too hard
Thats std::sqrt though - not sure whether the author is talking about that or the global one coming from c (which is most likely the same as the double version from std::sqrt).
On mobile... Leaving a comment to remind me to look at this further when I get home.
That's for C, though. `sqrt` in C++ is overloaded (since C++98), and implicit conversions don't help to disambiguate.
Wasm can't do anything that can't already be done by JS. There's lots of nefarious JS out there, but wasm doesn't change anything.
By jump table, you mean asm (generated by switch/case), an array of goto labels, or what exactly?
Whether unqualified `sqrt()` finds C++ overloads is actually a [bit wonky][1] and varies across implementations. [1]: https://www.reddit.com/r/cpp/comments/7c0g9b/overload_resolution_different_across_compilers/dpmsyz3/
Rust stdsimd tests the instructions generated in every function on its API by using a procedural macro that creates a test for each function that disassemble the functions at runtime and verifies the disassembly against the one it should have (e.g. when compiled with AVX2 it should contain instructions xyz). This basically caught many implementation bugs, code gen bugs in rustc,L some in LLVM, etc. Maybe these C++ libraries can do something similar, like have some define that transforms the API into Test so that the functions disassemble themselves and verify themselves. 
Great video, as always!! The use of `auto` is really convenient in `auto set = make_set&lt;...&gt;(...)`, but what if `set` is a class member, how to I define it?
C++ is a highly portable programming language and is often the language of choice for multi-device, multi-platform app development. This is a wise choice for you to use and here are some projects you can work on during your winter break. Since you haven't coded in a while, I will suggest for you some intermediary and then expert level projects if you so wish to dive deep. Intermediary Level 1. Write a program which performs addition, subtraction, multiplication of matrices. The dimensions of both the matrices would be specified by the user (dynamic memory allocation required). Use of structure or a class to define the matrix would be a good idea. (Intermediate) 2. Write a program which will perform the job of moving the file from one location to another. The source and destination path will be entered by the user. Perform the required error checking and handle the exceptions accordingly. (Intermediate) Expert Level 1. Write a simple payroll program that would include pay rates, and hours’ work for employees. 2. Write a phone/address book program, with data saved in binary files. The users should be able to add/delete/change the data. 3. Write a program which acted like a personal planner. In which a user can input in an event, a note of thing to do on a certain date. In conclusion, if you find the intermediary projects too easy, you can attempt expert level projects. In order to enhance your programming language, I recommend that you enroll yourself in a good programming school like Holberton School (https://www.holbertonschool.com/) and learn more programming languages. Good luck! 
Thanks. I'll have another look once on a proper computer.
Use save function, a lot faster to just bookmark it that way (it even has the same bookmark symbol)
Why is `char [4]`, `int [20]` written instead of `char[4]`, `int[20]`?
One can argue that all compilers that currently support C++17, also happen to support `#pragma once`. 
The *unit* ist not the final criterion for considering something a unit test as the unit can have any size, while still being considered to be, well, a unit. An *integration* test also has some sort of unit, that is getting tested, but the test doesn't work in isolation, for example you test one webservice call or even the whole webservice, or some overall process, covering different code components. If you need to execute the whole program, like with an integration test, the program can be still considered to be a unit. But hen the test depend on lots of things, like DB connections or stuff like that, or simply, that all other code pathes work, until you *"reach"* the dialog you wanna test. A unit test also should run *very* fast. I doubt that GUI tests run at an acceptable speed for unit tests. So I wont consider such a test a *unit* test - and I believe that many people would agree with these collection of aspects.
That's just the way Clang prints these types out (maybe there's a way to avoid it but I didn't do anything active to get that space in there is my point) 
In this case, ignore my comment. After all Bjarne is just a human, but he might (I don't know if he really does) welcome it if you send him an email about that error in the book.
This looks pretty neat. One big recommendation: You should really base your allocators on the STL's.
Agreed, on a normal basis I would do that, despite that I find them over-engineered compared to other allocator interfaces which are cleaner(imho like EASTL), however in my case I needed a simplified version with overflow logic(eg. I would estimate how many nodes the tree would have based on the number of items but on rare occasions it would fail).
Indeed, I forgot to add noncopyable however thinking again it would reduce the usability of it(boost has them) so I'll better implement those, thanks for spotting that! I have, but wanted something lightweight, I'll be using catch, thanks for the tip. BTW I'm open to any contributions/changes as currently it's still missing some important features(bulk loading, splitting heuristics, SSE optimizations), so feel free to do that. If I understand correctly the storage separation shouldn't be too difficult to do with the current design.
new line isn't escaped (that is using `\n`) if that's what you means.
I'm using it for one of my project so made a conan recipe - https://github.com/agauniyal/conan-variant. 
Raw RapidJSON will probably be faster than using it via Cereal, but it should still be fundamentally slower than Deco since it has to do more work. my Deco library provides high level API similar to Cereal, so it's easy to compare them. Personally my goal was to compare performance between Deco and JSON, using a fast JSON implementation, so I don't have a need for another benchmark. If you're really curious about it setting up a benchmark should be easy.
By "overflow", i imagine that you mean that a pool allocator is running out of slots? Since this is a rare situation, that's pretty much what `std::bad_alloc` is for. The thing about the "simplified" allocator is that, as a library writer, what matters is how simple things are for users of your library, and from that perspective, following the slightly more convoluted standard is actually simpler than having to learn a whole new allocator mechanism, no matter how simple it might be. My game engine's allocators are built to follow the STL. If you followed that, I could actually just drop in your library and everything would work for me. As it stands, I actually have to write extra wrappers if I want to use it.
Yes, exactly what I meant. Well, I'm aware of std::bad_alloc, however in our engine it's standard to not use exceptions, however your point is truly valid and will change to std::allocator for portability reasons, also that kind of use cases are quite rare. Any suggestions of a nice way to handle overflow w/o exceptions?
Which option best represents this job posting under "How Did You Hear About Us?" on the job application? Will "Recruiter" suffice?
Unfortunately, C++'s allocator interface doesn't support anything like `std::nothrow`, and it's hit or miss whether an implementation will return `nullptr` or just crash/abort if exceptions are disabled. You're stuck using a better non-STL allocator interface, though you can provide your own wrappers (and even automatically apply them) if you want to provide drop-in pure STL compatibility support for the developers who choose to use that stuff.
In a lot of contexts, an integration test would be something like testing that when you click on a GUI button, the application connects to the web service and downloads the data, while a unit test would be testing that clicking the button emits the right signal. Different groups will have different ideas about what needs to get integrated when they think of it as an integration test. As for size, you can certainly use the Qt test framework to make a bunch of small binaries for testing individual aspects of your larger application. It's up to the person writing the tests to decide if there's a good way to test it that is also fast, or what counts as fast in the context. Some people will consider a few milliseconds to be a slow test. Others will consider a few minutes to be pretty quick. Not saying you are wrong, just that reasonable people will have other perspectives depending on their context.
Do I need a PhD?
So, if I have the literal `C:\new folder` does that count as two lines?
I think the argument is that because std::variant does not support pattern matching, it will never be used over some my::name_space::variant&lt;T, U&gt; that does.
It's a simply huge assumption to think that if pattern matching is introduced, they won't find a way to have it supported in `variant`. Consider that structured bindings, which plays roughly the same role for product types as pattern matching does for sum types, has been made to work for both structs and tuples. 
Marc Mutz is for sure a very smart guy, but for some reason, he does not realize that Qt would be less easy to use without the benefit of Copy-on-Write (value-semantics, easier immutability)
Why is everyone so intent on making header-only stuff? It seems to have become a box to tick. Is having to compile in a couple of extra source files really such a bother? Or even link a library? I mean, I get the simplicity, but compile times on large projects are already an issue to the extent that you need distributed build systems, and this isn't helping. Sorry, I realize this is off-topic but I really don't understand why this has become a thing so much...
The problem with what you're asking is that you're pointing at just one simple case of an arbitrarily complex problem. Yes, the compiler can figure out this particular case, but can the compiler figure out what cases it should try to figure out? And worse, the algorithm for doing so would need to be written into the standard so that it would be consistent across implementations. Wherever the line is drawn between 'simple enough to be mandated by the standard' and 'too complex to be mandated' you're going to have programs that are _just_ on the wrong side of the line, and programmers pointing out that if the compiler figures out case A then it makes no sense that it doesn't figure out slightly more complex case A`. If we make your example real by filling in `something` it actually does work. E.g. when `something` is [`0xDEADBEEF`][1]. But if we make it [slightly more complex][3] then it crosses over the line where the compiler is currently required to diagnose it as an error, even though you as the programmer can see that it would be easy for the compiler to do just that little bit of extra work so you don't get an error. Currently the line is drawn where the contents of the braces is formally a C++ constant expression. Various compilers can compute at compile time [far more][2], but so far we have avoided mandating this of all compilers. Understanding the basic rule allows us to fix up the erroring code so it [works again][4]. [1]: https://godbolt.org/g/kEQ6DV [2]: https://godbolt.org/g/LHpMRX [3]: https://godbolt.org/g/p5PhTU [4]: https://godbolt.org/g/xa3QKd
I don't know, but I personally despise it. You're trading compilation time for convenience and I don't think that's a useful tradeoff. What I would like to see instead is people adding a script to someone can run that will copy the necessary bits into a directory with a CMakeLists.txt file that be consumed via add_subdirectory. That way someone can just do run-script --dir /project/lib/new-lib. They can then check that into source if they want, or add the calling of that script to their own scripts as necessary. 
You're right - there's no causal connection, but in practice, all compilers that support C++17 do and will continue to support `#pragma once`.
**Company:** Microsoft **Type:** Full time **Description:** Microsoft Project, with over 20 million users, is dedicated to providing every Project Manager in the world, the tools they need to effectively manage projects. For over three decades, Microsoft Project has been the industry standard in Project Planning for companies of all sizes. As a business, Microsoft Project continues to be one of the most profitable products for Microsoft. As a Software Engineer on our Team, you will have the opportunity to work in small, self-organizing crews, made up of Software Engineers and Product Owners, with a mission to bring the best project management capabilities to our users on both the PC and the Web. Delivering strong results will require you to engage with the wider engineering community across Microsoft Office. Key responsibilities: - Design and develop new features and capabilities in C++ for Microsoft Project. - Enable key new scenarios like Co-Auth on both the PC and Web. - Collaborate with engineers in Dynamics and VSTS, enabling deep integrations across the broader Work Management offerings from Microsoft. - Learn from and contribute to the vibrant community of engineers across Microsoft Office. Knowledge, experience and skills: - 3-5 years of experience in designing applications in C++ - Experience in working on a large codebase - Understanding of Windows based Native Applications - Ability to work collaboratively in small self-organized teams - BA/BS or MS Degree in Computer Science, or equivalent experience **Location:** Redmond WA **Remote:** No **Visa Sponsorship:** No **Technologies:** Code compiles with /std:c++latest. We use the latest MSVC supported features for new code, but (as any large codebase) you will find old code on battle tested parts of the codebase that have not received love in the last couple of years. We also use GSL, Boost and follow the guidelines as much as possible. **Contact:** Apply directly here: https://careers.microsoft.com/jobdetails.aspx?ss=&amp;pg=0&amp;so=&amp;rw=1&amp;jid=326835&amp;jlang=en&amp;pp=ss PM me if you have questions
I might have something like that prepared in the buffer, scheduled to be released in a week or so :)
Code blocks should be horizontally scrollable, but you need to pan directly on them (or at least my chrome on android can do that). I have code wrapping planned, but it's not ready yet. Layout: hmm. Any suggestion what to throw away or what to simplify? I've been on this for quite long so I'm maybe already blind to the obvious issues :)
 template &lt;typename Ret, typename... Args&gt; struct L&lt;Ret(Args...)&gt; { using this_type = L&lt;Ret(Args...)&gt;; constexpr L(Ret (*CallPtr)(const this_type &amp;, Args...)) : callable(CallPtr) {} template &lt;typename T&gt; constexpr L(const T &amp;Lambda) : callable(Lambda) {} constexpr Ret operator()(const Args &amp;... args) const { return callable(*this, args...); } private: Ret (*const callable)(const this_type &amp;, Args...); };
usage: constexpr auto recursive = L&lt;int()&gt;([](const auto &amp;l) { return 0; }); *** `struct L&lt;...&gt;` takes a signature of a callback. no need to explicitly provide type for recursive reference.
the horror!
The doxygen theme looks really good. Is the theme publicly available?
FYI it looks the same on an iPhone 6s.
I read that as ‘ms devs know that compiler/ide versioning has been a mess historically’
Well I love saturated colors, but not for text. As long as it is possible to tell them apart is enough for me. Also I hate gray on gray, it is far better to reduce the brightness of the monitor as low as possible and increase contrast. In that way those unavoidable transitions between dark and light backgrounds doesn't strain the eyes.
I have done this once for getting a reference to an object created and inserted into a container for those objects. Since whoever is using that code shouldn't be able to create those objects directly all the constructors are private, being the container a friend class. In that way the compiler will not let you to make that mistake because the constructors are private. You will be forced to use a reference as it was intended. 
So, What is the advantage of LMP compared to normal TMP / when would you use it? Btw, I hope no one writes factorial like that.
Nice. Although, text that is rotated 90 degrees is hard to read.
Great. I need more example projects. Always wanted something like [this](https://www.sfml-dev.org/tutorials/2.4/)
Yes it is! The blog article mentions http://mcss.mosra.cz/doxygen/ :)
If you don’t store, transform or concatenate lambdas, they have no advantage over named functions. 
&gt; Surely the compiler could work out that this isn't an actual narrowing conversion? The *static* type of expression `something &amp; 0xF` is `unsigned`, so it's formally still a narrowing conversion.
IDK if you asked this question, but if not it looks like you are right :) https://stackoverflow.com/questions/47383563/is-there-any-hope-to-call-a-common-base-class-method-on-a-stdvariant-efficient
That wasn't me, but yes, that's exactly it. The hand-rolled switch in the answer is very similar to my solution. 
Awesome. But I'm little concerned, read briefly examples and saw `new` multiple times and ctors taking addresses rather than references.
I'm painfully aware of these, trust me :) This is isolated to the scene graph / resource manager APIs, which date back to *very long ago*. It's due for a redesign and if you don't like it, you're welcome to completely ignore its presence and use for example [entityx](https://github.com/alecthomas/entityx) or your own custom thing in place of it.
I feel the library is trying to do too much: Custom containers, math utils, string utils, file system utils, etc. Why not take the advantage of the standard lib and other battle-hardened libraries and frameworks?
When can I expect new API? I have other non-Magnum projects too.
Congratulations! You've discovered [Y-Combinator](https://en.wikipedia.org/wiki/Fixed-point_combinator). You can improve this a bit by doing this (like they do in Y-Combinator): template &lt;typename FUNC, typename ...ARGS&gt; constexpr auto RecursiveLambda(FUNC lambda, ARGS&amp;&amp;... args) { return lambda(std::bind(lambda, lambda), args...); } Note `std::bind(lambda, lambda)` there. With this you will not need to pass `lambda` on the usage side.
Because most of those aren't in the standard lib ?
Should be fixed now. Thanks for all the reports.
Thanks for the insightful opinion. Let me explain: - Custom containers, string and filesystem utils etc. are only *complementing* STL and providing stuff that STL doesn't have (array views, for example). If possible, I'm using STL APIs (though STL has also its downsides), but also need to maintain compatibility back to C++11, so I can't make use of the recent stuff like std::filesystem. - Math: library that comes closest to what I need is GLM, but after evaluating it in other projects it felt being unnecessarily complex in some areas and too restrictive in others, slow to compile due to its heavy use of templates and not thoroughly tested or documented (just explaining my reasons, rant against GLM not intended). So I ended up writing my own. - For physics, asset loading and other complex stuff it's taking advantage of external libraries as much as possible. But in the core areas I thought it's better having a overarching API with consistent design that fits together instead of bundling various 3rd party libraries together.
Ok, thanks for the clarification, makes perfect sense.
Uh, no?
Generating each index from 0 to n-1 at compile time by using the y combinator and constexpr if to enable compile time recursion seems inefficient. template&lt;std::size_t...Is&gt; auto index_over(std::index_sequence&lt;Is...&gt;){ return [](auto&amp;&amp;f)-&gt;decltype(auto){ return decltype(f)(f)(IntegralConstant&lt;Is&gt;{}...); }; } template&lt;std::size_t N&gt; auto index_upto( IntegralConstant&lt;N&gt; ={} ){ return index_over(std::make_index_sequence&lt;N&gt;{}); } now your concat tuples is simpler and, well, better auto concat = [](auto&amp;&amp; t0, auto&amp;&amp; t1){ constexpr auto total = // as in your code auto get_join = // as in your code retirn index_upto&lt;total&gt;([&amp;](auto...Is){ return std::make_tuple( get_join(Is)... ); }; };
Yep, that would be a single line.
As said on Twitter, I'm mainly interested in a graphic engine that focuses on graphic rendering and let me provide the rest. So the main request I have (also expressed already on Twitter) is that I would like to see a tutorial where you build up some rendering code from scratch without relying on Application class that hides the context. I recommend looking at the SFML hello world example for that, it shows how to compose an application with it's different blocks. As said I'm looking for something that do only rendering and that I can plug into an application that already does the rest. I suspect I'm not the only one. In particular in gamedev programming experts circles.
I'd very much like to see such an example as I'm currently working on a program, where 2D/3D rendering is just one possible Backend to display the results (in addition to e.g. text output)
I added that on my top priority list and it's now pushed even higher: https://github.com/mosra/magnum/projects/6#card-6448253 :) There's now at least [documentation how to use custom platform toolkits with Magnum](http://doc.magnum.graphics/magnum/platform.html#platform-custom) together with a bootstrap project using Qt5, but no real full-blown example. Question: what platform toolkit would be best to use for that tutorial? I guess going with raw Xlib / WINAPI / ?! is way too low-level, so .. something else? Raw GLFW? SDL? SFML?
Quick! Launder that variable before the C run time police catch you! (Or we could, you know, just not use C to begin with.) Or heck, we could use the AAA idiom, like we're supposed to. This is an edge case that _should_ never be bumped into. Actually, I'm going to firmly say that if you have to use `std::launder` you're doing something wrong.
The name itself should already trigger you to think about the code you wrote that needs it :)
It would be great to have a better solution than `std::launder`, but the fact you need to use this does not imply that you are doing something wrong. In fact, you need this feature to implement variant. Of course, it is better to hide the usage of this feature in low level libraries and rely on those libraries when writing regular code.
It's hard to come up with a one-size-fits-most scene management API *fast*. I can't say a timeframe at the moment, sorry, but it will be definitely done. Just to reiterate: the current scene graph library is not doing much on its own, it just glues various already existing things together and its complexity comes only from generalization for diverse use cases. Using a 3rd party library or coming up with your own implementation is a completely valid option -- as with everything else, the magnum scene graph is a separate library so it won't be a bunch of dead code inflating your application size if you don't use it.
You can use a lambda instead of a bind, which tends to produce better code (not sure if it makes a difference here)
SDL and SFML are perfect base for this for me. Maybe look at (Dear) IMGUI examples. As it's not rendering it's output itself, it have several examples with tons of toolsets. 
Hi, mosra.I found magnum weeks ago and thinks it is a cool library. Have you looked at [oryol](https://github.com/floooh/oryol)? What do you think about it?
You might be right, I only checked out the implementation that is based on a solution similar to `std::aligned_union`. Could you link an implementation that is using recursive unions? 
I think MPark.Variant, Eggs.Variant and the libc++ implementation all use recursive unions.
Thanks for pointing this out! After looking at the implementations, I think you are absolutely right. 
I don't get the idea behind manipulating xxx_view in apis going forward. Views are useful if you want to manipulate a subset of the data without copying the underlying complete data, but in apis, aren't you better off handling concepts ? `auto to_upper(String auto &amp; s ) -&gt; String auto { } ` views are a poor man's concept, but they mess with both the nature of the type and the ownership model - you just have to hope that the view doesn't outlive the contained data, which can not be enforced by the compiler. Note that for "subset of a container-like" entity, we also have a better alternative to views : ranges ( they work similarly but ranges are, in my opinion a a better abstraction). Ranges should also model the same constraints that the iterable container they were created from : a range on a string is a string-thingy itself. In the end, you should either ask for a concrete type or a generic, properly constrained, type
https://i.imgur.com/fdv4Mr6.png
I think you're right. With lambda it will be better since will allow quit from stack overflow: return [](auto... args) {return lambda(RecursiveLambda(lambda), args...)}
&gt;In fact, you need this feature to implement variant (edit: at least some possible implementations need it). \*head tilts\* I would hope not. It's inefficient. Do you mean unions like c unions or like std::variant? I don't see std::launder in std::variant. I can imagine the standards library being like, "Support all the things!!" including const variables, but on the other hand it still should be a compiler error I would think. Hmm what the heck. I'll try it: #include &lt;variant&gt; #include &lt;iostream&gt; int main() { std::variant&lt;int, const double&gt; foo; foo = 1.1; std::cout &lt;&lt; std::get&lt;1&gt;(foo) &lt;&lt; std::endl; return 0; } rm: cannot remove 'test.o': No such file or directory test.cpp: In function ‘int main()’: test.cpp:6:11: error: use of deleted function ‘std::variant&lt;_Types&gt;&amp; std::variant&lt;_Types&gt;::operator=(std::variant&lt;_Types&gt;&amp;&amp;) [with _Types = {int, const double}]’ foo = 1.1; ^~~ In file included from test.cpp:1:0: /usr/include/c++/7/variant:995:16: note: ‘std::variant&lt;_Types&gt;&amp; std::variant&lt;_Types&gt;::operator=(std::variant&lt;_Types&gt;&amp;&amp;) [with _Types = {int, const double}]’ is implicitly deleted because the default definition would be ill-formed: variant&amp; operator=(variant&amp;&amp;) ^~~~~~~~ /usr/include/c++/7/variant:995:16: error: use of deleted function ‘std::_Enable_copy_move&lt;true, false, true, false, _Tag&gt;&amp; std::_Enable_copy_move&lt;true, false, true, false, _Tag&gt;::operator=(std::_Enable_copy_move&lt;true, false, true, false, _Tag&gt;&amp;&amp;) [with _Tag = std::variant&lt;int, const double&gt;]’ In file included from /usr/include/c++/7/variant:40:0, from test.cpp:1: /usr/include/c++/7/bits/enable_special_members.h:246:5: note: declared here operator=(_Enable_copy_move&amp;&amp;) noexcept = delete; ^~~~~~~~ bash: ./test.o: No such file or directory Not surprising really..
Sorry folks, it seems I've put this question in wrong sub - I guess I should head over to /r/cpp_questions 
It is about storing classes in variants that have reference or const fields. 
Like most containers, `variant` is not allowed to store references.
LLVM patch: https://reviews.llvm.org/D41723 Impact on C++ applications: &gt; When manually apply similar transformations to -mretpoline to the Linux kernel we observed very small performance hits to applications running typical workloads, and relatively minor hits (approximately 2%) even for extremely syscall-heavy applications. This is largely due to the small number of indirect branches that occur in performance sensitive paths of the kernel. &gt; When using these patches on statically linked applications, especially C++ applications, you should expect to see a much more dramatic performance hit. For microbenchmarks that are switch, indirect-, or virtual-call heavy we have seen overheads ranging from 10% to 50%. &gt; However, real-world workloads exhibit substantially lower performance impact. Notably, techniques such as PGO and ThinLTO dramatically reduce the impact of hot indirect calls (by speculatively promoting them to direct calls) and allow optimized search trees to be used to lower switches. If you need to deploy these techniques in C++ applications, we *strongly* recommend that you ensure all hot call targets are statically linked (avoiding PLT indirection) and use both PGO and ThinLTO. Well tuned servers using all of these techniques saw 5% - 10% overhead from the use of retpoline. GCC patches: http://git.infradead.org/users/dwmw2/gcc-retpoline.git/shortlog/refs/heads/gcc-7_2_0-retpoline-20171219 More information: - https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html - http://blog.cyberus-technology.de/posts/2018-01-03-meltdown.html - https://spectreattack.com/ - https://meltdownattack.com/meltdown.pdf - https://spectreattack.com/spectre.pdf - https://security.googleblog.com/2018/01/todays-cpu-vulnerability-what-you-need.html 
It is perfectly fine to store a data type that has reference fields in a container. 
It's a problem with any type if you use a `std::aligned_union` approach. If you change the type of the object which is stored in the aligned buffer using placement new then you can't hand out pointers to that buffer `reinterpret_cast`ed to the new type due to [basic.life]/8.2 (C++17). The pointer returned by placement new would be valid, but you would need to store it along with the variant, which is Not Good (tm). So you can `std::launder` the pointer to the buffer to say "there's an object here, honest", or you can sidestep the whole issue and use recursive unions.
Sure but that doesn't help all that much: #include &lt;iostream&gt; #include &lt;variant&gt; template&lt;typename T&gt; struct Ref { const T&amp; m_value; Ref(const T&amp; value) : m_value(value) {} }; int main() { int x = 5; double y = 5.5; std::variant&lt;Ref&lt;int&gt;, Ref&lt;double&gt;&gt; v = Ref&lt;double&gt;(y); std::cout &lt;&lt; std::get&lt;Ref&lt;double&gt;&gt;(v).m_value; v.emplace&lt;Ref&lt;int&gt;&gt;(x); std::cout &lt;&lt; std::get&lt;Ref&lt;int&gt;&gt;(v).m_value; } Now what do we do? Without `std::launder` the emplace to x is undefined behavior.
``` overide void Foo() { … } Object* obj = new Derived; ``` what
Ah, ok, I misread your post. Both of these are generally bad ideas but I guess as always there are some people who will like doing it.
You are saying that: std::aligned_union&lt;Foo, Bar&gt; x; new (&amp;x) Foo(); auto f = reinterpret_cast&lt;Foo*&gt;(&amp;x); f-&gt;~Foo(); new (&amp;x) Bar(); auto b = reinterpret_cast&lt;Bar*&gt;(&amp;x); I cannot hand out pointer `b` for some reason?
This is not a pointer-interconvertible case, so the value of `b` is unchanged by the `reinterpret_cast` and remains "pointer to `x`", not "pointer to the `Bar` object created by placement new". Using it as if it were actually pointing to a `Bar` object results in undefined behavior. Also, you forgot a `_t` and the size argument.
I'm not really sure what you are saying here. Yes, the values of `&amp;x`, `f`, and `b` are the same. But that does not mean that `&amp;x` is a pointer referring to the `Foo` object that was originally created, it does not have the right type to actually directly refer to the `Foo` object. And in any case, we do not try to use `x` to "manipulate" either the old or new object. I don't see how any reading of that passage would lead to the conclusion that following up that code with e.g. `b-&gt;bar_method()` is UB. Fixed the `_t`, and also added the `0` that should be the first argument, thanks. 
[basic.life]/8 is irrelevant. This is a simple`reinterpret_cast` case. The value of `b`, despite it having type `Bar*`, is "pointer to `x`", because the value of `&amp;x` is "pointer to `x`" and the `reinterpret_cast` doesn't change the pointer value. Because `b` does not actually point to a `Bar` object, using it as if it does is UB (e.g., for non-static member functions, by [class.mfct.non-static]/2; for non-static data members, by omission from [expr.ref]).
Did you also try using mapbox variant? I profiled a lot of variants a long time ago, it seemed to me that the compilers generated best code with the mapbox variant implementation, which is pretty simple. Basically the idea is a fixed sequence of if else can usually be optimized the same as switch case, and its easier to generate with templates. (Would love to know your thoughts about that though!) Edit: heres mapbox variant: https://github.com/mapbox/variant Here were my bench results: https://cbeck88.github.io/strict-variant/strict_variant/remarks/benchmarks.html
 auto b1 = new(&amp;x) Bar(); auto b2 = reinterpret_cast&lt;Bar*&gt;(&amp;x); I don't see how it is possible for `b1` and `b2` to be different values (provided the object `x` is at least as aligned as `Bar`, at least, although even if that's not true they might still always be the same), and the access through `b1` is well defined. Maybe this is UB, but it is UB on the same level as the UB necessarily involved in the implementation of `std::vector`.
https://cdn-images-1.medium.com/max/1500/1*u7hABsfu_ZWTuUFoe8kHeA.jpeg That is exactly how NOT to implement a class hierarchy, not an example of runtime polymorphism. That example isn't even polymorphic! Switching by type is NOT polymorphism. If you were even using polymorphism you'd not have to decide what class you were given. Please review the Liskov Substitution Principle.
If &amp;b is a legal pointer that you can modify through, I'm not sure how a statement in the form if (p == &amp;b) { *p = 5; } can be UB, unless it was illegal to simply form p in the first place (I don't remember whether the expression `&amp;a+1` is even legal in this situation). To me, this mostly just indicates inconsistency in the standard. Do you believe for example that: Given two pod variables of identical type, if they are bitwise equal in a certain point in the program's execution, substituting one for the other at such a point in an expression or statement should not change the program. If you believe this should be true, and it's legal to form two pointers that are of same type and have equal values, it shouldn't matter which of them you use. In any case, as I already said: I consider this more similar than not to the UB which is absolutely required to implement a conforming `vector`. If `vector` can live with UB then why `variant` suddenly should be held to a higher standard, or why I should not be comfortable with the pattern of code I showed above, is not clear to me.
ROP as a security *mitigation*. Now I've seen everything. 
`overide void Foo() { … }` should also be `void Foo() override { … }`
As it is in the article.... 
A couple interesting things: first, the [proposed](https://lkml.org/lkml/2018/1/3/770) retpoline sequence for the Linux kernel is slightly different, using `lfence` instead of `pause`: .section .text.__x86.indirect_thunk,"ax" ENTRY(__x86.indirect_thunk) CFI_STARTPROC call retpoline_call_target 2: lfence /* stop speculation */ jmp 2b retpoline_call_target: #ifdef CONFIG_64BIT lea 8(%rsp), %rsp #else lea 4(%esp), %esp #endif ret CFI_ENDPROC ENDPROC(__x86.indirect_thunk) EXPORT_SYMBOL(__x86.indirect_thunk) The `lfence` version seems to be officially "[blessed](https://lkml.org/lkml/2018/1/4/715)" by Intel: &gt; That is almost identical to what's in my latest patch set, except that the capture_spec loop has 'lfence' instead of 'pause'. &gt; &gt; As Andi says, I'd want to see explicit approval from the CPU architects for making that change. &gt; &gt; We've already had false starts there — for a long time, Intel thought that a much simpler option with an lfence after the register load was sufficient, and then eventually worked out that in some rare cases it wasn't. While AMD still seem to think it *is* sufficient for them, apparently. Second, there is some [debate](https://lkml.org/lkml/2018/1/4/708) about whether retpolines are enough on Skylake+: &gt; On Skylake the target for a 'ret' instruction may also come from the BTB. So if you ever let the RSB (which remembers where the 'call's came from get empty, you end up vulnerable. &gt; &gt; Other than the obvious call stack of more than 16 calls in depth, there's also a big list of other things which can empty the RSB, including an SMI. &gt; &gt; Which basically makes retpoline on Skylake+ *very* hard to use reliably. The plan is to use IBRS there and not retpoline.
I've seen someone using `std::map&lt;int, int&amp;&gt;`. (https://gcc.gnu.org/bugzilla/show_bug.cgi?id=83226)
So, help me understand. If I understand this article's description of the vulnerability, *all* executables are vulnerable. But, (at least in Linux) the kernel is more easily targeted due to common pieces between versions. My question is: if I update my kernel to one which patches against this, is my user code (built in-house) also vulnerable? If so, then my group needs to determine the cost of that vulnerability? 
It wasn't at the time I posted the first comment. Glad to see it fixed
The author does not speak about polymorphism via inheritance. The "if" that you see in the author's diagram is not user code, but describes what the compiler does under the hood, when a polymorphic function wrapper is used. Hence there is no "manual switching by type.". This being said, the title of this article is strange, and the article not so clear. 
As I understand it the `constexpr` requirements on `std::variant` basically mandates a recursive union, since you can't use placement new.
You're probably right. Constexpr placement new please!
It's not even really an accurate description of what the compiler does. It my *try* de-virtualization in some places (what we are talking about here) but it's far from being the most common. It's not decidable in many cases and so even a greedy optimizer has to fall back to thunk table.
Spoiler alert: the "m word" is monad.
If you patch your kernel you should be good to go; (and should do so anyway) its just going to incur a non trivial performance loss on intel chips.
That's simply not true in the world of modern optimizing compilers. Pointer equality (which is basically defined in terms of the address they represent) doesn't imply substitutability. The abstract machine's pointer carries a lot more information than just the address it represents, and an optimizer is entitled to use that information even if it's not encoded in the bitwise representation. This isn't unique to pointers, either: union U { int a; int b; }; template&lt;int U::*&gt; void f(); static_assert(&amp;U::a == &amp;U::b); static_assert(&amp;f&lt;&amp;U::a&gt; != &amp;f&lt;&amp;U::b&gt;); [N4303](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4303.html) explains how a compiler's aliasing analysis could cause problems with this kind of code pattern in the absence of `launder`.
&gt; The "if" that you see in the author's diagram is not user code, but describes what the compiler does under the hood, when a polymorphic function wrapper is used. Yes, like I said if you know what vtable is this is a lie of simplification, but it represents the world in a sense that normal(int, float, struct not inheriting from anything) types are not colored. As for article not being clear... I am sorry for that, like the article says for me looking at operator = as the hero of the story helped me understand the type erasure. :)
Thanks. So, with the kernel patch, one user program can't get to another program's data? 
The kernel is now supposed to be entirely isolated from user space and no longer have a probable issue; so for this particular issue yes ("meltdown"); it should be fine.
This is for Spectre. All sw are affected, but a lot are arguably not exposed; exposed ones will have to be recompiled (and not only the kernel).
C++ is a high performance language, none of the problems shown are real problems, except maybe aliasing and structured bindings(I have seen no benchmarks). std lib is not high performance library, especially stupid unordered_ crap. Some of the optimizations only work for specific usecases(fbstring) so std can not require them for all implementations. BTW I love all the downvotes the guy got here on youtube... just shows that C++ fanboys will downvote anything against their precious language... Gábor if you are reading this: thank you for the talks.
Formatted: void load(){ // dynamic memory pointer of texture class Texture *texture=new Texture(); newTexture *texture-&gt;loadTexture(string path); // If I deallocate texture here then newTexture no // longer has access to image stored in texture pointer } void freeMemory(){ delete newTexture; //Cant delete texture from here } Something is wrong with the line that begins with `newTexture`, and I'm not sure what your intention was in this line or exactly what `loadTexture()` does. Regardless, you should very likely be using `std::unique_ptr` or (less likely) `std::shared_ptr` rather than raw pointers when heap-allocating objects. &gt; if I delete newTexture in freeMemory does it deallocate *texture too? If you allocate an object with `new` and that object contains a pointer to another object allocated with `new`, then deleting the containing object won't delete its members. You'd have to write a destructor to do that, or better yet, use `std::unique_ptr`, and all the recursive deallocations will happen automatically.
hell yeah! i started this today!! thank you so much internet stranger 🙌🏾🙌🏾🙌🏾
I wonder, where does this "C++ is a high performance" thing came from? I mean, when I started with it, it was generally considered "a general-purpose programming language with a bias towards systems programming" (http://www.stroustrup.com/bs_faq.html#what-is). Then at some point it suddenly became regarded as a performance thing. Go figure. Yes, it does provide cheap or free abstractions, and of course it is better than heavy and slow ones, but it was not entirely designed with performance in mind. It haven't even had a standard support for concurrency for 28 years. That's not how you design high performance language. Yes, you can make it fast. You can avoid standard containers, RTTI, exceptions usage, even virtual methods, and you can write the most efficient specification for each of your templates' instantiations, but would it be C++ then? C++ power is not in performance, but in versatility. You can probably write more high-performant code in Fortran, and you can probably write more high-level code in Scala. But in C++ you can have both performance and abstraction at the same time.
I'm not sure if it's a good method. please give some comments. thank you!
So, you can universally use forward slashes as directory delimiter? 
Where can’t you use forward slashes as a delimiter? I’m a windows developer and windows accepts forward slashes in every context I’ve tried it in. 
Other than now being in the `std` namespace where it should be, i.e. no longer experimental, what's been fixed relative to g++ 7.1? In particular, does it now work in Windows? For 7.1 I used the following workaround code: #ifdef STDLIB_HOIST_UP_FILESYSTEM_NAMESPACE namespace std { namespace filesystem { using namespace experimental::filesystem; } // namespace filesystem } // namespace std; #endif #if defined( STDLIB_FIX_GCC_U8PATH ) &amp;&amp; defined( __GNUC__ ) &amp;&amp; defined( _WIN32 ) namespace std{ namespace filesystem { inline auto u8path( string const&amp; source ) -&gt; path { return path{ ::stdlib::wide_from_utf8( source ) }; } inline auto u8path( char const* const source ) -&gt; path { return u8path( string( source ) ); } }} // std::namespace filesystem #endif 
I don't think I would call it "concept". I mean, yes, it implements the computing science concept† known as "concept", but "concept" as a name of a language or library feature has been taken. Better name it something else... like "[Inverse](https://en.wikipedia.org/wiki/Inverse_(logic)) SFINAE Assertion" idiom? BTW, have you taken a look at detection idiom? You may find it interesting. †: Not pun. Just poor choice of word.
&gt; While your first workaround works, it is technically not allowed. Would you mind explaining why? I'm curious.
I am still amazed how genius was someone who came up with an idea to overload `operator/` for `std::filesystem::path`.
Actually, this is a Spectre fix so everything is impacted. Even if AMD deemed an exploit unlikely.
He means that end users are not permitted to place new things in namespace `std`. Defining an `fs` namespace is a good solution for an application. It's not good as a way to support what will be (or now has become) simple standard code.
That's only true for meltdown. This patch is for one part of spectre
Some cmd.exe commands only accept backslashes.
&gt; He means that end users are not permitted to place new things in namespace std while this makes sense, I'd really like to understand why this is UB and not a more specific error. I mean, it's not like the compiler can't detect it, can it ? 
The guy in the beginning is hilarious.
You can simplify error messages with SFINAE in the same way - proper static assertions.
Python's been doing this as well for some time already, it's really neat!
This is not true for any cmd.exe stuff I've tried on windows 10. 
The compiler really don't know the difference between your code and library supplied code. Because it doesn't know this it doesn't give an error. The risk of doing anything with namespace `std` is that at some point the standard will do something in that namespace, and you'll get conflicts. It's also confusing for anyone reading your code.
There also seem to be a lot of people who absolutely hate it
In general, lots of things are UB because the standards comitee does not want to force too many particular diagnostics upon implementations, because that would include being required to actually check for it, placing unnecessesary burden on implementations
&gt; The compiler really don't know the difference between your code and library supplied code. Because it doesn't know this it doesn't give an error. well, that's what I don't understand. If in my own code I have two functions named foo, of course I get an error so why wouldn't there be an error if I had, say, `std::foo` and a custom `std::foo` of my own code. So why wouldn't I get one with std ? What's the problem with putting things in namespace std and then fix them if one day the standard changes ? Why can't it be treated like all the other code out there ?
&gt; If in my own code I have two functions named foo, of course I get an error That is not universally true. You might have two conflicting inline definitions in different compilation units, in which case you can also run into strange behavior at runtime: the functions might be complex enough that the compiler still doesn't inline them and the linker will see that they are inlined and remove all but one of the definitions without checking if they are equivalent.
You can. It's just against the standard to do so. Namespaces exist so we don't walk all over other people's toes when writing or using libraries. Sure, you can ignore that, but if anyone else uses your code the would be confused and annoyed.
But even then it only helps to autocomplete with backslashes.
Syntax abuse is cancer
Actually I don't know what I should call it. Maybe trait? I just want to add constraints to the implementations, because SFINAE only constrains the users, while the implementations may make more assumptions than what they declared.
It's still syntax abuse because / was meant to represent division. I personally don't like syntax abuse in any form, but of course that's just my opinion, :)
Have you heard about `boost::spirit`? And what they did with operators there?
Do you have the same problems with `+` used for string concatenation?
Yes. I like Perl's approach of using an entirely different operator for that.
Why don't you just use Ubuntu 17.10 instead of your 4 years old version? 
Do you have any argument or just one-liners? 
straight to the point, great!
If I said I don't like the colour green, would you ask "do you have any argument or just one-liners?"
For me this is mainly due to the burden of legacy software: some of the tools I use were developed for Ubuntu 14.04, and the main devs are since gone. Switching to Ubuntu 17.10 is possible, but the burden of fixing whatever breaks in the process would be on me (the user).
If you use a package manager like hunter (https://github.com/ruslo/hunter), you can just have all this effort magicked away. I use boost from hunter in my project freeablo (https://github.com/wheybags/freeablo), and it's statically linked, and works cross platform with only a couple of lines of cmake.
Tbh it’s nice because python does it and filesystem is very close to pathlib’s api. Makes yanking loops from python into c++ easier
We got even [recursive directory iterator](http://en.cppreference.com/w/cpp/filesystem/recursive_directory_iterator).
I think you misunderstood his question. I don't think he was being snarky, he was asking a genuine question!
You should consider adding your library to currently fighting c++ package managers like buckaroo, cget, conan, conda, cpm, cppan, hunter, vcpkg and so on :P
I like PHP's "."
Perl uses . as well (PHP's syntax inherits a lot from Perl's)
But - mathematically speaking strings have a monoid structure under concatenation and it resembles a free group to some extent (string concatenation does not have an inverse). So I don't thing using + is so far off. Dot represents a dot product or member access in many other languages, so I really don't see how it is more appropriate except for the fact that it is unique in PHP. In my opinion, the true power of operators lies exactly in the overloading - i.e. fact, that they represent different but somehow related operations on various datatypes and implementation details are abstracted away.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I've done this before and have a github repository available [here](https://github.com/ttroy50/cmake-examples). It includes basic examples and progresses to more complex things (like using static analysis / testing frameworks). Most of the examples use modern CMake style (although some could be improved) and if you feel like making any updates I'm open to contributions. 
So far i did a couple of global runs to fix one clang-check at a time (for example adding override everywhere). I was planning to at least have all developers run it. Later i will try to get it added in our build &amp; test workflow. Another question: did other people notice that for example the range based for auto fix checks screw up or don't convert all loops? I simply enabled all checks for testing and got quite some compile errors due to the auto fixer. The auto fix for by value -&gt; const&amp; didn't work that well either. Some functions where used in a function pointer which only accepted by value arguments. The fix it re-wrote those functions to const&amp;, which failed to compile the cases where those methods were used in a function pointer.
You have a point, and I admit that using + to concatenate strings is not really that bad. You are summing them... somehow. But using division to separate paths, that's abuse.
Could you explain how? Never came across this
Codeplay is a leading developer of software tools and we are looking for responsible C++ engineers to work on debuggers, utilities, runtimes, compilers and demo applications targeting brand-new hardware such as GPUs, Mobile CPUs, and DSPs. Many of these systems or technologies are not yet publicly announced and therefore require confidentiality, so this is an opportunity work with new hardware and software before anyone else does! This position requires solid working knowledge of modern C++ (at least C++11), understanding of high-level C++ abstractions, and the ability to use and contribute to modern heavily templated C++ code bases. **The Environment** Codeplay has a relaxed working environment and you will be working alongside other creative and talented developers. Codeplay is regarded as being at the forefront of compiler and development technology and has active participation in several research programs within the European union, the Khronos Group and the HSA Foundation The ideal candidate is a self-motivated individual who can work through a problem from start to finish, to deadlines as required to support software projects, and sometimes under pressure. They will be working on technology that is usually not publicly announced and may be several years away from public release, and candidates must understand the secretive nature of the work that we undertake. The challenge for prospective candidates is to fully exploit the resources available to provide efficient build and test procedures for our software teams. The position is permanent and will be based at our head office in central Edinburgh. Salary Range (dependent on experience) £27,000 to £53,000. **What We Offer** Work on exciting brand-new technologies and standards with well-recognized customers, A friendly and relaxed working environment where colleagues support each other, Knowledge sharing: our staff frequently give company-wide presentations on new software and technology trends, personal projects and other relevant subjects, Great career prospects within a growing company, Positions are available at various levels, from entry-level Software Engineer to Senior Principal Software Engineer, depending on your skills and experience, We develop our employees and provide training in skills such as project and people management, networking and delivering effective presentations, Frequent opportunities to attend conferences and developer ,meetings, represent the company, and become a recognized expert, We encourage engineers to progress quickly in their roles, for example to become team leads (project management training will be provided), Codeplay has been recognized as an excellent employer and awarded the highly respected Investors in People accreditation, Opportunities to get involved with industrial standardization initiatives such as The Khronos Group and HSA Foundation, and various European research programmes, Working on early-stage technology offers opportunities to contribute/shape new hardware/software and standards, Flexible working hours, stock options and pension schemes. **Candidate Skills - Must Have** Solid knowledge of modern C++ (understanding of high-level abstractions), Ability to work with modern templated C++11 code bases, Working knowledge of debuggers, Self-motivation, with a willingness to learn new technologies on the job, Excellent communication skills, both verbal and written. **Candidate Skills - Any of the following would be beneficial** Memory management styles, Code security/exploit prevention, Performance profiling and optimization, Assembly languages, Object file formats, Build systems (e.g. CMake) and compiler tool-chains, Continuous Integration systems (e.g. Jenkins) and best practices, OpenCL/CUDA/C++AMP/other GPGPU language environment, OpenVX/OpenCV/other computer vision environment, HLSL/GLSL/other shading language environments, Games console/low-level graphics technology, The open-source Clang/LLVM compiler projects and the compilation pipeline, LLDB, LLVM's open-source debugger project. **Qualifications** If you can prove skills and knowledge through portfolio work, projects or previous employment, then a degree is not essential. The Cover Note/Letter is just as important as your CV/Resume, so please include one, stating why you believe you are a good fit for the position. If you have examples of your own software projects, we would love to see them, so please include links to them in your application. To apply for the position please use the following link - https://codeplay.com/company/careers/
&gt; That is not universally true. You might have two conflicting inline definitions in different compilation units, in which case you can also run into strange behavior at runtime: sure, but again I don't see a reason why stuff in the std namespace should behave differently than stuff not in the std namespace. It's already UB to break ODR, so why add specific cases for namespace std ? 
... why not just use [-DBOOST_ROOT=/path/to/local/boost](https://cmake.org/cmake/help/v3.10/module/FindBoost.html) ? 
You mean gdb-wasm? ;)
It's part of my CMake file. See eg. [this](http://www.mariobadr.com/using-clang-tidy-with-cmake-36.html).
`boost::spirit` is absolutely a cancer.
**Company:** [Miltenyi Biotec GmbH](http://www.miltenyibiotec.com/en/) **Type:** Full time **Description:** *Your Role:* * We are looking for talented developers who love learning new skills and want to work for a manufacturing company with the aim of making cancer history * You will be working within a cross-functional team of passionate engineers, researchers and experts from various fields, suggesting improvements and changes with regards to software quality by adjusting or adding requirements * You will be using programming languages like C++, Python or Java and design methods like UML * Your creativity and problem solving abilities will make a real difference *Your Profile:* * You are a qualified IT Specialist, alternatively you hold a BSc or MSc in Computer Science or a related technical field * You hold professional experience in designing and developing asset-related software using C++11/14 * Nice to have: Java and Python knowledge is an advantage * Agile development and effective project management following the Scrum approach aren’t just buzzwords for you * You should be able to look at a problem from users' perspective, discuss abstract concepts with fellow developers, as well as presenting the successful implementation *What we offer:* * Flexible working hours for a family-friendly career * Personal and professional development in our in-house academy * Intercultural and cross-border collaboration * A modern workplace and a role you can help shape * Short communication lines and a collegial company culture *Who we are:* * Our innovative solutions in the area of biomedical research and biomedicine make us a pioneer for the therapy of serious diseases * Today we are an interdisciplinary team of more than 2000 employees * Based in Germany near Cologne and with 14 additional, international locations we are a multicultural team * We develop innovative cell and gene therapy solutions – together, we want to make cancer history **Location:** Bergisch Gladbach, Germany **Remote:** no **Visa Sponsorship:** no **Technologies:** We mainly use C++14 and will switch over to C++17 shortly. Our target operating system is MS Windows, though we try to develop in a platform independent way. Your development environment will be MS Windows and Visual Studio 2017. We use Qt and Boost as well as SWIG to provide a Python interface. **Contact:** Either contact me via PM or use [the online form to apply](https://miltenyibiotec.softgarden.io/job/1628733/Software-Developer-m%7Cf-C++-for-our-medical-device-platforms?jobDbPVId=4359237&amp;l=de).
Conan is also worth checking out (https://www.conan.io/)
I got one: sudo apt-get purge cmake This one works great and is really practical
Yup.
Idk, division means nothing in this context and the operator greatly resembles something we use paths already ...
The real problem I believe is that most CMake commands are too low level. We really need a set of macros that are simple to read and can do most of the work directly for 99% of the cases. For example: https://github.com/Orphis/boost-cmake/blob/master/libs/filesystem.cmake This one defines a library and some tests that are built as separate executables. It will set lots of proper defaults too, could optionally do some sanity checks. 
...which suffers from a "semantic abomination" of simultaneously being an iterator *and* a range, but I've [complained about that before](https://www.reddit.com/r/cpp/comments/6s5j0h/c17_in_details_filesystem/dlajuza/?context=3)
Would it make sense if there were a language construct to tell the compiler that X aliases Y? Given how much trouble it is causing, why not just make it explicit? Sort of like an inverted restrict, telling the compiler that two unrelated pointers actually point to the same thing. Surely it would help with code generation.
&gt; you could have just written a much better performing, easy to debug, fast to compile parser by hand. Faster to compile and easier to debug maybe, but I'm skeptical about "much better performing" -- in my experience the runtime performance of Boost.Spirit is pretty stellar.
You could look at the Meson buildsystem. In my opinion it is way more understandable then cmake
Where does come from the performance of manually written parser? Did they assume something wrong or implemented in less optimal way?
Whoa there. I do like the role of `/` in `std::filesystem` but `boost::spirit` is an affront to the eyes and to the, uh, spirit.
I was hoping he'd talk more about situation with `union`. I see it used for type punning all the time without any discriminant, even though it's incorrect/UB. The situation is the same and the "correct" solution is also the same, but it's flawed. It's very cumbersome (defeats the purpose of many type-punning use-cases) and it's not really guaranteed to generate the desired code. In simple examples with optimizations enabled it does. No telling how that'd behave on different compilers in more complex scenarios.
I agree that overloading operators should be used sparingly, _but_ this might be one of the place where it makes perfect sense, because it makes the code far more readable. I mean, which is more readable? rootPath().join(foo).join("bar").join(baz); or rootPath() / foo / "bar" / baz; OK - to be honest, looking at both of these I'm really not sold on using the operator overload. It's a little less to read but it's hard not to see it as division, and really, how many path operations do I actually do in code? Perhaps better to be clear... but I'm on the fence.
Nice talk (and Scott's talk is also good). Worth noting that the main motivation given is satisfied by the standard library. [std::nextafter](http://en.cppreference.com/w/cpp/numeric/math/nextafter)
What would it help with? Compiler already assumes that two pointers alias if he can't prove otherwise.
There are a lot of rather high level commands to use in more recent CMake stuff. I wish I had some tutorials for "Modern CMake" though.
It is far easy to tune one to specific needs vs trying to make one generic to cover as many needs as possible and still be efficient. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7ocuwt/does_it_worth_is_to_complete_studying_c_as_a/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Also, boost has the same operator for concatenating paths.
IIRC Windows 7 dropped the old shell code for a new implementation, so it's possible this is only broken in XP and older.
It would provide a legal way to alias two pointers to different types, for one thing.
`filesystem` is awesome and gets more satisfying the more I use it. It removes tangled and lengthy nightmares of filesystem handling code that oft uses C-style unsafe functions to boot. So, yay! :D
Not sure if this won't introduce some other problems down the line.
I must agree with the downvotes for a very non-helpful comment, but I have to say that this is exactly the comment I was tempted to make. :p
Still, using "commands" instead of something that is a pure descriptive version (wrapped in a macro) is a big cognitive difference. 
Any concrete example? I would like to see the details.
&gt; One reason is that the forward slash clashes with the Windows convention for command line options. This has been driving me nuts, like, right now. Working on updating some very old command line tools code to modern argument parsing conventions (to solve compatibility bugs with things like Python's `subprocess.Popen`'s Windows-standard argument quoting conventions) and the ambiguity between `/foo` as an option and `/foo` as a path parameter is frustrating, and difficult to fix for back-compat reasons.
C++, with its Standard Library, has after three decades become such a *huge* language that nobody can be an expert on the whole thing. Don't be discouraged by this; instead be satisfied to learn a little at a time. Try to find those parts of the language that support whatever your current project is -- although I grant that for a newbie even this search will sometimes be slow. After a while, you'll come to have a general knowledge of the kinds of things that C++ can do, and then you'll know where to obtain the technical details of specific features. And remember: the experts do not always agree.
 [C:\Temp] &gt; md a/b The syntax of the command is incorrect. [C:\Temp] &gt; md a\b [C:\Temp] &gt; cd a/b [C:\Temp\a\b] &gt; cd ..\.. [C:\Temp] &gt; dir a/b b [C:\Temp] &gt; dir a/b/* Invalid switch - "*". [C:\Temp] &gt; _ 
Planning to update this for 2018, but so far not much has changed: https://www.youtube.com/watch?v=9WHRfU7U9lk
I use clang-tidy with run-clang-tidy.py, and run it from CI so that pull requests are verified: - https://github.com/Sarcasm/irony-mode/blob/82ba45ec15c9011bbdf1d69cf25c8193d33c0028/server/.clang-tidy I run it on Travis CI, see configuration here: - https://github.com/Sarcasm/irony-mode/blob/82ba45ec15c9011bbdf1d69cf25c8193d33c0028/.travis.yml#L49-L54 For the PR to get validated, I treat warnings as errors: - https://github.com/Sarcasm/irony-mode/tree/82ba45ec15c9011bbdf1d69cf25c8193d33c0028/server/build-aux/run-clang-tidy I have a similar setup for clang-format: - https://github.com/Sarcasm/run-clang-format I also have some notes about clang-tidy, which I will update soon now that I have started using it at work: - https://sarcasm.github.io/notes/dev/clang-tidy.html
wow that is great. 
 fs::path home = "~/"; fs::path p = "foo/bar"; std::open(home / p / "baz");
A real problem is that there's 2 cmake's. The pre ~3.0 global `include_directories...` and the post ~3.0 `target_include_directories, ...`. Anyone looking for references will find a mixture of both.
But that's not cross-platform! 
Quoting C++14, “The library never assumes that past-the-end [iterator] values are dereferenceable”, but the question of whether a past-the-end iterator can be deferenced is a different issue. Indeed the *assumption* would not be needed if they clearly could not be derferenced, like ever. Related and worth noting: it's explicitly allowed to dereference a nullpointer in `typeid` expression, and "after the lifetime of an object has ended and before the storage which the object occupied is reused or released" it's explicitly allowed to dereference a pointer to that storage location. In both these examples there is no object at the pointed location, which means that arguments based on the notion that dereferencing absolutely must refer to an object, are incorrect. Unfortunately the issue is subtle, there are a number of related (at least apparent) contradictions in the standard – which makes it possible to selectively read the standard as some people read their holy scriptures, to apparently prove just about any position...
I have just started evaluating Resharper++ 2017.3, and though clang-tidy seems slow, it works out of the box, without setting any option (but many are possible).
So now if you have a template that assumes the mathematical properties of "/" apply, particularly one that might be using SFINAE to specialize for that case, are going to be quite broken.
In fairness, you can do a clever implementation of operator+ that returns back a transient object that represents the composable operation.
Thank you for your response. I will def. check it out!
I maintain that we are in need of a standard-defined `as_punned_type&lt;T&gt;` builtin. uint32_t representation = as_punned_type&lt;uint32_t&gt;(4.7f); float &amp; original = as_punned_type&lt;float&amp;&gt;(representation); std::cout &lt;&lt; original &lt;&lt; std::endl;//Prints "4.7" representation++; std::cout &lt;&lt; original &lt;&lt; std::endl;//Prints whatever 4.7 + 1ULP is representation--; //double value = as_punned_type&lt;double&gt;(representation); //Won't compile because double is wrong size double value = as_punned_type&lt;float&gt;(representation); //Fine uint64_t &amp; u_representation = as_punned_type&lt;uint64_t &amp;&gt;(value); u_representation = ~u_representation; //Valid std::cout &lt;&lt; value &lt;&lt; std::endl; //I don't know what an IEEE754 double 4.7 is when inverted, but it'll print that. 
The problem of concatenating is resolved by expression templates, but I agree that it's a painful solution. We need some language improvements similar to copy elision.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
There'd be some problems, although clever use of the casting operator (and maybe a non-explicit constructor in std::string) might mitigate most of the problems. Rvalue references help minimize the problem a great deal.
This doesn't really goes against my point though, right? I was just using something as an example to show something different. Sorry if it wasn't really correct.
Same for strings and `operator+`. And I doubt someone would instantiate a template with path instead of an arithmetic type.
Ok, Sorry and Thank you!
Off the top of my head, it would be rad if the samples showed examples of: 1. Enabling sanitizers 2. Enabling various static analysis tools 3. Enabling valgrind 
Would you like me to randomly knock on your door and ask you if you can help with my cooking recipes?
Yup, std::string::operator+(const std::string&amp;) is an abomination for the same reason. It would make sense if you had a generic template for arbitrary types, but a specialized one for arithmetic types... which is a not entirely uncommon case for SFINAE applications. Right now what I've seen people do is code a special case for strings as well to avoid a problem. Lovely if we end up doing this for paths as well.
One example I've been wanting to see (though admittedly haven't looked very hard for) is the best way to have two separate projects in separate repositories. It seems like the best general solution to this is to set up an install target and install binaries and headers into the system somewhere so the next project can access them, but most CMake examples I've seen seem to be all over the place on how this is done.
Do you mean, two separate projects and then build both as part of the same "build tree"? Or have one consume the other as prebuilt binaries? 
Except that operator+ on strings is perfectly fine. The 0 element is the empty string. ` "" + a == a == a + "" a + (b + c) == (a + b) + c ` 
auto x = a + b would definitely not do what you expect, and you would need some invovled COW semantics to avoid problems with lifetime issues. Some of the problems with templates, specialization and type inference can be mitigated I agree it isn't trivial, and there are likely cases that couldn't be fully addressed. Once you do the operator overloading, you've already opened up the gates to hell though so... It works much better if you just get rid of the operator overloading and do things the right way.
Not OP, but I think he is referring to notations like .* vs * for element-wise multiplication vs matrix multiplication; and there are a lot of other examples.
I haven't looked at the new version but the old version was missing all the updates made during standardization. - generic/native flag for path constructor (for VMS, mainframes, etc) - lexically_meow path member functions - changes to implicit dot for empty directories - changes when appending an absolute path (and maybe an empty path) 
 - system_config_file = util::fs::BuildPath({system_dir, "tint3", "tint3rc"}); + system_config_file = util::fs::Path(system_dir) / "tint3" / "tint3rc"; I think the build path is more effective, doesn't use separate allocations.
Or, more generally, you can set `CMAKE_PREFIX_PATH` and it will search there as well (`BOOST_ROOT` takes preference). The advice in the article here is not great; editing the cache or `CMakeLists.txt` are both signs of hacking around CMake rather than simply using the configuration knobs already provided specifically for the purpose. However, one place where `FindBoost` is currently lacking is coping with the several incompatible ways of dealing with all the different naming schemes for all the python versions for the python and numpy libs used by different distributions. It's a mess, and I have a few tickets related to it. I ended up using `pybind11` for an easy life; being header only and cleaner, it doesn't require a bunch of shared libraries and encoding all of the insanity within `FindBoost`.
Here's hoping for `std::bit_cast`: void add_ulp(float&amp; f) { f = std::bit_cast&lt;float&gt;( std::bit_cast&lt;uint32_t&gt;(f) + 1); }
An official build system is the best thing that happened to C++ ever. Even better than C++11, concepts, lambdas or modules. Better than Qt! Better than clang! Thank God for cmake! Thank you cmake for improving the experience of using C++! Ps. Scons autoconf makefiles and premake sucks
Every call to a filesystem path consuming function on Windows performs a Win32 to NT kernel path conversion i.e. malloc some memory, do character-by-character conversion, call NT kernel function, free memory. It is this conversion routine which converts forward slashes to backward slashes, and that's why things appear to work fine most of the time. But command line args parsing libraries can and do get confused, they sometimes consider forward slashes to always mean options. If it weren't for that, you probably could mostly always get away with forward slashes most of the time on Windows.
I really like your idea. Other examples that would be valuable (probably some duplicates from other commenters in here): - Running static analysis - Managing which sanitizers are enabled - Using CPack or BundleUtilities or whatever it is to make MacOS app bundles/frameworks/DMGs and Windows installers, or at least how to configure Xcode/Visual Studio to build them correctly in the generated project (this might be the same as your 2nd bullet, but that whole aspect is still mysterious to me). - Setting up a project to be able to use system-installed libraries, build libraries from source, or prebuilt libraries in the same project folder (or overridden in the CMake config UI). - For using prebuilt libraries, handling platform and architecture, VC runtime versions, and debug vs release vs whatever variants correctly with suffixes (e.g. FMOD provides libfmod and libfmodL, the L suffix indicating it was compiled with verbose logging. If you teamed up with others who have tried to make similar resources you'd reduce your risk of being yet another out of date CMake resource. Do it! :D
VMS? I'm sure there's still a few Vaxen running somewhere...
It's not particularly expensive and gets done just once, but yeah.
noalias? Do you mean restrict? (I have no idea why C++ never lifted that from C, but at least it's a very common extension in C++ compilers).
Yeah my bad (I rarely use it).
This. I've recently been porting our build from a bunch of makefiles to cmake, and constantly having to wonder whether the answers I find to questions are correct for modern cmake or not has been pretty annoying. 
Once upon a time, classic MacOS used ':' as path delimiter, but I imagine that wasn't a big design concern in 2017. There may still be some obscure OS's that keep the Old Ways alive. (And, even if there aren't, the fact that there could be ensures forward compatibity if somebody makes such a system in teh future.)
Hm, now I am wondering if there's a compiler for c++17 that can target VAX...
gcc
AFAIK, libc++ has filesystem in std::experimental.
I made a quick-and-dirty custom cmake target for it so it just runs on every build and fails the build if it catches something. I think running it as you build or even while you code (if your IDE supports this) is definitely the way to go, though I would not recommend putting it in a dirty custom cmake target like I did.
 template&lt;class Callable, class... Args&gt; struct LambdaWrapper { using this_type = LambdaWrapper&lt;Callable, Args...&gt;; constexpr LambdaWrapper(Callable&amp;&amp; Init) : callable(std::forward&lt;Callable&gt;(Init)) , callable_final(&amp;Callable::template operator()&lt;const this_type&amp;&gt;) {} constexpr decltype(auto) operator()(Args... args) const { return (callable.*callable_final)(*this, std::forward&lt;Args&gt;(args)...); } Callable callable; decltype(&amp;(Callable::template operator()&lt;const this_type&amp;&gt;)) callable_final; }; template&lt;typename... Args, typename Callable&gt; constexpr auto wrap(Callable&amp;&amp; Lambda) { return LambdaWrapper&lt;std::decay_t&lt;Callable&gt;, Args...&gt;( std::forward&lt;Callable&gt;(Lambda)); } *** automatically wraps a lambda with a **generic first parameter**, providing the other parameter types with template args: `constexpr auto wrapped = wrap&lt;int&gt;([](auto self, int i){/\*...\*/});`
 template&lt;size_t ArgC, class Callable&gt; struct LambdaWrapperGeneric { using this_type = LambdaWrapperGeneric&lt;ArgC, Callable&gt;; constexpr LambdaWrapperGeneric(Callable&amp;&amp; Init) : callable(std::move(Init)) {} template&lt;typename... Args&gt; constexpr decltype(auto) operator()(Args&amp;&amp;... args) const { static_assert( ArgC == sizeof...(Args), "wrong number of arguments; remember: first parameter is invisible"); constexpr auto mptr = &amp;Callable::template operator()&lt;const this_type&amp;, Args...&gt;; return (callable.*mptr)(*this, std::forward&lt;Args&gt;(args)...); } Callable callable; }; template&lt;size_t ArgC, typename Callable&gt; constexpr auto wrap(Callable&amp;&amp; Lambda) { return LambdaWrapperGeneric&lt;ArgC, std::decay_t&lt;Callable&gt;&gt;( std::forward&lt;Callable&gt;(Lambda)); } *** fully generic lambda like so: constexpr auto wrapped_generic = wrap&lt;2&gt;([](auto self, auto a, auto b){ if(something) return self(a,b); else return 0; });
How about `&lt;&lt;` for streams?
std::path::lexically_normal( ) will get the normalized form of the path(e.g. \ instead of / on windows)
I guess the best reason is that they try to make sure that a conforming program will also work in later iterations of the standard. If you put stuff in std it is possible that this isn't the case anymore, because you have no way of knowing what a future standard looks like.
/u/mjklaim, /u/kalmoc, here you go: http://doc.magnum.graphics/magnum/examples-triangle-plain-glfw.html :) A fresh example showing how to hook Magnum directly into an existing GL context and window surface (in this case GLFW).
Thanks, your comment finally pushed me to create a dedicated page to help users decide: http://magnum.graphics/is-magnum-what-i-am-looking-for/
There's a bunch more examples now (and still more to come): http://doc.magnum.graphics/magnum/example-index.html
I had it fail when iterating via size()/operator[] would give different values back compared to begin()/end().
Literally the poster child even many members of the committee use as bad operator overloading. :)
&gt; Visa Sponsorship: No May I ask why? I see even some relatively small shops sponsor H1B's, so what happened with your HR?
i am using it within visual studio through Clang Power Tools: https://marketplace.visualstudio.com/items?itemName=vs-publisher-690586.ClangPowerTools mostly static analysis purpose. (using cppcheck, clang power tools, cpp depend, etc).
Indeed, pybind is absolutely better than boost.python ; it's cmake integration is great.
Thanks, great job! It's an unfortunate truth that too many projects fail to provide a high level overview - a one line sales pitch, if you want. It's one of my pet peeves and I'm glad to see something good came out of my comment this time! 
Its been most useful in making me feel less exhausted and disgusted (at the same time) dealing with the 20+ year old codebase I'm mired in at work. I found it easiest to add it into my `tasks.json` for vs-code by just running `run-clang-tidy.py` - it doesn't directly affect the build process, and really I only had to run it once or twice since I'm not adding much code, per-se
I was going to buy PVS studio until they essentially said "nah we don't want to sell to single-users - just use the trial and work around the limitations built into it forever". I literally wanted to give them money because I like the product but was told to hack around the trail version instead. Seems really weird to me...
Cool, as said on twitter I will have to try and explore more but it's a very good start. So after a quick glance: The only thing that bothers me (because I'm considering real cases) is why am I forced (per the Platform::Context API) to provide cli arguments? If I integrate a rendering engine in a program, I might not have access to these on rendering engine initialization and I might not want to use them, I might want to use specific options. I don't see a way to setup Context withtout these (except the deprecated default constructor). What I think would be better: Context constructor take a type that represent the supported options (no need for the rest), provide a free function translating cli arguments to this type. That way the user is free to ask for whatever setup. The other thing is that this don't need an asset system but you mentionned that the resource manager should be optional but is not. Could you clarify the implications? Is it implicitely instantiated in this sample?
I have made an application exactly for your use case, since I faced the same problem as you did. It can produce executables for 64-bit Windows, but it requires Linux, macOS or FreeBSD when developing. It's a configuration-free build system, where all compilation flags are auto-detected based on the names of the include files, using the package manager (pkg/pacman/brew) and pkg-config. The detection speed is much faster than the compilation and linking, and it works surprisingly well. It's called Sakemake (couldn't think of a better name, good name suggestions are warmly welcome!) Please give it a spin: https://github.com/xyproto/sakemake
Is this still valid?: https://www.viva64.com/en/b/0457/#ID0E5QAE 
&gt; I personally don't like syntax abuse in any form, but of course that's just my opinion, :) You monster just abused both : and ) in a single sentence. Don't you know how [confusing](https://xkcd.com/541/) that can get?
&gt; I literally wanted to give them money [We are Closing Down the CppCat Project](https://www.viva64.com/en/b/0320/). Alternative: [How to use PVS-Studio for Free](https://www.viva64.com/en/b/0457/). 
Yes.
And that's why unit-tests matter. To be honest, date-handling is tricky enough that I am surprised no one clamored for tests when the function was introduced. Maybe the commit was too big?
Agreed. But why not aim for 1st place? As C++ developers, we are trading our sanity for power already; I'd like to get as much bang as possible for my bucks.
[CppCon 2017: Scott Schurr “Type Punning in C++17: Avoiding Pun-defined Behavior”](https://www.youtube.com/watch?v=sCjZuvtJd-k)
C++ has much to help for writing high-performance idiomatic code, however there is a growing number of footguns which regularly catch the unwary (and others). I did not know, yet, about structured bindings; it's a stark reminder that introducing new language features is hard, and that forgetting to check their interaction with one of the so many already existing other features is all too easy. However, already in C++11 there are at least 3 issues with the language itself: - *aliasing*: the absence of proper support for aliasing is annoying, but the work-around is even worse. Type-based aliasing outlaws a lot of the type punning used throughout network stacks to get zero-copy parsing. As a result, `-fno-strict-aliasing` is a staple of low-level code, but inhibits a whole class of performance optimization. - *moves*: there are two issues with moves, (1) the fact that object must remain valid for destruction (and assignment if supported) after the move forces a "null" state, which itself generally imply branches and (2) the fact that too often `std::move` must be called explicitly, lest a copy is incurred "accidentally". - *implicit allocations*: implicit constructors, copy constructors, copy assignment operators, ... idiomatic C++ is all about implicit memory allocations; I've way too often stumbled upon a performance profile which showed up an innocent-looking piece of code as allocating. This was of course necessary prior to move semantics, but for the last 6 years it's just been a legacy issue.
*(sorry if I'm just [repeating myself](https://twitter.com/czmosra/status/949616739381280768))* &gt; why am I forced to provide cli arguments? True. It's weird, right? :D Don't remember the reason why I marked the empty constructor as deprecated. You can always pass `{0, nullptr}` there, but I'll un-deprecate the default constructor to make the API annoyance-free. The arguments are mainly for debugging purposes from the outside (managing driver workarounds, use of extensions...), so there's usually no need to override them from the application. If not passed there, the environment vars can still be used instead. But good point with the config: second item added to my TODO list. Asset system: there's the [Trade](http://doc.magnum.graphics/magnum/namespaceMagnum_1_1Trade.html) namespace that provides interfaces for asset import and conversion (and plugins then attach to it). As said on Twitter, it's currently built as part of the core library instead of being totally separate, so it *may* inflate binary size. The separation is easy (just yelling at the buildsystem for a while), but I need to be careful to not break backwards compat too much. (Third TODO for me.) Then there's a [ResourceManager](http://doc.magnum.graphics/magnum/classMagnum_1_1ResourceManager.html) class, but that's header-only and not used by Magnum core so it doesn't inflate binary site at all. &gt; Is it implicitely instantiated in this sample? To be clear: the only thing that's instantiated is the [Platform::Context](http://doc.magnum.graphics/magnum/classMagnum_1_1Platform_1_1Context.html) class and it handles *only* GL state tracking, nothing else. If you wouldn't need GL, you wouldn't even need to have this instance. In other words, there's no huge bloated resource-hungry subsystem running in the background without your consent (except for the GL driver, haha), it's just a bunch of things that may currently make the binary bigger if the compiler fails to throw the unused code away. This hopefully also makes it clear how to use more complex functionality (custom shaders/textures/materials, resource management) with your own window system handling: just use them as explained in the other examples, there was no additional hidden magic in the `Application` classes that made them work.
&gt; I thought that it is assumed that `char*` may alias into anything so are you sure that network stacks suffer from this? You can *read* any piece of memory (any `T*`) from a `char*`. What network stacks usually do however, is to go from a `char*` to a `T*` which is strictly forbidden under strict aliasing rules. &gt; Sufficiently smart compiler can figure out (have hardcoded) that moved from `string`/`unique_ptr` dtor is noop so at least for variables it can be optimized away(it is hard to prove it for reference arguments). Constant propagation, etc... may be able to figure it out. Maybe. And if it doesn't you get no warning. &gt; IDK, to me most of allocations in C++ are obvious, but hard to say without you giving specific examples. int find_exact(std::unordered_map&lt;std::string, int&gt; const map, char const* key) { if (auto it = map.find(std::string(key)); it != map.end()) { return it-&gt;second; } return -1; } int find_case_insensitive(std::unordered_map&lt;std::string, int&gt; const&amp; map, char const* key) { if (auto result = find_exact(map, key); result &gt;= 0) { return result; } std::string lower_key = to_lower(key); return find_exact(map, key.c_str()); } How many memory allocations occur in a call to `find_case_insensitive`?
&gt; (best case/worst case) well... you pass map as value, not reference so number of memory allocations is "infinite"(unordered_map allocates for every element). But that code is obviously bad. Regarding map.find I admit to being wrong. I would have assumed no allocations due to transparent comparators, but those only work for map, not for unordered_map... Kind of embarrassing for C++, but to be fair &lt; is much easier to model with templates than the fact that basic_string&lt;T&gt; and T* can model the same sequence. I do not want to be white knighting too much for C++, but if you use char* you are asking for problems like this. :) to_lower probably creates a string so memory allocation. regarding other stuff: thank you for clarification.
Could you suggest a use case that is _not_ superseded by requires-expression?
do you really want to #include &lt;concepts_flame_wars&gt; ? (y/n) ;) 
You could also do it with a path constructor or function and a comma-separated list, like for example `fs::path(rootPath(), foo, "bar", "baz");`. I'm with you and kind of on the fence too but the join version is really quite ugly as well. I think the operator overloading is okay :-) 
Cool, thanks for all these clarifications :D
That being said, even in my isolated code its problematic to pollute all source files with unnecessary info. Anyway you had that discussion, but personally I would prefer something like what most 3rd party in gamedev do these days: free until you make money. Maybe forcing to add a cpp with a constant that must end in the final binary would have been a good solution to detect people using your soft and less of a problem for users.
I guess there is code out there that relies on `T()` sfinaeing away, so I doubt this will find its way into the standard. But yes, I'd appreciate a shorter notation.
Ah! Good on you spotting the `map.find(key)`, it was indeed the one I intended as a trick. The pass-by-value is generally caught by lints, so it's not too bad, however apparently the templated nature of `std::unordered_map` is too complex for those lints to realize the issue. I've two incidences of this `map.find` issues in production :( Each time we wondered if we should just remove `std::string` altogether and replace it with another string implementation *without* implicit allocations, but it's quite the daunting prospect...
&gt; Maybe forcing to add a cpp with a constant that must end in the final binary would have been a good solution to detect people using your soft and less of a problem for users. What prevents you from removing the constant when building the actual release? You could even script it easily enough!
True!
You could make your std::string implementation constructor taking char* explicit then compile your source, see all the problem areas, then undo the constructor change. For example this is what Google style guide says: Type conversion operators, and constructors that are callable with a single argument, must be marked explicit in the class definition. As an exception, copy and move constructors should not be explicit, since they do not perform type conversion. Implicit conversions can sometimes be necessary and appropriate for types that are designed to transparently wrap other types. In that case, contact your project leads to request a waiver of this rule. Obviously std::string was implemented long before explicit keyword was added to C++. 
Concepts (at least part of them) have been voted into C++20, so it makes sense to think about what they already bring to the table when discussing hypothetical new features.
Why on Earth did they use such a long namespace name instead of something like std::fs?
It is often said about functions: Do one thing, and do it well. The same can be said about libraries. Here's one that just does date/time: https://github.com/HowardHinnant/date When a bug is found in it (and that does happen), it gets fixed and everyone who uses (and stays current with) this library gets fixed.
Literal stupidity. Not everything is an integer, not everything behaves like an integer, but yea, let's pretend every operator only does integral and bitwise things and are useless otherwise! /s
A shortcut for `declval` could be nice, and I'd use it, but I think require expressions will slowly replace the need for `declval` away, and concept ( + adjective syntax please ) will take over type traits rapidly. For example, your type trait will be far easier to implement with concepts: template&lt;typename T&gt; concept Drawable = require (T t, std::ostream o) { t.draw(o); } Remember that we must not make our horrible hacks easier to write, but we should have tools that don't require us to make horrible hack in the first place.
&gt; you could have just written a much better performing, easy to debug, fast to compile parser by hand. I am genuinely interested to use the parser you created that is better performing than boost::spirit.
I was recently looking for a run-clang-tidy with return code and couldn't find it. Thanks. I'm surprised authors didn't think of adding that. You should make a PR so that it could added to the original script.
People should stop using forward slashes as path delimiters on Windows and properly use back slashes. Forward slashes are not supported if you want to correctly support long paths (&gt; 250 characters). Many applications don't want to support it, because explorer doesn't support it and explorer doesn't support it, because Ms is afraid application won't support it. Every modern application should be writen with long paths in mind and only use full UNC paths so that they can support paths of up to 32k characters and support all kind of characters on filesystems, that support it and even case sensitivity on Windows!.
&gt; Now, the following question arises: "How can we improve our &gt;style to ward off errors like that?" &gt; &gt;I have no answer to that. This isn't intractible. In a language such as haskell it would be perhaps natural to give different types - which would catch this at the type level. It's probably too heavy handed to give day/month non-implicitly convertable types in this c++ example, but it's food for thought.
[The DateTime is the dumbest possible struct in protobuf.](https://github.com/google/protobuf/blob/master/src/google/protobuf/stubs/time.h) That's just... nooooo... and light years away from what you're talking about.
This can't be updated enough in case of this bug...
Sure? 'Cause they had tests. Note that the code coverage of 100% doesn't seem to help in this case either. Point being: all automated tests are just code, and as all code, they need to be *correct and cover all cases*; testing is *hard*.
How on earth was that a hostile response..?
I assumed since i was downvoted and then told my idea was &gt;That's just... nooooo... 
Euh... the "nooooooo" is directed to what protobuf did there, not your post. I merely wanted to say that, given what DateTime is there, what you're saying is nowhere near the radar 😀 Misunderstanding, shake hands? 😀
Because it a pointless vanity overloading of an operator. After years of experiencing strange and confusing overloads I thought there was consensus that operator overloading should be limited to operators where there is established practice (either in math, or in existing programming languages including C++ itself). In this case, established overloaded operators would have been sufficient. Using `/` as a minor variation on `+` is new, unusual, and confusing. And it (once again) opens the floodgates to "cool" operator overloads appearing everywhere "because the standard is doing it too". 
Actually giving `day` and `month` different types is exactly what is needed and not too heavy-handed for C++. https://howardhinnant.github.io/date/date.html#day
Ok so this is showing off some compiler feature right? Nvm that, why do we not have some general datetime library that gets linked to by everyone everywhere? One not doing this nonsense? [current year argument]
Howard's is probably the closest to that. It's progressing well through standardization, too.
This was about 8 months ago I was going to buy it. I'm not saying everyone would but I was going to. If they've deemed it not profitable to sell to single-users then that's their prerogative. I just found it really weird.
 CONSTCD11 inline day::day(unsigned d) NOEXCEPT :d_(static_cast&lt;unsigned char&gt;(d)) {} I feel like this should do some basic range-checking since the narrowing conversion is being explicitly allowed. CONSTCD11 bool operator==(const day&amp; x, const day&amp; y) NOEXCEPT; I noticed that all of the comparison operators take a reference to const even though sizeof(day) == sizeof(unsigned char) in which case taking by value would be just as cheap. I don't mean to split hairs, I was just curious about the design decision.
Does it work in a way where there are "automatic" comments on the PR on the lines flagged up by clang tidy? Because that would be my dream! 
On the narrowing, there is documentation that the value is unspecified if `d` is outside the range [0, 255]. And there is a member `.ok()` which will return false if the value is outside the range [1, 31]. `!ok()` values are allowed, and sometimes even useful. Internal range checking is avoided for performance reasons. If I add it, clients can't remove it. If I don't add it, clients can add it externally, and can choose to range check either [0, 255] or [1, 31] depending on their needs. Second question: As it is very short and inlined, I don't expect it to make any difference in generated code one way or the other. I think I chose `const&amp;` just for stylistic consistency with other calendrical and chrono types.
Unless decltype and declval are no longer to be used in C++20 onwards, I don't think it really matters what example is used. 
I am afraid that a lot of the advice is misguided and I would not necessarily recommend this approach on anyone else. However, it does highlight *the perfect storm* in terms of everything working against you, including the way packages and the link paths work on linux distributions. But the solution itself is not great. Statements like "possibly" the Boost_DIR variable will revert "but this is okay", or "some libraries may still be linked with...", or even the advice to hack the CMakeCache or override the global linker flags for the project to me indicate a lack of in-depth knowledge of what is going on, however, you are on the right track. L 1) CMake comes with what I call a 'canonical' FindBoost.cmake script (https://github.com/Kitware/CMake/blob/master/Modules/FindBoost.cmake), which should be the preferred option vs any re-implementation. In the header of that file, you can see that if the variable `Boost_ROOT` is defined prior to the first call to find_package(Boost), it will look there first before looking in system locations. I would check what that header looks like in the version of CMake/FindBoost included in your distro. You may need to set Boost_ADDITIONAL_VERSIONS if that revision of the script wasn't aware of boost 1.64. And you can use Boost_NO_SYSTEM_PATHS to prevent it from looking in the system path (/usr/local, /usr, /opt, etc). 2) The second problem you mention is CMake linker statements looking like `-lboost_numpy` instead of the full path. Indeed, this is problematic. If the linker statement looks like that, chances are it will use the system one if it is present in /usr/local/lib or similar. My first question would be... *how* is `target_link_libraries` called from the cmake scripts? The following line: target_link_libraries(Mytarget PRIVATE SomeLibrary) works in strange ways in cmake, but it is all documented. If 'SomeLibrary' is a cmake-defined target, it will link against it. If 'SomeLibrary' is an absolute path, the linker statement will look like -l/path/to/library.so. * If 'SomeLibrary' is just some name, I think CMake just passes it to the linker like that and the linker will try to find it in its search path. * There is an obscure exception when telling cmake to link against full paths, and cmake stripping them to just the library name. And that is if the library can be found in the LIBRARY_PATH environment variable which is used by the linker. Anyway, as for the actual piece of advice: a) if FindBoost or similar scripts do not create an import target e.g. Boost::numpy or the old style ${Boost_Numpy_LIB} or similar. My first advice would be modify the find packages yourself so that these are created with full path, and link against these. b) If the above is impossible, try to see if it's feasible to construct the full path to the correct library based on other variables in the find package c) If none of the above works for you, you can achieve the same effect of modifying CMAKE_SHARED_LINKER_FLAGS , by NOT modifying them. You can make a call to `link_directories(/path/to/libraries)`. However this is discouraged (you can consider that cmake function deprecated), should be used as closed as possible to where that directory is needed for linking, and again, I would only advise it if you can generate that path based on the call to find_package. Otherwise you would just be hacking a cmakelists in a non-generic way. 3) You are on the right track in your "Tale of two RPATHs" but the most important statement is right above. "This is caused by the different behaviors of CMake between build and install." This is 100% documented cmake behaviour, the "build tree" and the "install tree". When building with "make install", any path that is specific to the machine where the binaries are being built, is removed, so that the package is more "generic", but not necessarily relocatable. And this is where cmake is not at fault: "install", in the old linux days, means actually copying those files to the /usr/local, /opt/local or similar, because the dynamic loader at runtime is set to look in those locations. This doesnt mean that the files are "relocatable", alas, you can choose to install in a different prefix other than /usr/local, but then the linker will not find the required dynamic libraries. The solution to this problem varies from app to app. When it comes to producing apps that will run on a different linux system, you have some options: 1) target the distro itself, and only use system libraries, not 'custom' ones. Now you have your typical .deb file that targets ubuntu. 2) create a self-contained folder with your executable and its dependant libraries, but rather than expect the users to run the binary itself, you run it through a bash script. This bash script, you may have probably guessed, pretty much sets LD_LIBRARY_PATH prior to invoking your executable. Since its an environment variable, the change only affects that bash session and not the entire system. (Note: you're still not safe from being too distro specific, depending on what you have linked against, or which version of the standard library you linked against) 3) A different approach which is more common on macOS than it is on Linux, would be use "relative" RPATH keywords, i.e., you would have to set the RPATH in your executable to be "$ORIGIN/./:" (if libraries are in the same folder), or "$ORIGIN/../lib" (if you follow the classical lib/ , bin/ structure). You would simply set the variable CMAKE_INSTALL_RPATH to one of the former and that should work (and only affect the install targets) Your advice is flawed in the sense that by setting CMAKE_INSTALL_RPATH_USE_LINK_PATH to ON, those paths are hardcoded to be the ones on *your* machine. Copying the package somewhere else will cause the linker to not be able to find them unless the exact same path exists on the target machine. Side advice: you could have avoided this entire headache by compiling your entire version of boost as static libraries and forcing cmake to use those instead. :P 
There are too many genuinely stupid people who post on the Internet to be able to take something as a joke purely because it should be obvious. 
Learn templates, lambdas, and how you can mix those with classes and inheritance.
There is a useful list of books on [Stack Overflow](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list). In most cases reading a book is the best way to learn C++.
When it says `Dear PVS-Studio, please check it.` in the comment... does it imply that the source code is being sent to Viva64...?
Still used in AppleScript and there’s a CoreFoundation function for converting these paths to posix :)
You're returning a lambda expression, not a `std::function`. It's not the same thing. A `std::function` is a wrapper around a function object. This wrapper accepts function object were their return type differs but is convertible.
I completely agree. I emailed them long ago and said I would LOVE to pay them for their work. But there is no way I can justify a huge yearly cost for their product just for some personal projects which are open source and making no money. They released a stripped-down personal version. I bought it. Then they retired that product because not enough people who claimed they would buy it did. Now I feel DOUBLE cheated because they abandoned something I bought. It wasn't cheap. I think asking for a shoutout in every single source file is asking a lot. Especially after they've abandoned me. Other free-for-open-source products don't ask that much. I love their product. I seriously do. But at this point they're making me feel like I'm selling out.
Always prefer commands starting with target_
I can follow up on that. My understanding is that this is more of a timing issue. If we started the process before April we would only get the person in November. If after April we would have to wait until next November. Again, I am not sure and can follow up if you are interested.
&gt; You're returning a lambda expression, Where did you get that from? The OP returns `operation` which is a variable of type `std::function&lt;int(int, int)&gt; `. That being said, the explanation is probably the same and imho the question is off topic for this sub
Sorry for that brain hiccup
Well, compared to a single declval, using concepts is much more verbose, so it has the exact opposite effect of what the OP is suggesting.
This boils down to #include &lt;functional&gt; using a = std::function&lt;A()&gt;; using b = std::function&lt;B()&gt;; using c = std::void_t&lt;decltype(std::declval&lt;a&amp;&gt;() = std::declval&lt;b&gt;())&gt;; which compiles for `-DA=int -DB=float` (which is confusing) but not for `-DA=int -DB=void` or `-DB=std::string` (which is expected). 
Your second example shaves off, what, 8 characters? Even without the advent of concepts, this is a consumption of syntactic space for exceedingly little gain in code used only in some kinds of metaprogramming tasks most C++ users will never need to write.
Because target function doesn't have to have exactly same signature. It only has to be *callable* with that signature. Target callable is executed via a helper function, wherein return value gets implicitly converted to bool.
Jesus. How cutting of you. 
 boost::asio::ip::tcp::socket That's what boost style is all about. 
Yes, but no std::filesystem now.
Back quicker next time. &gt;_&gt;
I actually would kind of support this in the following cases: void foo(const std::vector&lt;int&gt; &amp; vec) { vec::const_iterator it = vec.find(4); } instead of decltype(vec)::const_iterator It would be nice if when :: is applied and LHS is a value, it just automatically applies decltype. I know I can use auto in this example easily -- I'm trying to think of a more compelling example...
Yeah, but just as the asio author didn't choose async_inpu_output::internet_protocol::transport ..., I don't see why the filesystem authors could not abbreviate that name too. Titus wrote a nice article about the problem with long namespace names (he was mainly talking about hierarchical namespaces) and I think this is a prime example of the unnecessary verbosity in c++. The one thing I whished c++ would have kept from c are the concise names.
Well, a digital mob can be a lot of fun.
That did the trick, thanks!
works fine for me in chrome. can get it directly from https://download.qt.io/ otherwise
Yes it does, as if the use cases become marginal terse syntax matters less.
Well that's why I said "unless" that happens.
But the + operator is generally assumed to be commutative (as a notational convention in abstract algebra), so you could argue that + is not a suitable choice for the string concatenation operator in C++.
Isn't `std::experimental::filesystem` still supported? Personally I'd just wait a couple more releases until c++17 support on gcc, clang and msvc is complete and then just switch over completely.
You brought up Concepts. The original question was about requires-expressions, which apply to constexpr if and static assertions just as well.
No, constexpr expressions &amp; macros are evaluated at compile-time, so the resulting machine code would be the same as hardcoding those "magic" numbers. 
That’s called reverse engineering, and no it is impossible to recover the C++ source code most of the time due to loss of symbol names and optimization.
https://en.m.wikipedia.org/wiki/Decompiler Tldr: you can get source code that behaves the same as the original source code, but it will look completely different. 
`brew install qt`
Even simple "programs" like "x+x" and "2*x" can't be recovered because they may both compile to the same assembly.
Two different C++ programs can compile to identical .exe files. Thus it is impossible in principle to determine the source, given only the .exe file. Example: return 0; return -0; return 5-5+0; 
No difference. Compilers optimize constants hard and they will sometimes refer to specific address, sometimes just duplicate it and place directly in an instruction.
You can get clues when decompiling a shared library due to existing symbols but for executable it's impossible - it's straight machine code and you can't determine anything except consecutive instructions. That's a sort of halting problem
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7op6xo/does_a_compiler_reserve_memory_for_magic_numbers/dsb9tbq/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7op91k/is_it_theoretically_possible_to_deterministically/dsb9trh/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7onvhg/gui_creation_qt_for_mac_osx/dsb9u30/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Please indent whole code when having it multiline, do not use `
&gt; Remember that we must not make our horrible hacks easier to write, but we should have tools that don't require us to make horrible hack in the first place. That's the best answer to this topic.
List initialization is just one of the five initialization forms. They are all useful.
There are a number of people who feel it was a grave mistake that braces, labelled as uniform initialization, don't work the same way in all cases like this. Using braces is a good idea in general, but it can quickly get hairy with unknown types because the user could pass something with a list constructor and expect the construction to not use it. This is what standard facilities do, e.g., `make_unique`, by using parentheses. There's been a fair amount of discussion on a good solution for being able to choose whether facilities use braces or parentheses because they make a difference in some cases like that. 
In theory, braces initialisation seems better, but because initialiser_lists exist (and because I don't know every type that has an initialiser_list constructor), I still use traditional syntax most of the time. The interaction between initialiser_list and universal initialisation is really ugly and kinda ruins them for me. 
If I know the type, I'll write {}. If the type is generic, I'll only write {} with zero parameters. Otherwise, I might construct an initializer_list I didn't intend to.
That's why I ask
&gt; If you changed it The same thing applies for order of arguments in ctor.
In cases where you want the values the class/struct represenrs to be initialized, you use {}. In cases you want the operational parameters of the class/struct to be set, you use (). 
Let’s flip your first sentence on its head: is there anybody who, in hindsight, *doesn’t* think this was a mistake?
The constructor I would consider part of the API of the struct, the order of declared members less so.
I really think this whole fiasco could have been avoided if `std::initialiser_list` had just been given it's own syntax. I know finding unused symbols in C++ is really hard, but let's pretend for a moment that `{[val1, val2, val3]}` could be made to work. What would be the drawbacks if such a syntax were the only way to construct an `initializer_list`? I think all the ambiguity would disappear, along with most (all?) of the surprises. Or are the scenarios where the current ambiguity is useful?
Isn't this initialization? Point(int x, int y) : x(x), y(y) {}
In a POD, the order of member variables IS also part of the API, for precisely that reason.
https://stackoverflow.com/questions/18222926/why-is-list-initialization-using-curly-braces-better-than-the-alternatives/37228443#37228443
It is. What is the point of your question?
Having that constructor would allow constructing the object as `Point p(a,b);` and have it initialize x and y.
That's a really good explanation. I will stick to this.
What's the problem with the old syntax but having `A a{b}` call the regular constructor with b arg, so if you want to use init. list you'd either use `A a{{b}}` or `A a = {b}`?
`std::vector x = {1,2,3};` resembles `int x[] = {1,2,3};`. `std::vector{1,2,3}` resembles `(int[]){1,2,3}` or `identity_t&lt;int[]&gt;{1,2,3}`. I guess this similarity was believed to be very important when `std::initializer_list` was proposed. If we don't want this syntactic similarity, then we don't need `std::initializer_list` at all.
I guess I'm thinking in a way because I try to avoid POD types as I prefer to more strongly define the semantics that I want.
Advice can be found in the C++ Core Guidelines: https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#es23-prefer-the--initializer-syntax
Sorry, I didn't want to link to that particular answer, rather the whole Q&amp;A. Fixed
I was with you until the last sentence. Surely, the ability to initialise a `vector` from a fixed list of values would still have value even if it didn't look identical to a C array?
Well, the driving idea was to allow initialization of a user defined array type (e.g. std::vector, std::array) in the same manner as arrays and pods, which I think was a good idea. But then someone thought it might be even better if this syntax could also call normal constructors and that's where the mess began (this is probably not the chronological order of events)
Why should A a{b} call a regular constructor at all? I don't think array initialization (or whatever it is called) should have a different syntax for std::vector than for a native array, but that syntax should not be able to call a regular constructor.
Yeah, the problem isn't the syntax chosen for `std:: initializer_list`. It's that the same syntax was chosen for both for `std:: initializer_list` and universal initialisation.
I like using braces over parenthesis when I can for the subtle hint of distinction between calling a function or creating a type. Especially helpful when separating nested arguments. E.g. lock_guard&lt;mutex&gt; guard{mtx_timestamps}; shr_timestamps.emplace_back(timestamp{vw, tp::now()});
I agree with you, I can think of very few hard rules that I have, maybe don't use goto. That's why I said "avoid", If I just wanted a place to put data I would prefer to use tuple rather than my own datatype if I'm not giving it any implicit behaviour.
Yeah, I prefer to add `=` when possible to avoid confusion.
You can safely type pun fixed size pod data with zero copies at runtime by faking the copies at compile time. Create a function that copies the bits of a block of data of type `A` into an array, destroys the `A`, then placement `new`s a `B`, then copies the bits back. Return a pointer/reference to `B`. If you the throw the optimizer at this function *it does nothing*, but in the abstract machine it creates a `B` with the same bytes as the old `A`. It is a inplace bytecast. You are responsible to bytecast back to `A`. 
I would suggest to just support polymorphic memory resource allocators instead of all kinds of allocators. That would be a good start. Search for std::pmr
Just to be clear, this is to be used only with types with a trivial default constructor and destructor, right?
I disagree with that. Tuple doesn't give names to the subobjects, making code using it usually less readable than if you'd written your own POD struct. Structured bindings can help here, but impose upon the client code to make use of them. The Kate Gregory talk on ten C++ Core Guidelines you should know makes a similar point, it is well worth watching. 
Imo, the user of pair an time across the standard library was a very bad design decision. They are helpful in generic code, but if I want.g. want to return two values I try to give them readable names.
So-called "uniform initialization" was probably the biggest mis-step in C++11 -- or specifically, the fact that `T(arg)` and `T{arg}` do different things if `T` has a constructor taking an `initializer_list`. Since it's too late to change this now, I wonder if any experts can tell me: would there be any problems, syntactically, with allowing the `T(arg)` form for constructing non-array aggregates? Then we could say "prefer round parens for object construction, and curlies for array-like construction" and this problem largely goes away. (Yes, we'd forego the protection against narrowing conversions for fundamental types, but (a) compilers warn about this anyway, and (b) generic code *already* invariably uses the `T(arg)` form -- this would just make such code easier to use with aggregates. And yes, there's the Most Vexing Parse to deal with, but again, compilers warn about it these days.) This seems like something Stoustrup could have introduced in the earliest days, shortly after inventing the constructor syntax, but chose not to -- so I presume there must be some problem with it, other than C incompatibility?
std::array works pretty good, no?
The {} construction would work with that constructor too.
Nice, going through the effort of keeping track of performance during optimization is often stated, but not always done.
Initializations in c++ are really complicated and still getting more and more complicated. So called uniform initialization doesn't make it better, since the underlying rules aren't simplified (plus, std::initializer_list single-handed breaks such uniformity). And you have to observe the actual type to understand the initialization. I'd prefer to limit the use of brace initializer to POD types
nice, maybe you can do proposal for c++20?
Which API changes would require a proposal? The exact algorithm is unspecified, and AFAIK libc already uses heuristics to avoid re-sorting already sorted data (or sorting "reverse sorted" data). Switching to another implementation can be done without modifying the standard.
True, I believe this situation is liked by very few. I tend to be pretty conservative in these sorts of claims, though, as I have certainly not encountered the majority of C++ users, but I have encountered enough discussion on the topic to claim what I did.
Similarly, I write `()` until the compiler barfs about function pointer blah blah which indicates most vexing parse, then in go `{}` until it compiles. I entirely admit I am old fashioned and still write `const type &amp;`, not `type const&amp;` or anything like that.
I have a library that does addition between integers, but it does it *perfectly*.
&gt; all automated tests are just code, and as all code, they need to be correct and cover all cases a thousand times **this**
Couldn't we speed this up by running it on a GPU and spawning one thread per universe? Parallel universes.
Would such a "lambda struct" be allowed to have template member functions? e.g. auto my_struct = [=] struct { template &lt;typename T&gt; auto add(T y) { return x + y; } // or even auto mult(auto y) { return x * y; } }; This is currently forbidden for local structs declared within functions.
Yes, some people on the mailing list mentioned this. I think that this should be a prerequisite ; even better, being able to use the abbreviated form of lambdas: auto my_struct = [=] struct { auto add(auto y) { return x + y; } }; 
There are other differences: struct Point { Point() = delete; Point(float x, float y) = delete; Point(double x, double y) = delete; float x; float y; }; Point p(1.3, 3.4); // fails Point p2{1.3, 3.4}; // ok 
Most likely, even if it eventually terminates (I'm not sure how long you've run it for) it seems like it's a pathological case somewhere. Have you reported it on [Developer Community](https://developercommunity.visualstudio.com/spaces/62/index.html)? They're pretty good at responses, although sometimes it can take some time.
I've run into that issue before with an intellisense bug I just couldn't figure out. If you're willing, and the project is simple enough, you can zip it up and send it over to them as part of the submission. Any files you submit via Developer Community don't get published (if such a thing is worrisome to you). Otherwise, I've also submitted git repos branched where there's an issue. Good luck!
See if removing one unrelated file at a time affects it. Then remove parts of files. I would imagine you can get the overall project fairly small by starting with the full thing and removing things bit by bit (or in a more binary search fashion).
Another thing to look out for when using {} for value initialization is the difference between value and empty aggregate initialization. Specifically, {} will always perform value initialization (even in the presence of initializer_list constructors) except when the type is an aggregate, in which case it will perform empty aggregate initialization. This means that if the type is not an aggregate and has a default ctor, the whole object will be recursively zero initialized, including member fields which have user-provided ctors. If the type is an aggregate, the fields are value initialized one by one, which means a member field with a user-provided ctor will not be zero initialized. For example: struct UserCtor { UserCtor() {} int x; }; struct TestAggregate { UserCtor val; }; class TestClass { public: TestClass() = default; UserCtor get_val() const { return val; } private: UserCtor val; }; TestClass t1{}; // t1.get_val().x is 0 TestAggregate t2{}; // t2.val.x is uninitialized 
I'm less sure. In real code, how often do you actually initialize a `vector` from hard-coded values? Anecdotally, I'm pretty sure the only code we have that initializes containers with `initializer_list` is the code that tests that `initializer_list` initialization works. :p
I've become increasingly convinced over the last few years that any language that doesn't have at least some support for named function parameters should be considered broken. C++ is easily my favorite/preferred language, so I hope people can find a way to get it to catch up in this regard without introducing another questionable design wart àla 'uniform' initialization. 
Are you using incremental build? Not that it is not a bug, but sometimes for me in bugs unrelated to this code compiled fine when I disabled incremental build.
Nope i wasn't using incremental build
http://www.learncpp.com
This is also the advice that I give. The curly braces represent data aggregation, and parentheses represent other sorts of function calling. What's the problem with that?
Hmm, I prefer to write `TestAggregate t2;`
&gt; I would consider `A a{b};` behaving differently than `A a = {b};` to be fairly surprising. And yet that's already exactly the case in C++17 since the incorporation of [N3922](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3922.html)... ;-]
Well he did forget to specify that "a quantum sorting algorithm" he's talking about is "quantum bogosort"... 
Not a fan. Too few use cases that matter for such relatively larget change to core language. Yes variant is ugly as hell, but if we can not get language variant(please just do not name it lvariant) I would still not be huge fan of this since it is not enough for new feature to be useful. It needs to be so useful that the cost of learning it by you and every developer that will maintain your code is worth it. 
There's nothing wrong with `const type &amp;`.
Great idea! I went ahead and ran the benchmark and added it to the repo. :)
Compile-time literals do not 'narrow', they either fit or don't fit.
Consider using C-Reduce to extract the buggy part: https://embed.cs.utah.edu/creduce/
Watch out for this kind of errors as they can spend a lot of your time discovering them. There are programs that might help with it, such as checkmarx checkmarx or others but it's recommended to do it on your own. Good luck! Ben.
1) It's not my job to decide what sorting algorithm other people use. It ended up being a fairly big win for scalar types so I kept it in; though you're not wrong. 2) This seems like something I would consult a given project's style guide for. I think it's more readable, you may disagree, and that's fine. 3) Tests run in about 10 seconds on my machine, if it were a major problem I would've done something more clever. But yes is_permutation is the bottleneck there for sure. 4) The data is already sorted with respect to `STATE`. This case is very much tailored to TimSort, but now that I think of it, libc++'s stable_sort should be able to handle that equally well. I must have messed something up and ran the libstdc++ benchmark when I meant to run libc++. I'll look into that shortly. 5) You can only memcpy pointers. can_forward_memcpy tells me that the iterator is contiguous and has a trivially_copyable value_type. can_reverse_memcpy tells me that an iterator is a reverse_iterator&lt;&gt; to an iterator which satisfies can_forward_memcpy. I use these when copying to and from merge buffer memory, as well as in the move_or_memcpy routine. Benchmarks show that it wins, so it stays. If I'm misusing these anywhere I'd love to hear where so I can fix it. :) 6) No. 7) [libc++ has no problem using gotos](https://github.com/llvm-mirror/libcxx/blob/master/include/algorithm). We can discuss the snot out of whether goto should ever be used but I'm opting to keep my two uses of it in the merge routine. 8) That's certainly fair. This is essentially me reaching out for peer review and I appreciate you taking the time to give me your criticisms! 
&gt; This means that if the type is not an aggregate and has a default ctor, the whole object will be recursively zero initialized, including member fields which have user-provided ctors. To be clear, this is only true if it has a default ctor that isn't user-provided. (`TestClass` is correct as shown, I just find that detail noteworthy.)
Mostly-universal initialization syntax.
&gt; would there be any problems, syntactically, with allowing the T(arg) form for constructing non-array aggregates? The only thing I can think of is going back to the most vexing parse.
Thanks, edited my post since thats an important point.
Yes. Only one (or none) of the two can be true for a given iterator type. If I have an arbitrary iterator type in some function: template &lt;class It&gt; void some_function_that_memcpy_can_speed_up(It begin, It end) { ... } How that function decides to use `std::memcpy` will depend on whether it is a `std::reverse_iterator&lt;some_some_contiguous_iterator&gt;` or just `some_contiguous_iterator`. For example, when I copy to the merge buffer, if the iterator is contiguous, I can just do something like: auto len = end - begin; std::memcpy(&amp;(*buffer), &amp;(*begin), len * sizeof(value_type)); // do stuff with `buffer` But if it's reverse-contiguous, I can do something like: auto len = end - begin; std::memcpy(&amp;(*buffer), &amp;(end[-1]), len * sizeof(value_type)); auto reversed_buffer = std::make_reverse_iterator(buffer + len); // do stuff with reversed_buffer But in order to take advantage of that, I need the context of whether it's a reverse-contiguous iterator in the first place. The nice thing is, for the merge routine, this works out so that when I memcpy to the temporary buffer, I can also memcpy back from the temporary buffer in the merge because the temporary buffer AND the being-merged-into range are either both contiguous or both reverse-contiguous. I hope that explains my reasoning well, and in much the same way, I hope I'm not misunderstanding the meaning of your question either.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7osfhd/best_online_tutorial_for_c/dsc4jgp/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Use the "Send Feedback -&gt; Report a Problem" and reproduce the hang - they have an advanced tool that will capture the state of Visual Studio IDE and all tools it launches, compress and send it to them for analysis - there might be enough information for the developer team to investigate. Crash dumps for IDE, compiler, linker and other tools are automatically included. I'm not sure, but maybe they also collect hang dumps. Anyway, ETW traces may give the relevant information as well.
Never read these. Thanks
 std::variant&lt;bool, int, float&gt; v = 5; switch(v) { case(bool value) { std::cout &lt;&lt; "bool " &lt;&lt; value; } case(int value) { std::cout &lt;&lt; "int " &lt;&lt; value; } case(float value) { std::cout &lt;&lt; "float " &lt;&lt; value; } } ?
https://www.reddit.com/r/cpp/comments/7mtgno/some_love_for_switch/drwjpxa/
This would certainly be useful to reduce the amount of hand-written local variable captures for variant visitors. Local templates would be great too. But... modules and static reflection are higher on my list.
&gt; In Clang's case where it calls the function that does the RMing it does so to avoid UB. Compilers don't avoid undefined behavior. When something is UB, the compiler simply doesn't consider it as a possibility. Not really avoiding, just not considering.
Well I don't think so, but then I still consider references to be non-nullable C pointers in my head, so you put a space between the type and the "it's pointed to". But many eminent committee members and such shake their head at my code and tell me off. And tools like clang-format default to `type&amp;`, and need to be told to do `type &amp;` and so on. I definitely think I'm in a minority!
Fancy stuff. Something to look forward to within the next few decades. I'm sure new keywords would be subject to bike shedding anyway. Maybe `switch union { ... };`?
idk... I would just like variant but we can not get that... Other than that... I dislike _ in keywords... inspect_s, inspect_e But language support for variants could be cool. I can not claim it is cool since I never used any language where it is used a lot so I can not speak from production experience...
&gt; AFAIK libc already uses heuristics to avoid re-sorting already sorted data (or sorting "reverse sorted" data) That's not the case on my machine (`glibc-2.26`, `libstdc++-7.2.1`, `g++-7.2.1`, with `-O2`). Sorting `1, 2, 3, ..., 10^7`: * `std::sort`: 342 ms * `std::stable_sort`: 587 ms * `std::qsort`: 549 ms * `tim::timsort`: 76 ms Sorting `10^7, ..., 3, 2, 1`: * `std::sort`: 272 ms * `std::stable_sort`: 490 ms * `std::qsort`: 506 ms * `tim::timsort`: 68 ms
It is a bug but since there are a lot of ways to trigger internal compiler errors or even make it generate wrong code without warning they probably don't care too much about this one.
From the paper: &gt; `lvariant` is used instead of `enum union` based on feedback in Kona.
I would give it a try and Benchmark this against libc++. And then post to the mailing list if you have positive results.
`.X` and `.Y`
The one reason I prefer `T const&amp;` over `const T &amp;` is that if I change my mind with respect to a function signature (either I change it from `T t` to `T const&amp; t` or `T const&amp; t` to `T t`), it's easier to make many changes all at once. (I usually can't just do find→replace all because they're not usually all the same type)
I was trying to choose different phrasing than all the items OPs linked to. Seems like a minor quibble, because neither of our phrasings is in the standard.
I believe it's a breaking change. #include &lt;vector&gt; #include &lt;algorithm&gt; namespace vec { struct const_iterator { const_iterator(...){} }; } void foo(const std::vector&lt;int&gt;&amp; vec) { vec::const_iterator it = std::find(vec.cbegin(), vec.cend(), 4); } The above currently compiles fine.
I mean, it's possible to provide this functionality without using `std::initializer_list`, at the cost of a different syntax. Like, it's possible to allow `vector x = list_of(1,2);` without using any magic type, and `boost::list_of(1)(2)` has been there for a long time. Plus, thanks to [CWG 1591](http://wg21.link/cwg1591), it's already possible to allow `vector x = {1,2};` or `vector({1,2})`, given a properly defined `vector`.
 &gt;2) This seems like something I would consult a given project's style guide for. I think it's more readable, you may disagree, and that's fine. FWIW I'm a big fan of the alternative operators. It is a minor issue having to add extra flags or includes for MSVC to use them though. 
Why do you assume that if a type has has an initializer_list constructor that's not exactly what the user expects to be called? 
Regarding the last point, in a realtime environment such as a videogame, a frame's "delta time" (implied by the function and param name) would never exceed a fraction of a second. As such, it would never lose significant precision. You're correct, of course, that it's something to be aware of for any time values that can accumulate, such as in a timer.
Avoiding undefined behavior is a lot different from not considering invalid paths in the program.
Good point.
Yes, it's a bug. I've experienced rare situations where something (invisible characters?) would make it report a spurious syntax error. I fixed the problem by deleting the line and retyping it exactly as it was. It was a truly WTF moment. 
Essentially, you can find all of that for c++ too, but there rarely are any de-facto standard libraries for a particular task and the standard library itself comes blank for anything except the absolute basics. So you'll probably spend a lot more time searching and putting everything together. That hasn't significantly changed since the old times.
Installing and importing libraries is still a pain in the a**. It's a little better with CMake, but using CMake in itself is quite painful. A good Unix workspace makes this process much easier for me, since all libraries are in standard location. For arrays, basic data structure and algorithms, use the STL. You have maps, which behave a bit like a dictionary, you have `std::array` for fixed arrays, you have `std::vector` for dynamic arrays, and `std::valarray` that ease arithmetics on a list. STL also provides many algorithms. There's [a page full of them](http://en.cppreference.com/w/cpp/algorithm). For matrices, find a good linear algebra library. I don't know them very well, but there are many of them for different purposes. For example, glm is specialized for linear algebra in OpenGL apps. You'll have to search for one that suits you since I didn't tried any other. For the two other points, there is no de-facto library that I know to do that. Again, I'm pretty sure there are many good library well suited for your needs. Check [cppreference library list](http://en.cppreference.com/w/cpp/links/libs) and [awesome c++](http://fffaraz.github.io/awesome-cpp/) Finally, please, **please**, learn to use `std::unique_ptr`, lambda expressions, RAII and move semantics. Also, you must think with *ownership* in mind with C++ objects. Most of the time, there is one owner for an object and multiple observers. When the lifetime of the owner ends, all observer are invalidated. For example, you have one `std::unique_ptr`, and many raw pointer for a dynamically allocated object. The `std::unique_ptr` is the owner, and all the raw pointers are only observing. When the raw pointer dies, so does the pointed object. Any raw pointers are pointing to an invalidated object. So you should ensure that the lifetime of the observers match the lifetime of the owner. This will save you so much trouble in C++. It took me years to learn how to properly manage lifetimes, but it's totally worth it.
I tried vcpkg with CMake, but I think my setup was faulty because CMake couldn't find exported the `xxx-config.cmake` provided by those libraries. I didn't tried Conan though, because we have enough of one scripting language (CMake), we didn't want to introduce Python on top of that. I might try it for fun and small projects though.
Damn, disappointing to hear that libraries are just as annoying as ever. I've heard of a library called boost, is that becoming the modern c++ catch-all package for numerical work? Do you also have in mind any intros to C++ that go into installing and using modern libraries and coding conventions/paradigms? For example, I've never heard of unique pointers before, but it seems like a life saver. 
I see... are there at least resources for managing libraries, dependencies, etc.? That will be a huge annoyance and difficult to document otherwise I assume. 
I think you should mention Howard's date time library, because as soon as you want to do more than specifying a time-out or measuring small time intervals, std::chrono doesn't help you and you have to revert back to the c library functions, that don't interact well with std::chrono.
If you are going to use for example OpenCV then it will be easiest to use the same libraries that they do.
For matrices/scientific routines you can try [Eigen](http://eigen.tuxfamily.org/index.php?title=Main_Page), it's a header-only library with a lot of linear algebra in it.
I really recommend using () instead of {} in most of cases. You can get various subtle troubles when using braces everywhere. I recommend using it only when it make sense.
well, I'd rather not think of this as a new feature, but as trying to make the language more homogen and less special-case-y. Whis is there that only structs with an `operator()` can be created as values anonymously ? Wouldn't the language be simpler if we said instead, "you can create anonymous stuff by putting a capture-expression in front of it and giving it no name", no matter what the "stuff" is.
I actually like this approach - it covers most situations and is easier to write. Using transparent lambda comparators is a bit more generic and covers more cases, but given that transparent comparator structs need to be symmetric and I need to write 2+ lambas for the initialization, I don't think I would ever use transparent lambda comparators. If you could you support a generic getter lambda instead of only supporting class member functions, I think your approach would be superior to the transparent lambda comparators.
If linear scaling in cores is so costly how the hell are we supposed to afford n! universes?? Clearly quantum computing will *never* happen. ^^^/s
you can try Xtensor as an alternative to numpy. https://github.com/QuantStack/xtensor or you can try Root from CERN as a full all in library, algorithms, matrices, plotting ...
C++ can be used to create high performance code. Nothing is high performance if you don't make it so, provided that the language allows it. 
I'm so concerned about these that I try to stick all relevant operators always to the appropriate thing template&lt;typename... Args&gt; // exactly this spacing, not "typename ...Args" T* func(Args&amp;&amp;... args) // as above z = *y_ptr * *x_ptr; std::forward&lt;Args&gt;(args)... // no space return std::is_same_v&lt;T, Ts&gt; &amp;&amp; ... Personally I prefer `const T&amp;` over `T const&amp;` because it feels more natural to read. And "const reference to T" is the same as "reference to const T" anyway 
There are packet manager for c++. On Linux systems, the system packet manager often provides all required libraries. On Windows you can use vcpkg and Conan is even cross-platform and seems to be the most popular packet manager for c++ nower days. Aside from the platform question those manager also follow different philosophies, so as I said, you have to do some searching and determine what works best for you.
My subjective impression is that boost was more popular in c++98 times than today. Generally speaking it is a large (by c++ standards) collection of libraries that generally are of high quality and follow similar design guidelines as the standard library and in fact, a lot of things that where added to the standard library since 98 come from boost. Unfortunately they don't remove their own versions in favor of the standardized ones.
&gt; 5) I do not understand the point of can_forward_memcpy_v and can_reverse_memcpy_v. Is there an iterator that can memcopy but it's reverse twin iterator can not? I know you can make one if you want, I guess, but is it realistic? Yes, `T*`. 
Thank, you I thought that simply doing reversing the order of the iterators in copy(r_it_end, r_it_begin, dest) would "just work" and you could memcopy them. BTW there is [reverse_copy](http://en.cppreference.com/w/cpp/algorithm/reverse_copy), I assume it is better to use it than copy with reverse iterators... Do you have opinion on that?
&gt; a generic getter lambda I think there is that stupid language limitation of lambdas not appearing in non evaluated context( you would need to make a lambda first and then std::multiset&lt;Person, decltype(lambda)&gt;... https://stackoverflow.com/questions/14896032/c11-stdset-lambda-comparison-function Could be wrong, like I said I am not a library developer, barely hacked this together. :)
This is exactly the issue I remember from messing around with `std::chrono` when C++11 was first becoming a thing. Falling back to the C-library print functions for dates/times is really sad, in my opinion. Why can't I use `std::chrono` with `std::cout` and `&lt;&lt;`? 
Also `O(1)` is not feasible, because to check whether the range is sorted or no we need `n - 1` comparisons, so `O(n)` is the best.
&gt; Unfortunately they don't remove their own versions in favor of the standardized ones. The boost versions generally provide more features than the standard versions, so it can be an advantage for many projects to just stick to the boost versions. Where things get tricky is that boost won't compile for some proprietary platforms so one needs to use standard versions, which can get messy. 
&gt; hat's not the case on my machine (glibc-2.26, libstdc++-7.2.1, g++-7.2.1, with -O2) He said `libc++`, and you are using `libstdc++`, so that would explain it.
sorry for offtopic, but what setting or add on/in are you using for the indented arrows layout? 
That's what `+=` is for
Huh. I wasn't aware of that one. It only seems to apply when intialising `auto` variable, right? If a type is specified for `A`, then `A a{b};` and `A a = {b};` should still behave identically?
I ran a few benchmarks against the timsort C++ implementation by gfx: of course it wins for scalar but I won't share the results here considering that stably sorting scalar types is fairly useless. On the other hand, it wins against the gfx implementation even when we drop the scalar optimizations (I just wrapped an integer into a dumb struct for the benchmark). In the following benchmark, `tim_sort` is the gfx implementation while `tim_sort2` is yours: https://i.imgur.com/lZOlhD3.png I also benchmarked it against the block sort C++ implementation known as WikiSort, in a case where block sort only allocates a stack buffer of 512 elements and doesn't allocate heap memory at all. Yours still win even though the conditions are not quite the same due to the lack of heap allocation in block sort (there is only a slight difference for shuffled patterns though): https://i.imgur.com/YzfILIu.png Eh, if I go through the trouble of adapting the implementation so that it passes the testsuite, I might replace the gfx implementation in my library by yours :p
Indeed. I've edited the comment and added numbers with `libc++`.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/7oygr5/help_why_is_the_move_assignment_operator_not/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I pretty frequently deal with (often `static`, usually `const`) containers of metadata-ish structs representing things like rule sets, file formats, etc. These are typically filled once and never touched. I was pretty excited about `std::initializer_list` when it first came out because it let me create these containers in a very declarative way, although the novelty quickly wore off once I learned of all the limitations of and complications caused by `std::initializer_list`.
Sorry, that was badly phrased. I don't necessarily want boost to remove those classes and functions, but I'd very much appreciate, if the internal dependencies between the boost libraries would be reduced as much as possible. Everytime I want to use just some tiny bit of boost, I get the impression I have to drag in half of boost due to those dependencies (with all the compile-time increase that includes). Of course that's an exaggeration, but you get my meaning. In all fairness: Boost is often used where newer toolchains are not available and hence not being dependent on "newer" language/library features is an advantage. Still, I think boost could really use a rejuvenation.
What I meant is that you could also do something like this - take a "getter" lambda as parameter and build the transparent comparator struct from the getter lambda. getter_comparator([](const Person&amp; person){return person.getName();})
Great work. Most of us wouldn't even consider trying to outperform the built-in sorts, and yet you went for it and succeeded.
&gt; that it's something to be aware of for any time values that can accumulate, *such as in a timer*. Yep, agreed.
You can do it: http://coliru.stacked-crooked.com/a/9088243c0940240e Here I am only using lambda, but you can make a function that takes a lambda and returns the transparent comparator... Problem is: IDK how to make that ugly constructor call less ugly... For me it is clearer to use type of comparator if I can(then it goes inside container &lt;&gt; as template parameter, than to use instance of comparator (then it goes inside () as constructor parameter ). 
details, anyone?
what ever happened to the fmt library proposal? 
IIRC there were some major changes to libc++ sort in the 5.x version series, but given that we are at libc++-6 right now, you might want to check that out. I don't think you'll see a new trend though. Also, IIRC timsort implementations had a bug that resulted in quadratic performance in some cases, so it might be worth it to check how these implementations perform depending on the input size. For example, libc++ uses different algorithms depending on the input.
I know this can barely be called pseudo code (and doesn't compile), but I hope you get the idea what I really meant (the lambda or whatever function ptr you pass probably has be made a member of the struct): template&lt;typename GetterLambdaT&gt; auto createTransparentComparatorStruct(GetterLambdaT lambda) { struct GetterComparator { using is_transparent = int; using typename Class = RETURN_TYPE_OF_LAMDA; bool operator()(const Class&amp; a, const Class&amp; b) const { return lambda(a) &lt; lambda(b); } template&lt;typename T&gt; bool operator()(const Class&amp; a, const T&amp; b) const { return lambda(a) &lt; b; } template&lt;typename T&gt; bool operator()(const T&amp; a, const Class&amp; b) const { return a &lt; lambda(b); } }; return GetterComparator{}; }
`std::stable_sort` is required to run in O(n log²n) when few or no memory is available. I'm unsure whether timsort is designed in such a way it can run with O(1) extra memory, so you would probably need a restriction that O(n) extra memory shall be available.
Another advantage of the Pimpl idiom is that you can use it to "hide" private members
I understand you code, but the point is how would you use it? It is runtime code, so you would need to call it as constructor parameter... Now the problem is that IDK how to call the constructor nicely without a lot of boilerplate, see the link I posted in the comment you replied to. BTW: how do you get the code to be nicely formatted like that? I hate reddit formatting :/ 
I think that would upset TJ "Henry" Yoshi...
Nah, you just proceed assuming you're in the universe where the range is sorted. There's no reason to check.
Wow, I didn't realize that name resolution can work that way... that's pretty terrible :( IMO either the value should shadow the namespace, or it should fail to, but both should not happen in a single scope. This code looks extremely obfuscated to me :(
As much as I dislike how Pimpl looks and handles, I'm starting to realize the (imo) unfortunate utility of it. I wrote a low-level Vulkan primitives library and I've had a few people mention a desire to use it in their projects, as their interface to that API. Seeing as how it's a low-level interface, and other people are using it, I'm beginning to think I should do this so I can avoid API breaking changes or (once I get it compiling into a dynamic library) ABI breaking changes. Either of those happening in the lower levels of a rendering project would be less than ideal, and I don't want to force users to recompile as I improve things like my allocator subsystem or accommodate Vulkan API updates/features/improvements. So despite my initial feelings of loathing towards it, I'm probably going to end up using it lol if nothing else, `std::unique_ptr` at least makes some parts of it considerably less painful, thankfully edit: this article is really nice though, since handling ownership carefully and rigidly is vital in Vulkan. that and it put some potential issues on my radar that I had no knowledge of
The answer to your question (sadly) is: no. There are probably libraries that do some of the things you want but you’ll have a terrible time installing them if your level of expectation is “pip install x”
&gt; I've heard of a library called boost, is that becoming the modern c++ catch-all package for numerical work? &gt; It's not specific to numerical stuff at all. It includes things like a library for making Python bindings, ASIO mainly for network communication, It had stuff like smart pointers before they were in the C++ language, stuff for writing parsers, atomics, string formatting, dynamically loading libraries. Some of that stuff may be useful in programs that do lots of numerical stuff, but it's not a direct analogue to something like NumPy. You can check out specific libraries at http://www.boost.org/doc/libs/
What is the name of your library? Is it open-source?
No, I don't.
Yes: Based on Filesystem TS implementation, with the changes applied by: - P0219R1 Relative Paths for Filesystem - P0317R1 Directory Entry Caching for Filesystem - P0492R2 Resolution of C++17 National Body Comments
They don't have to be "no longer used". If they are used 90% less, then reasons to make it more terse are 90% lower, and benefits are 90% less, while costs ... remain the same. The less often you want to use it, the less point there is in making it terse. 
I said "pod types". Plain old data. Basically, what a C struct is but in C++. The point is that you know the dtor doesn't actually do anything, the ctor leaves the memory in an undefined state, and the copy of data out then back ensures that the bits are all the same as when the function started. Except now you have a `T*` instead of a `U*` pointing to it in a standard compliant way. template&lt;class U, std::size_t N=1, class T&gt; U* laundry_pod( T* in ) { static_assert(sizeof(U)==sizeof(T)); static_assert(std::is_pod&lt;U&gt;{} &amp;&amp; std::is_pod&lt;T&gt;{}); std::array&lt; char, sizeof(T)*N &gt; bytes; memcpy( bytes.data(), in, sizeof(T)*N ); in-&gt;~T(); U* r = ::new( (void*)bytes.data() ) U; memcpy( r, bytes.data(), sizeof(U)*N ); } template&lt;class U, std::size_t N, class T&gt; U* laundry_pod( T(&amp;in)[N] ) { return laundry_pod&lt;U, N&gt;( std::addressof(n[0]) ); } `is_pod` needs replacing in C++20, I think by trivial and standard layout? Uncertain. 
The common advice is that braces are universal, but there's no wisdom behind it. Safeguarding against implicit conversions in constructor calls is inconsistent with the behavior of function calls, except when they implement aggregation. As you describe, it's best to use other techniques for handling function parameter conversions.
Personally I think that `std::chrono` is a badly missed opportunity in that it caters to overly limited use-cases: The better approach would have been to add the entire SI-system somewhat like [this](https://github.com/Florianjw/unit_demo) and have the chrono-functions act on that. imagine code like this: const auto dist = 17m; const auto avg_speed = 10m / 1s; # speciallize the literal 1 if necessary for performance const auto expected_time = dist/avg_speed; vehicle.start_driving(); // parallel sleep(expected_time - 100ms); vehicle.await_arrival(); // assume a busy-loop While you might say that `await_arrival` shouldn't be containing a busy-loop, let's assume for the sake of the argument that it does. In this case we have a great example for how the chrono-times could have provided a common class(-template) for all use-cases but instead limited itself to a rather small niche.
I'm not sure I understand why you'd use Pimpl instead of a pure virtual base class. 
&gt; whereas the boost version depends on binary boost libraries. Sort of. It depends on boost.thread and boost.system (for boost.error_code) by default. But this is configurable. By passing -DBOOST_ASIO_HAS_STD_THREAD -DBOOST_ERROR_CODE_HEADER_ONLY on the command line, everything is header only again and will use std::thread instead of boost.thread.
You can have copy ctor for a pimpl class, but not for the pure virtual base.
It's called "VulpesRender", which is a name I dislike since it's not really a renderer, per-se. https://github.com/fuchstraumer/VulpesRender It's totally open source and has an MIT license, but I have no plans to really like enforce the license or anything. Just don't want it to not-very-kindly commercialized ;p plus, without other open source libraries and projects, from Sascha's Vulkan examples to GPU-Open's memory allocator, i never would've made this thing 
Yeah, interfaces are easier like this but I'll admit my setup isn't really made for usage in a multi-API environment. it's hard to set that up without also setting up or complying to some kind of layer API used to interface with the graphics API layer/interface (what a mess of words that is/was lol). It could be done though, it's not like what I have going on is that complex and DX12 and Vulkan are at least cousins in terms of employment at this point - or, so I think they are at least. Haven't used DX12 myself, yet. When it comes to draw calls, my library shouldn't be an issue. I didn't create an abstraction for command buffers, which is what you'd record draw commands into. They are allocated and managed from a command pool however, and that does have an abstraction since that helps managed the lifetime and resetting (preparing for re-use, done at end of frame) of command buffers. You did remind me that I should probably make my command pool class more thread-safe, though. Also need to update the allocator for more rigid safety on that front too. I tried to avoid wrapping classes or vulkan objects that didn't benefit from it, or would've been hampered by it. The most sophisticated stuff I have is just the memory allocator. If you're interested, the repo can be found [here](https://github.com/fuchstraumer/VulpesRender). Input and tips for improvement are always welcome!
Is much better than a couple of years ago: 1. use hunter or conan with cmake, there are a lot of hello world cmake scripts on github and cmake is very easy to learn. 2. yeah, STL or Eigen (header only library) 3. also Eigen 4. jupyter notebook can also use python as far as I know. Just try to find a modern tutorial, old tutorials teach more C than C++ which are more and more two different things...
&gt; but I have no plans to really like enforce the license or anything. Just don't want it to not-very-kindly commercialized ;p What do you mean with that? MIT is pretty much as liberal as it gets and it allows pretty much anything with the code, except for removing the license and your copyright notice.
It crossed people's minds at the time (including mine). However `&lt;chrono&gt;` was *extremely* controversial going in. And the other side didn't want *more* functionality. They wanted what became C's `timespec` (a `{seconds, nanoseconds}` POD). And that is why the [`&lt;chrono&gt;` proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2661.htm#Overview) includes this line: &gt; This paper does not propose a general purpose physical quantities library.
I wish this pattern was unnecessary. It's so ugly looking.
proposal for function_ref is http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0792r0.html Wt latex template u got b*c?
Timsort had a bug where it didn't sort correctly. http://www.envisage-project.eu/proving-android-java-and-python-sorting-algorithm-is-broken-and-how-to-fix-it/
I'm not entirely sure I understand the claim to ABI compatibility - I can see how different compilers would probably give the same layout since it's just a smart pointer and a bunch of methods, but wouldn't those methods be subject to name mangling and be a link issue? You also need to be able to specify the calling convention and guarantee that it won't get optimised unexpectedly, right? Or does the author just mean ABI compatibility for the same compiler on the same settings?
Well, the idea is to use those techniques when they are necessary to solve problems, not because we like them or they are 'pretty'. 
I'm flattered somebody thinks it's maybe worth a damn to even use it! If you decide to go through with it, I'd be happy to help however I can! I'm now (today in fact) starting my next semester at school, so my availability will be erratic at best. I'm curious, are the test failures just because of the usage of C++17 features, or is the sort properly broken in some way? Also sorry in advance for my inconsistent style... I should check out clang-format...
I haven't actually run it through the testsuite, but I added more features to the sorting algorithms like projection support or proxy iterators support. I had a look at the code, and even though the projections would automatically be hooked in the comparison, proxy iterators support would need to use iter_move and the like everywhere, which isn't in the standard library. I also check things like whether a sorting algorithm works with non-default-constructible types and move-only types as required by the standard. Also I sometimes had problems with the gfx timsort implementation when sorting an std::deque: Valgrind complained about out-of-bound access, etc... If you want I can report what I find :) My library is mostly an aggregation of sorting algorithms though, so I wouldn't consider it a real-life use case, sorry ^^" I believe plenty of people would probably be glad to have a quality timsort implementation at hand though. Maybe a single header implementation as an alternative to the current one would help people to "drop it and use it" in a project :)
Because logically they are an alias. In a happy case the compiler will not need to generate slower pointer code, just inline the function and keep using the same registry. 
Not necessarily for the complete beginners, but videos from cppcons are amazing
&gt; Or does the author just mean ABI compatibility for the same compiler on the same settings? Correct. One of the advantages that pimpl gives you is that it allows you to change the, well, *private implementation* of a class without affecting that class's binary interface (on a given compiler). For example, normally something as simple as adding a new private member variable to a class would mean an ABI break (as it would change the `sizeof` the object), so an application compiled against library version N could not be linked against library version N+1. Pimpl adds a layer of indirection which avoids this problem, at the cost of dynamic allocation.
No need for extra flags, just `#define` them /s
This forces unnecessary virtual function overhead on every call. A better approach is just to downcast, since you know the concrete types anyway. // header file struct MyClass { void DoSth(); void DoConst() const; }; std::unique_ptr&lt;MyClass&gt; get_class(); // cpp-file class MyClassImpl : MyClass { void DoSth() {...}; void DoConst() const {...}; }; MyClass::DoSth() { static_cast&lt;MyClassImpl*&gt;(this)-&gt;DoSth(); }; MyClass::DoConst() { static_cast&lt;MyClassImpl const*&gt;(this)-&gt;DoConst(); }; std::unique_ptr&lt;MyClass&gt; get_class() { return std::make_unique&lt;MyClassImpl&gt;(); } One can even write a macro to do the casting. #define FORWARD_METHOD(n) MyClass::n() { static_cast&lt;MyClassImpl*&gt;(this)-&gt;n(); } FORWARD_METHOD(DoSth); FORWARD_METHOD(DoConst); It's slightly more work than using virtuals because one needs to write the forwarding ones-self. But better than traditional pImpl.
https://www.youtube.com/user/TheChernoProject
I have been trying to find time to play with [Jupyter C++](https://blog.jupyter.org/interactive-workflows-for-c-with-jupyter-fe9b54227d92) which seems to me like it would meet some of your requirements. At a previous job, we used VSC++ with Eigen (can be easily installed using NuGet) to do real time signal processing for [MWD](https://en.wikipedia.org/wiki/Measurement_while_drilling). A resource I would suggest is "A Tour of C++" by Bjarne Stroustrup. 
You're not missing anything. As far as I can tell, the *only* advantage of PIMPL these days is binary compatibility. In almost every other way, it's really at a disadvantage compared to a pure interface paradigm. The "advantages" of "no vtable" and "object can be created on the stack" feel a little disingenuous, because it also has corresponding "disadvantages" that largely negate those points. You're already creating almost much indirection via external calls as a vtable because of the internal pointer, and that internal object has to be dynamically allocated anyhow. And on top of all that, it's a pain to maintain and debug. A pure interface + factory that returns an object wrapped in a smart pointer is much cleaner, as it provides only public functions the client needs to care about. The only implementation detail the user sees is likely a protected destructor. And finally, don't get me started about the nonsense of performance concerns of vtables, which is a tired mantra from *decades* ago (and even then it was spurious in many cases). It's certainly not going to be a measurable factor in the vast majority of high-level interfaces, which is what these patterns are typically used for. 
 Do you have an idea why C++ hasn't developed tools like pip? Is it because C++'s philosophy doesn't mesh with using as few external libraries as needed or something? Or just that no one has put the work needed to get a C++ version of pip yet (bc it's presumably more complicated)?
I don't think there is a way to make this work with shadowing. Removing a `typedef` (namely `std::vector&lt;int&gt;::const_iterator`) would make `struct vec::const_iterator` visible. Thus the code would still compile fine but silently change meaning which is probably the worst kind of breaking change.
* Constructor rather than factory function. * Ability to behave as a value-type (copyable, movable) * No vtable overhead in calls
Is there a common name for this pattern?
How does it compare to linenoise? It is what I am currently using.
Looks like the readme is similar to linenoise README. Is it a fork of some kind?
One would wish that pimpl could be automated by the compiler, and just write `class [[pimpl]] my_class {...}`. Optionally enabled only in debug builds.
What are your requirements? 
Right now I would say that the build system should be able to used on Windows and Linux. And I would have an executable by the end of the day. Which requirements could I have been missed?
Cmake is the defacto standard modern buildsystem. I would recommend it. 
if you want something new, There are quite a few rising stars. saner syntax, integrated package manager, module support - from top of my head: build2, meson, 
This is the pimpl idiom, with the only difference that the pimpl itself is exposed rather than the wrapper. I advise against this, because it forces the user to use arrows rather than dots, thereby leaking implementation details to the outside.
Meson still relies on make so it suffers from all the same issue cmake does.
See metaclass proposal.
Another possible disadvantage of pimpl is that you have two `this` pointers.
Meson does not use Make. It has never used Make. It will never support Make in any way. Any pull request adding Make support will be immediately and unconditionally rejected. - The official stance of the creator and project lead of Meson (i.e. me)
Except it doesn't. http://mesonbuild.com/FAQ.html#why-is-there-not-a-make-backend
use cmake.
But it uses other build system, right ? I must I'm not very familiar with meson but the tutorial mention ninja. Both `qbs` and `build2`actually run the command and I have found that not relying on a 2 stage / 2 tools process is less error prone. Thanks for clarifying and the work you do :)
The README has "Origin" section which gives proper credit. Regards, A.
My work is based on linenoise-ng which is a fork of linenoise. Linenoise-ng added support for Unicode (UTF-8 input). My fork added on top of that a syntax highlighting and hints capability, also some extra line editing features and configurability. Regards, A.
I do not understand what are the advantages of using an empty {} initialization. The basic c-like initialization is clear: 1) Object obj; 2) Object obj = {0}; The first means i don't know/care about the value, and a static analyzer will catch uses of uninitialized members. The second one means initialize to 0, and it will not compile TestAggregate for example (good, no surprises). I understand that the intent of obj{} was to always initialize the object, but that is not a good thing ihmo (and it is not even true, as proved by your example). First of all the static analyzer cannot help anymore, but also reading the code it is not clear if the intent was to call the default constructor or to initialize to 0.
Cmake is great for windows. For linux though, Id recommend pkgconfig and makefiles. You really cant go wrong with them!
LLVM is a giant toolchain. What part do you want to learn?
ugh no, please don't. Especially considering that cmake has a good pkg-config integration (https://cmake.org/cmake/help/v3.10/module/FindPkgConfig.html)
Sounds like a general introduction and overview would be an excellent place to start.
 Stage 3 ends Jan 14th https://gcc.gnu.org/ml/gcc/2018-01/msg00033.html
because in 2018 the job is "run on windows, mac, linux with glibc, linux with musl, steamos, android, iOS, jolla, ubuntu phone, plasma mobile, emscripten, retroarch core, ps3, ps4, xbox 1, homebrew dreamcast emulator".
Hope you're not serious. 
I believe it's called sarcasm.
&gt; I don't remember the last game I bought that didn't at least run on linux / macos / windows. A program being cross-platform isn't the same as it being easily deployed on each platforms. Most games also use engine-specific stuff for deployment, like UE. make is perfectly fine when it does the job. You are correct though that cmake makes it a bit easier to distribute stuff cross-platform, but it will _still_ be a very unpleasant experience on Windows. If make does the job, use it. If you have to, use cmake! Personally, I use makefiles for my projects, and then have VS project files on windows.
He would still need to get the dependencies from somewhere. On Linux the system package manager could solve it, on Windows he would need to use Msys2, vcpkg, get libraries manually or some other method. A universal solution for both systems could be Conan.
Not LaTeX, this was made with Pandoc (Markdown) and some heavily-modified CSS file that whose origin I honestly do not remember...
The llvm website is a great place to start
&gt; Whis is there that only structs with an operator() can be created as values anonymously because they are the most common kind of structs being created. same as i=i+1; has a compact way of writing it(i++) and i+=2 or i=0; do not. So I do not care that much about language symmetry, I think most people learn lambdas without knowing they are stucts(I did and it did not hurt my use of them), so expanding this to structs will require learning new stuff. 
[Oh not this again!](https://www.reddit.com/r/linux/comments/7p0adj/linuxkernel_archive_linus_torvalds_i_want_to_do/dsdqae4/?context=1)
Aren't they also available with `/permissive-`, which is planned to become the future default at some point?
You can use a cross-platform building system, for example [CMake](https://cmake.org/). CMake is capable of generating Makefiles on Linux and Visual Studio projects on Windows from the same CMake project.
[LLVM documentation](https://llvm.org/docs/index.html) is pretty good, there are [LLVM Tutorials](https://llvm.org/docs/tutorial/) particularly designed for new users. There are also videos from [past LLVM meetings](https://llvm.org/devmtg/) covering ongoing efforts and sometimes the basics. In general, one would also read the code to understand the internals. I do not think there are any specific university courses on LLVM offered online, but then again: many things are evolving pretty quickly if one has a good understanding of compilers in general (i.e. read The Dragon Book, done some coursework, etc) I would suggest reading the code, asking questions on the mailing list (llvm-dev or cfe-dev in particular) or hanging out in the IRC.
I can't think of any advantage that makefiles has over CMake except perhaps that some authors are more familiar with them. Other than that? No, use CMake. 
&gt; Disagree, I would also argue that CMakelists.txt arent any better in this regard! Even a small Makefile is much less readable than a small CMakeLists.txt one: CFLAGS=-I. DEPS = hellomake.h OBJ = hellomake.o hellofunc.o %.o: %.c $(DEPS) $(CC) -c -o $@ $&lt; $(CFLAGS) hellomake: $(OBJ) $(CC) -o $@ $^ $(CFLAGS) Compare that symbol bloat to this: cmake_minimum_required(VERSION 3.10) project(example LANGUAGE C) add_executable(hello hellomake.c hellofunc.c) target_include_directories(hello ${CMAKE_CURRENT_SOURCE_DIR}) It's like saying "assembly does the job pretty well, so why bother with C++ which is a giant beast."
Hey /u/zturner_ , I have a few questions, if you don't mind. Your blog post implies that the main functionality of mspdbsrv.exe is merging duplicate type records during compilation to reduce link times. Are you sure about that? I'm skeptical because previously the activation of mspdbsrv.exe was strictly tied to /Z(i|I) (if you wanted PDBs, you also got mspdbsrv.exe no matter). This was changed later, now it's tied to a new flag, [/FS](https://docs.microsoft.com/hu-hu/cpp/build/reference/fs-force-synchronous-pdb-writes), and by default, you won't get mspdbsrv.exe. If the primary function of mspdbsrv.exe would be to save link times, it would be strange of Microsoft to suddenly default to turning mspdbsrv.exe off. Heck, the documentation of /FS even subtly recommends that you should avoid specifying it. So to me, it **seems** like the primary function of mspdbsrv.exe is providing high-level mutual exclusion, while the ability to merge type records during compilation might be just taking advantage of the opportunity. But again, I'm far from sure, that's why I'm asking someone more competent. (Small unrelated note: the documentation also says the following: "By default, when /Zi or /ZI is specified, the compiler locks PDB files to write type information and symbolic debugging information." According to my experiments that's not true, if I start a parallel compilation (*not* with /MP, as that would implicitly turn on /FS), I get C1041 errors sporadically (cannot open program database)) Did you come up with the name "type server", or is this the internal name of mspdbsrv.exe used by Microsoft?
If he are going to choose cmake there is also hunter package manager https://docs.hunter.sh/en/latest/
I'm wondering, why [Windows snapshot builds](http://llvm.org/builds/) is updated so infrequently. It would be nice to have it weekly as [prescribed](https://github.com/llvm-mirror/llvm/blob/master/utils/release/build_llvm_package.bat#L5).
cmake, C++ Implemented build system.
You can use [clangbuilder](https://github.com/fstudio/clangbuilder/) click **Building** to build llvm snapshot.
You could, I suppose, but wow, talk about a fragile, overly-complex design destined for a long, maintenance nightmare. This is one of those "code smells" that instantly raises the hair on the back of my neck, and makes me believe that whatever supposed benefits it provides is nowhere near the price you pay in code complexity and fragility. Just my opinion, of course. But personally, there would have to be an *extremely* compelling reason before I'd permit anything like this - or in fact, even a pimpl interface instead of a simple pure virtual + smart pointer + factory creation method pattern. 
CMake. Don't let people commit any makefiles, .sln files, or any build files to the repository. Ever. Be very strict about this, otherwise it's not gonna work. Since you mentioned you haven't chosen the language yet, this is /r/cpp but unless your team wants to learn about build systems, compiling, and C++ too (which is all awesome skills to learn but it's all time you will not be spending on immediate progress on the actual project), I would suggest you choose Python.
Consider looking into bazel, buck and please. They are all inspired or directly based on google's internal blaze build system. They all work very well if you have full control over your dependencies and don't need a lot of configuration. Personally bazel is my favourite. 
We will probably end up going with Python, but I've been working with C++ a lot recently and I know a few of the others know a bit. I've really been enjoying it. I haven't used CMake though. I'll keep it in mind if we go that route.
Thanks man. CMake seems to be the consensus.
I like this. I don't worry about it breaking old code, as people don't write this. The only argument I have against it is that it would potentially compile but produce incorrect results on old compilers that didn't support the feature... could be a pain for cross-platform projects.
As a person with long experience trying build systems I settled on Meson. The documentation kicks in the ass CMake documentation. It supports also more targets out of the box and the DSL is understandable. I prefer it. Genrators for Visual Studio and CMake, though, were better in CMake last time I checked.
Thanks for the info. Just my mistake I scanned too quickly :)
Doesn't the FindSDL module define imported targets? Using variables like that is the "old" way AFAIK
Is it useful to have? Sure. But I'm worried because it is yet another deviation from the rule, something C++ is often critized for already. And how would it compose? Would `a &lt; b &lt;= c` be ok? How about `a &lt; b &lt; c &lt; d`? How about `a &lt; b &gt; c`? And are we sure such expressions would always be unambiguous? Ultimately I'm wondering if we wouldn't be better off with something like a function `std::ordered (...)` that returns true if the sequence of parameters is ordered according to some predicate. Such a function doesn't introduce any weird new syntax or rules, its implementation is straightforward, and it doesn't introduce a potential incompatibility. 
Do you know how well it works with Android NDK? It seems a much more mature option than using [cdep](https://github.com/google/cdep), unchanged since October 2017.
Also it has become the official GNOME build system.
&gt; 1) It's not my job to decide what sorting algorithm other people use. It ended up being a fairly big win for scalar types so I kept it in; though you're not wrong. /u/Z01dbrg’s point is that it simply makes no sense to ever `stable_sort` `int`s. You can just `std::sort` them: the effect is the same, and `std::stable_sort` can never be more efficient than `std::sort`, but the inverse is likely. That said, I still see the point in special-casing those, since `stable_sort` could be invoked in generic code (though I’m hard-pressed to think of a realistic scenario).
Both Bazel and Buck depend on Java. They don't compare favorably to CMake which doesn't have any of such large dependencies. It may be fine to require Java in your organization but it's pretty much a no go for C++ open source projects.
I used Hunter both for Linux and Windows builds and it worked surprisingly well. What's great about Hunter is that it's just a CMake script with no additional dependencies.
This post is about getting data, not about being a proposal. But, yes, all of those would be okay. Certainly such a function wouldn't be straightforward to implement or specify *at all*. How do you let me write both inclusive and exclusive ranges on both ends?
There's a more idomatic/common way to do this: [The Curiously Recurring Template Pattern](https://www.fluentcpp.com/2017/05/12/curiously-recurring-template-pattern/).
&gt; talk about a fragile, overly-complex design destined for a long, maintenance nightmare. Worst case you get a static assert error when you change the implementation and have to decide if you want to change the ABI version or actually do an allocation for whatever (possibly optional) data you just added. People use inline buffers for small amounts of data with std::string all the time and boost also provides a small_vector class to avoid an allocation.
No, macros are devil.
So, every adult which communicates with others use phrases like "I was wondering why". But a genius has the great attitude of addressing others with a patronizing tone. Why not communicate like serious adults?
But, who do define a ```await``` to use like this? ```await do_work();```
IIRC making those keywords work as contextual keywords was too hard, so they simply made them keywords.
A standards-committee willing to break an untold number of existing codebases to save you the trouble of typing 3 more characters would be a far greater evil.
sadly, no :( : https://cmake.org/cmake/help/v3.10/module/FindSDL.html I guess it wouldn't be too hard of a first contribution to CMake though :p the Find modules depend entirely on volunteer work AFAIK.
He's talking about your tone, which is very condescending.
These tips are awesome!
Yes, TIL to read the include paths in the STL... I was like WTF, how can you not get&lt;0&gt; from tupple for 20 minutes... If I read the include paths in STL it would be obvious it is dragging in some unrelated crap(probably set -&gt; pair -&gt; get). 
Yeah, so the fallback could be to just fall back to `std::sort()` for scalar types, but it feels slightly like it would be... cheating? Idk. Maybe somebody just wants to use one fairly fast sort that should be stable when stability matters and should be as fast as possible in all cases. That's what the CPython guys wanted and thus that's basically Timsort's use case. A good default. &gt; std::stable_sort can never be more efficient than std::sort It *shouldn't* be, but in reality, Timsort ended up beating libc++'s `std::sort` on my machine for exactly this case (ints). Take from that what you will. Edit: Also consider the case where we're sorting pointers, indices, or something similar but the comparator is just using them as keys to fetch and compare something else. While the particular point that u/Z01dbrg is criticizing doesn't actually apply in this case, other special-cased optimizations can still be leveraged. 
All the examples I've seen of ExternalProject use it to download and build a dependency - I wanted to share a dependency on disk between multiple projects (especially since I sometimes want to test changes to the base project in dependent projects without having to make a commit in the base project).
&gt; Also consider the case where we're sorting pointers, indices, or something similar but the comparator is just using them as keys to fetch and compare something else. Good point, but still you can detect if comparator is std::less... Like I said my gut feeling is that nobody cared to optimize this... And also I assume radix sort will beat timsort for integers :) 
If the Windows crew is willing to use Cygwin, you can use the same makefile without dealing with CMake.
Your approach seems overly harsh. I've been maintaining two buildsystems for the same source tree for twenty years - the build-in one for Visual Studio for Windows, and a set of makefiles for UNIX. It's just not so incredibly onerous as some people make it out to be. Changes only happen when new files get added, and adding a file is a matter of adding its name in two places. That's all. 
coroutines are a special way of thinking program flow. It's good to rely on a naming pattern to recall this. I therefore think co_* is a good thing.
You may very well be right about the distinction between /FS and /Zi. It's been so long since I've actually used it that I might have been biased by the "old" meaning. As for the name "type server", it's the "real" name, but it's not strictly the name given to mspdbsrv. It's actually the name given to the intermediate PDB that is written as a result of using /Zi etc. https://github.com/Microsoft/microsoft-pdb/blob/master/include/cvinfo.h#L2005-L2010 is the codeview record that describes it. So say you are building a program named `foo.exe` so you expect there to be a `foo.pdb` at the end. If you use /Zi you'll get a file named vc141.pdb or something like that, and you'll *also* get a `foo.pdb`. `foo.pdb` itself contains only a single type record, which is one of these type server records that says "All the types are actually over there, in `vc141.pdb`". So in this case, the term "type server" refers to the file `vc141.pdb`, and not a process or IPC mechanism. I'm using it interchangeably since they're basically equivalent (i.e. the existence of a type server pdb implies you used /Zi, and using /Zi implies that you get a type server PDB). I don't know if there are other terms used to describe this internally at Microsoft, so all of my terminology is just based on the publicly available information + code drops they've given us on the github repo.
qbs is another of the modern ones with nice syntax.
[Here](https://github.com/simonwhitaker/gibo) is a tool to help with that. Make a good `.gitignore` the initial commit. Enforce out-of-tree builds, ie. build in a separate directory, so that build files have a smaller chance of being accidentally committed. 
we're taking a look, thanks for the report. - Steve , VC Dev Mgr
I don't know about you, but i find it easier to remember that if i want to use any function/class from STL i should include the header in which the function/class is defined and not depend on any transitive dependencies.
&gt; but still you can detect if comparator is std::less In fact I do in the exact case that you were criticizing with point 1, which is why that use case doesn't address your original, particular criticism. Really, I don't disagree with any of your points on this one. I just saw a winning optimization and took it. It's at the expense of simplicity and it's for a silly use case, but it's there and I'm not backing down damnit!
Have both a makefile and a VS project in your repo. On a small project, keeping them in sync is easy and will take way less time than getting everyone to setup CMake and learning it (unless you're using libraries built with CMake, add_library is nifty). Focus on your project rather than the tools you use. It's really easy to get bogged down trying to pick the perfect language, the perfect IDE, the perfect build system, etc. The less new things you're trying to learn, the more actual work you'll get done. Unless everyone in your team already knows modern-ish C++, make sure you have a good reason not to use Java/Python/whatever the default language at your school is. Don't just google "C++ tutorial"; the top results teach outdated style. Beg, borrow, or steal the [C++ Primer](https://www.amazon.com/Primer-5th-Stanley-B-Lippman/dp/0321714113/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1343780237&amp;sr=1-1&amp;keywords=c%2B%2B+primer) instead. Once you start working on more complex projects and run into the limitations of makefiles (like dependency management and packaging), or you want to get involved with an open source project that uses CMake, or even release your own library, then you should absolutely learn CMake. It's incredibly powerful and the de facto standard.
Thanks 👍
Thanks for the clarification on "type servers". As for my question about the main functionality of mspdbsrv.exe, you didn't exactly state it, but I'll assume you're not sure. I wish Microsoft published some blog posts about this topic (or toolchain internals in general) on the MSVC blog...
&gt; With Windows 8 and Windows 7 on older silicon (2015-era PCs with Haswell or older CPU), we expect most users to notice a decrease in system performance. :-(
I'm currently trying to use the Visual Studio 2017 integrated CMake 3.9 and I want to stab myself. Visual Studio is ignoring some compile flags (that I toggled with target_compile_options) so I couldn't get it to build with C++17 enabled. The documentation for CMAKE is also poor, with many deprecated functions not being labelled so until I stumble upon another newer function that says that it should replace the former.
It's possible the poster isn't a native speaker. I try to read these sorts of posts with optimism.
[maiken](https://github.com/dekken/maiken) is a cross platform build tool I wrote - you can have a look at [this](https://github.com/mkn/mkn.kul/tree/master/mkn.yaml) to see how to handle building across platforms with seperate source files/arguments The same command should be feasible regardless of OS/compiler 
Also there was a need to distinguish non-coroutine functions F func() { return {}; } and coroutine functions (which are functions with some generated body) F co_func() { co_return {}; }
You could maybe contact the Debian Clang folks to get the check run against all of the software in the Debian archive, since they've done the legwork to get just about everything to try building with Clang instead of GCC
You have discovered backwards compatibility. Let me introduce you to the [most vexing parse](https://en.wikipedia.org/wiki/Most_vexing_parse).
Great job, although it would be cool if it had a C++ API in addtion to C-style one — RAII for the library itself and for library-allocated strings, closures as callbacks (so that no userdata is needed) etc. But great little library nevertheless, thanks for sharing!
Lol, I thought I was on r/programming! But I'd suggest CMake and CLion then. Just install MingW on Windows. I use it too for my cross platform C++ code and it works really good 
`a &lt; b &lt;= c` and `a &lt; b &lt; c &lt; d` would be okay. `a &lt; b &gt; c` would not be okay. For details and rationale, see my R0 paper here, section 3.3: https://wg21.link/p0515r0 (note you do need to look at the R0 paper because this did not initially get consensus and was removed in R1 to be brought back in another paper, which Barry is now doing) That's an interesting note about `std::ordered`... the P0515 proposal did add two-way `std::strong_ordering` _et al._ which now could potentially be made variadic as part of this proposal. @sphere991 Barry, perhaps you can consider that for your paper as an optional suggestion? (It's always good to make nonessential things separable, so that if they turn out to be controversial the core proposal can make progress. Which is why we got `&lt;=&gt;` comparisons first, and now are looking at proposing chaining comparisons...)
How do you avoid the `#include` leakage when you just want a stack variable?
await could probably be forced through, but there are millions of uses of the identifier 'yield' in finance industry.
Second part: Nice usages http://blog.codeisc.com/2018/01/09/cpp-comma-operator-nice-usages.html
Some notes: &gt; Another nice point of the comma is that it introduces a sequence point after every left operand evaluation Since C++11, the terminology has changed. I'd probably say it introduces sequencing between operands. Also note that UB is orthogonal to order of evaluation. The UB comes from unsequenced operations on the same variable. &gt; f.e. function args evaluation order is an *undefined behavior* Similar to above, the evaluation order is unspecified. Any UB will come from the evaluations of each argument being unsequenced with respect to each other. In addition, C++17 made the sequencing indeterminate, so `f(++i, ++i)` is now well-defined, but which argument is evaluated first can still vary. As for usages, I think you got about everything I've ever used it for with the while-with-assignment (though `for` is often appropriate here), `decltype`, and multi-loop-increments examples. 
Then go use those other languages. If you don't care about backwards compatibility, then you go right ahead and use languages that break your code every new release.
I use plain GNU Make often. I typically see no need for cmake or any other meta-build system in my use cases. What cmake and autotools allegdly bring to the table is easier build portability. Well, I rarely care about that. I am always going to have precise control over the build environment and platform. So plain old GNU Make works great.
Tight shell integration. You can easily have Make cause all sorts of things to happen during the build. CMake is this arcane, poorly documented, and limited string macro processor that is a waste of time to bang your head against trying to make it do things. Shell and Make suck in their own ways, but not enough to justify CMake unless you need to build on disparate platforms.
Looking forward to trying this out, thank you for sharing it! :-)
It would be nice to have a breaking version of C++ at some point that solves stuff like that.
!removehelp
Around the same time as "std2"? It would be good to do away with ambiguous `&lt;T&gt;` and use something like D's `!(T)` instead.
Thanks for linking to Terry's blog post! That's definitely the best place to start right now. As the post mentioned, we've updated MSVC compilers to help Windows address CVE 2017-5753. Work is ongoing in MSVC and across Microsoft to help make everyone's software on Windows more secure and help mitigate any performance degredations that may occur. I'm not going to say much else about this topic here, nor will anyone else from Microsoft. A lot of people and businesses depend upon our operating system and tools. While we like to be open and transparent about everything that we do, we're going to err on the side of silence to help protect our customers. We will be coming out with a more informative blog post on the [VC++ Blog](https://blogs.msdn.microsoft.com/vcblog) Real Soon Now^TM but for the time being we're not saying much. If you've got a situation that needs immediate attention, please contact Microsoft Support through your company's channels or the [Microsoft Support web site](https://support.microsoft.com/en-us). 
When you have hundreds of source files, external dependencies, and custom build rules, pure makefiles become a pain in the ass real quick. 
coroutine should be great, but it need extra work to work with network TS
cmake. It's not great, but it works.
I have to admit this blew my mind as I've never used this operator to do anything fancy on purpose. As for the obfuscation example, do you have a step by step explanation if what's going on?
For the loop example: Why not use a do while loop instead.
you can just put arbitrary statements in the if? it just has to end with a naked boolean expression?
You can have an init-statement in [an if](http://en.cppreference.com/w/cpp/language/if) since C++17. Besides, in the parent's example it does end in a naked boolean expression.
I may be misunderstanding your suggestion, but typical use of CRTP wouldn't do anything to help with ABI compatibility. Unless you're saying that CRTP can be used internally for the implementation, but I don't really see how that would help for this pattern.
You can see that the Windows binaries already put `lfence` after certain conditional jumps with dependent loads. This can be enabled with the `/d2specload` option in VS 15.5.3 released today. `lfence` was not historically a serializing instruction, but the microcode update that's going around now makes it so. Also switch idioms appear to be differently generated, but that could be just me imagining things. Also, since they've made me look, Return Flow Guard seems to also exist now under the switch `/guard:rf`.
That's a very nice point, I'll add it. Thanks :)
My personal favorite is still the “down to” operator: `—&gt;`. For x down to 0 is `while ( x —&gt; 0) …`. 
The best use for the comma operator is in code golf.
hahaha that's a funny one
I actually did this on purpose once. I wrote ‘while (true == false == true == false)` to mean `while (1)`. I knew it was dumb as hell, but I guess i was proud of myself for thinking up the silliest while (1) conditional ever and thought it would be a cute mental exercise for whoever had to maintain my code. It’s probably still out there in production, (i no longer work there). 
There is a place where I love the comma to make pure one liner functions std::string reverse(std::string input) { return std::reverse(input.begin(), input.end(), input.begin()), input; }
Is that actually considered to be the comma operator? I thought it was just a separate syntax in itself.
Stupid phone. Fixed, thanks!
Yes it is. In his case, he's using the fold to create an expression that takes advantage of the comma to perform multiple push_backs. Fold can also be used with other operators like '+', '&amp;&amp;', etc
Ah yes perhaps, I didn't know if it's the case.
Yup, it's a fold using the comma operator. You can fold using most binary operators. Like: auto foo = (do_something(args) + ...); Or: (std::cout &lt;&lt; ... &lt;&lt; args);
&gt; While we like to be open and transparent about everything that we do, we're going to err on the side of silence to help protect our customers. Understandable, thanks for your reply.
You mean this library? [http://fmtlib.net/latest/api.html] Was there a proposal to make that part of `std`?
Same here. The problem with this kind of stuff is that not only do you have to be sure that you understand what's going on. You also need to feel secure about everyone who comes after you to edit/update/debug your function to also easily recognize the usage and understand it's nuances. Obscure stuff like this just isn't worth it, IMO.
Cmake is an OK solution in that it's the least worst solution if you don't want to maintain different buildsystems and want both unix and windows compatibility. Other than that, it generates kinda poor build systems on all platforms, especially Make based ones.
It would be also nice to have defense against comma overloading discussed. It is done by insertion things like cast to void (`(void)`). It is important topic when writing generic libraries. I personally consider overloading comma very bad practice, but some library author do it and generic code shall be prepared.
Slides can be viewed at https://ned14.github.io/outcome/videos/
well, in the article I use a proxy template for defense (C++03 Params example) and I think it's a nice solution. If you have any other ways please let me know, I'm interested
yes please!
Some thoughts: * Yay for `BOOST_DETAIL_SCOPE_GUARD_FN_ALIAS` * Why use `boost::detail::scope_guard::action` over a *lambda expression*? * `apply_impl` shouldn't be `constexpr` because `std::invoke` is not `constexpr` * What's the benefit of `detail::scope_guard::unwrap_decay_t` over `std::decay_t`? --- I would implement `scope_guard` by just templatizing over a generic `F` and using a lambda expression. Example: https://github.com/SuperV1234/ecst/blob/master/include/ecst/utils/scope_guard.hpp (Note that my implementation is not really complete as it doesn't really care about exceptions).
What do you guys think about adding this example to the post? https://ideone.com/XNhaMI
Because the pipe syntax is not agreed upon yet. It's just one possibility along others. Though it seems popular but also inspired by a different domain than monadic stuffs.
I tried to post on the c++ team blog, but it didn't work. A little bit off topic. Currently I'm fighting with slow debugging. I would be great to have selective inlining. Maybe it is possible with the upcoming c++ modules to enable inlining per module? And another question about constexpr. If an constexpr function that assigns to an non-constexpr variable is called with only constexpr arguments, why is this call not evaluated at compile time? (I'm using VS 15.5.5 in Debug konfiguration). In release it is optimized away, but that dosn't help me over slow debugging. constexpr double test(double a, double b) { return a*b; } void main() { double v1 = test(2,3); //debugging jumps into the function, but could have been evaluated at compile time constexpr v2 = test(2,3); //works (no function call) } 
I was picturing Python when I said it. Fracturing sucks and I don't like to lose old code but eventually biting the bullet might be good
ISPC isn't a fork of C. First, C isn't a program that be forked, second, it is a language that is mostly derivative of C, C++, and shading languages like the renderman shading language. ISPC also uses LLVM and has a stand alone 25 MB binary. It has been out for many years now. If anyone wants to integrate these techniques and ideas into their language standard, they are all right here for the taking. I don't think saying that Intel should have tried to get something like this in to a different standard is very realistic. In the meantime, anyone can use ISPC to produce some of the fastest programs possible. I'm not aware of anything that beats it's performance when used well.
&gt; First, C isn't a program that be forked That's not how forking works. Forking is just the action that takes a single path and diverges it into two paths. A language spec *can* be forked. &gt; second, it is a language that is mostly derivative of C, it's funny... usually forks have a lot in common with their parent. who would have thought? &gt; If anyone wants to integrate these techniques and ideas into their language standard You just described the language-spec-equivalent of a pull request. ---- yeah. your post was not helpful.
Last time I used open CL it was used to run code on the GPU. Is it now used to vectorize code on the CPU ?
OpenCL can be also used for multi-core vectorized code on CPU. Intel itself offers an OpenCL platform that runs on their CPUs.
You seem pretty desperate to dig in to bike shedding and semantics, so let me ask you this, have you ever actually used ISPC? Also if it is a 'fork', can you show me the point in time that it forked off from C? Are java, C++, D and objective C also forks? &gt; You just described the language-spec-equivalent of a pull request. Are you saying that you think that instead of Intel releasing this language years ago, they should have gotten mixed up with standards committees? If that had been the approach, this wouldn't exist in any form (all of those languages are still deciding on how to deal with SIMD, even with this as a working example). &gt; yeah. your post was not helpful. sorry. &gt; the important thing is that the post title claims C/C++, and /u/Z01dbrg correctly states that this is not C or C++, but rather a "fork" of C. It seems to me that neighther of you have actually used it at all. For someone trying to learn, calling it a 'fork of C' is going to do more harm than good. You allocate memory with new, there is a constant keyword, and there is limited operator overloading. There are structure of array features, range based for loops, special loops to loop over SIMD lanes, and a concept of varying and uniform throughout every program, which comes from renderman. It combines concepts from multiple languages into something new and again, for something to be a fork, it would have to have forked from one thing at a specific point, which doesn't make sense here. 
Agreed. I am similarly simplified here at https://github.com/ned14/quickcpplib/blob/master/include/scoped_undo.hpp#L95 I'm not at all sure of the gain of all the complexity in the OP's implementation. All the uncaught exception stuff seems to me totally superfluous. Just need an undo object, and some way of dismissing it if later logic determines that, and you're done.
&gt; have you ever actually used ISPC Since it does not even have a Wikipedia entry I guess very few people did. &gt; Are you saying that you think that instead of Intel releasing this language years ago, they should have gotten mixed up with standards committees? Yes. Fancy language is meaningless without proper funding and userbase(for example even with GC problems D can run circles around C++ from pure language perspective, but it has minuscule amount of users). So this is a fine research project language for Intel to gain insights and experience. But to promote it to end users is laughable. 
It was required for C++11 `constexpr` functions, but not anymore.
The hate being dumped here onto various folk isn't warranted. This is an ISPC compiler for the ISPC language, which looks a bit like C. It is not C, nor C++, but generates object files which can be linked into C or C++ programs (or Rust etc). ISPC was started as a postgrad project, then Intel hired the guy, and Intel adopted it. It's not like Intel are pushing this particularly hard, it's a service to the community. It also supports ARM NEON incidentally, and GPUs. CppCon a while back had a presentation on ISPC. I've used it during a contract. I'd highly recommend it, spits out nearly optimal SIMD code for Intel and ARM NEON. Easily beats SIMD intrinsics on the compiler. Support is also pretty good, though a bit DIY. I fixed a few bugs in NEON generation, they were reviewed and accepted within a few days. There is a helpful userbase community on their mailing list, and in general working with ISPC I found a positive experience. C++ devs should definitely strongly consider using ISPC as an alternative to other SIMD approaches. It's a lot cleaner, and produces better quality code with less effort, than SIMD programming via C or C++. 
&gt;Are java, C++, D and objective C also forks? C++ and Objective C definitely. Both are compatible with C code from the point they forked (with some intentional exceptions). Java isn't because while it uses braced syntax it is very much not C compatible. D I don't know enough about to say.
&gt; So this is a fine research project language for Intel to gain insights and experience. But to promote it to end users is laughable. You dismiss this very confidently, but for myself and the people who have used ISPC to create faster programs than would be possible with C++ alone would disagree with you. It isn't a research project just because you don't understand it, and I have no idea why you think a language from Intel isn't well funded enough. You do realize this has a limited scope and works very well within that scope right? It doesn't even produce executables, only object files that must be linked in.
If `a &lt; b == c &lt; d` doesn't resolve the same way as Python, it doesn't seem consistent enough to be worth the trouble.
&gt; You seem to want to dig in to bike shedding and semantics Aren't you the one who started this thread with an argument about how a derivative language or language extension shouldn't be called a "fork"? Pot, kettle, ...
In test frameworks like Catch, `CHECK(a &lt; b)` is more or less turned into `magic &lt;= a &lt; b`. Wouldn't chaining comparison wreak havoc with such frameworks? I'm also wondering whether such frameworks would then be able to decompose checks like `CHECK(a &lt; b &lt; c)`. If I'm not mistaken it would be turned in something akin to `(magic &lt;= a) &amp;&amp; (a &lt; b) &amp;&amp; (b &lt; c)`, which means that `a &lt; b` and `b &lt; c` would be evaluated separately and thus wouldn't be decomposed (at least that's how I read it). I'm all for chaining comparisons, but I fear that they're not compatible with that specific use case.
&gt; I may be misunderstanding your suggestion, but typical use of CRTP wouldn't do anything to help with ABI compatibility, which is one of the principle motivations of PIMPL You're 100% right. The presented pattern, though, isn't PIMPL, either, and in trying to avoid virtual functions: 1. Forces a 1:1 correspondence between interface and implementation, since you can't parameterize the static_cast. 2. Requires heap allocation, anyway. 3. Destroys a child object using a pointer-to-base with no virtual destructor. Compare the assembly, for instance, of the two techniques: /u/ivanstepin's: 1. [Without optimization.](https://godbolt.org/g/uWgo3w) 2. [With optimization.](https://godbolt.org/g/vpdNW6) /u/cdglove's: 1. [Without optimization.](https://godbolt.org/g/Q5STLa) 2. [With optimization.](https://godbolt.org/g/WCennr) I know which one I prefer. So yes, while in some sense the latter offers ABI compatibility, it does so at the cost of flexibility, correct resource management, forced heap allocation, and still has to chase a pointer anyway, despite the claim that it's better because it avoids "unnecessary virtual function overhead". Do PIMPL right, like [KDE teaches us](https://community.kde.org/Policies/Binary_Compatibility_Issues_With_C%2B%2B), or don't do it at all. 
You are right, but that does not matter, people here will downvote you because precious C++ committee can not be wrong.
&gt; You're 100% right. &gt; &gt; The presented pattern, though, isn't PIMPL, either, and in trying to avoid virtual functions: &gt; Tomato, tomato, I suppose. It's basically doing it the C way by using an opaque type and reference semantics instead of value semantics and an internal allocation or buffer. &gt; Forces a 1:1 correspondence between interface and implementation, since you can't parameterize the static_cast. What do you mean by this? &gt; &gt; Requires heap allocation, anyway. Unavoidable, unless you hard code a buffer into the header file, which comes with its own set of problems. &gt; &gt; Destroys a child object using a pointer-to-base with no virtual destructor. &gt; Just a bug. But thank you for calling out a missing virtual destructor on code I typed out on my phone while riding the subway. &gt; Compare the assembly, for instance, of the two techniques: &gt; &gt; /u/ivanstepin's: &gt; &gt; Without optimization. &gt; &gt; With optimization. &gt; &gt; /u/cdglove's: &gt; &gt; Without optimization. &gt; &gt; With optimization. &gt; &gt; I know which one I prefer. &gt; This test is completely invalid because it doesn't test the scenario we are tying to solve, which is some kind of compiler firewall. When everything is known in a single cpp file, and you're calling function on the concrete type, the compiler is able to inline everything away, even the virtuals, but it can't do anything about the heap allocation. Here's a more apples/apples comparison, your original version + heap allocation. https://godbolt.org/g/HKEAkU &gt; So yes, while in some sense the latter offers ABI compatibility, it does so at the cost of flexibility, correct resource management, forced heap allocation, and still has to chase a pointer anyway, despite the claim that it's better because it avoids "unnecessary virtual function overhead". &gt; &gt; Do PIMPL right, like KDE teaches us, or don't do it at all. The document you linked describes virtually the exact thing I posted, except it uses value semantics instead of reference semantics. Or am I missing something?
That page by KDE is just a list that explains what kinds of changes are permitted while maintaining binary compatibility, one of which is PIMPL (or as they call it, d-pointer). Also, the first example that you posted is not a valid demonstration of the technique. You create an instance of `MyClassImpl` on the stack, but that class cannot be visible to consumers of the library if our goal is to maintain ABI compatibility. The real thing would look like [this](https://godbolt.org/g/KN5N1C) instead. You'll notice it's much heftier than the version that uses `static_cast`. I'm fairly certain that in principle it is literally impossible to avoid heap allocation if you want to *guarantee* ABI compatibility throughout arbitrary changes to the features and/or implementation of an object. Fundamentally, heap allocation is the only way to avoid changing the memory footprint of an object while arbitrarily changing the amount of memory that the object can use. That being said, you're absolutely correct: There is a very very very serious problem with managing a pointer to a base class that has no virtual destructor. That's a recipe for catastrophic memory issues, and that should never be used. This is **exactly** where PIMPL becomes so valuable: You get to completely separate your library's API from your library's implementation without having any virtual function calls. The Interface Pattern and the PIMPL pattern are two very different design patterns which just happen to have some overlap in their benefits, but they should not be viewed as interchangeable, nor should one be viewed as inherently superior to the other. * The Interface Pattern should be used when you are defining an abstract interface which may be able to support multiple types or implementations of the same concept * The PIMPL pattern should be used when you want to implement a unique fully-derived object with the best performance possible while satisfying the constraint that ABI compatibility will never be broken, no matter what changes are made to the features or implementation.
How is it exposed? The impl is only defined in the cpp file. The only difference is it forces reference semantics instead of value semantics, which may or may not be a good thing, depending on what you are doing. Often, it's good because it doesn't hide the fact that there's an indirection happening.
Interesting. I only found out about `fmt` before Christmas and was planning on incorporating it into my projects anyway.
&gt; Also, the first example that you posted is not a valid demonstration of the technique. I know. I was trying to point out that the assumed overhead of virtual function calls wasn't necessarily a real problem, especially given that the alternative still required heap-allocating the object. It was supposed to be orthogonal to the discussion of ABI compatibility. Obviously I didn't do a good job making that clear. As far as I can see, it has no advantage over a bog-standard PIMPL implementation and plenty of unwanted risks/limitations. 
&gt; What do you mean by this? It's totally possible I'm misinterpreting something, missing an obvious thing, or it's just a matter of the reduced size of your example, but I can't see a clean way to have more than one kind `Impl` in your method. E.g. if I had: struct MyClassImpl : MyClass { int DoSth() { return 12345; } }; struct MyClassImpl2 : MyClass { int DoSth() { return 54321; } }; What would you propose as the implementation for `get_class()` and how would you know which type to downcast to in the base class? What if the Impl itself could be sub-classed? There are [potential issues with UB](http://en.cppreference.com/w/cpp/language/static_cast) doing a downcast via `static_cast`, too, but they can be avoided I'm sure. &gt; Or am I missing something It may just be semantics/common usage, but one of the key distinguishing traits of PIMPL is that the interface class owns a pointer-to-implementing-class. What you described *does* work as a compilation firewall, but it's not canonical PIMPL (or at least not as I've ever seen it) and it's not, as far as I can see, as flexible. Your initial assertion/argument against the pure-virtual interface was that it introduces virtual function overhead on every call and that the `static_cast` was superior. I don't think that assertion holds water unless you are willing to give up the ABI guarantees and do CRTP with value types/heap allocation. 
The iGPU is a separate device. The Intel platform supports both on Windows (you can choose which device to use); on Linux it only supports the CPU (the GPU is supported by a different driver, called beignet). There are also other platforms supporting the CPU. AMD for example has (or maybe had?) one. There's a FLOSS one called pocl too. 
Ah. Thanks for the clarification :)
Please float this on the Boost.Dev list and I'm sure there will be interest for it. I, for one, am certainly missing this on a day-to-day basis. Just yesterday I had to reimplement my naive `scope_guard`.
[DreamWorks](http://tabellion.org/et/paper17/index.html) is using it heavily in their new renderer. [Pixar](https://graphics.pixar.com/library/PxrMaterialsCourse2017/paper.pdf) also uses it some. Intel teaches seminars on it at SIGGRAPH. I'd claim that it's fairly well known in the graphics community at least. The [guy who started ISPC](https://en.wikipedia.org/wiki/Matt_Pharr) is a cool guy and holds a lot of respect (e.g., a technical Academy Award). It's also different from a fork of C in that it's not meant to be used to write whole programs. You're still expected to use C++ for your program's main code. Instead the idea is that you can write small kernels in it and have it vectorize the hell out of them for you. Then you link those kernels in and call them from your C++ code. It's a bit like CUDA in that respect.
&gt; no numbers for AMD slowdown I thought AMD didnt have the same issues, so wouldnt have slowdowns? Isnt it just intel?
AMD isn't affected by Meltdown, and is only affected by one version of Spectre. It is still affected though.
&gt; C++ multi-threading, how to use and write STL allocators, any kind of template programming, useful design patterns, CRTP, etc. What book covers those topics?
**Company:** [FlightSafety Simulation](http://www.flightsafety.com/fs_simulation_landing.php) **Type:** Full Time **Description:** FlightSafety Simulation (FSS) develops flight simulation training devices from classroom desktops to fully immersive simulators with motion, visual systems, and interactive networked capabilities. We are looking for experienced C++ developers to contribute to our cross-platform frameworks and to build tools for other developers and simulator support personnel. Our group deals with many of the non-aircraft components of a simulator such as selection of development tools, integration of 3rd-party solutions, and publication/consumption of data for distributed training. Tasks may vary from creating virtual cockpit GUIs and CPU instruction set simulators to implementing the C++ Networking Technical Specification. While C++ is the primary programming language, multi-language programming with Fortran, Ada, Jovial, C#, Lua, or Assembly for Intel and Motorola may occasionally be needed. **Location:** Broken Arrow, Oklahoma (A suburb of Tulsa) **Remote:** No **Visa Sponsorship:** No **Technologies:** - New development: C++17/2a. Stable development: C++11/14. Long-term maintenance: C++98/03. - User- and kernel-mode programming with almost no limitations of the use of C++. - Driver development for Intel NICs, FireWire (IEEE 1394), CAN bus, and reflective memory. - OpenGL, boost, google test, DirectX, clang, gcc, MSVC, clang-tidy, Qt **Contact:** Please apply here: [Requisition 7007](https://careers.flightsafety.com/job/Broken-Arrow-Engineer-Okla-74012/433619600/) and PM me. 
I just read an article about a path tracer ([MoonRay](http://tabellion.org/et/paper17/index.html)) made by Dreamworks that's written using ISPC. Interesting. &gt; We use the ISPC programming language to achieve improved performance across SSE, AVX/AVX2 and AVX512 instruction sets. Our system includes two functionally equivalent uni-directional CPU path tracing implementations: a C++ scalar depth-first version and an ISPC vectorized breadth-first wavefront version. Using side by side performance comparisons on complex production scenes and assets we show our vectorized architecture, running on AVX2, delivers between a 1.3x to 2.3x speed-up in overall render time, and up to 3x, 6x, and 4x, speed-ups within the integration, shading, and texturing components, respectively. 
Looks like a bad example. No practical use in extracting last argument.
Well, it's the best way to extract the last arg nowadays. About practical use, I can't see any too. I'll put the push_back + last arg examples. Thanks
&gt; How does it give up ABI guarantees? Just in case I wasn't clear: using CRTP, you can't do PIMPL-style ABI-guarantees. My point was that I don't think your statement: &gt; I was mearly pointing out that such a factory, when there's only one derived class, introduces un-necessary virtual overhead can be supported without measuring the specific use case, since compilers might de-virtualize certain calls, your solution still has the cost of accessing heap-allocated objects, etc. Nothing's ever easy anymore. :)
You should post this in the Q1 2018 thread.
&gt; can be supported without measuring the specific use case, since compilers might de-virtualize certain calls, Sure, always measure. That said, it's highly unlikely the functions will be devirtualized if we're correctly insulating the caller. Maybe with LTCG, but, I wouldn't necessarily like to count on that. &gt; your solution still has the cost of accessing heap-allocated objects, etc. &gt; &gt; Nothing's ever easy anymore. :) What cost do you think there is to access an object through a pointer instead of directly? 
FYI, you are shadowbanned. You'll need to talk to a reddit admin to get that lifted.
"Uncaught exception stuff" is essentially "just an undo object" where "some way of dismissing it if later logic determines that" is the common case where failure that requires the undo is signalled via throwing an exception.
No boost 1.66.0 yet, use 1.65.1.
You are aware of [Boost.ScopeExit](http://www.boost.org/doc/libs/release/libs/scope_exit/doc/html/index.html), right? The basic version has been there for a long time.
Something I have found useful in scope guards is a type-erased variant. It can store any scope guard, and lets me pass the "cleanup" code in a structure. Toss in move-to-clear, and you can have a collection of partly finished tasks that run on exit, but maybe can also be cancelled. Lacking type erasure, such cleanup functions cannot exist without exposing the code they are running, which is sometimes not worth the bother. 
Actually, CMake's looking like a porker compared to Yet Another Contrived Makefile: $ cat Makefile all: hellomake hellomake: hellomake.o hellofunc.o hellomake.h 
&gt; What cost do you think there is to access an object through a pointer instead of directly? More or less the same as a virtual function call: the cost of one pointer indirection.
Hi. No, it isn't. The do-while version would be something like: do { processWindowEvents(window); if (window.isOpen()) { // render etc } } while (window.isOpen());` Note that it is also inefficient!
Yes, but I can't justify to myself using macros for such a simple thing. I fully understand why they use macros (they need them to support C++03), but I don't need C++03 support.
of course, it's a joke hahaha just kidding, i am a noob at this 
i am not a professional at all, but it was an experiment i did
i know, it IS useless
how could you tell? mod privileges? 
Looks like conan has changed a lot since I last evaluated it. I'm excited to see what all it offers now! I hope they can add [lock files](https://github.com/conan-io/conan/issues/1042) without breaking compatibility. After seeing how handy they are, I consider that essential for a modern build tool. While I love Python, I am disappointed by how quickly they drop people into configuring their build imperatively with Python. 
That seems like a bad sign.
I don't like the nomenclature and the example use case... but yeah. Should be called a "closure", and you should use it for reproducible builds/deploys. The problem with locking versions in your normal build tree is you tend to end up with brittle code that breaks every time dependencies do finally get updated. Still, it's an important feature to have, and people should do what they want with it, but I don't much like that particular use case.
As drrivn hinted, CMake 3.10 doesn't offer out of the box support for boost 1.66 since it was released before 1.66. Generally when this occurs you can specify Boost_ADDITIONAL_VERSIONS before calling find_package to help the FindBoost module find the newer version. But boost 1.66.0 changed around the naming convention on windows and this approach won't work on all platforms. Boost 1.66 support is on track for CMake 3.11.0 
ty
&gt; I don't like the nomenclature and the example use case... but yeah. Was just having a discussion on nomenclature about this :) While there could be a lot of thought on what the most accurate term is, whether in theory, in implementation detail, or from a user perspective, some terms have already gotten enough use that I feel the de facto standards beat an artificial standard. My thoughts on the common terms I see - pin: The connotation for me is more of a user action - freeze: The connotation for me is more of taking a snapshot, like pipenv freezing your virtualenv - lock: I've only ever seen it used in this context. &gt; The problem with locking versions in your normal build tree is you tend to end up with brittle code that breaks every time dependencies do finally get updated. I've seen this at my job. We disable masters whenever possible and just reuse old builds of them but this means they aren't kept up-to-date and sometimes the upgrade process has been ... painful. (Note: our CI upgrades to the latest nightly deps on every build. Its a manual process to upgrade across major/minor/update but we have centralized feeds of these that we can easily switch between) In Rust, semver and not pinning libraries helps. To me, the ideal solution is to always check the lock file in and to have a [bot that creates PRs to update your dependencies](https://pyup.io/). In the semver world, I'd even like to see it upgrade the config file and not just the lock file. This would help raise awareness of new major versions and identify ones that didn't break your specific application.
It has tools like pip (maybe not quite as powerful) - the problem is that no single tool ever became the de-facto standard.
at 41:10 you are talking about [trivially copyable types](http://en.cppreference.com/w/cpp/concept/TriviallyCopyable) and no copy resize of array. Am I correct in fact requirement is a bit more loose, in a sense that [relocatable](https://github.com/facebook/folly/blob/master/folly/docs/Traits.md) types work fine also? I know that for talks using std concepts is preferable, I am just asking if I got the idea correctly.
They're working on it, that's a good sign.
I'm gonna raise a second point and say that Makefiles don't scale well when it's about readability and maintenance. Not that CMake is any best solution, but it does scale better than Makefiles.
Why are you not confident? The best way to learn is to actually work in it. Sure you'll have thousands of questions, but the internet is your friend and you can still ask question here on r/cpp_questions or on StackOverflow. You will gradually learn new things as you navigate through the existing code base or when you develop new things.
As a pro c++ developer for about 10 years now, I'd say getting a certification isn't something that a hiring manager is going to care about. I'd recommend saving your money *shrug*. My recommendation would be to think on what kind of programs you find interesting, and find an existing open source project doing that type of thing in C++. For example, if you're a fan of RPG video games, you might consider downloading the source code for a game engine like the OpenMW project (I'm not affiliated, I just was playing it recently so it popped into my head), and seeing if you can work out a fix for one of their bugs. Or if you're interested in multimedia, take a look at the VLC codebase. Or ask a friend of family member if they would benefit from a simple text processing program, and then grab a C++ framework like Qt, and see if you can build something that solves their issue. Personally, I started working with C, and only ended up in the C++ world by random circumstance at work. The initial learning curve, and developing an intuitive understanding of what a particular set of code ends up doing at the machinecode / assembly level, can be long and grueling. Personally I'd say to just start out worrying about getting the functionality that you want working, working. Worry about optimizing things far down the road. Fixing compiler errors, and just in general developing with the language, will help you understand things on a more intuitive level by osmosis. One thing to keep in mind is that if your code is hard to understand, you're trying too hard. Simple, easy to understand, code is generally code that's just as fast (or sometimes faster) than tricky obscure code... Not always, but generally. Also, Stack Overflow is your friend. Good luck!
To add to this, if there's a library or something that you use a lot and really like see about contributing to it. There's lots of projects that could probably use some cleanup and it gives you experience and something to point at in an interview.
Yes, it's looser like as you say. But the C++ standard has no concept of IsRelocatable, which is weaker than trivially copyable. So I didn't mention it.
totally true, nice point (I'm taking notes for improvements)
There's a difference between `static_assert(false)` and `#error`. Typically, `static_assert(false)` doesn't immediately terminate compilation, while `#error` does. For this reason, MSVC's STL now consistently uses `#error` to emit really fatal errors (e.g. trying to `#include &lt;optional&gt;` in C++14 mode). &gt; Use std::source_location That's experimental, not Standard.
So, use references instead of pointers. It's more efficient this way over a wrapper anyway. 
Ah shit, good point -- no smart references. 
Actually, I wouldn't call that "correct", depending on needs. I'm willing to pay for the slightly leaky abstraction because it's more efficient this way, but I still get the benefit of ABI stability, faster comile times, etc. 
Where is this Python example? Honestly, this would make me try out Conan, but I can't seem to find the example.
No, conan packages are de-centralized. Original boost developers won't publish the boost as a conan package. Packagers(=volunteers) may packaging and upload open-sources libraries like boost, openssl, so on, but they are not forced to do so.(some group named bincrafters are working on it anyway) I like the conan because you can easily deploy conan server with on-premise box, and I can use conan without global registry, like conan-center, conan-transit or bincrafters. Edit: typo
[One example](http://docs.conan.io/en/latest/creating_packages/getting_started.html) Weird, that suggests that `conan new` creates a python file by default rather than the text file.
This basically exists, and its called D.
https://stackoverflow.com/questions/146850/is-d-a-credible-alternative-to-java-and-c Is there a more recent question somewhere
Can't stop a good old fashioned mob pile on.
Agreed.
I meant it more from a healthy ecosystem standpoint. Boost is big and complex, but broadly used, so it's a good litmus test for how healthy the ecosystem is.
You can try to rewrite your Python test automation scripts in C++, for a start. And if your database has a C/C++ API (or an ODBC implementation), rewrite your SQL scripts in that. You can learn a lot by trying to eliminate boilerplate code using all of C++'s abstractions at your disposal. Obviously, don't replace your existing scripts, but you can use it for demonstration and maybe get your foot in the door that way.
&gt; Having your build break on those updates is a good way to encourage that mentality. And I see value in that. I also don't like random PRs failing because an updated dependency broke the build. That is a great way to discourage contributors. I feel that a bot that updates your dependencies is a happy middle ground.
Cool. I'd like to add serialization support for at least base_collection here: https://github.com/Ebenezer-group/onwards . Do you have any advice on that? I think I'd have to call is_registered for all derived types and then iterate over the segments of the types that are registered. It might be a little inefficient if there were a lot of derived types and only a few of them are registered, but not sure how often that happens.
&gt;#&amp;nbsp;5. Prefer pragma once over include &gt; Nowadays, the exotic C++ compilers that don’t support `#pragma once` are few and far between. Using `#pragma once` is less error-prone, easier and faster. Kiss the include guards goodbye. I replaced all my include guards with `#pragma once` recently and build times went up by a factor of 2-3x. Ended up using both. :/
&gt; spits out nearly optimal SIMD code for Intel and ARM NEON. Easily beats SIMD intrinsics on the compiler. That's a serious claim. I've written an intrinsics-based SIMD library (not as fancy as Boost.SIMD, but more template-friendly than the `float4` varieties) in C++ that both gcc and clang turn into code identical to my hand-written versions. And that includes type-punning to do floating point "booleans" that get converted to the correct opcode while the end-user code is just `if(any(x))`. I'm not saying ISPC can't generate quality vectorized code, but that it can do better than compiler intrinsics seems a bit overstated. I work in HPC, so I've seen/read about ISPC though I've never used it nor seen it used in the wild. I have a feeling the biggest roadblock to its acceptance was/is the need for a third-party compiler rather than direct support in *The Big Three*^1. Releasing it as open source is a step to making that happen. [1] Let's be honest, icc isn't a contender here. gcc, clang, and msvc are the supermajority in the C++ world. Even in HPC, icc is second to gcc (clang is pretty much nowhere to be seen which is sad) unless you are writing for the Xeon Phi. ifort, however, is pretty much the de facto Fortran compiler. As it should be. It has better language support and better code gen than gfortran.
What compiler are you using? It's quite surprising.
This rant is not directed at you. :) &gt; a C++ scalar depth-first version and an ISPC vectorized breadth-first wavefront version This drives me nuts. You can't change both the algorithm and the implementation and then proclaim that it was the implementation that made it go faster. I have seen this so many times in the science community. An author will claim "We moved from OpenMP+MPI to Widget-X, and we saw a 5x speedup due to Widget-X!" Ok, but did you try implementing the new algorithm in the old framework? "No." /ragequit. It's great that we can make software go faster, and I am all about any framework that can make it happen- especially with less user effort. But we need consistent, *repeatable* tests to make sure we understand how we made it go faster. Otherwise, it's all just wacky waving inflatable arm tube man nonsense.
A tour of c++(14) by soustrop
Why would it be more efficient? What you're doing is exactly the same as classic pimpl from the compiler's side. It's only more cumbersome for the end user.
Continuous builds largely mitigate the problem, but I agree about wanting to make it easy for people to contribute.
&gt; Stack Overflow is your friend It's handy, but please understand every line of code that comes from the solution. That being said, I like your post overall
You may find proposals - here: https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list/388282#388282 - or here: https://accu.org/index.php/book_reviews_redirect
It's a true claim though. Plenty of HPC folk are avid users and are on its mailing list. The reason it beats C++ is because the ISPC language forces you to write scalable code. Indeed it is often frustrating to turn some algorithm into ISPC which compiles, but once you figure it out, whoosh ... Also note ISPC generates LLVM, so it'll plug into any LLVM tooling you have. For example, debuggers.
Why not have coroutines as a standard library instead of having them integrated into the language itself? In that case, it would be perfectly feasible to use sane names and syntax like: std::await or std::yield and etc.
MSVC, not sure if it was 14 or 15. I suspect it was due to precompiled headers confusing the compiler as to which headers were already included.
In MSVC it should be exactly the same. &gt; The compiler recognizes the #include guard idiom and implements the multiple include optimization the same way as the #pragma once directive
Being able to generate different versions for different SIMD models (e.g., SSE, AVX, Neon) without having to rewrite the intrinsics is also really nice.
Well, if you were hired to do that, surely speaking to your colleagues /superiors would get you there, did you try that? If yes, and they somehiw don't want you to do it, then it's a whole different question 😉
I think if you re include headers that were in your pre-compiled header it ends up reparsing them. It looks like what happened.
I use the following for my C++ course: Stroustrup, B. (2014). Programming: principles and practice using C++.
If you already know programming and just need a condensed description of how things work in C++ then this one is very good: "The C++ Annotations" http://www.icce.rug.nl/documents/cplusplus/
I can't understand what it is for
Everything except getting the current executable path can be easily done with the C++17 filesystem library: auto exe_path = fs::path(…); auto file = exe_path.parent_path() / "input.txt"
**Company:** [think-cell Software GmbH](https://www.think-cell.com) **Type:** Full time **Description:** think-cell is a kind of company developers truly like. In fact, of our now 20 full-time developers, in 15 years of think-cell, only one ever quit his job. We are highly profitable, so we can give you the time and resources to write beautiful code. There are no meetings. All management (the two co-founders) are computer science PhDs, so no demands from people who don’t understand the trade. We are working on revolutionizing the way presentations are made, reinventing the user interface and largely automating the slide layout. At the same time, we integrate this product into Microsoft Office, which means reverse-engineering and disassembling the innards of Microsoft’s code. And we do this all based on our very large, home-grown C++ library, which we have the liberty to perfect along with the rest of our code. think-cell is the only German company funding a C++ ISO committee delegation, so there is a good chance that components we invent will find their way into the standard. We are growing the team slowly but steadily and would like to hire up to 10 C++ developers in the next year, either junior or senior. You can find the [full job description here](https://www.think-cell.com/en/career/jobs/development.shtml). In general, developers sit in offices with one or two other developers and their offices open to a great hall. You don't work in teams necessarily, though it may happen. In general, you discuss your tasks and projects with the Technical Director, according to where your interests and skills meet what is needed by the product and company. This is an amazing opportunity since we are not hiring for one project or objective in mind, but for multiple. There is no exposure of developers to clients, since there is a support team that works closely with them. However, they are much closer to the client than other companies, with only one “layer” of people in between, instead of 3-7 “layers” or intermediaries. The company has 41 employees already, 20 of which are in development. Nationalities at our company are varied, including German, Chinese, South African, Italian, Argentinean, Russian, etc. **Relevant questions:** Do you believe in beauty when it comes to programming? Do you have a vivid interest in elegant algorithms? Are you fluent in C++? If so, we would like to meet you. **What we offer in a nutshell:** A wide array of extremely challenging C++ development tasks. An international team of brilliant minds. A working environment that makes this team stay and grow. Enough time to make sure that every detail of your solution is perfect. A flat organization and plenty of room for your ideas. No scheduled meetings. Family-friendly working hours, no deadlines, no overtime. A competitive salary from the start and a raise to EUR 120,000 annually after only one year. **Location:** Berlin-Mitte. Chausseestr. 8/E, 10115 Berlin, Germany. **Remote:** No, we prefer to work at the same office. Since there is a no-meeting policy at the company, it’s good to have all colleagues nearby during office hours. However, these hours are flexible if the developers need to run an errand, they have to simply notify the others. **Visa Sponsorship:** Yes, we support candidates by sponsoring their VISA if they need one. Besides, to relocate a candidate, instead of a one-fits-all package, our CEO speaks directly to the candidate about his/her needs to relocate and if they are reasonable requests, we work to provide it. In general it may include support moving and accommodation when they first move to Berlin. **Technologies:** Please, see a detailed description of the technology we use under the subtitle ["about our software"](https://www.think-cell.com/en/career/jobs/development.shtml) **Contact:** Send us your CV/resume per email to [hr@think-cell.com](hr@think-cell.com)
&gt; `std::invoke` is not `constexpr` Wait, what? `invoke()` is new in C++17. Why on earth would they not have made it `constexpr`?
https://en.wikipedia.org/wiki/Working_directory
Hi, Seems to me you need to specify a complete list of the types that can potentially go into the collection as part of the associated `-out`/`-in` directive in the middle file. Trying to send a collection with elements of a different type than those specified can either throw or not send those.
&gt; but it actually depends on where you run main.exe from. This is actually the situation at the executable launch. You can use commands to modify that current directory during the execution. It can be useful (set the .exe directory as the current directory right after `main`), use a push/pop mechanism to make your life easier when dealing with a temp directory, but usually it goes terribly wrong (a lib set the current directory and break your assumptions, it's a global resource etc.) when you reach a certain program size.
Don’t need Windows tips though. I was working with Linux when I noticed something odd with my system() calling .sh files. Then tested with simple bash commands, then tested in Windows too.
Thought you were on windows because you suffixed your executable names with ".exe" :) On linux, you just do a readlink() on /proc/self/exe to get the executable path.
Thing is, ISPC won't compile if you've not written an algorithm which scales across SIMD. So in some ways the claim is right, though not as strong as a first interpretation of it would suggest (so you are also right)
Eventually you will run into a time when you must forward declare a function. The most obvious case is: foo() sometimes calls bar(), bar() sometimes calls foo(). But hopefully that won't be your only motivation. Write "literate" code - your first and most important audience is other humans. So group code meaningfully. You wouldn't write a novel by scattering paragraphs into chapters completely at random. Keep related functions closer together.
Is there a way to consume a package (with sources) and work on it at the same time? is it convenient?
No offense, but this post reads as if you're expecting someone else to take up your idea and execute it? The committee is made up of volunteers, so that is unlikely to happen. If you think you have identified a safe way to get 80% of the benefits of concepts with some minimal changes to the standard library, the way to make it happen is to go ahead and submit a proposal. More likely than not, you'll discover that the issue is more subtle than you assumed and it's really hard to define concepts that don't break currently valid code. (That's my personal prediction at least: The current standard library will be left as-is forever, and concepts will only be applied to the newly added parts) Also, if you strongly disagree with the policy paper, it would probably be more productive to write up your disagreements and communicate them to the authors of that paper, instead of just doing a posting to reddit that you disagree.
This is probably the wrong subreddit for this, since all your code is C, not C++ and the issue/feature you're referring to is platform-dependent... But yes, under both Windows and POSIX-like environments, the current working directory is completely independent of where the executable is stored. When you think about how command-line tools work (or write one), it's fairly obvious.
/r/cpp_questions
Because classic pimpl involves a double indirection, and the compiler's ability to inline that away is intentionally disrupted, so it's forced to generate an extra load instruction. 
PS: My timings are on a 4.8 Ghz intel 8700k chip using 1 thread only.
Why do you want to write same code twice?
As I told you on SO: it's verry fast.
&gt; it's really hard to define concepts that don't break currently valid code The only way I can think of to add concepts to existing library code is to allow concept checking to be switched off (perhaps even have them switched off by default). Generalizing this idea, introducing the concept of language extensions that need to be explicitly enabled (a la GHC extensions in Haskell) would allow the introduction of other features that need breaking changes.
I don't know the range in advance. It was just an example of the timings I get. One way to improve that I could think of is using a normal sort (like Introsort) and one that is optimized for a lot of duplicated values (like Tim sort) in parallel. And then return as soon as one of the two sorting algorithms is finished (which ever one 'wins').
If the question is really "how long does it take to sort 10k ints with std::sort?" then you will not get an answer here. Or better, the answer depends at the very least on the compiler (here included compilation flags) and the processor (assuming you are running on a single thread, but I guess you do if you are just sorting 10k ints). Stackoverflow and cppreference are filled with snippets that you can used to cook up a benchmark that you can run on the same machine where the haskell numbers were produced.
I'm using gcc 7.2.0 in Ubuntu. The question is more if the C++ speedup is 2x (or less), because then it's impossible to use it because of the FFI overhead. Or the speedup is 10x or more, which is substantial. I am currently benchmarking R and Python and consider what you wrote about the snippets.
I can't understand the purpose of this. Especially for pointers allocated. One can simply do the following: std::unique_ptr&lt;FILE, int (*)(FILE*)&gt; fp( std::fopen("dont_use_c_stdio", "r"), std::fclose ); if (fp) { }
If you're only sorting integers but you don't know the range, then go for ska_sort, it's probably the fastest hybrid radix sort around and even beats the spreadsort from Boost.
Could you clarify in what way you see that happening? Are you referring to downstream builds kicking off upstream builds or literally having the build set on an infinite loop? This specific instance I'm thinking of is from my github/travisci work and unfortunately neither are things I can do, so hoping you have a good third alternative.
What common compiler doesn't support pragma once ?
Thanks for the input!
Not really, I generally use the dedicated benchmark [in my sorting library](https://github.com/Morwenn/cpp-sort/blob/master/benchmarks/bench.cpp) but that's probably not the best thing around.
I'm vastly more concerned with SPECTRE. The current contract is in security software which works extensively with encryption keys. It's wide open for secret stealing currently, all the attacker needs is to get the machine to run some Javascript in theory. MELTDOWN is easy, we've already issued patched kernels. SPECTRE is a royal PITA, not just our apps but every single library we use needs to be recompiled. Painful.
I am using Meson. I think I will go with wrapdb for now. It is the natural step at the point I am now and takes less effort from my knowledge up to now. Anyway this is not going to work out of the box.
Thanks for your feedback really appreciated. I think I will go for wrapdb and meson as of now. It is what I find easier given my circumstances.
There is a difference between declaring and writing a function
the real honest answer for all these kind of questions, including gcc vs clang, is *it depends*, *you have to benchmark for your specific usecase*. [here](https://colfaxresearch.com/compiler-comparison/) is one performance comparison of compilers on numerical tasks -- results are different for e.g. [image rendering tasks](http://imagine-rt.blogspot.ch/2017/10/c-compiler-benchmarks-v2.html). The c++ code with std::sort would be simply (cfr. [example snippet at cppreference](http://en.cppreference.com/w/cpp/algorithm/sort)) std::array&lt;int, 10&gt; s = {5, 7, 4, 2, 8, 6, 1, 9, 0, 3}; std::sort(s.begin(), s.end()); using google benchmark for timing the complete code would be something like (not tested, might be prone to misleading results due to caching etc.) #include &lt;benchmark/benchmark.h&gt; static void standard_sort(benchmark::State&amp; state) { std::array&lt;int, 10&gt; s = {5, 7, 4, 2, 8, 6, 1, 9, 0, 3}; for (auto _ : state) std::sort(s.begin(), s.end()); } // Register the function as a benchmark BENCHMARK(standard_sort); // run all benchmarks BENCHMARK_MAIN(); As others said, you might get larger speedups changing the sorting algorithm to fit your problem rather than changing the language. Or maybe a combination of both would be best.
This post is depressing.... Metaclasses, I guess, by 2031? Am I being too optimistic?
[https://github.com/rollbear/variant_parse](Code)
I would be very suprised if c++ is much faster than haskel or any other programming language. If implementing sort in haskel was much slower than c++, then the library implementers would most likely write the sort function in c and call it from haskel (that's what python does most of the time)
I think the likelihood of "conceptifying" the existing standard library is somewhere near zero -- the risk of breakage is simply too high. Years of committee time would be wasted making sure no backwards-incompatible changes were accidentally introduced. Much better I think is the (AFAIK) current intention to put new, concept-aware facilities in namespace `std2`. This removes any risk of breaking existing code, and has the added benefit of allowing tweaks to interfaces based on 25+ years of usage experience (for example, changing the return types of certain algorithms). I don't know why you assume that the Ranges TS will not be merged into C++20. On the contrary, while I don't have any special knowledge, I would be very surprised if we *don't* see Ranges merged (at least the basic concepts and algorithms -- the views and actions from Range-V3 might take longer). Everybody seems to want it, and the fact that backwards compatibility isn't as much of a concern removes many obstacles.
Frankly speaking, I don't see a huge benefit from conceptifying existing algorithms. It's not that the requirements are particularly complex and at least for the errors I had to look at so far, the template call stack for the standard library algorithms didn't seem to be particularly deep.
Try armadillo for maths. http://arma.sourceforge.net
The sad thing is, I've the impression that development has slowed down since c++11 and the whole TS idea had rather the opposite effect of what was intended.
I haven't delved into the details, but I've read that spectre requires prior physical interaction with the machine before being able to exploit it through a Javascript, am I mistaken?
You will of course find opinionated fellows (such as myself) trying to express the idea that * and &amp; are grammatically bound to the name and not the type, and that const-on-the-right is more consistent across the language. However, we've probably also been in enough code-style wars in the workplace to know it's better to drop the opinion and leave it to be thought about, because at the end of the day the more important choice is to be consistent within the codebase that you're editing. However, I will also express the belief that being able to understand and adapt across these different styles will make you better at reading code in general, and _that_ is a very useful skill, because you probably read code more than you write it.
it would take much less time to just do a cp -rf of LLVM's stdlib in your own namespace and put concepts in there yourself
&gt; every single library we use needs to be recompiled Recompiled with what? With an updated (patched) compiler? Or with different compiler flags?
C++ 11 took thirteen years to make, it's why it's so big. C++ 14 and C++ 17 are in many ways point releases to C++ 11. C++ 20 will be the next big release, and it took eight years to make. That's faster than thirteen years. So things are speeding up.
Here is some C++14 code which sorts 10k random integers in the range 1-10,000: #include &lt;algorithm&gt; #include &lt;chrono&gt; #include &lt;iostream&gt; #include &lt;random&gt; #include &lt;vector&gt; std::vector&lt;int&gt; make_random_vector(int from, int to, int size = 10'000) { std::mt19937 rng{std::random_device{}()}; std::uniform_int_distribution&lt;&gt; dist{from, to}; std::vector&lt;int&gt; vec(size); std::generate(vec.begin(), vec.end(), [&amp;] { return dist(rng); }); return vec; } int main() { auto vec = make_random_vector(1, 10'000); auto start = std::chrono::high_resolution_clock::now(); std::sort(vec.begin(), vec.end()); auto finish = std::chrono::high_resolution_clock::now(); auto ms = std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(finish - start); std::cout &lt;&lt; "Sorting took " &lt;&lt; ms.count() &lt;&lt; " microseconds\n"; } Don't forget to compile with optimisation enabled. I would be very surprised if you got significantly different timings to Haskell for this sort of code. 
Updated compiler, and with special compiler flags. These have a catastrophic effect on performance, but in our case this is a thirty year old codebase, it's fine if it runs slower.
For Javascript, you can read the browser's memory easily enough. Once you can do that, you can figure out what gadgets to utilise to attack other processes. It's a non-trivial hack, but as the SPECTRE paper shows, ASLR has no effect, and a determined hacker will invest the effort. In my current contract's case, our software is facing nation state attackers. They will invest the effort, and compromise of the encryption keys and certs would have dire consequences. The only thing currently stopping them is that no unwhitelisted code is ever supposed to run on these servers, but customers have a habit of configuring their servers with custom stuff.
Thanks a ton! The R sort is twice as fast as the Haskell sort code. And the R sort function is rumored to be around 10% slower than C++. So form this estimate the C++ version would be more than twice as fast. I don't know what the Haskell FFI overhead to C is, but I will see. Maybe this eats up any speedups.
THANKS A TON! The result for my machine in 74.54 us.
nice! what's your machine if I may ask ? 
R's microbenchmark runs each expression 100 times, but after the first time the vector is going to be sorted. I imagine that rather skews your results.
&gt; Keep related functions closer together. That's right. Consider making a namespace to house functions and other items that are closely related.
Intel 8700k at around 4.9 Ghz with 4100 Mhz C19 RAM.
Just out of curiosity, what is the cpuid instruction in its rdtsc() implementation doing? It doesn't look as if its results are used in any way.
Okay, any general advice you can give for the "public", or "ordinary C++ library writer"? If I'm using the latest compilers, am I good with regards to SPECTRE, or should I do anything? And I suppose that MSVC 15.5.3, clang-5 and the g++-7 in the Ubuntu repo (7.2.x something) don't have these patches yet?
That's not the point, it's still non standard.
Aren't you calling `std::sort()` on the already-sorted array 999 times?
indeed, had corrected it a few microseconds before your post :p 
It didn't really slow down. It just almost nothing happened from 98 until the big drop of 11. Now it's more evenly spread out across more regular standards.
In the same file, I usually don't forward declare so I have to define static and anonymous namespace functions before I use them. If it's not static or in an anonymous namespace that's because it's called by another file so I just include the header I want. I don't ever forward declare in a cpp file. I just include headers because its more flexible.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I'm unaware of any released compiler with fixes yet. My general advise is not to worry. "Not your problem" for most people. Do watch out for what the STL maintainers do though, when they release an STL with a set of chosen mitigations, that's the time to apply the same mitigations to your code, if you control the binaries delivered to customers. So basically check around June/July and see what, if anything, has been done by the STL maintainers. I should say that SPECTRE based exploits involve an awful lot of work to develop, and the mild compiler mitigations likely to get chosen by STL maintainers simply make the time needed much longer to execute rather than fixing anything. In the end, it's the CPU which is defective, and fixed CPUs will eventually be released. There are flags for compiler mitigations which almost eliminate the problem, but they so do by disabling all speculative execution at every indirect jump and indirect data load which is awful for performance. 99% of end users won't need that. If you do, you are already onto deploying such fixes.
First of all, they didn't really work on c++11 for 13 years. IIRC they thought they weren't allowed to make substantial changes for a couple of years and hence only processed defect reports till ~03. That aside it remains to be seen if the difference between c++11 and c++20 will be anywhere near as big as that between c++98 and c++11. I very much hope so, but I start to doubt it. Consider: C++11 brought a memory model / support for multithreaded programming, constexpr, lambdas, variadic templates, R-value references, user defined litterals, auto and lots of smaller improvements - not to mention the significant additions to the standard library. The only similarly important additions to the language I can think of since then are improvements to constexpr, constexpr if and now concepts. I hope we will get modules and coroutines for c++20, but I believe it, when I see it. 
Does this also work with template classes? For template classes it's annoying having the whole implementation in the header, would be nice if it could be pImpl'd out to the cpp file.
Ah, I'd count Boost as the main work done first five years after 1998 you see. Tons of effort went in there, and it mostly stopped by 2005. We're still drawing down the benefits of that investment, the Networking TS entered Boost in 2003.
So, we getting `std::overload` in C++20?
I missed at least two #includes - sorry, I included another (private) header for logging that included them. Anyway, try it with the extra includes. 
I'm purely talking about the evolution of the c++ standard - with a focus on the language, as the size of the standard library is a joke anyway. But as I said, even if you count the full 13 years between 98 and 11, I don't see the kind of speedup in the evolution that was envisioned after c++11.
Okay cool! Thank you very much.
Maybe. [P0051](http://wg21.link/p0051) :)
&gt; the risk of breakage is simply too high Depends what you do. I think Iterators can be conceptified "easily" and if Boost, Chrome, Firefox, Windows and Office build with the changes then it is reasonable to ship it. Perfect safety does not exist. I mean you can go to GCC/Clang bugzilla and for EVERY release of GCC/Clang find horrible horrible bugs... but that does not mean that we should never use them. Like I said I see the committee being cautious but there is such thing as too much of a good thing. :) &gt; I don't know why you assume that the Ranges TS will not be merged into C++20. It may be, but like I said AFAIK ranges TS contains nothing beside building blocks.
&gt; The reality of this post is depressing.... Metaclasses, I guess, by 2031? Am I being too optimistic? Well if it makes you feel better after C++11 Herb told us we may get Concepts Lite in C++14. That did not make you feel better? Welcome to C++. :) 
Could you post a gist or so with the working code? I can't compile it yet. Also, do I need a specific compiler version? I tried with the g++ and the clang++ included with Ubuntu.
The haskell community is quite interested in the results. I am currently gathering all the data and code in a repository and will report back to the haskell community.
As with all things, it'll come down to what makes the library maintainer's life easier. Low hanging fruit will be picked first. I've no talk, nor planned talk, on this subject mainly as I've never deployed Concepts fully, I need - for now - to retain compatibility with C++ 14. So I have a preprocessor macro solution which expands into either Concepts or SFINAE, and that necessarily greatly limits how much Concepts I can use. I also have run into countless bugs in the GCC implementation, sufficiently so that I don't consider it currently usable. But it'll get better once the other compilers release their implementations later this year.
It sad that it has no C++ API.
I'll grant you that the language evolution is slowing down, but that's to be expected. I'm one of those in favour of a Python 3 type language break, so you mark up a namespace to say "this is C++ 2.0" and retain linkage compatibility with current C++, but otherwise it's a completely rebooted C22-compatible language without all the mistakes made in C++ 1.0. But that's a tiny minority of opinion on the committee, currently it has no chance of happening.
I just tried it in js: function test() { var q = []; for (var i=0; i&lt;10000; ++i) { q.push(Math.floor(Math.random()*10000)); } var before = new Date(); q.sort(); var after = new Date(); console.log(after-before) } Results: 10 - 20 ms. I don't get better resolution than that.
Is human readability actually important to you? If performance is important here, why not serialize to binary?
If somebody wants to see educational video that teaches kids not to use macros :) https://channel9.msdn.com/Events/TechDays/Techdays-2014-the-Netherlands/Modernizing-Legacy-C-Code
C++ continues to move from general purpose programming to niche programming. It's still one of the top 5 programming languages in terms of popularity, and therefore has a fairly liquid jobs market (though not as liquid as Java, Javascript, .NET or Python). But there's no doubt that in market occupation for newly started projects, it's well down from the 1990s. You only choose C++ for new projects nowadays if you have pressing reasons to do so. For all else, you're probably not wrong to choose Python or Java. I should say that for what it's especially good at, C++ remains unbeatable. Rust, Go and Swift have a while to catch up with C++'s maturity yet.
&gt; Having to name all your scope guard objects so that they don't conflict with each other quickly gets tiresome, We all know about all the issues with macros, and how they are mostly a tool for things you can't do any other way, and yet this is a good enough excuse? Let's not succumb to inertia here. There's no reason to have this macro at all; having a name for things is good. In your own toy example, rather than the silly name `my_guard`, the variable should be named `f_guard`: it's guarding resources controlled by variable `f`. Given how easy it is to write `ScopeGuard` by myself, this is probably enough that I wouldn't use the library; it would just encourage colleagues to write poorer code. Having to give an entity which is going to automatically run code for you a name is a very good thing, not a bad thing. Not to mention, it will be incredibly confusing if the unique name will ever fail. (Also: you wrote it quickly gets tiresome, but A better name for `scope_guard_failure` would be `exception_guard`; aside from being shorter and sounding nicer, it's more accurate: exceptions are not the only form of failure and e.g. a C style `return -1;` would not trigger `scope_guard_failure`'s destructor. Similarly, I might call `success_guard` `exit_guard` or `normal_exit_guard` instead. It seems like none of guards are dismissable, like the classic ScopeGuard. I'm not sure if all use cases can be easily handled without dismiss (though certainly most can). E.g let's say you are grabbing 2 C style resources, and using them to initialize a single C++ class that will guard both of them. You may want to get each resource and immediately create a scopeguard, then dismiss all the scopeguards after creating the C++ class. Without dismiss I think you'd be forced to factor this into a separate function returning the C++ class.
The choice of tools depend on what you are doing and that leads to the question what do you like? I like doing low-level graphics driver, rendering engine and other jobs like that so the language is a must for me (along with C, C#, LUA, GLSL, HLSL etc.) If you are not into anything that requires C++ then I don't have any arguments to sell it to you. I am not too much into web development so in the line of same reasoning I am not too much into WebAssembly, JS, HTML or anything like that. I do use those from time to time but not because I like it but because I have to and that means I probably don't do as good job with those as I do with stuff I really love doing. YMMV.
If you want to find a remote C++ position - forget about it. Otherwise, there are plenty of interesting opportunities if relocating and commuting to the office is your thing.
But it's not human-readable. 
Never heard of it before. Looks awesome, I'll take a look on it. 
After Googling for TOML alternatives, I've also found this: https://github.com/Enhex/Deco The : delimiter syntax sucks, though. Indentation could have been easily used.
&gt; WHY should I (or anyone) pick up C++ in 2018? If I were starting out today, I'd be learning C++ hardcore, because it's used for the jobs I like doing: telecom, finance, energy, transportation, other industries that make up civilization as we know it. There are also your apps like office/chrome or services like facebook/google/amazon if you're into that.. Granted, neither of those may be the things you personally like doing.
Faster than which YAML parser? I can write a slow-as-molasses deserialization engine for the "fastest" binary format out there, after all. :) "Features" of the format have little to nothing to do with performance if you're not using them. Do you have any hard measurements or samples of data and deadlines for loading? (e.g., do you need to load 10k key-value pairs in under 0.1 seconds, or what?) If you're sure YAML itself is actually for realsies the problem, perhaps you might consider Lua. It was originally meant to be a file format for _very_ large geographic data sets and only evolved into being a scripting language later. It still aims to be light and fast for loading large data sets. I don't know that Lua would be faster than a well-written YAML parser, but it's faster than a lot of alternatives at least.
I am happy to accept any decent pull request, also one introducing C++ API.
Well, I'm talking about changes in your dependencies breaking your code, because it's not resilient to those changes. So, what you end up with is source code that works, and then, without any changes, doesn't work, because you're now working off newer versions of your dependencies. Continuous builds help, because you tend to notice the problem sooner, and get it fixed sooner, so it is less likely to impact contributors. Repeatedly fixing such things helps you to establish more flexible code that can handle the typical changes that occur with your dependencies.
With the adjective syntax, I can see a huge advantage using them. We'll have constrained templates, so shrine interfaces, and we would write template function without the `template` keyword. It basically makes templates usable for beginners (almost) and with much less cognitive overhead. It see people afraid of templates but have no problem using `auto` as lambda parameter. Imagine that possible for normal functions and with strong interface. Introduce modules, and most of the time we wouldn't have to worry to move stuff into the header because everything can be placed in one file most of the time. So changing a function to a template will be to change the fixed type to a concept and add `auto`. Without the adjective syntax, sure I would use them, but it won't be as reachable or useful for beginners. It would mainly serves for library writers to ease writing constraints and beautify (or not?) error messages.
Not all resources are pointers. Try the same thing with posix file descriptors.
&gt; So you think we may get people like u/ STL retrofitting some of the old STL to concepts using "asif" rule. I am happy with that... The (current) standard library specification uses language along the lines of "this function shall participate in overload resolution only if &lt;condition&gt;". At the moment this is (basically) a directive telling implementors to use SFINAE; I expect that this could be replaced with (private) concepts or requires expressions post-'20, but that's really just an implementation detail.
I can't help but wonder why human readability matters to you.
https://godbolt.org/g/zMcxNE godbolt is an online compiler explorer, let's you pick from a variety of compilers. MSVC crashes here too but it has a few errors up front that might tell you more? 3 : &lt;source&gt;(3): error C2440: 'initializing': cannot convert from 'initializer list' to 'A&lt;int&gt;' 3 : &lt;source&gt;(3): note: No constructor could take the source type, or constructor overload resolution was ambiguous 3 : &lt;source&gt;(3): fatal error C1903: unable to recover from previous error(s); stopping compilation GCC also fails to compile but doesn't crash.
 cpp.cpp(8): error C2440: 'initializing': cannot convert from 'initializer list' to 'A&lt;int&gt;' &gt; constexpr A&lt;int&gt; var; compiles on MSVC
It doesn't for me (tested on VS2017 with latest updates). Also, this is NOT MSVC bug tracker. If you think you've found a bug post it in appropriate place. IMHO, the only interesting posts of such variety are about some program that behaves differently in all major compilers.
Interestingly, if you add the required constructor then it [compiles correctly](https://godbolt.org/g/Le56xt). The crash is still a bug of course, so it's worth reporting if you haven't already.
&gt; Having to give an entity which is going to automatically run code for you a name is a very good thing, not a bad thing. Do you propose we name every loop and conditional statement too then? They are, after all, entities that will automatically run code for you. It is useful to name outer loops sometimes (to break out of nested loops, like in Java), and C++ essentially let's you do that via labels and `goto`, but having to name every single loop would be incredibly tedious. Also, existing practice in languages that support scope guards natively (off the top of my head: D, Nim, Go, Swift) do not force you to name them. Your dismissability example is essentially correct (I assume you mean the class, once constructed, assumes ownership of both C resources), you _would_ need a separate scope for properly dismissing the guards, but it doesn't have to be a full fledged function, immediately called lambda expression does what we want: auto my_owner_object = [&amp;]{ int fd_a = /* ... */; if (fd_a == -1) { throw /* ... */; } BOOST_SCOPE_GUARD_FAILURE{close, fd_a}; int fd_b = /* ... */; if (fd_b == -1) { throw /* ... */; } BOOST_SCOPE_GUARD_FAILURE{close, fd_b}; return my_owner_class(fd_a, fd_b); }(); This has the added benefit of limiting scope of C resources. Would be even better is C++ had block expressions, but alas. The names are meh, yeah. If nothing else they are long. Naming things well is hard (which is why anonymous guard objects is a good thing, see? :P ), If it ever looks like this is going into boost for real, the names would probably be subjected to a vote.
Probably not relevant for the end result, but 10 000 elements, only 1000 different values - is that intentional?
Is std2 planned for C++20, or some later standard?
C++ is basically used where Java/C# are too slow or can't fully utilize the hardware. If you're not bumping into these problems then you probably don't need it, to be honest. Every programmer needs to understand Data Oriented Programming, and C++ makes applying these constructs relatively easy where-as getting the benefits in other languages tends to be harder.
The concept you're looking for is [current working directory][1]. There's a command on *nix, `pwd` for 'print working directory', that tells you what your working directory is. Any processes you start from a shell will start with that working directory, but it can be changed, e.g. using `chdir()`. Or using the C++ `filesystem` library you can get or set it with `std::filesystem::current_path()`. When you run software from an IDE like Visual Studio or Xcode the project settings determine the program's starting working directory will be. One of the common ways I see people stumble across the concept of a working directory is when they've written their program to work with the defaults of one of these, and then they try to move their program to something that uses a different default and their program can no longer find the files. [1]: https://en.wikipedia.org/wiki/Working_directory
I'm sorry, how is that a crash? It has gotten confused to the point where it gives up on the program, but that's not a crash. It's not even an ICE. And anyway, what's the point of reporting it here? Without any associated error messages, or even a compiler version number? 
&gt; but usually it goes terribly wrong [...] when you reach a certain program size. Indeed. Just another example of the problems with global, mutable data. Global locale, global working path, global rng state, ...
I omitted the rest of the error message: OP was asking if anyone could reproduce it, I was confirming it does reproduce and they're not crazy =) Internal Compiler Error in Z:\opt\compiler-explorer\windows\19.10.25017\lib\native\bin\amd64\cl.exe. You will be prompted to send an error report to Microsoft later. INTERNAL COMPILER ERROR in 'Z:\opt\compiler-explorer\windows\19.10.25017\lib\native\bin\amd64\cl.exe' Please choose the Technical Support command on the Visual C++ Help menu, or open the Technical Support help file for more information Microsoft (R) C/C++ Optimizing Compiler Version 19.10.25017 for x64 Copyright (C) Microsoft Corporation. All rights reserved. Compiler returned: 2
https://godbolt.org/g/ZRz5Gv 
being standard is a very rule to start with. In this case, microsoft does have a few arguments which have convinced me: &gt;We recommend the #pragma once directive for new code because it doesn't pollute the global namespace with a preprocessor symbol. It requires less typing, is less distracting, and can't cause symbol collisions—errors caused when different header files use the same preprocessor symbol as the guard value. It is not part of the C++ Standard, but it is implemented portably by several common compilers.
whys that?
Here are some ways. struct MyStruct { int i; }; void foo(const MyStruct&amp; one) { } void foo(MyStruct&amp; one) { } void foo(MyStruct one) { } void foo(MyStruct* one) { } 
The same way an int can. That's the thing with C++, structs/classes are, to a large extent, viewed the same as built in types. But I suspect you need to supply more info for your question. Or google more. Not sure this is the best place to ask.
Loops and conditionals run code immediately. I would not argue that they need names, any more than a lambda which is executed immediately and only once needs a name. Deferring code to be run until some situation occurs is another matter. And it's also another matter when your language supports it natively; C++ does not, RAII is a well understood and transparent mechanic, and that makes ScopeGuard easy to understand and reason about. Macros are a nasty language wart, if you want to use a macro there should be a very, very good reason. Avoiding giving a name is not a good reason, especially when you potentially expose yourself to weird bugs. Re dismissability; sure, I realize you could do it with an IEFE. I use these all the time for making things const or avoiding pointless initializations. But if you get an add a small piece of interface that will make it unnecessary to use them, I think it's better to have the option. I would add `dismiss` only to the classic scopeguard, not to the exception or non-exception versions. Yeah fair enough, but may as well go with the best names you can. I definitely feel like exception_guard is a very clear and not-too-verbose name. Think of naming things well as a challenge that pays off ;-).
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/7pqdb4/can_a_class_or_struct_be_passed_into_methods_if/dsj7ntv/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Class and struct are almost identical. Class had private members by default and struct has public by default. They’re equally efficient. Pass by cost reference or a pointer and you don’t have to copy the structure. I don’t understand what you mean by secure. 
Classes and structs in C++ are behaviorally identical. The only difference is that data members are public by default in structs and private by default in classes. for example struct MyStruct{ int i; }; i is public Mystruct mystruct; mystruct.i = 0; would work, whereas class MyClass{ int i; }; MyClass myclass; myclass.i = 0; would result in a compile error. 
I work remotely with C++.
I'm surprised it hasn't been mentioned, but there's a lot of legacy C++ code out there. I work on software that if it were started today, could probably be done in Java or Python, but it was started 20+ years ago, and is still being used and modified. Learning C++ will make you valuable to companies maintaining legacy code and give you the opportunity to work with cranky old farts.
Haha, seems like an absolute dream... having to solve bugs that said old fart introduced to the system in 1995. XD
we think we fixed this in 15.5 preview 2.
Hey, we're actively inserting new bugs all the time.
actually Sankel gave lecture ~5 years ago at Boostcon where he showed how crap Haskell sort perf was compared to C++ one. edit: title of the talk was "David Sankel: The Intellectual Ascent to Agda " 