One of the problems that I have with Python and similar languages aside from not teaching you all the things you and I both listed is that it doesn't force you to be disciplined in how you think about solving computational problems and you can still shoot yourself in the foot with type errors. It claims to be a clean language because there's usually only one obvious way to do anything as well as an object oriented language to help you model things in a way that fits your problem domain. That's all fine and good but meanwhile it allows you to just change both the type and value of a variable at literally any time even though that can make your code harder to understand and more error prone. Python allows you to add fields to an object dynamically that other objects of the same type may not have, allowing two objects of the same type to not necessarily behave uniformly or contain the same types of data which again can make your code convoluted and hard to understand. So where exactly is the advantage in using such a language other than uniformity across OSes, and ease of library management? There are still plenty of chances to shoot yourself in the foot: a function can add data members to an object without you knowing, a function can change the value of one of its arguments without you knowing and hell it can even change the type of that argument or one of its members which can lead to errors that a student or noob hobbyist would have just as much difficulty tracking down as some memory management error they might get in C++ before they get the hang of it and learn patterns like RAII. And all of that said it's much easier to go from a language like C++ to Python or Ruby or Lua or Java or Scheme than the inverse. And this is by no means an attack on Python in particular, I could make similar arguments against Racket/Scheme which my intro CS class in college used(and against I was a non-major taking it for fun).
I got my own game running, but get the following `cl.exe` is not found error: Starting compiler process ... Started process with PID 8760 Starting file system watcher for '&lt;MY_PROJ_DIR&gt;' ... Detected modification to: &lt;MY_PROJ_DIR&gt;\&lt;MY_SOURCE&gt;.cpp 'cl.exe' is not recognized as an internal or external command, operable program or batch file. Finished compiling "&lt;MY_PROJ_DIR&gt;\&lt;MY_SOURCE&gt;.temp.obj" with code 9009. I need to have `cl` on my path I guess.
In the example of when to use `std::move`: ``` #include &lt;utility&gt; struct U { }; struct T : U { }; U f() { T t; return std::move (t); } ``` .. why is the `std::move` not redundant in a compiler that implements the suggested wording change for CWG 1579?
I have the same question. Reviewing the trunk documentation https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html it appears that the answer is no, but maybe there's an in-development feature for this? Does anyone know of a tool that can suggest adding `std::move` calls?
Yep, "context-dependent" is the correct term here :)
It doesn't handle changing data layouts without restart, right?
Correct me if I'm wrong but I think that std::move is intended to be used when C++ is not smart enough to apply move semantics. If the compiler could know where std::move should be used wouldn't it be more sensible to force move semantics even without std::move?
Could possibly also use [variant](https://en.cppreference.com/w/cpp/utility/variant)
&gt; If you understand what you are doing nothing about the syntax is weird. Well... you should try to use more functions and arrays. For example, can you tell what this is? const int (*foo())[42]; Answer (click to reveal): &gt;!It's a function returning a pointer to a fixed-size array: `const int (*foo())[42] { return &amp;array; }`, see https://godbolt.org/z/KePmPP !&lt;
[removed]
&gt; Additionally, C++17 says that copy elision is mandatory in certain situations. This is what we call Named Return Value Optimization (NRVO). RVO is mandatory, NRVO isn't. I guess these two sentences may not be connected, but it sure seems like they are.
Clang-tidy does so, at least in some cases.
I corrected it on GitHub. thanks :)
Oh what a bummer... I thought there was a standalone Beast version as well (and there is/was) but I didn't realize it depends on boost.
You'll need to run "vcvarsall.bat x64" to set up cl with all the required dependencies. You'll find vcvarsall.bat under something like "C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Auxiliary\Build"
It is the shortest possible program that will output it's source text to stdout. &amp;#x200B; &amp;#x200B; Yes, it is empty. [https://www.ioccc.org/1994/smr.c](https://www.ioccc.org/1994/smr.c)
For me personally it achieved quite the opposite effect. I used beast in a couple of projects and now I consider never using it again because of that selfish attitude and lack of respect for both other boost developers and users. Why exactly do you think that your library is more important than all the other libraries in the change log and why should it steal the reader's attention? Are we all web developers now? Is it the only thing boost is good for nowadays? All the developers invested their time in improving their libraries and only your is worthy of extra attention? Do you want an attention grabbing war to break out in change log? It's just disgusting. P.S. If you want attention - use appropriate channels for that: blog posts, videos, reddit, twitter etc. not the damn change logs.
We have clang-format which works quite well together with some commit hooks to format on commit, a test that checks that all code is formatted. &amp;#x200B; Also the .clang-format you can just commit. &amp;#x200B; We also use a git submodule to distribute the clang format binary so that everyone has the same version
Alternatively, https://google.github.io/styleguide/cppguide.html#Reference_Arguments
Wait, this is already a feature in visual studio. Why do we need an external project for this if it is bound to MSVC anyways?
I have no experience or knowledge of flint++, but here's my opinion (from an LLVM developer) on clang based tools. I haven't dealt with clang-format in terms of reformatting code but many of the options I know are to deal with either existing code standards (LLVM, Google, etc.) with some options. If the options don't cover what you need in terms of formatting you'll need to roll up your sleeves and dredge through the history of how some formatting feature was implemented as an example. You may want to create a new style altogether to cover the rules you want to implement. If one of the rules regards *semantics* in a program, you're best off looking at clang-tidy for smoke testing a program to determine if it complies with the rules. Implementing simple checks in clang-tidy is not complicated and clang-tidy can also warn of formatting errors as you can pull location data for lexical tokens. If you're looking to implement new checks, looking at the existing checks can be very helpful. I implemented a number of checks for MISRA / JSF rules relatively quickly after the inevitable ramp-up phase of referring back to an existing check, cracking out the debugger, etc. Some programming rules can't be checked by an automated tool, so you may well need to institute code review to catch those cases.
Why don't you just check that the CPU supports it? Obviously things will crash if you try to execute a non-existent instruction
Id rather eat broken glass
Yep, the [edit and continue](https://docs.microsoft.com/en-us/visualstudio/debugger/how-to-enable-and-disable-edit-and-continue?view=vs-2017) feature has been available since vs2015. It would be nice if somebody gave an easy explanation where's the difference.
At first I thought it was Compiler agnostic, but it's bound to MSVC so it's kinda weird
As I said. Using std::bitset always works and we did not need performance
C++17 made NRVO mandatory. You can now return types with no accessible move/copy constructors, for example.
Your mistake is thinking that extra attention to beast comes at the expense of other libraries. Grow up.
I don't quite understand in the last example of why a move is necessary. If I have type T and a function returns type U, then would struct U { }; struct T : U { }; U f() { T t; return std::dynamic_cast&lt;U&gt;(t); } remove the need for `std::move`? If so, why can't C++ RVO a sideways cast? This creates a can of worms eg, imagine if f() has a template parameter T, do you `std::forward&lt;U&gt;(t)` for all situations, knowing in certain cases a typecast might make a move ideal, at the expense of situations where a typecast never happens? Do you, at this point in time, make two functions, one with `std::forward` and one without? On another note, in situations like the example in the article, I think using `std::forward&lt;U&gt;(t)` is more explicit than `std::move(t)` making the code more readable and therefore should probably be used. (If I understand std::forward properly.)
No, it didn't. It made changes to when object lifetime technically begins that has the same effect as guaranteed RVO, but nothing like NRVO is affected/guaranteed.
`dynamic_cast` is illegal there since both types are not polymorphic, and `static_cast` would be extraneous since the conversion is implicit. I don't really understand what you're getting at.
Oh right, changed to static_cast.
Earlier, I'm using it daily in vs 2010 (unfortunately).
Source?
&gt; One of the problems that I have with Python and similar languages aside from not teaching you all the things you and I both listed is that it doesn't force you to be disciplined in how you think about solving computational problems and you can still shoot yourself in the foot with type errors This is why I said it's beneficial to use both python and c++. &gt; Python allows you to add fields to an object dynamically that other objects of the same type may not have, allowing two objects of the same type to not necessarily behave uniformly or contain the same types of data which again can make your code convoluted and hard to understand. It's not really a problem in-practice. You also end up having to use the Class name if you want to modify class level, as in it's explicit. - modify attributes at class-level (which affects all instances) - modify attributes at instance-level (which affect one instance) In my experience, class level dynamic attributes tend to be uncommon. SQLAlchemy table classes are one. wtf_forms has one use. Otherwise I'm drawing a blank.
Code that can be maintained, fixed, and is understandable &gt;&gt; the fastest possible code Then again, I'm just a dumbass data science student at the end of his sophomore year
Well, I promise not to throw poo at you, unless you provoke. My brother? He'll probably do it anyway.
Try compiling both with full optimizations and looking at the resulting assembly. Also, making hunches about "faster code" without actually profiling isn't generally a good idea. Most C/C++ programmers will tell you not to prematurely optimize. You won't know where your code hotspots are until you run it with the profiler.
I don't think anyone would disagree, the thing is, I'm trying to figure out how to do both. I know there is no perfect way to code, but clear understandable code isn't really worth much if it runs like absolute garbage.
What you think is introducing inefficiency in your code and what is actually inefficient are often two different things. When analyzing the performance of something you've written, you need to find the actual bottlenecks restricting your program.
So the logic my professor used was simply that in the first scenario, we're needlessly storing the value in "r", when we could simply just return the value. Never has anyone mentioned profiling in any of my classes so far.. Thanks a lot! I'll be sure to do that with future code!
Your professor doesn't seem to know much about compilers. The optimizer will just erase the use of r and turn it into the other version. But, it's also a fairly bad example, since the version using r is just more verbose and not as simple. That's the reason not to write it that way.
Clear, understandable code is probably not going to run like garbage. You're going to find that most programming doesn't boil down to bit-level optimization techniques that might squeeze fractions of a percent of efficiency out of an algorithm.
And I'm assuming I do that with profiling as mentioned in the comments?
Yeah, you basically look for bottlenecks in code that gets called a lot.
Unfortunately he's more knowledgeable in mathematics than coding, yet he is the one teaching hands-on coding
Seeing as I'm obviously inexperienced, what exactly am I looking for? How or rather would those bottlenecks look like?
I made this batch file and put it in a place that's in my path. It should init everything for the latest Visual Studio you have, and the only thing you may have to tweak is the location of the VS installer install. By default it's 64-bit, but if you pass it `32` it'll init the 32-bit environment. I call mine "vsvars.bat": @echo off if exist "%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" ( FOR /F "usebackq delims=" %%i in (`"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -latest -legacy -format value -property installationPath -nologo`) DO ( if exist "%%i\Common7\Tools\VsDevCmd.bat" ( pushd . if "%1"=="32" ( call "%%i\Common7\Tools\VsDevCmd.bat" -host_arch=x64 -no_logo ) else ( call "%%i\Common7\Tools\VsDevCmd.bat" -arch=amd64 -host_arch=x64 -no_logo ) if ERRORLEVEL 1 ( echo Unable to initialize Visual Studio build environment popd GOTO Error ) else ( echo Initialized Visual Studio build environment popd ) ) else ( echo Unable to initialize Visual Studio build environment GOTO Error ) ) ) else ( echo Unable to initialize Visual Studio build environment GOTO Error ) EXIT /B 0 :Error EXIT /B 1
You want to look for code that gets invoked repeatedly. Once you know what code your program spends most of its time running, then you know where your effort should be directed. You wouldn't want to spend your time optimizing a function that gets called once versus one that could be invoked hundreds of thousands of time. Keep in mind, there are always exceptions.
This article is cool but it misses the elephant in the room. There are times when NOT to std::move in C++; for example on the same variable in a loop (without refreshing it in the meantime, obviously)... Now that might seem trivial so why would anybody want to do that? Oh but maybe because of the perfect forwarding pattern... Ok mistakes happen but surely this can be detected by unitary tests? Or maybe not! Some values are unspecified after a move, and in practice small things might act properly while their larger versions suddenly switch to empty at the second iteration. Now that's a problem. Because that's a bug. That should have been prevented by a non-fucked up move semantic, in the first place (see rust, for example). The article is merely about micro-pessimizations: I'm all for fixing them, but only after fixing bugs.
Thank you very much! Now I at least know where to start with digging for info
Here is a link to the assembly code with optimizations enabled. As others have pointed out it generates the same code: [https://godbolt.org/z/UideiO](https://godbolt.org/z/UideiO) &amp;#x200B; More generally its not worth prematurely optimizing until you have a good metric to profile the code with.
Thank you so much!! I was actually searching for a way to analyze the code, you saved me a lot of time
Move may have different semantics and observable side effects than copy-and-destroy. For a typical class, that would violate the principle of least surprise, but it's not forbidden by the standard.^1 E.g., as far as I understand: ... void foo(X x) { m_x = x; } Even though std::vector has a move constructor, and even if the compiler sees "x goes out of scope right away", it is not *allowed* to use X' move assignment. And I am convinced that's both intended, and that intention is good: Performance is an observable side effect, and when we need fine control over whether an expensive copy happens or not, we cannot play compiler roulette. --- ^1 ^(Compare the old copy elision rules: the compiler may freely choose whether it avoids a copy, even though that copy might have observable side effects. Such a rule does not exist for move)
Vanilla C++11 is not quite a replacement for MPL, but now we have Boost.MP11 which is a modern C++11 take on metaprogramming and a delight to use!
I do a lot of big-data processing (hundreds of GB at a time). Avoiding as much dynamic allocation, locking, disk access, and copying as you can in your hot path can be a huge win. Cache effects can make bucket containers a meaningful bottleneck. Disks are very efficient at sequential access. Non-sequential access on a spinning disk will kill you dead from the seek latency. Asynchronous code doesn’t improve efficiency, generally, it improves saturation.
A maintainable solutions is usually a solution that matches closely your problem. A solution that matches the problem closely is usually a solution that perform the solution with a minimal amount of "on the side" operations. Therefore, a good, maintainable and simple solution usually run well. Once you got that, you are good to identify bottlenecks and hot paths. Then you can profile and optimize it correctly according to your usecase. It's usually how you get to both. But, doing that has a cost. There are also cases where performance is not the goal, but precision or correctness is.
No problem... Compiler explorer is amazing.... If you turn off optimization you can see that the generated assembly is different... It also let's you compare compilers
Recent versions of clang have a warning when returning a local that's a subclass of the declared return type without using `std::move()`, as that produces a copy.
&gt; We also use a git submodule to distribute the clang format binary so that everyone has the same version That's quite clever!
Python's parser does it by having the scanner emit "indent" and "unindent" tokens, which the parser handles pretty much like a C-ish language parser would handle curly braces.
To add to the comments about profiling and checking the assembly - a lot of attempts to write optimized code by hand results in introducing some kind of undefined behaviour. This leads to people blaming the optimizer for being too buggy when in fact it is their bad code which throws out any guarantees a compiler can reason about. In other cases, it ends up being a pessimization and blocking the optimizer from doing something trivial, like copy elision or return value optimization. So for making code more efficient, first is not to get in the way of the optimizer. Don't throw away compile-time information, like types and values known at compile time, if you can help it.
I prefer to talk about c++, no politics and prejudice in the c++ world.
Yeah I thought returning an lvalue in a function with a single return statement was one of the times you really don't need to worry about moving. I think if you have branches and multiple returns then moving can be necessary.
This is also what I thought was the most shocking, just use `__cpuid(x)`, check it's at least a `Nehalem` (once, of course), and go! I don't understand how such a lazy solution can be chosen.
It's less limited than EnC. For Linux there's https://github.com/ddovod/jet-live
what if I only have one source file?
Ah there's an explanation: https://github.com/crosire/blink/issues/18
What I meant was a little different than what you addressed. And while I'm sure an experienced programmer who knows what features to avoid can sidestep the problem we are talking about beginners, some of whom are self teaching, like I did, and wouldn't have any teacher to guide them away from those things. Anyhow, suppose you have a class called Foo. Now you make two instances of this class as such: //Python a = Foo() b = Foo() //C++ Foo A{}, b{}; Now lets say we call some function bar on object a. //Python bar(a) //C++ bar(a); Now in Python this function could for whatever reason, let's say it's part of a library, dynamically add a member to a called pineapple of some unknown type for some unknown reason. If a already has a member called pineapple then you have a name collision which could become a bigger problem here. Meanwhile in C++(or any statically typed language) any attempt to do this would be an immediate compile time error because you can't add members to a class/struct instance once that class has been defined and since you can't instantiate a class that hasn't been defined, all instances of a given class have the exact same members(unless you count instances of derived classes). Now lets say you have another function from the same library that provides bar called baz which expects an object that has been passed to bar and has the member pineapple. If you pass a to it, it'll work, but if you pass it b which in the caller's mind is of the same type as a, uh oh, Houston we have a problem and don't know why. //Python baz(a) #works baz(b) #error As you can see this would be frustrating to a new programmer as they would have no idea what they did wrong because the functions they call(or don't know to call) could in theory be modifying the structure of class instances in dangerous ways. In the best case scenario unknown members are added to an object and by a function which another function from the same library might need without the caller necessarily knowing so. In the worst case a name collision could occur in which case Python is happy to let the library function override the value and type of that member at the instance level in such a way as suits the modifying library but also breaks compatibility with functions that expect an object of the class from which it was originally instantiated, possibly including its own member functions. E.g.: a.something() #error method something expects member pineapple to be a number when it's now an object of some arbitrary type Or if it's still a number its value was changed and the result of the method something is total baloney. I don't know about you but I wouldn't want to deal with that mess while teaching the basics of OOP in a beginner level programming class and I can see why instructors would opt to use a statically typed language like Java if they insist against C++.
What I meant was a little different than what you addressed. And while I'm sure an experienced programmer who knows what features to avoid can sidestep the problem we are talking about beginners, some of whom are self teaching, like I did, and wouldn't have any teacher to guide them away from those things. Anyhow, suppose you have a class called Foo. Now you make two instances of this class as such: //Python a = Foo() b = Foo() //C++ Foo A{}, b{}; Now lets say we call some function bar on object a. //Python bar(a) //C++ bar(a); Now in Python this function could for whatever reason, let's say it's part of a library, dynamically add a member to a called pineapple of some unknown type for some unknown reason. If a already has a member called pineapple then you have a name collision which could become a bigger problem here. Meanwhile in C++(or any statically typed language) any attempt to do this would be an immediate compile time error because you can't add members to a class/struct instance once that class has been defined and since you can't instantiate a class that hasn't been defined, all instances of a given class have the exact same members(unless you count instances of derived classes). Now lets say you have another function from the same library that provides bar called baz which expects an object that has been passed to bar and has the member pineapple. If you pass a to it, it'll work, but if you pass it b which in the caller's mind is of the same type as a, uh oh, Houston we have a problem and don't know why. //Python baz(a) #works baz(b) #error As you can see this would be frustrating to a new programmer as they would have no idea what they did wrong because the functions they call(or don't know to call) could in theory be modifying the structure of class instances in dangerous ways. In the best case scenario unknown members are added to an object by a function which another function from the same library might need without the caller necessarily knowing so. In the worst case a name collision could occur in which case Python is happy to let the library function override the value and type of that member at the instance level in such a way as suits the modifying library but also breaks compatibility with functions that expect an object of the class from which it was originally instantiated, possibly including its own member functions. E.g.: a.something() #error method something expects member pineapple to be a number when it's now an object of some arbitrary type Or if it's still a number its value was changed and the result of the method something is total baloney. I don't know about you but I wouldn't want to deal with that mess while teaching the basics of OOP in a beginner level programming class and I can see why instructors would opt to use a statically typed language like Java if they insist against C++.
About optimization, I answered once on Quora: [https://www.quora.com/What-are-some-common-tricks-to-decrease-time-complexity-of-C-code](https://www.quora.com/What-are-some-common-tricks-to-decrease-time-complexity-of-C-code) All steps are here: [https://github.com/topin89/raytracing/commits/master](https://github.com/topin89/raytracing/commits/master)
Write (or link to) a blog post about this, I'd read it. Might any of this stuff be useful additions to numpy/scipy as C++ extensions?
&gt; https://en.cppreference.com/w/cpp/language/copy_elision Not the most clear page on cppreference.com. It would be good if the different standards are described separately, so that the differences [between the std's] stand out as opposed to capturing everything on one statement.
Did you check this is actually what compilers do, becoz, the compiler is free to not do anything with your right-value cast (application of `std::move`)?
In this simplified case yes, on the other hand, if there is more than 1 return path, writing it that way can be a perfectly good solution, particularly if some [useful in that context] default value is set at construction.
&gt; Therefore, a good, maintainable and simple solution usually run well. Time and time again, this turns out to be true. On the other hand going for short code is not always very fast. I often find that 'boring' code [many lines that are almost the same, f.e.] **is** very efficient as the compiler probably 'thinks' it's boring as well, and that it can do much better (and goes ahead and does just that).
Thanks for the link! I decided to give it a try, unfortunately, it doesn't work, crashed after reporting an entry point address. Blink and target exe are both x32 bit. I tried another executable and it reports missing pdb or sometimes just crashes. It'd be cool if there were options like \`--help\` with the description where sources are, where .pdb directories are, etc. BTW is it possible to debug a DLL attached to a process to debug my library itself, provided I have pdb for it but I have no source for an executable?
I suppose. But it clearly never says that NRVO is required.
Yeah, yeah, don't dis-agree. It [the page] is very dense with `(C++XX)` sprinkled all over the place without any particular order or structure.
`std::move` is intended to be used when _the average C++ compiler_ cannot reasonably be expected to be smart enough (for example, because it relies on a significant amount of analysis). But there have already been plenty of cases where compilers turned out to be far smarter than the standard demands (it happens every time a compiler detects UB and makes an optimisation decision based on it). I'm also not suggesting the compiler provides a perfect and 100% complete list of warnings; just that there is a warning for cases it notices anyway but right now just ignores. Something like the example given in the other post, void foo(X x) { m_x = x; } The programmer might have overlooked it, but for the compiler this is an easy case to detect.
I don't see how it would. It just compiles and relinks the functions. I imagine any changes to data layouts would lead to crash/corruption.
Kind of, we had to put a command to update submodules into cmake in order to make it work properly but after that it works well
Actually it uses static reflection to read the attributes. Debug info &amp; co is needed to properly patch the elf relocation table of the executable (elfspy does not strictly do monkey patching directly in the executable). Also debug symbols are needed to get a good stack trace
Just remember that counting assembly instructions it \*not\* a substitute for measuring performance with a timer. A modern CPU might have quite a few instructions being executed simultaneously, so it doesn't necessarily mean anything if one path has more instructions than another: the longer path might have fewer dependencies between instructions and therefore still be faster. And the difference between the paths will likely still be dwarfed by cache misses, so a program architecture that stresses data organisation in memory is likely to be (much!) more efficient than one that focuses on micro-optimisations like removing one move or one add or something from the generated assembly. Anyway, here's an exercise. Does the following function have better or worse performance than the ones you've provided? int addition3 (int a, int b) { int \*result = static\_cast&lt;int \*&gt; (malloc (sizeof (int))); \*result = a; std::swap (a, b); \*result += a; int tmp = \*result; free (result); return tmp; } It allocates memory, so it must be worse, right? Answers here... [https://godbolt.org/z/Tv7d1S](https://godbolt.org/z/Tv7d1S) Let us know what your professor thinks about this solution ;-)
Oh, mocked functions are queried through static reflection too, It does no symbol search through the ELF, every patch is resolved at compile time (you will get an ugly static assert it you give an unknown name to [[unittest::patch()]]). the monkey patcher (elfspy in this case) takes the address of the function to patch as parameter
Care to open source the JSF rules?
Well, I guess the reasoning was: `static_cast` casts the type to `U` after which the compiler could move from it without `std::move` because it matches the return type.
Excessive asynchronous operations can actually show things down - see Microsoft's UWP where they made 1800+ API calls async, even though many of them would be 99.9% used serially / blocking and only one instance at a time - the cost of grabbing a thread (heaven forbid the pool is empty and you have to spawn a new one ) and passing parameters and results across threads only to return to where execution was paused becomes nothing more than added overhead.
&gt; in software engineering classes, efficiency is either underestimated or outright ignored. Most industries hiring programmers don't place a high value on anything beyond very basic algorithmic efficiency. The example you cited, RVO vs NRVO, is a distraction. Focus on when and how much you copy large chunks of data, and focus on pre-arranging your data so that you can iterate through it linearly in memory whilst processing it. Deeper understanding of the language is needed. Everything else is profiling and reading the disas.
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bcah5v/boost_1700_released/eks6rfd/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
In real life software engineering it's often better to make your code as readable as possible by other people than be as efficient as possible. You might shave off a nanosecond somewhere, but if it makes others scratch their heads and waste an afternoon, or delays a release because of an obscure bug, you have a net loss. In most cases the compiler and the processor instruction pipelone are much better at optimizing than you will ever be, and your choice is to write the best possible algorithm as clearly as possible.
The difference in software engineering is that most of the time you can change things down the road relatively easy. So the general rule is that premature optimization is bad. If you suspect some performance issues, you should use a profiler and then fix the root cause. Fun story: We have a XML parser using Xerces-C, which we considered pretty combat-proven and used in many projects. Later we had a project, where we had to parse XML files 20-30MB large. This took 10minutes, but was not a huge issue, because this was only done once a month. Once I tried to profile a different issue and then saw that a getter from our XML parser took 90% of the time. Turns out that we used wrong methods from Xerces-C to iterate over all elements, which itself iterated over all elements in every step. Fixed this and now parsing a 30MB file takes 20 seconds.
What amazes me most is that this happens already at -O1. I'm disappointed that GCC is unable to do the same when `new` is used instead of `malloc` (Clang can still do it). [https://godbolt.org/z/VDX4bp](https://godbolt.org/z/VDX4bp)
&gt; What ideas and concepts should I keep in mind when designing the algorithms for a program? I think in the long run it's helpful to have a basic understanding how a PC works. E.g. *why* it's usually [faster to process an array when it's sorted](https://stackoverflow.com/questions/11227809/why-is-it-faster-to-process-a-sorted-array-than-an-unsorted-array/11227902#11227902), or why [std::vector is usually faster than other data structures](https://www.youtube.com/watch?v=YQs6IC-vgmo). An approach that cares about that is Data-Oriented-Design. Here's an [introduction to DOD](http://gamesfromwithin.com/data-oriented-design), and here's a [collection of resources about DOD](https://github.com/dbartolini/data-oriented-design). But that said, while it's good to know all this, IMO it's hard enough to write readable and maintainable code. So, learn that first, and only then start to think about efficiency. PCs are crazy fast these days, compilers are great at optimizing, and the majority of code doesn't have to be optimized anyway.
You don't need to `std::tie` anymore, we have bindings. std::tuple&lt;A, B, Error&gt; foo(A a, B b); auto [a2, b2, error] = foo(a, b);
I'm wondering why with optimizations turned off it doesn't produce the same assembly code. Especially here which is the simplest NRVO case.
In this context [there is no "preferred way"](https://isocpp.org/wiki/faq/value-vs-ref-semantics). There are several very important answers behind that link. As the author says : " Please read them all to get a balanced perspective "
I don't see it here: https://github.com/cplusplus/papers/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+is%3Aopen+p0573, so somebody from the committee would have to say.
The benefits from optimisation often differ between software and mechanical engineering. I'm not a mechanical engineer, but I believe a lot of the optimisation in that field is about reducing materials cost. Either you are making a big thing, like a bridge or a building, where each item uses so much material that reducing the amount by 10% saves a lot of money, or you are making a lot of little things, where again reducing the bill of materials can save a lot of money. With software, the cost is often mainly in the human time needed to write it. Turning the written code into something that can be executed is done cheaply by the compiler, and making many copies of the final result is virtually free, so to reduce costs the thing to optimise is how long it takes a human to design and write it. Also, with modern software, the compiler will do a lot of the optimisation for you, and often the computer is so fast that further optimisation doesn't bring any real benefit. The difference between 1 and 2 microseconds often doesn't if the operation is only done once and its a human waiting for the result. And often the computer isn't doing anything else much anyway; a desktop PC will spend a lot of its time idling. There are exceptions. There are problems where even fast computers take a long time to solve, eg involving image processing with lots of pixels. Sometimes faster code matters because it consumes less electrical power, for example if it is running on a mobile phone with limited battery, or in Amazon cloud where you pay for how much you use. In practice for a lot of programmers, optimisation is a vice. It's fun and satisfying to make code run faster. It can be hard to resist doing it even in the situations where it doesn't matter. This is especially true for me because I am an old programmer with habits that date back to when computers were much slower than they are today.
I have never heard of any such proposals. When is it actually useful? Either a function is conceptually const, or it isn't.
i would be pretty angry if you take boost::random from me.... https://developercommunity.visualstudio.com/content/problem/86909/stdnormal-distribution-four-times-slower-than-the.html
&gt; EWG rejected P0573 because the SFINAE requirement interacts poorly with lambda captures, and it rejected P0644's unary &gt;&gt;in favor of a hypothetical keyword - except that it then rejected both candidate spellings of said hypothetical keyword. https://old.reddit.com/r/cpp/comments/7r9xnp/passing_overload_sets_to_functions/dsvfv7f/
I can't tell you how many walkthroughs I try to follow to get projects working that are from interpreted languages and they just never work. They always throw errors because they depends on something and that something doesn't work when I go to get it. However anytime I get a native committed executable I can just run it and it works. Interpreted languages have it so bad that I'm ticked off at the interpreted languages themselves for having such a broken ecosystem where nothing works. I hate interpreted languages because how much time I've wanted trying to get rid of error messages to go away I hate them so much.
Your mistake is thinking that attention span is infinite. After being distracted with toxic beast logs most of the readers won't have any energy or concentration left to read all the other change logs. &gt; Grow up This basically proves my point
For types you can use `std::conditional_t&lt;isConst, const Foo, Foo&gt;`, for methods I don't know.
I wonder if optimizing away new is allowed by the standard... I'm talking out of my ass here, but my 1^st thought is that in case the dynamic allocation is impossible, `malloc` returns nullptr so you're invoking undefined behavior. "It works anyway because we didn't actually try to allocate memory" is covered by UB. However, `new` throws, so the behavior is perfectly defined. I have no idea whether GCC still optimizes `malloc` away if you test the return value for null.
This is an incredibly good answer to the OP. Thank you for that!
&gt; Performance is an observable side effect, Disagree with the sentiment
Why? --- To make *my* point: Not in the wording of the standard of course - but certainly in the general meaning of the term. I would even argue: in the sense of the *purpose* of the standard term. Any protocol with a timeout and any machine with limited storage begs to differ. An unwanted copy can add a factor of N to the complexity of an algorithm. For a trivial edge case: a response arriving in after 1000 years is, for all practical purposes, a response not arriving at all.
Here is the official curated list of the changes for GCC 9 for anyone who is interested: [https://www.gnu.org/software/gcc/gcc-9/changes.html](https://www.gnu.org/software/gcc/gcc-9/changes.html)
You could also add a non const overload that is sfinae-ed out if is_const is true.
can I decide later?
Link to API returns 404.
The diagnostics stuff looks really great
Could, but that becomes: auto&amp; universal_get(){ return storage.first; } template&lt;... enable_if !is_const...&gt; auto&amp; get() { return universal_get(); } auto&amp; get() const{ return universal_get(); } At best.
&gt; very verbose syntax Can you give an example? IMO C++ is one of the least bloated languages out there. &gt; This C++ behavior can cause bad surprises for developers coming from other languages. Seriously? "This feature is bad because developers from other languages that don't know C++ at all will be surprised." That's not a valid argument.
If the caller is already controlling the context, then why can’t you use the traditional approach of two functions?
I'm not a mechanical engineer so maybe this is full of this, but I think you may be right about the difference in focus. Here's my stab at why: Mechanical projects are expensive to change, where as code is cheap to change. So MEs put a lot more into each iteration while a CE might just take a tiny change and rebuild (for free). A machine processes the output of a CE, while I'm not sure if such a thing exists for MEs. Some patterns are optimized for you in programming, so you can write what you want rather than how you want it. I think MEs have no equivalent. (would love to learn that I'm wrong) 10% efficiency in a car would have a serious impact on the product, costs, and environment while running a computer 10% less efficiently is often irrelevant to consumers. not saying it's a good thing, but I think it's true
Not having to use it.
I'm glad they are going to keep supporting #import. I use that in my on-line code generator..
&gt; If the caller is already controlling the context What do you mean?
\&gt; Can you give an example? IMO C++ is one of the least bloated languages out there. I did not say that it is bloated, but that C++ is very verbose, but at least much less verbose than Java. I guess, that it would be better to say complexity as there are lots of concepts one coming from those languages have to understand in order to be productive in C++ such as 6 special member functions, object slicing, smart pointers, const correctness and so on. It is not language criticism, but a guessing why one would hate or dislike to deal with C++. &amp;#x200B; \&gt; "This feature is bad because developers from other languages that don't know C++ at all will be surprised." That's not a valid argument. It is an assumption why someone would hate C++. The problem is that most of the time you don't want to copy an object and you don't want to pass an object by value and passing objects (instances of classes) by reference by default is the default behavior in most language that C++ makes verbose. For instance, if a pass an instance of class DataSet to a function display(DataSet dt), it will copy the whole object, while in Java, C# and other languages it would not happen as objects are passed by reference by default. In C++, to the same thing that is expected by most people coming from those languages, he would have to write display(const DataSet&amp; dt) or display(DataSet&amp; dt). &amp;#x200B; Another problem that can cause bad surprises is the object slicing that happens when a polymorphic object is passed by value losing its polymorphic abilities, for instance: &amp;#x200B; class Foo{ public: ... ... virtual void afunction() const { print("Foo"); } }; class Bar: public Foo{ public: void afunction() const { print("Bar"); } }; Here is a code that newcomers would expect to work and fails due to implicit passing by value and object slicing. &amp;#x200B; void callAfunction(Foo foo){ print("Calling method .afunction()"); foo.afunction(); } &amp;#x200B; Problem: The intent is just pass by reference, but it doesn't happen as most people coming from those languages would assume. Most of the time we don't want to copy a non-primitive object. &amp;#x200B; // Object slicing: Output will be "Foo" instead of "Bar". callAfunction(Bar()); The correct way would be define the function as: &amp;#x200B; // Passing by reference that is expected to be the default behavior // must be made explicit. void callAfunction(Foo const&amp; foo) // Or void callAfunction(const Foo&amp; foo)
Just like you learn everything else. Try to write something. Tic Tac Toe? Minesweeper? Text editor?
&gt; `int i = 5;` &gt; `i += (++i)++;` That's UB I think (definetly before C++17, since C++17 `i = i++` is well-defined, but I think `i += i++` is not, because it's just `i = i + i++` and the order of evaluation of subexpressions is unspecified).
Profiling is an advanced topic. In engineering it’s almost always better to focus on correctness first, so that’s what gets taught in undergraduate programs usually. You usually don’t even have enough time to cover fundamentals well, let alone performance. It should get touched on, however, if it’s a software oriented program.
I believe the creation of objects with malloc is fairly ambiguous in the standard, hence [this proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0593r3.html)
Are you sure? `i = i++` is well-defined in C++17, but I think `i += i++` is not, because it's just `i = i + i++` and the order of evaluation of subexpressions is unspecified?
This is highly dependent on the context and use case
Btw, works on Linux (cmake + make/ninja) and macOS (cmake + make/ninja/Xcode). As for now it is stable enough to be used in my daily work under macOS (gamedev mostly).
All the -fopt-info stuff looks awesome
Premature optimization is bad if it takes away from readability and does not appreciably improve performance. Having that intuition takes time to learn, so most people condense it down to “premature optimization is bad”.
You can start playing with Qt library if you want to make some gui application and connect some functionalities
Machine readable warnings! I vaguely remember seeing an example of nested warnings as well?
&gt; Even if X has a move constructor, and even if the compiler sees "x goes out of scope right away", it is not allowed to use X' move assignment. It is allowed, it just has to prefer copy assignment. This is why if you explicitly delete the copy constructor and copy assignment operator then move semantics will automatically be used.
Yeah, the two emojis actually used _*really*_ sapped my energy. /s
Outdated. Rules...
Sane error messages
&amp;#x200B; Hi, nana is not a very complex library, I think you will find much complex libraries. If you dont want to look closely enough, you may launch cmake gui and delete the cache to see the default options offered. User of your pack may expect to set those options too.
No.
coroutines
char8\_t, constexpr virtual functions.
The new warnings for redundant and pessimizing moves are going to be very useful for me.
The problem is people going to China put themselves at real risk of not coming back. As such they need to know that which frankly has nothing to do with politics.
The switch improvements look interesting. Does libstdc++ use the switching version of std::visit now? I know there that Michael Park article on how it can be a significant gain.
&lt;execution&gt; and redundant move warning probably. Looks good overall!
Noone is taking anything from anyone. std::regex is much slower under MSVC as well. But that does not matter as long as performance is not an issue :)
Actually nana is pretty complex once you realize how deep the dependency chain goes, this recipe version has 6. https://github.com/uilianries/nana/commit/5d86c79478c97c8123f515da4e305c156ce5216d I would call that "more than trivial" complexity if I were packaging it in debian format. For comparison, look at conan's port of imagemagick, which has 12 deps. https://github.com/bincrafters/conan-imagemagick/blob/stable/7.0.8-10/conanfile.py **This** is what I was hoping to discover by jumping into conan packaging. While it has all sorts of python abstractions to use the local package manager under the tools module, they don't use them often and opt to superseded whatever the base platform provides. Thus making it less relevant and perhaps laying the groundwork for future bugs. Like using "slightly different versions" of a jpeg library in the same project. The cmake gui is a good tip. I often avoid guis, habit. I found a CLI equivalent which is a little faster to sort through, "cmake -LAH | grep -B1 BOOL". Sample output: // Defining HAVE_BOOLEAN before including jpeglib.h JPEG_HAVE_BOOLEAN:BOOL=OFF -- // Activate automatic GUI testing? NANA_CMAKE_AUTOMATIC_GUI_TESTING:BOOL=OFF -- // Force use of Boost filesystem if available (over STD)? NANA_CMAKE_BOOST_FILESYSTEM_FORCE:BOOL=OFF -- // Enable class audio::play for PCM playback. NANA_CMAKE_ENABLE_AUDIO:BOOL=OFF -- // Enable the use of JPEG NANA_CMAKE_ENABLE_JPEG:BOOL=OFF
Sure, there are use cases where C++14 or so is not good enough. My point is rather that boost is /that much/ in many developers' mind that they #include boost in public header files, add boost to precompiled headers and what not even though in 95% it is not needed. And these 95% are an issue, especially if you have millions of lines of code to maintain. Doing a boost upgrade in our company takes ~3 months just to make sure no regressions were introduced. That is what I'm talking about. And here adding even more boost even through it's not required at all is counterproductive and a problem.
While I tend to agree, reality is that once boost is allowed in a company, it is used everywhere. By everywhere I mean also public headers, precompiled headers, forcing dependencies on other library developers. In such a case, upgrading boost takes a long time to make sure noone is affected by regressions. So yes, from this perspective, boost is forced upon many developers although it is not required in say 95% of the time. And imho this is an issue. Of course, this is not the fault of boost by definition, but boost could push also the industry to use more standard C++. I would very much like to see that :-)
they got gc yet it’s 2019 already dayyum
Are you kidding me? A French track? If its an international conference everything should be in english..
I always loved the KDE APIs. Is anyone using these professionally?
I just got done integrating KTextEditor into a scientific computing package at work so that users would have a better integrated editor for javascript/python scripts that can be injected into the solver.
Huh, interesting. Only skimmed the code obviously; want to dig in more and see how static reflection even \_can\_ read attributes (wasn't aware that was possible in C++ currently).
Very nice. I presume this is distributed internally. What are the KDE API distribution license like?
I'm not speaking about some implementation defined details. I'm speaking about the semantics defined by the standard. A conforming compiler has no choice but to apply move semantics when the source code fulfills the conditions for it to be applied. Implementations of move constructors or move assignment operators in the STL fall into two different categories (and code outside of the STL strongly should also be implemented for one of those 2 categories): either moved-from variables are guaranteed to get a specific value (typically something resembling 0 / null / empty), or they reach an unknown but valid state from which you should basically only do two possible operation: destruct, or assign a new value. And this is VERY unfortunate, because it shows that move is used for two quite different purposes with quite different end results in the context of the C++ language: ownership management vs backward compat optims. Regardless of those differences, it is most of the time an error to reuse a move-from variable (at least before assigning it to another value). So, a good solution from a language design point of view (but I recognize that C++ has backward compat constraints) is to provide move operations in the form of destructive move: that way programs cannot even attempt to reuse move-from variable, because they simply do not exist anymore. Now there would maybe be some problems for C++ to provide that, for example you can't really destruct individual members, so the whole usage model would have to be different, and I'm not sure if there could be a good solution or not. Anyway, back to the situation I described, and I was more talking about usage of std::forward so I should have written "There are times when NOT to ~~std::~~move in C++;" btw. Imagine you write a very simple template with perfect forwarding: template &lt;class T&gt; void foobar(T&amp;&amp; t) { foo(bar(std::forward&lt;T&gt;(t))); } This is perfectly fine. But the risk is that you absolutely shall not overlook the std::forward usage and its meaning when maintaining that function (and I almost did it once by putting that pattern into a mental classification of stereotypical modern template usage, rather than properly thinking about what everything does): template &lt;class T&gt; void foobar(T&amp;&amp; t) { for (auto&amp; foo: foos) foo(bar(std::forward&lt;T&gt;(t))); } The above example is both very wrong and very dangerous, because only the first iteration will yield useful results, and because you might not detect the problem early without doing extensive testing. You will not see any problem if *ANY* of those apply: * you test with only one iteration; * you test with only lvalues; * you test with a bar that has not rvalue ref overload; * you test with values that are "small" in an SSO-like situation.
I understand your point but boost _is_ standard C++. Thr fact that they supports older standard doesn't force you on supporting them. Even if boost was more modern if you have a gigantic code base upgrading it (or anything else) would cost you lots of time.
Yes, I definitely acknowledge the fact that boost is industry standard, probably more than C++14,17,... That's after all why it's so widely used.
The problem is that worrying about efficency for every little detail will drive you insane and really just distract you. Get it to work first, then use a better algorithm later on if you need to.
The KDE frameworks stuff is LGPL, just like Qt. We haven't externally distributed the version with KTextEditor yet, but that is simply because we haven't done a release since the integration work was done. The application is one that we sell, and will be distributing to customers.
If you are relying on no compiler speedups then don't use a new compiler. Could be they use move or just a new optimisation. You cannot rely on this not being the case.
Implementation of the "down with typename!" proposal. I hate those superfluous typenames :)
The flipside is an optimization that is not guaranteed is not portable. And these choices matter. Move semantics allow me to design an API where I can return an uncopyable object. An "move when the compiler fancies it" doesn't, even if that potentially applies to more situations.
You have no clue what you're talking about. You don't understand how to optimize code, nor do you understand fundamentals about building sustainable code bases. You need to do a LOT more listening.
Your professor is an idiot then.
That's really bad. Calling move prevents NRVO.
move when its' safe, as an optimisation. should be backwards compatible &gt;&gt; Performance is an observable side effect, &gt; Disagree with the sentiment
I couldn't agree more, but to be fair I can't call him an idiot yet since I know very little about programming as of yet
I don't know if anything I've said came off as rude, if so, I didn't mean it. I felt like it was interesting to see from another perspective. My tl;dr: is I think any programmer should experience both statically typed and dynamically typed languages. In practice I don't use regular JavaScript, I would write it in TypeScript. However, understanding regular JavaScript is still useful. If nothing else, there's lots of code you'll have to interact with that does just that. (For some of these (I'm not clear on when you're using a single-self-taught-user vs teach-new-students, so my replies are kinda jumbled.). Plus other parts might sound weird because I wrote it in one go -- as in some orders may feel weird)) I have to say `c++` compiler errors have improved a lot since when I was using it as a my main language. Nice :) I remember a single error that was 4-lines long, with dozens of `&lt;&gt;` because IIRC the wrong data type was used. &amp;nbsp; &gt; let's say it's part of a library, dynamically add a member to a called pineapple of some unknown type for some unknown reason. If a already has a member called pineapple then you have a name collision which could become a bigger problem here Why are you muting the class-level -- Usually that's more for shared singleton data. Usually it's better to use **kwargs`, or a `mixin`, or `subclassing`, or modifying a statically-named `attribute`, or `tuple`s, or `NamedTuples`, or even `dict`s. (I'm not expecting a new user to understand most of those, if any) If it's about a beginner not shooting themselves in the foot when being self-taught: don't they struggle as much with raw pointers, pass by-value-or-ref, const pointer vs pointer const, off-by-one errors including for(), why does STDOUT use a `&lt;&lt;` shift, namespaces in general, even to print STDOUT, clobbering current namespace by implicit imports, variable scoping etc? &amp;nbsp; If you're not explicitly using arrays, there's `std::vector` -- which adds the concepts of iterators and templates. I'll assume a classic for-loop is understood. There's still Some of these abstract iterators somewhat, but could be confusing. - loop using std::vector iterator - std::for_each - ranged based for loop, this alone has a ton of type varieties [examples](https://en.cppreference.com/w/cpp/language/range-for) &gt; dynamically add a member to a called pineapple of some unknown type for some unknown reason. If a already has a member called pineapple then you have a name collision which could become a bigger problem here. If there's a more explicit example I could give a better answer. This smells like it's not idiomatic, or, a better critique on problems with JavaScript. A factory function might be what you're looking for. Maybe an ABC. &amp;nbsp; Although it's actually useful there. You can test for features, which they client may not have. You can use a pollyfill to modify the browser's implementation -- adding features that don't exist. Ex missing the lastest addition to built in `Array`'s functions. If you can polyfill, then you're fine with `Array.foo` regardless if that feature exists in this browser. It's probably a bad (pineapple) behavior to use. (What I mean by bad, is when you create or delete an entire attribute -- whether its class level or instance level. In comparison to modifying attributes, which could be a `dict` / `object` themselves. ). More often you'll see an attribute which if set to `None` is fairly equivalent to `nullpointer`. the function `dict.get(key, default=None)` defaults to returning `None` (`nullptr`) unless you explicitly state a default to use. You'd use None if you're writing a linked list, but the current item has no next element. player_id = kwargs.get(username, None) if player_id: do_stuff() Both `None` and empty literals evaluate to False. entity_list = [] some_dict = {} So you could write: for entity in entity_list: print("spawning") If entity_list is equal to `[]`, the loop is never ran. If that doesn't sound right, JavaScript can use a lot of `c++ POD` by passing or containing `Objects` ( the `{}` literal) Below `**kwargs` represents the dictionary argument to a function. Python will give errors if you improperly call a method based on it's 1] position args, 2] keyword args, 3] arg is a dict itself You could have `class B extends A`. If you're (I forget the c++ term, overriding?) functions. Kwargs are an optional argument of `dict()` in python `object()` in JavaScript function init(**kwargs) { # here I opt-into calling the parent constructor then modify it myself. kwargs_modified = Super(B).init(**kwargs) # kwargs are mutated or used exactly like parent, # we extend that behavior in B. Create new values, filter lists, etc... kwargs_modified["name"] = "Jen" return self.init(**kwargs_modified) } One example is IE11 doesn't support a datepicker, it reverts to a plain input box. With a polyfill you implement one in javascript. Now you can treat IE+chrome+firefox as if they all did implement a date picker. In the case of javascript, rewriting logic at the class-level is important, but, it's scary elsewhere. It can be useful to transpile JavaScript ES6 to ES5. In effect, your code doesn't have to fork to a different branch based on client version. Personally, I don't write class-level mutations of the browser myself. But by using TypeScript or Bable or other modules you are implicitly. &amp;nbsp; That reminds me of mutating function arguments in the function body. You can, but, it can cause new bugs. I don't think in c++ you can opt-out of default mutability, so you're stuck with using const every time. In Javascript `const` can be misleading. It essentially is a `c const-pointer to dat`a, not a `c pointer to const-data`. &gt; **shadowing** In the worst case a name collision could occur in which case Python is happy to let the ... functions. In Python: shadowing comes into play when writing to a non-existing variable, which exists higher up (ie. global) You can force to not-shadow by using the keyword `nonlocal`. Check this example to see how it's different from `global`: https://stackoverflow.com/a/1261961 I'm trying to think of a good use case to purposely shadow in python. (or any dynamic language) Rust allows it, but I'm not totally sold. `let x = foo` in rest is similar to the `auto` keyword in `c++`. let spaces = " "; let spaces = spaces.len(); Here's another Rust snippet, output is `The value of x is: 12` fn main() { let x = 5; let x = x + 1; let x = x * 2; println!("The value of x is: {}", x); } So now you remove an accumulator (for lack of a better word) but now you have changing types implicitly. I assumed c/c++ didn't shadow, but TIL gcc has the argument: `-Wshadow` If enabled, it will throw an error when it shadows: void doSomething(int arg) { char* arg = ""; }
Your example is small, and both are comprehensible, however I'm sure you can imagine a larger, more complex example where the following is true: most companies also want to consider efficiency of *maintenance*. Overly "clever" code can be faster, but it's also a source of bugs and delays. That said, most shops using c++ are using it because they *need* it to be fast. If they wanted more easily maintained code they'd use another language, where development cycles are faster and there are more developers on the market.
It seems that only improved diagnostics are really useful for every user. The json output is awesome for tools, as long as they support it soon enough, and the range annotations for diagnostics are also a decent improvement. Other things are all useful, but applicable at a smaller scale.
Thanks for your interest. Knowing that multiple countries around the world are French speaking and that more than 2/3 of the talks are in English, could you elaborate on why you think this decision is making the event less international? This choice is not a unique peculiarity and international conferences having one track in the local tongue is something quite usual, for example with C++ Russia. Please also note that talks will be recorded and the video will be released later with the possibility of adding translated captions.
wow, that is nice! catch became too much of a beast so I just started hunting today for something small and fast. please don't let it bloat to death, and thanks!
&gt; memorizes /r/boneappletea
Apologies for the hard judgement, but to me it feels not very welcoming for non-french speakers. Especially because such tracks will probably attract people who don't speak English very well or not at all, which will make it hard to talk to others, right? Especially if talks on those tracks are of interest to me it would be very disappointing. Because you made a clear separation in topics: progress, produce, push\_forward and the progress track is completely in french i wouldn't be able to join the entire track, which seems weird?
Because the GC overhead is really missing on all those 8bit, 8MHz, 32kB flash and a WHOOPING 2kB RAM?
Nifty. Got a link?
Note that this is the third code sample from the blog, and not the "pessimizing move" example. The blog suggests to call `std::move` in this case because the return type of `f()` is the base type `U` rather than `T`. My question is why, if GCC 9 implements [CWG 1579](http://wg21.link/cwg1579). Wouldn't the `U` constructor overload resolution succeed and select `U(&amp;&amp;U)`?
Oh well. So much for that.
Sorry, I read your post too quickly. The blog actually says that the move is redundant because it will be moved implicitly if U has a constructor that takes T&amp;&amp;.
Oh that's really good to hear. So do you also ship on multiple platforms? I dread building KDE APIs on all the platforms I need to support. I don't built Qt myself either.
I was going to apply for a Junior C++ developer role in Chicago but that's closed, have only one year of professional experience in C++11/14/17 so might not qualify for the C++ developer role :(
P0732 (class as a non-type template parameters) allowing CTRE to work as intended.
One question: is std::move more performant than passing the address of an object? I don’t see how this could be but if this isn’t the case, why do we need such additional complexity?
I understand these concerns. Being welcoming to non-French speakers is indeed one of our priorities. We're working on ways to ensure the French C++ community at the conference will be as welcoming as possible. We have some experience with having international speakers at the C++ Meetups (that we organize too) and know that a surprisingly high ratio of the programmers are able and willing to speak in English and exchanging with the speakers. Our task as organizers will be to make sure these programmers meet the speakers. About the fact that non-French speaking attendees will not have access to all tracks, it is indeed true. Our reasoning is that Progress is the one track that is most likely to attract students and self-taught persons who are also the populations that is the most likely to be French speakers in the first place. We intend to make CPPP a recurring event and will definitely reevaluate this decision in the future if we find it is not working as we expected.
I think that if our company would send some people to this conference some would really like to follow the Progress track (juniors for example). They would have no use yet for the more advanced topics. I would expect french students to be able to speak English or are they not taught in English at university in France?
&gt;... how is it even allowed? The guys behind Boost don't give a fuck about that, just like me.
Good catch! Technically not completely wrong though. ¯\_(ツ)_/¯
That means you tried using `|` and it didn't work out? It's used extensively in Ivan Cukic' book so I'm guessing the scope of what you are doing is not the same?
http://wg21.link/p0634r3
Hard to read diffstyle proposal though
Donald Knuth : &gt;"We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%" Knowledge about algorithms and data structures, is what is necessary to create optimized code. Nowadays most of the "simple" "optimizations" are usually handled by the optimizer. That is why programmers should focus on creating code which is understandable and debugable. [https://en.wikipedia.org/wiki/Program\_optimization#When\_to\_optimize](https://en.wikipedia.org/wiki/Program_optimization#When_to_optimize)
It's crazy how, no matter what the platform, no matter what the name, everything you write is so recognizable. Although taking a (very brief and entirely normal) glance at your post history, your iconic faux-anti-boost posts do appear to be slightly less well received ahahaha.
I have a talk from cppcon which is entirely about the optimizer and what kind of optimizations you can expect it to do reliably. Certainly, your example will be trivially optimized so understanding that will help you realize that in that situation you should focus on clarity. Maybe the talk will be helpful; https://youtu.be/8nyq8SNUTSc
I mean that's exactly why you shouldn't use native arrays. If you want to represent some small number of same type values, e.g. N dimensional coordinates, using std array is preferable because it leaves open the option of returning by value, and just behaves more predictably in general.
The command line option to make all undefined behaviour implementation defined. Oh wait, that's just a distant dream...
Thank you very much! This is something I can listen to on the road
Orphan role seems like it can also be a big pain since you have to own the trait or the type. I have a ton of types for third party libraries that I wrote nlohmann json traits for. Having to use wrapper types as a workaround is really gross. For me personally this rule would hurt more than help.
Take a look at [doctest](https://github.com/onqtam/doctest). Most of what makes Catch nice, with far less bloat.
Take a look at [doctest](https://github.com/onqtam/doctest). Most of what makes Catch nice, with far less bloat.
Take a look at [doctest](https://github.com/onqtam/doctest). Most of what makes Catch nice, with far less bloat.
ADL of course has many issues, as far as swap goes though, IMHO the mistake is a very general one: don't conflate interface and customization points, except in the most trivial cases (e.g. a purely abstract base class). If std::swap was considered only interface, then you would have a customization point called say swap_trait. std:;swap could have been implemented to simply call swap_trait (since we're already in the right namespace), and then you would have the generic swap_trait implantation in std, and users could add their own implementations in their types namespaces. One tiny change, and the problem goes away. Anyone who is writing a library with customization points should cleanly separate interface and customization point and they will save a lot of headache.
 std::sort(v.begin(), v.end());
Fantastic. Thank you for your work. Will be following this.
It's not move semantics, it's copy elision that doesn't happen because of a move that it could warn about. Copy elision won't run the move constructor.
How would you pass the address of a local object, for example? If you can pass a pointer/reference to some object, when do. Move is needed when you can't (or when you need to express ownership).
I don't think you came off as rude at all. And I'd also like to appologize if I came off as aggressive. After reading your last response I get the feeling that dynamically typed languages and Python in particular are more sophisticated than I had thought and have features to mitigate some of the problems I had considered. In some sense though that still makes them complicated to learn. And I kind of switched back and forth between referring to students in a CS program to class and people learning independently at home. And if I could address what you said about raw pointers, off by one errors, value vs reference, and iterators and also add to that move semantics vs copy semantics, I'd say that all of those are things you have to learn eventually so why put it off? I had no difficulty with any of those things once I experimented around with them enough and I've heard others say similar things. I think we can agree that making a mistake and them fixing it is a fairly pragmatic way to learn programming because you remember the mistakes you made before and know to avoid them. I personally never had trouble with pointers because the materials I learned from explained pointers well as number that represents an address in the computer's memory which may or may not be the beginning of some object. I think C style pointer syntax confuses people because declaring a pointer variable and dereferencing a pointer look similar but that shouldn't really be an issue if the teaching material is written well.
Why are you even here@
Awesome book!
I profiled it a while ago, on gcc 8 it was already optimizing std::visit to be as fast as a switch/union IIRC
Looks amazing! Will follow this series
Also if the type has an inline, non trivial destructor. It can make a function too long and cause unnecessary instruction cache fetches.
That is not the way to think about it. Sometimes exceptions are appropriate sometimes they aren't. Names like foo do not give enough information for someone to give you advice on that, but I will try to give a few rules of thumb. First, this use of optional is a little perverse. Optional is for when you want to return a value or nothing not for storing a maybe&lt;error code&gt;. One of the important, but subtle difference between C++ and other languages is that it has value semantics. Optional is there to support the use case where you want to return a value or not. In the old days this was achieved by returning a pointer, but returning a pointer, by convention communicates that the caller will need to free the memory when it is done with it. Optional makes it clear this in not necessary. If optional is the right tool for your function the correct prototype is std::optional&lt;A&gt; foo(const B &amp;); std::optional&lt;B&gt; foo(const A &amp;); or even possibly std::optional&lt;std::tuple&lt;A, B&gt;&gt; foo(); If you really want to return an error code there are some other libraries that give better semantic that optional, but I would maintain that generally when you need to encode more information into a failure than just "this operation failed" what you want is an exception. There are really 2 types of errors: errors that are handled one layer up and errors that are handled more that one layer up. Errors handled one layer up generally do not need extra context in the form of an error message to figure out what happened. After all, they called the function that failed and thus know exactly what went wrong (maybe not the root cause, but enough to decide if they should retry or quit). It is the errors that have to propagate up the call stack that need context. Exceptions are a mechanism that is designed to do just this thing. Some C++ programmers are uncomfortable with exceptions, but this number gets smaller every day. Exceptions are idiomatic in C++ so it is best to just get used to it. If you cannot get used to it, there are languages like Go that do not support exceptions that you could use instead. Finally beware of people quoting the Google style guidelines. It seems like an appeal to authority because Google is widely respected for the quality of their technology, but their style guide for C++ is crap (it is not actually crap, but it takes someone that is an expert in the history of C++ to understand why there is so much terrible advice in it).
Yeah I really liked. Alex Allain is a talented writer. It was my first foray into the strange, mysterious, frustrating, but rewarding world of C++ and C.
Yeah I really liked it. Alex Allain is a talented writer. It was my first foray into the strange, mysterious, frustrating, but rewarding world of C++ and C.
 ##! Custom configuration, adapt to your needs set(CMAKE_CXX_STANDARD 17) Stopped reading at this point. It's not a good idea to manually set CMake variables like that. `target_compile_features(target PUBLIC cxx_std_17)` works much better because it is target oriented.
How do those libraries compare to this [expected](https://github.com/TartanLlama/expected/) lib?
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bcvrbo/professional_zerocost_setup_for_c_projects_part_1/ekuddpi/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
We only build on Linux (centos 6) and Windows. It wasn't actually bad, just calling CMake for each of the libraries in the correct order. The only real problem was getting some of the dependencies (mostly gettext) on Windows.
Fantastic; I'm looking forward to reading more. Keep up the good work!
Good to know, thank you!
Exactly. C++ has a larger cognitive overhead over other languages, making it more dangerous and error prone. You get a lot of benefits in return but it makes the language harder to work with. On top of that, C++ has rather exotic and incredibly powerful features if you delve deep enough into it. To a degree you need to be pretty intelligent to fluently work with the language.
FWIW, current maintainer of catch plans moving to a hybrid approach instead of single-header only model in some future due to a couple of reasons including compile times: [https://codingnest.com/the-future-of-catch2/](https://codingnest.com/the-future-of-catch2/)
The real question is whether it's important that the code is efficient. I'm willing to bet simpler more easy to read maintainable code is what you really want.
Here there is no point to orally argue about the safety of traveling in China. I think the way for you to seek the truth is to ask your friends or some people who have been to China before. Millions of people from different countries travel or go to seek a job in China every year. In fact there were lots of committee members coming to China to give a speech in the last three years. &amp;#x200B; All you heard about the risks or other fake news of coming to China or never going back is most likely from media, and this has nothing to do with our government. Chinese government won’t step into tourists’ visit to China, instead traveling to China is more encouraged because nowadays most of China’s first-tier cities are turning to be more westernized. &amp;#x200B; For any other countries even including yours, it is 100% safe to come back if you abide by the local laws. &amp;#x200B; What’s more, the city we invite you to give a talk is Hangzhou, a quite fascinating city in southern China known by the famous old saying “there is a paradise in heaven, while there are Suzhou and Hangzhou on earth”. I bet you will be deeply impressed if you come. &amp;#x200B; Go back to c++, I have organized some c++ meetings before, you could watch the videos here: [https://www.bilibili.com/video/av39793845](https://www.bilibili.com/video/av39793845) [https://www.bilibili.com/video/av47644468](https://www.bilibili.com/video/av47644468) &amp;#x200B; download the presentations here: [http://purecpp.org/detail?id=2064](http://purecpp.org/detail?id=2064) [http://purecpp.org/detail?id=2096](http://purecpp.org/detail?id=2096) &amp;#x200B; As all the speakers who attended the meeting were Chinese, for this time I wish the participation could be more diverse and non-national boundary. So I hope more international friends and experts could participate in this meeting in Hangzhou, China.
For C++ info, obviously (mostly where it pertains to C++20 and C++23). However, I generally use MSVC for Windows projects and Clang for cross-platform projects, so GCC is completely irrelevant to my needs.
So what about gcc excites you not to use it? Excites you enough you need others to know
May be you can me more nice on this one, for example explain why this is a bad idea. In fact the real project that use this flags use C++ filesystem in the three executables, that's not an excuse from my side, but anyway, thanks for the remark.
What can I say, I'm an excitable person.
What a confusing mess.
I think that comment is a bit overly harsh. While I generally agree, it basically doesn't matter for the language standard (as soon as you have a C++17 vocabulary type as part of a public interface ). I could also easily imagine breaking ABI changes between languages standards which could lead to very subtle bugs ...
Hello thanks you for the explanation, I will change it in the article and the code then !
Thanks.
Google's style guide in this area is so stupid it hurts.
I think [this](https://cmake.org/cmake/help/v3.1/prop_tgt/CXX_STANDARD.html#prop_tgt:CXX_STANDARD) is the correct property
It's sometimes not easy to know what a "simple optimization" is. Something might look simple but be more complicated behind the scenes. A beginner might think that passing by value is simpler and more understandable but it can lead to a lot of copying which is better avoided in my opinion.
can you just this from inside your program to write self modifying code?
Just sent a mail with your request to Herb Sutter. Stay tuned.
I would use some functions.
Stopped reading? Really? Aren't you being a little bit of a drama queen? Maybe you should be a bit more progressive instead of just disregarding anything her highness deems anything short of perfect? Nice addition, but you're a disrespectful jerk.
We should be seeing it implemented in C++26. Definitely gonna bring C++ into the spotlight!
Which CMake version added `cxx_std_17` and the rest as valid compile features? I ask because not that long ago, these feature flags did not exist, it was language features only. So if your project is not brand new, or you need to support platforms with older CMake versions, setting `CMAKE_CXX_STANDARD` is the only possible and portable way to do it.
&gt; Stopped reading at this point. Because... &gt; It's not a good idea... &lt;to do something&gt; &gt; &lt;something else&gt; works much better because it is target oriented. Wow, /r/iamverysmart much?
And what about try yourself first ? even a tiny bit maybe ?
What is?
Exactly, very well put.
Mostly, the entirety of CMake. Guess that comes with the territory.
For backward compatibility with CMake &lt;3.8 you can use set_target_properties(CXX_STANDARD 17)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bd0vgp/need_help_with_my_homework/ekv0aku/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Why would you want that, that what makes cmake 'such a mess' in the first place. Just install the bloody latest.
Looking forward for the next part. I'm coming to C++ from python (which is still my main programming language) and I feel that I spend more time messing around with CMake and my dependencies than the time I actually spend programming
That's not always possible. For a long Android builds used a Google supplied version of cmake that they'd forked from one before the 17 flag was available. Seems to be fixed to a newer version now, but who knows when you'll want something newer again?
I like the idea and I think it would be nice to be compatible with the [pitchfork directory structure](https://api.csswg.org/bikeshed/?force=1&amp;url=https://raw.githubusercontent.com/vector-of-bool/pitchfork/develop/data/spec.bs)
Hey ! It will be almost the same tree, expect that's external will be vendor in our case. But even the vendor directory will not be needed for this tutorial, dependancies will be managed by another tool !
Serialization is one case where it can be annoying. One solution is to have a generic serialization framework (either standard or widely used) that everyone uses... A more generic solution is compile-time introspection to automatically implement boring stuff such as serialization and deserialization without requiring dedicated interfaces. Bonus points if said compile-time introspection honors encapsulation, and thus only uses the public interface of a type when called from another library.
That's not modern C++ and the [Godbolt link](https://godbolt.org/z/KePmPP) is even set to use C.
Well, excuse for replying to the OP: &gt; I never found anything in C++ or C that I thought was complicated and convoluted. --- As far as C++ is concerned, I could come up with an example involving pointers to member functions. It just so happens that the syntax is arcane enough that it would take time, and I just happened to have the above demo in my godbolt scratchpad.
If you are building software for stable distributions such as Debian, Centos or openSUSE; it is easier to have two more lines of code than telling everyone you need to download the latest version for no reasonable additional benefit.
Hope more people land here and read your post. Thanks a lot
On the other hand, if everybody is pampered into using 'old stuff', we never make any progress and the world will be ruled by the lowest common denominator.
r0 is usually more readable. the diffstyle comes later as concrete wording.
That's literally the CMake documented way to set the C++ standard version once for all your targets. Check CXX_STANDARD target property docs "This property is initialized by the value of the CMAKE_CXX_STANDARD variable if it is set when a target is created." I would never want my users set my C++ standard through the command line. &gt; works much better because it is target oriented. That's your opinion. In a new project (like what the article is doing) I have full control of all my targets, and I will definitely want all of them compiled with the same standard. With as less burden config code as possible. You want to override that settings in a per target basis? Ok, set the CXX_STANDARD manually to override the global config.
It's true, could be worse. In this case the exact cases where the typename gets dropped since types are the only valid option are kind of hidden in the specification wording imo.
Fair enough.
I don't think NRVO is ever useful for primitive types. The difference you see is when the value of the expression is written to the memory location of r and then read back from memory again instead of being returned directly.
Exactly the "3%" that Knuth mentions. What happens behind the scenes is minimal compared to the effect of using more efficient algorithms and data structures. The way parameters are passed into a function is a matter of the design of the function, and should be taught as basic knowledge: [https://github.com/isocpp/CppCoreGuidelines/blob/master/param-passing-advanced.png](https://github.com/isocpp/CppCoreGuidelines/blob/master/param-passing-advanced.png).
How does this compare to [Live++](https://molecular-matters.com/products_livepp.html)?
So my implementation isn't too bad then :) `g["Block"] &lt;&lt; "&amp;EnterBlock Line (EmptyLine | Block | Line)* &amp;ExitBlock";`. I guess I could also rename `EnterBlock` and `ExitBlock` to `Indent` and `Unindent`.
But why?What does it mean that: &gt; the SFINAE requirement interacts poorly with lambda captures ? The paper proposes a smooth path between the most brief and the most detailed forms. Of course the brief form has to dictate some defaults. But to shoot down the whole proposal because of that...
&amp;#x200B; As someone beginning C++, OP has done the right step in the right direction, regarding thinking about error handling. On that note please allow me to offer some humble advice on the issue of standard C++ error handling concept, circa 2019Q1: 1. [Some C++ programmers are uncomfortable with exceptions, but this number gets bigger every day](https://www.reddit.com/r/cpp/comments/ae60nb/decades_have_passed_standard_c_has_no_agreed_and/) :) ("bigger" not "smaller") 2. Please make sure to read [P0709 R2](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r2.pdf) , then : 1. use std::exception if that fits your use case 2. or use std::errc if that fits your use case 3. or develop your own std::error\_code category 4. or develop your own error handling concept 3. if your software deliverables are not short-lived, you need to plan ahead. Please understand C++ exceptions are "going away", time table says C++23 ... there are several roadmaps documented to help in that respect, for that I might advise [proceeding this way](https://github.com/ned14/outcome). &amp;#x200B; Lastly, allow me to insert Herb's sentence here: &amp;#x200B; *"... C++ error handling continues to consume copious committee and community time wrestling with unresolved issues, over a quarter of a century after C++ exceptions were designed and implemented. "* (P0709R2, p56)
Unfortunately it is often the price you pay for maintenability. Read about "unity builds", that's how they take best from two worlds.
&gt; or you need to support platforms with older CMake versions, there is no reason to use an older cmake version. the cmake website has latest version official binaries for all platforms, which go back to decades-old linux distros.
You are wrong. While in general it is true that you should prefer target oriented settings in modern CMake, C++ standard is one of the exceptions because of ABI standard. Your whole project absolutely should be compiled using the same set of ABI-affecting flags and not doing so is a free ticket to the pain train.
If you're looking for something as close as possible to the interface of Catch but really light and thin - checkout [doctest](https://github.com/onqtam/doctest) - it is designed precisely to fill that void.
Extremely short and overuses highlighting to all hell. Also you might want to check the correct spelling of dependency ;-)
Please, feel free to come up with some *useful* code golf and post it in a separate thread here for criticism/alternative designs/modernisation. I am sure the community would be interested in countering the code of a Rust promoter/contributor such as yourself.
Good thinking here is: Including the error handling concept early, and thinking how to implement it. Using the std::option for to handle, something is "not there", situation, is the added plus. &amp;#x200B; Generally, my idea is to try to to do as much as possible with as little as possible. This Error type as presented is quite OK in that context. Nothing wrong with declaring it as type alias, by using the "using" mechanism. &amp;#x200B; Lastly yes, as you call them "In/Out" variables are most natural to implement by using standard C++ references. Some code: using my_error_t = std::optional&lt;std::string&gt; ; // A and B for the purpose of demo using A = std::string ; using B = std::string ; inline void foo ( my_error_t &amp; err_, A &amp; a_, B &amp; b_ ) { a_ = "Hello" ; b_ = "World" ; // default constructed optional instance // equals to std::nullopt err_ = {} ; } Solution usability is also important to show. void foo_test () { my_error_t err ; A a; B b; // notice the C++17, new if() syntax if ( foo(err,a,b) ; err != std::nullopt ) { std::cout &lt;&lt; "\n\nError: " &lt;&lt; err.value() ; } else { std::cout &lt;&lt; "\n\n" &lt;&lt; a &lt;&lt; " " &lt;&lt; b ; ; } } Enjoy the standard C++ :)
...what?
From Herb Sutter's parameter passing guidelines: Normal: [https://github.com/isocpp/CppCoreGuidelines/blob/master/param-passing-normal.png](https://github.com/isocpp/CppCoreGuidelines/blob/master/param-passing-normal.png) Extended (Advanced): [https://github.com/isocpp/CppCoreGuidelines/blob/master/param-passing-advanced.png](https://github.com/isocpp/CppCoreGuidelines/blob/master/param-passing-advanced.png).
Not universally true, they dropped support for HP-UX in 3.10, so we're stuck with 3.9.6 until we move everything to linux in 2-5 years or we get a compatible version of GCC compiled to satisfy [this issue](https://gitlab.kitware.com/cmake/cmake/issues/17137).
Yay, first release of boost::histogram :).
Care to explain why? Specifically regarding in/out parameters
Whauh is that fantastic? And if my project requires other directory then "server" I would still have to hack your CMake script so how is it zero-cost? :-) By the way you could do it in Bash so it would not require CMake (and Python) just to create few directories and files, and would be tremendous faster and more zero-cost than your zero-cost :-).
Yeah, I stopped reading the article and commented. Literally what I did. No drama, I am not obligated to read it until the end. I'm sorry if I came off as rude, I didn't foresee it would cause so much confusion.
You need to read the news and consider how many people are in jail in China right now on trump up charges. There has also been a massive exodus from China, of foreigners, recently due to a new and very negative climate with respect to foreigners in China. This is all the work of the government and has little to do with the average Chinese person. In a nut shell The government in China has turned evil once again. Seriously it doesn’t take much effort to keep up on current events in China.
&gt;when you get to the harder parts or try to do anything fancy But the question you should ask is does your project require those *harder* or *fancy* parts? The key with C++ is only use what you need to use. Just because it might have feature X doesn't mean your code needs or would even benefit from using feature X. *Right tool for the job* applies to the entirety of C++ as well.
After looking at the [nephtys](https://github.com/Milerius/nephtys) build system (assuming that is where these articles eventually go) build system, if I can give one possible improvement it would be to use interface libraries. One big way they can help is to encapsulate cross-cutting sets of concerns into named targets that are easier to remember, maintain, and use. Examples: Compiler warning options target_compile_options(nephtys_launcher PUBLIC $&lt;$&lt;AND:$&lt;CONFIG:Release&gt;,$&lt;CXX_COMPILER_ID:Clang&gt;&gt;:-O2 -march=native -Wall -Wextra -Wfatal-errors&gt; $&lt;$&lt;AND:$&lt;CONFIG:Release&gt;,$&lt;CXX_COMPILER_ID:GNU&gt;&gt;:-O2 -march=native -Wall -Wextra -Wfatal-errors -pipe&gt; $&lt;$&lt;AND:$&lt;CONFIG:Debug&gt;,$&lt;CXX_COMPILER_ID:GNU&gt;&gt;:-O0 -g -Wall -Wextra -Wfatal-errors -pipe&gt; $&lt;$&lt;AND:$&lt;CONFIG:Debug&gt;,$&lt;CXX_COMPILER_ID:Clang&gt;&gt;:-O0 -g -Wall -Wextra -Wfatal-errors&gt; $&lt;$&lt;AND:$&lt;CONFIG:Debug&gt;,$&lt;CXX_COMPILER_ID:MSVC&gt;&gt;:/Zi /FS /DEBUG /Od /MP /MDd /Oy- /W4 /permissive- /std:c++latest&gt; $&lt;$&lt;AND:$&lt;CONFIG:Release&gt;,$&lt;CXX_COMPILER_ID:MSVC&gt;&gt;:/O2 -DNDEBUG /MP /W4 /permissive- /std:c++latest&gt;) used in `nephtys_launcher`, `nephtys_client_shared_deps`, and probably others. This can be factored out into: # CMakeLists.txt add_library(error_settings INTERFACE) # Using namespaces causes CMake to error our in case of typos on the # consuming side, very important. add_library(nephtys::error_settings ALIAS error_settings) target_compile_options( error_settings INTERFACE $&lt;$&lt;CXX_COMPILER_ID:Clang&gt;:-Wall -Wextra -Wfatal-errors&gt; $&lt;$&lt;CXX_COMPILER_ID:GNU&gt;:-Wall -Wextra -Wfatal-errors -pipe&gt; $&lt;$&lt;CXX_COMPILER_ID:MSVC&gt;:/W4&gt;) # launcher/CMakeLists.txt target_link_libraries( nephtys_launcher PUBLIC nephtys::error_settings) You can do the same with the rest of the options, giving them concrete names that make them easier to refer to. For items which you probably want to be the same across all entities but you're not 100% sure, you can create a target like add_library(defaults INTERFACE) add_library(nephtys::defaults ALIAS defaults) target_compile_features(defaults INTERFACE cxx_std_17) And use it everywhere it makes sense. Personally I like to use targets for include directories too, like # common/include/CMakeLists.txt add_library(common_headers INTERFACE) add_library(nephtys::common_headers ALIAS common_headers) target_include_directories( common_headers INTERFACE $&lt;BUILD_INTERFACE:${CMAKE_CURRENT_LIST_DIR}&gt;) # e.g. client/CMakeLists.txt target_link_library( nephtys_client_shared_deps PUBLIC nephtys::common_headers) this also looks pretty nice if you plan to create re-usable CMake packages. See point 2 [here](https://www.reddit.com/r/cpp/comments/aenxzi/cmake_project_templates/edrcrjl/) for details. P.S. You can use the same principles as above and craft a CMake find library for noesisgui that exposes targets with correct properties that resolves to your vendor folder, or since you're already using Conan maybe make a Conan package for it. P.P.S. For anyone looking for concrete, approachable, and up-to-date CMake best practices I cannot recommend [Professional CMake](https://crascit.com/professional-cmake/) by Craig Scott enough.
Is the following code okay or not? void foo(Bar* bar); int main(void) { foo(nullptr); return 0; }; Also, what is more efficient? This: void foo(OutParam1* op1, Outparam2* op2, OutParam3* op3, OutParam4* op4) { // Do stuff }; Or this: struct OutParams { OutParam1* op1; Outparam2* op2; OutParam3* op3; OutParam4* op4; }; OutParams foo() { OutParams result; // Do stuff return result; }
Hey ! It's exactly what i'm doing today, i'm currently refactoring Nephtys so it's will look like you are pointing out.
Tell me about it. I spent the last several months getting Conan and CMake working on 5 platforms, writing ClearCase-to-CMake migration tools, and starting the process that will eventually take over the rest of our code base. I think it will be worth it, but it's hard not to envy the Java/Python side of the house.
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bcvrbo/professional_zerocost_setup_for_c_projects_part_1/ekvf2e1/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'm still not convinced GCC would be the best in terms of quality of errors messages. Take this simple example of an error you could very well make it practice: https://wandbox.org/permlink/pRdUhfTR7P0G0TtV Although the error messages in both GCC and Clang could be better, I feel Clang definitely has a cleaner, more concise way of telling you what's wrong.
For real. I'm starting to look for an alternative to Clion because it doesn't support a simple Makefile build system (without workarounds). This "[feature](https://youtrack.jetbrains.com/issue/CPP-494)" has apparently been in the pipeline for 5 years, and yeah, it's just getting ignored. I think it's time to finally move on to another IDE.
This was [discussed on Slack](https://cpplang.slack.com/archives/C2PQKRWJU/p1543949921317300). Barry Revzin (one of the authors of this paper) gave this example: &gt; template &lt;typename T&gt; int bar(int&amp;, T&amp;&amp;); &gt; template &lt;typename T&gt; void bar(int const&amp;, T&amp;&amp;); &gt; &gt; int i; &gt; auto f = [=](auto&amp;&amp; x) -&gt; decltype(bar(i, x)) { &gt; return bar(i, x); &gt; } &gt; f(42); // error Explanation: &gt; The `i` in the trailing return type is the outer `i` (it's non-const), the `i` in the body is the lambda capture (which is const) Apparently fixing this for abbr. lambdas to "do the right thing" by having the trailing return type refer to the lambda capture makes implementers uncomfortable: &gt; [Fixing this] would involve effectively doing sfinae on the body and implementers did not like that
The 4 output parameter strawman is a bit odd. Where did that come from? Who is advocating for a function that takes 4 pointers? They didn't I see &amp;myFoo at a call site and my project is following a style guide like Google's, I can reason that myFoo is an output parameter. It's self documenting. On the other hand, if I just see myFoo, I can't tell what's happening just by glancing at the function call. Also, I'm not arguing for using in/out parameters. For some reason if you are using one, I like the style that Google chooses to use over the Core Guidelines' take on it. And if you're worried about someone passing a nullptr as the out parameter, we have assertions for that 😉
One nitpick: I've more often seen "tests" (plural) than "test" on projects. Which makes me wonder if that ever had to do with "test" being a function/keyword of all shells.
I cannot spoil you, but this is volunteer, you will see in two articles why the name of the folder is test and not tests
Could you please provide some links or other sources? As a foreigner living in China I'd certainly like to be aware of these.
Warnings should theoretically go into toolchain files.
Welcome to the world of c++. Where spending more time on the build system, deps, ... Not-programming... Happens a lot. And solving things can take days instead of hours or minutes.
&gt; The 4 output parameter strawman is a bit odd. Where did that come from? Who is advocating for a function that takes 4 pointers? Nice way to dodge the question there. If it makes you feel any better, the question is just as valid for one return value/out parameter as it is for four. So please, answer the question. &gt; They didn't I see &amp;myFoo at a call site and my project is following a style guide like Google's, I can reason that myFoo is an output parameter. It's self documenting. Or maybe its an input parameter where nullptr is a valid input. So you haven't really gained anything, you have just moved the problem. &gt; And if you're worried about someone passing a nullptr as the out parameter, we have assertions for that 😉 And what if this function is used in a very rare execution path that isn't covered by tests? Now you have a crash in prod for something that shouldn't even compile. IMHO, it's far superior if you NEVER have output parameters. Either you return outputs, or you wrap your data in a class and only allow modifiers to modify the internal data. That way you ALSO know that a function argument never modifies the data, because they are STILL only ever passed by value or const ref/ptr. And you can have static analysis tools to detect any unsafe (I.e. not null-checked) pointer dereference. Ironically not Google's own tool Clang analyzer, which assumes that pointers can't be null unless you do null checks on them - I guess they had too many false positives due to their coding guidelines mandating passing out parameters by pointers instead of references..
:) IIRC my introduction to pointers wasn't a book or teacher -- it was using the internet. (as in: lots of partial or lacking information) &amp;nbsp; Earlier I mentioned c++ errors having improved. Now that I think about it, I'm not sure if the web compiler was using **gcc** or **[LLVM + Clang](https://llvm.org/)** -- In Rust you can use either. Maybe mine default to LLVM &amp;nbsp; I used to be familiar with the c++ rule of 3 and rule of 5, but, I'm rusty. Can you explain move semantics ? I thought it meant something where you're using a single resource that can only be owned by one resource. You move the ownership to another instance, invalidating the first ? I've also heard it's not special/new, under the hood it's re-casting for you? &amp;nbsp; A quote from the rust version &gt; from: https://doc.rust-lang.org/1.17.0/book/ownership.html &gt; Which means that there would be two pointers to the contents of the vector both pointing to the same memory allocation on the heap. It would violate Rust’s safety guarantees by introducing a data race if one could access both v and v2 at the same time. &amp;nbsp; Have you tried Rust? You might be interested. I've only started - but it has a nice toolchain. Compilation errors are so informative. - variables default to immutable, you have to opt-in for mutability - For packages: you can say "give me the latest version of this package that follows 1.3.4". Meaning it won't break your code. You don't have to worry about linking, or manually installing header files. You don't have to pollute a shared include directory with extra libraries. [Some languages (like python `venv` ) call this a virtual environment](https://docs.python.org/3/library/venv.html#module-venv). - Example of trying to use a reference to a value that left scope: https://doc.rust-lang.org/1.8.0/book/references-and-borrowing.html#use-after-free If using VSCode, make sure to get the extension: [Rust (rls)](https://marketplace.visualstudio.com/items?itemName=rust-lang.rust)
Yet for some reason people still don't get why single file libraries are a big deal.
If your project is c++ only, you can specify that in project() command. project(zero_cost_project CXX) It will get rid of identification and checks for C compiler.
Absolutely!
If performance is that much of a concern you shouldn't be using std::iostream at all.
Well I'm convinced. Time to go shopping for KDE libraries.
You could always give [Meson](https://mesonbuild.com) a try, it's been adopted by several Linux projects moving away from autotools.
I had the same goal for my own projects and came up with this \[cmake project template\]([https://github.com/tarberd/cmake-project-template](https://github.com/tarberd/cmake-project-template)). Give me a PM if you would like to colab!
I think that's fair and we probably end up with a nicer model for re-use from an individual developer perspective. Toolchain files would be formatted like # GNU.cmake set(CMAKE_CXX_FLAGS_DEBUG_INIT -Wall -Wextra -Wfatal-errors -pipe) # Clang.cmake set(CMAKE_CXX_FLAGS_DEBUG_INIT -Wall -Wextra -Wfatal-errors) # MSVC.cmake set(CMAKE_CXX_FLAGS_DEBUG_INIT /W4) which would then be used on build system generation like e.g. cmake -DCMAKE_TOOLCHAIN_FILE=GNU.cmake .. Nice things about this IMO: * this is completely independent of the project and could be used with any CMake project * easier to extend to other compilers vs the approach I suggested above where a consumer would need to read and edit the CMakeLists.txt * this enforces that the flags apply to all compiled targets, which may not be true if someone added a target but forgot to link `nephtys::error_settings` Downsides: * if you're already using `CMAKE_TOOLCHAIN_FILE` for something else, I guess this gets in the way - this can be overcome by using `CMAKE_PROJECT_&lt;PROJECT-NAME&gt;_INCLUDE` instead (we are using the former for the output of [`conan_paths`](https://docs.conan.io/en/latest/integrations/cmake/cmake_paths_generator.html) but can switch to the latter no problem since we know the project name when constructing the cmake command-line) * this neglects the desire of the project maintainer to be transparent or "enforce" a specific behavior - if it's that important then they can probably add these files to `cmake/` and explicitly `include(cmake/${CXX_COMPILER_ID}.cmake)` after calling `project()`
Sure, you can pick and choose diagnostics where clang is way ahead of gcc, but there are cases where it's the other way around. I've seen just clang "beating" gcc just as many times as I have seen it the other way around.
That's not universally true. There are very good reasons why older CMake versions are required. Not everyone has the ability to install the latest version. Sometimes it's because CI systems are fixed to specific versions. Sometimes we're contractually obliged to support exactly what is provided by a specific version of a specific linux distribution. Or for regulated products, such as medical devices, every tool and library is fixed at specific versions for the supported lifetime of the device. In all these situations, the individual developer does not make the choice on a whim. It's managed as part of the product lifecycle and can't be changed without the appropriate approval and (where required) the necessary documentation and regulatory paperwork and revalidation work.
Could you go over single include headers with this file hierarchy structure?
This is off-topic; please stop.
Just so you know, the compiler optimizes much more than what you are suggesting. It can omit the function call completely and perform manipulations on the stack frame of the caller. I wouldn't even bother trying to optimize, just write clear code and then profile.
&gt; The performance of any map depends on how good the hash function is. But even worse for robin_hood, for a really bad hash the performance will not only degrade, the map will simply fail with an exception if not even doubling its size helps. So choose your hash well. (Note, that some std::unordered_map implementations fail as well with bad hashes). Is this quote from your README still true? When I run the benchmarks your table seems to come up on top for all 5 hashing frameworks, including identity
You basically get this enforced, at least by the gcc, by the attributes [[ gnu::pure ]] and [[ gnu::const ]]. I suggest googling “GCC function attributes”. I wouldn’t be surprised if clang had analogous attributes too.
[The right operand is sequenced before the left operand](http://eel.is/c++draft/expr.ass#1.sentence-5)
How did you make the iteration order determenistic?
In addition to what everyone else has said about the optimizer and profiling, consider that the first step in thinking about performance is figuring out whether thinking about performance matters at all. If you are writing a a glorified “Hello, World”, then the cost of running your program is dwarfed by the cost of reading it from disk and the OS starting up a new process. It will be literally impossible to pick out the impact of doing an extra copy, even in unoptimized code.
You should watch this video: &amp;#x200B; [https://youtu.be/nXaxk27zwlk](https://youtu.be/nXaxk27zwlk) &amp;#x200B; It will show you how to measure your code speed and identify bottlenecks. You'll need to be able to read assembly to answer your question in full generality.
Thx
This is depressing to hear.
Which is fine if you're working with something completely stand alone, but not applicable if you're working with something that already has a different build system, which I would bet it's the majority of things to work withm, specially juniors. Either a project that already its build system or some kind of SDK
Hum, it is deterministic by default. If you insert the same sequence of values, and then iterate through the map, you'll get the same order every time you run the program, unless you do something specific to prevent this from happening. Abseil (and phmap if you #define PHMAP_NON_DETERMINISTIC 1) mix the hash with the memory address of the table, which is itself typically randomized thanks to [ASLR](https://en.wikipedia.org/wiki/Address_space_layout_randomization)
I use Rust and I love it but I remain 'sober' enough to realize that no tool is perfect for everything. That said, I even bought a hard copy of the book to support it's continued development. AFAIK rustc always uses LLVM as its backend but until recently the LLVM linker wasn't fully functional on all platforms so you needed either the GCC(ld) or MSVC(link.exe) linker to link compiled objects into binaries and static libraries. The same was true for the LLVM based clang and clang++ compilers as well. Since I use Windows I could choose either but I choose to use the MSVC linker for both Rust and C/++ since I already have the Visual Studio toolchain installed and don't want to deal with MinGW-w64 or Cygwin. So move semantics(which I also learned about from Rust) as I understand it have to do with the scopes of arguments passed to a function or operator. When you call a function(or use an overloaded operator defined as a function) you pass arguments for each parameter that the function expects, that's pretty basic stuff that any programmer knows. Now C, C++ and the overwhelming majority of programming languages have use what are called copy semantics by default. This means that when a function is called you can think of it as creating a new scope for the function body, making variables in that scope for all of the parameters that function expects and then copying the arguments passed for each parameter into the variables that were previously created. Move semantics can in some sense be thought of as the opposite of copy semantics. Under move semantics, instead of copying arguments from the caller's scope that are passed as arguments to a function into that function's scope, those arguments are moved into the callee's scope. In other words those variables no longer exist in the caller's scope because they've been moved. Here's an quick example in case that didn't make sense: //C/++ //Here's the declaration of a function void foo(int, double); //some test variables const int x{5}; const double y{3.14}; //we call our function foo(x,y); /*and we print our variables which we can do because they still exist and accessing them is a perfectly valid thing to do*/ std::cout &lt;&lt; x &lt;&lt; " " &lt;&lt; y &lt;&lt; "\n"; //Rust //Some function fn foo(a: i32, b:f32) { //some function body } //test variables let a: i32 = 5; let b: f64 = 3.14; //call test function foo(x,y); print!("{} {}", x, y); //error: use of moved values So basically when we called foo in C++ it copied the values of x and y into new variables in the scope of foo. When we called foo in Rust it moved x and y into the scope of foo so they could no longer be accessed from their old scope from that point on. If you pass a literal to a function as an operand to an overloaded operator I don't believe there's any difference between copy semantics and move semantics. But I'm not 100% on that because I still don't completely understand C++'s std::move and r-value references yet. In Rust if we want to keep move semantics but add the ability to copy a type manually, we can implement the clone trait for that object and copy it manually using its clone method. If we wanted a type to not have move semantics at all and to always be copied we can make it implement the copy trait(which requires the clone trait to already be implemented) and that type will have copy semantics just like in C or C++. Move semantics do complicate things in Rust especially as pertains to lifetimes but IMO they do help enforce correctness especially in the form of the RAII pattern.
In my experience, blink is considerably less restrictive than edit and continue. There are many cases where e&amp;c just gives up whereas blink happily carries on. I don't know how well it would work in a project that didn't previously use it, but starting a new project with it was a phenomenal experience. Only major drawback for me is that it doesn't (currently) do anything about dll changes.
Having used blink and only looked at live++, it seems like live++ is basically a more mature version of blink. However, blink is FOSS, live++ is subscription based. If the community were to really get behind blink, I imagine it would surpass live++ fairly quickly.
Experience taught me that maintainability is, indeed, way more important than speed in 99% scenarios.
It depends on how you do it. If you're changing heap allocated data, yeah that will require a restart (which isn't really something you can get around without deeply tying it into your app/all of your memory allocations). But temporary stack allocated data structures are fair game. With a bit of modification, it should be totally possible to have functions called before and after a code reload in case you want to serialize/deserialize your data though, which would solve the problem.
The last example in the article is ``` struct U { }; struct T { operator U(); }; U f() { T t; return std::move(t); } ``` The post claims that the `std::move` is NOT required here. That's correct. There is no need to convert `t` to an rvalue, because the program won't act any differently no matter whether it's an lvalue or an rvalue. The behavior is ALWAYS to call `T::operator U()`, which returns a prvalue of type `U` which can be copy-elided into the return slot. If `T` had had two different overloads of `operator U` — say, `operator U() const&amp;` and `operator U &amp;&amp;` — then the `std::move` WOULD have been significant. In that case it would control which of the two overloads got called. See https://wg21.link/p1155 for more information on that case.
They will know some English for sure, but not everyone is fluent. Making it in French gives more accessibility to them (and less to you, I get that).
&gt; "There are only two kinds of anything: the ones people complain about and the ones nobody uses." It works for everything, not just languages.
&gt; On another note, in situations like the example in the article, I think using `std::forward&lt;U&gt;(t)` is more explicit than `std::move(t)` making the code more readable and therefore should probably be used. (If I understand std::forward properly.) Definitely, *definitely*, **definitely** not! Don't *ever* use `std::forward` on something that's not a forwarding reference! I guess `return static_cast&lt;U&amp;&amp;&gt;(t);` would be acceptable, but as a reader, I would wonder what the heck you were trying to do with that clever code. For example, I would wonder if you really meant `static_cast&lt;U&gt;(static_cast&lt;T&amp;&amp;&gt;(t))`, which means something completely different.
But U doesn't have a constructor that takes T&amp;&amp;. U has a constructor that takes U&amp;&amp;, which is a different type from T&amp;&amp;. Therefore the `std::move` is not redundant. This is actually a terrible example because both T and U as written are trivially copyable. The blogger should have given them some non-trivial data members, like a `std::string` or something. https://godbolt.org/z/qzeM-6
\*\*Company:\*\* River Oakfield \*\*Type:\*\* Full Time, On-going contract, remote working. \*\*Description:\*\* Do you want to be an integral part in creating breakthrough technology for a cutting-edge cyber security company? Are you passionate about coding and enjoy solving difficult problems? We are looking for a Software Engineer with at least 3 years of recent C++ experience to work on building our next generation of security software for Windows. You will be working on our platform which collects metrics and activity from endpoints, such as event logs, file accesses, registry changes, network connections, resource utilization, etc. Other features included are similar to anti-malware and firewalls, like tamper detection, activity blocking, self updates, etc. **BE WARNED!** This project is not for the faint hearted. Our ideal candidate will “enjoy” reading obscure documentation, fighting legacy bugs in older versions of Windows and be intimately familiar with “trial by fire and error”. Not to mention weird compiler errors. **For this contract you must have;** * At least 3 years C++ experience * Proficiency with related Windows libraries, frameworks and tooling. * Strong understanding of C++ development methodologies * Ability to write clean, professional code * Excellent communication skills, both written and verbal * Ability to work both alone and as part of a team. * Strong work ethic and a natural love for technology \*\*Location:\*\* River Oakfield (ROAK) is a global provider of tailored cyber security solutions. We help enterprises and business leaders defend against digital attacks through a holistic range of products and professional services. We provide security coverage to a diverse client base, including S&amp;P 500 companies, financial services and private clients, powered by our world-class globally distributed team and proprietary technology. ROAK features a positive work culture with fantastic growth potential and adheres to a high standard of employment equity, while promoting a culture accepting and encouraging of diversity. Our main headquarters are in London, UK and Las Vegas, NV, USA. \*\*Remote:\*\* Yes. Or at our Las Vegas HQ. \*\*Visa Sponsorship:\*\* No \*\*Technologies:\*\* Experience in any of the following areas is highly desirable; * Event Tracing for Windows (ETW) * Windows Driver Model (Kernel Mode and User Mode) * File System Minifilter * Windows Event Log * High performance and low latency code * Compatibility with Windows Server 2008 SP2 and above * Anti tampering mechanisms * Secure by Design aka Defensive Programming \*\*Contact:\*\* If you are interested in taking on this challenge, please send an email to [cal@riveroakfield.com](mailto:cal@riveroakfield.com) with the following; * Brief cover page telling us about you and what excites you about this opportunity * Link to your GitHub or BitBucket (if applicable) * Link to your LinkedIn or resume * A link to your favourite XKCD and/or Software Engineering meme * An example of C++ code you have written (GitHub or Gist only please)
woo
&gt; Definitely, definitely, definitely not! Don't ever use std::forward on something that's not a forwarding reference! Oh.. okay.
To answer your question, they're the same because of RVO. But again, nobody here is advocating for this example of in/out parameters. I guess we're done here because I'm not going to dissect every contrived examples of where this style could lead to problems. It works for Google, and I posted it as a discussion point for an alternative style for in/out parameters.
Unrelated to GC, but at this point, my gut feeling says that C++ should be forked. It seems to me that the C++ ecosystem is held hostage by these puny platforms and whose vendors aren't going to implement the full standard anyway. Yet the language takes the toll as if they are going to implement it in their compilers.
The robin_hood hash itself is ok, and in practice when my table uses it, it has never failed and the likelyhood is extremely slim for a failure. We've been using the hash in production for quite a while and never saw an issue with this behavior. But if you use an extremely bad hash, [like this](https://github.com/martinus/robin-hood-hashing/blob/724d455a3c20aa6579d63f866f6b831f8094538a/src/test/test_random_insert_erase.cpp#L317) that always returns the same number regardless of the input, all values will hash to the same bucket. When one bucket has 127 entries the map will fail and throw an `std::overflow_exception`. Before that happens the map tries to double its size, for any reasonably good hash function this would resolve the problem, but not so for an extremely bad hash.
How about you put a bit more effort into making a significant post instead of spamming us with endless 30 minute effort posts.
I've said it before and I'll say it again. Forking the language is the worst thing one can do to C++. Think about what happened to python. Statistics say that despite 99% of libraries being python3 capable, only 30% of package downloads are for python3. In C++ it would be even worse. If you just create a zero-cost fork and keep support for those tiny systems, you would prevent a ton of cod from ever being updated and thus you're turning your back on a large part of C and C++ developers. It would only be worse if you shove GC and a VM in there, because you'd also be turning back, not just on the tiny embedded systems, but every system whose performance is top priority. I do have a couple of MCUs that fit the above description. Guess what, my compiler of choice is the latest GCC. Are you telling me that, in case of a fork, I won't be able to upgrade my compiler... ever again? Not to mention that there is a fork just like the one you want. It's called D. It's used bt... perhaps only the language designers.
&gt; To answer your question, they're the same because of RVO. For one parameter, yes. For multiple (where I would assume people actually start thinking about out params instead of return values), RVO makes returning by value cheaper. &gt; But again, nobody here is advocating for this example of in/out parameters. You asked why I think Googles style is stupid. I answered. I guess we're done here because I'm not going to dissect every contrived examples of where this style could lead to problems. We have very real problems in a very real codebase due to passing pointers around but assuming they can never be null. I guess other companies do as well. Tony Hoare, inventor of the null pointer, has called it a "billion dollar mistake". The examples I mention are far from contrived. It works for Google, and I posted it as a discussion point for an alternative style for in/out parameters. A discussion point you yourself seem unwilling to discuss?
How about reporting you ?
What about parsing C++ with inline python? py::exec(R"( x = get_answer() if x == 42: print('Hello World!') else: print('Bye!') )", scope );
? That’s not a great attitude towards the community you want the attention of so badly. Just asking you to put in effort before posting.
Well, I'm open about constructive commentary, you are the kind of guy who ruin the community.
I can't for the life of me think of a reason for ever writing the above code. How could it ever be valid for U to have a moving construct from one of its subclasses? The code is the school book example of explaining slicing. Am I missing something?
Even earlier, probably at least vs 2005 iirc. I remember one programmer in particular around 2008 which tried to convince others that it was a great feature. Problem was it only worked ~90% of the time, the remaining 10% of the time you spent tracking down a bug which didn't exist, forcing you to do a complete rebuild to be on the safe side.
C++ is hated because it is difficult to become experienced in it (not due to complexity but due to high number of features) and in the same time it is also very popular and highly used, making people feel frustrated, inadequate and helpless.
&gt; constructive criticism Don't spam the subreddit with low effort posts. Put together the whole thing and then post a link. This was basically "use cmake".
Well you don't understand the concept of series article then. Anyway 94% upvoted, maybe change your mindset ;)
Now that’s just plain C++ syntax. Or do you mean C++, but all raw string literals must be valid python? In that case you just stick the Python parser into the C++ parser, where the inner raw string parser would belong. :D
I think I've read somewhere that future versions of gcc (or rather libstdc++) will no longer need `-lstdc++fs`. Correct?
&gt; It would only be worse if you shove GC and a VM in there, because you'd also be turning back, not just on the tiny embedded systems, but every system whose performance is top priority. I never said anything about shoving GC and VM in there. I "only" want cross-compiler, cross-platform portable object code assemblies. Like the .net ones. An intermediate format that can be produced and consumed by all conforming compilers, and that the platform tooling turns into machine-specific instructions at link-time. But somehow, whenever I mention this, someone pops up and complains about "microcontrollers".
IMO what C++ ecosystem lacks is a tiny and simple logger **facade** which could've been used in both libraries and applications. All loggers I've seen so far try to bring their full infrastructure.
looks nice, I might use it in my side project. but why is it header only? Is it going to add a minute to my compile times?
I am using deus: https://github.com/ajmwagar/vim-deus
This one is not too bad, but the background is so bright. I think I prefer my background really dark, actually even 100% black, but there's like none of those.
True, surrounding pytho in `R"()"` does make it "just" C++. However vim's scripting language does allow inline blocks in a way that linters can't cope with. https://github.com/vim-jp/vim-vimlparser/issues/33 Extra fun: `EOF` isn't special and can be replaced with anything. Extra extra fun: The same is allowed for perl/tcl/ruby/mzscheme/lua and all of them are allowed to alter vim's global state.
Why don't you make your own? My theme is always a variant of CodeBlocks' dark theme: black background, white text, keywords in light or bold deep blue ( depending on the screen ), operators in bright red, preprocessor in bright green and comments in grey.
&gt; An intermediate format that can be produced and consumed by all In other words, a standardized AST. That's a whole other story. This idea isn't new, but there are reasons why a standardized AST would be bad. AST's are volatile creatures that break backwards compatibility all the time, in order to allow better optimizations. Standardizing it means setting AST layouts in stone. The other problem is... whose AST should be chosen as "the correct one"? MSVC back in 2013 didn't even have an AST (I don't know if the situation has changed). Clang and GCC, I believe, have incompatible AST's, but again, they are constantly changing.
I like Mariana, but that's probably not dark enough for you I suppose.
HOWEVER I recommend looking at this website for ideas! https://vimcolors.com/
Are you kidding me? 1 out of 3 tracks in the local language? Absolute scandal.
sorry, but I see no excuses in such a terrible performance. it's getting worse with each release. this tool should simplify the life of the developer, and not vice versa. they add so many unnecessary features to the IDE, instead of fixing the performance of the intellisense for example.
Sarcasm is a blessing
[https://www.youtube.com/watch?v=pfUmW\_Mf5qc](https://www.youtube.com/watch?v=pfUmW_Mf5qc)
Yes, it is already the case as of GCC 9.
I believe these are/will be fixed with ranges
That's why most hardware intrinsics are unsafe in Rust. If you run them on hardware that does not support them, the behavior is undefined.
I'm not sure I fully understand what's going on here. So after `A &lt;&lt; B` anything up to the `B` gets taken as input for `A`? Even if `A &lt;&lt; B` is the value of a variable that is executed? That's horrible. xD In that case, it's impossible to separate the parsing and interpretation logic. In lars::parser you can actually get this behaviour if you add program logic inside grammar filters that in turn influence the parsing process. Then again that is such a confusing thing to do.
&gt; I'm not sure I fully understand what's going on here. So after A &lt;&lt; B anything up to the B gets taken as input for A? Even if A &lt;&lt; B is the value of a variable that is executed? Not quite. After `A &lt;&lt; B` everything up to `B` gets taken as input for `A`, if and only if `A` is one of interpreter commands. The set of interpreter commands is: - `mzscheme` - `python` - `python3` - `pythonx` - `perl` - `ruby` - `tcl` The problem with parsing this, is that `exec` evaluates an arbitrary string. If that string happens to be one of the interpreter commands (from the above list, then `A &lt;&lt; B` expression is valid, and we have an inline block in another language. This is disregarding that some installation of vim may have not been compiled with every interpreter that vim supports. &gt; That's horrible. xD For parsing? I absolutely agree. &gt; In that case, it's impossible to separate the parsing and interpretation logic. I believe this is the case for vimscript.
But that can't be fixed in the current syntax, either?
Indeed. And they now seem to be in stiff competition over who can have the best diagnostics. As a user of the compilers, I think this is rather wonderful.
&gt;| That's horrible. xD &gt; &gt;For parsing? I absolutely agree. Also for reading and maintaining code. It basically means that after the first `exec some_variable` I have absolutely no Idea what the code below does or even which language which part of it is written unless I am 100% certain of the value of `some_variable`. Anyways, if I have time I think I'll write an example for mixed parsing / interpretation based on this.
&gt; why is it header only? Because that's the latest trend in C++ libraries, especially single amalgamation headers.
I'm quite confused about what this (vaguely named) library is actually for. The CLI telnet session gif makes it seem like it's also a telnet server, which doesn't make any sense to me for being a library that seems to be for creating simple shells. At the same time, there's OS-specific input handling, but that makes no sense over telnet, where all the input must be coming through stdin instead of OS APIs.
&gt; Also for reading and maintaining code. It basically means that after the first exec some_variable I have absolutely no Idea what the code below does or even which language which part of it is written unless I am 100% certain of the value of some_variable. True, but `s:` suffix in `exec s:some_variable` means that the variable is script scoped, instead of global (vim instance scope), so at least you know the variable is only used in one file. As long as you stick to best practices, it's not *that* bad. Though I agree that vimscript isn't a very good language. &gt; Anyways, if I have time I think I'll write an example for mixed parsing / interpretation based on this. That would be interesting to see, but if I was in your place, I'd probably say that it's just too much work.
Which will be use-able in production code in around 2025
&gt;That would be interesting to see, but if I was in your place, I'd probably say that it's just too much work. True, I was thinking in the lines of a short proof-of-concept example just for fun. Also that's why I added "if I have time". ;-) If I do write anything interesting, I'll post it here.
I'm not sure about the usage of the pipe operator in the Ivan's book, but I guess it's not about do-notation. I'll check it out for sure (I have his book), but I'd way the pipe operator (and any other function too) is not enough to emulate the do-notation. You can only implement the \`bind\` function. To have a do-notation, you need either a special language-embedded syntax (like in Haskell and Scala), or a massive usage of macroses / templates. In fact, there is an attempt to implement of this notation using boost::preprocessor, here: not DO(optional, (x, unit(1)) (y, unit(2)) (z, DO(optional, (x, make_optional(false, 5)) (_, unit(x - 2)) )) (_, unit(x + y + z)) ) (from [here](https://github.com/evgeny-panasyuk/monad_do)) &amp;#x200B; But this is not quite usable for the general-purpose code. Also, making C++ code to not to break on type deduction is hard and requires some additional machinery that I'm not very interested in currently.
Well, I think all hash tables would fail with a constant hash function. Maybe not as dramatically as with an exception, but most likely degrading to O(n) speed. I do understand better what you meant, though, so thanks!
I have had the same issue in that it seems like all the dark themes gravitate towards a background that tries to resemble a faded old school monitor. Drives me nuts. I found an emacs theme I kind of liked - and then hacked it up. You may get more value out of customizing one yourself.
do not use it personally but there's popular [https://draculatheme.com/](https://draculatheme.com/)
Recently switched to [Nord](https://www.nordtheme.com/), before that [Boxy Tomorrow](https://vscodethemes.com/e/trongthanh.theme-boxythemekit).
I use [https://ethanschoonover.com/solarized/](solarized).
Is it just me or is the obvious solution to have the free functions syntax prefer free functions first and have the member functions syntax prefer member functions first? This is the only choice that is backwards compatible, makes intuitive sense, and requires no new syntax.
I mean, ”prefer” itself is unclear. Prefer at all costs? Or prefer as a tie breaker, after considering other things (like templates vs non templates)? You can bet the committee has discussed at least one if not both options and there are probably some weird results either way.
Can someone explain to me why is this needed? I see only a sea of ambiguity here and no benefits.
I think you could only maintain backwards compatibility if you only expand the overload set when nothing in the C++17 overload set would match.
I second this! I resurrected my pet project just because of this :)
Here you can find the rationale behind it: https://daniele77.github.io/general/2018/10/01/cli.html
One benefit is that it allows you to "extend" classes that you do not own. You can just write a free function which can then be called as if it were a member function.
TIL. Thx!
What does that achieve? Like you can overload them from outside?
But why wouldn't you call it like a free function? To me that use case sounds like "I *want* &lt;thing&gt;" instead of "I *need* &lt;thing&gt;", so I still don't see it as a reason compelling enough to be in favour of this change.
Same use as for [Extension methods](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/extension-methods) in C#.
Looks like C++ is just hell bent on making the language complex and more academic. C++11 was a big jump with useful additions with increased cognitive load, wish it ended there.
One of the reasons is d(c(b(a(foo)))) vs foo.a().b().c().d().
 std::filesystem::path("C:\temp\hello.txt").extension(); 'h': unrecognized character escape sequence No? I think this way will work too: std::filesystem::path("C:/temp/hello.txt").extension(); But general aproch should be like this, probably: (std::filesystem::path("C:")/"temp"/"hello.txt").extension();
It is just a convention the STL follows, not a thing at the laguage level. If you name a template parameter Predicate, that might signal to users of you library that you have the same expectations
While the latter is more readable, imagine looking at new code and trying to figure out what `c()` is. Is it a member of what `b()` returned or a member function? If `b()` returns `*this`, then `c()` might even be a member of `a()`. It's not ambiguous only for compiler, but also for anyone reading the code.
&gt; (std::filesystem::path("C:")/"temp"/"hello.txt").extension(); Sorry to nitpick style, but this is (IMHO, YMMV) literally eyecancer.
The linked papers have plenty of motivation but it seems like it has become common practice to just look at the negatives and bash "C++'s complexity" without taking the time to read existing material. Anyway, to answer your question: * `reverse(filter(foo, collect(bar)))` is very hard to read compared to `bar.collect().filter(foo).reverse()`. The latter syntax currently requires access to `bar`'s internals, which doesn't work for things like Ranges. This is why `operator|` is used instead. * Generic code looking for either `erase(x)` or `x.erase()` currently needs to have some dispatching logic present, increasing its complexity. UFCS would allow a single generic function to find the most appropriate function.
I certainly don't think we should have said "we're done" at C++11. With reflections, herbceptions, and the freestanding proposals, C++ is only going to get better for people who care about every CPU cycle, so please, don't stop now.
Yes, the goal of the ISO committee is purely to make the language more complicated. This is exactly why **none** of the papers have a *"Motivation"* or *"Rationale"* section at all.
A simple thing you can try: try different compilers. The other day I was writing a parser for a file format and was trying to match the performance of a closed source package. Initially my parser was 50% slower and then I switched to clang from gcc and my code became only around 20% slower.
You could say the same about generic programming. Why not just copy paste. Do you really *need* reusable templates?
As always - it depends. If your a, b, c, d are, say, unquote, trim, substr, toupper and foo is a string - it should be obvious enough.
They use the term Datalog a dozen times but I have no idea what they are talking about.
MFC and ATL on Windows.
&gt; `reverse(filter(foo, collect(bar)))` is very hard to read compared to `bar.collect().filter(foo).reverse()`. The latter syntax currently requires access to `bar`'s internals, which doesn't work for things like Ranges. This is why `operator|` is used instead. Fair enough, though this example still doesn't convince me that UFCS (in any form) is a good thing to have. &gt; Generic code looking for either `erase(x)` or `x.erase()` currently needs to have some dispatching logic present, increasing its complexity. UFCS would allow a single generic function to find the most appropriate function. This I would take as a valid reason to consider UFCS. It's an actual problem that is being solved. Thank you.
Not exactly a fair comparison. `foo.a()` is about the same number of characters as `a(foo)`, while templates do save a lot of lines of code.
https://wikipedia.org/wiki/Datalog
I’m just addressing the argument that a feature’s value is ascribed by true need, compared to the desires of the programmer.
That is much closer to backwards compatibility but that definitely is still not backwards compatible, think of e.g. sfinae.
Rather than changing what existing syntax means, which is going to be fraught with compatibility issues, why not have a new "unified" call syntax? Personally, I'd rather get an error if I write `x.count()` and `x` has no `count` method, rather than calling a very-likely unintended `count` free-function that happens to be compatible because of an overlooked conversion. The `$` and `@` symbols have no standard meaning in C++, are commonly found on keyboards and aren't required to be allowed in identifiers (some compilers allow them, particularly `$`, but they're rarely used because it's non-standard and developers often don't realise it's possible)... Something like `foo $ (x, y)` could be defined as having identical behaviour to `x $ foo(y)` without changing the behaviour of existing code. Not the prettiest, but all the "good" symbols have been used.
Just use a raw string literal and stick with backslashes. Is anyone actually hardcoding such paths in real code anyway? I suspect not.
That's exactly what Stroustrup and Sutter [proposed in 2016](https://isocpp.org/blog/2016/02/a-bit-of-background-for-the-unified-call-proposal).
I feel like if this is the only real reason for UFCS, then in the context of an existing language, with massive existing codebases, introducing a pipe operator might simply make more sense. Assuming that a/b/c/d are all free functions, you could do something like: foo |&gt; a |&gt; b |&gt; c |&gt; d. And |&gt; could be specified to only call free functions, or to call both free and member functions, depending which we think is more appropriate.
there are no named template parameters (they are all positional), thus you cannot check the name. somebody has checked that each algorithm that takes a predicate will name that parameter 'Predicate' (presumably).
Native solutions, i know xwidget, now electron is very popular
Commercial sector uses HTML UIs because they are faster to develop, easier to deploy and generally are cheaper. Doing UIs in C++ is labour-intensive and expensive.
Optimizations like that are often done by the compiler itself, you don't really need to bother (writing clear code is more important). What you need to keep in mind when writing fast code is : * Big O notation * Parallelization * Cache coherency
It's just for the purpose of description. The standard uses this convention to avoid repeating the same requirement in the description of every algorithm.
Qt doing it in same way in QML a.k.a js.
&gt;herbceptions If that's not the title of a paper in the next mailing, I am going to be disappointed. :p
Sorry to disappoint, the paper is "throwing values". Herb's name is on it and so it got nicknamed "herbceptions".
I'm currently working in Juce. It seems to have a significant following though until this gig I'd not heard of it.
&gt; it seems like it has become common practice to just look at the negatives and bash "C++'s complexity" without taking the time to read existing material. The C++20 specification is some 1500 pages - almost twice the Java 8 specification, for example. It's not unreasonable to automatically push back on any new proposals that don't offer any obviously brilliant new features. Also, there are nine different proposals linked to from the original paper, which itself really has no motivating examples. And their motivation sections aren't really a voice from the heavens: &gt; Member functions and free functions have different call syntax. This makes it necessary to know if a function is a member function or a free function even if its semantics is substantially independent of the scope in which it is declared. Several examples can be found in the Standard C++ Library where the programmer is required to know what is effectively an implementation detail. I'm like - so? Yes, I have to know if something's a member or a method - like in pretty well every other computer programming language. So what? How does this lead me to mistakes? Yes, as in your example, sometimes two different libraries will implement exactly the same feature but one is a function and the other, a method. In those few cases this will be useful. But it seems more likely that these two libraries would in fact end up implementing different features or different signatures most of the time. An adaptor will work - for all of those cases. Metaclasses are really exciting. Concepts are exciting, if only for the suspense and the drama - the Duke Nukem Forever of C++. But UFC promises to make C++ even more difficult to read. I view it with a certain dread, because now when I see `foo(bar(bar(bing(x))))` there are now two choices per call as to what's happening...
still won't do auto-completion after one character?
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bdibgi/do_you_konw_the_git_repo_996icuwhat_do_you_think/ekyasq8/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thanks STL for adding the hint about what remote means when people say yes to remote.
In my company some projects uses wxWidgets.
Exactly. The UI development is usually not done in C++/by C++ developers as the skills needed are quite different.
Herb told us during lunch last week at ACCU that he hadn't heard of "Herbceptions" until only a very few days beforehand, and he wasn't exactly warm on that choice of nickname for that proposal. So I'd say your chances are very low!
Not root paths like that, but relative paths are pretty common. Think things like `"myapp/settings/config.json"` or the like. I generally just tell people to use forward slashes always all the time no exceptions. They work on Windows just fine in all the common APIs (including all the C++ stdlib ones) and are only a problem anymore in a few low-level Win32 IO APIs that aren't even really the use case for `std::path` (and since you *must* use Unicode/`wchar_t` in those APIs and you _must_ normalize paths in those APIs, you can just convert slashes when you're converting the path string anyway).
!remove
OP, A human moderator (u/STL) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bddmgk/color_themesschemes_for_code_editors/ekycf0a/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I like spdlog, but it can be a bit slow to compile. https://github.com/gabime/spdlog
Have you considered simply writing a little wrapper around `std::clog`, or if streams are too much, then around `std::fprintf`.
This is my thinking as well. This looks like a desire to very marginally simplify typing code at the expense of reading code. Some people might argue that this can be reasonably handled by an IDE but those are not language features and we should not start introducing soft dependencies on external features, especially for dubious gain. But I'm firmly in the make things explicit rather than ambiguous camp.
Given your user name, you might be amused to know that I was paid to write an operating system on the 65816 processor rather a long time ago...
... what do you mean ? works fine here : https://streamable.com/cb0bi
Because free function APIs are terrible. Every time I had to use one I wanted to gouge my eyes out because of how hard everything is to follow as soon as you've got overloading.
 struct X { int foo(long y); template &lt;typename T&gt; int foo(T y); }; int foo(const X&amp; x, char y); template &lt;typename T&gt; int foo(const X&amp; x, T y); int bar(X x) { return foo(x, 0); // Which foo is it? Are you sure? }
The biggest thing I want from it is it removes coupling of the data members and the interface in the same header. This means you can declare methods separately from the structure, which means you can significantly improve compile times because you don't have to include all of the related type headers. Currently the only way to have zero overhead 'pimpl' is to stick to c-style non-member functions for this reason.
&gt; I'm like - so? Yes, I have to know if something's a member or a method - like in pretty well every other computer programming language. well, no, see D for instance, where it makes everyhing much easier : https://tour.dlang.org/tour/en/gems/uniform-function-call-syntax-ufcs
Have you looked at [fmt](https://github.com/fmtlib/fmt) and [spdlog](https://github.com/gabime/spdlog)?
aka the "class" idea is causing problems because people are taking OO too far, and instead of stepping back and reevaluating, this monstrosity is their solution...
Yeah but it doesn't autocomplete my entire program after one letter /s
do you have a link to release notes/commit message with that? I cannot find it
Sure, but I get the impression that D's resolution rules are more straightforward than C++'s...
I would love to see that (care about every CPU cycle) more explicitly mentioned in the various proposals. I have worked the networking layer using a mix of both C &amp; C++.
Well, one of proposals with an obvious name would be "Leaving no room for lower level language", "Throwing values" would be a giant leap for exception usability, reflections will allow you to not rely on the dynamic `typeid()`, destructive moves are being researched and would allow more efficient moves where appropriate, [hardware_{destructive,constructive}_interface](https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size) allow some micro optimizations of very hot code paths, `[[likely]]` and `[[unlikely]]` attributes are being standardized, flat associative containers (depending on the use case) could improve performance a lot, contracts will let you specify preconditions and not throw an exception... I could probably name more things.
[PEGTL](github.com/taocpp/pegtl) is my favorite parser library.
Zenburn, although I was using zerodark for a little bit. And github-modern for papers, because dark mode doesn't translate well.
Ok, thanks for the reply :)
Today, I'd say it would call `foo&lt;int&gt;`. With UFCS it might be `X::foo&lt;int&gt;`. Am I sure? No.
They should make it so once you enter a character it autocompletes your entire program and then orders pizza
A lot of stuff can change sfinae results, like adding a member function, non member function... almost anything in fact.
Hi man, Interesting post. Your Github repo rocks. You seem to be exhausting the possibilities of the language.
We are heading towards: auto()
Yes, but it is worlds apart to make changes like adding a member function to a standard library class, than to change the core language lookup rules. For starters, the standard library has some careful wording about its API, and not everything you can likely do with your implementation is considered part of the API. I'm almost certain that sfinae'ing on the member functions of a class like `vector` is not considered part of the API; so you can do that if you want but the standard doesn't make any promises and it's not considered a breaking change to add member functions to vector. Whereas, function lookup rules are function lookup rules, and a change like this is certainly breaking, and its also much wider in scope practically speaking.
Does that include paying for the pizza or would I have to? Not sure it's worth implementing if the pizza isn't free.
I'm looking at the Java 8 spec here: https://docs.oracle.com/javase/specs/jls/se8/jls8.pdf. I do not see any sections that describe the standard library in its entirety, class by class, function by function, like there is for C++. Meanwhile, library specification goes from about pages 400 to 1500 according to this: file:///apps/homefs1/nir/Downloads/n4810.pdf. Even including the appendices after, it seems like the C++ standard is more than half library specification. This seems like a pretty apples and oranges comparison.
Hey, I don't know I can customize Qt themes, I will try figure out how to do that...
Not readable at all. Thank you for the good example. &amp;#x200B; ^(int foo(const X&amp; x, char y))
&gt; Also, there are nine different proposals linked to from the original paper, which itself really has no motivating examples. You mean the original post? The post has no "motivating examples" because the motivation of the post is neither to propose UFCS, nor to argue for or against it. The motivation of the post is to clarify that there are many different proposals that have historically fallen under the UFCS umbrella, and to try to provide a concise accounting of them. The papers themselves contain their motivation and arguments against. &gt; I would start to doubt my ability Why would you need to know what _kind_ of function gets called in order to understand code? I don't need to know the minutiae behind what: xs | view::filter(f) | view::transform(g) does in order to understand what that expression means. Is it important what type `view::filter` returns? No. And it's unquestionably easier to understand a left to right reading than an inside out one: transform(filter(xs, f), g) One direction of UFCS is motivated by xs.filter(f).transform(g) It's not a question of being shorter, it's a matter of being in the correct order (and also hypothetically much easier to implement than the current `|`-ed version).
Any UFCS proposal would, by design, make name lookup and overload resolution more complex. That's literally the goal. But it's not like we can't have these kinds of examples today: namespace N { struct X {}; int foo(X, long y); template &lt;typename T&gt; int foo(X, T y); }; int foo(const N::X&amp; x, char y); template &lt;typename T&gt; int foo(const N::X&amp; x, T y); int bar(N::X x) { return foo(x, 0); // Which foo is it? Are you sure? }
&gt; Not unless you want to write a compiler extension that adds that kind of function and enforces the behavior you want. /u/lycium Something like this already exists: `[[gnu::const]]` and `[[gnu::pure]]`. Not sure about enforcement but GCC applies relevant optimizations.
One of the KTextEditor devs here: Nowadays you could also use the KSyntaxHighlighting framework which ships a QSyntaxHighlighter. But if KTextEditor works for you as well, all the better :)
Yay I'm mentioned in Boost Spirit notes! This was a long way, I just wanted a home-made project; did not expect to find multiple bugs in Spirit X3 and surely I never imagined I could find a GCC regression.
Whoever's bright idea it was to use `operator /` as a path operator should really be shot. It's the only thing truly ugly in `&lt;filesystem&gt;.
There was a proposal for `.x.foo()`, don't know what happened to it.
We wanted a bunch of features from KTextEditor that made it a pretty good choice. The users pretty much wanted a mini-ide, and KTextEditor gave us line numbers, code folding, and code completion for pretty minimal effort. We were basically able to just blacklist a bunch of actions using KConfig and get exactly what we wanted. The only issue we have run into is that opening up a KXmlGuiWindow causes the application name to get appended to all of our windows, which we couldn't find the cause of.
I read the whole readme and I have zero idea of what the purpose here is, let alone why it needs cmake to build. I know it is frustrating to see this when you might have thought people would jump right in to the finer points of what you've done, but I don't understand what this does over what C++ already has built in.
Contrast of the scrollbar for dark theme still needs much improving.
Encourage working on call-site syntactic selection of call semantics? 1 | 3 | 3 | 6 | 8 My impression is for the people that do want UFCS, this is weird and pointless syntax. And for the people that don't want it, this doesn't really address the concerns anyway?
It doesn't require cmake. It's just a couple of headers with a \*\*cmake interface library\*\* to make it easier for inclusion in cmake projects. You can't build it alone, it is template library. I feel this should be obvious to most c++ devs.
The purpose is to allow more methods of initializing and to allow the user to specify a maximum storage size. It also guarantees no heap allocation will occur unless explicitly specified: by initializing with a pointer acquired through \`new\` or some smart pointer mechanism.
You have a cmake section right under setup. I can't figure out what this does, why would I assume it's template only?
Why not just make a class and overload operator() ?
look under cmake section it says manual (i updated to be more specific), this is for projects that do **not** use cmake. CMake defines an interface library target type which is for header-only libraries, this explicitly does not get built into any type of object or binary, it only specifies the relevant include directories needed to find the headers in a portable way. I could update the readme to be more clear about dependencies.
I use Qt Creator just about everyday. I find it has the best interactive debugger compared to other IDEs on macOS and Ubuntu. However, the editor itself is still clunky and slow. I really wish it had the feel and smoothness of Visual Studio Code.
&gt; foo |&gt; a |&gt; b |&gt; c |&gt; d. And now those free functions cannot have parameters.
What if you want to fill a container with callables from various sources of differing types (function pointers, lambdas, functors)? The point is 1 type can represent anything with a compatible call signature. You can have a `callable` as a class member variable without templating the parent class, due to type-erasure.
How is it clunky and slow? I feel VS is unusable without installing visual assist x, in contrast qtc works out of the box perfectly.
which win32 apis would that be?
They must effectively be unary, not nullary; making them unary is what utilities like `bind` are meant for.
Your copy ctor is broken. Your sfinae namespace isn't used in sfinae context. And only in implementation. Get it out of interface header, it is a pile of ugly noise. Your mem fun ptr requires an exact signature match, which means `[](auto&amp;&amp;)` lambdas often won't work. The signature of the type erased action can always be `R(void*, Args&amp;&amp;...)` (yes, `&amp;&amp;`) regardless of what it invokes. All 3 of copyable, movable and immobile callables have a use, and require 3 different types practically.
That's what Julia does if you didn't already know
Julia makes the pipe operator become the first argument
I agree, classes work extremely well for data structures, but when people start putting transformations into them the can of worms gets opened. If you look at a string, holding the data and accessing it is one thing, but should all the transformations go into the string class?
&gt;Online Our Junior Developer C++ position in Chicago is currently closed but will reopen in the fall when we start the recruiting season. You're welcome to wait until the role opens again or you can look on our website for other opportunities [https://akunacapital.com/careers](https://akunacapital.com/careers).
I'm thinking about going partly because the new location is closer to me. If there's interest in hearing about my [free code generator](https://github.com/Ebenezer-group/onwards) that would help me decide.
Is it possible to add extra text or even graphics at the end of each line or in between each lines easily? I'm thinking about line by line annotations while editing source files.
Why? In Elixir: `foo |&gt; f(x) |&gt; g(y)` means `g(f(foo, x), y)`. That is, the argument to the left of the `|&gt;` gets inserted into the first argument of the call to the right. So it'd really be `foo |&gt; a() |&gt; b()` for unary calls.
good point about the interface. I fixed a couple of broken constructors. I'm not sure about the copy constructor, what did you see wrong with it? I am now trying to enhance the sfinae to handle generic lambders.
On smaller projects it's fine. On large (500k+ LOC) projects it becomes slow to respond to keystrokes. This is observed on multiple computers with various configs. VS has its issues but the editor itself is top notch.
I've started using it and I don't really like it that much compared to VS or VS code. It's quite unstable giving me nonsensical errors (failing to stop the debugger) or taking forever to add files to the project. Still probably haven't figured a lot of things though (e.g. how to open files in tabs).
Learn the rule of 3/5 (zero). You have a non trivial dtor / ctor, thus you need a non-trivial copy ctor. I could spell it out if you still are missing it.
I mean when I hit 1 character, the suggestion dropdown should appear, not when you hit ctrl+space or type at least 3 characters.
I had to check to make sure, but i already have it implemented. It calls \`destroy()\`, then checks if the other callable is empty, if not it copies the state over. Are you talking about the lack of a cast to concrete type on \`m\_storage\` member?
I'd use it if I got a x64 binary by default on visual studio
I actually would be against such a thing because it's too radically different from anything in C++. I'd prefer to simply get abbreviated lambdas and solve things that way. It's a little more verbose, but more clear and additionally let's you place the argument anywhere. Even if this weird syntax is standardized it doesn't solve things when the argument isn't first.
use clang code-model
I was thinking of F#, but cool to know that Julia does it as well.
&gt; it's too radically different from anything in C++ Is it? With Ranges, we get `elems | view::filter(f) | view::transform(g)`. With this, we get `elems |&gt; view::filter(f) |&gt; view::transform(g)`.
In F# the piped argument becomes the last arg rather than the first.
ok now i get it. I actually thought about doing this with the copy/move constructors, i did not think much about the errors that could arise from a direct copy like that, so i moved on. Thinking more on it, i realize it is unacceptable.
What, I've only been using qt Creator for a couple months but the debugger seems to be very limited. Watch variables often don't work, the expression evaluator doesn't work at all condition breakpoints are hard to set and no interactive console are my biggest gripes. I've also had builds where the "this" object isn't expandable until a Creator restart. What do you like about the debugger?
Uhm, yes? With ranges, those are understood to be higher order functions. At least, that is my understanding, regardless of how they are implemented. User code can always choose to write a higher order function, so that `f(x)` returns some new function, sure. What you are talking about is basically like introducing currying, in a very limited context, to C++. C++ does not have currying, and hence it is extremely foreign to the rest of the language. When we want a higher order function, we ask for it explicitly.
This is precisely how Rust's [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html) trait works - `next()` returns an `Option&lt;Item&gt;`.
Strong pass.
Interesting, I didn't know that! Each time I hear about Rust, I want to learn it a little more :) Python also does something similar with iterators, but raises an exception instead of returning an optional.
I'm not sure sure why you think this is foreign, but may be the confusion is that you think this resembles currying and it definitely does not. Lemme expand on what I mean by `|&gt;` and maybe /u/vector-of-bool will write a proposal at some point. `a |&gt; f(b, c)` means precisely `f(a, b, c)`. The former is just syntax sugar for the latter. `f(b, c)` by itself may or may not be valid. That's it. I don't see how this is foreign given that: (a) we have function calls in the language, which this is, (b) we have libraries that are written precisely with the goal of achieving this syntax, and (c) it's also quite close what some people want from UFCS (though not what Bjarne and Herb ended up proposing): that `a.f(b, c)` means `f(a, b, c)`. I think it's less foreign than, say, abbreviated lambdas. I'm still not sure it's actually a _good_ idea, but I don't think it's really different from C++ (like, say, introducing currying would be).
Not exactly. &gt; free functions syntax prefer free functions first This part, yes. &gt; and have the member functions syntax prefer member functions first This part I guess technically yes, but only because there's no "second" here. In that 2016 proposal, `x.f(y)` would never call `f(x, y)`.
Lower-level NT calls (I don't recall the details; I believe most of them have `NT` in the name iirc though), or some "basic" calls like `OpenFile` when used with the `\\?\` prefix. The gist though is that they don't go through the FS translation layer in the Win32 API that performs normalization, so they need to directly match the "real" NT names. One of the various benefits of it though was (very) long path name support, back before Win10 started enabling them in higher-level APIs.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bdp233/from_where_should_i_learn_cpp/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
**Company**: [Disbelief](http://disbelief.com/) **Type**: Full time **Description**: Disbelief is a game development studio focusing on contracting and consulting services. We’ve worked with both AAA and independent studios to help their projects ship. Notable projects we’ve worked on include Gears of War 4, Borderlands: The Handsome Collection, and Perception. At Disbelief we value work-life balance, and want to create an alternative to the crunch-culture prevalent in game development. We also believe strongly in investing in our talent and our team. Disbelief is a place to puzzle out the solutions to cutting-edge problems in graphics and engine programming, but also a place where people can grow their careers and skill sets as valued members of a stable and close knit team. Currently, we’re looking for a junior programmer. This opportunity is for a full-time position in Cambridge, MA or Chicago, IL. Junior programmers at Disbelief are called on to develop and debug in a variety of areas from game play to core engine programming. You are expected to learn new systems and projects as you grow as a developer, with support and training from more senior members of the team. Most importantly, you will work to solve problems with the help of the team. We work with leading edge technologies to make them perform at the top of their capabilities, and we take pride in solving problems others can't. We believe a diverse team is a stronger team, and we encourage marginalized programmers to apply. *Key Responsibilities* * Clearly communicate your work to others * Debug code * Estimate task work * Consider performance when writing code * Document your code *Skills and Requirements* * BA/BS in Computer Science, or equivalent experience * Excellent communication skills, both verbal and written * Some type of systems programming in any language. * Good understanding of C++ * Knowledge of version control with P4, git, or equivalent **Location**: Cambridge, MA or Chicago, IL **Remote**: No, but we do enjoy working from home up to two days a week, when project constraints allow. Visa Sponsorship: No Technologies: Most of our work is C++ of varying standards with a sprinkling of other languages as needed for tooling. We do a lot of graphics programming work, using shader languages and platform graphics APIs. Since we often are debugging the lower levels of systems, being able to read x64 or ARM assembly is useful. Primarily we work with Unreal Engine 4, but we also work with Unity and custom game engines. Our work uses rendering, physics, audio, VR, AR, and other APIs frequently. Our primary platforms are PC, Xbox One, PS4, Switch, and VR/AR devices. **Contact**: [jobs@disbelief.com](mailto:jobs@disbelief.com)
**Company**: [Disbelief](http://disbelief.com/) **Type**: Full time **Description**: Disbelief is a game development studio focusing on contracting and consulting services. We’ve worked with both AAA and independent studios to help their projects ship. Notable projects we’ve worked on include Gears of War 4, Borderlands: The Handsome Collection, and Perception. At Disbelief we value work-life balance, and want to create an alternative to the crunch-culture prevalent in game development. We also believe strongly in investing in our talent and our team. Disbelief is a place to puzzle out the solutions to cutting-edge problems in graphics and engine programming, but also a place where people can grow their careers and skill sets as valued members of a stable and close knit team. Currently, we’re looking for a senior programmer. This opportunity is for a full-time position in Cambridge, MA or Chicago, IL. Senior programmers at Disbelief are leaders and developers in their project. You should be comfortable working independently and with a team to develop, test and integrate software into a larger codebase. A key responsibility is mentoring and guiding fellow programmers to improve. We believe a diverse team is a stronger team, and we encourage marginalized programmers to apply. *Key Responsibilities* * Clearly communicate your work to others * Mentor fellow programmers in and out of your team * Communicate with clients on team progress and problems as they arise * Debug code with precision * Estimate your and others work * Assess impact of issues on schedule * Diagnose and solve performance issues * Document your code * Study version histories and code documentation to solve present problems * Implement features in innovative ways *Skills and Requirements* * BA/BS or MS Degree in Computer Science, or equivalent experience * Excellent communication skills, both verbal and written * 3-5 years of experience in writing software in C++ * 5+ years in game development, or 10+ in a related industry * Experience working on a large code base * Experience with version control with P4, git, or equivalent * Experience with multi-threaded systems **Location**: Cambridge, MA or Chicago, IL **Remote**: No, but we do enjoy working from home up to two days a week, when project constraints allow. **Visa Sponsorship**: No **Technologies**: Most of our work is C++ of varying standards with a sprinkling of other languages as needed for tooling. We do a lot of graphics programming work, using shader languages and platform graphics APIs. Since we often are debugging the lower levels of systems, being able to read x64 or ARM assembly is useful. Primarily we work with Unreal Engine 4, but we also work with Unity and custom game engines. Our work uses rendering, physics, audio, VR, AR, and other APIs frequently. Our primary platforms are PC, Xbox One, PS4, Switch, and VR/AR devices. **Contact**: [jobs@disbelief.com](mailto:jobs@disbelief.com)
I didn't know about that but I tend to not want to use non-standardized language features.
You should add a license, hint, don't pick the wrong one!
&gt; but may be the confusion is that you think this resembles currying and it definitely does not I understand that it is just syntactic sugar. But it certainly resembles currying in this particular context, in curried languages like F# that also has pipe operator, when you write ` a |&gt; f b c`, if `f` takes 3 arguments, then `f b c` just returns a one argument function, and then `a` is fed into it (a just ends up in the last position rather than first). So it's a stretch to say that in this particular context (with the pipe operator), that this doesn't "resemble" currying; it definitely does. It's just that the curried formulation frankly makes much more sense, because |&gt; is just passing values forward through functions as you would expect. Under what you're suggesting, |&gt; doesn't do piping forward at all, it's just weird syntactic sugar for UFCS. Which is pretty bizarre; if you want syntactic sugar for a unified lookup, you may as well do something that involves `.`, because that's the only context ever in C++ where `f()` doesn't immediately try to evaluate something (a function, or constructor) with no arguments. So why not just `a.$(b,c)`? Hideous, maybe, but more honest. If we do `|&gt;` it should actually pipe things, and `a |&gt; f()` most definitely does not seem like `f(a)` at first blush to any C++ programmer. The first association they will make is `f()(a)`. For the "left-to-right" crowd, this doesn't really solve any problems in general, because eventually you'll need to pipe in the value into some position other than the first. And when things don't exactly work out, and you do need a lambda, how exactly will this work? b |&gt; [] { f???? } (); I actually am not even sure how things would work, with your suggestion. Versus b |&gt; [] (auto &amp;&amp; x) { return f(a, x, c); } Or b |&gt; x =&gt; f(a, x, c) Which looks great and almost resembling a functional language. In sum, I think you are taking a suggestion and syntax that is very naturally solving the "left-to-right" problem, and instead adapting it as "opt-in UFCS". These problems are really two different things, as you can see making |&gt; opt in UFCS just makes it a poor solution for piping. If you want to solve UFCS and provide a mediocre solution to left-to-right chaining, then have the syntax reflect that and stick to `.` or something that includes it. If you want to focus on solving left-to-right well then |&gt; shouldn't transform into a UFCS call.
I had some weird things happening when clang code model was added to the QtC. Especially under Windows. No auto completion for some files, extremely slow clangd compilation times and broken refactoring [?] Some of those I also observed under Ubuntu. For now, for largerish projects, I switched to VSS.
would it be bad if i give it a license to kill? i agree 100% with your suggestions, i'm just not great coming up with names.
There is a good place to ask questions like this r/cpp_questions .
I see you did those things, still need a license [as it stands, anything is unusable, as you retain the exclusive copy-right by default, that's how 'writing' in general works].
Thanks :) I think the language is keeping more secrets that we're still didn't reveal. Also, the new standard is coming, and I expect the concepts can allow a lot more things that can be investigated.
In between lines: no. At the end of lines or in the middle: yes, with the KTextEditor::InlineNoteInterface that was added in version 5.50: https://kate-editor.org/2018/08/17/kate-gains-support-for-inline-notes/ If anything is missing, please let us know on kwrite-devel@kde.org so that we can extend the interface.
That's for sure a production-quality library.
I work on large project and qt works just fine. We are provided with 16 cores and 32 gb of ram though.
It's actually semi-standarized. Compilers are required to ignore unknown attributes.
&gt; begging for "like, share and subscribe" you mean "star, fork and watch"
honest question, what happens if your range contains std::nullopts as a valid value
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bdqbk9/c_code_reviewhelp/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Ah. Yes I guess when using \\?\ all bets are off. (for the records and people strolling by: Never use OpenFile api, always use CreateFile, which does much more than its name leads on.)
Damn. Now I want to see this in the standard
The problem is that iterators are more general than that. For this particular use case, this design might be better. But what about bidirectional, random access, etc.?
Return it from the function.
&gt; Problem: The intent is just pass by reference, but it doesn't happen as most people coming from those languages would assume. How is that a problem of C++? It's not. Doing a similar thing for other languages would be equally stupid. For example, assigning a pointer to another one in Java wouldn't do a deep copy, so if I come from C++, shall I consider that a Java problem? Of course not.
Seems like there is an obvious solution that retains backward compatibility with the existing C++ machinery: lazy evaluation. When calling `operator++` on the filtered range, just increment an internal variable `numberOfStepsToTake`. Then, whenever the actual value is needed, such as in `operator*` or `operator==`, step through the underlying iterator and return the result when you've satisfied the increments. This avoids the double evaluation of the underlying iterator, because the underlying iterator isn't dereferenced until we actually need its value. It also has the added benefit of completely avoiding evaluation in cases where the value isn't actually used. The tradeoff is the same as the one for the solution presented in the article: an extra member value to keep around in your iterator.
Oh sorry I forgot to mention, one of the requirements was all the functions return void so I would have to use pointers I'm assuming
This should go in /r/cpp_questions
Bidirectional: add a prev method Random access: that's not an iterator, that's an index. If you really want it you could provide a next_n method or just use + and have that one not return the new value. You can also provide extra methods like size (or size hint) which now make sense because the iterator knows its own end
&gt; Random access: that's not an iterator The C++ standard seems to disagree with that. See also https://en.cppreference.com/w/cpp/iterator
Well one of the points of the article is that C++'s iterators are not designed very well.
Here is the way how Scala solve the problem. &amp;#x200B; &amp;#x200B; When you want to extends a already defined class, you can define a method which can be used to implicit convert the class to another class: &amp;#x200B; &amp;#x200B; Object Convert { implicit def toRichInt(i: Int): RichInt = ... } &amp;#x200B; &amp;#x200B; We can extend the Int with functions defined inside our RichInt: &amp;#x200B; &amp;#x200B; class RichInt { def RichInt(i: Int) { this.value = i; } def times(multiplicand: Int) = this.value \* multiplicand } &amp;#x200B; &amp;#x200B; The Convert object is able to convert Int to RichInt. We can import the converter functions, and implicitly call functions defined in our class: &amp;#x200B; &amp;#x200B; import Convert.\_ val i = 100; i.times(10); // -&gt; 100\*10 &amp;#x200B; &amp;#x200B; BTW, scala is a very well designed modern programming language, and it provides much more language features than any language I have learned. And surprisingly it is also very simple, \[the whole syntax grammar of scala\]([https://www.scala-lang.org/files/archive/spec/2.11/13-syntax-summary.html](https://www.scala-lang.org/files/archive/spec/2.11/13-syntax-summary.html)) can be printed in a single A4 paper, comparing to more than 1500 pages of c++.
Nothing is backwards compatible when you consider SFINAE. That's not a reason.
I think he meant VS *Code*, not regular VS.
If iterators (and ranges that are built on them) should not allow for random access, then what do you use for sorting, which is one of the most common, if not the most common algorithm performed on ranges? Other important algorithms such as partition, nth_element, etc also need random access.
&gt;the iterator knows its own end Only the end iterator knows it is the end iterator.
&gt; Learn the rule of 3/5 (zero). Could you elaborate on this one?
It's easier, sure. But not that much.
I was referring to the linked article where "end iterators" aren't a thing
Ranges are not the same as iterators. the sort algorithm should take a range, not an iterator. Iterators are for iterating, not for shoehorning into all element access
Well that doesn't explain what should be done instead. Have another thing (which isn't an iterator) and then a range can conceptually be either two iterators or two of these other things with a different interface? And then algorithms are overloaded for both cases?
I think it helps to forget about iterators altogether and use ranges as the primary entities instead. Then the question becomes how sort() could/should interact with them. One solution would be to introduce concepts to these non-iterator ranges. One of them would be a RandomAccessRange, which would have the methods next(), prev(), and at() (or perhaps std::next(), std::prev(), std::at(), in the spirit of std::begin()/end()). at() would also tie in nicely with the std::optional based approach - in case of an invalid index, it would just return std::none.
Here: ``` std::optional&lt;int&gt; op; auto v1 = optival(op) ; assert(v1 == 0) ; // ok ``` you change the semantics of `std::optional`. If you accept the default constructed value this way, you'll lose the information about whether or not the optional carried a value. I don't want the default constructed type if the optional carries no value. If I would, I'd use the member function `value_or`. I just don't see the benefit of `optival`.
Templates are duck typed so just use `*opt_` or `opt_.value_or(42)`. Maybe I've missed the point.
In practice I've found both Rust `Iterator`s and C++ `Range`s to be equivalently powerful, so if you understand one you should not have many troubles understanding the other. The libraries are however architectured in a completely different way. I learned range-v3 thoroughly first, and I find Rust `Iterator`s much simpler (e.g. implementing your own Rust `Iterator` is trivial when compared with C++ `Range`s).
&gt; But what about bidirectional, random access, etc.? Rust has these since 1.0, e.g., [`std::iter::RandomAccessIterator`](https://doc.rust-lang.org/1.0.0/std/iter/trait.RandomAccessIterator.html)
&gt; f iterators (and ranges that are built on them) should not allow for random access, then what do you use for sorting, Indexing. The GP you were replying to literally said: "that's not an iterator [in Rust], **that's an index**".
&gt; Well that doesn't explain what should be done instead. The GP did explain that, but explanations are of no use if you can't bother to actually read them.
They are very much not equivalently powerful -- Rust's iterators are, at best, bidirectional; this means that anybody who wants to parallelize iterators is stuck defining their own (see Rayon, where you have to implement a different iteration trait in order to get parallel iteration). This is in contrast to C++, where the iterator parallelization efforts was able to use the same iterators we've had for 20 years, as well as everyone else's.
Very good. If I may help on the issue of next() returning a copy? // created 2019 APR by dbj@dbj.org template&lt;typename T&gt; using ORW = optional&lt; reference_wrapper&lt;T&gt; &gt;; That is what next() needs to return. template &lt;typename InputIt, typename Sentinel&gt; struct InputRange { InputIt current; Sentinel end; using value_type = typename std::iterator_traits&lt;InputIt&gt;::value_type; // dbj: here we copy the optional which contains a wrapper to T // and a wrapper to T is contains a pointer to T // thus we do not copy the T ORW&lt;value_type&gt; next() { if (current != end) return *current++; else return std::nullopt; } }; Some testing mumbo-jumbo preparations using IV = std::vector&lt;int&gt; ; using IVIR = InputRange&lt;IV::iterator, IV::iterator &gt;; IV numbers = { 1, 2, 3, 4, 5 }; IVIR inr_{numbers.begin(), numbers.end()} ; Usage requires no change. cout &lt;&lt; "\n\n{" ; while (const auto value = inr_.next()) cout &lt;&lt; " " &lt;&lt; (*value) &lt;&lt; "" ; cout &lt;&lt; "}\n\n" ; Notice how much boilerplate is hidden. - "*value" returns reference to T, not T - calling "operator &lt;&lt;" on that resolves to T&amp; - which is then calling operator on std::reference_wrapper - that finally returns reference to *T, held inside it phew!
Ah, I remember those "halcion days" of Java, when C++ forums have been bursting with "proofs" on how much better/cleaner/smarter it is. Now we have a silver bullet of Rust.
Swift does the same thing. The `Iterator` protocol requires a `func next() -&gt; Element?` method.
Iterator::nth is O(1) for slices, how is this possible if they are “at best, bidirectional”?
&gt; Well one of the points of the article is that C++'s iterators are not designed very well. This is entirely the wrong take-away. Stepanov's iterators -- generalised pointers, in a sense -- are a beautifully elegant design that fit in very well with the built-in semantics of the language and have stood the test of time. What this article *is* saying is that Stepanov's design is not the only viable one; in particular, there are trade-offs involved in separating the operations of advancing the iterator and accessing the referred-to element. In this case, a fused advance+access operation avoids a call to a predicate; on the other hand, separating the operations allows for in-place operations like `remove` or `rotate` to be written much more easily.
This doesn't really change the problem. Before you dereference or increment the iterator, in most cases you have to check for its validity. So instead of doubly evaluating because of `operator++`, no you are doubly evaluating because of `operator==`.
On my MacPro with 16 cores and 32gb ram, it still is sluggish on large projects.
&gt; In practice I've found both Rust Iterators and C++ Ranges to be equivalently powerful I'm not a Rust expert, but from what I can gather there seem to be gaps compared to C++ when it comes to in-place operations on containers/collections. Unless I'm missing something, many useful in-place algorithms seem only to be defined for `Slice`, equivalent to C++'s `ContiguousRange` (or perhaps `std::span`). This is a vastly stronger condition than is required for almost anything in the STL.
Returning a pointer is still \*optional\* parameter :)
Similar to the `tmf::callable` namespace suggestion `callable.hpp` is a very generic name. It would be better if the include folder was laid out like include/tmp/callable.hpp include/tmp/callable.inl
 template&lt;typename Iterator, typename Predicate&gt; class output_filter_iterator { public: explicit output_filter_iterator(Iterator iterator, Predicate predicate) : iterator_(iterator), predicate_(predicate) {} output_filter_iterator&amp; operator++(){ ++idx; return *this; } output_filter_iterator&amp; operator*(){ return *this; } template&lt;typename T&gt; output_filter_iterator&amp; operator=(T const&amp; value) { if (predicate_(value)) { for (size_t i = 1; i &lt; idx_; ++i) ++iterator; *iterator_ = value; ++iterator_; idx_ = 0; } return *this; } private: size_t idx_ = 0; Iterator iterator_; Predicate predicate_; };
&gt; The parallel algorithms are a different implementation that the serial ones Well, of course they are? &gt; they often only works on RandomAccess or Contiguous iterators [citation needed]. `std::transform_reduce`, to take a random example, [works with just `ForwardIterator`s](https://en.cppreference.com/w/cpp/algorithm/transform_reduce). &gt; Rayon algorithms can work in parallel even on single pass forward iterators Are you sure about the single-pass assertion here? I can't see how that would work with multiple threads. &gt; Also, because of C++’s view / Action design, you can’t really have a view that owns its contents, or easily implement something like Rusts IntoIterator or collect. Isn't `collect` equivalent to Range-V3's `ranges::to_`? (Possibly with a `move` in there in C++). I'm not sure what `IntoIterator` does in Rust to be honest :).
First of all this is specifically for output iterators which are not the subject here. Even so, every evaluation of the predicate that you got rid of in `operator++` exists in `operator=`. The only overhead this saves is when the user would increment a bunch and then discard the operator without using it. The problem in the article is not solved by this.
They are different, but the types of programs you can write with both is pretty much the same. We could nitpick about the differences [0] [0] vector execution policies need ContiguousRange, so all C++ random access iterator of the last 20 years that haven't been updated to become contiguous don't work there "as is". Also, you are technically correct that Rust does not have a RandomAccessIterator, but it used to have one, and it was removed because it wasn't really necessary, since the `Index` and `IndexMut` traits already express "random access".
Interesting, I'll read through this, thanks!
It seems all the criticism of UFCS proposals comes down to ambiguity and complexity of lookup (meaning more mental overhead when reading code). I personally see absolutely 0 value in allowing f(x, y) call x.(y). How is f(x, y) easier to understand? It serves no purpose, so we should discount that option. However, I do see a use in simplifying the invocation free functions. Flat, left to right semantics are humanly intelligible and tell a story. foo.bar().baz() lists the actions in order, whereas baz(bar(foo)) looks like it lists the actions in reverse order. The human brain needs less "cycles" to parse the former as opposed to the latter. The question comes, how do we know what foo.bar() calls? A free function or a method? It is important to know, because methods are "blessed" by the class, and any idiot can write a free function. The answer is to have a new way of calling free functions, as has been mentioned before in this thread. No extra lookup rules are required for the existing call syntaxes. Let's say the operator was the double dot ".." foo..bar() always calls bar(Foo), and never calls Foo::bar foo.bar() always calls Foo::bar (as before) bar(foo) always calls bar(Foo) (as before) By having a new syntax for free function lookup, you can flatten code without messing up existing invocations. Easy. The only losers are the ones who want foo(x, y) to call x.foo(y), but who are these people?
I don’t see many parallel algorithms working with input iterators, yet in Rust you can iterate over the lines of a file in parallel while reading. &gt; Are you sure about the single-pass assertion here? I can't see how that would work with multiple threads. It works because Rust Iterators can own the elements. A Rust Iterator can pull from a Stream into a Vec and work on the Vec in parallel. A C++ View can’t do that by design. &gt; Isn't collect equivalent to Range-V3's ranges::to_? (Possibly with a move in there in C++). I'm not sure what IntoIterator does in Rust to be honest :). IntoIterator moves the input into the Iterator, making the Iterator own it, so your lazy or eager algorithms can make use of that when applied.
And one of my favorite features of Scala - that `import Convert._` statement is scoped - you can allow specific implicit conversion in current scope and not in whole project or file. For example: import scala.language.implicitConversions object Convert { implicit def toRichInt(i: Int): RichInt = new RichInt(i) } class RichInt(val value: Int) extends AnyVal { def times(multiplicand: Int) = value * multiplicand } object HelloWorld extends App { // 10.times(10) // error: value times is not a member of Int { import Convert._ println("Value: " + 10.times(10)) // Ok -&gt; 10*10 = 100 } // 10.times(10) // error: value times is not a member of Int } [Link to wandbox](https://wandbox.org/permlink/2NRDAg4FA2aaz77J)
&gt; it certainly resembles currying in this particular context I feel like the only salient feature of currying is decomposing a function that takes n arguments into a chain of functions that take one argument. Writing a binary function like `void add(X, Y);` and calling it like `auto f = add(x); f(y);` This... isn't that. &gt; eventually you'll need to pipe in the value into some position other than the first That's the thing though. Will you? All of the ranges adapters just need to pipe into the first position. Iterator chaining in Rust effectively works the same way. That's a LOT of bang for the buck. Like, sure, if you come up with a situation in which this is necessary, you will have to write an adapter that works differently - but saying that this doesn't solve the problem is a lot like saying abbreviated lambdas are bad because eventually you'll need to write longer lambdas? This is just sugar for the most common case. &gt; `b |&gt; x =&gt; f(a, x, c)` Which looks great and almost resembling a functional language. Just to make sure I understand, you mean for `x |&gt; y` to mean `y(x)`? In other words, you'd make `rng |&gt; filter(f)` work like: template &lt;Range R, typename F&gt; auto filter(R, F); // the real function that does the stuff template &lt;typename F&gt; auto filter(F f) { return [=](Range auto r){ return filter(r, f); }; } ?
When I referred to Jonathan's article about std::optional not supporting references, I thought: would this work with reference\_wrapper? But I decided the article was long enough already. And there it is :) Thanks for going the extra mile.
 &gt; in Rust you can iterate over the lines of a file in parallel while reading. Can you? I'd be interested to see how this is done. I can't see how it would work with any sort of decent performance unless you're copying chunks of the file into memory first (as suggested in your next point), but perhaps I'm lacking imagination today :). &gt; A Rust Iterator can pull from a Stream into a Vec and work on the Vec in parallel. A C++ View can’t do that by design. You most certainly can copy an input stream into a vector and work on the vector in parallel in C++. I'm not sure what views have to do with it? &gt; IntoIterator moves the input into the Iterator, making the Iterator own it, so your lazy or eager algorithms can make use of that when applied. I feel like I'm not quite getting why this is a benefit, or what it allows that C++ ranges do not?
MSVC has always used its own frontend. _Visual Studio_ uses EDG, and for Intellisense only.
As indicated for the third time, you do not sort using iterators, you sort using a range. An iterator is for iterating, a range is for operating on an ordered collection. Sorting is best considered an operation on an ordered collection rather than a form of iteration.
I don't understand. Is there any issue you want to discuss?
Rust isn't the only language with cleaner iterators than C++.
Only true for ranges which cover an entire container - in other ranges, the end of the range might not be the end of the container and thus know know that it's the end.
Iterators can be annoying when you do not have a sentinel value. In a for-loop you have the same issue (this is an infinite loop): for (uint8_t i = std::numeric_limits&lt;uint8_t&gt;::min(); i &lt;= std::numeric_limits&lt;uint8_t&gt;::max(); ++i) { // do stuff } Try writing an iterator in C++ or Rust that can iterate over all numbers of any type -- it's awkward. You have to have more unnecessary state (storing an additional boolean). The actual solution would look more like: uint8_t i = std::numeric_limits&lt;uint8_t&gt;::min(); if (i == std::numeric_limits&lt;uint8_t&gt;::max()) return; do { // do stuff } while (i++ != std::numeric_limits&lt;uint8_t&gt;::max()); It does not fit the iterator pattern. In Julia this problem is addressed quite nicely I think. It works similar to Rust and OPs post producing optionally an item (the value `nothing` or a value). But also initializing the iterator might return `nothing`. It transforms for element in iterable # do stuff end into x = iterate(iterable) while x !== nothing element, state = x # do stuff x = iterate(iterable, state) end and you need to implement `iterate(iterable)` to provide an initial value &amp; state OR nothing, and you have to implement `iterate(iterable, state)` to provide a new value &amp; state OR nothing. Is this something that other languages implement as well?
The downside of this (which is also true of all the other UFCS papers which had "CS2") is that this won't work: std::vector&lt;int&gt; ints = {1, 2, 3}; auto evens = ints..filter(is_even); We'd need to somehow find `std::ranges::view::filter` and that's not gonna work here (and certainly not for my own ranges that aren't in `std`). So would either need a new way of associating names or a way of providing a qualified name. Maybe you already had that in mind? auto evens = ints..view::filter(is_even);
I'm not sure if there's point discussing currying further, but FWIW, you seem to be jumping to a place of `|&gt;` is like `.` or `-&gt;`. I am thinking of `|&gt;` more like a pipe operator, the way `|` is currently used in ranges. In that context, function evaluation occurs before that operator would be applied. If you consider it that way, then the only way that it can work is if "evaluating" a function taking N arguments with N-1 arguments, returns a 1 argument function. &gt; That's the thing though. Will you? All of the ranges adapters just need to pipe into the first position ... Yes? You will? You're speaking frankly from a perspective of someone who's either writing a specific library designed with chaining in mind, or picturing a user that's just going to be using a specific library, and that's all. Real world applications are a lot more messy and you bring functions from a variety of sources to bear. Some of which will be written with such chaining in mind, some of which won't. If you're going to write the operator `|&gt;`, it should be a general solution, not a way to implement ranges. &gt; Rust effectively works the same way. Rust uses `.` for this. Which is exactly what I said before; if you want UFCS, then just make it UFCS? Or at least more resembling of `.`. Having a pipe operator which conceptually means something else, actually do UFCS is confusing and misleading. And Rust btw has abbreviated lambdas; without abbreviated lambdas most of the nice Rust iterator chaining code would anyway be much uglier than for loops. So the value is relatively dubious anyway. &gt; Just to make sure I understand Well, obviously it doesn't have to work exactly that way, as long as `filter(f)` returns a function operating on a range, it's find. That said, this isn't that different fundamentally from how ranges works now? `elems | view::filter(f)`; presumably `filter(f)` returns some kind of object, that knows how to operate on ranges in some sense, which is in turn composed by `operator|` with the actual range?
Views don’t own data. In Rust, the Iterator reads some lines into vectors, buffers them, does work stealing, starts processing lines as soon as the first lines are read while new lines are concurrently read, etc. In C++ you have to read the Lines into a Vector First, and then process them, and anything more complicated than that would be a lot of work.
Doesn't this break on transform ranges? The transform returns a value, `reference_wrapper` creates a "reference" (pointer) to that but that pointer is a temporary... Also I feel this could be silently wrong: `*current++;` may point to some internal variable. This variable is destroyed once you return but you have a dangling reference...
&gt; by incurring an overhead that only one of the three major compilers can avoid by optimizations in this toy example. Have you tried clang? The toy example gets optimized perfectly on clang starting at version 5! Seems GCC is just lacking here. Note also that the code is not identical but I'd argue it has the same performance.
In C++ Views don’t allow you to mutate a vector while iterating (by mutating i mean inserting or removing elements). That would not be very safe. In Rust some Iterators own the data, so they ca do that. The applications go from modifying things like the length of the data in place, to just having a ranges::to_ method that knows that the views operate on a vector that will be destroyed right afterward, and therefore it’s storage can be reused, as opposed to having to allocate a new vector for that.
The idea of an optional that's present, but whose value is nullopt anyway is pretty funny.
Very fair. I disagree, because I like having the (for example) `sort` and `nth_element` algorithms available for non-contuguous containers, but it definitely leads to uglier and less-safe code. In a language like Rust, where safety is paramount, I'm not sure how to implement something like C++'s iterators.
I suppose that for ranges that compute a value, like transform, you would return a "copy" anyway (I mean, a value, not a reference). I am not very familiar with it, but if reference\_wrapper does not change the way the return value is used, the range itself could decide if it returns a copy or a reference\_wrapper.
Why not just make a proper package for a package manager such as Conan? That way you don't have to deal with CMake.
I think it's a problem with clang code model. Whenever I enable that, the editor become unusable.
More PVS studio blog spam
Seems like something that should exist as a library for a long time before being considered for the standard.
I think the least disruptive way of achieving this would be with existing free function lookup rules, i.e. 1. Fully qualifying the namespace at the call site (allowing use existing namespace scopes) as per your example 2. Argument dependent lookup (the argument being the lhs of the double dot operator) 3. Importing the namespace with "using namespace". If that is not sufficient, we could have another kind of "using namespace" specifically for UFCS lookup, which avoids polluting your namespace scope with aggressive use of "using namespace". Perhaps "using.. namespace std::ranges::view"?
Oof. Some of the stuff the tool finds here is really interesting, but the tone of this is totally wrong. &gt; The projects authors definitely haven't done their best in fixing bugs before the release. Are you trying to *shame* FOSS developers into using your tool? WTF?
Why? This is just a bunch of useful constants.
Can't we just have both `operator *`, so you could access value multiple times, and `next` method as optional optimization?
If there's two evaluations within the same function, you can just store the result in a local (stack) variable to get rid of the second one.
Maybe it's just me but I have no idea what point you're trying to make or what your question is.
That's not what I mean. Consider the case where you're iterating in a loop, which is what happens behind the scenes in most operations. Your loop will behave like this. for (auto iter = begin; iter != end; ++iter) { do_stuff_to(*iter); } Unrolling the loop to make the problem clear you get the equivalent of the following. ++iter if (iter == end) break; do_stuff_to(*iter); Your proposal for an internal step variable gets rid of the extra predicate evaluations in `++iter` but moves them into the `iter == end)` step. Then when you use `*iter` you inevitably reevaluate the predicate for the current item, just like in the original problem of the article. The caller cannot cache the result of the evaluation during the `iter == end` step because the iterator interface does not allow it. If caching were to be implemented it would have to be done internally by `iter`.
Hmm, you're right, that's a good point!
I really like the idea, but I'm not sure it is **that** useful. It can totally exist as a library to prove its usefulness before being candidate to be included.
The tone of this blog post was a little more 'accusing' and less technically helpful than usual but, as a developer (though not on wireshark), I would appreciate the critique and summary review. The fact that the wireshark team now have access to the full results set and can perhaps sign up for a free ongoing use of PVS-studio is a benefit to everyone. Sure PVS-studio is being highlighted as an answer, but there are other static analysis tooks both free and paid for. I thank PVS-studio for the free efort they devote to continuing to publish these sorts of write-ups.
I’m confused by even the first snippet. “The task is to get the value of T inside” template &lt;typename T&gt; foo(std::optional&lt;T&gt; opt) ?
Are the ICE binary prefixes used with anything other than bytes?
Of course it's subjective, but the article does start by calling (one part) of using iterators "terrible" Personally, I find using algorithms like rotate pretty annoying -- I don't like having to write the name of the container 3 or more times in the same line. And I don't think I'm alone -- isn't this one of the big reasons for the whole ranges thing?
This is not an alternative design; it's an alternative abstraction. A C++ iterator is a stateless, abstract position in a sequence. What's presented here is a stateful interface for consuming elements in a sequence. In fact, if rename `next` to `get` you've essentially defined a Stream. I think it's important to avoid calling everything an Iterator, even though other languages have different concepts of what they are.
Thats already part of boost ratio no? I've no problem with putting some commonly used constants/type aliases into the standard library, but are those really commonly needed? I only interact with the existing ratios through chrono and otherwise never had a need for them. That isn't to say that they are useless, but if they are only used as an implementation detail of some unit library like chrono, I think the user can write out the typedefs himself. Seems like a low benefit, but also low weight feature, so why not?
Or maybe they like their series to consist of actual high quality articles, like this one? https://codingnest.com/modern-sat-solvers-fast-neat-underused-part-1-of-n/ Notice that it gives a proper introduction, overview of one topic along with full explanation and is longer than 1.5 screens.
I'm gonna be honest, never used conan. I've heard good things though.
&gt; have stood the test of time. I hate this phrase so much. It doesn't really mean all that much... it's basically a synonym for "nobody has thought of something better"... which is true until it isn't. It doesn't have more weight than that. And in this case, we've had plenty of problems with the iterator model. The biggest ones being that - iterator pairs need to be the same type - iterator-based algorithms don't compose at all - iterators are incredibly hard to write And smaller ones like output iterators are fundamentally weird, mixing multi-pass with reference stability, etc. The iterator abstraction was a very powerful abstraction that got us a long way. But I'm not sure it has "stood the test of time."
Well said. Naming things is hard :)
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bdw8lu/need_help_with_graphics_using_glm_maths_library/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The arrogance... That's what You get when unsocialized developers write something other than code.
You're calling Svyatoslav Razmyslov 'unsocialized'? Do you know him, or have you just judged him based on this one article? Presuming it's the latter, I'd say namecalling people you've never met is pretty unsocialized.
Sounds like a pretty clear cut case of “maybe not super-useful, but there are good points in favor and it doesn't hurt”. So: Yeah, why not. Though the text itself does read more like a manifesto than it should. Also: More importantly than adding the prefixes would IMHO be to add proper support for SI-units.
&gt; it is profitable to manufacture hard drives in terms of SI units and let naive consumers imagine more capacity than they actually get. Bullshit. Like a "naive consumer" would even know of binary prefixes...
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bdwvm1/loops_and_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Google "rule of three C++". Read wikipedia article. Find blogs on rule of three/five/zero. Read them.
How else can I judge a person who writes in a public forum: &gt; The projects authors definitely haven't done their best in fixing bugs before the release. Isn't this judgemental about the Wireshark team?
Yeah; removed.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bdx68p/im_a_beginner_to_c_help_me_install_and_use/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
For which containers do you want `sort` and `nth_element` available? I'm truly curious. The Rust slices implementation of these works for vectors, deques, etc. but when thinking about the collections for which it does not apply (unordered ones like flat hash maps, or ordered ones like btree sets, or heaps) a generic implementation of these does not make much sense.
&gt; How else can I judge a person who writes in a public forum You could reserve judgment altogether – you know, like a socialized person. ;-] &gt; Isn't this judgemental about the Wireshark developers? No. Saying they're incompetent or incapable of fixing said bugs would be judgmental; what was said was that they _are_ capable, and that the release had a lot of bugs. -- \[Try to\] Keep in mind that the author's native language is not English, and that Russian culture tends to be rather.. direct.
Well, that is because: &gt; you will need to understand pointers first, but that's to complicated for 80% of you anyway actually means: &gt; Actually I don't know shit about pointers
If you don't understand why such a way to call sort is superior then you are hopeless.
If you keep the concepts of sequencial vs random access separate then you make composition harder. For example my implementation of sort might have an initial call to is_sorted to skip sorting if it isn't needed. Is_sorted doesn't need random access. This algorithm could be applied to a linked list for example, but when used from sort, I need to be able to call it using a random access thingy. That is why C++ defines a concept hierarchy.
Sure, but while a consumer may not know the difference between 1TiB and 1TB, it still have a psychological effect just like when shops charge £4.99 rather than £5.00. A consumer thinks they're getting 1 whole TB, when really they're getting 0.9 of a TiB. TiB should be the standard, but it benefits HDD consumers to use a smaller(?) scale (TB) since it increases the perception of the storage space.
Have you seen a mechanism that actually \*effectively\* parallelizes bidits? As far as I am aware: 1. Thrust implements it by copying to a contiguous range first. 2. TBB implements it by not parallelizing random ranges. 3. MSVC++ (my implementation) implements it by forming vector&lt;iterator&gt; containing the division points, but this hasn't been shown to be faster than serial execution. There are a few algorithms that can make use of bidits (the classic example being partition) but I'm not sure if parallelism is much justification.
Meh, just follow the operator precedence order, there are only 17 levels.
Is that still the case? I thought part of the idea of their "front end rejuvenation" project and the experimental Intellisense engine option (which appears to be the default now, at least in VS2019) was them replacing EDG with MSVC's frontend.
I usually prefer C libraries to C++ because in C you actually need to document very well your stuff. However when I find a good one in C++, unfortunately that is not common, is usually overwhelmingly superior to C counterparts.
Rust is a pragmatic language, abstraction is not a goal but a mean to an end. Operations that `Iterator` does not have, that are widely useful, and that `Slice` has, are often implemented for collections that are not slices as well. The cases where I needed this in C++ do not exist in Rust. For example, I like that C++ has `sort` on random access iterators, so that I can use it with `std::vector`, `std::deque`, `boost::container::{vector, static_vector, small_vector}`, arrays, sorted vectors, etc. but in Rust all of these are `Slice`. Thinking about the collections that aren't `Slice`, either `sort` is not an operation that makes sense (unordered collections, collections that are always sorted, etc.), a much better `sort` can be implemented (e.g. quadtrees), or `Slice` sort can be re-used. One example of the later is a vector with holes. It's random access, but the elements are not contiguous, yet the element and holes are contiguous, and you often want to put the holes at the end, so you can just call the `Slice` `sort` with a custom comparison to handle that.
on mobile so only glanced thru the readme, but what's wrong with std::ratio?
To any C++ course you need experience in C++ imo.
/thread ... wait wrong website
Why learn html for a C++ course???
I would prefer keeping big sweeping changes like this in separate libraries. It would be nice if C++ were flexible enough that you could define `for` loop language constructs so that we wouldn't have tied the language down to one specific implementation of ranges.
If computing twice a value when deferecing becomes an issue in any codebase, wouldn't it be enough to add a new range view called `range::memoize` or `range::lazy` that would retain the computation? Having to opt-in to memoize would be good enough. Most of the transform | filter operations are usually cheap or done the other way around (filter | transform).
I always get a weird feeling whenever these articles/advertisements are immediately labeled as spam. Yes they are ads for their proprietary product, and yes they post links on several platforms... I tend to read/skim them and I must say they have improved my eye for spotting (potential) bugs in code.
Any good tutorials that you recommend?
You should learn C++. There are many courses around the internet.
Readability isn't really just about number of characters...
&gt;Is it enough to learn Java/html as a start I'm not sure what that has to do with C++ or game development. Honestly I wouldn't make the jump from Java (or even Javascript, if that's what you meant) to C++ game development all at once. C++ is hard. Game development is hard. C++ and game development at the same time with no previous experience is a real tall order. And if you mean that C++ course using Unreal Engine... ouch, even harder. Unreal Engine can be quite difficult, and their notion of C++ is a bit different than the C++ you'd learn elsewhere. You should say more about what experience you have, what your goals are and the details of this course. In general, though, I'd recommend learning just C++ first. Or really I would recommend learning any easier language first and get some programming experience before moving to C++.
That's great
YouTube channel theCherno
Or a `range::caching_filter` view that wouldn't need to store the whole transformed range at once. The filter knows which iterator dereferences are and are not likely to be repeated, so it can cache only what it needs when it needs it, right?
For making a course? No. For making a game? Depends on what you would like to learn. If you want to make games try Unity or Unreal engine tutorials, if you want to learn everything about how renderers work, gameloops, etc try SFML or OpenGL or both. Tip : Don’t start on your masterpiece as your first project. Start simple and build your way up.
now all we need is good documentation for CMake
Yes, that's still the case. The rejuvenation effort on their own compiler was to make it possible to properly implement things like constexpr and expression-SFINAE (not to mention all C++17 and newer language changes), but Intellisense is still powered by EDG, as is the completion engine in their VSCode extension.
The proposal is for additional `std::ratio` typedefs.
My Google-fu seems weak right now, but I know I've seen references like this, which mentions a "compiler-based intellisense engine": From: [https://devblogs.microsoft.com/cppblog/c-intellisense-improvements-predictive-intellisense-filtering/](https://devblogs.microsoft.com/cppblog/c-intellisense-improvements-predictive-intellisense-filtering/) And there was an experimental setting in the Intellisense options of VS2017 to enable a new Intellisense "engine", or something like that. I don't see the setting in VS2019, though. Maybe my memory is bogus and I'm making this all up.
I'm 99% sure the linked screenshot is VSCode, which is indeed now compiler-driven: using the EDG front-end. ;-] Predictive intellisense (aka Intellicode) is a filtering mechanism agnostic to which compiler is used to obtain the data to be filtered.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bdy5sd/thinking_of_starting_a_c_game_development_course/el1x0y9/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This stuff should probably go to /r/cpp_questions. &amp;#x200B; You never allocate memory for your Numeri\[\] array. Either use the new operator to allocate memory, or use a fixed size array (int Numeri\[size\]) or, preferably, use std::vector.
Yes, exactly
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bdzskb/string_gets_messed_up_in_class_function/el28xgg/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thanks Vince, can we now have a Part 2, of your article, please ? Beyond a "motivating example" :) Some more and different use cases perhaps?
That's not VS team's fault though, and that's a lot more work.
It's not that useful to many people obviously, but it's a small addition that won't make the language more complicated to understand. It's obvious what it does, the implementation cost is really low and while an external header only library would work just as well, it is more annoying to deal with.
Yes, that picture is VSCode and the blog is definitely linking to the wrong picture since the post is for VS. I'll look into what happened there. Thanks for pointing that out
Funny, this all started with a comment on Jonathan's post :) I take it as a compliment, thank you. Any suggestions? Frankly, I don't think I have enough experience with my own creation here to really go more in-depth. Somebody with work experience in another language with a similar design (Java, Rust, Swift according to comments here) could probably have better insights on the benefits and limitations of such "ranges".
I think the idea is that it isn't as surprising in the current syntax as it would be in the abbreviated syntax.
Visual Studio is the best CMake editor now...
He talking about the VS Code web crap.
is there a emacs equivalent extension?
What's wrong with CMake docs? It's perfectly fine, similar to python ones. They should only try to remove dead-ass content that is a legacy of version prior to 3.0
CMake documentation is insufferable, but not the worst, that crown would go to POSIX man pages.
I don't mean to whine, but 6 ads for such a small article is too much. On mobile, I've scrolled them more than the text itself.
It looks like it's going to be way too much, way too fast. It's only 5 months long. For someone who's a beginner-intermediate developer, I would start off with a course from coursera, udemy, or edx. Much cheaper...
Spot on!
Brian, The CfS is coming Real Soon Now™.
What the problem is?
I was learning Rust up to around 6 months until I figured I really cant make anything useful in it yet. Everything is made either for CLI, web, or games. I'm just a college student, not some god-tier programmer, I can't make libraries on my own because of obvious reason. My initial intention of learning low-level language is to do DSP programming and Rust quite suck for that purpose now. But we'll see. If Rust gets better in the future, I might come back to it again. Having built-in security in a proglang sounds great, I'm pretty sure I would appreciate it even more once I worked on some real-world project that allow me to shoot my own feet. As some might say, theory is useless if you don't know its value. Btw JUCE is awesome, if you're like me you should try it.
It's called an [X Macro](https://en.wikipedia.org/wiki/X_Macro).
Assuming this is meant to be a serious proposal, I would suggest the following: * Remove the "Conclusion" claim and the entire "Can we do better?" section. These are total bullshit and make your proposal look like a bad (and late) April's fool paper. Seriously. * Make an explicit reference to the relevant ISO publication, which, according to [Wikipedia](https://en.wikipedia.org/wiki/Binary_prefix) is ISO 80000-1:2009. Remember that the C++ standard is also an ISO publication. * It would be good to check the correct term used in ISO 80000-1:2009 to refer to these prefixes. While apparently "IEC binary prefix" is a common term used in practice, you should use the exact term used in ISO 80000-1:2009. I would not be surprised if they dropped "IEC" and just called them "binary prefixes", but I don't have the paper at hand to support this claim. * Unless sanctioned by the previous bullet point, do not use the three letters IEC in headlines, comments and the in the \[ratio.iec\] section id.
yep, that's great
Just look at the screenshot: add_subdirectory // Adds a subdirectory to the build It basically repeats the function name.
What would be a better description then?
That is your interpretation of what He said. I don't agree with it, so I will stick with mine.
What does adding a subdirectory to a build mean? Look for cmakelists files there and try to merge them? Add the folder to the include path? Add all the .cpp files in there to all binaries generated? How do the objects (whatever they may be) from the subdirectory become available to the project in the current folder? These are all questions I feel like every cmake beginner struggles with.
Which is one of the few features I like in C#. I'm actually all for CS4, but all the other ones in the article are totally not worth it, I can't even fathom how anyone can even argue that what C++ needs are even more complex &amp; subtle overload resolution. If anything, it should be explicit.
"Include CMakeLists.txt in source_dir as part of this build" or something like that
There is cmake-server, but looks like it use not standard protocol and it is impossible to use it via emacs-lsp
Meanwhile, in D... ``` import std.algorithm; import std.range; import std.stdio; void main() { iota(1, 6) .map!((n) { writeln("transform ", n); return n * 2; }) .cache .filter!(n =&gt; n % 4 == 0) .writeln; } ``` Without `cache` it works like it does in C++. With it, it only evaluates the transformation function once per element.
What's ugly about it? You're a \ kind of guy? ;)
Yeah, \ as a path separator should just be deprecated, even on Windows. A bit controversial, but case sensitive file systems should also get an axe, this is the one thing Windows actually got right. There's no reason for why path/Foo &amp; path/foo should be considered separate. I'd actually say that there's no reason for allowing `.` in folder names and files without `.` either.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
C++'s design of iterator as a pointer always struck me as weird. It forces the ownership of the value onto the iterator, which is rather awkward for values generated on the fly. The only real benefit I can see to this model is the abulity to mark an iterator as continuous, which can help with some optimisations.
Announce from the goma team: [https://groups.google.com/a/chromium.org/forum/#!topic/chromium-dev/eOtBzosZtd8](https://groups.google.com/a/chromium.org/forum/#!topic/chromium-dev/eOtBzosZtd8)
You're reallllly going to need to back these claims up. Case insensitive file systems cause massive performance issues. What's wrong with period characters in folder names? Wtf does a file need a period character?
I hope they make documentation so comfortable like Qt did.
didn't mean to imply that is the VS team's responsibility
Sorry, I use an adblocker, so I don't notice... I need to find out if I can move the blog to something else without breaking links too much.
Well that just sounds silly, as if Windows filesystems would be significantly slower than Linux due to case insensitivity. I find it incredibly hard to believe that the usual tricks for case insensitive comparison are inheritly unavailable for file systems. But then I'm hardly an expert on filesystems and would love to read up on the woes of case insensitivity for filesystems. I find case sensitivity to be just a source of errors with no real upside. Do you consider the first do in this sentence a different word than the second? File systems are frequently viewed by humans, and humans tend to consider stuff to be the same as Stuff. It's wrong because it's a HUGE source of programming bugs &amp; errors and unnecessary filesystem hammering. What can you tell me about what operations are valid on this path: `foo/bar`? Almost nothing at all, it could be a file, or it could be a folder ( or a plethora of other things, but that's beside the point because 99.999% of the time we're expecting either a folder or a file ). If folders can't contain `.` &amp; files always contain `.` it would simplify a heck of a lot of code. On the other hand, what's the upside of allowing it in folder names &amp; having files without it?
Will this work with bazel?
I would have to disagree. I honestly love POSIX man pages and wish the whole C++ standard library was documented just like section 3 of POSIX man pages.
Most of the time I have to lookup examples online to use some functions, or to lookup for more documentation about the values that common variables might take.
The one downside of the numerical integration as you have programmed it is that f(x_i) gets evaluated twice for each i, once as the right end point of the interval and once as the left. I would write the loop to only evaluate the right endpoint, and then save that for use in the next loop iteration as the left endpoint. You might also consider discussing the concept of formal order of accuracy, e.g. trapezoid is 2nd order accurate, so doubling resolution improves accuracy by a factor of 4, Simpsons is 3rd order, so 2x resolution =&gt; 6x improvement. That change in convergence behavior can make a big difference in computational cost when high accuracy is needed. Lastly, parable =&gt; parabola. Good stuff!
Thanks these are good points. I tried to get the code more into readability then efficiency. Also you’re right pointing out that a discussion of the formal order would have helped the quality of the post
Honestly, I don't know, but I think goma and "Remote Build Execution" with Bazel + GCP ( https://youtu.be/NcShWeGgWd0 ) are quite different things.
Compare [VirtualAlloc](https://docs.microsoft.com/en-us/windows/desktop/api/memoryapi/nf-memoryapi-virtualalloc) to [mmap](http://man7.org/linux/man-pages/man3/mmap.3p.html). &amp;#x200B; Microsoft (as much as I dislike them) has by far the best documentation I've seen. It's straight to the point, no bullshit. If I need to know what a parameter is, I can usually infer it from the declaration alone. If I need more information on any given parameter, it has a description all to itself. Again, no bullshit, clean and simple, get straight to the point. &amp;#x200B; POSIX? Here's your declaration bro: void *mmap(void *addr, size_t len, int prot, int flags, int fildes, off_t off); Are we going to mention that mmap can map other """object types""" like physical memory? YES! Are we going to mention MAP\_ANONYMOUS (which is implemented by every UNIX kernel) at least once? NOPE! Short and to the point? Fuck that, lets make the word count 3427 (THREE THOUSAND FOUR HUNDRED AND TWENTY SEVEN WORDS) long. &amp;#x200B; The descriptions given in man pages are consistently utter trash. Just go ahead and read through the first paragraph of mmap. Or even something as trivial as strcmp: The strcmp() function compares the two strings s1 and s2. The locale is not taken into account (for a locale-aware comparison, see strcoll(3)). It returns an integer less than, equal to, or greater than zero if s1 is found, respec‐ tively, to be less than, to match, or be greater than s2.
"note: you must join the documentation whitelist group to view the instructions" How about no?
Rust's rayon library does something like MSVC++. It traverses bidits from both ends till they meet, pulling elements into thread-local queues, and then doing the processing in parallel. &gt; but this hasn't been shown to be faster than serial execution unless your predicates et al. are vastly more expensive than iterating the range. AFAICT this is always the case, if your predicates are very cheap and/or your problem size is very small, parallelization is not worth it. Rayon let's users input a parallelization granularity (e.g. the number of elements that should be always processed serially), and this combined with the length of the bidit (e.g. doubly-linked lists that know their length would be one example) kind of kills this issue. There is no magic bullet for this, and if the user does not input a work granularity, the one provided is "incorrect" (e.g. because the program is running in a different system, etc.), then rayon will use heuristics for it, but that incurs a cost that might not be worth it. I mean, using bidits is already a smell, and if you are using bidits over tiny elements, then that smell becomes a stink. But if you have a List of loaded files (e.g. `List&lt;Vec&lt;u8&gt;&gt;`) and each file is big enough, and you want to do parallel processing on that, then parallelism can pay off.
&gt; what it allows that C++ ranges do not? The other comment hinted at this, but "consuming" the input (moving the input into the algorithm | making the algorithm own the input), gives you freedom to choose new implementations strategies. For example, consider `std::stable_sort`. It uses `get_temporary_buffer` internally to get a sufficiently large buffer, when possible. Leaving API issues aside (you can't pass it your own buffer, etc.), if you were to sort a vector with it, and the vector size is much smaller than the capacity, `stable_sort` could just use the storage at the end of the vector as a temporary buffer - no need to allocate a new one. There are many other examples where this matter, but these don't really apply to C++. In Rust, moves are destructive, so if you want to move some elements out of a vector, you need to own the vector, to be able to change its length. In C++ you just would move some elements out, and let default constructed ones in the whole and call it a day (probably hoping that nobody tries to use them as if they were meaningful elements).
All other languages I know (Java, Scala, Smalltalk, Python, Ruby, Rust, C#, Kotlin, . . . and even the C++ GoF book) use the term `Iterator`/`Iterable`/etc. to refer to what D and C++ call `Range`.
&gt; Try writing an iterator in C++ or Rust that can iterate over all numbers of any type -- it's awkward. You have to have more unnecessary state (storing an additional boolean). This is wrong. With Rust `Iterator`s at least you don't need to store a boolean, and doing this is not akward ( https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b7feaa840e7eb3796bb16a435ee7bcb3): for i in 0..=u8::max_value() { println!("{}", i); // prints 0, ..., 255 }
I think you made a typo, doubling the resolution for a third order accurate scheme actually gives you a factor 8 improvement
You're cheating since you're _using_ an iterator not writing one. And the iterator you're using has this awkward implementation. In fact the inclusive range iterator `from..=to` performs worse than the exlusive range `from..to`, see https://www.reddit.com/r/rust/comments/ab7hsi/comparing_pythagorean_triples_in_c_d_and_rust/ecy5pv7/ for reference. For the implementation is rust see https://doc.rust-lang.org/src/core/iter/range.rs.html#329-342, I'd say it's awkward.
Its almost completely missing examples and it is almost no way to differentiate between legacy and best practice
Is this post missing an /s? Get with the times, use smileys wherever you feel it's appropiate. Perhaps spirit should also get a smack on the fingers for daring to use bold text as well?
&gt; if your predicates are very cheap and/or your problem size is very small, parallelization might not be worth it. I've seen wins even with fairly small problem sizes, but all on random-access ranges. For example, parallel sort on our implementation for integers starts to win at around N = 1000.
Yes, looks like it. goma client/server appear to intercept compiler invocations, so it’s more like a distcc replacement that uses Google’s RPE protocol just as bazel does.
It'll be interesting to see how this compares to FastBuild.
Okay, the `VirtualAlloc` is more readable. But both start with a declaration and from there, a simple search in your lister will take you to the point where the argument is explained. And I see nothing wrong in the description of `strcmp` or the first two paragraphs of `mmap`. The opening paragraph of `man mmap` is to me equally hard/easy to read as that of `VirtualAlloc`, but sure, docs can always be improved.
Another alternative is [Gaussian quadrature](https://en.wikipedia.org/wiki/Gaussian_quadrature), which relies on using unevenly distributed points for better accuracy. Using 2 points gives an exact result for degree 3 polynomials (In general, using n points gives exact integrals of polynomials of degree 2n-1), while Simpson's rule only gives an exact result for quadratics.
Why do you want a unique instance of the template? There should be little observable difference compared to a single instance. The main things that would be observable would be static variables (which don't work fantastically in templates anyway) and function addresses?
I've scanned really quickly and I'll actually try it out when I get home, but the gist I feel I've got out of it is that it uses Debian-based docker (I saw apt) so that libs would stay homogeneous. For me I feel that is way easier than trying to maintenance each remote host to have the same headers...
Good point, will probably take it for the next post. Thanks.
So in Julia: x = iterate(iterable) while x !== nothing element, state = x # do stuff x = iterate(iterable, state) end what's the type of `nothing` in `x !== nothing` ? Is it `Option&lt;Iterator&gt;::None` or is it `Option&lt;Iterator::Item&gt;::None` ?
Wrong place, post here: r/cpp_questions
Can you back up the claim that case insensitive file systems cause massive performance issues? AFAIK, most OS just need the filename for the first `open`-call and use a file handle/descriptor for all file-related operations afterwards which does not care about a filename at all.
Some languages do have words that change its meaning when you change the capitalization of the word. I believe even English [0, 1 (the point about the Turkish i]. What if you need both these files in the same folder in a case-insensitive filesystem? Are these languages just fucked? [0] https://en.wikipedia.org/wiki/Capitonym [1] https://news.ycombinator.com/item?id=8876873
This would not be the ranges decision but one from the underlying range. So basically: If underlying range returns reference return reference too, else copy. Not really great for general purpose (potentially big objects) but if the compiler optimizes all away (which in C++17 it probably will due to prvalues) then it should be fine even returning a copy...
I better keep silent next time ... &amp;#x200B; 1. it is not a cliche, we are all crazy busy, with real life mundane C++ 2. I might suggest you make YAGR and whoever can/need/wants contributes ... 3. I am great fan of "do most with as little as possible", I dare to think this is the quality emanating from this R&amp;D. For starters I might suggest examples [from here](https://ericniebler.github.io/range-v3/) (Rv3 doc's) re purposed to use your solution. For my taste Rv3 are way too complex to use. I like the concept, but am uneasy about how it turned out, until now. &amp;#x200B; OK?
Why do they do this?
Tanh-sinh is probably a better topic for the next post. Very easy to understand in terms of the trapezoidal rule, and much more accurate than Gaussian quadrature.
Tnx
Looks like "Vundle for cmake". Good job! With a little more work you could abstract away the VCS and maybe even get this integrated in to cmake itself. It can be looked at as specialization of [ExternalProject](https://cmake.org/cmake/help/latest/module/ExternalProject.html) with just enough API to get the job done, instead of [this](https://stackoverflow.com/questions/38006584/how-to-clone-and-integrate-external-from-git-cmake-project-into-local-one). You could actually use ExternalProject internally to achieve multi-vcs support.
And that’s what I get for replying at 3am while trying to get the baby to sleep... thanks. Fixed.
It's not that hard, [https://github.com/ppetraki/conan-nana](https://github.com/ppetraki/conan-nana) . I would suggest [installing conan from locally pip3](https://docs.conan.io/en/latest/installation.html) (e.g. --user) and add \~/.local/bin to your path. You should be able to hit conan, vcpkg, and hunter in a day if you pushed. &amp;#x200B; [Meson wrap](https://mesonbuild.com/Wrap-dependency-system-manual.html) (pip3 local again) wouldn't be too hard with a header only library like this, example: [https://github.com/nlohmann/json/blob/develop/meson.build](https://github.com/nlohmann/json/blob/develop/meson.build) &amp;#x200B; build2 would be a little more work because of the overall learning curve. However I'm starting to lean in it's direction after experiencing "the full conan", which is starting to look like chef, but written in python.
To learn more about Remote Build Execution, *which is currently an alpha service*... I suppose they mean it's in alpha stage, so they restrict the amount of users.
Thanks for the kind words! Most of the work is actually already done by CMake's own [FetchContent](https://cmake.org/cmake/help/latest/module/FetchContent.html), I just built some version checking, options and error handling around it. At first I was actually trying to implement CPM based on ExternalProject, before I stumbled upon FetchContent in in the CMake Docs! Shame this feature isn't more well known.
My bad sorry.
My bad sorry.
Eh, still doesn't make sense to me. The software is open-sourced, why not the documentation?
It is not a C++ problem, but the implicit passing by value that exists only in C++ may turn off lots of people used to other languages.
To be honest it's a complete non-issue in at least English &amp; Swedish. There's loads of words which have different meaning depending on context, just from the top of my head: mine, cool, fuck etc. Under no circumstance should ever have a file called `Pole` &amp; one called `pole` in the same folder. Disregarding the technical issues of it, it's just asking for problems &amp; confusion.
Really looking forward to it
Yes, EDG powers both VS and VSCode IntelliSense. &amp;#x200B; I think when we migrated the blog to the new platform, some image links got mixed up, hence why there was a random VSCode image there. I remember writing that blog post, it definitely had a proper screenshot originally.
It might be that it has too much stuff internal to Google at the moment.
How do sinh and tanh relate to integration?
We're getting modules in C++20, which obviates the need for `#pragma once` and header files.
Yes, using my own experience. I have a Samba 4 file share that has many thousands of files. Any filesystem operations on it take bloody forever thanks to Samba4 defaulting to treating filenames as case insensitive. I renamed all files in this share with lowercase names, and turned on samba4's feature to force all lookups to be lower-case only. Things that used to take multiple minutes now take a second or two.
Modules is one reason, but determining the identity of a header is non-trivial as well. Are two headers the same if they have the same path? Are they the same if they have the same location on disk (i.e. the same inode)? Are two headers the same if their contents are exactly the same?\\ &amp;#x200B; Different compilers have chosen different strategies for determining header identity, and the all have problems.
&gt; Well that just sounds silly, as if Windows filesystems would be significantly slower than Linux due to case insensitivity. NTFS and Fat32 are slower than several Linux filesystems, last time I saw any performance benchmarks. &gt; I find it incredibly hard to believe that the usual tricks for case insensitive comparison are inheritly unavailable for file systems. But then I'm hardly an expert on filesystems and would love to read up on the woes of case insensitivity for filesystems. There's a wealth of articles on this on LWN.net https://lwn.net/Articles/772960/ &gt; I find case sensitivity to be just a source of errors with no real upside. Do you consider the first do in this sentence a different word than the second? File systems are frequently viewed by humans, and humans tend to consider stuff to be the same as Stuff. Different word? No, different semantic meaning? Yes. &gt; It's wrong because it's a HUGE source of programming bugs &amp; errors and unnecessary filesystem hammering. Filesystem hammering? What do you mean by this. I'd argue that programmers who can't handle the basic logic to distinguish between a file and a directory has significantly worse problems than searching the URI for a period character... &gt; What can you tell me about what operations are valid on this path: foo/bar? Nothing, because simply stating a relative file path doesn't actually say anything of significance. "foo/bar" might be a path to an HTTP resource relative to another URL. Maybe you meant "file://${PWD}/foo/bar", in which case you still don't know whether that's a file, unix socket, sysctl knob, directory entry, hardlink, symlink, tmpdevfs device node, or a variety of other special things that could be represented in the virtual filesystem tree. Each of the possible thing that that path on the filesystem might represent have a different overlapping subset of the possible operations that can be done on an item in the filesystem. The distinction is not, and never has been, only whether it's a directory or a file. It's not like you can't just add a check for if the path represents a directory or not. if(auto path = get_path("file://./foo/bar"); path.is_directory()) Do the thing. else Do the other thing. &gt; Almost nothing at all, it could be a file, or it could be a folder ( or a plethora of other things, but that's beside the point because 99.999% of the time we're expecting either a folder or a file ). Speak for yourself. I find myself expecting things on the VFS to be unix sockets a lot recently. Not so much files. &gt; If folders can't contain . &amp; files always contain . it would simplify a heck of a lot of code. How? Justify this claim. &gt; On the other hand, what's the upside of allowing it in folder names &amp; having files without it? The upside is that the VFS layer doesn't have to care about the actual contents of paths, only that the paths are represented by a unique blob of bytes. You're proposing that the VFS layer be modified to add an extra restriction so that *some* programs *might* have an easier time handling *some* operations, *assuming* that we ignore all backwards compatibility, *and* that making this change doesn't immediately break all sorts of things that use the VFS, like basically everything on a linux system that's not stored in /home/. &gt; EDIT: Here's how to make a good portion of programs malfunction. Look in their data folder, notice for example some_state.dat. Remove it, create a folder, with still the correct rights named some_state.dat. Notice how the program checks rights, sees it's there, then try to write to it only to fail because it's a folder. Wow, that's a pretty incompetently written program? My code would have aborted as soon as it saw the thing was a directory and not a file.
Wait, why are you using one or the other? I'm using both, `#pragma once` before header guards.
Weird to open source it at that point then.
Yeah, well, I don't dig rhetoric much when all I seek is valuable information.
We are about to get modules, which would make this feature obsolete
We are about to get modules, which would make this feature obsolete
`#pragma once` has different semantics from header guards. Pragma does it on a per-file basis, while header guards does it on a per-symbol basis. The exact same file can be included multiple times with pragma if it exists in different paths - header guards protect against this scenario. So the best thing to do is use both. Pragma first, then normal guards.
They're not standard because `#pragma` is for _non-standard_ options. Besides the already mentioned modules support, this would be a very weird precedent.
gaussian quadrature is other worldly. so counter intuitive at first (to me at least) but then it makes so much sense btw it's in boost
gaussian quadrature is optimal for smooth functions. what makes you say TS is more accurate?
it's the name of a common numerical integration technique. sinh/tanh transform the domain from -inf to inf.
You can test simple things like this at godbolt.org. [For example, this](https://godbolt.org/z/9awv3W) Even with minimal optimization, both functions produce the same assembly.
I sadly don't know enough about samba to discuss this further, but thank you bringing that to my attention. I would like to say that this has to be some samba-related issue because I did not had the same issue on a case-insensitive ZFS filesystem. That was a local filesystem though, not a networked filesystem.
Idiomatic hello world in a number of different languages are more understandable than C. What languages are you comparing to? Off the top of my head: python, C#, javascript, and most interpreted languages all have a more understandable hello world than C/C++. Don't get me wrong I love C++ but if you're attributing "brainwashing" to the reason the language isn't liked I think you're off base. The reasons that people don't like it that I've seen is: - A lot of the syntax is clunky because it has evolved over a number of decades and is expressed more nicely in different languages. - The compile and link process is confusing to beginners and errors esp in linking dump terrible stack traces - Template syntax + understanding SFINAE - Memory management was annoying and error prone before smart pointers - Lack of modules/easy code sharing All of those are legitimate complaints. Sometimes the tradeoff of control is worth it and sometimes it isn't and some people won't want to deal with the warts of the language when there are alternatives that fit their use case but don't require worrying about things like "the most vexing parse" etc. I'd also be interested in a citation for your claim of energy efficiency wrt C#/Java if you have one.
What does it do better than icecream+ccache?
Gaussian quadrature is not optimal. See doi.org/10.2977/prims/1145474600
Completely agree, C and C++ require more forethought and discipline to be used effectively, and there are a lot of ways to do things that might be called "wrong" by many. I think a lot of the complaints are historical, before the C++ standards the language was fragmented among platforms and it does require a bit more work to do things that are relatively simple in many other languages. That being said, there are really no other reasonable choices for many applications. You don't code high level managed languages with huge frameworks on integrated devices. In many cases, you don't even get to use the STL in those scenarios. This is, in my opinion, a lot of why C is still relevant today, especially with the advent of IoT, and coders who know how to safely program in C are highly valued for these specialty applications. With the current iterations of C++, the language is becoming MUCH more modern, expressive, and similar in features and flexibility to higher level managed languages. It is a fine time to be a C and C++ programmer!
Maybe it was hyperbolic of me to say "massive performance issues". Perhaps a better term would have been "significant or measurable performance decrease". Fundamentally what's being discussed here is a desire to go from a system (on Linux, anyway) where paths on the file system are *roughly speaking* simply unique sequences of opaque bytes. Toward that end, right now, aside from the path separator, and a very few other specially treated characters, a file name (and thus file paths) are just blobs of bytes with no semantics other than what the user assigns to them. This theoretically (I can't say I have experience with this, as I am a native English speaker and don't use non-english characters in file names) is a great boon for international computing, since there's no need to apply a scheme to the underlying filename bytes that attempts to provide "case insensitivity". The Unicode rules for transforming from "upper case" to "lower case", and doing case-insensitive comparisons are..... complicated. And Unicode is intended to support, theoretically, character encodings for which upper / lower casing something doesn't make sense, but (again, theoretically) "left-casing" and "right-casing" might. Supporting any form of "case insensitivity" automatically means we need to know with what "scheme" that case-insensitivity gets applied. Does it get applied on a per directory basis? Per file? Per underlying storage device? And even if we ignore all of the possible issues that come from the decisions that would need to be made about granularity, it's still fundamentally an additional operation that needs to take place any time you look for a directory entry, and thus a file handle, that might match the file path you're looking for. In the situation we currently have, we don't do all this extra work (except for Samba, grrrr), and file operations happen as quickly as the current amount of "things we do per file operation" permits. In the proposed situation, we would need to apply whatever the decided-upon case sensitivity rules to any operation involving a filepath, which is "significant or measurable" in exactly the meaning of that phrase. Personally I think that the touted benefits are not benefits, and the downside is enough that I don't think it should be done at all. Personally I think Microsoft's decision to make case-insensitvity the default on their operating system was a very harmful decision to the overall computing industry. Your mileage may vary.
don't see why this says it's optimal
What is your definition of optimal? This says that given N function evaluations, no quadrature method can converge faster than O(exp(-CN/log(N)), and then proves that tanh-sinh achieves that bound. &amp;#x200B; But if you definition is exactness on the highest degree polynomial for a given number of evaluations, then by this definition you are correct. In fact tanh-sinh doesn't even integrate constants exactly.
Might be a complete non-issue in these languages, but I do not know enough about every language in the world to say that every language does not have that problem. I understand your edit. It would be very easy, if every major OS had a default filesystem with the same properties. But even then, you would still need to be careful, maybe you encounter a ZFS filesystem with case-insensitivity in the wild, as ZFS allows you to enable both. Note: I do not do this, but had a customer who had done that. I think case-insensitivity in Windows came from a time, where checking if two words match under case-insensitive conditions was very cheap and easy, i.e. ASCII where you only need to clear a bit. I do not know if they would still do this today.
I think how close the result is? but I would expect the two definitions to go hand in hand I saw a link from Wikipedia that said you can computer weights for tanh/sinh faster and I guess that's a plus, but then again you can do that ahead of time for many applications
To be honest, I was only interested in the *massive*. I do understand that there are some performance issues, which, depending on the use case might or might not have influence on the performance overall. Case 1: A DB system opens a few (&lt;5) files during startup to open the actual DB and read/write to them. Here the cost of a few more CPU cycles is mostly negligible. Case 2: Your case with Samba, sadly there the increased amount of CPU cycles do matter. I also understand that case-sensitivity makes it very easy from the technical side - I was not here to argue if case-sensitive or case-insensitive is better (if I do have to: I like case-sensitive more). Considering encoding-aware filesystems too, esp. Unicode has very complicated rules for the whole case folding and normalisation of the byte sequence thing, so I understand that it is desired to avoid it if possible. Microsoft's decision mostly came from a time, where conversions where easy and very cheap, i.e. ASCII where checking would only cost clearing a bit. I do not know if they would still do this today, if they could choose again.
I really like it! We are currently trying to create a conan infrastructure for your embedded projects and our libs but: versioning aport from git our conan packages, ship them to an artifactory, pull them, take the binaries/build from source... just don't feel write in an active development state. Maybe your simpler approach would give us more speed and flexible while developing.
For the energy usage thing: [https://thenewstack.io/which-programming-languages-use-the-least-electricity/](https://thenewstack.io/which-programming-languages-use-the-least-electricity/) The original paper is the very first link of that article, if you want it. There are, of course, the usual imperial scroll of caveats here: they're only using toy programs from the [CLBG](https://benchmarksgame-team.pages.debian.net/benchmarksgame/), they're measuring energy consumption using software APIs instead of a hardware monitor, they don't account for compilation costs when dealing with compiled vs interpreted languages, performance varies wildly between different benchmarks, etc. etc. etc. Once you take that all into account, their raw numbers show that Java uses about 1.5x the amount of energy as C++, and C# about 2x. However, I think selling the choice of programming language based on its *energy usage* to a class of beginning programmers is putting the cart a few miles ahead of the horse.
Hah, I'd say you're right with the energy costs. Especially given the additional context. I think rusts performance there actually impresses me the most. Thanks for tracking that down for me.
Yes, and `Union{Nothing,Tuple{ElementType,StateType}}` in Julia-terms, where `ElementType` and `StateType` can be anything that makes sense to the iterator. For instance: `0x00:0xFF` is a constructor for an object of the type `UnitRange{UInt8}`, when calling iterate you get: ``` julia&gt; iterate(0x00:0xFF) (0x00, 0x00) julia&gt; typeof(ans) Tuple{UInt8,UInt8} ``` Iterating over an empty range: ``` julia&gt; iterate(1:0) julia&gt; typeof(ans) Nothing ```
Usually, Qt-creator doesn't have a debugger, it uses gdb, cdb or lldb. Visual Studio debugger is slow for big projects(more than 2 millions of LOC). It makes a lot of temporary project files. Once it crashes, something will go wrong unless you do a clean build. In Qt-Creator, it doesn't happen. I am using Qt-Creator for more than a year. It has other issues like, experimental plugins may crash, locator fuzzy search is not like visual assist, etc.
I've been learning C++ for about 5 months, and I had a hard time finding a good 2D Vector class, so I made my own. I hope to get some feedback on it, I tried to comply C++17 ideas as much as possible.
I've only looked through the first few lines so far but the first thing that comes to my mind: &amp;#x200B; static const double VECTOR2_MATH_PI = 3.14159265358979323846; &amp;#x200B; Make that &amp;#x200B; static constexpr double VECTOR2_MATH_PI = 3.14159265358979323846; &amp;#x200B; No point evaluating it at runtime.
I have not used constexpr before, but I'll look into it, and I've changed it! Thanks a lot!
Also, how would I make it more flexible? just a #define?
Probably easiest, yes. Something like #ifndef VECTOR2D_DOUBLE_TYPE #define VECTOR2D_DOUBLE_TYPE double #endif static constexpr VECTOR2D_DOUBLE_TYPE PI = ......; would do it, ugly as it is.
Well, could just do a #define VECTOR2D_MATH_PI 3.14159265358979323846...(etc) and that would "solve" it, or I could just use it directly since I'm only using it in one place at the time.. Thank you for the great feedback
Functions defined in the body of a class declaration are implicitly `inline`. Most functions can be `constexpr`. Some of the functions have unnecessarily restrictive types. For example, `dot` could be declared with a return value of `auto` rather than `double`. To instantiate a member variable from a constructor argument, it is generally better to pass by value and move into the member in generic code: `Vector2(T x, T y) : x(std::move(x)), y(std::move(y)) {}`. You could use `= default`. You could use `using alias = type;`.
I'd genuinely be a lot more inclined to avoid using a macro to actually define your value of Pi and make it a static constexpr variable (or even method) instead. You can always define it (at compile-time) as some high-precision floating point value and then static-cast it down to whatever precision is actually being used.
Fair! I'll do that
So with constexpr, can I do that just as long as I only have one return statement? I mean I can put it wherever and it compiles, but should I use it on functions with more than a return statement? Should I use it on templated functions?
Avoid including heavy stuff like ostream and math.
I know that I should avoid it, and I can definitely get rid of the `&lt;&lt;` operator, but I need math for sqrt () ? Or should I just declare it myself?
It’s not entirely clear from this release but this is actually more of a build server proxy/adapter. You use the goma client to send work to this server, which in turn makes jobs for a Remote Execution capable backend. One of which google has for sale, but only at an Alpha level. You can also setup [Buildfarm](https://github.com/bazelbuild/bazel-buildfarm) which is an open source implementation used in production at several companies. The upside of these systems vs ice cream or cache/distcc is that they distribute almost all the load off your machine, preprocessing, linking, compiling all happen in the backend, which lets you really scale out the build. Also the cache is shared globally with all your devs so everyone will do a lot less building. This includes your CI servers which can do “clean” builds a lot faster.
I don't know offhand how close they are. The main problem with Gaussian quadrature is that it is not adaptive. So if you don't think you achieved your required accuracy with N nodes, you have to throw away all those evaluations and retry with N+M nodes/weights. This is partially mitigated with Gauss-Kronrod quadrature, but then you can only refine once before throwing everything away. With tanh-sinh quadrature, you can halve the step-size as many times as you want and all the evaluations you've already performed are reused.
Do you have any tests for this? No tests makes it hard for anyone to consider using this.
As I said I'm pretty new to C++, and I have had a hard time finding literally anything on learning how to actually write tests...
I've used: https://github.com/google/googletest in many projects and think its pretty decent. Luckily, its pretty easy to get started writing tests for a Vector2D class, so it shouldn't be too hard to get some of your code covered.
I guess that's a nice place to start... I still have no Idea what they do, where to put them or anything like that, but I guess I'll have to figure it out. Just seems like one of these things you just "know"
 template&lt;class T&gt; constexpr T pi{ static_cast&lt;T&gt;(3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736)}; usage: `pi&lt;float&gt;` `pi&lt;double&gt;` `pi&lt;long double&gt;`
&gt;I can definitely get rid of the &lt;&lt; operator You don't have to include&lt;sstream&gt; template&lt;class stream_t&gt; friend stream_t&amp; operator&lt;&lt; (stream_t&amp; os, const Vector2&amp; vector2) { os &lt;&lt; "x: " &lt;&lt; vector2.x &lt;&lt; " y: " &lt;&lt; vector2.y; return os; }
Oh damn, thanks! I didn't know that
Tests help verify that the code you wrote does what you meant for it to do. If you have a test suite, it also helps protect your work from future changes that might cause regressions. Like, if you went and modified the way that the dot-product between two vectors worked, you could run your test suite and verify things are still working the way you thought. You would add some tests to your project, the goal being to test as much of your functionality as possible. A really simple example might be that you want to test that adding 2 vectors together works how you expect. You might write test which looks like: TEST(MyVector2D, Add) { Vector2D vec1(10, 10); Vector2D vec2(5, 5); Vector2D result = vec1 + vec2; EXPECT_EQ(result.x, 15); EXPECT_EQ(result.y, 15); } Now, if you were to modify some of your Vector2D code, and somehow broke some functionality which impacted the ability to add Vectors, you'd find out. Without tests, you would not find out until much later. This is a super simple test, but once you have a good test suite which covers all of your functionality, confidence in your own code improves. Also, others will see your test suite and feel more confident that your library does what its supposed to do. I also find tests are really great tools for documenting how your stuff works. I oftentimes jump straight to the tests of a new library to see how the author intended their stuff to be used. Also, nobody "just knows" about testing, in fact many people are very bad at it! It takes time to learn these things, but there is a very large payoff in code stability and confidence.
Okay! Thanks a lot for the insight, I'll see what I can do!
The window is shorter (narrower?) this year than it was last year.
Fair enough. Hard to tell from a single sentence since that doesn't convey tone so well.
And yet, `std::filesystem::equivalent()` is provided. I have never been convinced by the "what about network shares?" comments that always come up when standardizing `#pragma once` is considered. I am not aware of significant differences between compiler strategies for determining sameness, and the world continues to turn despite widespread use of `#pragma once`. If there is real implementation divergence, especially within a particular platform, I would like to learn the specifics.
C++'s Iterator concept predates the existence of most of those languages. It'd be a horrible choice of name if it was chosen today, but "we picked this name and then everyone else settled on a different concept using the same name" is a pretty good example of why naming is hard: even if you make a decent choice now, it may become bad in the future.
Supposedly, some proprietary NFS servers that change inode numbers while the compiler is running. In conjunction with some otherwise-innocuous voodoo involving symbolic links, and the fact that nested includes can be (and often are) specified by either file-relative or project-relative paths, it's possible to construct a case where `#pragma once` will do the wrong thing. The obvious answer is "don't use buggy NFS servers", but it's well-known that companies with a lot of sway insist on using something they already paid for, even when better alternatives exist.
There are other standard pragmas though.
The [Gauss-Kronrod](https://en.wikipedia.org/wiki/Gauss%E2%80%93Kronrod_quadrature_formula) is a gaussian quadrature suitable for adaptative integration.
Not a big C++ user, but wouldn't all those things guarantee the files are the same and thus the same header? You can't have more than 1 file at the same path, itd be the same file, thus the same header. Only 1 file can be at the same location on disk, one bit on disk should be allocated to only one file. If the contents are exactly the same of 2 separate files, are they not producing the same results (unless maybe they operate on files local to their path?) What am I missing?
The library support for the spaceship operator is currently incomplete, and `compare_3way()` has not yet been implemented.
&gt; and compare_3way() has not yet been implemented. Thanks for reply, whereas from the output of godbolt, compare_3way is supported in MSVC: https://godbolt.org/z/htQ0FE
You didn't instantiate the template.
Networked builds
Or don't use \`#pragma once\` on them, which they already can't do.
Try actually using that operator, and you'll see that it's not declared or defined anywhere.
Do you know when will reviewers be contacted/solicited?
If you have two versions of a same header you are asking for trouble. Anything that can break if you change the order of headers inclusion is terrible practice.
C++ headers can be really weird. For example, consider the following header file. #pragma once #ifndef FIRST #define FIRST template&lt;int N&gt; struct holder { enum {value = 1}; }; #else template&lt;&gt; struct holder&lt;0&gt; { enum {value = 0}; }; #endif The value of `holder&lt;0&gt;::value` depends on how many times the header file has been included. Therefore, the programs behavior depends on exactly how the compiler determines whether two files are the same file. Testing with gcc, a symlink is counted as the same file (two different paths, same inode). If two files are bit for bit identical, then they are counted as the same file, even though they are at different paths. However, adding a comment causes them to be treated as different files. However the committee would standardize it, it would be wrong in some case. This is a toy example, and anybody using such a hack is foolish. That said, I'm sure that it is used in practice somewhere, with very good reasons that are hard to change or standardize.
So you basically just get the worst of each and none of the upsides.
Many people suggested memoization/caching, and it is interesting to see that D chose that approach out-of-the-box. To me, it seems a little brittle, because it is now the responsibility of the programmer to determine when caching makes sense, but it is very flexible. It is a good solution to the problem of evaluating the transform twice. Still though, I'd be curious what it looks like to implement your own "iterator/range" like filter or transform in D. I'd hope it is easier than it is in C++.
I also strive for the minimalist approach as much as possible. I usually prefer less code if it is easier to understand, even if it is not as foolproof as some complex version of the code. Don't fight the language! To plug my other article, you can look at [this](https://www.fluentcpp.com/2018/04/06/strong-types-by-struct/) for another example of minimalism on a different topic :)
Think there's something with the rotations, rotated_rad() and rotated_deg() use different rotation matrices and neither return identity for angle=0. Normally you should have two x's and two y's, with cos() terms on the matching components and oppositely signed sin() terms on the cross components. I like that you have all of the component-wise operations, particularly vector * vector. Shader languages commonly support this and it's annoying when non-shader vector libs don't and force you to split to scalars. This won't be for everyone, but I've found it sometimes useful to create vector classes that use POD types and don't have any explicit ctors or assignment operators, relying on aggregate initialization syntax instead (float2{x, y}). This reduces function call overhead in debug builds and allows the vectors to be included in other structures that must be POD.
Try -fcoroutines -fno-exceptions
That would also mean they can't use (or update, if the patch them) any libraries that use `#pragma once`. Which relates to the foo-relative paths thing.
In the end, standard is just useful to keep your code portable. \#pragma once is _pretty_ portable as is, just go ahead and use it - no need to hold back.
You need to build the modules branch of GCC. Did you do that? The details are on the page you linked.
In his defense, EA does both, and has seen improvements in build times, up to 3%.
That is obviously not a use case for paragma once. If you have an #ifndef #else structure in there you are expecting it to be included multiple times, so why would you use paragma one?, I don't see how this is relevant.
In your (and my) dreams
There is absolutely zero reason to use #pragma once if you are already using include guards.
&gt; So the best thing to do is use both. Pragma first, then normal guards. FWIW, I see no reason to do this. The benefits as I see them to `#pragma once` are less clutter, less typing, and removing the mistake where you copy a header file, change it, then wonder why it's not building (because you didn't change the macro you use as a guard). If you're going to use both, I don't see anything else that the pragma buys you any more. Instead, it just adds *more* clutter. The only thing I know of is if you're on some dumb compiler where there's a performance difference that you've measured. But aren't basically all the common ones smart enough to basically do that anyway?
Isn't 3.14... just a double? You might have all those digits written, but that doesn't mean they are compiled into the code. To declare a long double literal, you'll have to suffix it with 'L' or 'l' (minor L).
Suppose someone is modifying a header file, while compilation is running.... Imagining an obscure scenario, where pragma once would break isn't hard. Imagining why that makes it not worth standardizing is. I know of many more projects that can't use exceptions and they are still part of the standard. And running a script that switches #pragma once to include guards is really not difficult if that ever really becomes a problem.
The rule of zero, yes. At minor cost you gain huge usability.
Except of course for the pragma being better to read, maintain, and convey intention.
You are right. Thanks.
Unless I'm looking at the wrong definition, I don't see where the rule of zero concerns non-copy/move ctors, i.e. float2(float x, float y).
Did you experience directly or indirectly any real world problem with \#pragma once? All I hear is a bunch of theoric problems, but I never encountered a real use case where \#pragma once is problematic.
That seems to be more down to the use of pragma than using both or ifdef by itself. The benchmarks I've seen (I couldn't find many recent ones) put pragma as the fastest method.
&gt; I don't see where the rule of zero concerns non-copy/move ctors, i.e. float2(float x, float y). Sort of, for aggregate initialization to work the class/struct cannot have user-defined-constructors, but you're right it can have apparently assignment operators [according to cppref and tested in some code].
When you pull it out of the queue, it's not in the queue. `cq_-&gt;Next()` pulls it out and gives you the value. Then the calls to Proceed() put it back in somewhat implicitly.
I would even go so far to add a pragma "definitely not once" in such a case.
Bike-shedding and insufficient need to overwhelm the same.
&gt; There is no advantage to use of both the #include guard idiom and #pragma once in the same file. The compiler recognizes the #include guard idiom and implements the multiple include optimization the same way as the #pragma once directive if no non-comment code or preprocessor directive comes before or after the standard form of the idiom: https://msdn.microsoft.com/en-us/library/4141z1cx.aspx
Yes, because legacy codebases cease to exist and will be replaced with well functioning codebases that depend on a major language redesign that has never been tested in an actual large scale production system.
Shhhhh Stephan, you're disturbing the FUD
that's cool but you'll have to keep recomputing weights
Regarding all the criticisms of `#pragma once`, what's wrong with simply defining it as-if it was a direct replacement for the semantics of include guards? Most manual include guards are some mangled version of the header file name. It has problems, but the same problems would have already existed with handwritten/maintained include guards anyway.
I hate this reasoning. You are basically saying a considerable benefit to all is not allowed, because some obscure corner case (that might not even be in use in the real world) must also be covered perfectly. What sort of twisted reasoning is that? Just go ahead and standardize it already (using the straightforward rule that files are equivalent if \`filesystem::equivalent\` returns true), and add a note that if you are doing anything that defeats \`filesystem::equivalent\` it is undefined behaviour. After all, that's how we solve every problem in the standard...
Well, if we are going to properly boosterize this, we need to add several variations to cover many cases that average users would not conceive. #pragma none Throws a compile error if included anywhere #pragma at least &lt;x&gt; times Throws a compile error if not included the minimal number of times. Note: less than and greater than is required. #pragma no more than %y% Throws a compile error if the is included more than y times. Note: % symbols are required around the number y to differentiate it from &lt;x&gt;. #pragma at least &lt;x&gt; but no more than %y% Throws compile error if the file is not included at least x times, or is included more than y times. Here we see the use of &lt;&gt; and % let’s us quickly decipher the authors intent on the number of times the header is included. #pragma at least &lt;x&gt; but no more than %y% excepting @z#z1$z2&amp;z3*z4(z5)z6’z7” Throws compile error if the file is not included at least x times, or is included more than y times. The z values allow additional values to be disallowed. Thus, an author could require a file to be included at least 4 times, but no more than 8 times, with an additional disallowance of 6 times causing a compilation error as well. If the z values are outside of (x, y), then the behavior is compiler dependent. Note, at least two working compilers are implemented such that z values outside of (x, y) cause those values to be allowed. Some requests have been made to require all z values to be between x and y, but now there are concerns about breaking existing compilers. There has also been requests to clarify situations where more than 8 z values are needed. In that case, the separating symbols are to be repeated, and placed on a new line. @z#z1$z2&amp;z3*z4(z5)z6’z7” @@z9##z10$$z11&amp;&amp;z12**z13((z14))z15’’z16”” etc...
I don't know exactly where that went off.
I think you misunderstood my post &gt; if you are already using include guards. Pragma once is great if used instead of include guards not in addition.
This is so far the dumbest proposal in the history of cpp so far. It's not an improvement rather a detrimental change which may brake already existing code base not to mention the confusion it is bringing in. If things are going to progress in this direction we, as a community, should seriously consider forking the language!
Who on earth would choose to build on a network drive? It is incredibly slow, and you are at constant risk from collisions with other users also running the compiler or editing stuff in the middle of your build.
Pragma once is missing an identifier, that would allow it to be defined in terms of include guards (not that this couldn't be added if course)
Compared to what?
As the other comment says, `cq_-&gt;Next()` not only returns an item from the completion queue but also removes it so that it won't be returned again. The official example is confusing because they then push exactly the same token on the queue every time, so next time you will get the same thing again after all. But you could have pushed anything onto the queue in the `void* tag` parameter. For example, if you have a class representing an outstanding RPC (like their `CallData` class) you could make your tag a pointer to `std::pair&lt;CallData, CallStatus&gt;` rather than putting the `CallStatus` as a member variable of `CallData`. Then your top-level thread code would look like this: void* tag; // uniquely identifies a request. bool ok; while (true) { bool result = cq_-&gt;Next(&amp;tag, &amp;ok); // Do something with "ok" and "result" std::pair&lt;CallData*, CallStatus&gt;* dataAndStatus = static_cast&lt;std::pair&lt;CallData, CallStatus&gt;*&gt;(tag); switch (dataAndStatus-&gt;second) { case CREATE: dataAndStatus-&gt;first-&gt;create(); break; case PROCESS: dataAndStatus-&gt;first-&gt;process(); break; case FINISH: delete dataAndStatus-&gt;first; break; default: throw std::logic_error("?"); } delete dataAndStatus; } Putting application-level logic in your top-level code that gets the next tag (called the "message pump" in Windows API speak) is probably not sensible. An alternative is to decide that the tags that push on the queue will always be pointers to callback functions. Then your message pump will be simpler: void* tag; // uniquely identifies a request. bool ok; while (true) { bool result = cq_-&gt;Next(&amp;tag, &amp;ok); if (!result) { break; // not sure if this is right } std::function&lt;void(bool)&gt;* callback = static_cast&lt;std::function&lt;void(bool)&gt;*&gt;(tag); (*callback)(ok); delete callback; } Then you can implicitly save a bit of state in the tag (like the `CallStatus`) by binding it into a lambda function. For example: auto fn = [this](bool ok){ this-&gt;process(ok); } void* tag = new std::function&lt;void(bool)&gt;(fn);
&gt; decisions sent by July 8.
I think hold up is the wrong word. To the best of my knowledge, no one is pursuing this. The obje fraction will tell you that we don't need typ improve headers now that we get modules, the other tells you about their super complex build setup, where pragma once doesn't work reliably and as always no one cares about making c++ more accessible for the average user. Well, for what it is worth: pragma once will most likely already work for the code you write and the systems you care about and when it doesn't, it is easy to switch to include guards, so I wouldn't care about standardization.
Be careful, not only the async interface is not well documented, but it has a caveat or two. &amp;#x200B; If you use the async interface, it means that you've RPC procedure that block and the client is likely binding a timeout on its context. To catch those, you either check the context at several point in your processing OR you use the \`ctx.AsyncNotifyWhenDone(tag\_ptr(this, PtrTag::AsyncNotifyWhenDone));\` to get notified. You can end up completing a RPC while the client is cancelling its context which can lead to some use-after-free or double free. It means you have 3 signals that can indicate the end of an operation: ok flag is false, you reached the end of your state machine, or the context has been cancelled. &amp;#x200B; In the end, it is not too hard to get it right but the state machine requires careful design, and async cancel + !ok notification can lead to race condition. What I did to properly trace the execution is to tag the pointer I use as GRPC tag so that when I get them from the completion queue I know what operation they come from. I do NOT rely on it for the state machine, only for logging, but it helped my understand how does GRPC work. For instance I use it this way within the tag: `ctx.AsyncNotifyWhenDone(tag_ptr(this, PtrTag::AsyncNotifyWhenDone));` And when I pop it from the CQ: &gt;PtrTagged&lt;Processable&gt; p(static\_cast&lt;Processable\*&gt;(tag)); &gt; &gt;DLOG(async\_log, debug) &gt; &gt;&lt;&lt; "[cq.Next](https://cq.Next)(): " &lt;&lt; std::addressof(cq) &lt;&lt; ", " &lt;&lt; p.get\_naked\_ptr() &gt; &gt;&lt;&lt; ":" &lt;&lt; to\_string(p.tag) &lt;&lt; ", " &lt;&lt; ok; &gt; &gt;static\_cast&lt;Processable\*&gt;(p.get\_naked\_ptr())-&gt;process(ok, p.tag); &amp;#x200B; Please note that I did not implement a stream RPC using the async interface but it should be very similar.
It's pretty neat that modules does that isn't it? Makes you think why wasn't it added sooner? /s
I appreciate your enthusiasm for sarcasm, but to become a master you mustn't use /s. *I'm a human being, and this action was performed manually.*
The problem is that the standard has no notion of files, just translation units. It would be so nice that the standard has a notion of file as it would ease so many things (especially regarding modules vs build systems). But, as is, you can not standardize `#pragma once` without talking about files and their properties. &gt; I hate this reasoning. You are basically saying a considerable benefit to all is not allowed, because some obscure corner case (that might not even be in use in the real world) must also be covered perfectly. Many parts of the standard are built this way. Just think about the discussion about two's complement integers, or `charX_t` begin UTF-X.
r/cpp_questions
standarizing #pragma once doesn't mean we will have to always use it in every file, it could be an option along with ehader guars, limitted to some scope of use cases.
I find it hilarious that so many people feel the need to punish you for accidentally posting your comment twice.
Great work! Where can I get source code of this debugger?
I'll be trying to upstream it, so you'll get it in clang trunk eventually.
And the world continues to turn despite `#pragma once` not being in the standard. I don't know why people are so hellbent on it being standard. Sure, it'd be _nice_, but I'd rather the committee work on other things than worry about how they're gonna have to actually put pragma once (and 'merging' files/TUs) into the standard...
One example is `#include "foo/bar.h"` and `#include "bar/bar.h"` when `/foo` is a filesystem link to `/bar` .
Thanks! For my projects the usual packaging workflow also seemed overkill and Git Submodules just isn’t flexible enough for non-trivial dependencies. I’m happy to hear that this might improve your workflow as well! :)
just curious if you came across the glm library at all during your search? that's a pretty common library that people use that probably has everything you need and you could compare your implementation against. Not that I'm advocating always jumping to libraries, it's never a bad thing to understand how they work under the hood.
Yeah, I did come across it and I do use it for OpenGL projects, but it feels very archaic and it's not really sleek at all. But thanks for the hint, I wasn't even thinking about looking at it's code, but it's a good idea! I do want it to be as modern as possible, though. Thanks!
Ah, didn't click that since the development is in a branch, it of course isn't in master :/ apologies. Cloning now! Thank you!
&gt; The problem is that the standard has no notion of files, Since C++17 it does, actually. &gt; 30.10.4.3[fs.def.file]file An object within a file system that holds user or system data. Files can be written to, or read from, or both.A file has certain attributes, including type. File types include regular files and directories. Other types offiles, such as symbolic links (30.10.4.19), may be supported by the implementation
can modules export macros now ?
NAS is common in larger environments since it makes it easy to swap out compute nodes. If you submit a job to a build farm, it either has to ship the source to the build nodes and the compiled objects back, or if you're on a common NAS it can just point the build nodes to the source and build directories, which speeds things up since they can be cached.
the stl generally requires only one predicate for utility functions. I agree that's annoying, but it would be more annoying (imo) for different implementations of the stl to be allowed to return different things. no one is forcing ==, &lt;, and &gt; to be consistent. with the spaceship operator I'm guessing this will become irrelevant
This: if (!(lhs &lt; rhs) || (rhs &lt; lhs)) { // lhs and rhs are equivalent } is not equivalent to if (lhs == rhs) { // lhs and rhs are equal } For instance, consider the case: class Person { public: friend operator==(const Person&amp; lhs, const Person&amp; rhs) { // Two persons are equal if they have the same SSN return lhs.ssn == rhs.ssn; } friend operator&lt;(const Person&amp; lhs, const Person&amp; rhs) { // Two persons are equivalent if they have the same last name return lhs.lastName &lt; rhs.lastName; } }; In this case, "optimizing" tuple::operator&lt;() by using operator== on the underlying types if they exist give the wrong result.
&gt;Many parts of the standard are built this way. Just think about the discussion about two's complement integers, or charX_t begin UTF-X. I hate those too ;-) I understand the reason why we have these things, but at the same time, I do believe the standard should occasionally verify that it still matches the general computing landscape. That means adding support for architectural features that are common now (like multiple cores, NUMA, GPUs, vec4&lt;float&gt;, etc.) but it should also mean dropping support for features that have fallen out of use. A good first step would be to look at which architectures actually have C++11 compilers. The standard does not need to concern itself with providing hypothetical support for architectures where people are not writing C++ anyway. As for files, I don't know where this story comes from that the standard doesn't know about this, but have a look at Lexical Conventions. The first two lines literally are: &gt; The text of the program is kept in units called source files in this International Standard. A source file together with all the headers (20.5.1.2) and source files included (19.2) via the preprocessing directive #include, less any source lines skipped by any of the conditional inclusion (19.1) preprocessing directives, is called a translation unit. Clearly it knows about files; translation units are defined in terms of files.
Is it useful to provide `&lt;` and friends? Sure you can define an ordering, but is it useful?
Yeah, for map () for example
&gt; spaceship operator I'm keeping that one.
Just write a script to replace every pragma once with a globally unique include guard and you have an ugly hack to go with your ugly hack of a network infrastructure.
The stl has undefined behavior in seemingly a billion places. Saying that if your comparisons are inconsistent the order is given by any one of the results seems so... benign.
Sure but this is not the case of trivial basic types, and there are typetraits that can figure this out
Why is compare_1 better? What are you using to define "better"? On x86 it appears to be taking more cycles.
What is that "considerable benefit"? What can you do with `#pragma once` that you cannot do without? Not having to type a few characters is not a "considerable benefit" (especially because that can easily be automated away in a decent editor). Having a `#pragma once IDENTIFIER` would clear most if not all criticisms on `#pragma once` (because it makes clear what identifier the compiler uses to determine that two files are the same), and most of `#ifndef` (not having to type stuff twice), but I am not aware of anyone pursuing that road.
_sigh_ “What is the holdup with standardizing a feature exactly like ‘#pragma once’ except with different syntax?” The question was clearly about the _feature_ and not the _syntax_.
As I sad in other response, for integers it cannot return different things no matter you use equality with less or 2 times less, only performance of generated code changes, logic is unafected. and tehre are type traits that can be used. In ohter cases in stl there are optimizations that use typetraits to select different implementation based on input types.
Adding source files with glob\_recurse is bad practice.
I think it was a reddit app bug, I didnt really post it twice I wouldn't take it as a punishment but as just taking advantage of the fact that downvoted comments get hidden, so they are just trying to keep the thread clean.
unfortunately the flat version can't express what the nested one does – you couldn't do `[=](Char ch2) { return pure&lt;R&gt;(R{dg0, ch1, ch2}); }` in the last lambda, because variables introduced in earlier lambdas wouldn't be in scope :(
And as I mentioned, as every other reply has correctly also stated: modules are standardizing something which includes that exact thing, just in as a part of a larger feature.
For a simple project? Certainly not.
Fair points. I'll clarify my post, and rebut it a little as well. \`#pragma once\` is useful, even if the behavior is subtly different with regards to "duplicated" files. If it is unclear whether two files are the same or not, maybe you shouldn't put yourself in a position where that matters. I use \`#pragma once\` pretty regularly. It has bitten me a few times. I used to use header guards pretty regularly. They bit me a few times too. So header guards aren't exactly the gold standard for idempotence either. In a strange twist, the file identity questions are an issue with modules. Modules don't have header guards, so the compiler needs to figure out if two different files corresponding to \`import foo;\` are the same or not. Most likely, it will use the same technology that \`#pragma once\` uses. All that said, I think the original post is accurate in that file identity and "modules are coming soon" are the reasons that \`#pragma once\` hasn't been standardized. Whether those are good reasons or not are left as an exercise to the reader.
All project start simple ;) If you just have one file : just put it in the add\_executable If you have more, each file addition would require a new cmake generation to be picked up... so adding the new files to a variables is just a small extra time, and far less error-prone.
this is well defined behavior. allowing it to choose which comparator would be unspecified and is a horrible idea. unspecified is vaguely ok when it doesn't change behavior. when it changes what function to call... hell no. &gt; the stl has undefined behavior actually the stl is just a list of definitions. so it cannot "have" undefined behavior. you can just misuse it.
the point about type traits is good. it could specialize sometimes. otoh maybe this is the wrong granularity for the change. it would be better if the assembly optimizer could recognize the pattern (can it? I still can't tell from your post) than to write a bunch of specialization. imo.
?
What did you not understand?
Modules achieve similar goals but require an entirely different source code organization model. `#pragma once` is useful when using the inclusion model (aka importing headers with `#include`). Modules are not the inclusion model -- the intent is to remove the preprocessor from the equation entirely. If you're using models, you probably don't even have headers. So no, modules are not a replacement for `#pragma once`, because `#pragma once` is a solution to an entirely orthogonal problem.
less cycles and smaller code at once is better or not ? lets stick to the example results with x86 &amp;#x200B; comapre 1 clang -O3 -march=haswell Instructions: 10 Total Cycles: 13 Total uOps: 15 Dispatch Width: 4 uOps Per Cycle: 1.15 IPC: 0.77 Block RThroughput: 3.8 [1] [2] [3] [4] [5] [6] Instructions: 1 5 0.50 * mov rax, qword ptr [rsi + 8] 2 6 0.50 * cmp qword ptr [rdi + 8], rax 1 1 0.50 jne .LBB0_3 1 5 0.50 * mov eax, dword ptr [rsi + 4] 2 6 0.50 * cmp dword ptr [rdi + 4], eax 1 1 0.50 jne .LBB0_3 1 5 0.50 * mov eax, dword ptr [rdi] 2 6 0.50 * cmp eax, dword ptr [rsi] 1 1 0.50 setl al 3 7 1.00 U ret &amp;#x200B; comapre 1 gcc -O3 -march=haswell Instructions: 12 Total Cycles: 14 Total uOps: 19 Dispatch Width: 4 uOps Per Cycle: 1.36 IPC: 0.86 Block RThroughput: 4.8 [1] [2] [3] [4] [5] [6] Instructions: 1 5 0.50 * movq 8(%rsi), %rax 2 6 0.50 * cmpq %rax, 8(%rdi) 1 1 0.50 je .L2 1 1 0.50 setl %al 3 7 1.00 U retq 1 5 0.50 * movl 4(%rsi), %eax 2 6 0.50 * cmpl %eax, 4(%rdi) 1 1 0.50 jne .L6 1 5 0.50 * movl (%rsi), %eax 2 6 0.50 * cmpl %eax, (%rdi) 1 1 0.50 setl %al 3 7 1.00 U retq &amp;#x200B; comapre 2 clang -O3 -march=haswell Instructions: 21 Total Cycles: 17 Total uOps: 28 Dispatch Width: 4 uOps Per Cycle: 1.65 IPC: 1.24 Block RThroughput: 7.0 [1] [2] [3] [4] [5] [6] Instructions: 1 5 0.50 * mov rcx, qword ptr [rdi + 8] 1 5 0.50 * mov rdx, qword ptr [rsi + 8] 1 1 0.25 mov al, 1 1 1 0.25 cmp rcx, rdx 1 1 0.50 jl .LBB0_7 1 1 0.25 cmp rdx, rcx 1 1 0.50 jge .LBB0_3 1 1 0.25 xor eax, eax 3 7 1.00 U ret 1 5 0.50 * mov ecx, dword ptr [rdi + 4] 1 5 0.50 * mov edx, dword ptr [rsi + 4] 1 1 0.25 cmp ecx, edx 1 1 0.50 jl .LBB0_7 1 1 0.25 cmp edx, ecx 1 1 0.50 jge .LBB0_6 1 1 0.25 xor eax, eax 3 7 1.00 U ret 1 5 0.50 * mov eax, dword ptr [rdi] 2 6 0.50 * cmp eax, dword ptr [rsi] 1 1 0.50 setl al 3 7 1.00 U ret &amp;#x200B; comapre 2 gcc -O3 -march=haswell Instructions: 16 Total Cycles: 15 Total uOps: 21 Dispatch Width: 4 uOps Per Cycle: 1.40 IPC: 1.07 Block RThroughput: 5.3 [1] [2] [3] [4] [5] [6] Instructions: 1 1 0.25 movl $1, %eax 1 5 0.50 * movq 8(%rsi), %rdx 2 6 0.50 * cmpq %rdx, 8(%rdi) 1 1 0.50 jl .L7 1 1 0.25 movl $0, %eax 1 1 0.50 jne .L7 1 1 0.25 movl $1, %eax 1 5 0.50 * movl 4(%rsi), %ecx 2 6 0.50 * cmpl %ecx, 4(%rdi) 1 1 0.50 jl .L7 1 1 0.25 movl $0, %eax 1 1 0.50 jne .L7 1 5 0.50 * movl (%rsi), %eax 2 6 0.50 * cmpl %eax, (%rdi) 1 1 0.50 setl %al 3 7 1.00 U retq
This is an abuse of terminology, muddying the waters. But no doubt you're referring to a definition of a formal meaning, e.g. in the C++ standard. Can you provide a link to that, please.
This is obviously just my personal opinion, but: 1) Globbing makes it easier to just reuse an existing cmake file 2) I can't remember the last time that I had an error due to globbing. 3) I had a few errors due to not adding a file to my cmake file and scratching my had for some time why I got linker errors. 4) Mst projects that start small, but become big have their build scripts completely rewritten in the course a dozen times over. The thing that annoys me here is nitpicking of completely irrelevant details points (a.k.a. Bikeshedding) instead of first asking, if the high level story makes sense: This seems to be a video, that is supposed to show how to quickly get a simple c++ project starting. But instead of e.g. commenting, that you don't have to create a visual studio project and instead can just use visual studio's "open folder" functionality, the first reaction from the c++ community here is to start nitpicking about small details of the cmake file (which anyway are of little consequence, if you consider that cmake is only used to generate project files in this example).
The reason that `#pragma once` hasn't been standardized is mostly just that nobody has gone through the effort of writing a proposal, getting it in front of the committee and defending it. After all, it already works everywhere, so what is the actual payoff of getting it into the standard?
the point to optimise - not sure wher this optimisation should go, but from user point I except to get best code possible. And this matters with operator less for me as it is often used during many sort oeprations.
I was redirected to : [http://box779.bluehost.com/suspended.page/disabled.cgi/www.fluentcpp.com](http://box779.bluehost.com/suspended.page/disabled.cgi/www.fluentcpp.com) &amp;#x200B; Oops ...
From the language lawyer perspective, STL can never have undefined behavior, because it is part of implementation (same as compiler). What it might have is non-conformance with standard.
Header units can export macros now, so you can `import &lt;my_header.h&gt;` and get the macros from it. Macros however, don't go in, just out, so you can't usefully do `#define _XOPEN_SOURCE` and import the header, you have to a -D on the compilation of the header unit.
Yes, I'm aware that it would be unspecified behaviour; I was contrasting it to undefined behaviour, which I consider obviously worse. Saying that the STL ‘‘cannot "have" undefined behavior” is at best unhelpful wordplay. The STL already chooses what functions it calls depending on the codepath it takes. `sort` calls different classes' `operator&lt;`s depending on the implementation, and if your `operator&lt;` isn't a total order then different libraries will do different things. The only difference here is that `tuple` would depend on both `operator&lt;` and `operator==`. There is no new gotcha' here.
I would argue it would be good practice, if CMake didn't have bugs, as it enforce you place and name consistently your files. I personally expect all source files in a directory to be all compiled and all linked together. It also reduce the cost of renaming and splitting files. I personally have a things setup so that subfolders are linked privately into the parent folder. It's incredible the amount of control over symbol exportation that provides.
Playing a bit of a devil's advocate here. The bar for compiler to not include same file twice would be higher than for \`equivalent()\`. For example, I can trick with OS, mount the same device in two different locations with different attributes and no user-space program will be able to determine that the file is the same. Everyone would be fine with \`equivalent\` to report the file is different. Standard will have to recognize that possibility with \`pragma\` and allow compilers some leeway of identifying equivalence of the headers - which means that it will become a quality of implementation issue, and for examples, compilers could choose to compare them based on string path value.
I've posted this library a few months ago, but I wasn't happy with it. The usage and the syntax felt awkward and left-recursion wasn't possible without workarounds. I rewrote the entire thing to give it a better design. The usage is very close to grammar notations and left-recursion - both direct and indirect - works. There is also a feature to parse incrementally (highly experimental). For basic usage see the [wiki page](https://github.com/LPeter1997/CppCmb/wiki/Basic-usage), but there is also the [examples folder](https://github.com/LPeter1997/CppCmb/tree/master/examples). Still missing a few things, like proper error responses, more examples and a bigger set of tests. A possible question that could arise: Why is the character matching parser not a builtin? Why do I have to write it myself? Answer: This library completely focuses on the atomic rules and combinators. It doesn't have the concept of a character or string. You could use tokens, characters, numbers, bytes... I'm planning to write a lexer extension that actually recognizes characters from regular-expressions and produces tokens.
A minor issue is that the docs for `VirtualAlloc` have had minor lies in them for a long time now, at least since WinNT 3.5, and remain still telling minor lies in latest Win10. As much as professional documentation writers usually write higher quality docs than devs do, they're also much further away from the implementation. One thing I will say for the Linux man pages is that when they're wrong, they get fixed. Though they're still inferior to the FreeBSD man pages. Or indeed FreeBSD docs in general.
operator&lt; https://en.cppreference.com/w/cpp/concepts/StrictWeakOrder operator== https://en.cppreference.com/w/cpp/concepts/EqualityComparable And if you have both operator&lt; and operator==, and they are consistent (I.e. a == b is true iff a &lt; b and b &lt; a is both false, you have https://en.cppreference.com/w/cpp/concepts/StrictTotallyOrdered
It's not a new term: https://en.m.wikipedia.org/wiki/Three-way_comparison#High-level_languages
I think of the stl as the standard template library, so it cannot nonconform. an implementation might not conform. and I think the implementation could be undefined...but that would be a bug
How are you generating these reports?
I just took a look at godbolt. you're right with clang: it emits bad code for the built in comparison. probably that's llvm's codegen's fault. GCC optimizes to one comparison per tuple member. GCC even translates your implementation to one comparison. very cool also, looking at the assembly made me realize your implementation might be wrong for doubles when they are Nan. since that's unspecified, any change is not allowed. so I guess really this optimization can only be made for very few types
[https://godbolt.org/](https://godbolt.org/) clone run on my local machine with compilators on my machine
Hi, i am a parser newbie so I hope the question makes sense: Can this be used to generate an AST for a programming language ?
Hi! Sure, you can! You can use the transformation functionality of the library to transform the raw output into anything. I'm planning to write an example that includes building an AST. An example: ``` ast_node* create_addition_node(expr* left, char op, expr* right) { ... } auto parse_add = (subexpr &amp; ch('+') &amp; subexpr) [create_addition_node]; ```
I think there was a proposal some years ago (I think between c++14 and c++17), but I've no Idea, what happened to it.
&gt; There is no new gotcha' here. Except that with your proposal, instead of requiring users to implement only `operator&lt;`, you suddenly require them to implement `operator==` as well. You'd break some of my code with this change.
I remember some benchmark, where once was even slightly slower, but don't remember the details.
code is generated with clang 8 and gcc 8.3 on linux with gcc stl. gcc - can generate much different code depending mcpu/march and as I remember code for cortex-a72 with out of order exeution can be worse that for just entire arch aarch64 with in order cpus ths is from golbot https://godbolt.org/z/dz1qAB acutaly no difference to my. -O3 -mcpu=cortex-a72 compare_2(std::tuple&lt;long, int, int&gt;, std::tuple&lt;long, int, int&gt;): ldr x3, [x0, 8] ldr x2, [x1, 8] cmp x3, x2 blt .L3 mov w2, 0 bne .L2 ldr w4, [x0, 4] mov w2, 1 ldr w3, [x1, 4] cmp w4, w3 blt .L2 mov w2, 0 bne .L2 ldr w2, [x0] ldr w0, [x1] cmp w2, w0 cset w2, lt .L2: mov w0, w2 ret .L3: mov w2, 1 mov w0, w2 ret
I stopped using RPC a long time ago. Just use async (messaging).
I've been keeping an eye on your updates in r/ProgrammingLanguages, looks like a very cool library although I am not fan of just having a large header. I wrote some basic parser combinators (although never wrote a library worthy of that name or any code that I would shamelessly release) and it's an amazing pattern but I've tried without success (but other attempts are planned) to think of ways to have generic error handling and ways to continue parsing after an error is encountered. Did you solve (or try to address) these problems ?
Just curious why does it feel archaic to you and not really sleek at all? Any C++14/17 things that you're missing? And the library is pretty organized and lightweight actually, I'd say?
Error-handling is still on my TODO-list, but I've experimented with some rules that will certainly help me solve this. [This blog](https://www.scheidecker.net/2012/12/03/parser-combinators/) gave me some ideas. I'd like to get to it very soon.
Or just make all non-trivial cases implementation defined behavior (or probably undefined behavior).
This seems like it it stretching really far. I can't imagine that you are actually pulling in headers from two versions of a project, mounted at different locations. Plus, at that point you could drop in an actually different version and have just as many issues.
\&gt; The parser combinators propagate that failure information outward, but may be absorbed if an alternative parser succeeds. Only when the failure is returned from the outermost parser does it become an error. At that point, the failure has information about all the alternatives at the point of failure, and can be turned into a useful error message. I have tried something along these lines and this is very much doable if you stop at the first error, however I didn't manage to modify the scheme I was using to allow to skip token(s) and/or a parser(s) (from the current stack) and continue parsing building a tree with "error nodes". In any case, I will continue to follow your great work there. :)
You might want to take a look at build2's packaging architecture as an alternative to conan. [https://build2.org/build2-toolchain/doc/build2-toolchain-intro.xhtml#guide-consume-pkg](https://build2.org/build2-toolchain/doc/build2-toolchain-intro.xhtml#guide-consume-pkg) It can handle unpackaged and system deps fine too. &amp;#x200B; The more I work with conan the more alarmed I get that it will turn into a DevOps mess like chef. From the recipes subset I've examined, there's a strong bias to source based dependencies, which in essence turns conan into an inverted container distribution with spotty coverage to ensure the deps are maintained, reused, and kept secure. &amp;#x200B; It undos a lot of what cmake provides via find\_package and neglects to do the fallback work to find something via pkg-config. Because if it's not there, you need to be an admin to install that package, which cramp's conan's easy install style. &amp;#x200B; I would sleep a lot better at night if I started with a container release of Ubuntu or Arch and started pushing everything it provided from those hardened source packages into whatever package manager my organization settled on and then examined what varied across other platforms I need to support and package that as well. &amp;#x200B; Then there's a great single source of truth to start from e.g. the Linux distro, and only the cross platform variants to really concern yourself with. You also get base platform updates for free, just setup a CI to fetch and build new versions.
Hi, I found a bug in the wording on the page: *If so, consider sharing it with other C++ enthusiasts by giving a regular program talk at CppCon 201****8****.*
Thank you for your answer. If I try to compile code that uses your library are there helpful error messages ? I found this to be pretty bad with boost::spirit, etc.
As I've mentioned, error-reporting is still a TODO, but is high priority. I'm planning to do that in the following weeks.
The benefit is not having to pollute each and every header with a set of magic incantations that are easy to get wrong (and many people do, using various reserved combinations of characters). It goes at least some way towards restoring a situation that should have been the default from the beginning, which is that headers are units, rather than just textual inclusions. It avoids nasty problems like accidentally having the same include guard twice, or accidentally having a different phrase in the #ifndef and the #define. If it were up to me, `#pragma once` would disappear tomorrow - because it would be the default for each compilation, with `#pragma multiple` replacing it for those people who really want the same file included multiple times. This should be easy enough - if you can 'automate it away in a decent editor', you can also automate it away in a decent compiler.
so .. with concepts in c++20 it could be specialized for all types that have strict totaly ordered comparision this could by optimised with type trais at compile time without breaking anything.
And how do you define "the same file"? Build systems that copy files exist. Compilers with builtin magic to have &lt;cstdio&gt; vs &lt;stdio.h&gt; in one file exist. Projects that merge header files ("amalgamation") exist. Attaching a unique identifier to each file solves these problems reliably and predictably. Attaching a unique identifier when a file is created can be automated easily. Figuring out in retrospect what files are copies of each other can not.
You have ended your std::count line with endl;
&gt;endl Thanks
&lt;&lt; endl; to be precise
It still does not work what to do??
I meant the cpp-compiler errors, in difference to parser errors. When debugging those the stack the cpp stack got really huge and this made a hand-written parser attractive(Small understandable stack). Additionaly the compile times of a hand-written parser were way better than with boost::spirit. But I think I will try your solution. Maybe it will save me some time compared to a hand-written parser.
Where is your code for the time? Where is your code for the joke?
the line for time is : the time is and the joke is a work in progress
I’m new to C++ myself, like 3 weeks but you don’t need to be using for single letters like ‘I’ and ‘B’, use ‘char’ for that, any text you send to the console should look something like this std::cout &lt;&lt; “write something cool” &lt;&lt; endl;
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bepbx5/code/el7jvqy/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
do you have 1 or “1” for your comparison?
Oh, my bad! I've tried to include some static assertions to help to some extent, it actually saved me a few times. But I think I can still improve.
I had a brief look at one of the examples and it reminds me of boost spirit a little..
Some syntax is boost-inspired, like the transformation syntax with op[]. But honestly, didn't use it that much to spot any more important similarities.
Fair enough! Good stuff! :-)
god. no.
In practice, I've found that touching the different objects for comparison ends up being the slow part of using operator&lt; in any kind of sort operation. The only time I haven't seen that to be true is when comparing stuff like strings where they can be huge and may not compare &lt; for some time but can short-circuit on equality when size != other.
It's a video to teach people how to do something. If we aren't teaching good practices then what is the point? It's like every time I need to search how to do something in CMAKE the correct way I run into a thousand different posts that show how to do it.. but do it in the wrong way.
Thanks for trying to cough up a reference. I see no definitions of "equivalence" versus "equality", though. In the first of the tree reference the term "equivalence" is *used*, in its mathematical meaning. Simple `==` as shown in your example is also a mathematical equivalence. In fact the current standard uses the term "equivalence" about a properly implemented "==", e.g. as in table 20 in C++17 20.5.3.1/2. --- I gather that the anonyous downvoter disagrees with the notion of using technical terms properly and not offer nilly-willy assertions, but lacked any argument, hence, voting.
Just searching Canon gives me a headache. It isn't immediately obvious how to do so, for one. And two, you have no idea who and where these things are hosted. Canon seems like a clusterfuck to me.
One can also treat \`#pragma once\` as a syntax sugar for header guards within the given file.
Thank you for your replies. I tried the library and it is actually quiet intuitive to make an AST while parsing 👌. But the error reporting can be quite verbose: For example if the type given to the cppcmb_decl macro mismatches the one I return in some user defined function the error msg is not very helpful. Could this be fixed with assertions ?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/beqgc5/help_with_homework/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's a lot like when YUM was invented so RPM could catch up to what dpkg and apt have been doing for years. I really don't want to see a repeat of that. To your point, I shouldn't have to specify which upstream to search into when I want a package (apparently -r all works). If it were Ubuntu and I have main, universe, and multiverse enabled, it's "just going to find it" and it will "just work". Their "main" is really really small and it's like everything that's interesting lives in "multiverse". I can't even ask the question "what does Qt depend on?" without sudo. ppetraki@vanguard:~$ conan info Qt/5.11.0@bincrafters/stable Qt/5.11.0@bincrafters/stable: Not found in local cache, looking in remotes... Qt/5.11.0@bincrafters/stable: Trying with 'conan-center'... Qt/5.11.0@bincrafters/stable: Trying with 'bincrafters'... Downloading conanmanifest.txt [==================================================] 152B/152B Downloading conanfile.py [==================================================] 9.3KB/9.3KB Downloading conan_export.tgz [==================================================] 1.9KB/1.9KB Decompressing conan_export.tgz: 100%|██████████| 1.84k/1.84k [00:00&lt;00:00, 804kB/s] Qt/5.11.0@bincrafters/stable: Downloaded recipe revision 0 Running: sudo apt-get update [sudo] password for ppetraki: &amp;#x200B; Really? C'mon. &amp;#x200B; The danger with conan is that the C++ community is basically desperate for a packaging solution and it's catching on without people understanding the consequences of the future tech debt.
As I can 'grep' my memory ;-) I never wrote code such that it have equivalence of overlaoded less operator not matching overlaoded equality opertor (only strictweakoredering from c++20 cncepts). I always in such situations when I need custom less operator that uses partialy object of comapraision I used algorithms with custom function object comaparisions. I tought about that as proper implementationand quality of code to have a matching overloaded comparision operators (stricttotalyordering from c++20).
Personally, I prefer doing it a bit differently for personal projects. Variant A: * create (or clone from VCS) folder with CMakeLists.txt and sources; * `cd` there and run `cmake -H. -Bbuild -G "Visual Studio 15 2017 Win64" -DCMAKE_TOOLCHAIN_FILE=&lt;path to vcpkg.cmake&gt;`; `-B` and `-H` are undocumented options, so there's a risk they get broken, but I'm OK with that; * build with `cmake --build build`. Optionally, add `-- -nologo -v:m` to reduce MSBuild rubbish; Variant B: * create (or clone from VCS) folder with CMakeLists.txt and sources; * open the folder from Visual Studio or VS Code - they support CMake natively (VS code requires extensions though); * in `.vscode` folder it creates add file `settings.json` and put there &amp;#8203; "cmake.configureSettings": { "CMAKE_TOOLCHAIN_FILE": "&lt;path to vcpkg.cmake&gt;" } configure and build. The upsides of the variant A (compared to the variant B) are: 1. works without fancy editors and extensions; 2. automatically finds the path to VS and sets up include and lib paths correctly (so, can be used outside the "VS command prompt" once configured); 3. can be used with VS versions that don't work with CMake natively; The downsides of the variant A (compared to the variant B) are: 1. uses MSBuild which is slower than Ninja and prints extra rubbish if extra flags aren't added; 2. The .sln and .csproj files are generated and one still needs to edit CMakeLists.txt first and then regenerate them, which is counterintuitive; (It's obviously possible to use CMake with Ninja and MSVC from command line, but I can't find the right incantation: it either tries to pick pieces of UNIX toolchains (e.g. Cygwin's `ld` for linking MSVC `.obj` files) arbitrarily or generates the Ninja files correctly, but without proper `include`/`lib` paths, so I have to run it from "VS command prompt", which I'd rather not.) Compared to the OP's approach, I prefer not to put path to `vcpkg.cmake` into the `CMakeLists.txt`, because the actual folder with `vcpkg` may be in different places on different machines. I also put the `build` folder under the project folder, which may require adding it to`.gitignore` or its equivalents;
Why on earth would you ever need a thousand digits of pi?
If I remember correctly, there were some performance issues with Qt in general on macOS until recently. Did you also observe that on other platforms?
The C++ STL isn't that all. Smalltak, Scheme, ... happened before it, Haskell happened more or less at a similar time.
comparing it with spirit: how ... close or far are you from them?
A year ago I looked for modern parsers and found only ones that were either modern but lacked "tooling" or annoyingly old (like spirit or worse) but with a decent library of utility parsers. In the end I settled with: giving my students another exercise (Haskell+parsec is better suited for that anyway)... Does your parser come with a small library like spirit or do I yet again have to reinvent parsing floats?
Stepanov created the first C++ version of the STL in 1993, one year before the GoF book was published and two years before the first version of Qt. Haskell existed, but was a toy research language.
Well, for the standard library it is well specified, that depending on the overload sets in the standard library can break between versions, as they are free to add overloads to std:: functions at any time. So you are not allowed to take the address of a function im the std namespace (or at least discouraged). But yes, changing the lookup rules would still be a breaking change, especially in client code.
The suggestion here is ultimately to replace if (lhs.x &lt; rhs.x) return true; if (rhs.x &lt; lhs.x) return false; With if (lhs.x != rhs.x) return lhs.x &lt; rhs.x; This doesn't work in the current (up through C++17) STL model since StrictWeakOrder doesn't say anything about != and the library can't just check if it's available since it might be sfinae unfriendly. It's also not generally a good idea since the != operation itself might be expensive and we're not gaining much information out of it. Sure it's better if we just have ints or in the ideal case where our x's are strings of differing lengths, but worse in others. In C++20, we can do better: if (auto c = lhs.x &lt;=&gt; rhs.x; cmp != 0) return cmp; The single three way comparison gives us all the info we need in one go, in a way that can be more efficient than two operations (e.g. for string it's one call to compare() instead of potentially two)
&gt; no one is forcing ==, &lt;, and &gt; to be consistent The new [`StrictTotallyOrdered`](http://eel.is/c++draft/concept.stricttotallyordered) does have this requirement.
... and is being removed from the library anyway.
Compared to not using pragma once and only using include guards. The documentation didn't say which compiler, it said "Some compilers". My guess would be MSVC.
&gt; so adding the new files to a variables Why do people do that actually? Why not just keep appending to the list in `add_executable`? I don't see the purpose of `add_executable(name ${SOURCE_FILES} ${HEADER_FILES})`.
It's definitely in the same "spirit."
Distributes caching, preprocessing, and probably linking.
Hello, Your request of unsigned types support is now queued up officially. You can track it in Developer Community : https://developercommunity.visualstudio.com/idea/539086/openmp-unsigned-typed-induction-variables-in-paral.html Feature suggestions are prioritized based on the value to our broader developer community and the product roadmap. So please go there and vote for it. In the meanwhile, please open a task there for your other requests.
Hello, Your request of size_t support is now queued up officially. You can track it in Developer Community : https://developercommunity.visualstudio.com/idea/539086/openmp-unsigned-typed-induction-variables-in-paral.html Feature suggestions are prioritized based on the value to our broader developer community and the product roadmap. So please go there and vote for it. In the meanwhile, please open a task there for your other requests.