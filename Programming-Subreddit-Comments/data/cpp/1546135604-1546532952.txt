You meant standard serial executor. The Networking TS have it's own but it's not supposed to be used in general code. You better have a bunch of serial executor implementations instead and use executors in interfaces.
&gt;Interop with other languages. absolutely, many languages have very nice built in bindings to C but not to C++ and this of course is partly due to the massive extra complexity of doing such a binding but also in large part due to lack of a standard ABI. I don't watch the discussions that closely but it seems that the Itanium ABI is very popular... &amp;#x200B;
What do you think about how D solves the preprocessor problem: https://dlang.org/articles/pretod.html
Interestingly, boost.runtime_cast (part of the typeindex library) claims to be significantly faster than dynamic cast whilst meeting feature parity. 
What kind of monstrosity of spaghetti code are you even working that causes that kind of cumulative pain? Sounds like pure hell.
That’s a good point about the iteration!
The issue is more that say I’m getting some error involving a vector / iterator / array. If it’s `std::vector` or something company specific like `eastl::vector`, I can be pretty sure the vector implementation has been thoroughly used and tested in millions of lines of code, whereas if I’m using `one_senior_devs::vector`, it’s *far* more likely I have to start debugging there, because even if the bug isn’t there, I need to judge the quality of one dev’s vector implementation to know that.
D doesn't solve all the problems C preprocessor solves, although it does alleviate a lot of them (and changes them to use a different name), so... yhea.
For the Manual RTTI code did you write it as a switch like a normal person would have? Something seems to have tripped up gcc. Can you share your code?
But wait... \*I\* wrote the vector I'm using, and the tests that test it. And there \*is\* a million of lines of code that is testing it every day. My vector code is no more likely to be buggy than the ten thousand times more other code I've written If the argument is you shouldn't use code that you wrote because it might be buggy, then we should all just quit, because the vast majority of our programs is code that we wrote, not code that has been used by hundreds of thousands of other people. If I'm incapable of writing a fully correct vector class, I would be completely incapable of writing the enormously complex and powerful automation system that sits on top of my general purpose code. To me, writing a vector class is a relatively small thing. I've written many things that are orders of magnitude larger and more complicated. Maybe, and I'm just throwing this out there... I'm damn good at what I do, and you don't have to worry about me? &amp;#x200B;
Can you name the problems not solved by D?
Platform specific things that only exist in that platform is hidden behind "version", which is literally the pre-processor.
That's a good point. I provide links to the code used for timings in the post. I did not originally use a switch statement for the manual RTTI approach, so I've gone ahead and done it. on clang ([http://coliru.stacked-crooked.com/a/d59814e0765c3499](http://coliru.stacked-crooked.com/a/d59814e0765c3499)) Typeid: Avg elapsed time: 47.75 ms, stddev = 7.71107ms Dynamic Cast: Avg elapsed time: 182.25 ms, stddev = 19.8119ms Manual RTTI: Avg elapsed time: 35.85 ms, stddev = 3.67459ms Single dispatch: Avg elapsed time: 36.9 ms, stddev = 5.93739ms Double dispatch: Avg elapsed time: 37 ms, stddev = 3.94702ms on gcc ([http://coliru.stacked-crooked.com/a/a193bc0b56c0a085](http://coliru.stacked-crooked.com/a/a193bc0b56c0a085)): Typeid: Avg elapsed time: 46.1 ms, stddev = 5.79383ms Dynamic Cast: Avg elapsed time: 210.4 ms, stddev = 32.7662ms Manual RTTI: Avg elapsed time: 38 ms, stddev = 3.62738ms Single dispatch: Avg elapsed time: 34.85 ms, stddev = 3.74552ms Double dispatch: Avg elapsed time: 42.25 ms, stddev = 7.59415ms
I suspect an array on that dimension is calling for a proper class to add semantics, but of course I don't have any real understanding of your use case. Assuming you're interested in dense multidimensional arrays, a typical choice would be the tensor library in Eigen. For something a bit more modern along the same vein, there is xtensor. I haven't used it myself, so I can't vouch for it, but it looks very promising.
This is interesting. TIL about boost `runtime_cast`. I find it kind of funny someone at Boost decided "hey, dynamic_cast is implemented so poorly in general that I think we'll just make our own". Seems a bit intrusive to add to a codebase, but not overly so.
But Modules are coming no?
How does that fix things? It still gives different results depending on bfs::path vs stdfs::path.
That's a really good point. 
I'm still getting 49MS on manual vs 21MS on double-dispatch. Are you using g++ 8.2.0? I do have a suspicion that my processor might be switching into performance mode right after manual RTTI and throwing the benchmarks. If that's not the case, then I guess it could just be another problem my computer is having right now. I'm going to reset my CMOS and try again.
Yeah, if I'm understanding correctly, why isn't this just at patch on gcc / clang?
I find myself using this sort of pattern when dealing w/message formats that are designed to be serialized as-is. What would actually be very useful in C++ is if you could custom define a field &amp; type &amp; values for the vtable pointer. I.e., something like struct Animal { typeid char animalType; .... } struct Horse: public Animal('H') { ... } And then have the compiler figure out appropriate dispatch code given the type, values, vtable size, etc. I wonder if that's ever been proposed, is impossible for some reason, etc.?
It shouldn't. Example given above should produce the original expected result of a path with "/a/b/c/d". Point being made is std::fs uses the '/=' and '/' operators to direct a appending to a path. The "+=" and "+" operators are not used in std::fs. So, unlike a string where you can concatenate using addition, std::fs doesn't behave that way. I can sort of see the semantics behind the notion. 
I added a slightly more in-depth comparison between CMake and bake here: [https://github.com/SanderMertens/bake/blob/master/README.md#how-does-bake-compare-to-cmake](https://github.com/SanderMertens/bake/blob/master/README.md#how-does-bake-compare-to-cmake)
As expected, that code example produces "/c/d" in g++ 8.2. int main() { std::filesystem::path x{"/a/b"}; x /= "/c/d"; std::cout &lt;&lt; x &lt;&lt; std::endl; }
Does compilers provide pre-instantiated templates like std::string? I mean i can understand the need to compile vector, but there is no need to instantiate string for every translation unit.
I just tried out some sample code. I see what you're getting at. I agree. Different results are being produced. The code... int main() { fs::path x{"/a/b"}; x /= "/c/d"; std::cout &lt;&lt; x &lt;&lt; std::endl; std::cout &lt;&lt; fs::absolute(x) &lt;&lt; std::endl; return 0; }; should produce the same results if `namespace fs = boost::filesystem;` or `namespace fs = std::filesystem;`. Where I believe std::filesystem is failing, and the problem we're encountering, is in the append statement as it is preceded by a slash. I suspect it is being "interpreted" to mean a root path. From [the description of std::filesystem::path::append](https://en.cppreference.com/w/cpp/filesystem/path/append) &gt;If p.is\_absolute() || (p.has\_root\_name() &amp;&amp; p.root\_name() != root\_name()), then replaces the current path with p as if by operator=(p) and finishes. This may be a bug. I'd punt this to standards PTB's to resolve (see [here](https://isocpp.org/std/submit-issue) for how to do that).
This is useful but a bit densely written. For more details on this problem, I believe there's this classic: [https://ericlippert.com/2015/04/27/wizards-and-warriors-part-one/](https://ericlippert.com/2015/04/27/wizards-and-warriors-part-one/) In most class A-class B interactions, what you really want is a class C that handles it.
I missed a step here in the explanation. I did get the append to work but I had to remove the leading slash (and possibly why being mistakenly "interpreted" as a root path). fs::path z{fs::current_path()}; z /= "c/d"; std::cout &lt;&lt; z &lt;&lt; std::endl; This snippet will produce the expected result of "/a/b/c/d". Note missing leading slash on append statement.
Is this your college paper you’d like written?
&gt; What has changed in how computers work since 1985? Nothing at the core, a lot in the details. &gt; Is the vision of C++ still as valid today as it was 33 years ago I don't think the vision of the language today is what it was 33 years ago; it's shifted with the times.
What this blog post calls a "single dispatch visitor" isn't a visitor at all. It's just a normal virtual method taking a `Person` as a parameter (wrapped for no reason in a `ReactionVisitor` object). What the post calls a "double dispatch visitor" is an actual visitor. The double dispatch is the whole point of the visitor pattern. If you replace the double dispatch with single dispatch it's not the visitor pattern anymore because it's indistinguishable from any other virtual method call.
1. People are now born with a cell phone stapled to their hand, and everyone who wants to get VC money has to pander to that audience pretty much I'm guessing. 2. Google figured out how to make a butt load of money off of us without having any actual obligations to us, and now everyone is trying follow suit by forcing us all into a monthly fee or add based digital service economy. 3. The personal computer revolution is being undone and we are coming full circle to just owning the equivalent of a really pretty terminal. 4. Endless effort has been spent on the browser to get it to the point of being a half-baked application platform. &amp;#x200B; All of these things are pushing the world away from what C++ is best suited for, sadly. It's all about small scale 'apps' written for phones or browsers to provide a means to access cloud based services. Yeh, a lot of the back end servers and the OS underneath those apps and the browser itself may be written in C++, but the venture capital and crazy IPOs and the new jobs and such are moving elsewhere in a major way. I think that sucks, but it is what it is. We are entering the 'auto-tune' era of software. But, hey, I'm not cynical about it or anything.
I'm a self employed web dev and copywriter, I'm a bit past college. Why bother posting at all?
Can you elaborate a bit?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/aate60/beginner_needs_code_to_be_reviewed_by_experts/ecuyc5v/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/aatw09/i_have_an_exam_tomorrow_on_oop_how_can_i/ecuyf93/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Thinking about consumer-level hardware: The hardware's still doing a classic sort of fetch-decode-execute loop, conceptually. But really, you've got deep instruction pipelines, speculative execution, branch prediction, and multiple levels of data and instruction cache that all have performance implications. And that's without going into multiple cores, doing computation on secondary processors like the graphics hardware, etc. The initial vision seems like it was object-oriented C, extended with zero-cost and low-cost abstractions. And I guess in those limited terms, the vision's similar. But I think the language focuses much more heavily on functional programming features and expanding the scope of the standard library, to degrees that it didn't previously. C's got a very "build your own" mentality. C++ is increasingly moving away from that, IMO.
* Everything is faster, but the relative costs have changed. For example, main memory is enormously slower relative to the CPU (especially in terms of latency instead of bandwidth). This means that programs have to deal with the cache hierarchy for performance. C++ is well-positioned to do this (e.g. `vector` is cache-friendly), although not all parts have survived unscathed (e.g. `map`'s pointer-chasing is punished today). * Engineering limitations have prevented single-core performance from scaling rapidly, so we now have multi-core systems. This requires a whole new layer of abstractions which we're still figuring out (mutexes, condition variables, futures, coroutines, etc.). * The lack of infinite single-core performance means that efficiency actually matters. This is one of the things that has kept C++ relevant. * We also have GPUs, which are less general-purpose but are amazingly, terrifyingly fast. Anything that can be mapped onto a GPU should be structured to do so (which is why graphics APIs that aren't designed with this in mind are irrevocably flawed - no, you can't just "set a pixel on the screen", that's not what GPUs do). * Power consumption matters a lot more, especially in datacenters (budget) and mobile (battery). C++ is fairly well-positioned to deal with this, being close to the metal. * Because computers are faster and have way more memory (today's L2 caches are as large as the main memories of my first computers), compilers can think more complicated thoughts, enabling advanced features in the language, and more advanced optimizations (which allow us to squash away more layers of abstraction). * Security is a concern. It always should have been, but now we know better. * Data is typically stored in more complicated formats these days, not lightly structured text files. This is more of a library issue for C++ (we have no Standard JSON etc. libraries).
Back end and batch is where it’s at with C++ these days. That’s what I’m doing at my company.
Both _named parameters_ and _named constructors_ are nice to have. `auto(...)` shouldn't introduce any new ruleset, it is exactly if it was `Type(...)` except the `Type` will be inferred in context by compiler.
Witness of that suffering here. Though I must say than in my opinion asio is a quite well-thought library. And it works!
No it was not object oriented C. It was more like an Object oriented language with low level control capabilities. This vision came first and apparently Bjarne once considered using fortran. However since C was becoming popular, he chose C. In C++, C should be regardered as a 'feature' rather than a base language
I'm agree. _list initialization_ was made for containers as its name demonstrate it. I should clarify `auto(...)` doesn't introduce any new ruleset, it is exactly if it was `Type(...)` except the `Type` will be inferred in context by compiler.
I wish we could represent brace-init as a list literal only, and brace-init didn't have its own ruleset for construction.
I hope major compilers would have an option to display a warning if `i` in `int(i)` is not an `int`. therefore we could use `int(...)` for construction only, and `static_cast` for typecasting. BTW, currently GCC will display a warning for `int x(3.5);` if `-Wconversion` compiler option is enabled.
"Feature" in concept, "base language" in the original compiler implementation, at the very least.
Fair enough. I was talking about the mentality though.
Nice article, in short: "use a virtual function in class A to expose an interface B, taking A as parameter".
The problem is not complexity per se, but what Scott Meyers called "accidental complexity" (IIRC). I.e. complexity not due to the inherent complexity of the problem being solved, but due to language/API design decisions. C++ is full of such accidental complexity. Sometimes due to backwards compatibility concerns, sometimes because people just didn't know better when a feature was introduced and sometimes, because the language is not designed by a payed design team but by volunteering individuals and/or based on compromises between large, slow moving corporations. I'm not saying that most of c++'s complexity is accidental but much more than need be. Just look at the sorry state of initialization: How many types of runtime initialization (default, value, zero, direct, list, none ...) are there already? Who remembers their exact relation, their meaning and how they map to the various initialization syntaxes and types to be initialized? 
It's interesting you mention the GPU because IIRC the C++ AMP project kind of fizzled away. And that was really the only general-purpose cross-GPU platform out there.
Could not agree more. especially since nowadays lots of programmers do not care about quality (npm community and electron mostly) where people prefer the most beautiful interface rather than a KISS application at the cost of 1GB ram. Examples: - slack - atom - [hyper](https://hyper.is) yes you've read correctly, a terminal in HTML, CSS and JS (electron) I think we definitely gone away from simplicity. Another good one: https://mobile.twitter.com/id_aa_carmack/status/771749108780523520
I'm with ya! "brace-init for list literal only" - i put something like this into my teams coding standard (which is the next best thing to putting it in the language)
Yep, have to agree there completely ! 
Those ads are brutal on mobile, but a great article on a common problem
for me personally, the fact that an arguably simple problem of executing code conditionally based on a criteria becomes difficult enough that it warrants a long blog post like this really only reinforces my opinion that inheritance based solutions are mostly harmful in the first place. Better go data oriented and define data that is granular enough to represent the needed behaviors, then compose: What noise to make can be an enum with Growl, Miau, Neigh Same with what emotion they instill: Fear, PetUrge, RideUrge Now an animal can be: struct AnimalType { std::string name; Noise noise; Emotion emotion; }; And we can define animal types in an `std::map&lt;AnimalTypeId, Animal&gt;` and to create instances we store what AnimalType they have through storing the type id for example in an `std::vector&lt;AnimalTypeId&gt;`. Much cleaner, no boilerplate and can easily be turned into a fully data driven approach. Inheritance is (or turns into) an anti-pattern most of the time.
For the bottom most type it should be the same speed every time.
Looks like it will only bring more edge cases, or I just can't wrap my head around this. Let's say I write: std::vector&lt;int&gt; vec1 ( 7 , 3 ); Will it make a vector of 2 elements, or of 7 elements using the 2nd ctor: https://en.cppreference.com/w/cpp/container/vector/vector ? Same applies to having: class Object { public: Object(int inVal) : mVal(inVal) {} private: int mVal; }; And: std::vector&lt;Object&gt; vec2 ( 7 , Object(3) ); What's the resulting size? And let's say `Object`'s ctor is 'explicit', what happens then? I've had similar issues with the `explicit`keyword and braced initialization. These ambiguities are so hard to deal with. 
This post neatly summarizes everything that's wrong with the OOP mindset/programming.
I like your idea, inheritance is definitely an anti-pattern most of the time. However I'm not sure about the map and vector thing: can't an `Animal` just have its `AnimalType` as private member?
If you need to store other data inside \`Animal\` instances, then sure you can make it a class/struct with \`AnimalType\` as a member and do an \`std::vector&lt;Animal&gt;\`. :) My example was for the case where an animal instance involves no more information than what type it is.
it seems your base class needs to know all possible derived classes beforehand. 
&gt; aggregates
You forgot [nodebots](http://nodebots.io/), [johnny5](http://johnny-five.io/) and [nodeOS with a broken `ls` command](https://node-os.com/). Now excuse me, I feel dirty.
Aggregates have no user-declared constructors. Neither `std::vector` nor your `Object` will be affected since they are not aggregates.
You have STL variant, although the animal type ID is a sequence number that you can't control. You could create a compile time translation table between your enumeration and that sequence number.
node.js on itself isn't that bad. It's basically v8 + additional modules. It's pretty fast and light. The problem, it's what the community has done with. By creating then thousand trillions modules for [nothing](https://www.npmjs.com/package/is-positive). So it basically means each time you want to download a npm application, you download the universe within.
You have to be able to control it because often it's part of a standard protocol.
Or a boost based codebase :')
One of the best example of what should have been core language and not library is std::atomic [https://godbolt.org/z/QYzHjR](https://godbolt.org/z/QYzHjR). I would say that any feature referenced from the core language features (std::move, std::forward, memcpy, std::atomic etc etc) should not be library but language features. For std::atomic it's even more important because it is part of the memory model for multithreading...
&gt;Is the debugger a tool of the past? Sounds like we should all just hit 100% test coverage and never step through the code. Does this reflect a good chunk of the sentiment here on /r/cpp? Life isn't so binary. OP just said don't rely on it as your primary tool. Sqlite has 100% coverage and still has bugs.
Sorry, I was being a little facetious - I think a debugger is very, very important, especially in games :)
No, because I don't think that's the case.
Oh man, that was exactly what I was thinking while reading the article. Lots of juggling around, causing performance penalties, for a set of problems that can be easily solved with data-driven... Still, kudos to OP, as it was a really interesting topic/way to resolve the problem.
I just said I'd use value\_type if there wasn't anything better. I'd also consider std::pair&lt; CustomerKey, SSLCert&gt;, or my own typedef of that.
As mentioned in the post modules and PCH will improve the compile times but most certainly wont solve the problem entirely.
Good article! Just some things I noticed: * Passing a unique\_ptr by reference: Seems really bug prone to me and should be avoided. We have shared\_ptr and weak\_ptr for this. * Moving a shared\_ptr is in fact very useful, because it doesn't increase the reference count and is therefore a lot faster.
Ever tried to understand what an undocumented algorithm is doing on the inside? I think not. Otherwise you would love debuggers.
Agreed! I use it for code exploration all the time.
I think it is good practise to step through new code before committing it, not to debug it, but to verify it is doing what you expect.
Did you know that dynamic dispatch on C++ is compiled back to virtual tables in most compiler implementations?
I can't fully agree with that statement, but I can't disagree either. I don't use a debugger as much as I maybe should. Instead, I'm indeed putting more emphasis on meticulous tests. And ideally, all problems should be caught at compile time anyway. ;)
And try Clang even with -stdlib=libc++. Quite amazing numbers.
I don't mind language features being exposed as regular library items: they are quite likely implemented underneath with compiler intrinsics.
Sorry, but this article goes into too much detail that it gets wrong, so I don't see the appeal for neither beginners nor experts. A sampling: - "lending ownership" - "no need to move anything with std::shared_ptr" - "Once again, smart pointers are powered by move semantics: the dynamically-allocated resource they hold is moved around, not wastefully copied;" - `return std::move(std::make_unique&lt;Object&gt;());`
What is a major dev tool?
&gt; - Closed source libraries (they do exist) I remember having to work with the client library of Oracle database. The library was obfuscated, all function names being 6 "random" letters, or something like such. If the library had been perfect, it would not have been a problem. Of course, it wasn't: it leaked, it crashed, ... it was always such a pain to debug it, but since we had to choice (if only to keep our application working), we had a partial mapping of the "random" name which was extended over time which we used to determine the exact cause of the issue, and then report it (and implement work-arounds, I never saw a bug being fixed). Honestly, at this point, I'd recommend *against* any closed-source/obfuscated library. I don't mind *paying* for libraries, it's totally fair, but I'm willing to pay extra for the source code... or to settle for a less able library from a competitor if it means I get the source code. I can't see any commercial advantage in distributing closed-source/obfuscated libraries; you burn out the good will of your commercial partners while hackers can still reverse-engineer the code anyway. &gt; - c++ interfaces in shared libraries that you want to update independently (that is already possible to some degree of course) Stability per compiler version is sufficient for this. &gt; - Interop with other languages. I am afraid ABI is the least of your worries. A restricted subset of C++ (inheritance and run-time polymorphism) is relatively easy to map; however Modern C++ templates + metaprogramming is just nigh impossible. The Nim language has the best possible C++ interop, when you compile it to C++. Yet even then it's complicated; Nim doesn't have SFINAE so it may emit C++ code which doesn't compile. The D language has possibly the next best, and is struggling with templates. They need to be instantiated within a C++ translation unit so that the C++ compiler can work its magic. SFINAE, Variadics, Concepts, `static_assert`, overload resolution, specialization resolution, ... there's a lot of C++-specific semantics which cannot be mapped cleanly to another language because different choices were made with regard to generics there. And with templates permeating the `std` library, it's not like you can really use C++ without solving those issues. `std::tuple` is a beast. `std::map::emplace` is a beast.
Isn't that what tests do? Most systems won't let you commit if a test fails.
/r/gamedev?
I find GDB useful for finding stuff like segfaults or other unexpected behaviour. Sometimes thats just better than writing a test.
&gt; Yes, you can't really rely on the debugger as your major dev tool for Modern C++. But Modern C++ does not stem from that school of thought, that the debugger should be a major dev tool... &amp;#x200B; To me this just sounds like a defensive argument against debuggers because "Modern C++" constructs have poor debugging support. I don't understand the reasoning against using tools that help you reason in more detail about your work. If anything, I think debuggers should become much more powerful and efficient, nothing has happened in this area for a long time.
Test just tells you if it got the right answer, not how it got that answer.
How would you extend this if you had another type of entity that reacted to each animal differently (i.e. a person might run from a wolf, but an ogre would pet it)?
I do understand what you are saying but I find it difficult to imagine a case where I would do that. If it's right by accident because of some lucky combination of 2 bugs cancelling each other out, testing different inputs will catch that. If I'm looking at code paths, a debug build might emit logs, or there's tools to analyse control flow. So I'm not saying you're wrong, but I am asking for additional explanation.
SFML is first and foremost a C++ library. It can, but doesn't have to, be used for game development. :)
+1
I think lending ownership can make sense in a parallel situation, no? Like if a pointer could go out of scope and you need to call a function with it, pass the shared_ptr itself so it increases the ref count and once *that* function is done you can safely delete it.
Personally, I couldn't live without my debugger. You think you know a piece of code.. Then you step through it and realise, nahh you don't! 
Doesn't it require you to manually annotate all your classes with proper macros? I.e. basically reimplementing typeid.
Last night was fun. I pushed a commit that worked on my machine, but it also had one test that said `LLVM error: Out of memory`. Travis failed for some seemingly unrelated reason, CircleCI failed for the same reason my local tests failed. Okay, so let's look at what the test does... Now let's try that behaviour from the user's point of view aaaand... sure enough I broke something. Now let's take a look at the new code - I know exactly which function breaks. Nope, nothing seems wrong... Luckily I was debugging a python extension module, so I could call the offending function directly. Result? SIGSEGV - it was about time I reached for the big guns (gdb)! Let's see... `gdb python`, followed by calling the offending function... Okay, so where's the segfault? Deep in some libclang function. 5 minutes later I realize I was storing a dangling raw pointer taken from `std::shared_ptr::get()`. Bottom line is that `gdb` showed me exactly where to look, instead of poking around in the wrong place. People need to use their debuggers much more.
Unfortunately not everybody has the luxury of (m)any automated tests in their legacy codebases... Also, a debugger can be really useful if you encounter some undefined behavior, if your tests fail without explanation.
&gt; Interactive debugging is the greatest time waste. Write automated tests for your debug hypotheses instead. That's nice and all... but how do you come up with the hypothesis? That's my primary use of a debugger. When faced with an unexplained failure on a largish integration test/application, I'll use logs and debugger to narrow down the issue until I can actually formulate an hypothesis. Once narrowed down and reproduced with a unit test, it's dead Jim. But narrowing it down can take hours...
&gt; I'd also consider std::pair&lt; CustomerKey, SSLCert&gt;, or my own typedef of that. Is that your final answer? Because it won’t compile. If you happen to have both a copyable key and value it will but won’t do what you want it to. I’ve seen this issue a few times in our codebase when someone thinks it’s better to type out the full type when for looping over a map and is a great example of why auto “just work” and is safer to use over anything else when for looping. 
`-fsanitize-address`
Make sense
Generally should default to passing by reference if you don’t want the called function to check for nullptr
I would hesitate to say that all problems should be caught by the compiler. Even in a perfect world the compiler is only there to translate the code you write into machine code. If the code is shitty. The machine code will be shitty. The compiler, while it has gotten very advanced, cannot and should not be reasoning about what your code does to try to warn or fix your mistakes. It should only do as direct a translation as it can. 
You're solving a different problem, though. Two different problems, actually. - A Person may Pet a Dog, but a Bird would Fear it. - One Person may Hunt with a Dog, but another may Cuddle with it. Your data-driven approach is not bad, per-se, but it's **Closed**. I cannot use your code as a 3rd-party library and add my own noises or emotions. At least, not easily (without conflicts). One of the advantages of Visitors is that they let you implement multi-methods relatively painlessly... though with boilerplate and bias. They allow Open-ended hierarchies.
TypeIndex itself does not, but runtime_cast does. The nice this is it's opt in instead of being universal and works in environments without rtti enabled. 
The actual goal is for environments that lack rtti, so this is a library solution to that. It's opt in instead of being on for everything by default, which might also be nice. 
Sounds like the stance people that 'master' the language but don't use it would have.
That sounds like a person that doesn’t or can’t use the Visual Studio debugger. I’ve built my entire career using it to fix errors and can say that without it I wouldn’t have the job I do today.
Hmmm. I understand the sentiment. Some time ago, people considered writing the code the easy part. They would just puke it out, and then spend the rest of the time debugging. This was common before unit testing and static analysis. Then we came to the realization that the closer you catch a bug to home, the cheaper it is to fix. So we started doing things like unit testing and static analysis of the code. I think that modern C++ aims to take this further, by simplifying concepts, making it easier to write, analyze and test your code, before you need a debugger. Now being pragmatic, I also know that forgoing a debugger completely in favor of the compiler, unit tests, and static analysis is insane. We're engineers, we solve complex problems in the real world, of course we need a debugger. What we don't need a debugger for though, is to tell us the code we wrote works for the happy path. I think we should put down our pitchforks and try to understand the other point of view. If we could write code, where we could prove it worked, before it ran. We wouldn't need a debugger. It would be a different world. We can learn something from that point of view.
I couldn't live without it, but then again I'm a mediocre developer. I recall Linus saying the debugger is a crutch.
It's neither required nor desireable for software to be bug free in order to be successful. Labor is the most expensive part of any business. SQLite has [711 times as much test code](https://sqlite.org/testing.html) as database code. That does not mean I want to pay my engineers to write 711 times as much test code as business logic on a simple internal crud application. It does not need that level of confidence and I do not want to pay for it. I buy them a debugger instead and have them write decent integration tests instead.
**Company:** JP Morgan Chase &amp; Co - Investment Bank [Link](https://www.jpmorgan.com) **Type:** Full time **Description:** JP Morgan Chicago looking to grow the core of its global technology team that drives our electronic trading businesses across Markets. This is a great opportunity to join business-aligned teams focused on *building connectivity and eTrading infrastructure* for our Industry-leading Macro (FX, Commodities and Rates) trading desks. We partner with Quant Research and Traders to deliver Market Making and Algo Execution solutions to the business, working in an energetic, fast paced environment. We are looking for **junior and senior C++ engineers** who can demonstrate potential, knowledge, and passion for building highly performant and deterministic software. This role is in a small team that functions as a startup and has at the moment high visibility to upper management due to its strategic position. **Location:** Chicago Loop, Chase Tower. On top of the blue line and 10 minutes walk from Union Station. Casual workplace attire. Flexible arrangements are common. **Remote:** No, **Visa Sponsorship:** Not for this role **Technologies:** We standardize at C++11 at this moment. Innovation is essential but there are strict coding style guidelines due to risk impact (think Knight Trading). Some Python and the occasional Java for integration. Being comfortable at working in a Linux development environment is essential since all work is done on RHEL/Linux. **Contact:** [Taleo Link](https://jpmchase.taleo.net/careersection/2/jobdetail.ftl?job=180122115) 
Could someone tell this c# kid why it's preferred over int a = 0; ? Or does it lead to a different behaviour?
Almost never. Unit test and simulation coverage. Make stuff break fast there, toss in debug statements as necessary, recompile and rerun. All data structures should be able to dump their state. Working on someone else's code base that's a monolithic piece of junk with almost no test coverage and no marshalling code? Might be stuck running a debugger at times.
Personally I'd rather do interactive debugging over writing unit tests any day but I'm probably in the minority there.
its only a crutch if you use it as a crutch. post mortem on a crash a stack trace and possible inspection is the first thing I do.
&gt; but doesn't have to That reminds me to ask: Is it possible to wait for an event from the OS as opposed to polling?
It's a damning condemnation of modern C++. I cannot believe it's being said with a straight face, because it's a scathing critique of a language to call it "undebuggable" IMO. Not to mention that C++ unit testing is a fucking shitshow compared to most languages.
For analyzing a crash, absolutely; I was rather talking about stepping through your own code as part of normal development.
Yes, but so does double-dispatch. I just don't hide it. `Animal`'s takes a `AnimalVisitor`. `AnimalVistor` contains a family of hand-written `virtual void Visit(Cat*) = 0;` for each subtype. So you touch `Animal` every time you add a subclass in that solution. I just don't hide it. Now you can forward-declare `AnimalVisitor` and only include its full definition when you need it; the same can be true of the `function_view` solution by taking a `AnimalCallback const&amp;`, and have `AnimalCallback` be a `struct AnimalCallback:callback&lt;Dog, Cat, Horse&gt;{ using callback&lt;Dog,Cat,Horse&gt;::callback; };`. 
Having worked on major console games - where I'm personally aware that the rate of development was beyond most peoples' imagination (due to use of debugger during all development, quick compilation, everyone using the debugger properly and not degrading the experience) - I feel personally attacked by this.
That's a great idea, but useless when you're in the wonderful world of Python that does some weird things with memory and the sanitizer reports false positives. Though for this specific thing it would have probably helped me. Why didn't I think of the address saitizer? 1) I'm used to debugging segfaults with `gdb`. 2) It was 02:00 am.
Yes, you can use [`waitEvent()`](https://www.sfml-dev.org/documentation/2.5.1/classsf_1_1Window.php#aaf02ab64fbc1d374eef3696df54137bc).
Thanks. And this actually waits for the OS to give control back to the application? I'm asking, because SDL2 opted for polling under the hood in their wait function which kind of ruins it for implementing non-game applications that aren't supposed to sip the battery.
I agree! Beast is intended only as a starting point for building higher level abstractions.
While the blog post is technically correct I personally believe the most important rule regarding passing `std::shared_ptr` to functions is to avoid it entirely - I've yet to see a use case where it is the best solution to pass `shared_ptr`s around directly. Common cases where it is done anyway: 1) You have common services that are shared between different components of the same system (e.g. a `Configuration` class that is reading the config file once and then passed to every other component that needs access to config flags). But in this case you don't need a `shared_ptr` because even though the service is shared its ownership is not - it is created once at the start of the application and destroyed on exit -&gt; `main` or a dependency injection framework/class is the single owner, just pass regular (non-owning) raw pointers or references 2) There is a resource or data that is shared across multiple threads where it is not known which of them uses the resource last. Common example is that of a twitter wall with multiple columns, one displaying all tweets of your feed, one displaying all tweets of a particular hashtag. If there is a tweet in both these columns with an image you only want to load that image to memory once but you don't know in advance in which of the columns it will scroll out of view last. So the common solution is to use a `std::shared_ptr&lt;Image&gt;` so that the image gets cleaned up once it is no longer visible in both columns. But here it is much better to make the `Image` class implicitly shared (possibly by using a `std::shared_ptr` as a PIMPL in the implementation of that class) and to just pass the images around by value. Makes for a much cleaner API. Since these resources are shared between different threads they better be immutable anyway, so the implicit sharing also isn't observable by clients.
can you give an example? 
Having to deal with multiple equal types. I have to use SFML's vector class when using SFML, but I also want to extend such a vector class to have more useful stuff, because SFML only seems to want to include the very basic. I think there was a discussion about being able to plug your own types into SFML.
This is the kind of thing a professor who has never shipped a major piece of software would say.
Having a look through could help you spot situations where it works with the test inputs but would fail with unexpected inputs
I use the debugger primarily as a fast-track tool to figure out where the program was when it broke. Once I know what the call stack looks like, I can figure it out from there. Sometimes I will look at some variables to figure out if they are in the expected state or not, but that's it, really. In particular, I consider stepping through code in the debugger to be a total waste of time. It takes forever, it floods you with massive amounts of unnecessary detail, and odds are that if you didn't understand what you were doing when you wrote the code, you still won't understand it when the compiler steps through it one laborious step at a time. If I get into a situation where I need it, I will instrument the code with logging statements instead and just run through it at normal speed. At least that lets me choose what I'm interested in - and that is certainly not every single statement. So I find a debugger to be an extremely useful tool, and I wouldn't want to do without, but I could certainly live with a much less capable implementation than the ones we have today.
The compiler is telling you exactly what the problem is.. no default constructor in Vertex. It's not the only error in the code anyway, in the constructor of Mesh you do a cycle by 4 on a 3 elements array. Also pretty weird choice to have a private constructor accepting a parameter in Vertex.. who's supposed to call that? &amp;#x200B;
I don't remember a specific discussion, but there have been multiple. The issue as far as I can see is, that there's no simple solution. A bring-your-own-vector class could potentially be done, but might introduce quite some verbose template signature. Often times it may also be a better design approach to separate the logic that would require a more extensive vector class from the rendering logic of SFML and have a conversion layer in between.
Why? Gtest is excellent. Never had problems testing. 
 enum class ReactionType reaction[] = {0}; Seems pretty obvious to me? You get the default semantics from default initialization, and can initialize it where you do care very easily.
No, it also does a loop with interwoven `sleep()` calls. Might be something to check, as SFML has recently switched to listening for device dis-/connect events, maybe this looping isn't required anymore. IIRC there's also an issue where closing the window may not trigger an event closed in time for the waitEvent to catch it, so you can essentially end up with a stuck process. I should pick up that discussion again...
You should write some code in C# and evaluate NCrunch - code coverage immediately inline, results within seconds. It's mind-blowing how differently you view writing tests when they actually tell you useful things quickly.
If you are complaining about the c++ toolset and its lack of integration with coverage tools, then I'm 100% with you, but gtest provides wonderful and meaningful results as long as I write good tests.
No, we are using optimizing compilers and modern optimizers need to find out lots of info what your code does.
Nonsense! Debugging is essential, not just in C++. Probably you shouldn't debug every single line of code you right, but debugging is the difference between knowing, and thinking you know what the code does.
Thanks for mentioning xtensor, I hadn't seen it yet! The python interface seems like a nice bonus.
Did you take a look at the difference of ASM between debug and release ? Also having to pull headers for the things mentioned above is kind of sad.
Maybe I am missing some important part of modern c++ ... But which constructs are we talking about here specifically?
I strongly disagree too. A good debugger is essential. I am using QtCreator on one project, with the MSVC toolchain, and QtCreator uses cdb there as debugger. And it is horrible. It doesn't show half of the variable's values, and you can't inspect most of them either. When you open the same project in Visual Studio and debug it there, everything is perfect again and the debugger displays all variables, you can inspect them, etc. It's basically a huge time waste having to deal with QtCreator's debugging.
How do you test for things that change during the execution of the program? I once had an issue with a graphics library that changed some OpenGL settings, which made Qt unhappy and crashed after some random time, but only if you interacted with it, it could idle fine for at least 30 minutes. And the crash logs showed that the crash was in the graphics driver. And it worked fine on AMD and Intel GPUs. Stepping through with a debugger looking at the relevant settings and when they changed made it pretty easy to fix, but I don't know what kind of test I could have used instead.
&gt; I should pick up that discussion again... Thank you very much.
Ah ok, missed that part. Thanks for clarifying!
They do vastly different things. One needs to walk the inheritance hierarchy and succeeds if any type involved is the one you’re looking for, including processing cross casts and failing if the particular path necessary to do that touches private inheritance, and the other one only compares the most derived types with no graph algorithms at all. Notably, in the “it isn’t that type” case dynamic_cast needs to walk the whole tree to show that no cast is possible.
That means it can’t deal with invading types from other DLLs/SOs — not feature parity. That restriction is the source of a lot of the inefficiency of both Itanium and MSVC’s implementations.
For the third time, I said I'd use value_type.
As long as C++ does not throw an exception when I dereference a nullptr, I will keep using a debugger. Yeah, I know, I should spend a week or so going through my existing code size inserting a clause inspecting every single pointer before I use it.
Maybe you missed the smiley behind my statement, but there is also some truth to it. If errors can be caught at compile time -- with the compiler actually *failing*, via static\_asserts, etc. -- that is always greatly preferable to finding errors at runtime (cause they might not be found for a long time). So, strong types and type safety should be incorporated into code design, APIs, etc. as much as possible. I'd argue that this kind of good design makes me having to debug my code a lot less than otherwise.
Or ranges...
One thing that caught me off guard, but it may be just my lack of knowledge: One of my many projects is an ImGui application that allows (among other things) for the user to label objects in a set of images. This is for AI training, the data gets fed to tensorflow at some point. The entire point of that portion of the application is to allow the user to label 10000 images as quickly and as painlessly as possible. This is mainly achieved by knowing that most of the images are going to be similar (part of a movie, for example). So, I load one image at a time, I update the sf::Texture object and I associate a sf::Sprite with it and I use a RenderTexture to display it in a ImGui window (because i draw on top of it labels and I need to resize the thing to fit the window, etc.). Now, when all the images are the same size all is fine. If it happens to have images of different sizes, I have found no other way to handle the issue, but to destroy the texture and the sprite and recreate them with new sizes. Kinda a pain. Very inefficient. But , on the other hand, it doesn't happen often and it probably doesn't matter much, if at all. But it did caught me off guard that i cannot tell the sf::Texture, hey, here is your new size and data.
And if using std::pair doesn't compile, that's a good thing. It means the compiler has caught my mistake. That's what manifest types gives you: the redundancy enables error-checking.
I've never been too worried about Debug performance, to be honest. Never worked in any domain where it really mattered, and therefore never really looked into it. I do think that sometimes when languages promise zero-overhead abstractions developers, myself included, may be a bit too keen to count on it to collapse layers of inlineable code. Sometimes, it may be worthwhile to have a little more copy/paste rather than layering piles of abstractions which should go away at compile-time. Either because they may not go away, or because they do make reading/debugging the code more onerous.
I'm not sure what more to say. Stepping through verifies that the code behaves as you expected. If there are multiple paths, it verifies that the path taken was the path you expected to be taken. Maybe there's a quick way and a slow way to the same result. Why are you so against this?
And that's now basically a non-issue, as far as I know. D2's runtime incorporates a lot of stuff from D1's Tango, making it redundant.
Oh no, I agree that compile time errors and warnings are an extremely nice things to have. And should be used and heeded as much as possible. All I was trying to say was that the compiler can not find all the errors in the code it compiles. It can certainly help as much as it can. I mainly wanted to clairify because I see a lot of people who are new to the language on here and it is extremely detrimental to them to just assume if the code compiles then it's good code. Because that is definitely not the case. 
While optimizing compilers do try to figure out as much as they can to try to reorganize code to run faster or make the output machine code smaller. A compiler cannot identify intent. And it should never "assume" that you meant one thing and change it to that when in reality you wrote another. That is what I was trying to say. The compiler will directly translate bad code into bad MC. And an optimizing compiler will translate bad code into fast bad code. That is the only difference.
if I were to implement a way of interacting I would completely encapsulate what it means to interact between two different objects in a seperate class. something like [this](http://coliru.stacked-crooked.com/a/145ee13efc7a3538) &amp;#x200B; I tried to match your layout as much as possible for presentation purposes! also it's very barebone, but you get the idea! :D &amp;#x200B; timings: clang++ -std=c++17 -O3 -Wall -pedantic -pthread main.cpp &amp;&amp; ./a.out 500000500000500000500000500000500000500000500000500000500000 carlivan test: Avg elapsed time: 8.2 ms, stddev = 1.81353ms &amp;#x200B; what do you think? :)
We have pch and SSD, looking into unity builds now. From what I read modules will be a far cry from solving compile time problems, maybe be on par what we get with pch now.
&gt; If the code is shitty. The machine code will be shitty. Not necesarely though, if you write shitty code the compiler might do legitimate optimizations and turn it into decent machine code. &gt; A compiler cannot identify intent. And it should never "assume" that you meant one thing and change it to that when in reality you wrote another. Slippery slope. Compilers can, do and will re-arrenge memory accesses to be more cache friendly. Technically that's a violation of what yo told it to do. 
Still a lot more salvageable than C++, though. Rust has far less technical debt to bypass.
I usually prefer to put the onus on the caller.
That's true - in the success case it's identical, because they both start at the most derived type, while in the failure case one stops immediately and the other will just run up your entire inheritance tree.
But you need unit testing to prove that your code will run, and of course you will need 3 times more unit testing code than the real code, and you need to test the unit testing coding as well. 
Not sure I fully grasp the issue at hand, but in case you didn't know, if you change the texture or the associated texture's size, then you need to adjust the texture rect. The [`setTexture()`](https://www.sfml-dev.org/documentation/2.5.1/classsf_1_1Sprite.php#a3729c88d88ac38c19317c18e87242560) function has a second parameter that will change the texture rect to the size of the texture. Alternatively, you can also manually set the texture rect with [`setTextureRect()`](https://www.sfml-dev.org/documentation/2.5.1/classsf_1_1Sprite.php#a3fefec419a4e6a90c0fd54c793d82ec2).
When did I say I was against it?
This is possible one of the reasons he claimed we should not use debug tools (he is using some creepy tools)
I almost never use the debugger and kindda agree with that statement. Stepping through the code and missing the spot I want to check is so frustrating and time consuming. I rather log or print all the stuff. I believe this has higher data throughput to your brain than stepping through the code. However segmentation faults really benefit from stack traces. I think it's the only efficient use of a debugger.
In MSVC I use _set_se_translator to turn seg faults into exceptions. Maybe there is a way to do this on other platforms.
Could you add some more info? I think this tries to create an array of an enum (although the code doesn't compile), how would you use this?
Out of curiosity what level of automated regression testing did those systems have? A debugger really does help but I find I lean on it more in codebases with poor coverage.
Check before the call. Otherwise you call the draw function, but it might do nothing. A function should do one thing, and do it well. 
Am wondering the same thing. I have the feeling there will be if/else chains somewhere, but I could be wrong.
sfml is nice. One issue I've had though is that full screen didn't work on my macbook's retina display 
This quote deosn't make a lot of sense to me. I use a debugger with modern C++ all the time. What I can agree with is that debuggers very often cause intellectual laziness which leads to slower development and less robust code. I have watched myself and every developer I've ever worked with poke around at problems that would have been easily avoided by coding more carefully in the first place. Debuggers often lead people to just spray out some code that is approximately right with the idea that you can just patch up whatever was off a bit with a few quick debugging sessions. When I don't have the luxury of a debugger for whatever reason I find that I write much better code the first time that is more clear and hence easier to reason about, which in itself leads to more reliable software. If I pretended like there was no debugger all the time I would write better code.
That's very intentional. Consider: # cd /a/b # cd /c/d # pwd 
Sounds like a sentiment from people who know the language, but don't use it. I've only worked with one codebase with ANY written tests and none that have significant coverage. It's just not worth the time.
Debugging may become slightly worse due to freqent usage of trivial functions like `std::move`, more complex case - debugging `std::function` call, even more complex - debugging `std::any` contents. Also debugging compiler generated code like constructor, destructor, operator= (and newly spaceship operator) was always a problem without great solution. 
I like it! Is there a reason to have a separate CRTP class? Also, I guess `overloaded` is what they have e.g. [here](https://en.cppreference.com/w/cpp/utility/variant/visit), but where does `function_view` come from?
If you're writing a public API with a lot of exposure, there's reason to pick one or the other. To keep your interface minimal. Otherwise, I do both. Have `drawInfoIfEnabled()` call `drawInfo()`. Then all calling code can tersely say what it means. It's not a problem if 10% of your code has to behave differently than the other 90%. And debugging or refactoring can become simpler when you have to search a large codebase for one form or the other.
Neither. Maintain an active set of things that need to be drawn instead of branching per drawable. 
How come? It's fundamentally just a series of virtual calls, so I'm not sure why that wouldn't work as any other virtual call from a dll.
"The most effective debugging tool is still careful thought, coupled with judiciously placed print statements"
Is there a chance for `view::zip` to be in C++20?
The second one is called “defensive programming” and there are great reasons to avoid it. Believe it or not, many people would prefer an ‘assert(infoEnabled);’ at the top, treating it as a logic error to call the function without info. There is also the OO criticism that ‘drawInfo()’ should take an object and verify its state. Lots to think about. I personally like asserts, or in modern c++, contracts.
Yes! It's so much more efficient to read a good log file than it is to set a breakpoint and realize that things went awry much earlier. 
I've literally got a t-shirt of this somewhere from my gamedev days
No preference involved here. If `infoEnabled` has nothing to do with the proper functioning of `drawInfo()`, it has no business being accessed in `drawInfo()`, and should therefore be tested outside it.
I think what irks me more than the comment itself is the overall attitude of the poster in that thread. If one of the goals of Meeting C++ is to "support the C++ community", then making sweeping generalizations and comments such as "check your bugs at compile time" isn't helping anyone. If anything, it comes off as ignorant, and reinforces the notion that there's a class of dogmatic C++ folk that are out-of-touch with pragmatic software development.
I think a big issue is the approachability of the debugger. On Windows, the MSVC debugger is a very polished experience with a bunch of data visualizers and a nice ui that using the debugger is the first thing you try if something is not working. GDB on the other hand is not like that. I have seen very good and experienced programmers prefer putting in printf statements instead of trying to use gdb. 
I don't disagree with you. My statement wasn't one of this OR that. I still rely heavily on the debugger. There is something to be said about understanding and learning other perspectives. Instead of just sitting in our comfort zone. Black and white thinking doesn't get us very far at all. I am a huge proponent of unit testing, I even use the debugger along with the tests to make things easier to reproduce in the debugger. You're lying to yourself, and to me if you think you need a debugger to prove your code works for the happy path. Unit tests help to show users and yourself how you expect a client to use your code. That is very, very important. You shouldn't need to write complicated code to prove your code works, and show how it should work. If this is the case, it means you have a design issue. I don't mean to say this is possible in *every* situation. I've worked in legacy code, I've worked in large code bases where people didn't know what the word "test" meant. The point is, that if you do your work with this in mind, you will make the code better, and not just keep it status quo.
Thank you guys for your opinion, I personally hadn't even thought about some of the aspects mentioned in the comments, and I find it really interesting to know what and how other programmers think. Sometimes it makes me reconsider some of my design choices and write better code.
You are right of course. The naming was a conscious effort on my part. Understanding the visitor pattern is a little difficult because of two virtual dispatches, so I thought the "single dispatch visitor" would be a good bridge for that. I hope I didn't do more harm than good with that choice.
Simply calling texture::update(pixels, width, height, x,y) didn't seem to change the texture's size, that is, the displayed image had a black bar if it was larger than before. so the only way that worked for me was to destroy the texture and recreate it and re-atach it to the sprite. everything else i tried (fedora 28, sfml 2.4.x) just resulted having black pixels if the new texture was larger.
Honestly, if you're having a unit test for each individual part of the system, integration tests, and then full-scale tests (in order: module level, interaction level, program level), they can be powerful tools to help you debug when you change something, but that is not to say debuggers aren't useful, they are the 2nd step after a test fails, to find the exact lines where something failed rather than what area something failed in.
I've been using sfml for everything for a while, for game dev. Its super easy to use and generally great but there are some definite shortcomings 1. It doesn't do batching so it takes a relatively small number of basic shapes to tank performance. Basic shape rendering also seems to be much slower than constructing a vertexarray manually and rendering that, which is confusing 2. Sf::keyboard doesn't support a full set of keys 3. Sf::fonts don't support subpixel Aa. I did hack in some code for this so I might contribute it, as well as a shader to get more accurate coloured font rendering 4. Sfml font (and probably in general) rendering performance is notably worse than imgui, about half speed or worse, in situations that are batched similarly. I suspect this might be because imgui has a central render loop where state is only bound as need be, whereas sfml is object oriented and can't rely on that so easily. I haven't dug through the source to find out why though 5. RenderTexture doesn't support AA in the same way that renderwindow does 6. Renderwindow push/pop/resetglstates are incredibly heavy even when you only really messed up a small part of the pipeline. Unfortunately you then have to go digging through the sfml source to figure out what you *actually* want to reset instead. Some sort of abstraction so you could say 'only these things are dirty' would be nice but this is probably not important overall as people who need the performance can probably do this themselves 7. This isn't really a criticism: Sfml implements wrappers around tcp and udp, but in practice for some game dev that needs reliable but fast networking neither work out of the box. A full steam p2p style autostun networking system is definitely too much to ask, but with the standardisation of QUIC it might be worth finding an implementation (boost is working on http3 so I imagine they'll provide a socket for quic) and building it in. For more common use cases or especially beginners using tcp/udp through sfml, this would solve a lot of use cases for networking being reliable and performant 8. being able to dynamically change the window style to borderless would have been helpful when dealing with an opencl/opengl interop application, due to recreating the window invalidating the context and thus killing opencl resources SFML is super good overall though, the main actual problem is just the performance, everything else is quibbles
It's fine really, I quite enjoy the challenge. It's just a big software tool that compiles on various combinations of compiler, architectures, and operating systems, so the total build time for every combination is quite high. In-house risk-pricing software that evolved over the decades into doing a lot of things.
Degug iterators are largely responsible for the debug performance. That's an implementation decision and not something to blame the committee or C++ for.
I'm just curious: in case \` uz\` will be Core Language feature - will it bring more inconsistencies ? What I mean is that, if we will take a look into \`size\_t\` definition \[1\] inside std, there will be: typedef */\*implementation-defined\*/* size\_t; This means that either Core Language feature needs to generate std::\* symbol (well, we have special std::initializer\_list, but \_was\_ this good design decision ?) or either definition is a bit dancy, like: "uz literal has implementation-defined type that is equal to what std::size\_t defined" or, for size\_t - "size\_t is implementation-defined type that is equal to what uz literal has". Isn't this too much ? &amp;#x200B; \[1\] std::size\_t: [https://en.cppreference.com/w/cpp/types/size\_t](https://en.cppreference.com/w/cpp/types/size_t) &amp;#x200B;
Some of us don't have the luxury of writing only Modern C++ in a platform-agnostic ivory tower. 
If the check is complicated, I'll include it in the function and make it very clear by the function name and documentation that it may or may not perform the task. Example - I might have a function with "throttled" as part of the name. Internally it tracks how frequently the task is done to limit it. Another example - I might have a function that sends updates, but only if the data has changed. Internally the data is compared to the last data that was sent. Both of those functions would then call another function that just does the task without any further checks. You get the best of both worlds that way. The function that does one thing, and the convenience function that performs checks.
I'm not sure i really understand the point of continuing with inheritance. If you want to manually assign behavior for all of the derived types, then inheritance isn't the right tool. The whole design of `AnimalVisitor` does away with the main benefit of inheritance: that adding a new type is supposed to be easy. If you want to deal with a closed set of types then using `variant` just makes strictly more sense. The article kind of reeks of "when all you have is a hammer". I'm kind of surprised that code like this is being written still. When people in the C++ community talk about the past overuse of inheritance, if they're not talking about code like this, then what are they talking about? I'd be genuinely curious to hear the author explain what the benefit of all this is over `variant` in the first place. Given that you're having to explicitly list your types anyhow in `AnimalVisitor`, and therefore there is no seamless way to add new types. They mention variant right at the end "when your hierarchy is finalized", but why do you have to wait until then, and not simply use variant throughout?
Does it try to consider two types with the same name in different DLLs the same? It sounds like macro embeds a symbol which would be namespaced to the DLL.
i prefer this one) `void drawInfo() {` `if (!infoEnabled) return;` `// ...` `}`
I feel the same way. I'd also add, testing GUI problems can be a pain in the neck. For example, a scenario that is inspired by an actual issue: When mousing over some objects that are supposed to glow with a highlight, some get highlighted when I don't expect, or don't turn off their highlight when the cursor moves away. I may know that I can reproduce a weird issue if I mouse over some objects from top to bottom, but not if I mouse over them from bottom to top. How do I make a unit test that I am sure matches the actual scenario? I can query an API to ask an object its color as part of a test. But I don't know enough to be sure if what I am seeing matches the object's internal state, or they have become desynchronised. How exactly do I accomplish the mouseover in a unit test? Do I have to record the mouse positions over time and replay them somehow? How confident am I in that replay? Submitting fake mouse move events through an API is obviously triggering a somewhat different code path than the original scenario. And then, I would need to let the replay run in real time, over and over, while I write various unit tests with blind hypotheses that each take as long as a manual run. I probably can't move the mouse while such a test runs, because the OS would still be submitting normal mouse move events, or else the replay events would be warping my actual mouse cursor. I could run it in a VM rather than my actual workstation, but obviously the VM has completely different video drivers. So if I fail to reproduce the bug in a VM, did I fix it? Or does it just not trigger in the same way in the VM. Oh, and if the rest of the app depends on OpenGL hardware acceleration features, I may just not be able to run most of the code in the VM at all. Using a breakpoint and a debugger to just see what the hell the internal state of the app is, while I can poke at it interactively, is super useful. Anybody making grand pronouncements about how "nobody" has a reason to use a debugger anymore is trying to generalise a really narrow perspective of "gee, I don't personally use the debugger as much as I used to, because it isn't as important in my current specific problem domain and for the sorts of problems I have been having recently" and then saying that it applies to all people everywhere. That inability to differentiate the self from others is a super common problem. I know, because sometimes I suffer from the same issue, and therefore so does everybody else.
I'm very weary of anyone saying you shouldn't do this or always do that. The debugger is a tool and a useful one at that. If it can help you do a particular task more efficiently then use it. If it can't then don't. It's that simple. The one thing where I generally agree that the debugger is less capable is in tracking some multi threading issues. But even then it really depends. E.g. the Microsoft debugger has excellent tools specifically for that purpose which might save you some time and headaches. So don't take this as the gospel. Understand what tools you have at your disposal and then apply the right tool at the right time.
There are three groups of people a see that are vocally anti-debugger: 1. People who grew up with GDB, found it so painful that they’d rather have an extremely slow edit-printf debug loop and yet refuse to try anything else. 2. People who work on a small, solo codebase for years and years. They have memorized every detail of the code and don’t need a debugger to reason out how it works. 3. People for whom debuggers are not an option because they work on distributed systems or don’t have a functioning debugger in their environment. In my case, I’ve spent much of my career stepping through large volumes of code I’ve never seen before trying to diagnose obscure mis-behavior. I work in medium-sized teams teams (tens, not hundreds) on medium-term projects (years, not decades) where more code is being written every day than I could possibly review. When I’ve had to work without MSVC’s debugger, this has been a very slow and painful process. Meanwhile, I’ve heard rumors of groups such as people working at Google on Android using C++ just accepting that progress is slow and painful because they grew up with GDB, used GDB all through school and went straight to using ndk-gdb at work. As far as they know, debuggers are just slow and painful. Why does anyone use them? They really shouldn’t. Wanna get a coffee?
My thoughts exactly. The post is, at best, naive.
I don't do it much anymore, but I agree it can be useful to step through code 'just because'. I remember a case where I blew the loop termination, so it went through a second time. As it happened, the result didn't change; it was just doing twice a much work as I had intended.
Discussions on this issue have been going on for a long time. And I don't think they have a whole lot to do with C++. The arguments in favor of using debuggers are obvious: basically, they can give you lots of helpful information. The arguments against using debuggers are less obvious, but still worthy of consideration, I think. We now understand a lot more than we used to about good practices in programming: proper attention to design, modularity, unit testing, making use of the type system, etc. Practices like these can often take the place of many things we used to use debuggers for, which makes debuggers less useful. More subtly, using a debugger can become "the easy way out"; it allows us to get away with being lazy and avoiding good practices. This can hurt us in the long run. Lastly, many people use a debugger in lieu of actually understanding the code they are dealing with, which can be a very bad idea. In the end, you have to develop your own style. If you want to use a debugger, then, certainly, do so. But be aware that use of a debugger can sometimes become an unhelpful "crutch". If you find yourself using a debugger as a way of avoiding writing tests, or as a substitute for understanding the code you are debugging, then you might want to back off from debugger use. Also, remember that in much of modern life, the limiting resource is *attention*. We are constantly presented with excessively provocative statements, because such statements are good at getting attention. If I wrote a blog post that makes essentially the argument of this comment, then everyone would say, "Ho hum." But if my blog post said, "Using a debugger will DESTROY your ability to write working code!!!" then I would probably get more views. That does not mean there are no problems with debugger use; but it does mean that claims about such problems are often rather overblown.
I know Carmack has said this is a load of bull and he uses debuggers all the time
Hard disagree. Debugger is invaluable for understanding your ( and used libraries ) code flow. That core dumps statement is dumb, my system often has 64kB or less of RAM.
Disagree with C++ unit testing somehow being inferior. I get code coverage ( also tracked online in the cloud), excellent mocking, rapid compile/test cycles. Catch2 and trompeloeil + Codacy driven by CMake in Clion.
gdb and lldb have many very decent frontends.
Thanks to this article I found out that there actually will be an upcoming WG21 meeting in Cologne in 2019. That's pretty convenient for me (2.5h land connection -- certainly easier to get to than Kona), so, heck, if I feel like it, I might decide to show up there to have a look. :)
I've found debuggers to be the **most** useful code exploration tool - for example when trying to figure out how a compiler works...
Yeh, a lot of 'programming' today is downloading some module manager, and some UI framework. Then you press a button and that module manager downloads 250 random modules that the developer probably knows absolutely nothing about and a lot of the time these days may never even look to see what they are. Then he packages and uploads that, and we run in inside our network. And we wonder why the internet is dangerous. And I think that maybe that 250 number is not THAT much of an exaggeration. &amp;#x200B;
What you describe is what Wikipedia calls [offensive programming](https://en.wikipedia.org/wiki/Offensive_programming), a category of defensive programming. I'd avoid implying that terminating on logic errors is not defensive programming. What isn't defensive at all is leaving the check out completely in all configurations.
Most (all?) do. I make use of that a lot, pre-instantiating variations that are widely used. &amp;#x200B;
I think the process of being part of the language development process should be made easier (as mentioned). Maybe there should be actually a "Q&amp;A" working group which fixes language bugs and STL implementation concerns rather then always implementing new "awesome" features. The thing with that is who wants to spend time writing proposals for bug fixes or in general spend time to come up with solutions to problems when he or she can spend time in comming up with new features? If the game industry has so much to complain why don't they spend time and work force (money) into the committee... Like Google google or Facebook do? 
In the latter case I would call the function \`drawInfoIfEnabled()\`. Otherwise it really doesn't matter.
I definitely vote for 1st one, because in case the function is not inlined, you save time for pointless function call in cases when the flag is false.
One big trap with debuggers is that people sometimes try to understand everything that they step through, reading one line at a time, hoping they'll eventually spot the buggy line. Unfortunately, this process can be extremely slow and may never yield anything interesting in a large codebase. At some point, you need to build trust on some of the abstractions and figure out the hypothesis you need to verify in order to stop "stepping in" every chance you get. Otherwise, the debugger is a great tool to help you understand control flow and how to read code and interpret it by yourself. Sometimes, stepping in might lead you to discover some conversion operator you had no idea was involved.
I agree that the STL (to the admittedly somewhat limited amount I've looked at it recently) has become pretty baroque. I hate to think what it looks like to a new programmer coming to C++. If I was just starting out and saw some of the long discussions that show up about it and how complex it's become, I'd probably be a future C# programmer. Not that C# hasn't had its own craziness, with enough syntactical sugar added to kill a diabetic developer. &amp;#x200B;
I'm profusely sorry about that. I will look for a better layout that utilizes screen space better. I've been cheaping out and using free Wordpress layouts, but I haven't been able to find a good one. I will resume looking, and purchase one if I need to.
Agreed. C++, while not as nice as debugging in python, is still extremely doable. If anything, I come away from comments like what OP is reporting feeling as though the originating author is the one not familiar enough with the power of debugging to find it useful. The author is saying more about themselves than they are about c++.
If it's just about changing the texture's size, you should be able to call [`create()`](https://www.sfml-dev.org/documentation/2.5.1/classsf_1_1Texture.php#a89b4c7d204acf1033c3a1b6e0a3ad0a3) on it (again) and thus change the texture size.
Range-v3 is a good approximation to what got into the standard though, and I believe Eric Niebler said that conceptifying range-v3 resulted in only \~20% compilation speed improvement.
Honestly, it isn't that bad. I wouldn't worry about it too much. 
Those tweets are bad and their authors should feel bad.
San Francisco based company Cloudy Horizons unveiled today its new flagship product, Hyper-Cloud. Touted by many as a guaranteed paradigm changer, Hyper-Cloud is a product far out in front of the cloud-based services wave. Capitalized by a Who's Who of the venture capital elite, Cloudy Horizons has been working for the last two years to bring its version 1.0 product to market. CEO Brian Thomas, in an exclusive interview with CloudWave magazine, discussed the rationale behind a product like Hyper-Cloud: "As cloud based services proliferate, we believe that keeping track of all of your cloud connections will become more and more difficult. Hyper-Cloud addresses this issue. Hyper-Cloud provides a single entry point to the cloud, simplifying and streamlining the customer's cloud oriented activities." Thomas explained that their preliminary research, the results of which underlies their extensive access to venture capital, indicated that consumers don't understand that there is more than one cloud, and are confused by dealing with multiple cloud-based vendors. Hyper-Cloud's business model is that Cloudy Horizons will act as an aggregator of cloud based services, presenting them to the user as available options, and providing an easy configuration utility to set them up. Customers will pay Cloudy Horizons the fees that they would have otherwise paid directly to the individual cloud-based service providers. Cloudy Horizons will use its sizeable customer base to negotiate 'wholesale' access to these individual services, and pocket the difference in cost. All user communications will go through Cloudy Horizon's cloud servers, allowing them to monitor the status of all services and user activity on those services. Asked if there were any potential privacy issues with this sort of arrangement, for instance might Cloudy Horizon's sell information about customer usage of specific services and so forth, Thomas replied, "Customers needn't worry about their personal information and access data. Cloudy Horizons believes strongly in customer privacy as it pertains to non-revenue oriented concerns." Asked if there was the eventual possibility of hyper-hyper-cloud type services becoming available at some point down the line, Thomas indicated that Cloudy Horizons has been working closely with law makers, none of whom (he is quick to point out) have any provable investment in Cloudy Horizons per se, to set national policy on the matter of cloud aggregation. Thomas feels, and he assures us that the lawmakers they are working with agree, that hyper-hyper-cloud aggregation services are not in the best interests of the consumer, and should be disallowed by law. Thomas' leadership in this new industry is further cemented by a thick portfolio of cloud oriented patents. From the use of bytes to store cloud gathered data, to the use of text in cloud based configuration interfaces, to their much touted 'liability reduction' technology patents designed to deflect blame for service disruption to the individual cloud vendors being aggregated, Cloudy Horizons is well positioned to dominate the new frontier of cloud service aggregation. Buzz in the industry has been high, and individual investors have been fighting for a choice spot in the upcoming Cloudy Horizons public offering. There has been some niggling in the press concerning the over $35M in venture capital that has gone into the salaries of Thomas and his three fellow founders before the product is even debuted, but Thomas dismisses this as attempts by potential competitors to undermine his company's momentum. "Success is not cheap. I and my fellow founders are so confident in the success of this venture that we felt it only prudent to set expectations early. Winners win, and we felt it important to demonstrate that we are already winning."
I've been there, I blame Microsoft, not qt. You have to find the right permutation of installing or reinstalling vs 2015/2017-win8/10 sdk-debugging tools. 
Which frontends do you prefer? I could never find something quite to my liking. 
Packaging sfml with an application has been pain for me. When there was something wrong with my build setup, it mostly was sfml. The newer cmake config is less of a pain but still required me to manually specify path for libs. Other than that, the API is nice, but fall short when you need more power of more control over the abstracted stuff. However, this library is a bliss for beginners and can enable very quick iterations without hassles.
Isn’t this something that should be better to deal with once we have contracts?
After 5 years of intense c++ dev (averaging around 10 hours every day) i can say with some confidence that this is infact completely true. c++ is a strict language which is possible to mentally model to an extreme. Now and then i do use the debugger (maybe twice a week) but it always feels like a very slow process, its generally just a waste of time - far faster to just write clear code using tools - themselves clearly written and just get it right, when a piece of code acts in highly unpredictable ways (even after rereading it) it probably means its too hard to reason about in it's current forumaltion - it's far fastest to just rewrite it.
Is this an aprils fools on new years?
CLion is my default ( especially as i switch between PyCharm and WebStorm quite often, and it's effectively the same ID ). Eclipse CDT does the job when needed. Followed by simple `gdb -tui` which can be excellent, if you bother to memorize shortcuts or keep a cheatsheet handy.
It might, but I don't think it's possible to have both of those classes in the same inheritance hierarchy anyway, so it's a non-issue.
I found [this article](http://blog.httrack.com/blog/2014/05/09/a-basic-glance-at-the-virtual-table/) that thoroughly explains how the virtual dispatch tables are implemented in some compilers.
I think this is true but it's proportional to how good you happen to be at reading sourcce code (assuming it's not full of calls to external unknown systems)
That say debuggers are adapting: if I'm not mistaken, MSVC skips calls to `std::move` and `std::forward`, and I seem to recall that they added dedicated support for `std::function` so that you don't have to jump through all the layers.
Pretty disappointing message to send IMO. Many new people use debuggers to learn what their code is doing and plenty of others use it to debug issues *before* you write a unit test (if necessary) for the problem. Also, pretty sure the quote from the second one is from someone who's never shipped a large, complex software project. At least judging from that and his other replies he seems very, very deep in the theoretical "always write everything 100% correctly" camp.
I've come to feel that it's a better use of time by far to just rewrite it in a clear well (and with comments).
I think part of mastering a language is learning how best to spend your time - i used to integrate lots of other peoples code (and therefor needed! the debugger) but now i'm a lead at my company and spend my time creating tools for younger programmers (either from scratch or from my other tools) i can think for as long as i need before typing and now the debugger just looks like an inefficient tool for mental modeling.. so i use the language everyday but i'm no longer in the mess of trying to integrate systems i only partially understand.
Then you haven't found the hen users. I love grub. When you know it it rivals visual studios debugger and even has features I don't know if VS can equal.
That's true I do not imply that these problems are unsolvable. Debugging may be hard with current tools but if they catch on it may be totally fine even when debugging complex constructs like ranges. It's just that some things even MSVC debugger haven't yet solved like compiler generated functions. Well, I hope that at least `std::any` visualization will be resolved sooner rather than later.
It depends. Both can make sense. Sometimes it is surprising if a call to drawInfo() does not draw anything. Other times it is expected. If drawInfo() has other checks, for example if it has to figure out how much of itself is not clipped out, it may draw nothing because it has nothing to draw. Doing that check in the caller can be clumsy or inefficient. It may be burdensome to the caller to have to know about the enabled flag.
That's the impression you give when you say you won't do it yourself and challenge those who do.
I think we all know that C++ does not always lend itself to best readability. It's not BASIC ( or contemporary equivalent, Go )
[25%](https://twitter.com/ericniebler/status/1041796655945674752) for a past September GCC implementation of concepts, with a probably rushed and old translation of range-v3 to it. That's just some indication of the biased evaluation, I'm not advocating concepts or c++, I don't. Most of the time I criticize it. I just see no value on rants about performance over emulators.
&gt;analyze deadlocks in post mortem core dumps Yeah, but this is a huge deal, so...
I would identify that as there being two data sets: A) the type of animal B) the type of the "reactor". Based on the combination of these, you want to run specific logic. An idea is to do something like: ``` using AnimalReactorPair = std::pair&lt;AnimalTypeId, ReactorTypeId&gt;; using Logic = std::function&lt;void(AnimalTypeId, ReactorTypeId)&gt;; std::map&lt;AnimalReactorPair, Logic&gt; logic; //...usage void react(AnimalTypeId animal, ReactorTypeId reactor) { auto found = logic.at({animal, reactor}); if(found != logic.end()) found-&gt;second(animal, reactor); else defaultBehaviour(); } ``` (disclaimer, rough code) Depending on specific requirements, you might need to add some other things, but the point is to focus on the data involved and what you need, then craft simple code that represents the data, and computes it. No extra fluff.
Thanks for the clarification, I guess it’s unfairly become a pejorative in my circles.
This ^
Or virtual calls, which are usually everywhere in a C++ codebase
The same can be achieved by extending the data-oriented approach - it's trivial to break out whatever is needed to make it represented by data instead of code if needed. See my other comment above for an example how both the animal and the reacting entity type and the logic itself is broken out into data.
(this is going to sound a bit dogmatic) As someone within a large company of c++ developers - there really are different 'classes' of dev, even within the same rooms i see some people rely heavily on one tool or another while others prefer to use their mental memory or even pen and paper - i know devs who write large hunks of code that generally work perfectly the first try - and i know devs close to the opposite - who write a bunch of junk and them step thru 50 times fixing each bit as they get there (in a kind of memoryless - mindless drone coding style)
I'm sorry if you saw that as a challenge, but it's not meant to be adversarial. As I said, I didn't understand the reason one would do this and was asking for more information.
To add to this a bit.. Perhaps you've noticed a chorus of game developers freaking out about Modern C++ not meeting their needs, and being huge fans of the debugger. It's due to a few things. \- Everything runs fast. It has two speeds - fast in Debug, and faster in Release. Running through a huge chunk of your codebase just to test out your changes is a reality - and it's not a problematic one. Once you have this, it's natural to try and find a way to make the most of it -- and it's even better than people think (an example is: sprinkling assertions throughout the code to test your assumptions and/or constraints, all over the place). Unit tests are nice, but having things actually run with assertions within is like an unholy marriage of integration testing and unit testing, with some leap of faith towards this stochastic approach hopefully catching enough over time, and/or just doing it since it has always tended to work out best in the past - and it's magnificent. \- It compiles fast, and people often actually bother to keep incremental builds working (and breaking that would cause everyone to flip their desks - so that doesn't happen). Once you've got everything running fast, you look at the next enemies. Compile times are one, and they get mercilessly attacked. When you can compile+run your changes quickly and run them with the debugger attached quickly, you get to build up your code step by step and verify them by actually stepping through them and watching the flow and variable values. A great bonus is that you write code that is easy to step -- since otherwise, you'd be working slower. Then if the next poor schmuck has to pick up your code and figure it out, it's relatively easy to do so (and you benefit from others having done the same). \- Visual Studio (with Visual C++)'s debugger doesn't suck and tends to work properly right away so long and continue to do so as long as the core devs bothered to set it up right in the first place. It's been in that state for most of the pas 20 years at least. Initiating 30+ debug runs per day is an absolute pleasure rather than a chore. I'm sure there are more. Mostly, I like being able to fix 5+ bugs per day (sustained) when I'm on it. I've tried on teams that don't use the debugger, and that doesn't happen - even when I AM using the debugger.. because the codebase evolves along with it. This is why there's a schism.
Could not agree more ! excellent post !
wow really well rounded perspective !
Absolutely agree ! in the real world you often need a debugger ! tho i suggest you atleat start building your seret tower while your young.
It is about what information is available in each module. You need to keep as much separation between modules to keep your module tests from exploding. So the primary question is who has 'logical' access to infoEnabled without creating a mess. In my experience, the parent module knows what is enabled and what is not. So I prefer the first one. In some cases, when infoEnabled is already available and if the function is getting called from multiple places, it would be nice to move the checks inside the function.
if narrowing down issues typically takes hours you have severe problems with the project that need to be rectified. **sometimes** problems can take hours to nail down, but that should not be the norm. Part of software dev is asking yoursef "how can this code fail" and then following that up with "if this code fails, how hard will it be to determine this is the specific place failing?". If your answer isn't "we'll know immediately" then you need to write code that specifically checks for the failure beforehand and explicitly errors out so that developers can go STRAIGHT to the problem.
Its a reflection on the previous RT, which is the reflecting on the debugability of Modern C++, and that its not always that great. (thats what the #lastRT is for) Which is true, but also was not really a major focus for its evolution from my point of view. Modern C++ tries to convert possible run time errors in compile time errors. But of course you'd still need a debugger to catch human errors in other peoples code. So I don't agree with Peter Sommerlad on that its only useful for finding deadlocks. I thought thread sanitizer is for that ;) But he kind of proofs my point from which school of thought some of Modern C++ comes.
Yeah agreed, i almost added ( and it happens to not a soup of templates, lambdas and callbacks )
&gt; go &gt; lol no generics 
Yes, that is the goal of Meeting C++. Why do you think I post blog articles and resources on a daily basis? Sometimes my job involves also posting my own opinion or reflection on something. Also, some people seem to see more in these tweets then there is. And suddenly claim things I never said or intended when posting this. Why do did you not post a link to the tweet or also copied the smiley (;P!) on the end?
In my experience, the biggest productivity hurdles in C++ are in the initial stages of setting up a project, build system, dependencies, etc. These hurdles are significant and painful (and represent the biggest shortcomings of the C++ ecosystem, IMO). Once you already have the build infrastructure and stuff set up, and you have experience with C++ and whatever IDE/toolchain you use, I think it’s mostly comparable to other languages in terms of productivity. The things you mentioned that would apply beyond the initial configuration of the project, such as header files being separate and templates being hard to read, don’t pose any significant productivity barriers in my experience. They are just things you get used to and learn to deal with quickly.
I'm in a fourth group that worked in large code bases and have seen entire teams use the majority of its developing time just digging in the debugger GUI. I'm not vocally anti-debugger in an absolute sense, I do am, when it's viewed as a must have so much that [cause people not to give a pause to think what they're doing](https://www.reddit.com/r/cpp/comments/aav7ci/do_you_use_a_debugger_much_meeting_c_claims_you/ecvtmb1/). The experience made me form the opinion that if things are leaning towards that state, it's because the codebase is flawed or rotted.
No, switching to a `shared_ptr` just to avoid passing a `unique_ptr` by reference (I assume you mean the non-const case) is a bad idea. For example: Imagine a `helper_function(unique_ptr&lt;MyType&gt;&amp; up)` that does some complicated stuff that ends with a call to `up.reset()`. This is still unique ownership. Just a part of the management logic for the owned object was factored out into another function. Switching to `shared_ptr` here is the classic case of abusing `shared_ptr` for something that looks vaguely like shared ownership on first glance, but is really as unique as it gets. I agree with your second point, though. That’s as simple a performance optimization as you can get, hardly hurts readability and has a low potential to introduce errors (just the usual “don’t touch moved-from objects” stuff).
void drawInfo() { if (infoEnabled) { // ... } }
The most painful thing about SFML is porting an existing application on Android. I know it's mostly due to Android limitations though
&gt; Package management is a big pain (often it'll take me 30 minutes of fiddling with makefiles to hook up an open source library) Only during initial phases of the project. Once build system, CI are setup correctly, everything is smooth. The problem is getting the build system done is a difficult task. &gt; More boilerplate code to write (eg it's standard to separate header files from source files) In a large project, you just need to ignore the implementation. This adds a lot of flexibility. &gt; Much more expressive syntax means it's much slower to read and use other people's code (templates, operator overloads, const everywhere) C++ is old and the syntax can't be fixed you know. ### Answer to your question * Most C++ developers work in a small part of a big system. Once you master stl, boost and the project specific libraries, you save a lot of time. * Over the years, you will build a lot of experience in how to use IDEs(Microsoft Visual Studio/QtCreator). The reason Golang doesn't have a dedicated IDE, because you don't need it. * Developer productive depends upon the developer and his ability to understand and solve the problems. * The difficult part of C++: metaprogramming are rarely used by most developers. In fact, it only solves system and language specific problems, not the problems related to business. 
c++ development keeps getting faster as you learn which tools to use and which to avoid - but it takes in the realm of 5-10 years before you can smash out projects at the speed of say a lua noob. However by that point the code your producing is gold and you would never want to go back... plan to program for less than ~8 years ? find another language.
They are the in the same inheritance hierarchy if they both come from a thing in a header. For example, every user std::locale facet ever.
So you're manually implementing a 2D vtable. Re: formatting - I think you wanted four spaces for block code. 
A lot. But a test doesn’t tell you what is broken just that something is broken. You still have to go find it.
It is about changing both the texture's contents (different image) and size. I tried just calling create again on the same object. Had the same results like update. Plus, i wasn't sure if it would take care to free the previously used memory. Now, it is entirely possible for me to be doing something completely dumb (using SFML wrong), but in this particular case it is just not that relevant since , well, how fast can a human traverse a list of images? I provide buttons and keyboard arrows for next/previous but that's all. 
The funny thing is that everyone who downvoted philocto's comment will live to see it as self evidently true. See you in a few years guys. We'll be over here writing greenfield code while you rockstar away your sanity hitting F10 over and over.
It can try to convert runtime errors into compile time errors, but I can't even put into words what a small fraction of bugs, especially the hardest bugs, that can cover. Yes, `void*` is terrible and I'm glad we have templates. Yes, you can see quite a few interesting examples of bugs where good use of types will help you catch errors at compile time. No, that doesn't mean that compile time errors can cover everything, or even most things, nor especially the most difficult bugs. A lot of the hardest bugs are just subtle or not so subtle mistakes in logic, or mismatches between the spec you programmed to and reality. Two recent bugs in some code that I wrote came out of simply forgetting to call a function in a particular place (in accordance with the design of the code). The output data wasn't obviously wrong. Comparisons with a previous version of the code showed that there was a discrepancy but it wasn't obvious from that what the problem was. It took hours of using both logging and debugging to track down this ridiculous error. How would type systems have helped with that? If all the code you're writing can have every single error caught at compile time (at least in the C++ type system), you're writing pretty trivial code. If the school of thought of modern C++ is that the type system is the only mechanism we need to catch errors, I can only conclude that the school of thought is not one interested in writing real world, complex programs. Fortunately, I actually don't think it's the case. People publicly advocating and promoting C++ should be acknowledging debuggability as a problem instead playing pretend.
as part of normal development? never. if you can't step through your own new code then you have a problem...
&gt; fall short when you need more power of more control over the abstracted stuff Do you have any specific examples in mind?
Actually, Im not so sure that `-lstdc++fs` won't be necessary in the future. `-latomic` is also still required half a decade after it's introduction. 
But otherwise you might call the draw function when you shouldnt and it might do stuff you dont expect. Keeping track of one check vs. many checks.
How do you not manually implement a 2D vtable? Formatting seems fine on my end
I lukę it OP. I think it was a good idea using that naming!
Double dispatch.
Oh hey, fellow german. Considering to join as well. Just wondering how expensive tickets will be.
In my situation, I wanted to manipulate the audio stream to create sound effects. I also wanted to play around with the channels. If I want to do that, I must use OpenAL directly or something else. Since I used sfml only for audio, I plan to try STB to load audio files and use libsoundio to stream it (if it work great for my needs). 
How is implementing that really quite verbose pattern any less "manual" (and better) than my proposed approach? IMO there's way more lines of code spread amongst several types with the double dispatch method for no real benefit other than working around an already poor tool to solve the problem (inheritance). 
For packaging, the new config system was better, but could be much better. I installed SFML in a local directory and added the path to `CMAKE_PREFIX_PATH`, but the resulted visual studio solution and Linux makefile did not set a path for `afml-audio.lib`. I changed the makefile and visual studio solutions manually to fix the problem in order to deploy. That was painful. Also, that may be just because of my specific setup, but I rely on the syntax `find_package(SFML REQUIRED)` to work for automatic package management. The problem is the config file is forcing components like `find_package(SFML COMPONENTS audio REQUIRED)`. My package manager failed to find the installed package. For this problem, I'd suggest to look at what Qt did. They had the find package with components like sfml, or separated packages for individual components. It would also allow `find_package(SFML-Audio)` One last thing: sfml should strongly consider *at least* adopt a C++11 style. It would make things a lot easier. Enabling move semantics on non copiable stuff would make things a lot easier. I really hope you guys make this library better. It have been really useful for me and made learning C++ much more fun and easy to experiment with.
It's better to call drawInfo and have it crash/assert on incorrect usage as a way to catch bugs, instead of calling it incorrectly and have a silent error. The latter is a lot harder to track down in big codebases.
Yeah, I'm sure there are compiler / platform specific solutions. 
Thanks for your list of feedback :) 1. There is indeed no batching, I'd say intentionally, as in "you get what you ask for". If you do 100 draw calls, you DO 100 draw calls. Batching systems can end up being specific to a specific use case, where SFML can only speculate. Also giving fine control over the batching may end up with quite some API bloat. I have some ideas for the future, where implementing batching might make a bit more sense. The general advice is to use vertex arrays or vertex buffers as soon as you need more than just a few shapes or textured sprites. 2. Yep, one of the things we hope to somewhat "fix" with scan code support in SFML 2.6. 3. Might be interesting to see what you implemented. I do believe that there's most likely things to further improve between SFML and freetype. 4. This can greatly depend on the implementation. Imgui and other libraries (e.g. SFGUI) will implement "complex" cache systems, render out fixed text into render textures, etc. Comparing the optimized text rendering of Imgui to the most basic text rendering of SFML will show up as performance difference. 5. The support for AA on RT has been added in SFML 2.5. 6. The general rule is to reset everything you changed, can't really comment on the performance impact. 7. I agree that the network module could use some update, but given that ASIO standardization is around the corner, kind of puts the whole module in question. Implementing QUIC seems a bit overshooting the goal here. 8. There was already quite a bit discussion around this and everyone agreed that a different interface would work better. I already planned to dig up that code and start pushing this forward soon. Generally, I think it's important to keep in mind that SFML is trying to achieve. The goal isn't to be a (game) engine or to be highly optimized for every case, but it's to provide a simple API which if required can be tamed to build better optimized abstractions on top. Thanks again, useful points. :)
1. Lambdas can capture variables. 2. Callbacks aren't special. You won't find the word "callback" in the language spec (probably). Are you casting the lambda to a function pointer? Thst's only possible if it doesn't have captures.
I do most of my debugging in VS2017 on a C++17 code base and find the debugging experience first class. I'm quite confused what the big deal is about.
Can't tell what kind of manipulation you had in mind. If it's not anything specific OpenAL related, you can do quite a bit with [`sf::SoundStream`](https://www.sfml-dev.org/documentation/2.5.1/classsf_1_1SoundStream.php#details). With audio it however seems like you quickly have to drop to the lowest level in most cases, as you do really want the lowest possible latency.
Is this a joke? Should you just mentally run the program then?
I'm a massive proponent of writing automated tests, but I really don't see a dichotomy between that and using a debugger. In fact, I spend a good bit of time inside the debugger while I'm writing my tests. I just see it like a magnified window looking inside the clockwork. Why on earth would I not want to use that if something isn't working how I expected it to?
You should definitely clarify what you mean by "callback". Anyway, the thing to remember about lambdas is that they're basically syntactic sugar for one of two things. If you don't capture anything, a lambda just defines a function with a compiler-decided name. If a lambda captures something, the lambda is an instance of a class (again with no name) where the lambda body is operator(), and the things it captures are members of the class. So, if you want to pass a lambda to a function, you should make it a template function, so that the template parameter can match the lambda's type.
Oh it must be because I mostly worked with `sf::Sound` and `sf::Music`. I'll try that before. I wanted to create a reverb and parametric EQ. It could be done by applying the effect before or splitting a sound into multiple tracks but it become tedious fast.
I don't quite follow with your first point. If you have installed SFML somewhere and want to find it from your own CMake script, you need to set `SFML_DIR` to the directory where the config files are located, those will then resolve all the libraries location and paths. Also depends when you tried it last, we had a few CMake fixes in SFML 2.5.1. That's however not what the "modern" CMake recommends. In modern CMake you work with targets everywhere and `sfml-audio` is a target here. Yes, C++14 or C++17 is coming with SFML 3, which is the next release after SFML 2.6. The more feedback we get the better we can make it - and the more contributors we get, the faster we can get there. :D
The ongoing work on heterogeneous computing kind of continue with the idea, so I wouldn't say it "fizzled away", it just passed the torch.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ab14lx/newbie_question_about_enumerations/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
But it might not be a hard error.
And what do you do when the 3rd unit test you are writing doesn't give you the expected result? If you don't see the issue within 30 seconds you will most likely fire up the debugger and have the test passing within and other 2 mins. Move on and write another 5 tests. Rinse and repeat. It's just another tool that complements all the others. Engineers shouldn't deny themselves the best tools around out of some sort of macho sense of "real coders don't need a debugger".
`SFML_DIR` should be optional. I have no other dependencies that need the path. I installed a few libraries into a local directory and set my prefix path to that. The `find_package` search in the prefix directory and finds the config files. Both on Linux and Windows. No hard-coded paths. Maybe I can send you a PM with my whole setup so you can try it? If someone in the SFML dir can make the experience better that would be really nice.
&gt; Are you casting the lambda to a function pointer? Thst's only possible if it doesn't have captures. To build on this, understanding lambda's internals could be thought of really like this: lambdas create a "phantom struct" that take all of the captures, build them inside of the constructor. After this, it builds a function (specifically an operator()) with the contents you listed, parameters you listed, and allows it to have the captured variables. It then creates the structure inside of the function you made it in. That's how EVERY C++ compiler handles lambdas, [C++Insights show you nicely](https://cppinsights.io/lnk?code=I2luY2x1ZGUgPGNzdGRpbz4KI2luY2x1ZGUgPHZlY3Rvcj4KCmludCBtYWluKCkKewogIGF1dG8gbGFtZGEgPSBbXShhdXRvIHgsIGF1dG8geSl7cmV0dXJuIHggKyB5O307CglpbnQgYSA9IDAsIGIgPSAxMjsKICAJcmV0dXJuIGxhbWRhKGEsIGIpOwp9&amp;rev=1.0) how lambda internals work. So, in essence, when you're trying to pass around a lambda to a function pointer, you're really passing around a structure being cast to a function pointer, [as seen here](https://cppinsights.io/lnk?code=I2luY2x1ZGUgPGNzdGRpbz4KI2luY2x1ZGUgPHZlY3Rvcj4KdHlwZWRlZiBpbnQgKGNtcEZ1bmMpKGludCBhLCBpbnQgYik7CmludCBkaWNrTW92ZShpbnQgYSwgaW50IGIsIGNtcEZ1bmMgZnVuYykKewogIHJldHVybiAoZnVuYykoYSwgYik7Cn0KaW50IG1haW4oKQp7CiAgCWF1dG8gbGFtZGEgPSBbXShhdXRvIHgsIGF1dG8geSl7cmV0dXJuIHggKyB5O307CglpbnQgYSA9IDAsIGIgPSAxMjsKICAJcmV0dXJuIGRpY2tNb3ZlKGEsIGIsIGxhbWRhKTsKfQ==&amp;rev=1.0), so basically, in a nutshell, the fact that the structure now has a constructor and needs to be initialized first with everything and therefore is not purely a function pointer as a lambda. My explanation was probably mediocre, but that's the gist of it.
What do you do when you're writing your tests to cover some new code and one fails in a way that isn't obvious? 
&gt; If you don't capture anything, a lambda just defines a function with a compiler-decided name. &gt; If a lambda captures something, the lambda is an instance of a class (again with no name) where the lambda body is operator(), and the things it captures are members of the class. Slight correction, at least with clang and OrangeC (unsure of GCC and MSVC), it always generates a structure/class, and it always defines certain functions, but doesn't always generate certain things (e.g. a private version of the function and a constructor, etc.) [Seeable here](https://cppinsights.io/lnk?code=I2luY2x1ZGUgPGNzdGRpbz4KI2luY2x1ZGUgPHZlY3Rvcj4KdHlwZWRlZiBpbnQgKGNtcEZ1bmMpKGludCBhLCBpbnQgYik7CmludCBkaWNrTW92ZShpbnQgYSwgaW50IGIsIGNtcEZ1bmMgZnVuYykKewogIHJldHVybiAoZnVuYykoYSwgYik7Cn0KaW50IG1haW4oKQp7CiAgCWF1dG8gbGFtZGEgPSBbXShhdXRvIHgsIGF1dG8geSl7cmV0dXJuIHggKyB5O307CglpbnQgYSA9IDAsIGIgPSAxMjsKICAJcmV0dXJuIGRpY2tNb3ZlKGEsIGIsIGxhbWRhKTsKfQ==&amp;rev=1.0) and [Here](https://cppinsights.io/lnk?code=I2luY2x1ZGUgPGNzdGRpbz4KI2luY2x1ZGUgPHZlY3Rvcj4KCmludCBtYWluKCkKewogIGF1dG8gbGFtZGEgPSBbXShhdXRvIHgsIGF1dG8geSl7cmV0dXJuIHggKyB5O307CglpbnQgYSA9IDAsIGIgPSAxMjsKICAJcmV0dXJuIGxhbWRhKGEsIGIpOwp9&amp;rev=1.0) and for the constructor, [Here's a nice bit of code quickly stolen from cppreference](https://cppinsights.io/lnk?code=I2luY2x1ZGUgPGlvc3RyZWFtPgogCmF1dG8gbWFrZV9mdW5jdGlvbihpbnQmIHgpIHsKICByZXR1cm4gWyZdeyBzdGQ6OmNvdXQgPDwgeCA8PCAnXG4nOyB9Owp9CiAKaW50IG1haW4oKSB7CiAgaW50IGkgPSAzOwogIGF1dG8gZiA9IG1ha2VfZnVuY3Rpb24oaSk7IC8vIHRoZSB1c2Ugb2YgeCBpbiBmIGJpbmRzIGRpcmVjdGx5IHRvIGkKICBpID0gNTsKICBmKCk7IC8vIE9LOyBwcmludHMgNQp9&amp;rev=1.0)
Yeah, it doesn't compile, it's illustrative of the concepts. It's an array, sized to the maximum number of things you have, with an enum value of how this thing reacts to other things. For the comment I was replying to, you'd do this: animalTypes[AnimalTypes::Human].reactions[AnimalTypes::Wolf] = ReactionType::Run; Where animalTypes is some statically sized array. You don't need to have it be static either - types can be a map, read from some data file with an ID assigned at runtime. Either way, this approach means that while you have a small number of classes, you can create a table of data. And if you end up with hundreds, all you need to do is load the table from somewhere. Everything else stays the same. There's frankly almost never a reason to inherit for these types of things. Better to just use data.
This isn't a problem in practice. The compiler maintainers and library maintainers know what type `size_t` should be, based on the platform being targeted. Compared to everything else that's necessary to implement C++, this is trivial.
I kind of agree with your first point, that's mostly what I use a debugger for too - just getting a quick picture of the stack, values etc... and that's usually enough to see the issue alongside the code. However, I'm not sure which debugger you're using, but certainly VS lets you set breakpoints and then let the execution run until it hits a certain line, another breakpoint or even a conditional breakpoint (some variable has reached some value etc...). Occasionally this can be very handy for trickier issues, and doesn't take long at all. If you're actually stepping through a module line by line, you're doing it wrong (or using a bad debugger).
I never meant to say anything you're doing is bad. I asked the question in the first place because I'm curious about DOD but don't really understand how to use it. Double dispatch is a bit clunky and kind of confusing. It's a bit more immediately obvious how your version executes. I do see what you're doing as more manual though. Each entry in the table needs to be populated manually, versus inheritance giving a hierarchy of behaviors that minimizes the number which you need to specify. This is especially a pain when you start adding things to the interaction. And to let me do that at all, I need mutable access to `logic` at runtime, but I don't like that the part of my code that concerns one animal/reactor can change the way an unrelated animal/reactor behaves in the interaction. It also doesn't seem good to be setting up the interactions at runtime, but maybe this kind of "setup" phase is a normal part of DOD. Otherwise, I don't see either technique as more verbose. You'll have to implement the same number of functions for both methods. I don't mind having the code for doing so spread among multiple types, and if you started adding to the interaction set after the fact as I'm discussing, you'd wind up with implementations in multiple places for your method as well.
It is difficult to do fully automated testing in interactive apps. But there's a lot you can do once you know some of the common tricks, and I think the fact that it's hard to do makes the payoff all the bigger. You're (sort of) asking 'how can I drive my entire system to test a small part of it'? Ideally, you need to be able to test each part of your system in isolation. You'll end up in the debugger anyway, but you'll have much less code to step through. &gt; How exactly do I accomplish the mouseover in a unit test? You don't. Your test calls the code that the mouseover handler would call. Unless you're suspicious of the GUI API itself, avoid dragging anything into your tests that can be avoided. Crucially, avoid dragging in things like OS event loops and global state - you want your tests to be as 'pure' as possible so you can use them as a basis for your reasoning. The difficulty here of course is that the mouseover handler may call other code you have no control over, which means you'll need to do some form of dependency injection and/or mocking, which is not convenient in c++ if you avoid dynamic polymorphism. &gt; I can query an API to ask an object its color as part of a test. But I don't know enough to be sure if what I am seeing matches the object's internal state, or they have become desynchronised. So make sure the API state change always goes through a single place in your code, and write tests to convince yourself the there's no way they can become desynchronised. Obviously this won't rule out a data race or memory trampling in your main program desyncing things anyway, but having the test lets you eliminate a bunch of possibilities very quickly. A lot of the problems you describe are only problems when you have low test coverage to start with. Admittedly, there's a large cost to getting coverage to the point where it starts to pay off, and a steep learning curve in working out how to write good tests in a given domain. I think interactive app domains tend to be harder than most in both cases - certainly much more than CRUD web stuff. But I think it's valuable to keep in mind the higher cost is the upfront investment, not the ongoing cost. I'm hopeful that automated testing use will gradually increase in games etc, as I think it will pay off hugely.
That's what CWG and LWG do when they're processing issues (versus reviewing papers). &gt; who wants to spend time writing proposals for bug fixes Implementers. We prefer to avoid implementing an unclear, inconsistent, or defective specification, so we are responsible for filing and fixing most issues. If anyone is skilled in Core or Library wording and wants to help, your help would be greatly appreciated - we have a near-endless stream of issues that need "drafting" (i.e. designing and wording a fix). This can be done without attending meetings in person, but requires the highest level of attention to detail.
Fair enough; I probably should have said something like, "they're syntactic sugar for something which behaves as-if it was declared like this". So, for example, you can cast a captureless lambda to a function pointer, so it behaves as-if it was defined as free function. Actual implementation details may vary.
Note that both `shared_ptr` and `unique_ptr` guarantee that moved-from is empty. (Avoiding doing anything with moved-from smart pointers is still perfectly reasonable.)
I wouldn't say the debugger is a tool of the past, but I certainly use it less than I used to since I started doing TDD. I actually run my tests in gdb more often than the code being tested.
I can’t speak for the entire industry of course, but my take is that the game industry was forced to fork much of the original STL due to performance concerns early. This engendered a sort of unhealthy mistrust that the committee held high perf concerns in enough regard to make api compromises where necessary (regardless of how true this is, the sentiment remains). Of course, this means that your average industry professional isn’t always caught up to speed when either the process changes, or the API itself changes. Cue the expected “outrage” when some venerable developer takes a gander at what’s to come and surprise surprise isn’t enthralled by what he or she sees. There is a study group for games, and while there may be eyes there with lots of c++ proficiency or game dev proficiency, there is rarely a lot of both. I’m just one voice, but I’d prefer a world where C++ was the perfect language for library authors, and not necessarily the language you expect to have full “batteries included.” This means features more important to me are core language features and tooling. In contrast, effort in STL land I believe is better served by the core language or third party package are less interesting. Of course, I recognize this is idealistic and compromises are natural, especially for a mission critical language in so many domains as c++. The nature of my job though, forces me to be fairly uncompromising as a matter of course. Others take this to an even more extreme degree, not always to good effect. 
I'm not sure if you meant train tickets or meeting tickets, so to clarify: WG21 meetings don't have tickets, and there is no charge to attend. (The costs are travel, hotels if you don't live in the area, and time.) There is a cost (to corporations, or unaffiliated individuals) to be an official voting ISO member, but you can attend meetings and vote in straw polls (where the actual design work happens) even if you don't participate in the official votes. (This is also the status for many people employed by companies, like me - each company gets one official vote, so additional company employees can participate in straw polls but not official votes.)
Yeh, sorry, I meant to pass to something that already takes a function pointer. So I guess the next question would be, what is the form for accepting an actual lambda as a parameter, which you can then call, in a way that doesn't require having to create some sort of ad hoc wrapper around it or have some other shortcomings? From poking about, I don't see a really good way to do that. Most seem to be clunky and/or seem to have undesirable performance costs, at least from reading comments. Assuming that lambas are always intended to be called and always passed to something that's going to call it, I would'a thunk that there would be a clean and efficient means to accept one as a parameter? I could give up the function pointer thing in some cases and accept a lambda, though in others I'd want to keep the function pointer because a named static or function is way more self-documenting and searchable. I'd use the lambdas for more ad hoc stuff. &amp;#x200B;
Debug, of course. I never said I didn't use a debugger. Sigh.
I consider this post to be definitely on-topic and it is welcome here.
I love gdb and I would definitely not call it "not polished". If you're one of those developers who read the fucking manual, gdb offers you tons tons of opportunities to improve your code. Hell I even use gdb to automate testing and test coverage. You can hack gdb with python code. You can program gdb to make test cases for you and run. I think gdb offers an excellent debugging experience, but you should RTFQ. Another thing I love about gdb is how transparent it is to its own bugs. When it incurs an unexpected internal state that is not worth violently failing, it prints debugging experience after this might be unreliable. Having encountered many debugger bugs in my life that simply made all our debugging efforts futile (imagine stepping through your code but debugger is stepping the wrong branch and you don't realize it for days) this is a really useful feature. Another thing I love is backward stepping which lets you go back as well as forward so that once you're in a bad state and forgot how you ended up like that you can go back. OR you can program gdb to run the program until you encounter the bug and then backward step to find the cause, a-ma-zing. calling this piece of complex software "unpolished" seems wrong.
&gt; If you don't capture anything, a lambda just defines a function with a compiler-decided name. This is incorrect. A lambda expression always constructs an object of class type with a function call operator (and for stateless lambdas, a conversion operator to pointer-to-function). Ask `decltype` and `is_class` if you want to see. &gt; So, if you want to pass a lambda to a function, you should make it a template function, so that the template parameter can match the lambda's type. This is correct guidance, and will generate efficient code. For example, it's how STL algorithms work - they are templated on predicate, comparator, etc. type, so you can pass a lambda with captures (or not) to `std::count_if()`. Alternatively, you can use `std::function` (and pay non-zero space/time costs) to pass lambdas and other callable objects to non-templated functions. For example, virtual functions and separately compiled functions can take `std::function&lt;Ret (Args)&gt;` and then be called with lambdas with the `Ret (Args)` signature.
FYI, the Q1 2019 thread will be going up soon (and the Q4 2018 thread will be un-stickied and locked). You can and should re-post this in the new thread when it's open. Thanks!
I make my own gdb scripts in python and don't use a frontend (I think tui is simply a bad frontend) so you can run the script and generate custom logs of your program (for the relevant portion) and then use Unix tools to analyze the logs. I agree with the OP quote in the sense that stepping through your code one line at a time is a little inefficient and logs offer a better debugging experience. BUT not all software is capable of producing logs for the bug in hand, so use your debugger to do so.
Off-topic. Consider r/ProgrammerHumor.
&gt; [1]. There is indeed no batching, I'd say intentionally, as in "you get what you ask for". If you do 100 draw calls, you DO 100 draw calls. Batching systems can end up being specific to a specific use case, where SFML can only speculate. Also giving fine control over the batching may end up with quite some API bloat. I have some ideas for the future, where implementing batching might make a bit more sense. The general advice is to use vertex arrays or vertex buffers as soon as you need more than just a few shapes or textured sprites. &gt; I get this completely, I've followed some of the discussion around batching in the past - constructing your own vertexarrays works perfectly fine for the most part, but if there were a simple concept of a shapearray that could all be drawn in one draw call it'd be super neat, mainly so I don't have to manually build my own circles! :) The main problem is that there is no real way to implement batching without diving into the level of constructing tris through vertexarrays, which feels like you lose a fair amount of the friendliness of SFML &gt;[2]. Yep, one of the things we hope to somewhat "fix" with scan code support in SFML 2.6. Sweet! This is great, hacking around this was on my todo list &gt;[3]. Might be interesting to see what you implemented. I do believe that there's most likely things to further improve between SFML and freetype. I'll make a patch. I've been using SFML for long enough that I should really contribute something back, subpixel font rendering doesn't lead to too much change, its mainly just a bit tedious as freetype's documentation isn't the best &gt;[4]. This can greatly depend on the implementation. Imgui and other libraries (e.g. SFGUI) will implement "complex" cache systems, render out fixed text into render textures, etc. Comparing the optimized text rendering of Imgui to the most basic text rendering of SFML will show up as performance difference. So: as far as I'm aware both imgui and SFML render out a font atlas - in ImGUI's case it builds a font atlas of *all* fonts, and in the case of SFML it builds a separate font atlas per font. ImGUI doesn't do anything that different otherwise, I haven't been able to figure out why it seems to be about 50% of the speed in SFML as it doesn't seem to be related to that fact. SFML overall seems to have some performance bottleneck somewhere which isn't entirely related to the usage of OpenGL - it might just be because in a rendering system which is completely deferred, 0 work has to happen at all to render a new object beyond binding necessary opengl state, whereas sfml doesn't operate on that level, in which case we're back to 'can batching work?' &gt;[5]. The support for AA on RT has been added in SFML 2.5. Oh awesome, time to update. This will fix some performance/interop problems with rendering the steam overlay for me &gt;[7]. I agree that the network module could use some update, but given that ASIO standardization is around the corner, kind of puts the whole module in question. Implementing QUIC seems a bit overshooting the goal here. This is fair enough, the main reason I suggest something like QUIC is because neither TCP nor UDP are actually *that* useful on their own for a lot of applications and will soon be a fairly standard protocol, but I suspect that something will come out based on the TS or boost &gt;Generally, I think it's important to keep in mind that SFML is trying to achieve. The goal isn't to be a (game) engine or to be highly optimized for every case, but it's to provide a simple API which if required can be tamed to build better optimized abstractions on top. Oh definitely! I super appreciate the work that everyone has been doing on SFML, and it has come an enormously long way. Thank you for replying, as well as building it! :)
I'm just rookie and I think SFML is tool for people like me, for beginners. It's super simple, powerful and very expressive. But there are couple of things I had to write myself which could be included in library: * lack of polygons in graphics (user should know cost of creating one, triangulation(and embedding texture) could be done on library's side), * SVG file into sfml graphics would be great addition, they are so similar (implement just subset of SVGs), * when using FindSFML.cmake from tutorial you have to copy content of lib/Debug and/or lib/Release directory into SFML\_ROOT.
So, sounds like you are more disagreeing with the statement that we shouldn't use debuggers with modern C++? Sure, you're also pointing out that we shouldn't over rely on them, which is fair enough. But this is not the original point that the OP was objecting to. And why I asked my rhetorical question. Sigh indeed.
I step through all my code. Everyone should.
Others have mentioned the most important things to consider. But here's another: the second form almost necessitates global or class member state, while the first form could be done with a free function with some minor changes (like passing a few arguments), and it could even be pure. That is one reason why I would prefer the first form.
Can you go more into detail about network module features? I will be working a lot with SFML networking on a project of mine and would be happy to contribute to the library with features.
You seen to only work on trivial problems. Good for you. But the real world isn't always that simple.
My point was more that `libstdc++` has a vector implementation that is insanely widely used, so the little bugs in it have been worked out. That’s the primary reason not to roll your own `X`. It’s not a personal attack on a given developer.
Hahahaha. Very funny.
Are you perhaps looking for std::function? You can define a lambda that captures arbitrary state and then assign it to a std::function of the same signature as the lambda. This is now a normally typed object which can be passed around, stored etc.. and is callable.
OK, the template thing worked. 
I don't use the standard libraries so std::whatever isn't available. But the templated thing worked just fine. &amp;#x200B;
What specifically are you wondering about? :) if you're talking about udp + tcp, its because UDP is unreliable and has a very low maximum amount of data you can put in a packet, whereas tcp is reliable but is essentially not a very good protocol in most other respects for a lot of applications (nagle, steam oriented, bad congestion properties) QUIC has the advantage of being encrypted by default, reliable, UDP based (less protocol rust), lower round trips for setup, exposes less information in packets (less tampering by middleware), better throughput, supports persistent sessions even if your IP changes, better congestion handling etc etc Its a strong improvement over any other practically available protocol about. UDP and TCP are fine, but for a lot of applications you really need something else. Valve provides a QUIC-like protocol in the form of game networking sockets, but there currently isn't a good cross platform easily usable implementation for people to pick up and stick in places
And it also allows me to use function pointers with the same methods, so works out pretty well.
Yea I do the same in Xcode and visual studio (cross platform app) and debugging is great
Makes sense. :)
I'm also coding cross platform, and if I can I'll do debugging on Windows because I find the xcode debugger not as good. It's also likely that I'm just not as good at using it, but it doesn't seem to do some basic things well like visualisation of STL containers.
Thank you!
The `sizeof` operator has had the same 'issue' since C++98. ;-]
Checkout [conan.io](https://conan.io), CMake and/or Meson Build. Using [conan.io](https://conan.io) in conjunction with either CMake or Meson and a CI server will improve project productivity greatly. 
Go is a small language by design. C++ is huge by comparison. C++ is not a language you learn in a few months whilst using it part-time. It takes full-time dedication for years to learn to wield it efficiently and correctly. Regarding packages and building, checkout [conan.io](https://conan.io), CMake, and Meson Build.
Bad or not - I'm responsible for it. Every code base I've worked on had some bad code.
&gt; I don't use the standard libraries…. Why not?
I hate even say it, because people somehow act like it's sacrilegious or something, but I have my own. I've posted a number of things about my code base lately if you are interested. I won't reiterate it here. But it's about a million lines of code all the way from build tools to virtual kernel to standard libraries and lots of general purpose stuff up through a very large and complex home automation system. &amp;#x200B;
It should be if you're trying to avoid calling it completely.
There are many types of programming. At the extremes are quick and loose and at the other end slower and vastly tighter and safer. Where you want to be on that spectrum relates to what the needs are of the thing you are trying to create. For a lot of things, speed kills and it's now how fast you get it done it's how right it is when you get it done. C++ is a sort of 'compromise language', and I mean that in a good way. It straddles a large swath of the middle of that range. You can do pretty darn high level stuff with strong type safety, and get down to the raw bits, all in the same code base. For some types of projects, that's a very powerful combination. It's not for hacking out a web site. And, you might not do the core of a nuclear power plant control system in it maybe. But for a raft of stuff in between it can be quite applicable. &amp;#x200B;
I'd want to create some sfml utilities to make networking easier since I'll end up writing my own on the way to build a project of mine with networking. I take it that you would want something QUIC based in the module. Anything else the network module could really benefit from?
I think that's utterly wrong. A debugger is a tool that you need to learn to use as effectively as any other of the tools involved, including the language and such. It's not something that you just start up and randomly step through masses of code to try to find something. And I also disagree with the 'just write good code' thing. I don't care how strongly typed a language is, that doesn't stop you from having one off errors or double deletes or a hundred other possible screw-ups that humans are susceptible to and that have nothing at all to do with type safety. Everything isn't a type. In the end, you should use all the tools you have. Tests, assertions, heap checkers, type safety, the debugger, scented candles, bundles of garlic, whatever works. And I also agree with some other folks that just randomly picking some piece of your code once in a while and just step through it. You might not have a clue at the implicit conversions and unneeded copies being made of things, dead code, and other things that might be there and never actually cause an outright problem, but that are things you'd want to get rid of. &amp;#x200B; Of course, my situation is somewhat different in that all of the code is my own code, so I''m never stepping into some mass of incomprehensible code that I don't understand. That makes a raft of difference when you are debugging. &amp;#x200B;
This and the Unconditionally implementing article are great! I hope P1186 does well. Which paper is proposing the ThreeWayComparable concept?
Yeah, I took a look at their cmake files and was confused that common folder names like "lib" and "libs" weren't in their prefix list.
If you're using the newer version you can ignore FindSFML in favor of simply using the "find" command.
The real answer here.
A container with a ForEach(UnaryFunction f) function seems weird over a container that has begin() and end() functions. This way the container can be used just like standard library containers. std::for\_each(InputIt first, InputIt last, UnaryFunction f) would then do what you want.
Exactly this. I spent way too long early in my career relying on printf debugging. Now when I write new code, I *start* by stepping through each new line of code in the debugger, inspecting values for sanity, whenever possible. It catches a huge amount of subtle bugs. People that don't like debuggers usually have just not taken the time to learn to use one well.
Hunter.sh: is developing nicely in making package eadier to integrate.
After Clinton, Bush, Obama and Trump, ethical standards have taken a hit. The only way safe way to provide software in this diminished environment is as an on-line service.
The only reason your mistake is possible in the first place is because you're avoiding `auto`. Stop being redundant and you eliminate an entire class of errors.
It is one of the common things people write when iterating on std function. std function is a one-signature arbitrary type owning copy and move supported function object type eraser. You can eliminate copy or ownership to a useful type. You can restrict the owned type to be bounded in size, be trivial to copy, or to be function pointers/member pointers which match exactly. You can boost the signature count to support overloading, but still habe one object instance. Function view here is an overload supporting non-owning version of std function. I find it quite useful for callbacks. The basic design is a bunch of `R(*)(void*, Args&amp;&amp;...)` owning CRTP bases with `R operator()(Args...)const` implementations that get their `void*` state from a common store. The most derived type takes a SFINAE tested `F&amp;&amp;`, stores a pointer to it in a `void*` and a set of `[](void* ptr,Args&amp;&amp;...args)-&gt;R` lambdas that cast `ptr` back to `auto pf=static_cast&lt;std::decay_t&lt;F&gt;*&gt;(ptr)` then `return ((F&amp;)*pf)(std::forward&lt;Args&gt;(args)...);` (or even `std::invoke`). Throw in `using bases::operator()...;` to get overload resolution and sacrifice a goat and done. --- `function_view&lt; void(A), void(B) &gt;` is heavily related to `std::variant&lt;A,B&gt;`. Visiting the variant is analogous to passing a callable to the function view. 
Testing is great to have, but programmers shouldn't be convinced to eschew tools that can help them. The fact that a debugger *is* a major dev tool used by millions of real programmers (yes, even with modern C++) won't be changed by statements like these. This is bad advice.
I think being able to execute large programs in your head is a valuable skill. You know what can help a person learn how to execute code in their head? Running a program with complex state and observing it execute. Debuggers happen to be great at this.
It's not about 'style', it's about the responsibilities of each function. You have to ask yourself when you're designing this logic, is it drawInfo()'s responsibility to check infoEnabled or not? Are there circumstances when the caller needs to know whether drawInfo() will be called? Are there circumstances when the caller *doesn't* need to know? Are there circumstances when drawInfo() might have to do its thing even when infoEnabled is false? The second pattern involves writing less code if drawInfo() is called in more than one place. It also leaves fewer pitfalls for someone else (or even yourself in the future) writing code that calls drawInfo(), *assuming* you are confident that drawInfo() should never, ever do its thing if infoEnabled is false. For these reasons, *if I knew nothing else about this program,* I would default to the second pattern. But there are cases when you might not want to do this. Also, ideally, if you use the second pattern, you should change the name of drawInfo(). Right now the name suggests that *it will do the thing,* without any conditions attached. Instead, call it something like 'checkDrawInfo()'. That leaves it more obvious that there's condition checking going on inside that function. In fact, you could even make checkDrawInfo() a separate function with nothing in it other than the condition check and the (conditional) call to drawInfo(). This is a little verbose, but might be appropriate under some circumstances (in particular, if drawInfo() is sometimes called without checking the condition, and there are many different places where drawInfo() will be called).
I don't have project ideas for you, but I'm looking for someone to work with. If we use [my software](https://github.com/Ebenezer-group/onwards) as part of your project, I'll spend 16 hours/week on the project for six months. If you come across something that's interesting, but big, you might be more inclined to tackle it with a partner.
Linus may say that because debugging the Linux kernel (on x86 at least) is a PITA. My little experience with it resulted in hanging when trying to resume from a breakpoint in irq disabled code.
It works using __PRETTY_FUNCTION__, so yes two identically named types will compare equal. What typeindex can't do, and RTTI can, is compare for near equivalence. It can only do exact equivalence.
I already have cursors (basically the same as STL iterators) and of course can do direct index based iteration for those that are index based. 90% of the time, I'm using indexed type collections and will just do a for loop with the index. It's simple and it's obvious what happening when reading the code, and I can easily look at the current value in the debugger. Though, one advantage is that my collections support thread safety. The ForEach can lock and do the loop/callback sequence all in one step. I don't need to do a separate lock around the loop. So that is a fairly useful benefit. Anyway, I'm just playing around with this stuff to see what I like and that was one I decided to try. I may keep it, I may toss it, depending on how useful it ends up being.
Sadly that's true. I was whining about this move to services below, but I should have brought up that one of the legitimate things driving it is a complete failure of morality on the part of a huge percentage of consumers. &amp;#x200B;
Would you consider dropping the C++17 requirement in favor of C++14? I got it to work with gcc 6.3 by taking out the template argument deduction and adding back the move constructors. C++17 does not appear to be essential to the function of your class header and gcc 6.3 and Visual Studio 2015 are still common build environments.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ab3nlo/some_projects_ideas/ecxefmo/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; It would be great to hear from someone who also found the language slow to code in at first but eventually go to a point where it felt much better. C++ caters to different experience levels pretty well. If you're an excellent coder in C and are familiar with a few other C-based languages, it'll probably take you 6-12 months to be comfortable with all the most important parts of C++ and be able to fluidly write decent code. If you want to be writing standards-quality or Boost-quality libraries, that's a different story -- C++ is a) huge and b) incredibly flexible. There are a lot of things to learn, and then hundreds of little techniques that don't really apply to any other language. I'd say 5-10 years is a reasonable timeline for language-lawyer "mastery" of it depending on how active/passive you are about learning it.
Well, then write a `std::function` of your own. It opens up a whole pile of options. In fact, write up to 8 of them. A `function_view&lt;Sigs...&gt;`, and then owning with copy enabled or not, move enabled or not, times ("supports dynamic storage" or "only fixed size storage"). Finally, a function that only stores fixed size trivially copyable storage, which makes itself trivially copyable. All 10 of those have various niches. You don't have to write all 10 to start. The type erased callback "deliver during function call" pattern is best handled by a `function_view&lt;Sig&gt;`; supporting `Sig...` means you can have a polymorphic callback, which is surprisingly useful. Owning function objects are great, as it lets you install callbacks for *later*. Some types don't support copy or even move, so supporting not having one or the other has utility. Function objects with limited trivially copyable storage have a few uses. I'll admit a bit esoteric, and they might not be needed in your code base. --- `std::function` and cousins are *vocabulary types*, like `std::any` and `std::variant` and `std::optional`. Having them in your coding vocabulary makes whole sets of annoying coding problems simply evaporate. 
There's no reason you can't implement `std::function` yourself. However, for the purpose you described, a non-owning `function_view` would be more efficient. This recent thread's comments have links to a lot of the options for type erasure of callables: https://www.reddit.com/r/cpp/comments/a6yg5g/mikael_rosbacke_embedded_friendly_stdfunction/
One thing at a time. This is a very large code base. I've already just done a massive binge to update it all to 'class enum' and I need to cool it for a bit and let things settle. &amp;#x200B;
It shouldn't be the case if that is your code. If it is someone else code the picture is different. 
Yep, big fan of Conan.io. It’s still not quite as mature and as fully featured as something like node, but it’s definitely a step in the right direction. It has saved me many hours of boring setup for various projects.
I'm not sure if this should be solved in SFML, I managed to work around it myself. But since you asked: Complex text layout (specifically right to left languages like Arabic and Hebrew).
Well, academia has been on it for years with no results. CUDA is still the de facto standard for GPGPU. And the situation for HLS for FPGAs is similar.
I have found it difficult to create abstractions in Go due to the lack of generics. It felt like hammering out similar code ten times instead of having good reusable code. Go also has it's fair share of package management issues, but I'll admit it is easier than C++. However, when it comes to debugging and/or low-level performance analysis, I believe C++ is still ahead of Go in terms of tooling.
Thanks, this is very helpful. If you swap out "excellent coder in C" with "proficient coder in higher-level languages like Go and Python", how much bleaker is the prognosis? Hoping that decent productivity is still reasonable within a year...
Some standards like the Google style guide do not allow pass by reference. The reasoning is debatable, but I'm sure a non-null pointer would be preferred in that context.
The complete Twitter thead is more nuanced than that. \*No one\* said we shouldn't use debuggers at all with modern C++. I also don't think it's such a problem, i.e. I disagree with the idea that "modern C++" is debugger unfriendly. Sommerlad says 'That assumption that writing tests costs more than debugging seems unfounded to me.', and I have to somewhat agree. Debugging is also not a substitute to writing careful tests, it's an orthogonal weapon to attack code problems. But re-read what I have actually written. All I have stated is that \*I\* don't use a debugger as often as I maybe should. Instead, I mostly develop my (library) code using repeated evaluation of tests, checking requirements, invariants, etc. plentifully in the code. Debugging mostly comes into play when dealing with third-party code such as external libraries, and fully understanding their behavior. Or to find logic errors in the interplay of components. YMMV, but in my case, "modern" C++ programming (strong types, shifting assertions to compile time, ...) has definitely shifted finding a lot of these problems/errors at runtime to finding them earlier, either at compile time or in the context of unit tests.
&gt; Generally, I think it's important to keep in mind that SFML is trying to achieve. The goal isn't to be a (game) engine or to be highly optimized for every case, but it's to provide a simple API which if required can be tamed to build better optimized abstractions on top. That's the point in SFML I find the weirdest. SFML is used for game developments in 90% of cases but refuses to be a game library. Why? 
Thank you very much, if I were skilled enough I would offer my help, but I am just a game developer student. In general I was just wondering why is there not one group which has only this one job, instead of 2. Moreover is that not sometimes the problem that members of the committee are too far away from actually average implementations?
Well, duh - of course I would run it from a breakpoint. But that still doesn't help much, does it? Either the problem area you are looking at is small, in which case you can just read the source and figure it out from there, or it isn't, in which case stepping through it is going to take unacceptably long. And what, exactly, will you learn from all that silly stepping? The order in which the statements occur should not come as a surprise, one might hope. So what you care about is the values of certain variables, right? But that's a rather massive undertaking: you need to have a mental model for what those values should be (i.e. fully understand your own logic). You need to decide, for (almost) every step, if you are going to step into, step over, or step out of a function. You need to inspect your variables on every step and decide if they are still ok or not. And if they are wrong, you need to then _somehow_ map that to a flaw in your logic - i.e. work backwards from there, and figure out where your reasoning failed in the first place. This is not at all an efficient process, and I'd really rather have logged values of parameters I find interesting. That lets me automate decisions on parameter validity, I don't get the mental overhead of deciding whether to step in/step out/step over, and after the problem occurs I can just scroll back in the log and see the whole trail of values that got me to this point. All in all, I consider stepping to be a gimmick, a toy. Debugging that way is a far harder problem than just looking at the source, since you need to mentally keep track of far more information. People do it either because they are beginners and lack understanding of the language fundamentals (like not knowing when the condition in a for-loop is checked), or because they hit a wall with a problem and are basically pretending to do something useful while waiting for inspiration to strike or a more informed colleague to take over. 
I've been using SFML and have been mentoring students that used SFML for years. It was too limited in certain aspects so I developped my own version of the SFML Graphics API with SDL as a backend. And I added all that I needed/wanted. To answer the inital question: - Joystick is not consistent when using different game pads (the buttons are not always in the same place) - That's already been said but the lack of scancode in Keyboard has been a difficulty for years. - Vectors are too limited, many classical operations on vectors are missing - Views... it's very difficult to use when the screen changes its size. Long ago, I developped external classes that handled everything but it was a nightmare because I could not see the internals of the View class and some corner cases could not be handled nicely. - A RenderWindow should not be a window (like a RenderTexture is not a Texture) but I know this one is difficult - The new VertexBuffer. I think there is something not in line with the rest of the API. Generally, you have one class for the ressources, and one class to display it (e.g. Texture/Sprite, Font/Text, etc). In the case of VertexBuffer, you have both in the same class, I think it is a design error. More generally, this project is not very friendly to simple proposals that could improve the library. Too often, they are rejected and the developpers explain how to *not* use the feature. See for example [here](https://en.sfml-dev.org/forums/index.php?topic=20052.0) where someone asks for a very simple overload for scale that should represents the vast majority of usage of this function (when zooming, you scale with the same factor in x and y). It's one line in the library so not a burden to maintain. And the answer is simply no. Another [example](https://en.sfml-dev.org/forums/index.php?topic=20792.0) where someone asks for a length method on vectors (IMO it should be a free function but anyway), one of the developpers explain that the feature has been rejected multiple times and that's all. The fact that it has been asked multiple times indicates that there is a need for such a function in the library but the answer is still no. 
Agreed. And isn’t that “valid but unspecified” state guaranteed throughout the STL? On the other hand, from my own experience accessing the moved-from object isn’t what causes most use-after-move bugs. It’s the erroneous assumption that the moved-from object still contains the original data, leading to a nullptr dereference in this case. That’s why usually I give the “don’t touch it” advice as a safe rule of thumb.
Again, stepping through something line by line is not the way to debug something efficiently. If you're doing that you aren't using your tools correctly. In order to see the value of important state you set up a watch, you don't need to keep drilling into things manually. You can do something like a binary search of breakpoints to see the value and where it goes "wrong", and figure it out from there. This is like logging out state but marginally quicker in that you don't have to write log lines, choose what to log, leave the IDE and grep logs. I still do that sometimes when I have a mutli-threaded issue and that is a good way to get to the bottom of those. I guess my point is that "use the best tools available to you" is a good stance, don't dismiss or belittle something when it is actually a powerful tool in certain circumstances just because it's not clever. 
Depends on your definition of "game library". From my point of view SFML is a "game library", but we don't want to be a game engine or provide features which a game engine usually provides. If you want everything that is required to build a game, then start with popular game engines such as Godot, Unreal or Unity. The reason we don't want to move in that direction is, because it's a very complex topic, everything has many different ways to implement something and engines are usually built around the specific needs of a game. As a rule of thumb, if you can build it on your own on top of SFML, then it probably doesn't fit into SFML's scope.
There's dozens of us! Dozens! 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ab5j82/opengl_win32_not_working/ecxptcb/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Ah, I miss read `CMAKE_PREFIX_PATH` as `CMAKE_INSTALL_PREFIX`. :D I'm not familiar enough with that portion of CMake to tell, whether there's something we need to adjust to support `CMAKE_PREFIX_PATH`. IMHO it might be less painful to try and follow the recommended usage of the library instead of trying to "force" integrate it into your build setup and then having to manually touch up some stuff. But if you figure out what needs to be changed (e.g. in the config file) to work with `CMAKE_PREFIX_PATH` let us know or create a PR, we're happy to improve our CMake scripts wherever we can.
Yes, valid-but-unspecified is the default guarantee for moved-from STL objects; certain classes strengthen it.
Do you know what we can do to improve the CMake files?
Core Language and Standard Library wording is way too different to be handled by the same groups. Yeah, we sometimes lack relevant real-world experience, especially in specific domains.
Fair enough. In regards to the lack ... Is there a plan to tackle this? For example take out the problem to the community? 
I'll say again: the redundancy enables checks. Writing out the expected type has a similar benefit to writing assertions. It also makes the code more readable. The type tells both compiler and human reader more about the intentions of the author.
Yea definitely, tools need to improve. But it shouldn't be generalized to debuggers being bad/waste of time/the wrong tool. Because there is one awesome one, in Visual Studio, and that one is amazing. Just means the rest need to catch up.
Yes I guess cdb is eventually a Microsoft tool and it really sucks a bit, nowhere near as good as the VS debugger. I haven't played around with different Win 10 SDKs, it was hard enough to find a download for the latest one that contains cdb. Anyway, it's Qt/QtCreator providing the overall experience, so I'd say they should probably share the blame. Of course Microsoft has probably not much to gain from improving cdb.
Regarding printing, printf is usually the method used in C rather than C++. In C++ one can either use the standard method of std::cout, or using a library such as {fmt}.
I explicitly checked with the GCC developers for this; please see [this reply](https://gitlab.kitware.com/cmake/cmake/issues/17834#note_390300).
I actually somewhat agree. The debugger is a tool for researching bugs, after they've occurred. It's irreplaceable, yes, and I'm not saying using it is bad. BUT, I know plenty of programmers who use it as a tool for testing, forsaking actual automated tests. The current debuggers are fine enough for their purpose.. But easier, better testing should be the priority. 
Have you ever worked with codebase that is testable that you straight away disagree with that claims? In todays internet I guess it is ok to have a strong opinion without a merrit, but consider this for a while: you have tests that cover 80% of your production code and you get a bug report. For those who worked a lot with tested code (i.e. compiler writers, system programmers, etc.) it is FASTER to put down a test and run it to prove there is a bug, than to sit for 2 hours starting and stopping debugger just to figure out what is wrong. It takes at most minutes to prove a bug and fix it with a test. I would never go back to wasting hours debugging production code. It’s so much faster to just put down some test and fix the bug PROVING it is fixed than to find something in the debugger, fix sonething else and believe it’s done.
&gt; so the question is whether the extra expressiveness outweighs a slower development cycle. You would want to use C++ for performance and control over memory (cache,locks,etc). Otherwise go, java, python, R, Matlab, whatever fits you better. 
I don't know for academia, but people at Codeplay seems to progress fairly well on the subject of heterogeneous compilation (not sure if fpga is in their focus though)
&gt; As a rule of thumb, if you can build it on your own on top of SFML, then it probably doesn't fit into SFML's scope. And that's why there are so many (sometimes poorly maintained) extension libraries for things that should directly be in SFML. The rule of thumb should be : if everyone need it and reimplements it every time, it should be in the library. 
It appears that you were misled by my use of "failure"; I apologize, this was not what I intended. Errors are usually much easier to investigate, precisely because they trigger logging, although sometimes understanding how a particular state was reached based on previous interactions to lead to the particular error is... complicated. Many times, however, the software simply fails to act as expected. It does not "error out", just takes a slightly different decision that one would have expected. There are multiple reasons: - the expectation is wrong; it failed to consider an event. - the expectation is wrong; it assumed a configuration, but another was used. - there is a bug in the implementation of some specification, somewhere. That's where debugging start from: I expected X, Y happened instead, why?
&gt; I'm curious about DOD but don't really understand how to use it. The way I see it, the point of it is to analyse the requirements of the problem to come up with the minimum data representation that fulfils it, then go from there. It's a data-first-code-follows kind of approach. For example, regarding your comment on how the double-dispatch method lets you not define stuff due to the hierarchical nature of inheritance, the exact same behaviour can be attained in a data oriented approach if such hierarchical behaviour is part of your problem. It's trivial to define a struct Animal that holds a `AnimalId inherits;` that specifies an optional inheritance. It's equally trivial to see how a barebones implementation of this would follow. At this point you might argue "but then you're just reinventing everything that the C++ inheritance features give you in the language" and that might be right - after all, this whole discussion spurred from an article showcasing exactly those language features so it is natural that this will do the same. In practice though, I have found a data oriented approach to be much more flexible when it comes to changing requirements where something like the double dispatch based on rigid class hierarchies for me have often lead to lengthy refactoring - maybe a requirement will be added/removed such that the double dispatch no longer reaches the finish line. On the other hand, approaches that focus on data representation and let code follow from that tend to be much more flexible since you just need to add/remove parts of the data structure and adjust the code accordingly, not rewrite/redesign class hierarchies and changing/applying OOP patterns accordingly. It is true that there's a difference in how the double dispatch "binds" in compile time while the proposed DOD approach uses runtime data. This is either a drawback (can lead to bugs, or slower performance) or a boon (you can now trivially load the data from a json or database to govern all interactions, which is comparably a lot less trivial for the double dispatch method) depending on what you need. But note also there are various ways of turning the data into compile time constructs in modern c++ if you really want to. For example something like a: ``` constexpr CompileTimeMap data = { //fill interaction map }; ``` ...is totally possible and will let the compiler go much further in terms of optimisation. I have myself used similar techniques to bring data problems into compile time in C++ and it can be a bit clunky but the language is largely moving in the direction where doing such is getting easier and easier (static reflection, allocations in constexpr, non-template type params, std::embed, to name a few). To round off a lengthy comment (sorry for that!) I'll just summarise by saying that my experience in mostly dropping the classical OOP thinking and going data-first has greatly simplified my code both in terms of writing it but also reading and adapting it, and now a lot of OOP to me just looks like unnecessary cruft (biased opinion probably, but that's my perception).
You would use C++ for control and performance. I wish Go had a better integration with C++ _ that would be a killer couple.
There is overhead for calling a function. but optimizer optimize well! In the case you DrawInfo() is not allow to be called when precondition is not met, assert infoEnabled in the function body and check on the caller site.
* What do you mean exactly with "polygons"? Do you mean to provide support for concave shapes? * SVG is a rather specific file format and IMHO doesn't really fit SFML's scope well. However it would be a great extension library, as you don't really need any changes inside SFML itself, but you can build it quite nicely on top. * You should use the INSTALL target when building SFML, then everything will be copied to wherever you set `CMAKE_INSTALL_PREFIX` in the correct way. As of SFML 2.5 you shouldn't use the `FindSFML.cmake` anymore, but instead use the config files, see the [migration thread](https://en.sfml-dev.org/forums/index.php?topic=24070.0).
Great points. I look at it this way: even the term "developer productivity" is I'll defined. A project may have performance or portability requirements that are difficult to achieve in other languages. Most success stories for non-C++ languages are in systems for which the main benefits of C++ are not required -- primarily performance and to a lesser extent portability. I also tend to think that C++ is the wrong choice for most programs. These days, most code should probably be written in an "easier" language that ends up using C++ only where heavy lifting is required (via a language binding, cloud API, etc.). That said, the improvements in C++ over the past 8 years or so have been pretty huge, so the kinds of programs for which C++ is "justifiable" is growing.
Yeah, I think this is pretty consistent with the way modern c++ is going, which to me is very worry-some. Where everything is template within a template in 200kloc of header code you need to include in every unit. Add often crippled debug build performance, you might end up having to debug release builds, in which most of the templates just disappear, so there is nothing to debug. C++ seems to be strongly set on a course of disregard for development productivity and fast iteration, and this is just another nail in coffin. 
&gt; Errors are usually much easier to investigate, precisely because they trigger logging, although sometimes understanding how a particular state was reached based on previous interactions to lead to the particular error is... complicated. you completely missed my point, but the fact that you started your reply by trying to claiming that's my problem means I'm ending the conversation here.
&gt; Bad or not - I'm responsible for it. thatsthepoint.jpg. imagine if everyone on your team would write code to detect the failure and report it explicitly so that future developers didn't spend hours trying to track it down. just imagine regularly finding problems in minutes vs hours and how much more productive you would be. And then realize there's a reason you're having to spend so much time tracking down failures and it's not because of bad code, but bad decisions. 
Lambdas are only an easier way to write a struct with an operator(). In fact, std::for_each is part of C++ 98.
That's just the calling convention making a difference. Passing by-value means the passed structure is already in the registers. If you look at https://godbolt.org/z/6Ee-7D you see the functions are identical except for which registers are used and movsd xmm0, qword ptr [rdi] # xmm0 = mem[0],zero movsd xmm1, qword ptr [rsi] # xmm1 = mem[0],zero Which just moves the data from memory to register. Small structures can be passed entirely inside the registers. If your structure is larger than 16 bytes in gcc/clang or 8 bytes in msvc (e.g. just add a double z to the structure) you will have the same code because internally the compiler converts it to passing a reference to a temporary stack value. So I wouldn't give too much emphasis on that part. (Further search: System V AMD64 ABI or Microsoft x64 calling convention)
I tried making a program that would pick anagrams from a file of 1000 lines, however I have no idea what is the problem here. If anyone would be able to help, I'd be very greatful.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ab78z4/the_anagram/ecxzxeg/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
From what I can see, there's no actual need to do anything with test.txt at all. You are checking to see if the two strings you pass to this function are anagrams - you never look at 'line' at all. I'd expect to see a sort(line.begin(), line.end()) - I think you may have got two parts of the program on top of each other here. Split this into two parts - one that just takes a and b, and checks if they are anagrams (that's the sort bit), and another that opens test.txt and iterates through the file checking your test word against the lines from your file (by calling the anagram function) Your error here is not sticking to the rule that a function should do one thing, and do it well :)
&gt; I (sic) it would make sense to me to add both GCC and Clang builds into Mozilla nightly testing. That's a difficult balance. On the one hand, it seems pretty clear from the amount of issues raised uncovered in both Firefox and GCC that there is definitely value for both projects; on the other hand, it's always annoying when hitting a bug in a one compiler and not another to have to find a work-around... so it's unclear if for the Firefox project the costs overcome the benefits. There's also a small tidbit alluded to in [the linked blog post](https://blog.mozilla.org/nfroyd/2018/05/29/when-implementation-monoculture-right-thing/): using LLVM allows cross-language LTO between C++ and Rust. The idea is simple, really, though the execution may require some effort: using Clang and rustc, one can convert both C++ and Rust code to LLVM IR, then use the LLVM toolchain to LTO all LLVM IR regardless of its source. This is quite powerful, since it enables inlining of C++ code inside Rust, and of Rust code inside C++, removing an otherwise "hard" optimization barrier. I don't think that maintaining compatibility with GCC would prevent setting up cross-language LTO; however it would certainly give a performance edge to the Clang setup, making hard for the GCC setup to keep up. This could possibly be alleviated if efforts to compile Rust to C (such as mrustc) were renewed; as GCC could then perform LTO across the C++ and C-from-Rust code.
Okay, thanks. I'll try to do it and succeed 
I Hope it will be voted in as Kona as lewg is okay with that design
This blog post was a great read, thanks a lot Honza Hubička, and what a great effort you're putting into making gcc better for us all. Thank you! I am sad to see Mozilla "give in" to compiler monoculture and clang-specific extensions. Also a lot of the arguments given by people, like "MSVC is the odd one out" (always requiring workarounds, lacking behind, etc.), are no longer correct, they haven't been since 2017 or at least 2018. MSVC is a fantastic and standards-leading compiler, as much as clang and gcc are. Sure we do see regressions in the MSVC compiler, sometimes it does still require workarounds, but so do clang and gcc. One particular thing gets mentioned way too little in my opinion: By building &amp; testing on different compilers, you catch so many more bugs, both at compile-time and runtime. All 3 compilers have different warnings, and one compiler nearly always catches things that another doesn't. Only this is already worth it to build &amp; test automatically with all three major compilers (MSVC, gcc, clang).
&gt;i find Node / Javascript code to be far more difficult to debug, because of async everywhere. So much this. My team has taken on a lot of Node code and we're basically learning it. Unit tests are... interesting.
I struggle to avoid reading `iota` as `itoa`; and thus getting confused. "Why do we want a string here?"
Unpopular opinion - intrusive pointers make both smart pointers and move semantics useless
Yeah, it's a real time saver to write modern C++ just so you can go back to debug by cout or setting up tests everywhere. I've just assumed my compiler &amp; ide-combo was bad so haven't thought twice about it, but it is worrying if this remains true.
&gt; Also a lot of the arguments given by people, like "MSVC is the odd one out" (always requiring workarounds, lacking behind, etc.), are no longer correct, they haven't been since 2017 or at least 2018. MSVC is a fantastic and standards-leading compiler, as much as clang and gcc are. I'm sorry but this is completely false. I've been tracking modern standards aggressively in my main codebase since 2014. I've reported 1 or 2 bugs to GCC and Clang - and for GCC it wasn't even GCC itself but related components (demangler and gdb). I have multiple pages of open issues on MSVC's tracker, a bunch of which are still open. The damn thing broke my code sometimes at ever **minor** update. It may be leading in programmer perception, but it is absolutely not leading in practice, especially when comparing to GCC 8 and clang 7.
Is there a "getOpenglFunctionPointer" function in SFML? SDL2/GFLW do have such a functions and it takes away all the pain of having to deal with platform specific stuff for my OpenGL library.
What is that pointer supposed to do?
Profile it and find out. I'd be incredibly surprised if those optimizations make using that ancient compiler worth it 
It would likely be far easier and more effective to use something like halide, ispc or a vectorization library. 
&gt;ancient compiler worth it You would be surprised how much of spanking New releases going out to the market are running firmware built with GCC 4.x. Should I mention also your entire banking and credit card server side infrastructure? Dont be that dismissive because there is an entire corporate environment universe you dont seem to know about.
In OpenGL you have to query all the function pointers that go beyond basic OpenGL (I think version 1.2) Something like: void* getFunctionPointer(char* name) But this function getter function is different on each OS. Already found it in SFML: https://www.sfml-dev.org/documentation/2.5.0/classsf_1_1Context.php
Those are optional components accepted by GCC Configure script, not that I have a choice there.
&gt; Imagine a `helper_function(unique_ptr&lt;MyType&gt;&amp; up)` that does some complicated stuff that ends with a call to up.reset(). This is still unique ownership. Agree with the OP, this is a bad idea as it obscures the intent at the call site. If it calls `reset()`, then it actually overtakes ownership and the `unique_ptr` should be declared by value and moved-from to make it obvious at the call site. Otherwise, the call site has no idea what happened in `helper_function`. Maybe it called `reset()` [1], maybe it replaced the value with another object [2], maybe nothing [3]. [1] In this case the signature should be `void f(std::unique_ptr&lt;T&gt;)` [2] Here, use `std::unique_ptr&lt;T&gt; f(std::unique_ptr&lt;T&gt;)` [3] Just use `f(T&amp;)` or `f(T*)` if the pointer is expected to be nullable. 
Unfortunately most code bases are not standard compliant. 
I wasn't being rude. I'm not familiar with graphite optimizations and have no idea how they perform on your machine. I can reason about performance with Big O and instruction count and cache coherence and all that stuff, but the absolute best way to know how well code performs is to run it and measure it's runtime. I also have no idea what your code looks like - maybe your code can benefit a lot from graphite optimizations, maybe not, bit without seeing it I have no idea I'm sure I would be surprised at how much shipping software is built with gcc 4, but that doesn't make it not ancient. Iirc gcc 4.9 was the first version with full c++11 support? With that version that you're missing out on structured bindings, constexpr if, and a bunch of standard library stuff that may or may not fit your use case - but it's awesome if it does (again, I know nothing about your code or what you're doing, so I have no idea how much benefit you'd get) You said you've gone through a lot of effort to use gcc 4. That tells me it's a lot of work for your to use that version and things would be easier for you if you use a newer version. If you need gcc 4 for graphite optimizations than they're probably not in newer versions. That implies that they've been replaced with something better - there's no good reason for the gcc developers to remove awesome optimizations. Therefore, I expect that using gcc 4 for the sole purpose of graphics optimizations is not worth it, both because you're missing out on some nice language features and because newer versions probably have better optimizations
gdb has a lot of features, and is complex as you said. The tool does not lend itself to be easily picked up and used. MSVC OTOH, does. I agree that calling it unpolished is unfair.
&gt;Only this is already worth it to build &amp; test automatically with all three major compilers (MSVC, gcc, clang). My generated code runs on Windows, but most of my software that generates the code doesn't run on Windows. I find it liberating to not have to support Windows in most of my software. [This program](https://github.com/Ebenezer-group/onwards/blob/master/src/cmw/tiers/genz.cc) has a call to winStart() that wraps a call to WSAStartup(). It's only one line, but the program is only 35 lines so it still sticks out as a portability wart. &amp;#x200B;
There is at-least one potential problem with using a debugger only when problems occur. In order to recognize and get a feel for when things go wrong, you need to know and recognize when things aren't wrong! When you include single stepping as part of normal development (especially on a codebase with multiple authors) you get a deeper sense of how things 'look' and 'feel' when its all working together. At some point you have to pick and choose which parts you treat as a black-box, and which you think have potential for further investigation.
I disagree, the tool maturity is pretty much there. In comparison with something like node, what's missing is available packages. Today, with conan you'll have to conan-ize many of your dependencies yourself. That's changing though. https://bintray.com/bincrafters Bincrafters have packaged boost and some other common C++ dependencies. Big help.
What I mentioned are not components of gcc, they are other wyas of getting SIMD vectorization and are more explicit without guessing at what the compiler will do.
&gt;you don't have lambdas, range-based for, move semantics, auto, structured bindings, constexpr if, or a ton of standard library additions Nothing in there add a single notch to my bottom line. No speed gain, no clarity, no gain in complexity hiding. Auto is actually forbidden in many commercial systems I know - the few that support C++11. Youd be surprised how little adoption C++11 has had so far. Many firms just stopped at it and are just mandating -std=c++11 while gladly taking the new compilers. &gt;If you need gcc 3 for graphite optimizations No. When writing mission critical software - where money or lives would be lost in case of a bug - one release can take a couple of months to be past recertification and go into production. There are libraries in use out there that have been processing billions in credit card transactions every day for over five years and nobody in their sane mind is going to upgrade the machines/OS and risk a mishap. They have to be rebuilt in the exact compiler version. Also many 3rd party libs are provided in compiler specific versions that not always match the default OS release. Eg RHEL 7.5 comes with native gcc 4.7.4 but I have tobuild 4.7.1, 6.1.0 and 6.2.0 to adapt to 3rd parties. It is really rare tge occasion where I have a build where I have complete discretion on compiler versions
Like I said, you mentioned that you had been through great pains to get gcc 3 running, so I thought using a newer compiler would be easier. I didn't know that you work in an environment where you have to use gcc 3 - that context was missing from your initial post 
... why do you use an old version of GCC ? Graphite is still here in the latest versions (and you only have to build with cloog, isl, ppl which ~~are a real pain to get right~~ only requires putting them in the right folder when building GCC). `-floop-parallelize-all` works fine in GCC 8 here.
War story: I got in the habbit of using `{{` even with other containers without really thinking about it. One day I wrote the equivalent of: `std::unordered_set&lt;std::string&gt; noise{{"meow", "bark"}};` Dispite it's looks, that does _not_ initialize the collection with two strings. Instead it calls the `basic_string( InputIt first, InputIt last, const Allocator&amp; alloc = Allocator() );` string constructor and initializes it with a single string (assuming it doesn't crash first)
You can write a test to try to reproduce the bug, and to act as a regression test moving forward. But just writing the test isn't remotely always going to FIX or even FIND the bug. Some bugs are horrendously subtle, particularly in a highly multi-threaded environment. And, in very configurable and flexible systems (such as mine), you may not even be able to reproduce the offending customer system. This generally requires that you dig in with the debugger and any other spelunking tools you've got built into your code base. It's just never as black and white as people seem to want it to be.
3rd party libs are provided at specific release versions I did not know they can be built together with gcc. Care to give a link? I had to build them in separate stages which required bootstrapping since ppl linked against the original stdlibc++
well you still have to build cloog/isl/ppl with gcc 8.2
https://gcc.gnu.org/install/prerequisites.html &gt; If an isl source distribution is found in a subdirectory of your GCC sources named isl, it will be built together with GCC. here's how I do it : https://github.com/OSSIA/score/blob/master/tools/sdk/Linux/gcc-deps.sh
Is that version out yet? If not, then yeah they're still developing it and they haven't finished setting up all the packages 
You only need one vector per compile target, so you can maybe configure it through compile time option. `-Duser_types_header=...h`.
MSVC is closed source so we can't fix any compiler bugs that we run into. It also means it's much more difficult to come up with workarounds for those bugs. MSVC bugs have been a noticeable source of pain over the years so we will not miss supporting it. The hassle of supporting MSVC is much higher than supporting GCC. I sympathize with arguments about compiler monoculture and I suspect Firefox will remain buildable with GCC, in part due to community contributions. I expect the list of people willing to do the work to keep it buildable on MSVC will keep getting smaller and smaller.
As I noted at the beginning - you have to have good coverage already. Then I can't imagine how I could find a bug in multi-threaded code using step-by-step debugging. I'd have to manually advance threads at given pace, then redo it over and over again after each mistaken step. Sounds like a huge waste of time to me. I never found a multi-threading bug using debugger that way - what always worked for me is surfacing a problem using test. Anyway I digress. I just wanted to note that OP probably never worked with tested code base therefore can't imagine how that world could look like. I did both - hours of debugging sessions just to find even the simplest mistakes. Now, following advice from much senior software engineers, I'm pushing to prove using tests that my code works, just like using scientific method in other engineering and science related fields. Then when a bug is found I prove that code is buggy and I fix it, proving I did it not just to me with a debugger, but to whole team with a test. And yes: it is not black and white. It's hard to test code that is not designed to be tested. And while I'm at it: what would you like your programmers to do with your money (if you'd be the one hiring them): write code (tests and production code) or write some code and then spend hours debugging that code? ;-)
&gt; MSVC is closed source so we can't fix any compiler bugs that we run into. It also means it's much more difficult to come up with workarounds for those bugs. This is certainly true, can't deny any of that. :-) But your post and opinions are very much focused on the past. It has changed. MSVC has changed. Sure, it's not perfect. No compiler will probably ever be and have no issues or no regressions. But MSVC has changed a lot. And a new minor release gets released now every few months, and Preview releases coming out more often (with things fixed earlier). Microsoft has changed too and is much more responsive with bug reports and much faster. It's still *the* major compiler on Windows, its code gen is really good, and the VS debugger is the best of its kind. If I was a Firefox contributor or considering to become, I wouldn't even consider touching the code unless it's working in VS and within the VS debugger. Unless it would be my paid day job, I'm not wasting my time with any other sub-par debugger (or no debugger at all).
This frankly looks like C code or really old, ugly C++, that should be completely overhauled. I've also never heard of winStart() or WSAStartup(). `main(...)` does the job for me, on all platforms.
&gt; when comparing to GCC 8 and clang 7 Since you're comparing the latest versions here, are you comparing these to the latest MSVC, 14.16, too? I agree 14.10 or 14.11 haven't really been up-to-par yet (I think these are from 2017 though) but since the last couple of releases, it's pretty great.
This x1000. I'd rather debug a function throwing when it shouldn't then try to find a function that doesn't error somehow when it should. Any* function should do what it was asked to do or fail in a way that the caller can tell. \*this rule can be broken at the edge of programs (e.g. in `main`) or very specific cases. If you aren't sure if you can break this rule, then you can't.
There’s nothing rude about the exchange except for your defensive childish response. The best way to know about the effects of optimization are to run it on your specific code and measure it. This is especially true for mission critical software. 
"Something old, something new, something borrowed, something blue…" If you have ideas on things to improve I'm happy to hear them. 
Would you rather have a function called `maybeDraw` that might draw and might silently fail? That's a huge pain to work with 99% of the time. Silent failures cause grief more often then not. If not for the original code author, then for the next person to use or maintain that code.
Graphite hasn't been maintained and most of the (all?) developers moved to Polly in the LLVM/Clang toolchain. All in all, this is an interesting idea, and it has some good success stories, but in practice it lacks a serious cost model for the target architecture. Meaning, it usually lose some percent on most applications, but can get big speedup on some.
I don't think anyone just randomly brings up a debugger and starts tracing from the start of the program to find a bug. That's a straw man argument. You obviously have some reasonable idea where the bug is before you start debugging. You use the debugger to prove or disprove those theories. You can't just change some code and re-run the test until the error stops happening. That could be pure luck. You use the the debugger to prove that what was failing is now working, not just newly failing to fail. Or you use it to find out that your initial theory on where the bug is was wrong, and you start generating new theories. And of course you get good at figuring out how to set appropriate conditional break points. That's often the best debugger tool of all. You aren't just tracing randomly, you are using the debugger to effectively dynamically place 'asserts' in the code on the fly.
I just built it
thank you very insightful response
Imagine you asking for directions at a foreign country and someone answers 'go look in your phone'
Imagine you asking for directions at a foreign country and someone answers 'go look in your phone'
I find it ironic that you are so strongly opposed to OOP, but your solution is (as you point out) essentially implementing the OOP features you want manually. Thank you for the explanation. Next time I look into DOD I'll try to keep the "data-first-code-follows" idea in mind and see if it makes the approach any clearer.
I've filed 2 bugs to MSVC in the past month - one instance of refusing to compile valid code and one _very_ simple optimization miss. MSVC always generates worse code in my projects (VS15 and VS 17), and it takes nearly twice as long to compile. I became so fed up with how much it lagged behind GCC and Clang that I've just flat out switched to Clang 7 on Windows using the LLVM Visual Studio plugin for all of my projects at work. It literally just took installing LLVM, that VS plugin, and `-T LLVM` to my cmake project generator for it to work.
Go for c++17. The advantages are (imho) substantial and by the time sfml 3 gets traction (not to mention during the time till you want to break backwards compatibility again) c++17 should be very widely supported.
This is actually the first time I've seen code use the function `try - catch` block. I'm not criticizing your code - just excited to finally see it used!
A year or two ago, I dumped Hunter because it handled cross compilation so badly. This is especially the case when the upstream dependency does not utilize CMake as a build system. Such as Boost. You end up going down the rabbit trail of custom builders for Hunter and stuff, which just got really nasty. At the end of the day, when you're truly cross platform: Android NDK, Linux, Windows: Nothing beats building binaries for each platform and keeping them in a submodule. Sounds terrible, because it is, but it's a lot better than finagling with Hunter.
**Sol 2** - Lua bindings: https://github.com/ThePhD/sol2 **effolkronium/random** - Convenience wrapper for std &lt;random&gt;: https://github.com/effolkronium/random **cereal** - Serialization: https://uscilab.github.io/cereal/ I'm a fan of the above because not only do they do their respective jobs well, but they all have (imo) beautifully elegant apis. 
So, incredibly obvious example... I've been doing a major reworking of a large code base to update it to 'enum class', and various related changes that involved. I'm starting to test those changes now and had a test falling over for some non-obvious reason. Brought up the debugger, told it to stop on exceptions thrown, and within 30 seconds I had it fixed. Obviously I didn't just start randomly tracing through the code. I knew it had to be throwing an exception and modern debuggers easily handling stopping on any or specific exceptions. An awful lot of problems are easily diagnosed this way. Though, it sort of requires that you are strict about exceptions really being about exceptions and not using them for stack unwinding or signaling type stuff. &amp;#x200B;
This is some great sleuthing! The part about sections in the PE file reminded me of this [post on Raymond Chen's blog](https://blogs.msdn.microsoft.com/oldnewthing/20181107-00/?p=100155), which sheds some more light on how all that works. 
Thanks. I knew about function try blocks, but forgot about them until recently. I found several other places in my code where I could use them.
Links to some (not all) of the related posts I've made in the past: https://www.reddit.com/r/cpp/comments/75fpye/why_is_the_committee_not_in_charge_of_a_build/do6ggoe/?context=3 https://www.reddit.com/r/cpp/comments/7pwxpf/dragging_c_into_the_modern_era_guy_davidson/dsq65ik/?context=3 https://www.reddit.com/r/cpp/comments/81rwwc/accio_dependency_manager/dv4xr12/?context=3 https://www.reddit.com/r/cpp/comments/85nbhp/oh_lockfree_circular_buffers_yay_hey_no_2d/dw2n8e2/?context=3 https://www.reddit.com/r/cpp/comments/8emja5/vcpkg_library_manager_now_also_on_linux_and_macos/dxy8hip/?context=3 https://www.reddit.com/r/cpp/comments/900dor/stdweb_view_proposal/e2ooqxi/?context=3
Right. Some rolling release distributions update faster than others. Gentoo hasn't updated to newer compilers yet, but apparently Arch has.
ranges-v3 and fmtlib. Actually, starting this year I will just assume "standard library" to imply these. Now if anyone could write a bearable parser library please...
Skimming those posts I see arguments why it can't be done, not that we shouldn't try. That's not the same I personally don't think it's possible, but I'm not against people trying
Can't hate a library that builds without hassles and provides elegant APIs.
I just started using MSVC again, after years of gcc and clang. I have been reporting bugs in the compiler and standard library for about a week now.
My position in all of my postings about this subject have been 1) the c++ standard should not involve itself with things external to the language to begin with. 2) the c++ standard would do a worse job than existing tools, with a variety of feature comparisons 3) that a standardized package manager would cause ongoing harm to existing r&amp;d departments if such a thing was standardized.
I call that style error oblivious. You try your best. If anything goes wrong, you might *log* it, but failure wasn't really an option, so you keep on trucking. For example, imagine some code that centers text. If it fails, well, you where asked to center text. Reporting back "no I didn't" doesn't really help much often, because what is your caller going to do? Throwing or shutting down is worse, as you upgraded a "text did not center" bug to "application crashed" or "text did not display" or similar. Logging "text failed to center" could help someone tracking the issue down later. Hut otherwise, do something reasonable, try your best, and keep going on. (Why did the text fail to center? Maybe the things centered against move with your text, or there isn't enough room, or the text is also anchored to something else, or your unicode engine that handled shaping errors out when you run it on the text for some unknown to you reason, or a myriad of other things.) It isn't always a good plan, but when failure doesn't give an alternative plan, it sometimes isn't bad. 
RapidJSON is great if you like punching yourself in the face or burning your hand on the stove. nlohmann's only gets better and better with every release. My simple theory is that if you need the speed that RapidJSON will provide then JSON is the wrong solution to your problem. 
Eh if it's in a library it's not that helpful IMHO. But I do server side C++ and so I'm approaching it from that point of view. Maybe it's more helpful in client side code. I'm a believer that code should (almost) always tell the caller if it didn't do what it was supposed to do. If the caller wants to ignore it, that's fine. But when writing a library I don't think the author can know who will call them. 
&gt; Now if anyone could write a bearable parser library please... Yes please LOL
fmtlib &amp; pybind11. Such simple yet such powerful libraries.
I agree that standardizing the way the metadata/config information for a standard build system or package manager would look is more important than standardizing the specifics thereof. Personally I think its I'll advised for the c++ standard to involve itself in this subject in any way, and I certainly don't want to see an implementation foisted on me.
I think I agree with everything you wrote here. The virtual function semantics stuff didn't even occur to me until you wrote about them.
Thanks for reminding me cereal, it looks to be a fantastic library!
I think some other language(s) support that and I ran across the concept while messing around in one of them. But I may be hallucinating. It would be an incredibly powerful thing. Otherwise, you have to do the much more wordy thing of having a public non-virtual, and a protected virtual. Being able to force derived classes to pre-/post-call or have to call, you could just do it directly and have the compiler enforce it. I realize that might get messy for the compiler and maybe it would require some crazy overhead or time penalty or something. But, if it's not crazy hard or piggy, it would be such a nice thing to have.
I can live without a debugger, I can live better with a debugger. I found I have less need for a debugger nowadays than I started using C++ many years ago. With unit test, careful design, RAII, and temporary `printf/std::cout`, etc etc, there is fewer chances needed for a debugger. But when there is some serious bugs such as memory corruption, a debugger comes to play nice.
A constexpr variable template with the value seems straightforward: template&lt;typename T, typename = std::enable_if_t&lt;std::is_enum_v&lt;T&gt;&gt;&gt; constexpr T MaxElemOf = T::Count; template&lt;&gt; constexpr C MaxElemOf&lt;C, void&gt; = C::Max; Demo: https://godbolt.org/z/8iyX0U
In recent memory, CTRE - https://github.com/hanickadot/compile-time-regular-expressions I'm also a fan of the ranges-v3 / ranges TS.
I tested my [serialization library](https://github.com/Ebenezer-group/onwards) against [Cereal and some others](https://www.linkedin.com/pulse/serialization-benchmarks-brian-wood/) a while back. It looks to me like the last update to Cereal was Feb. 2017. I've updated my library many times since then. I recall thinking that one of those updates would be a help to the performance of my library, but I didn't go back and run the test again.
Found these recently myself. `fmtlib` is great. And I migrated one of my libraries from `Boost.Python` to `pybind11`.
https://modm.io Finally truly portable down to the metal C++ code. If you aren't getting single-instruction GPIO toggles ur doin in wrong
Unfortunately sometimes you don't to choose the format when communicating with external services. :(
http://npm.anvaka.com/#/view/2d/copay-dash
So will the return type of file/function name be \`std::string\_view\` or simply \`const char\*\` ?
I read the paper [P1378](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1378r0.html) which proposes `std::string_literal` as type of string literals. It sounds good but... what about `printf` with "%s" specifier? I'm concerned existing code broken may be more than that the paper takes into consideration. 
You changed the answer on me there. I don't use STL, so I'm trying to implement your previous example, which one would think would work, right? I have this so far: template &lt;typename T, typename U&gt; struct bIsSameType { static const bool value = false; }; template &lt;typename T&gt; struct bIsSameType&lt;T,T&gt; { static const bool value = true; }; template&lt;bool bCond, typename T = void&gt; struct EnableIf {}; template&lt;typename T&gt; struct EnableIf&lt;true, T&gt; { typedef T type; }; template &lt;typename T, typename = EnableIf&lt;!bIsSameType&lt;T, tCIDLib::TCard4&gt;::value&gt;&gt; constexpr T MaxElemOf = T::Count; template &lt;&gt; constexpr tCIDLib::TCard4 MaxElemOf&lt;tCIDLib::TCard4, void&gt; = kCIDLib::c4MaxCard; But the compiler doesn't like T::Count. It doesn't think T is a type. The TCard4 branch presumably is working, since I got no complaints until it hits an enum based one. BTW, I'm flipping the logic because it seemed a lot harder to come up with an 'is enum' thingie, than to just check that it's not a TCard4. &amp;#x200B;
Thanks! This post actually sheds some light on that '$' delimiter. Awesome.
I did edit my answer substantially after I initially posted it; sorry about that. But, A) there are things in C++ that are **only** possible via the standard library or compiler intrinsics, and B) the current code doesn't strictly require the standard library if you know what type you want instead of using `std::underlying_type` (or if you want an object of the enum itself's type instead of its underlying value).
There are STL things that aren't possible. But the if the STL can do it, it has to be doable via the language, right? Otherwise, they aren't implemented in terms of the C++ standard, which I would think would be generally unacceptable by everyone. &amp;#x200B;
I think for as long as you've used the language, you have some deep misunderstandings about it. ;-] No aspect of the standard library **must** be implemented in standard C++, and quite a few aspects of the standard library **cannot** be implemented in standard C++. This _is_ acceptable, which is why some parts of the standard library are not optional, even for freestanding implementations. If you can't `#include &lt;type_traits&gt;` and use it then you're not writing C++, period.
There are an increasing number of things in the STL that cannot be implemented through the user-facing Core Language - typically they require compiler builtins/intrinsics/hooks although in principle compilers could directly implement them. `underlying_type` is a good example. `constexpr char_traits` is a more recent example.
It probably isn't that impressive but my favorite C++ code is a program I wrote in college that I'm still proud about. It is a program to blanket test CPU cache configurations simulated on a program called Dinero. You hand it a config file of all the ranges of cache sizes, and whatever the other values are on a CPU cache (I don't remember them since it has been a couple years), for each level. The program then generates every possible valid configuration available from the given ranges, then runs each configuration on Dinero dynamically allocating the proper amount of threads. Once all simulations are done, it takes all that data and processes it based certain criteria. The most valid configurations it has ever generated is something around 14 trillion 700 million and apparently the professor of the class I made it for has actually used it in his research (or at least he told me he had plans to and was excited to use it in his research since I offered to make it open source)?
My favorite is when said external service uses raw Java code to write XML, instead of, say, and XML library and so things that should be escaped when you parse them aren't escaped, and it crashes your ingestion code 70% of the way through a 2 gb XML document.
OK, I can accept that, though it seems not great to me. But, wasn't type traits introduced in C++ 11? If so, then all that code that was written in C++ before 2011 wasn't C++? That would be shocking to all the people who were writing C++ before 2011. And it would mean that I have a million lines of code written in a language that doesn't exist apparently. That's pretty crazy. I never knew I was that amazing. &amp;#x200B;
I've experienced this, only it was somebody manually writing XML with Node.JS string concatenation. They brought a gazillion dependencies, but apparently adding in something to properly put together some XML would be too much bloat :-p
nlohmann::json is great and has a nice api. I think the performance issue comes from using exceptions for flow control, namely throwing when there are missing keys. Nothing major tho. 
Qt/C++ [tasks](https://github.com/mhogomchungu/tasks) library to do asynchronous programming using futures. This library was the first time i went much deeper and used templates in any meaningful way and it made me appreciate them and i now use them much more liberally in my code. 
&gt; But, wasn't type traits introduced in C++ 11? If so, then all that code that was written in C++ before 2011 wasn't C++? That would be shocking to all the people who were writing C++ before 2011. Obviously not, but you're obviously targeting at least C++11 so my point stands. Each revision C++ standard lists the headers required for freestanding implementations; `type_traits` in particular is required from C++11 onwards. &gt; And it would mean that I have a million lines of code written in a language that doesn't exist apparently. That's pretty crazy. It _is_ crazy that you have so much code in not-actually-C++, yes, but it's hardly unheard of. &gt; I never knew I was that amazing. Being apparently unaware of the previous point, however... Failing to know basic details of something you've used for decades is not something to brag about. &gt; Ultimately products are the only thing you can sell, not knowledge of the language, sadly. That's funny; I, for one, have been doing exactly that for decades now. But that whole paragraph is very much offtopic – do you want to post defensive rants or get the help you asked for?
I'm not bragging about it. But the point of software languages is to create software products. That's what I'm very good at and that's what I've been doing for all this time. People around here maybe get too hung up on the language itself, when it's just a tool. And it's been a pretty good tool for a long time since before type traits existed. I clearly don't need type traits to create a lot of good software, hence I haven't taken the time out from using C++ to create product to worry about it. I'm playing around with some new features, to see if they are useful. But if it requires buying into the STL stuff I'll skip them. They aren't necessary to me. If there are some that I can make use of (like enum class) and that really increase compile time type safety, I'm certainly happy to incorporate them as time allows. Ultimately, I don't see learning modern C++ in toto as advantageous for career purposes, and hence not worth the effort. I think that's sad, but it's true. I'm learning C#, Blazor, Xamarin and so forth on that front. C++ is effectively a dead language. I say that as someone who has spent a long time using it and who really likes it and who would probably rather catch up on C++ than learn a whole new world, so I take no satisfaction in saying it. But it's true. 
FYI regarding `std::embed` introducing dependencies which build systems need to learn about, the way I was going to handle it when we constexpr-ify P1031 *Low level file i/o* was to add support to Reflection to introspect what files are read and written in constexpr. Same could go for `std::embed`.
https://github.com/BlackMATov/kari.hpp :)
A couple of responses: * Firefox binaries built with clang-cl work fine with the VS debugger. * Clang seems to have noticeably better code gen than MSVC. Here's a comparison: https://treeherder.mozilla.org/perf.html#/compare?originalProject=try&amp;originalRevision=2adb3cb404ad&amp;newProject=try&amp;newRevision=5336df94a9ce&amp;framework=1 * Speedometer scores increased by 6% on Win64 and 12% on Win32 with the switch to clang * We're still using MSVC for Win-ARM64 and here's an example from the most recent bug that we've had to work around: https://developercommunity.visualstudio.com/content/problem/201662/arm-neonh-doenst-support-arm64-compiler.html. This was reported in Feb 2018 and doesn't currently have a resolution. 
Same here. Plus you get OpenMP newer than v2, that's so ridiculous.
The codegen is quite ok and improving but it's far from "really good" when compared to gcc and clang.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
What are you looking for in a parser library?
This looks very interesting. I work on a system that has an STM32F103. From what I can see modm essentially replaces the cmsis and stm peripheral library with a modern cpp interface instead. Is this right?
https://github.com/ddemidov/amgcl One of the best quality numerical code I've ever seen. Regardless of it's usage it's really a beautiful library. https://bitbucket.org/blaze-lib/blaze/wiki/Home Blaze is currently my favorite linear algebra linbrary. The performance is a prime example of what C++ is capable of. And the code quality and style of the library is extreme. I cannot imagine what it takes to maintain such a huge library to that level.
You do have point. However I wasn’t arguing that `unique_ptr&amp;` is great but that switchting to a `shared_ptr` to avoid it is a bad idea.
I'd be interested, too.
Testing double sticky.
Very interesting. But was it really faster than adapting (which is probably mostly search-replace) the tests to another framework? ;-)
*New!* This is the top-level comment for **individuals looking for work**. Reply here if you want employers to contact you. You don't need to follow a strict template, but I suggest inverting the relevant parts of the employer template. For example, mention whether you're looking for full-time or freelancing etc. work, briefly describe your experience (not a full resume; send that after you've been contacted), mention whether you care about location/remote/visa, and list the technologies you're skilled with. Feel free to disregard all of these suggestions, except that you obviously need to provide contact details.
This is the top-level comment for **meta** discussion. Reply here if you have questions or concerns about this post.
I find that debuggers tend to make people look at a problem, and the solution, myopically. I've always found the humble debug print better at directing where the real problem lies - the design problem.
It's not undebuggable. It's not very usable with a debugger, but that's not the same as undebuggable. Using a debugger is not the only way to debug, and experience tells me it's not a good way to debug. &amp;#x200B; Java IDEs have good debuggers, and Java programmers I've worked with write the worst code because the debugger tells them the code is wrong. It doesn't tell them that their design is wrong, or that their understanding of how the application should work is wrong. Their wrong code could have been avoided, but they don't avoid them, because debugging a nasty nested loop seems easier than identifying an algorithm or chain of algorithms that works. It's easier to debug an algorithm, because we know they are correct. &amp;#x200B; C++ has the language and library features to write code correctly from the start. Correct code doesn't need to be debugged.
Can you please elaborate?
Interesting read. We just have that if/else pattern in one of our codebases. I'll definitely look into it to see, if this would benefit our code. Performance is not really an issue, but all the if/else clauses are smelly.
I also found CTRE to be quite useful. Documentation would be nice though...
Most probably a macro-less parser combinator library (close to Haskells parsec library) with easy to compose parsers. It should include a rather complete base parser library (I do not want to write a parser for floating point values myself) and the usual set of combinators. I guess the parsers provided by spirit would be a good example. Using types that play well together with modern C++ features like structured bindings would be great (CTRE does this pretty well). I'd like a good amount of type safety with respect to parsed return types as well. Generic code is nice, but with reasonable error output. Eigen is the maximum of acceptable compile error message complexity - spirit (and a fair share of other boost libraries) is certainly not acceptable. Composition should be done via a sane mechanism - most probably function composition or type-level template composition. Operator overloading abuse is a crime. And please, basic memory safety and proper lifetime handling is a fundamental requirement (looking at you spirit!). I think PEGTL is a good candidate, but it lacks a base set of common fundamental parsers. If anyone knows a library that fits the bill please let me know :D
In general, so little love for macros and exceptions today, so I want to respect my loyal work horses. ///////////////////////////////////////////////////////////////////////////// auto operator "" _sql(text const* script, size_t) -&gt; procedure; #if !teroxNoMacros || teroxNoMacrosExceptSql #undef sql #define sql(...) = #__VA_ARGS__##_sql; #endif ///////////////////////////////////////////////////////////////////////////// auto NorthwindDemoAsCpp::getProducts() -&gt; universals try { static auto selectProducts sql ( select productId, productName, quantityPerUnit, unitPrice, unitsInStock from Products where discontinued = 0 ) return selectProducts[nil]; } catch(Exception&amp; ex) { log::error("%: exception: %", __func__, ex.message()); return nils; } ///////////////////////////////////////////////////////////////////////////////////// &amp;#x200B;
fmtlib is a great library, although I don't know that I'd call the code itself beautiful or elegant. That's not an indictment of the fmtlib author, what he's doing isn't really natural in C++ and so it can get a bit ugly. But it's a testament to the authors skill that he was able to do it with such a straightforward and sensible api.
I try to avoid templates and libraries that rely heavily on templates. The reason is that it has a major effect on compilation times.
If you were also interested in the part where he describes how to find the functions names juste by looking at their type, I suggest you take a look at hoogle (haskell's api search engine : [https://www.haskell.org/hoogle/](https://www.haskell.org/hoogle/)) : For example : [https://www.haskell.org/hoogle/?hoogle=%28a+-%3E+b%29+-%3E+%5Ba%5D+-%3E+%5Bb%5D+](https://www.haskell.org/hoogle/?hoogle=%28a+-%3E+b%29+-%3E+%5Ba%5D+-%3E+%5Bb%5D+) will lead you to \`map\`. And in the C++ world, there is the FunctionalPlus api search engine : [http://www.editgym.com/fplus-api-search/](http://www.editgym.com/fplus-api-search/) (Type the same search in the search box : for example `([a], (a-&gt;b)) -&gt; [b]` or `(a -&gt; b) -&gt; [a] -&gt; [b]` (curried version), or as another example, search for `[maybe a] -&gt; [a]`
Boost Hana
I started a Youtube channel. I made this video since I felt that C++ is often neglected as a good "first" language in favour of Python. I don't think this is necessarily true. Anyways this is my personal opinion and hence I understand is subjective.
I can see how it can seem ironic, but the point is not to use it to implement something that you cannot do with OOP, the point is that in doing so you end up with less "fluffy" code that is less structurally rigid and more flexible for change. Yes, I'd strongly recommend trying the approach yourself. If you want some resources (some of which are highly opinionated, treat them as extremist resources with some useful information to be extracted), I'd recommend: http://www.dataorienteddesign.com/dodmain/ https://www.youtube.com/watch?v=rX0ItVEVjHc https://www.youtube.com/watch?v=QM1iUe6IofM
Cool - great that those binaries work with the VS debugger, hope it's the same awesome experience. Yea, sometimes issue reports do lie dead (or seemingly dead) for quite a while, and sometimes it is indeed a bit cumbersome to deal with the responses from Microsoft to some bug reports which seem like the employees are very low-skilled and haven't even read the bug report properly, and you need to fight a bit until you get to someone from the "first world" team that _does_ have the experience (and they're awesome!). But there's bug reports and regressions on the gcc tracker as well that lie dead for months and years and some of them are quite wide-reaching ones. Sure you could in theory fix them by yourselves but then again that's impractical because not everyone has *that* deep of a knowledge (particularly about compilers), and until something lands in the main trunk/release of the compiler, it's still a useless fix because no downstream client/user/project has the fixed compiler.
&gt; get OpenMP newer than v2, that's so ridiculous. Yea, totally agree on that one!
I actually was confused about that part of his talk. Why does ‘T f(T)’ have to be identity? It could be returning any T.
T f(T) should be interpreted as "for all T, when f is given a T, it returns a T". If you want to implement this function to work for all T then the only thing you can do is return what is given to you. If you return a specific T then it's no longer "for all T" and doesn't really honour the type signature. C++ allows this because templates aren't strictly generics, they're code generators. That's not to say you can't write generic code with them, but templates aren't generic by construction contrary to in Haskell where the compiler enforces parametricity.
I think that types are most often under-utilized. Possibly because of the overhead of defining a new type. To use types effectively, I would say that you need 2 steps: 1. Make illegal states unrepresentable. 2. Make illegal operations unrepresentable. Let's illustrate this with an example... say that you want an integral (monotonically increasing) ID for a collection of `Foo`. Most often, I'll see Primitive Obsession in effect: int customerFooId; Hopefully, someone comes along and realizes that a little semantics would help, to distinguish that `int` from the myriad other `int` that exist in the program: using FooId = int; FooId customerFoo; However, we're still falling short of (1) and (2) here! The first issue is (1): if IDs started at 1 (0 being invalid) and only increased, then the ability to assign 0 or a negative value is a mistake! Let's solve (1) with encapsulation: template &lt;typename T, typename Tag, typename Traits&gt; class Tagged { public: Tagged(): data(Traits::defaultValue()) {} explicit Tagged(T t): data(std::move(t)) { Traits::validate(t); } T const&amp; value() const { return data; } private: T data; }; using FooId = Tagged&lt;int, struct FooIdTag, StrictlyPositive&lt;int&gt;&gt;; Excellent, now with the validator we can rule out any invalid state (`::default()` may not even exist, if there's no such thing) and we have lowered the cost of creating a new strong type to the cost of a typedef! That's solving (1) in style! It's a bit dry, though, so surely a couple helpers would help. `operator==` and `operator!=`, a specialization for `std::hash`. Unfortunately, this is a slippery slope, and soon enough someone may decide to add `operator+`, `operator-`, `operator*`, ... and that's when (2) is violated. What does it mean, really, to add 2 IDs together? To add 3 to an ID? To multiply an ID by another? There lays the trap, solving it involves defining *new* types over `Tagged`, and adding new operations only on those new types. For example: template &lt;typename T&gt; struct IdTraits { static void validate(T const&amp; value) { assert(value &gt; T{0}); } }; template &lt;typename T, typename Tag&gt; class Id: public Tagged&lt;T, Tag, IdTraits&lt;T&gt;&gt; { public: using Tagged::Tagged; }; // Specialized `std::hash` again, sigh. And `Id` will NOT support addition, substraction, multiplication, etc... it's nonsensical. It could support `operator&lt;` (and co), as that makes our life easier in a number of situation, or specialize `std::less`. On the other hand: template &lt;typename T&gt; struct NumberTraits { static T defaultValue() { return T{0}; } static void validate(T const&amp;) {} }; template &lt;typename T, typename Tag&gt; class Number: public Tagged&lt;T, Tag, NumberTraits&lt;T&gt;&gt; { public: using Tagged::Tagged; }; // Specialized `std::hash` again, sigh. Will support all mathematical operators, it's a number! 
**Internship** I am 17 years old, soon to be 18, and am looking for an internship in Zagreb, Croatia. I have decent knowledge in C++ but my main goal is to get insight of how it is to work in a software company and experiance in general. You can PM me on here or I can give you my email if you prefer that way.
Load of crap. Worked in the language 10 years and I despise it. I still write in it, because other languages are worse.
https://github.com/ipkn/crow/blob/master/README.md I enjoyed using crow.
What type of documentation would prefer? API or internals? Or RE syntax? It's in my TODO list :)
I know you've dismissed spirit, but boost.spirit.x3 might be worth looking at.
never in a header, if you must in a cpp. Even then, keep the scope as small as possible.
Why not in a header? 
With intrusive pointers You can pass raw pointers around and build shared pointers from them since the counter is inside the object. There is no restriction.
If you need to 'use', only use what you need with 'use std::vector;' and in the smallest scope possible. But most of the time it's simpler to just write 'std::string' directly
Because then you have it in every file that includes that header also. There's so much crap in that namespace that your probably of a name collision approaches 1 once you pollute the global namespace like that.
You don't print like this in C++, printf is part of the C library. You can use "std::cout &lt;&lt; whatever", implements your own streams for your objects. If you're programming in linux, generally building libraries is not really a problem (you have either the lib in the package manager or a standard way to build it easily).
because everything that includes that header will have std imported. And it may produce name clashes and break the odr rule. (for example if you declare a function called hash)
**Company:** JP Morgan Chase &amp; Co - [Investment Banking](https://www.jpmorgan.com/global/cib/investment-banking) **Type:** Full time **Description:** JP Morgan Chicago looking to grow the core of its global technology team that drives our electronic trading businesses across Markets. This is a great opportunity to join business-aligned teams focused on *building connectivity and eTrading infrastructure* for our Industry-leading **Macro (FX, Commodities and Rates)** trading desks. We partner with Quant Research and Traders to deliver Market Making and Algo Execution solutions to the business, working in an energetic, fast paced environment. We are looking for **junior and senior C++ engineers** who can demonstrate potential, knowledge, and passion for building highly performant and deterministic software. This role is in a small team that functions as a startup and has at the moment high visibility to upper management due to its strategic position. **Location:** Chicago, IL, [Chase Tower](https://goo.gl/maps/Hr11jAVF1C72). On top of the blue line and 10 minutes walk from Union Station. Casual workplace attire. Flexible arrangements are common. **Remote:** Not full time. Remoting/working from home on occasion is common. **Visa Sponsorship:** Not for this role **Technologies:** We standardize at C++11 at this moment. Innovation is essential but there are strict coding style guidelines due to risk impact. Some Python and the occasional Java for integration. Being comfortable at working in a Linux development environment is essential since all work is done on RHEL/Linux. **Contact:** [Taleo](https://jpmchase.taleo.net/careersection/2/jobdetail.ftl?job=180122115) **UPDATE** I was asked on PM if fresh graduates will be considered even if the Taleo link specifies senior only. Answer is yes - this is because we are using a single Taleo REQ to source both openings. 
The namespace is there to prevent collisions or accidental uses of reserved keywords. It basically makes sure you don't accidentally use a std function or keyword when you actually want to give your own variable a certain name and you don't pay attention. That's why you should never use it in a header, it will apply to everything that includes the header. Every time you include the header it will force the namespace on you. Even worse if includes are nested and you forgot you put a using namespace somewhere in there. **Never use using namespace in headers** You can use it in cpp files if you feel like it helps, that way it's limited to the file and you should be fine. But often it's cleaner and simpler to define some types that deal with long keywords like using cf_vec = std::vector&lt; std::complex&lt; float&gt; &gt;; or just taking certain popular commands out of the namespace using std::cout; Just to make sure you know what's in your global namespace. But it's up to you, but most people tend to just stick with std:: but i'd say using namespace std in cpp files makes lots of code easier to read and write so go ahead and use it. 
Thanks a lot.
Don't do it in headers. Other than that, I consider listing things you use explicitly like this: ``` using std::string; using std::vector; ``` If it fits on one line and you have C++17: ``` using std::string, std::vector; ``` And if there's too many things just: ``` using namespace std; ``` is fine.
Are there internship opportunities ?
Picking nits: Making *Invalid* States Unrepresentable &amp;#x200B; Illegal should never be used unless it is against the law for real.
Just a week ago I debugged the following line for a few hours: &amp;#x200B; auto parse\_version = digit &gt;&gt; lit('.') &gt;&gt; digit; parse\_phrase(...); &amp;#x200B; Of course that is UB and the parser expression needs a deep copy wrapper. No deleted copy/assignment operator/ctors, no move semantics, most certainly no compiler error. Sorry, but whenever I use spirit I run into UB, special type incompatibility corner cases or stack overflows after less than an hour. I can't take this library serious. &amp;#x200B; Bonus: All endeavors I took to make spirit parsers take lambdas (real ones, not that phoenix abomination from the dark ages) were annoyingly complicated and needed wrapper functions. Essentially you add preprocessor defines to enable language features from 8 years ago and write a wrapper that tugs away the phoenix::bind drama. Correct me if I am outdated on this issue.
And by keeping the scope small, I hope you mean use 'using std::container;' in the relevant scope, not import an entire namespace
First of all I don't even know the RE syntax family. From the [NOTES.md](https://NOTES.md) section "Unsupported PCRE constructs" I concluded that it might be PCRE. Maybe mentioning or even linking the syntax specs is a first step (if it is PCRE e.g. you don't have to write the syntax yourself, just reference [pcrce.org](https://pcrce.org) and add a few hints about where you diverged). For the rest I am personally fine with actually reading the code, but I guess for beginners a documentation of the regex\_results struct, and the range adaptor would be the most important - the rest I found pretty self-explanatory from the few examples in the README.md.
With the namespace you get a bunch of very plausibly named functions predefined. I used to tell my students about \`using namespace\`. And then I give them an assignment to wrap a function \`swap\`. If you make a small error, such as parameter mismatch, or a capitalization error in the name, the code will use the \`std::swap\` function. Big confusion ensues. Ever since I'm advocating the explicit \`using std::whatever\`. 
I never use it and no one at my workplace did either. even if I use `std::string` heaps in a file, I still prefer `std::` there because of clarity/readability and I have never felt that it gets too verbose.
If only Spirit X3 had lazy parsers like Qi. Modifying parser state at runtime is painful.
&gt; keep the scope as small as possible Would you really go to the extend as doing `using namespace std;` at the top of every function in a file? I would it consider pointless noise at that point.
That’s a different definition of scope. In this case he doesn’t mean block scope, he means the scope of what using imports, so, instead of importing all of std with using namespace std; Do something like using namespace std::vector; So that you can write vector instead of std::vector; The reason is you might end up importing a function name that is defined elsewhere. Math functions that have a C version and a C++ version in the standard library come to mind as an example. Those are somewhat trivial since presumably they do the same thing but it’s also trivial to create a case where two functions don’t. 
If you updated the readme to look more like Cereal, you might get more traction. Hard to tell much about it, without a good readme
I'll add to this that I have seen someone do exactly this in a header and it resulted in an incredibly hard to debug error in a completely different part of the system. The potential for weird action-at-a-distance with doing this is huge.
Thanks a lot! :)
Thanks for iterating on the idea of separating the types from their interactions, carlivan! I think encapsulating these interactions between types into new types is definitely the right way to go. I think, like all approaches, yours has some tradeoffs. One the plus side, the base class doesn't care at all about the interaction layer. You could even generalize your approach to be able to register multiple handlers, kind of like a chain of command pattern. On the downside, the base class is forced to track a type index, and as a result there is a possibility that types that derive from your pass outside of the same shared library might end up with the same type index, so a bit of work will need to be done (dynamically linked libraries under this approach could have unspecified behavior)
Would anyone be opposed to a bot automatically replying to comments on this thread that don't follow the template? 
There is a talk about this for the language Elm that I really like https://youtu.be/IcgmSRJHu_8 for those that might be interested.
The code is indeed not particularly beautiful mostly because of portability requirements (version 4 works with most C++98 compilers and version 5 only needs a small subset of C++11). But it's getting better as support for modern C++ constructs is enabled. Hopefully in a couple of years most macro ugliness will go away and the code will be more clean and straightforward.
My name is Joshua Ogunyinka. I am an experienced C++ programmer based in Lagos, Nigeria and have been working with C++ for more than 7years. Here's a non-comprehensive list of my key skills &gt; Solid knowledge of Window API and it’s internals &gt; Good knowledge of frameworks: OpenCV, Boost (Spirit, Signals, Serializer), Qt. &gt; Good knowledge of designing and writing multithreaded systems &gt; Good knowledge of Design Patterns and OOP best practices &gt; Good knowledge of VCS and CI: Git and SVN I am open to relocating to another country(and this requires Visa) and also working as a remote developer. Here's my github repository https://github.com/iamOgunyinka and my personal website https://iamogunyinka.com.ng
Absolutely. But not in our specific group though. This goes through another process. I suggest you create a profile there and then reach out to [one of our recruiters](mailto:Kyle.Ingold@jpmorgan.com)
 \*\*Company:\*\* [Applied Research Associates](https://www.ara.com/) \*\*Type:\*\* Full time, internships \*\*Description:\*\* ARA's Advanced Modeling &amp; Simulation System's team in Raleigh, NC develops simulation software for a variety of defense and intelligence related applications. These include physics-based simulations, GIS, and geometric modeling among other topics. We are looking for developers and engineers from entry level up to senior level, as well as interns.. \*\*Location:\*\* Raleigh, NC, USA \*\*Remote:\*\* No. \*\*Visa Sponsorship:\*\* No, due to many of the contracts being DoD employees must be US citizens, and eventually able to obtain a security clearance. \*\*Technologies:\*\* C++11 to C++17. Mostly Windows, some Linux. Typical tech stack is Visual Studio 2017, Git, CMake, C++, and some Python. \*\*Contact:\*\* Send me a PM with any questions \*\*[Careers Page](https://recruiting.ultipro.com/APP1010ARAI/JobBoard/07442cec-d18e-4589-ab15-8342edc29af7/?q=&amp;o=postedDateDesc&amp;w=&amp;wc=&amp;we=&amp;wpst=&amp;f4=vPUzkJBRS1eh5_eZe5db9w) (and a few of the available opportunities)\*\*: * [Senior C++ Architect](https://recruiting.ultipro.com/APP1010ARAI/JobBoard/07442cec-d18e-4589-ab15-8342edc29af7/OpportunityDetail?opportunityId=73a81a7f-4b88-43c5-afb4-0675fecb9886) * [Mid-Level Augmented Reality Graphics Engineer](https://recruiting.ultipro.com/APP1010ARAI/JobBoard/07442cec-d18e-4589-ab15-8342edc29af7/OpportunityDetail?opportunityId=bb11812b-09bc-40f0-8856-c8efdda6be4d) * [Mid-Level Simulation &amp; Structural Engineer](https://recruiting.ultipro.com/APP1010ARAI/JobBoard/07442cec-d18e-4589-ab15-8342edc29af7/OpportunityDetail?opportunityId=617b27eb-d901-447b-9859-51f853802906) * [Algorithm Developer](https://recruiting.ultipro.com/APP1010ARAI/JobBoard/07442cec-d18e-4589-ab15-8342edc29af7/OpportunityDetail?opportunityId=9b9c7e99-e21d-440d-b587-8d70d17fef8b) * [Weapon Effects Modeling &amp; Simulation Engineer](https://recruiting.ultipro.com/APP1010ARAI/JobBoard/07442cec-d18e-4589-ab15-8342edc29af7/OpportunityDetail?opportunityId=a9df1c98-b199-4433-81a8-24b509215bb8) * [C++/C# Modeling and Simulation Software Developer](https://recruiting.ultipro.com/APP1010ARAI/JobBoard/07442cec-d18e-4589-ab15-8342edc29af7/OpportunityDetail?opportunityId=8d120f06-cd6d-40b8-9ced-ff3058faae76) * [Machine Learning A.I. Software Engineer](https://recruiting.ultipro.com/APP1010ARAI/JobBoard/07442cec-d18e-4589-ab15-8342edc29af7/OpportunityDetail?opportunityId=ad4e6fa8-1140-4c08-a504-bca9f7fb87c3)
We don't need more mantras, we need better mantras. I find yours nonsensical when discussing language evolution, yet that is when you bring it up. What does quantity of software have to do with language features? Beyond that, what are you critizing specifically? What new features push checking to runtime? Just because it "looks more like JavaScript" doesn't mean the compiler doesn't do the checking. 
Yep, pretty much, while also keeping your driver code to external devices generic and portable
I like the concept and you explain it quite well. The boiler plate code is somewhat ugly (but that's cpp), but easily reusable. Something I will take with me going forward. I did write boiler plate code for FSM a lot as they tend to appear all over the place in games. Or your typical float that is just something that goes from zero to one over time and one needs to call a function.. easy to abstract into a small class making your code more clear
i'm confused about it too, because `sqrt`, `sin`, etc. all have this signature, and none of them has anything to do with identity. i believe he somehow only cares about the types involved (give an R, get an R... identity!), but that's not really consistent with the next few examples. 
Cereal is a life saver
Hi guys! I'm an experienced c++ developer using the language for more than 10 years now. I'm working as a professional (living from the money earned as a) developer for more than 5 years. I recently finished MSc as a computer engineer with Visual informatics specialization in the end. I'm looking for a freelancer job to be able to save more money for the upcoming years (marriage, children and etc.). I'm using modern c++, seeking smart solutions to problems and am a fast learner. I'm familiar with python and various 3D applications and game engines, too. I'm experienced in many fields related to maths and physics also. I've never really did freelance work except a few paying little projects during university and a little tutoring of computer graphics, but I'd like to try myself out. I'll be very maximalist regarding quality and everything since I want to have good reputation and references in the future as well. 
Do you mean why does range have to use fancy concepts and templates? I'm not to sure on that myself. It do you mean why do ranges exist at all? Because it greatly simplifies using containers as an object directly e.g. sort(container) which in my mind is absolutely fantastic, the alternative is sort (container.begin, container.end) which is cumbersome.
I have the exact same question as you however I'd like to share a list that was helpful for me (Though much of it is largely out of my capabilities) [https://github.com/danistefanovic/build-your-own-x](https://github.com/danistefanovic/build-your-own-x#build-your-own-3d-renderer)
&gt; it only returns the word REVENGE and nothing else Most likely this is because you are using `std::rand()` wrong. Did you take a look into documentation of `std::rand()` ? Here it is [1]. First example shows what you need to do: std::srand(std::time(nullptr)); // use current time as seed for random generator Here is documentation for `std::srand()` [2]. You can google more about this, here is one simple explanation [3]. But. Important thing is that "rand() Considered Harmful". See [4] and google more. As alternative, cppreference documentation proposes C++ 11 alternative - "random number generation facilities". Take a look into [5]. It's true, however, that random number generation in C++ 11 is hard. See [6], as example. In your case, given `std::vector&lt;std::string&gt;` (or any other container that can be indexed by some number, for simplicity), the simplest possible way to get random element, as for me, will be to, well, generate random index. Here is example: #include &lt;cstddef&gt; // std::size_t #include &lt;random&gt; // everything in random_index() function #include &lt;cassert&gt; // assert std::size_t random_index(std::size_t count) { assert(count &gt; 0); std::uniform_int_distribution&lt;std::size_t&gt; numbers(0, count - 1); std::random_device rd; std::mt19937 generator(rd()); return numbers(generator); } There are few moving pieces in this code and it's better to study links I provided (and google) for better understanding of what and why. But the thing is that `random_index()` generates number in `[0, count)` range. As you can see, there is precondition for this function: `count` should be greater than zero (now this precondition is expressed thru `assert()`, but, if you are interested, C++ will support contracts soon [7]). Now, it looks like you need to read words from file properly. There are few ways of doing this in C++, as always, but, as for me, there is simple one, like this: #include &lt;vector&gt; // std::vector #include &lt;fstream&gt; // std::ifstream #include &lt;iterator&gt; // std::istream_iterator #include &lt;string&gt; // std::string std::vector&lt;std::string&gt; read_words(const std::string&amp; path) { using WordsIterator = std::istream_iterator&lt;std::string&gt;; std::ifstream file(path); return std::vector&lt;std::string&gt;(WordsIterator(file), WordsIterator()); } You need to be familiar with Iterators concept, how std::vector&lt;&gt; can be constructed and idea of input iterators that read from stream. Having those 2 helper functions, you can write needed `randomword()` function. Here is working example: #include &lt;vector&gt; // std::vector #include &lt;fstream&gt; // std::ifstream #include &lt;iterator&gt; // std::istream_iterator #include &lt;iostream&gt; // std::cout #include &lt;cstddef&gt; // std::size_t #include &lt;random&gt; // everything in random_index() function #include &lt;string&gt; // std::string #include &lt;cassert&gt; // assert std::size_t random_index(std::size_t count) { assert(count &gt; 0); std::uniform_int_distribution&lt;std::size_t&gt; numbers(0, count - 1); std::random_device rd; std::mt19937 generator(rd()); return numbers(generator); } std::vector&lt;std::string&gt; read_words(const std::string&amp; path) { using WordsIterator = std::istream_iterator&lt;std::string&gt;; std::ifstream file(path); return std::vector&lt;std::string&gt;(WordsIterator(file), WordsIterator()); } std::string randomword(const std::string&amp; path) { const auto words = read_words(path); if (words.empty()) { return std::string(); } return words[random_index(words.size())]; } int main() { std::cout &lt;&lt; randomword("words.txt") &lt;&lt; "\n"; } Note that few decisions were made: 1. You will have empty vector of strings if "words.txt" file does not exist. You can turn exceptions of file's operations if you wish. 2. When file is empty, empty string will be returned. [1] std::rand(): https://en.cppreference.com/w/cpp/numeric/random/rand [2] std::srand(): https://en.cppreference.com/w/c/numeric/random/srand [3] How does srand relate to rand function?: https://stackoverflow.com/questions/21273550/how-does-srand-relate-to-rand-function [4] rand() Considered Harmful: https://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful [5] random number generation: https://en.cppreference.com/w/cpp/numeric/random [6] Discussion On Why Generating Random Numbers in C++ is Hard: https://www.reddit.com/r/cpp/comments/6e3r5i/discussion_on_why_generating_random_numbers_in_c/ [7] contracts: https://en.cppreference.com/w/cpp/language/attributes/contract [8] Exception Handling and Opening a File?: https://stackoverflow.com/questions/9670396/exception-handling-and-opening-a-file 
I have been searching a lot and most of it is just managed systems.
The phrase "make illegal states unrepresentable" is a phrase that I've heard before, often in the context of OCaml. https://fsharpforfunandprofit.com/posts/designing-with-types-making-illegal-states-unrepresentable/ and https://news.ycombinator.com/item?id=17933911 credit OCamller Yaron Minsky for the phrase. Has anyone else heard this phrase in other places?
`sqrt` doesn't receive any `T`, though—only numerical ones. What is the meaning of `sqrt("Hello world")`, for instance? If you receive a value of type `T`, without any constraint, what operation can you do on it? Not a lot actually. You can return some constant, or return the value you received. Given we want our return type to also be `T`, we're only left with the second option. Hence—_id_
Thank you, that made it click for me finally. It's interesting how this was utterly obvious, like a tautology, to the speaker and a few people in his audience. Makes you wonder.
\*\*Company\*\*: [ScyllaDB](http://scylladb.com) &amp;#x200B; \*\*Type\*\*: Full time; remotes welcome &amp;#x200B; Description: ScyllaDB develops an open-source, high-performance, distributed NoSQL database, also (total coincidence) called ScyllaDB. ScyllaDB utilizes the asynchronous I/O engine [Seastar](http://seastar.io), which we also develop, to drive million of operations per second on large multi-core machines with fast SSDs. The stack includes everything from custom memory allocators, through a user-space TCP/IP stack using dpdk, through high-level concepts like query parsing and compilation and maintaining materialized views in synchronization with the base table. Linux environment. &amp;#x200B; Take a look at [https://github.com/scylladb/seastar](https://github.com/scylladb/seastar) and at [https://github.com/scylladb/scylla;](https://github.com/scylladb/scylla;) if you like what you see you'll enjoy working with us. We have a strong C++ team and don't shy away from the bleeding edge. &amp;#x200B; \*\*Location\*\*: Mostly remote around the plant; Israel; San Francisco Bay Area (around 15 countries) &amp;#x200B; \*\*Remote\*\*: Very much, most of the workforce is remote &amp;#x200B; \*\*Visa Sponsorship\*\*: in special cases &amp;#x200B; \*\*Technologies\*\*: C++17, C++ concepts, boost, asynchronous programming, distributed systems, future/promise, C++ coroutines (eventually), JIT &amp;#x200B; \*\*Contact\*\*: [jobs@scylladb.com](mailto:jobs@scylladb.com)
So of course in one of the very last things I converted I ran into something that I'm going to have to step back and think about. There are some things that accept a list of whatevers and they really need to do index based operations on them. My collections are polymorphic so there's a base TCollection class that can be accepted and that lets the called method accept any type of collection. However, that means all manipulation must be done via cursor. There's no way to do direct access since we don't know how the passed collection is accessed. In those cases where the thing called needed to do indexed operations on, say, a list of strings, I would just have them accept a vector of strings. That means only a vector of strings can be passed. BUT, now that there's further specialization available in the form of enumerations as indices, a vector of strings indexed by an enum is not the same as the default vector of strings indexed by a number. So you can't pass one of those to such a method. This doesn't come up very much, but it does happen. I'm not going to try to solve that now. There are other pressing needs, but I'll be thinking about it for a future binge. Some of these things could in theory be updated to use cursors, though it would make them a lot more messy and not so self-documenting necessarily. I can't templatize these these methods since they aren't even directly exposed to the callers. Most of them are dialog boxes that are hidden away inside a library and invoked via a call to the library's 'facility object'. This vastly reduces header dependencies and build times. I can't give that up. So it's a bit of a sticky wicket. Of course if the list is short I could just dump it to a regular vector of whatevers and pass that, and copy the results back upon positive return from the call. But that offends my sense of software rightness. In the end, I guess there's only so much you can do to deal with C++'s limited enumeration support. &amp;#x200B;
C++ is intended for all performance heavy things. If you are not going to work in AAA-gamedev, HFT, super-highload services and so on, you are better off with other languages - C#/Java/... In C++ in exchange for high speed you get a lot of problems, I wont get into them, you can read it for yourself. The question was - what can you develop with it? Well, pretty much anything. There is a C++ library for (almost) everything. A web-server? You got it. Some gui app? Qt and others are waiting for you. Is it reasonable to do everything in C++? No, of course not, but if you really want it, you can do it. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/abkfi5/help_with_project/ed19hpw/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Look at [last quarter's](https://www.reddit.com/r/cpp/comments/9kig88/whos_hiring_c_devs_q4_2018/) and [this quarter's](https://www.reddit.com/r/cpp/comments/abh8bm/c_jobs_q1_2019/) jobs threads for an idea of what people are using C++ for in production.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ablnk3/whats_next/ed1aezi/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I would be opposed - I think it would be unnecessarily noisy. Currently I manually review postings, permitting a bit of variance but mentioning any significant deficiencies. The volume of posts is still reasonable for a single human to process. If it grows massively, we can explore bot options. Thanks for the offer! If you would like to help, feel free to PM submitters about issues.
Meh. It just sounds like you aren't able to adapt your working style to whatever language you're using, and blame the language for your inability to use a language the way it was designed.
The notation that you are using does not imply templates are involved. T f(T/* unnamed */) { static var; return var; } Is a perfectly valid implementation. If you want to argue otherwise, you need to use notation that is conformant with c++. 
Something I've been considering is implementing one of the projects from [this channel.](https://www.youtube.com/user/keeroyz/videos) They're all really impressive and cutting edge but, often very technical.
Ah okay, I'm not that familiar with the OpenGL parts of SFML. Glad you found it. :)
But then you still need to implement some sort of interface and if you're already rebuilding SFML, why not just modify SFML's vector type?
If I can add to this, it really needs to be easy to use. Easy enough for absolute beginners to use and get right the first time. You shouldn't have to know about recursive descent parsing, EBNF, or whatever. Right now I'm thinking a fmtlib-like syntax (which, since standardization seems inevitable, will be familiar to everybody eventually) is the right way to go. Like how `scanf` is similar (though not identical to) `printf`. I've had something like this churning in my head for quite some time, but I don't know enough about what I'm doing yet to get started.
That does not seem like the right way to do it. My employer uses an intrusive reference counted smart pointer that was home grown (I'm the current maintainer of it) and its relatively similar to the "RetainPtr" proposal that I saw here on /r/CPP recently. Passing raw pointers around sounds like a surefire way to forget to increase the reference count.
&gt; The rule of thumb should be : if everyone need it and reimplements it every time, ***in mostly the exact same way***, it should be in the library. Ftfy
I used this notation just because the other commenter used it. If there aren't templates involved and T is a fixed type (not a type variable) then yes there are many potential implementations due to the fact we suddenly know much more about the type. We can't use real c++ to demonstrate these properties anyway because functions are not pure so you get values from elsewhere or magic up values of any type from nothing etc. etc.
This way it will not be intrusive for users. Every time user writes a type name, he would need to mention his custom vector type. Or he can create his own aliases, I guess...
Raytracers, Physics, Particle dynamics, evolution simulation, games with ai, webservers, image processors, classfification and clustering... are you really short on ideas !
Is this comparing PGO with MSVC to LTO+PGO with Clang? (I know that LTO with MSVC was used in Firefox builds at some point, but I am not sure if it went official). There is similar code size regression as compared to GCC if you switch to build benhcmarks. [https://treeherder.mozilla.org/perf.html#/compare?originalProject=try&amp;originalRevision=2adb3cb404ad&amp;newProject=try&amp;newRevision=5336df94a9ce&amp;framework=2&amp;showOnlyComparable=1](https://treeherder.mozilla.org/perf.html#/compare?originalProject=try&amp;originalRevision=2adb3cb404ad&amp;newProject=try&amp;newRevision=5336df94a9ce&amp;framework=2&amp;showOnlyComparable=1) I hope XUL section sizes PGO includes debug info (it doesn't for Linux)
Great Idea, karl shone fieger is a favorite !
Enabling cross-language LTO for Clang builds does not conflict with maintaining GCC LTO builds in good shape. Implementing GCC backend to Rust frontend is possible and probably would help Rust development as well. It is about 10-20k of code to add codegen for new IL (you can check, for exmaple, with Brig frontend in GCC or dragonegg).
the contract is, if you don't care about putting the pointer in an Intrusive pointer object, then you don't Care about it's lifetime.
Download GDAL data from your favourite US state and try to gerrymander the districts. Use dynamic programming to keep it efficient.
There seems to be an issue with things like, for example, [https://github.com/inetic/asio-utp/blob/master/src/socket\_impl.cpp#L26](https://github.com/inetic/asio-utp/blob/master/src/socket_impl.cpp#L26). It's posting the completion handler using the system executor instead of the handler associated executor. Beast has a helper to do this correctly -&gt; [https://www.boost.org/doc/libs/1\_69\_0/libs/beast/doc/html/beast/ref/boost\_\_beast\_\_bind\_handler.html](https://www.boost.org/doc/libs/1_69_0/libs/beast/doc/html/beast/ref/boost__beast__bind_handler.html) &amp;#x200B; Checking that you are using the correct executor probably is something that should be part of the unit tests. But to be honest I'm not sure how to best do that.
Only after very recently I'd been conveniently ignoring the new `io_context` and `executor` interfaces and was simply using `io_service` from the old Asio API. So thanks for pointing it out, seems I need to do more learning on that front. That said, I'm not sure I fully understand the issue you're describing. In [the link](https://github.com/inetic/asio-utp/blob/master/src/socket_impl.cpp#L26) I'm doing ``` _ioc.post([h = move(_connect_handler)] { h(sys::error_code()); }); ``` I.e. I'm not using the free function `boost::asio::post`. The `_ioc` member is passed to the `socket_impl` class (indirectly through the `utp::socket` class) by the user. Am I wrong in assuming that `_ioc.post(...)` will then use the correct executor?
For the purpose of pinning the project on my Github, I'm making a cross-platform visualizer and generative audio program. The core is C++ but I'm going to get it running on Raspberry Pi, iOS, and probably a couple of other platforms. I'm thinking that it's a good demo of my skills to showcase a well structured C++ program that can easily work across different platforms, languages, and graphics APIs.
FWIW, `io_context::post` is deprecated, so you _should_ be using the free function `boost::asio::post`. ;-]
Ah, good point :) Looking into `boost::asio::post`, seems ``` boost::asio::post(_ioc, [h = move(_connect_handler)] { h(sys::error_code()); }); ``` is what I'm after. Though that also seems to (needlessly in my case) use the `async_result` magic and thus slow down the compilation. Perhaps - given that _internally_ I'm using only handlers (no futures nor coroutines)_ - the better thing to do would be: ``` _ioc.get_executor().post([h = move(_connect_handler)] { h(sys::error_code()); }); ```
Or modern C++ is a dumpster fire of things being tacked on that have no good implementation, leading to code that is ridiculously complex to debug. Case in point, every lambda, smart pointers, std::function, most containers, everything in the Visual Studio STL, etc. Just stepping through modern C++ is agonizing, because almost every new feature adds a dozen stack frames that serve no purpose. Function pointers add zero stack frames, std::function adds a ridiculous number. All of which would be fine if optimized C++ builds were even vaguely debuggable, but they aren't. And again, this is modern C++ I'm talking about - the last 10 years of features added to it are much less debuggable than what I would call the original design of the language. Is that my failing to adapt to the language, or the language abandoning my needs?
Still incorrect, you need to extract executor from `_connect_handler` via `_connect_handler.get_executor()` and only fall back to `_ioc.get_executor()` if it doesn't exist. `asio::get_associated_executor` does this. Likewise with allocator. Once you've acquired an executive and an allocator this way, either do `executor.post(your_lambda, allocator)` or bundle them up into a callable handler class that has its own `.get_executor()` and `.get_allocator()`, which can then be passed to `asio::post()`.
So, languages and environments developed where debugging was poor or impractical. Ways of developing that did not rely on debugging resulted. Naturally people drink the koolaid and say that debugging is now a bad idea; except, of course, in the cases they know of where their solution falls flat. Nothing to see here, just usual overcommitment to newer techniques. 
Adding on, Clang usage has also increased immensely due to playstation consoles, and most AAA studios that ship multiplayer titles also have a good amount of linux knowledge in house as well. It is rare to be working in a codebase or engine that was not bootstrapped before the advent of C++11, which is part of the reason AAA game devs work in a world with macros that have sometimes been superseded by builtin functionality in some cases (but still in many cases not). Many codebases also have an extensive custom preprocessor needed to provide a tighter coupling between code and data than even the currently accepted reflection proposal. Several codebases I’ve worked in (all enormous) have occasionally been burned by overuse of one feature or another (e.g. shared pointers, stl containers) and all of them have needed to reach for assembly intrinsics a good deal to deal with register and memory types and memory buses C++ does not yet provide an abstraction for. Overall, the article here gives a pretty good overview though of the AAA gamedev landscape and almost every codebase seems to rhyme with any other, due to how the hardware and techniques have evolved over the years. 
You can make audio and graphics projects with the JUCE platform.
It would helpful if you add your current location and citizenship
My understanding is that both MSVC and Clang are LTO+PGO
Sadly, the language fights you when you try to make illegal states unrepresentable: * Not having a default constructor makes some `std` stuff not work. Also, a lot of code gets uglier, e.g. by necessitating `optional` if you have to delay initializing a class member until within the body of the constructor. * All movable classes necessarily have to have a nullish moved-from state. 
do i misunderstand this? in the whole segment he shows signatures, and asks "what could this be named?" the answer to what could "T-&gt;T" be is 100% not identity. i understand computation with types pretty well, but i think he is confusingly mixing things in this segment. yes, sin and cos are not templates, but _if_ he talked about it in an algebraic sense, then you don't care at this point, it's just _some_ field. 
That's pretty awesome, I used scratchapixel a little when I wrote a raytracer recently, but this is a gold mine
What is the meaning of `sqrt("Hello world")`? Obviously the opposite of `"Hello world" * "Hello world"`. https://codegolf.stackexchange.com/questions/135802/take-the-square-root-of-a-string In all seriousness though, the whole point of his game was a bit lost on me: i thought it was about guessing the method from an unnamed signature (maybe because i read the haskell comment just before). Your comment and rewatching the segment made it clear what he was actually asking :) 
Game devs are also frequently running on multiple platforms and typically must use the compiler version provided to them. That typically means being stuck supporting 2-5 year old tool chains. Even considering Clang alone, there is a huge differences between the current version and what was supported in Clang 5 or 6. I think the STL line is a bit off. Use of algorithms is common. Its the containers that cause headaches. Memory is tight - perhaps game devs may use all the memory available which means fragmentation and known allocation upper bounds are important. Allocator contention is also a big deal from a performance standpoint. The discussion about testing missed a few elements. Due volume of data games process given the resources available, there is frequently insufficient abstraction between the logic and the data to inject testing. It isn't insurmountable, but many of the techniques would involve introducing lots of layers of optional abstractions that otherwise wouldn't be required. A simple example is the way games often make heavy use of some sort of reflection system that defines data layout... with logic that operates directly on those structures. The volume of data that must be provided to perform non-trivial tests gets big quickly. Fundamentally, game development is an entertainment industry. Devs are concurrently building tools and functionality for other non-engineering devs to leverage. Those devs rarely can understand what they'll need until a year or two into a project. Substantial requirement changes are common. New platforms show up with APIs so unlike others that entire portions of architecture and abstraction needs to be revised, potentially multiple times in the scope of a single project. At the same time, the budgets are so large and ship windows so narrow - shipping in the window of other titles can doom an otherwise successful project as everyone is competing for gamers time and money - that anything that causes maintenance drag is a major problem. Unfortunately game devs have found it cheaper to brute force their way out than to maintain millions of lines of tests. As the post mentions, low unit level tests of stable elements make sense and very high functional testing get automated but the millions of lines of code in the middle rarely have great automated test coverage. For the record, my studio has had multiple people going to C++ conferences for years, tries to keep up with changes to the standard, writes replacements for standardized but not supported in toolchain code, does what it can. Its just a long, slow process with 30 engineers maintaining millions of lines of code in a codebase that was started decades ago without stalling the progress for hundreds of non-engineering devs working on the game at the same time.
Good point! Fixed, thanks! 
My jaw hit the floor. Thats all I can say right now.
&gt;For the reference Clang (since 3.4 ), GCC (since 5.0) and Intel (version 15.0) already have full support for C++11/14. That does is definitely not true. Looking at [cppreference](https://en.cppreference.com/w/cpp/compiler_support#cpp14), Intel still does not have full C++14 conformance. The one that bit me personally is user-defined string literals.
(meta) Imho Twitter and reddit are a great way to share your opinions with a large audience. OP probably wouldn't have written this post (great stuff BTW) if people didn't use Twitter to convey their concern. 
I know it wasn't the main point and isn't exactly on-topic for the sub, but my favorite part of that whole post was the part about how people in games QA get fucked over.
&gt; And it’s no secret that the STL containers aren’t a great fit for games. If pushed, we’d probably admit that std::string is OK, and std::vector is a reasonable default. But all containers in the STL present the problem of controlling allocation and initialization. Yep, not a great fit for many other things .. &gt; It’s quite a reasonable thing to look for a better alternative to std::map, or for a small-buffer-capable std::vector. It’s much less palatable to have to maintain your own implementations of, say, algorithms or type traits for practically no gain. I think it’s a shame that the STL is so strongly identified with its containers. Isn't the fix obvious ? The default containers and the allocator problem need an actual solution Instead we see things like oops, yeah std::function custom allocator support doesn't really work so lets just nuke it altogether without offering something like a std::delegate that wouldn't even need an allocator and still be fine for a wide set of use cases. 
I hadn't noticed that "Added examples showing how to write composed operations." in Boost.Asio 1.69 changelog. Really useful examples! &amp;#x200B; Still not sure how to best test it, though. If in [https://github.com/chriskohlhoff/asio/blob/765f197ed69caadd6ac35f6d031ba6ca3665a11d/asio/src/examples/cpp11/operations/composed\_5.cpp#L139](https://github.com/chriskohlhoff/asio/blob/765f197ed69caadd6ac35f6d031ba6ca3665a11d/asio/src/examples/cpp11/operations/composed_5.cpp#L139) (and L142) you happen to misspell "executor\_type" with, for example, "ececutor\_type" everything will seem to still be working... until it doesn't.
I see, thanks!
&gt; I've spent a not insignificant amount of time optimising compile times So have I. It was time not spent on making the codebase more readable, more reliable, or more functional. It was purely time spent counteracting a tooling issue. In other words, not what I want to spend my time on.
True, but it probably isn't an issue with the programming language, more just the people using it. &amp;#x200B; I do agree that having better trained, respected and paid QA guys will make programmers jobs a lot easier though
If the best advice you can give small teams is ‘ignore modern c++’ then that’s a failure.
This is exactly the same picture as in other industries that depend on C++ for performance. Tons of managers and devs I know who just roll their eyes at the state of Modern C++ and the STL.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Decent productivity is possible within a year, but there are going to be things that frustrate you and you just have to know and understand that the language is not deliberately obtuse but rather a product of development over time and of the times it was made in. If C++ was designed again today it would be a bit different but if the design goals were the same it would end up with a lot of similarities and be about almost as big again. There are usually good reasons for most of C++'s complexity, but don't let that complexity daunt you either. If you keep your code simple and don't try to get fancy (and Go + Python means you understand that concept) then it can be quite similar to what you know and productive. Let someone else do the advanced stuff for you by using libraries with documentation to get you going. Start out with the simple things but try to keep the OO design methods of Python in mind, it will serve you well as a base in the beginning. Later you will want to look at more functional coding methods as those become increasingly important as you go along.
And you can apply for a ticket here: https://docs.google.com/forms/d/e/1FAIpQLSd1SnRvNgiVSV9U-mX9HffbqYFTXngFKXLlcjbvrL11Q1QQGg/viewform?usp=sf_link
Thanks for the write-up. The part about the goat is probably clearest... ; )
Qt is the most successful C++ codebase out there. It is extremely consistent, well thought through and documented. It is a perfect example of what the STL should have been.
I sometimes believe the standard libraries allocator model is broken beyond repair and nuking it from std::function was exactly the right thing to do. 9 times out of 10, when I want to use my custom allocator I also want to use a custom data structure too. However, I'd love to see more building blocks for those custom datastructures in the stl.
&gt; using exceptions for flow control That is a capital mistake. It is lazy programming "Im just going to throw this and care later about returning sensible codes from my API"
**Company:** [Bloomberg LP](https://www.bloomberg.com/careers/technology/engineering) **Type:** Full time, internship **Description:** [Bloomberg technology](https://www.techatbloomberg.com) drives the world's financial markets, and we're looking for passionate and energetic problem solvers to join us. We have full-time software engineering openings across a variety of teams and geographic regions. Since this is the C++ subreddit, I expect most people looking here will be interested in that area. If you are a strong software engineer with a background that is not so much in C++, but you want to learn and work more with the language, we'd love to hear from you. We value your experience, proactiveness, and problem solving abilities - we have C++ training classes available once you get here. **Location:** NYC, SF, London, Frankfurt **Remote:** No **Visa Sponsorship:** Yes **Technologies:** It's a large company, so pretty much anything and everything is used somewhere. We are primarily a C++ firm, and use all sorts of languages/technologies depending on the project. C++-wise, most new code is compiling as C++14 (though we of course have older projects around - if this is important to you, it's worth asking the particular team). Most of our backend is running on Linux and other UNIX flavours. **Contact:** A selection of roles are linked below, but there are plenty more to be found [through our website](https://careers.bloomberg.com/job/search?fd=Engineering). If you are not sure which position to apply for, email your resume to [Jen - jcarberry7@bloomberg.net](mailto://jcarberry7@bloomberg.net) for NYC/SF, or [Kelly - kdonald1@bloomberg.net](mailto://kdonald1@bloomberg.net) for London/Frankfurt (put "Reddit" in the subject line), and we will do our best to help you find a job here that matches your skillset and interests. Alternatively, apply through the website to the general positions for [London](https://careers.bloomberg.com/job/detail/71441) or [NYC](https://careers.bloomberg.com/job/detail/57072). NYC: * [Senior Software Engineer - CIS Connectivity](https://careers.bloomberg.com/job/detail/72364) * [Senior C++ Engineer: Market Data Core Services Team - RDP](https://careers.bloomberg.com/job/detail/66484) * [Senior C++ Engineer - Communications Applications](https://careers.bloomberg.com/job/detail/71053) * [Senior Software Engineer - Electronic Trading (C++)](https://careers.bloomberg.com/job/detail/66457) London: * [Financial Applications Engineer (C++)](https://careers.bloomberg.com/job/detail/66953) * [Engineering Team Leader - Ticker Plant Pipeline](https://careers.bloomberg.com/job/detail/71628) * [Software Engineering Technical Trainer](https://careers.bloomberg.com/job/detail/71183) * [Senior Software Engineer - Trading &amp; Analytics (C++)](https://careers.bloomberg.com/job/detail/70592) Frankfurt: * [Senior Software Engineer - Frankfurt](https://careers.bloomberg.com/job/detail/68219) For internships and graduate positions, [check here](https://careers.bloomberg.com/job/search?el=Internships&amp;el=Students+and+Recent+Graduates&amp;fd=Engineering). ----- I'm not in the recruitment team myself, so I may not be able to answer all questions and can't handle applications, but I am a Team Leader in the Software Infrastructure department in London and came through the graduate training program myself (admittedly it's changed a lot since then...), so I'm very happy to talk to people about what we do and how we work. Especially as my group is hiring in [NYC](https://careers.bloomberg.com/job/detail/66484) and [Frankfurt](https://careers.bloomberg.com/job/detail/68219)! I'd also like to highlight the [charity work Bloomberg does](https://www.bloomberg.org/), and actively encourages employees to get involved in, which for me personally is a very satisfying reason to work here over some other big companies. ----- You can find some of what we do on [GitHub](https://github.com/bloomberg), and [see](https://www.youtube.com/watch?v=xWmdcvTedbc) [some](https://www.youtube.com/watch?v=ovxNM865WaU) of our [C++](https://www.youtube.com/watch?v=GehO6LPu4qA) [experts](https://www.youtube.com/watch?v=EglLjioQ9x0) on [YouTube](https://www.youtube.com/watch?v=FLbXjNrAjbc&amp;t=2679s) and [contributing to proposals](https://www.google.com/search?q=bloomberg.net+site%3Ahttp%3A%2F%2Fwww.open-std.org%2Fjtc1%2Fsc22%2Fwg21%2Fdocs%2Fpapers%2F2018%2F) for the language standard.
I wasn't implying C++ is to blame for labor conditions lol. I'm glad we agree though, Happy New Year!
This is the same as any other optimisation problem, is it not? Which is always a fundamental tradeoff. 
I was totally amazed by that. QA is a resource that helps improve your product. Why all the negativity? 
Well, struct no { no(no&amp;&amp;)=delete; }; then `f(no x){ return x; }` is illegal in C++. So `id` doesn't qualify. 
I suppose the problem is it feels easy and replaceable, when in reality it's just not.
Wow! I'll have to try this out on my STM32F407!
tl;dr: "Our industry is rotten to the core, please adapt the c++ standard to fit our deficiencies."
Excellent mocking? Compared to what, C? How does one even get decent mocking without reflection? 
Sure, you're correct. Doing this kind of equational reasoning doesn't really work in c++, you can always find a reason that it doesn't work, but you should take the spirit of the message: types constrain the implementation significantly. Sometimes enough that only one implementation is correct. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/abtncc/how_would_a_table_of_contents_of_a_perfect_cpp/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Saying that debugging is possible without a debugger is ridiculous - yeah sure, it can be done, but who wants to abandon an invaluable tool for the sake of some new features? People aren't going to change their programming style if it makes one of their most useful tools frustrating to use, when they can probably just keep using the language the way it was without the debugging hit. Also, I'm pretty sure the reason template metaprogramming is so underutilised by game devs is because the error messages that you get are horrendous when something goes wrong. Again, yeah, you can do it, but why bother when it's such an unpleasant experience when stuff goes wrong? I'm pretty sure that if the game dev industry's needs aren't addressed shortly then the industry will jump ship to another high level language - D, Rust, Go, or probably most likely if it has a release anytime soon, Jai.
I thought that was fixed in C++17.
I will forever wonder how different the landscape might have been if D didn't have a GC built in from the beginning (I know they are working on making it possible to not use it but that idea is so deeply rooted in people's heads a lot of devs may never give it another look even with the ability to avoid it now [at least mostly I haven't looked at the exact state of affairs in a while]). I know that's why I didn't bother with it for writing low level code since I already have c# on the GC side of the house, and have started picking up rust for lower level coding.
As someone who just went through this recently, the whole STL divide thing is jarring for people just learning the language. You constantly read places like reddit, stackoverflow, and even Bjarne who all recommend the STL and "modern" practices. Then you go and you see that the top two most viewed CppCon videos are talks about essentially avoiding the STL, and other reputable programmers like Torvalds and Carmack have been negative. I was a big gamer before learning C++, and a huge fan of guys like Carmack, so I naturally looked to that industry when I was teaching myself. I adopted the style of basically writing C code with very little or no STL and compiling with a C++ compiler. In fact I didn't even know what the STL was exactly, I just avoided it by default because it never appeared in the code I was looking at. Even though I was just an independent programmer I thought it was some terrible thing to be avoided. Admittedly I actually think this was a good learning experience in retrospect, but damn if I could have written better programs and saved a lot of time had I just used the STL. Adopting modern C++ and the STL has been a huge gain for me, someone who only works with much, much smaller programs. Anyways, I just thought it was interesting that two of the coolest industries that perhaps get people into C/C++ are essentially ones that avoid the modern features and STL.
Hello everyone, I'm 24 years old C++ newbie with C background and am looking for job where I'll be the least intelligent person in the room but the one hands on the keyboard. I'm blogging in [here](https://adem.codes/posts) and host personal projects on [Github](https://github.com/p1v0t). I was an intern at a computer harddisk producer for around 6 months, after I dropped out university, because decided programming is all I want to do. I'm living in Antalya, Turkey now and relocation is not a problem. Thanks for reading //
In quant firms there's a good number of devs who are from a non-computing background or they did a lot of competitive programming where the C++ code is not even close to production level standards, this is somewhat expected from those types of candidates even though working at the firm these types of habits should have been eliminated by senior devs during code reviews. On the other hand if this was HFT and not a prop shop, hedge fund then I'd be surprised since HFT's test C++ skills a lot more rigorously. 
Yeah, D would probably be the best candidate if it didn't have GC. I've done zero programming in D, but I'm guessing that even if your own code avoided GC, other libraries for basic functionality will be full of it. It's a shame, really. Go probably can't work for the same reason, and Rust is too high-friction with its focus on safety - game dev doesn't really care about unsafe code, as long as it's fast and it doesn't leak enough to be able to run for a day or so to pass Nintendo/Sony/Microsofts minimum req's. If Jonathan Blow gets his timing right with a release of Jai (with the amount of general uncertainty from the games industry in C++ right now), he could grab quite a chunk of the market I think.
An interview is a 2 way process. If someone rants like that for some toy code in an interview, then they are likely someone you don't want to work with on real code. 
Bug fixes and enhancements made to someone else's project make for a better portfolio. 
Noob question: whats wrong with stl containers and shared pointers? 
On the topic of automated testing, I think you can unit test almost everything in gameplay and probably should. It's just software after all. Of course you can write integration and higher level tests on top of that afterwards for testing larger concepts. But those high level tests often tend to be flaky. It's good to have low level tests as a foundation for checking what actually went wrong when something high level fails. However, with that said, it's been my experience that convincing developers in the game industry to unit test everything has been like paddling a canoe up a waterfall. The biggest roadblock has been the topic of mocking dependencies, which usually involves a mocking framework. The mention of virtual classes when mocking will get some people angrily shouting because of performance costs. It's a struggle.
Not a noob question at all, as I'm sure many general C++ practitioners may not have run into their limitations. Off the top of my head: 1. Containers have an extremely cumbersome interface for specifying custom allocators and tracking memory 2. Vector cannot implement the SBO (small buffer optimization) 3. Iterators are guaranteed to be stable, so map values are never stored contiguously and must be chained 4. Shared pointers, because of the existence of a weak pointer, are not as efficient as a simple atomically ref counted pointer (they are fantastically designed, but overkill for many use cases) 5. Because we don't have destructive moves, the existence of move constructors and copy constructors prevent allowing containers to just memcpy ranges of memory on resize (i.e. there is no way as a user to specify that this is possible without aliasing types or something) Keep in mind, I use STL containers and such in my own personal projects or one-off projects frequently. They are reasonably productive and you won't run into their limitations, but in a more performance critical or industrial setting, they can be counterproductive.
You should go for 100% test coverage, but how you debug your tests without a debugger...not everything can be so trivial.
&gt; Implementing GCC backend to Rust frontend is possible and probably would help Rust development as well. Yep, I think this is definitely something that makes sense mid-term, both to benefit from GCC's generally better code generation and to benefit from a larger selection of target platforms. Short/mid-term there are plans to add a super-fast Debug code generator (cranelift), which should pave the way to a multi-backend setup. Once it's there, adding another backend should be much easier.
Ranting about a rather irrelevant thing is not cool. Ranting against the recommended practice (well, at least more recommended than not) is a sign of a small mind.
No, there isn't always a reason it won't work. But if you are going to use axiomatic reasoning to state that the only function T-&gt;T is id, you should be correct and say the only noexcept function Regular-&gt;Regular is id. When you port logic from one domain to another you should be *careful*. Those details -- that C++ admits *more kinds of types* than Haskell does -- aren't just noise. Build a better abstraction and you get more interesting results. Even if the result is "avoid non-Regular types when you want to reason about them, because they make it hard". 
For those who want to address the point 2 and 3, folly has a small_vector class and Abseil has flat_hash_{map,set}. I am pretty sure that Google also has small/fixed vector class but don't know if they have a plan to release it. AFAIK, those two libraries have mostly self-contained dependency so it's pretty easy to use them.
The problem is not having a GC, rather the quality of its implementation.
And yet none of those developers who roll their eyes ever offer to get involved with even committee meetings or mailing lists to at least voice their pain points leading to the development being largely academic.
Ask three c++ programmers and you will get three different answers on whether to use `using namespace std;` or not ;). The part that I find really sad is that your preference one way or the other has very little to do with your qualification as a programmer. Any c++programmer should be able to adapt to whatever is the practice in the current project - ranting about it feels a bit like arguing if the star should go with the type or the variable name: put it in the coding guideline for heavens sake and be done with it.
He's going to be your boss, or at best your peer. His behaviour is acceptable to your boss. Do you want to work there? Well, do they pay enough money to make up for like zero personal development and ranting coworkers who are wrong? Seriously. Maybe you are hard up for cash, maybe they pay a million USD. If yes, take job. Otherwise run away. Interviews go both ways. If you aren't interviewing them, you need to learn how. 
I think testing gameplay itself might be difficult. But it shouldn't be difficult to test most of the methods that after independently called. Or to do UI testing to confirm that UI elements work and display properly at a variety of different settings.
Well they get shot down and despised as old farts, dinossaurs. Right in line with the current wave of intolerance and violence in campus (ie Antifa). Academics in general are isolating themselves from the capitalist pigs and the current sad and dysfunctional state of C++ perfectly reflects that.
At least everyone can agree to keep that crap out of headers, right? ...RIGHT?? 
I've slightly adjusted my post. I mean, some things are worth optimising, such as bad compile-time algorithms (quadratic number of instantiations). Even there, though, I think one of the primary reasons why these happen is that TMP has such a weird syntax and unusual "execution" model that programmers might not even be aware of what they're doing wrong. Better facilities (and C++ is moving there with constexpr functions and if constexpr) make bad algorithms less likely by giving programmers a more familiar model to work with. But including more than one needs is an artifact of the C++ compilation model of textual header inclusion. Optimising that feels like time wasted, because you are not working on a fundamental issue, you are counteracting a tooling issue. Again, C++ is improving (modules), but that's *because* the current way of doing things is suboptimal.
I have been in games for 20 years this year. I started on the verge of the C++ revolution. This is very accurate for everything I know and articulates some issues with unit testing well. A few additional thoughts though: 1. Content based unit tests should be developed and maintained by content people based on what they need to function to do their jobs. Programmers guessing at it isn't good enough. This would require a testing framework perhaps using the game scripting engine, and would go a long way to solve what I think is the biggest issue during development: basic functionality of the game constantly breaking due to bugs or other stability issues blocking everybody. 2. Proper usage of Data Oriented Design may not be compatible with STL containers at all, or any sort of atomic container that does it's own allocations, and seems to match better to code generation. 3. Having done a lot of analysis of our compile times, I think the biggest culprit is actually inherent to the C++ class syntax, requiring the interface to be declared with the data members, which are often unrelated to the end user of the interface. Being able to declare a static interface separately from the data (like a C interface has always been) removes the exponential explosion of header includes. There is a proposal which Bjorn himself made that would fix it https://isocpp.org/blog/2016/02/a-bit-of-background-for-the-unified-call-proposal but I don't know if I'll be able to use it in C++ before I retire.
100% Bullet dodged. I really dislike the idea of coding during interviews. It just feels so irrelevant to your skills as a developer, whether you can "code on command". I'd rather be able to ask you architectural / design pattern oriented questions, and get satisfying answers. Like, you being able to talk to me about RAII or about the usecases of a unique ptr is I think a lot more telling than you being able to merge-sort something. It's like you said, why in the heck would you ever implement your own if it exists in the STL, unless you had some very narrow usecase? I think Interviews are about asking 'why'. Why do you write software the way you do? Why do you use library X or pattern Y? What problem does Z solve? etc. etc. Just my 2c though.
The vast majority of the committee have day jobs in industry, not academia.
It is fixed every release. We will fix it again for C++20! &lt;/snark&gt; We will probably _improve_ the allocator model in C++20, and in future releases.
https://abseil.io/tips/153 discusses interesting points from the "don't do it" camp. Generally more relevant as your codebase gets larger, but can also apply to the std case if you like snake_case naming.
&gt; Anyways, I just thought it was interesting that two of the coolest industries (games and space travel) that perhaps get people into C/C++ are essentially ones that avoid the modern features and STL. Precisely one of the reasons we started up SG14 (games and low latency and embedded and similar fields). Games &amp; low-latency are some of the biggest industries using C++ today, yet games had no representation on the committee at the time (and still has only minimal representation). That said, it's very inaccurate to say that games avoid modern C++ features. People forget that while Carmack and Acton and others have their opinions and are big names, they are responsible for only a teeny tiny little fraction of the whole games industry. When any of us say "games don't do X" what we're really saying is "the games _we personally work on_ don't do X." Groups like SG14 and other industry groups attempt to take a broader view and collect many inputs and positions from many developers and companies before making statements about what games need out of C++, but people sharing opinions on blogs or GDC talks or whatever are generally only expressing their own personal opinions and experiences. Remember that.
It is a HFT job, so paying a million USD isn’t inconceivable...
weak_ptr has an performance cost to locking them that negates much of the usability benefits for common tasks (e.g. if you store a weak_ptr list of objects to update you will have a bad time) and shared_ptr will end up getting deleted in every way and every callstack possible. It'd be better to have your own smart pointer class that takes into account your engine design where you may have specific points in the frame where you can control life times in a way that has no additional runtime locking cost. STL containers are mostly OK but problems I have run into in the past are: 1. You need custom allocators to support memory alignment, which was not trivial to do (haven't looked into this recently though). 2. Platform implementation differences causing different behavior, even if it's due to a user error. 3. Poor platform implementation issues, e.g. std::unordered_map on VC++ had extreme debug deletion performance problems.
Check \`boost::beast\`
Part of that is bad code structure. You shouldn't _need_ to de-optimize your code's performance to mock anything, because you shouldn't have big messy dependencies that need mocking in the first place. Well-organized game code is simple data and discreet logic that can be isolated and tested with no mocking at all, and integration testing can deal with the interactions between those discreet pieces. The problem in the industry I've perceived is that most game code does not in any way meet the criteria of "well-orgnanized" and it's usually messy and over-engineered. :p
Also there isn't a non-atomic unsynchronized version of shared_ptr
To the point of removing allocators from the container type signatures ?
The only way were I can see that games "shouldn't be unit tested" is because of the fact that usually an error in the game is not "critical" and some bugs might even be better than the initial pretended behavior.
Indeed. I would thank the interviewer profusely for helping me dodge a bullet. Imagine if the interview had gone well, and they ended up ranting like that on your first day, after you've moved your family 2,000 miles to come work there. *Great*.
Unit testing really boils down to given some functionality and input, these are my exceptions about a single thing. The code tested can be run in isolation, ideally in a separate process. The topic of code doesn't really matter too much for unit testing you generally approach it all the same. However, unit testing can get hairy with things like static memory, tightly coupled dependencies, multithreading, and randomness. That's where mocking comes in, and the push back due to performance costs. But it's possible to unit test just about everything. Of course, adding unit tests to a large code base with existing game code is difficult and costly. TDD is a better way to start because you're writing the test cases of how your code should work before you write the implementation. It ensures that the person who wrote the code, also wrote the constraints of how it should and should not function. Writing tests for legacy code is not ideal but still has value. Something like UI testing is high level testing that usually involves the entire game to be booted up. When that class of testing fails, you're usually looking at dumps, logs, and screenshots to figure out the issue especially when it doesn't fail in an expected way. In this class of testing anything in the game could be a potential failure point in contrast to a unit test where it is much more focused. When a unit test fails, there's a good chance that the name of the test is enough to figure out exactly what went wrong. You'll need engineers to to do a lot more management with this class of testing. And often with the amount of intermittent failures that come with this class of testing, it begins to lose it's credibility among the development team when they get into the habit of, "My code didn't/couldn't cause that crash." That being said the class of testing is still good to have but, having unit tests as a foundation will make it much easier to figure out what your testing hasn't covered and will probably point you to the unit tests you are missing.
Re (5): there is work on [`std::is_trivially_relocatable`](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1144r0.html). Not clear if it's been cleared for C++20...
If we don’t restrict the analysis to things that are currently present, there’s definitely a lot more to talk about. I think adding on user code to fill in the gaps is generally easier than taking off or modifying though.
I wonder how much overhead this would have wrapping over say solarflare onload
Thanks for that link. I'm going to share it when discussing this in the future. Normally I try to rely on the two times I've seen abs cause runtime errors because some header somewhere did a `using namespace std;` conditionally so the code only worked properly on one platform. But the fact that `abs` and `std::abs` are two functionally different things should be a big red flag, IMO. There's also the issues with boost vs. std.
Sometimes that is bad though. Functions are called many more times than they are defined. There's no rule that will cover all cases and preferences.
But if I put it in the precompiled header, then I don't even need to type it more than once ... (☞ﾟヮﾟ)☞
Boost libraries. There are a number of reasons I don't use them. Firstly, I develop for Windows &amp; Linux. I'm creating currently a Reconnaissance Application for Windows and Linux. Using a Socket to do this isn't as Good. I tried using Winsock for an Http Server but it wasn't any Good as Pythons Flask framework. And the second reason, How to install it lmao? I'll try this.
Is making the `Image` class implicitly shared better than just aliasing `shared_ptr&lt;Image&gt;` ? I guess I could see in some cases having non-shared data (eg a currentRead index into the Image) or needing to hide some of the underlying `Image` API from the shared 'view' but in the general case this just requires some extra boilerplate to delegate your API to the underlying shared_ptr with little benefit. I guess you can also hide the shared_ptr API from clients and keep them from copying it and whatnot but is that necessary in most cases?
Herb Sutter makes shitloads Of money preaching to hedge funds. I've seen the damage that this functional shit has done to the industry. Actually Keep at it please. I have been cleaning up fucked up "modern c++" repos for over five years after some fat cat unleashed millions to rewrite perfectly functioning codebases just for the sake of modernizing it.
Yea I’ve been loosely following that proposal. But it’s just an example of one of those cases where I as a developer need it “now” and unfortunately cripples a lot of otherwise useful functionality in the STL
Isn't GC non-deterministic by nature ? Well, TBH, heap in general is non-deterministic and doesn't fit great many applications. 
Oh don't you just love code like ptr-&gt;AddReference(); // TODO: figure out why this is necessary ptr-&gt;AddReference(); return ptr;
If you don't want to use boost then just use libuv and incorporate your favourite opensource HTTP parser code. Figure out what of HTTP1.1 you need to support and then pray you don't need to use HTTP2 in the future
Wait so you pass around intrusive_ptr&lt;T&gt; objects? Is that not a type of smart pointer?
I know :(
Not at all :)
Libuv. Will look into it. Thanks!
I can pass around intrusiva objects or raw pointers it does not matter. You cannot do that with smart pointers. That is why intrusive pointers make move semantics useless
Sure, but there are hundreds of GC algorithms to choose from. Additionally, there are stack, globals, gc-free heap allocations, and code regions with non-gc code. The problem with the anti-GC crowd is that most always equate GC with something like Java OpenJDK GC, without spending any time understanding how system languages with GC heaps actually work. As Joe Duffy commented on his RustConf keynote, even with Midori performing quite well in front of them, many devs in WinDev kept stating it wasn't possible.
The most likely reason is that there are enough other people who want the job. You might say a good QA eng is not replacable, but the truth is they really are. And probably by someone cheaper. It's a matter of supply and demand. At will employment makes sure that it stays that way.
A great way to share your opinions and be forgotten five minutes later.
I’ve had fun with cpprest in the past. [https://github.com/Microsoft/cpprestsdk](https://github.com/Microsoft/cpprestsdk). It’s really easy to start a server, listen to named endpoints, handle things asynchronously, handle json etc. 
I'm surprised that both here and HN nobody has suggested namespacing just the components you're using to avoid polluting the entire source file (i.e. `using std::cout; using std::endl;` . I always prefer to use just the elements I need when using a large namespace like std. If I'm working with a third-party library and in the source file then I might include the entire namespace, but as much as possible I try to avoid namespace collisions. &amp;#x200B; &amp;#x200B; That being said. The interviewer was way out of line. Especially for toy code. None of it really matters at the end of the day, because the company should have an enforced coding style and automated checks for all code to ensure it adheres to it. Your personal preference of coding style should be irrelevant. 
Be glad that you got out of there... :-)
The part about testing was interesting. Missing a point 7, possibly. In finance at least, a broken test could result in significant real financial loss. The Knight Capital incident certain encouraged a lot of firms to be more rigorous in their testing.
Will look into this. Thanks alot.
Uh, i equate GC ( and heap ) with non-deterministic behaviour, performance has little to do with it. And that kind of kills it for anything real-time. Also, while i'm somewhat familiar with story of Midori, had a friend working in the team at some point, i haven't really followed. Wasn't it generally a pretty obvious flop with somewhat predictable outcomes ? 
goldbolt?
I understand that completely, but adding unit tests to an existing code base is $$$$$ expensive while adding limited automated system level tests is $$$. One is far more palatable to management especially as you can show it off to them as a user experience project to ensure delivery of a high quality gaming experience. Of course, designing with TDD is $ for the unit tests and $$ for the system level/ integration tests. If only we could all start from scratch.
&gt; The problem in the industry I've perceived is that most game code does not in any way meet the criteria of "well-orgnanized" and it's usually messy and over-engineered. :p I've found that to be true for one very important reason: "well-organized" code does not run as fast as possible because "well organized" often means "generic" and or no dependencies. In live game code you virtually always have dependencies because you don't want to do runtime/dynamic dispatch and the generic system I just built is actually only used in 3 places all of which could be setup as hard coded dependencies allowing the previous dynamic dispatch to now be compile time dispatch. At the end of the day game performance matters more than ease of test making.
https://github.com/civetweb/civetweb
I'm wondering if it was a test, a ploy. The interviewer might have been testing how the candidate reacts to an extremely poor criticism. The justification being that if the candidate is able to defend their position and not react in a similarly hostile manor, then they will be fine for less offensive criticism during the job.
99,999% of the time, if the atomic ref- count in shared_ptr appears in your profile, you are misusing shared pointers to begin with.
I wouldn't suggest that any team just stop and add 100% coverage of unit tests for already existing code. But, you can do it in pieces over time. Adopt TDD, and write tests when existing code changes. On top of that write tests when you fix a bug, and target problem areas that have frequent regressions. The more expensive part is the initial setup of the framework in CI. Usually you can just reuse the same build machines in CI to run the tests and code coverage. After that it should be smooth sailing. Just work on increasing code coverage where you can. &amp;#x200B; Higher level automation is usually more expensive because you have more complex failure conditions. Someone or some system has to create bug reports for any intermittent failures. You'll likely need labs for all the platforms your game supports. This usually requires the hiring of engineers to maintain. In my experience it's the more expensive option long term.
C++ is a big language. You can chose what feature you like and what not. There are those who avoid Boost. There are those who avoid stl. There are those who avoid exceptions, const, auto, lambda, void, streams, reference, non-public inheritance etc etc. Some really like to stick to C and cant handle C++. Some of them are really religious about their choices. At the end clean, readable, maintainable code that runs without leaks and crash is all that matters.
Lots of the work in the c++ committee is actually done by people payed from big SW companies (Facebook, google microsoft, nvidia ...). The problem is not industry vs academia, but certain domains against others. If the gaming industry doesn't sponsor people to work on c++, it is no wonder that it largely develops according to the needs of e.g. google (programs running mostly server workloads).
Not really. People try to patch it, but due to backwards compatibility, the fundamental design (and it's limitations) doesn't really change.
That kind of happened in c++17 with the pmr versions. 
Nobody uses the STL that is the gorilla in the room
It's still a meta build system, using ninja for the actual build like CMake uses make, so I would still call it out of the box. Or what do you mean by pairing?
lmao. You know someone somewhere made that argument...
I'm not sure I'm getting what his point is in the first example, I did: https://godbolt.org/z/mBZy4j It definitely seems that the using namespace ONLY introduces into its own scope...
Absolutely not true in my experience. 
Are you already experienced in C++? 
Your anecdotal experience is as valid as mine.
Beautiful webservers? 
Tell me one game engine that uses STL heavily
Given the lack of representation, and the massive baggage that backwards compatibility brings, wouldn't it be more feasible for SG14 (and related WGs) to essentially fork the standard and create a breaking dialect; rather than slowly bringing improvements into the standard? Especially considering that the nice people working on CL/Clang/GCC are already able to add experimental features (e.g. modules) long before they are official; surely there would be tooling support available.
I didn't claim otherwise, but you said "nobody" which can easily be proven to be wrong even with limited datasets whereas you need much more data to prove that it is correct (even considering that we are of course not talking about absolutely nobody but rather "only very few").
Interesting there are the same companies who developed more performant versions of the STL because of its obvious shortcomings.
https://github.com/ankushagarwal/nweb On windows, Compile it with mingw or better with MSYS2
Sure, because writing your own hash table and adding it to your code-base is much easier (and much faster) than convincing the committee to change the standard one in a backwards compatibility breaking manner and then wait until your c++ toolchain provides an implementation of that. Also, you can always tailor your datastructures to your specific needs. The stl tries to be extremely generic (which usually means it doesn't really excel anywhere).
No - keep it out of unlimited scope. Contrived example but // A namespace my_namespace { using namespace std; void Foo() { cout &lt;&lt; "foo" &lt;&lt; endl; } } // B using namespace std; namespace my_namespace { void Foo() { cout &lt;&lt; "foo" &lt;&lt; endl; } } A is ok whether it's in a header or a cpp file. B is a no-no (to me) whether it's in a cpp or header. Long compile times mean I sometimes end up with [Unity Builds](https://stackoverflow.com/questions/847974/the-benefits-disadvantages-of-unity-builds), where anything that puts things in global scope is bad. (I know unity builds aren't ideal, but they're an unfortunate reality for many of us)
&gt; doesn't that make them vastly less useful than they otherwise would be? HERESY Your question actually touched a very good point and it is very valid but it goes against the stateless narrative of functional programming, which is like religion these days. What you did was like going into the church and pissing on the Saint Cross
Doesn't really matter whether or not the interviewer was right, that's just not how you treat a co worker (current or future). Even if he did something awful like returned a reference to a local variable, or mixed new and free, you still don't scold someone in an interview like that!
There are soft real-time GCs being used in military scenarios. GCs don't run 100% all the time and if being a real-time compatible language is a requirement for systems programming, then even C fails that test, given how many systems would fail that litmus test. As for Midori, it is pretty obvious that any project torpedoed by internal politics instead of technical achievements is going to be a flop no matter what.
That is actually another point AGAINST lambdas. Proper function names are an essential part of self documenting, clear code. Lamdas by design destroy that self documentation mechanism.
&gt;The stl tries to be extremely generic And still, does not have a straightforward string split. [Meanwhile](http://doc.qt.io/archives/qt-4.8/qstring.html#split-2) This is what the STL should look like
Haha. Start scribbling notes furiously... "And where do you come down on spaces vs. tabs? Mm-hmm mm-hmm. And camel vs. lower camel? How much of your coworkers time would you say you waste each day with inane rants?"
You are completely missing the point, these axiomatic reasonings stem from type theory, and they do hold there. If you make a language, like C++ or Haskell, its your choice how strict your type system is. In Haskell, a pure function with the polymorphic type `T -&gt; T` has to be `id` since the type system is very rigid. In C++ it doesnt really work, but thats the fault of C++, not of the axiomatic reasoning if C++ chose to employ a (in the view of a functional programmer) flawed type system.
1. Every major mobile OS, game console, and desktop OS prefers either latest MSVC or some version of Clang, and the dominant server platform can easily use Clang or GCC. The non-MS platforms can be the bigger problem these days because sometimes you don't have the _latest_ Clang without building and maintaining your own toolchain installation, which is time consuming and burdensome for smaller dev teams. 2. Depends on the engine. Some engines allow nearly everything in "script" at suitable perf (e.g. Unity/C#) while others require more C++ coding for gameplay engineers (e.g. Unreal). The trade-off also depends on your role; engineers at Unity are writing a lot of C++ for the core engine facilities.
This guy C++s.
Well, I'm already not very popular around here. But, ultimately, the template thing suggested below works well enough and allows either a lambda or a function pointer to be passed, So it's a reasonable solution. &amp;#x200B;
Better escape anyway. I wouldnt work with someone trying to test me that way
boost compiles under windows&amp;linux (i think should apply to boost beast also)
I agree fully, but don't for the sake of all things good put a using directive in a header.
Agreed. If they stop the conversation after you finish explaining and say "Im sorry about that, that was a test to see how you faced hostile scrutiny, that's not how we operate normally," I might rethink. The thing is, there are lots of coders that cannot take scrutiny of their work. But if you can take offensive and hostile criticism over trivial matters calmly during a high pressure interview, its a decent indicator that you can take non-hostile criticism on the job. IDK to be honest, depends on how much the job was paying and how fun the problem set is.
The problem is engineering is all about tradeoffs, and the committee is tasked with making tradeoffs for "everyone". It's effectively an impossible task (though we all do our best).
&gt; A is ok whether it's in a header or a cpp file. If A is a header then it's still entirely unacceptable, unless you want `my_namespace::regex` and `my_namespace::vector` to be things. Which you don't.
Here is the talk I referenced before: https://steveire.wordpress.com/2019/01/02/refactor-with-clang-tooling-at-codedive-2018/
I don't think there's a way to express what actually happens, which is why the author says "roughly equivalent." As far as I know, there's no way to inject into a namespace outside of the current namespace other than using a using-directive or if your current namespace is an unnamed namespace (where they're automatically imported into the parent namespace). Perhaps it would be more clear to say "For the duration of the scope, it is as if they were declared in the global namespace" for that example? On the other hand, `testing::Expectation` and `testing::UnorderedElementsAre` aren't necessarily "injected" until they're used (but that doesn't make it any better; it's a ticking time bomb IMO).
you should always reference the global namespace for clarity &amp;#x200B; ::std::cout &lt;&lt; blah" &lt;&lt; ::std::endl; ::std::merge(...);
Boost and specifically Boost.Beast have no issues running on both Windows and Linux. If you're expecting the experience to be akin to Python's Flask framework you're going to be disappointed. Beast is meant to be a low level HTTP server/client library and it does that very well. You will not be up and running with 5 lines of code however like you would be with Flask. It hasn't been updated in a while but check out crow ([https://github.com/ipkn/crow](https://github.com/ipkn/crow)). It's built atop Boost.Asio and provides a more Flask-like experience.
Ngrok sounds like it might be helpful to me with my on-line code generator. Thank you. 
best way to get knowledge of you knowledge is to give you mini project to do, i hate when they give you like on paper some code, last time they gived me i told interwiver i am not tarded i would run code and solve this issue in 2 mins
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I know right. I had a productive coding day today and changed less than 20 lines of code. I spend much more time problem solving that churning out LoC, and I expect the people I interview to do the same. Also, don't get me started on obscure brain teasers... Real life is open book, people!
Or even pull it inside Foo(). Otherwise you'll have random std stuff accessable as my_namespace::cout etc.
Depends - in this example sure, but if you've got multiple functions all pulling members from the same nested namespaces (apache thrift comes to mind), introducing a namespace at a higher level than a function might be wise. I apply the same rules to variables as I do to namespaces - bring them in in the most limited scope that makes sense.
Python will feel consequences of community split even after 2020. Corporate codebases are slow to upgrade and 2020 will be a reason to start using, not python3, but compatibility libraries (python-future and six) to not upgrade the code. Splitting C++ in python3 style would mark the downfall of C++.
Ngrok sounds like it could be helpful to me with my on-line code generator. Thank you.
I agree on good names. `auto a_good_name = []...` fixes that problem. 
I tried to apply to work for Microsoft. I couldn't get their website to work after a week of not getting help from their tech support so I just gave up and never applied. After some research, the same issues that I ran into have existed for 3 or more years and still exist today. If they can't make a working job application website, why would we trust a compiler from them to produce correct or optimized code?
&gt; while others require more C++ coding for gameplay engineers (e.g. Unreal). I'm a little out of the loop, but in UE3 you could do a ton of stuff in UScript. Has that changed in UE4? Why? The underlying inheritance tree in native UE is the kind of stuff that fuels my nightmares.
You can do a ton of stuff in Unreal Blueprints in UE4. That's not generally the kind of stuff a gameplay _engineer_ is doing, though. It will vary by project and team, of course. :)
Don't view it as coding. View it as an interactive exercise in which you and a potential future co-worker collaborate on the design of a function or class. He starts out acting as a customer giving you a probably-incomplete list of requirements. Take his list of requirements and work out what else you need to know to actually design the function. Should it modify a passed-in value or return a copy? If it returns a copy, how should the memory be allocated? If it modifies memory, should it return anything at all, and if so, what? Draw out what's going on in memory, potentially across multiple iterations. Make sure you get corner cases locked down (What if it's passed a null or other invalid value? Can we cause a divide by zero?) Catch those instead of just letting the function crash. Honestly if you do all that, by the time you actually get around to writing code, I don't need to see you write code anymore. Though I'll probably still let you do it just so you're not an anxious wreck at the end of the day because I just stopped you there. Make that one small change in your outlook and your interviews will improve 100%.
SG14 is a study group of the ISO committee so it's very clear that they will not ever be making a forked standard. Someone else could certainly do so, but good luck; Clang and co are unlikely to accept PRs for features that aren't being proposed for the mainline C++ standard and game companies are unlikely to rely on an unofficial fork of Clang that implements Unofficial GamerC++. :)
Have blueprints replaced UScript? Blueprints seemed like more the realm of designers whereas UScript was better for gameplay engineers wanting to iterate quickly. I was much more willing to work on UScript as a gameplay engineer than blueprints, that's for sure. Designers are great, but they couldn't code and most things in games are far easier to code than to... wire up or whatever the blueprint vernacular is.
I'd have to violate some NDAs to do that... but they most definitely do exist. :)
I almost was there... Too many attendants at once for your talk :) the staff didn't let more people in the room. Thanks for the link and congrats for great talk!
Why are ranges required to implement sort(container)?
\*\*Company:\*\* a.i. solutions \*\*Type:\*\* Full time \*\*Description:\*\* We’re a team of software engineers, aerospace engineers, physicists, mathematicians, and data scientists building FreeFlyer, one of the top platforms for satellite orbital modeling and trajectory design. Our software is used by NASA and other space agencies and private companies for satellite mission planning and mission control. FreeFlyer has been used for spacecraft missions of all types, including the International Space Station, communications satellites, science missions, and several planned missions to the Moon and beyond. We are looking for someone to join our team who is excited to dive in and make an impact. By joining the team, you will have the opportunity to: \+ Solve interesting problems that are centered around high fidelity computational modeling, data structures, algorithms, data visualization, and performance. \+ Contribute to improving our software architecture and help us build a better product. \+ Learn from subject matter experts about everything that goes into sending a satellite into orbit. Our tech stack is primarily C++ and C# and are able to accommodate developers at various skill levels. We have a lot of challenging and interesting work to do in software architecture, data visualization, computational modeling, etc. \*\*Location:\*\* Washington, D.C. \*\*Remote:\*\* Yes\*. Part of our team works remotely full-time and we're able to be productive and communicate well. We'd prefer if new team members were on-site initially so that they can connect with our users and subject matter experts. \*\*Visa Sponsorship:\*\* No. \*\*Technologies:\*\* C++17. C#. Windows and Linux. OpenGL. \*\*Contact:\*\* [stefan.novak@ai-solutions.com](mailto:stefan.novak@ai-solutions.com). Alternatively, feel free to message me on [DC Tech's Slack community](http://www.dctechslack.com) (@stefan).
Boost runs on both operating systems. Is the syntax same?! This is great information for me. Thank you.
It's great. Do check it out.
I might install it on Ubuntu rather than Windows. I don't mostly use Windows. Thanks!
&gt; Why are ranges required to implement sort(container)? Define "container" – you'll probably end up with something resembling a range. ;-] &gt; Every example I've seen of ranges is utilizing fancy lazy evaluation akin to LINQ. Those are range _views_, which are a subset of ranges.
&gt;The non-MS platforms can be the bigger problem these days because sometimes you don't have the latest Clang without building and maintaining your own toolchain installation, which is time consuming and burdensome for smaller dev teams. I'd like to mention my [on-line code generator](https://github.com/Ebenezer-group/onwards). My approach is to minimize the code you have to download/build/maintain. And I like FreeBSD and small teams.
Defining container, I can just as easily come up with a pair of iterators. In fact, there are already functions in the STL that can take a container and return the begin and end iterator, std::begin and std::end. So implementing std::sort(std::vector&lt;T&gt;) would be pretty trivial. I'm hardly a rangeS expert, but if condensing two parameters down to one is the main driver it hardly seems worth it, no?
I gotta politely disagree. Some people can talk about patterns all day long but can't write a decent line of code to save their life. If they're going for a position where programming is required in the day-to-day, then they need to be asked to write some code. I keep my requests real simple, no need to write anything complex.
I have been a bit surprised by this whole conversation on standard C++. I spent close to 10 years in the game industry (left two years ago to travel and now working in finance), and I dont quite understand why people complain about the debuggability of modern C++. Let me explain: First, debuggability is extremely important, especially in games, for reasons already explained in the various blog posts that came out of this discussion (no clear spec except "feels right"/"fun", hard to write proper tests to check if behaviour is "phyiscally plausible", or "there is no z-fighting on the map"...). Running things in the debugger and being able to properly inspect data is the main way those problems can be investigated and solved. I think we need to separate modern C++ into two things, the language, and the library: Regarding the language, except maybe for lambdas, I dont see any modern feature that would be much harder to debug than C++98. The language is bigger, for sure, and that might be considered a drawback, but this is not hindering debugging by itself. The language did not get harder to debug, debuggers mostly got better (compare writing MSVC visualizers now to what they used to be, same for gdb which got python visualizers, DWARF now contains macro definitions so that you can evaluate expression containing macros, and can contain actual byte-code on how to find the value of an optimized variable...). Regarding the library, reliance on modern C++ patterns and on the compiler to inline many functions did make things worse. However, I dont think that is so significant because I dont expect that to hurt game developpers that much: Every place I worked in did not use standard containers and had their own implementation, which makes sense, `std::vector` is a good default implementation, but when you care about performance and control, you want to roll your own. Back in Eugen Systems, one of my first task was to implement a `ContiguousVectorInSitu` class that would provide guaranteed to be contiguous data with some configurable amount of stack allocated data to avoid allocations when that vector stayed small. We then realized we could just use an in-situ size of 0 to to have a normal vector, this allowed us to implement move semantics before C++11 (we just had a "Relocate" function to overload to provide specialized move support). We could out-perform `std::vector` because we had full control, and we could have nice debugging because we controlled the layout of the class (so we could write visualizer scripts). This is why I like C++, the focus on library writing means that when we care about performance, data layout or debuggability (and in the game industry we usually do), we can roll our own, making trade-offs based on assumptions we can make at our level, but that standard library writers cannot make (hey, we usually disable exception handling, so no need to copy-and-swap to ensure exception safety, we can write the obvious sequential code). And the best thing is, even if you roll your own, you can still `std::sort` those. Think about it, how many languages make it possible to define you own data structures, and still have a myriad of generic algorithms that will happily run on them ? C++ gives us control, and only Rust comes close to that. Because lets be honest, debugging a C based hash-map or vector implementation is much worse (either you have to go through lots of macro layers, which is not much more appealing than template instanciations, and/or you have to know what to cast all those void* to). SG14 can help get more things into the standard that we dont need to re-implement ourselves, I know its not common in the gaming industry to send people to participate in that (which I dont think is a way to avoid helping competitors, just look at how open the game industry usually is in describing their rendering techniques publicly once the game is released), but it would help. In the mean time, we can roll our own, and thats a good thing.
I very strongly disagree with almost everything you just said. :) &gt; because "well organized" often means "generic" and or no dependencies Well-organized does not mean generic. That's exactly why I just pushed against the idea that you even need crazy mocking frameworks to do testing in games. :) If there's any root cause of bad performance in gameplay code I've seen, it's either being too generic or it's being a spaghetti mess of dependencies that can't actually be optimized into more efficient algorithms built for modern hardware. You seem to be saying that having a mess of hard-coded dependencies is better than being generic, which may well be true, but they _both_ are terrible. :p &gt; In live game code you virtually always have dependencies because you don't want to do runtime/dynamic dispatch and the generic system These are also a false dichotomy. You can have isolated testable code without a single dynamic dispatch in sight. :) Data-oriented programming is especially well-suited here. A good data-oriented design is _very_ efficient and coincidentally exceedingly easy to unit test. As soon as you start hard-coding (or even _having_) dependencies, you code yourself into a performance dead-end. SIMD is harder. Multi-threading is hardware. Offloading to the GPU is harder. Distributing your server code across multiple machines is harder. Your _engine as a whole_ certainly has a ton of dependencies, but then that has nothing to do with _unit_ testing. And you're getting more into integration testing, stress testing, smoke testing, etc. But that's another topic of where the games industry traditionally does laughably badly, too. :) &gt; setup as hard coded dependencies allowing the previous dynamic dispatch to now be compile time dispatch. Whoever said anything about dynamic dispatch? I just said you don't need virtual bases or mocking at all! :) Isolated code (aka well-organized code) removes hard-coded dependencies, can still be pipelined via compile-time dispatch into _highly_ efficient processes, and can still be easily unit (and integration) tested and automated. Even in a big AAA game. I promise. :)
It's more complicated than that. Blueprints replaces _some_ of what USCript was used for. C++ replaces the rest. They've made hot-reloadable C++ modules that make it very easy to quickly iterate on gameplay code in native high-performance C++. Basically think of writing C# in Unity and how frictionless that (can) be, but apply it to C++. The idea being that modern C++ almost as easy to write as UScript, far less limiting than UScript, and far better documented and better tooled than UScript.
Back in the day it was all UScript. Kismet was their attempt at some sort of visual scripting system. Blueprints are now the modern replacement to Kismet. UScript has now been replaced by C++. Nowadays a dev will utilize all their tools. C++ for the most part, but if something is quick and simple to implement in Blueprints then they'll do it. 
C++ does not do that. It's a cultural thing. It prefers to make you explode because of your sins.
IIRC Knight was more of a process error (their dummy order sender got hooked up to live trading) than a lack of testing.
The article by Ben Dean that was linked to was infuriating to read. I agree that game developers could participate more in the language development and that's a perfectly valid criticism but going on to tell one of the largest groups of professional users of that language that they're just doing it wrong in this meandering rambling mess of an article just charges headlong into the absurd. &gt; Participate in standards discussions; get on the groups or the mailing lists; read standards papers and provide feedback to the authors. If you can also attend meetings, that’s great, but if you can’t, ***you can still do a lot to advance your perspective.*** That's literally what people are trying to do and this is the response it's getting. Debugger is slow? You're just doing too much. And you shouldn't be using the debugger anyways. Have you ever heard of these neat new things called "static analysis" and "testing"?! Sure the debugger on Windows is great and Microsoft and Sony have invested obscene amounts of resources developing other tools for game development and graphics... But you don't get to use Valgrind! I mean, Valgrind isn't any faster and won't solve your problem but I think we can all agree Linux is way cooler than Windows. And anyways debugging doesn't "scale". If you want scale you should add lots of logging. That's way better than just hitting a breakpoint, looking at state, and fixing the problem in 30 seconds. What's that? It takes too long to recompile after you added a new print statement? Surely you've just failed to maintain your build. Maybe you should hire someone to do that? You've probably never thought of that for team of hundreds of engineers and ludicrous budgets. Or buy better hardware, computers are pretty fast these days! The first thing you can have your new build engineer do is rip all the templated code and unnecessary dependencies out! Wait, woops. But anyways yeah you should definitely use Boost. What was I talking about again?
I could rant right back about shitty boost documentation that uses "using" in their example code. No example code, including code written in interviews, should ever import namespaces, because it's being written for the reader, who should be able to decide in their own context whether or not to import namespaces, and it's trivial to transform the code one way but not the other.
I agree. Absolutely no one will ever actually write any shipped code under such circumstances, but they are all tested in that way. I'm immensely experienced but I would suck horribly under those conditions. It's like standardized testing in schools. It's maybe OK for finding the average, but it's likely to discard or at least work against the exceptional or unusual talent. &amp;#x200B;
It sounds like your interviewer has yet to understand the point of namespaces...
&gt;At least everyone can agree to keep that crap out of headers, right? ...RIGHT?? Sure. In implementation files, there's nothing wrong with using namespace std. Makes for much more readable code. 
Interviewer sounds like an ass, but stds do clutter up code and contribute nothing to understanding code, so from a cognitive perspective it's not advisable to put stds everywhere. 
int * foo; Best of both worlds. 
But then encapsulation is broken when you reach for `using namespace my_namespace` and `std` is unexpectedly pulled too. It does work well for an `impl` or anonymous namespace though. 
I saw you at -1. I agree. Having moved around lots of teams (including games), it seems basically impossible to communicate just how fast the pace of development is on a competent gamedev team. The benefits are a result of everyone having worked together that way to endure it all works together in a streamlined manner. Those who haven't seen it just have to trust me - and they simply do not.
Any recs? What should I watch?
Prototype in Blueprint. Productionize in C++. For gameplay routines that run per frame, the virtualization penalty cost of blueprints is often too great. 
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/abvw6c/gamedev_introduction_to_modern_c/ed4hgdx/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I do that and also for things in the global namespace: ::socket(...); ::syslog(...); I'm reluctant to use using namespace std; , but I use using directives with most other namespaces.
Is making the Image class implicitly shared better than just aliasing `shared_ptr&lt;Image&gt;` ? Yes, you're guaranteed that the `Image` is not a `nullptr` and you can now also pass raw pointers to Images without having to double dereference them. When the only reason to use a `shared_ptr` is the performance optimization of sharing data instead of copying it then in my opinion that optimization should be transparent to the user. 
I think, referring to `::abs` as `abs` is a bug. It’s functionally different as in it has different behavior, but not a different purpose. 
I'm only personally familiar with a subset of boost libraries (as most people I imagine are). All of the ones I use (boost.asio, boost.beast, boost.coroutine and boost.serialization) have required no platform dependent code for my use cases (with the exception of setting up certificate paths for using tls with boost.asio).
À1
Serious question: why not just wrap the text `sql(...)` in quotes and `_sql` instead? The macro only offers slightly less code.
You're not wrong and don't deserve the downvotes. Game development is a competitive industry where the market performs more healthily than most domains, where exclusive contracts and/or access to customer specs are more common (and I've worked on both - before and after games. Pace of development on an experienced team is factors higher and makes the rest look like rubbish, and there's no turning back). If someone wants to win by doing things differently, then they're welcome to try and developers will eat up any post mortem or presentation on it to try and improve, since it's utterly cutthroat.
*sigh*. At every company I've worked at, the C++ standard library out performed the internal custom implementation *on average*. Meaning aside from edge cases, the default performance and behaviour of standard stl was better, including compile times. I also never hit an edge case that I couldn't work around through the facilities available in the C++ standard library, though admitedly, sometimes that took some work. I've spent a significant amount of my career replacing poor code with standard facilities, often during the optimisation phase, which I find ironic. You do have a point about the focus on library writing being beneficial, because there are cases, such as the small_vector optimisation you mention. But I have a particular beef about an entire industry shunning the standard library by default for performance reasons, when it's actually just to satisfy some edge cases and is probably costing performance on average. 
What is this terminal called? 
What if someone has a bare, global 'string' class that you include, and you do your internal 'using namespace std' and then freely use 'string', intending the 'std::' version? It'll be ambiguous. So no, not good enough.
**Company:** Corelight **Type:** Full time **Description:** Corelight is a high-growth security startup that emerged from the open source community of Zeek (formerly Bro), a powerful and widely-used network monitoring framework. We secure some of the most sensitive and mission-critical networks in the world, and our rapidly-growing customer base includes eight of the Fortune 50. Open source is in our DNA: Corelight was co-founded by the inventor of Zeek and its key open source committers. We are seeking an experienced C++ developer interested in developing future versions of Zeek with us. You will work on Zeek’s open source code base, and you will interact with Zeek’s global user and developer community to integrate feedback &amp; review contributions. Your work will shape Zeek going forward, and your code will become deployed widely by some of the largest organizations in the world. **Location:** San Francisco, CA; Columbus, OH **Remote:** Yes **Visa Sponsorship:** Yes **Technologies:** We use C++11 and newer, and we develop primarily for Linux and macOS. Strong Unix skills are a must. Python is a plus. A track record of open source development work is a strong plus. **Contact:** Please apply [here](https://corelight.com/company/careers/1457622/)
fish + some theme, maybe [bobthefish](https://github.com/oh-my-fish/oh-my-fish/blob/master/docs/Themes.md#bobthefish).
Do not get me wrong, I am not arguing game developpers should ditch the standard library types by default, I am arguing that if for some reason debugging is too painful with a provided type, reimplementing it is a possible approach, I consider it to be a big strength of C++ that you can do that without breaking all your code (reimplement `std::vector` keeping the same interface and all your `std::find_if`, `std::sort`, `std::lower_bounds` will still work). I am arguing that the stl is necessarily complex to debug because it has to deal with many corner cases, `std::unique_ptr` can be a pain to use in gdb because it needs to empty-base-optimize its deleter... if you never need a deleter writing your own `unique_ptr` can be much more debugger friendly. It is a trade off, and what we lose by not using a standard type should not be understimated. My point being, C++ allows us to make those trade-offs, this is a good thing. I would expect most time the stl gets replaced with a custom version, some profiling proves that it actually improve things, and I would strongly advise to keep a compatible interface with the stl so that swapping the implementation remains possible. Also, keep in mind that in the game industry you had until recently to support fairly esoteric compilers (not gcc, not clang, not msvc, looking at you GHS), so the quality of the provided standard library was not consistently best in class. To give more perspective, I worked in places where the `std::vector` replacement assumed types could just be relocated with a `std::memcpy`, and we wanted to have control of the layout of that class because we would load C++ object directly out of the dvd (yep, reintepret-casting memory freshly copied to ram, along with pointer and vtable fixup). I know all that is not standard compliant, but thats what we were willing to get to to improve loading performance on consoles. 
Live++ makes pretty much any code in C++ hot reloadable too, which is kind of crazy. I've been using it lately on a custom engine and it's a life changer.
&gt;weak\_ptr has a performance cost to locking them that negates much of the usability benefits for common tasks [Here](https://github.com/duneroadrunner/SaferCPlusPlus#dereferencing)'s a microbenchmark demonstrating it. For non-asynchronous situations, you could use ["registered" pointers](https://github.com/duneroadrunner/SaferCPlusPlus#registered-pointers) (shameless plug). As well as being faster, they are more flexible as they are not associated with any specific owning pointer type. In fact, they can also point to objects on the stack. A while back there was a [video](https://www.youtube.com/watch?v=4t1K66dMhWk) that talked about using "generational indexes" to make weak references safe in entity component systems. A commenter ("skulver") pointed out a more efficient, seemly overlooked, way to do it already in use. Registered pointers are basically the generalization of that technique, which can be used whenever you need a (non-asynchronous) safe weak reference. For the asynchronous case, a [version of `shared_ptr`](https://github.com/duneroadrunner/SaferCPlusPlus#asynchronously-shared-objects) that holds ownership of the access mutex, as well as the object lifespan, would be generally safer.
&gt; Just kidding Are you? That's my preferred style.
I've been on few talks there, did not see all of the uploaded but I'd recommend those: 1. [boost.tmp: Your DSL for Metaprogramming - Part 1 of 2 - Odin Holmes](https://www.youtube.com/watch?v=YLr6_ERNiQY&amp;index=11&amp;list=PLK3T2dt6T1fd6PILMU2lg7K6pWnUKl34S&amp;t=0s) Part 2 was good as well but in my opinon not as much interesting as part 1 2. [Taming dynamic memory - An introduction to custom allocators in C++ - Andreas Weis](https://www.youtube.com/watch?v=FcpmMmyNNv8&amp;index=16&amp;list=PLK3T2dt6T1fd6PILMU2lg7K6pWnUKl34S&amp;t=0s) 3. [There is a Better Future - Felix Petriconi - code::dive 2018](https://www.youtube.com/watch?v=WZdKFlH7qxo&amp;index=3&amp;list=PLK3T2dt6T1fd6PILMU2lg7K6pWnUKl34S&amp;t=0s) 4. [Choosing the Right Integer Types in C and C++ - Dan Saks](https://www.youtube.com/watch?v=IJaa58cfvOw&amp;index=10&amp;list=PLK3T2dt6T1fd6PILMU2lg7K6pWnUKl34S&amp;t=0s) \- not my top but I'd still recommend it. Rest of those which were uploaded might be good as well, I have just not seen them. I'd recommend more, yet not all videos has been uploaded until now. 
Failing to maintain the build and modify/build/test(debug) cycle is my pet peeve. When a codebase is big... If I do not have parts#### that you can work on independently but instead have to build and run **everything** to test any change, something is horribly wrong with my product design **and** the my understanding of said design (I have seen, times over, that people build everything and complain that it's slow, whereas one could just find relevant parts and their tests and work faster with that; or make tests oneself). Then, there's a question of spurious compile-time dependencies. Unless I take steps to avoid them (and there's tooling as well), they will creep in. Finally, there's the question of faster builds through tooling. Precompiled headers and incremental linking help (but see ####), so do the \*.inl files. One can go a long way using a non-optimized retail build and an even longer way using not-entirely-optimized build. Gamedev people who complain about the debug build being too slow do so because they don't have a way to de-optimize the build of the part they care about. Some/many don't even know that's possible.
I got consistently have experienced the opposite; defeating std containers performance-wise and bloat-wise has never been that difficult. The only advantage they have over custom containers is that the interfaces are standard. The caveats can mostly be defeated by strategic reserve member function calls and custom allocators. The bloat will still remain, of course, but even mobile platforms are starting to be fairly resilient to that sort of stuff. Nothing like that matters anymore so that's pretty cool (in a sense that can just hand-waive the well-known axioms like "premature optimization blah blah" and they even actually hold true!) 
Let's say we want to write SIMD stuff.. we are feeding data to ispc compiled function, we want to guarantee alignment beyond the platform/toolchain defaults -and- have custom allocator, we have to layer them like this: template &lt;typename T, typename A&gt; using AlignedVector = std::vector&lt;T, xxx::AlignedAllocator&lt;T, A&gt;&gt;; T = type, A = backend allocator It's nice that the std stretches to this kind of use cases but it's a lot of boiler-plate to fit a square peg into a round hole. We are getting far from vanilla std::vector here. It's just interface at this point, but at least it's a standard one. Yay.. (and this was just for correctness at this point, so that we won't page fault, nothing said about performance yet sans ispc).
Thanks for the update! We are using your library in our C++ project and we love it. It is simple and easy to understand and to use, good job!
Unfortunately I think we can go down the rabbit hole all day. If I saw someone writing a name that clashed with an std class I'd flag that in a code eeview, especially if it gets put in the global namespace. If it's third party code, I'm not really sure what id do, I've never has that issue...
I think keeping std helps clarity.
Hi, I'm a dev. working on the VC++ code optimizer, could you point me to the bug you filled for "very simple optimization miss"? We finally have a modern framework for implementing optimizations, makes the entire process much simpler and faster. Many new optimizations will be added, plus replacing some of the old ones with more powerful and advanced approaches. We're going to blog more about this work in the coming months, until then these two blog posts are an overview of this effort: [Introducing a new, advanced Visual C++ code optimizer](https://blogs.msdn.microsoft.com/vcblog/2016/05/04/new-code-optimizer/) [MSVC code optimizer improvements in Visual Studio 2017 versions 15.5 and 15.3](https://blogs.msdn.microsoft.com/vcblog/2017/12/03/msvc-code-optimizer-improvements-in-visual-studio-2017-versions-15-5-and-15-3/) Thanks, Gratian
I think it's zsh with oh-my-zsh, theme called [Agnoster ](https://github.com/agnoster/agnoster-zsh-theme)
When you see cout &lt;&lt; x &lt;&lt; endl; do you stop to ask yourself if it is the cout found in std? If not, then it is additional symbols on the screen that your brain has to process that contribute nothing to your understanding of the code.
Generally you shouldn't use cout and endl for anything than some dirty debugging, so I would start thinking if they have their own version in a different namespace.
I have no issue with specifying namespaces that aren't std. If you're using a boost alternative to std, then putting boost:: in front of it is fine, but the standard library is called the standard library for a reason, and is the most commonly used. There is a real cognitive cost to putting stds everywhere, a cost that a lot of people ignore, and the benefit is not worth the cost.
I read you loud and clear, but I still disagree.
That should go without saying ... (at least I hope so).
Hi there, I am an experienced C++ developer with more than 10yrs of experience. I have good knowledge of C++/C++11, multithreading, OOP concepts. Along with C++, i have also worked on python, angularjs. During my 10yrs of tenure, i have worked on various domains like Gaming, Investment Banking and Business Intelligence. Along with coding i have also managed small team of 3people. Out of my interest, very recently i have started learning Machine Learning on my own. I am living in India and can consider option of relocating to another country.
&gt; It is an ethical obligation to work to improve our profession. [...] Part of that obligation is to continue to study, to read papers and work through books. Not knowing the history of iota() should not be something to be proud of, but an embarrassment. Oh, come on... It shouldn't be either. Nobody should be *embarrassed* not to know the history of `iota` all the way back to APL. &gt; The name iota() was borrowed from APL. Ken Iverson’s ideas had a significant influence on the development of STL and our profession as a whole. That is why he has a Turing award. Maybe you should lift the "seperation of concerns" principle to real life: as a programmer you don't need to know the full history of a programming language and the languages it took inspiration from to be able to write a game engine in 2019.
I said generic, not complete. I don't disagree with your assessment though. I guess the general problem is that no one is willing to invest the time and face the hardships of getting the paper through the standardization committee for something one can write oneself in a couple of minutes. And of course, whatever you suggest as an api, someone will complain that you did it wrong, because it doesn't support his very specific use case or doesn'thave all the configuration knobs he wsnts. Similar problem with `&lt;random&gt;`
&gt; I don’t know of anyone on the committee who is primarily there to just collect feedback from the users of the language and try to incorporate it, except possibly Bjarne. The fact that many do this regardless, is out of their own sense of professionalism. If you want a stronger say in the future of the language, you will have to sit at the table. I think that might be a big problem. I don't have a solution to this because, as was said, the committee members are in there for their own interest. I do however think that the designers of the language should prioritize the really big problems (e.g. the compile times as mentioned) of the users.
(Not disagreeing, just offering more thoughts.) I've used `iota` a fair number of times, fully aware of what it does, but not knowing the origin of the name. I only learned it a few days ago when I bothered to look it up. For me to say "I used `iota` without knowing the name's origin" isn't quite "embarrassing," but I would be a little uncomfortable if someone asked me the origin of the name when I didn't know. I don't think Parent is trying to say "Not knowing something is a reason for shame." The original quote he's responding to wasn't "I don't know what iota means," it was (paraphrased) "Eric used the name `iota` to be clever and show how smart he is," which is 1) wrong, 2) ignorant, and 3) insulting. This is dangerously close to "celebration of ignorance," (closer to "condemnation of intelligence") which is something you'll see all too often in other fields, like mathematics, reading, and basic computer skills. When asked, many adults will say something like "lul I haven't read a book since high school," "I hated math in school. I was no good at it," or "computers are too complicated for me, I can barely work a printer." As if these things are something to be proud of. I don't think "not knowing the origin of `iota`" is something to be proud of, as Parent says. But I also think *flaunting* your ignorance should be something of which to be ashamed.
&gt; So I will write, and rewrite code often for a couple of weeks before I even attempt to compile it. His daily stand ups must be interesting
You could argue that limiting the namespace scope is much more maintainable code
Overall I agree with Sean Parent’s article. But I have problems with the section you quoted from, too, although for slightly different reasons. Sean brings up this argument as a response to some quotes from the earlier article by Aras Pranckevičius. In the relevant sections Aras mocks C++ for its bad naming in the standard library. And his point is absolutely valid: a function named after a greek letter – `iota()` – is meaningless; a `remove_if()` function that doesn’t remove anything is catastrophic. Sean’s response is fine in itself. The more you become an expert in the language, the more you should know about its history. But as an answer to the problems pointed out by Aras the argument doesn’t hold up. No matter what the history is: those are still bad names. A bit later in the artice Sean writes: &gt; A surprising amount of code that I’ve written in my career is still actively used [...]. A goal for a programmer has to be to look beyond the product they are shipping and recognize their obligation to create correct and efficient solutions and understand that their code may well endure, for good or bad. Here I get confused. Before he seemed to argue against Aras. But the above quote actually agrees with him implicitly. Taken at face value it means that `iota()` and `remove_if()` should never have been given those names.
libh2o
This is interesting. I have planned to replace `std::unoredered_map` with `absl::flat_hash_map`, but I still can't compile abseil in debug mode for my project. Also abseil is broken when used with CPython 3.4. Before I dive in and try out your hash tables a few questions: - Do you have `robin_hood::unordered_set`? - Swiss tables optimize for insertion and lookup, not for iteration. Unfortunately, for the most part, I need iteration. So if your implementation is sometimes faster and sometimes slower, for which of the three use cases does it work best?
If your goal is to write code that is easy to understand by other people, why would you pick `iota` over a raw for-loop that any programmer can understand?
&gt; It is an ethical obligation to work to improve our profession. [...] Part of that obligation is to continue to study, to read papers and work through books. Not knowing the history of iota() should not be something to be proud of, but an embarrassment. Elitist gatekeeping.
Unfortunately I don't support an `unordered_set` yet. It's difficult to answer your question without a benchmark, because it depends on what exactly you do. Iteration with `robin_hood::unordered_map` should be very fast for most use cases, especially when you have a high fill factor. The fuller the better because it won't have to skip empty buckets. The worst case is when insert a million items but then remove all but one element, then iterate this. I think then even std::unordered_map might be faster. It may be worth it to recreate the map in that case.
&gt;I don't think Parent is trying to say "Not knowing something is a reason for shame." That's literally what he said: "Not knowing the history of iota() should not be something to be proud of, but an embarrassment."
&gt;I don’t see the point in even trying to compile until I believe the code for the task I’m working on is correct and complete. So I will write, and rewrite code often for a couple of weeks before I even attempt to compile it. My favourite take of 2019 is already here. Who even _compiles_ these days?!
I guess the committee members aren’t paid (by the committee)? So it’s not straightforward that it’s in their own interest. I wouldn’t wish committee membership on anyone. I know compile times are long for C++, but are they actually worse than other comparable languages? I don’t have much experience outside C++, but I have seen complaints that sizeable Rust projects take time to compile (and a *lot* of memory).
Thanks for the answer. I believe I got the answer I wanted. If you're interested in my use case, here's my benchmark discussion on the abseil issue tracker: https://github.com/abseil/abseil-cpp/issues/223 I noticed that your hash map needs a good hash function, so what is the default? `std::hash`? Should I just bite the bullet and use `absl::Hash` when I give `robin_hood::unordered_map` a try?
Reminds me of how the Greeks felt you could think through any problem if you tried hard enough, and that experimentation wasn't required.
I have `robin_hood::hash` which uses a custom implementation for 32bit and 64bit values, and one for `std::string`. For all other data it falls back to `std::hash`.
In the context of the broader post I read that line to be &gt; "[Criticising the name iota while] not knowing the history of iota() should not be something to be proud of, but an embarrassment. It's a specific example of a more general principle: If you are going to bitch about a decision at least research the reasons for why it was made in the first place.
It might be possible for you to use a [SlotMap](https://seanmiddleditch.com/data-structures-for-game-developers-the-slot-map/) instead of a hashmap. Iteration and indexing will be faster than for any hashmap, but you can't use your own keys. I'm not aware of any good implementation though.
&gt; This is dangerously close to "celebration of ignorance," (closer to "condemnation of intelligence") which is something you'll see all too often in other fields, like mathematics, reading, and basic computer skills. Mathematics is hard to directly compare though because there's such a massive divide between "I nearly failed all my math classes in high school, I'm just bad at math, please help me reset my router" and "mathematics is an amazing functional programming language with terrible function names". The latter is the source of frustration that led to singling out the iota name (didn't Guy Steele give a talk about the problems with consistency in proof notation or something similar fairly recently?). Also, these people are not anti-intellectual. It's a principal engineer at the biggest game engine company in the world and the guy who wrote *the* textbook on realtime collision detection. I agree that `iota` is not that obscure (I learned it from Go "enums"), and people have been rude in particular about it when criticizing the original Ranges post. The criticism folks are trying to put forth is still valid (For example, I strongly agree with /u/be-sc's comment that `remove_if` and erase-remove idiom is a much better example than `iota`). Responding to criticism of the iota name by talking about APL and inclusion maps is kinda proving the point. Most of the time, I'd rather read a layman's loop than combinator soup.
Then he took the blog post out of context. Aras was saying that when reading the code and seeing iota() he didn't immediately know what was going on because he didn't understand what iota() was (this is valid, especially since itoa() exists and the committee knows it). That's a fair criticism. You shouldn't have to go look up ancient programming languages and Turing award winners to understand the code. I took the line as Sean being a bit of an ass. 
I should have read the code. Thanks for the answers, I'll definitely give this a try, but I will need `absl::Hash` too.
Beauty here describes the server source code, (not the actual website) Its a little difficult to explain until you've done it your self. lovely patters often emerge (if it's done well atleast) response handler patterns with with hierarchical chains of responsibility that type of thing. Often a very small amount of source code is able to achieve incredible robustness, functionality and extensibility; do try it.
According to this blog post, compiling code containing C++20 ranges (compared to their equivalents in Rust) is indeed slower. [https://atilanevesoncode.wordpress.com/2018/12/31/comparing-pythagorean-triples-in-c-d-and-rust/](https://atilanevesoncode.wordpress.com/2018/12/31/comparing-pythagorean-triples-in-c-d-and-rust/)
&gt;Not knowing the history of iota() should not be something to be proud of, but an embarrassment. &amp;#x200B; &gt;That any civilized human being in this nineteenth century should not be aware that the earth travelled round the sun appeared to be to me such an extraordinary fact that I could hardly realize it. &gt; &gt;“You appear to be astonished,” he said, smiling at my expression of surprise. “Now that I do know it I shall do my best to forget it.” &gt; &gt;“To forget it!” &gt; &gt;“You see,” he explained, “I consider that a man’s brain originally is like a little empty attic, and you have to stock it with such furniture as you choose. A fool takes in all the lumber of every sort that he comes across, so that the knowledge which might be useful to him gets crowded out, or at best is jumbled up with a lot of other things so that he has a difficulty in laying his hands upon it. Now the skilful workman is very careful indeed as to what he takes into his brain-attic. He will have nothing but the tools which may help him in doing his work, but of these he has a large assortment, and all in the most perfect order. It is a mistake to think that that little room has elastic walls and can distend to any extent. Depend upon it there comes a time when for every addition of knowledge you forget something that you knew before. It is of the highest importance, therefore, not to have useless facts elbowing out the useful ones.” &gt; &gt;“But the Solar System!” I protested. &gt; &gt;“What the deuce is it to me?” he interrupted impatiently; “you say that we go round the sun. If we went round the moon it would not make a pennyworth of difference to me or to my work.” ― Arthur Conan Doyle, A Study in Scarlet
Sean Parent is firm believer in programmers should know their algorithms. iota is succinct and its intentions are clear whereas a for loop could require considerable energy to process. https://youtu.be/W2tWOdzgXHA?t=508
Who need to worry about compile times when you can just do it in your head and only compile once before release? 
Thanks for that. I'm reading the blog post now. One thing I noticed about the post is: object_table[free / chunk_size][free % chunk_size].id = free; And then he talks about division being slow. This line can be optimized with a bit of boilerplate like shown in this article: https://embeddedgurus.com/stack-overflow/2011/02/efficient-c-tip-13-use-the-modulus-operator-with-caution/ Though compilers have got smarter in the previous 7 years.
I love it when candidates have Githubs, especially if the work ranges over a few years. I'm not going to judge you for work you did 5 years ago, but if I can look at that and then look at more recent work and see growth, that's a great sign.
I’ve seen a variation of this. It’s goes something like: "I don’t see the point in even trying to write code until I believe the design I’m working on is correct and complete." 
Though, if that mini project is going to take 10 hours to do a lot of your more senior or viable candidates are going to tell you to take a hike. Companies try this in the Android world all the time. If you're looking for a job, you're interviewing at multiple places. If all of them ask you to do homework that's suddenly a lot of extra crap you need to do, possibly while still in your old position.
This sounds like a much better approach. Design a real-world scenario, instead of expecting a candidate to have memorized some random algorithm. I like it!
Honestly if someone were to ask me to write something like a merge sort right now for an interview I'd tell them no. I don't know how to implement a merge sort, certainly not in any reasonable length of time within an interview. What's more, in my line of work the implementation of a sorting algorithm is very, VERY irrelevant. I don't work on low-end, RTOS type systems, and I don't work on large, highly parallelized data clusters. I expect to be able to hand my collection to a predetermined sort function, and have it work as expected. If asked "what if you really needed sortAlgorithmX?" then I'd say I'd pop over to stack overflow and find a good, well tested, battle-hardened open source library that implements the algorithm, because their code is going to be a heck of a lot more reliable than mine, and good software practices will keep their code decoupled from mine in case I want to swap it out for something else.
Using terrible examples only detracts from your intended point.
I wasn't aware that there is any c++20 implementation of ranges yet. Maybe the post is actually talking about ranges-v3 (a c++11 library emulating c++20 ranges?)
If you compare the actual code of both versions, `iota` is rarely more succinct or clear than a simple, raw for loop. I'm all for using algorithms, but the boilerplate that is required to call the current standard library algorithms make their use really ugly and verbose compared to a for loop.
Yes, something like that. I think there are multiple similar themes.
Lol, who in their right mind starts the design before he made sure his assumptions about the universe are correct and complete?
I've never heard of this guy, but this statement leads me to assume that you cannot trust his advice as "modern" C++. How do you go weeks without even running a unit test? Either you are a horrifically slow developer or you are using a process that is a throwback to the 80s. I notice he never even uses the word "testing". He vaguely uses the word "proven". What, is he doing formal validation of his C++?
On edge cases, it's possible, but my experience is that the optimisations don't hold when the code ages. Custom container classes that previously compiled faster, no longer do because the compiler changed, or someone added a function to OurLightVector that instantiates a quadratic number of templates. Similar for use of said containers throughout the codebase: someone used a custom container in scenario A, so now it's everyone's default without measuring but it's actually slower in all of those cases, but no one is measuring, so on average you're worse off. So, what do you do, write 10 special vector classes for all of these cases and expect programmers to pick the right one each time without measuring? No, they need to think about it, but in my experience this is less beneficial that figuring out something like how to make the data smaller, which will yield better results than any special container. The standard library gets so much attention that you're a fool of you think you can beat it on average. 
That's also the talk where he says, "this for loop is *obviously* an nth_element followed by a stable_partition and rotate with this iterator adapter" or some shit.
Chesterton’s fence
I hope Carl Sagan finally got to eat that apple pie: https://youtu.be/7s664NsLeFM
It really depends on the problem domain and scope of the application. For example, if you’re modeling, something, you want to ensure the model is correct before wasting time writing code for an invalid model. However most client applications do not fall in this camp. 
I’ve come to the same realization. I just use for loops when I can mostly because they are idiomatic and also I can easily reason about their performance. 
I'd give a million dollars to be allowed to work like he does. What? You estimate this task will take five points?!!?? Oh my gosh!!!!!! You can't possibly be trusted with that!!!! You **must** chunk it down to smaller Jira tasks otherwise our collective heads will explode!!!!!!!! I hate Agile with a passion and yet I'm deathly afraid it's the "democracy" of software development. i.e. it's bad except for all the others.
I’ve said this before but Pythagorean triples was a really shitty example to use. 
Yea he seems to imply it’s unethical to just know enough to get a job done well. 
The “obvious” is tongue-in-cheek , but he did transform a complex loop into an algorithm that is far easier to understand - once you’ve read the documentation of that algorithm, more correct and faster.
Need to build a real life to scale simulation of the game before even thinking about writing code. 
I remember a talk from (I think) Uncle Bob that contained, paraphrased from memory, "I've seen a lot of experienced and productive engineers come in and say yeah, I know how to use a debugger. They're great. But just once, I'd like to see an experienced and productive engineer come in and not know how to use a debugger." I'm not saying that I jumped on the bandwagon there instantly, and definitely may not agree with it in such strict terms, but there's an interesting thought experiment there in working out what personal or industrial practices need to improve or evolve in order to be able to satisfy that wish. And then there's the key question: with all that in place, would one be a better developer for it? I'm not going to toot my own horn here: the sign on my desk would say "\[1\] day(s) since last use of gdb". But perhaps we should give more credence to the thought that the debugger is the \_last\_ line of defence and not the first.
I mean, Sherlock Holmes was also a big fan of cocaine, so I'm not sure how much we ought to look up to him... ;p
It's not a terrible example. 
I assumed so, but I also assumed (hoped?) that the intention for that example was to illustrate a point at which doing that transform is no longer necessarily a net positive.
Agreed—although in this case, I think he's just a guy whose in a position in which: * He gets to only work on the difficult, interesting problems. * He's not just interested in getting it to work, or getting it to work efficiently, but also in directing code structure and architecture for a large engineering team, and presenting ideal(ish) interfaces. In other words, in his specific position, mulling over design decisions is actually the majority of his work.
While the STL is a lot better today, historically, gamedev has had platform compatibility and memory allocation issues with the STL, to the point where things like EASTL came to exist. Gamedev is one the domains where you write architecture specific code, sometime even work on bare metal, and you have very tight memory and performance budgets. The STL isn't always fully optimised for this.
Arthur Conan Doyle himself also had some [interesting beliefs](https://en.wikipedia.org/wiki/Arthur_Conan_Doyle#Spiritualism,_Freemasonry)
I simply write my whole application without testing and ship the source code without compiling, it's guaranteed correct Is it just me or is about 50% of all programming advice unbelievably terrible?
&gt; You shouldn't have to go look up ancient programming languages and Turing award winners to understand the code. But you should look up the history if you are going to go around bitching about decisions and sarcastically insulting the people who made them. Not doing so makes you look like a fool.
But the point is that the name isn't immediately obvious to the average programmer, and there is already an itoa(). That makes it a bad name, which was the point of the post. He could have put a footnote in with the actual meaning and history, but not doing so does not invalidate his argument.
Also my preferred style. Although I dont mind people putting it with the type. But I dont understand why people put it with the variable.
True, but in every other version of the code on that blog C++ wins. By those benchmarks we should all be using D!
Yes, I’m pretty sure that is the case. We can only hope that the C++20 ranges will compile faster (and generate better code).
remove_if has always bothered the hell out of me. First time I saw the pattern, I thought it was proof positive that modern C++ is garbage. I still do.
I wrote std::vector, std::list, std::map replacements in 2001 with identical interfaces just to see if could defeat the performance (as proof of concept, resulting from pretty much identical argumentation we have going on right now). They were faster in every situation and made it into the library and were in production for 10+ years. Drop-in-replaced with std equivalents in 2015 and the only visible effect is larger binaries. Some of our customers have quite detailed due diligence process for any 3rd party libraries and we were notified of regression (!) because of this change. Why did we do it, then? It was preparation work for migration to a new low-level framework. In hindsight should just kept going with custom containers. Before the 2001 proof-of-concept work, the customer containers existed for legacy reasons. Before the implementations started appearing in libraries shipping with compilers there was nothing else to do. It took a while for the quality to catch up in tool-chains we were using (primary ones at the time were Visual C++, GCC and Intel C++). The difference between implementation quality was just too much. Simple stuff like vector growth policy (GNU doubled size, Visual C++ / Dinkumware did grow by 50%) varied so much that it made real-world difference with the computers with much more finite processing power from current generation CPUs. Remember the 486? 386? 68000? R4000? Those were the CPUs we were dealing with. We didn't have CPU time to fuck around with back then. These days we got away with a ton of bullshit we didn't back then. Anyway. The Dinkumware implementations ran circles around anything the OSS side could come up with at the time, which was fantastic on Windows but on other platforms and consoles we would have to pay for a license. Any extra licensing or royalty fees were totally out of the question for trivial stuff like storing shit in a tree, linked-list or contiguous array-in-heap. Thank you, no thank you. :) What has changed in past 20+ years? We have more headroom in memory and CPU side that little things like these simply do not matter. If we are bottlenecked by CONTAINER IMPLEMENTATION we are probably doing something horribly wrong. It simply doesn't matter and so it makes more sense to go with standard interfaces, if not implementations. But it's folly to claim that they do have peak of performance, except some exotic corner cases. That simply isn't true. 
&gt; Gamedev people who complain about the debug build being too slow do so because they don't have a way to de-optimize the build of the part they care about. Some/many don't even know that's possible. That's a hell of a generalization. Most of the ones I know don't complain about the performance in debug because they're careful to keep it reasonably fast - hence the rationale for avoiding certain parts of the language. They also know you can disable optimizations but also know that it can take several minutes to reproduce a problem only to find out you guessed wrong about the source, have to stop and disable optimization in more code, then rebuild and start all over. 
I understand all of this; I was a game engine programmer for 15 years, and I said then, and continue to say now, that these are weak arguments. The memory allocation problem can be solved by using a stack based allocation system for tagging and other options, such as alignment, so that allocators don't need to be passed in everywhere. Forcing the API to take allocators everywhere is optimising the edge case at the cost of the general case where it literally doesn't matter. Debug performance is often touted as a problem, but games have NEVER been playable in debug even when the code was mostly C. Ever. We've been using tricks such as unoptimising only specific files or libs for as long as I can remember; this is not new so blaming the C++ standard library for this is disingenuous. The other pervasive argument is the need for a common implementation, but STLPort has been available since something like 1999 with support for most compilers, so again rolling your own is not necessary. This trend continues today by shunning boost too. Why is every company writing their own flat_map and small_vector and string_view when they're all available in boost? It makes no sense. People will say "boost compiles slow." Well, *some* of boost compiles slow, so don't use those bits, or use them with care, but the container library is not one of those to be concerned about. 
Just a recent example of "exotic corner case": https://github.com/t0rakka/mango/blob/master/source/mango/core/buffer.cpp The mango::Buffer class was backed up by std::vector internally just a few weeks ago. I was doing some (as a hobby/fun, not for work) project of compression tool-kind-of-thing as as you know when doing something for FUN things easily get out of hand and you go a bit too far with optimizations. You know how shit like that goes down. So I was there optimizing compression of one data set and started at 6.0 seconds for 2.2 GB of data with a specific configuration. I now have squeezed it down to 2.7 seconds and and next 100 ms are really, really hard but we'll see about that later. When I switched from std::vector backed Buffer to the current one above, that made 400-500 ms difference with 2.2 GB of data. That might not sound too much but for fun project it's worth it. When drag racing only zero's the limit.. well.. besides the hardware, of course. The use case here is very limited and trivial, I admit that. The "copy" is just memcpy, since I am dealing with raw bytes only. The std::vector has to use template meta programming to classify types if they can be moved, are trivially copyable and what not, and apply cool zero-cost abstractions to select implementations based on the type traits. But the workload is *essentially* the same and here we win by 10% or so with code I whipped up in one quick sitting. I didn't work on it for 20 years like the std::vector has SUPPOSEDLY been optimized. I am not saying you are one of those guys saying that "std::vector is optimized so well that it cannot be beaten", as much as I can see your argument is that it's not worth it trying to beat it as most of the time the replacement is worse than the original it is trying to replace. But the way I see it it can be beaten just sitting down and writing replacement FOR A SPECIFIC TASK in about 30 minutes of coding (plus all the bugs that there might be, heheh..) 
uhh..... what's the problem with remove_if? according to the documentation it does exactly what I would expect so I have to believe I'm missing something. http://www.cplusplus.com/reference/algorithm/remove_if/ 
It's not sacrilegious so much as a wasted effort, in most cases. Unless you absolutely can't use the STL (due to your platform) or you're trying to learn how to implement the STL, there's no reason not to use *any* of it.
I mostly agree with everything you've just said, or at least concede that the argument was stronger 15 or 20 years ago. The problem is that in the games industry these arguments are still being made, and they largely don't apply anymore. &gt; But it's folly to claim that they do have peak of performance, except some exotic corner cases. That simply isn't true. That's not what I said, what I said (and I think we agree on this) was that you're foolish if you think you can beat them on average. And with this I mean in a large application, with millions of lines of code all changing weekly and interacting with memory and cache in random ways. Microbenchmarking won't help you here, the only thing you can do is possibly optimise sections once the code is stable near ship, but then you might be stuck with that optimisation, which may have actually regressed, during the next product cycle. 
I often see things I don't understand and look them up, why is iota any different?
It doesn't actually remove anything from the list. It sorts the list so that the "removed" elements are at the end. Then you need to use erase to actually remove them. Weird choice but it has nothing to do with "modern C++" - it's been part of the standard library since C++98. 
I used \`iota\` for 20 years but never bothered to look up where that weird name came from. 
Considering that ranges-v3 iirc has to emulate concepts with one if the slowest tmp constructs there is (SFINAE), I would be very surprised, if a native implementation wasn't much faster. I can't speak for the code gen however.
It doesn't actually remove the items from a container. It just rearranges them and inside it and you have to call the erase function on the container to complete the operation. 
Does boost now work on consoles?
&gt;What, is he doing formal validation of his C++? To an extent. I doubt Sean is using Coq or Agda for formal proofs, but I'm pretty sure he could prove the correctness of the code that he writes. It's not actually all that hard... If you start with the STL, you have building blocks of formally verified algorithms. Validating uses of that is largely a process of ensuring the logical flow of the program by connecting the postconditions of one line satisfy the preconditions of the next and that you've properly managed your side effects (iterator invalidation, guards on shared data, etc.). This is one reason Sean argues for straight-line code -- it's easier to verify. Once you add loops and conditions, verification gets harder. Hence "no naked loops" and "small verified functions". 
oh I see. that's a bit strange but I can see why it would be useful as it guarantees no unexpected allocations.
&gt; "lol who compiles" That's such an outright dishonest paraphrase of an out of context quite that I don't know where to go from here, discussion wise. You've clearly made up your mind. To everyone else: **that's not what Sean Parent says at all.**
This is what happens when I'm not paying attention for a couple weeks. I'm never going on vacation again. 
Yes!
You have to admit that the Buffer implementation was pretty straightforward and vanilla. It's just hard to explain to myself how std::vector manages to burn cycles on something that trivial. What on EARTH is it doing? (the question is hypothetical, I do know what it is doing by looking ;) The effect of cache is mostly about data layout and access pattern. Don't get me started in tiling texture data or AoS vs. SoA nothing good comes out of it. Here's a blog post I wrote about effects of cache on memory layout: https://t0rakka.silvrback.com/software-rasterizer The downside of that post, not in hindsight, is that it does not talk about the performance versus LINEAR memory layout for the buffers and textures. The TL;DR version is: 4x4 block of data is stored in 16 consecutive memory locations so that the data is resident in one single cache line (the buffers are aligned to cache boundaries). Even in this situation we are STILL limited by the memory bandwidth!!! That is how insanely fast the ALUs and SIMD units are on modern processors. I can afford to run 100+ instruction "fragment shader" "for free" before experience any adverse performance side effects. That's insane. 
&gt; auto serialized = data::deserialize&lt;my_struct&gt;(buf); Shouldn't it be `auto deserialized`?
It's good advice for both sides of the table. If you're the interviewer, you really want to see what it's going to be like working with this guy. Well, the candidate too, really. A lot of my recent interviewers seem to be in tune with this, and you can really feel it going well when you involve them in working through your problem. I haven't had one of the dick-wavey "I'm cleverer than you!" ones in quite a while.
I guess alexandrescu also called his book modern.
I feel like chunks of the standard library were designed before we had a really good feel for OO programming and design patterns, or even idioms like RAII. Now we're stuck with stuff like iostreams because backward compatibility. That's all well and good, but I really wouldn't mind deprecating some stuff in the standard library over the course of a decade or so and replacing it with more recent offerings from boost or elsewhere.
Yeah, what the hell is that thinking? It's impressive to me that you can take an obvious negative and somehow morph into a positive It's funny that this doesn't even address the problem. One being able to only compile sporadically doesn't justify slow compile times. The two are unrelated Even if everyone would follow this guideline, it would still only be natural to ask for fast compile times 
Of course it does. The boost test matrix is something like 100 combinations of compilers and platforms. Some of the internal complexity people complain about is precisely because of this compatibility. Some games companies *are* using it without issue. 
Really? You expect this: vector&lt;int&gt; vec { 5 }; remove_if( vec.begin(), vec.end(), ( auto x ) { return true; } ); vec.size(); // returns 1 It doesn't remove anything! It's madness. If anything, it should be called move_back_if. And all because we're still trying to prop up a truly woeful idea in iterators. Containers in C++ are the least clean, least consistent and most confusing containers in any language, and it's largely because everything has to go via iterators. Can't just have contains() like everyone else, only find().
TIL there's a .rocks top level domain
There's a lot of typos in general.
You should definitely be using D ;) At the very least, give it a whirl and see if you like it or not.
\&gt; I know compile times are long for C++, but are they actually worse than other comparable languages? &amp;#x200B; Yes. I was going to post a link to my blog from earlier this week but @soundslogical already did. AFAIK, the only language that is slower to compile than C++ is Scala.
Some functions aren't important enough to deserve names.
In C it's common practice for callbacks to take a `void*` pointer that by convention is called the "context". This is equivalent to C++ lambda captures, and in fact, the only reason C++ has syntax for specifying captures has to do with lifetimes and performance. In any other language that I'm aware of the captures are handled by the compiler (usually because the GC eliminates the need to care about lifetimes, or in Rust's case because the lifetimes are tracked). So: if you already have a mechanism for passing "callbacks", I _hope_ they take a context pointer (otherwise they're not very useful). Just use non-capturing lambdas in that case and cast the context pointer to whatever data the callback is expecting.
Yes, you are right. Those are some convenience macros. But you can of course copy&amp;paste the code generated by the macro if you don't want to use macros at all. When writing the 'no macros' part, I meant that you don't need to declare your struct using BOOST\_HANA\_DEFINE\_STRUCT, or something like this to be able to iterate the member variables. I see it more as a serialization library (which works without macros in the client code) than a reflection library. I just wanted to share the underlying reflection technique because I think that there are many more use cases for it. &amp;#x200B; &gt;I'm nitpicking, but shouldn't it be `auto deserialized`? Yes, that's an improvement. :-) Updated the code. Thank you!
I was referring to people using std::abs as abs (they wanted it to use double without truncation), but yes I agree.
Sorry for that. Feel free to help me (private message, pull request, comment here, etc.).
I would expect the design decision was performance related, not iterator related. 
&gt;Oh, come on... It shouldn't be either. Nobody should be *embarrassed* not to know the history of iota all the way back to APL. Even there the name was *arbitrary* \-- because it was *arbitrary* in math in the first place. If you wanted to know the origin of the algorithm you could simply read the cppreference page on \`std::iota\` ([https://en.cppreference.com/w/cpp/algorithm/iota](https://en.cppreference.com/w/cpp/algorithm/iota)). The amount of effort it took to find that was literally typing "std::iota" into Google (or Bing) and then actually reading the page to find the note on the history of the name. (And the note has been there since Feb 2014 -- I checked in case anyone thought it might have been added as a result of this discussion.) If you want to know more, there's a thread to pull on. That either demonstrates: a profound lack of curiosity, an inability to find and assimilate information, simple laziness, or an affection for hyperbole. Reread Sean's article. That comment is made in the context of giving back to the community as a matter of professional obligation. It's easy to stand on the soapbox and shout angrily about the things you don't like, but it's not professional, and it's certainly not constructive. It takes a lot more to stand on the shoulders of others,\* but we're all better for it. \* I'd have used "on the shoulders of giants", but it seemed cliche -- it's kind of a corny sentence anyway.
&gt; The name iota() was borrowed from APL. Ken Iverson’s ideas had a significant influence on the development of STL and our profession as a whole. That is why he has a Turing award. The “ι” symbol was likely chosen because of its use to represent an inclusion map in mathematics. (...) Not knowing the history of iota() should not be something to be proud of, but an embarrassment. So what you're saying is - Ken made a mistake. Now we cannot learn from it and have to repeat his mistake - and feel embarrassed for not knowing its history? I feel like I'm taking crazy pills.
**Company:**[Stevens Capital Management LP](https://grnh.se/f330a6f81) **Type:** Full time **Description:** Stevens Capital Management LP (“SCM”) is a registered investment adviser that manages a multi-billion dollar hedge fund that has been in business for 30 years. SCM specializes in the rigorous development and disciplined implementation of empirically based quantitative trading strategies. Our highly productive team works in a fast-paced collegial environment, utilizing extensive data sets, technology and the scientific method to devise and employ trading strategies throughout the world’s most liquid financial markets. **Location:** Philadelphia, PA **Remote:** No **Visa Sponsorship:** Yes **Technologies:** C++, Linux. Perl, Bash, CSH, Sybase, SQL Server and Oracle is a plus. **Contact:** Please apply [here](https://grnh.se/f330a6f81)
But isn't C++ actually forking or fragmenting? The C++ core guidelines discourage the use of pointers and C compatible idioms. The Google C++ guidelines discourage use of exceptions, but supporting exceptions is essential for using RAII memory management correctly, and vice versa. I am sure there are cases where the same code means different things in different C++ versions, for example when using move semantics and smart pointers. Surely, one can still compile and build code written in different idioms, and link all that together, of course there is still a common API, but there are probably not many programmers which understand all of C++17. That means that larger organizations probably need to put restrictions on which language features are used, like Google does. And every organisation will do it in a somewhat different way. On the other hand, C++ seems like desperately absorbing features from functional programming languages, certain Java features, and so on, so there is also an enormous pressure to further extend the language, in order to stay competitive with more modern languages. And with each new feature, the interactions between features become even more complex, you see that when you look at Scott Meyers last C++ book. I can envision some point in the future where maintaining compatibility between different idioms becomes more costly than allowing a de facto language fork.
"How vector&lt;bool&gt; saved us from Nazi Germany"
To be fair, coding a lot and then having it compile the first try is the most confidence-boosting thing ever.
No, rather that it should have been imported as a unicode function name. The small i iota is a good choice; the name iota is confusing and lacks the good features of the unicode small i iota. Wait, that's insane. But still, I think, better than std iota. 
Having read this thread, we all know std::iota. So why would you prefer a raw loop rather than iota? iota gives you a smaller mental burden, among other reasons due to the fact that you do not have to maintain any loop-variables.
The advice in the blog post is: read twitter, focus on diversity and inclusion. Thumbs down. if you want to learn more C++, here are two excellent concrete starting points: “Make Classes Great Again! (Using Concepts for Customization Points)” https://www.youtube.com/watch?v=WsUnnYEKPnI “Get rich quick! Using Boost.Beast WebSockets and Networking TS” https://www.youtube.com/watch?v=7FQwAjELMek These videos are for the average C++ programmer, designed to be clear and straightforward with easy to read slides, and to teach you new ideas that you can use right away to help you in your career or personal projects. Also, don't snitch.
Quite. "It was hard to write, it should be hard to use".
This is also what I expect. I have heard that using concepts do provide a significant speed up in compile time.
The problem with D is that it is garbage collected.
&gt; Really? You expect this: I sure do, because I understand that there's no other way to implement it using just iterators. &gt; If anything, it should be called move_back_if. Can't do that either because the contents at the end of the container are undefined once running it. I do agree that remove_if is misleading at first, but one only needs to see it once to get it. I can not think of a better name considering what it does. Do you have a suggestion that actually conveys what it does? &gt; And all because we're still trying to prop up a truly woeful idea in iterators. The iterator API is the thing that lets me optimise code that would be otherwise very difficult using containers as they are in other languages, so I think it's brilliant. 
&gt;Do you have a suggestion that actually conveys what it does? From the top of my head `prepare_for_removal_if` would be honest; a bit longish, maybe, but then again it’s semantics are quite complicated.
Aww, thank you! I appreciate the call out. Sol3 is around the corner, I hope to publish soon...! But the documentation is so much efffoooort wdwadhwajkd. The good news is, the tutorials will be a lot more thorough now, which will hopefully help newcomers. I've walked a bunch of people through the process of getting sol2 in their codebases or from a for-fun spin-up project. It's really hard when they lack understanding of how to build Lua, so I think I need to write some tutorials on how to do this too. ... It's certainly a lot of hard work, though.
Yes, complaining is not constructive, but this judgmental attitude is equally unconstructive.
[he also doesn't take the 2 minutes to setup his blog](https://sean-parent.stlab.cc/about/) 
Thanks for the reply - I PM'd you about the issue
Most console platforms have heavy NDAs. How are these in boost, and where are the results published?