Casting away constness in that case is UB and its your own damn fault if it fucks up.
It's only UB because the compiler _can't depend on the variable being const_, which is the point.
OK, boost::optional or std::experimental::optional, etc. The thing that works now, doesn't work for non-PODs.
Generally, quads are sufficient, I think. Net's decimal type is an example of this,and what they recommend for money handling. Of course, I think they also provide a ratio type too, if that's any better. 
We all appreciate your hard work, Jens.
Well, that takes longer then expected... hope to have it up soon...
I have done big complicated embedding projects using both Perl and Boost.Python and I really wish it was more widely counselled against online. These languages are not made for embedding and are inevitably a pain in the ass as soon as you try and do anything complicated. You really need to have a list of very strong reasons not to use Lua or Guile or Squirrel or TCL or whatever, and instead go for Python/Perl/Ruby. These latter latter options are really not made well for the purpose and you are making your life harder for no reason.
This might sound like a dumb question, but how do I install pybind11 (for Bash for Windows)? 
Looks neat but neither the image nor the text really explain what this is, unless maybe if you know all the context, which I don't.
Personally I'd use [Node Addons](https://nodejs.org/api/addons.html). Allows you to write native modules in c++ that can be used in a nodejs server. Nodejs is pretty easy to pick up (it's all javascript), and it's got a nice little build system and API for making the modules with.
It's header only. Just copy the include dir https://github.com/pybind/pybind11
The point of the exercise is to allow traders, who don't know C++, but do know python, to develop their own strategies in python whilst still leveraging all the existing C++ infrastructure we have already; connections to markets, backtesting suites, position management, order management, risk management, parameter storage etc etc. We have an entire ecosystem built in C++ which we want to use. We're aware that python will be slower than native C++ code, but that's the trade off we're willing to make - empower the traders to develop their own strategies, instead of requiring them to use C++ and block their progress until IT resource becomes available. Whilst the performance impact is a trade-off we're willing to accept, we want to minimise that as far as possible, hence preferring to embed python rather than use an out-of-band process and some form of IPC to communicate.
I imagine in FICC it could be a big issue.
Or better, add as git submodule.
Those are fair points, but I was presuming we were discussing "change via the programmer" - not by random chance. Const is a basic thing the compiler cannot enforce, so relying on it for optimizations is a poor use of time - which is really the pragmatic angle of my argument. 
"Strict aliasing is a basic thing the compiler cannot enforce, so relying on it for optimizations is a poor use of time" "restrict is a basic thing the compiler cannot enforce, so relying on it for optimizations is a poor use of time" etc :-)
Thanks!
Nope, terrible writing. Sorry author, nothing personal, I just don't get your point.
 int x; const int y; void f(int const &amp; ref); main() { f(x); f(y); assert(y==0); } `f(x)` may change `x` (via `const_cast`, for example). That's allowed, and compiler can't assume otherwise. `f(y)` _might_ change `y`, but if it does, it is undefined behaviour, same as doing `(char*)0 = 'D'`. The compiler can assume y is always 0. If you think compilers should not make assumptions because "programmers might do it anyhow", consider: for (int i = 0; i &lt; 10; i++) f(x); // yes, x, not i The compiler can put `i` into a register and assume no one is writing to the random memory where `i` lives - even though programmers might do it anyhow.
Boost.python still requires manual calls to `Py_Initialize/Py_Finalize` instead of a more user friendly C++ RAII approach. (I know that the boost.python docs say not to call `Py_Finalize`, but that's a bug which was never fixed. It should be supported.) Pybind11 has a C++ `object` class similar to boost.python's, but it's not quite as powerful. The basics are supported: item and attribute access, function calls, importing modules, casting back and forth. Pybind11 also has some nifty features like calling Python functions with keyword arguments from C++: http://pybind11.readthedocs.io/en/latest/advanced/pycpp/object.html#calling-python-functions
Wouldn't it be possible for /u/STL to just place #pragma loop(hint_parallel(0)) in the library for std::execution::par algorithms and #pragma loop(hint_parallel(0)) #pragma loop(ivdep) for std::execution::par_unseq?
Great to see some coverage of rxcpp. We need more of that. I really like the notion of *distributed in time* (rxcpp) versus *distributed in space* (range-v3).
**Ten** decimal places? Holy crap! What sort of instruments need that? (The first one that comes to mind is Bitcoin)
People looking in this direction may also want to check out [SWIG](http://www.swig.org/). It supports a good many languages in addition to python and uses its own interface files rather than requiring you to modify your project's source code. I've been using it a bit for a project that I want accessible in multiple languages and it works quite well after getting used to it. 
Yup, I was really talking about double, stored as IEEE 754 in 64-bits, and not about floats. The video I linked to goes into entertaining detail about it, and I highly recommend it! But briefly, you run out of bits. The floating point is really clever about repurposing the bits it has - either to represent large values or to represent high precision. For example, if you're trying represent a large number, such as the largest unsigned 64-bit number (call it "MAX"). We've used up all 64-bits of the storage, right? What happens if you want to add 0.1 to that number to get "MAX.1"? We don't have any more bits! (Note: This is not how it works, but it's the best metaphor I can think of near midnight.) My point is that with a finite number of bits, it's hard to represent both large values and high precision at the same time. So the max number of digits changes after the decimal, depending on where your value is along the number axis.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/5gzbf5/best_way_to_link_c_backend_to_webapp/dawz2sv/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Am I the only one that ignores any post/article/code that has variable names with $ within them? Because you don't want to know what other things are going to be compiler extensions they are using and make it unusable.
I asked the author on this, and it seems to be a naming convention for things you can subscribe to. And $ in an identifier not sure if thats legal, at least GCC did compile code with it when I tried...
Depends on whether you need the Python language, or you also want to use the standard library of stuff. You can use the core language without the extra stuff, but if you want to be able to import all the usual things, you'll need to supply them. It's probably possible to hook the import and have it pull from a file embedded with the executable as a resource, but you won't get it for free. (And there may be licensing implications if something in there is GPL. You'll need to make source available anyway...)
Saying `fullscreen = 0` is unnecessary because enumerations (both unscoped and scoped) start at zero. `break;` after `return expr;` is especially unnecessary, and is significantly bloating the switch syntax. (In fact, in the final form, `default:` can just return, instead of breaking and then returning. This will make stuff line up nicer.) &gt; The first has a pretty easy fix; tell the lambda what it will return so the compiler can just sort that shit out for you; Sure, give the compiler all the credit, even though it's the Standard Library that had to provide this feature to you. :-P (The compiler deserves some credit for suffering at the hands of the STL implementer, though.) `return { {}, {} }` is unnecessarily complicated (it'll construct temporaries and then copy-construct them, according to my brain-compiler). Better to say `return {}` which default-constructs the pair directly. Your `invokeOptional()` isn't perfect-forwarding the args. It's also taking its callable by value. And it assumes the return type is (implicitly convertible to) bool. `(*(it-&gt;second))` has an inner layer of unnecessary parens (`-&gt;` binds most tightly, deref less so, although perhaps not everyone is familiar with that) and an outer layer of especially unnecessary parens. There is a `(void)` abomination in the code. &gt; `static MSG msg;` I don't know why this is static, but it looks extremely suspicious. `WindowMap::iterator it = s_WindowMap-&gt;find(wnd);` is missing a classic opportunity to use auto.
There's a fair amount that's changed in the language itself as well. I still think the quickest, easiest route to programming well in modern C++ is going to be *Accelerated C++* followed by a "what's new in C++11/14/17" kind of book. I'd love to recommend an alternative, but to my knowledge there is none that's comparable.
How do most of the traders know python? I know a trader and he doesn't know jack about programming.
Gatekeeping and politics appear to be a big reason. [From Bjarne Stroustrup himself](https://isocpp.org/blog/2016/02/a-bit-of-background-for-the-unified-call-proposal): &gt; To my surprise, many people came out strongly against x.f(y) finding f(x,y) – even if member functions were preferred over free-standing functions by the lookup rules. **I received email accusing me of “selling out to the OO crowd”** and people whose experience and opinion I respect insisted that x.f(y) finding f(x,y) would seriously compromise their ability to design stable interfaces. I think those fears are greatly exaggerated, but I could be wrong. Also, I prefer the dot syntax in some cases; for example, I find x.f(y).g(z) more readable than g(f(x,y),z). **However, there was no chance of acceptance of a proposal that included x.f(y) finding f(x,y).** Maybe modules will eventually help here. Furthermore, David Vandevoorde pointed out that because of the two-phase lookup rules having x.f(y) find f(x,y) would complicate the task for compiler writers and possibly be expensive in compile time. Language purists helped press it out of consideration. They fail to realize this would have actually *encouraged* the use of non-member functions.
We did a python course for the traders, so that's a large influence. Should probably read "of any languages the traders know, python is the most prevalent"
Looks like it's to make this more consistent: &gt; “`export import M;`” and “`export { import M; }`”, With the current draft you have `export module M;` but `export { module M; }` does something completely different (is a syntax error?).
The whole LEWG discussion was really interesting! I liked Niebler's deduction guide solution, and how attached people were to 'lock guard' :)
Reminds me of `__declspec(noinline) inline int foo()` (where we want inline for the linkage semantics but never want it actually inlined...)
It's a GCC/clang extension.
But you can also call it as `(**************************cosine)(1.0)`;
/u/foonathan Nice article as always. I would have preferred list constructors + uniform initialization to use double brace syntax (`vector{{1, 2, 3}}`, `vector({1, 2, 3})`). I never realized that the solution to that was so easy. And I've noticed the discussion over move support, so that's nice.
Ok, so negligible risk of having a "should have used the *other* one"-moment later on. And on second thought, just the `11` probably means that this project has more enthusiastic users and contributors than "pybind03". And thanks for the pointers, I'll give it another try!
Great article. I'm not a huge fan of `std::initializer_list` for all the reasons you mentioned - I think that variadic templates are almost always a superior choice. &gt; If you want a truly generic initializer list, use a variadic template and static_assert() or SFINAE that the type matches [...] Here's a *"trick"* I learned from [Piotr Skotnicki](http://stackoverflow.com/a/40015608/598696) on StackOverflow. Let's say you want all of your types to be `int`. All you have to do is define a `int_t` type alias that always evaluates to `int`: template &lt;typename&gt; using int_t = int; Then you can use it like this: template&lt;typename... Types&gt; void func_impl(int_t&lt;Types&gt;... ints) { /* ... */ } template&lt;typename... Types&gt; void func(Types... xs) { func_impl&lt;Types...&gt;(xs...); } This allows implicit conversions and gives errors similar to the following one: &gt; prog.cc:8:26: error: no matching function for call to 'func_impl' &gt; void func(Types... xs) { func_impl&lt;Types...&gt;(xs...); } &gt; ^~~~~~~~~~~~~~~~~~~ &gt; &gt; prog.cc:12:5: note: in instantiation of function template specialization 'func&lt;int, nullptr_t, int, int&gt;' requested here &gt; func(1, nullptr, 3, 4); &gt; ^ &gt; &gt; prog.cc:5:6: note: candidate function [with Types = &lt;int, nullptr_t, int, int&gt;] not viable: no known conversion from 'nullptr_t' to 'int_t&lt;nullptr_t&gt;' (aka 'int') for 2nd argument &gt; &gt; void func_impl(int_t&lt;Types&gt;... ints) { /* ... */ } It is much nicer when you already have a type pack, as seen in the original answer on SO.
Technically, you have a point and your example is correct. I should qualify my old statement by saying that is it not *always* possible to move from a const variable. In your code the cost of moving and the cost of copying are the same. However, for RAII (think `std::vector`) they are not. When moving the ownership of a heap-allocated chunk from one container-instance to another, you have to be able to null the old reference. Thus the variable you move from cannot be const; and it isn't for `std::vector`s move-constructor.
Unfortunately, the syntax is beyond fixing now. The problem with the fix suggested in the article is that it fixes the syntax, but only does so locally. Having the behaviour be inconsistent between standard library and some third party libraries is even worse than the consistently "bad" behaviour.
Well, there are plans for STL2 so it can be fixed there somehow.
I hope that http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0431r0.htm makes it. Its rules seem more consistent to me than the proposal it is based on.
`std::initializer_list` is the same regarding the length. That's why I recommended variadic templates as an alternative.
Yeah, the current state of affairs in C++17 (http://wg21.link/p0145) looks half baked to me. But it would be interesting to see the performance implications of P0431R0 (,say on SPEC).
That is a lot of boilerplate though. Not sure it's a sure gain of you do this a lot. Please don't even suggest using macros to reduce the boilerplate.
Well, you could use a variadic macro to reduce the boilerplate. */s* In all seriousness, the alternative is something like this: static_assert(std::conjunction&lt;std::is_same&lt;Ts, int&gt;...&gt;{}, ""); *(or `is_convertible` if you want implicit conversions)* By the way, [when you already have a type pack](http://stackoverflow.com/a/40015608/598696), I think that this technique is objectively cleaner. Another advantage is that using `int_t` [makes overloading trivial](http://melpon.org/wandbox/permlink/5oQc5PNPwWZumcvV).
&gt;If any of the clauses can be guaranteed to NOT be true then the destructor does not need to be virtual. There are several common cases where this could happen. For example: &gt; (...) &gt; You are following the Rule of Zero I would argue that this isn't the case, because rule of zero states that destructor in your classes should be default. But default destructors still are probably doing something - ie calling destructors of members, which perform resource management. Personally, I would rather staple virtual destructor on every base class, rather than debug potential memory leakage, or worse.
Actually I've managed to get it working with pybind11. [Posted it here](https://www.reddit.com/r/cpp/comments/5h7avu/embedding_python_in_c_with_pybind11/)
They're different tools for different jobs.
`wrapper&lt;T&gt;::wrapper(T const&amp;)` binds a temporary but does not extend its lifetime, so `initializer_list&lt;wrapper&gt;` must always be a temporary and never a named variable. It cannot be used in a range-`for` sequence, either.
Please elaborate on the lock_guard discussion! 
Hmmm, with concepts I expected // defined in Ranges TS template &lt;class T, class U&gt; concept bool Same = std::is_same&lt;T, U&gt;::value; void func(Same&lt;int&gt;... args) {} func(1, 2, 3, 4); to work, but apparently it doesn't. The slightly more verbose but theoretically equivalent template &lt;Same&lt;int&gt;... Ints&gt; void func(Ints... args) {} works fine though, so this may just be an implementation bug in the current GCC. 
As far as I know, only MSVC currently evaluates arguments right-to-left. All other compilers already do it left-to-right. So I don't expect significant changes in performance. (And by as-is rule if there i no visible change compilers can still order the computation whatever order they prefer).
With concepts, you could use requires with fold expressions and `std::is_same` this way: template &lt;typename T, typename... Ts&gt; requires (std::is_same_v&lt;T, Ts&gt; &amp;&amp; ...) ctor(T&amp;&amp;, Ts&amp;&amp;...) { } It will ensure that all `Ts...` are the same as `T`, and still give you a nice error message otherwise.
You can use the VisualGDB toolkit for Visual Studio. I suspect it's possible to fool the Android build engine for MSVC in to using a regular linux-targeting version of clang for Windows and a plain linux SDK (by arranging those tools in a path layout corresponding to that used by the Android NDK). However, I've not tried. I did however get VisualGDB to compile working MacOSX binaries using the osxcross version of clang. 
Well, you definitely don't want the destructor to *always* be implicitly virtual, because this implies a cost for non-polymorphic classes. But I like the idea of a rule that says a complier-generated destructor is virtual iff the class has at least one other virtual function, with an opt-out that if you write your own destructor, it obeys your rules. i.e. // Implicit virtual destructor due to virtual func() class example1 { virtual void func(); }; // Explicitly non-virtual destructor, as today class example2 { virtual void func(); ~example2() {} } // Explicitly non-virtual defaulted destructor, // to allow trivially-destructible polymorphic classes class example3 { virtual void func(); ~example3() = default; }; // Explicitly virtual defaulted destructor, equivalent to example1 class example4 { virtual void func(); virtual ~example4() = default; }; Admitted though I've just made this up on the spot, so there are probably problems with it that I haven't seen yet...
"scope_lock" or "scoped_lock" not "scope_guard" I think? (lock_scope might be more correct)
You're right, scoped_lock is what the paper proposed says: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0156r1.html It isn't part of the standard yet, since it has to go through LWG, but I have a hard time imagining the paper would succeed with the new name.
If you've got the opportunity, I'd love to see a performance comparison between the various Python bindings, as well as Lua and native C++ code. I've got an application where id like users to be able to write their own plugins with minimal effort, but I'm afraid the overhead might be more than i can take for a high performance application. Essentially the same code would be called billions of times over many CPU hours so overhead in the function calls could be a deal breaker. 
You just can't do inner-loop stuff with interpreter plugin code. It will slow the system to a crawl. It'll be thousands of times slower no matter what you use. You have to set things up so the plugin code just sets a bunch of paramaters used in a computation. XPCOM or something like it is maybe an option if you really need to do fast plugins with custom code.
u/gr8gamer 
&gt; Who knows what that'll do to your system. Guess there's one way to find out, but that'd take work on my end, heh. 
Because making anything virtual eventually results in a performance and memory hit. The old C++ adage "Don't pay for things you don't use" definitely holds in this situation. I do want to concede, though, that it's an odd design choice, simply because the moment you declare a method virtual, you almost always have to make the destructor virtual, or else presume that noone will ever *ever* ever *ever* dynamically allocate your class. I'm tempted to argue that in C++, implicitly defined destructors should be virtual if the class contains at least one virtual method, with the option to explicitly make the destructor non-virtual if that's really what the programmer needs.
You can use an elaborated type specifier for the tag for concision, like `using A = phantom_type&lt;int, struct A_tag&gt;;`
I am not familiar with Swift, but I would guess that it is something similar. Note that it might be much easier to do it in Swift because of modularity. Cross module optimization (CMO) is much harder to do efficiently in C/C++.
I'm confused about one thing: how is this not considered to be a linker bug? Isn't linker only supposed to collapse identical functions?
The real magic with GoogleTest nowadays is it now include GoogleMock and importantly the GoogleMock [matchers and EXPECT_THAT macros](https://github.com/google/googletest/blob/master/googlemock/docs/CheatSheet.md#matchers). These are extremely useful for verifying the contents of STL containers.
 frame$ | Apparently, you can put dollar signs in variable names in C/C++ on some compilers (like mvsc/gcc). I didn't know this. &gt; 6.34 Dollar Signs in Identifier Names &gt; &gt; In GNU C, you may normally use dollar signs in identifier names. This is because many traditional C implementations allow such identifiers. However, dollar signs in identifiers are not supported on a few target machines, typically because the target assembler does not allow them. http://stackoverflow.com/questions/7926394/in-variable-name struct $Y1$ { void $Test$() {} }; int main() { $Y1$ $x$; $x$.$Test$(); return 0; }
Beyond that, the failure messages are more easily parsed (mentally) than the gtest macros.
LuaJIT might be an option. Calls from LuaJIT to C are faster than *vice versa*, but they're both fast enough to do millions of calls per second, apparently, though I've never used it in a context where that level of performance was important. [http://stackoverflow.com/questions/12329128/](http://stackoverflow.com/questions/12329128/) 
Boost.Test has Turtle Mock. http://turtle.sourceforge.net/
Hmm, indeed, appears I was wrong.
Macros don't overload, at least not quite so easily. The compiler would complain but the default GCC behavior is to quietly replace a macro when it's redefined. Overloading is [possible](http://stackoverflow.com/q/16683146/153285), though.
Yes! C++17 `auto` braced-init rules for named types.
Some people believe being economical about how many "things" you use to solve a problem is better. However, that's extremely vague. Being economical about one kind of thing may lead to being highly non-economical on other kinds of things. I don't think that many people equate shorter (less characters, or less lines) code with better code. Paste examples of your code (with their purposes) so that people can make some sort of meaningful judgement. The question itself is very vague. Shorter always means shorter compared to something. In this case "something" is "other people's code from codewars", and I have no clue what their code sizes are. Besides, what is your size measure? Are you talking about lines of code? Number of functions? Number of classes? Number of files? Number of ideas and concepts put together? 
Alright lets start off with stating everything I say is merely assumptions based off what little information I have in the post. &gt;In this case "something" is "other people's code from codewars", and I have no clue what their code sizes are. Besides, what is your size measure? Are you talking about lines of code? Number of functions? Number of classes? Number of files? Number of ideas and concepts put together? Without knowing anything about code wars I would make the assumptions that it is web based and therefore a single file. He is comparing the sizes of his code to another code in a single file and his is larger. Now what makes it larger could be one of two things, either characters or lines. My bet is on a mix of both. I would say they probably have a better understanding of the language and therefore can make better use of functions and for loops to solve the same solution more eloquently. Which implies that I believe their shorter code is better. However much like in gamedev popping up all the time of "This is better than that, this art style sucks, that sucks" etc. The skill of a programmer and therefore the quality of their code is only dependent on the skill of the programmer. In other words short or long code can both suck. They could also be good. Which is why examples are needed to point out whats done better.
I use googletest in one of my projects. I'm actually compiling a separate executable to test a dll... I guess I shouldn't do that? It's pretty painless though. I come from writing tests with junit in java, and googletest is close enough to make the work. I haven't gotten into the mocking yet. My code is relatively functional (at least the parts I've written tests for is) so I haven't needed any mocking functionality yet 
I like dear imgui, but it suffers from a lot of formatting bugs and some really basic stuff is missing EG there's no drag and drop, no columns within columns (and columns themselves are very broken), you can't overlay two graphs (easily without reimplementing core functionality), you can't easily label histogram cells, no straightforward way to space vertically (hidden buttons, subtract padding perhaps?), no way to make a vertical line separator (to emulate columns), rendering text at anything other than the recommended size seems to be crap etc You can make relatively nice looking stuff with it though (I like the character layout [here](https://imgur.com/a/vFggU)), and it tends to be well structured. You can work around some of the above issues if you're willing to dig into the internal implementation and reimplement stuff, which is not *too* bad with the original as reference
Seconded.
&gt; Without knowing anything about code wars I would make the assumptions that it is web based and therefore a single file. He is comparing the sizes of his code to another code in a single file and his is larger. Now what makes it larger could be one of two things, either characters or lines. My bet is on a mix of both. OP actually mentioned line count as a measure of code size in the post, but OP also talked about splitting things into functions. OP said: &gt; Now in codewars you can see other people's solution and I always see a lot less code then what I wrote. I try to break my code up in functions but most of them do it in a lot less lines and one function. So I imagine OP has function decomposition somewhere in the middle of whatever size criteria is being considered. Maybe OP is considering doing less of breaking things into functions. I imagine there is more to what OP means by code size than that. 
GTest is great if you actually need mocks. Otherwise, something like Catch is good enough for the task.
 std::string ImANoobAndThinkThisIsEasierToWorkWith() { if(true) { return "But other people think it's the style of the devil yet are fine with decoding pointer/reference soup.\n"; } else { return "Oh well.\n"; } } Thankfully nobody else ever has to see/use my code!
I'm actually kind of interested in this. Is there any good reading about this?
Looks good, but it seems to lack `constexpr`. And indeed, the macro does seem unnecessary (it really doesn't save that much writing).
Codewars is all about writing software quickly. Real programming is about writing good code, meaning it's easy to understand, can withstand changes by other developers, don't have gotchas, is easy to debug. Breaking code into functions fits well with real programming, but perhaps not in a contest situation. In other words, choose your metric and people will give you what you ask for. The metric for Codewars is not good code, so don't expect to see good code.
There's a reason PCI Express 3.0 x16 slots have 32GB/s of bandwidth, and it's not because games reuse almost every bit of data every frame. They reuse what they can, but there's a lot of work happening in every frame.
Define "short"? Number of characters? Lines? Something else? A way better measure fir this kind of stuff is cyclomatic complexity. Try finding tooling that can tell you this and compare various solutions to the same problem.
/s? 
Templates are the more flexible solution for this problem but we can't use them everywhere because of the downside of templates. That's what I meant with theory.
is it possible to log number of AVX - SSE switches during runtime?
Added constexpr support. I find the macro to be useful because it abstracts expressing the intent of defining a phantom type of type T by removing the need to manually deal with the typedef and tag class.
interesting
Thanks, fixed
&gt; Why choose something different than the majority? Because it's objectively better. Just because something is used by a majority or it's a 'standard', doesn't mean it's the best and/or should be used without question.
&gt; objectively https://i.imgur.com/SxzJKGG.png
Jon and I have been busy, and hangouts on air shutdown. We do hope to restart it!
That's very interesting and good to know. Incidentally I've used the same i/o model in proposed Boost.AFIO v2 whereby io_service runs per user thread and I push concurrency onto the user to decide, so I am very specifically NOT using the ASIO reactor design which I didn't find to scale well with lots of disk i/o concurrency on storage going into the millions of 4Kb IOPS. I'm not looking forward to the Boost peer review on that design decision though :(
*sigh* You aren't funny. Trying to insult someone won't get you anywhere. There are objectively better formatting options. You should prefer consistency and clarity first. Placing a ```{``` on a new line beats the same-line ```{``` on both cases. The same with the CamelCase stuff, and others as well.
Please do!
Awesome! Thanks. 
&gt; Interestingly, since the calling convention is not an official part of the type system It is. [dcl.link] §7.5/1: &gt; All function types… have a language linkage. Not all compilers enforce this rule, though. (This is nonconforming.) More pertinent, [expr.prim.lambda] §5.1.2/6: &gt; The closure type for a non-generic *lambda-expression* with no *lambda-capture* has a conversion function to pointer to function **with C++ language linkage**… Thus the standard forbids MSVC's extra conversions. If every implementation does something nonconforming, perhaps that adds up to a defect…
My biggest issue with using unique_ptrs is compiler messages when I make a mistake. like trying to use a range-based for loop over a vector of unique_ptrs instead of an iterator based approach, for example. The error is always some code in the memory header with the message "attempting to reference a deleted function". I typically end up just pounding the code with a hammer until I can find where I was inadvertently attempting to copy the unique_ptr, but does anyone know if compiler messages for these types of things are getting better soon? (im running vc++)
But extracting the very same information about the code using the AST matcher is? I find it as a brute-force method at its best for the given task. Actually, I am playing with `libclang` Python bindings right now and, although not perfect, I don't see it being a clumsy API. It's pretty much straightforward and much better suited for the tasks from the OP. 
I agree with your other points, but this is wrong: &gt; less code == less instructions to execute ==&gt; faster Consider: - An O(log(n)) lookup on a map - An O(n) lookup on a linked list I think you'll agree the first one is more lines of code, and faster. Should we replace our maps with linked lists to reduce our line counts?
I've never been blessed by getting using libraries that do all the same thing. So in my codebase I choose to use what I like. If it's inconsistent with the standard library, I don't care much, cause if I matched that, it'd be inconsistent with glm, and Qt as well. Who cares if I'm inconsistent with one more library? If anything it's "nice" (really this is what namespaces are for, but some folks like to use "using" liberally) to signal that this is from another library. Really this is just another tabs, spaces, or tab and spaces argument. Sure there's some points for one thing or the other, but in the end, it doesn't matter, someone picks a style and you go with it, quietly complaining into your coffee or whatever.
I'm dumb and hadn't thought to do that. Thanks dude.
Wow yeah. Doesn't get much more obvious than that.
Thanks for your support. :) 
Sorry for the rant in advance, but I think there's something deeply wrong with the idea of reflection. It's a sign that you're trying to map the syntactic constructs of your language to the concepts in your problem domain, but this sounds fundamentally flawed to me. The same goes with generic debuggers. Stepping through your C++ code line by line and observing your C++ data types in memory seems like the wrong level of abstraction; again the same mistake of trying to model your problem domain with syntactic constructs...
Something to consider: the use case for reflection is when your syntactic constructs *are* the problem domain, e.g. serialization or debugging.
This.
&gt; Because of this, it is much easier to spot errors when performing a code review For whom? Other people might be used to other brace placement styles. 
&gt; Of course this is /r/cpp, so I'm going to be downvoted :) Complete with a passive-aggressive smiley at the end. 
What do you recommend over imgui? I haven't seen many libs that have been actively maintained or feature-complete. I'm just starting to learn this stuff, so I'm still searching for a gui lib to play with.
I'd recommend ImGui honestly (I'm definitely no expert in gui libs though), it has flaws, but its generally *fairly* intuitive to use. If you need a particular feature that isn't supported, you can fairly easily reimplement more advanced stuff using the existing functions as reference (and all the associated imgui helper functions to make it easier) It also directly and very easily integrates with opengl/sfml which is one of the main reasons I picked it, as I have a very peculiar rendering system
It would be really nice if they included a nothrow version in the standard library so I wouldn't always have to make my own.
True, however translation phase 1 requires that all characters in the Unicode ranges be placed into the \uxxxx variants. So, while we see the Unicode character, the compiler will see \uxxxx. :)
&gt; trying to map the syntactic constructs of your language to the concepts in your problem domain That's sort of the definition of programming, isn't it? I like std::string because if my problem domain involves string manipulation, I want to use the constructs of the language to to it, rather than inventing it all myself. The more that can be pushed into the language is a generic way, the less I have to reinvent in every program.
Ah, interesting. I don't envy anyone trying to pitch optimal Windows architectures on anything that is a "POSIX-first" environment... You might find this interesting: [PyParallel: How we removed the GIL and exploited all cores](https://speakerdeck.com/trent/pyparallel-how-we-removed-the-gil-and-exploited-all-cores). I only spend a slide on Registered I/O... but if you're doing anything network I/O related you can probably sympathize with the general content. *"What works well on UNIX isn't performant on Windows, and what is performant on Windows isn't possible on UNIX."*
Maybe I expressed it wrong, but, of course, what I mean is not changing the value from `int` to `const int` physically. It *starting to behave* (logically) as it was declared const int - that's the whole point. &gt; Not at all. Pointing to a non-const object through a pointer to const is fundamentally different from declaring the object as const. Yes, that's why I started to explain that we have a pointer and the object to which pointer points out. And, yes, they are totally different objects. And, if we will look to the pointer from this point of view - it (again) *start to behave (logically)* as it was declared const, e.g.: `int* const` inside const member functions
Ah, I see now how you meant that. I was thinking about the of the *effect* of the keyword. The guarentees of const are a subset of the guarentees of pure.
But by this logic your saying that because there is no consistency we should not strive for one either? Either you want consistency or not. Edit: by this logic every programmer on a team should be free to choose his/her preference when it comes to spaces/tabs and/or braces.
Qt
This is VS with [`/diagnostics:caret`](https://docs.microsoft.com/en-us/cpp/build/reference/diagnostics-compiler-diagnostic-options): 1&gt;------ Build started: Project: unique_ptr, Configuration: dbg x64 ------ 1&gt;unique_ptr.cpp 1&gt;unique_ptr.cpp(5,1): error C2280: 'std::unique_ptr&lt;int,std::default_delete&lt;_Ty&gt;&gt;::unique_ptr(const std::unique_ptr&lt;_Ty,std::default_delete&lt;_Ty&gt;&gt; &amp;)': attempting to reference a deleted function 1&gt; with 1&gt; [ 1&gt; _Ty=int 1&gt; ] 1&gt; auto ptr1 = ptr0; 1&gt; ^ 1&gt;memory(1857): note: see declaration of 'std::unique_ptr&lt;int,std::default_delete&lt;_Ty&gt;&gt;::unique_ptr' 1&gt; with 1&gt; [ 1&gt; _Ty=int 1&gt; ] 1&gt; unique_ptr(const _Myt&amp;) = delete; 1&gt;memory(1857,1): note: 'std::unique_ptr&lt;int,std::default_delete&lt;_Ty&gt;&gt;::unique_ptr(const std::unique_ptr&lt;_Ty,std::default_delete&lt;_Ty&gt;&gt; &amp;)': function was explicitly deleted 1&gt; with 1&gt; [ 1&gt; _Ty=int 1&gt; ] 1&gt; unique_ptr(const _Myt&amp;) = delete; 1&gt; ^ 1&gt;Done building project "unique_ptr.vcxproj" -- FAILED. A bit more verbose, but hardly *un*clear...
I'm actually in a camp that believes this should be true. I would have only one rule: be consistent within a file. I really don't think it matters. Different libraries use different styles anyway, so professional programmers need to be able to read and write different styles anyway. 
Nope, otherwise `std::optional` and `std::variant` would do it.
Unfortunately this is one of those situations where if we want this to be possible, I'm pretty sure we're going to need a proposal to extend the abilities of constexpr again. Which is fine by me, I'd love to be able to do more things with it. As it is we can't even overload functions for runtime or compile time if there are optimizations that can be done at runtime that can't at compile time due to constexpr limitations,
Team up with /u/zygoloid/ for a proposal to expose the full language (new/delete/reinterpret_cast/goto) at compile-time?
Is it possible to define a template equality operator for all 'visitable' structs, or would I have to add a separate one for each struct inside the VISITABLE_STRUCT macro?
Similar to what I've stated in another comment, if what you need is a general purpose C++ debugger exactly, it's obviously better to have it than not. But the problem is that you shouldn't be writing much code in that level of abstraction to begin with. BTW, I'm not saying you shouldn't be doing it at this point in time, with the current languages and tools and libraries we have (I think you should try to avoid it as much as possible anyway). My objection is the emphasis these things (reflection, generic debuggers) get. It just puts a veil in our thinking that we should be building abstractions. See, that's not just an academic discussion, this issue surfaces under many covers. You see all these people resisting metaprogramming (and abstraction in general really) on these grounds. Because it doesn't play well with debuggers or static analysis tools or many other things that assume you're spending your time in the wrong place. See, as programmers, we're trying to hold on to false conveniences and miss out on much bigger gains.
Kind of a tangent, but you might be interested in the upcoming [`propagate_const`](http://en.cppreference.com/w/cpp/experimental/propagate_const), which gives more intuitive semantics to pointers in some cases, making a const pointer act like it also points to a const object.
There are two main problems, for one of them I have PR against catch fixing it. 1) It catches sigsegv caused by stack overflow, but dies horribly, because it does not allocate a backup stack for such eventuality. This is easily fixed, as shown [here](https://github.com/philsquared/Catch/pull/753). Do note, that this is not really well optimized, but I didn't know where to stick a global allocation, so its always reallocated. :-D 2) The response to signal is insane, as it tries to perform orderly shutdown, but if you get a signal, there are more or less no guarantees about the state of your system (especially if you are a general purpose testing framework and those signals can originate from anywhere). I actually tried adding signal handling for Windows, but the current handling process led to hard crash in 1/3 attempts, deadlock in another 1/3 and weird-ass shit in the remaining cases. Not once was orderly shutdown achieved. :-D I know how to fix it and would probably be willing to, but first I want to see an active maintainer.
It seems like that enable_if would need to depend on the value of *this.
Right, and the destructor has no arguments. Well, I guess you'll need to get a make_string function then, which has an overload returning a wrapper containing either a constexpr type, or a unique_ptr with custom deleter to the string?
This isn't really a good example for why we need strong types. It's actually an example of why Python style keyword arguments would be helpful. Rectangle r(width=10, height=12); Frustratingly C already has this for initialising structs in the form of designated initialisers: struct point { int x, y; }; struct point p = { .y = yvalue, .x = xvalue };
I disagree. A common (yet rarely followed) C++ guideline is to avoid putting two arguments of the same type next to each other, as it is easy to mix up the order. So different types for the arguments is a great way to follow that guideline. And as opposed to named arguments, this is something that can be implemented easily. 
static const should have done the same here, right?
`optimal_tuple` should be trivial to implement in an efficient (compile-time efficient) manner with C++14 constexpr. You just need to create a constexpr token for each type in your tuple, and sort a list of pair of (token, alignment) and use the indexes in the sorted list to reroute the `get&lt;&gt;` calls. Should be ~20-25 lines of code.
Wouldn't that enable_if only need to depend on the *type* of *this?
Yeah, he definitely says as much and used to have fairly active development branch on github, but either he ceased working on it or doesn't work on it in public and the jump will be so large there is no point in taking fixes to Catch 1. Neither of which makes me want to spend a lot of time figuring out good way of integrating SEH into Catch 1.
&gt;For a reader of this call to the constructor, there is absolutely no indication which one of 10 or 12 is the width or the height. This forces the reader to go check the interface of the Rectangle class, that is presumably located away in another file. For this reason, the usage of too generic types is detrimental for readability, and for no good reason: the code knows very well that 10 is the width and 12 is the height; it just won’t say it to you. Isn't this part solved by good tools? Maybe I'm too used to C# and Java where using those languages without an IDE is a big no.
http://www.righto.com/2016/10/inspired-by-hn-comment-four-half-star.html?m=1
Because the allocator can have a destructor that frees all memory.
This will be a nice addition, however you will have the same problem when you pass numbers (values) directly to a function: do_something(10, 5, 6, 7); 
I know that. And experience has showed me that my team doesn't have a problem with using the mouse or using the shortcut. Also you can peek definition **quickly** so you don't have to search for the header file or open the file in a new tab.
I don't think you can even do that, because `reinterpret_cast` (and c-style casts) aren't constexpr either.
Interestingly, you can easily bring named arguments. template &lt;typename U, typename P&gt; class Value { public: using Underlying = U; using Parameter = P; explicit Value(Underlying u): mUnderlying(std::move(u)) {} Underlying&amp;&amp; get()&amp;&amp; { return mUnderlying; } Underlying const&amp; get() const { return mUnderlying; } private: Underlying mUnderlying; }; can be augmented with: template &lt;typename V&gt; class Argument { public: Argument() = default; V operator=(typename V::Underlying u) const { return V(u); } }; Once this is in place: using Width = Value&lt;double, struct WidthParameter&gt;; static Argument&lt;Width&gt; const width = {}; // ... Then named arguments are within reach: Rectangle r(width = 10, height = 12); This can be implemented either by: - having a compile time error if the arguments are passed out of order - providing multiple constructor overloads (of all permutations of arguments) - automatically reordering the arguments based on their types The latter requires a helper function: template &lt;typename T, typename U&gt; T either(T t, U) { return std::move(t); } template &lt;typename T, typename U&gt; T either(U, T t) { return std::move(t); } template &lt;typename T, typename A0, typename A1&gt; T pick(A0 a0, A1 a1) { return either&lt;T&gt;(std::move(a0), std::move(a1)); } template &lt;typename T, typename A0, typename A1, typename A2, typename... A3&gt; T pick(A0 a0, A1 a1, A2 a2, A3... a3) { return either&lt;T&gt;(std::move(a0), pick&lt;T&gt;(std::move(a1), std::move(a2), std::move(a3)...)); } And is then easy enough: template &lt;typename A0, typename A1&gt; Rectangle::Rectangle(A0 a0, A1 a1): mWidth(pick&lt;Width&gt;(a0, a1)), mHeight(pick&lt;Height&gt;(a0, a1)) {} See it [in action](http://coliru.stacked-crooked.com/a/6648343739413166).
When I do this I like to give the `NamedType` an implicit `operator T()`. It doesn't hurt safety, because it only goes one way (you'll have to explicitly turn it back into a named type to pass it on), and it frees you from typing `get()` everywhere when you just want to use the value. 
a scope is outside of bar....
Well, it means "the compiler wrote its body for you". `~foo() = default;` is user defined but still trivial because it isn't user provided -- the compiler provided the body.
Well of course. It's just a simple example to demonstrate the mechanic.
Maybe I am a little unthankful but I don't find very useful articles that show techniques without a good use case. Specially when the author doesn't put a disclaimer where he states that in this particular case it is not a good idea because at the end of the day the article is read also by newbies that do not know better.
&gt; Placing a { on a new line beats the same-line { on both cases. Whaaat? How can you talk about this and say that you are objective. It's obviously a very subjective point of view. 
&gt; sigh I get into this argument every time. Gee, I wonder why.
Wait a sec. Doesn't this imply that if a "destructor written by the compiler" that calls a "destructor written by the user" is a trivial? That doesn't sound right at all. According to [this](http://en.cppreference.com/w/cpp/language/destructor#Trivial_destructor), the condition for a trivial destructor is (also) that all of the base classes and members must be trivially destructible.
I like this. Reminds me of a transition between Optional implementations we're doing at work right now. Old one has a SetExists, a Get, etc. New one has mostly pointer semantics. Lots easier to type, keeps the creative stuff interns don't need to think about under the hood. 
What's the goal with this, out of curiosity? Edit - downvoted for a question?
https://gcc.gnu.org/bugzilla/show_bug.cgi?id=67348
"Nothing is stronger than an idea whose time has come." (с) Victor Hugo
Would the codegen be any different for a local const (non-static) std::array?
Why not just use plain old inheritance and avoid the need for the tag struct? struct MyType : PhantomType&lt;int&gt;{}; That's a concrete type right there.
https://groups.google.com/a/isocpp.org/forum/#!topic/std-discussion/PtJbyeG6W9g
tried that, success on gcc &amp; clang but failed on MSVC
Actually, copy-on-write is a pessimization here. The issue is that it requires the string storage to be mutable, so as to keep a counter of the number of owners of the data, and mutable and read-only do not mix.
Why does it fail? Something wrong with the syntax or with MSVC?
It would be nice if there was some documentation. Does it work both with stdout and stderr? Is the formatting cleanly removed when output is redirected somewhere? I see that there is an option to force the formatting even when redirecting?
Cool!
Thanks :)
Great, thanks. I'll probably use it to enrich logging output in my project.
I like that you support the Conan package manager. Especially on Windows it is often the case that thirdparty gets stripped out because it quickly complicates the build process. Letting Conan manage thirdparty gets rid of the hassle. This is especially important for a lib like this - it's not that important to have colors in the terminal, but if you get it "for free" you can just use it anyways. I think that libs like this will be used a lot more in the future just because something like Conan makes it much easier to have thirdparty under control.
I support conan, meson and simply including the single header file as well, but I understand what you're trying to say. Manually managing packages/libraries isn't worth the hassle when you don't necessarily want them, but conan makes it much easier to deal with them. Also conan devs are very helpful and provided great [support](https://github.com/agauniyal/rang/issues/29#issuecomment-251229441) to uploading my lib to conan.
Ah, I am afraid we were talking past each others because of a different definition of copy-on-write. The definition I was using was based on the previous implementation of `std::string` in libstdc++: that is, all `std::string` referencing the buffer are co-owners, and the buffer is thus reference-counted. What you seem to be talking about is different, and instead means having a string implementation that is either the owner of the buffer (which has at most one owner) OR only reference the buffer, transparently. (Something akin to Rust's `Cow&lt;&amp;str&gt;`). Indeed what you propose would work in this scenario... however I am unsure of the usability; it would be quite difficult to ensure the referenced buffer lives long enough (no lifetime tracking in C++).
The code assumes you're on an terminal that implements the ANSI escape sequences. If you're on a dumb terminal, you'll get garbled output. Programs that want to annotate their output with colors should have an easy way to just disable the annotations when they detect that the output is not a terminal or the terminal is dumb, for example.
I perform a check for terminals setting env TERM to some known terminals eg for value 'ansi' or 'konsole'. Rest are not affected unless someone forces colors. Feel free to look at the source inside include directory :)
Yes. Sorry I wasn't clear about that.
&gt; because the compiler will write code to push everything on the stack. But why?
it actually supports both and others too since it checks for substring matches rather than whole. Also, it's not possible for me to check and test for every existing terminal since I only know a dozens or more. So if someone discovers any non-working terminal, I'll modify the code to include it :) If you've something other in mind, I'll be happy to discuss it. Edit - I somehow missed terminfo and yes I'll take a look at it. But currently my lib follows graceful degradation so it will never output escape codes on non-supported terms but might miss some exotic terms and won't show colors. At the end it won't output garbage :)
There's a wiki inside github repo too, but I'll improve the documentation tomorrow since its 1 am here :)
Thankyou :) also my impl is much older and since there aren't a lot of ways for doing this task, our code might end up looking same.
what os/version are you using? which terminal? If you're talking about windows, I'm already using them :/ if you're using windows 10, only then I use escape codes which are supported by newer version of windows cmd. it also might be possible some tests wouldn't be calling reset at the end of program, leaving your colors changed. I'll make sure to check them.
Don't have time right now to test on my computer. Does it work on Terminology?
I'm sorry but I haven't tested on that terminal but it should work if Terminology follows vt100 confs. If you manage to test it and it still doesn't works as expected, feel free to notify me via github issue or email and I'll take a look at it asap :) Edit - Terminology page says this - &gt; Use it as your regular vt100 terminal emulator along with all the usual things like 256 color support (we attempt to emulate Xterm as closely as possible in most respects). so it should definitely work :)
Thankyou, I'll take a look at it :)
`style::reset` is handled incorrectly; your code hardcodes white foreground, but there's an escape code that actually resets to _default_, which is what you really want: `\033[39m`.
But they dont... -_- I think this is quiet bad because it's so unexpected. Especially in the constexpr case.
I deeply suspect that this issue was present only in debug / profiler-friendly configurations. Assuming these structures have no ctor defined, there is no excuse for the compiler not to figure out is a const array and just compiling it to memory. Also it likely should be returning a const &amp; depending on usage if it's called that often but that's a different issue. 
I don't know what /u/Rhomboid has in mind. Here are some of my opinions though. For many people, it's implicit that code should work, do what it's supposed to do, be correct, etc. It's a silly question if you take it to a superficial interpretation because it doesn't matter that your code runs fast, or is simple, etc. If it doesn't work for some cases, then it's useless in those cases, no matter how simple or well written it is. For example, I can drastically improve the readability of a quicksort implementation by replacing it with a statement to return the given sequence. Now, it's pretty readable and clear what it does: it gives back the given sequence. That, in many cases, won't be sorting the sequence, so it's not acceptable. However, I think there is more to the question than the superficial interpretation. So: &gt; Is readability more important than correctness? That assumes correctness is up for discussion, which it isn't for many people. However, I believe in practice that things aren't that simple. There are points of view which makes the question reasonable. One point which I think is related to your question is the following. Many people are willing to reduce the scope of a functionality. For example, it might be too complicated to actually write an algorithm for full blown collision detection in a game according to what the game designer needs (imagine low budget small indie teams). So, what some people might be willing to discuss is the reduction of how elaborate collision detection has to be in the game. Therefore simplifying what sort of collision detection must be implemented, and thus simplifying the involved code. In comparison to the original collision detection spec, the code which got written is wrong (because it doesn't cover as many collisions cases as the original spec asked for). The code is only correct according to the new spec, which is the one that actually got used in the game. So you wouldn't really say you traded correctness for simplicity, but that you traded features for simplicity. A lot of people actually believe in reducing features scope to make things simpler in earlier releases of a system. They know this initial version is not what they want (that is, strictly speaking it isn't correct according to the final/idealized vision), but they do it anyway because it's believed it's better to get something working as soon as possible. Another point is about bug fixing. There are projects which have known bugs that people don't fix because (of all or of some of these, among other reasons): - it'd complicate the system considerably; - the benefits aren't that many (possibly because the involved feature isn't used by a considerable fraction of the users the company has); - there aren't enough resources to be applied to that task (again, imagine the low on budget small indie team). Which turns out to be an example in which correctness got traded for something else (one of which might be simplicity as in the first item). In the end, I believe that in practice some people do trade correctness for other things in some cases, and simplicity might be in the middle of these "other things". Of course they still want their software to be useful, so there is a limit to this.
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5htldk/can_i_please_have_some_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The problem is the lack of actual value that could be demonstrated while we discussed it. I realize my name is on the paper, but I was simply writing up what we decided in the room. There was no benefit we could see to allowing it, and all troublesome-ness. Note that even allowing an empty variant wouldn't solve OPs problem and would be an ambigous situation.
Interesting, I wonder what the committee would do if that shows up in a NB comment. I see the value of the 'getElement' function, though question the usefulness on an empty tuple. What is the behavior of said function when 'i' is out of bounds? 
 using CapturingLambdaFnT = decltype(Lambda); It'll have a __thiscall calling convention using the anonymous class generated for the lambda. So: ReturnType(AnonymousClass00::*)(Parameters...);
Hmm. This seems like a definite compiler bug. Even gcc-4.4.7 at -O1 gets this [right](https://godbolt.org/g/UfCVzP)^1. clang needs -O2 to get there, but it's -O1 codegen isn't too bad. *** [1] Assuming my example is representative.
afaik font size isn't even configurable with most terminals via escape codes, so that would be very very tough to land in this lib :/
What about if the code was readable but didn't work? Would you merge it then?
Yes, they're just non-official. And sometimes they're really a demo -not working on every platform because of lack of my time to test each of them. But I'm working on automated building, so I'll just fix broken stuff later. I'm now establishing PoC of the whole system as much as possible.
No. Code must work and be readable/maintainable. One thing must not exclude the other.
I'm not hardcoding white foreground, `style::reset` does 'All attributes off', I'm not sure why it isn't working here. http://wiki.bash-hackers.org/scripting/terminalcodes#general_text_attributes
The readme shows a bool struct_eq() function. I guess an operator could be defined using SFINAE or something.
I agree that having something like typeclasses would be nice. However, typeclasses also have their (annoying) restriction that only one can exist for a given type, which then requires `newtype`, and things like `Sum` and `Product` for Monoid (for example). The fact that they use runtime dispatch would be a big no-no for C++, although with templates there's no reason it couldn't be resolved at compile time...
It's working... sorry :(
Why not build a rasterizer from scratch? You could do it offline or real time using CUDA or a compute shader. 
'All attributes off' doesn't affect colors; you still need `[39m` to reset the FG color to default, and likewise for `[49m` and the BG color.
Not of if they are static const or constexpr. 
Let me rephrase: Variables with automatic storage duration _do_ need different addresses; `const`, `constexpr`, or otherwise is irrelevant, the storage duration dictates this rule.
Yeah but we are talking about static storage duration, actually an even more limited version of it.
&gt; Class interfaces also tend to grow indefinitely, because there is always "more useful stuff" that can be added. For example, a string class (one of my pet peeves) could be extended with functionality for tokenization, path manipulation, number parsing, etc. To prevent "class bloat", you could write this code as external functions instead, but this leads to a slightly strange situation where a class has some "canonized" members and some second-class citizens. It also means that the class must export enough information to allow any kind of external function to be written, **which kind of breaks the whole encapsulation idea.** This is simply wrong. Writing functions that only work with one type, when they could work with a lot more, isn't giving you anything. Functions don't need to know a lot of information about a class, you only provide what's really needed. Take iterators, for example. Generic algorithms don't need to know if you're working with vectors, or sets, or arrays, etc; it only assumes that it's going to work with something that provides an iterator for it to use. And that will only require your class some way to give back an iterator. That's it. Encapsulation works much better with generic programming in that way.
Ehm, is this a thing we need to discuss here on /r/cpp ? What is significant in std::variant implementation?
can you make a working example. I don't know where you are getting `AnonymousClass00` from.
You may be interested in [this article](https://adishavit.github.io/2016/lambdas-callbacks/) by Adi Shavit 
Hey, syntax highlight in DISQUS is making me crazy (plus each edit seems to need approval) so I've just put a link to this comment in your blog. That's a suggestion on generating a tuple capturing or referencing (depending on value category): template &lt;class T&gt; using capture_t = std::conditional_t&lt;std::is_lvalue_reference&lt;T&gt;::value, std::add_lvalue_reference_t&lt;T&gt;, std::remove_reference_t&lt;T&gt;&gt;; template &lt;class... Args&gt; auto make_outliving_tuple(Args&amp;&amp;... args){ return std::tuple&lt;capture_t&lt;Args&gt;...&gt;(std::forward&lt;Args&gt;(args)...); } then you'd use this w/o extra facilities (wrappers/macros) in your capture clause and [generate](http://coliru.stacked-crooked.com/a/1d0b3f4603cbb166) the correct type if lifetime extension is needed, i.e. [ ](auto&amp;&amp;... args) { return [auto t = make_outliving_tuple(std::forward&lt;decltype(args)&gt;(args)...)](/*DIY*/){ /*DIY*/ }; }
Thanks for your advice. :) My work changes code little by little.
Constexpr and variadic templates are compiler features, variant is library.
And?
nice :)
Going off your caveats sections, you still might need \#ifdefs for your OS example. If you use something from `Windows.h` even from just the `the_os == OS::Windows` branch, won't it fail to compile elsewhere?
String matching isn't sufficient. There's a terminal database (terminfo, previously termcap), and you need to use that to be sure to cover all the possibilities, and also new termainals, user extensions etc. There's a reason for that abstraction to exist, and you should use it. You can avoid using it on Windows (there's a built-in terminal, and it supports ANSI), but that's not true on UNIX, where you have a plethora of terminals and configurations. The terminfo stuff was developed to abstract this away, and you should use it.
When did Bjarne write this? Can't find a date...
Thanks, I added some clarification :)
Didn't know there was a one feature per week post quota.
This is a really good paper, but I wish Bjarne would use [real concept names from the Ranges TS](http://en.cppreference.com/w/cpp/experimental/ranges) rather than inventing his own names, especially as it's likely people will still be reading this paper many years from now when Ranges will be widely available. For example, it's `Range`, not `Sequence`, `EqualityComparable` not `Equality_comparable`, `value_type` not `Value_type`, `iterator_t` not `Iterator_of`....
Doesn't pure also mean that a function does not depend on global state? Why not forbid accessing non-const global variables in a pure function? Then GCC would be able to optimize the example where a global variable is set in between two calls to foo(). Or is that too strict?
You mean `value_type` vs `iterator_t`? Yeah, that one is oddly inconsistent. From memory Range-V3 uses `range_value_t` and `range_iterator_t` for the two aliases, I'm not sure why it got changed for the TS.
This program compiles and runs correctly on both VS2017RC and http://webcompiler.cloudapp.net/: #include &lt;variant&gt; #include &lt;iostream&gt; template&lt;class T1, class... T&gt; std::ostream&amp; operator&lt;&lt;( std::ostream&amp; os, const std::variant&lt;T1, T...&gt;&amp; v) { std::visit([&amp;os](const auto&amp; x) { os &lt;&lt; x; }, v); return os; } int main() { std::cout &lt;&lt; std::variant&lt;int, long&gt;{42l}; std::cout &lt;&lt; std::endl; } 
That's decent, I guess. Some syntactic sugar on this would be nice, but thanks for the solution! I'm thinking of something like match(v) { (int i) { }; (float f) { }; } 
Typically you would use it with template lambdas, eg `[](const auto&amp; x) { std::cout &lt;&lt; x; }`. Also you can [combine lambdas](https://www.youtube.com/watch?v=W-xTpqj31mI).
It's possible to write a function to combine lambda functions into a visitor, so you can write something like std::variant&lt;int, float, std::string&gt; var{"Hello world"}; std::visit(make_visitor( [] (int i) { ... }, [] (float f) { ... }, [] (auto a) { ... } // "default" case ), var); which is about as nice as it will get without dedicated language support. I've seen a couple of `make_visitor()` implementations floating around (it's not all that complicated to write yourself once you realise you can inherit from a lambda), but it would be nice if it was in the standard library too.
Very cool. I also had this thought last night. Does gcc trunk support deduction guides yet?
This way may be solve some of described problem but add other problems. This is why we need [Uniform Function Call Syntax](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4474.pdf)!
You could use `if constexpr` to determine the type and generic lambda as the visitor.
I have a string class I use for compile-time string processing, and one for runtime string processing. I'd like to have just one class.
I don't see this growing dynamically to accommodate long strings. I see it throwing an exception when asked to hold more characters than the declared buffer size.
My rule of thumb is **everything** throws, except a few well-known things: * C calls * swap operations * move operations (people who want to throw from a move should be taken behind and shot) * primitive type assignments For everything else, using noexcept is a **bad** idea from the maintenance standpoint. That includes e.g. default constructors.
I guess I see where you are coming from, but I think that they like seeing the new features make it out into a real project. I also suspect there's a bit of bias towards clang here. Clang is a cool compiler/lifestyle, but the license bothers me a bit, especially with that pay for plugin, but that's not about c++, that's ideology with little relation to the language's ongoing development. Anyway, people are excited because something that used to be hard and ugly will now be a bit easier and cleaner. 
&gt; This program compiles and runs correctly on both VS2017RC and http://webcompiler.cloudapp.net/ Unsurprisingly, since VS2017RC and the web compiler do not yet have the `&lt;variant&gt;` changes from P0504 and P0510.
What about if you teamed up with conan.io? It's fully open-source (MIT). I don't see that cppan is sufficiently different, but feel free to correct me. Fragmentation is not really good when it comes to package managers.
We have different approaches. And our systems is very very different. So, merges aren't possible in the near future.
It's effectively a type-safe union. See http://en.cppreference.com/w/cpp/utility/variant for details and an example.
&gt; Note that even allowing an empty variant wouldn't solve OPs problem and would be an ambigous situation. The compiler must instantiate `std::variant&lt;&gt;` to determine if it can convert `std::endl` to it to decide if the `operator&lt;&lt;` overload is viable. If `std::variant&lt;&gt;` were instantiable, as in N4606, the compiler would instantiate it, quickly determine that no conversion sequence exists from the type of `std::endl` to `std::variant&lt;&gt;`, and remove the `operator&lt;&lt;` overload from the candidate set. EDIT: Note that N4606 `std::variant&lt;&gt;` has no constructors - except for copy and move constructors - that participate in overload resolution. (Which is why I tried to convince LEWG that this change was unnecessary.)
No, if any destructors in the destruction of T are user provided then the whole thing is user provided.
`constexpr` doesn't affect the storage duration, so I still don't understand what you're getting at.
100% agreed! `if constexpr` gets rid of all tag dispatching and most class specializations (especially if only a single member function requires modification, this is an enormous help) Now that you mentioned it, having a mixed runtime/compiletime version (where the runtime version would be the same as a plain if) sounds like an interesting idea. But implied/deduced constexpr (ie everywhere, also for functions) would be even better. [edit: spelling]
I've added [**a new section to my article**](https://vittorioromeo.info/index/blog/capturing_perfectly_forwarded_objects_in_lambdas.html#simpler_solution) that shows your solution, an even simpler version of it, and an explanation *(complete with quotes from the standard)*. Let me know what you think! :)
hm ... so would it be sensical to write static constexpr?
Let me get that straight. struct A{std::vector&lt;int&gt; x;int y;}; has a user provided destructor. Well then I just don't understand the meaning of "user provided".
It's a good article, however you should check your motivating examples. The first one doesn't need neither SFINAE nor tag dispatching, since it can be addressed with a simple overload, like this: template &lt;typename T&gt; auto get_value(T t) { return t; } template &lt;typename T&gt; auto get_value(T* t) { return *t; } Normal overload rules, together with partial order of template specialization will do the magic. The second example, while I agree that it can be simplified with `if constexpr`, is better addressed in C++17 using the newly added feature of "folding expression", like this: template &lt;int N, int... Ns&gt; auto sum() { return N + ... + Ns; }
And my point was, that I should start using else, because it is less bug prone.
There is already a well received proposal [P0051](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0051r2.pdf), which calls this function `overload`. It was not quite ready for 17, but it will probably voted on as soon as that is done.
I think Billy's thinking of triviality; i.e. I don't think your example has a user-provided destructor. N4618 [dcl.fct.def.default]/5: &gt; Explicitly-defaulted functions and implicitly-declared functions are collectively called _defaulted_ functions, and the implementation shall provide implicit definitions for them, which might mean defining them as deleted. **A function is _user-provided_ if it is user-declared and not explicitly defaulted or deleted on its first declaration.** A user-provided explicitly-defaulted function (i.e., explicitly defaulted after its first declaration) is defined at the point where it is explicitly defaulted; if such a function is implicitly defined as deleted, the program is ill-formed. [ _Note:_ Declaring a function as defaulted after its first declaration can provide efficient execution and concise definition while enabling a stable binary interface to an evolving code base. _—end note_ ] No mention of bases... [class.dtor]/6: &gt; A destructor is trivial if it is not user-provided and if: &gt; - the destructor is not `virtual`, &gt; - **all of the direct base classes of its class have trivial destructors**, and &gt; - for all of the non-static data members of its class that are of class type (or array thereof), each such class has a trivial destructor. &gt; Otherwise, the destructor is _non-trivial_.
X-Post referenced from [/r/linux](http://np.reddit.com/r/linux) by /u/xuhdev [Parallelize make by Default](http://np.reddit.com/r/linux/comments/5hz2er/parallelize_make_by_default/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
"Everything should be made as simple as possible, but not simpler." - Albert Einstein
It looks like the implementation carefully avoids the inheriting constructor issues by not using default constructor arguments for SFINAE. Having a "pattern-match" utility function working with lambdas in the standard would have been great, the `constexpr if`-based dispatching in the example here is not that elegant in my opinion: http://en.cppreference.com/w/cpp/utility/variant/visit
Yep, added a note, thanks.
As much as I love make, this is off-topic for /r/cpp.
Ah, yes. Sorry for the confusion. With destructors it really generally does mean "nothing happens" but with something like copy assignment operators there is a difference. A double, for example, is trivially copyable, but the bit pattern you get when you use the assignment operator can be different than if you use `memcpy`.
A function with C linkage can throw though. It's stupid to do it, but nothing stops you. I think that the biggest obstacle to a "viral" noexcept is the same reasoning as with "no checked exceptions": it leads to maintenance churn.
Can you give a code example of how you would tag-dispatch to delegating constructors with mem-initializer-lists?
kudos for going the extra mile with the standard quotes
epsilon isn't terribly useful in practice. epsilon is the difference between 1.0 and the next value. If your numbers are much smaller than 1.0, then std::numeric_limits&lt;float&gt;::epsilon() is too large. If you numbers are much larger than 1.0, then std::numeric_limits&lt;float&gt;::epsilon() is too small to affect an addition / subtraction operation.
Yes, that's what I typically do. I see people do this with their own epsilon (e.g. 2e-23) though, and I was wondering why. /u/ben_craig 's answer makes sense. I guess since you're expecting things to be near 0 in that specific test you could probably do with a smaller number than epsilon() (which seems to be 1.19e-07f)
Typically, you multiply epsilon by a scaling factor that would put it in the range of the values in question. 
I'm not entirely sure, but why does the committee prefer to do things library-wise?
Here is an admittedly contrived example: C:\Temp&gt;type meow.cpp #include &lt;functional&gt; #include &lt;iostream&gt; #include &lt;type_traits&gt; #include &lt;utility&gt; using namespace std; template &lt;typename X&gt; struct is_is_void : false_type { }; template &lt;typename X&gt; struct is_is_void&lt;is_void&lt;X&gt;&gt; : true_type { }; template &lt;typename X&gt; constexpr bool is_is_void_v = is_is_void&lt;X&gt;::value; template &lt;typename T&gt; struct Meow { T m_t; template &lt;typename Callable, typename... Args, enable_if_t&lt; !is_same_v&lt;decay_t&lt;Callable&gt;, Meow&gt; &amp;&amp; !is_is_void_v&lt;decay_t&lt;Callable&gt;&gt;, int&gt; = 0&gt; explicit Meow(Callable&amp;&amp; callable, Args&amp;&amp;... args) : Meow(is_void&lt;decltype(invoke(forward&lt;Callable&gt;(callable), forward&lt;Args&gt;(args)...))&gt;{}, forward&lt;Callable&gt;(callable), forward&lt;Args&gt;(args)...) { } template &lt;typename Callable, typename... Args&gt; explicit Meow(true_type, Callable&amp;&amp; callable, Args&amp;&amp;... args) : m_t() { invoke(forward&lt;Callable&gt;(callable), forward&lt;Args&gt;(args)...); } template &lt;typename Callable, typename... Args&gt; explicit Meow(false_type, Callable&amp;&amp; callable, Args&amp;&amp;... args) : m_t(invoke(forward&lt;Callable&gt;(callable), forward&lt;Args&gt;(args)...)) { } }; int main() { Meow&lt;int&gt; mi(plus&lt;&gt;{}, 9 * 9 * 9, 10 * 10 * 10); cout &lt;&lt; mi.m_t &lt;&lt; endl; Meow&lt;string&gt; ms([] { cout &lt;&lt; "Kitty!" &lt;&lt; endl; }); cout &lt;&lt; ms.m_t.size() &lt;&lt; endl; } C:\Temp&gt;cl /EHsc /nologo /W4 /MTd meow.cpp &amp;&amp; meow meow.cpp 1729 Kitty! 0 Meow&lt;T&gt; says "I am constructible from a callable object and arguments. I'll call the thing, and then if it returns non-void, store that in my m_t. But if it returns void, I will value-init m_t." This is not amenable to `if constexpr` because by the time the ctor body starts, you've lost the chance to initialize m_t (you can assign to it, which is totally different). The example is contrived because in most cases, this is not necessary - e.g. in vector's constructors we call a tag dispatch helper function to do smart things for RanIt ranges, which could easily be `if constexpr`.
On closer look, all four of these headhunters are from the same firm, and probably sit in the same room. (In New Jersey.) 
Yeah, I guess it would look something like this: http://hastebin.com/wayoguxuda.cpp There's a trait `visit_struct::is_visitable` that checks if something is a visitable struct. I didn't document it, but it's there for folks to find.
&gt; I am using llvm version 3.4 You should really upgrade ;-)
**No**, this is a common misuse of epsilon. You probably wouldn't like how this function behaves on real hardware. For most numbers with magnitude larger than 1, `floatequal` will behave identically to the equality operator, only slower. For numbers close to zero, `floatequal` will return `true` even if the numbers differ by an order of magnitude or more. If integers are accidentally used, `floatequal` always returns `false`.
I wrote a simple match template for this purpose: https://github.com/amaiorano/TinyCompiler/blob/master/src/variant_match.h Which I use to manage a simple state machine for my tokenizer [here](https://github.com/amaiorano/TinyCompiler/blob/master/src/main.cpp).
Limiting the implementation to only "safe" calls would be the point. You could always use a catch-all to signal that you know better, like a `const_cast`, and the compiler could easily not propagate the nothrow requirement into such blocks. try { m.at(1); } catch(...) {} 
`numeric_limits&lt;T&gt;::epsilon()` measures the [ULP](https://en.wikipedia.org/wiki/Unit_in_the_last_place) for values of the same order of magnitude as 1.0. It is wrong to hard-code epsilons (e.g. `2e-23`) when you don't know the magnitude of the numbers in question. A more correct version of `floatequals()` might look something like: return fabs(a-b) &lt; epsilon()*max(fabs(a),fabs(b)); ... but even that is only accounting for the limitations of underlying (IEEE-754) representation. The math that gave you `a` and `b` might cause you to add an additional scaling factor. See also https://en.wikipedia.org/wiki/Loss_of_significance and https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html 
I will consult with you next time before posting.
The conditional allows for ground to collide with ground and sphere[0] to collide with sphere[0] increasing `grounded`. What you actually want is if (o1 is ground and o2 is sphere[0]) or (o1 is sphere[0] and o2 is ground) then grounded++. In general it's better to post your code to PasteBin as it can be hard to read on Reddit (especially on mobile).
My guess is that you only want one addition of the vertical force. As it stands, I am imagining every time through the loop it is finding the down key pressed and adding the z component again. You may want to keep a boolean that tracks whether the contribution was already added, and then reset when the key is released. You could also play around with events so that pressing the key once is an event.
Unless there's something I'm missing, `grounded` is set to 0 when the force is applied and (if the conditional were correct) only ever increased when contact with the ground is made again. If the conditional is fixed, there will be a bunny hop effect unless a flag tracking whether or not space has been released is added.
Haha, reminds me of one codebase I had to repair where there was one "global variables.h" file, thirty various header files (no classes, mind you, just functions roughly grouped), and one .cpp that included a surprisingly short main() function. The hardest part was the ripping out of the "global variables.h" file. That thing was everywhere (by design!)!
[`std::nextafter` is much more useful, in my opinion](http://en.cppreference.com/w/cpp/numeric/math/nextafter). It lets you easily determine if two numbers are equal to within 1 ULP, which is a much more useful definition since most operations under IEEE floating point are expected to be correctly rounded to 1 ULP. Of course this can only account for the inherent rounding of the operation, it can't account for other types of loss of precision such as catastrophic cancellation due to subtracting two very close numbers. Those are the kind of thing that you have to design into your algorithm to avoid explicitly, e.g. by rearranging the order that terms are computed. 
So I did my first phone screen with someone and the recruiter came back asking for timings for a second phone screen which I responded to and since then she has just disappeared. I did interview onsite with the Ads team in Seattle as well. I thought I did well on most of the interviews, the one that was terrible was a design interview and honestly the interviewer just seemed completely not interested. It seemed like a one way conversation for the whole hour. I'm hoping I'm not being rejected based on feedback from the other set of interviews or at least if that is the case, that someone would at least show me the courtesy of responding and letting me know. 
This is a seriously awesome piece of library code. Congrats Michael Park.
Please keep in mind that recruiters are busy, so it's difficult to always expect very tight turnaround times (even though we try our best to give quick feedback). I don't know how long you've been waiting, so I'm not trying to justify, but just keep in mind that it's not that they don't care, usually they just don't have the bandwidth given the number of applications. Also, have you tried to simply ping them before posting here? That being said, please PM me your real name and I'll poke the recruiter, to be sure. Regarding the Ads team in Seattle; I'm pretty sure A9 will not base its decision on interviews done for a different position in a different team and by members of a different team. We normally hire our people ourselves, and I've never heard of someone being rejected/hired solely on the basis of interviews for other teams. 
Destructors without an explicit noexcept(false) specification are implicitly noexcept(true), unless the class has a sub-object whose destructor is noexcept(false). So you usually should not bother about destructors. 
I'd rather not want the compiler to be required to prove my noexcept functions are really noexcept. That's a job for static analyzers and they have all informations to do that without making noexcept viral.
This actually works: template &lt;typename T&gt; class phantom_type { public: constexpr phantom_type(const T&amp; value) : value(value) {} constexpr phantom_type(T&amp;&amp; value) : value(std::move(value)) {} operator T&amp; () noexcept { return value; } constexpr operator const T&amp; () const noexcept { return value; } T* operator-&gt;() { return &amp;value; } constexpr const T* operator-&gt;() const { return &amp;value; } T value; }; #define PHANTOM_TYPE(TYPE_NAME, VALUE_TYPE) \ struct TYPE_NAME : phantom_type&lt;VALUE_TYPE&gt; \ {\ using phantom_type::phantom_type;\ }; struct A : phantom_type&lt;int&gt; { using phantom_type::phantom_type; }; struct B : phantom_type&lt;int&gt; { using phantom_type::phantom_type; }; struct C : phantom_type&lt;int&gt; { using phantom_type::phantom_type; }; PHANTOM_TYPE(D, int) PHANTOM_TYPE(E, std::string) // Takes A phantom type void add_to_A(A&amp; a, int x) { a += x; } // Will be used to show accessing members struct S { int m = 0; }; PHANTOM_TYPE(PhantomS, S) 
&gt;noexcept is a binding contract Not necessarily. I like to declare everything `noexcept` but not necessarily guarantee that in the future. The reason is the compiler generates less dead bloat code for exception handling. If you want you can `#define NOEXCEPT_FOR_NOW noexcept`, to indicate that it might change in the future.
In theory yes, in practice exceptions are low overhead as long as nothing is thrown. The compiler will generate code to handle the throwing case, but it will (mostly) be out of the way of the rest of the code, so there might encounter an extra jump instruction, but that is about it. While making getters `noexcept` since they usually return a copy of a small type, or a reference to a larger one, the same can not be said for setters. If the setter modifies a string, it very well might alllocate memory, which might fail. Here is an example of codegen: http://pastebin.com/bpNCtA5v tl;dr: Probably doesn't matter. Benchmark first.
I think the double negatives got you there.
Exceptions really are the cancer of programming. I dont want to even think about the subtileties that might occur if I label my string-setter noexcept and then once in 10000000 cases it does throw and I am stunned.
You got `noexcept(true)` and `noexcept(false)` reversed.
The subtleties? The program crashes, and that is about it. There is no memory corruption, the program just crashes as the standard requires. (unless you `set_terminate`)
Thanks, fixed in the comment.
Thanks! Was thinking of writing a little blog post about it, but wasn't sure anyone would read it. Now am thinking perhaps it would be instructive.
Just to add my 2 cents, the classic go-to article for FP arithmetic is [What Every Computer Scientist Should Know About Floating-Point Arithmetic](https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html). It's a bit dated, but the first chapters are about rounding errors and float comparisons.
I think that in some cases it's good to artificially limit stuff, like `const` methods. Maybe a `nothrow` keyword to signify that at any point, no called function may call `throw` ?
Looks awesome I want to use conan.
Thanks, that's very clear!
David Sankel has been working on a language-based variant and pattern matching, and gave a [talk on them at Cppcon](https://www.youtube.com/watch?v=k3O4EKX4z1c) (the first half is about `std::variant`, the second about his proposed lvariant). Bjarne has also written about his desire to get pattern matching into the language. So, fingers crossed. 
I did come across a lot of these but none of them seem currently well maintained nor very clean and easy interfaces for my use case. I just called it quits and am doing it using cgi + a db table.
And your point is? If you use std::is_pointer you would get the exact same result. nullptr_t is not a pointer type.
To install your dependencies, to see them resolved before you, and to check the signatures of their authors. - Conan the Developer
It gets rid of the need for a tag class, which is good. Does having inheritance affects anything? I adopted it, and kept the tag class based approach on a secondary branch.
Pinging Boost.Accumulators author /u/eric_niebler
Pull requests are a thing.
You probably meant "to blog about something".
I stopped reading at Perl script. 
I'm really excited about Conan. It learned important lessons from biicode and I think it has the best potential for a C++ package system. I'd love it to replace my company's internal C++ build system and remove this sore spot from C++ development (I have a lot of rust/cargo envy) If I've understood the docs... Pros * Includes a porcelain CLI * Allows any build too for any language * VirtualEnv: create custom development environments with tools sourced from conan * SCM independent * Single or multiple build files * Artifact scope: (name, owner, version, channel) * One artifact per arch, build_type, compiler, compiler.version, and combination of options * Options (build config) vs Scopes (e.g. conditional steps) * Recursive dependencies * Dependency overrides Things to improve * Separate build configuration from locking dependency versions (see [Cargo's lock file](http://doc.crates.io/guide.html#adding-dependencies-from-cratesio) ) * Compilers should be conan packages rather than relying on whats installed on your system * Good for reproducibility / traceability * Good for getting a developer up and running * Good for encouraging cross-compiling * Simplify bootstrapping especially for windows * Should be an executable rather than python script (e.g. py2exe, C++, rust) * Make declarative build configurations powerful enough that you don't drop people into Python so quickly * Decouple build config and plugin system from a programming language * Don't want to be stuck with Python2 for forever or _insert compatibility requirements here_ * Artifact "compatibility" * If an artifact has a C API, then I don't need to rebuild it if I use a different compiler * Most important when providing "system" libraries * Separate -dev from -lib artifacts * On windows, I don't need to download all the .dlls to build against something. * If -dbg isn't separate, then that should be too. * I only care about having all the individual pieces in a running state when I am building the top-level application. * Custom project templates * [workspaces](http://doc.crates.io/manifest.html#the-workspace-section) and vendoring which I'm hopeful would help with * Mono repos * Psuedo mono repos (separate repos to avoid rebuilding the world but all repos treated as one atomic piece) * More easily developing across disparate packages for a single feature * Package download performance ideas: * Download diffs or psuedo diffs when upgrading a dependency * One type of psuedo diff is to compare manifest files for packages and only download files that are different compared to an older version of the package * Distribute through bittorrent EDIT: Formatting
The blog post is a great read. I'm surprised this happened to Eric Niebler - is that part authored by him? Maybe it's from his very early days as a programmer and the library is really old. He seems like a person that wouldn't be as careless as the person who wrote that code seems to have been. :-)
Well after a lot of trial and error and reading other people's complaints, I don't think emscripten is really designed for this cin-cout-cin-cout kind of structure I have in this game. I know the program I made wasn't designed to be used this way, but I thought I'd at least give it a shot. Thanks everyone!
I'm a huge fan of Niebler's other work, but Boost.Accumulator's documentation convinced me to roll my own solution. IIRC it has a few `TODO`s in it. Edit: a quick Ctrl+F yields 23 TODOs in one documentation page. They all concern complexity, but it was off-putting enough to keep me from using it. A library is only as good as its documentation.
Is he an Obrien?
borland still exists?
The pdf doesn't load for me right now, so [here's a version from Bjarne's site](http://www.stroustrup.com/hopl-almost-final.pdf).
Did you time travel here from the past?
&gt; what folks in this sub do with people that dare to disagree. A classic example of denial there - "I'm not wrong, I'm just a victim of a circlejerk/oppression/witch hunt..." Or you're just a bad troll.
And it tells why it is very fast when you know how to use it. The point you are trying to make is usually a newbie issue, copy vs reference semantics and some other gotchas. 
&gt; If other successful languages are the frame of reference, then I would say that C++ was a victim of its own marketing as the 'experts language' At CppCon this year, there were several folks who mentioned that C++ is seen as a language by geniuses for geniuses. In my personal experience (for whatever that is worth), I have found that this stems from how C++ is taught to students. Getting the "C with Classes" perspective out of the classroom is a big concern for a lot of folks these days. &gt;as well as the failure of its committee to react to enormous changes in computing: the Internet and the sharp drop in hardware prices for CPU, RAM, and GPU compute. The key failure on the committee's part was not realizing that they could put out a new standard whenever they wanted. There was a misconception that after the '03 TS, they had to wait a few years (5 I think it was). This delayed C++11. But now we have the three-year train system in place, so we should be getting better library features faster. &gt;In some sense, C++ was poorly positioned for the future as CPU and RAM increased in ways that would have been difficult to predict when C++ was first introduced... The memory and core explosions of the early 2000s did help languages like Java and C# become more popular because you could abstract away the hardware (after all, you had a *Gigabyte* of memory!), leaving C++ as a "fancy C." Then some crazy person decided that our telephones needed to talk to the Internet, then show us moving pictures, and then they started talking to us. But our telephones weren't just physically small: they had slow processors and tiny amounts of memory- very reminiscent of desktop machines in the 90s. So C++ found a new way to be helpful. But now we have a much bigger problem: the power wall. C++ can help us there, too. I'm not saying anything new here, I just think C++ is uniquely positioned to become a smaller, simpler language that can build zero-cost abstract software without me needing to hook up my telephone to the nuclear power plant.
Great post! I love "geniuses for geniuses" - it very nicely encapsulates perception of C++.
EDIT: OK. I'm downvoted to support C++ in /r/cpp. Thank you folks! This is such a stupid argument. &gt; more complex than C and was perceived at 1990s as a slower version of C - it prevented from C system programmers to flock to C++. Linus did not helped either with his statements about C++ Is this really an important statement for modern C++? C++ **is** more complex than C. So is any other language. Syntax-wise even Python is more complex than C. This means nothing. &gt; More complex than Java What does this even mean? If you're talking about templates, I would much prefer C++ sane templates instead of braindead Java generics. Complexity of C++ always boils down to how adept you're at in concepts you find complex. &gt; missing many useful libraries/frameworks at that time - which prevented from beginning programmers to jump on it. Who really cares about C++ being beginner language. C++ has never been the beginner language. Why does beginner's preference affect a language's performance? Do we not target to get better code, which, in practice, beginners cannot write? Do we not want to create languages programmers (not beginners) can feel at-home and easier to program?
I kinda see his point, though. Don't get me wrong, I'll choose C++ anytime over C, but I'm pretty sure I'm not good enough a programmer to make the kernel any better. Linus is one man controlling the dev of the kernel, and by and large, has done a pretty solid job. If C helps him reduce the amount of chaff to go through, he's got more time for important stuff. Of course he seems to have a strong dislike for the language itself, but you can't account for taste...
Why not use a null check instead of that magic value? Why not use thread local instead of static? If you care about performance, your code base is unlikely to be single threaded. Does it do anything other than store the offset for the last time it succceeded? 
Linus has been using C for so long, i imagine he just doesn't understand how well he knows the language. Just because you can be a well practiced expert like him, in 10+ years, should be reason enough that the language is fine! ... I agree, although while I've never tried or worked on a large scale C project, I've done it many times in C++. I wonder sometimes if it's really just different types of abstractions/patterns and maybe it's not as bad. Then you remember the philosophy of C and how it's always your job to do everything. Then the 'power' of the standard library, especially in today's world. It takes a shit load of time to learn how to use that language correctly and build up all the habits required not to make 'stupid' mistakes using it. I think of C++ mostly the same.. I just think it makes code origination and structuring easier / more commonly understandable.
1. I can't use a null check, since there are casts where the offset is zero, if the derived class has no members for example. 2. I implemented this for our codebase which is only single threaded. I will probably make it multi-threaded at some point. 3. Yes, check out the "How it works" section. I also store the vtable pointer
Its from 2009, so its a bit outdated...
It would be nice if a robust web framework was available for C++. 
So the MSVC dynamic_cast is still a slow mess of multiple string (class name) comparisons? I tried stepping into it back in the MSVC6 days, and almost never got out. :) Do the other compilers implement dynamic_cast in a faster way? If so, why cannot MSVC do the same?
`modules` and `concepts` are the results (in future) of that thought process. 
FYI, I just checked in support for multithreading.
As an Android developer who deals with both Java and C++ native cross-platform code, I don't find one language significantly more "expert" than the other. Memory management is more intricate in C++, but it also promotes stronger awareness of what you create, who owns it and and when it is deleted. In Java, it is very easy to leak a large object e.g. via an implicit reference from an inner class, exactly because you don't see it explicitly in the code. Also, mobile device industry is nowhere near the state where performance or memory efficiency, and especially power efficiency can be routinely sacrificed for ease of development. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. 
- Regarding bootstrapping for Windows, not sure what you mean, but there is an installer here: https://www.conan.io/downloads. It is generated with pyinstaller, so it is an executable, it does not require python installed in your machine. It might have a few minor caveats, but is good for most purposes. - Artifact compatibility can be achieved "widening" the settings in the conan_info() method of the recipes. You can declare something like "self.settings.compiler.version='Any'" if you know (e.g. C ABI) that it will be binary compatible - There are already some compilers and other tools packed as packages: https://www.conan.io/source/mingw_installer/0.1/lasote/testing, https://www.conan.io/source/cmake_installer/0.1/lasote/stable. 
[removed]
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5iaqj3/need_help_with_school_assignment_regarding/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
For me C++ was a victim of copy-paste compatibility with C. Sure it helped to get C++ adopted, but then we got: - memory corruption issues and UB inherited from C subset - MFC and ATL because developers couldn't grasp how Turbo Vision, OWL or VCL way better C++ libraries were, instead of thin class wrappers over C APIs - Lack of proper C++ libraries, because many companies would just throw a C API over the wall leaving to ourselves the pain of writing our own saner C++ bindings Nowadays I happily use it as layer between Java/.NET and the hardware, when the use case of library usage or performance asks for it.
When are we getting modules? C++33?
I attempted to disambiguate with static. The point is that the map is constructed somewhere else. Read it as: const map&lt;int,int&gt; global_map = {{1,1}}; int foo() noexcept { return global_map.at(1); }
So... C++ is too fast and good, so you can't improve on it.. so no one uses it because it's too good. Is there something here I don't understand? The arguments does not really resonate with me. 
How would anyone guess the meaning of `*dest++ = *src++;`?
Does anyone know what this part means? &gt; * Added pattern substitution for variable expansion `%{variable/pattern/replacement}` (and `%variable//pattern/replacement}` for replacing multiple matches)
Ok but most of the time you need to do something like this [] (auto c) { return c++; } C# lamdas are somewhat similar as well (input parameters) =&gt; {statement;} 
~~I'd guess it is used for regexes in the search-replace feature~~ seems not! 
&gt; &gt; &gt; Linus is one man controlling the dev of the kernel, and by and large, has done a pretty solid job. If C helps him reduce the amount of chaff to go through, he's got more time for important stuff. Linus's rant is only about kernel code. For userspace code he had his software ported from C / GTK to C++ / Qt
C++ is great for large scale and/or for teams of mixed expertise (these often go hand in hand), because C++ is better at letting you hide stuff that other devs shouldn't (or don't need to) see. And great it making it hard for you to do stuff that I don't want you to do. However, if you are an expert and/or someone who wants/needs to know all the details about what's going on, or you think "I know what I'm doing", then C++ can just get in your way. So you can imagine where Linus fits in the above. Also, for the areas Linus doesn't want to know every detail, he relies on other experts - maintainers, etc - people, not code. So instead of "I trust this class because of how it was written" you can do "I trust this code because of who wrote it". And, if necessary, you can dive into the code, in cases where trust has been questioned (due to a bug or whatever). C may be easier to debug when every line is questioned (as C++ hides stuff sometimes). That doesn't mean C is easier to build or maintain or build on. "What's going on" (low level) is just more bare in C, and that can help debugging. It's a trade off. (I like C++ in that trade off.)
Nice diagrams. I must say that whole root name/root directory/root path feels way over-engineered. In `build2` we have our own `path` (here is the [HEAD](https://git.build2.org/cgit/libbutl/tree/butl/path) if you are interested) and there we just have root directory. For POSIX it is `/` (i.e., empty name following by a directory separator) while on Windows -- `C:\` (i.e., `C:` followed by a directory separator). Of course this doesn't support things like `C:foo` (file `foo` in the current directory of drive `C`) but sure is a lot simpler (and more logical, IMO). The same goes for trailing slash -- in `build2` it (syntactically) signals the directory and its spelling will be used if you write `dir / file` but stem/extension functions still operate on the last component, not some imaginary `.`
Is it an issue when compiler merges v-tables?
Off topic, but it's a little unfortunate that C++ requires you to know about pointers, C arrays, null-terminated C strings etc just to write a `main()` function that reads command-line arguments. It would be nice if the standard could allow a more modern form as well, something like int main(std::initializer_list&lt;std::string_view&gt; args) (Just off the top of my head, I know this isn't mutable like `argv` is.)
Definitely good educational reading, thanks.
Very interesting. Thanks for sharing. For the multithreaded case, you might want to consider using atomics instead of thread-local storage. As long as atomics are lock-free for ptrdiff (I didn't check but they should be) they might be a little more performant. 
I just tried on my Mac, Compiler Explorer and Wandbox. They'll be comin' round the mountain when they come. It'd be cool to have a web site that generates these diagrams (as SVGs) for an input filename string. Some JS-fu required. Then integrate that into cppreference.com!
More importantly for me, Qt 5.7.1 has released. Finally able to disable docking animations! Weird bugs all around. 
&gt; OWL as in Borland? Wow, you and I might be of similar vintages! Probably! :) One reason why I was never impressed with C, and C++ was a more natural path for me, was that I happened to have access to Turbo C 2.0 and Turbo C++ 1.0 about the same time. On those days I was using Turbo Pascal 6.0 and did already a few simple Turbo Vision applications, besides some MS-DOS system level programming stuff, like everything on those days that needed to use the BIOS directly. So in terms of security and feature wise, C was pretty behind times already on those days, but C++ (even C++ARM) already provided quite a few features parity wise with TP 6.0 (some of them copied from C++ actually), which allowed a similar safety level.
Very nice article. High jacking this thread to ask a question about filesystem::path in general: &gt; Objects of type path represent paths on a filesystem. Only syntactic aspects of paths are handled: the pathname may represent a non-existing path or even one that is not allowed to exist on the current file system or OS. I would assume that the reason for this would be to avoid overhead by validating that the path object is valid, but has there been any discussion about this during standardization? Not validating that a path exists makes perfect sense of course (the library user might want to test if exists, create it or similar), but it would be very nice if there was some way of having constructors etc. throw an exception if the object ended up containing an invalid path. I am currently using boost::filesystem::path to store paths given from user input and having a way to validate that they are indeed valid paths before failing in mysterious ways somewhere deeper down in the code path would be very useful. Anyone who has some insight or arguments against that? Thanks.
I never said I'm right, actually I never stated anything with regards to whether the technical content is correct or not. My main beef was just that the response of that person was very cocky, and this blog post uncovered what's probably a few mistakes in the library - which is fine, everybody makes mistakes and (hopefully) learns. Anyway, thanks for the reply, and I hope you guys can sort that out and use all this to improve the library :-)
Another hilarious thing is that then the compiler removed all the C calls away and replaced with machine code :) 
Nice work! Caching is a great solution when it can be used. We know we can improve the performance of `dynamic_cast` in MSVC and we have some work on the books to do so. We can't get the 25x your library provides as we can only ship generally correct solutions. But we can make it faster. And for code where this caching library works it's a nice approach. 
My following comment is not so much related to Boost.Accumulator specifically. My sincerest respect for this very honest reply. I find that with Boost, it's sometimes very difficult to find out which libraries are still properly maintained and which ones are not. You're looking at a few dozen libraries and have no idea which ones are a good bet to use and probably future-proof, which ones haven't been updated in a while but it's because they're "complete" and reasonably "bug-free" so it's fine to use them, and which ones are not recommended to use anymore because nobody has looked after them in a long while and also they don't have a large enough user-base to uncover potential problems and bugs. I don't have a solution for it unfortunately but I do think it's a problem that boost has gotten larger and larger and you can't blindly recommend 100% of the stuff in it.
Of course, this will only actually be faster if your access pattern is repeated dynamic casts from the same base to a given derived type (since it is a cache).
Agreed. I was curious about this "faster `dynamic_cast`" and wanted to see some gory implementation details, but it's just a cache that uses `dynamic_cast` internally. As C++ programmers, we're drilled from an early age to _not_ use `dynamic_cast` at all, preferring virtual functions instead because 1) it's slow, and 2) it's tempting to make a type switch. With experience, we learn that it _can_ be useful in some situations, but I'd never put it in a tight loop or in any context where it needs to be called repeatedly. It's not even an interesting intellectual exercise. It has a few statics in a function template and sets them with `dynamic_cast` the first time.
&gt; lambdas look like line noise &gt; &gt; [] () -&gt; int { return 1; } Well sure, because you added noise to it: []{ return 1; } Looks pretty darn elegant to me.
I know how to work around it and, with all respect, I find your solution to be very hackish. My question was about why a class handling paths didn't have any way of validating that it's actually a valid path. I would think that would be an obvious feature. I'm fairly certain that on Unix almost any string can be a valid path as long as it's properly escaped (which might be a feature a path class as well), but I'm also fairly certain that there are some paths that can never be valid on Windows. So, not really asking for a solution, more asking if there's an explanation for this ;-)
Yes, I want to jump to tree location of actually opened file in editor. edit: I'm using Qt Creator 4.1.0 
It caches only the last dynamic_cast performed, not per-object, so it stores only 2 pointers total in static local variables. Theoretically this should be thread-local, as he stated in his reply above, but it's not right now. Edit: wrong, see /u/erichkeane 's post
&gt; (or just find it tediously long to type) Goodness gracious. Could we please stop using typing as an argument against anything? If typing is a problem, maybe software development isn't for you? I mean, do you think Stephen King, G.R.R. Martin or Tolkien ever told themselves "Gee, whiz, that word would be perfect here but I won't use it because **it's too long to type**!"? (I'm not picking on you O.P.. This is just one tiny battle in this huge crusade I'm fighting. ;))
Thank you!
this would not work for a valid path in a folder that you do not have reading rights for
Oh, okay, so it only provides a speedup in very narrowly defined and probably rare situations. Thanks for clarifying. It seems like that would give incorrect behavior if you loaded a dll, dynamic_cast to a type in that dll, unload the dll, and load another one. The vtable pointer that was cached is not only invalid now, but could point to another vtable by coincidence.
Yes, this is right, in our codebase this was a huge improvement though (about 40% total program speedup for our autotests).
I totally agree on that, but we are talking about a huge codebase here where rewriting is not an option unfortunately. 
Yes
It might be an issue if the compiler chooses to share the vtable of two objects with different offsets to the base class, but it seems MSVC does guarantee unique vtables (at least it did in all of my tests, and our huge codebase, and memoized_cast also depends on it). It might be very well that other compilers (which are not supported) perform this optimization.
Try Wt http://www.webtoolkit.eu 
https://github.com/tobspr/FastDynamicCast/blob/master/fast_dynamic_cast.h#L84 and ~15 lines after
&gt; With the correct numbers, the output from the implementation of P2 in Boost.Accumulators matches the output in the original paper assuming round to nearest. wow you don't think that might be worth mentioning in your blog post?
It's not just purist, it's simply a bad argument. The reality is that Java provided a very portable experience, in tooling compilers libraries and runtime that cpp has still not figured out. Being dismissive like he just was is a big part of the divide. 
I can only imagine the amount of anguish the committee endured to come up with a unique syntax for lambdas. It's not great, but once you get used to it, it becomes just as parseable as the rest of the language (YMMV). &gt;How would anyone guess the meaning of [] () -&gt; int { return 1; } Would a newcomer also guess that these two things do the same thing (although they don't have the same *type*)? [] { return 1; }; []()-&gt;int { return 1; }; 
Wow! You don't think, maybe, like I figured it out since writing the blog post, contacted Raj Jain to confirm my findings, and will write it up when I get a chance? See also https://svn.boost.org/trac/boost/ticket/12688#comment:2
Pretty sure its already there. There is a little button above the project tree in its docking tool bar that enables this 
sorry i meant as an addendum. it was clear that the blog post was written before that revelation. i'll just reiterate your closing remarks to any reader who finds that blog post not through this thread: &gt; Clearly, there is something wrong with the implementation of the P2 algorithm in Boost.Accumulators.
Oh yeah, I'm with you on that one. But yes, there are still people that use that argument unfortunately.
Sweeeet.
There is a file URI scheme one could validate against. https://www.wikiwand.com/en/File_URI_scheme
You're missing a large step in the argument. Academics (and other researcheers) want something they can write papers about, and get those papers published. Now, consider the situation (for example) when Java was fairly new. He could choose to write about C++ memory allocation. If he did, his paper was probably going to say (in essence) C++ typically involves allocating more, smaller objects on the heap than C did. After ten thousand hours of research and five thousand hours of testing, we found the following modifications to existing allocation code, that give approximately 8-10% improvement for the following programs. He could also choose to write about Java. If he did, his paper came out closer to: after 5 hours of research and 100 hours of coding, we came up with the following garbage collector that improved speed by a factor between 7 and 10, compared to Sun's JVM. Now quick: which would you rather do: a huge amount of hard work to get (maybe) a 10% improvement, or a tiny amount of easy work to get a 10x improvement? Which sounds enough more impressive that it stands a good chance of getting published? So, many academics and researchers ran away from C++ as fast as they could. Likewise, magazines and journals stayed away, because most articles basically boiled down to: "don't write unnecessarily horrible code." With other languages, there were often lots of "tricks" that made it easy improve execution speed, memory usage, etc., often by orders of magnitude. With Java (especially early on) it was often a matter of simply choosing a lesser-known part of the standard library, and pointing out that (because it was written in C++) by calling it instead of writing your own, you could get approximately the performance of reasonably written C++ relatively quickly and easily. An article telling a C++ programmer how to get the performance of reasonably written C++ doesn't really grab the reader's attention quite so much. Since they couldn't write a lot along those lines, people who wrote about C++ often wrote about odd little corner cases in the darkest nooks crannies of the language spec. What we see now is the natural result of those: people view Java as fast and C++ as unfriendly and full of odd corner cases. Both are true to varying degrees, but both are (for the most part) fairly misleading about the characters of the languages anyway.
Well they don't have to write "about c++" they could write using C++ though. And it ignores so many other uses of programming languages than research and academics.
FWIW video I did about it: https://www.youtube.com/watch?v=-3fVp0U4xi0
You're right, I don't know why I didn't notice that before.
C++98? No thanks. C++14/17? I actually like the language now, its no longer hideously crap (merely somewhat bad in many places)
I completely agree, but I still do not think it is the best fit for the job of making websites.
With thread local storage you need to execute the "slow" branch exactly once per thread. With atomics that would be the worst case, with the best (and most probable) case being just once per process. If you application relies on several short-lived threads, the atomics approach is bound to scale better. And I didn't mention the potential extra cost of accessing thread local storage. I said best/worst case because you don't need to do anything fancy with the atomics (in particular, you don't need a compare-exchange loop): since the slow branch always computes the same number, you can tolerate executing it multiple times in the unfortunate case that multiple thread enter the dynamic cast for the first time concurrently.
How is Java's portability related to language design and the fact that its templates are braindead shit? You could make Java with exact same C++ syntax and semantics and compile it to a virtual machine. Your argument is invalid.
and no raw anything (loops, new/delete, threads)
As strange as it may seem, the C++ Standard does not mandate a library implementation of library features. The Standard only mandates a library interface and a defined a behavior. This is usually good, since it decouples certain features from the language. However, nothing forbids an implementation to define, for example, `std::variant` as an alias for `__builtin_variant` and do everything with compiler magic. Of course, implementations do that only if there's a good reason, for example if there's some behavior that can't be expressed in the language. &lt;atomics&gt; is a clear example of that.
clang bug report for the same optimization: https://llvm.org/bugs/show_bug.cgi?id=21327
took me 2min to do a find in files in the source of devcpp, here is what I found (file macros.pas): http://pastebin.com/STzThA7k but you should really use an IDE that has been updated in the last 10 years...
In the last part of the blog post, the author of the blog post seems to misunderstand what is being said about garbage collection. In C, addresses are an abstraction; a garbage-collecting implementation might allow objects to change physical address, without changing the C address. Most implementations of C directly map physical addresses to C addresses. Actually that isn't even true on modern operating systems, the MMU maps physical addresses to a virtual address space. Different processes might use the same address value simultaneously for objects which live in different physical addresses and so on. The garbage collecting C implementation is similar, it will maintain a map between C addresses and OS addresses.
Much silliness. Pointers are locations of data. If the LHS and RHS in a pointer comparison contains the same 'location', be it a physical address, a virtual address, a custom whatever-address, they should match. Anything else is a bug, whatever the standard says. KISS. In every system I can name a pointer comparison will compile down to an integer comparison on the instruction level. 
Thanks a lot for your answer. I meant syntactically valid and I hadn't thought of all the different limitations based on which filesystem is in use, I had more or less thought "Unix: these limitations, Windows: these limitations". I can see that testing for a valid path would require touching the filesystem one way or another which brings us back to your first point. Makes sense. Thanks for taking your time to explain.
I am by no means an C expert but couldn't the compiler see this as UB if they stick to their interpretation?
&gt; I think that the biggest obstacle to a "viral" noexcept is the same reasoning as with "no checked exceptions": it leads to maintenance churn. Yeah, in most uses cases trying to write a function that can't throw in absolutely 100% of cases is nigh impossible or only limited to tiny toy functions. Pretty much anything can throw, like allocation. My take on `noexcept` is that it doesn't mean that it's absolutely physically impossible for it to throw, rather than it means that it will only throw in a "can't happen" type of situation, where the state is so munged up that crashing is the only option anyways. (Memory alloc is failing, what were you going to do anyways, *allocate* an error message?)
Could there be a problem with alignment, if the size of one of the structs is not a multiple of 4 or 8 byte and the compiler adds padding?
Just because right now we have a flat uniform memory on most systems does not mean this will stay this way. Who knows, maybe in 10 years we will have more special processors for special tasks that have different memory regions. Maybe someone comes up with a new design where things will be different. The question is, why do you want to be able to compare arbitrary memory regions? Is it that important to define now once and for all how computer memory has to look like?
Certainly not. Numerous things were removed, such as trigraphs, `auto_ptr`, and `random_shuffle`.
The problem is that the layout is completely independent of the language. There is not even a guarantee that pointers are numbers, just that they compare in certain circumstances. The problem with making the compiler 'know' what the linker is going to do, is that you then have to program the compiler with knowledge every linker known or unknown, since each can do the layout differently if they wish. I think that the behavior is right as-is, the cost of allowing an abuse of the language is high enough that I'd rather not see the languages changed over it. 
Yes, there is no guarantee that they are located next to each other. But the point is that the standard says that the comparison must evaluate to 1 if they happen to be next to each other: "Two pointers compare equal if and only if [...] one is a pointer to one past the end of one array object and the other is a pointer to the start of a different array object that happens to immediately follow the first array object in the address space." And clang does honor this.
At least it's not Turbo C++.
Have I been waiting for this talk!
They happen to be next to each other in some implementation of the compiler and linker. So what's the point if the very first assumption depends on the implementation anyways?
The point is that the compiler must generate code for this comparison and cant determine the result at compile time.
Then what's the point of a result that depends on the implementation?
Maybe its to determine how the implementation works.
Oh I'm all for getting rid of this stuff! Cleaning up these bits of the language goes a long way. New people don't have to discover `std::unary_function` and wonder when to use it. No more escaping question marks in string literals because trigraphs even take over those.
Well, I see that C++ is well on its way to reinventing Common Lisp.....*poorly*. 
It is pretty obvious that they consume more energy because more instructions are executed for same operation. Though i am pretty sure difference in power costs is way less than difference in development and maintenance costs. People are writing websites in certain languages because its more worth it than writing same thing in other languages.
&gt; There is not even a guarantee that pointers are numbers, just that they compare in certain circumstances. If that's the case, how can uintptr_t be a thing?
I'd assumed the people cost more than the power, but I'm thinking more about environmental concerns.
The comparison functors std::less/std::greater/etc. are guaranteed to work globally. Edit: at least I think so? Otherwise std::set&lt;int*&gt; would have issues.
Yes it would. So to comply with the C11 text, the compiler would have to jump through hoops .
IANALL but I think pointers are *castable* to (some) integer types, which does not mean that they actually *are* numbers.
If do not think there would be enough gain to be practical. There are lower hanging fruits for sure.
Bug reports are off-topic for /r/cpp. When uncommented, the "error" line compiles with VS 2017.
What a shame xlC and aCC are so far behind for those of us who have to support those platforms
You will still need to use std::make_shared ;)
I can cast back and forth between and int and a float, but that's not a guarantee that round-tripping never loses anything. In practice, pointers are numbers. it's just not a guarantee from the language so it can be used on hardware with exotic ideas about memory.
It is simply an integer that losslessly converts to a pointer and back. C/C++ standards guarantee that pointers INSIDE memory blocks are comparable, but there is no promise that you can get from one memory block to another, so comparing them doesn't make sense. If I was on a system where memory blocks were separate ethereal being, (or other non numeric unimaginable implementation) the implementation could simply issue an ID in a hashtable when you cast to uintptr_t. In that case, ordering those uintptr_ts would simply give you the order in which they were issued (or even some arbitrary guid!). C++ in particular (less so in C) strives to not make assumptions about the underlying storage medium.
*sigh*
&gt; Yes, it's very different in that "" has length of 1. It's a C string, char *, it's length is 1 and it contains /0, the delimiter. No. If I make a string `std::string str{""}`, I'm going to find that `str.size()` is zero. Similarly, in C, `strlen("")` is zero. "" is a zero length string no matter what context you are in, you are mixing up terminology and confusing things by counting the null character delimiter. &gt; That's like saying that a huge error message conceals the error. The exception happens because there's a problem. No. The point is that the error could be detected during compilation or by static analysis tools at built-time. That's the "loudest" kind of error. If instead you change it in to a runtime error, you are concealing the bug, by making it quieter. Indeed, it's counter-intuitive at first, but actually it's totally in line with the mainstream views of C++ that errors should be made compile-time rather than run-time whenever possible. Again, this is sort of the point of the article, you might want to try reading it again more carefully. The exception is bad because it creates overhead -- the compiler has to generate code to throw the exception and insert null checks for this string. Everyone who calls the `std::string` ctor has to accomodate the fact that this exception is thrown and could potentially be caught -- how much overhead that creates depends on how you implementation deals with exceptions, it might be a lot and it might be little. But no one actually ever catches this exception -- it's extremely complicated to handle such errors. You can't "go find the function" that is doing `std::string{nullptr}` and rewrite it or something, and the exception gives you no idea why this actually happened. So in reality no one catches it and it just terminates the program. I'm not even sure if it's documented how to catch it -- it's undefined behavior anyways. `std::bad_alloc` is a great exception. It means unambiguously you ran out of memory, it usually fixes the problem itself by freeing a lot of objects on the stack and calling their dtors, and there's usually reasonable places for you to catch and handle and recover from it after you have more memory. This `_M_construct` exception is a terrible exception. It's like if they had a `std::your_code_is_fucked_exception`. You can't realistically catch it somewhere and recover from it an continue -- some function was written wrong and constructs a string from a `nullptr`, which can never make sense. And if you recover by just trying to run it all again, you'll probably get the same thing again. In fact it would be far better IMO if they do what you suggest and "make a huge error message". They could instead write `std::cerr &lt;&lt; "fatal error: std::string constructed from nullptr\n"; std::abort();` or `std::terminate()`. That would be much much better than throwing an exception, since at least there's no overhead throwing an exception that *could in principle* be caught but in reality is everytime just going to call `std::terminate()` anyways, since you can't realistically handle this problem in an exception handler. Still not as good as skipping the null check entirely, making `std::string` faster, and relying on static analyzer to catch this if someone messes it up. If you want to have constant null checking and bounds checking, go write some java code -- half the reason to use c++ is that it *doesn't* have unnecessary checks like that. So it's bad if `std::string` does.
std::less does require total ordering but it is controversial see my [Stackoverflow answer](http://stackoverflow.com/a/31151779/1708801) for some background.
OpenCL has similar restrictions, where pointers belonging to different address spaces have different representations and cannot be compared.
If you use a reference, both the move and copy operators will be deleted by default, and cannot be implemented correctly in many scenarios. It also requires writing a custom constructor. Pointers work much better for POD types for these reasons.
For your theoratical perfect OOP code, it can be fine. In the real world, I would make it a pointer, since that's essentially the same. EDIT: I am beieg downvoted si let me ellaborate. alse please don't use the downvote button as a disagree button. If yiu think I am getting it wrong, please explain to me what I am getting wring. Having a reference in a struct is practically the same as a const pointer en thn sense as 'type * const var'. Both can only be assigned once, both can be null, and both will increase your class/struct size by sizeof(void*). If you are going to stick a const variable in a class, it will break the assignment operator and is generally going to be a mess. The fact that this pointer is constant really only restricts yourself, it will not make your code faster or better. Yes, when you have 'perfect software design', whatever that is, it can make sense to create a reference since some of the smantics are difwerent, but when you actually want to get work done, it makes no sense to prefer a reference over a pointer. 
Not the same. Pointers have optional semantics (can be null) while references assure you that they're initialized.
Consider: struct R { int&amp; _x; }; struct W { std::reference_wrapper&lt;int&gt; _x; }; int x = 0; Using `int&amp;` prevents copy/move-assignment: { R a{x}; R b{x}; auto c = a; // c = b; /* does not compile */ // c = std::move(b); /* does not compile */ } Using `reference_wrapper&amp;` allows copy/move-assignment: { W a{x}; W b{x}; auto c = a; c = b; c = std::move(b); } Depending on what OP is doing, it could be beneficial to have the copy/move-assignment generated by default.
But you have exactly the same "manual checking" to do with smart pointers, because you have to know your code organization to prevent cycles and use weak pointers at the right places. If you don't think of ownership when using `shared_ptr`, you *have* memory leaks. And don't get me started on `std::enable_shared_from_this` which has a tendency to permeate your code base and cause mostly pain and grief when you have a tiny little bit of inheritance. The couple : `shared_ptr` &lt;-&gt; `weak_ptr` is more or less the same relationship than the couple `value &lt;-&gt; reference`. Besides, `shared_ptr` has a **huge** cost. I worked a bit on a physics engine, and ported it from `shared_ptr` everywhere to values + references. The result ? We were able to have more than 30 times more objects being handled by the engine. 
&gt; All solution that relay on manual checking and control - are bad and should be avoided if possible. Isn't that kind of the opposite here? If you use `shared_ptr` your code is going to be littered with checks that the pointer is not null, whereas with references you _know_ that it cannot be.
Speaking of dynamic_cast and RTTI complexity on MSVC to start with, why is your object structure so complicated compared to GCC/Clang's ABI? You require about 16 objects for a 3-class hierarchy, where the GCC/Clang ABI gets away with 3 objects.
Indeed. It's also not nullable so you still get the main benefit of references. Is there any overhead between `reference_wrapper` and `&amp;`? 
No
Helps on MSVC2012+, but not before that point. You can also inherit from (for example) boost::noncopyable to avoid them. You can also just disable the warnings project wide, as they never serve any purpose other than to warn you for a known thing.
exactly, in callgrind the atomic primitives were at the top by an order of magnitude, even though the data store was only accessed by a single thread. I would love compiler vendors to allow to disable the shared_ptr thread safety "if you know what you're doing" but currently as soon as you use `-pthread` in GCC you get this overhead
Right I had kind of a brain fart about the null check. My main gripe with `shared_ptr` is that it's easy to create situations where the order of destruction is not well-defined and end up with leaks.
Well they don't support Windows CE either!
A null check in the vtable, not the offset.
I agree with you that `gsl::not_null&lt;T&gt;` may be better/more idiomatic for the case I'm describing, good point.
Hard ABI breaks are hard. But good suggestion, thank you. 
or massive callstacks when destructing them, if you're not careful
My bad you're right
Don't know if anyone else has said this. What you are looking for is a std::shared_ptr&lt;T&gt;.
The rationale behind returning a ```shared_ptr``` is: "someone somewhere created this object and I can share it with you too". If some API returns me a ```shared_ptr``` to something, you can bet I won't, not even for a second, think it might be ```null```. Now, that's very, very different, than sharing a resource that may be reasigned or freed at any time and for that the best construct would be a ```weak_ptr``` instead. There are really very few cases where ```null``` check makes sense with shared objects. _Edit_: WRT your example, if some API returns me a ```shared_ptr``` to a logger I assume the logger was already created by the time I make the ```getLogger``` call. It would make no sense to return ```null``` here as I have no use for a null logger. If, for some reason, it creates a logger upon request, better it throw an exception as something went very wrong, or at least return an error code.
Really not sure what you mean here. Phil is very active recently on github writing CATCH 2! Last commit was two weeks ago. He may not have been willing to merge changesets to CATCH 1 as it's going legacy soon. And BTW, Phil does read here, he may well reply to this.
Did you even read my post? Loops are super easy to detect. Needless to say how much artificial this example is and scream about bad architecture. And how it makes reference valid? Well instead of leak you will get a UB and probably crash, how is it better. Correct usage of refs will cost you 100x more energy and inflexible and you have no proper control over object state. What is your example point? You can shoot in your foot with C++ - yes you can. But with shared_ptr you need to write crazy spaghetti code, while with reference it is super easy to miss some branching. And you can have deadlocks with multithread, lets never use more than one thread. That's crazy logic you have here. Like seriously what are we arguing about? Are references are more safe, flexible, robust, industry standard and easy way to design your classes? No way. And this was an OP question. &gt;&gt;that's exactly the reason why I'm using C++ No. You write C code and compile it with C++. If you such a purist about performance write in C.
&gt; Loops are super easy to detect. Detecting loops in a program like this is a non-decidable problem, so no, it's not "easy" by any means. If you want pragmatic answers, just look at the accepted answer [here](http://stackoverflow.com/questions/776042/how-to-detect-cycles-when-using-shared-ptr) : "I haven't found a much better method than drawing large UML graphs and looking out for cycles." &gt; And how it makes reference valid? Well instead of leak you will get a UB and probably crash, how is it better. What I'm saying is that it does not matter if you use `shared_ptr`, references, raw pointers : unless you use a garbage collector (and get all its drawbacks), you **have** to design the ownership semantics of your software. There is no way out of this if you want your program to be correct. 
Are you serious? NO you don't need to. smh
Patches welcome! :-) * http://en.cppreference.com/book/ * https://en.wikibooks.org/wiki/Subject:C%2B%2B_programming_language
Assuming `getLogger` is _documented_ to not return null, `assert(logger != nullptr);` is appropriate; just as with throwing exceptions for precondition violations, trying to handle potential programmer error here is misguided.
The only correct way to document that something does not return null is to document it so that the compiler can check it, i.e. logger&amp; getLogger() const; 
You can show us an example code where you want to use them. 
Good old sunk cost fallacy.
The language has some problems with `const` everywhere, particularly wrt moves. If we make everything constant then you'd be stuck always copying and never moving. We have weird advice like "make this otherwise constant-thing mutable so that you get fast moves" which is quite unfortunate. Rust can potentially do it far better since it has destructive moves (though I'm unsure off the top of my head if the `Copy`/`Drop` traits currently disable destructive move optimizations in all cases or if there's another set of traits to allow destructive move optimization).
The second fix isn't because of const, it's because of properly declaring the variable only when it is needed.
msdn says that for, at least, win CE 2014 the last suppoerted MSVC is 2013 (or 2012 compiler but in 2013 VS).
&gt; \#pragma language_policy(const_by_default) Leaking that kind of line inside a header file could be nasty! Maybe this kind of mechanism would also require push/pop semantics such as with compiler warnings!
A MASSIVE thank you for that discovery. My code will never be the same.
Technically UB as hell, but auto offset = reinterpret_cast&lt;char*&gt;( static_cast&lt;To*&gt;(reinterpret_cast&lt;From*&gt;(1))) - reinterpret_cast&lt;char*&gt;(1); has worked for me. Note that for virtual bases, there is no such static offset (see this old but interesting [article](https://htmlpreview.github.io/?https://github.com/pbiggar/phpcompiler.org/blob/master/public_html/articles/virtualinheritance.html)). 
Lovely presentation, thanks!
is there a good solution to allow to move const objects? it's not a problem for value types... but for some larger things: like containers, custom app objects (that are movable). but as always, it's important to measure, measure... and not be too pessimistic about the performance. If your code is critical and low level, then you have to tune it anyway.
I agree with you in principle, but not everyone is in a position to choose their toolset. Source: stuck on VS2010 (among other, even more dated IDEs/tools) for now at work (though there is ongoing work to migrate us to VS2015). 
The "good solution" in my personal opinion is predicated on destructive move, which is useful for a number of other reasons (and why we keep seeing papers and informal proposals on how to add it to the language). Unfortunately, acceptable destructive move support is also (in my opinion) predicated on the standard acknowledging and relying upon much more sophisticated translation passes than what's currently codified in the standard. I give that about a 1:9238973492374 chance of happening.
Seems like an optimization that a compiler could make. If you're copying from a const object, and that object isn't used again, move from it instead? 
I love catch. I also love some of the optimizations others have done to speed it up, but the original commenter has a point. Phil has been busy in his new job, but the massive momentum catch had built is slowly stalling due I think to this issue. Perhaps it's time to build a community around catch (and v2) so that several maintainers can spread the load and keep on top of the PRs. I'm very grateful to Phil but I'm also concerned at the lack of visible progress in addressing issues and PRs. 
I'd like to mention this is not going into C++17, but it's safe to say it will make it into C++20 since it made it past EWG and there were basically no objections.
I agree. I would never recommend making an entire website in C++. However, I would recommend patching it in in various places where performance or strong type-based organization can help you.
Oh! It was listed under "accepted (new language) proposals" in Botond Ballo's [Issaquah trip report](https://botondballo.wordpress.com/2016/11/25/trip-report-c-standards-meeting-in-issaquah-november-2016/), so I assumed that it was accepted into the C++17 draft. I guess that didn't mean what I thought it meant. I look forward to it all the same!
 I found that similar syntax for lambda has been proposed in the generic lambda proposal. Why was the syntax rejected at that time?
&gt; Nowadays I happily use it as layer between Java/.NET and the hardware, when the use case of library usage or performance asks for it. Which still requires C because you have to use `extern "C"` to expose that high-performance code to Java, .NET, Python, etc. That's is to me one of the biggest failures of C++.
&gt;[**Hitler on C++17 [4:00]**](http://youtu.be/ND-TuW0KIgg) &gt;&gt;Hitler gets to know about the outcome of the C++ Standards Meeting in Lenexa, May 2015 &gt; [*^Andy ^Prowl*](https://www.youtube.com/channel/UCPe2aYwHUukof40_-fiLwuA) ^in ^People ^&amp; ^Blogs &gt;*^64,446 ^views ^since ^Jun ^2015* [^bot ^info](/r/youtubefactsbot/wiki/index)
I like this. Though it doesn't solve the problem for things like function arguments. 
You don't need the temporaries (of possibly non-copyable/non-moveable type) to "pass" type into the labmda. You may use some kind of tag: template&lt; class T &gt; struct U { using type = T; }; auto new_ptr = [&amp;ptr] (auto u) { using T = typename decltype(u)::type; return make_unique&lt;T&gt;(static_cast&lt;T&amp;)(*ptr)); };
Not on Windows, that is what COM and UWP are all about. I have not written extern "C" in ages. Also it extern "C" is only about ABI. It is actually extern "language", with language being C, pascal, fortran, or something strange (on mainframes). Also there isn't anything like C calling convention, rather OS ABI calling convention. So extern "C" is only a thing on OSes written in C. Case in point, on Windows, better speak COM and UWP, extern "C" isn't enough. For example I never had to care about extern "C" in Symbian or BeOS, both written in C++. Nor in any old OS not written in C, around 20 - 30 years ago.
&gt; and that object isn't used again A compiler is only allowed to invoke move operations at points defined by the standard, and the standard does not acknowledge anything nearly as sophisticated as use-analysis. The standard would have to be changed rather significantly to allow a compiler to make those kinds of optimizations. Also, leaving it an _optimization_ rather than a guaranteed behavior has all kinds of very large problems with move-only types (see the addition guaranteed copy elision in C++17 for examples of how copy-vs-move matters semantically). Therefor the standard would have to not only acknowledge but also _mandate_ use analysis in order for any change here to be useful. If it was that easy, it'd have been done ages ago. :)
https://github.com/vhf/free-programming-books/blob/master/free-programming-books.md#c-1
My code has to work on the "big three" OSes so I have to write `extern "C"` constantly. &gt;Case in point, on Windows, better speak COM and UWP, extern "C" isn't enough. I don't care a lot about UWP but I care about Windows. Why it is better for me to interop through COM with .NET, Java, Python or any other language than through `extern "C"`? If I use the later I just have to produce the shared library for each OS (basically recompile) and call the code through P/Invoke, JNA, Ctypes, etc.
I definitely agree with this! Please let me know if you know of anyone (yourself?) that would like to become a key maintainer (as an extra carrot it should entitle you to a free license JetBrains products too :-) ). One of my goals for Catch2 is to make shared maintenance easier too - it's a little awkward right now - but with a little hand-over it's doable.
Not much chance of me reading this, no ;-) I've been finding it a bit demoralising too. In fact that was one of my motivations for moving to JetBrains - to give me more time to spend on Catch. That's what I tried to address on the show - that it's taken a bit longer to get to the point I can actually do that - but I should be there for January. That said, as I've said elsewhere I am very open to having someone else help out with this - they'll just need a bit of ramp-up mentoring.
I've not pushed Catch2 publicly yet (and I've not actively worked on that for a couple of months either - at this point I need to catch up (no pun intended) more on Catch Classic first). I have kept up a trickle of activity over the last few months - but, yes, way less than it needs. Will be changing that very soon (January).
&gt; Please let me know if you know of anyone (yourself?) that would like to become a key maintainer That sounds like a horrible idea. ... I am in.
&gt; such an odd syntax would be accepted It's a lot less odd than the current syntax and parsers would have a way easier time with it (I think that's a concern that is now taken seriously, for example the structured binding syntax is square brackets instead of curly braces precisely to make parsing easier).
Good answer. The best OS for any kind of development is the one you want to develop for. It doesn't matter if installing third party libraries is a bit easier on Linux if you want to develop Windows applications with the VS toolchain.
What OS are you the most familiar with? If you have never touched a Linux OS then don't use that. Use what you know so you don't have to learn the OS at the same time. If Windows, I would recommend staying away from a complex IDE like Visual Studio and install GCC for Windows. Then use Notepad++ to write the code. Happy learning. http://mingw-w64.org/doku.php https://notepad-plus-plus.org
One gets to expose proper OOP interfaces, instead of plain functions. Also zero need to write import bindings on the caller language, provided they speak COM.
I see. It will depend on a project basis then. To me that does not represent an advantage given that I have to write those plain functions anyway for Linux and Mac OS X.
That's more of a Concepts thing.
The whole point is that the proposal allows you to _name_ the type inside the vector, which is lost with what you propose. I'm not saying what you propose is not useful, but I personally don't crave it.
Looking forward to watching this. Discovered Odin Holmes thanks to (the awesome) CppCast, and he's doing great things for C++ in embedded.
1) Invert the order of the two loops. 2) Don't erase the strings. Instead create a new vector and move the strings that match into it. 3) Don't use `string::find`. Since you are only interested in whether a string has a certain character or not, for each element in` stringArray` you can precompute a bitmask of 256 bits, where each bit is set if the string contains that char.
Lots of comments here but none strike at the heart of the matter. Your class should, if reasonably possible, not have references or pointers to things that are not owned by the class. Why? Because, the goals of classes are to maintain invariants over state. If you have a pointer or reference to an external object, that state can change without your knowledge or control. So a pointer or reference member variable can never be part of any invariants for your class. So why not just pass the pointer/reference in to methods of the class, instead of making it a member? There are obviously exceptions; the classic one is an iterator. It's entire purpose in live is to server as an object that references another, for the purposes of decoupling. But these exceptions are few and far between. In my experience most times that people design a class holding a non-owning view (raw pointer or reference), it's simply because it seems convenient, and is not actually the right choice.
thanks
Very useful, but `std::remove` is such an ill-chosen name...
It's faster to swap with last element in the array then pop_back if the order doesn't matter. Erase from middle of vector is expensive (all of the elements after the one you erase have to be moved). The pop_back is super-cheap O(1) and the swap is a potential move. Try that, let us know how it worked out.
Thanks
The paper gives one possible way of achieving this (restricting the type to a vector of some type). Paraphrasing it a bit: template &lt;typename&gt; struct is_vector : false_type {}; template &lt;typename T&gt; struct is_vector&lt;vector&lt;T&gt;&gt; : true_type {}; auto f = [](auto const&amp; vec) { static_assert(is_vector&lt;decay_t&lt;decltype(vec)&gt;&gt;::value); }; It requires the use of static assertion, `decay_t&lt;decltype()&gt;`, as well as two (maybe more in more complicated cases) additional class templates, which is all quite the boilerplate compared to `[]&lt;typename T&gt;(vector&lt;T&gt; const&amp; vec){ ... }`. As for other sane use cases, I'm afraid I am not very good at coming up them on the spot unless I have already had to used them myself (such as in the `dynamic_cast` example). You will have to refer to the paper or wait for someone else to graciously give an example for the both of us. Sorry. :(
If your into templates , and you can't find anything challenging, its time to start saving up those pennies and buy [The C++ Standard Library](https://www.amazon.com/Standard-Library-Tutorial-Reference-2nd/dp/0321623215/ref=sr_1_1?ie=UTF8&amp;qid=1482026106&amp;sr=8-1&amp;keywords=the+c%2B%2B+standard+library+a+tutorial+and+reference) , else your going to learn crap. Most folks buy it as a reference. I don't get contracts and you won't catch me without it. No money , no honey - and no jobs
If you are able to use something other than arrays, I would. This problem would be much better solved with a suffix array or radix tree, depending on what is the most important performance characteristic, insert time or query time. A suffix array would give you a slower insert time, something like O(log(N)*N) vs (mostly) O(N) for radix tree in exchange for O(log(N)*N) (plus the result set) for lookups on suffix array. The radix tree would probably yield the best result for this problem since it's a one shot thing, index once, query once. This is of course leaving out basic optimizations for this specific problem that appear omitted in your example, like starting with the longest words in the list and working backwards.. which means you no longer have to worry about mutating your list (which you shouldn't anyways, should simply mark the size of the entry in the array) as you exit when you find your first match.
Sorry guys, but as much as the product seems really nice, the trial version is basically useless. In order for me to even consider buying this, I need to be able to try it out on a real code base with a low barrier to entry (having to send you a personalized email is too much). Making the fully-featured 14-day version the de-facto trial would do the trick.
will try thx
I wonder, couldn't you replace the reference with std::reference_wrapper? You'd be able to implement copy and not have to change all . to -&gt; 
You're asking why 0 operations might be faster than 1 operation? Also, the comparison may be part of a branch depending on the comparison result, which could end up in a large runtime penalty. 
From your first implementation... template&lt;class Count, class Callable&gt; void times(Count n, Callable f) { for (decltype(n) i{0}; i != n; ++i) // ... Why use `decltype` here? You've already named that type... Why not just do this? template&lt;class Count, class Callable&gt; void times(Count n, Callable f) { for (Count i{0}; i != n; ++i) // ...
You're launching your app with F5, right? Try ctrl+F5, that should keep the console open. 
I actually do like the ruby version and those who do not should program more ruby :) (That is ruby, the programming language, not Rails the web frame work.) Anyhow, I think the idiomatic C++ version is to define a pseudo container and to use that with the new for index. Something like: for( auto i : up_to(10)) do_stuff(i); Boost's *counting_range* and *counting_iterator* provide this and it is easy to write a simple implementation.
Sorry xD
Having a utility `template&lt;class T&gt;struct tag_t{using type=T;};` globally is very useful. Together with `template&lt;class T&gt;constexpr tag_t&lt;T&gt; tag{};` and `template&lt;class Tag&gt;using get_type=typename Tag::type;` Now passing types via function arguments is simply `tag&lt;Foo&gt;` at callsite, and `get_type&lt;decltype(tag)&gt;` to extract.
There's a specific function in the C++ Library to avoid the ugly `(*(Callable*) nullptr)()` called `declval`. With it, the expression can be rewritten as `std::declval&lt;Callable&gt;()()`, which has a less hack-ish look. Just my 2 eurocent.
This would be my solution: http://coliru.stacked-crooked.com/a/c99b9eef195824fa Code using that enable1.txt word list: https://gist.github.com/labyrinthofdreams/6cfd77bc4e47ce91ec859dd5447ccf00 With that word list it's almost instant on my machine. First I count how many mismatches we can have by counting ? characters. Then I use set_intersection to find how many actual matches we have. Then I add those numbers and compare to word size. If they are equal then it's a match and then just check if it's the longest so far. edit: Accidentally pasted wrong code in gist.
Neat, thanks. One question: 1) what do your "const auto..." lines do exactly?
Novices get confused when they do things that leave whitespace on stdin (like op&gt;&gt; does) and then ignore() returns immediately. In general, I view either of these techniques as solving a problem that shouldn't exist in the first place.
To be precise, `std::ref` returns a `reference_wrapper&lt;T&gt;` which only acts similar to a plain reference. But you are right, the comment is poorly worded.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/functionalprogramming] [Reduce: From functional programming to C++17 Fold expressions - Nikos Athanasiou - Meeting C++ 2016 • \/r\/cpp](https://np.reddit.com/r/functionalprogramming/comments/5j2ccj/reduce_from_functional_programming_to_c17_fold/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Is loop unrolling the best way for for all values of N? For example if F is large but can still be inlined and N is large enough when int_c unrolls the calls, the larger code size may cause execution inefficiencies.
Uhm, what? Assignment assigns from an existing copy of the object, to another existing copy of the object. You can only assign an invalid value, if you allow an invalid value to come into being in the first place. Rigorous enforcement of invariants does not happen in the assignment statements; assignment statements are almost always easier to write than constructors. And nothing that I said has anything to do with encapsulation. If you decide to make your type assignable, you have to change . to -&gt; all over the implementation needlessly. For a large class this is an annoying change. This would be an acceptable trade-off if there was some benefit, but in the context of a class member for a non trivial class there is no benefit to a reference over a const pointer. A member variable declared const and not initialized inline has to be initialized in every constructor. The only way that a const pointer as a non-trivial class member can ever be null is if you explicitly initialize it as such.
&gt; Assignment assigns from an existing copy of the object, to another existing copy of the object. I thought you were speaking of any kind of assignment to the pointed-to value. Even then, you'd have to take care of other assignement operators, e.g. `foo&amp; operator=(bar b)`. &gt; If you decide to make your type assignable, you have to change . to -&gt; all over the implementation needlessly. For a large class this is an annoying change. You cannot possibly argue that it might be longer to refactor all the *uses* of a type instead of its implementation ? What if it's a library and you now have to change all the software using it ? &gt; there is no benefit to a reference over a const pointer. The compiler complaining to me if I forgot initialization is a huge benefit, even if it just saves a build-run-fix crash cycle. Pointers cannot offer this.
shared ptr does not exist to drop in solve your lifetime issues. It exists to express shared ownership of the lifetime of a value. Now, shared ownership is a complex situation that makes lifetime isshes harder. Shared ptr makes that slightly easier. A unique ownership situation is usually simller to reason about. Unique ptr solves a myriad of corner cases there. You can reduce shared ownership to something simpler (enforce a weaker form), like copy on write logically immutable objects (pseudo unique ownership, but use shared ptr under the hood), or unique ownership with weak references (short term only shared), etc. Treating it as "ownership problem solved" leads to crap in mmy experience. Either your lifetime problems where so simple you don't need it in the first place, or so complex that correctness is accidental at best. Even full on gc without paying attention leads to lifetime issues (leaks through zombie references, or "cleaned up" objects which you think are alive). 
No, unrolling is not always the best, and in fact I've seen cases where the compiler can do a better job if you just use a `for` loop with constant bounds. That's why there's [a warning](http://boostorg.github.io/hana/#tutorial-integral-more) in the documentation.
To be fair the C++17 version on trunk seems a lot simpler. In either case, I can't help but think this must take years to compile with sufficient use in a real project.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/cppcon] [CppCon 2016 Videos Megathread](https://np.reddit.com/r/cppcon/comments/5j41m4/cppcon_2016_videos_megathread/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Agree, the codes of sequences of integers seems... obscure. I think actually he tried a number of implementations, this might have been faster in regards to compile-time. (Just a guess.)
I am a little offended by your comment. It is very elitist and an attitude that is contributing to the slow and painful death of this language. &gt;If your into templates , and you can't find anything challenging, its time to start saving up those pennies and buy [The C++ Standard Library](https://www.amazon.com/Standard-Library-Tutorial-Reference-2nd/dp/0321623215/ref=sr_1_1?ie=UTF8&amp;qid=1482026106&amp;sr=8-1&amp;keywords=the+c%2B%2B+standard+library+a+tutorial+and+reference) , else your going to learn crap. Most folks buy it as a reference. I don't get contracts and you won't catch me without it. No money , no honey - and no jobs 
[removed]
To clarify, static reflection was not voted down - it's making lots of progress but just isn't yet in a ready-to-ship state.
How do you get the info on what's in there? You probe all possible types sequentially on a placement constructor, see which one matches and get the IDs from that, and convert that into types. Then you take a std::tuple (clone), reinterpret_cast that on top of the struct, static_assert that it matches as far as you can tell, and read your members because now you have names for them. You can't do that with just a struct without somebody defining it. 
.. Guess you could do that. Would compile slower, take more space and offer currently no benefits, and the main reason to try these things now is to see / show how much things improve when you have reflexpr, and why we want those things. 
It surprises me that the speed difference was so little, given that vtable pointer comparisons should be much less expensive than string comparison.
It's pretty straightforward once you take an algorithms class. The first step towards performance is identifying the correct data structure and algorithm to solve the problem. Only after that one should go to more exoteric approaches. 
Looks promising but does it support VS2015 and Intel 17 compiles ? 
Back when USA was full of immigrants from all over the world and many of them could not even spell their own name, it was difficult to make registers of people. So a system called "soundex" was invented which allows different spellings of the same name to be compared. If you look it up, there is a detailed description of how to create the soundex code of a word. You could then make a program that prints out all alternative spellings and similar sounding names to a name that you input, based on some dictionary.
At least in my opinion, this sort of list needs a fair amount of guidance before it's really useful. You need to already know the subject matter quite well to figure out which of these is helpful, and which is (for only one example) so ancient that the majority of it is better ignored.
Use the Clang model?
&gt; Allows control of underlying data structure Isn't the point of abstraction to hide this kind of thing from the user?
This looks very nice. I really could have used this one month ago.
If the alignment of the tuple and the struct are different, it should fail. If the sizes differ, it should fail. Those kinds of things you can static_assert. If all of those checks succeed, you can reinterpret_cast and keep your fingers crossed.
The addition of operator &lt; alone is enough to make me interested in this. I still can't believe std::bitset doesn't have that.
 if constexpr (std::is_callable&lt;Callable(count)&gt;() &amp;&amp; sizeof...(args) == 0) { std::invoke(f, i); } else { std::invoke(f, std::forward&lt;Args&gt;(args)...); }
Which user? The user of the object or the user of the type? In my work, we very frequently have to do with very explicit control of data layout and structure but abstract the access of that to down-level users. e.g., core engine code vs gameplay code. With this library, for instance, some public API may do this: using Flags = bitset2&lt;64, unsigned char&gt;; Users of this interface that are manipulating flags have no need to care about the size or the type of Flags, only the operations they perform on it. The internal implementation code that uses Flags however may be doing something that e.g. requires `unsigned char` instead of `unsigned int` (say, something that's alignment-sensitive, like copying it into a packed GPU buffer). This `bitset2` is now vaguely similar to the standard's types like `basic_string` or the like - a core type that comes up in user code when doing fancy template overloads or comes up in core code when using weird character traits - but which is almost always normally referenced by user code via wrappers or aliases like `string` or `u16string`. The updated `bitset2` could also be considered similar to the C++11 enumeration `underlying_type`. The user shouldn't really care what the type of a particular enumeration is most of the time, but sometimes they really do care and need that extra control.
From what I can tell, it doesn't look like this actually pertains to the MSVC compiler versioning (which is currently something like 19.x), only to the Visual Studio IDE versioning.
Yes and no on the book form, the man pages are very helpful but sometimes it is easier to look at the concept more unified. I've come from more high level languages, where certain concepts just don't exist when you get that high up the stack, like vectors for instance. It is helpful sometimes to see an example and for it to be explained. The man pages don't do a good job of explain the trade off of a particular thing. It more just tells you about builtin apis, which it is extremely helpful but problematic for beginners. Book or video form I think are best for that. However, both are seriously lacking for C++.
Thanks for responding, STmeow. &gt; The branded year isn't going away. This is just a change to the IDE version number. Okay, now I understand the last line on UV: "So in Help / About, you’ll see something like 15.1 (build 26230.0)", which would currently be shown as something like "15.0.26230.0 Update 1". But the confusion between years and versions will still remain the same. The only thing this changes is integrating the update number into the version :(
I would add to this that we also have multiple channels for the compiler (nuget, build tools, IDE package). At present we have no plans to unify our versioning and certainly getting to a shared libs / compiler versioning (compilers 19.whatever, libs 140/141/150) is higher on my list of problems to solve.
We [previously announced](https://blogs.msdn.microsoft.com/vcblog/2016/10/05/visual-c-compiler-version/) changes to the compiler versioning. The news there was: * VS 2017 RTM will be `_MSC_VER == 1910`. * VS 2017 Update 1 will be `_MSC_VER == 1911`. There are two policy changes here. Previously, major IDE versions (e.g. 2010 and 2012) came with binary-incompatible toolsets (e.g. compiler 16.0 and 17.0). Now, IDEs 2015 and 2017 have binary-compatible toolsets, so we're indicating that with compiler versions 19.00 and 19.10. (The last time we publicly released a point-one compiler was over a decade ago; different meaning now.) There will be binary-incompatible toolsets again at some point in the future, but the 2017 Update N series will remain compatible. The second policy change is that compiler updates will also be reflected in `_MSC_VER`. Previously, they could only be sensed by looking at `_MSC_FULL_VER` and knowing the magic build numbers (which are date-based; we didn't know what an Update would be until it was released and the date was carved in stone). This change happened because we have become far more aggressive about releasing new features in Updates. The compiler and especially the STL released many new features in 2015 Updates while preserving compatibility (a change from 2013 and earlier, where Updates were basically bugfixes; last major feature addition was TR1 in 2008 SP1). Since we've gotten comfortable with this process, and we expect to be able to release almost all C++17 features in this compatible form, we're continuing this in the 2017 Update series. (Indeed, the compiler front-end and library feature branch, WCFB01, has been continuously used for feature work; we just switched it over from merging into 2015 Update 3, to merging into 2017.) Indicating the Update level in `_MSC_VER` will make feature detection easier (yes, we know about feature test macros, no are aren't doing them at this point in time).
Have fun getting C1XX, the STL, *and Clang* all in sync. :-P
So GCC has simplified it's versioning system a while back, clang with the new version, and now MSVC? I'm sensing a common theme here.
What is the change to the standard in C++14 that's mentioned? Isn't this just application of the "as if" rule?
I have never heard anyone claim C++ is good for beginners. I would go for Python.
C++ is not beginner-friendly. I would recommend C++ as a second language.
I really want to know about the kernel tuning...
I doubt you're going to get any sort of absolute and final answer here. A lot seems to depend on your background and personality, so without knowing a *lot* about you personally, it's doubtful anybody can provide an answer that means much at all. Some people are most comfortable starting at very low levels of abstraction. I've known a fair number who've started with assembly language, and work their way from there toward higher levels of abstraction. A few never really move toward (much) more abstraction--I've known people who wrote assembly language for decades, and will probably continue to do so until they retire. Other people tend to start out with very high levels of abstraction (e.g., a Lisp or a Haskell) and work their way down toward the hardware. Again, some start with high levels of abstraction, and just stay there. C++ is fairly unusual because it *could* be a first language for people in either group. Even at best, it's something of a compromise for either direction. On one hand, it has a strong C legacy of direct access to the hardware. This makes it hard to view strictly as a higher-level language where you view everything at a high level of abstraction. On the other hand, there's a lot (especially with templates in the standard library) that's *quite* abstract (on the order of a Haskell, but with ugly/clumsy syntax). One of the hallmarks of the beest programmers has always been a high degree of flexibility in levels of abstraction--that is, somebody who's comfortable thinking in highly abstract terms, completely concrete terms, or anywhere in between. If you fall into that group of people, C++ will probably fit with your thinking better than almost any other language in reasonably wide use today--and in such a case, it's entirely possible that learning other languages first will be time you'll think of as wasted. And no, this isn't meant to be an elitist "only the best should do this" sort of argument. Comfort thinking at widely differing levels of abstraction *is* a trait of most of the best programmers--but it's not the only relevant trait, so just having this one trait doesn't mean you're necessarily a candidate as a great programmer, nor does it mean you'll like C++. At the same time, if you have a fairly narrow band of levels of abstraction at which you're comfortable thinking, chances are pretty good that C++ won't be a particularly good fit for you--you'll probably be able to learn to use it if you work hard enough, but there are likely to be other languages that will give you at least as good of results in return for less effort.
Thank you !
Wording changes are listed in [N3664](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3664.html#Wording).
Which book?
"...the kind of processing done in those environments is usually bounded and known." I absolutely agree. Can you clarify why this makes C++ a tough sell on microcontrollers? Perhaps you are referring to the fact that standard strings and many standard library containers use dynamic allocation? Can you provide some more examples of which language abstractions in C++ provide "diminishing returns"? We can probably both agree that type safety for register access provides benefits as argued by [this article](http://electronicdesign.com/dev-tools/evolution-special-function-register-abstraction), and implementing this kind of compile-time checking is impossible in C due to the lack of templates. As he says in the talk, Odin and the others working on Kvasir haven't really demonstrated ranges on microcontrollers yet. Representing a UART as a range means that the programmer can apply a rich set of Range v3 transformations on the data stream without copying it, by leveraging lazily-evaluated views. I think this idea has a lot of potential, but the argument would be more convincing if we could take a code example that does something useful and compare the RAM savings and expressiveness of the Ranges implementation to the "classic C-style" implementation.
I work at a small prop firm and our low latency system written in C is still very profitable.
If you aren't entirely settled on Java: I'm not familiar with that book, so perhaps it's great, but if you are new to programming and want to look at C++ I strongly encourage you to be sure to start with one that covers modern C++. I recommend "Programming: Principles and Practice using C++", by Bjarne Stroustrup. Not only is he the creator of the C++ language, but he also has direct experience teaching university students new to programming. The latest edition covers C++14. Good luck, have fun!!
Do have a specific project/goal in mind? The reason I ask is that some languages are better for than others, depending on the application.
&gt; Perhaps you are referring to the fact that standard strings and many standard library containers use dynamic allocation? This has a lot to do with it. Outside of the rich containers that the STL provides, C++ is mostly syntactic sugar. When I say it's a tough sell, I'm speaking from my experience in attemping to get my software teams to migrate from C to C++. People are hesitant because they feel the increased complexity does not justify the advantages. I can't really say that they are right or wrong there... it's no question that C++ is orders-of-magnitude more complex than C, and for some developers the cognitive burden is best avoided. &gt; Can you provide some more examples of which language abstractions in C++ provide "diminishing returns"? Operator overloading, function overloading, inheritance, virtual functions. In many embedded firmwares, there just isn't much of a need for these. When things are ad-hoc and special-purpose, these abstractions are hard to justify especially when they have a high propensity to obscure code rather than clarify. &gt; implementing this kind of compile-time checking is impossible in C due to the lack of templates. Agreed, but templates are simply a code generation tool. In C, we just write one-offs if we need type safety. Yes, it's annoying. AFAIK the only thing C++ offers that C does not is private data on the stack and destructors. Most everything else *can* be implemented in C, albeit painfully. &gt; the argument would be more convincing if we could take a code example that does something useful and compare the RAM savings and expressiveness of the Ranges implementation to the "classic C-style" implementation 100% agree as well. I tried to use an example of a circular buffer: one I wrote that was type-safe and compatible with STL algorithms, vs the macro-based version in C that coincidentally I also wrote about 4 years ago. I thought the arguments were pretty convincing, but not very many of the C programmers agreed.
Not particularly.. Just really interested in it, gonna see where it takes me I guess :)
If you are starting i will recomend you switch to Java/C#, you will get under control tons of stuff that will make your experience a nigthmare and when you are comfortable programing you can switch back to C++ with all the errors already learned and it will be much more easier for you Examples of that are that for example a null pointer exception or accesing an outer element of an array because the for is bad constructed or whatever are things that every programmer has suffered, one way or another, first me of course and in C++ you will get an error dialog saying nothing usseful so you will have to go and post it on a forum, SO or even here, while in Java or C# you will get an error, on what line and in one minute the error will be gone There are much more stuff that you have to be very careful also that may be leaking resources (who has never forget to close a fstream?) and things more complicated that in Java will be done automatically without any worrie at all
You just don't know what you're talking about. Yes, FPGA is a great way to go, and more and more shops are going that way. Yes, if you want to be the fastest, and that is your entire edge, you must be on FPGA (at least for many exchanges). No, that is not the only way to make money. There are tons of teams, making piles of money, still running code in C/C++, and even Java. To make money in HFT is a combination of speed and smarts. The smarter you are, i.e. the better your alpha is and the longer time horizon it holds across, the slower you can afford it to be. You seem to think (judging from your other posts as well) that HFT = exchange-to-exchange arbitrage. This is one tiny fraction of what HFT is. It's a very diverse world. Someone who actually knows the industry would know that.
A lot of people are saying that C++ is not a good language for beginners but I'm a newbie at programming and I've joined a college course about the basics of computing and we're doing C++ in it and I'm really enjoying it and finding it simple and fun to follow. It's possible that having a class environment helps in learning, and that maybe using a book on your own might not offer the same learning experience, but in my experience, C++ shouldn't be difficult to learn as a beginner
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](https://stackoverflow.com).
A `std::map` could do the job if you need associative relation between the "variable name" and the data
Hm.. thanks for the input! :)
The comittee stance is that it was always allowed, but C++14 wording changes have been made to make it clearer. Thus the optimization is valid for old standards as well.
You mean like "*That was so 2008*"?
[removed]
&gt; Today you can't make money with those sub-micro platforms anymore. This is _not_ a fact; it's hyperbole presented as fact in a way that implies the presenter is incompetent. Offensive indeed.
Note that this doesn't apply to explicit calls to operator new -- only to new expressions. This matters in practice, because it means that clang is unable to optimize away code like this: void someFunctionAcceptingAnInt(int); void itDoesntMatterIfThisFunctionGetsInlined(std::vector&lt;int&gt; vec) { someFunctionAcceptingAnInt(vec[0]); } void caller() { std::vector&lt;int&gt; vec = {0}; itDoesntMatterIfThisFunctionGetsInlined(vec); } You might think caller() could get optimized into: void caller() { someFunctionAcceptingAnInt(0); } But in fact, it will generate an extra two "operator new"s and two "operator delete"s, and some extra stores to memory, just on the off chance that you're replacing operator new and operator delete to do something wonky (and this is with exceptions disabled -- the result is even worse otherwise). (Personally, I think they should change the standard to allow this elision, because if you radically change allocator behavior, you deserve what you get). Edit: I hadn't gotten to the point of the video where he mentions this -- it isn't actually a limitation of inlining; the standards people interpret this behavior as being required by the standard.
Well, imo it's missing a warning to tell you when you don't use delete and it still elides it.
Not sure I understand the problem about C++ features implemented with Posix syscalls? How else would they be done? 
Don't do python. Pick a language with static typing
OP discovered programming isn't magic.
Here are some ideas: * Do as much as you can in user space. * Bypass kernel when communicating to external devices, DMA based (NICs, etc) * Disable any interrupts that are not used to support the running trading app * Disable or remove any process that is not related to supporting the trading app * Consider rebuilding kernel in "preemptible mode" * Apply scheduler patches to the kernel designed for low-latency scheduling instead of average best case scheduling * Remove any kernel modules that do support or are not used by the trading app * Apply kernel patches to remove code that enumerate any sub systems that are not used as part of the trading app (there's heaps of if-then-else-if stuff in the linux kernel) 
Probably I'm blind, but what exactly is the issue with the libstdc++-version of `to_string`? Seems like one stack allocation, and one maybe-allocation in the string constructor depending if SSO is used. Is it the copying of the content into the string at the end instead of constructing in-place?
I was talking about to_string() for example. 
There is not a "real issue" with it, but potentially faster per-type specialized versions could be implemented. As an example, [this question on StackOverflow](http://stackoverflow.com/questions/4351371/c-performance-challenge-integer-to-stdstring-conversion) reveals some interesting techniques. Standard library implementations could leverage compile-time knowledge of types (and knowledge of the current architecture) in order to make the conversion as quickly as possible. Another example is D's standard library's [`to!string` conversion](https://github.com/dlang/phobos/blob/master/std/conv.d#L1233-L1285).
And your proposal is? Current implementation could be improved, but honestly I don't see any reason in replacing *printf* calls. String conversions is hard (I looking at float and double types for example) and any new source code will contain errors. The current implementation already uses SSO where it possible, and your custom code will not escape allocation if resulting string size is bigger than 24 bytes (16 on x86) even if you implement entire conversion in C++. 
While I agree that "compile-time" type knowledge could be beneficial, at the same time there is also correctness issue. You can't convert only integers - float and complex numbers should be supported too. And what about other platforms? 
&gt; You can't convert only integers - float and complex numbers should be supported too. That's the whole point of the "compile-time type knowledge" I was talking about. You have a specialized fast way to convert integers? Then do this: template &lt;typename T&gt; auto to_string(T x) { if constexpr(is_integer_that_can_be_converted_fast&lt;T&gt;{}) { return fast_integer_to_string(x); } else { return slower_but_more_general_to_string(x) } } Correctness for `fast_integer_to_string` would be checked as any other function *(e.g. with code reviews and unit testing)*. &gt; And what about other platforms? #ifdef SOME_PLATFORM constexpr bool integers_can_be_converted_quickly = false; #else constexpr bool integers_can_be_converted_quickly = true; #endif // ... if constexpr(integers_can_be_converted_quickly &amp;&amp; is_integer_that_can_be_converted_fast&lt;T&gt;{}) { return fast_integer_to_string(x); } 
STL told sometime before that supporting this kind of code is hard IIRC. We are getting additional point of possible error. Yes - having ultra fast standard library would be nice. But not for a price of losing correctness. There is still a problem of consistency across platforms. Theoretically after C++17 you could propose something like you showed above. After all - we got SSO using similar arguments. 
What about pinning processes to CPUs? This effectively rules out the scheduler and its direct or indirect artifacts (context switch latency, cache invalidation). 
&gt;You might think caller() could get optimized into: clang does reduce it to that with libc++… if I use the flatten attribute, anyways. https://godbolt.org/g/QdQyyS
This is exactly on point. Learning it in a class environment is extremely helpful. Even if you're gonna learn on your own, make sure you get at least a few friends or a mentor to discuss along the way, or at least stay in contact with a teacher or a coder. Doing it by yourself, I can almost guarantee, will lead you to be far less productive than you could be otherwise. And when you stagnate in something like learning C++ (I did) it's extremely difficult to get back on track. TL;DR: Surround yourself with coders/aspiring coders.
This. Best book for learning C++.
The thing is, you're not unique. Everyone in the pure latency game has their own on-fpga tcp/decode/whatever solution. And then one day, someone beats you by 30ns (or the exchange introduces a latency floor/order quantization) and you go out of business. In a zero variance world there should only be one true latnecy arb winner.
I claim C++ is good for beginners and Python is harmful. Why do I think Python is harmful? Because it misses certain fundamentals that are essential in other languages, such as value semantics, that people have a hard time reconciling once they've gotten good at Python. 
What's not beginner friendly about it? I can think of a couple of things, but I don't think they're deal breakers, so what's your take?
Why not just use actual functions, not blocks. This is actually what people mean when they say, that your function is doing too much and should be separated in multiple smaller functions. What your example has done, is separated it into smaller functions and then inlined them. 
I think I saw a very similar failure case already reported when I looked. I wanted to mention it here as a general caution because despite the claims of it being awesome, my experience has not been the case (I've reproduced the failure on multiple systems).
I have a difficult time watching at work, could you post the slides? This looks promising (even if not ideal, it nudges me to reexamine my beliefs on good code!)
What kind of example are you thinking of?
haha, definitely a good idea.
RVO used to be "implementation detail" too. C++ committee is always interested in fresh ideas, or at least I was told so 🙂.
In that particular case lambdas could be useful as "local functions".
Whenever I can use Boost, I much prefer static_vector. It gets parts of std::vector’s interface that std::array lacks.
Okay? I don't understand the majority of your problems. I understand your problem with std::to_string a bit, but threads? random_device? I think it's clear that random_device opens /dev/urandom at linux?
And even if the implementation could use some improvement, submit a patch! https://gcc.gnu.org/contribute.html
In short, reg nms has two clauses that affect this: * Orders should execute at the national best bid/offer. So if I have MSFT at 41-42 on bats and 41-43 on NYSE, NYSE should execute a buy order at $42 not 43. * Exchanges shouldn't display orders that lock/cross the national market - you shouldn't have MSFT at 41-42 on NYSE and 43-44 on BATS That basically eliminates a lot of the cheap/quick arbitrage you could do when the markets were out of balance. Now, I'm not really sure of true inter-exchange arbitrage in the same vein as the above. I expect it's more in the vein of seeing that one exchange is imbalanced from the others and using that as an extremely short-term prediction of price movement, although that's not true arbitrage.
You don't have to make the individual sub-functions public APIs. This is an implementation detail that shouldn't be visible to the caller. 
One is implemented in terms of the other &amp;ndash; pure syntactic sugar.
I struggle to use std::array and I often fear I'm creating a lot of code if I use the size as a template parameter. And I have no idea how much code is actually still there after optimization. Say I'm creating a function `template&lt;size_t size&gt; std::array&lt;float, size) fft(std::array(float, size)`. Could be really neat because I could precalculate lookup tables at compile time and if my algorithm doesn't work with certain sizes the code wouldn't compile. Two problems though. I have no idea how much bloat std::array&lt;float&gt; a = { 1.0f, 2.0f }; std::array&lt;float&gt; b = { 1.0f, 2.0f, 3.0f, 4.0f }; fft(a); fft(b); causes. And if the reason to use std::array was to prevent or reduce allocation I can never pass in anything else. Or I would have to provide the same interface for std::vector with different performance. Iterators don't always help, because sometimes knowledge about the underlying container can yield some performance gains. And I might have to do that anyway because the size isn't necessarily known at compile time. I tried godbolt to get an idea of just how much code is generated, but it's pretty though to create a test case that doesn't get completely optimized away while not obscuring the output with thousand lines of assembly. I always end up just using std::vector and reserve() in cases where I know exactly how large it will be.
It's also notable that compilers have insider's knowledge about `printf` and al, and can potentially optimize `sprintf(buffer, "%d", 6);` into `*buffer = '6'; *(buffer + 1) = '\0';`.
Interesting. I'm having trouble reading that as anything but an implementation bug, given that std::allocator is defined to get its memory from ::operator new, and that ::operator new calls can't be elided (see e.g. https://llvm.org/bugs/show_bug.cgi?id=21145 ).
what
So in your opinion, readable code isn't a useful thing?
Can't think of something on top of my head but if I remember something I'll let you know. This also might happen less / more in different areas of c++ programming.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. 
Lambdas too. In fact, you are encouraged to use lambdas, for example, to initialize constants when you have some work to do before getting to the final result. Something like: const auto value = [&amp;] { auto values = std::vector&lt;T&gt;(); // ... do some work, mutating values ... return std::reduce(values.begin(), values.end()); }();
You have this specialization option: template&lt;typename T&gt; class Func; template&lt;typename Ret, typename... Args&gt; class Func&lt;Ret(Args...)&gt; { //implementation }; So, specializing for foo and bar would give you template&lt;&gt; class Func&lt;void()&gt; { //foo specialization }; template&lt;&gt; class Func&lt;int(int,float)&gt; { //bar specialization };
The compiled binary when you pass around an `std::array&lt;float, 5&gt;` does pretty much the same thing as paying around 5 floats as parameter
I appreciate what you are saying. So to clarify, I'm not saying that this is better than refactoring into functions. But, functions tend to grow in complexity because people don't always refactor, for whatever reason. So, the suggestion is to write the code in such a way that limits complexity, should the function grow over time.
Thanks, I will try and get that uploaded for you.
Sorry it wasn't clear before, but foo() and bar() may have the same signature, and I'd like to have separate specialization for them. *edit*: I edited my original question to reflect that.
You can use `auto` for the template parameter (C++17's new feature). template &lt;auto&gt; class Function; And specialize each case the way you wanted. template &lt;&gt; class Function&lt;bar&gt; { ... }; [Example](http://melpon.org/wandbox/permlink/mlifpl0MDlq1RQ6x).
The initial code returns 0. You initialize it2 to end and before changing anything you check it against end() . 
What if the only reason I'm using the template is to reduce copies to a minimum? I have to copy once if I don't work in-place, but if I only know the type of the iterator, what would I return? If I return std::vector, but the user passed in std::array he probably has to convert the vector to an array because that's probably what he is working with. If I know the type of what was passed in I can return the same. I can't really return an iterator in that case can I? Though I guess my understanding of templates is probably my C++ weakpoint.
We're talking about `std::array`, not primitive arrays.
My usual use case for naming lambdas is ```std::find_if(begin, end, fairly_specific_predicate)```, where the line above is some variation of ``auto fairly_specific_predicate = [=](auto a, auto b){return ...;}`` it lets me reason about the predicate separate from the algorithm or the bare loop, and once that's abstracted away the rest of the function becomes a little cleaner. or maybe something like chunking up layout definitions? They all fall under the category of ``gen_gui``, but maybe break it up in to ``gen_header``, ``gen_form``, ``setup_gui_events`` etc, 
That's true for C-style array's, but the parent was talking about `std::array`, which can and will be passed ~~by value~~ in registers if its small enough: ➜ cat array.cpp #include &lt;array&gt; int foo(std::array&lt;int, 1&gt; arr) { return arr[0]; } ➜ g++ -c array.cpp -std=c++14 -O3 ➜ cpp objdump -d array.o [...] 0000000000000000 &lt;_Z3fooSt5arrayIiLm1EE&gt;: 0: 89 f8 mov %edi,%eax 2: c3 retq (so it's effectively negative overhead compared to a raw array)
any plan to add (proxy) iterators?
The new feature is roughly just syntactic sugar for the solution you already posted but considered too verbose, unfortunately. You could use a macro `DT(f) decltype(f), f` in the meantime if you're that eager to make the more concise. For reference: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0127r1.html
Hope this is okay. I've put the text of the talk in the Notes. http://docdro.id/1PWmjLr 
Fascinating discussion. Thanks for the link.
Also `partial_sort` doesn't document the `middle` parameter, even though it explains its use in the return value section. It also says that the order of the elements in the `[middle, last)` range are unspecified, yet the code example asserts that it will print a specific order. Looks like the article could do with a round of editing.
And if you forget to put the final parentheses, `value` gets the type of the lambda with no compiler error.
The examples don't use auto.
Doesn't mean you should use it though. Stick to existing conventions here.
!removehelp
Small fix: `if (loc_a.distanceTo(loc_b) &gt; MaxDistance)`
Oh my no no... It's just the guys I work with who don't believe in using anything unless it's the best damn optimized solution.
&gt;no pun intended I call bullshit.
No, it's determined by the system ABI and the class layout. (because other code linking against this function needs to know how to pass parameters based on the function signature) In my example i'm on x64 linux, so i'd expect up to `std::array&lt;int, 6&gt;` to be passed in registers, but I didn't verify this. Of course, strictly speaking class layout *is* the compilers decision, but it there is not a lot of leeway. For example, the optimizer cannot just decide to change "small enough" based on optimization level.
Still, someone has to maintain the private functions
This needs forward iterators. You are doing a multipass.
If you call `for_each_adjacent` with `first` == `last` then `auto next = std::next(first)` will cause UB. The `first != last` check needs to go before the loop. EDIT: As a coincidence, this algorithm was added to [range-v3](https://github.com/ericniebler/range-v3) just yesterday! [`ranges::view::sliding(2)`](https://github.com/ericniebler/range-v3/commit/d9142861f603f3eda375d82d203f57279d78b83f) has the desired semantics.
- `is_sort` (sic) and `is_sorted_until` aren't "sort functions"; they don't sort anything. - `stable_sort` is O(Nlog^2 N) only if there's not enough memory available, otherwise it's also O(NlogN). - Code examples are generally terrible. Gratuitous copies, misuses of `endl`, unnecessary includes, missing includes, pointless use of `distance` on random access iterators... 
I saw that, but I didn't see an easy way to apply it to this problem. Do you have a solution using `adjacent_filter`?
I guess I meant to say both, it's passed by value in the C++ sense in response to the parent saying it isn't, and also by value in the sense of the ABI (i.e. not by hidden reference) to confirm the grandparent stating it is actually the same as passing 5 float parameters. Probably there is a better word for this, but I don't know it.
Filter with the predicate and then take the `distance` of the resulting range? 
.. Why?
I'll just drop [GSL](https://visualstudiomagazine.com/articles/2016/06/01/using-the-not_null-template.aspx) here.
An even better approach would be to statically guarantee that a pointer is not null.
Yes it works, but it's a bad idea. You hide a design flaw, which the possibility to double dereference a ptr behind anorther one, which is throwing exceptions in object destruction which might leave your program in an unretrieveable state. Having an assert there would be the better solution.
You want to fail fast in debug mode, but recovering is interesting when the app is in release, running in production. You'll abort an operation (and ideally, log the issue), but the software will still be running.
Yes, I knew about not_null, but it's a different approach. The main difference is that safe_ptr allows 2 code paths ( regular one and the exception one ) thus enabling a different code style ( I won't say better... ) 
Isn't that what references are for?
Exactly. I believe GSL's not_null is the best compromise we can get. It catches "obvious" mistakes at compile time and, best of all, points you at correct place to fix it.
I think it's often a mistake to pass around smart pointers anywhere below the topmost level. When you get a smart pointer, check its nullity at the very top level and throw your exception if so - and then only use it as a reference thereafter. Then your code would become simply: template&lt;typename T&gt; void foo(T&amp; x1, T&amp; y) { x.bar(); y.baz(); } So much less! Also, it means that function `foo()` can be used on anything - references or any type of smart pointer.
that isnt static
`assert` is a macro, we can do defensive programming with it: i.e. we can throw a `logic_error` exception in release if this is really what we want to do.
So this is a type that can be null, but users promise to never use when null, on penalty of a throw. In comparison, a pointer type that cannot be null on penalty of throwing or not compiling (at construction) might be better in many situations, including the sample code you posted. If you need it to sometimes be null still, an optional of a not-null pointer returns those semantics. An advantage of that is when you pass from one not-null poonter to another, or dereference, no checks need be made, as they are guaranteed by the type. As you sweep the code base to have more and more proven non-null pointers, the overhead and locations where a throw can happen both evaporate to fewer and fewer. In terms of testing this is great, because to cover the non-linear code paths (not just lines; paths) is *hard* when every line contains an implicit goto.
&gt; Of course that's not possible in a language like C++, otherwise the compiler would do it always. It's possible, unless you explicitly make null pointers. Use only unique_ptr's constructed with make_unique, shared_ptr's from make_shared and references to the contents of the former, and you won't have any null pointers. It also loses you the ability to communicate "no such thing" as a null pointer, which is what null pointers are used for very often.
I feel like pointer-to-pointer just makes things worse.
Never mind, I misunderstood how it works. I think I didn't give it enough credit in the case where the RHS element is removed and then the predicate must be called again with that element for the next pair anyway.
It somewhat is: If you have a function taking such a `non_null` object, you know that it can't be null, otherwise the function would not have been called, because you can't construct null non-null objects.
It will still be running, but now running incorrectly. Why are you still executing after trying to reference an object that wasn't set? Why didn't you set it? Was that a reference to an account balance? How do you 'keep running' in that case? Set everybody's balance to zero? Fail the deposit? There is no way to 'keep running' and have all of the balances add up. 
&gt; It's possible, unless That's the very opposite of "statically guarantee".
Do not use exceptions for control flow. 
Why? Sounds like you want a non-optional pointer (it's never null). For that, you should better throw from a constructor. What's the point on waiting for a dereference? But... you're better off with an assert in \_DEBUG, crash in prod, and a good test suite. Also code analysis, that can discover silly mistakes.
This is somewhat offtopic, but I do not know where else to post this. I want to report a bug in g++ but the gcc bugzilla has had account creation disabled for quite a while now. If someone has an account, I'd be glad if you could submit. The problem is that g++ does not recognize that reference members in unions are prohibited and happily accepts faulty code, and then crashes later. It affects, according to gcc.godbolt.org, this 6.3 release and the 7 snapshot. [Runnable link.](https://godbolt.org/g/5Mf3yC) Clang and MSVC diagnose the error correctly. 
Thanks. https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78890
There are things that you can guarantee, why would you misuse the term to describe something that can't be guaranteed? 
https://gcc.gnu.org/gcc-6/changes.html &gt; * The C and C++ compilers now offer suggestions for misspelled field names: spellcheck-fields.cc:52:13: error: 'struct s' has no member named 'colour'; did you mean 'color'? return ptr-&gt;colour; ^~~~~~ The spelling of "colour" is incorrect!? *sips tea angrily* 
How dare these colonials try to force their bastardised spelling on us. I'll be letting Lizzy know all about this and Her Majesty will be sending her best naval men out to have a jolly good scrap with these "Americans" *eats scone furiously*
&gt; It will still be running, but now running incorrectly. My users prefer **ten thousand billion times** having a clean "Sorry, due to a bug this software has to shut down when you press OK" dialog, than the OS X / Windows spinning ball of death that makes the whole computer lag that happens when you actually dereference a null pointer.
&gt; you know but the compiler does not, which is what "static" means.
Not exactly, a reference also cannot change. Sometimes pointers need to change, and also not be null. I think of references as just a little syntactic sugar. They don't really guarantee much of anything. Iirc the actual original reason that prompted their addition to C-with-classes was to create a reasonable syntax for operator overloading :)
I had found one as well and couldn't report it: https://www.reddit.com/r/gcc/comments/5h7kli/g_bug_beporting/
Yes.
If you send a plaintext email to overseers@gcc.gnu.org they will create a bugzilla account for you. 
One way is to post a testcase on stackoverflow and ask why it doesn't compile, and say your compiler version is the one that has the bug. (But don't mention compiler bugs at all or let on that you already suspect it might be a bug, or else the trolls will abuse you for posting a question instead of posting a bug report). Then once the hive mind agrees that it is a compiler bug, someone will submit it so that they get internet points. 
I wonder if these corrections are locale dependant.
I have completed the compiling it. Now, compiling some projects
Eli Bendersky's blog post about [C++: Deleting destructors and virtual operator delete](http://eli.thegreenplace.net/2015/c-deleting-destructors-and-virtual-operator-delete/) may help answer your first question.
Understood thank you
Not sure if serious...
Thanks for your comments. That's an interesting point, that within an object-oriented codebase can be a lot of very C-style code, handling the logic. 
I just got it working on my system for targeting webassembly clang version 4.0.0 (trunk 285666) (llvm/trunk 285664)
I bet this is a contrived example; it seems much more likely that the compiler uses code to compare an invalid struct member with similar existing struct members, rather than a word dictionary. Names in C and C++ are often abbreviations anyway.
Is that true? because I tried writing them an email and I got a response that the email couldn't be delivered (3 months ago)
It's merely saying that `struct s` has a member named `color` but not one named `colour`, and the words happen to be similar. This has nothing to do with locales and is no different than struct foo { int bar; }; int main() { foo f; f.baz = 42; } // ... error: 'struct foo' has no member named 'baz'; did you mean 'bar'? f.baz = 42; ^~~~~~ Clang has been doing this for years.
&gt; When closing namespaces, close all in the same line and write a comment like this. C++17 `namespace foo::bar {}` is underrated.
Done: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78897
That's a different but appears to be similarly caused as the one I linked. The one I linked is in "complete_ctor_at_level_p, at expr.c:5876" rather than in "output_constructor_regular_field, at varasm.c:5019". Mine is related to using placement new in a constexpr context, which granted isn't currently valid c++, but it still shouldn't cause an ICE. The code I linked is as minified as I could make it, although my coding style leaves in quite a bit of whitespace that can be removed.
I'm not sure if I understand this correctly, could you given an example?
Any reason why it's so inefficient? I though about using it sometime in the future, but I couldn't find any good benchmarks.
Just quality-of-implementation issues, nothing inherent to the design. [Boost.Regex](http://www.boost.org/libs/regex/) performs well.
Some code offers "safe" getters, e.g. int window::safe_get_width() { if (!this) return 0; return get_width(); } Makes some wrong code not crash. Bad practice. Wrong code must crash and be fixed.
It's essentially suggesting the member whose name has the lowest edit difference to the one provided. I think. It could also use a dictionary, or the longest common prefix, but neither of those is very good for abbreviated names. 
I guess it will get better over time. The more people use std::regex, the higher the pressure for a decent implementation will become.
clang-tidy has a modernize feature that surprised me with its boldness. I don't know whether it will replace auto_ptr with unique_ptr though. 
Author here :) The first one is not necessary, it just converts an `error_code` into a bool in a more explicitly way. This style is also used extensively throughout Asio. The second one is achieved using the [Boost.Parameter](http://www.boost.org/doc/libs/1_61_0/libs/parameter/doc/html/index.html) library, useful for defining functions with a lot of parameters, but is optional in Amy. Guess I should probably remove this "feature", or at least remove it from the examples.
It's little creature comforts like this that really excite me.... test.c:3:1: error: version control conflict marker in file &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ^~~~~~~
Nope. You done goofed up there, son.
See those contrails overhead? That's the joke going by.
Yea, there is [a GitHub issue](https://github.com/liancheng/amy/issues/1) for this but I haven't got time to work on this yet.
Ok, but look: `int &amp; foo = *static_cast&lt;int *&gt;(nullptr);` References bind just find to null. There's no "static guarantee" of any significance. What C++ references give is at best a little trivial syntactic analysis. `int &amp;` is just a fancy language for `int * const`. Hence I say, syntactic sugar. Compare that with e.g. the rust borrow checker. That's what is meant by static guarantee, that's the kind of reasoning I consider "hard" compared to what C++ does.
You're referring to this? template &lt;typename Dummy = void, typename = std::enable_if_t&lt;AllowNull, Dummy&gt;&gt; void reset(); But I can make the template well-formed: struct my_type {}; template &lt;bool Val&gt; struct enable_if&lt;Val, my_type&gt; { using type = my_type; }; ptr.reset&lt;my_type&gt;(); But I can always revert back to the code I originally had there: template &lt;typename Dummy = std::false_type, typename = std::enable_if_t&lt;Dummy::value || AllowNull&gt;&gt; void reset(); I changed it specifically because on can easily make the template well-formed, but when it is required for correct behavior, I'll use it again.
But why? C++ has RAII
No; I think that's the point being made.
I was curious why someone would try to reimplement Andrei's [`SCOPE_EXIT`](https://www.youtube.com/watch?v=WjTrfoiB0MQ).
I really like that compilers are now getting written with more than just the language's syntax in mind. Roslyn, for example, stores whitespace information as part of the AST. This helps when converting ASTs back to their original textual forms, and also to make idiot-proof error detection. That feature is very cool indeed.
In my opinion they should be happy that someone **makes an effort** and tries to report a bug and not put a number of obstacles in their way. In fact, if someone wants to report a fault back to you, you should make sure he/she has **as little obstacles as possible** in their way for reporting it. Many people do want to make an effort to report something but can't be bothered to take more than 5 or 10 minutes for it - if the first attempt fails, they won't try a second time. This is valuable feedback that gets lost.
I think /u/raevnos was making a funny
For this particular problem, I'll stick up for the for-loop: static const double MaxDistanceWithoutABreak = 100; double legDistance(const City&amp; startCity, const City&amp; endCity) { auto startLoc = startCity.getGeographicalAttributes().getLocation(); auto endLoc = endCity.getGeographicalAttributes().getLocation(); return startLoc.distanceTo(endLoc); } int computeNumberOfBreaks(const std::vector&lt;City&gt;&amp; route) { auto numLegs = route.size() - 1; auto numBreaks = 0; for (auto i = 0; i &lt; numLegs; ++i) { auto d = legDistance(route[i], route[i+1]); if d &gt; MaxDistanceWithoutABreak { ++numBreaks; } } return numBreaks; } Not as elegant as the STL solutions, but if the objective is to make the purpose and method easy to understand, this is hard to beat.
And this is using it
This is certainly true. But unfortunately we have no other option. Bugzilla got bombarded from SPAM bots using fake accounts. So in order to protect this critical piece of infrastructure, account creation had to be disabled. And by the way LLVM did the same thing a little later (,see llvm.org/bugs/).
Euh, yes, C++ does not try to prevent you from shooting yourself in the foot. You just showed an elaborate way to do it, but many more are available. references give you a certainty that, in correct code, a given "pointer" is not null. This is IMO huge for code quality and simplicity over never really knowing, and I have seen. numerous C codebases who suffer.
Not that I know of.
note that the gcc standard library is called libstdc++, not libc++
Thanks, fixed.
Seams reasonable. Why have different naming conventions for classes and structs? A type is a type. What about other types such as enum classes as well as type aliases (typedef and using)? Also doesn't mixing tabs and spaces break automatic formatting? After getting used to clang-format I will never go back to manually fiddle with whitespace formatting.
Clang got this some time ago, but removed this optimization because it broke too much stuff. Maybe with concerted effort they can push this through.
Yes, I can confirm, boost::regex is quite good. And it's more or less perl compatible, unlike std::regex.
Look at the very bottom of the page.
I guess the first quarter of your link was what he mentioned as a side-talk off tangent thing, which spurred me to ask my question. But I literally laughed out loud when he was saying: "Why does Java and C# have interfaces?" "Well, C# has them because Java has them"
Nice try, but not buying it.
Ah, scanned the architecture-specific stuff and missed it, thanks
If it's `std::enable_if`, you are not allowed to specialize it on pain of UB, so a hypothetical sufficiently devious compiler can special-case it.
P0052: - http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0052r2.pdf - https://github.com/PeterSommerlad/SC22WG21_Papers/tree/master/workspace/P0052_scope_exit/
"complex" is subjective. to me it seems like a basic feature used in a variety of programming idioms.
Yeah, but a hypothetical devious compiler would want some form of users, so it would issue a diagnostic then. Anyways, I'll add a note.
Comeau C++ Compiler, Bursting With So Much Language Support It Hurts!
Is this valid: `using Ts::operator()...; `. AFAIK it's not in C++14, is that a new feature with C++17?
[Image](http://imgs.xkcd.com/comics/workflow.png) [Mobile](https://m.xkcd.com/1172/) **Title:** Workflow **Title-text:** There are probably children out there holding down spacebar to stay warm in the winter\! YOUR UPDATE MURDERS CHILDREN\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/1172#Explanation) **Stats:** This comic has been referenced 961 times, representing 0.6814% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_dbil1qm)
Those who don't know RAII are cursed to reimplement poor reimplementations of it... poorly. 
In my experience, the most productive way to understand a million-line C++ project is to work on refactoring it into a 500k-line C++ project, then hiring someone way better than yourself to refactor *that* into a 250k-line C++ project. I've yet to see a large code base that came from "industry" can't be shrunk by a factor of 5 or even 10. Sure there are exceptions, but few and far between. If the codebase grew organically it will be big, full of redundancies, and full of code that does things at way too low of a level of abstraction.
&gt; angrily tut tut!
I wouldn't consider it a "creature comfort". Not having messages like that is a basic usability bug. Programming languages are there to be used by humans. A compiler that doesn't have the human programmer in mind when issuing diagnostics is broken at a fundamental level.
I agree - that's a great change.
`__COUNTER__` is always preferred. `__LINE__` can easily lead to duplicate definitions, potentially violating ODR, etc. `__LINE__` was meant for diagnostic macros, not for uniqueness. E.g. if you have macros that use `__LINE__` in multiple header files, and include them into your translation unit, the `__LINE__` numbers could very easily clash: there's no mechanism to ensure that all `__LINE__`s are unique across multiple files. TL;DR: **Only use `__LINE__` when you are providing diagnostic feedback that points to a source line. Do not use it for anything else!**
I do similar things without thinking about the details of it when a function starts to get hairy. Nice job identifying a good and useful pattern :)
They aren't. You don't need to use a VCS to write and run software you would compile with GCC. You *do* need the linker, though.
This user prefers spinning ball of death much more to corruption of the file I'm editing.
&gt; You don't need to use a VCS to write and run software Yes. You don't need the presence of atmosphere to write and run software you compile either. But everyone who has to develop in such circumstances has a hard life ahead of them. By pretending that VCS is not an essential part of the development workflow, you only encourage the poor sods who still think that way. Please don't. If you develop something, anything at all, even a one afternoon throwaway, you do `git init` or `hg init` before you start, and you use the repository to keep track of your work. Doing otherwise in this day and age is sheer insanity.
No, it's just an honest assessment. Why does the compiler need to care about what VCS you're using? Does it also need to be aware of your text editor? Surely the text editor is more important than the VCS.
&gt; Maybe in your code, but what about someone else's code? Then they're using it wrong
&gt;eats scone furiously Oi, it's pronounced scone, not scone!
I'm not advocating writing code like that, but who says it's wrong? Does the standard say it's wrong? `__COUNTER__` is not standard in the first place. Does your company coding standards say it's wrong? Who actually says its wrong?
I work with a scripting language called Angelscript that exposes C++ functions directly to scripts. Multiple inheritance isn't supported because of (among other things) not knowing how to offset the this pointer for the call. I've also seen games avoid MI to reduce the size of pointers to member functions.
If I'm not mistaken, that's how a few implementations are defined - state machines they're called i believe. Microsoft had a talk on it during CppCon. 
FYI in C# you can provide separate implementations for methods with identical signatures from multiple implemented interfaces using explicit interface implementation. Calling the method through a particular interface will resolve to the corresponding implementation.
The size of the pointer increasing is a msvc ABI bug. It really causes compilation error that shouldn't happen according to the standard. They should really try to make a new ABI cleaned up from all the mess they done before. Sure, you can't break everyone's code... But it shouldn't be that problematic, they break it every version anyway.
I did convert a large VCL C++ Builder app to Qt. But I have no experience with Firemonkey so I can't help you I suppose.
Crypto++ implements these state machines for its non-blocking I/O and filter classes. In practice, the code transformation, when done by hand, is relatively rote, but extremely brittle and hard to get right. Of course, it would be much more usable if it could be done by the compiler. Our current infrastructure uses stackful coroutines (we call them components) implemented using Windows fibers. Much more intuitive, and easier to get right (in the absence of a compiler transformation).
I never noticed that `using ...` proposal, would really appreciate if you could provide a link to it. I wonder what else is allowed.
Yup. No reason I shouldn't be allowed to use multiple inheritance just because some people can't control themselves. C++ has virtual inheritance, anyway.
Good point, and very true. The difference I think is that in Java the programmer still implements the one method which may have been declared in different interfaces and have incompatible semantic meanings and therefore it's impossible to implement it correctly. But at least the programmer did it. Whereas in the diamond problem, the compiler either needs to fail or make a decision that could quietly introduce issues without a programmer being directly involved. But I think this also nicely shows the different approaches languages take. "In practice both have issues, so why not allow MI" (C++). "Without full MI the theoretic ambiguities can be avoided without the compiler needing to guess. (Java)" (and then, Java added default methods in interfaces...)
&gt; The size of the pointer increasing is a msvc ABI bug MSVC has an ABI for inheritance implementation details?! Where?!
There you go! https://www.codeproject.com/Articles/7150/Member-Function-Pointers-and-the-Fastest-Possible
How about cmake server mode?
For plain C I've made something similar recently - https://github.com/zserge/pt Not as safe as C++, implemented in just macros, but supports various styles of local continuations and provides a nice while-loop that yields on every iteration. Very helpful in small embedded projects. Also, I believe switch/case is probably the worst local continuation as it doesn't allow you to have nested switch/cases in your code. setjmp is probably better if you can afford it, and gcc/clang now support goto label references which is less limited than standard C switch/case.
So, write a function that takes a collection of lambdas, and returns a function-like object that selects between them using overload resolution rules. I'll be waiting for tue multiple inheritance-free version of this in the corner. Let me know when you are done. And yes, the Turing tar pit means this, and everything else, is not required to solve any particular problem. But the ability to overload like this means I can: auto sorter = order_by( overload( identity&lt;BobType&gt;, get_field_bob )); sort( begin(v), end(v), sorter ); auto r = equal_range( begin(v), end(v), foo ); And I just took a range of element, sorted them by `bob`, then searched for the element whose `bob` is equal to `foo`. The tools you can build are powerful and can make complex code into simple code. 
Note that this article is from 2012. These days, lambdas are well-supported in every compiler and are a better alternative to `std::bind` in almost all cases.
But that's not MSVC nor ABI, that's just some guy looking around how they implemented stuff.
&gt; VS_DEBUGGER_WORKING_DIRECTORY With the new support, you can set the working directory for a CMake debugging session by adding a property "currentDir": "&lt;yourdir&gt;" to your debug configuration in launch.vs.json Yes, RC.2 ships with CMake 3.6 and likely RTM will also ship with that version. We're in progress of rebasing our code to version 3.7 and we plan to push the code to a public repo ASAP. Here are the versions of the different components in RC.2: cmake version 3.6.20160606-g836e2-dirty-MSVC cl.exe: Version 19.10.24728.0 devenv.exe: Microsoft Visual Studio Enterprise 2017 RC Version 15.0.26014.0 D15REL hth
&gt;Knock knock. “Race condition.” “Who’s there?” Hah.
Well, the reason for using CMake is so I won't have to have IDE specific files or such. So I'll probably stick to nightly CMake builds until you migrate to CMake 3.7 (and beyond). By the way, to have a short linebreak on Reddit you need to have 2 spaces after your line. Doing that would improve formatting of your comment :)
Pretty much this. Unless you have a long term goal to move to Qt or to learn Qt then there is no reason. Qt is great but it's far from perfect and can be very frustrating to work with (like all large frameworks). Good luck.
Can I just upgrade from RC1, or do I have to uninstall and install new version ?
Upgrade is supported. In VS, in your Notification tool window, you should see the option to upgrade. If not, please relaunch the VS installer and you should see the "update" option.
You have almost got to the point here. Only one step is left. &gt; Because the numbskulls in charge didn't make them usable, that's why Ok, but who is in charge in our case? In FOSS, everyone is in charge. Everyone. Yes, and **you**. So instead of ranting here, go and do something to improve things, numbskull! (I found your rant completely unfair towards all those people who invest their time and effort to provide us with GCC, libstdc++ etc.)
Why use an `atomic&lt;long long&gt;` when you can use `atomic&lt;std::chrono::nanoseconds&gt;`? Why lose the type information? Also, if you're going to spin, it makes sense to at least `std::this_thread::yield()` the current thread, in case there are multiple threads per core.
I've experienced bugs with the size of pointers varying depending on code using them before or after the class definition. The compiler will happily allow you to pass differently sized pointers around and corrupt the stack. This was a few years ago, when i was still using VS2010/2012 so it might have been fixed by now.
These things are offered in commercially supported products. Most of the code is developed by people who are paid for it. FOSS is, in effect, a good way of simplifying the logistics of multiple commercial entities contributing to the projects. Enabling individual contributions is, in case of big projects, almost an afterthought and of little consequence.
I agree with you about using an atomic duration (which is allowed since duration has `= default` copy constructors and operators and is therefore trivially copyable, the requirement for `atomic`). However, I don't think `yield` would make sense, since the whole point of a spinlock is to avoid a context switch. Calling `yield` would cause such a switch if there was another process waiting. Using "real" mutex's `lock` function will achieve the same result.
__COUNTER__ isn't immune either -- it can lead to subtle ODR violations when used across translation units. I wish the standard would provide a __UNIQUE_HASH__ or something to allow for this sort of thing more easily.
Thanks for the call out to my blog post!
If you can't get the lock and are committed to spinning, then it doesn't much matter what you do between now and trying the lock again, as long as its relatively short. Getting the time is almost never a syscall anymore; it's fetched via VDSO on Linux and FreeBSD and presumably something similar on Windows. Otherwise, I agree.
Thank you, I will try. Are JSON files documented yet? Thing is so fresh Google fu ain't helping yet.
Using something as simple as a point type as an example isn't ideal. Also, std::unique_ptr or std::shared_ptr instead of a raw ptr would better follow modern idioms.
Well may be not changed to irritating :) Because compiler will not be able to do full optimization on this class, pointer indirection, bad memory layout and so on. So in some cases it could be may be 10x slower or may be even more, but of course it is only my guess. If some one has time to make a benchmark, fell free to do this :) PIMPL makes sense only for big and heavy classes. 
yes, but it hasn't graduated to MSDN yet. You'll find all the details here: https://aka.ms/cmake#configure-cmake Also, VS offers IntelliSense while editing the CMakeSettings.json file which I hope helps too
Binary exponential backoff up to a predefined blocking threshold is a known good comprimise for any kind of multithreaded polling. I just start with a 1 nanosecond sleep and double the sleep until I reach the threshold, then block the mutex. No reason to have an atomic anything in there at all since the backoff time is going to be local to the lock call anyway
Can you help me out with linking libraries in clion? I want to link a library called libcs50.a but am unable to find an option to do so.
Sounds like you needed to forward declare the impl in the .h file so you could access it, boost unique/shared can make some simple errors look really weird. Also, I think unique &gt; shared in this case as I can't think of when you would ever want to share the impl. So for example in the .h file you could have: struct impl; class example : boost::non_copyable { public: ... private: boost::unique_ptr&lt;impl&gt; m_impl; } I know that definitely works. Your public functions would be the things you wish to expose and in the .cpp file they would simply call your impl.
It may not definitely work, as `~unique_ptr()` contains a call to `~impl()`, which is not defined at the point of the call. You need to do a `example::~example() = default;` in the header to avoid. This is valid for `std::unique_ptr` at least.
Not in the header &amp;ndash; `impl` still isn't defined there. That needs to go in the source file, after the definition of `impl` is visible.
That was awesome. And Java sucks.
It could still be a class emulating an arithmetic type, or an extended-integer type. Point-being, if the goal is to be correct/portable, then use `duration::rep`, not whichever concrete type your implementation happens to use presently.
For Linux the terminal size change is communicated to your program via the [`SIGWINCH` signal](http://man7.org/linux/man-pages/man7/signal.7.html). After receiving that signal, you can query the (new) size using the [`TIOCGWINSZ` ioctl](http://man7.org/linux/man-pages/man4/tty_ioctl.4.html).
For Windows, your console app will need to call [ReadConsoleInput](https://msdn.microsoft.com/en-us/library/windows/desktop/ms684961\(v=vs.85\).aspx) and look for messages of type WINDOW_BUFFER_SIZE_EVENT
That makes a lot of sense, cheers.
Are you saying 'almost' all as a sort of catch-all? I converted a 1m+ LOC codebase to compile with C++14 on the 5 series of GCC, and found no place where a boost::bind or boost::lambda could not be replaced with a C++11 lambda, nor where it was cleaner/easier to read to use the former over the latter.
&gt; Though, there is a little problem over arrays is that it takes a bit more memory than an array and may cause performance issues if the vector is made quiet large. Huh?
It depends on how big your project is and what parts of the VCL you would need to replace. There are many similarities, but the API is organized differently. If you use a lot of database components, it could be a hard time. If we're talking MLOC's, it's not worth it. What we've found is best to do is remove as much dependencies on third party libraries as you can, relying on STD and portable open source libraries if you need to and only then interface with your app. It's a lot of work but worth it. In the end if you do take the plunge, I think Qt and especially QtQuick is way nicer to work with than FireUI. QML is visionary space-tech IMO. Plus, you get more frequent updates, the docs are top notch and you lose the dependency on the compiler, which is years behind the standard in C++Builder, even the "new" Clang-based compiler. Bear in mind that the pricing for Qt is steeper than for C++Builder if you can't comply with LGPL (which can be a problem on mobile). 
Yeah, cuz the interior of vector is made through more complex function. But for usage it is more flexible than arrays.
BAH! Pedantry will get you everywhere around here. Yes, I should have clarified C++14. Thankfully, our codebase hasn't starting leveraging move-only types at all. Heck, I even had to remove a few std::auto_ptrs and 'auto' storage classes. Maybe in another decade we can start modernizing :P
 So I am getting that I need to look for messages? is there a good tutorial for this, and is this how you do it in a more general-case, for lets say a class function, or is it just better for other thing that I do have the code for to do a listener/listenee system?
memory leak hiding is not a real problem if you have serious code testing: you test with sanitizers and gcc that is actually leaking will show you the problem since it now has sanitizers.
What I meant to say is that surely writing `long long` is ugly when std types exist
The sign of the type was not meant to be my complaint, just rather the use of `long long` at all, rather than a std type.
&gt; QML is visionary space-tech IMO. +1, it's reactive programming for user interfaces done (almost) right.
The problem with LGPL on mobile is with signing packages. You basically need to give away your keys so that anyone can repackage your application. As with the object files, it poses a serious risk of facilitating reverse-engineering, which is permitted by the license BTW. Edit: I may be in the wrong here, but there is definitely a problem when you need to supply everything the user would need to repackage the app themselves. From a business standpoint, not everyone is comfortable with this. 
Why crap? Don't you think that designing interfaces in C++, flexible and easily modified at that, is awkward to say the least? 
It really depends on your domain. In my domain: 1. Input is structured, either as xml/json or in a specific binary encoding 2. In the xml/json text, a xml/json decoder is obviously better than a regex 3. In the binary encoding case, a dedicated decoder is both faster and easier to write than attempting to use regex (most fields are fixed-length or length-prefixed) So... I mostly use regexes in Python scripts for quick filtering and with `ag` for searching across files :)
So you think Qt before QML was awkward? Qt Widgets (i.e C++) is awesome. Wouldn't it be good to have similar awesomeness for mobile platforms as well? 
What I like about the first attempt is that the proto really mirrors the one of find, and, as you suggested, could mirror find_if with split_if just as well. What I mean by idiomatic, is not really "idiomatic C++". As you rightfully noted, C++ is so versatile that there is no really "idiomatic". That being said though, the *STL*, especially &lt;algorithm&gt; look like they have some kind of design rules, with the iterators, ways of iterating, etc etc. For instance, no algorithm that I know of uses CPS like in my second attempt. The first attempt looks really good and idiomatic but has this poor inconsistency that ruins everything :(
Does it have specific recommendations regarding floating point?
Usage as a compilation firewall to reduce dependencies and build times is also a thing...
&gt; `vector&lt;char&gt; vowels('a',5);` No.
An explicit call to the OS sleep() makes no sense, though. If you sleep() you are: * entering the kernel * putting the thread on a list somewhere ... which is exactly what happens if the thread sleeps on the lock(). It is strictly *less* efficient for the thread to manually sleep() while doing a try_lock() than for it to just lock()
I don't know this for sure but I guess there is no level A software (e.g. flight control) that uses floating point. The standard probably doesn't forbid it per se but makes it pretty much impossible to come up with the required proofs because of the problems mentioned above. Bottom line is: if you can't prove it don't use it
Wow. Really interesting. I bet they have more specifications than actual code
* SEI CERT C Coding Standard + Rule 05. Floating Point (FLP): https://www.securecoding.cert.org/confluence/pages/viewpage.action?pageId=372 + Recommendation 05. Floating Point (FLP): https://www.securecoding.cert.org/confluence/pages/viewpage.action?pageId=158237216 * High Integrity C++ Coding Standard - http://www.codingstandard.com/rule/4-3-1-do-not-convert-an-expression-of-wider-floating-point-type-to-a-narrower-floating-point-type/ - http://www.codingstandard.com/rule/4-4-1-do-not-convert-floating-values-to-integral-types-except-through-use-of-standard-library-functions/ - http://www.codingstandard.com/rule/5-7-1-do-not-write-code-that-expects-floating-point-calculations-to-yield-exact-results/ 
With PIMPL you have to write bodies for the public interface that forward the calls to the private implementation. Unless you need to do some extra work aside from trivially calling the function (for example, bonus error checking), this becomes redundant and annoying. What are people's thoughts on an alternate approach: make a pure virtual class as the public interface, and derive the implementation from it? It has the advantage of not having to write two bodies per function.
Qt Widgets still exists, and is still supported. You don't *have* to use QML at all. If you're targeting mobile platforms, you probably *want* to use QML though.
I've never liked the dichotomy the article seems to create - that most software is written by egoistic, "up-all-night, pizza-and-roller-hockey software coders", and systems software is written by stuffy "grown-ups". Embedded/systems critical software is generally more robust because: 1. Its usefulness is predicated on it being (almost/hopefully) bug-free, moreso than desktop, server, or web applications. 2. More time and money is put into design, testing, and review to ensure the previous point. The vaguely ageist vibe is annoying too. Seasoned engineers are worth their weight in gold, but there are certainly 20-somethings out there writing solid systems code.
split() is a pet peeve of mine since I once had to lock down and redesign it in a framework where people kept patching it for their use case and breaking it for others. First, note that there are actually two different and commonly wanted behaviors for a split() function, one where you care about empty tokens between delimiters and another where you don't. The most common cases are extracting tokens between commas and spaces. C#'s String.Split() allows you to select behaviors via StringSplitOptions; Python and Perl appear to special-case the second behavior when splitting on whitespace. [N3593](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3593.html) selects behavior based on the delimiter object. A split() algorithm that has no state other than the range it is working on has a weakness: the termination state is identical to that of an empty final token in the case of a trailing final delimiter (a,b,). For this reason, an interface like the first where you keep passing a narrowed range back can't really work as expected. However, a for_each() interface like the second is awkward to use. IMO, custom iterator type is the only way to go; it's idiomatic, can store the extra needed state, and can be used with existing adapters to use with range-for or to get a get_next_token() style enumerator interface. 
Out of curiosity does this have anything to do with game hacking? 
nope, i'm trying to make an extension to some software i wrote a few years ago that i no longer have the source code to :((
They are here, but there is no promise on API stability so the headers are private : https://github.com/qt/qtquickcontrols2/blob/5.7/src/quicktemplates2/qquickbutton_p.h
This article confuses a few issues. Array is not the stack based version of vector. Array is a fixed size container with the size encoded in the type, vector isnt. This has implications for metaprogramming. And vector can be stack based with suitable choice of allocator (though would have max size limited by stack size). Similarly, one could trivially introduce HeapArray&lt;T,N&gt; which is fixed size and uses heap. 
&gt; Hello World also does not make any sense It does. it is the simplest example showing how to print a line of text. There is no harm from using that code everywhere. On the other hand, if a novice sees this tutorial and decides to use PIMPL for simple types like `Point2D`, his code will be horribly inefficient.
You can have a nullptr in space. I work with them currently. What you can't do is blindly deref a pointer without checking for NULL.
In the immortal words of Walter White, "you're goddamn right"
People just represent company's culture and mentality. One company says: "You are an engineer. There are specifications, rules, guidelines. Follow them." Other says: "You are the best, and we need your best code yesterday." How their employees will look like? 20-something working in company with highly standardized and formalized technical process would hardly pull all-nighter and wear flashy t-short. 
What's the motivation for avoiding floats? Also, when you do use dynamic memory, how do you handle the possibility that an allocation fails?
Not to be too critical, but your article doesn't seem to use any C++11 feature. You show iteration of a `vector` with the size instead of using iterators (C++98/03) or a for-range loop (C++11/14), no actual use of `auto` even in the most obvious of classic use cases. TL;DR: This is C++98...
(A) floats have ... weird ... behavior at the extreme ends with loss of precision. It's possible to have arithmetic on them that results in no-op, or the number failing. It's a lot safer to use fixed-width integral fields with use-case-defined scale semantics. (B) My mission CPU doesn't have floating-point hardware. Re: dynamic memory, my specific solution is that I statically allocated a slab of memory to be used as a ring buffer in emergencies. If `malloc` fails, I use the slab. If `malloc` fails and the slab is full, well, fuck. Something has to get thrown out, and that's a different failure case that my design doc has space for. Eventually, my client will tell me what acceptable failure handlings are (throw out oldest message, throw out newest message, do something else). But yeah I have a lot of analysis in my work for "should we use `malloc`, and if so, what if it fails?"
&gt;I guess there is no level A software (e.g. flight control) that uses floating point Very interesting. How is that possible? How do they do all the calculations then? 
I see. As you have mentioned you don't use floats unless necessary, even then it is checked. But you are writing drivers, and I believe naturally you are not exposed to a lot of floats. What about avionic/flight control system engineers? Things as simple as latitude/longitude/weight/speed/... are floating points. There are also a lot calculations done with these numbers. How is it possible not to use or even check the determinism of every single arithmetic operation done with such numbers?
It's fine as long as you're handing out references or pointers. I am having to refactor a work project so all outside calls have extra validation applied, so I'm kinda wishing we had taken the time beforehand to use pimpl.
I figured by now automatic tooling could destroy all formatting and rebuilt it... not that far yet?
Just want to point out that "dollars and cents" are also fixed point, just in a way easy to express in natural language.
I see. Thanks!
Also, please, at most use `"includes"` only for the relevant header for this file. For everything else, `&lt;put/it/in/a/pretty/include/namespace&gt;`. It may be longer today, but tomorrow you'll more or less just have to `s/include/import/;s/\//./g`, and also it dramatically reduces the possibilities of problems due to two headers having the same name.
[removed]
Thanks for your suggestion, I didn't think of that back then. I updated the document now :)
Perhaps you can provided some insight into the size of your team?
For my current mission, me. Usually, five to ten.
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/5k475d/injectable_qt_widgets_application/dblqw78/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
np, /u/nixservice mentioned you will need the PDB as well. Also try some of the other decompile tools.
Degrees, arc-minutes, arc-seconds, milli-arc-seconds, micro-arc-seconds
From a modern point of view QtWidgets is awkward. As is WinForms, VCL and the likes. Think about your UX designer bringing you all those shiny responsive mockups with tons of transitions and you trying to implement them imperatively. And then they change one thing and it collapses. Declarative UI programming is faster and more flexible. It's real.
To be fair on the developers I read somewhere a long time ago that they swapped out a system that did match with an upgraded one that didn't hence the bounds problem.
Where does it say that declarative UI can't be brought into C++?
It does seem you are right.
&gt; which is possible but pointless. this is a very common feature asked in the mailing list though. C++ can get very high level with templates &amp; friends, so why not leverage this to build UIs ?
&gt; Think of it as a layer of abstraction that's easy to get optimized away by the compiler. Is there a way to enable these optimizations for std containers only, on debug mode ? Because my debug binaries are approaching the gigabyte, while the release ones are less than five megabytes.
That requests 97 copies of a character with value 5.
PLT?
To amplify: DO-178 has an additional document DO-332 to cover Object Oriented Technology and Related Techniques. The book is actually somewhat longer than DO-178 itself, and can be summarized in one sentence: "The RTCA does not trust abstraction."
When does dereferencing a null pointer every lead to lagging the whole computer? The operating system notices you tried to dereference an invalid pointer, and you get a SIGSEGV, which if unhandled crashes the application. If anything handle the signal, and do your error handling there (display a message, save backups, write logs, etc.) and then call `abort`. Maybe writing to some place in memory that isn't a null pointer could cause issues that would lag the computer, but you also can't detect that by checking for null pointers so the whole thing is moot anyway. tl;dr: Null pointer dereferences do not cause lag.
That would be awesome 
By that description, couldn't you do `-O0` and stick with opting-in to only the optimizations you want? `-Og` should be acceptable in any case.
&gt; quick tip would be instead of using endl just use '\n' because using endl also calls flush() on the stream which in this case adds unnecessary overhead I think this is something that beginner shouldn't even bother about...
Excellent material, it is interesting to see things like that, thanks for sharing
just do a google search for "spinning beach ball of death"
I don't see why not, it doesn't introduce any new concepts and is in my opinion a good habit to get in to
~~True, but the beginner should also be aware that this overhead will never ever be an issue unless they do some really performance-critical code. It's a good habit to get in to but be aware that it couldn't matter less for a RPS game.~~ _Edit:_ I stand by my point but agree with /u/dodheim's post below, a beginner shouldn't learn `endl` by default.
If you mean fixed point as in a certain number `k` of decimal places, you can just multiply the numbers by 10^`k` and then treat them as integers during addition and subtraction. If you're trying to do something a bit more clever, you could take a look at the Boost Multiprecision library, it has a rational number type `boost::multiprecision::cpp_rational` that provides a rational number type of unlimited precision. That said, I don't think the industry could ever be described as "agreeing on" boost, and I can't imagine it powering the Hubble Space Telescope, but it is one option.
For a filestream, `endl` vs `'\n'` can be an order or two of magnitude difference in performance. `endl` should be an obscure, forgotten manipulator, definitely not something people use by default.
Can you give a good reason to not just use a subset of C++ instead of writing things in C? There is an insane amount of functionality that things like templates alone can provide. Also, I don't see what the problem with zero-cost (or low one-time cost) abstractions is. I have more of a problem with having to learn how every device has every register set up. And heavens no if you forget to initialize the right defaults. That's actually why I like Rust, and use it more and more. Almost all of the code you write is glue-code (the same type of code that Odin is using ranges for), and at the end everything works and connects, while every function and method is trivially simple.
No db. I used sqlapi++. Also dependencies with VCL are not that high except for the TChart library. I've been able to try Qt for linux and Windows but not for mobile. Can be the mobile toolset for qt be evaluated too? It looks like it is not available for download unles you pay. The other thing that worries me is the fmx performance and limitations. There were some complains on the web about fmx at xe2 but now they are way past it. I'm strugling to find more modern user experiences with fmx 
How painful was it?
C++ realy likes types to be regular-ish value types. Interfaces wrapped in cow pointers with smart cloning on copy aren't bad. Act like nullable values, just have to use `-&gt;`. 
Download the open source version. It has all the commercial components under GPL. You just need to answer the questions as if you were building an open source app. Just remember that you're not permitted to use what you write with the open source version with the commercial version later. Concerning performance, there are some pitfalls in QtQuick, particularly if you use lot of js, but it comes with an excellent profiler and so most of the bottlenecks can be easily identified. You will find that doing things asynchronously and offloading more demanding work to C++ works wonders. 
&gt; That said, I don't think the industry could ever be described as "agreeing on" boost, and I can't imagine it powering the Hubble Space Telescope, but it is one option. I agree with you, 100%. But there should be some kind of a standard/library that the industry agrees on. Shouldn't be?
The whole STL threading library in libstdc++ is a pthread wrapper. Not sure about libc++, though, so relying on this wouldn't be a good idea.
Yes - I've done it before, in my game hacking youth. It was done with PySide tho, but algorithm is mostly the same. From source perspective you do in your thread func everything you would do in main func. Keep in mind that, for some strange reason std thread doesn't work from DllMain
&gt; How to make a good and idiomatic split algorithm? Here are three more (just API design): enum class options { empty_tokens, no_empty_tokens }; std::vector&lt;std::string&gt; split( const std::string&amp; src, const std::string&amp; separators = ",", options opt=options::empty_tokens) { ... } void split( const std::string&amp; src, std::vector&lt;std::string&gt;&amp; dst, const std::string&amp; separators = ",", options opt=options::empty_tokens) { ... } template&lt;typename TokenVisitor&gt; void split( const std::string&amp; src, TokenVisitor&amp;&amp; visit_token, // void visit_token(const std::string&amp; token); const std::string&amp; separators = ",", options opt=options::empty_tokens) { ... } Client code: for(auto&amp;&amp; w: split("sample text", " ")) // (1) std::cout &lt;&lt; w &lt;&lt; ", "; auto words2 = std::vector&lt;std::string&gt;{}; split("sample text", words2, " ", options::no_empty_tokens); // (2) auto print_word = [](const std::string&amp; token) { std::clog &lt;&lt; token &lt;&lt; "\n"; }; split("sample text", print_word, " "); // (3) 
Two orders of magnitude still don't matter at all for a RPS game. Still, I completely agree with the second part of your post - I will change mine.
this is the kind of answer i was looking for, mad respect to you man
I could get most of things working, but please allow me to ask you few more things If i set `configurationType` in json then `CMAKE_BUILD_TYPE` is not set and that is kind of required. I do pass it manually through `variables` but it feels wrong. Is there a right way to get build type in `CMakeLists.txt`? Looks like `generator` option specifies architecture we want to build. Is there a way to mix 32 and 64 bit executables in single build? Looking at `CMAKE_CXX_COMPILER=C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.10.24728/bin/HostX86/x86/cl.exe` does look like each arch has it's own compiler which is a shame. I tried meddling with `/machine:X64` parameter but i could not get it build 64bit executable with `Visual Studio 15 2017` generator. It is a shame though because we can easily do it with gcc by swapping `-m32` and `-m64` compiler options. But maybe there is a way to do this after all?
/u/GlowingChemist , /u/dodheim I agree that in performance-critical code people should use `\n` to specify that line has ended, but from the point of someone who is just learning about printing something to console, reading something from it or basic flow control (if, switch, functions, loops) it brings unnecesarry complexity. Not to mentiont that explaining that there is a special character `\n` just now will make someone belive it's something totally strange and unique etc. but in fact there are more such caraters like `\t` etc. And learning about them all now is like giving someone new documentation of `printf()` and having them to learn it by heart... Who would like that? In simple applications where you have something like: ``` int number; std::cout &lt;&lt; "Gimme a number: " &lt;&lt; std::endl; std::cin &gt;&gt; number; ``` performance is not an argument... And once someone learn basic programming, it's no problem to switch to faster solutions (but less readable).
`tie` takes care of flushing output before waiting on input. There is no perspective in which what you have is an improvement on int number; std::cout &lt;&lt; "Gimme a number: \n"; std::cin &gt;&gt; number; If `'\n'` and `endl` are both new, there's no point in promoting the latter, or especially making it appear canonical. ;-]
THIS guy is excellent 
Indeed. That header is not usable as-is.
It starts pushing args on the stack not because it's run out of GPRs, but because it's just the [calling convention](https://en.wikipedia.org/wiki/X86_calling_conventions#x86-64_calling_conventions)
Have you tried adding print statements to validate your assumptions or to debug the code with a debugger? These are both very common techniques that get results far faster than asking human beings online over the holidays
Why can't GCC figure this out with "too many" arguments?
/u/myrrlyn does your code use threads? If not, how are multiple tasks scheduled? Also what is the QA process like? As well as verifying functionality, does the QA dept. check code coverage and internal details like that?
You did not get latest memo from Herb Sutter? Latest consensus is you should not pass shared_ptr around unless there is explicit shared ownership between the 2 class. Sharing shared_ptr complicate the object lifetime and its destruction timeline.
For Pimpl, it is usually the dll or *.so that owns the pointer and responsible for destroying it because the application and dll could be using different memory allocator and the smart pointer ABI could be different as well. So raw pointer is the best bet. Note: I am not the blog writer.
Null pointers should be tested with an `assert` not an exception.
The two lists `Boost's primary test compilers are:` and `Boost's additional test compilers include:` are more or less identical, except for one or two items (or I'm blind!). It's quite confusing and hard to read. Why not just include the _additional_ compilers in the second list, instead of duplicating most of the list?
I was hoping to read that the VS2017 RC was supported, but didn't see a mention of it. I was hoping this was because the second list was a mistaken copy of the first! Can anyone confirm or deny that this is supported yet, or do we need to wait for 1.64?
What I meant was template&lt;typename Callable, typename... Ts&gt; auto foo(const Callable&amp; fn, Ts const&amp;... ts) { return fn(ts, foo(fn, ...)); } 
wouldn't it instead be up to VS2017 to support boost (like they want to do for Boost.Hana for instance) ? Libraries should be coded against a standard, and compilers implement this standard
It's not apparent to me what that is supposed to expand into...
Yea, I was hoping this too. Would be really sad to have to wait until 1.64.0.
Exactly. And then there's the [boost binaries](https://sourceforge.net/projects/boost/files/boost-binaries/), which will also be missing for ages for VS2017. In case of VS2017 it's probably less of an issue as it's binary compatible with VS2015 and you can probably just use the vc14 binaries. However let's see how well this works in practice with CMake and various build setups. Usually, there's at least some kind of issues ;-)
I guess you can write about it on their mailing list. 
Can't be bothered to register there - tried once but this mailing-list stuff has so horrible UIs (not the Boost mail-list specifically, all mail-lists), I prefer forums or something like reddit, that you can browse and post online. Either they read it here, or it's their loss.
Similar to operator+ (((1 + 2) + 3) + 4) fn(fn(fn(1, 2), 3, 4))
The [cppreference article on pimpl](http://en.cppreference.com/w/cpp/language/pimpl) has some discussion of the trade-offs vs pure abstract class.
But it looks like `ts.bar` is called with no parameters in the _fold expression_ while it's really a two parameter function, are the parens part of the syntax? If so does it perform binding? If bar takes three parameters could you say (bar("add"), ... ts) 
Who said it's a binary function? o_O It's a nullary function, and it's indeed being called with no arguments.
So the expansion I guessed in my first post is wrong? Please show the expansion, from what you just said it sounds like each member in the parameter pack has its *foo* member called with no parameters. This sounds more like *forEach* than *fold*. 
I think you're confusing me with /u/A_Seat_For_One, I didn't want anything other than to understand what you wrote. What does it expand into? I don't want to be rude but this is the third time I ask, please tell us so I can stop making wrong assumptions. 
It can if you define `_HAS_AUTO_PTR_ETC` before including any headers. There's also `_HAS_FUNCTION_ASSIGN`, `_HAS_OLD_IOSTREAMS_MEMBERS`, and `_HAS_TR1_NAMESPACE` for similar purposes.
I am not quite sure he (?) saw your update; you can type `/u/&lt;user-name&gt;` to ping a user (reddit will change it to an hyperlink to the user page AND notify them too).
Just use conan.io http://docs.conan.io/en/latest/getting_started.html You just need to add one line into conanfile.txt to install new version of boost or any other library
Well it may not be a big deal but if it was my software, my homepage, or my release notes, I would always be interested in how to make things better, even small things, and especially if it's something confusing like two near-identical tables (which could possibly even be a mistake). Another user that posted above me here got confused as well so it's definitely not just me. Anyway - I'm leaving it at that.
Sorry I wasn't clear. By 0 conflits I mean that all 4 sorts I'm using are being used in different functions. They DO sort the same list however. I basically have *1 - Sort course list by number of students (Ascending) *2 - Sort course list by number of students (Ascending) *3 - Sort course list by average student entry grade (Ascending) *4 - Sort course list by average student entry grade (Ascending) If I execute function 1, it will execute function 1,2,3 and 4 and not sort anything at all . If I comment 3 of those functions out, the remaining function will execute properly. I'm really confused by this error.
&gt;... the non-idiomatic use of C#/Pascal function naming convention... No idiomatic in the Unix-like world.
No. I wasn't really interested in getting the smallest possible size, just what would be the result with regular optimization settings. But the code is there if you want to try it yourself.
Underscores and a K&amp;R derived layout is the original C and C++ style. It's unfortunate that Microsoft adopted a different non-standard style, but luckily it seems the pendulum has swung back in favour for the original style these days for 'Modern C++'. I don't mind different styles but I wish people just kept to the idiomatic style like how it is for most other programming languages. Usually, but not always, this is the style of the standard library. See also CppCoreGuidelines.
It was quite the major undertaking. I would prefer not to repeat it. Almost everything is different so it is pretty much a rewrite of all GUI-touching code. 
In the game industry exceptions are usually disabled for performance reasons instead of code size. I can guess that code size is mostly a concern in the embedded market. 
K&amp;R style was basically "typing sucks". Bad idea with that. Not saying that Windows API follows a great style and in fact I think is shit but the truth is that at the time there was literally no "original C style" at all and everybody developed their own style. Also: &gt;See also CppCoreGuidelines Naming convention is one of the weirdest things in the core guidelines. It says "avoid CamelCase" but all types (classes, structs, etc.) are defined using it in the examples. Why CamelCase for types and snake_case for functions and variables? Because fuck you, that's why.
Your post has been automatically removed because it appears to contain profanity or slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/5jz3sz/c_pimpl_idiom_c_automatic_allocation/dbowsqd/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Dear AutoModerator, Bad boy. Down.
It would be interesting to compare to a compiler that uses setjmp/longjmp exceptions (I believe mingw32 on Windows does this).
I have read that before and I wonder if it is actually still relevant. Aren't exceptions today zero cost in the case when no exceptions happen and relatively cheap when they do? 
Yeah but according to the core guidelines you are doing it wrong and you should follow snake_case for all. But magically the examples don't follow it for types and what is worse is that some types follow CamelCase: struct Cable { int x; // ... }; But others follows what I would call the "ISO standard **but...**" style that uses snake_case but with uppercase (it seems Stroustrup likes it): class My_map { // ... }; I mean they say that developers should be consistent with the naming rules but they are not consistent in the core guidelines. The guidelines are interesting but the part about naming conventions I prefer to ignore it.
They are zero cost in terms of performance, not code size.
I wonder if the c results would change if the code was compiled as the "c subset of c++" verses actual c. I wouldn't expect a big difference, if any at all. 
Shameless plug: https://github.com/Orphis/boost-cmake Just add_subdirectory() this as a submodule and it will download latest sources (I have a patch for 1.63 pending) and build some of the most popular compiled libraries when used. Just link them using the Boost::foobar targets. And this works on most major platforms, tested on Windows, Linux, macOS, iOS, Android and just uses whatever build flags you have, so it will work with sanitizers directly too. I'm working on adding the remaining libraries and fix a few things there and there.
How about C version using gotos? It's not unusual way of error handling in C.
depends on the platform, but yes.
Wasn't the conclusion of OP's measurements that C++ exceptions produce smaller code size than C-style error structs?
That seems like it could run counter intuitive to many people, it would be cool to see examples that beat the common or 'intuitive' path.
It might not be an issue with x86 consoles, but could have been an issue with other architectures (just a wild guess, I don't know anything about this, treat this post as nonsense)
Show me evidence.
Here are the results I got using goto (w/ gcc7 on linux x86_64): version | binary size :---|--: C | 191195 **C (goto)** | **176091** C++ | 146059 C++ (noexcept) | 107787 The function used for the "C (goto)" results looked like this: int func222(char **error) { int result = -1; int a, b, c; struct Dummy *d = dummy_new(); a = func227(error); if(*error) goto exit_; b = func224(error); if(*error) goto exit_; c = func228(error); if(*error) goto exit_; result = a + b + c; exit_: dummy_delete(d); return result; } 
boost build is not a horrible build system, actually I find it has some features that no one else has. I think for many projects it's much better to drive the MSVC compiler directly from CLI as it does rather than try to emit a project file like cmake does. Making it work entirely from command line makes it work much better with appveyor CI. I don't think boost build is suitable for most or even many projects, but for building test suites and small libraries I think it's great. Much better than autotools or scons for instance. The problem with boost build is 1.) The documentation is not adequate at all. For anything beyond the most basic usage you are really on your own, and the error reporting of that language is not that great either. There needs to be a much better documentation effort to justify using it in a project as important as boost IMO, and comparing with the documentation for make and cmake is setting the bar too low. 2.) The name is awful. It should not be called "boost build" or "boost.build". Both of these names are ungoogleable. You just get instructions "how do I build boost". `bjam` was a much better name and they should have stuck with that or gone with an even more distinguishing name.
Yes, but often in games we don't care about error handling at all, we can just crash. Not always, of course, but often we control the environment enough that we don't need to worry about it. With this in mind, we used to disable exceptions because the code gen would be smaller and would save memory. On the PS3, for example, we only had 256 megs of CPU memory so if we could save 2 or 3 megs off of the executable size, it was significant. 
-Os is the default setting for an Xcode release binary. So Apple thinks it's a solid strategy, at least. 
I would never use "company x does it" as a reason.
... apart from the fact that boost supports various platforms and a hefty amount of compilers. In such context, what is deprecated/removed machinery?
`auto_ptr` was deprecated by the Standardization Committee in C++11 and has been removed for C++17 (with "zombie names" wording permitting implementers to continue providing it, if they choose). Boost has extensive technology to conditionally compile code for various platforms. What they should do is avoid using auto_ptr for platforms where unique_ptr is available.
Lol, there was some tests in phoronix a few months ago where they totally disproved this, for both clang and gcc. It was the expected O3 &gt; O2 &gt; Os &gt; O1 &gt; O0, with sometimes, but rarely O2 taking the lead Edit: sorry, sometimes -Os is even worse than that : https://www.phoronix.com/scan.php?page=news_item&amp;px=GCC-6.1-Compiler-Optimizations
I dislike this option because it needs another container, hence another allocation and isn't lazy
I think you are missing couple of adjectives there, including "horrible", "absurd", and couple similar ones.
Some projects use an interrupt-driven event loop, some use an actual scheduler and processes with context switches. Depends on the requirements and constraints. Hard real-time use a strongly deterministic system; soft real-time usually are on more capable hardware and can use a more capable kernel with real threading. We strive for perfect thread safety; I write shared code that has to be fully re-entrant, but for me that just means mutex-locking shared resources and that's about it. We require &gt;90% code coverage in unit tests, an integration test suite, manual reviews, and then what is called "a day in the life" testing. The code is deployed to a real hardware set and run for a long time, and we stress test it with the expected and some unexpected load conditions and make the environment hostile. For satellites, this means vacuum, vibration, temperature, and radiation testing of the hardware, over- and under- stimulating sensors for software, and making the satellite think there's a problem from which it must recover for the full system. This day in the life usually takes a week, minimum.
How long since this has been true? Don't modern games need to deal with network disconnections? Controllers being unplugged? Corrupt save files?
I did not in fact get a ping until afterwards; I didn't know the pinging would apply to edits though, that's neat.
`(ts.bar(), ...)` expands to `(T0.bar(), T1.bar(), T2.bar())` etc. For example: template &lt;typename T, typename... Args&gt; void push_all(std::vector&lt;T&gt;&amp; v, Args&amp;&amp;... args) { (v.emplace_back(std::forward&lt;Args&gt;(args)), ...); } auto v = std::vector&lt;int&gt;{}; push_all(v, 1, 2, 3, 4); The `push_all` function will expand its fold expression into: (((v.emplace_back(1), v.emplace_back(2)), v.emplace_back(3)), v.emplace_back(4)); That's it.
&gt; I don’t think you can be a good professional if you only know one language. All the real big systems are built using more than one language, and if you want to be an IT [professional], then you better know a few. We use quite a few at Morgan Stanley, and a lot of them are the most common ones – I can think of about 10, but I wouldn’t want to leave any out, so I’ll decline to comment further. - Bjarne I wonder if he ever writes Java. That would be an interesting interview, lol. 
&gt; These numbers vary a lot. But at this point you're probably thinking that exceptions at least are reliably slower, even if they don't throw. Actually, with this amount of variance, any results are meaningless, unless repeated thousands of times, which would not be very nice towards Coliru infrastructure.
If you're using builtin `operator,` then yes, of course, because builtin `operator,` only communicates void-expressions (so there is no state to accumulate). This is inherent to the operator, it _couldn't_ have any other behavior inside of a fold expression. _Overridden `operator,`_ may have any semantics the author likes, though, so you can't generalize it that simply...
As with most people of his stature "whatever he wants [in between working on standards], as long as his name is attached to OUR company"
Ehhh I've seen people on /r/cpp agreeing that raw pointers are OK for some use cases. Namely, for when: - somebody else owns it - thing's lifetime is longer than variable's owner's - you want to re-assign it, etc. I think that both `std::reference_wrapper&lt;T&gt;` and `std::not_null&lt;T&gt;` cover this use case, though. Strangely, those are not very popular, even here, especially wrapper...
They also have a hard limit on app size, binary size is a big deal for iOS.
Will we be able to upgrade from RC to RTM?
Static analysis. Thread safety isn't ungodly hard if you plan for it way way in advance, and make allowances in the design for locked shared resources, message passing instead of shared-state contention, and single ownership. The huge design process helps, as does the fact that we don't have to make general-purpose software that has to be ready for *anything*. Being able to tailor our functionality for known constraints helps a lot. For instance, I know ahead of time how many clients I have on my driver library, what their properties are, and can tune my work beforehand rather than having to solve it perfectly in the general sense and tune at runtime. I do not envy real OS or language developers at all, and have greater sympathies for projects using Global Locks. We strive to keep all our work as modular and self-contained as possible. It comes with a little more overhead in development time and code size, but it tends to pay off in performance. ____ It also helps that I fly a single-core CPU. Peripherals can contest occasionally through interrupts and DMA, but that's what planning is for. But yeah mostly it's planning before, manual static analysis during, and testing afterwards that finds bugs. It helps that QA and the devs keep score on who finds what haha
Its side effect doesn't matter, the idea of folding here is that `operator,` will be unfolded the same way every other operator gets unfolded. It just so happens we can take advantage of `operator,` to execute code in a way that seems like we're in fact doing a foreach.