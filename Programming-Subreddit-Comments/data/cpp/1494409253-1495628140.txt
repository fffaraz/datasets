Right, my thoughts exactly. I suppose we can also fall back to "normal"/local invocation for broken compilers provided that the information we have extracted from the preprocessed output (like module imports) is still accurate.
STDs spread like wild fire also, it does not mean they are good.
Is wild fire spreading meant to be a good thing or should we call the buck fire brigade?
You may also want to have a look at [cpp-dependencies](https://github.com/tomtom-international/cpp-dependencies)
GCC handles this by emiting spaces. Given the following text: #define A - A-a; Preprocessing it gives `- -a;`. There's a `--traditional-cpp` option to disable this, which gives you `--a;` instead. You can see similar results with things like `a/* */b`, which will become either the 2 tokens `a b` or the single token `ab` depending on the option.
Thanks, never thought about these things (here is some [more info](https://gcc.gnu.org/onlinedocs/cpp/Traditional-Mode.html) if you are like me)! So my understanding is `--traditional-cpp` is non-conformant. I now see the problem: $cat &lt;&lt;EOF &gt;test.cxx #define A - A-a; EOF $ g++ -E test.cxx - -a; $ clang++ -E test.cxx - -a; $ cl-15 /E test.cxx --a; If anyone knows how to coerce VC to do the right thing I am all ears.
Do you want feedback based on - "this is some code I've done as an exercise, I don't plan on any one using it", or - "this is a lib I plan to make available to others or myself" If it's the latter, better run before any redditor with a security background read your post ^ ^
CppCheck, PMD, OClint, clang-tidy
boost::flat_map needs to be in all the graphs.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [Alien2909/Password_Generator/.../**main.cpp#L37-L63** (master → 9648a2d)](https://github.com/Alien2909/Password_Generator/blob/9648a2d6fcea512838b9e4dd95883386cdc2b19d/main.cpp#L37-L63) * [Alien2909/Password_Generator/.../**main.cpp#L8-L10** (master → 9648a2d)](https://github.com/Alien2909/Password_Generator/blob/9648a2d6fcea512838b9e4dd95883386cdc2b19d/main.cpp#L8-L10) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dhdhjsu.)^.
&gt; Checks only occur when calling `at` Indeed, and I would recommend to use `at`instead of `[]` &gt; There's no need to use a potentially heap-allocated string for something initialized from a literal which is known at compile-time. Unless you work on a specific platform where heap-allocation is expensive: it's not going to matter. Also, why adding `constrepr` would not prevent heap allocation? (It's a genuine question, I haven't work with `constrexpr` yet) Why not `string_view`, I had the impression that `string`=possession and `string_view`=view of something owned by someone else. I guess the "someone else" is here the const char*, I thought it had to be an instance. Well, TIL.
Very nice. I don't understand though why it is implementing a whole test framework? Surely being "no-dependencies" can be achieved by shipping gtest or whichever framework you like together with the project.
&gt; Indeed, and I would recommend to use `at` instead of `[]` That's bad advice in my opinion. You should only use `at` if the index you've received is out of your control (e.g. user input) and you cannot assume it's in range. Even then, `at` throws an exception, which (again, in my opinion) is a terrible way of dealing with an "out of bounds" case and isn't friendly to no-exception projects. I would rather create a function that returns `std::optional` instead of using `at`. But I honestly cannot recall a situation where I had to index a container with something that logically "could be" out of bounds. --- &gt; Unless you work on a specific platform where heap-allocation is expensive: it's not going to matter. So what? Why would you waste resources, even if it doesn't matter? Your application is not the only thing that's running on the machine. C++ allows us to elegantly write programs that do not waste hardware resources, and I don't see why we shouldn't take advantage of it. `std::string` is inherently more complicated than `constexpr std::string_view`. One is a dynamic resizable buffer, the other one is a compile-time-known view of a buffer - it's "less mutable" and easier to reason about. --- &gt; why adding constrepr would not prevent heap allocation? Defining a variable as `constexpr` forces the compiler to evaluate it at compile-time. Even though allocations cannot (yet?) be modeled at compile-time, the usage of `constexpr` here is orthogonal to heap allocation - `std::string_view` is enough to guarantee that we only have a view of a string (no ownership, no allocations). 
&gt; Why std::function? "streams are already rumored to have overhead, let's throw more overhead on top of that"? I don't see how it would introduce overhead.
i have make it better https://github.com/Alien2909/Password_Generator/blob/master/main.cpp 
&gt; Well, not all of us have the choice of using the latest compilers. I spend a lot of time writing C++98. :-) My comment is that the language or even the author is not responsible for the debugger stepping into a different function to that which the maintainer desired. Perhaps there is a way to configure the debugging environment to continue until it reaches `f`'s frame.
The trick is to write the shortest possible quine. You'll have a hard time beating smr 1994. http://www.ioccc.org/1994/smr.hint
It's had its chance for more than a year. It [failed miserably](https://meta.stackoverflow.com/questions/348030/is-documentation-a-failed-experiment).
std::string cannot be constexpr, so it does make sense. I think constexpr auto pass_leters = "whatever" would be better imo. 
std::string_view is only part of C++17, which has not become standard yet on all compilers. I know that AppleClang is still using &lt;experimental/string_view&gt; (which I love). I'm all for string_view, but as a beginner I don't think they'll understand it / need it. 
Truth. I spent a while rejecting terrible edit after terrible edit, but there's such a steady stream of them. I give up. Wish I could just stop getting notifications about it...
The wikipedia links define precondition and postcondition symmetrically and suggest both of them are dealt with by asserts, as it defines them as program logic errors. Herb's article specifically excludes assert type conditions: "(In particular, here I don't consider programming mistakes, which are a separate category and are normally dealt with using assertions.)". He defines pre- and post-conditions in terms of exceptions, e.g. postcondition failure to allocate memory after a string::append() - this is clearly not a logic error. So again: there are 2 senses of error - logic vs unexpected, which are assert vs exception respectively. And either pre- or post- can be an assert or an exception depending on the nature of the error, not whether it's before or after some piece of code, which seems irrelevant. For instance if you made the same check for available memory either before via a preallocation, or later on-demand, does that change it from an assert to an exception? If I read from a socket at the start of some code or at the end and it fails, does that determine if it's an assert or exception, or is it always an exception because it's never a program logic error? (and precondition and postcondition definitions aren't as clear cut as you suggest, if Herb is to be believed that failure to allocate memory is a valid postcondition, but wikipedia says it's a type of assert). &gt; Yes, but this isn't a condition that needs to be checked This is the exact definition of an assert - something you expect to be unconditionally true given correct program logic and which doesn't depend on uncontrolled external factors (filesystem, memory, network, user input, etc.).
In what way is a C library "*even better*" than `boost::regex`?
Got it, thanks. Funny enough, this particular example works if we preserve comments (`/C`).
It pollutes the global name space. Let's say you define a function called "log10". If you include the header &lt;cstdlib&gt;, you get the function "log10" too. Except, since it is in the name space std, the way you call the function is by calling std::log10. However, if you use namespace std, and you call log10, which will it use? Answer is, compile error! It's better to use std::log10 if you want their log 10, vs log10 for your defined log 10. I hope that explained it. Edit: changed &lt;cmath&gt; to &lt;cstdlib&gt;, whoops. 
I didn't know this existed. After looking at it a bit, I don't care either. SO as a whole really is a bit of a wasteland. Just a garbage heap of stupid questions. You need google to search it effectively, so why even bother? Before we had SO we had all kinds of better resources. The popularity of SO has caused those other sources to basically pitter away, but the quality hasn't been replaced. Its success and its failures I think can pretty much be blamed on one thing: gamification. Gets the numbers to come and participate...and then encourages quick, incomplete, or downright wrong answers to get upvotes.
Try doing university assigments, they help alot
&gt; However, why use std::string_view vs. std::string is hard to explain (non-owning reference) A person who isn't prepared to understand that contrast isn't ready for C++ in the first place. C++ is all about value semantics, and if you don't understand that plus dynamic object lifetime then you're simply using the wrong language.
That's fair. I was taught c++ when I was 12, and I never understood any of that and I was incredibly confused at the time. Now, 4 years later, I'm beginning to understand it, and I think that there needs more explanation / focus into the memory aspect of c++. 
Fair enough. std::string's inefficiency was what really annoyed me when I was trying to optimize my code / memory allocations, I'm glad it's being addressed in the standard library.
&gt; the `stl_vector.h` I have on my system (MinGW) 0. The header has been called `vector` since C++98; if you're using something non-standard then we're having different conversations. 0. I'd take UB over a lazy and strongly-arguably incorrect way of handling a programmer error (if you're indexing into a vector out of valid range then you're violating the container's preconditions, which by definition can only be programmer error). &gt; Some errors aren't caught by the test system (and using passive-aggressive remark isn't a good idea). Aggressive-aggressive: if you're not testing correctly then it's your fault. Test with assertions enabled; that's what they're for. &gt; I prefer a tiny performance hit to a potential oob, but ymmv I'd prefer to pay nothing when I _know_ there's nothing to pay for; that's a large part of why I'm using a systems language in the first place. &gt; For some software, you can't use debug build as the performance hit is too big Optimizations enabled + assertions enabled is the expectation here. "Debug build" is a silly MSVC concept, AFAIK. &gt; Finally using `at` allows one to have an `assert` that can recovered from An exception is not an assertion; that's the whole problem: the stack potentially gets unwound with the former, actively sabotaging simple debugging.
As good a place as any. They gloss over the build process for you and I'm a firm believer in knowing how that works well enough to hand-author a makefile when you need to, but I don't think most programmers subscribe to my particular religious convictions. It does require some trickery to get text windows to stay open if you're writing console-output-only code, but that's reasonably well documented.
Why would you want to compile to a complex and slow language? Why not compile to C?
Take a look at this code: [Log10](https://godbolt.org/g/3X3auT). See, there's a compilation error. The compiler doesn't know which function to use; you::log10 or hey::log10. The [cppreference page](http://en.cppreference.com/w/cpp/language/namespace) lists some examples.
note that on 64 bit systems unsigned int is not big enough to hold indexes for very large arrays.
&gt; About UB: programmers make mistakes, shits happens. Which is why sane stdlib implementations have debug assertions &amp;ndash; I've already covered this. &gt; &gt; Aggressive-aggressive: &gt; Awesome way to debate /s You passive-aggressively complained about it being passive-aggressive, so I made it less so. If you're unsatisfied, perhaps you were too passive-aggressive in your complaint and I misunderstood. &gt; Except tests won't 100% foolproof your program If both you and your stdlib maintainer fail to catch OOB violations on a standard container, then one or both of you are grossly overpaid. &gt; Yeah, if you're 100% sure, then no need to test, nor assert. I'm not advocating no protection; **always** assert, and if you're doing your job right then it will inform you when you need it and remain cost-free when you don't. &gt; Nope, some similar concept with gcc (with debug info or not). That's agreeing with me &amp;ndash; libstdc++ will happily notify you of OOB violations for `operator[]`... &gt; And then if your advice don't apply to one of the most used compiler, maybe you should mention it Can _you_ not compile with `GLIBCXX_DEBUG=1` and optimizations enabled at the same time? Because if you can't for some reason then maybe you should mention it. ;-] &gt; I meant: during prod, having an exception that can be caught instead of a `std::abort` or similar is way better. No, having a crash dump that gives you an exact image of the conditions wherein the error occurred is far better than some caught exception which at best gives you an unwound stack and a simple backtrace. _Uncontestedly_ better. &gt; cya Bye!
&gt;* Added header files to project tree, even if not listed explicitly in &gt; project files What's the rationale behind this change? 
Indeed, that's the goal.
&gt; Now, 4 years later, I'm beginning to understand it C++ is an incredibly rich language that is full of subtleties -- and it is always growing. Even after 20 years I cannot claim to be an expert. 
Ah, I always forget to check the sidebar when I visit a new subreddit. Thanks
That seems to be a pretty off-the-wall reaction to what the article claims: division by two can be faster with unsigned. For this to really matter you would need: * To be in a very narrow scope where you need to micro-optimize. * To have most of your operations be divisions by two or powers thereof. When those two things *actually* matter you're going to want to do more to document this than through use of unsigned types. Using the shift operator for example documents something very different from `x/i`. The `size_t` thing is a complete red herring. It's basically required to be unsigned most of the time due to the standard's constraints and how computer architectures work in general. It has to be something of the right size to hold any and all index type values.
&gt; for C++17 TSaster I am disappointed by this characterization. We moved three TSes into the C++17 standard: FileSystem, Library Fundamentals and Parallelism.
[removed]
First, even if it takes 60 cycles, that will still probably happen rarely and won't dominate your performance unless you are diving a huge array of 64 bit integers. Second, 32 bit integers are 9 or 10 cycles and not 60 like 64 bit integers. I would like to see an example program where this actually shows up on a profiler. My guess would be that someone worrying about nonsense like this would have a full 'OO' style program with inheritance, lots of heap allocation and lots of pointer chasing. 
Also: did you profile it yourself or do you just blindly believe it? Don't get me wrong, the article is great. But I generally don't like assuming the performance overhead of language features just because "you heard it somewhere". I hear it all the time: "virtual function calls should be avoided, they have overhead" sure they have... but did you measure it? Does it actually matter? 
C++ is faster than C for a lot of things. See `std::sort` vs `qsort`. Syntactic abstraction is costly in C, whereas in C++, not necessarily. People, in any languages​ will end up abstracting things away, like a storing algorithm. In C++, you have the power to do so without any runtime overhead. In C, runtime overhead occurs, and to remove it, you must rely on duplicating code or using macros.
If your language forces memory and binary size overhead, it won't be a better C++. It will be something that has a completely different goal, like being an easy to use OOP language. Sadly, I think there are already a loadfull of languages that has that very same goal, and achieving it quite well.
Gamification is exactly the reason that places like reddit and SO are massive man. The strict moderation is there to control the masses. It would be a wasteland if there was no moderation, and people wouldn't contribute if there was no point. 
I'm not the one posting a click-bait title without mentioning 2 of the most anticipated features of C++. 
If I wanted to use OOP, I'd use Java or C#. And there are few things that isn't nessessarly true in regards of "required" overhead. Reflection can be implemented without any runtime or size overhead. Reflection can be implemented at compile time, which transforms looping over members with instancing many time a block of code. For dependency injection, reflection isn't even required to implement it. I implemented myself a dependency injection library in C++ only named kangaru, and can work with only tiny amount of runtime overhead. By the way, C++ is a multi paradigms language. It means that functional programming is a thing in C++, generic programming is a thing too, and concept oriented programming is the next big thing. And of course, OOP is a thing too.
Usenet had plenty of participants, and the quality was better. The point for us was the language (or whatever other newsgroup you were watching)...not points. Debates were had about much--something SO shuts down immediately as "too chatty". If you can even find an ISP that gives NTP access anymore, it's pretty much a desert now.
&gt;constexpr lambdas &gt;Guaranteed copy elision &gt;Structured bindings &gt;constexpr if-statements &gt;Selection statements with initializers Nice!
The quality is great on reddit too, just not all the places. Things were different back then though, I'll grant you that.
Structured bindings, yaay! Anyone know about the status of them in gcc and clang so they can be used in a cross-platform project? &gt; the /permissive- compiler option This must be one of the worst named compiler options. Does it put the compiler into a more permissive mode? A permissive mode "minus" some things? Or is it a double-negation and it enables a non-permissive mode? Only the documentation knows... Anyway don't want to nitpick on this, great work otherwise and thank you very much for the blog post and both the Core as well as STL overview! :-) How come "&lt;filesystem&gt;" is still missing? (it says so in the bottom table). The link says "Microsoft/Dinkumware Began shipping the TS version with Visual C++ 2015"? Also it says "Parallel Algorithms" - missing, I thought at least some of them were already in there? :-)
Yeah, already had the rant when it got introduced [here](https://www.reddit.com/r/cpp/comments/5dh7j5/visual_c_introduces_permissive_for_conformance/da4l4tv/). Anyway, it'll probably be fine after a little getting used-to, and at this rate the VS going I'm hopeful that it'll be on-by-default for regular (non MFC/ATL etc.) cpp projects in the next major VS version.
I updated the post at 3:30 PM Pacific after receiving better information from the compiler team, specifically: "For Preview 2, the /permissive- compiler option will activate partial support for two-phase name lookup (partial meaning roughly 60% complete)." I previously thought that this wouldn't be available until VS 2017.3's final release. Currently, this is controlled by an **undocumented and unsupported** compiler option `/Zc:twoPhase` (because it activates incomplete codepaths). We've already verified with Clang that the STL is actually two-phase clean, and we recently activated C1XX `/Zc:twoPhase` test coverage, allowing us to find compiler bugs and prevent regressions. So far, I've encountered only three in the STL's tests, where the compiler didn't understand `Test&lt;int, int&gt;{}()` (fixed now), UDLs (also fixed now), and variable templates being used as defaults like `bool = is_integral_v&lt;T&gt;` (currently being investigated).
We shipped a Filesystem TS ("V3") implementation in VS 2015, which has received minor bugfixes throughout that lifecycle and VS 2017. However, we've found various implementation bugs and limitations (notably maxpath), and the interface has *significantly* churned as part of becoming Standard. As a result, we're planning to overhaul our Filesystem implementation in the next major binary-incompatible version of the libraries, since we can't really mess with the 2015/2017 msvcp140.dll's exports.
The seemingly arbitrary accumulation of deviations from traditional C and C++ reminds me a lot of [Holy C from the Temple OS guy](http://www.templeos.org/Wb/Doc/HolyC.html). You seem to really dislike bitwise operations. They got robbed of their idiomatic operators because this allegedly misuses math symbols but then you propose to use + and - for public and private?
It also inhibits a whole class of other compiler optimizations. Use size_t instead of unsigned int for representing array lengths/offsets.
Ooh I see. Looking forward very much to that then! :-) Thank you for the replies and great work guys in the past few years!
It's analogous to GCC's `-fpermissive` and `-fno-permissive`, but with two differences: 1. Where GCC names flags `-no-blah`, MSVC names them `/blah-` 2. MSVC's permissive mode is on-by-default (for now) and you have to turn it off explicitly. GCC's is off-by-default and you have to turn it on. _(edit: so, yeah, you got it right. Except I have no idea when it'll switch over to being default)_
In VS 2013 and earlier, we shipped Filesystem V2 as &lt;filesystem&gt;. In VS 2015/2017, Filesystem V2 is gone, and we're shipping the Filesystem TS (V3) as &lt;experimental/filesystem&gt;. We support &lt;filesystem&gt; as a synonym. (We also aliased `std::tr2::sys` to `std::experimental::filesystem::v1` but that was probably a bad idea, since V2 and V3 are almost completely interface-incompatible.)
Okay! Thank you for the clarification :-) (I think the MSDN page I linked is a bit misleading then.)
I'll continue to use doubles and doing `reinterpret_cast` on them, thank you very much.
&gt; The output is streamed to the CMake Output window – *CTest is not* ***yet*** *integrated with the Test Explorer.* If anyone from the MSVC team can answer, is there a concrete plan to make this happen? I'm really excited for this one. Last time I tested CTest it quite nicely handles the output of Catch (and I assume other unit test libraries out there) and so this is a pretty big thing as it will finally enable use of VS's Test Explorer without having to rely on MSVC's unit test library.
I've already explained why `export import M` is logical.
[Do your worst!](http://i.imgur.com/Fqu0WC4.png)
Great progress. Do you know if it is now possible to use Eric Neibler's range-v3 unmodified with Visual C++ 2017, or do we still need to use the version modified for Visual C++ 2015?
Optimizing integer division by known power of 2, doesn't strike me as a good reason to choose a modulo 2^n arithmetic type in general.
For me, it is simpler to just recommend never to use leading underscores unless you are an implementer. If I want some helper functions, I usually put them in namespace detail (like Boost does). For private member variables use a trailing underscore.
The +/- are only ideas. I don't know if I'll ever actually implement them. In fact, I'm not so keen on encapsulation, and experience shows that when you have code intended to be consumed by 3rd parties, your initial decisions regarding access modifiers are often wrong. As far as bitwise operations go, I think it's mainly FPGA developers that need them. As a result, I do believe bitwise operations need to be done well (specifically for FPGA, not for general-purpose programming), but for that, we need some other kind of paradigm that I'm working on. Essentially, the problem with bitwise operations is they are very difficult to reason about unless they are in graphical form. You'll notice that there are early seeds of VHDL support in Tlon, that's a hint as to one of the directions it's heading.
So? First rule of optimization: measure. When profiling shows that there is a performance bottleneck in a piece of code performing divisions by 2 on guaranteed non-negative integers, then (if that ever happens) it's no big deal to add a comment and replace the `/` with a call to an optimized version, like: // For x &gt;= 0 only. template&lt; class Int &gt; inline auto fast_half( Int const x ) -&gt; Int { return static_cast&lt;make_unsigned_t&lt;Int&gt;&gt;( x )/2; } Rare problem solved, at the cost of one round of running tests again. The solution of solving that rare case, that I have yet to experience as a problem, by adopting a modulo 2^n arithmetic type in general, can, on the other hand, be really expensive.
Currently (as in, I've seen indications that this may change in the future), a module can only have one *module interface unit*. So if you want to have your classes both defined and implemented in a single place then all of them will have to be in the module interface unit. This can probably work for simple, one-two class modules but will becomes unmaintainable for any sizable module. Also there is this concern: currently we often use headers as the specification of a class. Some (including myself) even factor inline functions into a separate file in order to keep the interface as readable as possible. Finally, any real project will most likely have to support both modules and headers for a very, very long time.
Awesome, thanks.
The feature tables explain what VS 2015 and 2017 contain. &lt;string_view&gt; was added in VS 2017. Additionally, `/std:c++17` is required to activate C++17 features that aren't marked with "[14]" (indicating unconditional support, even in the default C++14 mode). Please, please upgrade to VS 2017. It is so much better, we've fixed so much stuff in addition to adding features.
If only it supported a target view instead of a directory view. My source directories for each target are flat (because #include), and I use source_group to organize them with virtual folders. However, with a folder view I just get a giant list of source files in my solution explorer, which is just unworkable. Next to that I have code that gets generated into the build directory, far away from the rest of the source code. Good luck finding those back in the folder view. I'm not even sure how it deals with multiple targets in the same directory, imported targets like ExternalProject, and other stuff that simply does not relate to the directory structure. I thought the CMake server provided a list of all the targets and their sources, so I still find it very odd that this wasn't used. The whole thing feels like it was designed by someone who hasn't used C++/CMake with Visual Studio before. So I'm sticking to the good old Visual Studio generator for now, and I can only hope that they will eventually try to match it more closely.
So how will this work? Let's say I have a (sizeable) library that I want to turn into a module for other applications to consume. As you say, I need a single file to define the module interface. Do I put all my classes ("things that go into the module interface", I mean) into that one file? Do I write a bunch of header files and just include them there? Do I create a bunch of 'submodules' and import export (snigger) them? It may be a bit early to ask for best practices, but it certainly isn't too early to think about it ;-) Basically I'm trying to get a feel for the 'vision' of how this is going to look like. 
Yeah, I've been thinking about it a bit and planning to write something up soon'ish. Here are some raw thoughts: If you have an existing library, the most realistic scenario is that you will have three types of users: 1. Those that want to continue to include headers. 2. Those that want to use modules when available and fall back to headers when not. 3. Those that want only modules. In this case you would want to continue to have headers to support the first crowd. And the third bunch is each -- they will just use `import` and build system magic will sort them out. This leaves us with tricky #2. My current thinking is that you should make them include (as in, `#include`) the module interface unit which behaves like an `import` if modules are available and as a header otherwise. In other words: 1. `#include &lt;libhello/hello.hxx&gt;` 2. `#include &lt;libhello/hello.mxx&gt;` 3. `import hello;` On the implementation side, the module interface unit (`hello.mxx`) sets things up (e.g., for exporting) and includes the headers (`hello.hxx`). If you want to see what it all looks like, here is a [test project](http://codesynthesis.com/~boris/tmp/libhello-1.tar.gz) (works with Clang 5/trunk). 
For the record, I'm in the third group. I want to speed up compiles of my own source code. I'm fully in control of what gets written and how, but I am constrained by having to compile on Windows (Visual Studio) and Linux (currently gcc, but could be clang as well I suppose). One thing I have at least considered, but not tried in anger, is to have my own little 'windows.h' module - basically import export (hehehe) only those symbols I need myself, jury-rig anything that only comes in macro form, and see if that speeds up compilation. I had a quick go at this but didn't quite manage to get it working yet - my own fault, I'm sure. 
There are distributed build plugins for VS like incredibuild so it seems distributed builds are already possible.
Circular dependencies between modules would need to be allowed for this to work. From what I've seen, the clang implementation doesn't allow them. Btw, it's also a feature that I look most forward to in C++, I hope it comes some day.
&gt; Most compilers seem to generate about 4 to 5 instructions. Ok, let's see what happens there: int f(int x) { return x / 2; } $ g++ -O2 -S -masm=intel -o - main.cpp _Z1fi: mov eax, edi shr eax, 31 add eax, edi sar eax ret Actually it's only 3 instructions: shr/add/sar Can we fix it? Of course we can! int f(int x) { if (x &lt; 0) __builtin_unreachable(); return x / 2; } $ g++ -O2 -S -masm=intel -o - main.cpp _Z1fi: mov eax, edi sar eax ret TL;DR: ints are OK as long as compiler knows that they're non-negative.
Well, I'm FreeBSD ports maintainer for 10+ years, which means I've had experience with a lot of build systems in not-quite-common (software is usually tested on and tuned for Linux, while FreeBSD has some differences) and quite strict (build is required to respect system compiler, flags and paths) environment. Summarizing my experience: - autotools are tolerable. While they are abomination from architectural standpoint and are really hard to debug, they generally work and are patchable easily enough. - cmake is a revelation. It has clean and compact declarative syntax, and it works out of box, from finding depends to testing. - scons is just not usable. I can't even call it a build system, it's more of a python framework for writing build systems, and each user actually does write her own build system. Each SConscript has its own way of handling build options and flags (from scons args or from environment; parsed manually; problems with spaces in e.g. cflags), dependency detection is written from scratch (hardcoded paths; pkgconfig output parsing; lack of detection, e.g. libraries are just listed verbatim, while FreeBSD also requires -L flags) and this is usually written in horrible imperative way, with a lot of python native code (string parsing, filesystem stuff, sometimes system calls()) Here's a nice example: https://github.com/simtr/The-Powder-Toy/blob/master/SConscript Porting each SCons-using project is a pain, and I haven't seen a project which didn't require SConscript patching, and patches are sometimes comparable in size to SConscripts themselves. While SCons is probably first to blame for not providing the essential build system functionality people have to reimplement, I also tend to blame python a lot, as it makes it too tempting to just write custom routine for some task instead of reading build system docs and using builtin functionality.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [simtr/The-Powder-Toy/.../**SConscript** (master → 9bc19d9)](https://github.com/simtr/The-Powder-Toy/blob/9bc19d9933cddd99d3dee56cee2a84640531a21d/SConscript) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dheyxyk.)^.
Good luck and do share your experience!
I think what makes "universal forward declarations" especially hard is that you would need to figure out a way for the compiler to match the forward-declared types with the later encountered definitions. And of course, the name matching is not enough. Consider this: forward Foo::Bar; Is this `class Bar`˙in `namespace Foo`? Or in `class Foo`? Or something else? Sure, one can argue that the Standard should define a prioritized list of options to try and the first one matching should be considered true, but that gets out of hand easily and we would have "most vexing parse 2", which nobody wants. 
Why do you want forward declarations? I think that the only reason to have them is to have self referring pointer structures, like trees and lists. There is also a problem if you want to define friends of template classes, then may you may need a forward definition. std::string is not a regular class, it is an abbreviation of std::basic_string&lt;char&gt; . 
I do not understand what you are trying, and how it fails. std::string is defined with a typedef. On my system, a forward declaration cannot be replaced by using or by typedef. Only by a full struct declaration. 
My quine uses `c++11`, maybe that's your issue? It compiles just fine for me with gcc 5.4 and clang 3.8. Here's [ideone output for proof](https://ideone.com/JfAhvV) - although for some reason ideone trims the output's first empty line (which is present in the source file).
std::function is overhead on top of overhead (virtual dispatch on top of heap allocation)
Ideally, you will not need header files. The question of whether you have a better code structure by putting everything in a single source file is open to debate among architects. There is a technical constraint you should keep in mind: cyclic dependencies between module interfaces are not allowed. In my own coding, there are cases where I put an entire module definition in a single file (usually, these are "foundational" modules). And there many times (the majority I think), where I put implementations of modules in several files. Note also that if you put the definitions of your member functions in their class definitions, they will be assumed to be inline. How much attention the backend of your compiler pays to that varies. That may or may not be what you wanted.
Why should one us ninja?
&gt; I was thinking more along the lines of exporting specific symbols only I believe that is the right direction. &gt; Windows.h is huge, but the number of symbols I actually use is probably less than 200 My recommendation for consuming a highly non-modular header file like `windows.h` is to continue to `#include` it before you declare your module. Then consume only the symbols you want from such a header. The compiler will retain just what it needs. Modularization is primarily about architecture decomposition, and this goes all the way to the runtime. If you're talking about `windows.h`, it is not sufficient to just be able to say something like `import Microsoft.Windows;`, you also want to know what that entails in terms of runtime and dependencies. It is a deep and complex problem; the architects have looked at it and concluded that if you are considering consuming modularized windows.h then you might want to start migrating away from `windows.h`, towards [API Sets](https://msdn.microsoft.com/en-us/library/windows/desktop/dn764993.aspx) as a good first step. /u/berium and I are having an offline discussion about his hello example. 
I went a step further... OMG [look at this](https://gist.github.com/rafalcieslak/bb4176efeb5128ef87a64aaf255eba3c)!
This is impossible to read.
Omg that is genius You are a quine god
Stopwatch?
This tool above uses the Ninja log to generate its output. And in general, Ninja is much faster than alternatives like make, msbuild or xcodebuild. As a bonus, it parallelizes your build by default forcing you to have proper dependencies (that's a VERY good thing). And it will show you the command line that fails automatically too, unlike with the make generator, you will have no idea of what was run and failed (unless you use VERBOSE=1 on the command line). That's a very good thing for CI.
Yeah but you don't have to use it. I think it's unreasonable to suggest that std::function shouldn't be supported for the reason you give.
Depends on what is slowing things down. On Windows, I've used XPerf and had it hook process creation and destruction, as well as sample CPU usage. The xperf viewer could then generate a stacked bar graph of per-process cpu usage over time that told quite a story. My build process had quite a bit of time where the cpu wasn't being used effectively due to serialized steps and excess shell process creation. I believe perf on Linux can gather the same information, but I don't know if there is a similar visualization. Even if it turns out that you are getting good build parallelism, and 95% of your time is spent doing compiles and links, you may be able to spot particularly expensive files and do something about them.
I didn't want to update because I was having issues with both the installer and the IDE where I get an error at every stage. Plus, some tools I use (e.g. clang-format) weren't available last I checked. Maybe in the future. Thanks :)
For fun, I decided to switch to plain C, which allows for some extra code-golfing. Here's my 64 byte version: `main(c){printf(c="main(c){printf(c=%c%s%c,34,c,34);}",34,c,34);}` I don't suppose I'll ever get it shorter than this.
And yet... the introductory example uses exceptions? 
No, please don't do in-source builds! Also I wouldn't call the build folder "binary folder". It's actually more of a temporary folder with various fluid build artefacts. What I would call "binary folder" is the installation folder ("install" target in CMake). This tutorial has some nice pieces in it but other stuff really shouldn't be done like that, see e.g. above. And you should not teach to use this old-style cmake that your example code on GitHub is using. You should teach the target-based approach and many more new modern CMake features that replaced old code.
That's interesting, but it doesn't immediately make sense to me. 1. Why were there so many divisions 2. Were the divisions on 64 bit integers and did they need to be? 3. How did you optimize them?
This site's design is so bad... Unreadable.
The naming convention that the whole standard library and language uses just wasn't good enough? Is there a compelling reason to use your library over [this](https://github.com/ptal/expected) or [this](https://ned14.github.io/boost.outcome/index.html)?
Shit, you're lucky compared to C99/C11 support.
&gt; Anyone know about the status of them in gcc and clang so they can be used in a cross-platform project? GCC and Clang are miles ahead of MSVC for C++17 support; http://en.cppreference.com/w/cpp/compiler_support
Why not use expected&lt;T, E&gt; as that's the standards proposed C++ either monad?
I really wish you'd invite Jon Kalb to keynote personally :)
Not true... my point is that the actual instruction runs in the same number of cycles. Both are implemented using the same Barrel Shifter structure in logic. I'm a hardware designer and have worked on CPU. If the compiler decided to insert new instructions in the signed/unsigned case, that's a different story. 
Alas, chances are that people will just have their include files do module imports under the bonnet if modules are available, else fall back onto textual include. https://stackoverflow.com/questions/34652029/how-should-i-write-my-c-to-be-prepared-for-c-modules/38227761#38227761 has far too high a rating for my answer :(
It's actually still pretty readable Congrats! Now to see if i get ideas on how to shorten mine while still making beautiful code
&gt; No, please don't do in-source builds! What are the downsides?
Makeheaders does this. Been around for ages. Still not quite ideal.
Sure that's a fine argument but suggesting that supporting std::function adds overhead is wrong unless you're saying the only way it can be supported is to *only* support std::function, which nobody was talking about.
Qt Creator 3.5.1 was released on October 15th, 2015. That's a *bit* dated and weird to talk about it in May 2017. The workflow has changed in Qt Creator 4.0, you can edit the existing CMake variables, like you do with `cmake-gui`. Qt Creator 4.3 will be released soon, version wich has support for [cmake-server](https://cmake.org/cmake/help/v3.7/manual/cmake-server.7.html).
Very interesting! I was looking for something like buildbloat - will try it on our codebase asap :-) A side note (though it does not answer the question): Don't forget about ccache and icecc. Also: http://www.bitsnbites.eu/faster-c-builds/
Well, this isn't about Keynote speakers. But I agree that Jon could be a good candidate. But there are so many good candidates, and only a few keynotes every year.
Sounds to me like it validates the idea though, even if it isn't completely original. 
Just installed the preview, and intellisense is giving me [these errors](http://i.imgur.com/SyOmbqx.png), even though it compiles just fine. is there any way to fix this?
That would be gcc-7 and clang-4. I wouldn't call that "miles ahead" - but definitely a bit ;)
Mostly it was shouting "I WILL BURN THE WORLD TO GET `if constexpr`, MARK MY WORDS" whenever passing a compiler dev in the hallways.
Don't know how that compiled, it shouldn't have (unless a macro was hiding a semicolon).
2017's installer was totally rewritten and doesn't suck anymore (now that we're past RTM).
&gt; No, please don't do in-source builds! Agreed, it's important to separate the source from the (maybe multiple) project and build directories. &gt; Also I wouldn't call the build folder "binary folder". Unfortunately it's the official CMake name for the generated directory.... Which at first confused me a lot, I remember. &gt; It's actually more of a temporary folder with various fluid build artefacts. What I would call "binary folder" is the installation folder ("install" target in CMake). Wait aren't you mixing the install and binary folders? 
Recycling some bits: https://www.reddit.com/r/cpp/comments/66no4v/question_about_c_version_on_nintendo_switch/dgoxaho/ Excerpted from that response: &gt;&gt; As for C vs. C++, MSVC is intended to work for both. We had a huge conformance gap with both languages and we chose to fix our C++ conformance issues first. Frankly, the number of C++ developers using MSVC dwarfs the number of C developers. Also, the C Standards have been a bit, um, interesting as of late. &gt;&gt;We have done C99 conformance work, most notably C99 _Bool, compound literals, C99 designated initializers, and variable declaration a couple of years back. Implementing a conforming preprocessor is a huge benefit for both C++ and C conformance. We hope to start that work any day now. After we tackle C++ conformance we'll turn our attention to C conformance. We are excited to (finally!) have some two-phase support. This is the end result of a long process to replace our old token-stream based parser with something new and shiny: more details in this [blog post about rejuvenating the MSVC compiler](https://aka.ms/CompilerRejuvenation). While the switch is currently undocumented and unsupported, two-phase will be complete and working Real Soon Now^(TM). 
So to draw all this together, in a future version of MSVC we will have a `/permissive` switch that allows MSVC-specific nonconforming behaviors. We named the switch `permissive-` for now because we wanted to prepare for the future. Thanks for the reddit link, /u/flashmozzg! Here's the [blog post about the /permissive- conformance switch](https://blogs.msdn.microsoft.com/vcblog/2016/11/16/permissive-switch/).
/u/STL is passionate, as we like to say around here. Sometimes his passion is exhibited through burning large swaths of land as he walks by. He's not just a library, he's a force of nature. 
I think it's mostly because it pollutes your source directory unnecessarily. Out of source builds are cleaner. What I really like about out-of-source builds is having separate build folders for different configurations. For example, you can have a build folder for a debug configuration, release configuration, with clang instead of gcc, one with a cross compiler, using built-from-source dependencies instead of system dependencies, etc. all coexisting without the need for environment variable fudging. mkdir build_debug pushd build_debug cmake -DCMAKE_BUILD_TYPE=DEBUG .. make popd mkdir build_release pushd build_release cmake -DCMAKE_BUILD_TYPE=Release .. make popd mkdir build_clang pushd build_clang cmake -DCMAKE_CXX_COMPILER=clang .. make popd git clone https://github.com/jbeder/yaml-cpp.git ../yaml-cpp pushd ../yaml-cpp mkdir build pushd build cmake -DCMAKE_INSTALL_PREFIX="$(readlink -f dev_install)" -DBUILD_SHARED_LIBS=ON .. make install popd popd mkdir build_source_deps pushd build_source_deps cmake -DCMAKE_PREFIX_PATH="$(readlink -f ../../yaml-cpp/build/dev_install)" .. make popd Then you can just go into each build folder and run `make`.
Can we use template variables with a defaulted template parameter as a stop-gap for the unsupported inline variables?
Why would I build Buck if I already got it, assuming I'm not working on it?
Explicitly: https://github.com/CaseyCarter/range-v3
ImGUI is awesome. Only the column system sucks right now. They want to completely change it though. Got no experience with Cinder.
Recycling bits: https://www.reddit.com/r/cpp/comments/65k7yj/what_is_the_point_of_concept_and_module_ts_when/dgcja12/
Cool, I actually had not looked at the article, was just responding to that particular comment. Skimming the article now I'm not sure why /u/sumo952 thinks you're doing an in-source build. You clearly state in the article: &gt; **A common practice is to create a subdirectory build beneath CMakeLists.txt.** &gt; &gt; **By keeping the binary folder separate from the source, you can delete the binary folder at any time to get back to a clean slate. You can even create several binary folders, side-by-side, that use different build systems or configuration options.** &gt; &gt; The cache is an important concept. It’s a single text file in the binary folder named CMakeCache.txt. This is where cache variables are stored. Cache variables include user-configurable options defined by the project such as CMakeDemo’s DEMO_ENABLE_MULTISAMPLE option (explained later), and precomputed information to help speed up CMake runs. (You can, and will, re-run CMake several times on the same binary folder.) &gt; &gt; You aren’t meant to submit the generated build pipeline to source control, as it usually contains paths that are hardcoded to the local filesystem. Instead, simply re-run CMake each time you clone the project to a new folder. I usually add the rule *build*/ to my .gitignore files.
It was fine until to get access you have to pay 10€
Modules are more than just for speed. They make heavily templated code easier to write (particularly useful with Concepts).
Typedefs like `std::string` are also an issue. Consider this hypothetical translation unit: forward std::string; void g(const std::string&amp;); void f(const std::string&amp; s) { g(s); } How does the compiler know how to mangle `f` and `g`? After all, `std::string` is really `std::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt;&gt;`. I could forward declare the latter, but now I have to be aware of implementation details (and I *think* that standard libraries are allowed to introduce more template parameters as long as they have defaults, but I could be wrong).
Hey, I just read through that linked thread, and I noticed you said you guys are planning on implementing C99 and C11 when you're done with C++, any idea on a timeline for _Generic and &lt;threads.h&gt; features from C11? I only ask because I write a few cross platform C libraries, primarily on my Mac with Xcode, but lately I've been going through it in VS (2017 community, if it matters) and trying to fix it up over there as well.
it sucks when you want to build multiple configurations
Okay agreed I guess it's not a full in-source build so not as bad, but still not too good. It's "in source" in the literal sense that it's inside the source directory. You say by yourself "The binary folder was a subdirectory of the source folder.", which is the definition of "in source". But it's not too bad since it's in a *separate* build folder inside the source directory so it can easily be deleted. Still, IMHO, build belongs completely *outside* (e.g. parallel to) the source directory.
&gt; For one, you now have two definitions of Class1, which isn't technically legal. I believe the standard doesn't say that these symbols should be linked together, so extra support from compilers would be needed. &gt; This is going to result in no inlining optimizations The generator can output the function body into the header if it finds the 'inline' keyword, so that shouldn't be a problem. &gt; you've got the modules TS It doesn't look like the modules TS will support many of the features that I mentioned, like not transferring dependencies, removing private members from the interface, etc.
very interesting article and I appreciate the real world example which is hard to come by. I'm still beginning with tmp. Could this be done with hana or would it even make sense to use hana here? Thanks in advance.
You are right, name mangling is probably the main reason why you can't forward declare a typedef or a type alias. What a shame.
Note that as /u/GabrielDosReis says, modularizing `windows.h` is a huge problem with unnecessary complexity. `windows.h` has been cluttered and out-of-date almost since it was introduced. Don't believe me? See [Raymond Chen's post about `WIN32_LEAN_AND_MEAN`](https://blogs.msdn.microsoft.com/oldnewthing/20091130-00/?p=15863/). So far the Windows team has been working on modularizing discreet components in a large codebase. This is similar in spirit to the API Sets mentioned above. Those were an effort to provide a better-factorization of the Windows includes such that developers didn't have to link in all of Windows. This means that Microsoft isn't planning to modularize `windows.h` anytime soon. Maybe one day, but there are far more appropriate targets for our efforts. 
But then I have random build directories polluting my projects folder. Build go in a subdirectory. 
The author's other "articles" include '*Learn and master GraphQL by building real web apps with React and Node*' and '*Learn C# using Unity 4.6 &amp; Unity 5. Your first 7 2D &amp; 3D games for web &amp; mobile*' &amp;mdash; obvious spam is obvious. Where's medium.com's option to flag/report articles? Are they all actually curated? Sad if so.
With most `expected` monads (see `Result` in Rust and `Maybe` in Haskell), the first type parameter is conventionally the "success" parameter.
&gt; Try reading the thread you're participating in. I believe mr-agdgdgwngo has read it. Supporting "std::function explicitly" is a totally different proposition from "...only support std::function"
Is there a portable way to do it?
It's amazing how much "*but it's the default one that comes with my distro*" holds C++ back.
And also from "_just_ std::function explicitly", which is what was actually said. ;-]
Yes, and especially people who think C++ development is hard and all IDEs suck! Sure if they all use UI's from 2012... People are always amazed when I show them debugging my code in VS. (and stuff like Edit &amp; continue, ...). And then they go back to their own PC and open gedit and complain about C++ again ;)
This is good feedback, thanks. We are planning to provide a target view in addition to the directory based view that exists today. This feature has a fairly high priority on our backlog. You should be able to build and debug multiple targets in the same directory through the CMake menu, debug drop down, or by right clicking on the relevant CMakeLists.txt files. Though if their source code is outside of the root directory you will not be able to view it until we implement the target view.
They gave me the feature so I called off the world-burning.
There is. Our plan is for CTest to have first class support in the IDE with full integration with the Test Explorer. Though I cannot comment on exactly when we may be shipping this functionality.
&gt; Forward declaring classes and structs have different syntax. How so?
 if("${PROJECT_SOURCE_DIR}" STREQUAL "${PROJECT_BINARY_DIR}") message(FATAL_ERROR "In-tree builds are not supported; please run cmake from a separate build directory.") endif() To force this.
&gt; constexpr operator bool()const { return !isLeft; } I don't so much mind the concept of `Either` but this operator suggests it's really just `expected&lt;T,E&gt;` by another (misleading) name.
It doesn't affect anything if you don't track the files. They aren't part of the repository anyway. Even Visual Studio does this with its project manager.
`Maybe` takes one type parameter, C++'s equivalent is `optional`. I was pointing out that `expected` is not a meaningful name for an `Either` monad, which is either a `T` or `E`. &gt; the first type parameter is conventionally the "success" parameter. So 1) `Either` isn't just used for errors, it's for anything that could be two things, for example an iterative computation that is either in progress or finished. and 2) in haskell the second parameter is the one that doesn't terminate a computation (so success, if you're using it for error handling).
I also add if ( EXISTS ${CMAKE_BINARY_DIR}/CMakeLists.txt ) message( FATAL_ERROR "In-source builds not allowed (found CMakeLists.txt). Please make a new directory (called a build directory) and run CMake from there. You may need to remove CMakeCache.txt and CMakeFiles" ) endif() Your one stops in-source builds from the root directory. This one prevents accidentally running cmake if you are in a sub-folder (sub-project) of source tree.
I started using CMake about 7 years ago when I was put on a C++ team. I had never used it before and found that the documentation on it was lacking horribly... at least back then. I agree with some of the criticisms mentioned in this thread but overall I wish I had had something like this when I was put on my team and told "CMake it!"
From working a little bit on an unwinder implementation, and dealing with performance problems there, I find Niall's numbers plausible. I don't think he said that the performance is exponential though. I think he claimed that it was linear in call stack depth, with the implication of a high constant 'm' on that mx+b. I believe that the performance is a bit worse than linear to be honest, at least for the Itanium ABI (i.e. most everything that isn't Microsoft). It's more like count(frames between thrower and catcher) * log(exception propagation sites). When an exception is thrown in the "zero overhead" model, the implementation does a binary search on a table to figure out what actions are needed for the current code location. One of those actions may be an RTTI comparison. Frequently, the actions will end up adjusting the code location (to another frame, a catch block, a destructor), where the process can then begin again. This keeps happening, one frame (or less) at a time, until you get to the last catch block and wrap things up. All the code that is doing this matching and searching throw tables takes time. With return codes, you get lots of instances of an extra dozen or so instructions. With exceptions, if you throw, you get to go through a lot of libraries and data structures.
&gt; Also, Windows.h defines obscure macros like near / far / min / max As well as every function name that has an ascii and unicode overload. A good reason to start member function names with a lower case letter, avoids running into that issue. min/max can also be disabled with #define NOMINMAX .
Thanks, I'll make sure to add a few suggestions to that uservoice page :)
GetObject() used to be my bane.
Yes but all that work is done *only* if there's an exception. OTOH, the overhead of return codes are *always* there. Plus the problems of forgetting to check the return codes, etc.
You can't have tried very hard, I said the path in the video. Source code for the benchmark: https://github.com/ned14/boost.outcome/tree/master/benchmark Now, I need to make it clear that I and others *suspect* that it's RTTI lookup which is causing the linear scaling of exception throw and catch cost to stack frames unwound. But in truth nobody knows, I have no idea, and I didn't investigate. Regarding exceptions being slow, Bjarne and/or Herb was referring to the non-throwing case. And they are correct. But throw and catch on table based EH implementations is very slow, and is getting slower as main memory becomes ever slower than CPUs. Anyway please knock yourself out with my benchmark, it is extremely simple and very flawed, but I'd love to know the cause of throw...catch being slow as much as anyone. I look forward to a definitive answer posted on /r/cpp with evidence!
I believe what Stroustrup/Sutter said is that *old* compilers were very bad at exception handling, and so exception handling got the bad reputation. Also do you know https://godbolt.org/ ? Put some code there and check the generated assembly. It's a wonderful tool to see how compilers deal with each choice. I've already dispelled many C vs C++ myths with it.
I agree with all of the above. My test was deliberately unrealistically simple. In any real world code base, it will likely scale worse than linear for all the reasons you just said. I was still surprised at that linearity though. Sure, it's scanning a table per frame, but there is surely a ton of scope for doing better than that at the cost of additional code bloat somehow. Still, exception throw and catch is not historically an area to be optimised, though I do note that MSVC is twice the performance of anyone else because they precompute metadata at compile or link time so the TEH unwind doesn't have clever. Nice to be able to control one's ABI of course ...
I'm still not sure what Microsoft was thinking here...
It's possible that `[[assert axiom: x &gt;= 0]];` (or `expects` here if you consider it more of a precondition) will have this behaviour with Contracts. I know there's been discussion about whether the compiler should be able to optimize code based on that, but I can't remember if something was decided on.
Firstly, out of order execution CPUs are very good at giving you free of runtime cost return codes because they can fold the check of an integer to be zero into spare execution ports most of the time. Secondly, the overhead of return codes is usually fixed and therefore predictable. In low latency programming, you want predictable costs, not minimum costs. C++ exception throw costs are hideously unpredictable, hence most games and finance folk turn them off, just to get the guarantee you'll never pay that cost. Expected, Outcome et al make it *much more convenient and safe* to use error codes than before. Yes, the overhead is always there in the same way as pre-table EH always generated a constant overhead whether you used them or not. But sometimes the programmer really would greatly prefer constant overhead than unpredictable overhead. And furthermore, if failure is at all not uncommon, return codes really shine performance wise.
Thanks Gaby. :)
:(
You're talking about [a file that has been shipping since Windows was 16 bit](https://blogs.msdn.microsoft.com/oldnewthing/20091130-00/?p=15863/). What Microsoft was thinking has always been "let's not break compatibility." It's a bit unfair to look at a 22 year-old design decision and question what the developers were thinking. Microsoft has been trying to improve things with, for example, [API Sets](https://msdn.microsoft.com/en-us/library/windows/desktop/dn764993.aspx). (Explained more in detail [here](http://www.geoffchappell.com/studies/windows/win32/apisetschema/index.htm).)
I use exceptions, what are some alternatives? Obviously if something happens in a library I want the user to be able to respond to it. std::optional?
Speaking of &lt;threads.h&gt;, when will glibc provide it? C threads are largely absent (see https://sourceware.org/bugzilla/show_bug.cgi?id=14092) The expectation of MSVC supporting it while no one else does seems a bit -- odd.
Also, success might not be expected. 
&gt; C++ exception throw costs are hideously unpredictable, hence most games and finance folk turn them off, just to get the guarantee you'll never pay that cost. If you're concerned about the performance of the throwing case that's a pretty solid indicator that the thing wasn't actually exceptional. I'd go ahead and posit that the avoidance of exceptions in most areas of the C++ world is due to cargo cult thinking rather than anything rational.
&gt; If you're concerned about the performance of the throwing case that's a pretty solid indicator that the thing wasn't actually exceptional. Exceptions needn't be rare to be exceptional. Stroustrup: &gt; Given that there is nothing particularly exceptional about a part of a program being unable to perform its given task, the word “exception” may be considered a bit misleading. Can an event that happens most times a program is run be considered exceptional? Can an event that is planned for and handled be considered an error? The answer to both questions is “yes.” “Exceptional” does not mean “almost never happens” or “disastrous.” Think of an exception as meaning “some part of the system couldn’t do what it was asked to do”.
The best universal advice is "write idiomatic code &amp; optimize when benchmarks reveal problems". This means use exceptions where they make sense &amp; only optimize exceptions when they are in your hotpath. For me, a good rule of thumb on when to use exceptions is whether or not the caller of the function is reasonably expected to be able to deal with an error. For example, if you have a failure to do something deep in the internals of your code in response to a user-initiated action, exceptions work great to transport the error across logical layers with all the information needed to display the user with a meaningful error message. Similarly, if you have an error on a thread that you know is handled on another, throwing exceptions works well here too (you catch at a very high-level &amp; propogate). Boost exceptions make this even better because you can gather up any relevant information for the exception as you traverse the stack, which means you don't need to propogate this stuff down the stack as with regular exceptions or up the stack as with return codes (i.e. your code interfaces don't bloat with a bunch of extra arguments just because you want rich details about the context of the exception). It's also a good rule of thumb to throw an exception when you want to make sure the program terminates if you forget to handle it (i.e. you're violating some critical invariant &amp; it wouldn't be correct to continue running). That way you know you won't accidentally corrupt user data/send wrong stuff over network/etc &amp; you have a nice way to add error recovery for entire categories of errors.
So he was responsible for the wildfires in Washington State 2 years ago....
I would say that it's probably worth looking into sccache now: https://github.com/mozilla/sccache A ccache from Mozilla with S3 support for shared cache between builders. Depending how big your infra is, it might be worth it!
Coworker: Why is my method called GetCurrentTick() causing a link error for a method called GetTickCount()? Me: *sigh*
Sure, fair points. I imagine there are a myriad of reasons we'll never know. But if I had to guess, I'd say two things. First, software was just smaller back then, all the way from applications to operating systems. The idea that you'd have one header to include in everything that got everything you need made more sense back then. Second, software was less mature back then, and thus less componentized. What we attribute to parts of an OS today we used to attribute to the OS itself. Everyone remembers when the web browser was "just" part of the OS. But can you imagine a world where DOS allowed you to swap out the file system, the thread pool, or the memory manager? All of these are separable and configurable (with the proper magic) today. But back when you just got what came with the system. One header to rule them all seems like it might have made more sense in those days. 
I hadn't considered that second point before. That'd definitely be a decent enough reason to not split them into multiple headers.
&gt; Exceptions needn't be rare to be exceptional. I wasn't saying that exceptions needed to be **rare**, I was saying that in most cases **exceptional** things are irrelevant to the performance of whatever code you're writing. I work in finance and several times per week I'll be discussing a list of options with a co-worker and we'll come to the conclusion that the performance actually isn't relevant, it's whatever makes the code the cleanest and the easiest to understand. Why? Because for what we're doing the hot path is dead simple and rarely fails. It's super fast and we carefully keep it super fast. But that's not the bulk of the code. The bulk of the code supports that super fast and hot path. Things like loading configuration or setting up the environment for the hot path to run in. Is it **rare** for the configuration file to be missing? No, but it's exceptional, and the performance in some sense is irrelevant because the user isn't going to notice and complain that it takes 1ms for the application to fail to start rather than 1μs. Which ties into what /u/vlovich [was saying](https://www.reddit.com/r/cpp/comments/6an103/exceptions_performance_again/dhg6rmn/): Write good code and mostly that'll be fast enough. When necessary write fast code. If you do this you'll free up developer time and energy to write and maintain fast code, rather than spreading developer time creating maintenance nightmares in fast code everywhere such that you don't actually have time to properly care for the performance critical parts of your project.
Gotcha. I misunderstood. Yes, I agree, if you're concerned about the performance of the throwing case, *that's a premature optimization*. 
One ring to rule them all!
`WIN32_LEAN_AND_MEAN` is effectively needed for Winsocks 2, as I recall. So, always define this. As well as `NOMINMAX` and (the default now) `STRICT`. And `UNICODE`. That's about it. Wrap that in a header of your own and don't, don't ever, try to include *parts* of `&lt;windows.h&gt;` without including the whole shebang.
You can combine the exception and return code ideas, for the case of "no result", by returning an optional such as `boost::optional` (to be part of C++17, as I recall). Then there is an ordinary return. But if the caller mistakenly tries to access a non-existing result, *then* there is an exception. As far as I know this idea was first discussed and promoted by Barton and Nackman in their "Scientific and engineering C++" book, where the class was called `Fallible`. For some (OK, now pretty old) authoritative discussion of exception performance, see section §5.4 Exception Handling in the standardization committee's [Technical Report on C++ Performance](http://www.open-std.org/jtc1/sc22/wg21/docs/TR18015.pdf), from 2005.
Thanks. What is the difference between the link above and the previous repo at https://github.com/microsoft/Range-V3-VS2015? Also, do you have an idea of what needs to be added to the compiler and when we can expect that?
Musl and PDClib support it, but yeah a lot of libraries are shunning it instead of writing a simple wrapper around posix, like I can understand not trying to add support outright, but not even a wrapper? that's just lazy.
You should have an actual condition as well. Condition variables are commonly used for producer/consumer relationships. One thread for example puts something in a vector and then notifies the other. The other thread should check if there is something in the vector for it to consume and only wait if there isn't.
Sure, just added MIT as dual-license to the repository. 
Well clang spits out a warning with -Wall, so I assumed it's not allowed. But good to know. &gt; warning: 'A' defined as a class here but previously declared as a struct [-Wmismatched-tags]
Precompiled headers are nothing but an optimization: instead of including text, you include the AST. But you include the same stuff. From what I've seen in clang's modules, the same thing happens. No dependencies are reduced. Take a look at my example above, how you don't depend on Class2 when "importing" Class1.
1. Because the core algorithm of what to_string does depends on divisions. And since they are divisions by 10, they aren't one of the values that can be handled "nicely". 2. Yes; a big part of the improvement was factoring things out to do blocks of 32 bit chunks, so that 32 bit divides were used instead of 64 bit divides. See &lt;string&gt; :) 3. ^^
&gt; If you include Windows.h in all of your compilation unit, which is very often the case, compile times skyrocket. That's what a PCH is for.
&gt; They make heavily templated code easier to write IDK that. Link with example? 
Probably still a good idea to initialize it explicitly.
Let's talk about: `class LibraryLoader { int LoadLibrary(...); };`
When writing a new project, I'd like to have all legacy cruft turned off, and I'd like to be able to use any standards-compliant compiler to do Windows development. As things stand currently, any non-Microsoft computer targeting Windows has to jump through massive hoops, spend untold amount of development hours either making their own modifications to windows headers (the headers do not comply with the C nor C++ standards), or adding hacks to their compiler so that the MS versions of headers can be used. People often say "MSVC++ works so naturally with Windows, why would you use any other compiler?" The reason MSVC++ is ahead (IMO) is because the Windows API contains a lot of non-standard features locked into the MS compiler. Anyone using other products such as Embarcadero, or g++, inevitably suffers: always being a step or two behind MSVC, not having latest standard support , etc.
I have considered starting a blog that would be about the subject, at least initially. Would that be of interest? 
[https://twitter.com/Ca1ne/status/862678559428628481](https://twitter.com/Ca1ne/status/862678559428628481)
Are there any plans for Windows API to receive an overhaul in the future?
I walk through an openfile() implementation for each of the four forms of error handling described in the talk. As I mention in the talk, nobody would implement them that way in real code, they are for exposition to communicate the ideas behind the talk.
&gt; If you're concerned about the performance of the throwing case that's a pretty solid indicator that the thing wasn't actually exceptional. Exceptions are C++'s language feature for doing error handling and robust applications should always handle their errors properly. Whether the success path is the most common code path or not is something that completely depends on the type of application one is writing. &gt; I wasn't saying that exceptions needed to be rare, I was saying that in most cases exceptional things are irrelevant to the performance of whatever code you're writing. In lots of applications, the success path is actually the "exceptional" (as in less common) code path. For these kinds of applications, C++ "zero-cost success path exceptions" are the worst possible (performance wise) solution to error handling. Even though using exceptions is the idiomatic way of doing error handling in C++, I wouldn't consider that avoiding them for the code-paths in which errors are the common case is premature optimization. 
[\[basic.def.odr\]/6](http://eel.is/c++draft/basic.def.odr#6) &gt;each definition of D shall consist of the same sequence of tokens and &gt;If the definitions of D do not satisfy these requirements, then the behavior is undefined.
&gt; optimize exceptions when they are in your hotpath. Optimizing exceptions when they are in your hotpath means changing the signature of your functions, possibly breaking APIs and ABIs. So while I agree with your advice in general, if you know a priory that errors are going to be as common or more common than success, and that the API is going to be used in hotpaths, design the API with that in mind.
Is windows.h never updated? Otherwise this project would need to be constantly kept in sync, right?
Also, for MSVC it's not just a simple wrapper around pthreads as pthreads don't exist on non-posix systems. So there's another reason.
&gt; This project is dual-licensed under the "MIT" &amp; "Unlicense" license. Isnt code copied from original headers? I do not think you can relicense code from headers written by microsoft.
Nope. I am currently blog-less. I would not be surprised if I took inspiration from the same blog post though.
Technically speaking, no code was ever copied from any of Microsofts headers. I never looked at any of these. I got all my information from the MSDN. Even if I was copying code, there has to be a license exception somewhere, because `#include &lt;Windows.h&gt;` is just copying Microsofts code into my project and would violate any normal licensing. I had the same thought, since my declarations are nearly identical to those appearing in Microsofts Windows.h header. And you can't copyright an API, which Google has proven against Oracle in court. You can't not license any work. Even if I wouldn't attach a license, it still has an implicit copyright.
Windows.h is rarely updated, but it is updated. Microsoft will likely never do any breaking changes which requires any changes in these files. Otherwise, there is no real need to keep them constantly in sync, because this files are currently missing most of what is defined in Windows.h, which is point of why this project exists in the first place. You maybe use 10% of whats declared there, if you could only include this 10% everything would be cool, but you can't, hence this project. If there is anything missing you would like to use in this headers, open a pull request (or issue) and I can merge your changes into it.
To be honest i do not believe no code came from microsoft headers :p Not that using any of this would cause any problems anyway, im just curious about technicality of the license. I think these headers must follow whatever original license was there. All in all cool stuff you got there. Now we just need a complete `ntdll.h` ;)
One of my favorite and most commonly used techniques ever.
That video is about Clang modules, and most problems were because of macros exporting and their build system. Another issue with that approach is that it tries to change header semantics to module semantics without changing syntax and of course it leads to a lot of subtle problems. Modules TS proposal should be free of these problems, I believe current speed is just a temporary problem with microsoft implementation of them.
Yes, that was my impression as well, plus the recompilations caused by aggregating multiple headers into a single module.
&gt; With return codes, you get lots of instances of an extra dozen or so instructions. True, but I also only get a number as error info. When I add more info, I also get more instructions. That can be alleviated by using thread-local storage, but is not exactly pretty. It's also harder to make arbitrarily rich (think boost::exception).
We could banish CRTP with concepts
I'm just passing on hear-say here, so take it with a grain of salt: The Microsoft implementation of modules is just caching tokens (or something similar). E.g. the performance isn't that great, but they can support all the ancient code. Source: Smalltalk with someone from MS ranting about this. &lt;/hear-say&gt; The clang implementation is working on declarations which forced people to modernize their code, but it's much faster. For us up to 90% of the *parsing time* (translating to about 50% of the compilation time) disappeared when using clang with modules.
The thing is that if you handle spurious wakeups properly, it also makes you not spuriously sleep because the condition is checked before sleeping. In a sense, you can treat them both with the same fix -- properly having a "message" or "condition" separate from the variable (guaraded by a mutex), and passing the lambda checking it to the wait function. Spurious sleeping (going to sleep when there is something to do) is a different problem than spurious wakeups (waking from sleep even when there is nothing to do), but the same solution fixes both. 
Looking on numbers, it's very likely that you're right. It feels like modules work like index for searching tokens in headers, and after using some function or class for the first time it starts parsing them.
&gt; splitting the standard library into hundreds of modules will just make it tedious to import. This is false: modules can include other modules which makes it trivial to provide both, fine-grained modules for single components, and agglomerations of modules for comfortable imports. For example, on range-v3 you can import `std::copy` if you want to by just including: #include &lt;range/v3/algorithm/copy.hpp&gt; or you can include all of the algorithms by doing #include &lt;range/v3/algorithms.hpp&gt; These approaches are not either/or, and Range-v3 provides both. I don't see why the standard library cannot do the same. Note also that while users can write their own agglomerations of commonly-used modules from the fine-grained approach, the opposite is not true: one cannot "slice" a `std.container.vector` module out of `std.core`. 
Depends on what you are using as your status code. True, most libraries will pass / return something that is very similar to an int. You could also pass / return a struct {int; info*;}; Or any other error object you want (std::error_code?).
&gt; The point is there is no point in importing individual parts if importing the whole thing costs you just as much. Sure, but we know that importing the whole thing doesn't cost just as much as importing only what one needs. If we ever managed to make that true we wouldn't need `import` statements (in general) at all, because we could always just import everything everywhere (since it doesn't cost anything to do so). 
For us clang modules consistently deliver a compile-time reduction of 20-30% across a couple of projects. Sadly that is far from enough. For example, we have a couple of TUs that always instantiate the same generic code with the same type of arguments, and clang modules doesn't seem to be caching template instantiations or generated code for these.
* Not every build system supports different precompiled header for different set of files. * Huge precompiled headers are slow on gcc (or at least were last time I checked) * Modules force you to modularize your code * Huge precompiled headers leads to frequent recompiling for a lot of files * Modules can help with ODR problems 
That would be really great.
&gt; but we know that importing the whole thing doesn't cost just as much as importing only what one needs. The committee says it should. *And so it is*.
Considering API definitions were copied (be it msdn or headers) copyright does not entirely belong to person who copied. This is a derivative work now.
Can anyone provide a source for what modules are? Also, will this be a compiler specific feature or part of the standard?
God speed!!! I'm amazed by CMake. It's super powerful but it has some of the worst documentation I've seen. For example, I stumbled across an undocumented command for building Python c extensions in the findPythonlibs. That command has saves me a lot of time and really opened up my ability to connect my C projects with Python but I wouldn't know it's there if I didn't stumble across it in someone else's code on GitHub. Any chance you'll be covering the more exotic features of CMake? CTest and CPack? I tried a million time to get CPack to create a OS X Bundle with shared libraries such as ffmpeg and I never get it work. 
It's a proposal for the future standard. Latest proposal - http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/n4647.pdf but if you like something more readable, http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0142r0.pdf is better
Gamification clearly doesn't work to maintain quality. It's just impossible to leave the door open to an online community and not see a downward spiral, no matter your moderation algorithm. Seriously vetting participants is the only approach that works, but nobody wants to do that.
If you can have blog post that includes the information about how to successfully use CPack to produce a Mac OS X Bundle that includes the external shared libraries, then HELL YES! You would have my interest. I can't get that damn thing to work and all the CPack tutorials are for Debian packages or attached sample code doesn't work. 
How so? They are apples and oranges, or am I missing something?
CRTP can be used to implement members. class Foo : public impl_oper_plus_assign&lt;Foo&gt; { //would have operator+= (const Foo&amp;) here };
Use `stx::variant` it will use C++ headers from your standard library. Repo: https://github.com/tcbrindle/cpp17_headers
Outcome toes a middle line, so: BOOST_OUTCOME_TRYV(do_something1()); BOOST_OUTCOME_TRYV(do_something2()); BOOST_OUTCOME_TRYV(do_something3()); Is this the same as simply wrapping if(rc!=0) return rc; in a macro? Yes, it is.
Thanks for the link, optional and variant account for about 90% of the boost types that end up in our header files so it will be interesting to see if we get an improvement in compilation times.
The idea behind CRTP is class must implement certain functions else it won't compile Same can be done with Concepts without odd inheritance syntax May be I'm missing certain usecase where CRTP is required and Concepts doesn't cut it
Huge precompiled headers are also slow on Visual Studio - Epic recently switched away from precompiled headers in UE4 to an include-what-you-use model and actually got a compile time speed _boost_ in the process.
That thing fell down the ugly tree and hit every branch on the way down. It's even worse than just having the ifs. Those are at least explicit rather than magic macros whose names contain 19 characters. The point of a language extension would be to have roughly that functionality, but with simple and readable syntax.
I don't think this is relevant, here is why: 1. Modules specification AND implementations are still exploring the domain (in the case of C++) so measuring them now is good to get the current state, but it says nothing about it's actual potential; 2. I don't know what is your precompiled header. If there is vector&lt;int&gt; declared in, and all other types you mentionned, then it basically mean that the current module implementation don't retain the instantiated types (for whatever reason) but it's still possible to have this optimization as soon as you have everything as modules - I suppose optimization for templates is not enabled yet in all modules implementations; 3. To exploit the full potential of modules, the build system have to be built around it too, which mean the build system have to know C++ (at least partially). So far no build system was publicly built around modules (except work in progress in build2). This have a major impact on any benchmark because importing depends on the build context. 4. With what flags did you compile? Debug mode? All the context have an importance here. 5. This is not an actual project. Real project keep getting weird architectures that make sense in their context. This is what you should be evaluating. That being said, I hope these simplistic tests will be impacted in the future, otherwise module adoption will be complicated....
&gt; The point of a language extension would be to have roughly that functionality, but with simple and readable syntax. I have asked various people on WG21 to have the try keyword gain new expression semantics like in Rust or Swift, but there is opposition, mostly due to ignorance of the use case (not my words, their words). They want to see how Expected fares first, and in a later standard start fiddling with the try keyword if that is what becomes obvious. There is also the later monadic programming framework which ties together future&lt;T&gt;, optional&lt;T&gt;, expected&lt;T&gt; etc which almost certainly would affect what an expression try keyword would do. So don't expect language changes until at least 2025.
2. Precompiled header is just `#include &lt;vector&gt;` 3. I don't understand why special build system can change compilation speed in such simple case - compiling 100 independent files. Anyway, special build system is needed only to parse dependencies correctly, not to speed up it, or an I wrong? 4. Release mode x64 5. Of course, actual projects will react differently - for example, unused imports seem to not affect compilation speed, and in real projects there may be a lot of them.
No, just no. Put it in your precompiled header and forget about it. Some people have **way** too much time on their hands. And what about maintenance?
I'm glad to hear that since this is exactly the purpose of the book. CTest and CPack will also be covered in a dedicated chapter with some configuration examples taken from real-world projects to bring the reader up to speed quickly on how to use CMake for testing and packaging C/C++ based projects.
There is no right or wrong answer here, it all depends on what do you need the programming language for, there are ALWAYS pros and cons to each language depending on the platform used, the goal of the program to create, the resources available, etc. If you just want to learn how to program something simple and tested maybe C# is a better start, if low level is what you seek c++ may be a better option if you want your code to run on "almost" any platform out there today.
Would you happen to know where what language excels at what?
&gt; On the other hand, Rust feels like a convoluted set of syntax sugar on top of a weird syntax that tries to be C++ on rails. &gt; Haha, that cracked me up :)
I think you got the idea around CRTP wrong. I mostly usr it to add new functionality in classes that uses functions in all of these classes. For example I have a set of four classes that look like this: struct Derived1 { std::vector&lt;int&gt;&amp; container(); }; // More classes like that that returns different types of containers. I would like to add begin(), end() and stuff in all these classes. CRTP can help you generalize the implementation of function across multiple classes: template&lt;typename T&gt; struct MyCRTP { decltype(auto) begin() { return static_cast&lt;T*&gt;(this)-&gt;container().begin(); } }; Voilà! Just add every other function you need and you just saved yourself duplicated code. 
I guess I'll keep reading C++ Primer then. Then maybe learn rust in the future as it peeks my interest once more.
Thanks for starting this conversation. What are the compiler flags you used to conduct the experiment? The precompiled header implementation in VC++ is essentially a memory dump and reload of the compiler. So, the compiler does not do any additional work when you use a PCH. The price you pay for that is you have no isolation semantics, and huge on-disk memory consumption. Internal measurements and requirements indicate it is not the technology of future. Regarding difference between '#include' and 'import', I would like to know the characteristics of your measurements before I comment further. However, there is one thing that you said that is true: with modules, the compiler materializes only things you use, unlike for '#include'.
&gt; The price you pay for that is you have no isolation semantics, and huge on-disk memory consumption. Since the file is just being re-used, isn't it just cached in RAM/VRAM?
Indeed. By several measures, PCHs aren't the future for internal builds at Microsoft.
Ah, I didn't know about this effort. The forward compatibility is an idea I hadn't thought of. In the context of compilation time vs `boost::variant` though, I don't see how this is relevant. Presumably @ojd5 isn't currently using a compiler that has a `std::variant`, and even if they were, a `std::variant` isn't automatically going to be faster to compile...
&gt; Yeah, but you can't access the standard freely as some random programmer. cppreference.com &gt; One of Rust main points IMHO is that the compiler take care of this for you :) Yeah, I agree on that one advantage. But it's still not a major point if you consider everything else. &gt; One of my biggest gripe with C++ is that it merges its metaprogramming and its generics in the templates, leading to IMHO hard to read and sometimes understand code. C++ could definitely benefit from a better metaprogramming sublanguage. `constexpr` already solved a lot of the missing parts but not all of them. What are the SFINAE alternatives provided by Rust? &gt; The real point of having pattern matching is when you couple it with the algebraic data types and a whole ecosystem built with this in mind. For real algebraic data types Haskell does a better job than both C++ and Rust. &gt; I guess it's subjective, but for me Rust is now easier to read than C++. Of course the part of it being "weird" is subjective to how long you've been working with it. I said it in the sense that it's not similar to any other language, so the weight of learning every quirk should be taken in consideration when comparing both languages. The semantic meaning of a missing `;` at the last statement is really confusing, especially with the trend of newer languages eliminating the `;`s entirely. The special symbol abuse is very high as well, which makes the language feel very perly, and reduces readability considerably. The module system is quite complicated as well and uses weird naming like "crates" wtf. Why couldn't they just use conventional names like "modules" and "packages"? Tooling is also non-existent. One of my favourite things about C++ is how I can just save a file and have every type mismatch highlighted in Syntastic. In Rust it's not possible because the module system doesn't allow it. Those seem like minor things, but they tickle my OCD too much I just gave up when I tried giving the language a chance.
Not for VC++. See my [comment here](https://www.reddit.com/r/cpp/comments/6aqihe/some_modules_benchmarking/dhh4tcw/)
You took the words out of my mouth :-)
&gt; Isn't there a way to only import &lt;vector&gt; ? No, see the [Standard Library Modules](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0581r0.pdf) proposal.
Actually you have no assurance that `#include &lt;vector&gt;` gives you only `std::vector`. In all practice, it gives you a lot more than you realize. `#include &lt;vector&gt;` may even give you the entire Standard Library.
&gt;Perhaps rust has more compile-time checks for race conditions, which would be nice, but not necessarily required if you design your code correctly to avoid them in the first place. Just wanted to clarify, using safe Rust (eg, code which does not need the unsafe keyword and constitutes the majority of the code in applications and libraries), there is not race conditions. It's statically impossible (assuming the unsafe abstractions are correct. The STD which provides thread abstractions is both small and has a lot of eyes on it, so you can trust them to be thread safe). There IS a caveat to that though: in order to fulfill that, the "borrow checker", which is the system that enables this static guarantee, can make it sometimes cumbersome to write code. There is still a lot of work going in to making this part of the language more flexible / ergonomic so that you can still get these checks without being forced to write awkward and sometimes in inefficient code 
&gt; I don't understand why special build system can change compilation speed in such simple case - compiling 100 independent files. Anyway, special build system is needed only to parse dependencies correctly, not to speed up it, or an I wrong? No, you are correct. In this case the modules are pre-compiled by Microsoft and the build system doesn't need to worry about keeping them up-to-date. Things will be a lot different thought if you want to import modules that need to be compiled from source (either third party or your own). In this case there is a lot of things that have to be done by the build system to aid parallelism.
Did you have a look at the Stackoverflow book list for C++?
wat. I'm a C++ dev all the way, but this was the strangest defense of C++ I've ever read. &gt; C++'s documentation is actually more than up-to-date, since it's a standard Reading the C++ standard to figure out how to program in C++ is not something anybody does. It's not a tutorial. It's not even in a good format to be used as a reference - which is why I rely on cppreference most of the time... &gt; Segfaults are mostly caused by [...] That's just an odd thing to argue. First, you can of course still get segfaults using modern C++, but also the alleged origin of UB in C++ isn't the issue at all. The issue is that segfaults exist. &gt; move semantics | same as above Rust's move semantics are just memcpy, so it's more like destructive move, which isn't something that C++ actually has. For instance, moving a unique_ptr requires 2 writes in C++ because you still have to null out the source. &gt; C++ has actual generics [...] No, C++ does not have actual generics. C++ has duck typing. &gt; type inference | auto `auto` is a lot weaker type inference than Rust offers. 
&gt; Internal measurements and requirements indicate it is not the technology of future. That may be, but unless modules can be realistically implemented to be as fast or faster than what we have right now with PCHes, modules are also not the technology of the future. :)
While I'm a huge fan of ML's pattern matching and variant syntax, and really want these in my c++ code, i think they've done a good job of making a library implementation. The cost of embedding variant deeply in the core language are much higher in terms of getting anything wrong and bring stuck with a poor implementation because of backwards compatibility requirements. As for the issues with multiple int types in a single variant, I believe this can be solved with type aliases or maybe strong type containers, like single field structs.
You probably misinterpreted everything I said. &gt; Reading the C++ standard to figure out how to program in C++ is not something anybody does. It's not a tutorial. It's not even in a good format to be used as a reference - which is why I rely on cppreference most of the time... I didn't suggest reading the standard as a reference. But that the standard is a base for every reference, so they can be updated even before the new standard is officially released (just as cppreference does). &gt; That's just an odd thing to argue. First, you can of course still get segfaults using modern C++, but also the alleged origin of UB in C++ isn't the issue at all. The issue is that segfaults exist. When people talk about segfaults, they're actually talking about accidental segfaults caused by random mistakes allowed by a language, which if you use proper modern C++ you probably won't make. If you want to get really precise, you can have segfaults in any language: just do a kill -SEGV. It's pointless to discuss that. &gt; Rust's move semantics are just memcpy, so it's more like destructive move, which isn't something that C++ actually has. For instance, moving a unique_ptr requires 2 writes in C++ because you still have to null out the source. Okay, so their move works differently in the language level, but the goal is still the same. &gt; No, C++ does not have actual generics. C++ has duck typing. How's that not generic?
I look forward to it then.
I'm subscribed to both r/rust and r/cpp. I learned C++ when I was ~12 years old, like 20 years ago, and used it for years. I used to really enjoy it. Now my favorite PL is Rust. :D C++'s one biggest, and decisive advantage: it's old and established. There are plenty of jobs and there will be for years to come. It will take years until Rust is not totally dwarfed by C++ in real business. It is more portable. Also, doing very low-level stuff (like memory-mapping structs, etc.) might be more convenient. Having said that... unless paid for it and for good business reason, I wouldn't ever use C++ over Rust for anything. :D . But you asked about advantages of C++ over Rust, so I won't get into details.
Hi Michael, I'm the one who put together the C++17 headers linked above. I saw a note about the release of your library on Twitter and was going to contact you but I figure Reddit is as good a place as any! I'd like to change my cpp17_headers to use your `variant`rather than the current implementation, as yours is compatible with C++11 and MSVC and the current version is not. Would you feel strongly about offering a single-header version, say just `variant.hpp`? Don't worry if not, I can glue all the current headers together myself (I'd have to make some changes anyway to support forward-compatibility and the `stx` namespace), but I'd prefer to diverge as little as possible from "upstream". Thanks, and congratulations on this awesome release!
&gt; "should I learn C++ or Java." The answer is JavaScript. Let's go webscale!
Curiously, it is a recurring mistake that people use "recursive", the correct/original term is "recurring". 
&gt; Yeah, but you can't access the standard freely as some random programmer. You can't? Looks like I've been hacking all this time and never knew it!
&gt; Everyone remembers when the web browser was "just" part of the OS I wouldn't be so sure about this statement either =)
It's not that simple. You're assuming everyone shares your priorities. Yes, if you want to learn the language that is more widely used and that your future employers are likely to be using, there's no contest: learn C++. But not everyone is immediately concerned about that. What if you're not going to be looking for a job in the immediate future, or you're confident your career is safe and just want to learn something new? What if you know you want to learn a language that can be close to the metal, but the lack of standardized build and packaging tools around C++ is a turnoff and Rust's Crate looks really appealing? What if you want some decent abstractions, but C++'s abstractions look overly complicated and constrained by historical decisions? &gt; The relevant question in regards to C++ is still "should I learn C++ or Java." And for Rust it is "should I learn Rust or Haskell." I don't understand this at all. There aren't many situations where I would be seriously deciding between C++ and Java. * I might use Rust if I had to be close to the metal and wasn't constrained by outside concerns (for instance, a small solo project). * I might use C++ if I had to be close to the metal and needed to work with other programmers who are likely to not know Rust. * I might use Haskell for general programming tasks that don't need to be close to the metal. * I might use Java for general programming tasks that don't need to be close to the metal and could benefit by a massive ecosystem of libraries or for which I need to work with people who know Java.
Whether you should try Rust or not comes down entirely to "Do you want to use Rust?" or "Are you curious about Rust?"
AFAICT, you can only freely download the draft. [The actual standard costs $133](https://isocpp.org/std/the-standard).
&gt; cppreference.com AFAICT, you can only freely download the draft. [The actual standard costs $133](https://isocpp.org/std/the-standard).
&gt; I'd like to change my cpp17_headers to use your variantrather than the current implementation, as yours is compatible with C++11 and MSVC and the current version is not. Sounds great! &gt; Would you feel strongly about offering a single-header version, say just `variant.hpp`? It doesn't sound like too big of a deal... but let me sit on it for a bit. I'll get back to you here :)
No. Exceptions are for when a function could not complete its primary purpose.
 I don't see how that precludes pre-compiled headers. Just use smaller, more targeted PCH. My experience with PCH in VS is very positive, if you manage them well, they work great. If modules ends up slower than PCH, I can't see much incentive to switch..
&gt; `#include &lt;vector&gt;` may even give you the entire Standard Library. While this is technically correct, am I wrong to expect that a _good_ standard library implementation won't do this? I do not use the MSVC standard library, but the standard libraries that I do use at least try to give me the minimum amount of code possible, and do take patches that improve this.
Careful with the snowball effect. If you chose languages by the amount of people that use them, then the most popular languages will be even more popular, and any other languages will die out. If you don't even give Rust a chance and go straight for C++, you're only contributing to that. Imagine if people said the same thing about Java when Kotlin and Scala were starting to appear. Encouraging diversity is good because it helps solve problems faster. Also, you're quite wrong that there are no Rust jobs. There are, and they sometimes even get announced in This Week in Rust posts. You do have to look for them, yes, and they might be in lower quantity than C++ jobs, but that doesn't mean Rust has no jobs.
Do you have any more info on doing opengl stuff at compile time? I've done opengl stuff but wouldn't know where to start with using tmp or if contexpr for it. What can be optimized using it?
The draft is usually enough unless you actually implementing your own standard compliant compiler. It's huge. It's hard. But I'm yet to see any other language (besides C of course) in which standard can answer even the most obscure behaviors. Some of this answer will point to UB but that's different story. Tho I didn't look for Ada spec. I suppose they have something very similar, if not better. 
Learn both, probably C++ first. Rust is a nice language, a little different in syntax but it's not that difficult. It has an easy to use standard package manager, which I really wish C++ had, and you don't have to write header files. I'd recommend learning about how memory is managed in C++ first, especially smart pointers, before learning Rust as it'll make it much easier to understand what it is trying to do by restricting you.
&gt;I have no idea what the real advantages of C++ over Rust are Mostly that people actually use it... Snarky, one-liner aside, C++ is much more mature and far, far, far, far, far more widely used in industry. This doesn't necessarily make it a better language but it does make it more likely to help you get a job. It also makes it more likely that you'll be able to easily find or hire developers to work on a project in C++ than Rust as way more programmers know it. C++ is definitely more stable. Rust literally just reached the milestone of having a stable API a few years ago (although I believe a few areas might still be unstable?), which means that their first release where they promised further updates wouldn't break existing code was literally decades after C++. The upshot of this is that Rust is still seeing some pretty major changes as it matures, while C++ has been around forever and can be relied on. This isn't as important for small personal projects, but it's absolutely crucial for anything large and complicated (read expensive). TL;DR: Rust is young and cool, and it brings a lot of promising new concepts with it. But C++ is a tried and true industrial workhorse and that isn't changing any time soon.
Go is a competitor to the Java space, not the C++/Rust space. Rust and Go are nothing like one another and really don't deserve to be compared.
I "expected" a different "outcome" but I suppose that was "exceptional" thinking.
Hey any news when this is going to YouTube? Or where is the slides? Thanks.
This is not how one speaks to the Supreme Allied Commander in Boost.
How about ML which has an actual formal semantics.
I think you are getting dangerously close to "for each task there is a different tool" thinking. HN would not approve. 
FWIW, I have come across _multiple_ instances where MSDN docs are outdated (and consequently wrong) WRT parameter/return types vs. the actual shipped headers &amp;ndash; things like the docs saying `DWORD` when the actual type is `DWORD_PTR` and has been for 15 years. Don't trust the docs. ;-]
Not sure what you're talking about: Rust indeed [has GUI libraries](https://github.com/rust-unofficial/awesome-rust#gui), Qt bindings included. Actually, Rust has many, many libraries. And where it doesn't have pure-Rust implementations, it just gets C or C++ bindings (e.g. Qt or something), which are (if implemented correctly) safer than the original library, which in my experience is a huge pro.
`tuple` is actually fairly low in the stack. First, there's `tuple` support machinery in `pair` and `pair`'s in `&lt;utility&gt;`, which is included by the entire universe since `move` and `forward` are in there. Second, `tuple` is a necessary building block anywhere the STL needs to package up a parameter pack and pass it around (e.g., `scoped_lock`, `thread`). The current standard library modules are produced by including a bunch of headers and then `/module:export`ing that blob of stuff. In the future we'll want to do explicit work in the standard library to provide good modules support; that work just has not yet been done.
&gt; When people talk about segfaults, they're actually talking about accidental segfaults caused by random mistakes allowed by a language, which if you use proper modern C++ you probably won't make. If you want to get really precise, you can have segfaults in any language: just do a kill -SEGV. It's pointless to discuss that. There are no bad programming languages, just bad programmers then? You know even the best 0.0001% of programmers make bugs, and having a language and compiler which prevents as many types of bugs as possible is really important. In this aspect, Rust seems vastly superior to C++.
So, if we can get some vague reflection-a-like ability we can reflect on the various members of a vertex struct. With a bit of hackery, you can do things like properly set the various `glVertexAttribPointer` calls, since those need num of elements, datatype of elements, and the size + offset of the vertex attribute. From what I understand, `if constexpr` makes branching, including branching through a member of a struct, much easier. [I tried to do this using boost, but it ultimately didn't quite work](https://gist.github.com/fuchstraumer/52153c11915289dfc61aad77234b5157)
If you are getting seg-faults writing C++ you should probably stop coding like it's 1999.
This guy has the right answer! As it is learning C++, especially modern C++, is a smart move. A wide range of concepts can be explored with this language. However it is highly advisable to not get tied down to one language, the CS field is very dynamic, it is highly unlikely that a 20 year old will be using the same language 30 years later. Very few die completely but market forces will cause new tech to supplant the old. Frankly i know little about RUST, but do know it isn't widely adopted right now. Until that happens i think you would be wasting your time. By widely adopted i mean big companies or organizations. Now that being said there are options that might be worth pursuing if you are interested in a more modern language. Swift, Julia, go and a bunch of others have much to be said for themselves and more importantly have wide adoption in their domains. Im getting a bit long winded here but when it comes right down to it the task at hand often chooses the language. Avionics for example still uses ADA, embedded programming is often C++ or even old C. Python on the other hand dominates scripting. So don't think about one language as the best way to learn programming. C++ in my mind is a good place to start, especially if you commit to following what amounts to a complete CS program. You can start out simple and quickly move to higher level concepts. More importantly there are a ton of resources to support learning CS and C++. 
Yep, need to stress this learn modern C++. By the way I'm not leaning towards C++ because it is a modern solution, it still has a lot of baggage from the early years. Rather it is the wealth of resources that makes it a good place to learn CS and not just programming. 
We update it pretty regularly (but centers more around new books being published than new releases of the standard).
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [cplusplus/draft/.../**papers** (master → 8279660)](https://github.com/cplusplus/draft/tree/82796606a63a7c62b05785593f651fba105f1c2c/papers) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dhhztl9.)^.
I was wondering how that was handled, makes sense you guys just took the sane approach and didn't even try
&gt; Rust for some core concepts about move semantics, concurrency and memory safety. Learning rust's way of doing these won't teach you anything about anything other than how to get rustc to stop complaining. It's a language so mired in its "big ideas" that half of things you have to learn have no applicability to general programming, which make it a bad first language in my opinion.
I think this is an outdated idea. I work in the gallery/museum space as well as for advertising agencies and all of the large scale stuff is c++ these days. See [this 5 year old talk](https://vimeo.com/51533137) on the very subject.
&gt; excellent Visual Studio development Am I the only one who has nothing but trouble with it? It takes forever to boot up, crashes constantly, is slow as shit, the list goes on. Is it because I haven't forked out for the enterprise version? What gives?
The idea here is not to learn Rust's way; it's to learn why Rust is the way it is. And it's very applicable in general programming. Everybody knows that shared mutable data without mutexes means possible race condition. That happens in any language. What Rust enforces is that if there's mutable data, then it must be a unique access. It makes sense, because that prevents race conditions from happening in the first place. All that's left to do is to figure out how those concepts can be applied to C++ to produce better code. It's possible to learn all that without learning Rust, but Rust makes it a lot easier to grasp, especially with the `&amp;mut` syntax helping you see where mutation happens and with its very verbose ~~complainer~~ compiler. And I see it being very useful in C++: imagine that you could get rid of a mutex by rearranging some funcions around in a way that you're sure there's only a single mutable access point at all times. Performance would most definitely go up. Rust helps you figure out a pattern. And with the pattern, you can apply it to C++.
In London all the big paying finance jobs are really into c++, heavy on template programming.
No. I'm saying that rust is actually worse than C++. It's just being so much hyped that people are flocking to it, the systems languages version of what happened with ruby, nodejs, and then go in the web world. People just like using the new shiny language and forget about everything else. 
The only thing you say is either "it comes from C++" (C++ took from C and made it better too so what's the argument?), or "C++ can do that too, even though it's much more difficult and you can shoot yourself in the foot, but hey, only bad devs create bugs so it's never a problem, at all".
If I need to keep the ABI **and** improve performance of thrown exceptions, **then** I create another API version with error-return. Internally, anything can be changed, of course, but not before a case for better performance is established and justified. Clients who care about performance can switch. What you wrote is **way** too much hand-waving and speculation for my taste.
Oh, it's pretty rough and ready in Boost. People are unfiltered with one another all the time. Nobody worries too much.
Absolutely right. Specifically, throwing an exception means "I abort what I am doing right now". That can be incredibly useful in some circumstances because how easily C++ lets you register stuff to be called when execution flow is aborted. As I mentioned in my talk, in rare limited circumstances exception throws as control flow really is the correct design. Though I emphasise the *rare* and *limited* qualifiers.
I think that you're entirely wrong in your logic. Your "fails" is normal occurence. You would have been better had you used an exception to exit upon "found it". Basically, you are deconstructing a strawman here.
It's actually getting seriously hard to find decent gamedev candidates, and working conditions only suck if you're willing to put up with them. OT though. C++ is ubiquitous and C++11 and beyond fix a great deal of the old issues with the language. Rust is very promising and the library/package manager is great. IDE support is generally bad... Honestly my main gripe with rust is that it's not possible to create a double linked or tree structure in "safe" code (without using a vector or an array to back). Parent -&gt; Child, Child -&gt; Parent links are everywhere in gamedev and you really have to fight the language to do it in Rust.
Dang that pattern matching thing is really cool! Do you know how well compilers are able to optimize the code? And how hard are the template instantiations on the compiler in typical use? 
The strawman in your argument is that you, abstractly speaking, have a function `bool matches(password)`, and you want to turn it into something else, and you want to use exceptions to report the usual outcome. The flaw in you thinking is that `!matches(password)` must be exceptional, an error. Ask yourself, why would that be? Why does it even matter to ascribe error/not error to your function - at all? I did not consider multithreading, but offhand, I don't see a correlation. I have written quite a bit of code with exceptions in multithreaded scenarios, so I am reasonably confident that I know where I stand :-).
“Nobody's using it, so I won't either”, said everyone.
I'd say first do a command line calculator. Doing graphics will likely result into learning more about a GUI library than the language itself. But if you wan't to do graphics you are gonig to need a GUI library like QT, windows forms or similair. You could also use OpenGL or DX 11 but those have a steep learning curve.
How would someone differentiate modern C++ from old C++? I've been learning a bit of C/C++ at college, mostly for programming competitions, and I have no idea if I'm on the right track or not.
That's interesting. I would have recommend learning Rust first for memory management, because it's much easier to let the compiler catch your mistakes than catching them with gdb/valgrind, especially as a beginner.
&gt; With rust you won't be able to do anything before digging into type theory. Have you actually tried Rust? I don't have any formal background in type theory, my eyes gloss over any "type proof", and yet I have no difficulty understanding Rust. Not saying there's no type theory behind Rust (I hope there is, and they manage to prove it's a sound language), but it's definitely NOT exposed, and there's a conscious effort to use English words in the documentation.
&gt; It's not just the body of work done in the language, but the tooling, maturity of the language, and the capabilities of the compilers (and having many to choose from so as to have a richer marketplace of ideas). This. I very much think Rust is a superior language to C++; however I have a large C++ codebase to maintain, for which I enjoy having a good IDE to quickly navigate. Rust is cool for new small/medium scale projects, existing or large projects may wish to wait a bit.
As they say: http://bholley.net/images/posts/thistall.jpg
He could use something like SFML which I guess it's a middle ground​ between Qt/Windows Forms and OpenGL/DirectX
You're right; but I'll still take that above no help at all ;)
The second part of the Outcome tutorial shows how to mix type safety in different E types but at the same time allowing code with no knowledge of your E types to "catch" errors from them. As far as I am aware, it matches exactly what C++ exceptions provide, but I will absolutely agree it requires much more typing out of code, and debugging and unit testing it would be required which isn't necessary with C++ exceptions.
From what I've seen, most of the *evangelists* were newcomers to the language who got over-excited. Most of the actual developers in the Rust community are seasoned enough to know that it takes more than waving a magic wand to rewrite any codebase from scratch and wouldn't ever seriously suggest it.
Obviously it depends on the project and what you're trying to do. But I think #1 is a pretty serious consideration for a substantial project potentially. I have a friend who started a company making embedded devices (and now has done a successful exit) and he did a big evaluation on Rust. He reached the conclusion that while he would have rather used Rust than C because of better idioms/higher stability, in the end #1 was too big of a factor. They would have to reimplement too much of the stdlib and other "common" tools and when all was said and done would have too much work and overall the whole thing would likely be less stable because they'd have a much larger effective codebase they had to maintain. Obviously it's totally case by case, but depending on the project #1 may be a serious issue. OTOH this was maybe 2 ago and things have surely improved since then. 
&gt; Rust also has unsafe blocks which can make tracking down weird errors easier (this is just the theory, no idea how true it is in practice). In practice you're unlikely to ever need to write an `unsafe` block yourself. The Redox *kernel*, which is the lowest-level code you can think of, has less than 10% of unsafe code AFAIK. Most Rust programs don't have a single `unsafe` (they rely on the Standard library to handle the unsafe bits for them).
Concerning the call stack depth, is the depth from the outermost try/catch, or does it extend all the way up (say to main())?
Oh, how so? I admit I don't really know how exceptions affect optimizations
Modern C++ started with the C++11 standard which introduced numerous concepts to make memory management safer (smart pointers) overall just generally more usable. Just a few things can think of: type inference (auto), move semantics, ranged loops, lambdas, initialization lists. There's probably tons of other stuff I'm missing. It will continue to change/improve in the next few years as well when compilers fully adopt C++17 and (hopefully) we get modules!
*Disclaimer: I've been developing professionally in C++ for 10 years, and I discovered Rust 6 years ago (and it was quite different back then).* **Interesting**. I've seen many people asking about the benefits of Rust over C++, so I think it's great that you are weighing your options carefully rather than just follow the hype. In terms of language: - C++ meta-programming for now clearly has the upper-hand: `constexpr`, variadic templates, non-type template parameters (ie `std::array&lt;T, 42&gt;`). It can be a bit clunky, but clunky is better than impossible (the Rust story is changing rapidly here, but my most optimistic projections for `constexpr` and non-type generics are Q3/Q4 2017). And concepts will, one day, clean this up a lot. - C++ has well understood idioms, from SFINAE to object-oriented design patterns. New features may sometimes rock the boat a bit, but modern C++ is not THAT different from 10 years ago (recommended readings: C++ Coding Standards, by Sutter and Alexandrescu, and Effective C++ &amp; co, by Meyers). Rust is only beginning this journey. In terms of tooling: - C++ has IDEs, static analyzers, debuggers, etc... available for every major operating systems (Rust doesn't have a working debugger for native Windows binaries AFAIK); also, note the S, there are several to pick from so you can choose whichever suits you (or the project) best. *On the other hand, I am still pinning for modules, hoping they'll clean up the poor build/test experience in C++*. In terms of ecosystem: - C++ has strictly more libraries published, and documentation, ... it can take a while to sift through everything, but it's still faster to take a few hours to locate a library than a few months to write one, - C++ has strictly more books published, and more experts available to teach; though estimating the quality of said books and experts can be difficult (anybody can claim to be an expert...), - C++ has WAY more jobs for it (I could probably count available Rust positions on my fingers). Good C++ developers are actually in relatively high demand, and thus fetch a higher salary, simply because many developers wouldn't touch systems programming with a ten-foot pole, - C++ is there to stay for the foreseeable future, too many companies have significant codebases in C++ that will require maintenance for the decades to come, and said companies have a keen interest in evolving the language rather than having to rewrite everything. The sheer number of people involved in working on the C++ Standard and the number of assorted compilers is a clear indication of this. --- So, really, there's nothing wrong with learning C++ for. Especially if you hope to monetize your experience. I'd still recommend making a detour by Rust at some point; and learning Rust first might make it easier to learn C++ by teaching you proper memory management strategy *from the compiler*. However, I'd NOT learn Rust and C++ back-to-back. Breadth of experience matters here, and I'd encourage you to learn a radically language in between (Erlang? Prolog? Haskell? JavaScript?). Oh, and if you aim for the industry, give yourself a basic level in Python. It's the goto scripting language, so not only does it help sifting through logs, it also helps automating tasks and is present in *many, many, codebases* for this role.
Yes, obviously. on Windows they'd probably wrap it around winthreads.
That's not what I said at all. My point was that since they weren't needing to choose a language because of specific work requirements, which one they choose *is* largely irrelevant, at least within the context OP provided.
Use of RAII. Heavy use of STL (new features like smart pointers), use of STL Strings over c-strings (where applicable), use of auto, lambdas, init lists, ranged for loops, new, and some other stuff.
But these are things you HAVE to pick up in Rust. The Rust book goes over them briefly, and if you ever watched any presentation from the Rust team on what and why Rust is, they go over it too. Sure, if you're learning Rust first you won't get the obvious C++ counterexample of why doing so is a bad idea, but it's not as if the reasoning isn't exposed and transparent. You have to follow the rules to get your software to compile, and any book or teacher is going to teach you why. I would agree though C++ as a first language is probably easier. That's how I learned. 
Finance man. It's huge in finance. Fast paced and $$$
I would not say made up; those are facts after all. They are, however *sarcastic*, as indicated by the note. My point was that I would avoid arguing over *stability* and instead emphasize *maturity* (or lack, in the case of Rust). The latter is not contestable.
The keyword was repurposed because nobody could find any code that used it in it's old meaning. You could prefix declarations with `auto` to explicitly say that they are not `static`. But writing it simply without `auto` had exactly the same semantics. Nobody ever used the old `auto` to the point where most programmers weren't even aware that this was an option.
It was similar to 'register', right? I sometimes used it in the 80-ies on an amiga compiler and it made a difference there.
Indeed. And so he is presumably going to make that decision based on the attributes of the language, its ecosystem, and its community... which seems to be what he was seeking advice about.
&gt; The question is: does offering finer-grained modules beyond "top-level"/agglomeration modules delivers any advantage? That is a good question. I don't see any. The discussion in this subthread hasn't shown me any. The headers have grown unprincipled, things get thrown in there before something else vaguely similar or remotely connected was therefore, e.g. we believe `std::unique_ptr` is in the wrong header, so are the parallel algorithms, etc.
Hmm, "didn't even try" what? Regarding "consumption by someone somewhere not in your organization": that isn't covered by the cited portion of the documentation.
Because the implementation is incomplete and has some known bugs. Just because something gets voted into the standard doesn't mean implementations magically appear under a tree ready for use.
&gt; As you say with "due to its shorter history", deprecations are likely to still happen in the future. How is that an argument that it's more stable? It was a tongue in the cheek comment to illustrate that stability is not necessarily on what you should based your entire judgement. Which is why I followed up with *maturity* instead, which seems to me more valuable. --- &gt; Error handling seems to have shifted from ... Well... there are multiple ways to deal with errors, but I don't necessarily see a *shift* in there. The use of `and_then` is generally found in functional style code, it is rather handy, then, as it allows you to handle errors in the midst of a transformation chain. The `try!` macro [has been present since 1.0](https://doc.rust-lang.org/1.0.0/std/macro.try!.html), 2 years ago, and serves another purpose: bailing out of the function *now*. In this case, you don't transform the error explicitly, just pass it on to the upper layer. The `?` is mostly syntactic sugar for the `try!` macro, no new concept involved. I wouldn't really count such a simplistic change of syntax as a change of idiom. `error_chain` is... both different and not really. Its most exciting contribution (beyond boilerplate reduction) is providing backtraces + nesting of exceptions. However, note that those are mostly transparent from the source code point of view: you're still using the `try!` macro or `?` operator to bail out early as usual, the fact that the error carries more information is transparent. All in all, I do agree that Rust is still searching how to handle errors: easy vs explicit, ... however in terms of *standard* the only change since 1.0 was syntactic (replacing a macro by an operator), which I hardly see as a big change of idioms. *Note: then again, many developers seem to place such emphasis on syntax, than maybe they count syntactic sugar as a change of idiom? For me, it's just too superficial to qualify... no semantic change.* 
`variant` was never in `experimental` in the first place. The `std::filesystem` spec was still being changed until a couple of months ago. There wasn't time to update the `&lt;experimental/filesystem&gt;` code to meet the new spec in time for the GCC 7.1 release.
range-v3 fixes this, so arguably, the STL2 could fix this as well and, e.g., offer one header/module per algorithm Btw, at least with clang, creating one module per range-v3 header vs putting all of range-v3 in a single module ("umbrella module" is how clang calls these) delivers a compile-time speed-up of the whole range-v3 test suite of about ~10%.
Whoops for the lack of clarity. \#1 referred to your "blissfully glossed over fact" number one - that Rust has the much smaller ecosystem. I don't think we see things differently - it's just pros/cons for different development scenarios. I'm not qualified to say anything useful in the embedded world, but friends of mine who are seem to be extremely interested in the future of Rust for that kind of use case. Fingers crossed I guess. 
`auto` is deprecated? wat
Thanks! The (ab)use of exceptions makes it such that it generates some terrible code-gen. I'm using it way more than I need to because it simplified the implementation, but I do need it in order to support the `when` construct the way it is right now. Currently, I'm more focused on figuring out to do support exhaustive checking.
Powerful design pattern in my experience, but there are a couple of things to make it a bit nicer. The private constructor and friend class trick in the post is very helpful to avoid confusing errors. In addition, I find it helpful to sometimes have Base and Base_CRTP (which inherits from Base), so that you can keep different subclasses in the same container.
&lt;insert generic C++ vs Rust civility reminder&gt;
Thanks Vinnie! Very timely for me as I've just recently played my hand at writing my own "async HTTP GET operation" using Beast. One thing I notice is your tutorial uses a lot of Beast helper objects, which will certainly help users of Beast. However, it does gloss over a lot of the gotchas when writing composed operations for ASIO in general. Some things that I've come across while writing my own: * You **must** use asio_handler_invoke() when calling the end users completion handler. They could be using a strand, and my understanding is that you need to do this to ensure their handler is dispatched back to that strand (Your internal handlers can be dispatched across any number of threads not on the users strand, and this is fine). * Even if you can complete immediately, you should **not** call asio_handler_invoke() from your top-level async function (It could block!). Only do this from a handler of one of the async operations you're composing or, if you can complete immediately, post() the handler using the io_service. * You should call asio_handler_invoke() in an ADL compatible fashion * You should release any locks before invoking **any** handlers (As I said above, any intermediate handlers can be dispatched to any thread in the io_service. This could cause deadlock. They could even run on the same thread but end up trying to re-lock a non-recursive mutex. * You should release any locks **before** calling result.get(). This makes using lock guards fairly error-prone because "return result.get()" won't trigger RAII and release your lock until after "get()" returns. If the user is using coroutines, get() blocks and you're now blocked while holding a lock. Ouch * Despite all this, you have no idea if the user is using threads, so shared state (like a result cache or any intermediate I/O objects you're using) needs to be locked. tl;dr you can't assume anything about threading while writing a composed async operation. tl;dr you can't assume anything about what a users handler might do in terms of calls or locking, or whether it'll block tl;dr you don't know if result.get() will block or not. Please feel free to correct me if I'm wrong
Hmm...I'm very happy to hear feedback! There is pretty much nothing on the Internet in terms of tutorials or how-tos on how to write composed operations. This is a situation which I would like to rectify! However, looking over your list I can only come to one conclusion - and please understand my intention is to convey this as professionally and constructively as possible: either I have been doing everything wrong, or most of the items on the list above are incorrect! I'll address each one individually. * **asio_handler_invoke** is not something that you typically need to call directly, especially on the final completion handler. Rather, it is something that you *overload* for your composed operation. That's why its called a "hook." The only time you need to call the hook is when you are forwarding it to the overload that resolves when using the final handler [**1**]. It is stated that *"internal handlers can be dispatched across any number of threads not on the users strand"*. This is incorrect according to the Boost.Asio documentation [**2**]. * As above, you should never call **asio_handler_invoke** directly. And you should never call the final handler immediately during the execution of the corresponding asynchronous initiation function. You correctly pointed out that if you want to call the handler right away, before performing any intermediate operations, you should use **io_service::post**. However, post only allows nullary handlers (handlers whose call signature contains zero parameters). Most completion handlers need an error code at a minimum, possibly more parameters. How do we bind those arguments in a way that preserves the **io_service** guarantees? You certainly can't use **std::bind**, since that destroys the type information and loses the associated hooks. You might be tempted to use **io_service::wrap** but that calls **io_service::dispatch** rather than post. Boost.Asio has a wonderful class for binding parameters to a completion handler in a way that preserves the hooks, but alas - its not a public interface [**3**]. Fortunately, Beast comes to the rescue with the convenience function **bind_handler** that takes care of all that boilerplate for you [**4**]. * This is true. Asio has some helper functions for making sure that calls to **asio_handler_invoke** are not made from a namespace that contains overloads of that function [**5**]. Unfortunately those are not public interfaces. Beast to the rescue again :) [**6**] * If you implement your composed operation correctly, there should never be a need for a mutex. The Boost.Asio documentation even has a dedicated section titled "Use Threads Without Explicit Locking" [**7**]. Consider the case where there is only one thread calling **io_service::run**: additional synchronization primitives such as mutexes or strands are unnecessary (this is known as an "implicit strand" in the Asio documentation). * You definitely want to release locks before calling **boost::asio::async_result::get** but it is better not to have the locks in the first place as mentioned in the relevant Asio documentation section. * A correctly written asynchronous composed operation should be agnostic to the users decision on whether there are multiple threads or not. Asio's asynchronous model allows these operations to be written in a style that allows for composition and extensibility without knowing about the details of dispatching, strands, or locking. * You shouldn't care whether or not **boost::asio::async_result::get** blocks or not. It sounds to me like you might have used some of the hooks incorrectly when writing your composed operation, and then you suffered a series of consequences from that decision which could only be fixed in ways that circumvent the asynchronous model's independence from explicit locking. I would suggest studying Asio's own composed operations to serve as a model for how they might be written. This is the approach I used when writing Beast's composed operations and also the format I followed when I wrote the echo_op example. I hope this helps!! Footnotes: [**1**] Boost.Asio's composed operation for **async_read** only calls **asio_handler_invoke** from the hook, never directly to invoke the final handler in the upcall: https://github.com/boostorg/asio/blob/7a79c157fc231faa818ec88b80c2b2fd4d32d70b/include/boost/asio/impl/read.hpp#L495 [**2**] *"When asynchronous operations are composed from other asynchronous operations, all intermediate handlers should be invoked using the same method as the final handler."* http://www.boost.org/doc/html/boost_asio/reference/asio_handler_invoke.html [**3**] See **rewrapped_handler**: https://github.com/boostorg/asio/blob/7a79c157fc231faa818ec88b80c2b2fd4d32d70b/include/boost/asio/detail/wrapped_handler.hpp [**4**] See **bind_handler**: https://github.com/vinniefalco/Beast/blob/f2d825594ee34ccc1ebc0b231899a1735245778d/include/beast/core/bind_handler.hpp#L19 [**5**] See **boost_asio_handler_invoke_helpers** https://github.com/boostorg/asio/blob/7a79c157fc231faa818ec88b80c2b2fd4d32d70b/include/boost/asio/detail/handler_invoke_helpers.hpp#L24 [**6**] See **beast_asio_helpers** https://github.com/vinniefalco/Beast/blob/f2d825594ee34ccc1ebc0b231899a1735245778d/include/beast/core/handler_helpers.hpp#L17 [**7**] "Use Threads Without Explicit Locking" http://www.boost.org/doc/libs/1_64_0/doc/html/boost_asio/overview/core/strands.html 
Ok there's a lot of things to chew over here. I will concede I have no idea if what I'm doing is correct, but hopefully we can get to the bottom of this together. &gt; asio_handler_invoke is not something that you typically need to call directly, especially on the final completion handler. The documentation doesn't read like that to me. It reads like it's saying you *have to* call this hook if you want to maintain the guarantee that the completion handler runs in the right context. Your initiating function hasn't got direct access to the users strand, so you can't use **stand::wrap** or **strand::dispatch**. If you look at the example underneath [asio_handler_invoke](http://www.boost.org/doc/libs/1_64_0/doc/html/boost_asio/reference/asio_handler_invoke.html) it does just that, but obviously the default (for simple, unwrapped callables) is a direct call. I've been following advice from Tanner Sansbury as posted on StackOverflow - [How resume the execution of a stackful coroutine in the context of its strand?](https://stackoverflow.com/questions/26694423/how-resume-the-execution-of-a-stackful-coroutine-in-the-context-of-its-strand) and have been experimenting with how handler invocation and result.get() works with stackful coroutines. &gt; It is stated that "internal handlers can be dispatched across any number of threads not on the users strand". This is incorrect according to the Boost.Asio documentation Maybe they shouldn't be dispatched across multiple threads, but nothing in Boost stops from this from happening. For example, looking at your tutorial... you haven't used a strand anywhere. What stops the calls to **async_read** and **async_write** inside **echo_op::operator()** being dispatched on another thread? These functions only take an I/O object (the stream), which in turn only knows about the io_service, which in turn can have many threads running through it. &gt; However, post only allows nullary handlers (handlers whose call signature contains zero parameters). Most completion handlers need an error code at a minimum, possibly more parameters. How do we bind those arguments in a way that preserves the io_service guarantees? I have a composed operation called async_init() and, if it discovers that initialization is already in progress, does this: handler_type handler (std::forward&lt;CompletionToken&gt; (token)); // A thread-safe check is done here to determine if initialization is currently in progress, if so it does... io_service_-&gt;post ([ this, handler = std::move (handler) ]() { async_init (std::move (handler)); }); My child handlers call asio_handler_invoke like this // 'handler' here is a copy of the handler constructed from the completion token in the initiating function // 'ec' is the result of a child async operation (a timer in my case) asio_handler_invoke ([ h = handler, ec ]() mutable { h (ec); }, &amp;handler);
Agreed. This whole article says that the borrow checker does that, when in fact it does something else completely different. What the article really explained is how to mimic Rust's move-by-default behavior and how to make types not `Clone` and `Copy` by deleting the copy constructors. Still pretty useful article, and very practical too. It's just not what the borrow checker does.
That's a fair use-case
Anyone who is reading or participating in this thread - if you are getting the impression that this advanced form of asynchronous programming is hard, then you are right! It is very tricky to get right. That is why I have developed this tutorial, and the Beast utility classes which ease some of that burden, so that you can get correct behavior in your own asynchronous composed operations with a smaller time investment.
&gt; "Calls to asio_handler_invoke must be made from a namespace that does not contain overloads of this function" Doesn't my lambda meet this requirement, given that I haven't created any such overloads? The type information of the users completion handler is maintained within the lambda, and asio_handler_invoke takes a pointer to this type as it's second argument. ADL therefore should find the appropriate overload by looking in the namespace where this type lives. After all, I haven't used any 'using' directives to get these calls to work, and ADL can't be using the first argument (which is a lambda in my own namespace). I can confirm this, because when I replace '&amp;handler' with 'nullptr', it won't compile. I can see why calling a wrapper in a neutral namespace to guarantee ADL is used is a good idea, but I don't think it has any effect when you already control the namespace and don't need to create your own dispatch method.
Your lambda fails this invariant: *"...all intermediate handlers should be invoked using the same method as the final handler"* [**1**] First, recognize that your lambda is itself an intermediate handler. When **io_service::post** invokes your lambda, it will use the default implementation of **asio_handler_invoke** which is simply to call the handler directly [**1**]. Now consider the following: struct my_handler { void operator()(); template&lt;class F&gt; friend void asio_handler_invoke(F&amp; f, my_handler*); template&lt;class F&gt; friend void asio_handler_invoke(F const&amp; f, my_handler*); }; This declares a completion handler which defines its own method of invocation (the overloads of **asio_handler_invoke**. Consider what happens when this statement executes: ios.post(my_handler{}); Eventually Asio will wind its way down into **boost::asio::detail::task_io_service::dispatch** and execute the following line [**2**] boost_asio_handler_invoke_helpers::invoke(handler, handler); Since the type of **handler** is **my_handler&amp;** it will call this overload: asio_handler_invoke(my_handler&amp;, my_handler&amp;); This provides an opportunity for that user defined overload to use whatever custom strategy it feels is necessary to invoke the handler. Now consider the following statement: ios.post([auto h = my_handler{}]{ ... }); As before, Asio will wind its way down into **boost::asio::detail::task_io_service::dispatch** and execute the following line: boost_asio_handler_invoke_helpers::invoke(handler, handler); Since the type of the lambda is something like **lambda_f9af36d2531**, it will call the default version of **asio_handler_invoke** which looks like this [**3**] inline void asio_handler_invoke(lambda_f9af36d2531 const&amp; function, ...) { function(); } You can see that **my_handler**'s overload of **asio_handler_invoke** is not called right? I hope this is clear, its definitely a little confusing but I think you will agree. And thus, we have violated this invariant: *"...all intermediate handlers should be invoked using the same method as the final handler"* References: [**1**] **asio_handler_invoke** http://www.boost.org/doc/libs/1_64_0/doc/html/boost_asio/reference/asio_handler_invoke.html [**2**] **boost::asio::detail::task_io_service::dispatch** https://github.com/boostorg/asio/blob/7a79c157fc231faa818ec88b80c2b2fd4d32d70b/include/boost/asio/detail/impl/task_io_service.hpp#L37 [**3**] Default handler invocation hook https://github.com/boostorg/asio/blob/7a79c157fc231faa818ec88b80c2b2fd4d32d70b/include/boost/asio/handler_invoke_hook.hpp#L65 
&gt;"Calls to asio_handler_invoke must be made from a namespace that does not contain overloads of this function" &gt;&gt;Doesn't my lambda meet this requirement, given that I haven't created any such overloads? No. The requirement applies to those who are *calling* **asio_handler_invoke**. And the only place that users should be calling this function is from their own overload of **asio_handler_invoke** for their completion handler. Example [**1**]: template&lt;class Function&gt; friend void asio_handler_invoke(Function&amp;&amp; f, echo_op* op) { return beast_asio_helpers::invoke(f, op-&gt;p_.handler()); } Since the enclosing namespace of **echo_op** has overloads of **asio_handler_invoke**, the call in the body of the function above must be made from another namespace. That's what **beast_asio_helpers::invoke** is for. References: [**1**] echo_op.cpp https://github.com/vinniefalco/Beast/blob/acd1f4f8c5f02facb87381cca823edfcb230ab69/examples/echo_op.cpp#L107 
There's a get out clause in the asio_handler_invoke documentation that you're overlooking, and it's in the very next sentence &gt; This is required to ensure that **user-defined objects** are not accessed in a way that may violate the guarantees. If I'm writing a HTTPFetcher class with an async_http_get operation, with a bunch of private sockets, parsers, timers etc, and none of my intermediate handlers touch user-defined objects, then I'm golden. Furthermore, unless I accept that i'm creating these objects anew on every request (which would preclude any kind of connection pooling, caching or internal buffer management) I still require synchronization. Even when I'm within a single strand provided by the user, another strand could be running in another thread calling in to different instance that shares some pooled application-wide resource.
&gt; Just wanted to clarify, using safe Rust (eg, code which does not need the unsafe keyword and constitutes the majority of the code in applications and libraries), there is not race conditions. It's statically impossible (assuming the unsafe abstractions are correct. The STD which provides thread abstractions is both small and has a lot of eyes on it, so you can trust them to be thread safe). This is true, if "race condition" is changed to "data race". Rust only stops "low-level" lack-of-synchronisation problems, it doesn't stop arbitrary race conditions (like things being synchronised safely, but in the wrong order). Of course, this is still great, as data races are really insidious, but it isn't quite the magic that guaranteeing never having any race conditions at all would be.
By the way, this lambda: timer-&gt;async_wait ( [ timer, handler = std::move (handler) ](boost::system::error_code ec) mutable { std::cout &lt;&lt; "7\n"; asio_handler_invoke ([h = handler]() mutable { h(); }, &amp;handler); // Works and ADL safe std::cout &lt;&lt; "10\n"; }); will not run in the context of the coroutine, it will run in the context that has **main()** on the stack. This will cause a problem for any non-trivial composed operation since it will break invariants (coroutines are protected by a built-in strand which you are bypassing in the lambda). If you don't believe me, just get a breakpoint at the first line the lambda and look at the call stack :) 
take a look at mine ( https://github.com/bhuztez/borrow )
You got it right this time. The lambda passed to **async_wait** is called from the context of **main**, while **h()** happens in the context of **handler**. It is true that there is quite a bit of boilerplate and attention to details in order to get a composed operation to work exactly correct in all cases, but the reward is more utility for the user who will be largely insulated from this behind-the-scenes work. If you think its bad design, you should open a LEWG issue against the Networking-TS specification stating your case, before it gets voted into the C++ standard library, where it will remain for quite a long time if not forever, in that state. Be sure to include proposed wording for your fix, as issues with proposed wording are taken much more seriously.
Actually the more i think about my code the more it makes sense. I'm guessing 'h()' just marks the coroutine ready (moves it to the ready queue) and calls io_service::poll() What exactly is the problem with this except for the fact that the whole asio_handler_invoke mechanism is pointless? Why not just write the following and get on with life? timer-&gt;async_wait ( [ timer, handler = std::move (handler) ](boost::system::error_code ec) mutable { std::cout &lt;&lt; "7\n"; handler(); std::cout &lt;&lt; "10\n"; }); This is basically what it's doing now anyway and it's easy to verify that 7 and 10 execute on the same stack
Not really a great solution because if your user has an implicit strand (for example, just one thread calling io_service::run) they are paying for an unnecessary strand dispatch.
Yeah I don't know I think that headers are simple and maybe having the option to use either wouldn't hurt. It makes alot of sense considering you are just referencing another file
5.6 is also LTS.
As someone coming to rust from mostly using C++, I found using rust really made me think about memory safety much more than befure. I think it can help improve how one approaches C++ programming when it comes to this issue as it forces you to pay attention to it.
Without modules, non-template code goes in the implementation file, but template code has to be in the header file (but not inline). With modules, template code doesn't need special treatment.
Ah for some reason my brain didn't consider 5.10+, I was thinking that after 5.9 came 6.0.
&gt; If you think its bad design, you should open a LEWG issue against the Networking-TS specification stating your case What really gets me about this is that N4045, which claimed to be a general mechanism for building async operations, has no equivalent for asio_handler_invoke, and gives examples where you call handlers directly aka 'handler()'. Look at the wait_op example. If such a hook is generally necessary, where is the revised proprosal? I also see no mention of such a hook in the Networking-TS (N4588) either, so I'm very confused.
Having the same background as you did (C++ first, then Rust), I also think that learning Rust has improved my C++. Before, I when I had an intuition that something looked wrong, I'd try to use experience/imagination to see if there were situations where it could go wrong, which was somewhat hit or miss. Now, I just use Rust principle: **Aliasing XOR Mutability** which underlies the borrow-checker, and think to myself "Would Rust allow this? And if not, why would it complain?" and it helps me reason in a more principled way about whether what I'm doing is OK or not.
Ok, that's good news. I also don't see any mechanism inside Asio that allows intermediate handlers to run on the users coroutine. How could that ever be so? After you call result.get() the coroutine is blocked waiting for a return value on the stack, so stealing that stack would require the function that calls yield on the coroutine to be able to wake up spuriously, check if that value is ready, and then call io_service-&gt;poll() if it is not, would it not? It seems your suggested breakpoint check produces the result I would expect. 
You can do #include&lt;file.cpp&gt;. 
I hope they get rid of MOC. 
Is your disc-based hash map implementation available on GitHub?
I haven't delved too deeply into it but this looks quite interesting! Especially that it is header only with minimal dependencies. Does this function similarly to NuDB? I would be interested to know what the differences are (I am the author) https://github.com/vinniefalco/NuDB
There is a RC: https://blog.qt.io/blog/2017/05/09/qt-creator-4-3-rc1-released/
It's not going to be happening any time soon. I don't see any problem with it, since C++ doesn't offer it through the language.
I feel that. But on the other hand, it does make coding easier by using meta-programming. I wish, C++ would add some feature like that, but I don't know, if it's possible?
I guess developers don't like x.10+ versions.
Which they got written in build directories.
what does this mean ? 
I think the biggest difference is that reads, writes and deletes should all be very fast. Other than that it is probably a little simpler and likely has less features as far as I can tell. It doesn't use buckets and just uses linear probing, which works in general since any key+value that is larger than the block size will use multiple blocks. This implies that the slots for the hash-map will be sparse. Hopefully that makes sense without much context. There is an in depth explanation in the comments of simdb.hpp.
Yeah, I think that's pretty accurate. 
Makes for an annoying sort :)
I am still confused as to the complaint about header files.
&gt; I am almost 50, I have worked in many places in more than one country and I have never seen people doing it. I don't know what to tell you. I've worked for 3 large companies and 2 of the 3 did this. Boost also does it (see BOOST_USE_WINDOWS_H) &gt; Why do you say that pch are a hack? Primarily because they force a tradeoff that leads to leaky include habits and changes in the order of include files. Example: How many PCH files should you have in your project? At one extreme you have one PCH file and you need to be selective to what you put in it. Can't put too much or you will slow down the compilation of smaller cpp files. Can't put too little or you won't see a benefit on bigger cpp files. Regardless, some files will be including things they don't need and can silently inherit a dependency they didn't mean to. Furthermore, because the PCH needs to be included first, it changes the order of include files from that which is listed in the cpp file. I don't like that. At the other extreme you can autogenerate a PCH file custom for each cpp file. But with this approach you probably only want to put stable headers in there (boost, std, platform headers, etc) so again you're changing the order of includes. But what's worse is that by autogenerating the PCH, you can end up with so much stuff in it that compilation is slower because the disk I/O starts to dominate (PCH files are rather large). In between is maintaining a PCH by hand or automatically per module or directory, etc. But regardless of what you do, in some files you're dragging in more than you need and in all files you're changing the order of includes.
Good points. About pch leaking into what is included, unwanted dependencies etc: to my knowledge, the way to avoid it is to have a build that doesn't use pch. That checks for issues. But, use pch for developer builds. They are most important to be quick.
There is not such a thing as GCC 5.0. It gies like this: GCC 4.9 -&gt; 5.1 -&gt; 6.1 -&gt; 7.1 | \-&gt; 6.2 -&gt; ... \-&gt; 5.2 -&gt; 5.3 -&gt; 5.4
Compile time reflection is being discussed for C++2x. However some of the MOC features can be achieved with current template meta-programming, but it isn't portable across all compilers the Qt guys want to support.
Qt is pretty old library, before the days that STL was part of C++ compilers. Even nowadays I guess they might have customers using compilers that aren't fully C++ compliant in regards to STL implementations, or customers that don't want to use it.
It is hard to kill C as long as we having UNIX systems around, or POSIX compatibility for that matter. Any successful system programming language is kind of married with the OS that gave birth to it. Many business still use Cobol, because maintenance is cheaper than rewriting the whole stuff into language X. At least those of us in platforms not so UNIXy can hope for better languages, even for low level coding. 
The best thing you can do is to frequent the C++ resources on the net. www.isocpp.org has a lot of information not the standard, though not a good place to learn. Of course right here on Reddit there is a C++ resource. For a language reference you have: http://en.cppreference.com/. Someplace on stackoverflow there is a recommended reading list. Most of the books I have read are rather dated at this point so I have a hard time making a personal recommendation.
[Respek](http://cdn.chud.com/e/ed/ed9550cd_respek_small.jpeg)! I've done smth similar ~15 years ago, only back then we didn't have C++11 :) Few questions after skimming through source code: * what platforms are supported? * what compilers are supported? * how do you ensure your operations are lock-free? (I don't see any is_lock_free calls in the code) * why to read value I need to look it up twice? (one -- to get a length, another -- to get data) what if key gets deleted in-between these calls? * from description it isn't clear how blocks are connected to number of key-value pairs it can store. Can you clarify? * what happens if put() can't find any space? 
Tell you what. I program in C at work. My colleagues never mention safety. Not just memory safety. Any kind of safety. Lately, We start doing multithreading. But we never talk about thread safety. When I caught a function returned a pointer out of mutex protection, my colleague say it had nothing wrong because the object never changed. And then I found the object changed somewhere. We never talk about type safety. Lately, a colleague starts converting pointers to void* before passing into a function, and then convert it back inside the function. The best part? My team leader thinks it is a good idea and I have to follow it. I am not saying every C people are that hopeless. It's just... some of them simply don't aware of the whole concept of "safety", memory or thread or type or whatever. It is impossible for them to appreciate safe languages or safe practices. In their world, there is no such thing.
 &gt;* how do you ensure your operations are lock-free? (I don't see any is_lock_free calls in the code) When would a function with that name ever appear in lock free code? 
I really don't think the subject is planted, it is a real concern for many developers. As for plain old C it really should die in the same way that BASCI, COBOL and many other languages have more or less died.
I would expect that in 100 years computers would be writing their own code from high level human requests. Seriously I'd expect that most of the current trendy languages like RUST, Swift, Go, and what ever, will have died off; replaced by new tech that is human readable but optimized for computer generation. The fact is, you can pick up the most modern language you can find, and realize that technology wise it doesn't offer a lot above C as C is now. Sure the people using the languages think they are the best thing since slice bread. Objectively though memory safety isn't a huge step forward. You still have human programmers keying in detail at a very fine deal to generate useful software.
But what if the key was deleted and then the same key but with different value was inserted?
I currently program in C++ and Java, and for many years I programmed in C. Everything is a tradeoff. Unfortunately, C is a powerful and (superficially) simple tool, and not everyone is mature enough to use a tool like that responsibly: it's a bare razorblade in a world full of safety-box-cutters. The safety you get in other languages is not "free": it's built on restrictions, and often, even when all the restrictions are simplified at compile-time and don't force/encourage programmers to "do it another way", the resulting code is significantly longer and more "complicated". The harder it is to understand what code is doing, the harder it is to find mistakes in code reviews or maintain the code when it needs to be updated. The more surprising side-effects a language creates as it adds this complexity, the more likely there will be subtle language-induced side effects that people might not know, appreciate, or understand. When designing a language you can generally trade any of the following for some measure of another: verbosity, readability, performance, and safety. tl;dr: there's no substitute for responsible programming practices. Languages are ultimately tools that each make tradeoffs, and choosing the right tool and a responsible wielder of that tool are as crucial to overall success as the tool itself.
Yeah, sure. PCH trades build speed for added complexity. I have seen people build retail with no pch (risk) as well as having that other build config (work).
Yeah I was tired when I posted that I was complaining about them. I was saying I like them and I wish rust had that option.
Then the get() will read that key instead. If the buffer isn't large enough to hold the new value, get() will return false. get() does need to be changed to return the actual length it read though. It can be used anyway, but I think that will be a high priority fix. 
&gt; Come talk to me when you've ported something built atop Win32 overlapped I/O over to Linux. Or completion ports ...or RIO socket code.
I don't know. For some reason GCC developers decided upon such a numbering scheme. In their scheme, `x.0` is a development version, and when it reaches release, the first release in this series is named `x.1`, followed by patch releases `x.2`, `x.3`, etc.
Yeah, but every time a developer has to write something for you to interact with OS X syscalls, that means new lines of C get written by someone. Hence why I love the approach taken by Google and Microsoft where trying to use C on their OSes is an exercise in pain. It is doable, but productivity goes almost down to zero, given the amount of FFI boilerplate. Same can be told about Apple with Swift, but there is still too much UNIX under Cocoa and UI Kit, which probably will never go away.
C also did not offer much about other languages back at its day. Actually back when MS-DOS developers were starting to adopt it, it was quite bad compared with Turbo Pascal, regarding the language features. But C had UNIX adoption by the enteprise and the rising FOSS community behind it, so here we are now enjoying its security flaws, which also plague C++ given the language's compatibility.
I would start with the comments at the top first if trying to get a clear picture of how it works. The short answer to your questions is that it works the same way regular lock free algorithms work - atomics. The most fundamental atomic operation is compare-and-swap, which will change memory only if it matches a certain value, while not letting other operations modify the memory in between the comparison and the write.
**Company:** [DarkVision Technologies](https://darkvisiontechnologies.com) **Type:** Full time **Description:** See below. **Location:** (North) Vancouver, BC, Canada **Remote:** Preferably full-time, on location. However, we're open to a part-time split office/work-from-home setup (if you're still in school for example), provided you reside in Vancouver or surrounding cities (we'd like face-to-face contact at least one day a week). Worth mentioning: up to 8 weeks of vacation a year. **Visa Sponsorship:** Not at this time. **Technologies:** C++11/14, Windows (x64) &amp; PetaLinux (arm-64), DirectX, CUDA, small amounts of Boost. **Contact:** email me at [suter-at-darkvisiontech.com](mailto://suter-at-darkvisiontech.com). Don't worry about a cover letter -- send me a resume and let's start the conversation from there. **About DarkVision:** DarkVision Technologies Inc. was founded in 2013 by a group of experienced entrepreneurs that have expertise and a track record in developing and commercializing imaging technologies. The company has developed a new ultrasound-based imaging technology used to inspect the inside of oil and gas wells to improve well integrity and minimize environmental impacts. The company’s first field-ready hardware has been designed from the ground up including the ultrasound transducers (designed and built on-site), the mechanical housing (a 15,000-psi pressure vessel) and the electronics (a custom FPGA and arm SoC Architecture running an embedded Linux). Our image processing pipeline processes up to 20 Gbits of data every second to create visually compelling and intuitive datasets that can be used to find small cracks in wells that can be many kilometers long. Our team consists of experts from machine vision, medical imaging, aerospace, and computer graphics sectors who have come together to revolutionize the way oil and gas wells are inspected and visualized. With a number of North America’s largest oil and gas companies already secured as early customers, DarkVision’s flagship product is now making its debut in the field. **Why DarkVision:** We’re not a typical oil and gas service company. We’re not your typical 'app 2.0' or LOB company. And we're not a 20-year science experiment that never delivers a product of value. What we are is a technology company that has chosen to solve a critical and real problem for one of the largest industries in the world. We combine the right balance of big-picture thinking with pragmatic plans to develop technology that leaves the lab and works in the real world to solve our customers’ problems. **Position Description:** We are seeking to recruit a talented software engineer to develop our embedded, desktop and cloud applications. The right candidate loves modern C++ and loves to write high-performance data processing, rendering and image processing code. **Responsibilities (include, but are not limited to):** * Implement the 3D visualization engine in C++ on windows. * Implement computer vision/image processing algorithms on an ARM SoC embedded Linux platform. * Implement data processing pipeline code for post processing ultrasound data for defect detection. * Implement efficient data streaming algorithms for a responsive end user experience while browsing data sets that contain hundreds of gigabytes of information. * Implement stateless web services in C++ including database communication. * Implement cloud services on Amazon Web Services including deployment and configuration. **Qualifications:** * Bachelor of Computer Engineering, Computer Science, or related field * 2-5 years C++ experience (variable depending on the candidate) * C++11/14 and Boost experience **Bonus Qualifications:** * DirectX/OpenGL/Vulkan/OpenCL/CUDA experience * Image Processing, Computer Vision and Machine Vision experience * Web Services and Database development experience * Amazon Web Services experience **Compensation:** * Competitive salary * Full benefits * Up to 8-weeks vacation (yes 40 days!) 
&gt; Windows is only designed to make thread creation cheap Lol. I was playing with my newly born thread pool few days ago -- Windows creates threads real fast... First few hundred or so... Once you hit some threshold -- it gets quite slow. :)
&gt; even after systems are so far away from the C system model sadly the systems that C models are from the 40s... if they withstood 70 years, I think they can still survive one hundred more.
&gt; Cross Platform - Compiles with ... I meant hardware platforms :-). Is it only x86 and x64? You may want to add some defines to make sure this code fail to compile on unsupported platforms... &gt;&gt; why to read value I need to look it up twice? &gt; You don't if you use one of the C++ functions that will give you back a string or a vector Are you sure? This looks like two lookups to me: bool get(str const&amp; key, str* out_value) const { u32 vlen = 0; len(key.data(), (u32)key.length(), &amp;vlen); new (out_value) std::string(vlen,'\0'); bool ok = get(key.data(), (u32)key.length(), (void*)out_value-&gt;data(), vlen); return ok; } &gt; Technically the number of blocks is the same as the maximum number of key-value pairs it will be able to store So -- you use one block per KV-pair? &gt; ... if every key-value pair fits into a single block What happens if it doesn't? Looks pretty good, tbh. Good job! I'll dig in the code in spare time -- may will spot smth. :) 
What complaint?
It was written under contract for a client. Oh, and that 1M op/sec is per CPU core, it scaled linearly with extra cores at about 1.5x faster per doubling of core count. But I've promised you code Vinnie, and I intend to deliver you something AFIO based on how I suggested NuDB ought to be by the end of this summer.
&gt; Since it uses only memory mapped files, persisting to disk might be low hanging fruit, though with all the OS specific parts, the windows side will probably be the tricky part. I tried calling FlushViewOfFile() as a quick test, but it didn't seem to work immediately. If you add disk persistence, I think you'll run into lots of other fun like TLB shootdown overheads. You need a very different design for fast disk persistence across many cores, it's not just a case of using real files to back your memory maps, you'll find all sorts of unhelpful behaviours like delayer allocation and badly timed page zeroing by the kernel will wreck your performance.
I think it's a matter of what languages people already know how to use, what they're being taught in the first place, and what they are required to use in their job.
&gt; The best part? My team leader thinks it is a good idea and I have to follow it. That's not a terrible idea, and it's a common way in C to implement a form of information hiding. If this particular type pointer is only ever exposed as "void*" to consumers of the API, and the definition is never provided in a public header, you have a primitive form of information hiding that lets you extend or change the underlying structures with new library releases. I'm not saying they're doing something like that, but it's not terribly uncommon for C libraries to be coded up this way. Also, there's nothing wrong with returning a pointer outside of "mutex protection". Why do you think this is a problem? I'm not sure what you mean, exactly. As a counterpoint about lumping all the C people together in the same category, I can't tell you the number of Java programmers I've dealt with who think because they are writing code in a managed language with a GC, they can't have memory leaks. That's astounding to me. 
&gt; from the 40s Wut? FORTRAN appeared in 1957. Most folks don't count FORTRAN as a predecessor to C, but there are a few who say it has to because it evolved CPL, which evolved BCPL, which evolved C. Maybe I don't understand what you're suggesting here, but if you take out the "C" from "C system model", maybe... yeah. 
I was talking about von neumann machines (to which c, fortran, and others map quite closely vs for instance LISP, Prolog, etc)
Ahh, okay. That said, I have heard other people complain about them.
&gt;Ahh, okay. That said, I have heard other people complain about them. Yeah I'm saying they aren't that bad.
therefore you build the handle yourself
Why should I waste dozen of hours building a handle for a deeply flawed tool when I can just get some real knife and use it.
.... If you really want people to look at it upload to github. 
Opaque pointers with the structure types themselves give you some degree of memory safety. I'll get a warning if I try to pass a foo* to a function expecting a bar* (both opaque). Not so if it expects a void*
because no knife will ever be as sharp ;-p
What? C is not a particularly powerful programming language. Name 3 features that make C "sharper" then other system programming languages.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [steemit/steem/.../**chainbase** (master → b197a8a)](https://github.com/steemit/steem/tree/b197a8a00da3f5b3cec8d0ebf7aee9647d6f6fd1/libraries/chainbase) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dhkdkpe.)^.
C++14 thank goodness, that will make my life at work a tad smoother! Now if only we could get some Clang action...
Webengine is a downgrade so far as I'm concerned. You can't do any of the things I wanted in it without implementing a rudimentary user script system in it. It is good for user controls, so far as it might be less likely to hang, but it isn't what I wanted when I was told that Qt might be what I was looking for. 
Interoperability, speed, size
I've tested it only on x64 Windows, Linux, and OS X. I don't think there is anything stopping it from working on AArch64, POWER or more exotic platforms that still have 64 bit atomics, but I haven't looked into them and don't have any way of testing on them. Yes the convenience function does the len() and get() calls for you. It does them because it stores arbitrary bytes as keys and values, so you need to know how large a value is to allocate memory for it. &gt; What happens if it doesn't? A linked list structure of blocks is made out of indices. A BlkLst struct at a certain index will contain the index to the next block and so on until hitting LIST_END. &gt; Looks pretty good, tbh. Good job! Thanks!
asm beats c on both speed and size. Rust beats it on speed in some cases. Interoperability is really the only point you have and that is rarely required.
I hate exception, I never used it in my code...
The thing is not many people are going to be willing to download and unzip some files. Github is much better for things like this and people can fork your code if they need plus open issues, etc. Also, just in case you don't know, if you have a .edu email you can get the github student pack for free. 
You can you Qt Webkit just as fine. They are reintroducing new up-to-date version as a TP with 5.9 (if they make it in time) or 5.10. https://github.com/annulen/webkit/releases
&gt; I immediately deem such code as problematic to use until further detailed analysis. Well that's a good attitude to have in any circumstance.
&gt; Come talk to me when you've ported something built atop Win32 overlapped I/O over to Linux. Over my career I've come to move away from overlapped I/O in Windows, it always feels like spaghetti. I now prefer to use a thread with blocking I/O. Which is portable if you use standard threading.
Self-documenting code is valuable.
Why do you think it is consumer API? No, they are all internal. All are internal to the project, some are internal to a single file. Returning pointer out of mutex protection is of course problematic. The whole point of mutex lock is to protect data from data race. Returning pointer out of protection encourage data race. Example: typedef enum { FILED_NAME_A, FILED_NAME_B, FILED_NAME_C, FILED_NAME_D } field_name_t; typedef struct { pkg_mutex_t mutex; char field_a; short field_b; int field_c; long field_d; } pju_info_t; void *pju_info_get(void *obj, field_name_t field_name) { pju_info_t *pju_info = (pju_info_t *)obj; void *result; pkg_mutex_lock(pju_info-&gt;mutex); switch(field_name) { case FILED_NAME_A: result = (void *)&amp;pju_info-&gt;field_a; break; case FILED_NAME_B: result = (void *)&amp;pju_info-&gt;field_b; break; case FILED_NAME_C: result = (void *)&amp;pju_info-&gt;field_c; break; case FILED_NAME_D: result = (void *)&amp;pju_info-&gt;field_d; break; default: result = NULL; } pkg_mutex_unlock(pju_info-&gt;mutex); return result; } void pju_info_set(void *obj, field_name_t field_name, void *v) { pju_info_t *pju_info = (pju_info_t *)obj; pkg_mutex_lock(pju_info-&gt;mutex); switch(field_name) { case FILED_NAME_A: pju_info-&gt;field_a = *(char *)v; break; case FILED_NAME_B: pju_info-&gt;field_b = *(short *)v; break; case FILED_NAME_C: pju_info-&gt;field_c = *(int *)v; break; case FILED_NAME_D: pju_info-&gt;field_d = *(long *)v; break; default: } pkg_mutex_unlock(pju_info-&gt;mutex); } Finally, I am not lumping all C people together. Quoting myself: &gt; I am not saying every C people are that hopeless.
C is a blade without an handle, being held with bare hands, where each movement produces little blood drops, regardless how smooth it was.
Also it's much easier to write compilers and get C code to work in weird platforms. Hence why C still is King in embedded dvcs. In general, C is the way to go for writing system/kernel level stuffs because you don't care much about data abstraction, but you want the compiler to write the smallest amount of instructions - almost line-by-line - to avoid the craziest fuckery.
The top answer says that everyone uses event based nonblocking IO instead of async IO because millions of threads are bad. But the lacking kernel support for async IO is the prime reason that you need threads in the first place to do async IO.
I agree there is no substitute for taking responsibility, but I disagree with you on several other points. &gt; The safety you get in other languages is not "free" If you mean that languages other than C have slower runtime performance then I disagree. C++ and Rust can both provide the compiler with more information about the actual use of data so it can better optimize. Things like casting void pointers damage performance, because the optimizer has no clue what that value actually is used for and cannot make some optimizations because of this. This is born out in benchmarks of highly optimized code. To continue down the path of optimizing compilers, it scary how close to C some languages are getting that we have traditionally thought couldn't compete; in some benchmarks Javascript is only half the speed of C, (which is much closer than most want to admit). If you are talking about code clarity or ease of finding bugs, then I must ask why the vast majority of CVEs are against C code event the vast majority of code is not C. Sure there is a great deal of C out there, even if we say 30% of all code is C, the amount of vulnerabilities is so much higher than 30%. The relative difficult of writing buffer overflows and use after free bugs in other languages is one obvious mechanism that explains this. I think it clearly points to an issue with the language itself. &gt; C is a powerful and (superficially) simple tool, and not everyone is mature enough to use a tool like that responsibly I do not think anyone is "mature" enough for the level of responsibility C requires to write well. 
Would it be so hard to write a Curl replacement in Rust? If someone does this and it is ready for use for, let's say, 80% or Curl uses, then what happens the next time there is a critical vulnerability found in Curl? Curl is an easy one because it is a small standalone library and program. If C interop is strong can't parts of other programs be replaced? Isn't that exactly what is happening with Firefox and Rust replacing the renderer?
BUNICODE is the new BASCII
I didn't downvote you but I can guess why you were downvoted. &gt; think that c will become drastically more memory safe with the use of "top down" style debugging techniques. Things like fuzz testing This doesn't make C memory safe, it just fixes memory bugs in C code. Writing memory bugs in Rust or Idiomatic C++ is just plain hard to do and that is why those languages are considered safer.
I am not aware of any. Sadly C devs will Highlight Linus' singular genius as their example of why C is good without every reading his C. His C is really good.
No, it's not the same thing when you have multiple opaque types, and you try to pass the wrong one to a function. Or, example like this: char* device = "my_device_id"; my_lib_device_t the_device = my_lib_open_device(device); my_lib_device_do_something(device); This will happily compile if `my_lib_device_do_something` takes a `void*`, but not if it takes a `my_lib_device_t`. 
That's an unofficial fork of the old QtWebKit code, with no official releases yet. It looks very useful already, though.
&gt; Still, changes in the desktop world occur, such as Wayland coming out, and they very promptly added support. Nope, they added support for wayland mostly for it to be used on embedded devices (look at Qt Compositor) and Jolla. The quality of the Qt wayland platform plugin is so bad, that KDE is currently thinking about forking the code, also due to the infamous Qt upstreaming process (endless awful reviews that take way too long, even for trivial patches). &gt; And if, like me, you want to target desktop and mobile from a large core Qt-based codebase, you wouldn't say "they only care about mobile now"... you're grateful you can re-use that core codebase and deploy to all those platforms. Except that Qt Widgets doesn't work that well on mobile and Qt Quick not that well on desktop. Quick Controls (2) are lacking and third-party collections aren't great either. &gt; As for OP's bug, it has 3 votes, 3 commenters (including the poster) and 4 watchers. I haven't seen it myself and maybe it's quite bad, but surely those numbers give an indication as to why it possibly hasn't been considered particularly high priority. Plus of course, it's open source, if it's really killing you could look into it. Particularly if it's a regression because you could do a git bisect and figure out which commit caused it. That's not the only example, there are many many more like this. Just search for open Qt 5.8 bugs, they gave up on the 5.8 branch entirely (no 5.8.1 will be released) and skipped to 5.9 directly. I'm one of the Qt maintainers for a linux distro (openSUSE) and we skipped Qt 5.8 for multiple reasons, for instance Wayland was completely and utterly broken for desktop platforms (mostly due to https://bugreports.qt.io/browse/QTBUG-58423)
What a clickbait! 
Book recommendation: [[PDF] The Art of Multiprocessor Programming](http://www.e-reading.club/bookreader.php/134637/Herlihy,_Shavit_-_The_art_of_multiprocessor_programming.pdf)
&gt; Based on what? The benchmarks I've seen say that Rust and C++ are about the same speed as C at best, [...] The classic example is of C++' `std::sort()` vs C's `qsort()`. C++ tends to outperform C wildly in these tests: &gt; STL’s sort runs 20% to 50% faster than the hand-coded quicksort and 250% to 1000% faster than the C qsort library function. Source: http://www.geeksforgeeks.org/c-qsort-vs-c-sort/
Can I gave that Google Plus blogpost? Failed to find it using traditional methods. Sadly, I think that Fuchsia is in the same league like Google Wave or Google Glasses - aka "ahead of its time". You don't need it on traditional devices and AR is really far from getting general (or any) adoption. Sorry, no computer games in real life yet... 
Firefox new rendering engine is developed in Rust because they need to parallise the rendering stage, last time I checked. No - 80% is not enough. What is more important is that LLVM tooling doesn't have the same adoption even as GCC. And we have miriad other compilers and devices. With C - pick your vendor compiler and you are good to go. 
 anttirt@anttirt-ubu64:~ $ cat test.c struct opaque_a; struct opaque_b; struct opaque_a* make_a(void); void thing_a(struct opaque_a*); struct opaque_b* make_b(void); void thing_b(struct opaque_b*); void* make_c(void); void thing_c(void*); void* make_d(void); void thing_d(void*); int main(void) { thing_a(make_b()); thing_c(make_d()); } anttirt@anttirt-ubu64:~ $ gcc -Werror -Wall -c test.c test.c: In function ‘main’: test.c:18:10: error: passing argument 1 of ‘thing_a’ from incompatible pointer type [-Werror=incompatible-pointer-types] thing_a(make_b()); ^ test.c:5:6: note: expected ‘struct opaque_a *’ but argument is of type ‘struct opaque_b *’ void thing_a(struct opaque_a*); ^ cc1: all warnings being treated as errors 
&gt; Writing memory bugs in Rust or Idiomatic C++ is just plain hard to do While you are right about Rust, the following is "modern"/idiomatic C++: auto times(int a) { return [&amp;](auto&amp;&amp; v) { return a * v; }; } auto six = times(2)(3); Spot the bug. No C++ compiler even warns about this. If you argue that this is not common/idiomatic/modern C++, then maybe your C++ isn't "modern enough", since this kind of code is extremely common when using range-v3 and the STL2 to make custom range adaptors: auto less_than_times(int a, int b) { return view::filter([&amp;](auto&amp;&amp; i) { return i &lt; a; }) | view::transform([&amp;](auto&amp;&amp; i) { return i * b; }); } for (auto&amp;&amp; v : {1, 2, 3, 4} | less_than_times(3, 5)) { // ...2, 4, 6... }
You don't even need that mutex. It's not doing anything. 
c++90 `auto` is deprecated (see comments above for more details).
In terms of functionality, Rust can do it. The issues are the amount of work that needs doing, and also platform availability. At this time, Rust is dependent on LLVM, and as such is limited to the platforms that LLVM supports.
So you mean the C (actually B) `auto` not the C++ one.
Certainly far from dead. Slightly less popular than Swift, Obj-C, even Ruby.
That's interesting, thanks for correcting me and providing some insight. I guess we all have our own perspectives based on our own usage and I've probably been lucky in not hitting many of these issues. It's certainly interesting to know what problems others are seeing.
Well, every tool you use to avoid C interfaces from the OS do use this C interface at some point. It's not because they're hidden for you that you could do without them without a massive undertaking of rewriting every single runtime and library you depend on, nevermind the OS and it's standard libraries.
It's aiming to be part of standard Qt packages again: http://lists.qt-project.org/pipermail/development/2017-May/029795.html
I would seriously reconsider my approach if my design required hundreds of threads (or a magnitude more threads that there are hardware threads).
Ooh yes about time that the VFX industry got c++14 by default. now wont be stuck on gcc 4.8.3! (i secretly compile new gcc versions and use them. shh dont tell anybody)
OMG also just noticed that python will be going to python3 in 2019. 
/u/andralex Can you elaborate on this statement about Rust CFFI? &gt; [30:37] ... and Rust is coming with alien syntax, doesn't play well with C, cannot link well with C, can't call into C code and back, it's completely different from C... I haven't needed to use Rust's CFFI yet, but some libraries I've used do and they are very happy with it. EDIT: this also is discussed a bit here: https://www.reddit.com/r/rust/comments/6bpg90/systems_programming_panel_at_dconf2017_walter/
No! Stop putting words in my mouth! 
It does not. If you want to store multiple values at one key, you would need to serialize those values into contiguous memory.
IIRC, it turns up in template instantiation contexts sometimes, but it's never something you'd write yourself.
Ah yes, good catch. 
Yeah, we actually *made language changes* to retain good C FFI. Not sure what Andrei means here.
No, that's one piece of what he says. Read the whole answer. It never makes sense for sockets, and for files writes are already buffered and reads can be prefetched with fadvise.
Maybe he means that in Rust one needs to wrap C headers manually or using a binding generator, but this seems to be the case for D as well. For example [MPI bindings for D](https://github.com/DlangScience/OpenMPI/blob/master/source/mpi/package.d.in) seem to have the same problems as the [MPI bindings for Rust](https://github.com/bsteinb/rsmpi): - tied to a particular MPI implementation (e.g. OpenMPI, MPICH, ...) - require some glue-code The Rust bindings use a "build script" (`build.rs` + `libclang`) to work around these issues (modifying the wrappers depending on the API/ABI of the implementation used); the D bindings could probably do the same. But in C++ one can just include the MPI C headers of any implementation and be done with it. So... unless I am misunderstanding something, Rust and D are on the same ballpark here: C bindings are easy for 99.99% of the interop, but in the 0.01% of the cases they might require extra logic to handle complex C conventions (e.g. the `MPI_INT` above could be a global object of type `some_custom_struct*`initialized by a static method, or it could just be defined as `2`, depending on the implementation...). 
&gt; If I had a library to open pdf-files with a function... &gt; that uses exceptions for error-handling, I would need to use it as... Why do you think you would **need** to use it so? I suggest to you to go back to your existing error-return code and see how often you do this: result = do_something1(params)); if (!result) return error(result); I bet you that the above is a vast majority of your code. I say that because it is a vast majority of **any** error-return code. From there, the argument that you're making ("see? exceptions are complicated") is **extremely** misleading, because you are taking one example out of context. The reason exceptions are expedient is **exactly because** they cater for the common case ("if error, get out"). Say that there's `do_something_1/2/3`. With error return, it's: result = do_something1(params)); if (!result) return error(result); result = do_something2(params)); if (!result) return error(result); result = do_something2(params)); if (!result) return error(result); ... and you do not see the trees from the forest, every single time. With exceptions, it's do_something1(params); do_something2(params); do_something3(params); The argument you're making is **exceedingly** disingenuous. &gt;My original point was that if a priori you know that exceptions are not the best fit for your problem, not using them (and using something better) is the correct approach. Your original point, the one I reacted to, is this: [Optimizing exceptions when they are in your hotpath means changing the signature of your functions, possibly breaking APIs and ABIs.](https://www.reddit.com/r/cpp/comments/6an103/exceptions_performance_again/dhgkwky/) To which I replied "If I need to keep the ABI and improve performance of thrown exceptions, then I create another API version with error-return." You then invented a password finding scenario where you wanted to treat a non-matching password as an error: [I wrote a small program to brute-force pdf passwords. By design, the hot-path fails 99.99999% of the time.](https://www.reddit.com/r/cpp/comments/6an103/exceptions_performance_again/dhi5cm2/) This, again, is **exceedingly** disingenuous, because 99.99999% failure rate is not normal. Only to that, I replied that you would have been better off using an exception to signal finding a match. I said that because I imagined a deep stack in which at some point a password match is found. and you want to terminate further processing. So I wrongly judged your situation. Sure, I take that back, in an absence of good context, I made a wrong call. Finally, note that you changed your scenario from "I'm cracking for a password" to "I am opening a file". Erm...
&gt; I bet you that the above is a vast majority of your code. I say that because it is a vast majority of any error-return code. Zero, since I use `fmap` (in this case, `and_then`) :/ That is, your example above looks like this: return do_something1(params) .and_then([&amp;] { do_something2(params); }) .and_then([&amp;] { do_something3(params); }); Not as implicit as exceptions, but does the trick. &gt; Finally, note that you changed your scenario from "I'm cracking for a password" to "I am opening a file". Erm... The easiest way to brute-force a pdf password is to attempt to open the file with all possible passwords and stop when one succeeds. 
How are you managing to instantiate that constructor as `path&lt;void&gt;`? The only way I can do so is `std::is_constructible&lt;std::experimental::filesystem::path, void&gt;` but why would you be asking if something is constructible from `void`?
There are some rare cases where this makes sense. For example, it might make sense to move from const objects that have mutable members. Your object may have memoized results which are stored in a mutable cache. Even if the object is const, you could still move the cache.
"Sour**s**e Code" Not lying, that mistake is adorable \^\^ I took your "Console Movement.cpp" and created a pastebin link (1Month valid). The other files seemed not to be relevant. https://pastebin.com/Jtt0h0FD &amp;nbsp; Unfortunately I don't have time to give you actual feedback though, I'm sorry. Keep trying!
Well, it was a test, tbh. But... You need "hundreds of threads" when you deal with a lot of slow I/O -- most of the time you'll have only few threads active. You might say "just use IOCP -- they were specifically designed for that", but (a) it is windows-only construct (with implementation depending on certain retarded thing they did in kernel resulting in all these events/mutexes/etc being rather slow); (b) not every I/O call has related support (OVERLAPPED struct, etc) and I am not writing a driver just to make my stuff work with IOCP. P.S. I could use some sort of multiplexing (support multiple tasks executed by few threads -- effectively emulating hundreds of threads), but it is not always possible -- your code has to be written in certain way (like support non-blocking reads, etc) and often you deal with 3rd party libs.
&gt; Hmm... It is not size of atomics that matter it is your expectations about them. I remember devising a lock-free algorithm where 'unit-of-operation' was pointer+counter (and the idea was that it works as long as no one is able to increment counter 4Gb times). This logic couldn't work on platform that doesn't have atomic operation on data that is twice larger than pointer. You will have to be more specific here about what you mean by expectations. I'm not aware of what platforms aren't able to do fast 64 bit compare and swap instructions. x64 (except for some of the first AMD chips), AArch64, and POWER actually all have 128 bit (aligned) compare and swap instructions as far as I can tell. &gt; Why you need 64-bit atomics specifically? Or you need only atomic pointer operations? In this case it is for having a 32 bit unsigned version and a 32 bit unsigned index pair. This is what the VerIdx struct is. The version is to confront the ABA problem when comparing keys on put() or del(), though there may still be better designs. &gt; So, we do look up twice if we have no idea how large data might be. You can still provide a function that finds key, grabs read lock, allocates memory, copies data, releases the lock. But, yeah -- it is probably not a good idea. Algorithm can be somewhat improved with an initial guess, if guess was wrong -- you just repeat operation with new length. I don't want to do this for two reasons. The first is that the lock (actually a reader count) would be kept longer than possible. The second is that it adds memory allocation (and specifically it would be whatever operator new uses) into the core design instead of keeping it in functions that can easily be taken out. Building in the ability to switch allocators would then make the top level simdb class a template. I am definitely open to suggestions and I don't think what you are saying is ridiculous in any way, but I'm not convinced yet that these design trade offs are worthwhile. This is because convenience functions can be, and are already, built in to simplify the interface. If you think about the scenario where calling get() would fail because of the size that len() gave you, it would mean that another thread is either deleting or changing the key. My thought so far is that this scenario _might_ be uncommon, but also that in the case that the key has changed or has been deleted, you would want to get the updated version or know that it was deleted. I'll give it some thought though, there could certainly be some validity there such as passing an allocation function through a function pointer.
Yes, it's very strict about it, and when the compiler isn't sure if something is safe, it assumes "no". Hence my statement that rust trades simplicity for verbosity: you have to convince the compiler that what you're doing is safe, and that isn't always easy or brief.
&gt; Lol. I bet the first thing user will do is to write his own function to try to avoid double lookup :-). I suggest adding "helper" function on the side (maybe in global namespace) that implements "best effort" approach and has a big red sign that describes everything that might go wrong with it. There is already a get() overload that returns a std::string. I might have cleaned out a version that returns a std::vector, but that does need to be in there. There are probably convenience functions that I'm not aware of, but is a function that just returns a std::vector what you are thinking of?
&gt; In fact, one of the Fuschia OS leads recently did a G+ post on their language choices and why they are using C++ but basically ignoring all the aspects that you seem to revere (because it's unmaintainably complicated, especially when not using the std lib, essentially). Source? Google not returning anything.
Yes... It is non-const, isn't it?
If you're gonna be pedantic you can also say the differences in those benchmarks are due to one using the STL and the other not. Zero to do with the language. But actually, it's not just the difference in algorithm. The language *does* help. From the article: &gt; STL’s sort ran faster than C’s qsort, because C++’s templates generate optimized code for a particular data type and a particular comparison function. If you take the same program written using "the C subset of the C++ language", they will have equal performance: https://rusty.ozlabs.org/?p=330 Only, once you've switched to C++ you gain access to language features that allow you to easily get faster than C. It's true you also get access to language features that allow you to easily become slower than C, but as long as you avoid those in your hot code paths, it's not that hard to be better off using C++ (not to mention the maintenance advantages the rest of your code will receive).
Eh, no. Same-algorithm sort, C++-style, is faster exactly because the compiler can generate and inline stuff. C-style sort relies on pointers to data as well as on pointers to comparison functions which can't be optimized out. C++ code is also smaller (caveat: for *one* template instantiation of the algorithm).
Const r-value reference are very very rarely used. I used them once to ensure that the parameter was a temporary, even if I didn't move from it, and I wanted to call the const overload of its member functions. The parameter was an instance of a proxy class and I didn't want people to accidentally create non-temporary instances of it.
&gt; Would it be so hard to write a Curl replacement in Rust? A resounding yes here. Obviously, rewriting is hard for anything with such a long history, but the biggest difficulty is that * if this keeps the existing C interface, it's still unsafe because of all the existing C callers * if it changes to a better C interface, it is still unsafe because new C callers will bork it, many old clients will not migrate and will therefore stay as borked as before * if it changes to a Rust interface, the world needs to be rewritten in Rust It's **way** harder than you think. It's **way** harder than I think, too - but at least I am not optimistic :-).
Actually, the code has data races even with the mutex. The getter does not do the actually getting. All it does is returning a pointer. The actual getting happens outside the getter. Outside the getter, the pointer is dereferenced, the data is read without mutex protection. If the read happens at the same time when someone use the setter, data race happens.
Yes. I would also note that I *approve* of C++ making those breaking changes. Actually, I would rather it made *more* breaking changes, as there are clearly suboptimal parts of the standard library that could be done better in hindsight. Stability implies stagnation (at the extreme), and that's NOT a desirable property. Of course extreme churn is not desirable either, so there's a balance to be reached.
It can be used with `= delete` in conjunction with a `const T&amp;` overload to disallow that overload's binding to temporaries (the const rvalue reference is a better match and is deleted).
So you fancy ++(C++)?
COBOL still lives on unfortunately.
Yeah it highlight the number of times code was "passed" in the margin
Ha! They can be much better -- orders of magnitude better -- than normal C developers, but to say they can do memory safety without mistakes (which is what your statement sounds like), then I just have to point out that flaws are found in the Linux kernel all the time.
I really like that you Visual Studio guys are here, reading reddit comments and take care of the issues like this was the official bug report platform. *thumbs up*
Can you load things compiled with it into Maya etc? I'd love to hear how you accomplish that, I'd always assumed it was impossible. 
I know one can include coverage info into the coverity from atleast Bullseye Coverage tools but afaik, coverity itself does not provide a way to generate that data.
Damn iPhone! The down votes likely come from programmers that think they are a special class of human. It is a significant problem in the community. I guess the idea that they can eventually be replaced by the very technology they are creating is a huge problem for them to digest. I just see a very different industry in 100 years. Frankly the changes will be like what we have seen in other industries like Mechanical engineering but probably more disruptive. 
The insight you would be looking for is AI technologies which should get there in 100 years. That is a "Programer" should be able to ask a computer to develop a software solution for a problem and wait for the computer to deliver a solution. Im expecting an iterative process where the computer learns from the programmers directions. In other words the computer becomes a partner in development. Basically these days the computer is a slave crunching code and doing little else to move the process along. 
In addition to all the other comments, consider the trick of just accepting the vector by-value: class Key { public: Key(std::vector&lt;string&gt; id) : id(std::move(id)) {} std::vector&lt;string&gt; id; }; That way the caller can pass in either an l-value or r-value &amp; you only need to write the function once and you get optimal performance either way. Use `&amp;&amp;` if you want different behaviour for copy vs move (which would be weird IMO) or if you want to enforce that the caller is providing an r-value (in which case you may want to consider explicitly deleting the `const&amp;` constructor as a form of documentation). This trick is best-suited for constructors (i.e. can be applied blindly). It's possible to construct corner cases outside of constructors where performance is sub-optimal (mainly around `operator=`), although usually you would probably be OK with it anyway in most cases.
And how do you cancel those operations?
No, but it does mean that using it with custom function objects comes with extra overhead (type erasure, possibly with a trip to the heap) compared to a direct call.
We've removed a fair number of older books--but some, despite being old and in many ways outdated, simply don't have more modern equivalents. For example, *Advanced C++ Styles and Idioms*, *Accelerated C++*, and *Large Scale C++ Software Design* are all old and at least partly outdated--but I don't know of anything more up to date that would really replace them.
Yes it is correct in your version, not in OP's. 
&gt;This feature does not seem to be useful at first glance. Thanks to the brilliant friend injection techique discovered by Filip Roséen , stateful metaprogramming has become feasible in C++. I wouldn't rely on this. http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html#2118
If my_lib_device_t is typedefed as a struct pointer, the struct only needs to be forward declared for it to compile and function as intended.
defining the function as int test(void*); instead of int test(my_lib_result_t t); results in no warning. So a rather important difference for anyone who doesn't ignore warnings. That reminds me that I have to check our build script once I am back at work, I think someone "accidentially" commited a change with the -Werror flag removed. 
[CancelIoEx function](https://msdn.microsoft.com/en-us/library/windows/desktop/aa363792(v=vs.85\).aspx)
[Part two goes deeper](http://nibblestew.blogspot.com/2017/05/emulating-rust-borrow-checker-with-c_15.html).
`CancelIoEx` doesn't qualify is "*portable*."
It's a Windows API function. You would use the right I/O system calls for each system you want to port to. Different systems provide different system calls, there's no getting around that. 
I'm pretty sure its "Source code" and not "Sourse Code." And the other files contain the headers required to run the code. But thanks for the paste bin.
The spec says a `filesystem::directory_iterator` opened for an empty directory should be the end iterator. I don't see any difference in behaviour between my `directory_iterator` implementation and Boost.Filesystem w.r.t empty directories - what am I missing? Do you mean non-existent directories not empty directories? That was another defect in the spec, fixed by https://wg21.link/lwg2723 and implemented in current GCC releases. 
The original post didn't even hint that there would be a part 2. 😐
And my `filesystem::exists(path, ec)` isn't broken. It was following the spec precisely, but the spec was broken, see https://wg21.link/lwg2725 (GCC 6.3 and 7.1 implement the resolution, and so does the unreleased tip of the gcc-5-branch).
Shouldn't it be fine if the ABI doesn't change? 
That is very interesting, I'm glad I know about it now.
Global reference captures are a bad idea generally (imo). In this case, had you specified the capture parameters manually I think you'd almost certainly capture the ints (or any other trivial type) by value, or for non-trivial types look to either move the types into the lambda or otherwise guarantee the scope of reference captures aren't smaller than that of the lambda. Boo for the language letting you do it, perhaps, but there's a lot of gotchas like this in every language and the answer is often 'don't do that' in the form of best practice. I work with similar code every day and it's fairly rare to find myself debugging issues like this. The majority of my time is spent writing, testing and fixing logical or design errors.
I know you want to be charitable because he's earned a lot of respect, but on this he's completely wrong.
No, we are on the same page.
read about posix cancellation points. They are rather non-trivial to use, though...
&gt; Global reference captures are a bad idea generally (imo). Agreed, but lots of people use it conveniently. &gt; but there's a lot of gotchas like this in every language and the answer is often 'don't do that' in the form of best practice. So whats your recommendation? Specify the capture parameters manually all the time? Note that specifying `[&amp;a]` wouldn't have solved the problem, only make it more obvious. &gt; I work with similar code every day and it's fairly rare to find myself debugging issues like this. Neither do I, but every month/two months I do end up debugging something like this, and then it is a time-sink because not even ASan catches this. I need to go full-blown MSan to find the culprint. Note also that, e.g., in Rust, there are no capture clauses, because the compiler is able to deduce them correctly for you every time.
Maybe we misheard, maybe he misspoke, maybe he had some particular detail of Rust CFFI that isn't as good as it should and for him that's a deal breaker. It is not about him being Andrei. When users express concerns, even if their concerns are unreasonable, they still point to things that could be done better (docs, error messages, ergonomics, advertisement, ...). More often than not, the users concerns are very valid. Hearing them out is always worth it. 
This questions comes up from time to time, and yes, the Qt Project is indeed distributed and the infrastructure is in place. However, within The Qt Company, we strongly value actual interactions between developers and other employees, and we want our offices to be lively and interesting places to be. This is difficult to achieve in a distributed environment, so for the time being, we don't hire remotely.
If latest libstdc++ implements https://wg21.link/lwg2723, I look forward to removing my workarounds.
If latest libstdc++ implements https://wg21.link/lwg2725, I look forward to removing my workarounds.
I played it, this is awesome! Everything works, stone always rolls toward me, I can't go over the fence, stone stops when it hits me, everything. Next thing you can do is to invent ways for a player to earn points and lose a life, so that we can actually compete :) Btw, there is a std::abs function available to you in standard library. You didn't need to write your own. Check out other std functions you can use to make writing easier.
Does `return ( ... | ( 1&lt;&lt;(args+OFFSET) ) );` work?
C++17 changes noexcept to be part of the function type, where before it wasn't - so I suspect that this was legal under C++14 and now isn't.
I am enjoying the SEH code being verbatim copy of Catch's code, including comments (except for one Search+Replace on Catch to doctest).
That's true - it is directly taken from Catch. Do you think [this note](https://github.com/onqtam/doctest/blob/master/doctest/doctest.h#L25) in the beginning of the header is enough to honor the license? I really don't want to infringe on the license... Also I'm starting to diverge from the interface of Catch - for example the decorators or the templated test cases
5.8 is simply broken on vs2017, since _BitScanForward is not marked as constexpr.
I definitely like your suggestion a lot better than what I had posted. Storing the lambda in the shift_off object and then calling it in the fold expression is way cleaner than trying to define and call the lambda at the same time (in the middle of the fold expression, no less). A little bit of an excuse, but I didn't actually realize that you could have more than a single return statement until after I figured out the fold expression stuff. After I learned that and did the for-loop version, I never went back and cleaned up the fold expression version.
This looks sweet! I'm looking forward to trying it out since I use Catch for everything. One thing struck me about the github page, my first question is 'how do i put tests next to the declaration and not run them' and I have to look at that ACCU thing to realize this. It might be worth putting `DOCTEST_CONFIG_DISABLE` and `DOCTEST_CONFIG_IMPLEMENT` examples front and center on the github `README` since this is doctests biggest selling point to my mind. Cheers!
No didn't know that, thanks for pointing out! Cool to see that this is actually a thing and we might see it in the next standard
Nice article. Well written and informative.
&gt;we have also encoded the exception-type into the function signature That's not necessarily a good thing. The number of different error forms tends to grow with the stack depth. So either all error forms are conflated into one big "master error type" (good luck getting different parts of the codebase, think 3rd party libraries, to agree on it), either writing the "leftMap" parts becomes a PITA. There's a reason why Java checked exceptions have a bad name; same thing here, really, only with the "left" of the return value. std::string usage in the sample can throw btw, which makes the sample code the worst of both worlds: it's exceptions-enabled code that pretends it isn't. Very strong personal opinion ahead: this kind of stuff should be used over exceptions only when one has to (because the profiler has shown a problem there[1]), not as a matter of fact. One should not forget the benefits of exceptions * As TFA puts it, "Functional composition is hard" - with exceptions, it's trivial * With exceptions, comprehension of the useful functionality is easy, because error handling is out of the way for that reading * corollary: understanding error handling is also easy because `catch` blocks are rare and stand out like a sore thumb [1] even then, the first step should be to turn the biggest offender(s) into an error-return.
And the more you should read that such videogames are not *one-man's* workcrafts.
This is perhaps the most insightful, level-headed comment I've read in a long time.
I don't like leaving the web browser just to quickly look at someone's code. I don't imagine I'm unique in that respect. Take this as a rule of thumb: if you can't see it in the browser, most people won't bother. As you hopefully now see, the purported use of the code has no relevance here.
This sounds like something that should be checked my a static analyzer. Kind of disappointed that the clang analyzer doesn't check it.
Checked exceptions in Java are really bad in multiple ways. Imho the most important drawback is that they undermine designing abstractions! (The infamous ``SqlException`` is a great negative example - try writing any kind of DAO interface that you wanna implement by using a relational database...) The Spring framework has done lots of effort to offer more usable APIs for lots of things that require checked exceptions within their JDK origin. That is some kind of practical prove that this concept does not scale well. I have also seldomly seen a business Dev that has handled those checked exceptions in a plausible way - most of the time they rethrow as ``RuntimeError`` and the ignore them. Or they catch all and just do logging or some kind of stuff just to get rid of those exceptions in their higher call stack. Last thing to mention explicitly: In Java there are also **unchecked** exceptions too. So there are two kinds of exceptions, not only one.
Preview 2 is next, at an unspecified date. The compiler front-end and library branch WCFB01 is merging into the Visual C++ branch WinC, and my checkin needed to get into that merge for Preview 2.
The git-hub link is: https://github.com/Spl1ce/Open-Source-Modifiable-CPP-Console-Movement-Engine-Windows-Only Updates are there, and there is also a wiki for adding more things. I'm new to C++ and i came from python, so i approach things all in the console, I'm looking at gui librarys.
Ah got it. Didn't notice those extra parentheses. [it works!](http://coliru.stacked-crooked.com/a/fa6bc55e224f5c22) Good call on the extra parentheses.
Thanks!
The parsing is but one example where one needs more info than `error_code/category`. Surely you want to provide line and the column, probably the additional info about related tokens etc. Now consider that this various info gets combined up the stack with other stuff. It's somewhat easy when you're one library, tight control over stuff. But combined, less lo.
&gt; This [no overhead &amp; safety] is a big deal, and it illustrates how powerful the C++ language is. But maybe it's fair to say the idea is well-known in functional languages, which provide compacter &amp; better readable syntax via pattern matching. 
Why would I want to use Buck Build over CMake?
Nice features. Signal reporting is probably the most useful for me. `CAPTURE()` probably comes after that. It's too bad it's a breaking release with the change to how `TEST_SUITE` works but at least it's a simple regex replace fix (`sed -i "s/TEST_SUITE(/TEST_SUITE_BEGIN(/" test/*.cpp`).
The article is actually a decent list of things to consider when creating a project and has little to do with Buck Build itself. Here's the quick summary: - DON’T: Concatenate .cpp files into a single translation-unit - DO: Make your dependencies clear - DON’T: Use include_next, unless you really have to - DO: Keep private headers and exported headers separate - DON’T: Include .cpp files - DO: In your examples, use the library how it is intended to be used - DON’T: Copy your dependencies into your project - DO: Namespace your header files - DON’T: Overuse the preprocessor - DO: Abstract platform differences using files - DON’T: Depend on compiler specific features (unless you really have to) - DO: Use folders to partition categories of files
Unrelated to the contents, the page is crazy annoying to my (desktop) Firefox browser. If I scroll to the bottom, I have to hit back a gazillion times to leave the page. Is this on purpose, or b0rked? (As a grizzled veteran I'm in the simple error-code camp myself, but find content this at least thought provoking.)
I kind of wish I had read these when I was learning about CRTP. I think I would have "gotten" it faster.
Well by "C will become safe" I meant "Writing C will become safe". r/cpp is nothing if not pedantic. The way I see it programming languages that are difficult to use incorrectly are difficult to use at all, and therefore difficult to learn. This impacts their ability to be adopted by design and is their Achilles heel. New languages have to be easy to learn. If you can imagine a future where we had perfect static analysis, there would be no need to have any language be safe by design, and we could only focus on ease of learning. e.g. if you typed this c: char * str = malloc(15); sprintf(str, "Hello World %d", n); doSomething(str); You would be insane to code in this style today. But if the compiler could report that this would crash if n is greater than 99 or less than -9 and that str was leaked because it automatically fuzz tested all functions (or some other analysis), you modify it to be: if (n &gt; -9 &amp;&amp; n &lt; 100) { char *str = malloc(15); sprintf(str, "Hello World %d", n); doSomething(str); free(str); } And now the static analysis is happy. This would be so far ahead of all of the static typed safety that we have now, and be educational by design. The end result will be the same functionality wise. The big benefit is that every moron on the planet will be able to be a competent programmer, something that a language like Rust can never compete with, because Rust can't be used by morons. 
I don't think the moc is going anywhere anytime soon, but I wish they would add template support. I see no reason I can't have a template derivative of qobject. The moc should generate a template moc class. I work with modern c++ and qt for different clients (currently a qt client) and it always feels like qt is fighting the tide with everything they do.
 I have a simpler--though more limited in functionality--script on my machine. It uses [`Invoke-CmdScript.ps1`](http://poshcode.org/2176) from Lee Holmes' PowerShell code archive. vcvars.ps1: c:\bin\scripts\Invoke-CmdScript.ps1 "C:\Program Files (x86)\Microsoft Visual Studio\Preview\Community\VC\Auxiliary\Build\vcvars64.bat" 
I haven't had to deal with such large code bases. Is there a good consensus on where the unity build improvement is coming from? Is it just because linking is slow? Is it because the compiler is redoing parsing work? Makes me wonder if there's internal state in the compiler that can be dumped to file and reloaded or shared across compiler invocations and/or processes.
What's the difference between doctest and Catch?
The article addresses the misconception that this is a compiler enforced checked exception like eg. in java. It is not encouraging the usage.
well I thought about making the breaking change quite a bit and decided its now or never - doctest isn't that popular yet, and I think this should be the last breaking change for the next couple of years
&gt; (good luck getting different parts of the codebase, think 3rd party libraries, to agree on it) That's just a variant, and with exhaustive visitation nobody needs to agree on anything, and adding/removing error codes will produce compilation errors in all the places you need to update.
&gt; the same performance characteristics as error-codes. So, bad? Seriously, on modern hardware exceptions outperform error code patterns in most cases. The modern case against exceptions in C++ is more about poorly written code leaking memory when an exception is thrown.
CRTP is a compile-time alternative to virtual functions; if you weren't using virtual functions then, no, it's probably not bringing anything useful to your table. But, that's not to say it'll never come in handy. :-]
&gt; Makes me wonder if there's internal state in the compiler that can be dumped to file and reloaded or shared across compiler invocations and/or processes. This is _exactly_ what precompiled headers are.
Oops! Thank you.
"Officially released versions" of VS in any supplemental package (i.e., Build Tools or NuGet packages) will match version-for-version the tools shipping in actually released versions of VS. The idea is that when we release a version of VS, we'll also publish the same tools in a NuGet format. And, of course, a Build Tools. And the idea is great. The implementation is still a mess. But we're straightening it all out, I promise : )
How is it an alternative to the virtual functions when the virtual functions are mainly used where the type is not known while using CRTP you always know the type? And given the capabilities of modern compilers CRTP has no advantage over virtual functions.
That's true of CRTP _because_ the consumers must be templates; it does not translate to separately-compiled non-templates. If you put all your polymorphic-class consumers in header files then sure, it _could_ be easily devirtualized, but that would rather defeat the point of dynamic polymorphism to begin with.
and SCARY.....
I do not follow you. What _dynamic polymorphism_ you are talking when talking about CRTP? Or you mean that if we are not using CRTP but VF instead we have code hidden in cpp which is not visible on the calling site and it might diminish the devirtualization? It may and it may not. I have measured simple cases and with /GL switch on MSVC there is a marginal difference between VF and CRTP (CRTP was actually slower). So you can't say CRTP faster VF: it might be in theory and it might be not. So instead of blindly replacing VF to CRTP one should measure first. 
(Dynamic polymorphism is referring to virtual functions; CRTP is one idiom for _static_ polymorphism.) Right, LTO can mitigate virtual function overhead, but I don't assume it's the norm. LTO is only turned on by default with MSVC and is opt-in with other toolsets (AFAIK), and in any case I have projects that I can't build with LTO due to excessive memory usage by the linker. &gt; So you can't say CRTP faster VF: it might be in theory and it might be not. Well, I never did say that... &gt; So instead of blindly replacing VF to CRTP one should measure first. 100% agreed, though personally I default to templates and so rarely have any virtuals to consider replacing. ;-]
To be fair, I don't think Buck is a meta build system. It does require *both* Python and Java, though.
&gt; vector&lt;any&gt; bam! right in the performances! edit: actually it seems that your post is not really a Rosetta stone but showing off more or less how JS features are implemented. While a rosetta stone generally aims to show how to solve the tasks with the "best practice" in its languages.
I do wish that there was some kind of way of expressing this so that compile-time linters/warnings could catch if you aren't catching some exception type. Not usually useful except for I/O type exceptions where you want to make sure it's handled somewhere up the stack. 
For variadic functions, why not just take an initializer list directly rather than requiring another memory allocation and copy by implicitly turning it into a vector? You could also use variadic templates, but then that would require all variadic functions to be template functions and then things could get a bit messy inside those functions. 
https://en.wikipedia.org/wiki/Polymorphism_(computer_science) The *print* function you mentioned falls in the category *Parametric polymorphism*. An example of *subtyping* with both CRTP and normal polymorphism: http://clang.llvm.org/docs/RAVFrontendAction.html It's about calling member functions of objects whose class is not **defined** yet.
Thanks! Yes, it's hard to find a good price when selling internationally. Value of money varies greatly in different parts of the world. To address this we plan on introducing discount offers e.g. for students, open source developers, promoters with our 1.0 release. If you are interested in Sourcetrail then you should get a test license first (https://www.sourcetrail.com/test-license) and if you are interested in buying then we will find a solution.
Some of the comments on the EULA are quite interesting. Looks like AMD wants its own icc.
~40€ for the private/academical **non-commercial** licencse?? Someone seems really confident in his product.
Yeah, you are right we could put the test license form on the trial page. Thanks!
Thanks! We support CMake via generating a clang Compilation Database, this is not supported by every generator however: https://www.sourcetrail.com/documentation/#Choosingtherightprojectsetup I have to think about high level class diagrams, it's not that easy. I opened a feature request: https://github.com/CoatiSoftware/SourcetrailBugTracker/issues/378
As an AMD developer points out in the comments on the Phoronix forum, this is basically just LLVM/Clang + the changes that aren't ready to be upstreamed yet, released with some boiler plate EULA and some marketing fanfare. The improvements in this compiler are going to be upstreamed when they are cleaned up to an acceptable state for merging. This is not AMD trying to do an ICC style compiler product, and I don't think AMD has the manpower to do such a thing.
And it is more usual to have the error first in Haskell. With Either, you tend to instantiate the Functor and Monad on (Either e) so that you can compose different operations all returning Either e [something]. (curried type in a sense) In the rare cases where you want to push the errors through a series of monadic transformations, while pick the first non-error value that comes out, you can put the value first.
The coroutines proposal is in a sense the `do` notation for C++. Namely, if you don't use `co_await` with a future, but another monadic thing like `expected`, you get a *pretty* syntax for monadic error handling. expected&lt;std::string, E&gt; f() { auto v = co_await g(); // where g() returns expected&lt;int,E&gt; co_return std::to_string(v); }
&gt; produce almost identical assembly: https://godbolt.org/g/5f6mT9 I may have not used `Either` correctly, but things change if, say, you need to compute `f(num) + f(num + 1) + f(num + 2)) * m1 * m2)`: https://godbolt.org/g/XgzqVr Linear code for exceptions and checks and jumps for `Either`
Multiple ones. Two 10 core xeons, with hyperthreading for 40 cores total. I think the build system splits it up into 20 cpp files per compilation unit.
here about 40 minutes in: https://channel9.msdn.com/Events/Build/2017/B8105
&gt; With exceptions you can throw any type in any point; this can be very surprising. This is as expected with C++, and the principle of least surprise refers (as far as I can remember) on how to design the architecture and APIs, not what exceptions code is allowed to throw. &gt; Mind that this means that what a function throws - as far as the language is concerned - is an implementation detail. Yes. (and I think this is a good thing). &gt; To know if and what you need to catch, you need to examine all execution paths of a particular function and its callgraph - this is something that can be easily missed during PeerReview. Sounds like an unrealistic effort to me, unless you are coding for a project with very stringent requirements (medical laser treatments, life support systems, auto-pilot systems and so on). &gt; How else do you ensure that code works as expected ? Testing. &gt; do you have 100% test coverage? In this case 100% means not only every file, it means all execution paths and be aware exceptions add hidden execution paths. So if you always have truly 100% coverage; why use types at all ? ... and if possible, executed on all machines in the world that exist or will ever exist? Can you set this goal-post up any higher? Maybe add estimation of chances of random hardware failures? If I cannot reach the impossible goal you set, then surely I must index all exceptions in all libraries in my code and standard library, otherwise **I will never know my code works as expected**! &gt; A better solution would be just to enforce by the compiler that all the exceptions are handled at compile-time before reaching a function that is marked as noexcept (and make main implicitly noexcept). Here's a counter-example: My (strawman) application is writing to files on disk, but because it is installed on predefined OS configurations, it always has writable directories to write into. So, I can afford to never check for boost::filesystem errors within the app, and leave it to fail with unhandled exceptions in that case. With each failure, I will raise an error with whatever system administrator I have, saying "I got no write access to x/y/z directory for my application". Here, handling boost::filesystem errors is out of scope for the application specs, and _you want these errors to remain unhandled_. Compiler writers should not enforce that all exceptions are handled (and that's a terrible idea). &gt; Meaning you want to use the value(extract it from the either) you have to handle the error. &gt; Eithers are meant to be used through their monodic API, either you transform (pure functions) the values of each branch or you unwrap the either by joining both execution paths. Meaning you want to use the value(extract it from the either) you have to handle the error. ... and if your stack is 10 functions deep, do you do this to the return value at each level, or do you just add your join code at each level of the call stack, even in pass-through functions? Another point that is missed by this proposal: what do you do with functions that return a status code, like printf? Because **virtually nobody writes code that checks the return value of printf calls**, this would be a silent failure. When designing a function that has to report errors, report errors through raising exceptions. These **do not depend on the client code needing to extract the value for something useful** in order for error cases to get handled. This is what I meant by silent failures. 
I liked this post. As a C++ programmer, I found it helpful to gain a better understanding of Javascript which I only use occasionally for some hack written by just trial and error. I also think that it would be helpful should I ever need to, god forbid, translate some code from C++ to Java Script. Your next task, should you decide to accept it, would be draw the map between Jquery and C++.
I hope they don't, and instead put more functionality into it. Introspection into all members would be generally useful. I don't get people who think code generation is bad.
STL doesn't provide copy-on-write values like `QVector` or `QString`. These aren't a hammer that solves all problems, but they are quite useful, and are decent general-purpose containers.
&gt; I wish they would add template support It's not that easy - there's only so much template support you can add before moc turns into a C++ front-end.
&gt; and adding/removing error codes will produce compilation errors in all the places you need to update. The revenge of checked exceptions. EDIT: exceptions can be caught polymorphically. What about variant inside of Either?
Cool. When can we try it?
Hey, I can look over the source later if you need be, but I'm really commenting to say keep it up! I was in a similar situation at your age(17 now), but I kept with it(tinkering, reading source code of things I used to understand them) and I love everything programming now! Find some niche you like and make a program that does that. Improve it. You'll learn a lot by just asking, "What's the next step?. I found game hacking and reverse engineering really fun and a challenge, which led to me discovering Kernel/OS development​ and theory. That led to even more topics, and so on, and here I am now :) At times it may be discouraging when you find a weird piece of code you don't understand, but think of it as a new challenge! 
*Effective Modern C++* is practically the closest we have to the "New Testament" of C++ learning, and serves as a good volume to preach and learn from (oh god so many unintended religion metaphors). *C++ Primer, 5th Edition* is also excellent for beginners, as it covers C++11 as best as it can. If you see `new` and `delete` a lot, you're probably in the wrong place. Especially if you don't see all the things the standard library offers: `std::array`, `&lt;algorithm&gt;`, `std::shared_ptr`/`std::unique_ptr`, etc. Somehow I managed to not learn about `std::vector` until after I had been programming C++ for a month :v
Interesting article that describes the concept of an Either in a nice way. However I find it a bit of a shame that the article never mentions one of the stronger points why exceptions are good and where other error handling faulters. The problem of error handling in constructors. If I'm not to use exceptions there, I am forced to introduce the possibility of my class to enter an invalid state which is not as clean and a potential source for errors. I also like to have a consistent error handling strategy so it would be silly to just do it differently in the cases of a constructor IMO. What are your thoughts on that? :)
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp. 
&gt; To know if and what you need to catch, you need to examine all execution paths of a particular function and its callgraph - this is something that can be easily missed during PeerReview. Nonsense. Exceptions are used to signal that a function cannot fulfill its contract and that the execution cannot proceed normally. In the extreme case, you don't need a single catch in your program and it will just crash upon exception; in that way an exception is like a SIGSEGV. (How do you handle signals during peer review? E.g., SIGFPE for division overflow? Dividing `INT_MIN` by `-1` will cause SIGFPE on x64, so you cannot just make a rule that every division has to check against divisor being 0.) But, you can act upon exceptions more freely. In a slightly less extreme case, you can have a single try-catch block around main that catches all exceptions and exits the program gracefully. This works because you can catch exceptions polymorphically. Usually you make "modules" in your program with well-defined inputs, outputs and state, and handle exceptions and recovery on module boundaries. How would you implement polymorphic return values? By allocating them on the heap [which in itself can throw], and only doing *that* would be a fair performance comparison of return values vs exceptions. &gt; How else do you ensure that code works as expected? Bunch of asserts on invariants on internal states and testing. &gt; A better solution would be just to enforce by the compiler that all the exceptions are handled at compile-time before reaching a function that is marked as noexcept. This is not doable in practice due to the separate compilation model. How are you going to do this for libraries distributed only in binary form? They can throw exceptions derived from `std::exception`, but without source code, how is the compiler going to know this? Besides, a program where the whole body of main is wrapped in `catch(...)` trivially satisfies this requirement. So what would be the point of such a rule? &gt; In doubt always check in the assembly if all abstraction collapse after inlining (don't forget -O3!) Compilers have inlining limits, so what do you do when your "zero-cost" abstractions spread throughout the whole codebase hit the wall? 
This seems quite far outside the bounds of what WG21 does.
Don't the [C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md) address this? Or are at least supposed to? Here's the section on [code layout](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Rl-knr).
https://xkcd.com/927/
Sounds neat, but I'm unsure why you'd pick a compiler for a specific CPU, sure I guess it's fine if you know for a fact your target hardware is only going to be AMD but what if I want to support optimised version for Intel and AMD, produce separate executables?
&gt; I have problem with customized build step with every build tools. You must be dealing with toy projects if you use no code generation of any sort. I have fairly small projects (50kLOC) that use 5-10 code generators. It's a non-issue in practice. I have no clue how people get by without plenty of code generation (that C++ compilers themselves can't do). Sorry. It's like night and day. Even a simple lexer or a parser generator can go a long way in making your code easier to maintain and understand. &gt; there is perfectly viable solution exist already I keep hearing that and every time I chuckle. Alas, to humor you, I've just looked around and [Verdigris](https://woboq.com/blog/verdigris-qt-without-moc.html) seems to be the only potentially "viable" solution in the future. Right now, with the stable compilers out there, the number of viable alternatives to moc is exactly zero.
VC++ already has a compiler switch to bias towards optimizing for AMD CPUs or Intel CPUs, I wonder if other compilers also have the same sort of feature already. 
Learn about GCC and clang's -march option.
It isn't in C++ fancy nephew, ++(C++). Also, isn't that a syntax error?
Thanks, got it.
msvc has /favor and gcc has -mtune
&gt; C++ also has 40 years of compiler tweaking to get the best possible optimizations Rust uses the LLVM backend, so all of the optimizer work that affects LLVM backends propagates from clang to Rust.
Anyone else getting JS:Includer virus alert on that page? (I have Avast)
I'll probably end up using the typeid implementation rather than macros which violate SOLID principles.
an advice: SOLID principles are exactly this, principles. Principles are not mantras or absolute rules that you will have to always follow. They are advice, given by people who saw than generally, given conditions A, doing B tends to give C. If your code is slower, and longer, following the principles is a bad idea. 
&gt; The second is that type_info by itself has problems across DLL boundaries and the like since each unit requires its own definition of the type, so comparing pointers is insufficient for checking equality, meaning that string comparisons were required. That's honestly not a C++ / dynamic_cast problem, but a MS Windows problem. Other platforms absolutely don't use string comparisons for dynamic_cast and just compare pointers, which is cheap.
Yours are probably solvable, though.
If only. I think committees by their very nature have unsolvable problems. 
There is some attempt on this: [More C++ Idioms](https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms) on Wikibooks
&gt; However I find it a bit of a shame that the article never mentions one of the stronger points why exceptions are good and where other error handling faulters. The problem of error handling in constructors. You can lift the invalid state to a type that supports an invalid state (i.e. an optional): http://foonathan.net/blog/2017/01/09/exceptions-constructor.html
&gt; compare pointers, which is cheap Was not aware of that, but that just means the Linux ABI is broken in various contexts with shared objects and hidden symbols, would it not?
While in many cases RTTI might just be unnecessary, I have a project where I used RTTI to get the name of the object the I get through an so file on Linux and a dll file on Windows that I was test to print . Many, if not all, RTTI implementation will remove typedef and give you raw underlining type. Also this project thought me about GCC name mangling before Jason Turner metioned it on C++ weekly.
Thanks for the warning, not clicking that link then :\
One thing to note: your first link is actually compiling with _Clang_ 4.0.0, and your second _GCC_ 4.4.7. They are different compilers and have different output. This stackoverflow posts details it with specifics: http://stackoverflow.com/a/28058430/214063
I don't think that's relevant in this case; Clang gives an error whereas GCC gives a warning, OP's just reading their compiler comparison wrong.
The g++ compiler used doesn't yet support `-std=c++11`, only the experimental `-std=c++0x`. So it's a pre-C++11 compiler. I'll take @tcanen's word for it that it's from 2009; that's the explanation of the behavior.
If you need something easy and quick, I'd recommend libcurl. https://curl.haxx.se/libcurl/ 
Perhaps Standard C++ Foundation would be a better choice to host this as another guideline project? But I think all they can do is to host it. Someone got to do the actual work.
The difference in behavior with the modern toolsets is exactly the same as the difference in behavior with the older ones &amp;ndash; the underlying issue is simply error vs. warning diagnostics, and applying a certain popular compiler flag to both would have made the outputs equivalent. I'll take 3 minutes of actual investigation's word for it... &gt;_&gt;
I (obviously :-)) disagree that writing code with exceptions is harder. To my mind, the reason is: in vast majority of situations, upon an error, code cleans up and gets out. Exceptions cater for that state of affairs, and writing incessant if-s (or using libraries that make if-s more palatable) is busywork, noise. I disagree that debugging such code is harder, too. What's the reasoning behind this stance? I do think that two approaches require a different reasoning, different mindset. With exceptions, the key insight is "anything can throw", and the rest follows from it. That's wildly different from error-return. I absolutely agree that the two approaches can (and need to) mix in a given codebase. At my work, lower levels often end up in some C libraries, so... :-) But what I prefer, by and large, is to collect any error info available at the spot, and throw. I think, you and I belong to different... ahem, tribes. I am old enough to realize that technical arguments, when looked at in enough details, end up in a vote for this or that preference, a popularity contest if you will. So I am openly stating my preference and bias :-).
This looks great! Definitely interested, but I'm curious if there is Visual Studio 2017 support in the works? I think it's too late to be buying software/extensions that can't support that. I've already moved on :) From a quick read it wasn't clear - can this just be used as a VS extension to graph and explore existing code, without creating anything first on the Sourcetrail side? Sounds awesome if I can just open an existing VS .sln, and hit some hotkey, or select some menu option, and see graphs.
That is fine for a commercial use licence, but it is a quite high price for a non-commercial version. 
Not to mention the market share to pull such a stunt
Other people have the correct answer, but oh god that syntax is horrible. This is why people are put off C++, because books like this put shit like ```int a{ld}, b = {ld};```. Just fucking write int a {ld}; int b {ld}; int c {ld}; int d {ld}; It's clear, concise, efficient and correct (as correct as a narrowing conversion can be). There is zero benefit in cramming initialisation onto one line like this and serves only to make it harder for a human to parse the code.
- `visit(variant, [](auto&amp;&amp; v) { ... });` where `auto&amp;&amp;` matches everything. - `visit(variant, [](base_type const&amp; v) { ... });` where `base_type const&amp;` will perform slicing. Basically you can match variant types using template argument deduction + argument dependent lookup + overload resolution (normal C++ function calls), so you can do everything from matching exact types, to slicing, to matching exactly multiple types, sfinae, ... 
It's probably most useful for hpc when you have a nice homogeneous cluster. Or when performance is so important that you can justify the cost of building twice and handling the distribution/installation issues.
See GCC's function multiversioning feature for a simple way to do that branching, https://gcc.gnu.org/onlinedocs/gcc/Function-Multiversioning.html
The benefit is feeling "clever" for knowing obscure syntax when you write it. A similar pet peeve of mine is putting whitespace in the wrong places and omitting it where it would help: if(i&lt;3)Function ( a, 123 ); 
What is the use case for such a library that justifies such sophisticated optimization?
&gt; normal method : for, iterator If classic `for` is normal, is range-based `for` abnormal? &gt; for auto loop We don't call it "for auto loop". Its name is "range-based for loop`. &gt; printf(" #3 - for each loop - c++11 \n"); `for each` is not C++11. It is a Visual C++ extension introduced before C++11. &gt; for_each No example with lambda? &gt; It would be better if I could handle the parallel loop. &gt; This is next time. These sentences are strange. I don't understand.
&gt; Was not aware of that, but that just means the Linux ABI is broken in various contexts with shared objects and hidden symbols, would it not? Could you be more specific? This is an area of interest to me; I know of a few issues. I would like to understand the specifics of what you consider in "Linux ABI is broken in various contexts with shared objects and hidden symbols".
Excellent points about PCHs.
Somebody should really replace those snakes with dragons. Invoking undefined behavior is the only way to see one nowadays. Also those dragons should spit &amp;sect; signs that reference the ISO standard.
C&amp;sect;&amp;sect;
I guess C++ modules will help with that. 
Yep, use GraphViz and implement the Reingold-Tilford algorithm to place the nodes neatly. I did this to plot k-d trees and red-black trees.
also somewhat related: I only worked in one project where in code review, there was an explicit requirement for checking errors on every API (everything was in an if statement, with error propagation logic in the true branch). Handling printf errors was a mess, because you had to handle incomplete print-outs, failed print-outs and successfull ones; since printf return value is dependent on the size of the printed output, when formatting strings, you had to compute the size of the resulting string separately, to have something to compare it to. Every time I hear someone say "printf offers the same functionality as std::cout" I remember those ifs in ifs, to check if we are handling a failed print, a partial print or a successfull print and ignore the rest of the spoken argument. 
Your post has been automatically removed because it appears to be a "help" post - e.g. a C++ question or homework related. Help posts are off-topic for r/cpp; this subreddit is for news and discussion of the C++ language only. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6bw3vl/any_help_for_a_newb/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Then also read about anonymous namespaces ([see on cppreference](http://en.cppreference.com/w/cpp/language/namespace#Unnamed_namespaces)). They make their content invisible to other translation units.
&gt; I think, you and I belong to different... ahem, tribes. Definite agreement on that. Much tribal segmentation comes from difference in beliefs over the competency of the average programmer. My tribe tends to have a patriarchal mindset that it is the job of the skilled programmer to cater to the average programmer, and not to hurt their pretty little heads too much with stuff like "detail". Other tribes - not necessarily yours - think that C++ should always be written by experts for experts, and only the competent need apply. Still other tribes take a hard Randian view that the world is full of danger, and insulating people from it is morally wrong. All these are long established tribes in C++, and interestingly roughly map onto religious divides. But I am now straying far off topic. I'm not sufficiently tribal to think my tribe always right and the other always wrong. And I can wear another tribe's clothing easily if a client demands it. Thankfully we are rather more evidence based here in compsci than they are in religion-land, and there is no hard evidence that any of the tribes are right or wrong, else they'd have self corrected. That suggests all remaining differences are mainly due to lack of empirical proof, and that's a very healthy thing I think.
If comparing pointers, that requires the `type_info` object to be identical across the entire program space. Including across shared library boundaries. Since `-fvisibility=hidden` is all but mandatory on C++ apps on Linux to avoids some pretty gnarly ELF bloat or exceptionally long link times, that would imply that if RTTI is just comparing pointers and a `type_info` from `A.so` is passed to `B.so` (which also emitted its own `type_info` for the same type, say because it was header-only) and used for comparison then it will result in a false negative. That's a fairly contrived scenario to directly illustrate the case, but the general setup is not uncommon to what I've seen in actual plugin architectures in the wild.
If I was CEO of a company that just suffered millions in losses due to a memory safety bug in purchased software, I'd be demanding that the vendor use a memory safe language. 
Haha, if I have a cure for malaria I don't need to breed mosquitoes to make the point :-)
&gt; Most of the time I've seen the working programmer follow a rant about dynamic_cast or turned off RTTI and instead go off and re-invent their own RTTI wheels, it has re-invented them square with latent disastrous bugs. I've definitely seen that too. The current game engine I work on has a very elaborate RTTI-like mechanism that is reimplemented basically just because they need additional runtime reflection data for scripting and IO and such, has definitely had bugs, but the dynamic casting system it uses was written specifically because it was measurably faster than `dynamic_cast` at least on some platforms and their SDKs/compilers (though I don't know if it's been measured against all the current SDKs our company targets).
D relies on the C interface to the OS, too. However, we've started adding annotations to these so the compiler can do some more checking of usages of them. For example, memcpy() can look like: void* memcpy(return scope void* d, const void* s, size_t n); This tells the compiler that memcpy does not escape d, that anything reachable through s is not modified, and that d is returned by memcpy. Hence, void* foo(char[] s) { char[3] d; return memcpy(d.ptr,s.ptr,3); } returns a compiler error. memcpy remains a memory unsafe function, but some usage checking is possible.
My personal opinion is that any program which uses downcasting is broken. A very simple example: struct Base { virtual ~Base() {} virtual void doit() = 0; }; struct Derived: Base { void doit() override { std::cout &lt;&lt; "Hello, World!\n"; } }; struct Decorator: Base { Base* b; void doit() override { std::cout &lt;&lt; "Hi!\n"; b-&gt;doit(); } }; void hello(Base* b) { if (auto d = dynamic_cast&lt;Derived*&gt;(b)) { d-&gt;doit(); } } int main() { Derived d; hello(&amp;d); Decorator dec { d }; hello(&amp;dec); } will print "Hello World!" once and only once. The decorator pattern is broken (and any adapter/proxy/... pattern) because someone thought it was a good idea to use downcasting. Downcasting makes your codebase extremely brittle, because it violates the Liskov Substitution Principle: you can no longer infer the requirements of a function based on its signature, you also have to know what type it potentially downcasts to. And even if you infer correctly when you make the call, any change to the function implementation that introduces a downcast might violate your assumption and *silently* break the code. That's terrible. I'd rather you used a Visitor if you need double-dispatch.
Also mobile devices. If I need to leave the reddit app to download and still can't check I'm out.
I was mainly going to use double dispatch for returning correct values from a function template. I.E. searching base class vector for correct derived type. Is this an inherently incorrect design because it seems required.
That would solve it for more cases. Might still be some issues with dlopen'd libraries? But that's corner-casey enough it's probably not worth caring about. I don't see any docs on whether these kinds of symbols are always visible even with `-fvisibility=hidden`, and I'm not sure this matters enough to me to do an experiment. :)
Hm... even without the return, still unsafe :) But of course foo is not marked @safe, so you wouldn't get an error. With @safe you would, which is the point.
The reason `__PRETTY_FUNCTION__` doesn't work is because it's treated as if there was a `static const char __PRETTY_FUNCTION__[] = "function_name";` statement at the beginning of the function definition. This also goes for `__func__`. In clang, however, it is treated more like a magic constant, and thus even works in C++11 mode. This is what I've worked out from trying to make something like the C++17 source context thingy. Getting the function name in a constexpr setting just won't work in GCC. 
clang-format is already a defacto standard. This tool is so reliable, and tested, so well supported by major players, so easy to use and well integrated into every IDE, lends itself so well to automatic enforcement... Basically I am going to take an extremist view point here: If you aren't using clang-format in 2017, you are wasting time.
I think this is exactly the description of CRTP which is confusing to many people. Virtual functions need to be used to specify *any* runtime polymporphic interface. On the other hand, CRTP is not necessary to specify a compile time polymorphic interface. In fact, nothing is because C++ templates are untyped. CRTP is only related to polymorphic inheritance by the fact that both can provide default implementations. That's only one small aspect of virtual functions and one which many people eschew entirely. The main usage of CRTP for me has absolutely nothing to do with virtual functions. It helps you implement a class in separate modular bits. A la Andrei's policy oriented design.
Why would you put anything private in a header, at any time? That just creates an unnecessary compile-time dependency for clients. For example, private static methods and fields should better be in an anonymous namespace in the cxx file. Templates are the only reason to put implementation details in the header (don't know ifmodules change anything there).
You might want to take a look at Beast, it's proposed to Boost and should go in review soon. It's certainly the closest to a future standard http lib: https://github.com/vinniefalco/Beast 
Training, yes (though there is some more specialized hardware). When actually using it on a mobile phone, you might use the GPU, you might use a DSP if you have low-level access, or you might use the CPU.
Thanks for letting us know! I fixed the wrong URL.
Yeah, saying `for each` is C++11 is like the opposite of reality. When C++11 added its construct, that extension was deprecated.
One good reason to put implementation details in a header is to implement a header-only module. That has advantages (like, very much simplified build and distribution) and dis-advantages (like, possibly increased build time), as most things do. It' just another tool in the toolbox, and is IMO certainly not a technique that one should voluntarily abstain from on ideological grounds.
The Boost library convention is to put implementation details of stuff at namespace scope, in a nested namespace called `detail`. My own convention is to call it `impl`. It's that simple. The class construct's access specifiers provide a little more support from the compiler. But even then they don't stop anyone determined to access stuff. There are all kinds of circumventions, ranging from constructs totally within the C++ type system and rules, such as inadvertent use of `protected` stuff via member function pointers, and such as Johannes Schaub's ingenious template trick for accessing `private` parts, to brute force no-rules attack such as using the preprocessor to redefine `private` to `public`. So, even the access specifiers don't provide any absolute protection. It's all about guarding against **inadvertent** use of implementation specific features. And then a nested `impl` namespace is reasonably good, good enough: by no means perfect, and lacking tool support, but reasonably good enough.
In addition to the other comments, please also be aware that the pipe operator is *not* part of the Ranges TS. There's bound to be a lot of discussion about whether overloading operator| is a good idea when it is proposed.
I think the main point is, Rust's type system DEPENDS on information that's not available in the C api. Rust doesn't work in cases where complete type information is not available. It's quite some work to call out to C, and then make shim's to implant Rust's expectations from the type system over the top. Then you have C interfaces which take function pointers as callbacks... that can get really hard to reconcile.
Gcc is incorrect in this case.
Thanks for your suggestion, but it looks somewhat heavy for my system..... Is there any lighter way?
Thanks for the reply!! I will look around your suggestion!
&gt; Virtual functions need to be used to specify any runtime polymporphic interface. I find _this_ statement confusing &amp;ndash; "runtime polymporphic interface" as in dynamic polymorphism? If so then totally agreed; if something else then I'm not sure what you mean. &gt; CRTP is not necessary to specify a compile time polymorphic interface. Right; as I said in another comment, CRTP is one approach to static polymorphism, not the only approach. &gt; The main usage of CRTP for me has absolutely nothing to do with virtual functions. It helps you implement a class in separate modular bits. For me, I use mixins for modular bits, but I use _CRTP specifically_ as a replacement for virtual functions; I don't see what the pattern brings to the table if you're not going to use the base type 'polymorphically'.
Ryzen has lots of problem, don't buy it
I believe the `=&gt;` operator is expected to be used for [abbreviated lambdas](https://wg21.link/p0573r0), though it is not set in stone yet. sort(begin(v), end(v), [](auto const&amp; a, auto const&amp; b) =&gt; a &lt; b); Last I heard, [everything but the first sub-proposal was rejected](https://botondballo.wordpress.com/2017/03/27/trip-report-c-standards-meeting-in-kona-february-2017/). There was also mention of introducing a [spaceship operator `&lt;=&gt;`](https://wg21.link/p0515r0) as part of a proposal for revamping comparison operators.
The `type_info` objects have weak/vague ELF linkage, as do template instances. So the ELF linker guarantees you only have a single copy of each `type_info` and template symbol. That is to say, the linker **guarantees** the ability to do pointer comparisons no matter how many shared libraries have an instance of a symbol. It works transparently, and is a very different story to the limitations of PE-COFF and DLLs. Anyone unconditionally hiding symbols is asking for a world of trouble.
We tend to remove beginner questions. In other words, if it could've been easily answered by most people in r/cpp_questions, it shouldn't be here.
A common way around not being able to report an error from a constractor, one that does not lead to an object being created in invalid state, is to use static factory function for object construction. Move all the ctor code that can fail (or just all the ctor code) into a static method, which returns the constructed object on success or an error code on failure. Mark the ctor private, so that the only way to create an object would be through the static method. That way, if you have an object, it's always valid. Something along the lines of class Foo { public: static Either&lt;Foo, FooErrorCodesEnum&gt; create(short arg1, int arg2, long etc) { auto local1 = canFail(arg1, arg2, etc); if (!local1.isLeft) { return Right(FooErrorCodesEnum::Error1); } else { return Left(Foo(local1)); } } private: Foo(int arg1) : member1(arg1) { } int member1; } Probably not the prettiest (or valid) c++ code, but gets the point across.
If inlining is important (it is), then one should provide .inl files, which contain "inline-able" code and provide an optimized build where those are included in headers, versus unoptimized one where they are included in .cxx.
Thank you for the Pointers Gone Wild talk. Very interesting! I understand the scoped/return "annotations" are part of the type system in D. Is that correct? Does this already cover a protection against situations like these? vector&lt;int&gt; foo = {2,3,5,7}; auto&amp; ref = foo[2]; foo.push_back(11); // possibly invalidates ref cout &lt;&lt; ref &lt;&lt; '\n'; That kind of scenario is prevented by "borrow restrictions" (not an official name) enforced by the borrow checker in Rust, for example. And I believe the static C++ analyzer that is in development at Microsoft and which works with minimal annotations based on Sutter's and Stroustrup's ideas is supposed to catch this kind of error as well. (Not sure that it does right now).
I bought the non commercial version and do like the software. Also the devs are very responsive over email. My main feature requests for the tool are a. Please fix https://github.com/CoatiSoftware/SourcetrailBugTracker/issues/78 . This will make the tool much more powerful. Not having a powerful querying language substantially limits what I can do with the tool. b. Please consider exposing the graph via some kind of scripting api. Some kind of visitor python api that allows people to create a subgraph of interest would be very powerful.
Yet another product that nobody can buy. And you have the gall to post it here. Go to hell. Come back once you have a Buy button on your website.
VB Classic is as dead as COBOL. I'm told that VB.NET is a reskinned C#.
I hope it was fun regardless.
You don't need to make everything safe; you just need to make the curl replacement safer than what currently exists.
Yes. First off, `ref` is not allowed on local declarations. But suppose it is a pointer. The idea with D is to only allow scoped pointers into a data structure, which are not allowed to survive beyond the expression they appear in.
Sure, I do enjoy my work, else I'd do something else.
I had the same idea yesterday. Assuming I have a module B. What is the current behavior with modules in the following two cases? Case 1: import A; module B; export EntityOfA someFunction(); Case 2: export import A; module B; export EntityOfA someFunction(); Will case 1 compile? Will another compilation unit using import B - See all entities of A by name only? - See all entities of A by full definition? - See only the entities used in the interface of B by name only? - See only the entities used in the interface of B by full definition? Same questions for case B. And how do forward declaration work in the context of modules? Will they become obsolete same as precompiled headers? Or can forward declaration be used to create cycles across modules. And I hope the upcoming VS will use the knowledge of export and import to make __declspec(dllexport/dllimport) obsolete. 
Does this work with strict aliasing? (the conversion from `uint32_t` to `uint8_t*`)? I was under the impression that the only allowed type you could "pun" to was a `char*`? (random [SO](http://stackoverflow.com/questions/98650/what-is-the-strict-aliasing-rule) link that says it, best source I could find offhand) Edit: On re reading, I didn't actually notice that he had conversions to uint16_t* and uint32_t. I'm also pretty sure that you could move some of th checks to compile time (e.g. Read only vs writ eonly registers£ with 0 performance hit. Will investigate later, as am on mobile right now. 
I think it is better to start with some light reading first. In my opinion, C++ in 21 days is a good resource for a newbie. In fact, I have taught myself C++ with it. Once you get comfortable writing C++ programs, you can refer to Stroustrup's book for sweet corners in the language.
Can't wait for ranges, and I'm especially gladdened by the syntax. It was a GREAT choice to use the pipe character in this context. Ranges will likely become second-nature to us all as we absorb the syntax, and so it's a forward move for C++ as a whole. Iterators are messy, ranges are clean. We will all write better code as a result -- and with the (greatly useful) advantage of lazy eval. I'm especially interested in the crossover with coroutines, that should be very interesting.
This is the one valid use-case: type erasure with checks that the value matches your type expectation when you actually want to retrieve it. It's actually so valid that there's [`std::any`](http://en.cppreference.com/w/cpp/utility/any) for this ;)
Dude, acting like I'm a beginner at this point in the conversation is just condescension. If I keep mentioning Modern C++ Design which you have apparently have not read, do you really think that an example from Wikipedia is going to be informative? Yes, the example you showed me shows the typical misunderstandings regarding CRTP. Base is providing only interface and derived is providing only implementation, so why isn't derived simply a member of base? This example shows nothing of the necessity for CRTP.
The difference is that https://github.com/CaseyCarter/range-v3 is simply my fork of https://github.com/ericniebler/range-v3 ("upstream" range-v3) and https://github.com/microsoft/Range-V3-VS2015 is the repo that specifically supports Visual C++. 
If you have a well written answer on this topic explaining the situation, I would be very very interested to read it. Even googling around, everything I see are just explanations of CRTP for rank beginners, explaining how you don't have virtual function call overhead. Of course that's true but there are many ways to achieve that and there's very little discussion of what CRTP provides uniquely. MCD is one of the few places where I have read discussion of CRTP that's not for beginners, and since you've read it you know it's all about CRTP as mixins/policies, not CRTP as a replacement for virtuals in any way, which is exactly the opposite of how you have been presenting CRTP up and down this thread.
I use the wintellect ps module It's got a cmdlet Inport-VisualStudioEnvironment -VSVersion 2017 -arch amd64
Yes, blocking I/O is more portable. But you're kind of missing my point: blocking I/O doesn't use NT to its full potential. We port Unix stuff over to Windows all the time and then bitch when Unix-centric syscalls like `fork` don't work right. The Windows-centric equivalent is overlapped I/O. Win32 is built atop asynchronous I/O. If you want your I/O to be as performant as possible on NT, you need your I/O code to comply with its async model. Yes, it's hard to reason about. Yes, it's not as portable. But try taking code that uses Win32 overlapped I/O and port it elsewhere and you'll find that it just doesn't work as well.
&gt; Wasn't familiar with the feature so I looked it up. It just looks like the ability to do IO asynchronously. Is there anything more to it? Because Linux has had that for ages. Even if for some reason it didn't, you can trivially make things asynchronous by doing the IO operation on a separate thread. Overlapped I/O + I/O Completion Ports on NT will mop the floor with any Linux pseudo-AIO any day of the week.
How does this work in a computer with an OS and virtual memory? Does the video card have a specific protocol to write to video memory?
Just search your favorite online bookstore, there are a couple. None is completely up-to-date but it was ever thus. I don't think the techniques you'll learn from them will have been made /wrong/ by language changes, just, sub-latest, greatest style. As for being hard to understand, that's just the territory, making a functional programming language out of subtle tricks with the C++ language. I can vouch that you'll have your hands full with the one from the Boost developers at least. There's a new one coming at the end of 2017. 
Should I use this opportunity to plug my fledgling library again? :p https://github.com/crazy-eddie/arduino_modern
There is certainty that GCC is, in fact, wrong in this case.
I was about to mention along the same lines as well.
I am trying to do a numerology as a final project, input first, middle then last name each of them has a value http://imgur.com/a/JT1ch like that my first name is 38 i want to split it to 3 and 8 then add them both and do it again with its outcome.
I get that, but the pmr implementation seemed quite complete already, even back on gcc 6. What's missing?
The synchronized and unsynchronized pool resources and the monotonic buffer resource. And correct alignment, see bugs 77691 and 70940. The implementation needs more work.
Maybe you mistook *a character type* to mean `char`. There are several character types. `uint8_t` is very likely to be a typedef for a character type, although the standard doesn't guarantee that and theoretically that code could be an aliasing violation on some non-existant system.
because chaining using simple function wrapping is very very ugly once you want to compose operations. But I agree that | might not have been the best choice.
Your first bullet-point is: "Enforces hardware semantics through type safety. Can't read an input pin for example". should that rather be "can't **write** an input pin"? Or is my reading comprehension just off today?
I recently bought [C++ Templates - The Complete Guide](http://www.josuttis.com/tmplbook/index.html) book and discovered that 2nd edition is planned on September, 2017. It is less hardcore than Modern C++ Design (to be fair, it is hard to find book that comes close), but still dives pretty deep.
What's a better alternative?
You can't guarantee that uint8_t is typedef'd to char, so this is relying on undefined behaviour. Regarding character types, I'm not sure what you mean here. The best reference I can find is in my original post, where the poster specifically talks about a char, (and then mentions that the rule holds for signed char and unsigned char, although I can't source that). Also here: http://en.cppreference.com/w/c/language/type where they mention compatible types, and specifically that char, unsigned char and signed char are _not_ compatible. Neither of these sources mention anything about uint8_t and its suitability. 
If you're going to reply with snark then I'm going to reply with snark too. &gt; It's not UB on any platform that exists It's UB on a platform where a char isn't 8 bits, such as: https://en.m.wikipedia.org/wiki/36-bit any of the 36 bit architectures with 9 bit bytes. [heres a link to a data sheet of a TI dsp with a 16 bit char](http://www.ti.com/lit/ug/spru307a/spru307a.pdf) Posix says a char is 8 bits, but it's not standard. Also, the GCC developers don't necessarily agree that an int8_t is a character type: see [here](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=66110) &gt;Why don't you just read the text of the strict aliasing rule instead of trying to infer things about it from other sources Because it's a 1400 page document that falls back to another 600 page document. I'm trying to read it now, but the closest I can come to is section 3.9.4, maybe you could point me to where on the 2000 pages it lives so I can understand it? 
Non-Mobile link: https://en.wikipedia.org/wiki/36-bit *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^70208
&gt;It's UB on a platform where a char isn't 8 bits, `uint8_t` does not exist on a platform where char is not 8 bits. &gt;Also, the GCC developers don't necessarily agree that an int8_t is a character type My claim is that *on platforms in which int8_t is a character type*, using int8_t to alias some other type does not violate the strict aliasing rule. In previous comments you seem to be applying some principle "If code is UB on one platform then it is UB on all platforms", however there is actually no such rule. &gt;I'm trying to read it now See [basic.lval]/10 in C++14. Actually the relevant part says "a `char` or `unsigned char` type", which doesn't make sense. The standard doesn't define "a `char` type" or "a `unsigned char` type" anywhere. It does define the two types `char` and `unsigned char`, and various other character types. (The C standard says "a character type" which is clear and unambiguous, but not relevant to C++). Certainly this phrase in C++ means to include `char` and `unsigned char` but it's not clear whether it also includes `signed char` or other character types. That's moot for our discussion though, as `uint8_t` is, on all currently platforms that exist and define it, a typedef for `char` or `unsigned char`. 
Well D has better interoperability, because it has C++, Objective-C and COM ABI compatibility, unlike C. It is easier to write faster code in D than C. http://blog.mir.dlang.io/glas/benchmark/openblas/2016/09/23/glas-gemm-benchmark.html Binary size: you can copy and paste a function written in C with minimal changes into a D program and get identical assembly. Source code size: D obliterates C, no questions asked, since it's a much more expressive language. https://blog.thecybershadow.net/2014/03/21/functional-image-processing-in-d/ To sum up: :C A C programmer :C++ A C++ programmer (throwing up) :D A D programmer
I think &gt;&gt; Is a lot more logical from a c++ perspective.
you might want to read a little e.g. stuff like https://www.cs.utexas.edu/users/pingali/CS378/2008sp/papers/gotoPaper.pdf to see that the benchmark is flawed and mir.glas apparently single threaded only with no interoperability to common languages ;-p c is simple, fast, works almost everywhere (e.g. embedded systems) and the only downside is that you have to think about what you are doing. (being forced to do that is actually a plus)
I thought I was being original when I made this a connection with checked exceptions. Others did it as well!? Oh well, never an original thought, me... :-) ~~As for the rest of your post... I **really** don't wish to pass error handling strategy around. I wish to do diddly squat - until I really have to. And that's exactly what exceptions give me.~~
For simplicity?
Is there a reason to use `pthread` directly and not C++11 `&lt;thread&gt;`? Edit: Also, is there a reason to use implementation-specific `__hread` instead of C++11 `thread_local`? And `bind` instead of a lambda?
I wrote a [simple header-only modern c++11/14 thread pool](https://gist.github.com/jrandom/ddb986d4e2c6e91926657736e97d2d54) that also supports futures since those can be super handy. There is absolutely no reason to write system-specific c++ thread code in this day and age.
Scope?
ThreadPool is missing a join() function. That makes it a bit unusable if you can't wait until everything is finished. Also the solution you did in the test (the sleep(2);) is extremly hacky. That should be a join(); Edit: Also a bit more advice: * Using owning raw pointers (every * you fill with something like new) is dangerous. Better use `std::unique_ptr` ([see here](http://en.cppreference.com/w/cpp/memory/unique_ptr)). In your case you could skip using pointers all together and use a `vector&lt;Thread&gt;` instead of a `vector&lt;Thread*&gt;` * Prefere something like `std::lock_guard` ([here](http://en.cppreference.com/w/cpp/thread/lock_guard)) to explicitly calling `lock()` and `unlock()`. In your implementation of `addTask()` if the call to `taskqueue.push_back(task)` throws an exception, then `mutex_` is locked, but never unlocked again. `std::lock_guard` will correctly unlock the mutex even with exceptions. * Also you should use something like `std::atomic&lt;bool&gt;`([link](http://en.cppreference.com/w/cpp/atomic/atomic)) for `running_`. The compiler *may* optimize the variable access in `while(running_){` in such way, that `running_` is only read once. **If** the compiler does that, then all worker threads would run forever. This problem is avoided by using *atomic* variables.
Any reason why to use this over [progschj/ThreadPool](https://github.com/progschj/ThreadPool)?
It might be just a way to lay the foundation for an IDE that does just enough, years down the road. Like restarting VS from scratch, and maybe end up with a new IDE, but really nail the editor part first? I'm down because it'll mean the msvc compiler might get easier to work with as a result.
On Windows I prefer regular VS (although I use Code for other languages than C++ and just regular text file editing in general). On Mac I pretty much can't use Xcode on my somewhat old MacBook because it's just too slow. Code works fine, albeit with (so far) more limited code completion etc. Haven't tried CDT or CLion but in my experience Eclipse is an absolute hog so I wouldn't expect it to perform better. 
Bitfields are a pain. Volatile ones doubly so, especially since the common compilers generate shit code for volatile bitfields. Source: Wrote hardware abstraction for [this](http://www.ti.com/lit/pdf/sprugs5), bitfields and all.
&gt; I'd love it if there was an easier way to index Qt projects from the qmake .pro file, and automatic adding of the necessary Qt headers. you can just right-click on a class name somewhere in your code, `refactor -&gt; Add include #include &lt;QSomeStuff&gt;` 
&gt; progschj/ThreadPool Neither is lock/wait-free but use mutex for synchronisation so I wouldn't go there. I'd start with wait- or lock-free and have separation of input queues and workers so that can synchronise work/dependencies within queues. Then add optional fences between tasks in the queue as option. Maybe cancellation of tasks that haven't yet been dequeued. And finally, possibility to "join" some something like per queue wait. That would float my boat. :) 
&gt; but what's even the purpose of regular VS if you don't have a sln/project file? You can't build, intellisense probably won't work well No longer true with VS 2017, fwiw. It can "open a folder" without any .sln file required, and both its Intellisense and debugging features work in that context. Like VSCode, it just requires a couple .json files in that mode to give appropriate hints about include paths or binary locations. They made a big deal about the CMake integration in 2017, but that's basically just a small helper layer to avoid having to write those .json files and instead extract the information from CMakeLists.
To be honest I'm not really that deep into the topic and have no idea about half the stuff you're talking about :-) So for general, non-critical use cases, would you not even recommend progschj/ThreadPool? Is there an alternative, well-tested, single-header, C++11/14 thread-pool that you could recommend? Preferably on GitHub?
We got "Visual Studio", "Visual Studio for Mac" (based on monodevelop" and "Visual Studio Code". All of them are completely different and duplicating same functionality 3 times. Not sure this is going to work out in the long run...
Regular vs is really, really hard to author extensions for
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [t0rakka/mango-examples/.../**concurrency.cpp** (master → 4421a0f)](https://github.com/t0rakka/mango-examples/blob/4421a0f0d70e4f8a0edf06be3b620d30b2a10d96/misc/concurrency.cpp) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dhtn9ny.)^.
Visual Code is much better than VS in my opinion. Much more useful. 
fwiw, there is no C++ support in VS for Mac yet, and most of the code for the C++ extension is shared. We are porting the VS lang service in chunks over time to VSCode. which is why the features are lighting up as they have been. (tag parse for coloring and navigation, then quick info, then squiggles, etc) 
Actually I think we're talking about completely different things here. What I was asking about is a simple, lightweight threadpool that you can drop into your project and which will do fine if you spawn a handful of threads and some thousands of tasks maybe. I think what you present is much more complex and meant for high-performance applications where every microsecond counts.
progschj's pool is pretty good for what it is. There is not much of an design latitude for a minimal mutex-based thread pool, and that one is implemented good enough. I did my own independently, and later realized that my implementation is almost line-to-lline with progschj's. Look also at /u/jrandom 's pool in the comments, which is aloso very similar. The OP's pool, on the contrary, makes some questionable (and even dangerous) choices (see other comments in the thread).
Your post has been automatically removed because it appears to contain profanity or slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/6caavw/a_tiny_c_thread_pool_welcome_to_star_and_fork/dhtwgk3/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I am looking forward to integrate it with nvim: https://github.com/neovim/neovim/issues/5522 https://github.com/autozimu/LanguageClient-neovim
&gt; It is also free VS Code is free, but [not Free](https://code.visualstudio.com/license) (as [in Freedom](https://www.gnu.org/philosophy/free-sw.en.html)). You can use it without paying money, but you are not allowed to reverse engineer it, or distribute it to others.
&gt; You can use it without paying money, but you are not allowed to reverse engineer it, or distribute it to others. Yes you are. From the license page you linked: &gt;This license applies to the Visual Studio Code product. The source code is available under the MIT license agreement. Additional license information can be found in our FAQ. The FAQ further links to [this Github issue on the vscode github explaining everything in more detail](https://github.com/Microsoft/vscode/issues/60#issuecomment-161792005) &gt;The cool thing about all of this is that you have the choice to use the Visual Studio Code branded product under our license or you can build a version of the tool straight from the vscode repository, under the MIT license.
Last time I ported an algorithm to go and benchmarked, it was quite a bit slower. I'm not sure if it's specific to my algorithm, a consequence of a richer runtime or just that code gen needs improvement. Also, there's a whole bunch of excellent libraries for video encoding that are made to be used from C++ or C. You could use them from rust or go, but why bother?
&gt; there's a whole bunch Which others than ffmpeg?
Embedded audio/video software engineer here: A lot of it is about a culture that develops within a certain community. If you work on legacy flight controllers, expect to be tested on Ada, if you work on embedded audio/video (or other signals and systems devices) expect to work on C++. There are actual benefits of C++ here: * These systems often have (soft) real-time constraints, so languages like Python or PHP is unlikely to be adopted, at least in the core system. C++ works well in this environment. * These systems often operate on a fixed energy budget, so taking longer to do things in an inefficient language can be costly. Chips are often selected for lower clocks and power draws, as well. C++ is pretty darn close to the most efficient toolchain system you can get. * These systems often have memory constraints such as 256 MB for a 1080p60 video playback system, or 512 MB for a 4K60 playback system. It sounds like a lot, but it gets gobbled up very quickly because these protocols are often optimized for the wire and not for the processing. You may have to store and process video frames out of order, which means holding on to lots of video memory. Even more so if you're going to permit fast-forward or rewind operations. C++ leaves memory management to the programmer, which fits this model really well. * C++ toolchains permit optimizations that are simply not possible in other languages. For example, [link-time-optimization](http://llvm.org/docs/LinkTimeOptimization.html) can radically alter the program by looking at the entire system in intermediate representation and identifying optimization points such as dead-code elimination, branch elimination, branch prediction, constant folding, devirtualization, etc., that could not be done when linkages are only determined at run-time. The downsides to languages like Rust and Go are that for embedded systems, the silicon vendor typically provides a SDK of supported software. These usually include the bootloader, kernel, drivers, toolchain, and userspace software. The toolchain is often binutils, gcc, g++, and gdb, without all of the other languages. You can use other languages, but they're "unsupported", which often means the paying client will veto that decision. They could be convinced, but it has to be explained in the language they speak (dollars), and it needs to have data support it. It ain't easy, but if you can do that, then you can write the next encoder/modulator in Rust.
[Somewhat related](https://www.reddit.com/r/rust/comments/6b3huc/gstreamer_and_rust_a_perfect_match/). Go has a runtime and can't be embedded as easily as c/cpp/rust.
It sits on the same level as say Sublime Text or TextMate. When I am working on my small projects, I find VSCode to be "just right" when it comes to bells &amp; whistles combined with performance. I use vim for small scripts usually (or if I am making a small change and I'm "already there") and I'll use Eclipse or the like whenever I am working on larger projects as the extra bells &amp; whistles make up for the sluggishness.
Simply put, anything with videos is enormously resource intensive, both in processing time and resource use. C++ is fast, has amazing tools for optimization, and can handle stuff like SIMD. Then C++ wins over other performance languages simply from ergonomics - it's much more flexible than many competitors, has better tooling than most of the newer alternatives, and is almost absolutely easier to find people for the project. And finally, after all this time being used in the field, it's gained inertia. The developers in the field have used C++ for so long that the "C++ way" is just ingrained into how they work. It would need to be a fairly big advantage to warrant reworking the mental model.
Check out Kode Studio.
Last night, gcc-7 was backported to Ubuntu 14.04 (same version as WSL) on the [toolchain ppa](https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test)
A language build around a GC and one that had its first stable release barely two years ago. Are you sure you are talking about "better" solutions or did you just miss the hype train - I think Dart is once again the best thing since sliced bread (TM) . 
You're right, this is nowhere as powerful as concepts because it prevents independent libraries from working with one another. I thought it was interesting to show this usage of CRTP though. The main one being adding functionality, we agree on that.
Not quite sure about "flexible" or "finding people" (a C++ developer can learn Rust quickly), but I agree that you probably nailed it with (1) availability of tooling, especially in embedded projects where the vendors have limited SDK, and (2) inertia/maturity, which among other things mean than people are experienced with the libraries/tools/SDKs and doing it in C++ is a known quantity.
OP deleted his post and disappeared which is a shame because the code could be made into solid one with not too much trouble. It's still a good thing the dangers are pointed out because the very same could bite his own production code later on and debugging concurrent code is really painful.
&gt; The downsides to languages like Rust and Go are that for embedded systems, the silicon vendor typically provides a SDK of supported software. These usually include the bootloader, kernel, drivers, toolchain, and userspace software. The toolchain is often binutils, gcc, g++, and gdb, without all of the other languages. That's pretty much the reason that Rust isn't (yet) used that much there. Together with the "infancy" of Rust, that is.
I've worked your remark into the post, it's very much to the point thanks.
Yeah, I've been having problems with the syntax squiggles ever since I included the boost::program_options library in my project....I've tried adding the header file path to the c_cpp_properties.json, but that didn't seem to fix it. Then again, judging by the complexity and size of Intellisense, is it really surprising that the VS Code C++ extension doesn't work that well? Even intellisense constantly breaks on my MSVS 2015...I guess C++ is just a very tricky language to parse 
C doesn't provide much information to the compiler, hence optimizations are more aggressive with C++ (exception specification, metaprogramming, value categories, type traits, references, specific casts etc), contrary to what people usually think. The common "C++ is faster" statement is just a side effect of the language's capabilities of letting the compiler know as much as possible. For example, in C, pointers exclude so much information the compiler can't make assumptions and optimize further.
Totally with you there. It's easy to fall in love with your own code but when you look at old code you wrote most of the time you are very disappointed at your past self. Outside parties don't have the same filter so that's why it's really valuable to get feedback. At work it's 50/50 that code goes in as-is after code review by someone else. Some times it's a real revision-a-thon to get anything going forward but every time it has been worth it. 
This was essentially what I was trying to hit on, but it looks like I probably could have worded it a lot better lol. 
The Rust and Go bit was just an aside that I threw out, not serious considerations (hence talking out of my ass). The point I wanted to make was more along the lines of what u/gimpwiz replied with: &gt;There also is and has been a critical mass of c++ work in these areas for a couple decades. Even if a language is a perfect replacement and superior, it takes a long time to unseat the king. I just didn't do a very good job of it.
Can confirm. I've seen plenty of people get Rust running on all sorts of things, from AVRs to the Nintendo DS, it's always required a fair bit of effort on their part. I think the first step for serious embedded Rust will be some ~~crazy~~ pioneering company building a bunch of tools for their own use, then releasing those tools as a product in some way. 
What's SIMD?
just read those original proposals which contains detailed break down.
Compounding this, compilers do really bad once stuff gets thrown into memory. 
&gt; For example, in C, pointers exclude so much information the compiler can't make assumptions and optimize further. In general I agree, but it's worth point out that C99 has `restrict` precisely for giving the compiler extra information which it can use to optimise. Standard C++ doesn't have this, although AFAIK the big three compilers all implement some form of it as an extension.
Now we are talking. I have to say, I think we owe this to jetbrains and microsoft. They brought competition to C++ IDE. Right now CMake support is the first class citizen in QtCreator (much better than the previous version), I can tell because I use QtCreator for my day to day programming and not for Qt only, I mostly use it as IDE for CMake projects. I have very high hopes for ClangD. I how even Visual Studio would aboundan their intelligence engine ( which far far inferiour than than Clang's one ) and go with Clangd. Believe me, no one wasted so much time trying different IDEs. I am obsessive. and I admit it. QtCreator with Clang Code model is the only ide which provides full functionality as true IDE with great performance. with this change, I have to try eclipse again.
&gt; Making Base's destructor virtual will result in the expected behavior: &gt;&gt; Destroying derived &gt;&gt; Destroying base How does this work? How does it know to also call the base class's destructor?
There's a whole bunch of separate libraries for specific formats (most of which ffmpeg can wrap so you generally don't use them directly...).
So is it simply adding a base destructor call to the end of the derived class's destructor?
I dunno why you got downvotes. Sometimes reddit is stupid.
&gt; If I was CEO of a company that just suffered millions in losses due to a memory safety bug in purchased software, I'd be demanding that the vendor use a memory safe language. You'd lose tens if not hundreds of times more money rewriting the software in another language. Which could just result in a slower, unusable product.
Basically yes.
C++ doesn't have *methods* , but different kinds of functions, one of which are *member functions* . If you read the standard, you'll find zero mentions of methods.
Are your slides online somewhere?
More fun facts about vtables: (collected from experience and not standards, use at your own risk) The address of the virtual function table (if your debugger will show it to you) can serve as a poor-man's run-time type identifier. This is surprisingly useful with debugging dumps from stripped binaries*. The address of the virtual function table "rolls back" while processing a destruction chain. If you are managing memory manually (via placement new and explicit destruction\*\*) without clearing the data you can identify "destroyed" objects in memory by these values and stale bare pointers\*\*. \* Yes, some people have to debug crashes that only appear in stripped release binaries, welcome to the jungle. \*\* these things should probably be avoided unless you are working on embedded systems with memory constraints and terrible support for STL and modern C++... I'm looking at you Xbox,Xbox360,PS,PS2,PS3! 
This is why you use std::size_t for indices.
Unless you need a C++ library. There's kinda sorta no reason to use C unless your platform lacks C++ support, which has happened to me when working on obscure platforms. You can always code C style inside a C++ environment if you like. It's one of the idioms it supports. I have done this and it works well.
Sounds like game development :)
Maybe "method" was not defined in the standard, but it's OOP term, and C++ implements OOP.
Yet another PVS-studio advert.
Signed overflow is UB; `std::size_t` is _exactly_ what's called for here.
The poor-man's RTTI can be effective, but an important warning should be heeded: The vtable pointer can't always be assumed to have the same address as `this`. A compiler may have to choose between locating a vtable-less base class at `this` *or* the vtable. Last time I checked, major compilers differed in this decision.
Yes I like how he always adds subtle humor at places in his book(s), too. Also I think the calculator example is awesome, I've extended it over and over and learned a lot, use it everyday almost at uni.
Largely a lack of time and resources on my end. There are some problems that need solving before we can start packaging libc++, most importantly how we want to deal with installing multiple versions. Unlike LLVM/Clang that can version and install multiple different executables next to each other, the same doesn't hold for libc++. IDK much about debian packages so I'm not sure the best way to handle this.
Chrome and Chromium are significantly more different than VS Code and whatever the built-from-source version is called. Chrome includes additional closed-source components, while VS code differs only in the branding.
Oh, it gets even worse than that. There is no guarantee that there is only one vtable pointer! Though, these are the cases when *_cast&lt;&gt; behavior will surprise most people and many other things violate common sense.
It's largely a question of LLVM support; Rust itself doesn't have direct support for such things, but there are crates like [this one](https://github.com/aweinstock314/llvmint) that provide access to LLVM's intrinsics.
What you are saying may be true for the VSCode source, but not for the VSCode product you download from code.visualstudio.com.. The license for that explicitly disallows freedom 0, freedom 1, and freedom 2, at least.
Again. You can't buy it, and it's priceless. Go away troll.
The most interesting part about vtables comes up in the context of multiple inheritance. You could do another blog post about that.
And the final piece is virtual inheritance.
https://web.archive.org/web/20170202031016/https://www.viva64.com/en/order-faq/#ID0EWBAG Read that entry, pay attention to the sexism.
Ah geez that's disappointing. 
The IDE yes, only work on Windows, but you can develop and deploy to Linux(only Intel processor by now), OSX(and iOS) and Android.
And most of us can't even appreciate it because of their weird licensing and lack of support for individuals and/or one-off purchases, 'indie', student, etc. The idea of my purchased software ceasing to work when I stop paying 'maintenance' means I'll never buy-in. Can understand no more updates after x time, though. Gotta make money somehow!
&gt; I'm happy to switch to Python if people prefer and if there's a comparable benchmarking library. Why not a _C++_ library? [Nonius](https://nonius.io/)
I think vtable is implement-defined..
FWIW, gcc has several subdirectories called e.g. "5", "6" and "7" below "/usr/include/c++" and "/usr/lib/gcc" so that multiple versions of libstdc++ can co-exist. With `update-alternatives` you can easily switch between different versions. Why would such a scheme not work for libc++?
Having multiple vtables happens all the time when using interfaces. Every interface and every base class's interface, and every base class which has virtual functions not from an interface, adds another vtable! 10 vtables for you, and 7 for you...
He has a great personality. The man is a genius, I'll give him that. As a teacher? I don't maybe perhaps the thing is *&lt;mumbles to himself&gt;* he's passable.
I cannot vote up this reply enough :)
Disagreement on this list is expected. Here's mine. File extension - I don't think it is a language feature at all. Reference type - I don't think it is a near-duplicate. Pointer and reference are of different semantics. Imagine `T* smart_ptr::operator*() const` vs `T&amp; smart_ptr::operator*() const`. Reference passing - &gt; it can easily hide the fact that another function can change the value of a variable even though no function has a pointer to the variable. With function declaration, I don't know how to hide it. Variable initializer - Actually, the situation is worse than that... Optional argument - I don't think C variadic function counts as "optional argument". I would compare C variadic function with C++11 variadic template. Compound data - In C++, class and struct are synonym. Member hiding - Linkage and member access control are quite different.
I used to think that references are redundant, until I learned operator overloading. If I have two `std::vector`s and I want to compare them using operator==, I most likely don't want to pass them by value, "pass by address" seem unnatural in this case and actually doesn't work in C++.
You're right: it's only equivalent for classes with a user-provided default constructor.
People find me strange if I say I first read all his book cover to cover. It's always interesting. Those books are not just references, you see a lot of work put in them. And some nice jokes.
[Google benchmark](https://github.com/google/benchmark) also figures out the iteration count necessary to get statistical significance. 
Any experienced GPU-Devs here, especially CUDA-Devs? I'd like to hear your thoughts about this. Is it "nice, but nothing you'd use in practice"? Do you see the dominating position of NVIDIA/CUDA changing in the next +5 years?
Years ago I used to work somewhere with a coding standard that said "no references, they are just a confusing way to write pointers". But that was using cfront as a compiler, and there was no STL. I assume they've learnt better.
Another alternative is to use the [OpenMP accelerator model] (http://processors.wiki.ti.com/index.php/OpenMP_Accelerator_Model_User%27s_Guide) which got its inspiration from the [OpenACC model](https://www.openacc.org/).
I can't say I'm very experienced, especially not with the current state of things, but a few years ago I was doing some work with GPU using mostly CUDA, but also some OpenCL (to see if we could use it, basically). My take on SYCL is that it's exactly how things should've been those years ago. OpenCL is so ugly, the Khronos Group never intended anyone besides tools developers to actually *use* it. CUDA was a lot better (it doesn't make you put kernel code in strings, for god's sake), but is also plagued with lots of BS that SYCL appears to do away with. I say good riddance to bad rubbish, and if it's built on top of OpenCL then there's a decent chance this could see wide-spread adoption. A cause for celebration, if ever there was one.
&gt; might work fine if you're a student Then it does its job. It's a course textbook geared towards novice programmers, some of whom may have never programmed before.
Shared memory is essentially using the cache as scratch space instead of cache. It's fast and it can be shared between all the threads in a block (a chunk of threads), but it's very space constrained. It doesn't use a different address space. It's just a memory window without a global memory backing store. 
This is `__local` in OpenCL, which is also exposed by SYCL. 
It's not going to displace CUDA unless it can actually run on NVIDIA GPUs. Right now it just supports Intel and AMD. ~~It also looks like it would hide the abstraction of blocks in CUDA. Block sizing and interthread communication in a block can be really important in CUDA so it's hard to imagine this displacing CUDA without that.~~ There are a lot of things I just can't tell from the the short write up. Are the texture units exposed? Can you do asynchronous work submission? Does it support dynamic parallelism? * Edit: Got a question about blocks cleared up
I used the simplified interface for specifying the data; you can describe blocks (work-groups) in a similar manner to OpenCL using ND ranges.
I'd take anything over raw CUDA or raw OpenCL if it's fairly lightweight, available on all platforms, modern C++, and an open / open source solution.
Well, that's simple, the alternatives ​were even worse.
very cool how it integrates with the parallelism ts that said, i'm not going to register to download a beta. when will it be on github?
you're not checking whether any of your calls fail
Funny enough many people say the same about C++. It became popular because alternatives at the time were worse and it is a cross-platform meta generator, still it does its job and for now there aren't many alternatives that will easily overthrow it and became de-facto "build system".
The answer to your question is obvious: There have been many reviews in between AFIO and Outcome. **Why did they not have this problem?** If it is still not clear to you: **What else do the Outcome and AFIO reviews have in common?**
you mean when im trying the get the window and process id? those dont fail (that's why I deleted that code)
I don't think any lines were crossed (yet).
This! You'd think that the person who came up with the CMake syntax would know a little C/C++ and make it familiar=easy to learn. Instead this person decided to try something new that the world has never seen before!
https://www.gnu.org/software/gsl/manual/html_node/Incomplete-Gamma-Functions.html
[Gamma function](http://en.cppreference.com/w/cpp/numeric/math/tgamma). [Natural log of gamma](http://en.cppreference.com/w/cpp/numeric/math/lgamma) might be useful too from the looks of that wikipedia page. So you just need to write code to calculate the gamma distribution. That's just translating math to C++. Shouldn't be too hard.
&gt; If it is still not clear to you: What else do the Outcome and AFIO reviews have in common? They have many things in common, one of which is that they are both libraries that attract a lot of reviewers (a lot for Boost standards is &gt;5). This means that a lot of people find these libraries interesting/potentially useful enough to invest their own free time into giving feedback, which is good, and it also means that depending on how you are following the mailing list, things can be hard to follow, which is bad (things get discussed/explained twice, etc.). Still it is enough for somebody to make a condescending comment and receive a condescending answer for things to heat up. I had this feeling multiple times while reading the thread, where somebody re-asked/re-answered a question making it sound like "are you too stupid to understand my question/answer". It is maybe sad that I kept reading because this is how it always has been, but being condescending/passive-aggressive doesn't really help anybody here. IMO if everybody would be actively trying to be nicer to each other these things wouldn't happen. &gt; There have been many reviews in between AFIO and Outcome. Why did they not have this problem? Boost.SIMD had its own fair-share of drama as well, not the same kind of drama, and provably unavoidable drama anyways, but everybody could have been still nicer to each other.
&gt; So you just need to write code to calculate the gamma distribution Yes, but it is the same problem stated a bit differently - gamma distribution is proportional to incomplete gamma function
C++ AMP was meant to be it, at least as far as 'available on all platforms' goes. Sadly, Microsoft doesn't seem to be giving it much TLC right now, and other compiler makers (e.g., Intel) seem to be less interested in having their own implementations.
Yeah, reading some more about them, the equations given for incomplete gamma functions use a gamma distribution and the equation for that needs the lower incomplete gamma function. Bit of a chicken and egg problem. 
&gt; and classifying it as "external library" is impractical That's debatable (we're a non-boost shop except for standalone asio). Anyway, there's an implementation of the quantity OP wants in cephes: https://github.com/jeremybarnes/cephes/blob/master/cprob/igam.c (except that they'll need to multiply by tgamma(a), but w/ever) Also if they're trying to evaluate something out in the tail of the distribution, sampling isn't going to be efficient or accurate. 
Sounds like you haven't seen [waf](https://waf.io/) yet.
how does one debug things like that? I'm hoping to get into the industry somewhere as a graphics programmer and this would be useful to know - I'm already working as a graphics programmer (intern, but somehow with full workload :v) on a VFX program and need to debug some crashes on specific hardware (also, its vulkan woo)
Maybe this paper is out of date, but an ["expected" proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4109.pdf) describes a "map" and "catch_error" syntax. return safe_divide(j, k).map([&amp;] (double q) { return i + q; }); Has that been dropped? This usage doesn't seem to work in Boost.Outcome, but it did in ptal/expected.
Given that it mixes high-level abstraction and some of the key low level features (`__local` for shared memory) that allow for the best GPU acceleration possible, I think SYCL has a great chance. As /u/Qauntumtroll pointed out, both APIs are kinda gross. I am *still* irate that Nvidia encourages usage of their vector types but *doesn't provide operators for the bloody things*. OpenCL is all kinds of ugly, [but given that it's merging with (or becoming more like) Vulkan](https://www.pcper.com/reviews/General-Tech/Breaking-OpenCL-Merging-Roadmap-Vulkan), that might improve shortly. So SYCL can only really go up from here, because using OpenCL already means it's cross-platform and as verbose and technical as Vulkan can be it's really a clean, well-defined API. Getting OpenCL anywhere near that state will be *lovely* and the improvements should bubble upwards (I would hope). Browsing the SYCL spec feels better than browsing the OpenCL spec, to say the least. disclaimer - I've only written one CUDA project (and it was a 6k SLOC hackjob for a project), and haven't touched CUDA since. Never used OpenCL but a friend wrote an entire rendering engine using it (brilliant but *completely* mental), and I've seen enough of that to be terrified. Long Live SYCL, I hope
It is a slight misnomer. The article is covering the CMake language. 
This is quite an uncommon, albeit audacious, approach to good C++ practices, this needs to be shared.
I sat on that post for three days before sending it. Due to poor documentation, people were not understanding what Outcome does. Something had to be said, else everyone is wasting their time.
This is no different than what Red Hat does with RHEL, for example. The branding is owned by Red Hat, but all the code is freely available, and folks have built CentOS which has literally all the same guts but without Red Hat branding / support.
Built my one once (for science, you know?). After I had the features and the design of the thing down I had to do language. After a day I just went for a JSON library, since I already have another language project going on and I'm lazy. I made sure to write "JSO notation" throughout the documentation though.
Intel did work on implementing C++ AMP in clang. I recall a presentation they gave a few years ago and the LLVM conference on their work. I'm not sure what the status is or what's happened since.
!removehelp
Because Clang looks for libc++ in an entirely different manner than it does libstdc++, and libc++ uses a different versioning scheme for its headers, `v1` meaning ABI v1, unlike GCC which has i different set of headers for every version. Also Clang doesn't look for libc++ under `/usr/lib/gcc`for obvious reasons, so we would have to come up with a new scheme under `/usr/lib/clang/&lt;version&gt;/` but we would have to propose such a scheme on the lists teach the Clang driver about this first. These problems are in no way insurmountable, they just require a lot of somebodies time and effort.
There are no good notations. I don't like "JSO notation" because of braces that take up lines, quotes and forbidden commas at the end (also, the type system is poor).
Well, that's simple, the alternatives ​~~were~~ are even worse.
Thanks for these insights. Since `/usr/lib/clang/` already has different versioned subdirectories, the libc++ binaries would only have to be stored for each released version of clang. One could also store the headers per clang release and let `v1` be a symlink to whatever clang version is active (controlled by `/etc/alternatives/`). This would not disrupt current build scripts that have manual include path for libc++. Would something like that work?
Overall this is a great introduction to the CMake Language, and thank you for writing it. A small issue is that section on find_package is slightly misleading as it glosses over the "Config" mode which occurs if the "FindX" mode fails. In general config modules are superior compared to find modules as they are shipped with the project you are searching for, and therefore not tied to a CMake release.
The best part is `if` statements. `YES` is true, so is `Y`, but `YE` is a variable which will resolve to false if it doesn't exist. `NOTFOUND` is false, so is `BEER-NOTFOUND`, but `BEERNOTFOUND` is a variable which you can set to true. Incredible.
Qt5 is the most popular project that provides Config mode support ( That I am aware of ). 
It's not covering the important parts that you need when writing a CMakeLists.txt for your project. It is very scripting specific.
Very nice idea :) could be useful for configuration stuff
I heard it is coming in December 2017 (according to Amazon) Publisher: Addison-Wesley Professional; 2 edition (December 11, 2017)
`frozen::bits::next_highest_power_of_two` is using a 32-bit algorithm for `size_t`.
Lakos' lecture on allocators is also great (and a lot of fun). There is a 100 minute version from ACCU on Youtube.
Link? 
QMake is really only intended to facilitate simple build systems, maybe with some Qt features in the mix. CMake has far more powerful and comprehensive features. In my experience, most production-level C++ projects are going to be big and complex, necessitating a powerful build system. I wouldn't criticize anyone for choosing QMake over CMake, but it's a moot point when it comes to projects that QMake wouldn't be able to handle in the first place.
People involved with Boost can be passionate but generally they all want to see the language move forward. Boost is known for high-quality libraries which is largely a result of the review process. That said - I agree and it is really sad that sometimes reviewers/authors leave the bounds of civil discourse. It can be hard to have your work criticized and it can be difficult to respond as a reviewer to get your point across. Giving the other party the benefit-of-the-doubt seems to be a skill that has been lost in the current era of internet. Not all reviews are toxic. PolyCollection was just accepted after a very civil exchange. While the Outcome review is a little more energized and there is some frustration, I think it has managed to stay out of the name-calling mud and mire so far. I hope all parties continue to remember we are all trying to achieve better. I also hope that at some point an actual review is submitted. (o;
a lot! haha
Not only that, but despite being on chapter 6, you should do yourself a massive favor and go to the appendix concerning FLTK, install it, then go to chapter 12 (where the graphical chapters begin) and work through the drill and get the first example code to run the chapter opens with. It probably won't, and now you'll need to consider whether it's worth it to spend the many, MANY hours searching for the corrections you'll need to make to get it running. I eventually got it working, but it wasn't without great deals of stress, frustration, and about 6+ hours. That's why I dislike the book. It's not a bad book, but if you can't work through the graphical chapters, there isn't much reason to read the book at all. You're going to miss basically all of the aspects of OOP, depth in encapsulation, inheritance, and more. It's a shame, because it's a fun read, and Stroustrup is a really colorful character. I guess that's the price you pay for writing a book that incorporates tailored code and external libraries.
Let's see... std::terminate in ctor; it is better to call notify after you unlocked mutex; no handling of job's exceptions (or requirements imposed); in various places push_back calls can throw and screw your state; quite confusing organization of tasks and jobs (btw, typically job consists of tasks, not other way around :)); casting size_t to int and etc. Yep, upvote and share away! ;) P.S. One more -- std:function cctor can throw
Code seems quite a lot more complicated than [this](https://github.com/progschj/ThreadPool)? Doesn't look like the best implementation to me?
Here is one way: my_ctor() try { //create bunch of threads } catch(...) { //do the same thing i do in dtor throw; } 
Ok, I guess what I mean is: Which part in the c'tor can call std::terminate? So which part should be wrapped, or the whole? And do you have any idea why the author didn't do it or nobody submitted a PR/Issue yet? Is it something that is more of a design choice and not really a bug?
std::thread ctor can throw. About why it isn't an issue -- didn't you see recent posts? A lot of people got tired of having to think about lack of resources and demand C++ exceptions to be switched off. They'd rather have your program die mid-flight than being inconvenienced in this way ;-)
Meanwhile using gradle instead of cmake. 
Understanding the CMake language is pretty helpful when writing (or debugging someone's buggy) Find modules.
Yes and no. You can always have your own FindXXX.cmake in your module path too, they won't be tied to a release. Also, if you require a version new enough and fixes have been made upstream that don't require any new feature, you could shadow the upstream one with it.
Assuming by rvalue parameter you mean rvalue reference, then yes, there's quite a difference: the former moves out of your original object into a new one, while the latter is just a reference like any other except that it will only bind to rvalues. For this discussion, the former is the right approach (no reference involved on the parameter) since the whole point was to own a copy of the data.
Sorry, yes; rvalue reference :) I guess my confusion is that if I have a function taking an rvalue reference, a std::move into it is seemingly valid. Oh, I see what you're saying - if a copy is required, move into the value param which makes a copy, otherwise use an rvalue ref param, which of course will move out what it's given (depending on the function's implementation)... got it! So let me rephrase... what's the difference between passing a value into a value parameter vs moving it into the parameter, if both lead to the function taking a copy?
Are there better alternatives in 2017? 
&gt; what's the difference between passing a value into a value parameter vs moving it into the parameter, if both lead to the function taking a copy? They both lead to the function having its own separate object with the same data, but that doesn't mean it's necessarily a "copy". The former will make a copy, or error out if the type is non-copyable; the latter will move, or make a copy if the type is non-movable, or error out if the type is non-copyable and non-movable. &gt; Oh, I see what you're saying - if a copy is required, move into the value param which makes a copy, otherwise use an rvalue ref param, which of course will move out what it's given (depending on the function's implementation) The general guidance is: take a const-ref if the function doesn't unconditionally need its own copy of the data, or a value otherwise. Taking an rvalue-ref is a more advanced scenario and is not usually done in isolation (it's usually one of two overloads); forget about that as far as "general guidance" goes.
I'm not sure if your register_function does what you think it does. m_userF get's accessed at function execution, not at registration. Hence if you register two functions, only the latter will be called from Lua. 
I prefer [EDN](https://github.com/edn-format/edn) \([Implementations](https://github.com/edn-format/edn/wiki/Implementations)\) to JSON for the following reasons: * It's designed to be data-centric with well defined notation for arrays, lists, sets and maps. * Supports standard (Java-ish) literals for integers, decimals, characters and booleans. * Also supports lispy literals such as :keywords. * Doesn't require identifiers to be "quoted". * Commas are entirely optional.
My version supports synchronization - it's possible to wait for a bunch of related jobs/tasks (whatever your terminology is) to complete. I guess there is no best implementation. If you don't care about sync then sure, go ahead and use the one you linked. But most use cases requires some form of waiting. As an example, I use (a variation of) my implementation in rendering code. I allocate some memory, enqueue jobs to fill this memory block with VBO data, and then send it to the GPU. You can't do that without some form of waiting.
Fixed! Thanks \o/
Low-quality bait.
You could future-proof it and makes sure it works with any integer that's a power of two thanks to `std::numeric_limits`. I've got an equivalent algorithm here: https://github.com/Morwenn/cpp-sort/blob/master/include/cpp-sort/utility/bitops.h#L50-L61 The loop is generally unrolled under any half-decent optimization level, so it shouldn't incur any overhead :) EDIT: Ok, I was wrong about the "half-decent" optimization level. Actually, you need -O2 with the latest Clang and -O3 with the latest GCC to get a fully unrolled loop. It shouldn't make a difference though since you're only using the function in a `constexpr` context.
I tried to turn your GitHub links into [permanent links](https://help.github.com/articles/getting-permanent-links-to-files/) ([press **"y"**](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) to do this yourself): * [Morwenn/cpp-sort/.../**bitops.h#L50-L61** (master → c7ddbb9)](https://github.com/Morwenn/cpp-sort/blob/c7ddbb92800d5267a629c6ea43ad9186377f2641/include/cpp-sort/utility/bitops.h#L50-L61) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dhx9xph.)^.
Some thought about the return type: if the function allows passing in multiple typed but convertible values, it has to return a value of common type (or user specified type via template parameter) instead of returning a reference. I had once implemented a variadic `average` function returning `std::common_type` as the result. That was necessary since the average of some values is not necessarily the same as any of them, considering `int`s' average value.
Sub-par libs are the ones that crash when you change compilers, and if you need synchronization then you're fucked with such a lib like the one you linked. Sorry. I recognize my errors when I make some, I don't try to make them pass as a better solution than others'.
Congrats!
qmake is actually as bad / worse as a language. Namely, the way it handle escaping, scripting, etc is awful. Implementing a code generation step with qmake is a pita for example, also little/no support for dependencies, etc On the other hand, QBS is quite great and works well as a general purpose build system.
you can do alot in cmake and after I really understood it it was very easy to use - i actually find the strings and commands only syntax elegant. the reason for sometimes strange seeming behaviour is that simple things can be don very simply. e.g. set(sources path/to/file/a.txt path/to/file/b.txt ) is much nicer than set(sources "path/to/file/a.txt", "path/to/file/b.txt" ) (all those commas and quotes are just uneccessary when working with files) return values would have been nice - however i can simulate them also structured data like maps and serialization to/from json is implementable in cmake - no problem even concurrent scripting is possible if you're interested look at [https://github.com/toeb/cmakepp](https://github.com/toeb/cmakepp) cmake imo should be understood as a cross platform shell language and all the hate is unecessary - just a bit more education as the op is doing right now :) 
Actually, Boost.PolyCollection should perform better as `std::vector&lt;boost::variant&gt;` does not pack same-type elements together and misses CPU branch prediction opportunities. In a sense, a more similar data structure would be a `std::vector&lt;boost::variant&gt;` sorted by `std::variant::index`. 
To be honest, that snippet doesn't look like much of an improvement at a glance. It's almost the same, in fact. I was thinking of a much more radical change, maybe something like (very loosely inspired by gradle): const sdl = find("SDL", "2.0.*") const boost = findOrFail("boost") const mySources = [ "library.cpp", "library.h" ] targets { simpleLib { type = staticLibrary sources += mySources sources += dir.recursive('src', '*.cpp *.h').filter { name != "myExe.cpp" } if platform == "Android" { sources += getAndroidSources() // This can be a custom function included from a different file } } myExe { sources = "src/myExe.cpp" use(boost.components.serialization) // This would set include directories, compile definitions and linked libraries if sdl.found { use(sdl) definitions += "HAVE_SDL" } includePath += simpleLib.includePath libraries += simpleLib // This would set the proper options on compilers that support it, do nothing on others errorWarnings = warnings.missingOverride } } if compiler.isClang() and build.debug and file.exists(path.projectRoot + "/extra.cpp") { // Modify targets after they're created... targets.myExe.sources += (path.projectRoot + "/extra.cpp") } I'm not saying it would look anything like that, this is just to showcase how much different from the cmake language it could be. Ideally it would be a statically typed language, so you could have tooling with **full autocomplete for all data structures and available functions** and navigation - that would make it a lot more user friendly, because having to constantly look up all this crap manually is one of the things that makes any build system experience so poor.
A printed copy of Pratical C++ Metaprogramming was given to each attendee of C++Now last week (courtesy of Christie Digital).
What if multiple coroutines running on different threads `co_await` on the same `corsl::future` while it's not ready? From what I see in your code, other consumers will be dropped in that case since you simply use a [lock](https://github.com/AlexBAV/corsl/blob/master/include/corsl/future.h#L144) for `await_suspend` and there's only one slot for the continuation. And your `await_ready` is also not thread safe since it simply [reads a non-synchronized value](https://github.com/AlexBAV/corsl/blob/master/include/corsl/future.h#L38).
&gt; I assume they've learnt better. Do we tell him about the [Google Style Guide](https://google.github.io/styleguide/cppguide.html#Reference_Arguments)?
I never knew it was so hard to stay updated about the new C++ features. Everyday they create new ones. 
m_userF doesn't need to be accessed at registration because it's used only in order to access an already registered function. Basically it's the key that tells which one from the functions inside m_userFunctions to execute
It was meant to feed into standardization, which it has done. The Parallel STL (now part of C++17) is an evolution of C++ AMP as well as CUDA. Parallel STL follows the AMP model of parameterizing the algorithms, using an execution policy parameter instead of putting the policy in the name. The main parts of AMP that were not standardized are `array_view&lt;T&gt;` (much of which is now being standardized as `span&lt;T&gt;` except not the multidimensional and disjoint memory space copy control parts) and the `restrict` clause (which may or may not be important long-term as GPUs are able to run more and more of full C++).
&gt; Anyway, how can you handle, for example, an exception in push_back ? You can't. yes you can. This argument reminds me 2 decades (or more?) old claim "you can't write exception safe stack". Look it up -- you'll find answer to your question :-) &gt; Agreed about releasing the mutex before calling notify to avoid a pointless context switch. Well, it is ok on some platforms (that optimize away associated problem). But general advice is to do it outside, if possible. 
Ohhh, I was actually looking for something like this and dreaded using some 5 year old library or writing it form scratch or using the experimental&amp;not very efficient std::any.... this might be absolutely perfect, thanks a lot :D
&gt; That isn't really up to you to decide. Yes, in fact, it is up to me to decide the use-case of the code I write, as well as the constraints and guarantees (or lack thereof) it provides, thank you very much. Most code don't handle memory allocation failures. Not because devs like to write bad code, but because it is impossible to handle dynamic memory allocation failure. Plain and simple. If you need N bytes to store the result of a computation, but you have at most N - 1 bytes left, there is nothing you can do. Sure, sometimes you can. Sometimes you can just free some memory you used for caching or something, and retry. But that's a bandaid. If your program's working set requires more memory than you have, you're screwed. If calling `push_back` with an int is causing a memory error (because that's exactly what you're talking about in my code) then there is nothing more to do. Throwing an exception will just delay the inevitable termination of the program, and may even cause more trouble (what if the exception handling code itself allocate memory? Event printing an error message could raise another OOM error). Now imagine this scenario : you have a function "allocating" 1024 bytes of memory on the stack, be it with `char foo[1024]` or `alloca` or otherwise. But, too bad, only 512 bytes remains on the stack. It crashes (or not, which is arguably even worse). Do you check that in every function ? No. Of course not. Even if you wanted to, you can't. You *expect* the caller to have reasonable stack size available when calling your code. I expect the caller to have reasonable heap size available when calling my function. As long as it's documented, it works pretty well. Considering my use case when implementing this, which is an application using at most *megabytes* of RAM but having a soft real time contraint, the choice was easy. Of course if you're implementing a critical system where an OOM crash can kill someone, or even just a kernel/driver/important daemon or something, you may have special contraints about OOM robustness. But then, maybe you should use libraries that takes that special requirement into account. I won't slow down my code for everyone just because a few people need that robustness. Those people can use other libraries more suited to their needs, and there is nothing wrong with that. Just like there is nothing wrong for me to not handle an issue that is at most extremely hypothetical in my use case, to satisfy requirements I don't have. Desktop PC nowadays have Gigabytes of memory, often 8 or more. And then there is the swap, which was precisely implemented to prevent the very issue you're talking about (OOM crashes), often adding hundreds of gigabytes of potential memory to the mix. There is NO point in handling that, unless you have very special requirements. And certainly not while it has performance implications.
QMake is honestly surprisingly flexible. I have a project that builds a bunch of shared libraries and an application, and does tests on one QMake project. It's not pretty. It's kind of ugly. But, maybe it's not really that much uglier than the CMake version would be. And at this point, I think we can all agree it could hardly be uglier than the Automake version would be.
I'm supposed to be able to untar and include, right? Can you help me understand this compile error? include(ExternalProject) ExternalProject_Add( outcome URL https://dedi4.nedprod.com/static/files/boost.outcome-v1.0-source-latest.tar.xz CONFIGURE_COMMAND "" BUILD_COMMAND "" INSTALL_COMMAND "" ) add_executable(main main.cpp) set_property(TARGET main PROPERTY CXX_STANDARD 14) target_include_directories(main PUBLIC "${CMAKE_CURRENT_BINARY_DIR}/outcome-prefix/src/outcome/include") -- #include &lt;boost/outcome.hpp&gt; int main() { boost::outcome::expected&lt;int, int&gt; e; } On VS 2017, I get [this long page or errors](https://pastebin.com/FWd47dV9).
See [Fix with support for VS2017 Update 1](https://lists.boost.org/Archives/boost/2017/05/234938.php)
I guess he means the link to the paper at the end of the blog post: http://dl.acm.org/citation.cfm?id=3078160 That's a regular ACM publication, and the fact that it's a "closed access publication", doesn't have anything to do with the openness of SyCL. Though most journals/conferences offer to pay to make publications open access - maybe in that case CodePlay should do that, if possible.
I don't know if this has been mentioned anywhere, but is there an ETA for when the videos will be online (assuming they will be, of course)?
&gt; Though most journals/conferences offer to pay to make publications open access - maybe in that case CodePlay should do that, if possible. This ranges from ~1000-5000$ . Most of the journals allow the authors to distribute a draft of the manuscript (that is, pre editorial changes) without consequences, but don't know about ACM.
@tcbrindle: I decided I'll provide a `variant.hpp`, similar to how Catch does it. I think I'll only have it available as a download on each release, rather than keeping an outdated copy in the repo. What do you think?
That's just a macro that pushes `__FILE__` and `__LINE__` into a vector, not exactly what I'd call a "portable stack trace". I was expecting something that wraps [`backtrace()`](https://linux.die.net/man/3/backtrace_symbols) and [`StackWalk()`](https://msdn.microsoft.com/en-us/library/windows/desktop/ms680650(v=vs.85\).aspx), like in [this tutorial](https://oroboro.com/stack-trace-on-crash/). [edit: jesus, this thread is a clusterfuck]
&gt; I have a project that builds a bunch of shared libraries and an application, and does tests on one QMake project. It's not pretty. It's kind of ugly. But, maybe it's not really that much uglier than the CMake version would be. Seems to me that especially if you used so-called "*modern CMake*" that'd be a breeze to implement in CMake, no ugliness necessary.
Probably not terrible, but I still find CMake syntax just sort of inherently ugly.
You're overthinking things. You should follow the instructions on https://ned14.github.io/boost.outcome/introduction.html, so: add_subdirectory( "${CMAKE_CURRENT_SOURCE_DIR}/boost.outcome" # path to outcome source "${CMAKE_CURRENT_BINARY_DIR}/boost.outcome" # your choice of where to put binaries EXCLUDE_FROM_ALL # please only lazy build outcome on demand ) target_link_libraries(myexe PRIVATE boost::outcome::hl) You don't need to set properties or include paths. That's all automated with the above. Alternatively, don't tell cmake anything and simply include the outcome header file directly e.g. #include "boost.outcome/include/boost/outcome.hpp"
And yes, Microsoft decided to ship Update 1 exactly when I froze Outcome for review, and of course it didn't compile. So I made a special cherry pick of master branch just for VS2017 Update 1. Develop branch also works too of course, though it's seen very heavy churn this past three weeks and is probably broke somehow.
You really, **really** should use boost.stacktrace. It has a far superior implementation quality to almost all other stacktrace libraries, including an actually reliable backend for Windows which doesn't use the crappy DbgHelp.
&gt; The general concept is stack-tracing, period A "stacktrace" is very commonly held to mean a trace of the call activation record entries, e.g. the stack of return pointers, which isn't this. :) &gt; What kind of software are you building where you can't afford to allocate a string and push a vector once per context? AAA video games. One might have potentially have tens of thousands of those contexts per frame (in our case, on the order of a hundred thousand). It's pretty easy to let little inefficiencies like these boil up to the point where they take multiple milliseconds altogether, which is a huge portion of your budget (11-33ms total per frame, depending on target framerate). Worse, it's hard to find and measure those inefficiencies because they aren't individually big and easy to spot. And you're in real trouble on mobile or some console platforms where memory budgets mean all those variable-sized allocations are going to fragment your heap to shreds. And those are exactly the kind of light-weight diagnostic aids you might want to keep enabled in optimized release builds that need to hit those frame budgets on years-old consumer hardware. Same performance concerns would be present in real-time software, high-frequency trading, high-availability software or anything sensitive to heap fragmentation, tiny embedded systems... really, many of the kinds of things for which one might choose C++ in this day and age. :)
&gt; 3) It is a portable stack trace. And to people who have experience with this sort of thing, it is neither. You do seem to have an unreasonably combative attitude about comments here, so I wonder why you have posted at all, if not to receive feedback. You can keep calling it that, but everyone else in the world would assume you are talking about what "portable stack trace" *actually* means. 
&gt; add_subdirectory( I tried that too, but it doesn't seem to play nice with cmake's [ExternalProject](https://cmake.org/cmake/help/latest/module/ExternalProject.html) add_subdirectory( "${CMAKE_CURRENT_BINARY_DIR}/outcome-prefix/src/outcome" # this is where ExternalProject puts the untared src "${CMAKE_CURRENT_BINARY_DIR}/outcome-prefix/src/outcome-build" # this is where ExternalProject wants to put build artifacts EXCLUDE_FROM_ALL ) This results in `FATAL: You must set a binary directory that is different from your source directory.`. And it turns out it's not the second argument it's complaining about; it's the first. It doesn't like the untared source being inside the CMAKE_CURRENT_BINARY_DIR -- which is the default location ExternalProject uses. &gt; Alternatively, don't tell cmake anything and simply include the outcome header file directly e.g. I changed my cmake to get rid of all mentions of ExternalProject, and instead I just manually put the untared source in with my main.cpp and included it as you suggested, but I'm still getting the same compile errors as I was originally. :-/
And it's a hundred times more complex while not offering anything in return but automagic check-pointing. Which is why there are plenty of situations where something like this is a viable alternative.
I guess I'm taking this discussion on a tangent, but if all you do is shoot down any suggestions/discussion, why did you post it here?
Say you have these classes: struct base { virtual void foo() = 0; }; struct child_1 : base { std::string name; void foo() override { std::cout &lt;&lt; name &lt;&lt; "\n"; } }; struct child_2 : base { std::array&lt;int, 10&gt; data; void foo() override { std::cout &lt;&lt; "data = { " &lt;&lt; data[0]; for (int k = 1; k &lt; data.size(); ++k) std::cout &lt;&lt; ", " &lt;&lt; data[k]; std::cout &lt;&lt; " }\n"; } }; You cannot have a vector of `base` directly, you'd need to store pointers to them instead: std::vector&lt;std::unique_ptr&lt;base&gt;&gt; But this isn't optimal for branch prediction or cache performance / prefetching. This library effectively allows you to use an interface similar to `std::vector&lt;std::unique_ptr&lt;base&gt;&gt;`, but under the hood it actually stores: struct data { std::vector&lt;child_1&gt; child_1_data; std::vector&lt;child_2&gt; child_2_data; }; That way they are in the same area of memory and all `child_1` instances are accessed together, which has performance benefits. Overall, I think it's a very clever library that seems quite useful.
I never mentioned performance. Having to make manual changes all the time is error prone. &gt; And as an added bonus you get general purpose tracing and descriptions in your stack-traces. And that is positively false, because it's not general purpose, and it's not a stack trace. It's context tracing. Like you see with exception stacks. 
These are not discussions/suggestions. This is arguing definitions and going off on any tangent that will stop discussion from happening. What I'm saying is basically that most of the time, you don't need more than this; and the approach comes with advantages. And no one yet managed to confront that argument, most insisting on finding exceptional cases where it wouldn't work. I often wonder why people in these kinds of environments are so keen on defending the ignorant, abusive and competitive status quo; so willing to trade progress for a brief ego-boost and a couple of minutes of hatred.
&gt; Arguing definitions is really one of the least interesting forms of communication Hah, you might just be in the wrong field then. :p &gt; The obvious solution Is to write the handful of extra lines required to achieve the mandatory level of efficiency for one's domain. :) Granted, your domain may not require what mine does. We each tend to only really think about our own problem spaces, and I'm certainly no exception. &gt; I suspect you don't want exceptions or boost::backtrace's either in that kind of code. Nope. We avoid Boost like the plague as its sole purpose that we can tell is to inflate compile times. I wasn't the one that suggested that you wanted boost.stacktrace, though. :) That said, we do collect actual stack traces sometimes (in the error case, or for - ironically - the heap allocation tracer) in these scenarios because walking said stack is incredibly fast when all you're doing is grabbing the return addresses and streaming the raw binary data to a log. Not fast enough for live production releases, but fast enough to put in optimized development builds and still have a playable framerate on developer machines. An offline tool or external process can process those binary dumps to produce human-readable logs or graphs. Shifts as much of the overhead as possible out of the hot code. And no, we don't use exceptions either, but the general concept you're aiming for here is useful with just about any diagnostic system. It allows you to emit diagnostics at the point of failure (or throw an exception as you're doing) without needing to pass down a bunch of metadata to the leaf functions. e.g., I want to put the file reference of the current game object being loaded, because game objects load dependent resources, and one of those might fail to load. Seeing `file not found` is useless. Seeing `loading foo.mesh; file not found` is still hard to fix on its own since it doesn't indicate why that file is even being loaded. Seeing `loading level2.world; loading enemy.dat; loading foo.mesh; file not found` makes it super easy to go find and fix the broken content. A further more complex feature that can be added (usually on an opt-in mechanism in my experience) is to get the error contexts to travel along with asynchronous requests. That rather necessarily ends up requiring allocations and realization of the logged data unless one goes to rather great lengths that probably aren't worth it for all but the most demanding of situations. &gt; general purpose and powerful enough to tame the complexity I'm facing Fair enough. :)
What if an instance of the type is going to be accessed by different threads (non-modifying operations)?
But misusing a term, and having *multiple people* give you constructive criticism by suggesting you try a *different term* because what is meant by that term in most circles has a specific meaning that is different from this, and then you simply insisting that you have a "portable stack trace" and people are just arguing definitions is just you being combative. But, you know, just continue to do whatever. I don't care. You want to call it that, you call it that. And you'll continue to confuse people, and further, you'll look a little silly. Because you'll just keep getting the same feedback. There's a wiki page on "stacktrace". You can go read it. From /u/SeanMiddleditch: &gt; A "stacktrace" is very commonly held to mean a trace of the call activation record entries, e.g. the stack of return pointers, which isn't this. :) Perfect constructive criticism. So did /u/personalmountains. 
I can only guess he just loves the downvotes. Or maybe it was to get traffic to his newly created projects, and see if they'll give him money. 
I suppose you are just trolling here. Bye. I'm saddened /u/SeanMiddleditch actually spent as much effort giving you any feedback now. 
Dito. I'm not, his comment is the only thing worth reading in this entire thread.
You're argument against boost::stacktrace is simply it's too bulky for your use case. Most people find boost::stacktrace useful because of breath of features it provides, the _lack_ of which is your selling point. You're looking for an argument where there isn't one. I'm sorry not a lot of people seem to find this as useful as you do. It sucks but it really doesn't help your cause (being recognized) if you go around alienating everyone that's bothered to say something about your stuff. 
And yet, all you did was say something shitty back to him and then tell him his was egotistical for arguing definitions. You're an ass. 
This looks super awesome, then I realized its (obvious) dependency on Boost. I'm trying to keep my current project 'pure' mostly for reasons of self-development and coming up with interesting solutions. I wonder how close to this kind of business folks have gotten with the new C++17 features? Variants, visitors, etc. Side-question: is it always the case that using a Boost-based lib requires one to bring in the entire 'Boost' library? I've never used Boost so I'm not sure if my terminology or understanding is correct. EDIT: Thanks for the hint above about `std::vector&lt;boost::variant&gt;` and sorting by `boost::variant::index`. I'm sure `std::variant` in C++17 could be used instead :)
Arguing definitions is egoistical, or do you have a counter-argument that makes sense? How is not agreeing being shitty? And you will know better one day; until then, we will unfortunately have to put up with this nonsense.
&gt; No, that's my argument; that this is a viable approach that's often overlooked. &gt; That's just a macro that pushes __FILE__ and __LINE__ into a vector... 
&gt; Arguing definitions is egoistical, or do you have a counter-argument that makes sense? How is not agreeing being shitty? If you build a bicycle and offer it up to someone and say, "how do you like my automobile?", do you think that it's bullshit for someone to tell you that it doesn't look like much of an automobile? If you stand around calling everyone else "egotistical" for suggesting that you're not giving them an automobile, what do you call that? &gt; And you will know better one day; until then, we will unfortunately have to put up with this nonsense. I'm 50. I've lived in the world of software engineering since I was 19. When do you think that day might be? I think the one that will know better one day will be you. And if you don't, you'll find yourself either a) totally alone, or b) in some field where people would appreciate that kind of idiocy. Try creative writing. Or maybe performance art. And, if you want my feedback. What you've built here is a toy. I don't have further comments about it. It has no utility for me because I can do all that already much less manually. Maybe don't post a couple dozen lines of code as though you've discovered some better mousestrap to the internet and ask for feedback if all you want to hear is "A+, I'm gonna go use this right now! Never thought of this!" 
Just move on, build other interesting things, and let those cool things do all the talking. Good luck. 
I would actually go the other way: keep posting this sort of stuff, but learn to handle criticism. The fact that you learned something, reduced it to something reusable, posted it, added a write-up and participated in a discussion is a _good thing_. I would urge you _not_ to stop. What you need is to get rid of this "me versus the world" attitude. There are a lot of very knowledgeable people here (and some trolls, but that's the internet). Take in the good, leave the bad, learn a bit on the way there, everybody wins. [edit: pinging you in case you didn't see this: /u/andreasgonewild]
How is this over 300 KB for a glorified std::expected&lt;T, E&gt; implementation that only supports C++14, when Vicente's own expected&lt;T, E&gt; implementation is one third that size (100 KB) and even supports C++11? Forgive the choice of words if people are sensitive to hearing this phrase - but this truly does look like over-engineering to me.
Not sure it is worth it to make a post for every trip report. So, also see [Ben Deane's Trip Report](http://www.elbeno.com/blog/?p=1443) and [Kirk Shoop's Trip Report](https://kirkshoop.github.io/2017/05/23/cnow_trip_report.html).
&gt; These are not discussions/suggestions. This is arguing definitions and going off on any tangent that will stop discussion from happening. ♫♪ _Irony_ ♫♪
Use `/u/` rather than `@` to notify people on Reddit. :-] (paging /u/tcbrindle)
Boost is pretty modular and you can pull in just the parts you need. Skimming through the source code of this one in the [detail directory](https://github.com/joaquintides/poly_collection/tree/master/include/boost/poly_collection/detail) it appears to depend on boost/core, boost/mpl, boost/iterator, and boost/type_traits, so really not all that much. 
That's the point though, making a C api 'safe', while technically impossible, since you can't guarantee the API actually is, has been really hard to structure in general in my experience. So I've failed to do it to a 'quality' level on multiple accounts now, and then in that situation, using the API remains an unsafe operation; which means the unsafety proliferates. It feels very un-rust to settle for that mark, and then I get sort of stifled and lose enthusiasm when I realise I failed to do what I expected I could.
That's a massive and fairly unrealistic assumption. For instance, just today I had to dive into the Curl C api...
 Do any pet project or join open source projects to ain experience! With C++, the more you do, the more you learn. Try to follow conference YouTube channels like cppnow, cppcon and meetingcpp
I do follow those YouTube channels already :). They're so cool, I try to watch a talk at least once a week. Also a bit intimidating what some people manage to do with C++. The open source project idea sounds like a good idea :). I should probably sit down and finish at least one of my pet projects, haha :)
You're being picky with something that is controversial, and depends heavily on context. Memory allocation failures cannot be reliably detected, let alone handled. It's possible for malloc/new to return a non null pointer that will page fault without a warning when written to. On a default Linux configuration, only obvious overly large allocations will ever raise std::bad_alloc. Normal, fragmented exhaustion of memory will NOT. Even in strict no-overcommit mode under Linux, std::bad_alloc may not be reliably thrown in some edge cases. More info on this : https://www.kernel.org/doc/Documentation/vm/overcommit-accounting Windows behave in a similar manner. Under these operating systems, std::bad_alloc is nothing more than a safeguard against overly large allocations, resulting from a programming error (use of non-sanitized inputs for example), and do nothing against actual OOM. In my case, I'm allocating vectors in small steps increments. Sure, internally, std::vector probably allocate more than needed, in exponential increments, to amortize the cost of actual memory allocation. But it does not matter: in no event can this create an overly large allocation, so on a classical Linux/Windows system, my code is NOT gonna throw std::bad_alloc. std::bad_alloc MAY be thrown when trying to load a 100GB file, or blindly trusting a `Content-Length` header, exactly as the video you linked points out. In these case, then yes, maybe trying to catch that would be useful. Getting an OOM error by actual lack of memory is a truly exceptional event, than you should check when it makes sense, using appropriate techniques (hint: catching std::bad_alloc is not). Programs that need this kind of robustness use other strategies to get around that problem: not using dynamic memory is one, preallocating and having fixed bounds on everything is another one, preallocating and then distributing chunks of memory via a custom allocator that never overcommits is another. Trusting new and friends to throw std::bad_alloc is NOT. It's just being naive. Plus, you seem to imply that it's an easy fix, and that I should just add a `try/catch` there and there. It's not. I use a free list, what if I can't allocate a task to mark it as free? If I just ignore it then it's a memory leak, ironically. If I throw then one thread will have to handle the exception and the waiting thread will deadlock. Nice. I could prealloc the free list, but then what if the prealloc fails? And if the prealloc went fine, and I create 3 jobs, the first 2 are fine but the 3rd throw a memory error, what do I do? If I increment the job counter then it's a deadlock. If I don't, then some thread will wake up BEFORE the task is completed, and I can't check for that in an exception handler because the thread may very well wake up before I catch the exception (race condition). And then, even if I manage to handle that, memory exception exists in worker thread, too. What if I catch std::bad_alloc in worker_main? Do I stop the thread? Then it's a deadlock. If I don't: race condition and a probable crash. There is no obvious solution and no obvious way to signal a waiting thread that one of the workers got an OOM. Handling memory error is not a simple `try { ... } catch (const std::bad_alloc&amp; e) { ... }` there and there. This is just the illusion of security. It requires a different design, much more complex, and much slower. And it assumes that std::bad_alloc is reliable. It is absolutely not the case, as I said earlier. &gt; Oh so you're worshipping at the cargo cult of performance. So you benchmarked with/without exception safety, right? I don't worship any cargo cult. I considered the implementation of exception safety, concluded it would be quite difficult and slow down things a lot due to massive locking, for absolutely no gain, because OOM would still crash it anyway, so I discarded the idea. Seems quite rational to me. Telling people to catch unreliable exceptions everywhere at the expense of everything else all the time seems more in line with the idea I have of cargo cults, however. &gt; Okay Rasmus Lerdorf. Ad hominem and (condescending/ironical) appeal to authority does not warrant any kind of answer. Now I don't answer this for you, as much as I answer this for people reading this discussion, in hope that they will see how ridiculous your arguments are. This could have been a nice discussion about OOM, but that's completely out of the scope of my thread pool implementation. The article was meant to be an introduction to the C++11 threading classes, and how they can interact to create useful systems (in that case, a thread pool), as long with an implementation that is reasonably efficient as well as reasonably powerful and readable, while in no way perfect. You're completely missing the whole point of the article.
learn how to use build systems &amp; cpp infrastructure correctly - it will keep you from having a ton of headaches ie * cmake, msbuild, make (or whatever build system you're targeting) * dependencies structuring projects correctly: * public headers * private headers * source files * precompiled headers * when to dodeclaration/definition separation * dependencies ... learning basic usage of stl and maybe even boost is usefull the programming itself is not that hard to get a hang of but coming from a pretty automated build environment like VS/CSharp you might get more problems than you're used to 
Eta is within a month. We had Bash Films record this year - they are the company that records LLVM and CppCon.
Care to elaborate a bit on private/public headers? I can guess what it is about, but have never heard of such concept till now
Thank you for the great answer! :) Yes, CMake is something I need to definitely learn. Yes, C# + VS puts you in this bubble that makes it hard to get out off.