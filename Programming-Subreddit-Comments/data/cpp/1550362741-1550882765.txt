Btw, being finally able to port it over to 100% pure C++11 is very nice! Back in the day, I had to create my own asm code for different architectures wrt the atomics, membars and compiler barriers.
I think you should be the one testing it and posting benchmarks.
My algorithm takes around 35 seconds for me on MSVC 2017, and around 122'ish seconds for std::shared_mutex. The timings are similar with GCC 7.3 on Windows. Mine wins. Also, a couple of kind souls tested it out on Linux. Read all of the following: https://groups.google.com/d/topic/comp.lang.c++/g6veUOvOAu0/discussion (read all!) Linux Timings: https://groups.google.com/forum/#!original/comp.lang.c++/g6veUOvOAu0/hMIu5VBSBAAJ https://groups.google.com/forum/#!original/comp.lang.c++/g6veUOvOAu0/JGUwfe6eBAAJ https://groups.google.com/d/msg/comp.lang.c++/g6veUOvOAu0/xN97v-pOBAAJ Why can't you give it a go for yourself?
It seems like this is just a read and write counts with atomics, yet you are calling it a new algorithm. What is 'new' about it? Also have you compiled this with warnings? There seems to be heavy reliance on integer overflow wrapping around.
I have also used this with a lot of success. Accept no substitutes.
The whole point of them is that they don't mean anything, they're just generic names for functions. But Silicon Valley managed to find offense in them.
&gt;is extremely easy using CMake If you want to make a library don't force *your* preferred build system on everyone else. There are many, many build systems out there. CMake is one of them. Many people think it's garbage. I won't argue whether it is or isn't. SQLite is trivial to integrate into any existing project or build system. Just drop in a few files. Voila! &lt;rant&gt; Trying to compile OpenSSL is a god damned nightmare. I shouldn't have to install Strawberry fucking Perl just to configure a simple C library. That's insanity. &lt;/rant&gt; Libraries should have *no opinion* on what build system or environment should be used. Libraries should be as easy as possible to integrate into a wide range of build systems.
Yes thank you!
Thanks!
Which is weird because g++ has ABI versioning and compatibility versioning.
Can't they just increment the abi version?
Why does `noexcept` prevent it from being trivial?
If all you have is a handful of files, and they don't have any kind of complicated dependencies, then sure it's fine. But when your dependencies start to grow and those dependencies have dependencies of their own, and the versions start to diverge, and when you can't rely on the host system and need to start vendorizing things, that's when you really start to hate this anarchy. (That said, things are definitely better than they used to be, I complain about cmake but oh god it's so much better than autotools or plain old makefiles or some of those other horrors from ancient times)
Where have you seen my algorithm before? It is a full-blown general purpose read/write mutex that only relies on fetch-and-add. No CAS loops. Been around for over a decade. Also, there is no integer overflow or underflow. The only way that can happen is if the number of threads that all take read locks is greater than LONG_MAX. That is a lot of threads... m_count never goes over LONG_MAX and never goes below -LONG_MAX. I suggest that you study my algorithm a lot more deeply. 
I still found it a bit of a PITA on Windows - using Visual Studio - last time I tried. Visual Studio's still popular in certain niches, and I recall a lot of the enthusiasm I've seen for header-only libs came from game developers using Visual Studio. If there has been major improvement over the past couple years, I'd be very interested. 
It's [part of CERN's ROOT library](https://root.cern.ch/cling) and is actually a pretty sophisticated and mature tool. It also works in Jupyter.
Would be nice if it had comments
Ouch! No shi%. Ummm.... Will add some comments in. Sorry about that. Yikes!
Np, thanks :)
The absence of `= default` prevents triviality. Pair's assignment operator assigns through references (a poor choice from the TR1 era), so it has to be manually implemented instead of defaulted (unlike the copy/move constructor).
It's a shared mutex, not just a mutex. Take a look at the std::shared_mutex implementation for reference/comparison: https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/std/shared_mutex
I'd like to thank you, Phil, and other contributors for the excellent work on Catch2. I really believe your work has positively impacted the quality of C++ code in the world by encouraging more and better test coverage, simply by making unit tests so ridiculously simple. Catch2 is fine for me as a single-header. As you acknowledged, the ease of trying it out was what attracted me to the library to start with. Most of the time, I'm including it as part of a library's unit test suite, so I don't really need it as a full third-party library dependency for the actual project - just the tests. It's convenient to just be able to include it as part of the unit tests' source files, then include and forget it. I also acknowledge that some people dislike single-header libraries, possibly because it correctly highlights the lack of a unified package manager for C++, or because it prefers convenience before build times. For my own open source libraries, I've actually started offering both traditional and header-only libraries, so people can choose the version they prefer. I do this with a [utility library I wrote](https://github.com/JamesBoer/Heady) that generates a single header from sources, and performs some very simple transformations in the process. Oddly enough, the inspiration for writing this utility and taking this approach was Catch! I wonder how feasible it would be to write the library to be able to use either style? Some of the other improvements, including basic runtime optimizations, more modern C++ 17 support, and so on, all sound great. But honestly, for my purposes, Catch2 is just about perfect as-is right now. Don't feel guilty if you need to focus a bit more of your time on your family instead of a free project that doesn't put food on the table.
Library recommendations are off topic. Try /r/cpp_questions
More importantly will it even matter? Not sure at this point what good modules really are. 
&gt; If you want to make a library don't force *your* preferred build system on everyone else. Unless you're paying him he can do whatever he damn pleases. Many of us very much do want libraries to be built with these tools so we can at least try to pull C++ out of the build-tool stone age.
Forgot to mention it but u/beached did - `std::swap` isn't constexpr until 20 either.
I had some fun fixing that for my stuff. could not use ns::swap as ADL is using in swapping all the time. Ended up going with ns::cswap that will use what it knows of and then fallback to ADL with swap/std::swap. 
 #define RWMUTEX_COUNT_MAX LONG_MAX long count = m_count.fetch_add(-RWMUTEX_COUNT_MAX, std::memory_order_acquire); if (count &lt; RWMUTEX_COUNT_MAX) { long rdwake = m_rdwake.fetch_add(RWMUTEX_COUNT_MAX - count, std::memory_order_acquire); if (rdwake + RWMUTEX_COUNT_MAX - count) { m_wrwset.dec(); } } This subtracts LONG_MAX from count, making it negative, then adds that to
How it isn't? We are talking about header-only libraries, not about ones that require compilation. Whether the library has 1 header or 100, there is no difference.
&gt; There are many, many build systems out there. CMake is one of them. CMake is one of them. Bzzzzztt, wrong already. If you want people to take you seriously, don't criticize things you don't understand.
TIL C++ is finally getting designated initializers. 11 years after C. Better late than never I guess.
Huh, they actually added default member initializer for bit-fields - what paper is that?
Those issues are 100% orthogonal to the question if you distribute your library as a single header or as a "classic" collection of multiple header and source files.
Catch-style single header library means that it expects to be given one file where it stamps out its implementation. For Catch, it means that a single file should have `#define CATCH_CONFIG_MAIN` or `#define CATCH_CONFIG_IMPL` line before the include. The reason not to stamp out the implementation bits everywhere is that they easily take 4-5s to compile.
That's sad if true. I actually found regex&lt;&gt; extremely useful in a recent small project, once I learned the boilerplate. I'm more concerned about the whole STL ecosystem than regex specifically frankly. 
The location of Patreon doesn't matter, the problem is VAT. To keep the potential Patreon income above board, I would have to register myself as a person who receives money on which the VAT was paid abroad and then file a monthly report. This is annoying enough that I keep postponing creating a Patreon, because it would mean a monthly administration even if my Patreon income ends up being 5 bucks. 
I'm out of the loop, when was the last time Qt had a license change?
If you're writing c++ outta for performance. Odds are, you have decided on platform long before you start your project. It's not a choice - if you need cross platform, you write cross platform. If you need windows, you exploit the win api or mfc/atl. Your other option is to structure your code where you can do the "processing" part with the stl and be cross platform, and your fluffis written in a platform specific way. Planning is just part of the language requirements...
IMO, there needs to be a tool that can automatically convert a header only library into a traditional .h/.cpp setup. Use the header only to get going, then use the tool to refractor and improve compile times. Or maybe there is such a tool already? It's a big world. 
What kind of application are you developing? Is there any non-tech reason to make it platform agnostic? What are tech difficulties prohibiting cross-platform development? If you don't have a strong non-tech reason to do so, and can't find easy solutions/workarounds to the difficulties, then my answer is no, vice versa.
It may just be for flexibility. For all we know, a few years down the road, a successful Windows C++ program has to be ported to run on Linux/Unix or vice versa. By keeping the code base cross platform from the start, the porting will be less painful.
way too verbose
I wasn't just talking header-only libraries. A poster above listed SQLite as a "good" example. That library is distributed as an "amalgamation", where they take all the development files and basically `cat` them together into one single .c file. This is so horrible, I can even begin to fathom why anyone would do or replicate this. From not being able to parallelize the build, ever, to not being able to use Git as the unified tool for version handling, etc.
You're just making a case *for* using CMake, not against. Just saying...
C99 was 20 years ago.
CMake is *the* de-facto standard build system for C++ out there. You can't deny that. Most libraries I encounter out there are either built using CMake or support CMake integration, either by config files or find modules. CMake is not perfect, but it's not the horrible hell some people make it out to be. These people often don't know how to write *modern* CMake. It's a lot worse to force another build system onto users of your library -- users simply *expect* CMake support these days, and don't want to have to deal with one of the niche build systems. Or some horrible custom solution; OpenSSL being a case in point there. Or having to try to use dependencies built from N build systems in your project, while trying to maintain a one-command from source build... good luck!
The github link is buried in the paper: https://github.com/plasma-umass/Mesh/
Indeed. And even if you distributed your library as a single header file, you should *still* provide CMake integration by providing a target that sets include path, etc.
For me it's not the one or the other. Usually we write everything possible in standard C++ (maybe sometimes in Boost), e.g. file I/O, networking, threads, etc. Some stuff, e.g. USB device management, is not possible platform agnostic and gets encapsulated in a class with ugly ifdefs. I also think the interface of WINAPI is plain ugly and our encapsulation then provides nice modern C++ interfaces (RAII etc). Usually we try to avoid any Windows specific types and encapsulate them also.
Oh yes. https://github.com/ned14/quickcpplib/blob/master/include/boost/test/unit_test.hpp. It has CATCH and standalone back ends. You'll note it has the same macro API as Boost.Test. Then if you outgrow it, you can switch to Boost.Test very quickly and easily. Standalone Outcome uses this lightweight test framework. Boost.Outcome uses identical unit test code, but with Boost.Test. I'm not claiming my test framework is good for anything but basic testing. But it's good enough most of the time for most use cases. I'm very happy with it.
I'd recommend this Scott Meyer talk where he goes into details about why you should try and keep things "cross-platformable". [https://www.youtube.com/watch?v=RT46MpK39rQ](https://www.youtube.com/watch?v=RT46MpK39rQ) Ultimately, it depends what version of C++ you use. C++17 has filesystem which greatly diminishes the need for native calls. It also depends if you are writing UI, which tends to dictate your data structures and spread throughout a codebase. Ultimately, in any serious project, you'll always have some form of platform specific code somewhere. Especially in high-performance (aka what C++ was meant to do). The question is how much and how do you abstract it to keep it maintainable.
Amalgamated Sqlite builds faster than any of my files which includes a few of boost &amp; std headers
You do not choose a language. You choose a problem space.
There are a lot of projects that ultimately have *some* native API requirements, and that might be for performance, or it might just be functionality that only native APIs provide. Keep in mind that writing portable vs non-portable code isn't a binary choice. You just wrap any OS-specific functionality behind your own internal API boundaries. In my own game engine, there are roughly half a dozen platform specific APIs for graphics, audio, input, windows/app management, files and paths (std::filesystem will replace this when it's more broadly available), and utility functions. The game engine uses these generic cross-platform APIs, and they're translated into platform-specific calls behind that. I'd estimate about 95% of the code is completely portable C++, while only about 5% is platform-specific.
Why isn't there a way to mark such things as trivial?
This sounds like premature optimization. When in doubt, remember that [You Ain't Gonna Need It](https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it). Factor your code in clean, unit testable components, and if you ever actually need cross-platform support you'll be able to easily refactor the platform-specific bits out while using the tests to validate that everything is still fine.
\&gt; CMake is *the* de-facto standard (meta) build system for C++ out there. You can't deny that. I would say CMake is the most common C++ (meta) build system. But I would not call it standard. Google uses Bazel. Facebook uses Buck. Pants and Meson are used by I'm not sure. Premake and various forks are used. Unreal uses its own damn system. Every company I've worked for have had custom systems. Whether they're horrible or merely less-horrible-than-CMake is debateable. Single-file libraries are immensely popular because they're easy to integrate. The Catch2 author states this was, without a doubt, one of the reasons the library is immensely popular. Expecting users to use CMake for their project will significantly reduce adoption rates. If Catch2 had done that from the start it may have never caught on.
&gt; Factor your code in clean, unit testable components, and if you ever actually need cross-platform support you'll be able to easily refactor the platform-specific bits out while using the tests to validate that everything is still fine. for me this is premature pessimization. I'd argue that writing cross-platform code in e.g. Qt (or whatever x-platform framework you fancy, really) is easier and faster than using winapi / MFC directly - even for apps that are bound to run on a single platform I'd always choose these ones because the MFC API is so easy to misuse. 
This is the right answer IMO. Even with just one platform initially this is good practice. It makes adding support for other platforms a small, predictable amount of work, helps with testing etc...
OS-specific API's and the standard library are often not your only choices though. Remember that there are tons of great third-party libraries out there which abstract away lots of platform-specific stuff for you. If you're writing something that is to be released externally, cross-platform is great as that will make your program accessible to more users. If you're only doing something to be used internally it will depend on your own or your company's work platforms. Oftentimes it's really not that much harder to make things cross-platform from the start though, so if you can do that I'd say go for it.
Thanks, but that doesn't answer my questions, which was \*why\* handling exceptions is slower than using return codes.
I love command lines, they are so clutter free. 
Umm, have you ever considered just registering Patreon in a country not related to the jurisdiction you live in?
I always thought that tiles UI happened exactly because of few uncontrollable marketoids at MS. And current content chewer model too. Can you please prove your words by pointing to some *community* requests which caused its adoption? What I saw along all these years is the opposite, where users are frustrated this crap yet totally ignored. Current C++ governance model causes issues to even track progress, not to mention participation. Google groups just for people release steam, not to mention they're hard to enter (SG2). Some closed invitation-only mailing lists for chosen few only. Unmanageable N1234 paper lists, without any proper grouping...
Honestly, that's unrelated. That's a matter of comparing C code without dependencies to C++ code with a lot of dependencies, and thus headers to be preprocessed. Take any reasonably complex C++ project, plus its dependencies, make an "amalgamation" out of it, and weep because you can't parallelize the build anymore. And you probably have other issues, like trying to make your dependencies build with the same compiler invocation. It's just an extremely dumb method to distribute code, under the guise of trying to make it easy.
&gt; C++ however doesn't have an official implementation, all it has is the ISO standard which is then turned into multiple competing/complimentary products by multiple different vendors/organizations. As a result, there's no prototype implementation of all those features scheduled for next standard. Still wonder why not test all of them on smth like CLang an gather true usage feedback.
\&gt; Google uses Bazel. Facebook uses Buck. I am very, very happy to stay away from those. Overly complex, and much more complex to set up (and yay, I need a Java JRE!). I've been regularly compiling TensorFlow with Bazel for a few years now, and I can't really remember when Bazel *didn't* give me lots of pain. Also note that these were designed inside large companies with very custom setups and many languages, where someone, at some point, decided to roll their own build system. This might have been *before* CMake emerged as the de-facto standard for C++. And whether these systems are well designed or a success \[outside of the company\] is up for debate. Not a common case by any means, so you can't infer that other people should be using these build systems. \&gt; Every company I've worked for have had custom systems. Well, that's either stupid, they have very special circumstances (see above), their projects have zero external dependencies, or this is the case purely for historical reasons, and the cost to switch to CMake is perceived (often wrongly so) as too large. \&gt; Expecting users to use CMake for their project will significantly reduce adoption rates. If Catch2 had done that from the start it may have never hit critical mass. I sort of doubt this, but it this were really the case, this would be quite sad. There's nothing difficult about adding a \`find\_package()\` call and the name of a target.
Yes, I understand there are popular libraries like Boost, Qt, GTK etc. that abstract away many of the common things like file system, networking, UI and threading.
Ah, my mistake, I thought this was about header-only. Nevermind. As for amalgamations, they are useful for several reasons. It is a way of getting LTO without LTO, a way to spot ODR issues, and it is very fast to compile+link when you don't have many cores. As for Git, I am not sure why you say so. There are plenty of projects using generated files of some kind everywhere, and there are several ways of dealing with them.
I understand. I am just worried if I start on the wrong assumption of simply targeting Windows and using MFC for example, and sprinkling `CString` everywhere, refactoring later on will be like a rewrite using C++ standard library. So I was wondering if we can do file I/O using the `fread`/`fwrite`/`ifstream`/`ofstream` that are guaranteed to work everywhere with all C/C++ compilers and OS platforms, why would one bother with using the one provded by Windows API (`FileRead`/`FileWrite`)?
&gt;I understand. I am just worried if I start on the wrong assumption of simply targeting Windows and using MFC for example, and sprinkling CString, CList, CArray, CMap everywhere, refactoring later on will be like a rewrite using C++ standard library. Don't get me wrong, using them do make sense if the entire project is built on MFC. I just hope not to have a mix of MFC collection classes and STL collection classes in the same project for consistency. &gt; &gt;So I was wondering if we can do file I/O using the fread/fwrite/ifstream/ofstream that are guaranteed to work everywhere with all C/C++ compilers and OS platforms, why would one bother with using the one provided by Windows API (FileRead/FileWrite)? I understand. I am just worried if I start on the wrong assumption of simply targeting Windows and using MFC for example, and sprinkling `CString`, `CList`, `CArray`, `CMap` everywhere, refactoring later on will be like a rewrite using C++ standard library. Don't get me wrong, using them do make sense if the entire project is built on MFC. I just hope not to have a mix of MFC collection classes and STL collection classes in the same project for consistency. So I was wondering if we can do file I/O using the `fread`/`fwrite`/`ifstream`/`ofstream` that are guaranteed to work everywhere with all C/C++ compilers and OS platforms, why would one bother with using the one provided by Windows API (`FileRead`/`FileWrite`)?
"My requirement is that i must know all the features of C++" Good luck with that. 
Thanks
It's likely that the c/c++ API are implemented on top of the windows API, so you could potentially save some CPU cycles by using the windows API directly. 
pcp &gt; cpp
It's easier to start cross-platform from the begging and then, when you understand which parts require some native API to squeeze some extra bits or get some platform-specific functionality, abstract them away nicely. That way you'll just be using a regular developing workflow. If you start platform-locked then It'd be much harder to "refactor" your code into cross-platform application if such a need arises. Almost impossible in some cases (i.e. equal to the full rewrite) so It's rarely ever done.
To unwind a stack by table, the runtime must scan the EH tables and figure out what stack frame unwind routines need to be called, and then call them. This involves the CPU doing a lot of work which superscalar architectures are very bad at (i.e. cannot pre-execute and cannot dispatch multiple opcodes per clock cycle), so even if the entire working set is in L1 cache and the entire routine is inside the CPU's uop cache, it still runs slowly. Return codes unwind the stack normally. CPUs cache stack returns, branch predictors prefetch them and much of your stack unwind is already pre-executed by the out-of-order executer by the time your logic decides to return a success or failure. So it's a simple case of deciding what pre-executed outcome to throw away. If you run Outcome on a much older CPU, you'll find there isn't zero overhead on success like on the top end CPUs. That's what originally motivated introducing table based EH, it made sense on old CPUs. But even low end modern CPUs are increasingly out of order capable now. So basically the hardware has changed, so return code EH is much more efficient than it once was, and table EH is relatively much worse than it was.
A tour of c++ is a pretty good start. 
Oh the silent sheep downvoters, crawl back to stackoverflow
Take his point seriously: C++ is a much more complex language than C. Learning all of it is hard. I doubt even the C++ standard committee members know every little detail of the standard library, for example. You have to decide if you want to learn as much as possible about C++, or just do a quick tutorial. It's mutually exclusive.
Indeed, PNG pixel data needs to be explicitly converted to little endian. Just added this conversion to `master`, as well as an option to keep big endian. (Platform endianness detection to be maybe added later.)
Single header library doesn't require any build-system and as such it can easily be integrated into any project using any build-system. I'd take header-only lib other the same lib spread out over multiple files with some arcane build system to build it which is a pain to integrate into my own build and that comes with it's own set of problems.
I really would recommend against starting a project using MFC Strings and Container in 2018. Regarding ReadFile(Ex)/WriteFile(Ex), the API provides more flexibility than fread/fwrite, such as asynchronous IO. question is, whether you need it. And also whether you can come with a straightforward abstraction for it so that you don't shoot yourself in the foot in case you need to port it to some other platform later. Also ReadFile/WriteFile work directly with windows handles, so you can for example pass them between modules, as they are not dependent on C runtime used. It really depends on what you need. For example we have a usecase where we needed to iterate through a folder as quickly as possible, but while also getting information about each file along the way. The truth is, almost all abstractions, including std::file\_system suck for this\*. Because for directory iteration, they will only give you path for each entry which you need to stat later. That can be painfully slow on Windows with network shares. On Windows, what you really want is to use \`FindFirstFileEx\` and \`FindNextFile\`, which will give you all relevant information during traversal. Similarly for OS X, you can use \`getattrlistbulk\`. Both are much faster than readdir and stat for each entry. But this is very easily abstractable. \* maybe except \`QDirIterator\`. But Qt as core dependency is out of question for us
Hmm you do not need to register for VAT though if your yearly revenue is below around €60k (exact amount depends on the country). So I don't think you would have to bother with VAT at all. Maybe I'm just not familiar with what you're talking about. What do you mean with &gt; register myself as a person who receives money on which the VAT was paid abroad , does that have a specific name or something?
Hmm, so would that not be up to the user to put that `#define` in his appropriate project file? It is too when they're using the header downloaded from GitHub, so I still don't see how or why that would change if the single include header is installed (copied) by a package manager?
Very interesting, not what I expected. Thank you!
That's the point though. If Catch2 was a plain old library, you wouldn't have to do that, and because a good package manager can take care of the compilation for you, using Catch2 as a single header library from package manager takes more effort, than using a plain old library from a package manager. If Catch compiled itself into a static library as other libraries are doing, the user then does not have to place that define anywhere. This makes it 
Ah, I see what you mean now, thanks! So you really don't need to add an extra step to the packaging (with a .cpp file etc.) if you want to give the user the same experience as downloading the single-header (or through git submodule), but through the package manager. You only need that step if you want to give the user the better experience of not having to bother with the macro, which makes sense since the package manager can compile libraries for you, which is actually one of its main points.
&gt; don't people use a build system? That's the problem, people use **many** build systems, so providing a library which work with every single build system under the Sun is a daunting task.
That's C++ fault, really. The fact that there is no standardized way to describe a C++ library or C++ package, so that users can pick their favored build system/package manager and just build the library/download the package is moronic. Header-only libraries are a way for library authors to retain their sanity when faced by a large number of potential build systems, each configured in their own way and with their own idiosyncrasies. Single Header libraries are the more extreme version which minimize the number of files to copy/move around when "installing" the library.
This only works if your library is trivial to build. If it requires nontrivial configuration steps, you want an existing build script. Look at the configuration checks GLib does for example. Do you really want to have to do all that by hand?
I guess @personalmountains comment was referring to the python code in the previous comment, not to the cli library (which is indented correctly).
My presentation was not meant to damage the C++ community, and I certainly hope I did not do so. Anyone please note that the title of the lightning talk ends with question marks. I was wondering about this claim that noexcept is "slightly harmful" (Terry Mahaffey, 2017). This is also why I made a benchmark. Now I'm very happy to see that the benchmark results do in various cases show a significant positive performance effect. If anyone still wants to have a look, the benchmark is at https://github.com/N-Dekker/noexcept_benchmark I'm interested to hear any suggestions to further improve the benchmark.
And that's how I know I'm getting old I guess... Wishful thinking on my part.
Nothing wrong with using fprintf in C++.
Aha that is 100% false. Allocator2 will be called to deallocate memory allocated by Allocator1 and that my friend is where shit goes south. Therefor all allocators have to be singletons/global or access some global resource (like malloc). You know that and you just don't want to acknowledge it. 
I know but I just want a version using std::string instead of char \*.
No I meant if you're using a modern build system, adding third-party libraries isn't exactly a challenging task, source files or not. Regardless of the build system used by the consumed library. The only exception I can think of is when the library deviates from sensible conventions regarding directory structure. But that has nothing to do with header only and such a library would not be available as header only anyway.
You can still use fprintf with std::string :) fprintf(stderr, “%s\n”, std::string(“hello world”).c_str()); Although some people may disagree, printf is generally pretty great (though not typesafe, but most compilers will warn you). If you find that streams look bad and make you do uncomfortable things, there is no sin in using printf!
&gt;std::string(“hello world”).c\_str() I did the reverse thing. I would sent a string.c\_str() and it did not work, but your solution worked ! Thank you very much !
Ah that! I fully agree with you. I mean, in your own company you already add libraries and programs regularly, so creating a build file for a 3rd party library is nothing "new". Not plug and play, but it's generally a one-off anyway (unless updated versions shuffle files around). I remember adapting 3rd party libraries before; the company I was working on had its own package manager/build tool and a well-defined directory structure, so 3rd party libraries had to be converted for it. It was a pretty easy process really, though it required converting the directory structure, fixing includes, etc... as necessary. I guess people are picky these days, and really want a zero-effort experience (plug and play), and so will prefer header only libraries. Well, not that I don't want a plug and play experience myself...
Isn't this what you are looking for then? http://www.unicode.org/Public/11.0.0/ucd/EastAsianWidth.txt It is a list that says which ranges are wide and fullwidth, straight from the Unicode itself. Although that list doesn't give you enough information about 0 width codepoints. For those you probably should look here: https://www.unicode.org/Public/11.0.0/ucd/auxiliary/GraphemeBreakProperty.txt Anything that is extend/prepend/control/zero width join should be 0 width.
&gt; std::string(“hello world”).c\_str() How does this work? Isn't the \`std::string\` temporary destroyed after the call to \`c\_str\` and thus leaving the returned \`const char\*\` dangling?
No, this is not what Live++ uses. How should the OS be able to generically replace code and relink it with existing state, without knowing anything about the executable and its state? Many people seem to believe that hot-reloading means re-routing old to new functions, and that's it. In reality, re-routing functions is about 10% of the work that has to be done, and it's much more complicated than that if you want to support generic C++ code &amp; executables without any DLL exports or similar.
The OOP is strong with this one. For one, you never initialize balance to anything. 
put code snippets in places like ubuntu paste next time 
Why do say OOP is not so cool nowadays? Do you mean it's not "hip" and people are pushing newer programming patterns? 
No. Temporaries are only destroyed when the full expression has been evaluated.
Thank you.
&gt;I would say CMake is the most common C++ (meta) build system. But I would not call it standard. I kind of agree with him though. You are right companies are using different things but when we are talking about libraries, specially cross-platform, they are either header libraries or libraries that provide at least an option to be build with CMake out of the box. Or at least that has been my experience.
I found a library called utf8proc which has a function to retrieve information about a codepoint, including its width. I'll probably use it, but for now I've kinda "dropped" support for advanced unicode support in my project because it's too much work for too little reward. (People using unicode characters in code are still fairly rare)
tbh why dont u just help me out with the problem or just not comment at all if you dont help by commenting
You probably shouldn't use the Windows functions. But how do you think the standard library implements \`fread\` &amp; others?
“Please help me and I want to put as little effort into it as possible to make it harder for you to help me and by the way f*ck you for trying to give me advice”
nope im not acting like u think i am. just by commeting to my post to judge me for not doing something right, thats not an advice.
That's *literally* advice - it makes it easier for people to read, understand, and chime in. People are volunteering their time to help strangers out on here, and seeing a wall of unformatted code makes it that much harder to quickly assess. There's also /r/cpp_questions which is probably a better place for this. That's also friendly advice. Good luck.
This subreddit is for discussion the C++ language itself. It is not the right place to submit help requests. OP, I would strongly suggest you repost this (with proper formatting) on /r/cpp_questions or StackOverflow.
setw sets the width for the next field, so you need to use it before you stream out ERR. Right now you're setting a width for the " | [" string.
I did, sorry for the confusion. Note that you can ping users with `/u/username` instead of `@username` on reddit.
Overall, I quite like the implementation presented^1 . The most interesting part, personally, is 2.6: a lightweight encoding of type IDs not requiring the full weight of RTTI... although there's no mention of virtual bases (often recommended for exceptions), so it's not fully clear to me how those are supposed to be handled. What I found pretty strange for an implementation targeting embedded devices, though, is: &gt; **2.3 Handling Exceptions** &gt; Once a catch block is executed, the `active` flag of the exception `state` is cleared, memory is allocated on the stack for the exception `object`, and the move or copy constructor is invoked to transfer `ownership` of the exception object into the current block. It's unclear *how* the implementation acquires the necessary memory on the stack for the exception being caught. It seems that in the worst case this could require `alloca`, as there is no a-priori bounds on the size of exception objects, which I find strange for an implementation targeting embedded devices where bounding stack depth is also generally required. --- ^1 *I don't care much for the tone, however. There's way to much emphasis on how "novel" the implementation is and how "right" the authors are, when really they are essentially encoding `Expected`/`Result` at the compiler level. Funnily enough, I recall the Midori language/OS doing the reverse: using `Result&lt;T, E&gt;` as a return type, but using exception propagation techniques for the error case.*
Easiest way is to use a formatting library. I can recommend http://fmtlib.net/latest/index.html - unlike printf, it is type safe. Unlike ostreams, it is easy to use. 
Dude not cool If you want people to help you, at least use the correct formatting so people can clearly read the code. If you want the code formatted in `typewriter` just indent each line by 4 spaces, and indent that just like you would in your source code. You aren’t even in the right subreddit: if you need code help head on down to r/cpp_questions, where the lovely peeps would love to help you.
Firstly thanks for posting this link. I was totally unaware of this research. I believe so is the WG14 and WG21 leaderships. I will be posting this paper to them shortly. (As an aside, why don't academics ask us to review their papers? Their benchmark results are presented in an unrealistic and unhelpful form which over dramatises the paper without giving the specific numbers the standards committees actually need :( ) I am surprised their results are so bad though. Outcome based code is two or three times faster than theirs. I guess the thread local flag storage really impacts optimisation! I agree about the irritating tone, and lack of due credit for the implementation design (Herb's paper is barely mentioned at the end, and is misquoted and misrepresented to boot). But all extra empirical data is useful.
I'm currently redoing benchmarks for Outcome on newer ARM CPUs and will add them to the FAQ when ready. I expect no regression from when I last tested a few years ago on the Cortex A15, but you never know until you test.
&gt; I did, sorry for the confusion. I see! :-D
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/arkuh6/how_to_add_padding_to_stdcout_regardless_of/ego5132/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehell
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ardhk3/any_standard_for_lock_less_publisher_subscriber/ego52ix/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/arl9g2/c_code_not_working/ego547t/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Which is mainly for cases you can't do otherwise, even more so for GCC and C++ which is part of defining the GNU/Linux platform, where usually tons of generically shared libraries and programs are supposed to work well together even when they directly use C++ interfaces.
Well, yes, rewriting from MFC to std library would be a pain, but why in the world would anyone even be considering MFC/ATL for a new project these days? Those technologies are still technically "supported", but basically in maintenance mode. I can't even imagine a scenario in which I'd recommend using them, even if you were guaranteed that your project was only going to be on Windows. Even putting that aside, as I stated before, the choice here is not binary. You'd want to use std C++ for your internal logic, and transform your data only for interaction with the UI. Are you familiar with the [model-view-controller paradigm](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller)? Essentially, it's a common pattern for UI systems that dictate a clean separation between your core functionality (the model), and the UI's display of that information (the view). So, please don't go sprinkling CString, CList, CArray, or CMap everywhere in your core logic. If you do that, you're irrevocably binding yourself to one platform. Why do that these days? I can literally think of no good reason to do so. As to the std vs FileRead/FileWrite, the reason you might choose the native APIs could be performance or extra features. For instance, you can use memory mapped files using Windows APIs for better performance or even sharing data across processes, but not with standard C++. C++ standard libraries give you a somewhat lowest-common-denominator of functionality across different OSes, but doesn't let you take advantage of various lower-level features. For most cases, those lowest-common-denominator functions are "good enough" to use, but occasionally a program with extreme performance requirements comes along in which it's worth putting in the extra work to use the native APIs.
The fuck? Judge you? It's impossible to read code like that instead of properly formatted code #include &lt;iostream&gt; int main() { std::court &lt;&lt; "They literally gave you his advice\n"; }
&gt; There's nothing difficult about adding a `find_package()` call and the name of a target. It’s incredibly difficult if you aren’t using CMake!
It is absolutely useless to dismiss issues by pretending the problems some people have do not even exist, or that extremely large parts of the industry are completely wrong. Even more so by using a laconic call to "simply use unit tests". While big game dev are actually doing it. Unit tests are great but they are not the silver bullet you seem to think they are. And from an economic point of view, would that dichotomy really exist (which I affirm it does NOT), the optimize the implementation once vs. every dev on earth has more work to do would have its advantages... What really do not exist are the imaginary games that workaround the debug build perf issue the way you describe, because it is practically quite unrelated. Meanwhile, people for example keep maintaining and using EASTL - and THAT is a practical example of part of the solution well suited for their workflow and the domain they work in. 
And it is UB if the type actually was not. So I don't really get what the point of what you would obtain by "just pretending"? A program that has no meaning? Seems not very useful.
I mean, that's what the comment I replied to was asking for. There's a reason there's no way to "properly" "just pretend".
The point is that you just add the third-party library to your own build system, which is usually pretty straightforward for most libraries, especially the ones that are of the size header only libraries are
So how difficult I'd if to activate on current vs? I'm stuck at vs2012 as that's the latest one that is easy to replace malloc without considering the Ms runtime. 
I mean initially it was a question about the (lack of) equivalent of a Rust feature that presumably actually can work in some cases if the user's code is carefully written. So given in the C++ world memset would *not* formally work (without in depth changes of the standard), yes, I agree there is no way to "just pretend" :P
IMHO, should be a lot slower in MT (and/or high tempo allocation/deallocation) environment. &amp;#x200B; Good for "allocate once, run forever" code
Porting is not a very sustainable option. Development with constant compilation on all platforms is how to do it, making proper choices along the way.
after vs2012 it's become extremely hard to replace MS's absolutely pathetic memory allocators that fall down with hardly any effort with multithreaded code. I would love to switch to their newest express compiller if i could trivially stick in a working malloc implementation. And we're talking several orders of magnitude wrt to performance...
I've been hearing people tag things they don't like as "premature optimization". This type abuse is starting to make the term a joke and does not apply to things like improved code quality, etc.
That is only one person's opinion. Just because one person thinks they are bad does not mean anything. Therefore, you can keep using them as before.
It would be awesome if these conferences were to stick to technical matters alone. All this social commentary is unnecessary and is probably best given on social psychology conferences. Yeah, I know you can just not go to a talk, but still... completely unnecessary.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/arni1x/coming_from_c98_what_should_i_learn_to_keep_up/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Step 1: what is your stopping case? Step 2: how will you recursively move the variables involved toward that stopping case?
Premature optimization is doing work earlier than it needs to be done, including architecture work. Deciding that you need to make everything into a microservice when your code will never need to scale in that manner is premature optimization, because it will be a lot more work. Encapsulating a potentially platform-specific behavior in a component (audio, video acceleration, etc.) is good design. Jumping straight to saying that you need to use a cross-platform library when you're not likely to ever use that is premature. Such a decision constrains your choices and in some cases appearances - just being cross-platform doesn't make a framework better; Qt is at least as much of a mess as WinAPI, while providing visuals that look substantially less native.
I just have a hard time coming up with what the question wants. After it gets explained to me I am able to come up with something. My buddy reads these questions then bam already has it done and moves on to the next. Like how can I improve ;\_; I suck at this stuff... curious to know if there are tricks to easily grasp it. Or ways to understand it a bit more.
Maybe visualise what the starting point is, what kind of data do you have, and what the end result has to look like. Then try to divide the problem in as little steps as possible and start from there. Once you have an overview of all part problems you should have it easier to put everything in code. (Divide and Conquer)
I'm a sadomasochist
Do you know how to define a recursive function? Do that first. Then start refining it.
[Link to the paper objected](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1364r0.pdf) from Microsoft
I do yes. But this question is just an example to many others. Some not even function related. I am literally just garbage at programming...
I will definitely divide everything into pieces. I was not thinking of it this way and will give it a try. Thank you!
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
count will never be negative. The \_only\_ way this can happen is if n number of threads concurrently take a read lock where n is greater than LONG\_MAX. That is a lot of threads. You need to calm down and take another look. Keep in mind that fetch\_add returns the \_previous\_ value! You seem to be missing that. Btw, I am going to add some comments to the code today.
Should have some fairly informative comments by sometime today. After dinner. :\^)
What to do when experts disagree with one another?...
As a programmer who practically lives in the Win32 API and often writes programs targeted only at Windows, you should stick with the C++ standard library when it is readily available for what you need. The OS APIs are targeted at a C or minimal C++ subset that is more focused on interoperability and binary compatibility than ease of use, whereas the standard library will use more familiar types, exceptions, etc. Going directly to the Win32 API also isn't necessarily better for performance -- putc()/fwrite(), for instance, is often faster because it does I/O buffering closer to the application than WriteFile() does, which requires a system call. If you are looking at Windows sample code, you should also be aware that it is prone to using Windows types and conventions gratuitously. Even if you are writing directly to the Windows API, there is no need to use DWORD over uint32_t or ZeroMemory() over memset()/std::fill()/initialization for your own data structures. MFC is a rather old library and is outperformed by newer libraries in both performance and design. It dates back to when compilers didn't even support `bool` as a language type and is now essentially on life support. For container types, you're better off using STL's types than MFC's. The cases that are hard to decide are ones where framework libraries are wrapping a large API surface and trying to provide a feature set that is significantly different than the OS API. Graphics and particularly UI libraries are prone to heavyweight layers with significant tradeoffs. 
This entire thread belongs in /r/choosingbeggars
&gt; although there's no mention of virtual bases Meh, imho overdone. Base classes are really only needed for catch-all blocks, which shouldn’t be needed all that often (and if you genuinely need something like that where you just care that an exception was thrown regardless of what it was you can always do `try {/* do stuff */} catch (...) {/*finally*/; throw;}` &gt; It seems that in the worst case this could require `alloca`, Just subtract the size of the largest exception from your stack budget. Exceptions rarely need to be more than a few bytes if you don’t need a human readable error message, which presumably you don’t if you’re doing embedded and memory usage is a big concern. 
Btw, you don't seem to realize that only single thread can perform this code because you failed to mention that this is under the protection of a lock. It is a one to many relationship wrt a single writer and multiple readers: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ void lock() // procedure of ct\_rwmutex { m\_wrlock.lock(); // you omitted this \_critical\_ aspect. Why? &amp;#x200B; long count = m\_count.fetch\_add(-RWMUTEX\_COUNT\_MAX, std::memory\_order\_acquire); &amp;#x200B; if (count &lt; RWMUTEX\_COUNT\_MAX) { long rdwake = m\_rdwake.fetch\_add(RWMUTEX\_COUNT\_MAX - count, std::memory\_order\_acquire); &amp;#x200B; if (rdwake + RWMUTEX\_COUNT\_MAX - count) { m\_wrwset.dec(); } } } \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ &amp;#x200B; Why did you omit that part wrt the lock? Humm.... &amp;#x200B;
That's exactly what I'm concerned in the previous thread. As said in this paper: &gt; Unfortunately that glass is not entirely clean. Not only is that paper misleading by implication, but it contains several outright misstatements. Representatives from big companies may propose modifications that are at local maximum for themselves with a biased magnifying glass.
&gt;Ayyadurai &amp;#x200B; Have you tested it for yourself? It is beating a lot of std::shared\_mutex impls.
&gt; (People using unicode characters in code are still fairly rare.) If comments count then I strongly disagree. I've worked in a few places with code largely commented in Chinese or Russian – that's where a lot of math doctorates are hired from in the last ~10 years.
Really wondering if you're just trolling. MFC in 2019, if you're seriously suggesting that as an option, you have seriously missed something. You write standard C++ whenever possible, and MFC is dead, most likely not even properly supported or maintained by Microsoft anymore.
&gt; It's unclear how the implementation acquires the necessary memory on the stack for the exception being caught. "We propose a statically sized buffer using a simple constant time stack allocator for our exception object, with a heap-backed fall-back upon buffer exhaustion for those applications who cannot compute or do not require run-time determinism. The size of this buffer will be given a default value by the ABI in use, but will be optionally application-overridden at link-time via a linker command-line parameter, to optimise or prevent any and all heap allocation."
Fwiw, I need to code up a different type of benchmark. One that measures how many reads and writes per-second, per-thread can be performed on a shared data-structure, like a list or something. &amp;#x200B; Readers would iterate the whole list. &amp;#x200B; Writers would push and pop items from the list. &amp;#x200B; How many reads and writes can be completed per-second, per-thread if the test was run for a fixed amount of time...
How can count never be negative when you are subtracting LONG_MAX from it?
I don’t think most libraries warrant non-trivial configuration steps. An explicit goal of library writers should be to make their library as trivial as possible to integrate and build.
Because it is LONG_MAX to being with. Take a closer look at the constructor of ct_rwmutex. Please. :^)
If count can only have two states, LONG_MAX and 0, why not use an atomic bool?
No and why would I? So many people post their little pet projects here with no effort into showing why people should actually try them. You're just another random person begging for people to help him. No reason to take any of you seriously.
Man, you are really missing things now. m_count can have any value between, and including, -LONG_MAX and LONG_MAX. Read the code again, very carefully.
My algorithm has been out there for a while, since 2008-2009. I just got around porting it to pure 100% standard C++11. Just wanted to see how it stacks up against std::shared\_mutex on other people's systems. Is that a really bad thing to ask for?
I just read the original paper linked to and nothing about it suggests it was written by experts.
The paper says it's written for linux and macOS binaries, so it may take some effort porting it to windows...
The only way to solve this is to stop writing proposals and counter proposals and start writing actual code, IMHO. In the end tunnel various trade-offs can only truely be appreciated with a working implementation. Everything else is just speculation.
The only way to solve this is to stop writing proposals and counter proposals and start writing actual code, IMHO. Various trade-offs can only truely be appreciated with a working implementations. Everything else is just speculation.
911 I'd like to report an incident, there's been a murder, the victim's name is P1364R0, and bystanders report P0866R0 leaving the scene of the crime
That's why this process exists in the first place, right?
&gt; invented &gt; My algorithm has been out there for a while sigh.
I don't think Windows supports mapping different virtual pages to the same physical page. Unix memory-mapping API is very flexible but Windows one not so much.
If that is true, then how can count never be negative?
Windows does support double-mapping memory mapped sections. Mapping granularity is 64K, however. 
I'm wondering though, how do you break the ABI on a pair? There aren't many ways to put 2 things together. Is it the empty base optimization?
I can't wait for the response to the response.
FWIW Python implemented coroutines on top of generators and said it was the same thing, but, as you mention, later they added syntax on top of it to make an explicit semantic difference between coroutines and generators.
This is how our ABI works. The usual difficulty is that this means the stack can't be unwound until a catch block completes (since the exception lives on the stack frame of the thrower).
This sounds amazing! I'm hoping it's short-term... But regardless, when it _is_ announced will it be here, or the vcblog, or somewhere else?
Came here to state verbatim same as GP. As you elaborated on, the language is very large and complex, and thats before you get into the relatively small standard library (small compared to say C#, Python or Java). There are a lot of syntactic corner cases (such as most vexing parse). Decyphering template errors is still as mess, although compilers are getting better at emitting more helpful diagnostics (but you may still get 20 screenfuls of errors for a single typos).
&gt; Mesh runs on Linux; macOS support should be considered alpha-quality, and Windows is a work-in-progress.
count can never be negative because only one thread is allowed to decrement LONG_MAX from ct_rwmutex::m_count. Think if 3 threads are reading. So ct_rwmutex::m_count = LONG_MAX - 3. Then the writer decrements m_count by LONG_MAX, and gets LONG_MAX - 3 in return as count. Remember that fetch_add returns the previous value. Then it checks to see if LONG_MAX - 3 is less than LONG_MAX. If so, it knows it has exactly 3 readers. count will NEVER be negative.
May be a dumb thought, but I wonder if this would impact certain security protection measures on memory such as ASLR.
The comment that started this whole stubthread was about integer underflow. Which _is_ UB.
Just giving an example from an old project I encountered 6 years ago. You may be surprised there are some really old codes that people do not bother rewriting that are still in use today. They have grown too big to replace. I was just wondering why someone would choose to lock themselves in to Windows/MFC/Visual C++ compiler from the beginning. &amp;#x200B;
Back in college, while doing any computer science or IT degree, I guess most students are taught C/C++ programming using gcc, standard C++ and perhaps the STL. In the professional world, use of proprietary frameworks and tools is common. So this led me to wonder as a C++ programmer, should I be a purist or fundamentalist sticking only to standard C++ or to just go along with the flow using popular proprietary stuffs promoted by Microsoft.
This is true for everyone, not just representatives from big companies. What you're really seeing here is a battle between proponents of their own stackless and stackful coroutine solutions. Personally, I feel that the quoted text is unprofessional and that P0866R0 is at least as biased, with the authors primarily citing their own work, compared to P1364R0 which pulls in arguments from a wider variety of external sources. Nevertheless there are good points made on both sides. 
I've never understood the obsession with exception performance... you must be throwing a lot more than me... For me exceptions are only for fairly serious errors... so there performance doesnt really matter. Normal conditions should be handled with normal code.
There is no integer overflow or underflow. You simply do not know what you are talking about. Look again: m_count = LONG_MAX; 3 readers come in. m_count = LONG_MAX - 3 a write does, count = fetch_add(m_count, -LONG_MAX); count = LONG_MAX - 3 if (count &lt; LONG_MAX) { there are exactly LONG_MAX - count = 3 readers } If you just cannot grasp something that simple, well, that is fine. But I am basically through trying to spoon feed it to you. I mean, it is fairly basic arithmetic. You need to study up on how signed integers work. Sorry, but you are having a lot of trouble understanding it. You are a funny person.
&gt;My requirement is that i must know all the features of C++ By this.. i mean that i should know all the basic features like., operator overloading, virtual functions, STL and other stuff that i dont know. &amp;#x200B; Hope i am clear.. Im in my clear mind and not expecting to learn A-Z.
No, comments don’t count. I’m strictly speaking about the code itself.
Fwiw, there is no integer overflow or underflow in here. Some people are radically misunderstanding the arithmetic. I know it needs better comments, however, I boiled down the main case in one of the sub-threads here to the following simple example code that has no UB: &amp;#x200B; [https://pastebin.com/raw/5tFGqMRR](https://pastebin.com/raw/5tFGqMRR) &amp;#x200B; Where is the UB? Where is the integer overflow or underflow? There is none.
If it's trivial, it can be `memcpy`'d. If you have a user-provided copy constructor, assignment operator or destructor, then it is assumed that `memcpy` would not have the correct behaviour, and so this class would not be `is_trivially_copyable`.
Why did Phil stop working on Catch? And what would it take for him to return to working on it? 
Wasn't the committee going to pursue fibers and stackless/core coroutines independently anyway?
Then how can this be true &gt; m_count can have any value between, and including, -LONG_MAX and LONG_MAX.
This should go in r/cpp_questions &amp;#x200B; This sub is related to cpp projects/articles/news/presentations/etc. &amp;#x200B; That said, it looks like a bug in GCC as Clang compiles fine. IME clang is normally right and gcc is wrong when they disagree about such things.
Fork and the ISO group will be dead in the water as the industry will refuse to join. 50 years worth of code out there, including the GNU C library which is the real workhorse behind the C++ language.
Troll! What a joke.
I could agree, but what about the code size? Or really embedded things (microcontrollers). Or runtime-bound guarantees in cost. There are still use cases for this. Might not be your use case, but these use cases do exist. Or imagine a custom hardware driven by C++ software manufactured at scale: if you need 4KB of memory instead of, let us say, 2KB and you manufacture 300,000 pieces, you know... more cost. &amp;#x200B; I hope the day I jump into embedded, because I plan to, I can use all the language as much as possible. And exceptions is not one of the things I will be able to use probably, in the current state of things. &amp;#x200B; &amp;#x200B;
It is nice maybe for some scenarios as an improvement for the current system. But a value-based approach like Sutter's I think beats this.
You think you invented skipping a mutex with an atomic reference count
Another option is to ask yourself "have I solved a similar problem before?" Preferably it's a simpler problem which you can then think about what you learned from it and how you could use that knowledge in your current one. Also a good option is to minimize your problem, reduce it to the most mininal version of itself and see if you can solve that.
Or... provide an attribute so that the user can specify it.
You cannot even barely understand it. What a joke.
It's a relatively simple system that's meant to define how C++ classes have to be written so they're compatible with C structs, not a framework for tagging arbitrary special member functions as trivial. The probability of a user-provided special member function being compatible with `memcpy` is so low that it's not worth creating a whole new system for it.
I'd like to emphasize the last part: Avoid letting platform specific types (e.g. Win32:s DWORD) get exposed in "public headers" (i.e. headers that get included in lots of platform agnostic code). You do not want to include "windows.h" in all your compilation units (it has a negative impact on build times, it pollutes your namespace and it's a slippery slope into non-portable code). For similar reasons you should avoid 3rd party types (e.g. boost) in interfaces too, but that's a slightly different situation that can be managed by making informed decisions. For example, in BuildCache I have lots of Windows specific code, and lots of POSIX specific code, selected with #ifdefs and encapsulated in helpers/classes with platform agnostic interfaces: https://github.com/mbitsnbites/buildcache
Interesting you say that, since you seem to be going to great lengths to not explain what it is you think you invented.
Congratulations! I envy your stars and forks (laugh) It seems people like the immediately usable software more than snazzy C++17 code ... Especially good to see the design described in simple uml. What understands he uml files? Now the dark side (of me) :) - why the "CamelCase"? - why the (it seems) excessive inheritance? - As OOP aficionado you know that "naming is everything" so this confuses me: `Menu: public Command`? Menu is probably not kind-of-a command? - at some points in code you use modern C++ "properly" and then in others, your code looks like the celebration of legacy STL cryptic days. - there is very little (if any?) of type aliases (`using` or `typedef`) - Boost is very fine, but why would CLI library depend on Boost? Telnet (ASIO) probably could be done as a "plugin" - Boost Algorithm? Can be all simple (and very few utilities you use) done inside the lib. - Why not having `using namespace std;`? - Performance. probably not that crucial for the CLI but. vector and string everywhere are the immediate performance improvements opportunities. - C++14 ok but why not the standard C++? 17. Example: string_view and literals make simple, robust and fast code. extended if() syntax too. And so on ... I declare myself a friend, not the enemy. I might have some time to fork this and "put my money where my mouth is" :) This is good work but I am itching to improve it ...
There are really constrained systems that just can't afford exceptions. Hard realtime systems can't afford to throw any kind of exception. Mission critical systems mostly aren't allowed to use the heap and dynamic allocation. So the problem is that exceptions are non-deterministic. The performance and binary size are just a very welcome side effect of implementing exceptions that are actually useful in wide variety of systems, not just your "smart" phone and desktop.
It goes both ways. A few years ago I had something that compiled under Clang but not GCC and when I reported it the GCC dev pointed to the exact line in the spec that said it should *not* compile. Something to do with a `const std::vector&lt;const std::string&gt;` but I forget the details.
Why not have it live on the stack frame of the catcher? Of course this is under the assumption that the maximum possible size of the thrown object is known in advance. Is that reasonable? If you can generate better code if you knew this information, I'd be happy to tell you what the largest exception is that I might conceivably throw. Set a minimum limit of whatever the largest size is that is thrown in the standard library and we are all set. 
I believe there is quite a bit of code based on Microsoft's implementation of the coroutines TS. Fibers (cooperative multithreading) in general also have been in use for decades, but I don't think there is any native c++ implementation to code with (libraries do exist however). Personally I think we are at the point where the committee (or rather the ISO plenum) needs to make a decision: Do they want coroutines as currently designed in c++ or not. If they want it, they need to merge it and then make improvements iteratively and incrementally based on large scale user feedback. If not, they should bury it for good. Fibers should be a completely separate topic.
I had hoped so too, but I guess the backers behind fibers an coroutines still see each other as competitors (and maybe they are). 
Yes, I mean that OO is not hip. People feel cool writing code that seems like mathematics (I've nothing against maths, I myself have a solid math background), and doing so give up some good non-functional properties they could achieve with other paradigms. I don't criticize Java or other languages. I don't criticize other paradigms, either: I'm just against people who don't use their brain :-) I was referring to java just because when it was introduced back in 1995 it was advertised as a strictly object-oriented language. Unfortunately, some developers didn't understand OO in the first place but were forced by the language to use some OO mechanism (e.g., inheritance) and -- guess what -- they used it improperly. The result is a style where you add interfaces and inheritance everywhere, without a good reason, and missed to use it where can be useful. I'm using the expression "fake OO you find in typical Java programs" to refer to that kind of \[bad\] OO code, that you can actually find in every language, by the way. In fact, Java programmers today are better at writing OO code than they were in the past. For me, OO is defined by the properties of the code you get. In particular (for me): an OO structure is one that given a meaningful change in the specs minimizes the total size of the artifacts you have to update, encouraging the creation or deletion of entire artifacts instead \[see [http://www.carlopescio.com/2012/12/ask-not-what-object-is-but.html](http://www.carlopescio.com/2012/12/ask-not-what-object-is-but.html)\]. BTW: if you like my code/design you could be interested in my blog [daniele77.github.io](https://daniele77.github.io) and maybe follow me on Twitter at @DPallastrelli :-)
I find the implication, that no research was done on the performance consequences of the proposed new exception model before it was announced, more than a little worrying. Actually I already find it strange that Herb's paper takes the form of a mandatory ABI design. I was under the impression that ABI decisions were left to the implementation (which may choose to adopt the ABI model designed by a CPU manufacturer) in order to allow the best possible implementation. It would have been more appropriate as a research paper, describing an alternative implementation that compilers may choose to adopt, or not, depending on their needs. And please don't tell me it was all based on *"I think this is probably faster"* without any attempt at actual measurement!? The mind boggles... \&gt; Outcome based code is two or three times faster than theirs. How did you make this comparison? &amp;#x200B;
&gt; Why not have it live on the stack frame of the catcher? The exception object has to exist before the associated catch block can be matched; the stack frame of the catcher is unknown at that time. For example: struct B {}; // these types might not be known at all struct D1 : B {}; // by the compler generating the catch block in another DLL static D1 d1; struct D2 : B {}; static D2 d2; static B&amp; f2(bool b) { if (b) { return d1; } return d2; } static void f1(bool b) { throw f2(b); } void exportedFunction(bool b) { try { f1(b); } catch (D1&amp;) { // Does control transfer here, or to the caller? // Can't know until the exception object is actually constructed } } &gt; Of course this is under the assumption that the maximum possible size of the thrown object is known in advance. Is that reasonable? I don't think so; even without the catch matching issue you wouldn't want to pay for that in the case that no exception actually happens. &gt; Set a minimum limit of whatever the largest size is that is thrown in the standard library People aren't limited to throwing standard library exception types.
`Mesh generally matches the runtime performance of state-of-the-art memory allocators while reducing memory consumption; in particular, it reduces the memory of consumption of Firefox by 16% and Redis by 39%.` This sounds too good to be true... surely there's a space-time tradeoff?
I didn't write that my library allows adding arbitrary code w/o adapter, but that my design would allow such an extension. On the contrary, had I chosen inheritance / run time reflection, such an extension could not even be possible.
&gt;{fmt} library is also targetted for C++20 wow, wasn't aware of this
I'm not updated either. But AFAIK the license changes were especially harmful in the beginnings.
Thank you for the comment. &gt; It seems people like the immediately usable software more than snazzy C++17 code ... Real people are busy developing real applications, and they need tools to get their work done quickly. &gt; why the "CamelCase"? Is this a problem? (kidding :-) If you really want to know why you can have a look here [https://twitter.com/DPallastrelli/status/1095659395323777024](https://twitter.com/DPallastrelli/status/1095659395323777024) but don't expect smart justifications for a style matter :-) &gt; why the (it seems) excessive inheritance? No excessive inheritance. I used it when required, by choosing knowingly among class inheritance, interface inheritance, composition to get the non-functional properties I wanted from my design. &gt;As OOP aficionado... No, I'm not an OOP zealot. Just trying to use the right tool to get the properties (functional and non-functional) I wanted to achieve. In particular: Menu is-a Command, because when you start the CLI, every Menu shows as a command you can digit at the prompt (e.g., if you define a Menu "foo", you get the command "foo" in the Cli to enter the submenu). &gt; at some points in code you use modern C++ "properly" and then in others, your code looks like the celebration of legacy STL cryptic days. "properly" according who? :-) kidding. Give me an example, so I can check. &gt; there is very little (if any?) of type aliases I used some, where needed to make the code clear. &gt; Boost is very fine, but why would CLI library depend on Boost? Telnet (ASIO) probably could be done as a "plugin" It is already a plugin. If you don't include the header file of certain features, you don't need ASIO. &gt; Boost Algorithm? Can be all simple (and very few utilities you use) done inside the lib. Yes, I could remove it and rewrite at hand some string algorithm. Probably more trouble than it's worth. Maybe one day. &gt; Why not having "using namespace std;"? because we're in header files. Yes, I could have used it inside some member functions, but then the character counter would increase instead of decrease :-) &gt; Performance. probably not that crucial for the CLI but. vector and string everywhere are the immediate performance improvements opportunities. I know the alternatives. But -- really -- we're speaking about an I/O bound application. We're spending a lot of time waiting for the user input or the OS writing a string on the console. \*In this case\* I don't care about some extra milliseconds. But hey, I know how to optimize my code when I need to. &gt; C++14 ok but why not the standard C++? 17. Example: string\_view and literals make simple, robust and fast code. extended if() syntax too. And so on ... A couple of \[good\] reasons: first of all, some of my user (and myself!!!) are still bound to old C++14 compilers for their projects. Second: C++17 features are not a game changer for my library (excluding maybe some little syntax sugar it would be fancy to have). Thank you again for your questions. &amp;#x200B;
https://gcc.gnu.org/bugzilla/show_bug.cgi?id=80438
This is https://gcc.gnu.org/bugzilla/show_bug.cgi?id=80438 (found via https://stackoverflow.com/questions/43430921/deduction-guides-and-variadic-class-templates-with-variadic-template-constructor). As a workaround, try adding another deduction guide: template&lt;class...U&gt; foo(U...) -&gt; foo&lt;U...&gt;; // existing template&lt;class U, class... Us&gt; foo(U, Us...) -&gt; foo&lt;U, Us...&gt;; // added https://godbolt.org/z/zLknyz 
Of course there are many old code bases that use MFC/ATL. Many of those will never be updated or upgraded to something newer. Your question though sounded like it's aimed at new projects - i.e. "Cross platform C++ vs WinAPI **today**". Sorry if I misunderstood. Microsoft changed a lot over the past 3-5 years, they promote and actively life cross-platform more than ever. Just look at WSL, VS's CMake integration, their alignment with standard C++, or the VS Linux/WSL integration. And I am pretty sure nobody from the Visual C++ team would recommend MFC/ATL anymore at all. Sure, they're a commercial corporation and their end goal is still to convince you/us to use *their* own proprietary IDE and compiler - but because it's the best - and not because you have to because of some form of vendor lock-in.
Yet you say "constant changes of license". The last license changes I could find are: - 2005, when Qt became available under GPL on Windows, which made it available under GPL on all supported platforms (it already was GPL for Linux and Mac). - 2009, when Qt also became available under LGPL. Both those changes were rather positive, I wouldn't classify them as harmful at all. Were you perhaps talking about the Commercial license changing its terms? Because that would make more sense given how you talk about companies being reluctant to adopt Qt, as companies are a lot more likely to use the Commercial license than individual developers. I can hardly find any information on the Commercial license though.
 struct Foo { tuple&lt;Bar&gt; tpl; }; `Foo` does not have a ABI version.
Per [Itanium C++ ABI](https://itanium-cxx-abi.github.io/cxx-abi/abi.html#normal-call), trivial and non-trivial types are passed and returned differently. Trivial types may be passed and returned in registers.
I just wish they separated their documentation better to indicate what is the “modern” way of doing it vs the old way. Also, more thorough / better examples. 
I have several counter-arguments to that (hierarchical, as it turns out): * (Almost) everything we do exists within a social context, and it is naïve to pretend we can entirely detach from that. Like it or not, we all have a social responsibility, all of the time. You can choose to care or not care about that, of course, be that in specific contexts or all the time. * Software Engineering is specifically a highly collaborative practice, and sometimes has **exactly the opposite** stereotype. This is something we need to address specifically, in addition to the more general point above. As practitioners we need to pay attention to these matters, and constantly try to improve, the same as we should with our technical skills. It is also and extremely unhelpful stereotype for working with those outside of our world. We want young people to have the right impression of what we do, so they may choose to pursue that path, and we want people in other professions to better understand what we do, as they all work with us in some way, even if our users are sometimes quite distant. * The more recent trend of addressing social matters in a Software Engineering context is not abstract or unnecessary, but **in response to observed problems**. I really hope I don't need to tell you this, but just taking the most obvious example, (depending on who you believe) the proportion of women in Software Engineering roles is somewhere around 15%-20%. Subtle and explicit sexism is both a cause and result of this, and won't go away unconciously. Now apply this same thinking to everyone else. I certainly want people to think about how they work with me, and why I might do things differently to them, even though I look around right now and all the people sitting within distraction-range of me are heterosexual, university-educated, white, cisgendered men. Sure, it doesn't need to dominate every conversation, but it is foolish think that means we can or should ignore it completely. I really hope you will spend at least **some** time thinking about how to make life easier for the people you work with. But feel free to spend just as much time thinking about some new template metaprogramming technique, because that's totally fun too!
Is it normal for these bugs to go unconfirmed for over 2 years? It’s pretty easy to confirm and I’d be interested to see how they’d interpret the standard for this to be *correct* behavior. 
&gt; I find the implication, that no research was done on the performance consequences of the proposed new exception model before it was announced, more than a little worrying. Forking a compiler, adapting it to implement a new ABI and doing a decent job of getting it to produce optimised code is many weeks of work by a compiler expert. And pointless to do unless WG21 have agreed to the proposal in principle first. WG14 have however agreed to this in principle. There is a counterproposal paper for WG14 I'm currently working with its author upon. It actually proposes almost exactly what the OP paper implemented, and uses C attributes to mark up the ABI for each function. I don't think that counterproposal will fly personally, but it's good that WG14 explores the options for itself before it decides. &gt; &gt; Outcome based code is two or three times faster than theirs. &gt; How did you make this comparison? You can do the math from the figures listed at https://ned14.github.io/outcome/faq/#what-kind-of-runtime-performance-impact-will-using-outcome-in-my-code-introduce. Raw values are found in an Excel spreadsheet in the git repo. Due to demand, yesterday I added results for mid-tier and low-end CPUs, so in addition to a high end Skylake CPU, there are now numbers for ARM CPUs including a low end Cortex A53. I should mention the OP's paper benchmark is not comparable to my benchmark. They adapted an XML parser, which would give unrealistically favourable results to this approach. My benchmark is complete pie in the sky, and has no relevance to real world use cases at all. (Before someone goes snarky, my benchmark is to test *relative* performance against known totems. So I can categorically say that *as control flow*, Outcome is more than 250x faster than throwing and catching an exception. I cannot say anything useful about real world code except personal anecdote, which is that I've found no performance loss on the kind of CPUs I'm using, and with the kind of code I'm working with) 
Agreed, and when we layout text, we should use real text and not lorem ipsum.
Any idea if {fmt} have partial constexpr stringbuilding yet? As in, `("Hello %s %d", "world", runtimevar) -&gt; ("Hello world %d", runtimevar)`
The lib the proposal is based on doesn't and I hope the proposal doesn't either as it should aim to minimise compilation overhead as much as possible.
The main problem regarding exceptions in embedded system is first the non-deterministic time to execute the code. In many cases, the time to execute matters less than the fact it is always execute in nearly the same amount of time
Maybe you can implement that by using partial function application: auto format = [](auto const&amp; runtimevar1) { return [runtimevar1](auto const&amp; runtimevar2) { return fmt::format("Hello %s %d", "world", runtimevar1, runtimevar2); }; }; No need to bake that into the library.
I really like the freestanding standard library: there's no good reason to not have things like priority queues, heaps, std algorithms and so on on embedded platforms.
Is this a limited position? Is remote really possible? How exceptional must a candidate be?
You might want to look at the rw mutex implementation of the Linux kernel, unless I'm missing something it's been done before. Here is Linus talking about it in 2001: [https://yarchive.net/comp/linux/semaphores.html](https://yarchive.net/comp/linux/semaphores.html)
You're right, constant changes wasn't appropriate. I'm talking about the beginnings of Qt as a powerful framework in the days of KDE (vs GNOME) desktop Linux. Although the issue was different back then we could say that directly or indirectly it all comes down to limitations both in the GPL (or GPL like) and the commercial one. The pre 2005 limitation under Windows, for instance, also prevented many people to adopt it. I get why it didn't came out sooner though.
Not sure if different things. Rather, more people have experience with the coroutines TS and found there are several major ways of improving it. That is partially the point of a TS, so it has been a success. Whether or not those improvements are worth enough to delay until C++23, remains to be seen. In my opinion, delaying is fine as long as all major compilers seriously support the new spin at roughly the same time we would have gotten the current TS in C++20.
OK, this is quite fun. Working backwards: The difference to `overloaded` is that `overloaded` does not declare a constructor (other than the implicitly declared default and copy constructors). Since `foo` does have a constructor this case the constructor generates an implicit deduction guide [based on the constructor](http://eel.is/c++draft/over.match.class.deduct#1.1): template&lt;class... T, class... U&gt; foo(U...) -&gt; foo&lt;T...&gt;; // implicit template&lt;class... T&gt; foo(T...) -&gt; foo&lt;T...&gt;; // explicit You can see that clang is preferring the explicit guide, while gcc prefers the implicit guide. This is an overload resolution problem; when two deduction guides are found to be ambiguous, [explicit deduction guides are preferred over implicit deduction guides](http://eel.is/c++draft/over.match.best#1.12). But clang and gcc disagree over whether the deduction guides are ambiguous: template&lt;class... T, class... U&gt; int f(U...) { return 1; } template&lt;class... T&gt; int f(T...) { return 2; } int i = f(1, 2); This program (not involving deduction guides at all) is accepted by gcc (selecting #1) and rejected by clang (as ambiguous). Retracing our steps, this means that going back to deduction guides clang gets to tie-break the ambiguity by selecting the explicit deduction guide over the implicit deduction guide (generated from the constructor template), while gcc cannot do this as it has already selected the implicit deduction guide as a preferred candidate. We can construct an even simpler example: template&lt;class... T, int = 0&gt; int f(T...); // #1 template&lt;class... T&gt; int f(T...); // #2 int i = f(1, 2); Again, gcc (incorrectly) selects #1 while clang rejects as ambiguous. The problem is that gcc's overload resolution code is a bit of a mess of heuristics put in place to try to come up with what feels to be the correct result rather than to follow the letter of a standard which has often been ambiguous, inconsistent or perverse. Looking at similar bugs, a delay of several years is not unusual. Lack of developers is a problem as well, of course.
My main objection to the above is the people giving the talks **are not qualified**. Programmers give programming talks. Dentists give talks on dentistry. Social psychologists and sociologists give talks on social matters. I am yet to see any quantitative data from any of these talks. No p-values, ANOVAs or any of the typical apparatus. Even in your comment above you make arbitrary statements like &gt; Subtle and explicit sexism is both a cause and result of this Umm, *citation needed*. For all of this. If you don't present quantitative data, then all this is wishy-washy hearsay with no scientific foundations.
To get some glimpse on what happens at the meeting, you may use [#CppKona](https://twitter.com/hashtag/CppKona?src=hash) hashtag on Twitter.
A big part was the [CppOnSea](https://cpponsea.uk) conference 2 weeks ago which he organized... :)
Why do you mention exceptions here? RAII is not about exceptions, and is perfectly usable on even most constrained of platforms.
Technical matters do not exist in a vacuum. A lot of technical issues exist because of toxic/otherwise poor culture, poor people skills and bad working environments. For both work and life quality, they're the #1 thing to fix.
Because that optimization was done for the Coroutine TS and for example in a new version of Clang was broken. You cannot compare it to mature optimizations such as inlining or other existing compiler technology.
&gt;If you dig deeper, one interesting insight is that if you can have a magic special character that is always guarantee to be smaller than the other side no matter what data it had (integer, float, string, etc), then it’ll just work. Of course, we had no such luxury as the smallest byte is 0, and any data can also be 0. But that does provide some additional hint: what if we can artifically artifically inject such marker into the string such that the one that is longer has a bigger byte marker? Or... Null terminate the strings? Assuming you can't have null characters inside the string as a valid thing, anyway. Also, the given scheme fails in this case: &gt;A: A, A, A, A, A, A, C &gt;B: A, A, A, A, A, A, B, B &gt; &gt;Encoded: &gt;A: A, A, A, A, A, A, 1, C, 0... &gt;B: A, A, A, A, A, A, 2, B, B, 0... A is "greater" than B, but memcmps as _less_ - the only way to fix this would be to put the "more" bit _after every character_: &gt;Encoded: &gt;A: A, 1, A, 1, A, 1, A, 1, A, 1, A, 1, C, 0 &gt;B: A, 1, A, 1, A, 1, A, 1, A, 1, A, 1, B, 1, B, 0 
I saw this section, however this seems to be about the *initial* exception allocation, and it did not look like (to me) this was used for 2.3. After all, the text says: &gt; memory is allocated on the stack for the exception `object`
So initial releases might not show optimal performance. Does it matter if it needs a few iterations until all compilers do proper optimization of a language feature that will stay with use till the end of c++? Do we have to pessimize the future in favor of the present? IIRC, they were able to implement those optimizations in clang in a couple of months, I don't think it will take long after coroutines are merged into the standard, until compilers will do this pretty reliable. What I'm afraid of is this: The more you let the programmer inspect and control low level details (e.g. allocation), the more complex your program becomes, the more restricted the optimizer is in what it can do for me automatically under the "as-if" rule and the more likely it is that the programmer implements an optimization that gets outdated and actively harmfull as compilers and hardware evolve over time. 
The best C++ programmers aren't purists or fundamentalists, and don't blindly use only proprietary stacks. They're pragmatists. Use what works for your use case.
The whole point of a format library is ergonomics. Expecting the user to do this is ludicrous.
\`{fmt}\` is a big improvement over \`iostream\`, but I'd really rather see something like [https://abseil.io/docs/cpp/guides/format](https://abseil.io/docs/cpp/guides/format)
Oh come on, that's not awesome! Those are five marginal language improvements. It's not bad that we get it, but we can easily live without any of that stuff. A working module system that really improved our lives would be awesome. Reflection would be awesome. Networking would be awesome. This? This is "meh" at best. 
One on one arena battle? :-D 
Thanks! That makes more sense now. I was fuzzy before on the implicit deduction guides. I guess their priority would be to support newer standard features, or else they'd lose out badly to clang. 
And ultisnips, ALE
Yeah, I think that although this is a relatively long-standing bug, we can hope that as C++20 approaches it should get some more attention. Certainly it would be embarrassing for such a simple and natural example to fail (even if the workaround is relatively straightforward).
Currying :) 
Runtime performance is the priority. Compilation performance must come second. 
High level networking does not belong in the standard. 
Attempting to learn from application-level Microsoft code, hm. What did I miss.
TBH, I'd switch to JavaScript &amp; Electron before using windows APIs. I'm really not a fan of platform lock. It's probably irrational due to working on cross platform toolchains. But I fucking hate one platform software. 
I don't know what you consider to be "high level networking", but std::socket should most definitely be in the standard. At least I think we can all agree that this networking fad is probably not going away any time soon... 
Right. But I thought people want to put asio in the standard. 
mortal kombat!
&gt; but I'd really rather see something like https://abseil.io/docs/cpp/guides/format Ewww, printf format specifiers. What's the purpose? Also, does it support custom types?
There a few asynchronous tricks asio does such as Windows overlapped-io that are simply not going to be available in a standard way. C++ needs to performant or a major reason for it being is gone. It's good to get a std::socket, it's also good to get asio as standard as well.
Thank you for that! At first glance the implementation is very different; need to read it more carefully. I see cmpxchg in there, and some loops. My ct\_rwmutex structure does not use CAS and has no explicit loops in the code. Working on another type of benchmark, and some comments in the code. Also, my work guarantees that there is no write or reader starvation because it alternates them in batches, like a bakery algorithm. If anything it is like a special Benaphore geared towards a read/write mutex: &amp;#x200B; [https://www.haiku-os.org/legacy-docs/benewsletter/Issue1-26.html](https://www.haiku-os.org/legacy-docs/benewsletter/Issue1-26.html)
No wonder my algorithm seems to do fairly good on Linux wrt some really nice people who tested it: &amp;#x200B; [https://groups.google.com/forum/#!msg/comp.lang.c++/g6veUOvOAu0/L7Sjs0xOBAAJ](https://groups.google.com/forum/#!msg/comp.lang.c++/g6veUOvOAu0/L7Sjs0xOBAAJ) &amp;#x200B; [https://groups.google.com/forum/#!msg/comp.lang.c++/g6veUOvOAu0/hMIu5VBSBAAJ](https://groups.google.com/forum/#!msg/comp.lang.c++/g6veUOvOAu0/hMIu5VBSBAAJ) &amp;#x200B; Well, working on a new benchmark, with comments in the code. :\^) &amp;#x200B;
Correct me if I'm wrong but I think std::span ended up with both size() and ssize() for unsigned and signed.
I wouln't expect normal user to curry formatting. It's quite a special need. A format library should not complicate it's interface just to make complicated and unusual cases more convenient.
Holy moly! Read all of the following post: &amp;#x200B; [https://groups.google.com/forum/#!original/lock-free/zzZX4fvtG04/ebVWl0BCBAAJ](https://groups.google.com/forum/#!original/lock-free/zzZX4fvtG04/ebVWl0BCBAAJ) &amp;#x200B; WOW! Btw, **Dmitry Vyukov** works at Google and develops the GO language! Why did I fail to put a licence on my work. Damn it. &amp;#x200B; Here is his response when I asked him what he thought about my algorithm: &amp;#x200B; **Dmitry Vyukov:** I think it's one of the best algorithms out there. The complete fairness for both readers and writers is notable. And the wait-free fast-path for readers. It still suffers from high cache line contention even on read-only workload, but it's as good as one can get with a centralized design (i.e. not per-thread/cpu distributed stuff which has own problems). I would expect a CAS-loop-based read lock to degrade significantly under high read load. Btw your algorithm is used as the standard Go RWMutex for the past 7+ years= : https://github.com/golang/go/commit/daaf29cf932 (I should have mentioned your authorship somewhere!) As for potential improvements I can only think of optimizing uncontented writer lock/unlock to be 1 RMW each, i.e. not offloading writer competition resolution to a separate mutex, but rather incorporate it into the same atomic variable readers and writers use for synchronization with each other. Do you think it's possible? With CAS-loop? Or maybe with some smart atomic\_fetch\_or? Wait, atomic\_fetch\_or is compiled to a CAS loop on x86 anyway. These new C/C++ atomic interfaces sometimes make me forget that. &amp;#x200B; &amp;#x200B; WOW! &amp;#x200B;
My understanding is that `std::span` ended up with only unsigned `size()`, but that a `std::ssize()` free function was added that wraps `std::size()` and casts the return value to a `ptrdiff_t`. None of this is reflected in N4800, though..
I haven't kept up with CPP news lately and I'm genuinely curious what tools you're talking about?
Perhaps Meson, see [https://mesonbuild.com/index.html](https://mesonbuild.com/index.html). I don't have real world experience with it, but I have tried it out on a personal project and it seems great. Meson is used by many notable open source projects.
My algorithm is being used by the Go language: for over 7 years. Read all: &amp;#x200B; [https://groups.google.com/forum/#!original/lock-free/zzZX4fvtG04/ebVWl0BCBAAJ](https://groups.google.com/forum/#!original/lock-free/zzZX4fvtG04/ebVWl0BCBAAJ) &amp;#x200B; **Dmitry Vyukov** works for Google. Fwiw, I am creating a new type of benchmark that will have a lot of comments.
Oh ... my god. All I have is the libc++ 7 implementation and [cppreference](https://en.cppreference.com/w/cpp/container/span), in both cases there's just `size()`, returning `std::ptrdiff_t`. If the API is still undergoing such major changes, why is it not hidden in `std::experimental`? Having it in the standard namespace made me think it's stable enough to start relying on its design. I don't think suddenly slapping an additional `ssize()` on everything is a good way forward. Like if the duality/fragmentation between `std` and `std::ranges` wasn't enough already, now we're "fixing" unsigned sizes by providing a bolted-on function? :(
&gt; I don't think suddenly slapping an additional `ssize()` on everything is a good way forward. It's a free function that calls `size()`. As to the rest, `span` was in the GSL with a signed size type – that was the experimental phase. Having had experience with that, they have since decided that the inconsistency of having a signed size was bad. Seems like the system working as intended to me.
Another amazing blog post from you, thank you very much. It was a pleasure to read it, it was understandable, enlightening, full of so much information, and I appreciate all the direct links to the references. There's literally no better way of writing a blog post. I found one small typo xD "omipresent" should be "omnipresent", I guess. Keep up this amazing work...
There were some really good points in this talk, I particularly liked the idea of a `matrix_view` you’d use to look at transposed matrices rather than creating a new matrix instance just for a transpose. Given that the author is pro game development, I’d be excited to use this set of classes if it becomes part of the standard.
Thanks a lot! :) This one took me quite a while, didn't expect `std::span` to be so ... special. Typo fixed, cheers!
Notably, UTF-16 is *not* a sane encoding. And floats aren't particularly difficult, they are already sign-magnitude form, which (other than the endianness thing) just requires inverting *everything* if it's negative, or just the sign bit otherwise. Maybe you want to normalize `-0.0` into `+0.0` first, but there's no way to preserve NaN behavior (and good riddance).
One thought that comes to mind that any "guideline" that proposes anything alongs the lines of "almost always [X]" must *surely* be bunk. I don't want rules that I follow "almost" all the time and the fact that we have such rules at all is unfortunate.
Meson is the most popular of the new batch of build tools. There is also QBS, which I really like, and build2, which gets posted about pretty frequently by its creator on this subreddit.
First of all: Thanks to the paper he mentioned, it is “always auto” now the “almost” can be dropped. This completely answers several questions regarding style, including how to find variable declarations. Now, for the non-brace-syntax. It is even worse. While this might still be expected, though I assert it is terrible: auto x = int(3000000); auto y = short(x); This is absolutely an atrocity: auto x = "foobar"; auto y = long{x}; Note that no compiler will warn you for using that code, because `T(x)` is actually a C-style-cast in disguise. And C-style casts should really get deprecated, because they are an abomination! With braces, everything behaves as it should: auto x = int{30000000}; //auto y = short{x}; // ill-formed. auto x = "foobar"; // auto y = long{x}; // ill-formed This is why I recommend that everybody uses braces almost all the time, despite the issues with the initializer-lists. And yes, that “almost” really sucks. My personal approach is that I use `()` for non-init-list-ctors of containers and braces everywhere else.
Did you intend for your 'atrocious' code to use parenthesis?
I ended up with auto everywhere, explicit type where it makes it more readable or when creating a new variable and brace only. auto lock = std::lock_guard{mutex}; auto i = int{94}; auto const&amp; employee_name = employee.name; No initialised variable, no vexing parse, and (almost) uniform everywhere.
&gt;Note that no compiler will warn you for using that code, because &gt; &gt;T(x) &gt; &gt; is actually a C-style-cast in disguise T(x) IS a C-style cast. Where is the disguise?
(T)x is an actual _C-style cast expression_; T(x) is a _functional cast expression_ that is equivalent to a C-style cast.
Did you figure out why it hangs regularly? Why is it slow to start discovery after a build? 
why would you write `auto i = int{94}` instead of `int i {94}` ?
Yes, consider it a sign of how used I am to `{}`.
Microsoft's version? or mine? If you're using the live testing, or any of the parallel features, they don't work so well with it. I haven't actually had many problems with it. What size project are you experiencing it on?
In that it looks like a constructor- or function-call and is not the syntax used in C.
I'm using Google Test Adapter. I have a solution with about 100 projects loaded but actually 30 projects compiled and less than 10 projects containing tests (around 1k tests). After a build, it can take more than 10 seconds before it starts to launch test discovery: during this time, nothing is printed in the output. As feature, I would love to have manual discovery with a button in the test explorer to avoid wasting time with unnecessary discovery. For this aspect, VS Code is far superior for test discovery and test execution. But VS remains better for compilation and debugging. I wish a Visual Studio taking the best of both software. 
Hmm. That would be a good feature. I haven't used VS Code for this. So it's taking 10 seconds before the discoveryengine.exe is even run? 
In the former you get to write auto in the latter you don't. You do like C++11 features, right? ;)
I agree. Auto Everywhere makes the code harder to read and reason about. Auto makes sense in a lot of places, and I miss it when I write Java, e.g. map iterators, but strongish typing is one of the strengths of C++ over, say, python, but auto destroys that. I've been told to use an IDE, which I do, but 2 of my 9 work hours are spent in vim over ssh on the train, and it is much harder to figure out what object some 3rd partly library is returning if it is declared auto.
agreed, also in tooling like stash for PR reviews, I want to know the type if it's not locally apparent.
&gt; If the API is still undergoing such major changes, why is it not hidden in `std::experimental`? Well, C++20 hasn't been released yet, so you should treat every API it introduces as experimental and subject to later changes. How are you going to start relying on its design if it hasn't been released yet? 
some find the = more readable. like in the article stringlist policies(get_policies()); vs stringlist policies = get_policies();
&gt; no compiler will warn you for using that code, LLP64?
Hey, what do you think about using Python as the main umbrella language and patching in type-specific (templated?) C++ modules as desired &amp; needed? I’m just learning programming but this seems like a great approach and yes, using auto seems a little like trying to make C++ into Python, I mean as a relative beginner type-identification in C++ makes things nice and clear at least.
Just to be consistent with other declarations. If I always do `auto &lt;name&gt; = &lt;type&gt;{&lt;expr&gt;};` then I stay consistent.
Yeah, I can live with the confusion of &gt; vector&lt;char&gt; v(42, 'x'); being not a function execution. Well it's not nice but just knowing vector&lt;&gt; being a class instead of a function will solve the confusion. Even if I hit my head hard tomorrow, it's just one Google away. Even for poorly-written third-party libraries it's quick. Now understanding &gt; vector&lt;char&gt; v{42, 'a'}; requires considerably more time for me currently. Someone, teach me a quick way...
Uninitialized variables are a very good thing: they enable static analysis to spot bugs and show the actual intent of the code. What is not good is compilers not initializing the variables in the actual binary/code sequence, but that is a different issue.
Genuine question: in my experience, AAA simply serves to hide the types present in the code which makes it much harder to understand (if easier to read). I haven't really heard a good argument for this style, it seems like its only purpose is that it generally makes code easier to write I at least sometimes find myself accidentally writing a wrong function name or whatnot. With explicitly stated types, you have to state your intention which the compiler checks, which catches a class of error. With AAA, you lose that guarantee for no good reason. Additionally it becomes massively harder to grok the types going on in the code, and you have no idea if the developer really meant size_t() - 1 or if its a bug It also seems needlessly different to existing code, like east/west const or similar bikesheds
What about uninitialized variables?
This is a good [blog post](https://foonathan.net/blog/2016/03/03/cmake-install.html) about structuring a project, especially using CMake to build. Actually it's a popular structure of libraries as we often see on GitHub.
If I had to choose a part of the language to be fixed, it would definitely be initialization mess. &amp;#x200B; If I could choose 2 things, then add modules as well :)
Can’t be dropped in class members
AAA is in my opinion for short scripts and tools. For long-term maintainable code or for APIs I just use it for unnamable or difficult to name types. The rest goes with its type everywhere, it is easier to follow. &amp;#x200B; Since a "script" as in self-contained tool is usually a throwaway thing or just a processing tool with, let us say, 200 lines of code, it is convenient to code in a "pythonic" style. In that case I find it useful and not worrying. In the other cases, it will create trouble for you later down the road.
It’s easier to read when I understand the code add, but more difficult when trying to learn a new code base and I need to look up what each function returns. 
I use it when iterating over ideas early on and type names are subject to a lot of volatility. 
I love that: `std::string(foo)` is a declaration of a string named foo, if there is no foo in scope. 
Indeed this is the approach I take as well, although short throwaway tools have a n increasing tendency to outlive their stay in my experience heh, although obviously this is a context thing What I don't understand is people who seem to advocate structuring code everywhere using this style
A lot of our stack is built this way. We have C++ objects that are used in production code, but are also wrapped in boost python for research so that we use identical code in both places. So, we can test new ideas in python, while use the core, tested C++ libs for research and backtesting, and know that we don't have divergent code written twice in both languages.
Even coming back to code that I wrote a few months ago is harder with auto. So much is made of writing code that is easy to read, even if it is a little longer to write, and then we go and declare EVERYTHING auto. It doesn't make sense.
To be fair, the reverse was the norm before. It just didn’t have a sensationalized name. Almost Always Not Auto. Where you just used auto when you had a long, noisy type name like iterators. 
Yeah I’m a bit apprehensive with “almost always auto”, but that said I did recently update the code in most of my personal projects to use `for(auto&amp; item : container)` and I must say I generally do like that I can change out the container type in this way without having to modify the item type. I don’t think I use `auto` anywhere else though.
You can delay a bit refactoring for the sake of deployment speed. It is just a tradeoff.
&gt;I did not say we need to pessimize the future on those optimizations should not be implemented. I just made the point because you say "Why everyone is now suddenly afraid of..." and I gave you a factual answer, a reality of the status and why people might be afraid. You are shifting the conversation somewhere else. &amp;#x200B;
&gt; std::vector&lt;char&gt; vc {42, 'x'}; I mean... no. There is a *reason* why this is called **uniform** initialization and it should be used *when uniformity is important*. It does not mean "all initialization code must be uniform from now on". What's funny, uniform initialization also prevents narrowing conversions (`int x{7.5}; // nope`), but in the above, it... well, kinda does the opposite. Which is the decades old problem of C++: whatever feature there is in it, it is there for a reason. The trick is knowing that reason and using it *when the reason matches the situation in code*. So... `std::vector&lt;char&gt; vc(42, 'x');`, offhand, is **fine**. 
[gdb-dashboard](https://github.com/cyrus-and/gdb-dashboard)
Looks like a cooler wrapper to use GDB on command line, I will give it a try. Have you used it? is it web based? Does it integrate with tmux?
I just use terminal stuff, and it integrates fine with tmux, it does support browser viewing though. I like it because it's a thin good enough wrapper, I have all the control gdb can give me , plus the nice thin TUI.
Amen. I really don't see what is wrong with int x = 5; And why everyone was recommendibg using braces instead. I guess it does prevent some bugs where you get problems by doing an implicit type cast, but I've literally never been bitten by that bug, and all the examples I've seen seem contrived. I've seen enough issues with initializer list constructors to steer clear unless I know exactly what they're doing. 
Title is intriguing :)
Word. Expressing intent is very valuable for catching bugs, and auto removes that. I only use it for iterators and the like, or in the rare case where I have a dependent type. 
cgdb or vscode with any of the gdb extensions
`a b(c d);` is *never* a function execution, is it?
C+20 isnt approved, so it's much more than experimental! 
Eclipse CDT have a great debugger integration with gdb.
Not to be flippant, but: lldb
&gt; The = sign is your friend. Agreed.
I put a mouse over the function and I see it.
Auto does not "destroy" strong-ish typing, it merely makes it less strong-ish in certain situations. vim has tooling, too.
42 as an integer is implicitly converted into a char, because they're both primitive numeric data-types. You can try it by trying to compile &gt;vector&lt;char&gt; v {300, 'a'} which gives the error &gt;error: narrowing conversion of ‘300’ from ‘int’ to ‘char’ inside { } [-Wnarrowing] As std::string isn't a primitive and thus can't be implicitly converted from an integer, it's calling the fill-constructor using a size_type instead. In my opinion the fill-constructor is a little over the top. It's just adding confusion; if you want to fill the vector with copies of one given element just call fill... Doesn't need a constructor for this.
A big reason why is nothing is actually decided until plenary. 
Oops, right, I was half asleep. I should have written declaration.
Qt Creator has pretty great integration with debuggers. 
Thanks. I totally agree with you.
The braces from hell.
CLion has good debugger support
These are different things from language standpoint, though.
You should check out P1385, it's exactly this and aiming for C++23
Does it work now on Linux? I tried it 3-ish years ago and couldn't do any useful debugging because it (lldb) segfaulted rather often.
KDevelop has nice gdb integration.
Actually, almost all guidelines (pun intended) - no matter in which domain - come with some caveat, so they can't be applied universally. It is just in the nature of things.
AAA makes the code more generic and resistant to change. If I have `SomeResult GetSomething()` and write `SomeResult x = GetSomething()` then I'll have to change a bunch of places in the code if `GetSomething()` is changed to return a structurally compatible `SomeBetterResult`. With auto it'll just work. Even better with auto, if `SomeBetterResult` derives from `SomeResult`, the explicitly-typed code would inadvertently slice the return value; if you're lucky you'll get a compiler warning. With auto, the "right thing" will happen (i.e., no slicing). IME, auto vastly simplifies refactoring the code. Also, I don't think it obscures anything. With a good IDE, I'm only a mouse-hover or keypress away from finding out the actual type if needed. 
+1
There's nothing wrong with `int x = 5;` but it's inevitable to have more complex types, where you have to choose a style among std::pair&lt;int, const char*&gt; x(42, "foo"); std::pair&lt;int, const char*&gt; x{42, "foo"}; std::pair&lt;int, const char*&gt; x = {42, "foo"}; std::pair&lt;int, const char*&gt; x = std::make_pair(42, "foo"); auto x = std::make_pair(42, "foo"); auto x = std::pair(42, "foo"); auto x = std::pair{42, "foo"}; ...
I didn't get this far into my investigations, I've just notice that nothing is logged into the output window (tests tab) until a certain time. But definitively I'll try to investigate because it didn't get better in VS2019. I'll let you know if I find something.
Thought I was on r/spam for a second
&gt;But isn't the fill-constructor potentially faster than the fill call? Constructing an empty vector doesn't really have an overhead in that regard. I guess you're saving one function call. However I'd say that the function call is neglect-able in comparison to a ressource-heavy fill. But keep in mind that this is just a guess from my side, I'd have to compare its performance in order to be sure about this...
First of all - as pointed out by herb Sutter in the talk where he coined that term - you can still have explicit types if you want. They just wander to the right hand side. As far as the advantages go - You can't forget to initialize a variable - Less redundant type declarations, which means - less visual noise when reading - Easier refactoring - Less chance to get the type wrong (e.g. you think the variable has the same type as the return type of a function, but in reality it is just something convertable to it). Now personally, I only use auto if the type is obvious (return type of a factory, result of a static_cast a.s.o) or I don't actually care (iterators, functions that return multiple values via a wrapper struct) and of course generic code. It is not nearly almost always, but still pretty often and I find the code both easier to write as well as easier to read.
same with me &amp;#x200B;
199$ per year!! is it worth that amount?
Isn't your first point also solvable with type aliasing?
No
I'm just comparing to my experience with C++11 in 2009/2010 (then called C++0x). A year before it got released and the API design for new containers could be already mostly relied on (apart from implementation bugs). The modifications done after that were just minor (e.g. `std::unordered_map::reserve()` or `std::map::emplace()` being added later), it was definitely *not* undergoing such major changes so close to a release. Same thing with containers like `std::optional` (or, IIRC, `std::string_view`) in C++17, the basic workflow was agreed upon and pinned down long before C++17 was out. In my opinion, as soon as a type appears unprefixed in some STL implementation, early adopters will start using it (and learning it) — if, at that point, it's still too dangerous or too annoying to use, something's *really* wrong — bad workflows are hard to unlearn and even harder to remove from existing code. Another thing to consider is a time in a few years from now and code that has to run on older compilers. If `std::span` switches to unsigned `size()` and fixes the dangerous constructors for libc++ 9 (too late for version 8 now), you have to delay adoption of `std::span` by another two years because it has a totally different semantics in libc++ 7 and 8 — and you can't check whether it's usable just with `__has_include()`, you have to rely on various implementation-specific version macros. Together with usual production code having to support compilers from the past five years, that means we can't reliably start adopting `std::span` until ~2025, depending on when usage of libc++ 8 dies out. I'll be too old to care by then. Compare that to the case where inclusion to the standard would mean the basic workflow *has to be* pinned down and without obvious warts — the type is either there, working, or not at all.
That is a very interesting and valid point, although I disagree with it, and it did not seem to be the point you were making above at all! &gt; awesome if these conferences were to stick to **technical matters alone**. All this social commentary is **unnecessary**. You didn't seem to be saying "this content is important and should be handled better", you //seemed// to be saying "I write code, I don't care about this stuff". That's why I wanted to react and try to convince you it really is important. If you already believe it is important, and look to educate yourself and change your own behaviours in a way that works for you, that's great! That said, I still disagree with you about the current content of talks at conferences having no value. I see the benefit of augmenting the content with a more rigorous scientific approach, but I also see huge value in simple human experience. We listen to experienced engineers and trust their technical opinions because of their experience; I see that applies to a large extent to their experience of professional behaviour too. It doesn't have to be all or nothing. And in reality, so many people simply aren't talking or thinking about these topics at all, so kicking off that conversation is waaay more important than keeping silent in fear of not having all the details correct. I fear this meta-conversation is just noise distracting from talking about the real problem. (And yes, I realise the irony that I am actively participating in that noise...)
&gt; In my opinion, as soon as a type appears unprefixed in some STL implementation Isn't it under the experimental c++2a compiler flag? So it's not like you can suddenly add it to a C++17 code base and then run into issues. IMO, you are already running under experimental mode if you care compiling with that flag. 
My preference: // initialization (direct default construction): Type identifier; // initialization (direct construction): Type identifier { construction params }; // initialization (proxy custom construction): Type identifier { some expression yielding Type }; // assignment: identifier = some expression yielding Type; This disjoints the initialization syntax from the assignment syntax and offers a uniform initialization syntax. And it lends itself to easy formatting if you need to break up a line into multiple lines.
My preference: // initialization (direct default construction): Type identifier; // initialization (direct construction): Type identifier { construction params }; // initialization (proxy custom construction): Type identifier { some expression yielding Type }; // assignment: identifier = some expression yielding Type; This disjoints the initialization syntax from the assignment syntax and offers a uniform initialization syntax. And it lends itself to easy formatting if you need to break up a line into multiple lines.
My preference: // initialization (direct default construction): Type identifier; // initialization (direct custom construction): Type identifier { construction params }; // initialization (proxy custom construction): Type identifier { some expression yielding Type }; ^-- Type, Type&amp;, Type&amp;&amp;... // assignment: identifier = some expression yielding Type; This disjoints the initialization syntax from the assignment syntax and offers a uniform initialization syntax. And it lends itself to easy formatting if you need to break up a line into multiple lines.
I choose none of the above.
There is a very simple answer to that: Don't use them!
&gt; Can’t be dropped in class members. Okay, I'll give you that one. Though when it comes to class-members it's less of a problem to overlook a new variable. &gt; Also awkward to static_cast reference_wrappers. I don't know exactly what your problem is, but to quote STL: A cast conceals that something is broken. IMO that means that you should rarely use them in the first place and that they should indeed stick out. Also, serious recommendation: *Whenever* you write a cast, identify *what* is broken before doing so. It may well be some aspect of the language and if that's the case by all means go on. 
My (tentative) take on this issue: conceptually, there are four ways to initialize something. 1. Just give me a value of this type. 2. Create a copy of an existing value. 3. Use a parametrized factory. 4. Create a collection from explicitly specified items. I think these four map quite naturally to default construction, construction using "=", constructor call using parentheses, and braces-based initialization. vector&lt;string&gt; v1; // Just give me a vector&lt;string&gt; vector&lt;string&gt; v2 = x; // Create a copy (actually, I would use "auto") vector&lt;string&gt; v3(42, "s"); // Parametrized factory vector&lt;string&gt; v4 { "a", "b", "c" }; // Collection from items I think this makes my intent clearer than the braces-for-everything convention. It also avoids some of the pitfalls. The article points out that `vector&lt;char&gt; vc{42, 'x'}` creates a vector of size 2. Sure, but *I don't ever do that*. Based on the above idea, I'll do `vector&lt;char&gt; vc(42, 'x')`, which does exactly what it looks like it does. The article seems to agree with me, more or less, although the idea is stated differently: &gt; Simple guidelines for variable initialization in C++: &gt; * Use = whenever you can. &gt; * Use initializer-list syntax {} only for element initializers (of containers and aggregates). &gt; * Use function-call syntax () to call a constructor, viewed as an object-factory. 
For compile times it would be nice to have Containers::ArrayView with vector and array included also in the list.
If you are buying for yourself it is $89 and gets cheaper after that. If your work is buying it $199 is not expensive for the increase in your productivity. I own a license and love it. My work refuses to buy it because it is Russian. 
Not really. Uninitialized variables are important for proper static analysis.
https://www.reddit.com/r/cpp/comments/aabthn/modern_c_lamentations/
These are things that should have been factory methods: std::vector&lt;char&gt; aaaaaaaa = std::vector&lt;char&gt;::make_fill('a', 8); Constructors that take random parameters that aren't immediately understandable at a glance should be _named_.
I would like to see an example for that.
Not really. Not with many great IDE’s already out there. 
In C++17 with guaranteed elision it will now work. No move happens because the return'd value isn't materialised until it hits the variable declaration, so it never exists as a temporary. See: https://gcc.godbolt.org/z/JVEt7F
Please don't go too crazy with costumization points. I'd rather have a couple of simple default types and functions that establish certain concepts / patterns and can be used as a lingua franca to exchange information between libraries. The result doesn't have to be optimal for all use cases. It should be easy to use for non-experts, good enough for most usecases and provide an easy way to exchange information between independent libraries (e.g. my sensor api, some filter/fusion algorithm library and the graphics library that allows me to display the results). If I do have very specific reuqirements and I depend on getting the maximal performance, chances are that no matter how much customization points you offer, they will not be good enough and I'll just use a specialized library that has been reviewed, tested and optimized by domain experts anyway. I certainly want static and dynamic sizes, but please don't make std::allocator-like types part of the type.
This is pretty accurate
Thanks for your reply :) I thought it is obvious I do not suggest, using namespace std; outside of your own namespace? Anyway, I have boldly forked and changed your code :) It is [still C++14 and "no telnet" version does not have any dependency on boost](https://github.com/DBJDBJ/cli/tree/dbjdbj_no_boost/cli). &amp;#x200B; Compiles builds and runs. &amp;#x200B;
The `static_cast` was in reference to this example: auto foo_vec = std::vector&lt;std::reference_wrapper&lt;Foo&gt;&gt;{}; // foo_vec gets set for (auto&amp; foo : foo_vec) { // foo is std::reference_wrapper&lt;Foo&gt;&amp;, // not a Foo&amp;. } for (auto&amp; foo : foo_vec) { // foo is a Foo&amp; }
&gt; My claim is that "Uniform initialization is not broken", just that "uniform" doesn't mean "use one style for everything even if it means different things". That's exactly the reason we (/parts of the community) came to the conclusion that we should call it [unicorn initialization](https://i.imgur.com/9aGiFzt.jpg) instead. &amp;#x200B;
I'm aware of it, I don't think it adds anything productive to the discussion and this post is kind of my answer to it. In my opinion, uniform initialization is the correct term. There is a good uniform rule when to use what. It is just not, what some people claim what uniform initialization is about.
imports std, then defines a range class. Sounds yummy. Then implements a manual binary search. You would get two questions from me: * Formally prove me that index will never go out of bounds Just looking at: size_t index = v.size() / 2; size_t step = index / 2 + 1; while(true) { if(v[index].hi &lt;= p) index += step; if(v[index].lo &gt; p) index -= step; Let's say ```v.size()``` is 2, so index is 1, and step is 1 if ```v[1].hi``` is ```&lt;= p```, then your index goes immediately out of bounds. Then, the next question will be * Formally prove me that your while(true) always stops You'll have a hard time, as you always exit when you find the range (ie: you crash when you don't find the range). You code only works because ranges cover everything. You could get the exact same result by using only the lower bound + sort + binary_search. Also, the question ask to find *one* value in a set of ranges. Sorting the range is much more costly than just looking for the correct one (sorting is only useful if you have more than log(n) searches to do, which is not what the question was). Also, no comment, no asserts, no test. You really want to post this here ? 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/as9f5b/with_which_one_of_these_books_should_i_start/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I started on the same path with the same goals 15 years ago. Back then it was OpenGL instead of Vulkan and C++ was a bit more painful. You definitely need both research and practice. Read books whenever you can't motivate yourself, they will give you new things to try. "API design for C++", "C++ concurrency in action", "Game engine architecture" by Gregory and Scott Meyers modern C++ book. Keep everything in an off-site repository. Bitbucket is great for private ones. University courses can be very useful for specialized topics and some offer there materials online for free. Most importantly: start small, make a polished and finished Pacman or Tetris clone before you try anything more complex.
Thanks, it somehow remember that GCC was giving me an error in this case. I guess my memory has failed me again.
As you can understand, I can't merge a PR that breaks the API (particularly if there are no good reason -- i.e., changing gratuitously from CamelCase to snake\_case): there are already lots of projects using the library, and can't ask every user to change their code. In addition, as I was pointing out in the previous comment, I really don't feel the need to use string\_view given that the speed of the library is already limited from the I/O nature of the library. Besides, to add string\_view remaining in C++14, one should import the whole string\_view code in the project. BTW: on the snake\_case VS CamelCase religion war :-) Maybe you noticed that you had to come up with bad class names like "cli\_type" and "menu\_type", because "cli" and "menu" were already used. See? By limiting yourself to only lowercase characters in identifiers, you're reducing very much the space of combinations (e.g., if you have a 3-char identifier, using only lowercase chars you get 17576 possibilities. With mixed cases you have 140608 :-)
r/subsIfellfor 
Good point: Use braces or parens depending on whether to store values in a container or parametrize an object. The only problem with the parens: It doesn't always work due to most vexing parse :(
The biggest problem IMHO is the confusion between constructor params and initializer list elements. It can be fixed with a second layer of braces. Calling init list: vector&lt;int&gt; v{{10, 11}}; // two element array Calling parameterized constructor: vector&lt;int&gt; v{10, 11}; // ten element array Initializers would always be init lists so no change: vector&lt;int&gt; v = {10, 11}; // two element array I wonder if it is too late to fix this. Anyway it IS broken because it requires careful conventions to avoid design pitfalls.
So how would `SomeResult` and `SomeBetterResult` live side by side? E.g., having multiple functions, some of which return result, and some return a better result. In any case, I consider type-aliases like that to be "obfuscation".
You are complaining that span is not consistently named with string_view and that span and string_view behave differently. That they behave differently (span allowing mutation whereas string_view doesn't) was exactly th reason they decided to use a different name instead of array_view. Now we can certainly argue whether or not the names are chosen well or not, but I for one are happy that different things are called differently.
&gt; Anyway it IS broken because it requires careful conventions to avoid design pitfalls. It's not like `++` operators are without pitfalls. At least `vector&lt;int&gt; v{10, 11}` can't lead to UB.
Sorry to disappoint you: Every single one of those will produce a 2 element vector, just as expected. No, it isn't broken. 
When i read "almost always" what comes to mind is "have decent defaults and the bare minimum of alternative settings".
In theory yes. In practice, that seems to be an extremely rare case. 
Almost always don't trust "almost always" guidelines
That's basically how I do things apart from using `{}` instead of `=` for the second line. `{}` for values/list of values `()` for factory `=` never?
That read an awful lot like a commercial for this compiler. That said I have a C++ project that targets a lot of compilers and I'm curious to see what happens if I build on this one.
I really appreciate your comment! I come from a small OpenGL background (I learnt the basics and did a small game engine a year ago). After that I did not have free time for my personal projects until now. I am planning to dedicate around 2-3 hours daily when I come back from work! &amp;#x200B; Start small! Copy that! I will do a clone of a simple 3d game (maybe minecraft) once I have the basic setup, and then work from there!
IMO the broken thing is allowing `{}` form initialisation to call constructors with parameters when the type also has an initialiser list constructor - it's just begging for bugs, as the types of the items in the list can change it between constructor parameters and a list of items... This would be a non-issue if containers like vector had their constructors _named_, like "vector&lt;int&gt;::make_filled(4, 5)" - then there's no chance of that being confused with an initialiser list or vice-versa!
Knightmare? I see you have achieved the power of Geass
I stand by both of these points. Look, we have this separate field called *social science*, when research councils give universities grants towards academic research on which government policy can then be based. It's an established science. It has research methodology, ethics guidelines, standardized ways of reporting statistical effects, and so on and so forth. It's a separate field. People study it and make conclusions based on data. Now when I see a developer at a technical conference making sweeping generalizations about the entire field, that is completely invalid. First, they don't have the sample size. They have experience in working with one organization, and even if that org is Google-scale, they still have exposure to just one organizational culture. Naturally all that they observe is nothing more than their own personal interpretation of reality that they try to project unto the entire field. Their conclusions do not apply universally because they didn't do any research to check that they do. Let me give you this analogy: suppose I do go to the dentists' conference and try to give a talk. That would of course be ridiculous because I'm not a dentist. But hey, I've been to a dentist therefore I also have experience of dentistry, *my* experience. So let me give the talk! Hopefully you can see the failure in logic here. No dentists' association will let me in to give such a talk because I'm unqualified. And they would be right. It's not my field of expertise, there's very little I can contribute to the conversation. The point is, your experiences and feelings about the industry are more or less irrelevant to the industry at large. You can do a blog post on how good/bad everything is, but if you give a talk, literally every statement needs to be prefixed with *in my opinion* because you have conducted no research into the topic if you are talking about. And if you *have* conducted said research, then again, you would publish it in JPSP/PS/etc., and give this talk at conferences related to occupational/social psychology, not programmers' talks. Now, the second part. The reason why so many people simply aren't talking or thinking about these topics is because they are largely irrelevant. People paid money to come to a technical conference to learn technical matters, to interact with other developers, to talk engineering. Sure, engineering doesn't exist in a vacuum, but would you really argue that programmers are more socially engaged than, say, doctors/teachers/policemen? And let's not forget that the skew towards introversion in IT is very real and noticeable. So my point is twofold: these talks are both unnecessary (they do not add value to developers' lives) and are not a true reflection of anything, because the people giving these talks are not qualified social scientists.
{fmt} can actually evaluate format strings at compile-time: http://fmtlib.net/latest/api.html#compile-time-format-string-checks However I don't think any specific way to do it has been proposed for standardization.
&gt; both dy­nam­ic-size and fixed-size ar­ray views in a sin­gle type (which, as I un­for­tu­nate­ly soon re­al­ized, on­ly com­pli­cates ev­ery­thing with­out hav­ing any re­al ben­e­fits) This is the reason I absolutely despise `gsl::span`/`std::span`.
Also in agreement with this: https://stackoverflow.com/a/18222927
gdb -tui
Wrong place to post this. I would suggest /r/cpp_questions or stack overflow for questions.
I figured it out. my e1, e2, and e3 were not initialized to false :) &amp;#x200B; `atomic&lt;bool&gt; e1{false}, e2{false}, e3{false};`
Yes, that is exactly the one wart I'd like to get removed, but imho it is not enough to call the thing broken - at least not more broken than all of c++ is anyway. I think named constructors (be it reall names or at least my example with explicitly specifying parenthesis or braces) would be a very nice and helpful feature. 
I'm interested and revolted.
Maybe not if you’re just paying for the debugger. If you use it as a main IDE though I think it’s worth it.
There is an abseil mailing list / google group where you may get better answers from Abseil devs. 
I have tried flat_hash_map and can dig out benchmarks if you want. `std::hash` is bad according to Abseil and a few other implementations., so switch to `absl::Hash` before trying to make any kind of conclusion.
&gt; I tried to replace **all** instances There are cases where flatmaps perform worst than node based maps. For example when storing big very objects (that's why [absl::node_hash_map](https://abseil.io/docs/cpp/guides/container#abslnode_hash_map-and-abslnode_hash_set) exists). Are you sure that it make sense to replace **all** your unordered_map by flat_maps ?
In the talk, "[Curiously recurring C++ Bugs at Facebook](https://youtu.be/3MB2iiCkGxg?t=1743)", Louis Brandy observes that this specific rule causes insidious service crashes due to the following: - coder wants to lock `std::mutex m_mutex` - coder writes `std::lock_guard&lt;std::mutex&gt; (m_mutex)` - this locks nothing, instead creating a shadowing lock_guard named m_mutex - you just crashed Facebook Fix is to name the lock: `std::lock_guard&lt;std::mutex&gt; **lock** (m_mutex)`, but you can go a while not noticing this problem because it's an RAII type that you'd not otherwise mention by name in that scope.
It turns to a bug when someone mistakenly types `std::unique_lock&lt;std::mutex&gt;(mtx);`
Ha! Beat me to it
According to the paper, there is a small runtime cost. They are citing about 1% for Firefox. 
If they don't, we generally call them rules, not guidelines.
&gt; Yes, [calling a constructor with {}] is exactly the one wart I'd like to get removed. Right, so the idea is something like 'never use {} when you intend to call a constructor'. In that case, why not rely on copy elision and just put an '=' in there?
I'll have another post focusing on (growable) arrays vs std::vector. Comparing a lightweight view with an allocating / moving / resizing vector wouldn't be fair I think.
Thanks for the feedback. I already am using a few node maps over the place, because we rely on reference stability there. Typically we only store pretty small objects, so the flat containers are fine.
Check the task manager, there should be a discovery engine process that spins up. That'll help determine whether or not the problem is in the Google test discoverer or VS itself.
Was this a fork of emscripten? 
do you have any insight in my use case of absl::flat\_hash\_map&lt;size\_t,pointer&gt;? This takes 12% of the calculation time with absl\_flat\_hash\_map, while previously this was not even showing up in profiles.
Sorry, I don't follow. 
`absl::flat_hash_map` is very sensitive to quality of hash function. You need to have good entropy in last 7 bits of the hash (in addition to the hash as a whole). If your key is a size of something which is often divisible by a power of two, of a pointer which is normally aligned, you have a problem.
Imho the difference between a rule a and a guideline is how strict they are enforced.
If you're ever iterating over the map, `absl::flat_hash_map` may be struggling as that is not the use case it was optimized for. Beyond that, just benchmark the hell out of everything and see what works best.
&gt; it's also good to get asio as standard as well. It's really not. There's no reason that high level, opinion-heavy software should be standardized. It should be able to be programmed in standard C++ and then people should choose if they want it beyond that. There is plenty of core language stuff that needs to be dealt with by the committee. No need to add anything else onto their plate.
r/cpp_questions or r/gamedevelopment
Is it position involving actual coding tasks? I'd like to work for an open source project like this but coding, not just "talking" :)
No support for exceptions with as argument "it is inefficient". Any kind of project at scale will use exceptions?
For some constexpr functions you could call it with a runtime parameter from your unit test and step into it there?
Yes I know that's not a complete solution for all cases. I would be interested if anyone runs with your approach or anything similar.
No, but the cost seems to be why people of a certain mindset go with it. :/
I'm currently working on a lot of benchmarks comparisons of hashmap implementations over here, with multiple hashing algorithms: https://github.com/martinus/map_benchmark I found that absl is very sensitive to a good hash, so it is best to use absl's hash whenever possible. For integral types this is one of the fastest hashes you can possibly get with reasonable avalanching. I've played a bit around with it, it basically compiles down to a single MUL, 2xMOV, 1xXOR and even has a bit of hacking prevention using using address randomization. I don't think MSVC's std::hash uses the identity function? from what I've tested it uses an FNV1a implementation which is reasonably good for a hashmap. Identity function (as you described) is used by libstdc++. FNV1a is slower than absl's hash, but the avalanching is good enough for absl's hashmap so that its worst case performance does not degrade. Also, absl is extremely fast for lookups but it is not the best option though if you insert &amp; erase lots of times. Then your fastest choice (according to my current benchmarks) is [tessil's robin-map](https://github.com/Tessil/robin-map) which uses a bit more memory though, and a tad slower is [my robin_hood map](https://github.com/martinus/robin-hood-hashing) which usually uses exactly the same amount of memory as absl's flat_hash_map. Here are (preliminary) benchmark results for lots of randomly inserting &amp; removing elements with different hashmaps and different hashes ([code is here](https://github.com/martinus/map_benchmark/blob/master/src/benchmarks/RandomInsertErase.cpp)): Hashmap | FNV1a| Identity| absl::Hash| folly::hasher| robin_hood::hash ---|---|---|---|---|---|--- absl::flat_hash_map| 25.5352| 183.194| 18.138| 22.1158| 17.8021 absl::node_hash_map| 29.6394| 196.26| 22.2014| 27.3532| 22.0358 folly::F14NodeMap| 38.6769| 33.9723| 32.7204| 35.2787| 33.8648 folly::F14ValueMap| 34.7796| 30.361| 28.5139| 30.0064| 29.0919 robin_hood::unordered_flat_map| 21.5066| 10.8395| 18.1578| 21.5079| 12.1088 robin_hood::unordered_node_map| 22.5736| 11.4019| 18.3801| 23.4385| 12.4587 ska::bytell_hash_map| 27.3448| 14.5934| 21.6022| 24.6685| 16.2232 spp::sparse_hash_map| 60.2839| 122.345| 54.3344| 57.6067| 46.4481 std::unordered_map| 50.8486| 34.0295| 45.7516| 48.8786| 43.3777 tsl::hopscotch_map| 32.6428| 11.615| 24.7136| 29.1479| 19.2307 tsl::robin_map| 23.8052| 9.41616| 16.0248| 19.8659| 11.2013 tsl::sparse_map| 42.3753| 181.639| 37.7362| 41.944| 26.601 As you can see absl maps are extremely slow with identity hash.
No, both projects are derived from LLVM/clang, but Cheerp is independently developed.
Although Cheerp 2.0 does not fully support exceptions, code using exceptions can still be parsed and compiled (if you add the -fexceptions command line flag). If an exception actually happens at runtime the code will abort by raising a JS exception. In our experience some (but not all) large scale projects use exceptions, typically to deal with unrecoverable error conditions. Since code compiled with Cheerp will report a JS exception in these situation a proper UX for error handling can still be done on the JS side. It should be noted that, at this stage, WebAssembly itself does not provide support for exceptions.
Is the core of it the translation from LLVM IR to webasm? 
Cheerp is much more than just the Wasm backend. Cheerp supports compiling to pure JavaScript or a mix of Wasm and JavaScript with automatically generated bridge code. You can directly use DOM APIs and JS libraries from C++ and write C++ classes and functions which can be used from JS. The frontend emits proper error messages when trying something which is not supported by Wasm, for example passing a DOM object to a Wasm function. This said, the Wasm backend of Cheerp is also better, as demonstrated by our results on both performance and code size.
I observed the first mentor did do coding projects. Certainly there will be many code reviews.
Any Android or UWP project, as exceptions are required.
 // using GetSomethingResult = SomeResult; using GetSomethingResult = SomeBetterResult; GetSomethingResult GetSomething(); It's no more obfuscating than 'auto'
That all sounds great, what kinds of things does it do to eliminate unused functions and libraries? All C++ compilers still annoy me to a huge degree when they seem to have 'link time optimization' etc. etc. and individual functions isolated into sections, yet anything that links the standard library has the same large overhead no matter what gets used. Has cheerp itself been compiled to webasm? 
Out of interest, does cheerp support threaded C++ code compilation? If so, how does it support Wasm?
Thanks for this information. i will look into the msvc implementation for size\_t, it might be the reason. Interesting thing from your benchmark is that std::unordered\_map actually performs better for identity hashes (probably because they take no time).
 u/martinus: i ran my case and it seems the case is very specific in the sense that 80% of the lookups are not in the hash table. Inserts only happen at the start, afterwards its only lookups that have only a low hit rate.
You failed to understand what you replied to. 
What do you mean? Like, that non-owning threads can unlock a lock obtained on \`SRWLock\`? &amp;#x200B; Whatever the case, SRWLock seems to be an apple to a \`std::mutex\`'s orange -- read-write locks are a principally a different pattern of synchronizing concurrent code than simple exclusive locks.
I have benchmark results for random lookups when 25% of the lookups are success, that's close to your use case. The numbers are 32bit random numbers though, so not more or less sequential. That's probably the reason why identity hash is the quite fast in this benchmark. I'll add a benchmark later where only the upper 32bit of a 64bit key are random, I guess that many hashmaps will simply time out or overflow when Identity hash is used. Hashmap | FNV1a| Identity| absl::Hash| folly::hasher| robin_hood::hash ---|---|---|---|---|---|--- absl::flat_hash_map| 17.8838| 12.9861| 15.1068| 17.8123| 14.9603 absl::node_hash_map| 22.253| 16.5902| 18.9137| 22.0351| 18.5572 folly::F14NodeMap| 27.097| 22.6691| 24.338| 25.431| 23.9752 folly::F14ValueMap| 26.9593| 22.6288| 24.0245| 24.841| 24.066 robin_hood::unordered_flat_map| 16.6196| 12.8208| 14.3628| 17.2145| 13.7669 robin_hood::unordered_node_map| 18.4745| 14.2956| 16.124| 19.1269| 15.5422 ska::bytell_hash_map| 25.5273| 19.5553| 21.7629| 25.9553| 20.7439 spp::sparse_hash_map| 27.8838| 21.9487| 25.4554| 28.0008| 23.9829 std::unordered_map| 89.9193| 78.5821| 84.5322| 94.8805| 84.2364 tsl::hopscotch_map| 27.9904| 21.2885| 23.1049| 27.2787| 23.9657 tsl::robin_map| 25.74| 19.4226| 21.8307| 26.5169| 21.3234 tsl::sparse_map| 25.9516| 19.8323| 21.8677| 25.8702| 22.156 The numbers that I insert are not sequential though, but 32bit random numbers.
One of the arguments for AAA actually.
Absolutely possible. Care to explain?
SRWLock is the primitive for mutexes on Windows - similar to futex on Linux, but less powerful.
&gt; I found that absl is very sensitive to a good hash, so it is best to use absl's hash whenever possible. If I correctly remember Matt Kulundis introduction of [Abseil's Hash Map](https://www.youtube.com/watch?v=ncHmEUmJZf4), he specifically mentioned that a quality hash was expected. I think the line of reasoning was that good performance in the presence of a naive/bad hash was a myth, so you might as well rely on hashes being good (and fast).
It increases code size.. 
I think his reasoning is correct, and that libstd++ uses identity function as a hash is an extremely bad idea.
Strings are always a tradeoff. You're not just going to have "better strings". It would be very useful to talk about how this string is different than std::string. For one, it's objectively more complicated to use correctly. 
The catcher doesn't know how much space it needs, probably? Consider: class base_ex {}; class derived_ex: public base_ex { char c[alot]; }; void foo() { throw derived_ex; } void bar() { try { foo(); } catch(const base_ex&amp;) { /* how much space do I need?! */ }
We have a dedicated llvm pass that analyses the function call graph of the entire application and drops unused functions. We also have a pass called `PreExecuter` that executes global constructors at compile time and creates global variables with the resulting computed state. This is particularly useful for dropping functions that are used only in global constructors (for example there is a ton of code in the standard library that is used to initialize the globals `cout` and `cin`, that without `PreExecuter` would not be possible to drop with regular dead code elimination). You can see more about it [here](https://github.com/leaningtech/cheerp-meta/wiki/Cheerp-PreExecuter) As for compilation of Cheerp itself to wasm, it is currently not possible (making the entire clang/llvm codebase compile to wasm would be a nontrivial task)
It is also no less obfuscating than auto, so what is the advantage over auto?
Sure, that's the status quo. But we could change the language to allow this: try { foo(); } catch(base_ex &amp;&amp; ) { /* note that &amp;&amp; there. We need sizeof(base_ex) bytes. That's because we don't keep the original thrown exception around, we convert it to the type we catch. */ } I don't know about you, but in most cases I don't care about the type of the exception that was _thrown_, I only care about the type that I _caught_. And that type I know in advance, it's right there in the catch block. Currently catching by rvalue reference is not allowed, which means we could decide to use it for this type of situation. I'm not sure if it would do much for performance, but it would certainly mean the space usage would become entirely predictable. 
std::exception has `virtual const char* what()`.
Very interesting. One thing that wasn't clear though: will this library be providing an expression template engine? Or would that be built on top of these types?
https://github.com/cs01/gdbgui a web-based gdb front-end
No, threaded code is currently not supported since the browser is still a single threaded system at this stage. When wasm will introduce threads we will provide support for them.
Very cool, thanks. What makes compiling clang and llvm to wasm nontrivial?
That's not strictly true- you can achieve threading through the use of web workers, which is a standard from W3C. Emscripten currently supports threads via a flag which compiles to some JavaScript web worker scaffolding along with WebAssembly that's ran in the web worker. It's also worth noting that as of Chrome 70, there's some WebAssembly pthread-like threads that you can try out through an Origin trial. I haven't been keeping up with it recently so I'm not sure what stage it's at, but they seem to be powering ahead with native threading support! Cheerp seems pretty interesting regardless though- and it'll be interesting to see how both Cheerp and WebAssembly evolve in the future :)
 int x; int y; if (foo) { x = 2; f(x); y = 3; } else { x = 42; f(x); x = 1337; } printf("%d\n", y); // Warning: y might not be initialized here. 
Web Workers are actually more similar to multiple processes, than multiple threads, as each leave in a separate address space. Eventually SharedArrayBuffers will allow to actually have multiple execution threads in the same address space and that is a fundamental building block for true Wasm threading.
I'm working on a proposal to add std::string_view support for the &lt;regex&gt; header. The initial draft has been posted here [1]. At the moment I'm updating the proposal based on the feedback I received. [1] https://groups.google.com/a/isocpp.org/forum/?fromgroups#!topic/std-proposals/-GTwXQkwaRs
I look forward to the day when SharedArrayBuffer returns to us all! Spectre / Meltdown has definitely been a huge setback for threading capabilities. That's interesting though, I didn't realise web workers were so separate. Thanks for the info.
\&gt; \`vector&lt;int&gt; v{10, 11}; // ten element array\` The comment explains what the poster thinks should happen, not what does happen.
Any idea how they are working around the Spectre concerns?
Ok, there's a bug in that code. How would you fix it while preserving the uninitialized variable? 
My understanding is that the problem can be ignored as far as all the threads execute code from the same origin. The idea being that you will be able to exploit the bug, but at most you will read information you already have access to.
Also an argument for avoiding default ctors. You don't get this problem with \`lock\_guard\` for instance.
This is way too abstract to comment on it, because it is neither a complete example, nor good code. I'm certain that no matter what would cause you to write this, there would be a much cleaner solution. If this really were self-contained, it would be this: f(foo? 2 : 42); std::cout &lt;&lt; (foo ? 3 : 1337) &lt;&lt; '\n'; // Assuming that this is your bug Look how much more straightforward the code is. The original should have never even passed code-review.
And...? What? What do you expect will happen? We are not going to be calling `what()` on the originally thrown object, we are going to construct a fresh new object deeper down in the stack, and that one is in perfectly fine shape by the time execution gets there. The mechanism is straightforward: 1. Upon throwing, the thrown object is constructed at the top of the stack. 2. The nearest matching catch handler is found. The stack, at that point, has space reserved for the caught type. 3. The _caught_ object is instantiated by move-constructing it from the thrown object. It's a different type! You know what type it is in advance! 4. The stack is unwound, starting with the original thrown object at the top of the stack (which we no longer need), until we get to the catch handler. 5. Execution continues with the catch handler, which has its own, local copy of the exception object. I'm not sure it would do much for performance, but it certainly lets you put a firm fixed upper bound on space usage. 
If you think that's wrong, instead of just "huh", you should link to either the source or instructions to get the source.
http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap03.html &gt; A program whose executable file was produced by compiling with c99 using the flags output by getconf POSIX_V7_THREADS_CFLAGS, and linking with c99 using the flags output by getconf POSIX_V7_THREADS_LDFLAGS and the -l pthread option, or by compiling and linking using a non-standard utility with equivalent flags. Execution of a multi-threaded program initially creates a single-threaded process; the process can create additional threads using pthread_create() or SIGEV_THREAD notifications. I'd never heard of this SIGEV_THREAD thing. Does that let you create a thread without pthread_create showing up? Hrmm.
I think I found the answer: &gt; A program whose executable file was produced by compiling with c99 without using the flags output by getconf POSIX_V7_THREADS_CFLAGS and linking with c99 using neither the flags output by getconf POSIX_V7_THREADS_LDFLAGS nor the -l pthread option, or by compiling and linking using a non-standard utility with equivalent flags. Execution of a single-threaded program creates a single-threaded process; if the process attempts to create additional threads using pthread_create() or SIGEV_THREAD notifications, the behavior is undefined. If the process uses dlopen() to load a multi-threaded library, the behavior is undefined. 
I'm not sure how other browsers are planning to tackle it (assuming you're referring to browser-level mitigations) but chrome has a feature called site isolation so that the browser renderer only handles one site at a time. You can read a bit about it here: https://security.googleblog.com/2018/07/mitigating-spectre-with-site-isolation.html?m=1 Other than that, I'm not sure what else is in the works to mitigate it, but chrome re-enabled SharedArrayBuffer in chrome 68 when this "site isolation" feature was released.
POSIX seems to mandate the check being correct: https://www.reddit.com/r/cpp/comments/aq6v21/shared_ptrt_the_not_always_atomic_reference/egtx9ew/ 
Creating threads via clone(2) involves neither `pthread_create` nor `sigev_thread`. 
This benchmark is very helpful. Can you also provide a comparison against sorted std::vector&lt;pair&lt;A,B&gt;&gt; with look up using std::lower_bound. I played around with your and tessil’s map and found a sorted vector approach is significantly faster for my project.
So, in terms of the original conversation, `SRWLink` is analagous to `std::shared_mutex`, NOT `std::mutex`. It may be true that `std::mutex` is implemented in terms of `SRWLock` (there have been [benchmarks](https://github.com/rust-lang/rust/blob/2a663555ddf36f6b041445894a8c175cd1bc718c/src/libstd/sys/windows/mutex.rs#L7) by the Rust community, for instance, demonstrating that `SRWLock` was in general faster for implementing its `std::sync::Mutex` structure), but the **cross-platform guarantees** provided by C++'s `std::mutex` DO state that calling `std::mutex::unlock()` on a non-owning thread is undefined behavior, period. It's good to know what the actual behavior might be on Windows, but by definition, you shouldn't depend on undefined behavior!
That's funny because I had to investigate a 'deep' bug in a Makefile system and many years later now I use cmake and I totally prefer Makefiles: much less magic, so much more debuggable. That said, I still don't understand why all these systems haven't been replaced by a Lisp tool, at least you'd have a proper language and a good debugger (and no I don't especially like Lisp but it seems to ne the 'right' tool here) 
Thanks, that makes sense!
&gt; clone, __clone2 - create a child process Clone creates a new process, not a simple thread in the same process. Therefor it doesn't seem very relevant in the context of the current conversation.. right?
What is this trying to imply?
&gt; My main objection to the above is the people giving the talks are not qualified. Kate Gregory is qualified.
good. i don't want some half-assed webassembly advert being able to use all my cores
&gt;&gt; With a normal mutex we would be fine, ... it doesn’t matter if we unlock it on a thread other than the one we locked it from. &gt; Really? In most (all?) mutex implementations unlocking from a non-owner thread is either an error or an undefined behavior. After such mistake, it's hard to view the rest of this writeup seriously. This was the thing I was annoyed about - mutexes generally are able to be unlocked from a different thread. This person did not say `std::mutex`, and Sean wasn't talking about `std::mutex`, and therefore this person is just incorrect.
&gt; It's a separate field. Ah yes, and so are ethics and computer science. And still, it's important to keep the former in mind when considering and doing work in the latter. This is why people coming from a broad range of backgrounds working in tech is important, and for us to consider the "human" side of things too. &gt;they do not add value to developers' lives Please don't speak for me.
&gt; E.g. when I have a data structure MyTree that for whatever reason can't (yet) be constructed from a std::initilizer_list, I don't want my users to be able to do MyTree&lt;int&gt; tree{1,2}; and (rightly) expect this to create a tree with two elements. You can try do something like this: template &lt;typename T&gt; S(std::initializer_list&lt;T&gt;) = delete;
For small sizes, yes the sorted vector is likely faster. For lookup, not necessarily for insertion. This also depends on the object sizes.
Why don't you tell us what you don't find sufficient about gdb/ddd and then we can help you figure out what options there may be.
1. This isn't the place for this (there are programming questions subreddits, this one is for articles conf etc) 2. Look at boost::asio for the network stack. Your brain will trying to get anything done but this is normal with boost 3. You probably want to serialize your data structures in which you may want to use a library such as protobuff that will handle all the annoying things for you
The fact that marking something as *not* throwing an exception prevents it from being trivial is silly, though.
No, the compiler settings do. `Foo` also doesn't specify which C++ standard to compile under, or architecture, endianness, padding, etc. GCC has C++ flags for which ABI version to use, as well as a minimum ABI target.
Readability without having to rely on an IDE sophisticated enough to figure out what the 'auto' actually is
&gt; That read an awful lot like a commercial for this compiler. That's completely okay in my opinion. I find it is clearly market as such, the title reads like a 2.0 product announcement very much. The third sentence of the blog post reads "Cheerp is an open-source, commercial C/C++ compiler" (it's unclear to me what _"open-source, commercial"_ means but at least I know right from the start and can read more about it if I want to know). And well, I find it a really interesting blog post, also from a technical perspective. And it's a highly relevant topic and it's really good to know what's possible in the C++/WASM landscape currently! Both in terms of commercial and non-commercial solutions!
Doesn't it only check them? It doesn't actually format them.
Use ZeroMQ
To get started with basic socket communication, you could have a look at the examples of my C++ socket library: https://github.com/bernhardHartleb/simple-socket It also supports Unix sockets (datagram or stream). For data exchange with a web app, consider JSON.
Monodevelop was always what I used.
Good to know these static warning stuff, thx!
Holy cow, that's awesome for debugging remote applications!
You are being down voted because your post exposes a deep wound: on Unix C++ relies completely on the C library to exist. In fact most of the C++ libraries are just thin wrappers.
This is off-topic. [As previously mentioned](https://www.reddit.com/r/cpp/comments/aqvn96/why_are_you_programming_in_c_instead_of_c_java/egm5x3o/), please don't post troll bait. Specifically, #1 and #2 are off-topic (questions about Rust). #3 is a negative leading question, although in theory it could prompt interesting discussion. #4 is off-topic, as it is a question about managed languages (merely comparing things to C++ doesn't make them on-topic).
Eeh, I'd go with boost::asio or the old timey C APIs (Man socket.) Neither are all that terrible. It's harder to construct an iostream from an old timey int filehandle though. I don't think there's a portable way to do it. So boost::asio might be better from a frustration standpoint.
[[deprecate]] is interesting lol
That's a pretty smart abuse of the compiler.
&gt;AAA That would be just trading one set of bugs for a bigger set of bugs. With some exceptions I'd be willing to admit, I hold that all of this modern trend of being less explicit is just asking for trouble. We've spent decades trying to get away from loosely typed languages for a very specific reason, and now people are trying to make C++ a loosely typed language. Not to mention of course never use OO because that's horrible. And God forbid use an actual index in a loop. If you use auto, you only have to make one mistake, which can easily not be caught by the compiler if the thing you happen to assign to the auto typed variable happens to have a viable syntax, which is not at all that difficult, particularly with the other modern trend of doing so much stuff with operators instead of named methods. If you indicate the type, you more likely have to make two mistakes, since one mistake will get caught because the types are not convertable. &amp;#x200B;
With auto the right thing will only happen if you do the right thing. If you assign the wrong thing to the auto variable, and the thing you assign happens to implement a viable interface (not that unlikely with all the operator based stuff people use these days), then now you have something that doesn't cause an error but doesn't work either. Using an expilcit type requires you make two mistakes to screw up, most of the time anyway. And, the bulk of the time, if you change the type, the compiler will find every place for you and you can make sure you are doing the right thing. With auto, you will have to find them all yourself, and we know how good humans are at that. &amp;#x200B;
The thing that I don't get is, somehow we managed to write probably a few billion lines of code before auto or uniform initialization was introduced. I don't remember considering it remotely a nightmare. It's pretty straightforward in actual fact, one of the least worrisome things when writing large amounts of code, IMO. &amp;#x200B;
The conversion operator is not explicit – stop using `auto` where you name the type anyway and you won't need a cast: Foo&amp; foo = foo_vec[0];
That looks better now, but pre-`auto` having to name the type twice wasn't something anyone wanted.
Unless you're doing this project as a way to learn C++, I'd strongly recommend doing it in another, much simpler language such as Python.
I'm doing it to learn, plus I subjectively hate Python and Java. Their formats don't challenge me to think. 
Well so it template metaprogramming :)
Even the [Handy Guide to Handling Handles](https://www.codeproject.com/Articles/1044/A-Handy-Guide-To-Handling-Handles) doesn’t cover creating an iostream from a C library handle. Must be damn near impossible!
&gt; C++ a loosely typed language Type inference doesn’t negate being strongly typed. Haskell avoids explicit variable annotation, and isn’t loosely typed because of it. Ideally using AAA goes hand in hand with stronger types. bool Connect(Host, Port, UseSSL); Is a lot harder to call incorrectly if Host, Port, and UseSSL are all distinct types. 
You can take a quick peek at my basic [socket-based client-server library](https://github.com/JamesBoer/Scs) for some sample code if you like.
Metaprogramming uses the spec as intended. In this case, you are relying on compiler-specific error/warning messages.
I would make a distinction between strong vs. weak typing and explicit types vs. type inference. `auto` will infer types, but it doesn't allow any extra conversions.
That would require different benchmarks. Insertion is incredibly slow with the flat maps. Here are some flat map comparisons that should be very similar to what you describe: https://stackoverflow.com/questions/21166675/boostflat-map-and-its-performance-compared-to-map-and-unordered-map
another tip: in clang compiler errors are generally much more informative than in gcc (though there have been improvements in recent versions of gcc)
Sure, my comment was partly tongue in cheek. At the same time, much of template metaprogramming is a hack. When templates were added to C++, it wasn't intended for TMP. It's a useful hack, though, but a lot of the work in the past few years has been about making compile time programming easier (constexpr). 
It negates being strongly typed in the places you use it such that you don't explicitly indicate the expected type, i.e. where mistakenly setting it to something else doesn't cause an error.
A shame you could not wonder and keep reading: &gt; The main use of clone() is to implement threads: multiple threads of control in a program that run concurrently in a shared memory space. 
Thanks for the explanation. Imho it is a horrible idea though.
Didn't think of that. Thanks!
Now you need an IDE sophisticated enough to find out what the alias stands for. How is that any better?
For good iteration performance with reasonably good insert/remove/lookup performance, [`tsl::sparse_map`](https://github.com/Tessil/sparse-map)is excellent. About 3-4 x faster than absl's flat or node hashmap. Here is my iteration benchmark result: hashmap | FNV1a | Identity | absl::Hash | folly::hasher | robin_hood::hash ---|---|---|---|---|--- absl::flat_hash_map | 12.163 | 11.753 | 12.173 | 11.835 | 12.001 absl::node_hash_map | 12.467 | 12.264 | 12.382 | 12.211 | 12.350 folly::F14NodeMap | 16.218 | 16.175 | 16.217 | 16.065 | 16.106 folly::F14ValueMap | 15.502 | 15.788 | 15.801 | 15.934 | 15.510 robin_hood::unordered_flat_map | 9.057 | 8.980 | 8.993 | 9.011 | 8.978 robin_hood::unordered_node_map | 10.178 | 10.240 | 10.175 | 10.210 | 10.236 ska::bytell_hash_map | 22.591 | 22.553 | 21.271 | 22.842 | 22.970 spp::sparse_hash_map | 5.336 | 5.256 | 4.356 | 5.209 | 4.289 std::unordered_map | 22.202 | 22.438 | 22.474 | 22.715 | 22.208 tsl::hopscotch_map | 17.441 | 17.032 | 17.471 | 18.263 | 17.677 tsl::robin_map | 28.753 | 28.973 | 28.877 | 28.158 | 27.988 tsl::sparse_map | 3.353 | 3.311 | 3.268 | 3.391 | 3.251 
CMake makes your library users happier :)
...yes that’s my point 
I wouldn’t classify `auto` as type inference. It uses template deduction rules. 
Thanks for this. How large was a single pair in your benchmarks? I have a very specific where blindly replacing STL maps and sets with `absl::flat_hash_{map,set}` yielded considerable lower performance, but using `absl::flat_hash_map` and `std::unordered_set` or `std::set` was significantly faster. More details [here](https://old.reddit.com/r/cpp/comments/aha5nn/is_c_fast/eee8gwx/?context=3)
Calling a virtual function at compile time requires that the compiler knows the type of "this" if it can deduce it, then there is a more explicit way to do the same thing without using virtual functions (by using variants or templates). 
One thing you are omitting is that gsl::span places high priority on range checking. Even iterator dereference is checked. That results in a lot of code and probably also compile time overhead. I'm not claiming that it's necessarily the right thing to do for a supposed vocabulary type, but you are somewhat comparing apples and oranges here.
C++20 already allows using virtual functions in constexpr expressions. 
Potentially, or you could use an alias more informative than 'GetSomethingResult'
Is there a tweet for using whitespace generously? :) auto rootMenu = make\_unique&lt; Menu &gt;( "cli" ); rootMenu -&gt; Add( "hello", \[\](std::ostream&amp; out){ out &lt;&lt; "Hello, world\\n"; }, "Print hello world" );
I thought the whole Idea of that particular alias was to be able to switch the return type of a function just as easily as if you would use auto. If you start encoding any more information than just the function name, you are starting to loose that ability.
The paper https://wg21.link/P1064
What version of llvm/clang is this based on? What c++ standard library is used. Are you generating cmake toolchain files or how is one actually using your toolchain?
You can't move a derived class into a base class without a loss of information called object slicing. I am reading what you're writing and I am thinking that you "know" stuff but do not understand it.
C library doesn't do sockets. Operating system libraries do that. **All** languages use that. It's pretty amazing how many misconceptions you crammed in one sentence.
Strongly typed isn’t the terminology you’re looking for then, type deduction doesn’t effect strong / weak typing.
What’s the distinction between auto and type inference? Just that auto is a subset, given that it’s deduction (with all those caveats).
I was actually a bit worried about this potential gamedev slant, but then I think the paper mostly gets it right. IMO it's much more important to involve both the broader linear algebra community (including Eigen &amp; Blaze developers!), as well as the machine learning community.
Pretty much. It goes back to the non uniformity of decltype. Again, this is just my opinion. There’s no one true definition you can point to. 
I'm using only a map&lt;int, int&gt; for this benchmark, so your use case is quite different. 
You are reading what you want to read, which is not what I wrote. I'll try one more time, and then I'll stop. Here goes: So we throw an object of one type, and it has a bunch of information in it. And we catch an object of another type, which has a different bunch of information. How can we do this? We need a function that converts from the first type to the second type. We are not slicing the original object, we are constructing a new object instead, from information in the original object. 
Alright. I wasn't expecting a use case as complex as mine, I was just wondering how complex your use case was. Thanks for the reply anyway.
My go-to solution for this problem is nanomsg (the Golang implementation is called Mangos). It's very easy to use and and is better optimized than ZeroMQ. The advantage is that you can easily switch between IPC and TCP (among other protocols) if at some point you want to run your programs on separate computers.
Try out WebEngineView instead. IIRC, WebView uses WebKit, while WebEngine uses the Chromium renderer, just like Electron does.
in what way is it better optimised than ZeroMQ. We use ZeroMQ quite a bit
Thank you good to know. I guess I will have to wait a few years then... :-P
Fwiw, I wrote a crude new benchmark that measures how many reads and writes can be performed in a given amount of time. My algorithm vs std::shared\_mutex. So, we are \_primarily\_ looking for how many reads can be performed in this test at 60 seconds. The number of threads is variable and is determined by std::hardware\_concurrency \* THREADS, set at 8 in the test. This is the latest version 0.1. It will say the version number in the output. Here is the code: &amp;#x200B; [https://pastebin.com/raw/1QtPCGhV](https://pastebin.com/raw/1QtPCGhV) (hit refresh if you don't see version 0.1) &amp;#x200B; I am getting timings like: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ cpu\_threads\_n = 4 threads\_n = 32 writers = 16 readers = 16 test duration = 60 seconds \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ &amp;#x200B; Testing Version 0.1: Chris M. Thomasson's Experimental Read/Write Mutex \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ Raw Reads: 54195 Raw Writes: 3232 reads\_per\_tick = 902 writes\_per\_tick = 53 Ticks = 60.0432 \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ Testing Version 0.1: std::shared\_mutex \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ Raw Reads: 23452 Raw Writes: 1873 reads\_per\_tick = 390 writes\_per\_tick = 31 Ticks = 60.0513 \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ &amp;#x200B; My algorithm is beating std::shared\_mutex on my end by performing more reads that std::shared\_mutex. I am wondering if you can run the benchmark and show me what you get? &amp;#x200B;
Of course. I'll see to it right away :-) No, seriously, this library started many years ago. In the beginning, it was very different (e.g., C++98), and unfortunately includes multiple styles (e.g., spacing are not consistent). I plan to fix the spacing differences over time (e.g., removing unnecessary spaces at the beginning and end of parameter lists), because -- unlike CameCase -- it doesn't break API compatibility. BTW: the style with so many spaces is borrowed from the so-called "publishing style": sometimes, in papers and articles you use more spaces to improve readability.
Yeah, I agree; one of the things I liked in the youtube presentation was his statement that this library is made for “90% of the developers,” meaning it’s not targeting any specific industry or esoteric use case, but meant for the majority of development use. I feel this is the kind of sentiment used for a lot of things in high quality C++ nowadays, which is really great in my opinion.
WebView is deprecated in favor of WebEngineView. WebEngine and Electron both use Chromium internally, so I don't expect the performance to be much different. Since it's coming from Qt itself I expect that WebEngineView will integrate in the existing Qt code better than Electron
Ah, I didn’t know the paper number, thanks. I’m a bit bummed that it’s scheduled for C++23, it’s something I kind of wish we had in C++17 today.
If you're already using Qt, stay away from electron.
Mostly the interaction with the underlying OS. Invoking a compiler actually involves looking over the filesystem for headers and libraries and spawning multiple processes to compile all the sources and link them in the final executable. These OS-level primitives do not have a natural mapping in the Web platform, although they can be emulated. This does not mean that compiling clang/LLVM to wasm is impossible, but it will take some work.
Cheerp is based on LLVM/clang 3.7.0, we plan to progressively modernize our codebase over the course of 2019. The c++ library is libcxx. Cheerp accepts standard gcc-like command line options so it can be easily integrated in any build environment. We also provide a ready-made cmake toolchain file, see here for more info: [https://github.com/leaningtech/cheerp-meta/wiki/Getting-Started#using-cmake](https://github.com/leaningtech/cheerp-meta/wiki/Getting-Started#using-cmake)
If you have MSVC , then go to `VC/Tools/MSVC/$version/include/memory` file (or `VC/include/memory` before 2017). If you don't, you can get a copy via NuGet, for example: https://www.nuget.org/packages?q=VisualCppTools. Runtime support routines can be found in `VC/Tools/MSVC/$version/crt/src`.
So boost asio directly makes a syscall??? Jesus Here, educate yourself https://www.gnu.org/software/libc/manual/html_node/Sockets.html Still, the linux Kernel and every other kernel out there are written in C. Do you even code? 
Here, educate yourself https://www.amazon.com/dp/1729850677
the compiler itself is open source, but I believe they provide support services subscritions.
**Company:** [OxFORD Asset Management](https://www.oxam.com/careers/) **Type:** Full time **Description:** We are an investment manager based in central Oxford, UK. We are seeking outstanding software engineers to develop and maintain system-critical software. You will be responsible for all aspects of software development on a diverse range of projects, such as automating trading strategies, integrating third party data into our system and the development of data analysis tools. You will work as part of a highly skilled and motivated team who care deeply about software quality, efficiency and robustness. A background within finance is not necessary for this role. The ideal candidate will have several years of experience of commercial C++, a thorough understanding of the STL and be comfortable with good software engineering practices such as unit testing and code review. We also welcome enthusiastic graduates and postgraduates in mathematics, statistics, computer science and the natural sciences with experience in C++. **Location:** Oxford, UK. Central offices located close to local amenities, parks, restaurants, shops and bars. **Remote:** We do not offer remote working. **Visa Sponsorship:** Yes **Technologies:** C++17 on Linux. Python used for internal scripting and research. **Contact:** [recruitment@oxam.com](mailto:recruitment@oxam.com)
Truth hurts. I can't help you ignore reality.
We found that QWebEngine has much worse memory performance than CEF. So we load CEF directly. There are open source QT wrappers for CEF as well.
[Cheerp is open-source software and is free to use **for GPLv2 projects**. Non-copyleft commercial licenses, commercial support and consulting packages are available from Leaning Technologies.](https://github.com/leaningtech/cheerp-meta)
What are you doing with the web content? Might be that you need to disable some unused features in QWebEngine
Do you think you’re right and the standard library is wrong? 
&gt; So boost asio directly makes a syscall syscall != system library. &gt;Here, educate yourself &gt;This chapter describes the *GNU* facilities for interprocess communication using sockets. &gt; *sys*/socket.h 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/asoe1y/cant_decide_on_a_book_to_buy/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
We're rending some content, running g some js etc... Nothing too heavy. We did side by side tests that showed CEF quite a bit less resource hungry. I don't have the exact data at hand anymore.
WebView is not deprecated and works on mobile platforms unlike the WebEngineView. 
&gt; Your brain will hurt trying to get anything done asio's TCP streams aren't much different from Hello world
Sounds good, but it would be even better, if it was possible to use c++17. Not sure how invasive your changes to llvm are, but I think it would be great if they somehow could regularly be rebased onto the latest llvm.
https://www.webtoolkit.eu/wt
Needs a Napoleon hat to make it more glorious. 
boost::asio + Unix Domain Socket. platform abstraction + tcp-like Look&amp;Fill.
How do folks call that "system library" my friend?
This question is about trying to show web content in a native app, not trying to build a webapp.
Any tldr?
nanomsg also supports IPC on windows, while zmq does not.
The sad truth is just that in hinsight the goal of a uniform intialization syntax seems reachable and the whole concept was very sound until std::initializer\_list came into play... &amp;#x200B; Now we have to find additional explanations/ make them more complicated than what was originally intended.
 You don't understand how programming languages or how operating systems work. I mean, you **know** stuff, but your **understanding** is piss poor. Good luck with that. 
IRC, you are confusing WebView with Qt WebKit. WebView just uses system-provided web view/browser (relevant for mobile), if available.
You can't constructing that new object because you have no space for it, you only have space for a base class. I am starting to think you have 0 understanding of computer memory.
I'm real happy to learn the `[[deprecated]]` trick. I've used the `print_types` metafunction before but it's not useful if the compiler error is triggered before the case you're interested in is reached. 
The abstract for the talk is the following: &gt; Today asynchronous programming is in great demand, &gt; especially after it has become a huge success in the Node.js ecosystem. &gt; &gt; The standards class in C++ for asynchronous results std::future, &gt; provides a basic, but non zero cost, abstraction which also misses useful features. &gt; &gt; In this talk, I will present my continuable library which implements &gt; futures in a different, but more allocation friendly and improved way. &gt; &gt; Together we will go through the features of the continuable library, &gt; and how you could make use of it, to improve your codebase today. &gt; This includes chaining continuations through `then`, &gt; asynchronous exception handling and making use of the coroutines TS. &gt; &gt; Further my goal is to also show you the tricks and interesting meta-programming techniques &gt; used in the implementation of the library, which makes it possible to &gt; stay allocation aware while being feature rich.
I'm the speaker and would be glad to answer your questions to the talk right here. Repository: https://github.com/Naios/continuable Slides: https://meetingcpp.com/mcpp/slides/2018/Continuable.pdf
&gt; Not seeing all of windows.h in intellisense anymore. Literally just uncheck all the windows junk in VS...
Not sure I agree with you. Imho, you can't make it more uniform than it is at the moment: 1) Historically, we already had two syntaxes: `{}` for datastructures inherited from c and `()` for objects with constructors and I think there is a legit interest in being able to initialize a pair the same way as a struct with two elements or in general being able to "promote" a simple pod to a datastructure with a constructor without having to change all callsites. So making the `Foo f{...}` syntax available to types with constructors was imho a correct decision. 2) On the other hand, you need a way to distringuish between the creation of a `vector&lt;int&gt;` of size 10 and a `vector&lt;int&gt;` that is initialized with a single element of value 10. So those two usecases need a different syntax in one form or the other. 3) Although it often seems annoying, it makes actually a lot of sense that you don't have to instantiate a separate constructor each time you are creating a `std::vector&lt;int&gt;` with a different number of initial elements. As a result, we either need a "magic" type `std::initializer_list`, or a completely new syntax for declaring constructors to achieve the same thing. Think about it for a moment: How would you write a constructor for a deque&lt;int&gt; that can take an arbitrary number of ints without something like a std::initializer_list? Not saying the system can't be improved or that some details should have worked differently from the beginning, but overall I don't think there was a much better solution - or do you see one? 
This is a really great talk for people who want to start using templates But in generall just a delight to watch!
Everything is great with gdb, it is just that I am looking for a GUI alternative and DDD isn't that great.
As someone else stated, $89 if you're buying it yourself and the price goes down every year (and the $89 is for a perpetual license -- you can keep using it forever, just can't get upgrades after 1 year). Every person may vary, but I find it to be very, very good and worth the price to me, and I don't even use the debugger.
Uncheck what, where? Is there an option somewhere that stops windows.h from filling up intellisense? 
&gt; this modern trend of being less explicit AAA doesn't force you to be less explicit. You can still write the expected types if you want to, you just don't _have_ to if you think it's obvious.
Very nice. Also includes information on git, make, cmake, perf, valgrind, etc.
what parts of ddd don't you like? (seeing a pattern here?)
That's true. But I don't HAVE to use asserts or checks or write comments or do or not do any number of things if I think it's obvious. The problem is, with humans, it's usually not nearly as obvious as it seems. And to the 2nd, 3rd, and so on person who has to maintain it, it gets progressively less so. The purpose of explicit expression of semantics and intent is not for when you write it, it's for three years later when some obscure problem shows up in the field and someone needs to give into that code and find the problem as quickly as possible. 
I actually agree with point 1 and 2 completely. Where the whole thing went wrong is the precedence of the std::initializer_list constructor. C++ is already more than complicated enough since nearly every single piece of the language has some kind of exception to it. Do it way X unless you run into case Y then you have to do Z or potentially XZY if you care about performance on top. std::initializer_list is exactly this. That it takes precedence complicates everything further and my (not that thought trough) solution would be that it's materialized only by an extra pair of brackets. std::vector a{10,5}; //has 10 elements with value 5 std::vector b{{10,5}}; //two elements 10 and 5 std::map&lt;int, int&gt; {{{10,5}, {12,5}}}; To make it worse std::initializer_list can generate unnecessary copies and can't handle move only types types like unique_ptr (since it's not moveable) . And due to ABI(!) concerns it will probably never be fixed (if I followed that discussion correctly)... For me that is reason enough to call it unicorn instead of uniform intialization.
QtCreator is amazing. It's like Visual Studio with its features and relative ease of use.
Youtube has an "unlisted" option where it's still publicly viewable if you have the link, but doesn't show up anywhere else. I'm not sure what they fixed with the new version, but it is available here. https://www.youtube.com/watch?v=SzoquBerhUc 
rr absolutely does work with multithreaded applications. It has been used to debug many multithreaded races in Firefox and other applications. That wiki text is misleading so I've fixed it. rr doesn't use multiple \*cores\* but that's not necessary to reproduce and debug most thread-related bugs, especially if you record with rr's "chaos mode".
Try a few thousand runs of your application under rr ([https://rr-project.org](https://rr-project.org)) using chaos mode (\`rr record --chaos\`), deleting the trace directory after each successful run. If you catch the bug under rr then debugging it under rr will be pretty easy.
&gt; If you don't, you can get a copy via NuGet, for example: https://www.nuget.org/packages?q=VisualCppTools. "*last updated 8/24/2017*" ;-[
I disagree here. You can develop with standard c++, cmake and qt creator without ever using any qt in your code or being reminded/forced to do so.
Likely sooner. Nowadays new features can get implemented fairly fast. A GCC patch was being worked on last Fall. &amp;#x200B; &amp;#x200B;
Thank you
Thank you
&gt; all of this modern trend of being less explicit Yeah, I admittedly feel this less explicit is kind of killing C++. One of the kind of big interesting points of C++ is how verbose and explicit it is, you have to ``typename`` and ``::value`` and ``std::`` to get what you want, no room for ambiguities whatsoever and the code becomes a beautiful flow of various kinds of prose, kind of like an epic. But as of late? Your example of ``` void ComplexOperation() { auto; } ``` is admittedly something I fear we are going to end up seeing (it's incomplete tho: the return type should also be ``auto``). 
"static dispatch" is the term you're looking for, I believe.
did you think they were going to patch the existing language?
Definitely hitting this one up.
Congratulations, and best of luck to your group!! :-)
Wow, impressive slides. Good to see the next generation learning modern cpp in such a manner.
Nice examples of interval math and computation.
You could use std::type_info or std::type_index (depending of your requirements for the map) for the key, and using typeid to obtain that from a type.
I think you can also use EMSCRIPTEN_KEEPALIVE so you don't have to specify it on the command line. It is just an alias for `__attribute__((used))` in emscripten.h
Hm..I tried EMSCRIPTEN_KEEPALIVE, but for some reason it didn't seem to work for the c++ example. It's very possible that I did something wrong though.
Maybe `cwrap` requires it.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
1. If you're taking on a game project as a single person then you need all the help you can get, and that means using an existing game engine. Unless what you want to do is develop and sell a game engine (it would become the focus and not the game). 2. Any programming framework takes time to learn and master. An existing game engine would abstract the graphics engine. 3. C++ is a great language, but you have to find the subset that works for you. There is no reason to use every available feature. 4. Unity would not be as widely used today if performance was an issue. Don't compare these engines on performance only, but also portability, the genre of the game and any other requirements you have.
Awesome news.
oh my I need to test that one as soon as possible!
If you’re interested in 3D graphics, you should be more concerned with learning the fundamentals of linear algebra and the n building up to the fundamentals of 3D graphics and then building up from there. It’s an almost separate domain from many other general purpose client programming domains. Then you have the split between real time and offline graphics rendering, and understanding art pipelines. My point is: there’s general purpose programming, there’s graphics programming, and there’s game engines which encompass the two. 
This is great and all, but... what are realistic scenarios for needing to parse GBs of JSON? All I can think of is a badly designed REST service.
&gt; parsing of JSON per se Per se? 
So how does it compare against [https://github.com/nlohmann/json](https://github.com/nlohmann/json) for example? I see that you have to semi-manually allocate and free memory. Also, traversing the tree seems quite obnoxious in comparison. This is clearly a library for people who care mostly about speed from what I can tell.
I guess nlohmann/json is much slower...
This doesn't really answer your questions, I don't have expertise on the subject and don't mean to claim it, and it's not supposed to but it will sound discouraging, but… if you want to make and successfully sell a video-game as a one-man team, programming is probably one the least of your worries, since lion's share of work here is covered by using an engine. You have to make at least some of the assets somehow, make an actual game that is fun to play, and market the product since you plan to make money off it, and you need some experience in each field to get good results.
I'm really not a fan of the idea with the extra braces, because - apart from the ugliness- then you have a different syntax for arrays and simple struct-like types on the one hand and containers on the other and you effectively introduce a 3rd initializationsyntax- that doesn't make teaching c++ any easier either. I also don't see, why it is a problem that that constructor takes precedence. It would be much more suprising to me if the constructors for `std::vector&lt;int&gt;{1}`, `std::vector&lt;int&gt;{1,2}`, `std::vector&lt;int&gt;{1,2,3}` and `std::vector&lt;int&gt;{1,2,3,4}` would behave differently, whereas the syntactic differences `std::vector&lt;int&gt;{1}` and `std::vector&lt;int&gt;(1)` use a different syntax and hence I'm ok with them behaving differently. That you can't move elements out of an initializer_list is indeed annoying. The advantage is that the elements can be put into read-only memory (not sure how useful that is in practice though).
https://www.khronos.org/gltf/
The compiler won't care, but readers will. Ideally the ordering in the header won't be arbitrary, but will reflect something about the code. It may be ordered in sequence of the expected use cases, or even just into public, protected and private sections. If the ordering in the header communicates something that helps the reader understand the code, then it stands to reason that the order in the implementation should be the same to provide the same benefit to the reader there. If the ordering is random, then at the very least it becomes easier to navigate the implementation if they match.
Easy to test yourself that order does not matter. "Does the order of function HAVE to be the same"
How does this compare to kewb-see by Bob Stegall? Here is his [CppCon 2018 talk](https://youtu.be/5FQ87-Ecb-A).
I had in mind other people who will read my code
Is the bulk of the data in glTF stored as JSON?
i see. order is a plus, but how much of a plus is debatable. 99.9% of the time i wouldn't care about it (editors have search functions). i think this boils down to whether you want to contribute your own meticulousness to the world. the world will accept your code in any order, because this function order is nowhere promoted as good practice and a reasonable man would not complain about wrong order (programmers are hardened folks).
I think you're still missing the point. You can still explicitly name the type you're expecting with an auto declaration. If you choose not to do that when you should it's a problem with (of lack of a) code review process. 
It also means that in a time slice of 2 ms you can spend less time parsing json and more time doing useful stuff
Textures are referenced externally by name, and those will always dwarf everything else, but vertex and other scene data can get plenty big on its own.
&gt; That you can't move elements out of an initializer_list is indeed annoying. The advantage is that the elements can be put into read-only memory (not sure how useful that is in practice though). This should be transitive from the value-category of the initializer_list; what you said should hold true if it's `constexpr` or similar, but if it's an rvalue it should be possible to move from.
Yeah, if the file is short enough to vgrep, there probably isn't that many things to order in the first place, and id not, you'll just use a search or jump to definition/declaration in an IDE. 
I think you have slightly missunderstood what I meant. What I meant is the following: assert( std::vector&lt;int&gt;{1} == std::vector&lt;int&gt;(1)); assert( std::vector&lt;int&gt;{5, 10} == std::vector&lt;int&gt;(5, 10)); std::vector{1,2,3}; //fails to compile similar to std::vector(1,2,3) std::vector{{1,2,3}}; //ok uses std::initializer\_list constructor With this it would be easy to teach that you can always use {} for constructors. That would be true uniform initialization for me. Now we have to say (as you suggested)- use this when that and that when this. Oh and be aware that {} does have a different meaning when there is a constructor taking std::initializer\_list. As if C++ intitialization rules would not be complicated enough... &amp;#x200B;
Bold claims... I'll check it out
Log files are often just giant dumps of json objects. The rate of accumulation on these can be measured in gigabytes per day.
Nlohmann/json is optimised for usability, parsing and producing json requests or config files, that sort of thing. It’s not built for super high throughput, which is sometimes what you need.
Very cool. Are there some validations that could be removed if you're confident that your data will be valid for even more speed?
the online advertising industry involves hundreds of thousands of json messages per second
doesn't the order in the header influence the function's position in an export table? quite important for loading by ordinal 
Yo can read this to learn about all the differences [https://nanomsg.org/documentation-zeromq.html](https://nanomsg.org/documentation-zeromq.html)
!removehelop
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/at0c40/does_the_order_of_your_functions_has_to_be_the/egxze8y/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The performance seems to be stellar, however the C++ side of things could be greatly improved. Just by skimming the library: * Everything is defined in the global namespace; * There is a weird mix of C++03 and C++11 usage (e.g. `NULL` and move semantics) * Manual memory management everywhere (`new`/`delete` instead of `unique_ptr`) * Useless checks (e.g. ` if(ret_address != NULL) delete[] ret_address;` And more... If this gets cleaned up and gets a nice API it could be a hit!
`^ This question is ill formed. [-Wspellcheck]`
saving this for later… but just looking at the interface, it feels closer to a C-like than a C++. sure, nlohmann/json is slow compared to a lot of parsers, but it's really easy to use and it's interface is very usuable. Usually you have to choose to optimise for speed or usability. I think it wouldn't be too difficult to have a very light wrapper over the top of this to have a slightly more intuitive interface, whilst still keeping the majority of the performance.
I've worked on several bank projects that stored large dumps of market data, or results from calculations, for example, in large XML or JSON files. At least for testing purposes these need to be parsed and compared efficiently - just simply because there is so much of it the batch needs to complete in a reasonable time frame. I've written something similar (not public) for that reason - nothing else I found could do it.
per second?
how can optional&lt;T&gt; be unconditionally trivially_relocatable ? if the optional is engaged it should be at best as trivially_relocatable as T no ?
Actually animations and meshes can be put in external binary blobs too. Also there is a glb format for a reason too :P
Indeed. And inversely for std::any
Ah, that's good. TIL about that and glb!
Research extensively data oriented design, in particular using Entity System implementations, and design choices. I think a well designed entity system should be at the core of any up and comming game engine. A really good model, though one that doesn't get as much credit due to it's poor support is Qt 3D, take a deep dive into Qt 3D Entity system. In reality Qt3D is just an aspect (or system) of an entity system. Qt's entity system was not publicized as an entity system, and they chose to primarily focus on qt3d specifically, but the entity system used to support Qt3D is one of the best designs I've seen. It's totally overkill, but it's worth taking notes on.
These are complete show-stoppers.
It doesn’t really bother me. What I grapple with is how to order class member variables, whether to pack them to minimise padding or group them logically.
Entity-Component system was something that I was also going to include in the list. I have also seen, that google is actively developing an open source PBR engine called Filament. It also relies on a ECS and even if it might be overwhelming for a newbie (supports Android, iOS, Linux, macOS, Windows, and WebGL), the principles behind seem interesting and the architecture of the project is superb. For Reference I leave here two links: \- [QT3D and how ECS was implemented](https://www.kdab.com/overview-qt3d-2-0-part-1/) \- [Filament PBR engine by Google](https://github.com/google/filament) 
No I was surprised that they were going to do it.
i think it could matter if you define template specializations in different orders
In the footnotes the OP says that any can store an object inside itself (small buffer optimization), and thus cannot be trivially relocatable (we cannot know if the stored object is trivially relocatable or not in compile time). 
It’s classic academic coding style. Some poor schmuck without any development experience has to implement the idea of this paper their advisor wants them to write. You’ll see some of the worst code in academia. 
Yep, it's parsing of JSON by or of itself. /s
&gt;No memory is shared, so value\_ptr is inherently thread-safe. So long as the copy operation is atomic, if it isn't then we cannot be sure we aren't copying a place in memory that is being written to.
since they will be destructed in the opposite order they're listed it can be important if some members have dependencies on others
I can't tell if this is sarcasm.
I guess that would be easily solveable by using std::atomic&lt;std::value\_ptr&lt;T&gt;&gt; similar to shared\_ptr [https://en.cppreference.com/w/cpp/memory/shared\_ptr/atomic2](https://en.cppreference.com/w/cpp/memory/shared_ptr/atomic2) &amp;#x200B;
I'd be more interested in a simdcbor. It's cool you can do this and all, but if throughput is a major concern you should rethink your choice of message format. Maybe this would be useful for writing a really fast JSON to CBOR converter.
I'm not sure what the author might have intended to mean by saying it's inherently thread-safe, but looking at the implementation, it is most certainly not thread safe, inherently or otherwise: https://github.com/LoopPerfect/valuable/blob/master/valuable/include/value-ptr.hpp
Maybe. Are there benchmarks for parsing many, many small json documents? Optimising for that is a different exercise.
Hello Berium. I am really looking forward on how build2 will improve over the time. One big criticism that I have against build2 is that the DSL is way too terse. I would like to give you an insight of my thinking model when I read a build2 buildfile. ``` exe{foo}: libue{foo} libue{foo}: cxx{*} ``` I assume `exe` means `executable` (why do you save 6 characters in a file that you should update once in a blue moon, witch itself can be generated with `bdep new`?). Since `:` is also used in makefiles to create rules, I can deduce that `exe{foo}` should be the declaration of an executable target named foo, witch depends on `libue{foo}`. The target `libue{foo}` itself depends of `cxx{*}` witch most certainly means all c++ files. However I have no clue what `{foo}` means in `libue{foo}`. Or is `libue` a keyword? I checked in the [documentation ](https://build2.org/build2/doc/build2-build-system-manual.xhtml) if `libue` appeared somewhere. You can find it in a buildfile in section "1.9 Implementing Unit Testing", but without any explications. So when I see ``` exe{foo}: libue{foo}: cxx{*} ``` I have no clue what this does. And to be honest, having to open the documentation to read a build file is a real issue. Editing buildfiles may require the documentation, but reading it should be crystal clear. Unfortunately it was in impression that a colleague also had when he took a look at build2, even if I was pretty enthusiastic about build2 at that time.
This is a very long article with a clickbait title for something simple: a smart pointer that copies the object it's pointing at. Basically `unique_ptr` with a copy ctor and assignment operator that get a `new T(*get())`. I'm failing to find a useful use case for this. Most of my stuff that's on the heap has reference semantics and usually can't be simply cloned. For the rest, I'm usually pointing to a base class, so that won't work either. The only thing I can't think of, and that's basically the only example given, is a straight pimpl idiom. But to be used from outside the class, it would actually require the definition of the opaque type at the site where the copy is made, or least anchoring the copy constructor with `=default` at a place where the definition is available. So basically, this can save a few character when copying a pimpl from a translation unit where the definition is available. Unless I'm missing something.
Next-gen filesystems.
What about: https://github.com/jbcoe/polymorphic_value 
Just a quick glance over it looks like yep, that does indeed support what pretty much everyone would expect to happen for copying and also supports propagating ```const```.
Not sarcasm. These four issues are extremely poor practices. &amp;#x200B; &amp;#x200B;
As someone who works in a physics lab, I can confirm.
I may drive up for this! (down in Windsor)
From the doc you refer to: A utility library (u in libue) is a static library that is built for a specific type of a primary target (e in libue for executable).
Very cool! I didn’t know Sparta even existed. But I also live in a cave. &gt; SPARTA is language-independent Also very cool! Has it been used in anything other than ReDex yet? Unrelated: I love this trend of people linking to the Wikipedia page of technical phrases. Someone writes, say, a garbage collector, and there’s a link to the article about garbage collection and to the article for the specific algorithm they implemented right in the readme. It’s almost like people want other people to learn new things!
I've been waiting for this, specifically for the ESP32. I read somwhere that it is coming too. I love CLion, despite its tendency to use all the memory. 
My uni doesn't even teach modern C++... had to learn it on my own. What they teach is an abomination. It's basically C++98 mixed with C functions.
1. Unless it is hidden somewhere, you have to fix cpu throttle in benchmarks 2. How many digits after the dot you're really confident to?
I also still don't get it, and I fully agree that this is a very real issue. So libue is a keyword? It means "library utility executable"? What? Why do I need that in the first place?
Right around the corner! Do it!
Yes it is. "Utility" means a library for an internal usage, like for linking bunch of objects to both "main" program/library and unit test executables. Did you try to read the doc? 
From the documentation you linked to (by doing ctrl-f "libue"): &gt; Let's examine how this support is implemented in our buildifle, line by line. Because now we link hello.cxx object code into multiple executables (unit tests and the hello program itself), we have to place it into a utility library. This is what the first line does (it has to explicitly list exe{hello} as a prerequisite of the default targets since we now have multiple targets that should be built by default): ./: exe{hello}: libue{hello}: {hxx cxx}{** -**.test...} &gt; A utility library (u in libue) is a static library that is built for a specific type of a primary target (e in libue for executable). If we were building a utility library for a library then we would have used the libul{} target type instead. In fact, this would be the only difference in the above unit testing implementation if it were for a library project instead of an executable: So (I think) in your example above, `foo` is an executable which depends on a utility library called (we presume) `libfoo`, which is build from all the cpp files in the current directory? Maybe? 
I use these kinds of smart pointers for type erasure. Think something like ```std::function&lt;T&gt;``` that can be used as a uniform interface for any callable object with signature ```T``` and supports copying... now imagine you had something like ```std::function&lt;T&gt;``` but for any type period and has support for making copies or reassignment just like ordinary values do. That's basically the biggest use case for how I use these kinds of smart pointers. I expose one single public interface ```I``` with many potential implementations and ```clone_ptr&lt;I&gt;``` allows me to treat that interface as if it were a value like any other value just like ```std::function``` lets me treat callable objects just like regular values. I find it to be really useful in practice since value semantics are easy to reason about and compose well with container/collection classes, whereas reference semantics do not.
If build2 wasn't going out of its way to be cryptic here there wouldn't need to be a RTFM on this.
It's gotta be sarcasm. The code works and does what it says on the label. These points a re all style, not substance.
Note that it's not really a "keyword", it's a type of target, like "exe". To put it another way, these are target names that also have a type. The type is defined by the "cxx" module (there could be other types from other modules, maybe yours in the future). So here `libue` is a type and defines how it can be used and how it will handle it's prerequisites (the things on the right side of `:`).
If I understand correctly, your `clone_ptr` would use some sort of virtual `clone()` member function instead of copy constructors/assignment operators? I guess I could see this working in more cases, but it's not really what this `value_ptr` is about. For whatever reason, I'd also feel somewhat uneasy having smart pointers cloning stuff on copy. When I have a clonable hierarchy, I usually have to take great care of how and where I clone them. Again, they also typically have reference semantics.
&gt; And to be honest, having to open the documentation to read a build file is a real issue. I think this is crux of the matter. To quote Bjarne Stroustrup: *For new features, people insist on LOUD explicit syntax. For established features, people want terse notation.* So, as a designer, you have to make a choice. Our choice was to optimize for every day use by people who read and understood the documentation over someone who is looking at the `buildfile` for the first time and couldn't be bothered to read the fine manual. 
A solid implementation of a ```clone_ptr``` uses the normal copy constructor and assignment operator. No virtual ```clone``` method is needed.
Then I don't understand "`clone_ptr&lt;I&gt;` allows me to treat that interface as if it were a value". How do you make a copy when all you have is an interface if you don't use virtual functions?
It's the more the like the prose the where the every the other word the in the text the is the the. There's a difference between being explicit about your intentions and chogging a bunch of code at your compiler to shut it up.
Before you told me I didn't know that reading manual is something bad.
No `libue` is not a keyword. It is a *target type name*. There are a bunch of predefined ones but you can also define your own. And you don't have to use a utility library if you don't need one. You are reacting to an example from the parent which they copied from release notes that showed a completely unrelated feature (target chaining). Utility libraries have their uses, it's all explained in the documentation, but you have to read it.
No amount of reading the manual is going to make the build description language any less bad.
What you do mean by 'name'? If it's not something the compiler understands, i.e. naming the variable or providing a comment, then why wouldn't you just use the actual type and get the compile time safety for the same amount of effort? 
Precisely by using type-erasure. If you're wondering what implementation techniques exist to implement type erasure, that's a non-trivial implementation detail but Sean Parent gives a good talk on what it is and how to use it in C++ in this video: https://www.youtube.com/watch?v=QGcVXgEVMJg
The same way `std::function` does it: type erasure. Meaning, store your own references to necessary methods (copy constructor), either directly in the object, or in the vtable of a hidden templated class you create.
Just write ``` auto my_fancy_variable = my_fancy_variable_type{fancy_expression()}; ``` instead of ``` auto my_fancy_variable = fancy_expression(); ```
Ok, I will volunteer to be the idiot. Can some try to explain to me the difference between a value pointer and a value?
Oh, nobody’s blaming you. If anything, the authors are the victims. 
Hm, didn't know know that you and couple of others are everyone.
I'm using `perf system tune` to fix the CPU. The results seem to be very consistent, I take the median of multiple runs the error is usually below 1/100th. Not that this precisions matters here. But the folly benchmarks above are quite wrong because I didn't set the compiler flags correctly, thus it was not compiled with `march=native` which has disabled a few optimizations. 
That, to me, just seems silly compared to just using the actual type and avoiding all the problems and telling the compiler exactly what it is you want. Sorry. 
&gt; telling the compiler exactly what it is you want That's literally what this is doing. The difference is that this version doesn't cause parsing ambiguities in edge cases.
Using a virtual clone method as an implementation detail is one of the main ways to do this.
Well, a struct can store a value pointer to itself, for example. But not itself.
``` exe{hello}: { cxx}{hello} \ {hxx }{forward types} \ {hxx cxx}{format print utility} ``` ``` doc{INSTALL}@./: install = false ``` ``` ./: {*/ -build/} doc{README LICENSE} manifest ``` Yes, it's just me and like 5 other people. Everyone else in the world thinks this is a fantastic DSL that is easy to read and write for humans. I apologise. 
Thanks. I knew the term, but I don't think I've had to use type erasure myself, and so didn't think of it. I stand corrected that this is a useful variation on the original article's `value_ptr`.
In my opinion that is a poor way to implement it and it's not the technique used by my own library or other fairly well known implementations of ```clone_ptr```. Copy constructor and assignment operator already exists and are well understood, I think it's best to re-use them.
Oh! Thanks for the precision. That's great news!
I'm not really sure what you mean by "copy constructor and assignment operator". That isn't a technique for actually making a correct copy of a type erased object, it's just an interface. The implementation of type erased objects needs some way to call the copy constructor (you wouldn't typically be able to call the copy assignment operator) of the original object before it's been type erased. Inheritance is one way of doing it, or you can do it in more manual ways than basically are similar to hand-spun inheritance, but with more control (std::function typically uses the latter, boost::any uses the former, not sure about std::any).
Fair enough, we disagree then. My own implementation reuses the class' copy constructor and assignment operator and there are other implementations that do the same thing. If you prefer using a virtual clone method to implement then, then that's cool too. I mean the thing about C++ is there's always 10 different ways to do things so who knows what's best, just giving my 2 cents.
From what I can tell, a value pointer has a few other useful properties: * It points to something in the heap * It can be `nullptr` (though `std::optional` can do this for values) * It can be moved cheaply (which may or may not be true for values) * It can be recursive (a struct can't hold a copy of itself) One thing I don't see yet is how a value pointer works with polymorphism, which might also reveal a few other differences.
&gt; Rust, Python, etc. all benefit from the simplicity of having (1 person / small group) in charge and there is only 1 official implementation. How is having implementation-as-specification beneficial? &gt; This inherently complicates things as you no longer can have the "beneficial dictator" in charge. I am happy there is no "beneficial dictator" in charge making arbitrary decisions he deems appropriate. &gt; Can C++ do better C++ already does better. Development of the language is determined by the stakeholders in the industry. Participation is relatively open (everyone can at least submit a proposal), and work of WG is organised according to well-defined ISO rules rather than someone's arbitrary process.
Thanks, it was really hard to find this snippet before you have pasted it. You probably need to also remove all the spaces, not just newlines, to make your reasoning more convincing. 
&gt; These points are all style Strong disagree. These are about maintainability and best practices. Though not show-stoppers, I'd say they are important. Code like this could be riddled with "old-style" bugs when faced with real-world usage. I'm not saying it is but in 2019 `new`/`delete` is a code smell not a style preference.
I think you're still misunderstanding. I don't require the user class to have a clone method. It's an implementation detail only: class any { struct any_base { virtual unique_ptr&lt;any_base&gt; clone() const = 0; }; template &lt;class T&gt; struct any_holder : any_base { T m_data; unique_ptr&lt;any_base&gt; clone() const override { return make_unique&lt;any_holder&gt;(m_data); } unique_ptr&lt;any_base&gt; m_ptr; }; This is a very simple and clean way to do type erasure (and the way that typically is shown in Sean Parent's talks). The alternative to this is basically just emulating the vtable by hand, in one way or another. Almost always more code/messier but can be better performance wise when you are prioritizing the performance of some functions over others.
&gt; I love this trend of people linking to the Wikipedia page of technical phrases. It's almost like people have rediscovered what the "H" in HTML stands for. But snark aside, yeah it's a good thing.
I think the counter argument is that most people do not want to be build system experts. Projects of almost any size usually only have a few people who truly know the build system. Everyone else follows the patterns and focuses on moving the project forward. So I think your are optimizing for the wrong user, for a programming language terse can make sense, for an auxiliary tool it should be more progressively usable. The “80’s” style syntax of build2 crossed it off my list for C++ build systems. Life is too short to learn another esoteric tool, *and* teach it too a bunch of people who just want to do something else.
IMHO this school of thought is a bit anachronistic. 30years ago perl was all the rage, but nowadays a steep learning curve can be a showstopper. 
Site is bit broken on mobile for me
I absolutely agree with this quote *in the context of something that is highly used*. However, you should not spend (unless you are developing a build system obviously) more than 5mn a week in a build system (and I think 5 mn is already way too much). This means that a build system user is never going to be familiar with any abbreviations or weird syntax. I use vim everyday, so `:set nonu` makes perfect sense for me. However if I add it in a config file, I will write `:set nonumber`, because I know that I will nearly never re-read this configuration file. There is also a big difference between verbosity and abbreviations. If you need 3 lines instead of 1 keyword, then yes 1 keyword is much better. If you need 3 or 10 characters, it's the same concision. When I read the meson documentation (for example [this sample](https://mesonbuild.com/Meson-sample.html) or any other samples in the documentation), they were some places where I thought "It could be **a bit** better", but close to 0 places where I had to stop while thinking "What does this means?". However, when I read a build2 buildfile, there is nearly not a single token that I immediately understand (or at all). Build2 has features that I would like to have, like modules support, faster build, being able to run multiple build with different compilers in one command, globing, continuous versioning … But I'm using meson+conan on my personal project because I can understand them. And the fact that build2 is in active development was far from being an issue when I did this choice given that at one point the only compiler that supported a C++20 feature I was using was a 3 days old gcc 9.1.
This is mostly what I came up with earlier, based on sakarri's answer. You both seem to be saying the same thing. What are you two disagreeing on?
I understand what an object file, an executable, a static library or a dynamic library is. I have no idea what a utility library is. Even with the full name of `libue` I still can't understand what the buildfile is doing. And why does `libue` need `{foo}`? What is `{foo}` here?
Having to read a manual to understand a basic feature is a design failure. Having to read a manual to understand the details of a complex feature or to write something is ok.
To be honest, I tried to understand what your snippet could do. I have not a single clue, except that it build an executable named hello from C++ files (I don't know witch one) and that there is some documentation related stuff.
I mean C++ is so complex and you can get little things wrong that have huge consequences that it's hard to really know what's simple and what's complex. I mean sure your approach is simple and clean but has a memory leak since ```any_base``` doesn't have a virtual destructor. Okay so you give it a virtual destructor and now you're carrying this extra overhead, compiler has to generate RTTI for your wrapper, etc... when all you want is one single virtual function. As it pertains to ```clone_ptr```, you use a function pointer to avoid that overhead. I don't think a function pointer is more complex but I don't want to argue the point too hard because as I said, there are probably dozens of ways of implementing these things. Really what was most important was that the object being copied has its copy constructor invoked rather than introducing another virtual method. How you go about implementing that behind the scenes is up to you. If you want to introduce a wrapper class with a virtual method and virtual destructor, go for it... if you want to store a function pointer to a static function... I think that method works better.
That's because this type is misnamed. It should be "heap_value". There are many reasons why you might put some (in this case all) of your data on the heap, while retaining value semantics -- std::string and std::vector being two major examples.
I believe that's a gross mischaracterization of Bjarne's quote. There's a difference between redundant explicitness (`template` in front of all the things that are a template) which is what Bjarne was lamenting and between terseness (`exe` instead of `executable`). Bjarne is saying that we shouldn't have to spend time telling the compiler things it already knows for the sake of users who haven't yet spent the minutes necessary to know that `auto` means a thing must be a `template` implicitly, among other things. Bjarne is not saying is that we should prefer names, like `std::strv` instead of `std::string_view`. There is no benefit to anyone to being terse to the point of losing clarity, not even to experts. Tab-completion means that typing the long-form name takes about as many keystrokes as the short-form name; tab completion actually works better with a longer name since it means I can type `vie-TAB` and still see `string_view` in the drop-down which wouldn't be the case with an extreme shorthand. This is the problem the previous poster mentions with build2. `exe` and `executable` should be the identical set of keystrokes (`exe` vs `ex-TAB`), but the latter is certainly clearer. And this `libue` is an abomination; I can't "find" it by `utility` nor by `executable` nor by `library`, only by `lib` and looking up in the documentation which magic incantation is required. I do expect to have great tab compleition in build2 btw, because as a brand new project in active development in 2019, you naturally have adding an LSP server for build2 so we have refactoring, search, and completion support in all our editors and aren't stuck writing code like cavemen in the 90's, right? :p
Should go in r/cpp_questions
I didn't know this subreddit existed. Thanks.
 &gt; These are about maintainability and best practices. Which is style, right? It's not functional. Nobody's going to re-write existing code that works for this.
If you care that much about "practices" in 3rd party packages, I have some bad news for you.
The overhead is the cost, usually counted in time or memory usage. You should limit it because it makes your program run slower and take more memory. Where it happens is a huge topic. You mostly learn case-by-case until you have a good understanding.
I disagree, this question is fine here. This is not "my program doesn't work, do you know why?".
Maintainability is not "style" but it is a problem for the maintainer to worry about, not the user. 
It's literally a cpp question
Famous last words. Are you saying the code is "done"? There is no such thing. A different contributor adds an early return to a function somewhere and now you've got a memory leak. This kind of thinking is what gets is heartbleed and other vulnerabilities.
Agreed, this code has numerous resource management bugs in regard to the handling of exceptions. It needs to be rewritten in either C style or in C++ style to be usable. In the current state it will be a source of delightfully rare crashes to any program that uses it.
_Overhead_ is time spent not accomplishing useful work. When you call a function, stuff needs to happen to jump to it, then more stuff happens to go back to where you were. In the middle, the content of your function is executed. The stuff that happens before and after is _overhead_. It doesn't do any useful work, it's just there because it's required to execute your function. If the overhead is too high, you're spending most of your time not doing anything useful. For example, calling a virtual function is typically more costly than calling a non-virtual function. The overhead is higher. If you call your virtual function in a tight loop, you can end up spending most of your time calling and returning. A better alternative could be to call it once and put the loop inside the function. Another example would be writing individual bytes to a file. Without buffering, each byte would require a system call, which is typically very expensive. You'd spend more time jumping in and out of the kernel than writing bytes. You can decrease overhead by writing large chunks at once. Whether overhead is a problem or not is highly situational. The rule of thumb is to write clear and correct code first, then optimize if your profiler shows that it's a hot spot. However, it's still something you should keep in mind.
How do you know the code works? If I see something in the style mentioned above (if (p) delete p; ), I would become quite nervous. I become even more nervous when I see manual resource management. NB: Do not look at MY code - I know that we all write awful code sometimes.
A discussion can be in the form of a question. The rule doesn't ban question marks.
Someone said "first make it work, then make it fast". I think that's a pretty good general approach.
I’ll keep that in mind. I was shooed away for a similar style question so I thought that was the policy. 
&gt;over someone who is looking at the &gt; &gt;buildfile &gt; &gt; for the first time and couldn't be bothered to read the fine manual. unfortunately, that leaves everyone who is new to the language with having to learn \*another\* language, just to build an executable... which \*should\* really not be that hard. Also, how is saving a few letters "optimizing"? Do you often edit the build files on your projects? For me that is something very rare...
sounds like it is what CMake calls "object library"? this kind of guessing troubles me, when it is in such a basic step in a build system... I had actually never heard "utility library" as a term before, much less that abbreviation...
It depends upon what sort of overhead you are talking about. More importantly if you are asking this question you don’t really know enough about programming to be asking it. Sorry but this isn’t something that gets answered simply, especially when you take such a broad question into account. More importantly you should read up on the dangers of premature optimization. In many cases optimization to early in the design cycle can lead to bad code. Your first step in optimized code is to learn to write clean logical code that anybody can read. Fail at this and you will never be able to optimize that code down the road. That is even if the code needs it. As you gain experience you will learn to avoid the less than optimal approaches on specific platforms. This isn’t optimizing your code so much as it is understanding howto write properly for a platform. You will also develop a better feelfor which constructs In C++ better fit aproblem at hand. Again not really an attempt at optimizing but rather a growing understanding of C++. In a nut shell it is almost always a bad idea to be thinking about optimizing code before an app is even written. The exception might be library writers or peolple doing kernel level work, but that is not you nor the general programming populace. Frankly the best thing you can do is bury the word optimizing in a dark place for a few years. Initially you will not become a better programmer by focusing on optimization, rather you might become a terrible programmer. Your number one goal should be to learn to write clean logical code that anybody can read. That should be followed by learning the language and Libraries throughly. 
Or you could've used protobuf/thrift/asn.1/cap'n'proto/avro... surely such data has lots of floats (probabilities, etc.) now you end up formatting, then scanning them back (and lose some precision long the way). &amp;#x200B;
The newlines are in there. If you can't see them, whatever app you're browsing is buggy. Don't blame me for that. These are straight copy &amp; pasted from the first few pages of the manual so I really don't want to hear anything about cherry picking. 
The description language really is cryptic... and even though I have even written my own little toy build system (able to even build boost if it were not for the circular dependencies), I also never heard of a "utility library"...
I'm not a fan of control flow without keywords, even though it looks cute.
wat?
i want to create cross-patform GUI library ?
Are you asking if that's what you want?
I've taken to saying: first make it work, then make it fast. If you run out of time half way through that process at least it still works. If you run out of time before you ever get it working it doesn't matter how fast you had it because it's not usable.
What have you looked at so far?
If you’re only concerned about the color, any IDE/Editor you use will probably let you input those colors which you can get from a screenshot 
The sidebar's usually helpful for finding related subreddits: &gt; For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
 &gt; How do you know the code works? The tests are passing. That means someone defined works by writing a set of tests. If they wanted a better or different definition of "works", they'd write better or different tests.
&gt; Are you saying the code is "done"? I don't think I've said that, no.
There are a couple different approaches to polymorphism, all with their own tradeoffs: 1. Just don't support polymorphism. Slice away. 2. Only support types that inherit from some sort of `Clonable` interface. 3. Implement your own type erasure à la `std::function`.
The simplified version: a value will be on the stack (similar to std::array), while a value_ptr will on the heap (similar to std::vector).
Depends on the domain and how you define "fast" and "works". In a lot of domains the choice of C++ is due to the need for performance, and hence slow is entirely useless, whereas fast with a few to-be-fixed bugs is not. While some performance can be gained by profile-&gt;optimise-&gt;repeat, if you have a fundamentally poor design wrt perf, or have thousands of micro-pessimisations throughout your code then that's harder to fix after the fact than bugs. So if performance is important (and it probably is in C++) think about those things from the start: consider compact data layouts, minimising churn on dynamic allocations, using appropriate data structures, interfaces which permit things like results caching or quantisation, code/data structures which permit SIMD/threading/GPU, etc. This is not to say that everything needs to be highly tuned from the start (you really need profiling to know where to concentrate that effort), but it should be tunable. Nor does it mean that the code should not be designed for reliability (e.g. avoid naked new/delete, pointer soup, C arrays, etc.), but reliability and perf are not mutually exclusive. 
Would a more verbose syntax help sufficiently here? executable{foo}: library(utility,executable){foo}: cxx{*} 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/at8v1a/new_student_what_compiler_should_i_use/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's not. It's saying, whatever this thing happens to return, take it. It's not telling the compiler anything explicitly about the nature of the variable. The only thing that will save you is if the subsequent use of it is syntactically incompatible. That may or may not be the case. THIS, OTOH, does tell the compiler what you intend: MyType&amp; myVariable = getSomething(); It's that much more likely to catch errors made during modifications later on. The person reading that knows what myVariable is supposed to be, because I said so. Anyhoo, that's all I have to say about that. Actually, I should be encouraging you to do as much of this stuff as possible. It'll just increase the likelihood that you won't be any competition to me. &amp;#x200B;
I think it's important to teach the style of C++ that you're most often going to see, which from what I've experienced is mostly classic-style c++ with modern bits thrown in.
Practically speaking, how impactful is method calling overhead?
Right. But "fast with a few to-be-fixed bugs" still works. I was more talking about spending so much time trying to get the "fast" part that you never get to anything that works - regardless of how many bugs still have to be fixed with it.
Manual memory management is a perfectly legitimate thing to do in lower level, smaller, high performance chunks of code. I'm constantly flabbergasted at how people act about these sorts of things these days. OMG, having to write a constructor is doing to destroy us, an indexed loop is an abomination, class hierarchies are evil. Sometimes, you have to man up and take off the floaties if you want to write tight, fast code. Not saying this has anything whatsoever to do with this code, I'm just talking about the general attitude I see so much of these days. I'm obviously all for safety, but we are getting paid for our knowledge and experience, and I think any experienced developer should able to safely take advantage of the speed advantages of lower level languages where it matters, so that it doesn't matter so much elsewhere. &amp;#x200B;
&gt; Which is style, right? To me, style deals with white space, brace placement and stuff like that. Basically, things that wouldn't be reflected in the AST, let alone the IR. White space is style. Memory management is not style.
A favorite recent-ish quote of Alexandrescu (paraphrased): "A 1% efficiency improvement in a single service can save Facebook 10x my salary just in yearly electricity costs." Performance matters. Every cycle you spend needlessly is electricity cost overhead or device battery consumption. Json speeds can matter at smaller scales, too. Replacing json with alternative formats has been an active set of tasks my team is working on for optimizing load times in an application. We're dealing with a fairly small set of data (a thousand small files or so), but parsing was still a significant portion of load time. With a fast enough json parser, we might not have had to spend dev time doing this change.
Maybe I worded the question incorrectly but everybody is assuming my skill level and that I haven't written the app yet. I have already built the app in question and I was watching a video on C++ optimization that mentioned overhead quite a bit. I understand what it is abstractly, sure that's somewhat obvious, but I wanted a more concrete explanation so I asked here. &amp;#x200B; "More importantly if you are asking this question you don’t really know enough about programming to be asking it." That's some pretentious bs. I'm not the most experienced developer in the world but I am looking for ways to optimize as I work a lot in the audio domain with real-time DSP. I'm trying to understand EXACTLY what causes more or less overhead so I can be more thoughtful when writing.
That would be nice and dandy if unique_ptr's weren't practically free.
https://i.imgur.com/nxHDRJy.png
But it's also not always what you want to happen. Just because you give someone else a pointer to something, doesn't mean you want to give up access to it.
&gt; It's not telling the compiler anything explicitly about the nature of the variable. Presumably you actually plan on using the variable, e.g.: myVariable.doSomething() If you get the *wrong* type back, guess what? It fails to compile. If "myVariable" comes back as the wrong type and you try to pass it to a function expecting a MyType, it fails to compile. It's very difficult to imagine what kind of scenario you're actually afraid of. You might as well also disallow method chaining: "getSomething().runAction()", because maybe some day™ someone changes getSomething such that calling "runAction" now deletes all the files on your computer. Caveat: no one is saying "always use auto". Just that it's not the pit of despair you make it out to be.
I work on a medium size project with hundreds of integration tests (running executables end-to-end checking they produce expected results) and hundreds of unit tests. Maybe thousands, don't know exactly, didn't count. I recently discovered a critical bug that makes the application crash with a fairly trivial input case that's been introduced in a refactoring more than 3 months ago. "Tests pass" tells you nothing about a project other than that it works in the cases the developers thought of. It's the cases developers didn't think of you need to worry about.
...what are you talking about? You can pass raw pointers around. Just don't pass raw owning pointers. `new` tends to imply raw owning pointers.
It is not really related to C++ either.
Actually, given how many things people do these days with operators and templates, it's not that highly unlikely that they would be syntactically incompatible. 
unique\_ptr is an owning smart pointer, is it not? If so, you can't mix it with raw pointers, that's just asking for trouble. So you can't keep a pointer and give one to someone via unique\_ptr. If that goes out of scope at some point, it will delete the object behind your back. And it uses move semantics, so the original owner no longer has access to the object once it's been coped or assigned to give it to someone else. &amp;#x200B;
Optimizing for DSPs has little to do with optimizing C++ in general.
But you've made my point: refactoring isn't without risk. We might *want* the end-result to be better, but it might not be so despite our best efforts.
I guess that's the difference. To me, style is more than whitespace and brace placement. 
&gt; If so, you can't mix it with raw pointers, that's just asking for trouble. Because...?
A lot of answers I've received could easily be resolved with "choose a better format". JSON for logs seems like a symptom of the industry moving to the lowest common denominator because people could only hire Node.JS programmers.
Sufficiently impactful for the optimization of in-lining a function to exist.
Sounds like they are employing terrible software architects and engineers. If anything, I would actually use this project to convert those large dumps of XML and JSON into a better format and then move the platform to use the better format right off the bat.
The point is we've been running all of our tests dozens of times per day over that entire period, successfully dodging this bug the entire time. Tests are not sufficient. Code quality is important for detecting edge conditions without actually having to run the code.
Is "next-gen" a euphemism for "slow"?
&gt; I'm trying to understand EXACTLY what causes more or less overhead so I can be more thoughtful when writing. the answer is probably specific to your application. you may get better answers asking about profiling techniques. because in general it just comes down to measure, change something, repeat until you're happy. and something thats "a lot of overhead" in one application may be irrelevant in another. personally i get the impression that you may also be interested in knowing more about which operations generally have a higher cost? I am hesitant to even say, but I think memory allocations are a pretty common operation to at least be conscious of, also atomic operations. other things: compact data structures are good, keeping the optimizer in mind at least somewhat (e.g. something like range-for, std::sort, etc. may be easier for the optimizer to work with that something you hand made), branches can get costly, exceptions maybe (like you probably dont want to unwind the stack all the time for no good reason). obv optimizing early is a waste of time and can screw up your code, but at the same time you dont want to be wasteful, so i tried to at least mention some things i consider in a codebase where performance isnt super critical.
&gt;Performance matters. Every cycle you spend needlessly is electricity cost overhead or device battery consumption. Yes, so for the life of me, I don't understand why people let JSON permeate throughout their design in the first place? JSON is great for things like RESTful microservices because it's simple for that use case. On an somewhat related note, it's funny how interviews for jobs tend to revolve around data structures and algorithms, but none related to design sense, like "where would you use JSON". &gt;With a fast enough json parser, we might not have had to spend dev time doing this change. The downside of this, as I've witnessed in many projects, is that delaying the move to better things just makes it harder to change down the line. And down the line, when you've got JSON everywhere for everything and the marginal returns for optimizations diminishes, you're stuck with JSON.
What better formats?
Your recursive implementation is seriously broken. The first line of code dereferences the `begin` iterator without testing if `begin != end`. This fails for an empty range or if the recursion reaches the end of the range.
I confirmed with Arthur this is a mistake 
What? No we can't. Advertising send advertising info in JSON messages. Google OpenRTB.
Was just about to post this
Yes
If you're accidentally mixing syntactically valid types then you've got deeper problems.
Rule of thumb: try to do what you were asked. Need to send a message through TCP to a server? Open a socket and send the damn packet. Do not waste time creating nice frameworks. Good code is working code thatis delivered on time.
If you pass a copy of a `value_ptr` to another thread the copies are completely independent; they don't share any resources. The only way to mess up is to pass a pointer (or reference) to a `value_ptr` to another thread, which you shouldn't be doing (you should aim for shared-nothing except in very special cases). ` unique_ptr` also has this property, whereas `shared_ptr` actively helps you violate the shared-nothing principle. 
A format designed for the use case, and not a general format that happened to be used for microservices. The architects should be doing their job to figure out what formats are out there.
In general, don't let CPU do anything but achieving your goal in time-critical pieces of code. I mean, it's OK to do almost anything in your "OnButtonClick()" handler, cause mouse click is 20 ms long, so if you add 20 ms delay - user won't care. In 20 ms your CPU may perform 20 millions operations, so don't care. But when you're processing each pixel of 20 megapixel image you have to think what you're wasting CPU time for each of those pixels. Using system API, both directly or indirectly will result in a thousands CPU cycles. Using kernel API will waste those thousands cycles on context switch doing no useful work. So, try to avoid IO and heap memory reallocations in long loops. Read once input array and then process. Allocate memory before tight loop and then use. Then you may read "what every programmer should know about memory" and try to don't waste CPU time for waiting for a slow RAM operations. But I'd like to highlight: don't waste your time (lifetime) on unnecessary optimizations. Think about how much time you will save for user. E.g. application startup will take 10 seconds and user starts it once a day. You may work for a week and save for him 9 seconds per day by optimizing by 1000%. This is not a big difference. On the other hand, just 30% speedup when rendering a frame in 3D application is a big deal, because there is a lot of frames, and a lot of waiting time for user. 
I had a professor who always told us to avoid "egregious inefficiency". That is, if you can look at a piece of code and say "this is obviously inefficient and I can fix it with the following quick steps", then it is worth it to do so. Over time, those kinds of efficiency gains become habitual. You just start writing your parameters as `const std::string&amp;` rather than `std::string` by default, because you've done it consciously so many times in the past. However, if you have to spend more than a short amount of time thinking about whether a piece of code is inefficient and how to fix it, then it's probably not worth pursuing unless profiling proves that the code is a bottleneck. The other rule was to never sacrifice readability for efficiency unless it was a proven bottleneck, in which case you leave thorough comments explaining why the code is written in an unreadable manner, and what it is accomplishing.
... :/ That's a non-answer. Of course specifically-designed formats are always going to be better. We used common formats so we don't have to do this.
Why is it a non-answer? That's part of their job as architects. You obviously didn't read the second sentence in my answer - they should look for common formats that are better designed for the use case. I didn't say "design new ones from scratch". &amp;#x200B; A simple Google search to start with is not that hard. Defaulting to JSON or XML means not even an attempt to find out what else is out there. Compared to my "non-answer", your "answer" is practically the lazy way out.
I see, if that's the case then the author misunderstands what thread-safety is. That definition would make ```vector```, ```string```, heck even ```int``` thread safe since you can make copies of them and pass those copies to other threads. Thread safety is a property of the operations performed on an object shared between multiple threads. All of the operations defined on ```value_ptr``` are not thread-safe.
Because big companies who can afford to hire people to write custom formats aren't the only ones that need to use such formats? Yes, there are other formats, but they're usually poorly supported. There's a balance to be had between speed and usability. JSON seems to be that balance (at least if you're using nlohmann json), unless you need high throughput.
It's an owning pointer. If you keep a raw pointer, but make a call to something that puts it into an owning pointer, as soon as that call returns, the owning pointer will delete it and your raw pointer is now invalid. If you go the other way, you keep the owning pointer and pass out raw pointers, then you've accomplished nothing over just using raw pointers to begin with. 
&gt; If you go the other way, you keep the owning pointer and pass out raw pointers, then you've accomplished nothing over just using raw pointers to begin with. Not really. You're making sure every resource gets freed. Unless your code is really simple or you're not using exceptions, something's gonna leak. I'm sure you're gonna disagree though and you probably never write any such bugs! Although somebody in this thread has already identified a few bugs related to this in this library.
That's trivially possible to do if operators are involved. All kinds of classes will have operators. And, for that matter, how many classes have an append method or various other common method names. With auto and templates it wouldn't be that hard for such a thing to happen. Will it happen all the time? No. but that's hardly the point. It's the kind of subtle bug that can be created after the fact by accident, and if the compiler doesn't catch it, it can be messy. Anyway, as I said, that's all I have to say about it. I'm not going to get into a religious argument. I think my way is more robust, and therefore a competitive advantage, so I would hope all of you do the opposite ultimately. 
And if performance is important, learn Data-Oriented Design. The goal of DOD is to optimize to the *advantage* of maintainability and simplicity. So if you need fast code, DOD is a must. [This is a great resource for DOD.](http://www.dataorienteddesign.com/dodbook/) [The most popular CppCon talk (by Mike Acton) is amazing and should be watched 5 times.](https://www.youtube.com/watch?v=rX0ItVEVjHc)
You are risking it gets freed while someone else has a pointer to it, which is the worst kind of bug and the hardest to catch. 
&gt; which is exactly the risk with raw pointers That's far from being the only risk with raw pointers.
In long loops of DSP, it's probably reasonable to think about memory access patterns, cache and data locality per-thread, and CPU branching. CPU has a hardware prefetcher and a branch prediction, so try don't swindle it. Something like 'if (array[other[i]])... else... ' may result in a disaster, because the CPU can predict neither branching nor memory access location here. In case if you're manage to fit data you're being processed in cache - you'll have a speedup. But if you're modifying same data from different CPU threads - you'll have a huge performance penalty. Consider looking into "what every programmer should know about memory". 
The use case was for a bank. Banks, and most other large companies, are the main users of their own volumes of data, with no need for excessively generalized consumption for interchange between companies. For interchange, especially as short messages through microservices? Yes, use JSON (or XML). For GBs of financial data that's mostly going to be used internally? General formats are a poor choice. It's a wonder how you can even consider your "one-size-fits-all" argument is better than my "non-answer".
Except it's not because if your approach is inherently slow then you can't improve on it that much compared to using an actual algorithm.
The author is referring to the basic thread safety guarantee: distinct values can be modified concurrently, and a single value can be read concurrently. https://herbsutter.com/2014/01/13/gotw-95-solution-thread-safety-and-synchronization/ Yes - vector, string and int preserve the basic thread safety guarantee, whereas shared ptr does not (although it does have the basic thread safety property in itself). 
I took an advanced c++ course in my local community college - I was pleasantly shocked to see shared_ptr and threads involved.
Taking parameters by value is great when you want to take a copy for example. If you just want view a string, there's `std::string_view`. I do get your point, but with C++11 move semantics passing by value is often the right thing to do.
And maintenance friendly
You're really reaching here, but I agree that this is devolving into religion and personal preference.
Overhead, in the context of abstractions, is referring to the difference in performance between accomplishing work through an abstraction versus a manual implementation. C++ focuses on providing tools to create abstractions which are no less efficient than writing the code by hand. Virtual method dispatch and exceptions sometimes add overhead, but using templates to describe generic algorithms usually will not.
What about ```shared_ptr``` violates the basic thread safety guarantee? Distinct values can be modified concurrently and a single value can be read concurrently. I will confess I have not yet read the article you linked to, but if the article claims values are thread-safe then I'm inclined to disagree with the article. A value is neither thread-safe or not thread safe, it's the operations performed on a value that can be said to be thread safe or not. ```value_ptr``` does have some operations that are thread-safe, the getter methods, but even its copy constructor is not strictly thread safe, it's only thread-safe if the object it points to has a thread-safe copy constructor. As such I think calling ```value_ptr``` inherently thread-safe is a meaningless qualification. Imagine writing a linked list class and saying your linked list is inherently thread safe because you can copy it and pass the copy to another thread...
The problem here is that there is no easy answer. Suppose for example you are considering OpenCL for DSP work. That is you want to get C or C++ code running on a GPU or other OpenCL supported device. There are all sorts of overhead to consider in this situation. For example is the overhead of data transfer to the GPU so much that GPU computation isn’t worthwhile. This is also very hardware dependent so you need to consider the hardware the code runs on to understand how transfer overhead for GPU compute will be impacted. Then you have data setup overhead just to get the data ready for For GPU processing. In any event there are issues with overhead throughout any programs you might write. Like somebody posted earlier overhead is anything that isn’t directly executing your code. Even if you write your app in assembler and use every trick in the book there will still be overhead. Plus there is no guarantee that you can do better than a C++ compiler. In fact in most cases modern development tools will beat humans trying to write faster code in assembly. There are whole books written with regards to application performance and optimization. So you need to understand why there is little chance of getting credible answers to your questions. In a nut shell one would have to post a book here. There is also another issue here when it comes to DSP like work. In many ways this is hard math not so much computer programming. Optimization is as much about grasping the math and all the associated tricks and shortcuts for the algorithms you are working with. In a very literal sense you need to know how an algorithm can be best arraingement noted for the execution units it is running on. This isn’t exactly programming from my perspective, more multi discpline engineering. 
When you buy concert ticket online and they add 10% fee for doing literally nothing that’s overhead
Obviously it's not the ONLY risk, but the point is that he hasn't gotten rid of the risk by using the smart pointer. 
No that risk, but he's gotten rid of other risks caused by raw owning pointers.
I have a version of this (named \`heap\_value\`) just for recursive std::variants.
I was flippant of course. My version of 'peer psychology' or something. Well, if this a-hole WANTS me to do it the other way, I'll do it his way just to show him. 
I've spent years developing a messaging and serialization library. It's still not done, but it's getting better.
&gt; I do get your point, but with C++11 move semantics passing by value is often the right thing to do. _Only_ if you need a copy of the value anyway; for pure observation purposes, unless the type is very small, const-ref is still the way to go.
There are risks to doing anything pretty much. The point is, there are legitimate arguments for using raw pointers. It's been done since the dawn of computer time, and it can be done perfectly safely if you take appropriate care, and sometimes worth it if performance is a big issue. I mean this IS C++, not C# or Javascript. 
Indeed, I'm fully aware of it. C++ is tricky when you want to avoid copies.
I should really stop arguing with people who love raw owning pointers.
Did I say I LOVE it? No. I avoid it in general as much as anyone else. I just said it's not like it's some crime against humanity if someone chooses to take on the extra burden in some cases for performance reasons, just as most all optimization is something of a risk because it increases complexity. The lower down the food chain the code is, it becomes more justifiable to take more of these risks. The higher up, the less justifiable. I work at both extremes and everything in between. And most of the time the pointer is owned by the class that created it and is never seen outside of it. So there's just not really much of risk to begin with. The owning class, though not a smart pointer, will create it and its dtor will clean it up, so it would be redundant to put it in a smart pointer in that case. It's mostly when they are passed around in some way that it becomes more of an issue. And, if that's in some very perfomance constrained code, and the control points are well defined, it's not like it requires super-human abilities to get it right. 
Graphics programming and making games are pretty separate ideas. If you're interested in creating that amazing particle effect, then making a game in Unity or from scratch won't really include that aspect. If you're interested in making a game which you find fun to play, then C++ or C# or DirectX doesn't really matter, it's about creating a sandbox to demonstrate mechanics, and you're not likely to run into a performance barrier, so just use an existing game engine. It does not take 3 years to learn how to get started making fun games, nor does it take 3 years to learn how to put triangles on a screen. If 3d graphics is the only thing that excites you, then working for a company who will hire you to do that is likely to be the highest paying option. Most people who make their own games are less successful than Jeff Vogel: https://www.youtube.com/watch?v=stxVBJem3Rs However, if you have an uncompromising vision what you want your games to be, consider doing it as a hobby, or take the chance that you will struggle to make ends meet. 1. A small game is smaller than anything you've mentioned here. A game of 2D virtual tag with rectangles for characters can be fun if well-crafted. How long and hard it is to provide the same interactivity and graphics of UE4 depends on the expertise of the person making it. Here is the result of thousands and thousands of hours of effort by someone who knew what they were doing: https://vimeo.com/257396793 From here: https://www.quora.com/How-long-would-it-take-for-one-person-to-build-unreal-engine While not every one of the 700 people at Epic games works on UE4, they've been iterating on their game engine since the 90s. There are many open source game engines available for personal projects including Torque 3D and UE4. Why not start there if you want to make a game engine? 2. I found the APIs for graphics programming such as OpenGL or DirectX to be a pain to use and require quite a bit of effort and mathematical knowledge to get to a result which doesn't look pitiful by today's standards of graphics. However, I also found that the APIs for using certain web frameworks to be mysterious and also a pain to use. It turns out that it takes effort to get anything substantial done. I would say that the result of hours of work doing something in web dev looks more impressive than a similar amount of effort trying to make something happen on the screen if you start from the most basic APIs. 3. C++ has a lot of features, and you don't have to use all of them. C# and JavaScript also have a lot of features. Companies hire developers to make new things in C++, so I think that means that it's not obsolete. The game engine you use will have a larger impact on your ability to be productive than the language it's written in. 4. Crysis and Unity game engine have different goals in mind. People have made some pretty amazing games in Unity, and some of them are fun to play on smartphones. There's a lot of performance decisions to be made in making a game engine which have a bigger impact on performance than the language the engine was written in. Making games isn't about C++. Making graphics also isn't about C++. There are a lot of things that you will need to know to make graphics or games which are important and harder to learn than the language you happen to be writing in.
&gt; Did I say I LOVE it? No. No, you said there are valid legitimate arguments for using them then proceeded to spout nonsense. &gt; It's been done since the dawn of computer time Not an argument. &gt; it can be done perfectly safely if you take appropriate care everything can be done perfectly safely if you "take appropriate care." Yet leaks and bugs always happen. Those can easily be avoided with `unique_ptr`. &gt; sometimes worth it if performance is a big issue What performance gains do you get from using raw pointers over unique_ptr? &gt; it would be redundant to put it in a smart pointer in that case Until you forget to delete it. Which I've seen far too many times in far too many projects to just be told "oh you just need to be careful." No. It costs practically nothing to use `unique_ptr`. &gt; it's not like it requires super-human abilities to get it right. Heh. Most bugs in software are just silly mistakes. We use constructs to help us avoid those mistakes.
As pointed out, unique_ptr uses move semantics. If you ever need to copy or assign it, or do it by accident, you are screwed. If it's purely within the class, then OK, you will probably be ok. But the compiler isn't going to tell you if you mistakenly assign it and the original is toasted until it happens you get a null reference when you reference the original. You could use a counting pointer, but then it's definitely not free, and folks who work at a really low level would laugh at you if you make these arguments. Different tools for different jobs. Everything has risks and nothing is going to prevent it. 
Found the unionized programmer
I feel you. And JavaScript is taking it all to the cancerous extreme :)
More like the entrepreneurial programmer.
&gt;const int threads_num = std::thread::hardware_concurrency(); &gt;std::thread pool[threads_num]; [std::thread::hardware_concurrency](https://en.cppreference.com/w/cpp/thread/thread/hardware_concurrency) isn't `constexpr`, so this is a VLA which isn't even C++...
The difference is that `shared_ptr` offers another operation - indirection - which can result in thread unsafe operations. Raw pointers have the same issue, but `unique_ptr` and `value_ptr` do not - indirection through them gives access to a value which is distinct if the pointer is distinct. That is, they preserve the basic thread safety guarantee with respect to the pointee. `shared_ptr` does not, since distinct pointers can have the same pointee. Indeed, a linked list also has the basic thread safety guarantee - most classes do! It also preserves the basic thread safety guarantee with respect to its elements, as containers do in general. It would be great if you were to read the article. Having a common vocabulary is essential to communication, and Herb Sutter has done more than most to establish the terminology. The GotW series are classics of the genre. 
As I'm still learning modern C++, I often don't know how to even go about making it faster, so I focus more on refactoring and organizing my abstractions. Once all of my files are not too long, and all of my functions as well, then I'm happy. Hopefully down the road, a well organized project will be much easier to make fast.
I did read the article and your interpretation of the basic thread safety guarantee is significantly broader than what Herb defines in that article as well as what is specified by WG21's definition below: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2669.htm The basic thread safety guarantee is a property of the operations performed on a value, not of a value itself. Every value you can imagine, including even an ```atomic_char``` can be involved in a thread unsafe operation. That guarantee is defined as follows as per the link I gave you: &gt;The basic thread-safety guarantee would be that standard library functions are required to be reentrant, and non-mutating uses of objects of standard library types are required to not introduce data races. Note that the guarantee is about functions, not about values. It's like the basic exception guarantee... you don't say that a value or a type provides the basic exception guarantee, rather you say that a function provides the basic exception guarantee. As per WG21, unless explicitly noted, all functions in the standard library provide at least the basic thread safety guarantee, including operations on ```shared_ptr```.
Overhead can be many things in many contexts, but something that is accepted in C++ community is: - overhead compared to hand-written code - there should be no place for anything other than assembly between C++ and machine code. So, if you can do better with your own abstraction than by writing a generic piece of code, it could be considered kind of a "bug" in some circumstances. In C++, for example, this: struct MyStruct { int a; float b; }; unique_ptr&lt;MyStruct []&gt; arr = make_unique_default_init&lt;MyStruct[10]&gt;(); //... should be the same as this (even safer actually the one above): MyStruct * arr = new MyStruct[10]; //... delete [] arr; The layout will be what you expect, all packed, no hidden costs. unique_ptr is one pointer, the deleter is not stored (it is a template specialization) and you have to call anyway new and delete. Also, since you do not want to initialize that array (maybe you want to use it as a buffer) you use the default_init variant. Result: no hidden initialization (AFAIK), new and delete called for you, exception-safety (extra feature!) and same code generated. 
Thanks, I was looking for that paper. The paragraph I'm interested in is on constrains on programs : &gt; It is undefined behavior if calls to standard library functions from different threads: - share access to an object directly or indirectly via their arguments, including this, and - at least one of the arguments accessing a shared object is non-const, and - one call does not happen before the other ([intro.multithread]). If we only use container like types including exclusive pointers, or even const propagating pointers, then we will never fall foul of this rule. But if we use non const propagating raw or shared pointers then via const arguments we can end up mutating an object concurrently , or accessing it while mutating it concurrently. You may be right that this is going beyond what's in the paper or article. But I think it's an obvious extension or corollary. I'd be happy to use a more precise term if that'd help - transitive basic thread safety? 
But are they parsed in bulk, or individually?
Just got the second edition. Could someone explain the code in Listing C.7 incoming.wait() .handle&lt;withdraw_ok&gt;([&amp;] const withdraw_ok &amp;msg{...}) .handle&lt;withdraw_denied&gt;([&amp;] const withdraw_denied &amp;msg{...}) .handle&lt;cancel_pressed&gt;([&amp;] const cancel_presses &amp;msg {...}); What aspect of the language is being exploited here to cause only one handle&lt;T&gt;() function to be called? &amp;#x200B;
Thnks, for all I put your comments as part of post and fix recursive solution. **VLA** seems to be interesting too, I heard about that but I somehow expect that number of cores is **constexpr** but it make sense for the future try to define something as **constexpr** if you think so. I see now from implementation that it depends on **POSIX** calls. So that's the reason but it still must be the same value. As it is hard to adopt a new core during the runtime?
For what it is worth, I think you made the right decision. 
Terseness it's not about faster writing. Everything equal it also makes things easier to read. SNR (signal to noise ratio) is a very important aspect of readability. strv would indeed have been a better name for a type that is going to be used all over the place. A programming language should be optimized for people using it (and hence getting familiar with it) and not for people that want to decide after 5 min looking at some random code if they like the language. 
Reading your comment elsethread, I may have grossly underestimated your skill level and my comment above may be mostly useless to you. I'll try to come up with something better, but I'm mostly making this up as I go. I can think of three major categories of overhead: the system, you, and all the crap in between. ### System There are things you can't generally change, I call it "the system". There's nothing you can do to fix those, except by _avoiding_ them. - Calling a function requires pushing registers and arguments; - Calling through a function pointer requires an additional read; - Executing a syscall uses some sort of software interrupt and needs some context switching, sometimes having to block the process and do a full context switch to another process until data is available; - Unaligned reads and writes; - Any time there's a [CPU cache miss](https://en.wikipedia.org/wiki/CPU_cache#Cache_miss), data has to be read from RAM, [which is very slow](https://stackoverflow.com/q/9936132/4885801), and some cached data will have to be evicted; - [Branch prediction may fail](https://stackoverflow.com/q/11227809/4885801); etc. Inlining, functors, buffering, [locality](https://en.wikipedia.org/wiki/Locality_of_reference) and the elimination of branching are possible solutions to the above. However, aggressive inlining may reduce the overhead of function calls, but they'll likely increase the number cache misses, for example. You have to learn about these potential problems and try to circumvent them if they become problematic. ### You Then there's you, with all the overhead _you're_ putting into your program: - Error checking; - Recalculations instead of caching; - Bad algorithm choices; - Heap allocations that could be on the stack; - Too many `shared_ptr`; - `vector` instead of `array` when possible; - Linear searches in a large container; - Binary searches in a small container These are things that are ultimately "bugs", that is, they're a problem introduced by the programmer. These are usually pretty easy to fix and can sometimes make a huge difference. ### The rest Then there's all the rest, all the crap you can't really see: - Objects being unnecessarily copied for parameters, return values or locals; - Conversions; - Thread synchronization, starvation; - Exception handling; - RTTI; - Missed or overaggressive optimizations Plus all the stuff in the "you" section above that's not actually written by you and is hidden deep in the dozens of libraries you're using. This stuff is hard to find. They usually slowly slip through your fingers on profiling, when you go deeper into function calls from a hot spot, but without ever seeing anything egregious. The language itself can help, for example with move semantics or copy elisions. Sometimes a large chunk of code may benefit from being redesigned from scratch, sometimes it gets worse. What should be obvious by now is that there is no real solution to "overhead" or inefficiencies in general. You have to regularly profile your code and learn about potential issues and keep them in mind while you're writing. This comes with experience and by reading about other people's problems. Read this subreddit frequently, sort StackOverflow by votes and read all the questions from the first 50 pages, subscribe to its RSS feed, read blogs. Do your homework by staying up to date and by learning from other people's mistakes. 
If you use function pointers you need one pointer per function per object (e.g. 3 pointers if you want to support copy construction, copy assignment and destruction). Inheritance only uses a single pointer per object and one pointer per function (in this case, 3 per erased type), so instead of an N*M overhead, you get N+M*T (N being the number of objects, M the number of functions the wrapper supports and T the number of erased types). So I'm not all that sure if the function pointer version really is less overhead - especially not if you have many objects of the same type.
&amp;#x200B; CamelCase is the last on the long list of problems I can see there. Generally I am using your confused "project" to try my C++ lib "in the wild". You are young and you are doing right things in the right time. But please devote some more time to the quality of the content of your offering which is code (C++). And perhaps programming in general too. It is very good you have added UML to the project. Although there is a "room for improvement" over there too. Your packaging is very good and this is why you have stars. Understand not , this as unfounded critique. If you want to gain something from my fork please do proceed in the issues section of it on the github ...
This is 100 times better. I still don't kown what a utility executable library is, but I don't have the feeling to read something in an odd foreign language. This look familiar enough to make me open the manual because I want to understand more precisely what this is, not because I need to understand the basic meaning of this expression.
I'm a fan of everything that makes c++ code less verbose and increases SNR. If the stuff here would be useful in my code, I can't tell (we use exceptions most of the time)
Come the fuck on
&gt;If I see something in the style mentioned above (if (p) delete p; ), I would become quite nervous. How do you get any work done? 
Yes, exactly. This should have been my reply ;-). To add to that, people seem to be fixating on syntax of the core, fundamental elements of the language (targets, prerequisites, dependency declaration) which is something that appears repeatedly in any non-trivial `buildfile` and which is something that we've made quite terse because, realistically, if you are going to use `build2`, you will need to learn those things. On the other hand, more obscure things (say, variables that contain options, such as `cxx.coptions`, `cxx.poptions`, etc) are quite a bit more spelled out. 
Thanks, I appreciate the kind words. I suspect quite a few feel the same but since it's not a "problem" for them, they don't feel the need to express it. BTW, I've asked on the slack channel for feedback from those who've actually used `build2` on real projects.
The point is you don't know at **compile** time how many hardware threads are available. I could compile on my pc then run on yours, and as long as they are both the same architecture (probably x86_64) that would work fine, even if one of us has 4 cores and the other has 2. You are right of course that this won't change in the middle of a single run of your program. (Actually, I wonder if it can in theory... in some virtual environment or [IBM hot-pluggable cpus](https://www.ibm.com/support/knowledgecenter/en/SSZJY4_3.1.0/liabp/liabpprocessorhotplug.htm)?)
Someone who is learning c++ will not need to understand the example discussed here in order to use b2.
I already answered to all the questions about my coding/design in your first post. But no: despite the picture of my profile, I'm not young at all and I have quite a lot of experience in software industry and academy. I give talks at conferences and write articles on peer review journals. Bottom line: who likes my library can use it freely, who finds bugs or wants new features can open issues or open a PR. People who don't like the library can go on and don't waste my and their time.
what about complex and valarray ? content of &lt;random&gt; and &lt;filesystem&gt; ? &amp;#x200B;
Individually via HTTP
I really like that suggestion of reading the top-voted SO questions! I just had a look, and it seems like a great way to learn to avoid common mistakes, and interesting techniques. It's like a Scott Meyers book. (In fact, isn't that pretty much how he wrote the first one, albeit with newsgroups instead of Stack Overflow?)
Using other people's misery for your own benefit is always a good trick.
[removed]
Overhead is the wrong thing to consider, at least until you are within about 20% of your performance goal. First, make sure you have the right data structure and algorithm. Overhead comes in when, for example, you realize that for N=5 and your particular program, a linear search over a vector actually beats unordered_map.
Before optimizing, make sure you have a performance goal. Stop when you reach it. That's not to say you should write gratuitously inefficient code before then, but maintainability and readability are more important.
Yeah, it also mixes new/delete and malloc/free (see jsonparser.cpp for a malloc) in the same code base which immediately makes me nervous. &amp;#x200B; This code does not appear to be safe either, it passes multiple buffers as pointer + length instead of making use of safer abstractions. This is also not something that would hinder performance if it is done. &amp;#x200B; It is a nice idea but the implementation could use a lot of improvements.
But where is the actual compiler?
Okay thanks! Maybe it was an a bit too "complicated" example to show target chaining, people not familiar with build2 will read the release notes (particularly if they're posted on reddit), and then see this example "out of context", and then the confusion starts and people including me start to argue that such a simple example should be self-explanatory (without having to read the docs). Anyway you got my upvote, not sure why people would down-vote that post.
Okay, so it's a pre-defined target type name. It sounds like exactly what the cmake-equivalent of _object libraries_ would be. These are not often used in practice and not the most used or most seen concept. Perhaps there would be a better example to illustrate chaining, which is more common and to which people can related more easily, without having to read the docs first, know what a utility library is, and a target type is?
Since it's based on llvm, it's probably built on top of clang.
I can believe that, but where is it?-) The repository only contains that README and examples. seanbaxter doesn't seem to have other relevant repositories.
It seems to be not released yet, from the README: &gt; The Circle compiler is nearing the end of private development. I look forward to a public release.
&gt; But I'd like to highlight: don't waste your time (lifetime) on unnecessary optimizations. Think about how much time you will save for user. E.g. application startup will take 10 seconds and user starts it once a day. You may work for a week and save for him 9 seconds per day by optimizing by 1000%. This is not a big difference. &gt; &gt; On the other hand, just 30% speedup when rendering a frame in 3D application is a big deal, because there is a lot of frames, and a lot of waiting time for user. The good old [Amdahl's law](https://en.wikipedia.org/wiki/Amdahl%27s_law) is also useful when doing simple calculations regarding speedups gained by optimizations.
This is a really interesting project! Hopefully the compiler will be out to play with soon
Perdon me to be skeptical, but a single guy doing an enhanced C++17 compiler front end, without apparently using CLang, in 100000 lines of code, and without showing source code...
Well as a user I only used `libue` once and chaining makes sense in these cases where one target is basically just a different version of the same thing (in the example the library is generated for unit testing probably, but what we really want as an end product is the executable version). I don't remember a simpler example in my experiments with build2 though I didn't try chaining yet so I don't know the limitations (like would it work to do `exe{myprogram} : cxx{main} lib{libprogram} : cxx{**}` ? I don't think so but I didn't have time to even read the new section of the manual. If it worked, then that would be a better example (because the confusing part is `libue` and why it's useful, but a bit contrieved to do that instead of through 2 lines).
&gt; BTW, I've asked on the slack channel for feedback from those who've actually used build2 on real projects. That's subject to survival bias. 
This looks like everything I ever wanted before I knew lisp
I mean it for sure looks like some impressive work. That being said - he just states he's using a custom C++ (clang) frontend. I wouldn't imply from this that his custom frontend isn't build on top of clang.
The source code is available at the following address: [https://github.com/PardCode](https://github.com/PardCode) 
isn't that something to let the compiler worry about for you?
/r/d_language
The documentation is a really interesting read. Lots of good idea. I don't have time to beat up on it yet, but it's not obviously stupid, aside from the intrinsic "inventing a new language only works out 0.1% of the time if that" problem. Let's see what the compiler is like! 
Hey I think r/cpp_questions is better for this type of question. Also I think people will need your build command do diagnose linking errors.
That is the issue with to much automation. The compiler correctly identified that there is no reason to existence and optimized away all possible program output. Resulting in the whole source tree to be optimized away.
I wonder what this is? [Opens `main.cpp` and looks at the very first non-include line] const char* __author__ = ... [Welp](https://en.cppreference.com/w/cpp/language/identifiers).
Not even slightly. D has introspection, but not complex generation. 
Thank you for the response! When you say some binaries would these be files included in the Lua download file? 
[Yes it does](https://dlang.org/articles/mixin.html).
Your fix for the recursive implementation still has a bug. If the recursion reaches the last element of the range the call `any_of_aux(++begin, end, predicate);` is the same as calling `any_of_aux(end, end, predicate);` and your code then dereferences the first iterator.
What? You can literally compile in constexpr strings with mixins, D has the most powerful CTFE and code generation features out there. This has been used for things like ctRegex (see talk [here](https://archive.org/details/dconf2014-day01-talk04)), which takes a statically known regular expression and creates a specialized type at compile time. 
Would you agree with me that from an initial glance, basically `@meta` is `constexpr!` if taken to its fullest logical extent? So because he's fleshed out the constexpr interpreter to execute any C++, `constexpr! printf(...)` simply executes by interpretation during the compile. Once you have a full fat C++ interpreter, then all the introspection, reflection stuff is dead simple to implement, at least for a subset of possible architectures and platforms. Though, I wish he'd chosen to replicate the proposed Reflection TS syntax personally. Putting on my WG21 hat for a moment, most of WG21 are aiming to reach this one day, where most of any possible C++ can be executed either at compile time or runtime. Implementing that is in fact quite easy. It's the *mixed mode* which is really hard, so how exactly ought compile-time and run-time execution interact? What's possible? What's reasonable? What's safe? That's why WG21 will take at least until 2030 to reach maximum constexprification, because where and how to draw that demarcation line is *hard*.
Didn't this already get deleted once?
I deleted it.
This looks like the default syntax highlighting in Visual Studio.
Thank you, I noticed too, with slight differences but I really don't know the name of it. I searched visual studio ide light syntax but found nothing. Thank you for your time chaosmeist3r
What are the pitfals of `++`? 
I propose the name AAAA: almost always avoid auto
Yea I don't know much about lua or windows but typically when you download a library that isn't "header only" it will come with some build instructions to build and install the library. On Linux you get a .so or .a file that represents a compiled library, idk what the windows equivalent of that is (dll?). Maybe see the instructions that came with the lib, if you already built and installed the lib maybe see if there are instructions for linking with your project
&gt; Note that no compiler will warn you for using that code, because T(x) is actually a C-style-cast in disguise. And C-style casts should really get deprecated, because they are an abomination! There is another problem here: `T(x)` is very often used in templates so that it can both call constructor where `T` is a class and just form a built-in type when `T` is not a class.
The core thing is that attributes can be applied to the smallest entity possible - 1 specific overload or 1 specific specialization.
Reflection is a potential place to make TMP in C++ much better.
Try to put `extern "C"` around the lua include, like this: `extern "C" { #include "lua.hpp" }` It'd not be the first C library to ignore C++.
Yet in reality compile-time calculation is (expectedly) mainly used in two situations: 1. tblgen 2. constexpr calculation. I don't need a perfectly working example of complie-runtime interaction - just leave it stupid and give me something like compile_printf() which literally prints a string to source file before all other stages executed.
Assuming this lives up to app it's promises, I can easily see this becoming my primary development language instead of "plain" C++. In general, it seems that this is full of ideas that are really necessary for C++ to reach it's full potential, but that the committee won't get around to adding for at least another 6 years.
Even before you look at the atomics, Dekker is supposed to take turns, your algorithm doesn't, Also, thread::yield is pointless.
I did try this however I believe the lua.hpp file is used for cpp now. I think extern c is only used in the case of the Lua.h and co. files.
Will C++ compilers eventually turn into an adhoc lisp systems with labyrinthine syntax?
This is not correct in its provision of mutual exclusion - you need `memory_order_seq_cst` on the stores as well. Since in general you would also want to not just provide exclusion, but also synchronization between the critical section contents, you want at least `memory_order_release` on the unlock portion. As the other reply notes, this is not actually Dekker's algorithm; it's possible for it to livelock even if all the memory orders were `seq_cst`.
&gt; It's saying, whatever this thing happens to return, take it I really don’t know how many different iterations of “using auto does not in any way prevent you from exactly specifying the type you were expecting” you need before you get the point.
adding yield in the else section makes it take turns fairly.i already modified that part.
I've been working on something that's a mix of closed and open source code for decades. I've also been encouraging people to not neglect working on closed source projects. So you can blame me for this person having the chutzpah to think that they deserve to be compensated for their labor. Years ago on comp.lang.c++, I said something like: pay me now or pay me 1000 times more later. 
I ran your program and it didn't take turns. Using thread::yield is basically always an error.
How about this: #include &lt;iostream&gt; #include &lt;atomic&gt; #include &lt;thread&gt; using namespace std; const int COUNT = 10; int main(int argc, char** argv) { atomic_bool f1{false}, f2{false}; thread t1([&amp;]() { for(int i = 0; i &lt; COUNT;) { f1.store(true); if(f2.load() == false) { cout &lt;&lt; "T1 in critical section" &lt;&lt; endl; ++i; } f1.store(false); this_thread::yield(); } }); thread t2([&amp;]() { for(int i = 0; i &lt; COUNT;) { f2.store(true); if(f1.load() == false) { cout &lt;&lt; "T2 in critical section" &lt;&lt; endl; ++i; } f2.store(false); this_thread::yield(); } }); t1.join(); t2.join(); return 1; } 
here's my output: T1 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section
here's my output: T1 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section
Often times book authors manually create their own syntax highlighting specifically for their books. If you want this exact syntax you will likely have to create it yourself with your IDE.
Blasphemy. Everyone knows that its your responsibility to live like a pauper so that they can have stuff for free.
To be honest, I am uncomfortable with the `gmtime` example. I really like reproducible builds, so non-reproducible reads seem like an excellent way to shoot oneself in the foot to me :/ Regarding the challenges of cross-compiling compile-time evaluation, I seem to remember that floating points are especially tricky to handle if one wants both compile-time and run-time evaluations to yield the same results. And of course, there is the grand question of memory allocation... allocating memory is fine, but using the addresses is a mess. If the user has a `unordered_map&lt;void*, int&gt;` and iterates over it at compile-time: how do you guarantee they always see the same sequence of numbers? Because if they do not, once again the build is non-reproducible... :/
Be careful of atomics. For example, in a multi-threaded program, copying a `std::shared_ptr&lt;T&gt;` is surprisingly expensive, even if the atomic to increment is already in cache and uncontended. The issue is that atomic operations impede pipelining, so while the atomic increment itself is fast, there are delays around the actual operation :/
Not sure why output matters, but here's what I got on my first try (with gcc/linux) was T2 in critical section T1 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T1 in critical section T1 in critical section T1 in critical section T1 in critical section T1 in critical section T1 in critical section T1 in critical section T1 in critical section T1 in critical section 
can you try this version, it creates the threads close to one another: #include &lt;iostream&gt; #include &lt;atomic&gt; #include &lt;thread&gt; using namespace std; const int COUNT = 1000; int main(int argc, char** argv) { atomic_bool f1{false}, f2{false}; auto proc1 = [&amp;]() { for(int i = 0; i &lt; COUNT;) { f1.store(true); if(f2.load() == false) { cout &lt;&lt; "T1 in critical section" &lt;&lt; endl; ++i; } f1.store(false); } }; auto proc2 = [&amp;]() { for(int i = 0; i &lt; COUNT;) { f2.store(true); if(f1.load() == false) { cout &lt;&lt; "T2 in critical section" &lt;&lt; endl; ++i; } f2.store(false); } }; thread t1(proc1); thread t2(proc2); t1.join(); t2.join(); return 1; } 
clang, not c-lang
"close to one another" is not meaningful in multithreading. The output I got is about the same mix of runs of 1's and 2's and occasional alternations (only much longer because you made it 1000 iterations)
I don't know where the difference is coming from. mine behaves fairly on release and debug builds on both my Mac and windows machines.
I don't know why you expect them to alternate. There is literally no reason for them to do so. Your T2 can do all 1000 iterations and complete before T1 makes it to its first f2.store(true). Or the other way around.
I tested with GCC, Apple's CLANG, and latest LLVM; look at the difference in behavior: ************************************* * GCC -Ofast -march=native -lstdc++ * ************************************* T1 in critical section T1 in critical section T1 in critical section T1 in critical section T1 in critical section T2 in critical section T1 in critical section T1 in critical section T1 in critical section T1 in critical section T1 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section T2 in critical section ****************************************** * Apple CLANG -Ofast -march=native -lc++ * ****************************************** T1 in critical section T1 in critical section T2 in critical section T2 in critical section T2 in critical section T1 in critical section T2 in critical section T2 in critical section T1 in critical section T2 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T1 in critical section T2 in critical section T2 in critical section T1 in critical section T1 in critical section T1 in critical section ***************************************** * LLVM CLANG -Ofast -march=native -lc++ * ***************************************** T2 in critical section T1 in critical section T2 in critical section T2 in critical section T2 in critical section T1 in critical section T1 in critical section T2 in critical section T1 in critical section T1 in critical section T1 in critical section T2 in critical section T1 in critical section T2 in critical section T2 in critical section T2 in critical section T1 in critical section T2 in critical section T1 in critical section T1 in critical section 
could you also try this variant that works for 16 threads please? #include &lt;iostream&gt; #include &lt;atomic&gt; #include &lt;thread&gt; #include &lt;vector&gt; using namespace std; const unsigned int COUNT = 10; const unsigned int THREADS = 16; const unsigned int THREAD_MASK = 0b1; int main(int argc, char** argv) { atomic_uint flag{0}; auto proc = [&amp;](int t, unsigned int thread_mask) { for(int i = 0; i &lt; COUNT;) { if(flag.fetch_or(thread_mask) == 0) { cout &lt;&lt; "T" &lt;&lt; t &lt;&lt; " in critical section" &lt;&lt; endl; ++i; } flag.fetch_xor(thread_mask); this_thread::yield(); } }; vector&lt;thread&gt; vt; for(int i = 0; i &lt; THREADS; ++i) vt.emplace_back(proc, i, THREAD_MASK &lt;&lt; i); for(auto&amp; t : vt) t.join(); return 1; } 
 i gt wat ur sayn, jst dnt agre wit ya
When I look at a new language, I ask "what can this tool do for me, how can I use this to make my life better?" But C++ people especially seem to be hellbent on the question "how can I break this". I don't get this mentality. If you found a way to make the build non-reproducible, and you want reproducible builds, then find another way.
Make sure you link lua.lib and define "LUA_API" to equal "__declspec(dllimport)".
Lets you swap out menus around a state-machine like system. I like the design choice you as well. Nice work
In my experience, implementing the permissive meta context was much easier than implementing the not-actually-restrictive core-constant-expression context (i.e. the context of constexpr functions). There, constexpr enforcement is really done in the interpreter, rather than at definition. The standard requires only that there be some set of arguments for which the constexpr function evaluates in a core-constant-expression fashion, which I find a rather flaccid kind of contract. Instead of dealing with an increasingly complicated and nuanced set of constexpr carve-outs, I just provide the meta context and let you do anything you want. I think it's a very good feature that reduces cognitive burden on the user. There are some decisions to make on how to mix meta- and real-valued expressions, but I don't think it's that hard, either to implement or to understand as a user. Something like argument deduction through alias templates? Now that's hard. The clever bit of design is that meta control flow statements open a porous scope allowing real declarations to fall through and deposit themselves in the innermost real scope: template&lt;typename... types_t&gt; struct tuple_t { @meta for(int i = 0; i &lt; sizeof...(types_t); ++i) types_t...[i] @(i); }; I haven't gotten the sense that there's movement to build out C++'s imperative metaprogramming constructs, at least to the degree that Circle does. The motivation behind the meta scope was to use reflection to produce the exact same class definition as if you had written the class by hand (like the flat tuple class here). It's understandable to think of meta as "constexpr minus the const," but I see it more generally as a set of tools for data-driven imperative code generation. Why does meta include a full interpreter? The data-driven part needs data, and you need to do real work with side effects to produce that data--like parse a file.
It's actually quite a basic example. But from my perspective the level of complicated build files makes it too challenging for beginners for even simpler tasks and to get started. Even myself, I feel like I want to use build2, but then I get discouraged by the necessary effort for the most simple tasks. I believe it's instead a great tool for really complex tasks, if you know it well enough.
Part of the slowness of the parallel solution is surely from thread creation and the use of mutexes, but part of it is also because you don't have an early out anymore. The sequential version stops at the first 'true', while the parallel version always checks everything. 
Do I define this in the header file?
Why do you need a name? Just change the colours yourself.
&gt; then it's just as easy to argue someone will forget to assign it to the pointer. No that's much harder to argue. :( A null-pointer reference is easy to catch. A memory leak isn't.
You're being downvoted because it's off-topic.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
/r/cscareerquestions 
Stop spamming. This is your last warning.
You can #define it in your code before you #include lua.hpp, but the better way is to add it to your compiler options (i.e. "/DLUA\_API=__declspec(dllimport)" in msvc).
This looks really interesting.
I really recommend that you take a look at Haskell's fancy macro mechanism, known as template haskell. It works by allowing you to define functions which return an object of type AST. Whenever such a function is called with a dollar sign before it, the compiler calls it during compilation and replaces it with the AST that it returned.